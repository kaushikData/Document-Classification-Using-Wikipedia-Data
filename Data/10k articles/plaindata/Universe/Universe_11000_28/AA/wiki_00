{"id": "42092473", "url": "https://en.wikipedia.org/wiki?curid=42092473", "title": "Aero-propulsion Systems Test Facility", "text": "Aero-propulsion Systems Test Facility\n\nThe Aero-propulsion Systems Test Facility, located at Arnold Engineering Development Complex is a unique national facility designed to test aircraft propulsion systems in true mission environments without leaving the ground. The test unit is owned by the United States Air Force and operated by National Aerospace Solutions.\n\nThe need for an advanced ground-based, propulsion test facility was identified by a joint NASA and Department of Defense Aeronautics and Astronautics Coordinating Board in the 1960s. The Aero-propulsion Systems Test Facility was specifically designed for testing integrated, full-scale propulsion systems under simulated flight conditions. Construction begun in 1977 and took seven years to complete. Following integration and activation, the facility reached initial operational capability in September 1985.\n\nThe Facility can simulate altitudes up to 75,000 feet, at speeds up to Mach 2.3, for engines rated up to 100,000 pounds of thrust. The air supply compressors can provide up to 1,500 pounds of air per second into the test cell to simulate airspeeds up to 1,800 miles per hour. The compressors, totaling 215,000 horsepower, are started by one of the largest variable frequency starting systems in the world. An additional 960 pounds per second of airflow is also available by drawing outside air directly into the C-2 test cell.\n\nInlet air to the tested propulsion systems can be conditioned up to 450 degrees Fahrenheit by large combustion air heaters. These heaters can burn either diesel fuel or waste aviation fuel and generate up to 1,000,000,000 BTU per hour. Exhaust gases are cooled by direct-contact water spray, which reduces the temperature to 200 degrees Fahrenheit. Additional water spray cools and cleans the exhaust gas to less than 150 degrees Fahrenheit before it enters the exhaust compressors.\n\n\n"}
{"id": "48680511", "url": "https://en.wikipedia.org/wiki?curid=48680511", "title": "Agrivoltaic", "text": "Agrivoltaic\n\nAgrivoltaics is co-developing the same area of land for both solar photovoltaic power as well as for conventional agriculture. This technique was originally conceived by Adolf Goetzberger and Armin Zastrow in 1981. The coexistence of solar panels and crops implies a sharing of light between these two types of production.\n\nAgrivoltaics has been massively implemented in Japan since 2004 and then, Agrivoltaics has expanded in Asia and Europe. Several crops can benefit from these systems, including fruit production.\n\nIn 1981, Adolf Goetzberger and Armin Zastrow were the first to propose the concept of a dual use of arable land for solar energy production and plant cultivation in order to improve overall production. They were addressing the ongoing discussion on the competition for the use of arable land between solar energy production and crop. The light saturation point is the maximum amount of photons absorbable by a plant species. As more photons won’t increase to the rate of photosynthesis, Akira Nagashima suggest to combine PV systems and farming to use the excess of light. He developed the first prototypes in Japan in 2004.\n\nThe term “agrivoltaic“ was used for the first time in a publication in 2011. The concept is known under several names in the world: \"agrophotovoltaics\" in Germany, \"agrovoltaics\" in Italy, \"solar sharing\" in Asia. Facilities such as photovoltaic greenhouses can be considered as agrivoltaic systems.\n\nAs one of the objectives of the agricultural systems is to preserve agricultural land, it is generally considered that agricultural production in agrivoltaic should not be neglected. The constraints on agricultural production vary from one country to another according to the legislation or according to the type of crop and to the objectives of the agrivoltaic system (optimization of the volume of agricultural production, quality of agricultural products, energy production...).\n\nJapan has been the forerunner in the development of open field agrivoltaics worldwide since 2004. Between 2004 and 2017, more than 1,000 open field power plants were developed in Japan.\n\nIn 2004 in Japan, Akira Nagashima developed a demountable structure that he tested on several crops. Since then, many field projects have been installed in Japan with a large number of crops (citrus fruits, peanuts, eggplants, cucumbers, cabbage, rice, vines, mushrooms ...) or livestock. Removable structures allow farmers to remove or move facilities based on crop rotations and their needs. Increasingly large plants with capacities of several MW have been developed since 2004 with permanent structures and dynamic systems. For example, a 35 MW power plant, installed on 54 ha of crops, was commissioned in 2017. The shading rate of this plant is 50%, a value higher than the 30% shading usually used on Japanese agrivoltaic power plants. Farmers cultivate, among others, ginseng, ashitaba and coriander. Soon, the island of Ukujima should host a solar power plant of 480 MW, part of which will be agrivoltaics. The project has been under study since 2013 and the various partners have signed an agreement for the start of construction in 2019.\n\nTo obtain permission to exploit solar panels over crops, Japanese law requires farmers to maintain at least 80% of agricultural production.\n\nIn 2016, the Italian company REM TEC built a 0.5 MWp agrivoltaic power plant in Jinzhai County, Anhui Province. Chinese companies have developed several GWs of solar power plants combining agriculture and solar energy production, either photovoltaic greenhouses or open-field installations. For example, in August 2016, Panda Green Energy installed solar panels over vineyards in Turpan, Xinjiang Uygur Autonomous Region. The 0.2 MW plant was connected to the grid. The project was audited in October 2017 and the company has received approval to roll out its system across the country. Projects of several tens of MW have been deployed. For instance, in 2016, in Jiangxi Province, a 70 MW agrivoltaic plant was installed on agricultural and forestry crops.\n\nFor 30 years, the Elion Group has been trying to combat desertification in the Kubuqi region. Among the techniques used, agrivoltaic systems were installed to protect crops and produce electricity. Regarding the equipment for the desert areas, Wan You-Bao patented in 2007 on a shade system to protect crops in the desert. The shades are equipped with solar panels.\n\nSouth Korea is conducting initial tests of agrivoltaic power plants, drawing on the Japanese example since 2017. Agrivoltaic is one of the solutions studied to increase the share of renewable energies in Korea's energy mix. Their goal is to reach 20% renewable energy in 2030 against 5% in 2017.\n\nProjects for isolated sites are being studied by Amity University in Noida, northern India. A study published in 2017 looks at the potential of agrivoltaism for vineyards in India. The agrivoltaic systems studied in this article consist of solar panels intercalated between crops to limit shading on plants. This study suggests that agrivoltaic systems can significantly increase the incomes of Indian farmers.\n\nThe Universiti Putra Malaysia, which specializes in agronomy, launched experiments in 2015 on plantations of Orthosiphon stamineus (Java tea). It is a fixed structure installed on an experimental surface of about 0.4 ha.\n\nFraunhofer ISE has deployed their agrivoltaic system on a shrimp farm located in Bac Liêu in the Mekong Delta. According to this institute, the results of their pilot project indicate that water consumption has been reduced by 75%. Their system would offer other benefits such as shading for workers as well as a lower and stable water temperature for better shrimp growth.\n\nIn Europe in the early 2000s, photovoltaic greenhouses are emerging. Part of the greenhouse roof is replaced by solar panels. In Austria and then in Italy, open field agrivoltaic systems appeared from 2007, followed by France and Germany.\n\nIn 2004, Günter Czaloun proposed a photovoltaic tracking system with a rope rack system. The first prototype is built in South Tyrol in 2007 on a 0.1 ha area. The cable structure is more than five meters above ground. A new system was presented at the Intersolar 2017 conference in Munich. This technology is potentially less expensive than other open field systems because it requires less steel.\n\nIn 2009 and 2011, agrivoltaic systems with fixed panels were installed above vineyards. Experiments showed a slight decrease of the yield and late harvests.\n\nIn 2009, the Italian company REM TEC develops a dual-axis solar tracking system. In 2011 and 2012, REM TEC built several MWp of open field agrivoltaic power plants. The solar panels are installed 5 m above the ground to operate agricultural machinery. The cover of photovoltaic panels shadow is less than 15% to minimize the effect on the crops. They are the first to offer automated integrated shading net systems into the supporting structure. REM TEC also designs dual-axis solar tracking systems integrated into greenhouse structure. The control of the position of the solar panels would optimize the greenhouse microclimate.\n\nSince the beginning of the 2000s, photovoltaic greenhouses have been built in France. Photovoltaic greenhouse designers continue to innovate to improve both agricultural production and power generation. For instance, the concept of Agrinergie has been developed by since 2007. The first power plants consisted of alternation of crops and solar panels. The new power plants are greenhouses. In 2017, the Tenergie company began the deployment of photovoltaic greenhouses with an architecture that diffuses light in order to reduce the contrasts between light bands and shade bands created by solar panels.\n\nSince 2009, INRA, IRSTEA and have been working on the Sun'Agri program. A first prototype installed in the field with fixed panels is built in 2009 on a surface of 0.1 ha in Montpellier. Other prototypes with 1-axis mobile panels were built in 2014 and 2017. The aim of these studies is to manage the microclimate received by plants and to produce electricity, by optimizing the position of the panels. and to study how radiation is distributed between crops and solar panels. The first agrivoltaic plant in the open field of Sun'R is built in the spring of 2018 in Tresserre in the Pyrénées-Orientales. This plant has a capacity of 2.2 MWp installed on 4.5 ha of vineyards. It will evaluate, on a large scale and in real conditions, the performance of the Sun'Agri system on vineyards.\n\nIn 2016, the Agrivolta company specialized on the agrivoltaïcs. After a first prototype built in 2017 in Aix-en-Provence, Agrivolta deployed its system on a plot of the National Research Institute of Horticulture (Astredhor) in Hyères. Agrivolta win several innovation prizes Agrivolta presented its technology at the CES in Las Vegas in January 2018.\n\nIn 2011, the Fraunhofer Institute ISE started a reaserch project on agrivoltaics. Research continues with the APV-Resola project, which began in 2015 and is scheduled to end in 2020. A first prototype of 194.4 kWp is being built in 2016 on a 0.5 ha site belonging to the Hofgemeinschaft Heggelbach cooperative farm in Herdwangen (Baden-Württemberg). They estimate that such structures will be profitable without government fundings after 2022.\n\nThe Agronomy Department of the Aarhus University has launched a study project of agrivoltaic system on orchards in 2014.\n\nIn 2017, Work-ing d.o.o installed a 500 kW open field power plant near Virovitica-Podravina. The agronomic studies are supported by the University of Osijek and the agricultural engineering school of Slatina. The electricity production is used for the irrigation system and agricultural machinery. At first, shade-adapted cultures will be tested under the device.\n\nIn the United States, SolAgra is interested in the concept in collaboration with the Department of Agronomy at the University of California at Davis. A first poxer plant on 0.4 ha is under development. An area of 2.8 ha is used as a control. Several types of crops are studied: alfalfa, sorghum, lettuce, spinach, beets, carrots, chard, radishes, potatoes, arugula, mint, turnips, kale, parsley, coriander, beans, peas, shallots, mustard ... Projects for isolated sites are also studied. Experimental systems are being studied by several universities: the Biosphere 2 project at the University of Arizona, the Stockbridge School of Agriculture project (University of Massachusetts at Amherst).\n\nThree 13 kWp agro-photovoltaic systems were built in Chile in 2017. The goal of this project, supported by the Metropolitan Region of Santiago, was to study the plants that can benefit from the shading of the agrivoltaic system. The electricity produced was used to power agricultural facilities: cleaning, packaging and cold storage of agricultural production, incubator for eggs ... One of the systems was installed in a region with a lot of power outages.\n\nThere are three types of Agrivoltaics that are being actively researched: solar arrays with space between for crops, stilted solar array above crops and greenhouse solar array. All three of these systems have several variables used to maximize solar energy absorbed in both the panels and the crops. The main variable taken into account for agrivoltaic systems is the angle of the solar panels-called the tilt angle. Other variables taken into account for choosing the location of the agrivoltaic system are the crops chosen, height of the panels, solar irradiation in the area and climate of the area.\n\nThere are different configurations of agrivoltaic devices. Goetzberger and Zastrow have studied the conditions for optimizing agrivoltaic installations. Presented in the early 1980s, these conditions still serve as a reference in the definition of agrivoltaic systems:\n\n\nExperimental facilities often have a control agricultural area. The control zone is exploited under the same conditions as the agrivoltaic device in order to study the effects of the device on the development of crops.\n\nThe simplest approach is to install fixed solar panels on agricultural greenhouses, above open fields crops or between open fields crops. It is possible to optimize the installation by modifying the density of solar panels or the inclination of the panels. In Japan, agrivoltaic systems generally consist of dismountable light structures with light and small size solar panels to reduce wind resistance.\n\nIn more elaborate configurations, agrivoltaic system use a tracking system. Solar panels can be controlled to optimize their positioning to improve agricultural production or electricity production.\n\nThe first dynamic agrivoltaic devices were developed in Japan. The panels are manually adjustable. Farmers can modify the position of the solar panels according to the season or stage of crop development to increase or decrease shading and power generation. Japanese companies have also developed several more sophisticated systems. For example, crops grow under systems composed of tables (25 solar panels) fixed dual axis tracker.\n\nIn 2004, Günter Czaloun proposed a photovoltaic tracking system with a rope rack system. Panels can be oriented to improve power generation or shade crops as needed. The first prototype is built in 2007 in Austria. The company REM TEC has deployed several plants equipped with dual axis tracking system in Italy and China. They have also developed an equivalent system used for agricultural greenhouses.\n\nIn France, Sun'R and Agrivolta companies are developing single axis tracking systems. According to these companies, their systems can be adapgted to the needs of plants. The Sun'R system is east-west axis tracking system. According to this company, complex models of plant growth, weather forecasts, calculation and optimization software are used. The device from Agrivolta is equipped with south-facing solar panels that can be erased by a sliding system.\n\nThe Artigianfer company developed a photovoltaic greenhouse whose solar panels are installed on movable shutters. The panels can follow the course of the Sun along an east-west axis.\n\nThe difficulty of such systems is to find the mode of operation to maintain the good balance between the two types of production according to the goals of the system. Fine control of the panels to adapt shading to the need of plants requires advanced agronomic skills to understand the development of plants. Experimental devices are usually developed in collaboration with research centers.\n\nThe solar panels of Agrivoltaics affects crops and land they cover in ways more than providing shade. Two ways are affecting water flow and heat. They also allow for more revenue per acre to be created. For example, grape farms with appropriate spacing could increase revenue 15 times.\n\nIn experiments testing evaporation levels under PVP for shade resistant crops cucumbers and lettuce watered by irrigation, a 14-29% savings in evaporation was found. Agrivoltaics could be used for crops or areas where water efficiency is imperative.\n\nA study was done on the heat of the land, air and crops under solar panels for a growing season. It was found that while the air beneath the panels stayed consistent, the land and plants had lower temperatures recorded. With rising temperature from climate change this may become important for some food crops.\n\nSimulations and studies on Agrivoltaics indicate electricity and shade-resistant crop production do not decrease in productivity, allowing both to be simultaneously produced efficiently. Dinesh et al. found lettuce output was found to be comparable in Agrivoltaics to monocultures. Agrivoltaics work best for plants that are shade resistant, with potential functioning crops being \"hog peanut, alfalfa, yam, taro, cassava, sweet potato\" along with lettuce. Simulations performed by Dupraz et al. found the potential of land productivity to increase by 60-70%. Furthermore, Dinesh et al. found that the value of solar generated electricity coupled to shade-tolerant crop production created an over 30% increase in economic value from farms deploying agrivoltaic systems instead of conventional agriculture. It has been postulated that Agrivoltaics would be beneficial for summer crops for the microclimate they create and the side effect of heat and water flow control.\n\nShade resistant crops are not typically grown in industrial agricultural systems. For instance, wheat crops do not fare well in a low light environment, meaning they would not work with Agrivoltaics. Agrivoltaics do not yet work with greenhouses. Greenhouses with half of the roof covered in panels were simulated, and the resulting crop output reduced by 64% and panel productivity reduced by 84%.\n"}
{"id": "32568191", "url": "https://en.wikipedia.org/wiki?curid=32568191", "title": "Alisagar lift irrigation scheme", "text": "Alisagar lift irrigation scheme\n\nAlisagar is a park, tourist attraction and an irrigation project which is 13 km (6.2 mi) from Nizamabad and 2 km (1.2 mi) off the Nizamabad-Bodhan road. The park was opened by the Nizam of Hyderabad in 1928. The forest spread along with the summer house, well laid out gardens, an island and hilltop guest house make it a favored getaway. Adding to the attraction is the deer park and facilities for trekking and water sports.\n\nIn the year 1931, the Alisagar reservoir or lake was built by the order of the Nizam of Hyderabad. Later in the year 1985, the deer park was established with an aim to offer a safe haven to several species of deer. A natural habitat was created for the deer. Dense vegetation can be witnessed in this region.\n\nAlisagar lift irrigation project is a lift irrigation project located in Nizamabad district in Telangana, India. The lift canal originates from the back waters of Pochampadu Dam\n\nAlisagar Lift irrigation scheme is intended to stabilize the gap ayacut of 53,793 acres from distributor 50 to 73 of Nizamsagar Project. The foreshore water of Sriram Sagar Project at Kosli (Village) will be lifted in three stages to feed the Alisagar balancing Reservoir at Mile 54 to Mile 56 on Main Canal of Nizamsagar Project.\n\nIn the first stage 720 cusecs of water from Godavari River is proposed to be lifted from Kosli (V) Navipet (Mandal) Nizamabad Dist. and proposed to be dropped into cistern at Bharath Tanda. From there, the water is proposed to be dropped into Thadbiloli Tank by Gravity Canal.\n\nIn the second stage water is proposed to be lifted from the foreshore of Thadbiloli Tank and proposed to be dropped into a cistern at Kalyanpur Gutta. It is proposed to carry water by gravity canal called Link Canal into Distributary No: 50 to irrigate 9,302 acres and another at higher level to irrigate 10,052 acres and balance water is proposed to be dropped into Pocharam Tank by gravity canal.\n\nIn the third stage water is proposed to be lifted from Pocharam Tank and dropped in a cistern near Alisagar Gutta.\n"}
{"id": "19190191", "url": "https://en.wikipedia.org/wiki?curid=19190191", "title": "Assigned amount units", "text": "Assigned amount units\n\nAn Assigned Amount Unit (AAU) is a tradable 'Kyoto unit' or 'carbon credit' representing an allowance to emit greenhouse gases comprising one metric tonne of carbon dioxide equivalents calculated using their Global Warming Potential.\n\nThe \"assigned amounts\" are the Kyoto Protocol Annex B emission targets (or \"quantified emission limitation and reduction objectives\") expressed as levels of allowed emissions over the 2008–2012 commitment period.\n\nArticle 17 of the Kyoto Protocol allows emissions trading between Annex B Parties (countries). Parties that have \"assigned amount units\" to spare because of reductions in emissions below their Kyoto commitment set out in Article 3 and Annex B may sell those units to countries that have emissions exceeding their targets. Article 17 also requires that any such emissions trading shall be supplemental to domestic action for the purpose of meeting quantified emission limitation and reduction commitments (QELRCs).\n\n"}
{"id": "21713669", "url": "https://en.wikipedia.org/wiki?curid=21713669", "title": "Atomic demolition munition", "text": "Atomic demolition munition\n\nAtomic demolition munitions (ADMs), colloquially known as nuclear land mines, are small nuclear explosive devices. ADMs were developed for both military and civilian purposes. As weapons, they were designed to be exploded in the forward battle area, in order to block or channel enemy forces. Non-militarily, they were designed for demolition, mining or earthmoving. However, apart from testing, they have never been used for either purpose.\n\nInstead of being delivered to the target by missiles, rockets, or artillery shells, ADMs were intended to be emplaced by soldiers. Due to their relatively small size and light weight, ADMs could be emplaced by military engineers or Special Forces teams, then detonated on command or by timer to create massive obstructions. By destroying key terrain features or choke points such as bridges, dams, mountain passes and tunnels, ADMs could serve to create physical as well as radiological obstacles to the movement of enemy forces and thus channel them into prepared killing zones.\n\nAccording to official accounts, the United States deployed ADMs overseas in Italy and West Germany (Fulda Gap) during the Cold War. The most modern types (SADM and MADM) were deployed in South Korea. Seymour Hersh referred to the deployment of ADMs along the Golan Heights by Israel in the early 1980s.\n\nADMs have never been used commercially although similar small devices, often modified to cut down on fission yield and maximize fusion, have been deeply buried to put out gas well fires as part of the Soviet test program.\n\nThe Soviet Union tested the use of nuclear devices for mining and natural gas extraction (stimulating gas flow in a similar manner to fracking) on several occasions starting in the mid-1960s, as part of the Nuclear Explosions for the National Economy program. Tests for similar purposes were carried out in the United States under Operation Plowshare, but due to radioactive contamination caused by the tests, no direct commercial use was made of the technology although they were successful at nucleosynthesis and probing the composition of the Earth's deep crust by Vibroseis which has helped mining company prospecting.\n\nIn the 1950s and 1960s, the United States developed several different types of lightweight nuclear devices. The main one was the W54, a cylinder 40 by 60 cm (about 16 by 24 inches) that weighed 23 kg (50 lb). It was fired by a mechanical timer and had a variable yield equivalent to between 10 tons and 1 kt of TNT. A Field non-variable yield version of the W54 nuclear device (called the \"Mk-54 Davy Crockett\" warhead for the M-388 Crockett round) was used in the Davy Crockett Weapon System.\n\nThe Mk 30 Mod 1 \"Tactical Atomic Demolition Munition\" (TADM) was a portable atomic bomb, consisting of a Mk 30 warhead installed in a X-113 case. The X-113 was 26 inches (66 cm) in diameter and 70 in (178 cm) long, and looked like corrugated culvert pipe. The whole system weighed 840 pounds (381 kg). Production of the TADM started in 1961 and all were removed from stockpile by 1966. A weapons effect test of the TADM was made in the 1962 Johnny Boy (\"Johnnie Boy\") shot of the Dominic II series (which is more accurately referred to as Operation Sunbeam), the yield of Johnny Boy/Johnnie Boy was about .5 kt. A preceding ADM test which resulted in a comparable yield, was test shot \"Danny Boy\" of Operation Nougat, also producing a yield of about 0.5 kiloton.\n\nThe \"Special Atomic Demolition Munition (SADM)\" was a family of man-portable nuclear weapons fielded by the US military in the 1960s, but never used in actual combat. The US Army planned to use the weapons in Europe in the event of a Soviet invasion. US Army Engineers would use the weapon to irradiate, destroy, and deny key routes of communication through limited terrain such as the Fulda Gap. Troops were trained to parachute into Soviet occupied western Europe with the SADM and destroy power plants, bridges, and dams.\n\nThe weapon was designed to allow one person to parachute from any type of aircraft carrying the weapon package and place it in a harbor or other strategic location that could be accessed from the sea. Another parachutist without a weapon package would follow the first to provide support as needed.\n\nThe two-person team would place the weapon package in the target location, set the timer, and swim out into the ocean where they would be retrieved by a submarine or a high-speed surface water craft.\n\nThe \"Medium Atomic Demolition Munition\" (MADM) was a tactical nuclear weapon developed by the United States during the Cold War. They were designed to be used as nuclear land mines and for other tactical purposes, with a relatively low explosive yield from a W45 warhead, between 1 and 15 kilotons. Each MADM weighted around 400 lb (181 kg) total. They were produced between 1965 and 1986.\n\nIn the aftermath of the collapse of the Soviet Union, the United States and Russia developed a deep cooperation designed to assure the security of Russia’s nuclear arsenal. While a number of steps were taken to consolidate and improve the security of Russia’s strategic nuclear arms, particularly under the Cooperative Threat Reduction program, concern remained over the security of the Russian tactical nuclear weapons arsenal. In particular, a serious debate arose over the status of what are known as “suitcase nuclear weapons,” very small Soviet-era nuclear devices. This debate was all the more relevant when one considers the potential destruction that could occur should such a device fall into the hands of an organization like al-Qaeda. The term suitcase nuke is generally used to describe any type of small, man-portable nuclear device although there is serious debate as to the validity of the term itself. In a worst case analysis, a suitcase nuke would be small enough to be hand-carried into a major population or leadership center (downtown Manhattan or Capitol Hill, for example) undetected and then detonated. Although, by most accounts, the yield of such a device is likely far less than ten kilotons, its combined effects may have the potential to kill tens of thousands, if not more. There is a great deal of confusion over just how many of these suitcase devices exist or if they even exist at all. By some accounts, the Soviet Union built hundreds of these devices, of which several dozen were missing. Based on other reports, suitcase nukes were never built in large numbers or were never deployed.\n\nThere is no definitive open source information on the number, location, security, or status of these suitcase nuclear bombs. No Soviet suitcase bomb or any of its presumed components has ever been found, much less used, in the three decades after the collapse of the USSR. , it is likely they would not work or would fizzle at worst by lack of the required specialized maintenance common to all nuclear weapons, if they ever existed.\n\nOn February 23, 1999, the PBS investigative program \"Frontline\" aired a special on Russian nuclear security which included a series of interviews with several of the individuals who spoke publicly during the 1997 debate on suitcase nukes. Alexei Yablokov appeared and reasserted his position that some number of small atomic charges had been built, even going so far as to speak of their weight (“thirty kilos, forty kilos”). Yablokov accused the Russian government of misleading the public on the situation, pointing to the inconsistencies in denials by the FSB, MINATOM, and the information that was publicly available on the Internet (“…if I’m looking at a [picture] of an American weapon, I must be sure that we have an analogy…″). On the same program, Congressman Curt Weldon recounted a meeting he held in December 1997 with Defense Minister Igor Sergeyev. During this meeting, Weldon asked Sergeyev specifically about the small ADM devices. According to Weldon, Sergeyev’s response was: “Yes, we did build them, we are in the process of destroying them, and by the year 2000 we will have destroyed all of our small atomic demolition devices.” Weldon went on to express confidence in Sergeyev’s statement but also raised concern as to whether or not the Russian government had accounted for all of its nuclear devices. \"Frontline\" also featured several American and Russian experts and officials who presented differing views on the subject. General Vladimir Dvorkin, a former officer in the Strategic Rocket Forces and subsequently Director of the Fourth Central Research Institute in Moscow, admitted that “some small devices existed in the United States and Russia” but that something that small would have a very limited shelf life and would have little deterrent value. Dvorkin discounted the validity of statements, saying “…Lebed is probably the least informed person as far as this topic is concerned…an expert in military folklore.” The former commander of U.S. nuclear forces, retired General Eugene Habiger, also appeared on \"Frontline\" and expressed doubt about the size of such devices, calling the term suitcase “a little optimistic.” Additionally, Habiger spoke of the systems set up by the Russians to track their nuclear weapons, saying “If the Russians were as deadly serious about the accountability of the nuclear weapons that I saw and have been involved with, I can only surmise that they have the same concerns with the smaller weapons.”\n\nBy late 1999, the concern had expanded from nuclear armed Chechen rebels to include concerns about Osama bin Laden’s al-Qaeda network. Although unsubstantiated, some reports suggested that bin Laden had already managed to acquire weapons from the Russian nuclear arsenal. In August 1999, Voice of America broadcast a story about the threat posed by bin Laden. In it, Yossef Bodansky, an American terrorism analyst, author, and head of the Congressional Task Force on Terrorism and Non-Conventional Warfare claimed that he had learned, through sources in Russia and the Middle East, that bin Laden had “a few of the ex-Soviet ‘suitcase’ bombs acquired through the Chechens.″ Two months later, on October 5, the Moscow daily Komsomolskaya Pravda published an interview in which Bodansky, citing “various intelligence sources,” claimed that bin Laden had acquired, through Kazakhstan, “from several to twenty tactical nuclear warheads.” Bodansky also claimed that bin Laden had attempted to buy “nuclear suitcases” in Kazakhstan. In the same article, the director of the Atomic Energy Agency of the Republic of Kazakhstan declared that all nuclear weapons had been removed “long ago” from Kazakhstan and that suitcase nuclear devices were never built in Kazakh territory. The head of counterintelligence for the Kazakhstani Committee on National Security told Komsomolskaya Pravda that all nuclear weapons were removed from Kazakhstan in 1995 in accordance with the START I treaty and denied reports that bin Laden had attempted to purchase nuclear weapons there. Bodansky’s claims surfaced again on October 25, 1999 when The Jerusalem Report published an article on bin Laden and suitcase nuclear devices. In this report, Bodansky’s claim of “a few to twenty” weapons was repeated. In addition, Bodansky claimed that bin Laden had purchased the weapons using “$30 million in cash and two tons of Afghan heroin.” Very little information is available to back Bodansky’s claims and they remain in doubt.\n\nFollowing the September 11 terrorist attacks on the United States, fresh attention was focused on al-Qaeda’s desire for weapons of mass destruction but with more urgency than in the past. A serious concern was that al-Qaeda terrorists might attempt to obtain Russian warheads or weapon-usable nuclear materials. Former GRU Colonel Stanislav Lunev’s 1998 statements were resurrected following the attacks. During an appearance on CBS, Lunev reasserted his claim that suitcase bombs existed, even going so far as to claim that bin Laden had obtained several of the devices from the former Soviet Union. In the same segment, Michael O’Hanlon of the Brookings Institution discounted Lunev’s claims: “Our view is that this is not a major worry. If those devices ever existed, they were under the control of the Soviet state, and not available to terrorists.” On December 20, 2001 UPI reported that the FBI had stepped up its investigation into terrorist access to Russian nuclear stockpiles. Representative Weldon, once again at the forefront of the debate, stated “Do I think he [bin Laden] has a small atomic demolition munitions, which were built by the Soviets in the Cold War? Probably doubtful.”\n\nOn January 17, 2002, Russia’s Atomic Energy Minister, Aleksandr Rumyantsev, told Interfax it would be impossible for terrorists to construct a portable nuclear weapon, citing a lack of “necessary potential and materials.” The Interfax report went on to state “major nuclear powers have an effective system of control over miniature nuclear charges, which weigh a total of several dozen kilograms.” According to Rumyantsev “all of these [miniature nuclear devices] are registered… it is technically impossible for such charges to find their way into the hands of terrorists.”\n\n\n\n"}
{"id": "17493765", "url": "https://en.wikipedia.org/wiki?curid=17493765", "title": "Berge G. Larsen", "text": "Berge G. Larsen\n\nBerge Gerdt Larsen (born 16 November 1952) is a Norwegian businessperson.\n\nLarsen graduated from University of Newcastle with a Bachelor of Science in chemical engineering and from University of Texas at Austin with a Master of Business Administration.\n\nFrom 1989 to 1995 he was managing director of Odfjell Drilling. He was chief executive officer of DNO ASA from 1996 to 2002, and has served as the executive chairman of their board of directors since 2002. He has also served as chairman of the Norwegian Rig Owners' Association and Bergen Shipowners' Association.\n\nLarsen has a taxable net worth of about US$158 million.\n\nLarsen was investigated by Norwegian authorities over an alleged multi-million kroner tax evasion, but he was acquitted by theGulating Court of Appeals on 31. August 2016. The Judgment is final. He is expected to file very substantial claims for compensation after being wrongly investigated for more than 10 years.\n"}
{"id": "83124", "url": "https://en.wikipedia.org/wiki?curid=83124", "title": "Black dwarf", "text": "Black dwarf\n\nA black dwarf is a theoretical stellar remnant, specifically a white dwarf that has cooled sufficiently that it no longer emits significant heat or light. Because the time required for a white dwarf to reach this state is calculated to be longer than the current age of the universe (13.8 billion years), no black dwarfs are expected to exist in the universe now, and the temperature of the coolest white dwarfs is one observational limit on the age of the universe.\n\nThe name \"black dwarf\" has also been applied to substellar objects that do not have sufficient mass, less than approximately 0.08 , to maintain hydrogen-burning nuclear fusion. These objects are now generally called brown dwarfs, a term coined in the 1970s. Black dwarfs should not be confused with black holes, black stars, or neutron stars.\n\nA white dwarf is what remains of a main-sequence star of low or medium mass (below approximately 9 to 10 solar masses ()) after it has either expelled or fused all the elements for which it has sufficient temperature to fuse. What is left is then a dense sphere of electron-degenerate matter that cools slowly by thermal radiation, eventually becoming a black dwarf. If black dwarfs were to exist, they would be extremely difficult to detect, because, by definition, they would emit very little radiation. They would, however, be detectable through their gravitational influence.\nVarious white dwarfs cooled below 3900 K (M0 spectral class) were found in 2012 by astronomers using MDM Observatory's 2.4-meter telescope. They are estimated to be 11 to 12 billion years old.\n\nBecause the far-future evolution of stars depends on physical questions which are poorly understood, such as the nature of dark matter and the possibility and rate of proton decay, it is not known precisely how long it will take white dwarfs to cool to blackness. Barrow and Tipler estimate that it would take 10 years for a white dwarf to cool to 5 K; however, if weakly interacting massive particles(WIMPs) exist, it is possible that interactions with these particles will keep some white dwarfs much warmer than this for approximately 10 years. If protons are not stable, white dwarfs will also be kept warm by energy released from proton decay. For a hypothetical proton lifetime of 10 years, Adams and Laughlin calculate that proton decay will raise the effective surface temperature of an old one-solar-mass white dwarf to approximately 0.06 K. Although cold, this is thought to be hotter than the cosmic background radiation temperature 10 years in the future.\n\nOnce the Sun stops fusing helium in its core and ejects its layers in a planetary nebula in about 8 billion years, it will become a white dwarf and, over trillions of years time, eventually will no longer emit any light. After that, the Sun will not be visible to the equivalent of the naked human eye, removing it from optical view even if the gravitational effects are evident. The estimated time for the Sun to cool enough to become a black dwarf is about 10 (1 quadrillion) years, though it could take much longer than this, if weakly interacting massive particles (WIMPs) exist, as described above.\n\n"}
{"id": "37778891", "url": "https://en.wikipedia.org/wiki?curid=37778891", "title": "Catalina Solar Project", "text": "Catalina Solar Project\n\nThe Catalina Solar Project is a 143.2 megawatt (MW) photovoltaic power station located near Bakersfield, Kern County, California, owned by enXco, an EDF Énergies Nouvelles Company. It covers area of .\n\nConstruction began in May, 2012 and was fully completed in August, 2013. It use thin-film PV panels bought from Solar Frontier (CIGS type) and First Solar (CdTe type).\n\nPhase 1 had a nameplate capacity of 60 MW and was connected to the grid in December, 2012.\n\nenXco has signed a 25-year Power Purchase Agreement (PPA) with San Diego Gas & Electric (SDG&E) for the production from the station.\n\nThat clean electricity could offset roughly 74,000 tons of carbon emissions each year.\n\n"}
{"id": "312910", "url": "https://en.wikipedia.org/wiki?curid=312910", "title": "Chaff", "text": "Chaff\n\nChaff ( or ) is the dry, scaly protective casings of the seeds of cereal grain, or similar fine, dry, scaly plant material such as scaly parts of flowers, or finely chopped straw. Chaff is indigestible by humans, but livestock can eat it and in agriculture it is used as livestock fodder, or is a waste material ploughed into the soil or burnt.\n\n\"Chaff\" comes from Middle English \"chaf\", from Old English \"ceaf\", related to Old High German \"cheva\", \"husk\".\n\nIn grasses (including cereals such as rice, barley, oats, and wheat), the ripe seed is surrounded by thin, dry, scaly bracts (called glumes, lemmas and paleas), forming a dry husk (or hull) around the grain. Once it is removed it is often referred to as chaff.\nIn wild cereals and in the primitive domesticated einkorn, emmer and spelt wheats, the husks enclose each seed tightly. Before the grain can be used, the husks must be removed.\n\nThe process of loosening the chaff from the grain so as to remove it is called \"threshing\" – traditionally done by milling or pounding. Separating remaining loose chaff from the grain is called \"winnowing\" – traditionally done by repeatedly tossing the grain up into a light wind which gradually blows the lighter chaff away. This method typically utilizes a broad, plate-shaped basket or similar receptacle to hold and collect the winnowed grain as it falls back down.\n\nDomesticated grains such as durum wheat and common wheat have been bred to have chaff that is easily removed. These varieties are known as \"free-threshing\" or \"naked\".\n\nChaff should not be confused with bran, which is finer scaly material that is part of the grain itself.\n\nChaff is also made by chopping straw (or sometimes coarse hay) into very short lengths, using a machine called a chaff cutter. Like grain chaff this is used as animal feed, and is a way of turning coarse fodder into a form more palatable to livestock.\n\nIn botany, chaff refers to the thin receptacular bracts of many species in the sunflower family Asteraceae and related families. They are modified scale-like leaves surrounding single florets in the flower-head.\n\nChaff as a waste product from grain processing leads to a metaphorical use of the term, to refer to something seen as worthless. This is commonly used in the expression \"to separate the wheat from the chaff\" from Matthew 3:12 which says: Whose fan is in his hand, and he will thoroughly purge his floor, and gather his wheat into the garner; but he will burn up the chaff with unquenchable fire. Compare also the \"Parable of the Tares\", which refers to a mixture of wheat and tares (a kind of weed). Another example is in Psalm 1:4 of the Bible, which says: The ungodly are not so: but are like the chaff which the wind driveth away. (KJV)\n\nHungarian engineer László Schremmer has recently discovered that by the use of chaff-based filters it is possible to reduce the arsenic content of water to 3 microgram/litre. This is especially important in areas where the potable water is provided by filtering the water extracted from the underground aquifer.\n\n"}
{"id": "52621017", "url": "https://en.wikipedia.org/wiki?curid=52621017", "title": "DTEK Skhidenergo", "text": "DTEK Skhidenergo\n\nDTEK Skhidenergo () is the main power generation company of DTEK.\n\n\n"}
{"id": "31509928", "url": "https://en.wikipedia.org/wiki?curid=31509928", "title": "Deformed power", "text": "Deformed power\n\nDeformed power is a concept in electrical engineering which characterize the distortion to the sinusoidal states in electric network. It has been introduced by Constantin Budeanu.\n\nIt is defined by the following formula:\n\nwhere S, P, Q, D are the apparent, active, reactive and deformed powers.\n\nIn linear electrical components like electrical resistance occurs no deformed (distortion) power. It is caused by nonlinear loads represented for instance by semiconducting devices (rectifiers, thyristors) especially when used for rectification of an alternating current to a direct one. The rectification is needed especially for providing current for electric traction and electrochemical industry.\n\n\n"}
{"id": "21632019", "url": "https://en.wikipedia.org/wiki?curid=21632019", "title": "Dongfang Electric", "text": "Dongfang Electric\n\nDongfang Electric Corporation () is a Chinese publicly traded corporation engaged in the manufacturing of power generators and the contracts of power station projects. According to Platts, in 2009-10 the company was the second largest manufacturer of steam turbines by worldwide market share, tying with Harbin Electric and slightly behind Shanghai Electric.\n\nIt was founded in 1984 and is based in Chengdu, Sichuan. Its subsidiary is Dongfang Electric Corporation Limited () (,). Its H shares and A shares were listed on the Hong Kong and Shanghai.\n\n\nDongfang was accused by General Electric in court papers of benefitting from a rigged tendering process awarded by South African utility giant Eskom to install a new boiler at the Duvha Power Station. General Electric claims that Dongfang got the contract event thought its bid was R1 billion (US$76 million) more than the General Electric bid.\n\n\n"}
{"id": "1986774", "url": "https://en.wikipedia.org/wiki?curid=1986774", "title": "Frame and panel", "text": "Frame and panel\n\nFrame and panel construction, also called rail and stile, is a woodworking technique often used in the making of doors, wainscoting, and other decorative features for cabinets, furniture, and homes. The basic idea is to capture a 'floating' panel within a sturdy frame, as opposed to techniques used in making a slab solid wood cabinet door or drawer front, the door is constructed of several solid wood pieces running in a vertical or horizontal direction with exposed endgrains. Usually, the panel is not glued to the frame but is left to 'float' within it so that seasonal movement of the wood comprising the panel does not distort the frame.\n\nFrame and panel construction at its most basic consists of five members: the panel and the four members which make up the frame. The vertical members of the frame are called stiles while the horizontal members are known as rails. A basic frame and panel item consists of a top rail, a bottom rail, two stiles, and a panel. This is a common method of constructing cabinet doors and these are often referred to as a five piece door.\n\nIn larger panels it is common to divide the panel into one or more sections. To house the extra panels, dividing pieces known as mid rails and mid stiles or muntins are added to the frame.\n\nThe panel is either captured in a groove made in the inside edge of the frame members or housed in an edge rabbet made in the rear inside edge. Panels are made slightly smaller than the available space within the frame to provide room for movement. Wood will expand and contract across the grain, and a wide panel made of solid wood could change width by a half of an inch, warping the door frame. By allowing the wood panel to float, it can expand and contract without damaging the door. A typical panel would be cut to allow 1/4\" (5 mm) between itself and the bottom of the groove in the frame. It is common to place some sort of elastic material in the groove between the edge of the panel and the frame before assembly. These items center the panel in the frame and absorb seasonal movement. A popular item for this purpose is a small rubber ball, known as a \"spaceball\" (a trademarked product). Some cabinet makers will also use small pieces of cork to allow for movement. The panels are usually either flat or raised. \n\nA flat panel has its visible face flush with the front of the groove in the frame. This gives the panel an inset appearance. This style of panel is commonly made from man-made materials such as MDF or plywood but may also be made from solid wood or tongue and groove planks. Panels made from MDF will be painted to hide their appearance, but panels of hardwood-veneer plywood will be stained and finished to match the solid wood rails and stiles.\n\nA raised panel has a profile cut into its edge so that the panel surface is flush with or proud of the frame. Some popular profiles are the \"ogee\", \"chamfer\", and \"scoop\" or \"cove\". Panels may be raised by a number of methods - the two most common in modern cabinetry are by coving on the tablesaw or the use of a panel raising cutter in a wood router or spindle moulder.\n\nFrames can be constructed by several methods: cope and stick, mortise and tenon, bridle joint, or a simple butt joint. Cope and stick is the most common method, as it is more efficient to manufacture. Mortise and tenon is the strongest, and is often used for large doors which will have greater stresses imposed. Bridle joints are typically used in less formal work, as the exposed endgrain is considered unattractive; while butt joints, being weak, are only used on very small assemblies.\n\nThe stiles and rails often have a profile cut into the inside edge of the outside face - usually a smaller version to match the profile of the panel. In some panel styles, a profile may also be cut on the outside edge of the outside face.\n\nIn modern cabinetry, the cope and stick joinery is achieved with a set of special router cutters. These cut the profile on the edge of the frame parts and also cut a reverse version of the same profile in the ends of the rail so that they may be slipped over the ends of the stiles and glued in place. If done correctly, the cope cut in the end of the rail will mate perfectly with the sticking profile. When glued together, the resulting joint will have sufficient strength for most cabinet door applications without further reinforcement. For extremely large and heavy doors, the cope and stick joint can be further reinforced with dowels, loose tenons, or by some other method. \n\nFor the other methods of frame construction, the inside profile is created either by mitred sticking or by an applied moulding.\n\nIn mitred sticking, the profile (known as the sticking) is applied to the edges of both the rail and stile and then a section of the sticking at the ends of each stile is removed leaving a mitred edge which aligns to a similar mitre cut on the ends of the sticking on each rail. This traditional method is more time consuming to complete, hence the popularity of cope and stick for manufactured items.\n\nWhen applied moulding is to be used, the moulding is applied to the inside edge of the outer face of the frame after the frame and panel have been assembled.\n\nThe process of making raised panel doors begins with gluing up panels, and then moves into cutting and preparing the frame parts. Next, the panels are cut to size and shaped. Parts and panel are sanded before construction. It is also common to apply a finish to panels prior to assembly so that raw wood is not visible if the panel shrinks. The joints are glued and set into clamps. If the frame and panel items are paint grade they are sometimes nailed at the frame joints on the reverse side. The door then moves on to finish sanding where it is brought to its final thickness, and the outside profile is added if required.\n\n"}
{"id": "15166114", "url": "https://en.wikipedia.org/wiki?curid=15166114", "title": "Generic Substation Events", "text": "Generic Substation Events\n\nGeneric Substation Events (GSE) is a control model defined as per IEC 61850 which provides a fast and reliable mechanism of transferring event data over entire electrical substation networks. When implemented, this model ensures the same event message is received by multiple physical devices using multicast or broadcast services. The GSE control model is further subdivided into GOOSE (Generic Object Oriented Substation Events) and GSSE (Generic Substation State Events).\n\nGeneric Object Oriented Substation Events (GOOSE) is a controlled model mechanism in which any format of data (status, value) is grouped into a data set and transmitted within a time period of 4 milliseconds. The following mechanisms are used to ensure specified transmission speed and reliability.\n\n\nGeneric Substation State Events (GSSE) is an extension of event transfer mechanism in UCA2.0. Only Status data can be exchanged through GSSE and it uses a status list (string of bits) rather than a dataset as is used in GOOSE. GSSE messages are transmitted directly over IEC/ISO 8802-2 and 8802-3 using a similar mechanism to GOOSE messages (refer IEC 61850-7-1 Clause 12.2, IEC 61850-8-1 Clause 6.4). As the GSSE format is simpler than GOOSE it is handled faster in some devices. GSSE is being progressively superseded by the use of GOOSE and support for it may eventually disappear.\n\nEquipment manufacturers have started to offer non-standard protocols to report events over substation networks, citing advantages to these approaches. \n\n\n"}
{"id": "1048678", "url": "https://en.wikipedia.org/wiki?curid=1048678", "title": "Glued laminated timber", "text": "Glued laminated timber\n\nGlued laminated timber, also called glulam, is a type of structural engineered wood product comprising a number of layers of dimensioned lumber bonded together with durable, moisture-resistant structural adhesives. In North America the material providing the laminations is termed \"laminating stock\" or \"lamstock\".\n\nBy laminating a number of smaller pieces of lumber, a single large, strong, structural member is manufactured from smaller pieces. These structural members are used as vertical columns or horizontal beams, as well as curved, arched shapes. Glulam is readily produced in curved shapes and it is available in a range of species and appearance characteristics to meet varied end-use requirements. Connections are usually made with bolts or plain steel dowels and steel plates.\n\nGlulam optimizes the structural values of a renewable resource – wood. Because of their composition, large glulam members can be manufactured from a variety of smaller trees harvested from second- and third-growth forests and plantations. \nGlulam provides the strength and versatility of large wood members without relying on the old growth-dependent solid-sawn timbers. \nGlulam has much lower embodied energy than reinforced concrete and steel, although it entails more embodied energy than solid timber. However, the laminating process allows timber to be used for much longer spans, heavier loads, and complex shapes. Glulam is one tenth the weight of steel and one sixth the weight of concrete – the embodied energy to produce it is six times less than the same suitable strength of steel. Glulam can be manufactured to a variety of straight and curved configurations so it offers architects artistic freedom without sacrificing structural requirements.\nThe high strength and stiffness of laminated timbers enable glulam beams and arches to span large distances without intermediate columns, allowing more design flexibility than with traditional timber construction. The size is limited only by transportation and handling constraints.\n\nOne of the earliest still-standing glulam roof structures is generally acknowledged to be the assembly room of King Edward VI College, a school in Bugle Street, Southampton, England, dating from 1866, designed by Josiah George Poole. The building is now the Marriage Room of Southampton \nRegister Office.\n\nTwo churches in Northumberland are now thought to have the earliest extant uses: Holy Trinity, Cambo (1842), and Holy Trinity, Horsley (1844), and four 1850s Merseyside churches also feature laminated timbers: St Mary, Grassendale, St Luke, Formby, St Paul, Tranmere and Holy Trinity, Parr Mount, St Helens .\n\nThe first industrial patented use was in Weimar, Germany. Here in 1872 Otto Hetzer set up a steam sawmill and carpentry business in Kohlstrasse. Beginning in 1892, he took out a series of patents. DRP No. 63018 was for a ventilated timber floor deck that could be tightened laterally after installation, to compensate for shrinkage. Hetzer continued to patent various ingenious systems, but the first of these that could be compared with subsequently standardised horizontal glulam was DRP No. 197773, dated 1906. \n\nThis entailed vertical columns which transitioned into curved glued laminated eaves zones, and then became sloped rafters, all in a single laminated unit. Each component, bonded under pressure, comprised three or more horizontally arranged laminations. The result was the first glulam portal.\n\nIn 1895, Hetzer moved his company to Ettersburger Strasse, still in Weimar. At the height of production, in around 1917, he employed about 300 workers, and Müller includes a fine engraving of the railway sidings and works in 1921.\n\nIn 1909, the Swiss engineering consultants Terner & Chopard purchased permission to use Hetzer's patent, and employed glulam in a number of projects. These included the distinctive bell-shaped roof dome of the former Hygiene Institute, Zurich, 1911, now the main building of the University of Zurich.\n\nThe technology arrived in North America in 1934 when Max Hanisch, Sr., who had worked with Hetzer at the turn of the century, formed the firm Unit Structures in Peshtigo, Wisconsin to manufacture structural glued laminated timber. The first building in the United States to use structural glued laminated timber was a school gymnasium in Peshtigo.\n\nA significant development in the glulam industry was the introduction of fully water-resistant phenol-resorcinol adhesive in 1942. \nThis allowed glulam to be used in exposed exterior environments without concern of gluline degradation. The first U.S. manufacturing standard for glulam was Commercial Standard CS253-63, which was published by the Department of Commerce in 1963. The most recent standard is ANSI/AITC Standard A190.1–02, which took effect in 2002.\nThe roof of the Centre Pompidou-Metz museum is composed of sixteen kilometers of glued laminated timber. It represents a 90-metre wide hexagon with a surface area of 8,000 m². The glued laminated timber motif forms hexagonal wooden units resembling the cane-work pattern of a Chinese hat.\n\nA 2002 case study comparing energy use, greenhouse gas emissions and costs for roof beams found it takes two to three times more energy and six to twelve times more fossil fuels to manufacture steel beams than it does to manufacture glulam beams. \nIt compared two options for a roof structure of a new airport in Oslo, Norway – steel beams and glulam spruce wood beams. The life cycle greenhouse gas emission is lower for the glulam beams. If they are burned at the end of their service life, more energy can be recovered than was used to manufacture them. If they are landfilled, the glulam beams are a worse alternative than steel because of the methane emission. A more recent study by Chalmers University of Technology was not so optimistic. Nevertheless, it showed that while the absolute greenhouse emissions are strongly dependent on the method used to calculate them, the environmental profile of glulam is typically as good or better than steel in an example structural application.\nThe cost of the glulam beams is slightly lower than the steel beams.\n\nWhen glued laminated timber was introduced to the building technology in the early twentieth century, casein glues, which are waterproof but have low shear strengths, were widely used. Joints with casein glues struggled with detachment due to inherent stresses in the wood. The invention of cold-curing synthetic resin glues in 1928 (\"Kaurit\") solved these problems - resin glues, which are inexpensive and easy-to-use, are completely waterproof and enable high adhesive strength. The development of resin glues contributed to the wide use of glued laminated timber construction.\n\nThe use of finger joints with glulam allowed for production of glulam beams and columns on large scale. Glulam finger joints were developed to provide broad surface area for gluing. Automatic finger-jointing machines help cut the finger joints, connect and glue them together under pressure, allowing for a strong, durable joint, capable of carrying high loads comparing to natural wood with the same cross-section.\n\nComputer-controlled fabrication (CNC) allows architects and designers to cut glued laminated timber in unusual shapes with a high degree of precision. CNC machine tools can utilize up to five axes, which enables undercutting and hollowing-out processes. In contrast with laser cutting machines, the cost-effective CNC machines carve the material using mechanical tools, like a router.\n\nSports structures are a particularly suitable application for wide-span glulam roofs. This is supported by the light weight of the material, combined with the ability to furnish long lengths and large cross-sections. Prefabrication is invariably employed and the structural engineer needs to develop clear method statements for delivery and erection at an early stage in the design. The PostFinance Arena is an example of a wide-span sports stadium roof using glulam arches reaching up to 85 metres. The structure was built in Bern in 1967, and has subsequently been refurbished and extended. Eastern Kentucky University's Alumni Coliseum was built in 1963 with the world's largest glued laminated arches, which span 308 feet, 3 1/2 inches. \n\nThe roof of the Richmond Olympic Oval, built for speed skating events at the 2010 Winter Olympic Games in Vancouver, British Columbia, features one of the world's largest clearspan wooden structures. The roof includes 2,400 cubic metres of Douglas-fir lamstock lumber in glulam beams. A total of 34 yellow-cedar glulam posts support the overhangs where the roof extends beyond the walls.\n\nAnaheim ICE, located in Anaheim, CA, is also an example of using glued laminated timber. Disney Development Company desired to build an aesthetic ice rink with less cost, and glulam was one of the most qualified materials in order to meet the owner's requirement. The architect Frank Gehry, suggested a design with large double-curved Yellow-Pine Glulam beams, and the ice rink was constructed in 1995.\n\nPressure-treated glulam timbers or timbers manufactured from naturally durable wood species are well suited for creating bridges and waterfront structures. Wood’s ability to absorb impact forces created by traffic and its natural resistance to chemicals, such as those used for de-icing roadways, make it ideal for these installations. \nGlulam has been successfully used for pedestrian, forest, highway, and railway bridges. \nAn example in North America of a glulam bridge is at Keystone Wye, South Dakota, constructed in 1966–1967. The da Vinci Bridge in Norway, completed in 2001, is almost completely constructed with glulam.\n\nThe Kingsway Pedestrian Bridge in Burnaby, British Columbia, Canada, is constructed of cast-in-place concrete for the support piers, structural steel and glulam for the arch, a post tensioned pre-cast concrete walking deck, and stainless steel support rods connecting the arch to the walking deck.\n\nGlulam is also used for the construction of multi-use facilities such as churches, school buildings, and libraries, and the Cathedral of Christ the Light in Oakland, California, is one of the examples in a way to enhance the ecological and aesthetic effect. It was built as the replacement of the Cathedral of St. Francis de Sales, which became unusable because of the Loma Prieta earthquake in 1989. The 21,600-square-feet wide and 110-foot high Vesica Pisces-shaped building formed the frame with a glued-laminated timber beam and steel-rod skeleton covered with a glass skin. Considering the conventional way of construction with steel or reinforced concrete moment-frame, this glulam-and-steel combination case is regarded as an advanced way to realize the economy and aesthetic in the construction.\n\nThe world's tallest glulam structure has been built in Brumunddal, Ringsaker, Hedmark, Norway, it is an 18 storey building.\n\nGlulam timber is a important component in hurricane-proof building systems. CAT 5 hurricane-resistant log houses are built of glulam timber \n\nThe following CEN standards are relevant to the topic of glulam. They are used by all of the countries that subscribe to the European Committee for Standardisation:\n\nSince the year of 1963, The United States have been operating the glulam manufacturing standards. The current standard form (ANSI A190.1-2002) was developed and published in 2002, by the American National Standards Institute (ANSI). In 2017, the Standard was revised (ANSI190.1-2017) and is now applied on manufacturing glulam and controlling its quality.\n\n\n"}
{"id": "13935859", "url": "https://en.wikipedia.org/wiki?curid=13935859", "title": "God's Country (1985 film)", "text": "God's Country (1985 film)\n\nGod's Country is a 1985 documentary film about Glencoe, Minnesota, by French filmmaker Louis Malle. Original footage of a farming community, 60 miles west of Minneapolis, Minnesota was filmed in 1979 for a PBS documentary. But for the next six years Malle was too busy with other projects to finish this work. He returned in 1985 for a follow-up and found the community reacting to the mid eighties crisis of overproduction in farm country. Malle documented a sense of frustration and apprehension from the same participants he had befriended in better times half a decade earlier.\n\nThe film is occasionally shown on Turner Classic Movies, and is available on DVD from the Criterion Collection.\n\nThe name of the film comes from the widespread belief in American folklore that the United States of America has an exceptional status in the world as \"God's country\" or \"the promised land\" because, metaphorically, early European settlers such as the Puritans of Massachusetts Bay believed they were founding at God's behest a shining city upon a hill.\n"}
{"id": "2750334", "url": "https://en.wikipedia.org/wiki?curid=2750334", "title": "Gregory Schulte", "text": "Gregory Schulte\n\nGregory L. Schulte (born 1958) was the U.S. ambassador to the International Atomic Energy Agency from July 2005 through June 2009. Schulte served as the Permanent Representative of the United States to the United Nations Office at Vienna, the International Atomic Energy Agency, and other international organizations in Vienna. Assuming his post on July 13, 2005, Schulte was charged with advancing the President’s agenda in countering proliferation, terrorism, organized crime, and corruption, while promoting the peaceful use of nuclear energy.\n\nAppointed by President George W. Bush in January 2003, Schulte served as Executive Secretary of the National Security Council (NSC) through March 2005. He was accountable to Condoleezza Rice for overseeing the NSC staff, the national security decision-making process, and the White House Situation Room.\n\nSchulte served as Senior Director for Southeast European Affairs on the NSC staff from 2000 to 2002, overseeing U.S. diplomacy and military deployments in Bosnia and Kosovo and collaboration with the United Nations and European Union. He helped guide and coordinate interagency efforts to bring democracy to Serbia and prevent civil war in Macedonia.\n\nFrom 1999 to 2000, Schulte served as Principal Director for Requirements, Plans and Counterproliferation Policy in the Office of the Secretary of Defense at The Pentagon. His duties included review of U.S. war plans and policy oversight of efforts to protect U.S. and allied forces in the face of nuclear, biological, and chemical threats.\n\nAs Special Assistant to the President for Implementation of the Dayton Peace Accords on the NSC staff from 1998 to 1999, Schulte coordinated U.S. diplomacy and support for the NATO air campaign that stopped ethnic cleansing in Kosovo. He co-chaired the NSC Executive Committee that planned for the subsequent UN and NATO missions in Kosovo.\n\nFrom 1992 to 1998, Schulte was assigned to the NATO International Staff in Belgium. As Director of the Bosnia Task Force, he helped prepare NATO’s first \"out of area\" operations and manage its relations with the United Nations, Russia, and other Partner countries. He worked with NATO political and military authorities to develop guidance for air strikes in Bosnia, deployment of IFOR, and transition to SFOR. He simultaneously served as Director for Nuclear Planning, assisting in the restructuring of NATO’s nuclear weapons posture after the Cold War.\n\nSchulte worked for the Secretary of Defense from 1985 to 1992 as Director for Strategic Forces Policy and Assistant for Theater Nuclear Forces Policy. He contributed to two nuclear weapons treaties, two Presidential Nuclear Initiatives, a Strategic Targeting Review, a Failsafe and Risk Reduction Review, and NATO’s Nuclear Planning Group.\n"}
{"id": "34425026", "url": "https://en.wikipedia.org/wiki?curid=34425026", "title": "Guamblin Island", "text": "Guamblin Island\n\nGuamblin Island, also known as Socorro Island, Nuestra Señora del Socorro or Huamblin, is a Chilean island. It is part of the Chonos Archipelago, although it is some 25 km distant from the other islands of the archipelago, far out in the Pacific Ocean.\n\nThe island is a National Park, and listed as an Important Bird Area. It is a breeding ground of the sooty shearwater.\n\nIn June 1973, the Liberian oil tanker \"Napier\" ran aground on the island and sparked an oil spill releasing 30,000 tons of oil. After the rescue of the crew, \"Napier\" was fired upon and set ablaze by Chilean Hawker Hunters with the purpose of burning the oil to avoid further pollution.\n\n\n"}
{"id": "11255842", "url": "https://en.wikipedia.org/wiki?curid=11255842", "title": "Half Gone", "text": "Half Gone\n\nHalf Gone: Oil, Gas, Hot Air and the Global Energy Crisis is a book by former oil geologist Jeremy Leggett about both oil depletion and global warming.\n\n\n"}
{"id": "13645", "url": "https://en.wikipedia.org/wiki?curid=13645", "title": "Horse", "text": "Horse\n\nThe horse (\"Equus ferus caballus\") is one of two extant subspecies of \"Equus ferus\". It is an odd-toed ungulate mammal belonging to the taxonomic family Equidae. The horse has evolved over the past 45 to 55 million years from a small multi-toed creature, \"Eohippus\", into the large, single-toed animal of today. Humans began domesticating horses around 4000 BC, and their domestication is believed to have been widespread by 3000 BC. Horses in the subspecies \"caballus\" are domesticated, although some domesticated populations live in the wild as feral horses. These feral populations are not true wild horses, as this term is used to describe horses that have never been domesticated, such as the endangered Przewalski's horse, a separate subspecies, and the only remaining true wild horse. There is an extensive, specialized vocabulary used to describe equine-related concepts, covering everything from anatomy to life stages, size, colors, markings, breeds, locomotion, and behavior.\n\nHorses' anatomy enables them to make use of speed to escape predators and they have a well-developed sense of balance and a strong fight-or-flight response. Related to this need to flee from predators in the wild is an unusual trait: horses are able to sleep both standing up and lying down, with younger horses tending to sleep significantly more than adults. Female horses, called mares, carry their young for approximately 11 months, and a young horse, called a foal, can stand and run shortly following birth. Most domesticated horses begin training under saddle or in harness between the ages of two and four. They reach full adult development by age five, and have an average lifespan of between 25 and 30 years.\n\nHorse breeds are loosely divided into three categories based on general temperament: spirited \"hot bloods\" with speed and endurance; \"cold bloods\", such as draft horses and some ponies, suitable for slow, heavy work; and \"warmbloods\", developed from crosses between hot bloods and cold bloods, often focusing on creating breeds for specific riding purposes, particularly in Europe. There are more than 300 breeds of horse in the world today, developed for many different uses.\n\nHorses and humans interact in a wide variety of sport competitions and non-competitive recreational pursuits, as well as in working activities such as police work, agriculture, entertainment, and therapy. Horses were historically used in warfare, from which a wide variety of riding and driving techniques developed, using many different styles of equipment and methods of control. Many products are derived from horses, including meat, milk, hide, hair, bone, and pharmaceuticals extracted from the urine of pregnant mares. Humans provide domesticated horses with food, water and shelter, as well as attention from specialists such as veterinarians and farriers.\n\nSpecific terms and specialized language are used to describe equine anatomy, different life stages, colors and breeds.\n\nDepending on breed, management and environment, the modern domestic horse has a life expectancy of 25 to 30 years. Uncommonly, a few animals live into their 40s and, occasionally, beyond. The oldest verifiable record was \"Old Billy\", a 19th-century horse that lived to the age of 62. In modern times, Sugar Puff, who had been listed in \"Guinness World Records\" as the world's oldest living pony, died in 2007 at age 56.\n\nRegardless of a horse or pony's actual birth date, for most competition purposes a year is added to its age each January 1 of each year in the Northern Hemisphere and each August 1 in the Southern Hemisphere. The exception is in endurance riding, where the minimum age to compete is based on the animal's actual calendar age.\n\nThe following terminology is used to describe horses of various ages:\n\n\nIn horse racing, these definitions may differ: For example, in the British Isles, Thoroughbred horse racing defines colts and fillies as less than five years old. However, Australian Thoroughbred racing defines colts and fillies as less than four years old.\n\nThe height of horses is usually measured at the highest point of the withers, where the neck meets the back. This point is used because it is a stable point of the anatomy, unlike the head or neck, which move up and down in relation to the body of the horse.\n\nIn English-speaking countries, the height of horses is often stated in units of hands and inches: one hand is equal to . The height is expressed as the number of full hands, followed by a point, then the number of additional inches, and ending with the abbreviation \"h\" or \"hh\" (for \"hands high\"). Thus, a horse described as \"15.2 h\" is 15 hands plus 2 inches, for a total of in height.\nThe size of horses varies by breed, but also is influenced by nutrition. Light riding horses usually range in height from and can weigh from . Larger riding horses usually start at about and often are as tall as , weighing from . Heavy or draft horses are usually at least high and can be as tall as high. They can weigh from about .\n\nThe largest horse in recorded history was probably a Shire horse named Mammoth, who was born in 1848. He stood high and his peak weight was estimated at . The current record holder for the world's smallest horse is Thumbelina, a fully mature miniature horse affected by dwarfism. She is tall and weighs .\n\nPonies are taxonomically the same animals as horses. The distinction between a horse and pony is commonly drawn on the basis of height, especially for competition purposes. However, height alone is not dispositive; the difference between horses and ponies may also include aspects of phenotype, including conformation and temperament.\n\nThe traditional standard for height of a horse or a pony at maturity is . An animal 14.2 h or over is usually considered to be a horse and one less than 14.2 h a pony, but there are many exceptions to the traditional standard. In Australia, ponies are considered to be those under . For competition in the Western division of the United States Equestrian Federation, the cutoff is . The International Federation for Equestrian Sports, the world governing body for horse sport, uses metric measurements and defines a pony as being any horse measuring less than at the withers without shoes, which is just over 14.2 h, and , or just over 14.2 h, with shoes.\n\nHeight is not the sole criterion for distinguishing horses from ponies. Breed registries for horses that typically produce individuals both under and over 14.2 h consider all animals of that breed to be horses regardless of their height. Conversely, some pony breeds may have features in common with horses, and individual animals may occasionally mature at over 14.2 h, but are still considered to be ponies.\n\nPonies often exhibit thicker manes, tails, and overall coat. They also have proportionally shorter legs, wider barrels, heavier bone, shorter and thicker necks, and short heads with broad foreheads. They may have calmer temperaments than horses and also a high level of intelligence that may or may not be used to cooperate with human handlers. Small size, by itself, is not an exclusive determinant. For example, the Shetland pony which averages , is considered a pony. Conversely, breeds such as the Falabella and other miniature horses, which can be no taller than , are classified by their registries as very small horses, not ponies.\n\nHorses have 64 chromosomes. The horse genome was sequenced in 2007. It contains 2.7 billion DNA base pairs, which is larger than the dog genome, but smaller than the human genome or the bovine genome. The map is available to researchers.\n\nHorses exhibit a diverse array of coat colors and distinctive markings, described by a specialized vocabulary. Often, a horse is classified first by its coat color, before breed or sex. Horses of the same color may be distinguished from one another by white markings, which, along with various spotting patterns, are inherited separately from coat color.\n\nMany genes that create horse coat colors and patterns have been identified. Current genetic tests can identify at least 13 different alleles influencing coat color, and research continues to discover new genes linked to specific traits. The basic coat colors of chestnut and black are determined by the gene controlled by the Melanocortin 1 receptor, also known as the \"extension gene\" or \"red factor,\" as its recessive form is \"red\" (chestnut) and its dominant form is black. Additional genes control suppression of black color to point coloration that results in a bay, spotting patterns such as pinto or leopard, dilution genes such as palomino or dun, as well as graying, and all the other factors that create the many possible coat colors found in horses.\n\nHorses that have a white coat color are often mislabeled; a horse that looks \"white\" is usually a middle-aged or older gray. Grays are born a darker shade, get lighter as they age, but usually keep black skin underneath their white hair coat (with the exception of pink skin under white markings). The only horses properly called white are born with a predominantly white hair coat and pink skin, a fairly rare occurrence. Different and unrelated genetic factors can produce white coat colors in horses, including several different alleles of dominant white and the sabino-1 gene. However, there are no \"albino\" horses, defined as having both pink skin and red eyes.\n\nGestation lasts approximately 340 days, with an average range 320–370 days, and usually results in one foal; twins are rare. Horses are a precocial species, and foals are capable of standing and running within a short time following birth. Foals are usually born in the spring. The estrous cycle of a mare occurs roughly every 19–22 days and occurs from early spring into autumn. Most mares enter an \"anestrus\" period during the winter and thus do not cycle in this period. Foals are generally weaned from their mothers between four and six months of age.\n\nHorses, particularly colts, sometimes are physically capable of reproduction at about 18 months, but domesticated horses are rarely allowed to breed before the age of three, especially females. Horses four years old are considered mature, although the skeleton normally continues to develop until the age of six; maturation also depends on the horse's size, breed, sex, and quality of care. Larger horses have larger bones; therefore, not only do the bones take longer to form bone tissue, but the epiphyseal plates are larger and take longer to convert from cartilage to bone. These plates convert after the other parts of the bones, and are crucial to development.\n\nDepending on maturity, breed, and work expected, horses are usually put under saddle and trained to be ridden between the ages of two and four. Although Thoroughbred race horses are put on the track as young as the age of two in some countries, horses specifically bred for sports such as dressage are generally not put under saddle until they are three or four years old, because their bones and muscles are not solidly developed. For endurance riding competition, horses are not deemed mature enough to compete until they are a full 60 calendar months (five years) old.\n\nThe horse skeleton averages 205 bones. A significant difference between the horse skeleton and that of a human is the lack of a collarbone—the horse's forelimbs are attached to the spinal column by a powerful set of muscles, tendons, and ligaments that attach the shoulder blade to the torso. The horse's legs and hooves are also unique structures. Their leg bones are proportioned differently from those of a human. For example, the body part that is called a horse's \"knee\" is actually made up of the carpal bones that correspond to the human wrist. Similarly, the hock contains bones equivalent to those in the human ankle and heel. The lower leg bones of a horse correspond to the bones of the human hand or foot, and the fetlock (incorrectly called the \"ankle\") is actually the proximal sesamoid bones between the cannon bones (a single equivalent to the human metacarpal or metatarsal bones) and the proximal phalanges, located where one finds the \"knuckles\" of a human. A horse also has no muscles in its legs below the knees and hocks, only skin, hair, bone, tendons, ligaments, cartilage, and the assorted specialized tissues that make up the hoof.\n\nThe critical importance of the feet and legs is summed up by the traditional adage, \"no foot, no horse\". The horse hoof begins with the distal phalanges, the equivalent of the human fingertip or tip of the toe, surrounded by cartilage and other specialized, blood-rich soft tissues such as the laminae. The exterior hoof wall and horn of the sole is made of keratin, the same material as a human fingernail. The end result is that a horse, weighing on average , travels on the same bones as would a human on tiptoe. For the protection of the hoof under certain conditions, some horses have horseshoes placed on their feet by a professional farrier. The hoof continually grows, and in most domesticated horses needs to be trimmed (and horseshoes reset, if used) every five to eight weeks, though the hooves of horses in the wild wear down and regrow at a rate suitable for their terrain.\n\nHorses are adapted to grazing. In an adult horse, there are 12 incisors at the front of the mouth, adapted to biting off the grass or other vegetation. There are 24 teeth adapted for chewing, the premolars and molars, at the back of the mouth. Stallions and geldings have four additional teeth just behind the incisors, a type of canine teeth called \"tushes\". Some horses, both male and female, will also develop one to four very small vestigial teeth in front of the molars, known as \"wolf\" teeth, which are generally removed because they can interfere with the bit. There is an empty interdental space between the incisors and the molars where the bit rests directly on the gums, or \"bars\" of the horse's mouth when the horse is bridled.\n\nAn estimate of a horse's age can be made from looking at its teeth. The teeth continue to erupt throughout life and are worn down by grazing. Therefore, the incisors show changes as the horse ages; they develop a distinct wear pattern, changes in tooth shape, and changes in the angle at which the chewing surfaces meet. This allows a very rough estimate of a horse's age, although diet and veterinary care can also affect the rate of tooth wear.\n\nHorses are herbivores with a digestive system adapted to a forage diet of grasses and other plant material, consumed steadily throughout the day. Therefore, compared to humans, they have a relatively small stomach but very long intestines to facilitate a steady flow of nutrients. A horse will eat of food per day and, under normal use, drink of water. Horses are not ruminants, they have only one stomach, like humans, but unlike humans, they can utilize cellulose, a major component of grass. Horses are hindgut fermenters. Cellulose fermentation by symbiotic bacteria occurs in the cecum, or \"water gut\", which food goes through before reaching the large intestine. Horses cannot vomit, so digestion problems can quickly cause colic, a leading cause of death.\n\nThe horses' senses are based on their status as prey animals, where they must be aware of their surroundings at all times. They have the largest eyes of any land mammal, and are lateral-eyed, meaning that their eyes are positioned on the sides of their heads. This means that horses have a range of vision of more than 350°, with approximately 65° of this being binocular vision and the remaining 285° monocular vision. Horses have excellent day and night vision, but they have two-color, or dichromatic vision; their color vision is somewhat like red-green color blindness in humans, where certain colors, especially red and related colors, appear as a shade of green.\n\nTheir sense of smell, while much better than that of humans, is not quite as good as that of a dog. It is believed to play a key role in the social interactions of horses as well as detecting other key scents in the environment. Horses have two olfactory centers. The first system is in the nostrils and nasal cavity, which analyze a wide range of odors. The second, located under the nasal cavity, are the Vomeronasal organs, also called Jacobson's organs. These have a separate nerve pathway to the brain and appear to primarily analyze pheromones.\n\nA horse's hearing is good, and the pinna of each ear can rotate up to 180°, giving the potential for 360° hearing without having to move the head. Noise impacts the behavior of horses and certain kinds of noise may contribute to stress: A 2013 study in the UK indicated that stabled horses were calmest in a quiet setting, or if listening to country or classical music, but displayed signs of nervousness when listening to jazz or rock music. This study also recommended keeping music under a volume of 21 decibels. An Australian study found that stabled racehorses listening to talk radio had a higher rate of gastric ulcers than horses listening to music, and racehorses stabled where a radio was played had a higher overall rate of ulceration than horses stabled where there was no radio playing.\n\nHorses have a great sense of balance, due partly to their ability to feel their footing and partly to highly developed proprioception—the unconscious sense of where the body and limbs are at all times. A horse's sense of touch is well developed. The most sensitive areas are around the eyes, ears, and nose. Horses are able to sense contact as subtle as an insect landing anywhere on the body.\n\nHorses have an advanced sense of taste, which allows them to sort through fodder and choose what they would most like to eat, and their prehensile lips can easily sort even small grains. Horses generally will not eat poisonous plants, however, there are exceptions; horses will occasionally eat toxic amounts of poisonous plants even when there is adequate healthy food.\n\nAll horses move naturally with four basic gaits: the four-beat walk, which averages ; the two-beat trot or jog at (faster for harness racing horses); the canter or lope, a three-beat gait that is ; and the gallop. The gallop averages , but the world record for a horse galloping over a short, sprint distance is . Besides these basic gaits, some horses perform a two-beat pace, instead of the trot. There also are several four-beat \"ambling\" gaits that are approximately the speed of a trot or pace, though smoother to ride. These include the lateral rack, running walk, and tölt as well as the diagonal fox trot. Ambling gaits are often genetic in some breeds, known collectively as gaited horses. Often, gaited horses replace the trot with one of the ambling gaits.\n\nHorses are prey animals with a strong fight-or-flight response. Their first reaction to threat is to startle and usually flee, although they will stand their ground and defend themselves when flight is impossible or if their young are threatened. They also tend to be curious; when startled, they will often hesitate an instant to ascertain the cause of their fright, and may not always flee from something that they perceive as non-threatening. Most light horse riding breeds were developed for speed, agility, alertness and endurance; natural qualities that extend from their wild ancestors. However, through selective breeding, some breeds of horses are quite docile, particularly certain draft horses.\n\nHorses are herd animals, with a clear hierarchy of rank, led by a dominant individual, usually a mare. They are also social creatures that are able to form companionship attachments to their own species and to other animals, including humans. They communicate in various ways, including vocalizations such as nickering or whinnying, mutual grooming, and body language. Many horses will become difficult to manage if they are isolated, but with training, horses can learn to accept a human as a companion, and thus be comfortable away from other horses. However, when confined with insufficient companionship, exercise, or stimulation, individuals may develop stable vices, an assortment of bad habits, mostly stereotypies of psychological origin, that include wood chewing, wall kicking, \"weaving\" (rocking back and forth), and other problems.\n\nStudies have indicated that horses perform a number of cognitive tasks on a daily basis, meeting mental challenges that include food procurement and identification of individuals within a social system. They also have good spatial discrimination abilities. They are naturally curious and apt to investigate things they have not seen before. Studies have assessed equine intelligence in areas such as problem solving, speed of learning, and memory. Horses excel at simple learning, but also are able to use more advanced cognitive abilities that involve categorization and concept learning. They can learn using habituation, desensitization, classical conditioning, and operant conditioning, and positive and negative reinforcement. One study has indicated that horses can differentiate between \"more or less\" if the quantity involved is less than four.\n\nDomesticated horses may face greater mental challenges than wild horses, because they live in artificial environments that prevent instinctive behavior whilst also learning tasks that are not natural. Horses are animals of habit that respond well to regimentation, and respond best when the same routines and techniques are used consistently. One trainer believes that \"intelligent\" horses are reflections of intelligent trainers who effectively use response conditioning techniques and positive reinforcement to train in the style that best fits with an individual animal's natural inclinations.\n\nHorses are mammals, and as such are warm-blooded, or endothermic creatures, as opposed to cold-blooded, or poikilothermic animals. However, these words have developed a separate meaning in the context of equine terminology, used to describe temperament, not body temperature. For example, the \"hot-bloods\", such as many race horses, exhibit more sensitivity and energy, while the \"cold-bloods\", such as most draft breeds, are quieter and calmer. Sometimes \"hot-bloods\" are classified as \"light horses\" or \"riding horses\", with the \"cold-bloods\" classified as \"draft horses\" or \"work horses\".\n\"Hot blooded\" breeds include \"oriental horses\" such as the Akhal-Teke, Arabian horse, Barb and now-extinct Turkoman horse, as well as the Thoroughbred, a breed developed in England from the older oriental breeds. Hot bloods tend to be spirited, bold, and learn quickly. They are bred for agility and speed. They tend to be physically refined—thin-skinned, slim, and long-legged. The original oriental breeds were brought to Europe from the Middle East and North Africa when European breeders wished to infuse these traits into racing and light cavalry horses.\n\nMuscular, heavy draft horses are known as \"cold bloods\", as they are bred not only for strength, but also to have the calm, patient temperament needed to pull a plow or a heavy carriage full of people. They are sometimes nicknamed \"gentle giants\". Well-known draft breeds include the Belgian and the Clydesdale. Some, like the Percheron, are lighter and livelier, developed to pull carriages or to plow large fields in drier climates. Others, such as the Shire, are slower and more powerful, bred to plow fields with heavy, clay-based soils. The cold-blooded group also includes some pony breeds.\n\n\"Warmblood\" breeds, such as the Trakehner or Hanoverian, developed when European carriage and war horses were crossed with Arabians or Thoroughbreds, producing a riding horse with more refinement than a draft horse, but greater size and milder temperament than a lighter breed. Certain pony breeds with warmblood characteristics have been developed for smaller riders. Warmbloods are considered a \"light horse\" or \"riding horse\".\n\nToday, the term \"Warmblood\" refers to a specific subset of sport horse breeds that are used for competition in dressage and show jumping. Strictly speaking, the term \"warm blood\" refers to any cross between cold-blooded and hot-blooded breeds. Examples include breeds such as the Irish Draught or the Cleveland Bay. The term was once used to refer to breeds of light riding horse other than Thoroughbreds or Arabians, such as the Morgan horse.\n\nHorses are able to sleep both standing up and lying down. In an adaptation from life in the wild, horses are able to enter light sleep by using a \"stay apparatus\" in their legs, allowing them to doze without collapsing. Horses sleep better when in groups because some animals will sleep while others stand guard to watch for predators. A horse kept alone will not sleep well because its instincts are to keep a constant eye out for danger.\n\nUnlike humans, horses do not sleep in a solid, unbroken period of time, but take many short periods of rest. Horses spend four to fifteen hours a day in standing rest, and from a few minutes to several hours lying down. Total sleep time in a 24-hour period may range from several minutes to a couple of hours, mostly in short intervals of about 15 minutes each. The average sleep time of a domestic horse is said to be 2.9 hours per day.\n\nHorses must lie down to reach REM sleep. They only have to lie down for an hour or two every few days to meet their minimum REM sleep requirements. However, if a horse is never allowed to lie down, after several days it will become sleep-deprived, and in rare cases may suddenly collapse as it involuntarily slips into REM sleep while still standing. This condition differs from narcolepsy, although horses may also suffer from that disorder.\n\nThe horse adapted to survive in areas of wide-open terrain with sparse vegetation, surviving in an ecosystem where other large grazing animals, especially ruminants, could not. Horses and other equids are odd-toed ungulates of the order Perissodactyla, a group of mammals that was dominant during the Tertiary period. In the past, this order contained 14 families, but only three—Equidae (the horse and related species), Tapiridae (the tapir), and Rhinocerotidae (the rhinoceroses)—have survived to the present day.\n\nThe earliest known member of the family Equidae was the \"Hyracotherium\", which lived between 45 and 55 million years ago, during the Eocene period. It had 4 toes on each front foot, and 3 toes on each back foot. The extra toe on the front feet soon disappeared with the \"Mesohippus\", which lived 32 to 37 million years ago. Over time, the extra side toes shrank in size until they vanished. All that remains of them in modern horses is a set of small vestigial bones on the leg below the knee, known informally as splint bones. Their legs also lengthened as their toes disappeared until they were a hooved animal capable of running at great speed. By about 5 million years ago, the modern \"Equus\" had evolved. Equid teeth also evolved from browsing on soft, tropical plants to adapt to browsing of drier plant material, then to grazing of tougher plains grasses. Thus proto-horses changed from leaf-eating forest-dwellers to grass-eating inhabitants of semi-arid regions worldwide, including the steppes of Eurasia and the Great Plains of North America.\n\nBy about 15,000 years ago, \"Equus ferus\" was a widespread holarctic species. Horse bones from this time period, the late Pleistocene, are found in Europe, Eurasia, Beringia, and North America. Yet between 10,000 and 7,600 years ago, the horse became extinct in North America and rare elsewhere. The reasons for this extinction are not fully known, but one theory notes that extinction in North America paralleled human arrival. Another theory points to climate change, noting that approximately 12,500 years ago, the grasses characteristic of a steppe ecosystem gave way to shrub tundra, which was covered with unpalatable plants.\n\nA truly wild horse is a species or subspecies with no ancestors that were ever domesticated. Therefore, most \"wild\" horses today are actually feral horses, animals that escaped or were turned loose from domestic herds and the descendants of those animals. Only two never-domesticated subspecies, the Tarpan and the Przewalski's Horse, survived into recorded history and only the latter survives today.\n\nThe Przewalski's horse (\"Equus ferus przewalskii\"), named after the Russian explorer Nikolai Przhevalsky, is a rare Asian animal. It is also known as the Mongolian wild horse; Mongolian people know it as the \"taki\", and the Kyrgyz people call it a \"kirtag\". The subspecies was presumed extinct in the wild between 1969 and 1992, while a small breeding population survived in zoos around the world. In 1992, it was reestablished in the wild due to the conservation efforts of numerous zoos. Today, a small wild breeding population exists in Mongolia. There are additional animals still maintained at zoos throughout the world.\n\nThe tarpan or European wild horse (\"Equus ferus ferus\") was found in Europe and much of Asia. It survived into the historical era, but became extinct in 1909, when the last captive died in a Russian zoo. Thus, the genetic line was lost. Attempts have been made to recreate the tarpan, which resulted in horses with outward physical similarities, but nonetheless descended from domesticated ancestors and not true wild horses.\n\nPeriodically, populations of horses in isolated areas are speculated to be relict populations of wild horses, but generally have been proven to be feral or domestic. For example, the Riwoche horse of Tibet was proposed as such, but testing did not reveal genetic differences from domesticated horses. Similarly, the Sorraia of Portugal was proposed as a direct descendant of the Tarpan based on shared characteristics, but genetic studies have shown that the Sorraia is more closely related to other horse breeds and that the outward similarity is an unreliable measure of relatedness.\n\nBesides the horse, there are six other species of genus \"Equus\" in the Equidae family. These are the ass or donkey, \"Equus asinus\"; the mountain zebra, \"Equus zebra\"; plains zebra, \"Equus quagga\"; Grévy's zebra, \"Equus grevyi\"; the kiang, \"Equus kiang\"; and the onager, \"Equus hemionus\".\n\nHorses can crossbreed with other members of their genus. The most common hybrid is the mule, a cross between a \"jack\" (male donkey) and a mare. A related hybrid, a hinny, is a cross between a stallion and a jenny (female donkey). Other hybrids include the zorse, a cross between a zebra and a horse. With rare exceptions, most hybrids are sterile and cannot reproduce.\n\nDomestication of the horse most likely took place in central Asia prior to 3500 BC. Two major sources of information are used to determine where and when the horse was first domesticated and how the domesticated horse spread around the world. The first source is based on palaeological and archaeological discoveries; the second source is a comparison of DNA obtained from modern horses to that from bones and teeth of ancient horse remains.\n\nThe earliest archaeological evidence for the domestication of the horse comes from sites in Ukraine and Kazakhstan, dating to approximately 3500–4000 BC. By 3000 BC, the horse was completely domesticated and by 2000 BC there was a sharp increase in the number of horse bones found in human settlements in northwestern Europe, indicating the spread of domesticated horses throughout the continent. The most recent, but most irrefutable evidence of domestication comes from sites where horse remains were interred with chariots in graves of the Sintashta and Petrovka cultures c. 2100 BC.\n\nDomestication is also studied by using the genetic material of present-day horses and comparing it with the genetic material present in the bones and teeth of horse remains found in archaeological and palaeological excavations. The variation in the genetic material shows that very few wild stallions contributed to the domestic horse, while many mares were part of early domesticated herds. This is reflected in the difference in genetic variation between the DNA that is passed on along the paternal, or sire line (Y-chromosome) versus that passed on along the maternal, or dam line (mitochondrial DNA). There are very low levels of Y-chromosome variability, but a great deal of genetic variation in mitochondrial DNA. There is also regional variation in mitochondrial DNA due to the inclusion of wild mares in domestic herds. Another characteristic of domestication is an increase in coat color variation. In horses, this increased dramatically between 5000 and 3000 BC.\n\nBefore the availability of DNA techniques to resolve the questions related to the domestication of the horse, various hypotheses were proposed. One classification was based on body types and conformation, suggesting the presence of four basic prototypes that had adapted to their environment prior to domestication. Another hypothesis held that the four prototypes originated from a single wild species and that all different body types were entirely a result of selective breeding after domestication. However, the lack of a detectable substructure in the horse has resulted in a rejection of both hypotheses.\n\nFeral horses are born and live in the wild, but are descended from domesticated animals. Many populations of feral horses exist throughout the world. Studies of feral herds have provided useful insights into the behavior of prehistoric horses, as well as greater understanding of the instincts and behaviors that drive horses that live in domesticated conditions.\n\nThere are also semi-feral horses in many parts of the world, such as Dartmoor and the New Forest in the UK, where the animals are all privately owned but live for significant amounts of time in \"wild\" conditions on undeveloped, often public, lands. Owners of such animals often pay a fee for grazing rights.\n\nThe concept of purebred bloodstock and a controlled, written breed registry has come to be particularly significant and important in modern times. Sometimes purebred horses are incorrectly or inaccurately called \"thoroughbreds\". Thoroughbred is a specific breed of horse, while a \"purebred\" is a horse (or any other animal) with a defined pedigree recognized by a breed registry. Horse breeds are groups of horses with distinctive characteristics that are transmitted consistently to their offspring, such as conformation, color, performance ability, or disposition. These inherited traits result from a combination of natural crosses and artificial selection methods. Horses have been selectively bred since their domestication. An early example of people who practiced selective horse breeding were the Bedouin, who had a reputation for careful practices, keeping extensive pedigrees of their Arabian horses and placing great value upon pure bloodlines. These pedigrees were originally transmitted via an oral tradition. In the 14th century, Carthusian monks of southern Spain kept meticulous pedigrees of bloodstock lineages still found today in the Andalusian horse.\n\nBreeds developed due to a need for \"form to function\", the necessity to develop certain characteristics in order to perform a particular type of work. Thus, a powerful but refined breed such as the Andalusian developed as riding horses with an aptitude for dressage. Heavy draft horses developed out of a need to perform demanding farm work and pull heavy wagons. Other horse breeds developed specifically for light agricultural work, carriage and road work, various sport disciplines, or simply as pets. Some breeds developed through centuries of crossing other breeds, while others descended from a single foundation sire, or other limited or restricted foundation bloodstock. One of the earliest formal registries was General Stud Book for Thoroughbreds, which began in 1791 and traced back to the foundation bloodstock for the breed. There are more than 300 horse breeds in the world today.\n\nWorldwide, horses play a role within human cultures and have done so for millennia. The genetic makeup of the human population in a geographical area is affected by the presence or absence of horses (more variation in Africa, less in Eurasian steppes). Societies where horse riding is an integral part of life have developed traditional attires specially suited for horse riding such as tightly wrapping waistbands or cummerbunds giving wide support useful for protecting the spine during long journeys, and voluminous headgear such as turban to protect the skull during falls from the horse. Horses are used for leisure activities, sports, and working purposes. The Food and Agriculture Organization (FAO) estimates that in 2008, there were almost 59,000,000 horses in the world, with around 33,500,000 in the Americas, 13,800,000 in Asia and 6,300,000 in Europe and smaller portions in Africa and Oceania. There are estimated to be 9,500,000 horses in the United States alone. The American Horse Council estimates that horse-related activities have a direct impact on the economy of the United States of over $39 billion, and when indirect spending is considered, the impact is over $102 billion. In a 2004 \"poll\" conducted by Animal Planet, more than 50,000 viewers from 73 countries voted for the horse as the world's 4th favorite animal.\n\nCommunication between human and horse is paramount in any equestrian activity; to aid this process horses are usually ridden with a saddle on their backs to assist the rider with balance and positioning, and a bridle or related headgear to assist the rider in maintaining control. Sometimes horses are ridden without a saddle, and occasionally, horses are trained to perform without a bridle or other headgear. Many horses are also driven, which requires a harness, bridle, and some type of vehicle.\n\nHistorically, equestrians honed their skills through games and races. Equestrian sports provided entertainment for crowds and honed the excellent horsemanship that was needed in battle. Many sports, such as dressage, eventing and show jumping, have origins in military training, which were focused on control and balance of both horse and rider. Other sports, such as rodeo, developed from practical skills such as those needed on working ranches and stations. Sport hunting from horseback evolved from earlier practical hunting techniques. Horse racing of all types evolved from impromptu competitions between riders or drivers. All forms of competition, requiring demanding and specialized skills from both horse and rider, resulted in the systematic development of specialized breeds and equipment for each sport. The popularity of equestrian sports through the centuries has resulted in the preservation of skills that would otherwise have disappeared after horses stopped being used in combat.\n\nHorses are trained to be ridden or driven in a variety of sporting competitions. Examples include show jumping, dressage, three-day eventing, competitive driving, endurance riding, gymkhana, rodeos, and fox hunting. Horse shows, which have their origins in medieval European fairs, are held around the world. They host a huge range of classes, covering all of the mounted and harness disciplines, as well as \"In-hand\" classes where the horses are led, rather than ridden, to be evaluated on their conformation. The method of judging varies with the discipline, but winning usually depends on style and ability of both horse and rider.\nSports such as polo do not judge the horse itself, but rather use the horse as a partner for human competitors as a necessary part of the game. Although the horse requires specialized training to participate, the details of its performance are not judged, only the result of the rider's actions—be it getting a ball through a goal or some other task. Examples of these sports of partnership between human and horse include jousting, in which the main goal is for one rider to unseat the other, and buzkashi, a team game played throughout Central Asia, the aim being to capture a goat carcass while on horseback.\n\nHorse racing is an equestrian sport and major international industry, watched in almost every nation of the world. There are three types: \"flat\" racing; steeplechasing, i.e. racing over jumps; and harness racing, where horses trot or pace while pulling a driver in a small, light cart known as a sulky. A major part of horse racing's economic importance lies in the gambling associated with it.\n\nThere are certain jobs that horses do very well, and no technology has yet developed to fully replace them. For example, mounted police horses are still effective for certain types of patrol duties and crowd control. Cattle ranches still require riders on horseback to round up cattle that are scattered across remote, rugged terrain. Search and rescue organizations in some countries depend upon mounted teams to locate people, particularly hikers and children, and to provide disaster relief assistance. Horses can also be used in areas where it is necessary to avoid vehicular disruption to delicate soil, such as nature reserves. They may also be the only form of transport allowed in wilderness areas. Horses are quieter than motorized vehicles. Law enforcement officers such as park rangers or game wardens may use horses for patrols, and horses or mules may also be used for clearing trails or other work in areas of rough terrain where vehicles are less effective.\n\nAlthough machinery has replaced horses in many parts of the world, an estimated 100 million horses, donkeys and mules are still used for agriculture and transportation in less developed areas. This number includes around 27 million working animals in Africa alone. Some land management practices such as cultivating and logging can be efficiently performed with horses. In agriculture, less fossil fuel is used and increased environmental conservation occurs over time with the use of draft animals such as horses. Logging with horses can result in reduced damage to soil structure and less damage to trees due to more selective logging.\n\nHorses have been used in warfare for most of recorded history. The first archaeological evidence of horses used in warfare dates to between 4000 and 3000 BC, and the use of horses in warfare was widespread by the end of the Bronze Age. Although mechanization has largely replaced the horse as a weapon of war, horses are still seen today in limited military uses, mostly for ceremonial purposes, or for reconnaissance and transport activities in areas of rough terrain where motorized vehicles are ineffective. Horses have been used in the 21st century by the Janjaweed militias in the War in Darfur.\n\nModern horses are often used to reenact many of their historical work purposes. Horses are used, complete with equipment that is authentic or a meticulously recreated replica, in various live action historical reenactments of specific periods of history, especially recreations of famous battles. Horses are also used to preserve cultural traditions and for ceremonial purposes. Countries such as the United Kingdom still use horse-drawn carriages to convey royalty and other VIPs to and from certain culturally significant events. Public exhibitions are another example, such as the Budweiser Clydesdales, seen in parades and other public settings, a team of draft horses that pull a beer wagon similar to that used before the invention of the modern motorized truck.\n\nHorses are frequently used in television, films and literature. They are sometimes featured as a major character in films about particular animals, but also used as visual elements that assure the accuracy of historical stories. Both live horses and iconic images of horses are used in advertising to promote a variety of products. The horse frequently appears in coats of arms in heraldry, in a variety of poses and equipment. The mythologies of many cultures, including Greco-Roman, Hindu, Islamic, and Norse, include references to both normal horses and those with wings or additional limbs, and multiple myths also call upon the horse to draw the chariots of the Moon and Sun. The horse also appears in the 12-year cycle of animals in the Chinese zodiac related to the Chinese calendar.\n\nPeople of all ages with physical and mental disabilities obtain beneficial results from association with horses. Therapeutic riding is used to mentally and physically stimulate disabled persons and help them improve their lives through improved balance and coordination, increased self-confidence, and a greater feeling of freedom and independence. The benefits of equestrian activity for people with disabilities has also been recognized with the addition of equestrian events to the Paralympic Games and recognition of para-equestrian events by the International Federation for Equestrian Sports (FEI). Hippotherapy and therapeutic horseback riding are names for different physical, occupational, and speech therapy treatment strategies that utilize equine movement. In hippotherapy, a therapist uses the horse's movement to improve their patient's cognitive, coordination, balance, and fine motor skills, whereas therapeutic horseback riding uses specific riding skills.\n\nHorses also provide psychological benefits to people whether they actually ride or not. \"Equine-assisted\" or \"equine-facilitated\" therapy is a form of experiential psychotherapy that uses horses as companion animals to assist people with mental illness, including anxiety disorders, psychotic disorders, mood disorders, behavioral difficulties, and those who are going through major life changes. There are also experimental programs using horses in prison settings. Exposure to horses appears to improve the behavior of inmates and help reduce recidivism when they leave.\n\nHorses are raw material for many products made by humans throughout history, including byproducts from the slaughter of horses as well as materials collected from living horses.\n\nProducts collected from living horses include mare's milk, used by people with large horse herds, such as the Mongols, who let it ferment to produce kumis. Horse blood was once used as food by the Mongols and other nomadic tribes, who found it a convenient source of nutrition when traveling. Drinking their own horses' blood allowed the Mongols to ride for extended periods of time without stopping to eat. The drug Premarin is a mixture of estrogens extracted from the urine of pregnant mares (pregnant mares' urine), and was previously a widely used drug for hormone replacement therapy. The tail hair of horses can be used for making bows for string instruments such as the violin, viola, cello, and double bass.\n\nHorse meat has been used as food for humans and carnivorous animals throughout the ages. It is eaten in many parts of the world, though consumption is taboo in some cultures, and a subject of political controversy in others. Horsehide leather has been used for boots, gloves, jackets, baseballs, and baseball gloves. Horse hooves can also be used to produce animal glue. Horse bones can be used to make implements. Specifically, in Italian cuisine, the horse tibia is sharpened into a probe called a \"spinto\", which is used to test the readiness of a (pig) ham as it cures. In Asia, the saba is a horsehide vessel used in the production of kumis.\n\nHorses are grazing animals, and their major source of nutrients is good-quality forage from hay or pasture. They can consume approximately 2% to 2.5% of their body weight in dry feed each day. Therefore, a adult horse could eat up to of food. Sometimes, concentrated feed such as grain is fed in addition to pasture or hay, especially when the animal is very active. When grain is fed, equine nutritionists recommend that 50% or more of the animal's diet by weight should still be forage.\n\nHorses require a plentiful supply of clean water, a minimum of to per day. Although horses are adapted to live outside, they require shelter from the wind and precipitation, which can range from a simple shed or shelter to an elaborate stable.\n\nHorses require routine hoof care from a farrier, as well as vaccinations to protect against various diseases, and dental examinations from a veterinarian or a specialized equine dentist. If horses are kept inside in a barn, they require regular daily exercise for their physical health and mental well-being. When turned outside, they require well-maintained, sturdy fences to be safely contained. Regular grooming is also helpful to help the horse maintain good health of the hair coat and underlying skin.\n\n\n"}
{"id": "12074874", "url": "https://en.wikipedia.org/wiki?curid=12074874", "title": "Industry Technology Facilitator", "text": "Industry Technology Facilitator\n\nIndustry Technology Facilitator (ITF) is an oil industry trade organisation established in 1999. It is owned by 30 major global oil majors and oilfield service companies. \n\nThe group has offices in Aberdeen, UK, Houston, USA, Abu Dhabi, UAE, Perth, Australia and Kuala Lumpur, Malaysia.\n\nITF currently has a membership of 30 global operators and service companies including:\n\nThe topics addressed by these ITF sponsored technologies include seismic resolution, complex reservoirs, cost-effective drilling and intervention, subsea, maximising production, integrity management, and environmental performance.\n\n"}
{"id": "17493450", "url": "https://en.wikipedia.org/wiki?curid=17493450", "title": "Ivar Brandvold", "text": "Ivar Brandvold\n\nIvar Brandvold (born 1956) is a Norwegian businessperson, currently the chief executive officer of Fred. Olsen Energy.\n\nHe graduated from Norwegian Institute of Technology with a master's degree in mechanical engineering.\n\nHe then worked at Kongsberg Engineering before being hired by Norsk Hydro in 1984. Having risen to Head of Drilling in Norsk Hydro, he left in 2007 to become Chief Operating Officer in DNO ASA before replacing Helge Haakonsen as CEO of Fred. Olsen Energy in November 2009.\n"}
{"id": "54161658", "url": "https://en.wikipedia.org/wiki?curid=54161658", "title": "Jessica Lovering", "text": "Jessica Lovering\n\nJessica Lovering is an American astrophysicist, researcher and Director of Energy at the Breakthrough Institute. She supports the innovative development of new nuclear power plants in response to climate change. She also sits on the Advisory Committee of the Nuclear Innovation Alliance, and was a speaker at Nuclear Innovation Bootcamp at the University of California, Berkley in 2016. Her biography at ClimateOne states that Lovering \"works to change how people think about energy and the environment\". Her written work has featured in various publications, including journals \"Issues in Science and Technology\", \"Science and Public Policy\", \"Foreign Affairs\" and \"Energy policy.\" Websites featuring her work include various nuclear energy blogs and EnergyPost.eu. She has worked as a researcher on the documentary film \"Pandora's Promise\" and appeared in the TV series \"Abandoned\".\n"}
{"id": "38557800", "url": "https://en.wikipedia.org/wiki?curid=38557800", "title": "Jiayuguan Solar Park", "text": "Jiayuguan Solar Park\n\nThe Jiayuguan Solar Park is a 52 MWp photovoltaic power station located in the Jiayuguan City region, in China. It uses fixed tilt arrays. The first stage, 40 MWp, was completed in 2012.\n\n"}
{"id": "41649447", "url": "https://en.wikipedia.org/wiki?curid=41649447", "title": "Kalu Ganga Dam", "text": "Kalu Ganga Dam\n\nThe Kalu Ganga Dam is a large gravity dam, and the second vital component of the larger and more complex Moragahakanda — Kalu Ganga Project, currently under construction across the Kalu Ganga (\"Black River\") at Pallegama, in the Matale District of Sri Lanka. Construction of the project was launched by President Mahinda Rajapaksa on . The maiden waters of the dam was released in July 2018. \n\nThe larger combined project involves the construction of the Kalu Ganga Dam and Reservoir, along with the separate Moragahakanda Dam and Reservoir, for irrigation and power generation purposes. Both these sites would be located approximately apart.\n\nThe total development cost for both sites totals to approximately (approximately ) and is being carried out by SMEC Holdings and Sinohydro.\n\nThe development of the Kalu Ganga segment would cost . 22% or of this is funded by the Kuwait Fund, 27.5% or is funded by the Saudi Fund for Development, while the rest if borne by the Government of Sri Lanka. The funds will be payable in , including a 5-year grace period.\n\nThe funding from OPEC will carry an interest rate of 3.2%, and a service charge of 1% on the principle amount withdrawn and outstanding.\n\nThe primary Kalu Ganga Dam will be a high concrete gravity dam, measuring in length. To support the new Kalu Ganga Reservoir created by the dam, two additional saddle dams will also be created to contain the reservoir. The primary dam and saddle dams are estimated to cost approximately .\n\nIn addition to using the reservoir's water for irrigation, a percentage of it would be consistently transferred via tunnel to the Moragahakanda Reservoir for further irrigation uses and hydroelectricity generation.\n\nA large area of forest east of Pallegama has been cleared for the construction of the dam and even more so for the construction of a new residential and agricultural colony east of the dam. The forest area cleared is adjoining Wasgamuwa National Park and linked the forests on the eastern side of Knuckles Mountain Range with the Wasgamuwa National Park. Elephants and other wildlife used to inhabit this area and used it as corridor. There are attempts to minimize environmental impact by reforesting catchment areas, and declaration of elephant corridors to Wasgamuwa, Girithale, Mineriya national parks.\n\nSeveral old villages, including Pallegama and Rambukoluwa, have to be abandoned and all the residents have to relocate to the new colony, about 5 to 10 kilometers northeast of Pallegama. Each family is compensated with two acres of land, 1.5 acres of paddy land and half an acre in the residential area to construct a new house.\n\n"}
{"id": "17744", "url": "https://en.wikipedia.org/wiki?curid=17744", "title": "Lanthanum", "text": "Lanthanum\n\nLanthanum is a chemical element with symbol La and atomic number 57. It is a soft, ductile, silvery-white metal that tarnishes rapidly when exposed to air and is soft enough to be cut with a knife. It is the eponym of the lanthanide series, a group of 15 similar elements between lanthanum and lutetium in the periodic table, of which lanthanum is the first and the prototype. It is also sometimes considered the first element of the 6th-period transition metals and is traditionally counted among the rare earth elements and in 3rd group. The usual oxidation state is +3. Lanthanum has no biological role in humans but is essential to some bacteria. It is not particularly toxic to humans but does show some antimicrobial activity.\n\nLanthanum usually occurs together with cerium and the other rare earth elements. Lanthanum was first found by the Swedish chemist Carl Gustav Mosander in 1839 as an impurity in cerium nitrate – hence the name \"lanthanum\", from the Ancient Greek \"λανθάνειν\" (\"lanthanein\"), meaning \"to lie hidden\". Although it is classified as a rare earth element, lanthanum is the 28th most abundant element in the Earth's crust, almost three times as abundant as lead. In minerals such as monazite and bastnäsite, lanthanum composes about a quarter of the lanthanide content. It is extracted from those minerals by a process of such complexity that pure lanthanum metal was not isolated until 1923.\n\nLanthanum compounds have numerous applications as catalysts, additives in glass, carbon arc lamps for studio lights and projectors, ignition elements in lighters and torches, electron cathodes, scintillators, GTAW electrodes, and other things. Lanthanum carbonate is used as a phosphate binder in cases of renal failure. It is also an element in the 6th period and in the 3rd group.\n\nLanthanum is the first element and prototype of the lanthanide series. In the periodic table, it appears to the right of the alkaline earth metal barium and to the left of the lanthanide cerium. Lanthanum is often considered to be a group 3 element, along with its lighter congeners scandium and yttrium and its heavier congener, the radioactive actinium, although this classification is sometimes disputed. Similarly to scandium, yttrium, and actinium, the 57 electrons of a lanthanum atom are arranged in the configuration [Xe]5d6s, with three valence electrons outside the noble gas core. In chemical reactions, lanthanum almost always gives up these three valence electrons from the 5d and 6s subshells to form the +3 oxidation state, achieving the stable configuration of the preceding noble gas xenon. Some lanthanum(II) compounds are also known, but they are much less stable.\n\nAmong the lanthanides, lanthanum is exceptional as it does not have any 4f electrons; indeed, the sudden contraction and lowering of energy of the 4f orbital that is important for the chemistry of the lanthanides only begins to happen at cerium. Thus it is only very weakly paramagnetic, unlike the strongly paramagnetic later lanthanides (with the exceptions of the last two, ytterbium and lutetium, where the 4f shell is completely full). Furthermore, since the melting points of the trivalent lanthanides are related to the extent of hybridisation of the 6s, 5d, and 4f electrons, lanthanum has the second-lowest (after cerium) melting point among all the lanthanides: 920 °C. The lanthanides become harder as the series is traversed: as expected, lanthanum is a soft metal. Lanthanum has a relatively high resistivity of 615 nΩm at room temperature; in comparison, the value for the good conductor aluminium is only 26.50 nΩm. Lanthanum is the least volatile of the lanthanides. Like most of the lanthanides, lanthanum has a hexagonal crystal structure at room temperature. At 310 °C, lanthanum changes to a face-centered cubic structure, and at 865 °C, it changes to a body-centered cubic structure.\n\nAs expected from periodic trends, lanthanum has the largest atomic radius of the lanthanides and the stable group 3 elements. Hence, it is the most reactive among them, tarnishing slowly in air and burning readily to form lanthanum(III) oxide, LaO, which is almost as basic as calcium oxide. A centimeter-sized sample of lanthanum will corrode completely in a year as its oxide spalls off like iron rust, instead of forming a protective oxide coating like aluminium and lanthanum's lighter congeners scandium and yttrium. Lanthanum reacts with the halogens at room temperature to form the trihalides, and upon warming will form binary compounds with the nonmetals nitrogen, carbon, sulfur, phosphorus, boron, selenium, silicon and arsenic. Lanthanum reacts slowly with water to form lanthanum(III) hydroxide, La(OH). In dilute sulfuric acid, lanthanum readily forms the aquated tripositive ion : this is colorless in aqueous solution since La has no f electrons. Lanthanum is the strongest and hardest base among the lanthanides and group 3 elements, which is again expected from its being the largest of them.\n\nNaturally occurring lanthanum is made up of two isotopes, the stable La and the primordial long-lived radioisotope La. La is by far the most abundant, making up 99.910% of natural lanthanum: it is produced in the s-process (slow neutron capture, which occurs in low- to medium-mass stars) and the r-process (rapid neutron capture, which occurs in core-collapse supernovae). The very rare isotope La is one of the few primordial odd-odd nuclei, with a long half-life of 1.05×10 years: it is one of the proton-rich p-nuclei which cannot be produced in the s- or r-processes. La, along with the even rarer Ta, is produced in the ν-process, where neutrinos interact with stable nuclei. All other lanthanum isotopes are synthetic: with the exception of La with a half-life of about 60,000 years, all of them have half-lives less than a day, and most have half-lives less than a minute. The isotopes La and La occur as fission products of uranium.\nLanthanum oxide is a white solid that can be prepared by direct reaction of its constituent elements. Due to the large size of the La ion, LaO adopts a hexagonal 7-coordinate structure that changes to the 6-coordinate structure of scandium oxide (ScO) and yttrium oxide (YO) at high temperature. When it reacts with water, lanthanum hydroxide is formed: a lot of heat is evolved in the reaction and a hissing sound is heard. Lanthanum hydroxide will react with atmospheric carbon dioxide to form the basic carbonate.\n\nLanthanum fluoride is insoluble in water and can be used as a qualitative test for the presence of La. The heavier halides are all very soluble deliquescent compounds. The anhydrous halides are produced by direct reaction of their elements, as heating the hydrates causes hydrolysis: for example, heating hydrated LaCl produces LaOCl.\n\nLanthanum reacts exothermically with hydrogen to produce the dihydride LaH, a black, pyrophoric, brittle, conducting compound with the calcium fluoride structure. This is a non-stoichiometric compound, and further absorption of hydrogen is possible, with a concomitant loss of electrical conductivity, until the more salt-like LaH is reached. Like LaI and LaI, LaH is probably an electride compound.\n\nDue to the large ionic radius and great electropositivity of La, there is not much covalent contribution to its bonding and hence it has a limited coordination chemistry, like yttrium and the other lanthanides. Lanthanum oxalate does not dissolve very much in alkali-metal oxalate solutions, and [La(acac)(HO)] decomposes around 500 °C. Oxygen is the most common donor atom in lanthanum complexes, which are mostly ionic and often have high coordination numbers over 6: 8 is the most characteristic, forming square antiprismatic and dodecadeltahedral structures. These high-coordinate species, reaching up to coordination number 12 with the use of chelating ligands such as in La(SO)·9HO, often have a low degree of symmetry because of stereo-chemical factors.\n\nLanthanum chemistry tends not to involve π bonding due to the electron configuration of the element: thus its organometallic chemistry is quite limited. The best characterized organolanthanum compounds are the cyclopentadienyl complex La(CH), which is produced by reacting anhydrous LaCl with NaCH in tetrahydrofuran, and its methyl-substituted derivatives.\n\nIn 1751, the Swedish mineralogist Axel Fredrik Cronstedt discovered a heavy mineral from the mine at Bastnäs, later named cerite. Thirty years later, the fifteen-year-old Vilhelm Hisinger, from the family owning the mine, sent a sample of it to Carl Scheele, who did not find any new elements within. In 1803, after Hisinger had become an ironmaster, he returned to the mineral with Jöns Jacob Berzelius and isolated a new oxide which they named \"ceria\" after the dwarf planet Ceres, which had been discovered two years earlier. Ceria was simultaneously independently isolated in Germany by Martin Heinrich Klaproth. Between 1839 and 1843, ceria was shown to be a mixture of oxides by the Swedish surgeon and chemist Carl Gustaf Mosander, who lived in the same house as Berzelius: he separated out two other oxides which he named \"lanthana\" and \"didymia\". He partially decomposed a sample of cerium nitrate by roasting it in air and then treating the resulting oxide with dilute nitric acid. Since lanthanum's properties differed only slightly from those of cerium, and occurred along with it in its salts, he named it from the Ancient Greek \"λανθάνειν\" [lanthanein] (lit. \"to lie hidden\"). Relatively pure lanthanum metal was first isolated in 1923.\n\nLanthanum is the third-most abundant of all the lanthanides, making up 39 mg/kg of the Earth's crust, behind neodymium at 41.5 mg/kg and cerium at 66.5 mg/kg. It is almost three times as abundant as lead in the Earth's crust. Despite being among the so-called \"rare earth metals\", lanthanum is thus not rare at all, but it is historically so named because it is rarer than \"common earths\" such as lime and magnesia, and historically only a few deposits were known. Lanthanum is considered a rare earth metal because the process to mine it is difficult, time-consuming, and expensive. Lanthanum is rarely the dominant lanthanide found in the rare earth minerals, and in their chemical formulae it is usually preceded by cerium. Rare examples of La-dominant minerals are monazite-(La) and lanthanite-(La).\nThe La ion is similarly-sized to the early lanthanides of the cerium group (those up to samarium and europium) that immediately follow in the periodic table, and hence it tends to occur along with them in phosphate, silicate and carbonate minerals, such as monazite (MPO) and bastnäsite (MCOF), where M refers to all the rare earth metals except scandium and the radioactive promethium (mostly Ce, La, and Y). Bastnäsite is usually lacking in thorium and the heavy lanthanides, and the purification of the light lanthanides from it is less involved. The ore, after being crushed and ground, is first treated with hot concentrated sulfuric acid, evolving carbon dioxide, hydrogen fluoride, and silicon tetrafluoride: the product is then dried and leached with water, leaving the early lanthanide ions, including lanthanum, in solution.\n\nThe procedure for monazite, which usually contains all the rare earths as well as thorium, is more involved. Monazite, because of its magnetic properties, can be separated by repeated electromagnetic separation. After separation, it is treated with hot concentrated sulfuric acid to produce water-soluble sulfates of rare earths. The acidic filtrates are partially neutralized with sodium hydroxide to pH 3-4. Thorium precipitates out of solution as hydroxide and is removed. After that, the solution is treated with ammonium oxalate to convert rare earths to their insoluble oxalates. The oxalates are converted to oxides by annealing. The oxides are dissolved in nitric acid that excludes one of the main components, cerium, whose oxide is insoluble in HNO. Lanthanum is separated as a double salt with ammonium nitrate by crystallization. This salt is relatively less soluble than other rare earth double salts and therefore stays in the residue. Care must be taken when handling some of the residues as they contain Ra, the daughter of Th, which is a strong gamma emitter. Lanthanum is relatively easy to extract as it has only one neighbouring lanthanide, cerium, which can be removed by making use of its ability to be oxidised to the +4 state; thereafter, lanthanum may be separated out by the historical method of fractional crystallization of La(NO)·2NHNO·4HO, or by ion-exchange techniques when higher purity is desired.\n\nLanthanum metal is obtained from its oxide by heating it with ammonium chloride or fluoride and hydrofluoric acid at 300-400 °C to produce the chloride or fluoride:\n\nThis is followed by reduction with alkali or alkaline earth metals in vacuum or argon atmosphere:\n\nAlso, pure lanthanum can be produced by electrolysis of molten mixture of anhydrous LaCl and NaCl or KCl at elevated temperatures.\n\nThe first historical application of lanthanum was in gas lantern mantles. Carl Auer von Welsbach used a mixture of 60% magnesium oxide, 20% lanthanum oxide, and 20% yttrium oxide, which he called \"Actinophor\" and patented in 1885. The original mantles gave a green-tinted light and were not very successful, and his first company, which established a factory in Atzgersdorf in 1887, failed in 1889.\n\nModern uses of lanthanum include:\n\nLanthanum has no known biological role in humans. The element is very poorly absorbed after oral administration and when injected its elimination is very slow. Lanthanum carbonate (Fosrenol) was approved as a phosphate binder to absorb excess phosphate in cases of end stage renal disease.\n\nWhile lanthanum has pharmacological effects on several receptors and ion channels, its specificity for the GABA receptor is unique among trivalent cations. Lanthanum acts at the same modulatory site on the GABA receptor as zinc, a known negative allosteric modulator. The lanthanum cation La is a positive allosteric modulator at native and recombinant GABA receptors, increasing open channel time and decreasing desensitization in a subunit configuration dependent manner.\n\nLanthanum is an essential cofactor for the methanol dehydrogenase of the methanotrophic bacterium \"Methylacidiphilum fumariolicum\" SolV, although the great chemical similarity of the lanthanides means that it may be substituted with cerium, praseodymium, or neodymium without ill effects, and with the smaller samarium, europium, or gadolinium giving no side effects other than slower growth.\n\nLanthanum has a low to moderate level of toxicity and should be handled with care. The injection of lanthanum solutions produces hyperglycemia, low blood pressure, degeneration of the spleen and hepatic alterations. The application in carbon arc light led to the exposure of people to rare earth element oxides and fluorides, which sometimes led to pneumoconiosis. As the La ion is similar in size to the Ca ion, it is sometimes used as an easily traced substitute for the latter in medical studies. Lanthanum, like the other lanthanides, is known to affect human metabolism, lowering cholesterol levels, blood pressure, appetite, and risk of blood coagulation. When injected into the brain, it acts as a painkiller, similarly to morphine and other opiates, though the mechanism behind this is still unknown.\n\n"}
{"id": "3512082", "url": "https://en.wikipedia.org/wiki?curid=3512082", "title": "Low-g condition", "text": "Low-g condition\n\nLow-\"g\" condition is a phase of aerodynamic flight where the airframe is temporarily unloaded. The pilot—and the airframe—feel temporarily \"weightless\" because the aircraft is in free-fall or decelerating vertically at the top of a climb. It may also occur during an excessively rapid entry into autorotation. This can have a disastrous effect on the aircraft, particularly in the case of helicopters, some of which need the rotor to constantly be under a non-zero amount of load.\n\nIn smaller airplanes\n\nMost smaller airplanes and gliders have no problems with 0\"g\" conditions. In fact, it can be enjoyable to have zero gravity in the cockpit. To produce 0\"g\", the aircraft has to follow a ballistic flight path, which is essentially an upside down parabola.\nThis is the only method to simulate zero gravity for humans on earth. \n\nIn helicopters\n\nIn contrast, low-g conditions can be disastrous for helicopters. In such a situation their rotors may flap beyond normal limits. The excessive flapping can cause the root of the blades to exceed the limit of their hinges and this condition, known as mast bumping, can cause the separation of the blades from the hub or for the mast to shear, and hence detach the whole system from the aircraft, falling from the sky. This is especially true for helicopters with teetering rotors, such as the two-bladed design seen on Robinson helicopters.\nThis effect was first discovered when many accidents with Bell UH-1 and AH-1 helicopters occurred. These particular helicopters simply crashed without any obvious cause. Later, it was found that these accidents usually happened during low terrain flight after passing a ridge and initiating a dive from the previous climb.\nArticulated and rigid rotor systems do not lose controlling forces up to 0\"g\", but may encounter this depending on their flapping hinge offset from the mast. However, dangerous situations, as with a teetering rotor, may not occur.\n\nOn fixed-wing aircraft\n\nLow-\"g\" conditions can also affect fixed-wing aircraft in some instances, mainly by disrupting the airflow over the wings, making them difficult or impossible to control via the aerodynamic surfaces.\n\nThe controllability of an airplane by the control surfaces only depends on airspeed. So, if one keeps airspeed, control is retained. Usually the controllability is even increased, because there is no need to produce lift. 0\"g\" forces are a minimal problem for fixed wing aircraft, but there are exceptions, including, but not limited to, airplanes with gravity-fed fuel systems.\n\nTo simulate 0-\"g\" conditions some space agencies uses a modified passenger aircraft to simulate a low-\"g\" condition. The ESA uses an Airbus A300, for example. NASA has the Vomit Comet. One upside down parabola simulates 0\"g\" for about 25 s.\n"}
{"id": "3673778", "url": "https://en.wikipedia.org/wiki?curid=3673778", "title": "Ludwieg tube", "text": "Ludwieg tube\n\nA Ludwieg tube is a cheap and efficient way of producing supersonic flow. Mach numbers up to 4 in air are easily obtained without any additional heating of the flow. With heating, Mach numbers of up to 11 can be reached.\n\nA Ludwieg tube is a wind tunnel that produces supersonic flow for short periods of time. A large evacuated dump tank is separated from the downstream end of a convergent-divergent nozzle by a diaphragm or fast acting valve. The upstream end of the nozzle connects to a long cylindrical tube, whose cross-sectional area is significantly larger than the throat area of the nozzle. Initially, the pressure in the nozzle and tube is high. To start the tunnel, the diaphragm is ruptured, e.g., by piercing it with a suitable cutting device, or opening the valve respectively. As always when a diaphragm ruptures, a shock wave propagates into the low-pressure region (here the dump tank) and an expansion wave propagates into the high-pressure region (here the nozzle and the long tube). As this unsteady expansion propagates through the long tube, it sets up a steady subsonic flow toward the nozzle, which is accelerated by the convergent-divergent nozzle to a supersonic condition. The flow is steady until the expansion, having been reflected from the far end of the tube, arrives at the nozzle again. For practical reasons, flow times are about 100 milliseconds for most Ludwieg tubes. For many purposes, this flow duration is sufficient. However, by taking advantage of multiple quasi-static flows between expansion wave reflections, experimentation times of up to 6 seconds can be achieved.\n\nThe Ludwieg tube was invented by Hubert Ludwieg (1912-2000) in 1955 in response to a competition for a transonic or supersonic wind tunnel design that would be capable of producing high Reynolds number at low operating cost. Professor Ludwieg was also responsible for the experimental demonstration and explanation of the large effect of sweep on the drag of transonic wings (his dissertation in 1937).\n\n\n"}
{"id": "22158796", "url": "https://en.wikipedia.org/wiki?curid=22158796", "title": "Martin Doughty", "text": "Martin Doughty\n\nSir Martin Doughty (11 October 1949 – 4 March 2009) was the Chair of Natural England and a well-known figures in modern British conservation.\n\nDoughty began his working career as a lecturer in Environmental Management at Sheffield Hallam University. \n\nSubsequently he worked primarily in the public or voluntary sectors with roles such as Leader of Derbyshire County Council from 1992 until 2001. He was also a Board Member for the Countryside Agency (1999 – 2005) and was the Chair of English Nature before taking up his final position as Chair of Natural England.\n\nHe received a knighthood in 2001 for services to local government in Derbyshire, followed by Honorary Doctorates from Sheffield Hallam University in 2002, Cranfield University in 2005 and Derby University in 2006.\n\nHe died of cancer in March 2009.\n\n"}
{"id": "12026392", "url": "https://en.wikipedia.org/wiki?curid=12026392", "title": "Meentycat wind farm", "text": "Meentycat wind farm\n\nMeentycat wind farm is a wind farm located close to Ballybofey, Donegal, Ireland and erected in 2004. The farm was built and is run by Airtricity.\n\nThe farm has 38 Siemens wind turbines, 23×2.3 megawatt and 15×1.3 megawatt turbines giving a total of 72.4 megawatts. \nMeentycat wind farm near Ballybofey in Co Donegal has an installed capacity of 72MW, making it the largest wind farm in Ireland. \n\nWith a total of 38 turbines on five sites, Meentycat wind farm generates enough electricity to power the equivalent of approximately 45,000 homes a year, with CO savings approaching 200,000 tonnes per year. \n\nPower from the turbines is transmitted to the national grid via a 110kV substation located at Meentycat, a 5km 110kV overhead line and a 110kV substation at Drumkeen to the east of the wind farm. In January 2011, it was the largest wind farm (by electricity generated) in Ireland. It is now owned by SSE Renewables Holdings Limited part of the Scottish and Southern Energy Group \nhttp://www.sserenewables.com/what-we-do/onshore-wind/ireland/meentycat/\n\n"}
{"id": "3362378", "url": "https://en.wikipedia.org/wiki?curid=3362378", "title": "Merrifield resin", "text": "Merrifield resin\n\nMerrifield Resin is a cross-linked polystyrene resin that carries a chloromethyl functional group. Merrifield resin is named after its inventor, Robert Bruce Merrifield (1984 winner of the Nobel Prize in Chemistry), and used in solid-phase synthesis. The material is typically available as white beads. These beads are allowed to swell in suitable solvents (ethyl acetate, DMF, DMSO), which then allows the reagents to substitute the chloride substituents.\n\nMerrifield Resin can be prepared by chloromethylation of polystyrene or by the copolymerization of styrene and 4-vinylbenzyl chloride.\n"}
{"id": "205406", "url": "https://en.wikipedia.org/wiki?curid=205406", "title": "Microgram", "text": "Microgram\n\nIn the metric system, a microgram or microgramme (μg; the recommended symbol in the United States when communicating medical information is mcg) is a unit of mass equal to one millionth () of a gram. The unit symbol is μg according to the International System of Units. In μg the prefix symbol for micro- is the Greek letter μ (Mu).\n\nWhen the Greek lowercase “μ” (Mu) in the symbol μg is typographically unavailable, it is occasionally—although not properly—replaced by the Latin lowercase “u”.\n\nThe United States-based Institute for Safe Medication Practices (ISMP) and the U.S. Food and Drug Administration (FDA) recommend that the symbol μg should not be used when communicating medical information due to the risk that the prefix μ (micro-) might be misread as the prefix m (milli-), resulting in a thousandfold overdose. The non-SI symbol mcg is recommended instead.However, the abbreviation mcg is also the symbol for an obsolete CGS unit of measure known as millicentigram, which is equal to 10 μg.\n\nIn the UK, because serious medication errors have been made from the confusion between milligrams and micrograms when micrograms has been abbreviated, the recommendation given in the Scottish Palliative Care Guidelines is that doses of less than one milligram \"must\" be expressed in micrograms and that the word ‘microgram’ must be written in full, and that it is never acceptable to use “mcg” or “μg”.\n\nGamma (symbol: γ) is a deprecated non-SI unit of mass equal to one microgram.\n\n"}
{"id": "43424960", "url": "https://en.wikipedia.org/wiki?curid=43424960", "title": "National Energy Policy of Nigeria", "text": "National Energy Policy of Nigeria\n\nThe National Energy Policy establishes guidelines for the protection of the environment in the exploitation of Nigeria’s fossil fuels. It also emphasizes the exploration of renewable and alternative energy sources, primarily solar, wind, and biomass.\n\n"}
{"id": "31894022", "url": "https://en.wikipedia.org/wiki?curid=31894022", "title": "Nina Leopold Bradley", "text": "Nina Leopold Bradley\n\nNina Leopold Bradley (born Nina Leopold) (August 4, 1917 – May 25, 2011) was an American conservationist, researcher and writer. Her father was the renowned ecologist Aldo Leopold. She died May 25, 2011, aged 93.\n\n"}
{"id": "6060764", "url": "https://en.wikipedia.org/wiki?curid=6060764", "title": "North East Assembly", "text": "North East Assembly\n\nNorth East Assembly (NEA) was the regional chamber for the North East region of England. It was abolished in March 2009 with its functions being transferred to One NorthEast, the Regional Development Agency, and the Association of North East Councils, the Local Authority Leaders’ Board. \n"}
{"id": "20066819", "url": "https://en.wikipedia.org/wiki?curid=20066819", "title": "RADET", "text": "RADET\n\n"}
{"id": "6527803", "url": "https://en.wikipedia.org/wiki?curid=6527803", "title": "Self-interacting dark matter", "text": "Self-interacting dark matter\n\nIn astrophysics and particle physics, self-interacting dark matter (SIDM) assumes dark matter has self-interactions, in contrast to the collisionless dark matter assumed by the Lambda-CDM model. SIDM was postulated in 2000 to resolve a number of conflicts between observations and N-body simulations (of cold collisionless dark matter only) on the galactic scale and smaller. It was also used to explain the 2015 observations of ESO 146-5 the core of the Abell 3827 galaxy cluster. However, the latter finding has since been discounted based on further observations and modelling of the cluster.\n\nSelf-interacting dark matter has also been postulated as an explanation for the DAMA annual modulation signal.\n\n\n"}
{"id": "48035430", "url": "https://en.wikipedia.org/wiki?curid=48035430", "title": "Shell Anacortes Refinery", "text": "Shell Anacortes Refinery\n\nShell Oil Products US, a subsidiary of Royal Dutch Shell PLC, operates the Puget Sound Refinery located on March Point outside of Anacortes, WA. The plant is the largest taxpayer in Skagit County and one of the county's largest employers. The refinery has a 145,000 b/d capacity, making it the 52nd largest in the USA, in 2015, with facilities that include a delayed coker, fluid catalytic cracker, polymerization unit and alkylation units. Based on the secondary processing units in place, the facility likely follows a 3-2-1 crack spread. Shell’s refinery produces three grades of gasoline, fuel oil, diesel fuel, propane and butane. This plant is currently the only refinery in Washington state unable to accommodate tight oil via rail. The permitting process is currently underway for the proposed 60,000 b/d unloading capacity of the East Gate Rail Project.\n\nThe Puget Sound Refinery was built by Texaco in 1957. Its initial 45,000 b/d capacity came online in 1958.\n\nPrior to 1998 Shell Oil operated the Shell Anacortes Refinery. Shell and Texaco combined their refining and marketing operations, assets valued at $17 billion, in 1997. The joint business, Equilon Enterprises - later to become part of Motiva Enterprises, subsequently co-owned both refineries on March Point outside of Anacortes. Antitrust litigation accepted the deal under the condition that Shell sell its preexisting refinery. Tesoro, an independent Texas-based midstream and downstream company, won bidding for Shell's refinery at a $237 million, with an additional payment of $60 million for net working capital. The refinery is now known as the Marathon Anacortes Refinery.\n"}
{"id": "24082675", "url": "https://en.wikipedia.org/wiki?curid=24082675", "title": "Social and environmental impact of palm oil", "text": "Social and environmental impact of palm oil\n\nPalm oil, produced from the oil palm, is a basic source of income for many farmers in South East Asia, Central and West Africa, and Central America. It is locally used as a cooking oil, exported for use in many commercial food and personal care products and is converted into biofuel. It produces up to 10 times more oil per unit area than soyabeans, rapeseed or sunflowers.\n\nOil palms produce 38% of the world's vegetable-oil output on 5% of the world’s vegetable-oil farmland. Palm oil plantations are under increasing scrutiny for their effects on the environment, including loss of carbon-sequestering forest land. There is also concern over displacement and disruption of human and animal populations due to palm oil cultivation.\n\nAn estimated 1.5 million small farmers grow the crop in Indonesia, along with about 500,000 people directly employed in the sector in Malaysia, plus those connected with related industries.\n\nAs of 2006, the cumulative land area of palm oil plantations is approximately . In 2005 the Malaysian Palm Oil Association, responsible for about half of the world's crop, estimated that they manage about half a billion perennial carbon-sequestering palm trees. Demand for palm oil has been rising and is expected to climb further.\n\nBetween 1967 and 2000 the area under cultivation in Indonesia expanded from less than to more than . Deforestation in Indonesia for palm oil (and illegal logging) is so rapid that a 2007 United Nations Environment Programme (UNEP) report said that most of the country's forest might be destroyed by 2022. The rate of forest loss has declined in the past decade.\n\nGlobal production is forecast at a record 46.9m tonnes in 2010, up from 45.3m in 2009, with Indonesia providing most of the increase.\n\nOil palm is a valuable economic crop and provides a source of employment. It allows small landholders to participate in the cash economy and often results in improvements to local infrastructure and greater access to services such as schools and health facilities. In some areas, the cultivation of oil palm has replaced traditional practices, often due to the higher income potential of palm oil.\n\nHowever, in some cases, land has been developed by oil palm plantations without consultation or compensation of the indigenous people occupying the land. This has occurred in Papua New Guinea, Colombia, and Indonesia. In the Sarawak state of Malaysian Borneo, there has been debate over whether there was an appropriate level of consultation with the Long Teran Kanan community prior to the development of local land for palm oil plantations. Appropriation of native lands has led to conflict between the plantations and local residents in each of these countries.\n\nAccording to a 2008 report by NGOs including Friends of the Earth, palm oil companies have also reportedly used force to acquire land from indigenous communities in Indonesia. Additionally, some Indonesian oil palm plantations are dependent on imported labor or undocumented immigrants, which has raised concerns about the working conditions and social impacts of these practices.\n\nIn Indonesia, rising demand for palm oil and timber has led to the clearing of tropical forest land in Indonesian national parks. According to a 2007 report published by UNEP, at the rate of deforestation at that time, an estimated 98 percent of Indonesian forest would be destroyed by 2022 due to legal and illegal logging, forest fires and the development of palm oil plantations.\n\nMalaysia, the second largest producer of palm oil has pledged to conserve a minimum of 50 percent of its total land area as forests. As of 2010, 58 percent of Malaysia was forested.\n\nPalm oil cultivation has been criticized for:\n\nIn some states where oil palm is established, lax enforcement of environmental legislation leads to encroachment of plantations into riparian strips, and release of pollutants such as palm oil mill effluent (POME) in the environment.\n\nMore environment-friendly practices have been developed. Among those approaches is anaerobic treatment of POME, which might allow for biogas (methane) production and electricity generation, but it is very difficult to maintain optimum growth conditions for the anaerobic organisms that break down acetate to methane (primarily \"Methanosaeta concilii\", a species of Archaea).\n\nDamage to peatland, partly due to palm oil production, is claimed to contribute to environmental degradation, including four percent of global greenhouse gas emissions and eight percent of all global emissions caused annually by burning fossil fuels, due to the clearing of large areas of rainforest for palm oil plantations. Many Indonesian and Malaysian rainforests lie atop peat bogs that store great quantities of carbon. Forest removal and bog drainage to make way for plantations releases this carbon.\n\nResearchers are looking for possible solutions and ways to help the situation and have suggested that if enough land is conserved and there remain large enough areas of primary forest reserves, the effects of the palm oil industry may not have as much of an impact on wildlife and biodiversity. Environmental groups like Greenpeace, the Roundtable on Sustainable Palm Oil, and Amnesty International are also taking part in advocating bans on unsustainable palm oil crops and the companies that purchase these exports.\n\nEnvironmental groups such as Greenpeace claim that this deforestation produces far more emissions than biofuels remove. Greenpeace identified Indonesian peatlands—unique tropical forests whose dense soil can be burned to release carbon emissions—which are being destroyed to make way for palm oil plantations. Greenpeace argues the peatlands represent massive carbon sinks, and they claim the destruction already accounts for four percent of annual global CO₂ emissions. However, according to the Tropical Peat Research Laboratory, at least one measurement has shown that oil palm plantations are carbon sinks because oil palms convert carbon dioxide into oxygen just as other trees do, and, as reported in Malaysia's Second National Communication to the United Nations Framework Convention on Climate Change, oil palm plantations contribute to Malaysia's net carbon sink.\n\nGreenpeace recorded peatland destruction in the Indonesian province of Riau on the island of Sumatra, home to 25 percent of Indonesia's palm oil plantations. Greenpeace claims this would have devastating consequences for Riau's peatlands, which have already been degraded by industrial development and store a massive 14.6 billion tonnes of carbon, roughly one year's greenhouse gas emissions.\n\nEnvironmentalists and conservationists have been called upon to team up with palm oil companies to purchase small tracts of existing palm plantation, so they can use the profits to create privately owned nature reserves. It has been suggested that this is a more productive strategy than the current confrontational approach that threatens the livelihoods of millions of smallholders.\n\nIn the two countries responsible for over 80% of world oil palm production, Indonesia and Malaysia, smallholders account for 35–40% of the total area of planted oil palm and as much as 33% of the output. Elsewhere, as in West African countries that produce mainly for domestic and regional markets, smallholders produce up to 90% of the annual harvest.\n\nAs a result of Malaysia's commitment to retain natural forest cover on at least 50 percent of the nation's land, the growth of new palm oil plantations has slowed in recent years. According to Malaysia's Plantation Industries and Commodities Minister Bernard Dompok, significant expansion of palm oil is no longer possible, therefore Malaysian farmers are now focusing on increasing production without expansion.\n\nIn January 2008, the CEO of the Malaysian Palm Oil Council wrote a letter to the Wall Street Journal stating that Malaysia was aware of the need to pursue a sustainable palm oil industry. Since then the Malaysian government, along with palm oil companies, have increased production of certified sustainable palm oil (CSPO). Malaysia has been recognized by the Roundtable on Sustainable Palm Oil as the largest producer of CSPO, producing 50 percent of the world's supply, and accounting for 40% of CSPO growers worldwide. Indonesia produces 35 percent of the world's CSPO.\n\nIn Indonesia, the Indigenous Peoples' Alliance of the Archipelago (AMAN) under the direction of Mina Susana Setra has fought for policies that find balance between economic need and indigenous people's rights. 99% of the palm oil concessions in the country concern land that is occupied by indigenous people. In 2012, AMAN led an advocacy team which won a Constitutional Court case recognizing customary land rights; however, implementation of programs that protect indigenous rights, the environment and developers have failed to come to fruition except in limited cases.\n\nIn Africa, the situation is very different compared to Indonesia or Malaysia. In its Human Development Report 2007-2008, the United Nations Development Program says production of palm oil in West Africa is largely sustainable, mainly because it is undertaken on a smallholder level without resorting to diversity-damaging monoculture. The United Nations Food and Agriculture program is encouraging small farmers across Africa to grow palm oil, because the crop offers opportunities to improve livelihoods and incomes for the poor.\n\nFood and cosmetics companies, including ADM, Unilever, Cargill, Procter & Gamble, Nestle, Kraft and Burger King, are driving the demand for new palm oil supplies, demand was partly driven by a need for a replacement for high trans fat content oils.\n\nAlthough palm oil is used in the production of biofuels and proposals have been made to use it in large installations, a 2012 report by the International Food Policy Research Institute concluded that the increase in palm oil production is related to food demands, not biofuel demands.\n\nBiodiesel made from palm oil grown on sustainable non-forest land and from established plantations reduces greenhouse gas emissions. According to Greenpeace, clearing peatland to plant oil palms releases large amounts of greenhouse gasses, and that biodiesel produced from oil palms grown on this land may not result in a net reduction of greenhouse gas emissions. However, research by Malaysia's Tropical Peat Research Unit has found that oil palm plantations developed on peatland produce lower carbon dioxide emissions than forest peat swamp. However, it has been suggested that this research unit was commissioned by politicians who have interests in the palm oil industry.\n\nIn 2011, eight of Malaysia's Federal Land Development Authority (FELDA) plantations were certified under the International Sustainability and Carbon Certification System (ISCC), becoming part of Asia's first ISCC certified supply and production chain for palm biodiesel. This certification system complies with the European Union's Renewable Energy Directive (RED). In 2012, the European Commission approved the RSPO's biofuel certification scheme allowing certified sustainable palm oil biofuel to be sold in Europe.\n\nThe Roundtable on Sustainable Palm Oil (RSPO), founded in 2004, works to promote the production of sustainably sourced palm oil through involvement with growers, processors, food companies, investors and NGOs. Beginning in 2008, palm oil that meets RSPO introduced standards has been designated \"certified sustainable palm oil\" (CSPO). Within two years of implementation, CSPO-designated palm oil comprised 7 percent of the global palm oil market. As of October 2012, 12 percent of palm oil has been certified by the RSPO. However, in the first year of CSPO certification only 30 percent of sustainable oil was marketed as CSPO.\n\nIn \"The Economist\" in 2010, the RSPO was criticized for not setting standards for greenhouse-gas emissions for plantations and because its members account for only 40 percent of palm oil production. In a 2007 report, Greenpeace was critical of RSPO-member food companies saying that they are \"dependent on suppliers that are actively engaged in deforestation and the conversion of peatlands\".\n\nFollowing a contribution of $1 billion from Norway, in May 2010, Indonesia announced a two-year suspension on new agreements to clear natural forests and peatlands. Additionally, Indonesia announced plans to create its own organization similar to the RSPO, which, as a government certification system, will introduce mandatory regulation for all Indonesian palm oil producers.\n\nIn 2011, Malaysia began developing a national certification, the \"Malaysia sustainable palm oil\" (MSPO) certification, to improve involvement in sustainable palm oil production nationwide. The certification program, aimed at small and medium-sized producers, is expected to be launched in 2014. Malaysia has initiated its own environmental assessment on oil palm industry based on Life Cycle Assessment (LCA) approaches. LCA has been applied to assess the environmental impact of production of oil palm seedlings, oil palm fresh fruit bunches, crude palm oil, crude palm kernel oil and refined palm oil. The assessment on downstream industries such as oil palm plywood and bio-diesel, was also conducted.\n\nOil palm producers are eligible to take part in Clean Development Mechanism (CDM) programs in which developed nations invest in clean energy projects in developing nations to earn carbon credits to offset their own greenhouse gas emissions and to reduce greenhouse gas emissions worldwide.\n\nInvestors have been cautious about investing in palm oil biofuel projects because of the impact the expansion of oil palm plantations has had on tropical rain forests, but according to the South East Asian CDM development company YTL-SV Carbon, many CDM projects in the palm oil sector focus on improving use of waste products to reduce gas emissions and do not contribute to the establishment of new oil palm plantations.\n\nThe World Wildlife Foundation (WWF) publishes an annual report on the use of sustainable palm oil by major corporations. In the 2011 report, 31 of the 132 companies surveyed received a top score for their use of sustainable palm oil. This represents an increase from 2009, the first year the report was issued, where no companies received top scores.\n\nThe WWF reports that 87 companies have committed to using only sustainable palm oil by 2015, including Unilever and Nestlé, both of which committed to exclusively using sustainable palm oil following demonstrations and urgings from environmental organizations in the late 2000s. However, according to the WWF, the overall growth in the use of sustainable palm oil is too slow.\n\nRetailers who have made commitments to offering products containing sustainable oil, including Walmart and Carrefour, have attributed the slow rate of growth in the availability of sustainable palm oil to a lack of consumer interest and awareness in products made with sustainable palm oil. These companies have expressed concern about the potential impact of low consumer demand on the cost and future availability of sustainable palm oil.\n\nIt may be possible to persuade governments of nations that produce competing products to enact protectionist legislation against the products of deforestation, an approach that was presented in a report by the National Farmers Union (United States) and Avoided Deforestation Partners. The 2010 report estimates that protecting the of mostly tropical forest that are lost annually worldwide would boost American agricultural revenue by $190–270 billion between 2012 and 2030. However, several conservation groups, including Conservation International, Environmental Defense Fund, National Wildlife Federation, and The Nature Conservancy, presented a rebuttal to the report, stating that it was \"based on the assumption, totally unfounded, that deforestation in tropical countries can be easily interrupted, and its conclusions are therefore also unrealistic.\"\n\n\nCompanies:\n\n\n"}
{"id": "13134006", "url": "https://en.wikipedia.org/wiki?curid=13134006", "title": "Tokyo Metropolitan Government Bureau of Waterworks", "text": "Tokyo Metropolitan Government Bureau of Waterworks\n\n\n"}
{"id": "3219248", "url": "https://en.wikipedia.org/wiki?curid=3219248", "title": "Transgranular fracture", "text": "Transgranular fracture\n\nA transgranular fracture is a fracture that follows the edges of lattices in a granular material, ignoring the grains in the individual lattices. This results in a fairly smooth looking fracture with less sharp edges than one that follows the changing grains. This can be visualized as several wooden jigsaw puzzle pieces with the grains showing, but with each piece having grains running in a different direction. A transgranular fracture follows the grains in the wood, not the edges of the puzzle pieces. This is opposed to an intergranular fracture.\n"}
{"id": "34447137", "url": "https://en.wikipedia.org/wiki?curid=34447137", "title": "Transport energy futures: long-term oil supply trends and projections", "text": "Transport energy futures: long-term oil supply trends and projections\n\nTransport Energy Futures: Long-Term Oil Supply Trends and Projections is a report published by the Department of Infrastructure, Transport, Regional Development and Local Government, and prepared by the Bureau of Infrastructure, Transport and Regional Economics (BITRE) of Australia in 2009, which calculate peak oil to occur in 2017, after which oil supply is projected to decline rapidly. It is report number 117.\n\nOn 20 January 2012, an article in the Daily Telegraph of Australia reports that a French man had put the report on the internet, while there is no sign of it anywhere on the official webpages of BITRE. The author of the article accuses the government of purposely covering up the report from the public eye, while at the same time postulated that the report was sent to a number of European organisations, reasoning this was an explanation for the report being leaked.\n\n"}
{"id": "6282950", "url": "https://en.wikipedia.org/wiki?curid=6282950", "title": "Vacuum variable capacitor", "text": "Vacuum variable capacitor\n\nA vacuum variable capacitor is a variable capacitor which uses a high vacuum as the dielectric instead of air or other insulating material. This allows for a higher voltage rating than an air dielectric using a smaller total volume. However, many dielectrics have higher breakdown field strengths than vacuum: 60-170 MV/m for teflon, 470-670 MV/m for fused silica and 2000 MV/m for diamond, compared with 20-40 MV/m for vacuum. There are several different designs in vacuum variables. The most common form is inter-meshed concentric cylinders, which are contained within a glass or ceramic vacuum envelope, similar to an electron tube. A metal bellows is used to maintain a vacuum seal while allowing positional control for the moving parts of the capacitor.\n\nNikola Tesla filed a patent in 1896 for a vacuum capacitor. The original use was to enhance the quality of the electrical components for handling \"currents of high frequency and potential\". These components were necessary for the DC impulse research which Tesla was studying. Commercial products have been available since 1942.\n\nVacuum variable capacitors are commonly used in high-voltage applications: 5000 volts (5 kV) and above. They are used in equipment such as high-powered broadcast transmitters, amateur radio RF amplifiers and large antenna tuners. Industrially they are used in plasma generating equipment, for dielectric heating, and in semiconductor manufacturing. The main applications today are RF plasmas of 2 to 160 MHz where the vacuum capacitor is used as the impedance variation part in an automatic matching network in the fabrication of chips and flat panel displays.\n\nOther variations of vacuum capacitors include fixed-value capacitors, which are designed very much like the variable versions with the exception of an adjustment mechanism.\n\nWhen compared to other variable capacitors, vacuum variables tend to be more precise and more stable. This is due to the vacuum itself. Because of the sealed chamber, the dielectric constant remains the same over a wider range of operating conditions. With air variable capacitors, the air moving around the plates may change the value slightly; often it is not much but in some applications it is enough to cause undesirable effects.\n\nVacuum variable capacitors are generally more expensive than air variable capacitors. This is primarily due to their design and the materials used. Although most use copper and glass, some may use other materials such as ceramics and metals such as gold and silver. Vacuum variables also vary in adjustment mechanisms.\n\n"}
{"id": "5052348", "url": "https://en.wikipedia.org/wiki?curid=5052348", "title": "Valve transmitters", "text": "Valve transmitters\n\nMost high power transmitter amplifiers are of valve construction because of the high power required.\n\nSince valves are designed to operate with much higher resistive loads than solid state devices, the most common anode circuit is a tuned LC circuit where the anodes are connected at a voltage node. This circuit is often known as the anode tank circuit.\n\nAn example of this used at VHF/UHF include the 4CX250B, an example of a twin tetrode would be the QQV06/40A. The tetrode has a screen grid which is between the anode and the first grid. This is grounded at the operating frequency, but carries a DC potential, normally 10 to 50% of the plate voltage. The screen grid serves to increase the stage gain while also providing shielding which increases the stability of the circuit by reducing the effective capacitance between the first grid and the anode.\n\nFor very high gain circuits, the shielding effect of the screen may not be sufficient to prevent all coupling from the plate back to the grid. Even a small amount of feedback may cause tuning difficulties and perhaps even self oscillation. Coupling of energy from the output back into the input can also occur due to poor circuit layout. It is therefore often necessary to add a neutralization circuit, which feeds some of the output signal back to the input with proper amplitude and opposite phase so as to cancel out the above-mentioned undesirable effects.\n\nIn common with all three basic designs shown here the anode of the valve is connected to a LC circuit needed to tune the plate circuit to resonance. Power may be coupled to the antenna via an additional inductive link as shown. More commonly modern circuits use a Pi network to resonate the plate circuit and match it to the antenna while also reducing harmonics.\n\nFor a fixed anode voltage the anode current of a triode can be described by the following equation\n\nI = {K.(E-N)} + {K.(E²-N)} + {K.(E³-N)} etc.\n\nFor a tetrode the equation will be:\n\nI = {K.(E-N)} + {K.(E²-N)} + {K.(E³-N)} etc. + {K.(E-N)} + {K.(E²-N)} + {K.(E³-N)} ... etc.\n\nNote that the K constants for the second grid are smaller than those of the first grid because the second grid is further away from the cathode.\n\nAs the second grid (screen grid) in a tetrode is maintained at a constant potential the equation for the tetrode can be reduced back to that of the triode as long as the screen grid is kept at the same potential.\n\n\"In short the anode current is controlled by the electrical potential (voltage) of the first grid.\" A DC bias is applied to the valve to ensure that the part of the transfer equation which is most suitable to the required application is used.\n\nThe input signal is able to perturb (change) the potential of the grid, this in turn will change the anode current. Another term for the anode in a valve is the plate so hence on many designs the anode current is named the plate current.\n\nIn the RF designs shown on this page between the anode and the high voltage supply (known by convention as B+) is a tuned circuit. This tuned circuit has been brought to resonance, and in a class A design can be thought of as a resistance. This is because a resistive load is coupled to the tuned circuit. In audio amplifiers the resistive load (loudspeaker) is coupled via a transformer to the amplifier. In short the load formed by the loudspeaker driven via the transformer can be thought of as a resistor wired between the valves anode and B+.\n\nAs the current flowing through the anode connection is controlled by the grid, then the current flowing through the load is also controlled by the grid.\n\nOne of the disadvantages of a tuned grid compared to other RF designs is the neutralization is required.\n\nAn example of a passive grid used at VHF/UHF frequencies include the 4CX250B; an example of a twin tetrode would be the QQV06/40A. The tetrode has a screen grid which is between the anode and the first grid, the purpose of the screen grid is to increase the stability of the circuit by reducing the capacitance between the first grid and the anode. The combination of the effects of the screen grid and the damping resistor often allow the use of this design without neutralization.\n\nThe signals come into the circuit through a capacitor, they are then applied to the valve's first grid directly. The value of the grid resistor determines the gain of the amplifier stage. The higher the resistor the greater the gain, the lower the damping effect and the greater the risk of instability. With this type of stage good layout is less vital.\n\nPassive grid design is ideal for audio equipment, because audio equipment must be more broadband than RF equipment. A RF device might be required to operate over the range 144 to 146 MHz (1.4% of an octave) while an audio amp might be required to operate over the range 20 Hz to 20 kHz, a range of three orders of magnitude.\n\n\n\nThis design uses a triode, the grid current drawn in this system is larger than that required for the other two basic designs. Because of this, valves such as the 4CX250B are not suitable for this circuit. This circuit design has been used at 1296 MHz using disk seal triode valves such as the 2C39A.\n\nThe grid is kept at ground, the drive is applied to the cathode through a capacitor. The heater supply must be isolated with great care from the cathode as unlike the other designs the cathode is not connected to RF ground. The cathode may be at the same DC potential as the grid if a valve such as the 811A (zero bias triode) is used, otherwise the cathode must be positive with respect to the grid to provide proper bias. This may be done by putting a zener diode between the cathode and ground, or by connecting a suitable power supply to the cathode.\n\n\n"}
{"id": "5048141", "url": "https://en.wikipedia.org/wiki?curid=5048141", "title": "Vanadium(II) oxide", "text": "Vanadium(II) oxide\n\nVanadium(II) oxide, VO, is one of the many oxides of vanadium. VO is a long-lived, electronically neutral reagent chemical. It adopts a distorted NaCl structure and contains weak V−V metal to metal bonds. As shown by band theory, VO is a conductor of electricity due to its partially filled conduction band and delocalisation of electrons in the t orbitals. VO is a non-stoichiometric compound, its composition varying from VO to VO.\n"}
{"id": "2204862", "url": "https://en.wikipedia.org/wiki?curid=2204862", "title": "Viscosity index", "text": "Viscosity index\n\nThe viscosity index (VI) is an arbitrary, unitless measure of the change of viscosity with temperature, mostly used to characterize the viscosity-temperature behavior of lubricating oils. The lower the VI, the more the viscosity is affected by changes in temperature. The VI was originally measured on a scale from 0 to 100; however, advancements in lubrication science have led to the development of oils with much higher VIs.\n\nThe viscosity of a lubricant is closely related to its ability to reduce friction in solid body contacts. Generally, the least viscous lubricant which still forces the two moving surfaces apart to achieve \"fluid bearing\" conditions is desired. If the lubricant is too viscous, it will require a large amount of energy to move (as in honey); if it is too thin, the surfaces will come in contact and friction will increase.\n\nMany lubricant applications require the lubricant to perform across a wide range of conditions, for example, automotive lubricants are required to reduce friction between engine components when the engine is started from cold (relative to the engine's operating temperatures) up to when it is running. The best oils with the highest VI will remain stable and not vary much in viscosity over the temperature range. This allows for consistent engine performance within the normal working conditions. Historically, there were two different oil types, recommended for usage in different weather conditions. For winter use, the engines required motor oil with the viscosity rating 5, while for warm and hot season it had to be changed to oil with 30-40 viscosity rating. Later on, there appeared multi-grade motor oils, which contained polymers that made the oil film thinner at higher temperatures without thickening the oil.\n\nThe VI scale was set up by the Society of Automotive Engineers (SAE). The temperatures chosen arbitrarily for reference are . The scale was originally interpolated between 0 for a naphthenic Texas Gulf crude and 100 for a paraffinnic Pennsylvania crude. Since the inception of the scale better oils have also been produced, leading to VIs greater than 100 (see below).\n\nVI improving additives and higher quality base oils are widely used nowadays which increase the VIs attainable beyond the value of 100. The Viscosity Index of synthetic oils ranges from 80 to over 400.\n\nThe viscosity index can be calculated using the following formula:\n\nwhere \"U\" is the oil's kinematic viscosity at , and \"L\" and \"H\" are values based on the oil's kinematic viscosity at . \"L\" and \"H\" are the values of viscosity at 40°C for oils of VI 0 and 100 respectively, having the same viscosity at 100°C as the oil whose VI we are trying to determine. These \"L\" and \"H\" values can be found in ASTM D2270.\n"}
{"id": "5097759", "url": "https://en.wikipedia.org/wiki?curid=5097759", "title": "Vox AC30", "text": "Vox AC30\n\nThe Vox AC30 is a guitar amplifier manufactured by Vox. It was introduced in 1958 to meet the growing demand for louder amplifiers. Characterised by its \"jangly\" high-end sound it has become widely recognized by British musicians and others.\n\nThe Vox AC30 was originally introduced in 1959 at Hank Marvin's request as the \"big brother\" of the fifteen watt (15 W) AC15 model, Vox's original flagship amplifier, because the AC15 was not loud enough with the screaming fans at Cliff Richard's concerts. The AC15 was powered by a pair of EL84 tubes, an EF86-driven \"Normal\" channel, an ECC83-driven \"Vib-Trem\" channel, and rectified by an EZ81. The original first-generation AC30 used a GZ34 tube rectifier, three ECC83s (12AX7) for the Normal channel and the tremolo/vibrato oscillator/modulator circuits, one ECC81 (12AT7) phase inverter, and EL34 tubes in the power amplifier circuit.\n\nThis first generation of AC30s were housed in \"TV-front\" cabinets, much like the early to mid-50s tweed Fender amps, and had a single 12-inch Goodmans 60-watt speaker, as opposed to the later, conventional twin 12-inch speaker configuration. These early amps sported a thin white covering (\"Rexine\") with a small printed diamond pattern and larger diamond pattern grill cloth. However, the EL34-powered AC30 was short lived, and a new AC30 version appeared in late 1959. This second generation AC30/4 had two channels with two inputs, hence the \"4\" in the model name, and a single tone control, and was powered by a quartet of EL84 (6BQ5) power tubes, making it truly a doubling of the AC15 power amp circuit. The AC30/4 also carried over the AC15's preamplifier circuit, which included the EF86 pentode in its \"Normal\" channel. Vox initially offered a 1×12\" version but subsequently introduced the 2×12\" AC30 Twin, which solved the volume problem at larger venues. The first AC30 Twins used two Goodmans Audiom 60 15-Watt Speakers, followed by Celestion G12 alnico speakers.\n\nBy 1960, Vox had forsaken the more conservative TV-front look for the now legendary cabinet design that has remained largely unchanged since 1960. The new cabinets featured a different covering known as fawn Rexine, which was a sort of beige leathercloth with a subtle printed grain. The front baffle was now divided by a thin gold-toned strip with the upper valence covered in fawn Rexine, and the lower grille covered in brown diamond cloth. Ventilation was provided by three small brass vents on the top of the cabinet, and the TV-front's single suitcase type handle was replaced with three leather straps.\nSince the higher output AC30/4 shared its preamplifier design with the lower powered AC15, Vox discovered the high-gain EF86 tube was susceptible to microphonics, or even failure, when exposed to the increased vibration present in this uprated amp. Vox soon tired of the problem so to cure AC30/4 reliability issues caused by the troublesome EF86 preamp tube, in late 1960 Vox redesigned the preamp circuit, replaced the EF86 with an ECC83 (12AX7), and released this new design as the AC30/6. The AC30/6 was now an amp with three channels, each channel having two inputs.\n\nAbout this time, the \"Top Boost\" (or \"Brilliance\") feature became available as Vox's optional addition of a rear panel-mounted circuit that introduced an extra gain stage and tone controls for bass and treble (as opposed to the single \"tone\" control of earlier AC30s). The unit became so popular that its features were soon incorporated in newer AC30/6 models, and the controls moved from the rear panel to the control panel. Vox AC30/6 amplifiers from around 1963 had already implemented the top boost, and therefore had three tone controls. People began to refer to these amplifiers as AC30TBs. Later on, Vox also offered additional versions of the AC30 unit. In addition to the \"Normal\" version without the Top Boost, and the Top Boost version (which was a Normal version with the \"Brilliance\" unit added), Vox, with slight circuit modifications, created two more versions that were \"voiced\" in Brilliant (Treble), and Bass styles. Over the years many different AC30 models appeared but many consider the AC30 \"Super Twin\" to be the ultimate AC30, with a \"trapezoid\" shaped head and a separate speaker mounted on a trolley (see \"The Vox Story\", Petersen & Denney 1993, p.39; see also the Vox showroom web site).\n\nIn the late '60s Jennings drifted into financial problems and the company experienced various owner changes. Quality control was also inconsistent.\n\nDuring the Vox brand's early '70s \"Dallas Arbiter\" period, the tube rectifiers of AC30s were replaced by silicon rectifiers, which became standard on later AC30TB models. In the late 1970s Vox also introduced a solid-state AC30 (AC30SS), which is the AC30 model that was used by Status Quo. A tube AC30TB with spring reverb feature was reintroduced in 1978.\n\nIn spite of at least one AC30 production run titled \"Limited Edition\" of 100 units with starting serial number 0100 (1991) (no reverb), production of the AC30 has practically never ceased: Newer AC30s are reissues of the various top boost AC30/6 (AC30TB) models. AC30s made between 1989 and 1993 also had spring reverb as a standard feature.\n\nThe Rose Morris company, who owned the Vox name through the 1980s, sold Vox to Korg in the early 1990s, who then manufactured a reissue of the early '60s AC30 Top Boost, correcting previous inconsistencies ranging from the correct style grille cloth to the GZ34 rectifier tube. These AC30 amps were mostly offered in the traditional black Tolex/brown diamond grille configuration, but were also available in limited numbers with purple, red, or tan tolex. These amplifiers, like all AC30s to this point, were manufactured in Great Britain. These were available with a choice of Celestion \"Blue\" or \"Greenback\" speakers. In the mid 1980s, a company in Marlborough, MA, called Primo, imported and began re-distributing the AC30s in the U.S.\n\nIn 2003, Vox created the \"AC30 Heritage Handwired Limited Edition\" amplifier (AC30HW). This amplifier differed from the standard offering in notable ways. First, the circuitry was constructed using old-fashioned tag strips. According to Vox this was far more labor-intensive, but it allowed for easier repair versus circuit boards because there were no copper tracks to burn. According to the Vox showroom site:\n\n\"1960s era Vox amps were hand wired on tag strips. The connecting lead (or wire) from each electronic part was manually wrapped around a terminal, or \"tag,\" and then soldered. This mode of amp construction is very labour-intensive and the workmanship and accuracy of the employee building the amp will affect the performance of the product. It was for this reason that most electronics manufacturers transitioned to phenolic printed circuit boards by 1970.\"\n\nThe second notable difference was the features and control layout. Guitar Player magazine reviewed the amp in its \"Exotica\" feature, December 2002. The article specifies details of the amp, including price, and its control layout:\n\n\"The AC30 HW ($4,000; head $3,250; 2×12 cab $1,350), which was developed with input from boutique amp designer Tony Bruno, features the famous Top Boost preamp, but has a control that is quite different from the standard model. For starters, there are only two inputs, which are marked Hi and Lo (AC30s traditionally have six inputs). To the right are the volume, treble, bass and tone-cut controls, a tremolo section with speed and depth knobs, a reverb section with reverb and tone controls, and a master volume.\" [And further into the article:] Top of the Marque. The AC30HW is by far the best AC variant to date. Few amps come close to matching its radiant complexity and those that do typically don't offer reverb and tremolo. The only downer about the HW is that only 350 of them will be made (along with 200 heads and cabinets).\"\n\nIn 2004, Vox introduced a new series of amplifier called the AC30 Custom Classic. It claims to combine attributes of the original AC30 with what Vox sales literature refers to as a \"boutique\" of features. Specifications of the AC30CC series are two Inputs (Top Boost and Normal), an Input Link Switch for blending channels, a Normal Volume knob, a Brilliance Switch, a Top Boost Volume knob, a Treble knob, an EQ Standard/Custom Switch, Bass and Reverb Controls (Tone, Mix, and a Dwell Switch), Tremolo Speed & Depth knobs, a Tone Cut knob, a Master Volume knob, a Standby and a Power Switch, switchable cathode bias (Output Bias switch: \"50 Hot\": 33W at full power, \"82 Warm\": 22W at low power), switchable filter values (vintage/modern), and a true bypass effects loop. Newer AC30CC (or \"Custom Classic\") reissues (CC1, CC2X CCH head) are produced in China.\n\nAt the 2010 Winter NAMM expo Vox introduced the Custom series; these models were updates to the 2004 Custom Classic series amplifiers and featured two channels (Normal and Top Boost) with two inputs for each channel (High and Low), more akin to the original AC30/4 layout released in 1958. It was available with either Greenback speakers (C2) or Alnico Blue Speakers (C2x), and was also available as the AC15. Later limited edition models include the AC30BL, a tygoon blue tolex with grey speaker cloth, an AC30C2RD with a red finish, an AC30C2-BRG a British Racing Green tolex finish with a grey speaker cloth and the AC30C2 Black Comet; featuring a patterned finish all are identical to the C2. The amp featured an option known as \"Jumping\" where the High-Normal channel could be linked to the Low-Top Boost channel with a patch lead, whilst the guitar is plugged into the High-Top Boost channel, allowing both channels to sound and create a fuller, thicker overdrive sound. The amp also featured a solid-state rectifier to increase reliability. Controls include a Normal volume, Top Boost Volume, Treble and Bass controls, Reverb Tone and Level controls, Tremolo Speed and Depth controls, a Tone Cut control (to add further control over the higher-frequencies), a Master Volume, and a Standby and Power Switch. A true bypass effects loop, extension cab output and external cab output were also included; as well as an input for the external foot switch (to control Reverb and Tremolo). The amps are produced in China. The amps were released to critical success, garnering awards such as Music Radar's \"Guitarist Choice\" award. \n\nIntroduced in 2010, the amp featured Hand-wired turret board construction (against cheaper PCB construction), Birch-ply cabinets featuring solid bracing and a natural high frequency diffuser (versus MDF cabinets and no high frequency diffuser); All-tube design (different from the Custom series tube pre/power amp but solid-state rectifier); ECC83/12AX7 preamp tubes (×3) EL84 power tube quartet; (AC30 models); EL84 Duet (AC15 models); GZ34 rectifier (AC30 models); EZ81 rectifier (AC15 models); came factory-fitted with matched Ruby Tubes to provide extended dynamic range; maintained the traditional VOX two-channel design (Top Boost and Normal. High and Low inputs for each channel); the Normal channel features an additional BRIGHT switch; The top boost channel features a HOT/COOL switch to achieve even more gain. A Master Volume/BYPASS switch completely bypasses the Master Volume section allowing incredible levels of gain and sustain to be achieved. OP mode switch cut the amp's Output Power level in half (30 > 15 on the AC30, 15 > 7.5 on the AC15) allowing higher levels of saturation to be achieved at lower volumes. A Vintage fawn-colored vinyl covering, reminiscent of the 1960 classic AC30 and was available with either Celestion Alnico Blue or Celestion G12M Greenback speakers. A VFS1 footswitch controls the Top Boost channel's HOT/COOL switch was also included. The Heritage series 50th anniversary models incorporate the classic EF86 pre-amp tube, which although subject to failure in the late '50s had been re-introduced and improved. The classic EF86 pre-amp tube is remarkable for its high gain and for the notable harmonic overtones it produces and feeds to the power tubes when driven into distortion, providing the creamy distinctive VOX sound of the early hand made amplifiers produced by Jennings of Dartford. Clapton, Cream, Pink Floyd and Queen are ambassadors to the success of the early AC30s. The Heritage series 50th anniversary model stands alone as either the AC15 or AC30 with this distinct circuitry not found in the current VOX line-up.\n\nRecently, Vox released a limited edition version of the amp, the AC30BM, based on the tone of one of the amp's most prominent and consistent endorsers, Brian May of Queen. The amp is limited to only a few hundred examples worldwide, in a 'never-to-be-repeated' run. As the amp is designed to replicate May's tone, there are no controls on the amp except for a single volume control, though a switch enables the user to halve the number of output valves (therefore reducing the output to 15 watts as well as the volume, making it more suitable for home use), and there is a boost function operated from the included footswitch.\n\nAs of 2006, a company having licensed the name JMI (Jennings Musical Instruments) began manufacturing period correct, British made AC30 \"copy\" amplifiers, available in both black and beige. Since this incarnation of JMI has never owned the Vox brand, their official website lists the disclaimer \"JMI amplification are in no way affiliated with Vox amplification (Korg)\", and the models are listed as 30/6 (6 input) and 30/4 (4 inputs, sans \"Brilliant\" channel). As originally the case in the 1960s, Top Boost is offered as a retrofit upgrade and is not standard, and the original configuration 4/6 inputs are offered with options for Green/Blue speakers, the blue speakers being similar in appearance to the Celestion alnico speaker but made by Fane International with fiberglass voice coils, which allow them a much higher 100 watt power rating. JMI later changed alnico speakers to ones made by Tayden.\n\nAnother recent addition is the VOX AC30VR (Valve Reactor). According to the Vox website, this version of the AC30 includes both \"solid-state\" and \"tube\" technology. Originally designed for the Valvetronix modelling amplifiers, the Valve Reactor circuit places a 12AX7 dual triode vacuum tube (or \"valve\") into the power stage, which is a tube configured to act as a small power amplifier. Too small to be used as an amplifier on its own, the output of this Valve Reactor circuit is fed to a solid state power amp that boosts the output signal.\n\nThough widely believed to be a class A amplifier, the AC30 is in fact class AB. It uses a quartet of cathode-biased EL-84 output tubes in push-pull configuration. The high bias condition is believed by some to be the source of the amplifier's famous immediate response and \"jangly\" high-end, though the lack of negative feedback, minimal preamp circuit, simple low loss tone stack, and the use of cathode biasing on the output stage play at least as large a role, if not larger. The Celestion \"Blue\" speakers that are integral to the AC30 also contribute much to the sound of the unit. The two 12\" 15-watt speakers, often overdriven and at the brink of their power handling capability, provide a cutting mid-range speaker sound that is immediate and sharp and a distinction from the Marshall or Fender-style amplifier.\n\n\n"}
{"id": "4512387", "url": "https://en.wikipedia.org/wiki?curid=4512387", "title": "Water gas", "text": "Water gas\n\nWater gas is a mixture of carbon monoxide and hydrogen produced from synthesis gas. Synthesis gas is a useful product, but requires careful handling due to its flammability and the risk of carbon monoxide poisoning. The water-gas shift reaction can be used to reduce the carbon monoxide while producing additional hydrogen, resulting in water gas.\n\nSynthesis gas is made by passing steam over a red-hot carbon fuel such as coke:\n\nThe reaction is endothermic, so the fuel must be continually re-heated to keep the reaction going. In order to do this, an air stream, which alternates with the vapor stream, is introduced for the combustion of carbon to take place.\nTheoretically, to make 6 L of water gas, 5 L of air is required.\n\nOr, alternatively, to prevent contamination with nitrogen, energy can be provided by using pure oxygen to burn carbon into carbon monoxide.\nIn this case 1 L of oxygen will create 5.3 L of pure water gas.\n\nThe water-gas shift reaction was discovered by Italian physicist Felice Fontana in 1780.\n\nWater gas was made in England from 1828 by blowing steam through white-hot coke.\n\nIn 1873, Thaddeus S. C. Lowe developed and patented the water gas process by which large amounts of hydrogen gas could be generated for residential and commercial use in heating and lighting. This gas provided a more efficient heating fuel than the common coal gas, or coke gas, which was used in municipal service. The process used the water-gas shift reaction:\n\nThe process was discovered by passing high-pressure steam over hot coal, the major source of coke gas. Lowe's process improved upon the chimney systems by which the coal could remain superheated, thereby maintaining a consistently high supply of the gas. The reaction produced carbon dioxide and hydrogen, which, after a process of cooling and \"scrubbing\", produced hydrogen gas.\n\nThe process spurred on the industry of gas manufacturing, and gasification plants were established quickly along the Eastern seaboard of the United States. Similar processes, like the Haber–Bosch process, led to the manufacture of ammonia (NH) by the combining of nitrogen, found in air, with hydrogen. This spurred on the refrigeration industry, which long used ammonia as its refrigerant. Prof. Lowe also held several patents on artificial ice making machines and was able to run successful businesses in cold storage, as well as products which operated on hydrogen gas.\n\nWater gas has a lower heat of combustion than coal gas, so the calorific value was often boosted by passing the gas through a heated retort, into which oil was sprayed. The resulting mixed gas was called \"carburetted water gas\".\n\n\"Semi-water gas\" is a mixture of water gas and producer gas made by passing a mixture of air and steam through heated coke. The heat generated when producer gas is formed keeps the temperature of the coke high enough to allow water gas to be formed.\n\nPure hydrogen can be obtained from water gas by using the water-gas shift reaction, after subsequent removal of the carbon dioxide formed when carbon monoxide reacts with water.\n\n\n"}
{"id": "39538223", "url": "https://en.wikipedia.org/wiki?curid=39538223", "title": "Yuzivska gas field", "text": "Yuzivska gas field\n\nThe Yuzivska gas field is a Ukrainian natural gas field that was discovered in 2010. It will begin production in 2017 and will produce natural gas and condensates. The total proven reserves of the Yuzivska gas field are around 70.8 trillion cubic feet (2000×10m³) and production is slated to be around 960 million cubic feet/day (27.4×10m³). The total exploration investment is expected to range between 250-300 million US$. \n"}
{"id": "25772247", "url": "https://en.wikipedia.org/wiki?curid=25772247", "title": "ZND detonation model", "text": "ZND detonation model\n\nThe ZND detonation model is a one-dimensional model for the process of detonation of an explosive. It was proposed during World War II independently by Y. B. Zel'dovich, John von Neumann, and Werner Döring, hence the name.\n\nThis model admits finite-rate chemical reactions and thus the process of detonation consists of the following stages. First, an infinitesimally thin shock wave compresses the explosive to a high pressure called the von Neumann spike. At the von Neumann spike point the explosive still remains unreacted. The spike marks the onset of the zone of exothermic chemical reaction, which finishes at the Chapman-Jouguet state. After that, the detonation products expand backward.\n\nIn the reference frame in which the shock is stationary, the flow following the shock is subsonic. Because of this, energy release behind the shock is able to be transported acoustically to the shock for its support. For a self-propagating detonation, the shock relaxes to a speed given by the Chapman–Jouguet condition, which induces the material at the end of the reaction zone to have a locally sonic speed in the reference frame in which the shock is stationary. In effect, all of the chemical energy is harnessed to propagate the shock wave forward.\n\nHowever, in the 1960s, experiments revealed that gas-phase detonations were most often characterized by unsteady, three-dimensional structures, which can only in an averaged sense be predicted by one-dimensional steady theories. Indeed, such waves are quenched as their structure is destroyed. The Wood-Kirkwood detonation theory can correct for some of these limitations.\n"}
