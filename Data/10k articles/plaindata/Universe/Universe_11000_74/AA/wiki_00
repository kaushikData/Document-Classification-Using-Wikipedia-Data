{"id": "10382537", "url": "https://en.wikipedia.org/wiki?curid=10382537", "title": "2003 Melbourne thunderstorm", "text": "2003 Melbourne thunderstorm\n\nThe 2003 Melbourne thunderstorm was a severe weather event that occurred over the city of Melbourne, Australia, and surrounding areas of Victoria, from 1 to 6 December 2003. The Australian Bureau of Meteorology called the storm a \"once in 100-year event\".\n\nAccording to the Bureau of Meteorology, the storm formed at around midnight on the night of 2 December over Craigieburn, then grew in size as it moved in a south-easterly direction (the Bureau issued a severe thunderstorm warning based on their observations at 11.38 pm). The two hours from midnight to 2 am saw extremely heavy rainfall, with some areas recording more than 100 mm of rain in that time. The rapid rainfall caused flash flooding, which resulted in extensive damage to property.\n\nA number of motorists were trapped on the roofs of their cars as chest-high floodwater accumulated under the Bulleen Road Bridge on the Eastern Freeway. They were rescued by Melbourne's Metropolitan Fire Brigade using two maritime response unit boats. Severe hailstorms caused thousands of dollars of damage to cars in the suburb of Lilydale. Rail company Connex Melbourne announced that flooding and power damage at Blackburn, Surrey Hills and Boronia railway stations would cause transport delays the following day. Victoria Police arrested two people in connection with incidents of looting in Fairfield which had occurred during the height of the storms.\n\nThe Bureau of Meteorology referred to the 2003 Melbourne Storms as a \"once in 100-year event\" but two similar storms, the 2005 Melbourne Thunderstorm and the 2010 Victorian storms, have hit Melbourne both which were also called a once in 100-year event.\n\n\n"}
{"id": "34914757", "url": "https://en.wikipedia.org/wiki?curid=34914757", "title": "2012 Astrakhan gas explosion", "text": "2012 Astrakhan gas explosion\n\nThe 2012 Astrakhan gas explosion occurred on February 27, 2012 at an apartment building in the city of Astrakhan, Astrakhan Oblast, Russia. It was caused by a natural gas explosion. The blast killed at least 10 people and injured 12.\n\nA nine-storey apartment block collapsed after a gas explosion. The rescuers battled to find up to 14 people still feared trapped under the rubble.\n\n"}
{"id": "6938279", "url": "https://en.wikipedia.org/wiki?curid=6938279", "title": "Australian Marine Conservation Society", "text": "Australian Marine Conservation Society\n\nThe Australian Marine Conservation Society (AMCS) is an Australian environmental not-for-profit organisation. It was founded in 1965 as the Queensland Littoral Society before changing its name to the Australian Littoral Society and then finally in 1995 to its current title. It works on protecting the health and vitality of Australia's coasts and oceans.\n\nThe Australian Marine Conservation Society is Australia's only national charity dedicated exclusively to protecting ocean wildlife and their homes.\n\nThe key focus of AMCS is to create large marine national parks (marine sanctuaries), sustainable fisheries and protect and recover our threatened ocean wildlife, such as our sharks, seals and whales. AMCS also works to protect Australia's coasts from inappropriate development, including along the Great Barrier Reef. \n\nThe Australian Marine Conservation Society is an independent charity, staffed by a committed group of professional and passionate scientists, educators and advocates who have defended Australia's oceans for fifty years.\n\nThe Patron of the Australian Marine Conservation Society is author Tim Winton.\n\n"}
{"id": "4331792", "url": "https://en.wikipedia.org/wiki?curid=4331792", "title": "Azienda Elettrica Ticinese", "text": "Azienda Elettrica Ticinese\n\nAzienda Elettrica Ticinese (AET) is a electricity wholesaler based in Bellinzona (Ticino, Switzerland). It's a commercial independent public body owned by the canton Ticino.\n\nAET is a public company founded in 1958, which is active in the selling, production and transport of electricity in Switzerland and abroad. AET’s institutional mandate is to guarantee the procurement of electricity for the Canton of Ticino at competitive prices. AET owns and operates a number of hydroelectric and solar generation assets. Furthermore, it owns 420 km of high-voltage grid and the 2014 revenue amounted to 1.1 billion Euro.\n\nOn the 31.12.2014 the AET group had 434 employees.\n\n"}
{"id": "40774157", "url": "https://en.wikipedia.org/wiki?curid=40774157", "title": "Boterwaag", "text": "Boterwaag\n\nThe Boterwaag is a former weigh house for butter in The Hague, Netherlands. The right half is a café.\n\nThe left-half of the building was designed by the architect-painter Bartholomeus van Bassen. He designed and built it in 1650, after the Prinsegracht canal was dug in 1640. He oversaw both projects in his role as city architect and headman of the Guild of St. Luke. After he died in 1652, the local painters became dissatisfied with the guild and founded the Confrerie Pictura in 1656, which met upstairs. They shared their meeting room upstairs with the guild of apothecaries, and the city apothecary shop was across the street. In 1681 the right half was built as an extension, and new scales were installed inside that can still be seen by visitors to the café there.\n\nIn 2013 a replica of the 17th-century brass bell was replaced on the facade that had been stolen in 1980s.\n"}
{"id": "18795464", "url": "https://en.wikipedia.org/wiki?curid=18795464", "title": "Bragg Institute", "text": "Bragg Institute\n\nThe Australian Centre for Neutron Scattering (ACNS), formerly the Bragg Institute, is a landmark neutron and X-ray scattering facility in Australia. It is located at the Australian Nuclear Science and Technology Organisation's (ANSTO) Lucas Heights site, 40 km south west of Sydney, in New South Wales, Australia.\n\nThe Institute was formed in December 2002 in preparation for the start-up of the Open-pool Australian lightwater reactor in 2006, and named as a tribute to the father-and-son team Sir William Henry Bragg and son William Lawrence Bragg, who were jointly awarded the Nobel Prize for Physics in 1915 for pioneering the analysis of crystal structures by means of X-rays. Following a restructure of scientific operations in 2016, the Institute was split to form two distinct research platforms, ACNS and the National Deuteration Facility.\n\nACNS operates the cold- and thermal-neutron scattering facility associated with the OPAL research reactor, including 14 operational neutron beam instruments, and one instrument in transfer from the BER-II Research Reactor at the Helmholtz-Zentrum Berlin. It houses a helium-3 polarisation system to enable polarised-neutron experiments, two small-angle X-ray scattering instruments, an X-ray reflectometer and Physical Properties Measurement System.\n\nNeutron scattering covers an extremely wide range of disciplines from fundamental physics, through chemistry, materials, and biology, right through to interdisciplinary areas such as engineering and archaeology. Science at the Australian Centre for Neutron Scattering covers many of these areas, usually in collaboration with other groups, with a focus on the application of neutron scattering to crystallography, soft condensed matter, solid-state physics, physical chemistry and increasingly biology. The ACNS identifies 6 key scientific projects: The Food Science Project, Thermo-Mechanical Processes, Energy Materials, Magnetism, Cultural Heritage and Planetary Materials.\n\nFrom its inception until 2016, the Institute was led by Robert Robinson. In 2016 Jamie Schulz became leader of the ACNS. ACNS currently employs approximately 100 staff.\n\nAccess to the neutron instrumentation at the ACNS is available to all qualified applications through either proprietary fee-for-service research, non-proprietary peer reviewed merit access, non-proprietary peer reviewed research program process for 3-year programs, or fast-turnaround experiments. Research proposals are accepted and reviewed twice yearly via the ACNS Customer Portal.\n\n"}
{"id": "56962845", "url": "https://en.wikipedia.org/wiki?curid=56962845", "title": "Bund Deutscher Holzwirte", "text": "Bund Deutscher Holzwirte\n\nBund Deutscher Holzwirte (BDH) (English: Association of German Wood Scientists) is a professional and alumni association for graduates of the German degree course for Holzwirtschaft (English: Wood Science), founded in 1950.\n\nThe BDH was founded on 22 July 1950 in Hamburg (Germany) by graduates of the degree program for Holzwirtschaft. \nThis course of study was established in 1939 by the Reichsinstitut für ausländische und koloniale Forstwirtschaft (English: Reich Institute for Foreign and Colonial Forestry). As of 1946 the University of Hamburg continues the course.\n\nThe purpose of the BDH is 'to promote wood economy by exchanging professional experiences as well as maintaining personal contacts of the members, to support the professional development of the members and to inform about the degree program for Holzwirtschaft' (translated paragraph of the statutes).\n"}
{"id": "35845754", "url": "https://en.wikipedia.org/wiki?curid=35845754", "title": "Chlormequat", "text": "Chlormequat\n\nChlormequat is an organic compound with the formula that is used as a plant growth regulator. It is typically sold as the chloride salt, chlormequat chloride, a colorless hygroscopic crystalline substance that is soluble in water and ethanol. It is an alkylating agent and a quaternary ammonium salt.\n\nChlormequat has been called the \"most important inhibitor of gibberellin biosynthesis.\" As such, it inhibits cell elongation, resulting is thicker stalks, which are sturdier, facilitating harvesting of cereal crops.\n\nIn the United States, chlormequat is classified as a low risk plant growth regulator and it is registered for use on ornamental plants grown in greenhouses, nurseries, and shadehouses. It is not approved for use on crops intended for use in food or animal feed.\n\nThe (rat, oral) is low, approximately 670 mg/kg.\n\nExposure to high levels of chlormequat has been linked to developmental toxicity in animal models. It also affects reproduction in mammals.\n\nIt is classified as an extremely hazardous substance in the United States as defined in Section 302 of the U.S. Emergency Planning and Community Right-to-Know Act (42 U.S.C. 11002), and is subject to strict reporting requirements by facilities which produce, store, or use it in significant quantities.\n"}
{"id": "81825", "url": "https://en.wikipedia.org/wiki?curid=81825", "title": "Composite armour", "text": "Composite armour\n\nComposite armour is a type of vehicle armour consisting of layers of different material such as metals, plastics, ceramics or air. Most composite armours are lighter than their all-metal equivalent, but instead occupy a larger volume for the same resistance to penetration. It is possible to design composite armour stronger, lighter and less voluminous than traditional armour, but the cost is often prohibitively high, restricting its use to especially vulnerable parts of a vehicle. Its primary purpose is to help defeat high explosive anti-tank (HEAT) rounds.\n\nHEAT had posed a serious threat to armoured vehicles since its introduction in World War II. Lightweight and small, HEAT rounds could nevertheless penetrate hundreds of millimetres of the hardest steel armours. The capability of most materials for defeating HEAT follows the \"density law\", which states that the penetration of shaped charge jets is proportional to the square root of the shaped charge liner density (typically copper) divided by the square root of the target density. On a weight basis, lighter targets are more advantageous than heavier targets, but using large quantities of lightweight materials has obvious disadvantages in terms of mechanical layout. Certain materials have an optimal compromise in terms of density that makes them particularly useful in this role.\n\nThe earliest known composite armour for armoured vehicles was developed as part of the US Army's T95 experimental series from the mid-1950s. The T95 featured \"siliceous-cored armor\" which contained a plate of fused silica glass between rolled steel plates. The stopping power of glass exceeds that of steel armour on a thickness basis and in many cases glass is more than twice as effective as steel on a thickness basis. Although the T95 never entered production, a number of its concepts were used on the M60 Patton, and during the development stage (as the XM60) the siliceous-cored armour was at least considered for use, although it was not a feature of the production vehicles.\n\nThe first widespread use of a composite armour appears to have been on the Soviet T-64. It used an armour known as Combination K, which apparently is glass-reinforced plastic sandwiched between inner and outer steel layers. Through a mechanism called thixotropy, the resin changes to a fluid under constant pressure, allowing the armour to be moulded into curved shapes. Later models of the T-64, along with newer designs, used a boron carbide-filled resin aggregate for greatly improved protection. The Soviets also invested heavily in reactive armour, which allowed them some ability to control quality, even after production.\n\nThe most common type of composite armour today is Chobham armour, first developed and used by the British in the experimental FV 4211 tank, which was based on Chieftain tank components. Chobham sandwiches a layer of ceramic between two plates of steel armour, which was shown to dramatically increase the resistance to HEAT rounds, even in comparison to other composite armour designs. Chobham was such an improvement that it was soon used on the new U.S. M1 Abrams main battle tank (MBT) as well. It is the fabrication of the ceramic in large tiles that gives the Challenger and Abrams their \"slab sided\" look.\n\nChobham's precise mechanism for defeating HEAT was uncovered in the 1980s. High speed photography showed that the ceramic material shatters as the HEAT round penetrates, the highly energetic fragments destroying the geometry of the metal jet generated by the hollow shaped charge, greatly diminishing the penetration. The effectiveness of the system was amply demonstrated in Desert Storm, where not a single British Army Challenger tank was lost to enemy tank fire. (However, one was destroyed by friendly fire on March 25, 2003, killing two crew members after a HESH round detonated on the commander's hatch causing high-velocity fragments to enter the turret.) Chobham-type armour is currently in its third generation and is used on modern western tanks such as the British Challenger 2 and the American M1 Abrams. The Abrams is also unique in its usage of depleted uranium armour plates in conjunction with composite armour, increasing overall vehicle protection. \n\nAll modern third-generation main battle tanks use composite armour arrays in their construction. While many of these vehicles feature the composite armour permanently integrated with the vehicle, the Japanese Type 10 and Type 90 Kyū-maru MBTs, French Leclerc, Iranian Karrar,Turkish Altay, Indian Arjun, Italian Ariete and Chinese Type 96/98 and Type 99 tanks use a modular composite armour, where sections of the composite armour can be easily and quickly switched out or upgraded with armour modules. The adoption of modular composite armour design facilitates far more efficient and easier upgrades and exchanges of the armour. \n\nSoviet/Russian main battle tanks such as T-90s T-80Us and the Chinese Type 96/99s use composite armour in tandem with explosive reactive armour (ERA), making it hard for shaped charge munitions such as HEAT rounds and missile warheads to penetrate the frontal and a portion of their side armour. The most advanced versions of these armours such as the RELIKT-1 and Kontakt-5 armour provide protection not only against shaped charges but also kinetic energy penetrators by using the explosive force to shear the projectile apart.\n\nApplique armour has also been used in conjunction with composite armour to provide increased amounts of protection and to supplant existing composite arrays on a vehicle. The German Leopard 2A5 featured distinctive arrowhead laminated armour modules that was mounted directly onto the turret composite arrays, increasing protection markedly above the previous 2A4 model. \n\nComposite armour has since been applied to smaller vehicles, right down to jeep-sized automobiles. Many of these systems are applied as upgrades to existing armour, which makes them difficult to place around the entire vehicle. Nevertheless, they are often surprisingly effective; upgrades with MEXAS ceramic armour to Canadian M113s were carried out in the 1990s, after it was realized that it would offer more protection than newly built IFVs like the M2 Bradley.\n\nIn 2004, Marvin Heemeyer used an \"ad hoc\" composite armour on his Komatsu D355A bulldozer (\"Killdozer\") used in a rampage in response to a dispute with the city he lived in over a zoning issue. The armour, at some places a foot thick, consisted of a layer of concrete sandwiched between layers of steel, successfully rendering the vehicle impervious to small arms fire and small explosives used by law enforcement in an attempt to stop the vehicle.\n\n"}
{"id": "2152426", "url": "https://en.wikipedia.org/wiki?curid=2152426", "title": "Cyclone furnace", "text": "Cyclone furnace\n\nA cyclone furnace is a type of coal combustor commonly used in large industrial boilers.\n\nDeveloped in the early 1942 by Babcock & Wilcox to take advantage of coal grades not suitable for pulverized coal combustion, cyclone furnaces feed coal in a spiral manner into a combustion chamber for maximum combustion efficiency.\n\nDuring coal combustion in a furnace, volatile components burn without much difficulty. Fuel carbon “char” particles (heavier, less volatile coal constituents) require much higher temperatures and a continuing supply of oxygen. Cyclone furnaces are able to provide a thorough mixing of coal particles and air with sufficient turbulence to provide fresh air to surfaces of the coal particles.\n\nCyclone furnaces were originally designed to take advantage of four things\n\nA cyclone furnace consists of a horizontal cylindrical barrel attached through the side of a boiler furnace. The cyclone barrel is constructed with water cooled, tangential oriented, tube construction. Inside the cyclone barrel are short, densely spaced, pin studs welded to the outside of the tubes. The studs are coated with a refractory material, usually silica or aluminium based, that allows the cyclone to operate at a high enough temperature to keep the slag in a molten state and allow removal through the tap.\n\nCrushed coal and a small amount of primary air enter from the front of the cyclone into the burner. In the main cyclone burner, secondary air is introduced tangentially, causing a circulating gas flow pattern. The products, flue gas and un-combusted fuel, then leave the burner and pass over the boiler tubes. Tertiary air is then released further downstream to complete combustion of the remaining fuel, greatly reducing NOx formation. A layer of molten slag coats the burner and flows through traps at the bottom of the burners, reducing the amount of slag that would otherwise form on the boiler tubes.\n\nCyclone Furnaces can handle a wide range of fuels. Low volatile bituminous coals, lignite coal, mineral rich anthracitic coal, wood chips, petroleum coke, and old tires can and have all been used in cyclones.\n\nThe crushed coal is fed into the cyclone burner and fired with high rates of heat release. Before the hot gases enter in the boiler furnace the combustion of coal is completed. The crushed coal is fed into cyclone burners .The coal is Burned by centrifugal action which is imparted by the primary air which enters tangentially and secondary Air which also enters in the top tangentially at high speed and tertiary air is admitted in the centre.\nDue to Whirling action of coal and air, a large amount of heat is generated (1500-1600°c)and that covered the surface of cyclone and ashes are transformed into molten slag .The molten slag drained from the boiler furnace through a slag tap.\n"}
{"id": "2735653", "url": "https://en.wikipedia.org/wiki?curid=2735653", "title": "Dado set", "text": "Dado set\n\nA dado set or dado blade is a type of circular saw blade, usually used with a table saw or radial arm saw, which is used to cut dadoes or grooves in woodworking. There are two common kinds of dado sets, stacked dado set and wobble blade.\n\nStacked dado set consists of two circular saw blades fixed on either side of a set of removable chippers. As the dado set spins, the two outside blades cut the dado walls and the chippers remove the waste material in between and smooth the bottom of the dado. The chippers are added or removed to the set as required to make a dado of the desired width. Chippers can also be interspersed with spacers to finely adjust the dado width. Consequently, changing the dado width requires the complete removal of the dado blade set from the arbor. After disassembly, chippers and/or spacers are used to achieve the desired width of the dado set.\n\nWobble blade or wobble dado or adjustable dado consists of a circular blade mounted on an adjustable multi-piece hub, that varies the angle of the blade to the arbor shaft. The width of the dado cut increases as the angle gets farther from the radial normal (90°) to the arbor. While it is possible to adjust the thickness of the cut while the saw is mounted on the arbor, accurate adjustment is usually difficult because tightening the arbor nut often changes the adjustment. Also, because of their inherent geometry wobble blades can only produce a flat-bottomed dado at one width setting, which may be a disadvantage in certain joinery operations. Another disadvantage of a wobble dado over stacked dado is undesirable vibrations. The magnitude of these vibrations varies with the blade's angular offset. In other words, the wider the dado, the stronger the vibrations.\n"}
{"id": "14289159", "url": "https://en.wikipedia.org/wiki?curid=14289159", "title": "Ednatol", "text": "Ednatol\n\nEdnatol is a yellow high explosive, comprising about 58% ethylenedinitramine (aka Haleite or Explosive H) and 42% TNT. It was developed in the United States circa 1935 and used as a substitute for Composition B in large general purpose and fragmentation bombs. It has a detonation velocity of approximately 7,400 metres per second.\n\nEdnatol was also used as Pentolite is used: in rockets, grenades and high-explosive antitank shells. Ednatol was cast in the same manner as amatol. The resulting explosive was stable, non-hygroscopic and could be stored for long periods.\n\nEdnatol has no civilian applications. It was developed by the U.S. Army at Picatinny Arsenal exclusively intended for military use and was especially popular during the Second World War. It is now an obsolete explosive and therefore unlikely to be encountered, except in legacy munitions and unexploded ordnance.\n"}
{"id": "9129313", "url": "https://en.wikipedia.org/wiki?curid=9129313", "title": "Einar Håndlykken", "text": "Einar Håndlykken\n\nEinar Bakke Håndlykken (born August 9, 1976 in Trondheim, Norway) is a Norwegian environmentalist and director of Zero Emission Resource Organisation (ZERO). Håndlykken started with environmentalism as a youth in Grenland Natur og Ungdom, and became deputy chairman of the national organisation in 1997 and in 1999 and 2000 he was chairman. He worked for Bellona from 2001 to 2002, when he co-founded ZERO.\n"}
{"id": "31725936", "url": "https://en.wikipedia.org/wiki?curid=31725936", "title": "Energy in South Africa", "text": "Energy in South Africa\n\nSouth Africa was the world's sixth hard coal producer in 2009. \nHard coal production was 1,620 TWh in 2009 and total energy production 1,995 TWh in 2008.\n\nAround 77% of South Africa's energy needs are directly derived from coal and 92% of coal consumed on the African continent is mined in South Africa.\n\nSouth Africa was the sixth top hard coal producer in 2009: 247 Mt hard coal, below Australia 335 Mt and Indonesia 263 Mt and above Russia 229 Mt. South Africa was the fifth top hard coal net exporter in 2009: 67 Mt hard coal of the world total hard coal export 836 Mt.\n\nIn 2009 247 Mt hard coal production is 247 Mt*0.564 toe/Mt*11.630 TWh/toe = 1620 TWh and export 67 Mt*0.564 toe/Mt*11.630 TWh/toe = 439 TWh.\n\nCoal production and use creates in South Africa Coal combustion wastes (CCW), coal mine wastes (AMD) and toxic coal land fires. Coal combustion wastes (CCW), contain toxic substances like arsenic, cadmium, chromium and lead. Hundreds of South African old coal mines are filled with sulphate salts, heavy metals and carcinogenic substances like benzene and toluene. This AMD damages wildlife and spreads illness and disease. According to Greenpeace most shockingly is eMalahleni 'place of coal', Mpumalanga province, surrounded by 22 collieries and steel, vanadium and manganese plants. One of the biggest old mines is the Transvaal and Delagoa Bay (T&DB) mine, closed in 1953. 60 km downstream from Emalahleni AMD leaked into the water supply in 2006 and 2007 killing thousands of fish, crocodiles and freshwater turtles and poisoning the water used by communities. Coal fires continue in the disused mines.\n\nCoal mine owners include Anglo Coal (ex Amcoal) a subsidiary of Anglo American plc, Glencore, Exxaro and South 32.\n\nIn 2008 electricity was produced 241 TWh with coal. In 2008 electricity production + imports – exports – losses was 232 TWh.\n\nThe government owned national power utility Eskom dominates the country's electricity sector. With 27 operational power plants generating over 95% of the country's electricity and over 40% of all electricity on the African continent making it one of the ten largest power utilities in the world. However government's inability to keep Eskom's generating capacity up with economic and population growth due to a lack of investment by government has created a large energy shortage and led to an energy crisis in late 2007. This has forced the company to implement loadshedding in specific areas of the country at certain times to reduce pressure on the national grid and initiate an ambitious program to increase energy production. This has led to speculation by the national newspaper, the Mail and Guardian, that the country might face a complete grid failure.\n\nThe portion of renewable energy as a percentage of final energy consumption in 2012 was 16.9%. Most of that was from the burning of traditional biofuels for heating.\n\nIn terms of share of GDP in 2012, South Africa was the fourth largest investor in renewable power in the world after Uruguay, Mauritius and Costa Rica. That rate of investment is expected to continue. Renewable energy will play a larger role in future.\n\nSouth Africa's per capita greenhouse gas emissions are the highest in Africa.\n\nSouth Africa's commitment to renewable energy lags behind that of China, India, Brazil, and Russia. South Africa receives more than twice as much sunshine than Germany, where over 15 percent of the national electricity supply comes from renewable sources.\n\n\"South Africa's National Energy Regulator (NERSA) announced 31 March 2009 the introduction of a system of feed-in tariffs designed to produce 10 TWh of electricity per year by 2013. The feed-in tariffs announced were substantially higher than those in NERSA's original proposal. The tariffs, differentiated by technology, will be paid for a period of 20 years.\n\nNERSA said in its release that the tariffs were based, as in most European countries, on the cost of generation plus a reasonable profit. The tariffs for wind energy and concentrating solar power are among the most attractive worldwide.\n\nThe tariff for wind energy, 1.25 ZAR/kWh (€0.104/kWh) is greater than that offered in Germany and more than that proposed in Ontario, Canada.\n\nThe tariff for concentrating solar, 2.10 ZAR/kWh, is less than that in Spain, but offers great promise in the bright sunlight of South Africa. NERSA's revised program followed extensive public consultation.\n\nStefan Gsänger, Secretary General of the World Wind Energy Association said in a release that \"South Africa is the first African country to introduce a feed-in tariff for wind energy. Many small and big investors will now be able to contribute to the take-off of the wind industry in the country. Such decentralised investment will enable South Africa to overcome its current energy crisis. It will also help many South African communities to invest in wind farms and generate electricity, new jobs and new income. We are especially pleased as this decision comes shortly after the first North American feed-in law has been proposed by the Government of the Canadian Province of Ontario\".\n\nHowever, the feed-in tariff was abandoned before being promulgated in favor of a competitive bidding process launched on 3 August 2011. Under this bidding process, the South African government plans to procure 3,750MW of renewable energy: 1,850MW of onshore wind, 1,450MW of solar PV, 200MW of CSP, 75MW of small hydro, 25MW of landfill gas, 12.5MW of biogas, 12.5MW of biomass, and 100MW of small projects. The bidding process comprises two steps:\n\nThe first round of bids was due on 4 November 2011. The SA government is expected to announce preferred bidders before COP17 in December. PPA's are expected to be in place by June 2012. Projects should be commissioned by June 2014, except CSP projects which are expected by June 2015.\n\nThe average indexed bid prices (2012) for the supply of energy in the first bid window for the various renewable energy technologies were:\n\n\nThe average indexed bid prices (2012) for the supply of energy in the second bid window\n\n\nThe average indexed bid prices (2013) for the supply of energy in the third bid window\n\n\nEskom claims a standard electricity production price (2012)of R0.31 per kWh (Eskom-predominately Coal and Nuclear), however energy generated from Eskom's new coal power plants have been estimated to be R0.97 per kWh.\n\nSecret price contracts between Eskom and the Australian mining company BHP Billiton less than half Eskom's reported production price in the period.\n\nMany abandoned mines have been burning since the 1940s. Persistent and toxic mine chemical leakages pollute waterways and kill animals. In 2006, about 80% of South Africa's coal exports was in Europe.\n\n\n"}
{"id": "2431881", "url": "https://en.wikipedia.org/wiki?curid=2431881", "title": "Foaming agent", "text": "Foaming agent\n\nA foaming agent is a material that facilitates formation of foam such as a surfactant or a blowing agent. A surfactant, when present in small amounts, reduces surface tension of a liquid (reduces the work needed to create the foam) or increases its colloidal stability by inhibiting coalescence of bubbles. A blowing agent is a gas that forms the gaseous part of the foam.\n\nSodium laureth sulfate, or sodium lauryl ether sulfate (SLES), is a detergent and surfactant found in many personal care products (soaps, shampoos, toothpastes, etc.). It is an inexpensive and effective foamer. Sodium lauryl sulfate (also known as sodium dodecyl sulfate or SDS) and ammonium lauryl sulfate (ALS) are commonly used alternatives to SLES in consumer products. \n\nThere are two main types of blowing agents: gases at the temperature that the foam is formed, and gases generated by chemical reaction. Carbon dioxide, pentane, and chlorofluorocarbons are examples of the former. Blowing agents that produce gas via chemical reactions include baking powder, azodicarbonamide, titanium hydride, and isocyanates (when they react with water).\n\n"}
{"id": "37044040", "url": "https://en.wikipedia.org/wiki?curid=37044040", "title": "France–Pakistan Atomic Energy Framework", "text": "France–Pakistan Atomic Energy Framework\n\nThe France–Pakistan atomic energy framework, or also known as France–Pakistan nuclear deal, is a bilateral energy treaty signed by the governments of France and Pakistan on 15 May 2009. The framework of this agreement was a 15 May 2009, in a joint press statement of President Nicolas Sarkozy and President Asif Ali Zardari, under which France agreed to provide assistance to improve the nuclear safety of its nuclear power installations and related civilian nuclear facilities under International Atomic Energy Agency (IAEA) safeguards and,as well as the transfer full civilian-based nuclear technology to Pakistan.\n\nIn contrast to Indo-American nuclear agreement, this framework restricted itself to only to co-operate in the field of \"nuclear safety\", as quoted by the French Foreign Ministry. While foreign service officers and the Foreign minister Shah Mahmood Qureshi outlined what they termed as \"significant development\"; however, a French official stated that his nation has \"no intention\" of pursuing a civilian nuclear trade deal, roughly equivalent to Indo-US deal, with Pakistan.\n\nSince 1967, France has emerged as the biggest defence contractor of Pakistan, despite its good and relatively close relations with India. Pakistan is one of three original participant states (others being India and Israel) that refused to be signatory of the NPT. On March 1976, France and Pakistan signed a mutual agreement for the supply of plutonium-based nuclear reprocessing plant at the Chasma. However, this deal came under attack from various countries, particularly the United States, for two reasons. First, Pakistan under Prime minister Zulfikar Ali Bhutto was putting efforts to gain success in its atomic bomb project. Second, the French deal was not completely under the inspection of the International Atomic Energy Agency (IAEA). The United States pressed full scope and built momentum on France to re-consider its decision, while on other hand, Bhutto threatened the France that the future contracts would be contingent on its first fulfilling the \"contractual obligation\" to the legally obliged agreement. In 1976, Henry Kissinger arrived Pakistan with tough message which became publicly known in Pakistan. In a short span of time, France under pressured by the various countries, cancelled the project with Pakistan.\n\nDespite France's willingness to give a green signal for this agreement, the confusion remains over what was agreed. The officials of Pakistan's Foreign ministry had undertaken to supply Pakistan with \"civilian nuclear technology\", the French officials stressed on the fact that \"France had agreed only to co-operate in the field of \"nuclear safety\". Although, in an official press French President Nicolas Sarkozy marked to his counterpart that \"France wanted Pakistan to have a wide-ranging deal to buy nuclear equipment\" like the one obtained by its rival India, but later spokesman for the French presidency was careful to rein in expectations and much of the details were closed to the public.\n"}
{"id": "13464118", "url": "https://en.wikipedia.org/wiki?curid=13464118", "title": "Gary Taubes", "text": "Gary Taubes\n\nGary Taubes (born April 30, 1956) is an American science writer. He is the author of \"Nobel Dreams\" (1987), \"\" (1993), and \"Good Calories, Bad Calories\" (2007), titled \"The Diet Delusion\" (2008) in the UK and Australia. His book \"\" was released in December 2010. His main hypothesis is that carbohydrates stimulate the secretion of insulin, which causes the body to store fat. In December 2016, Taubes published \"The Case Against Sugar\", which further expanded his arguments against dietary carbohydrates and sugar in particular.\n\nBorn in Rochester, New York, Taubes studied applied physics at Harvard University (BS, 1977) and aerospace engineering at Stanford University (MS, 1978). After receiving a master's degree in journalism at Columbia University in 1981, Taubes joined \"Discover\" magazine as a staff reporter in 1982. Since then he has written numerous articles for \"Discover\", \"Science\" and other magazines. Originally focusing on physics issues, his interests have more recently turned to medicine and nutrition.\nHis brother, Clifford Henry Taubes, is the William Petschek Professor of Mathematics at Harvard University.\n\nTaubes' books have all dealt with scientific controversies.\n\n\"Nobel Dreams\" takes a critical look at the politics and experimental techniques behind the Nobel Prize-winning work of physicist Carlo Rubbia.\n\nIn \"\", he chronicles the short-lived media frenzy surrounding the Pons–Fleischmann cold fusion experiments of 1989. He opines in the book that heat generation in the experiments of Drs. Martin Fleischmann and Stanley Pons was due entirely to difference in ionic conductivity of deuterated salts solutions compared to normal aqueous solutions.\n\nHe also formulated an allegation of fraud regarding the results from John Bockris's research group.\n\nTaubes gained prominence in the low-carb diet debate following the publication of his 2002 \"New York Times Magazine\" piece \"What if It's All Been a Big Fat Lie?\". The article, which questioned the efficacy and health benefits of low-fat diets, was seen as defending the Atkins diet against the medical establishment, and it became extremely controversial. Some scholars interviewed for the article complained that Mr. Taubes misinterpreted their words or treated them out of context. Taubes himself stated: \"[E]ven though I knew the article would be the most controversial article the \"Times Magazine\" ran all year, [the reaction] still shocked me.\" The Center for Science in the Public Interest published a rebuttal to the \"Times\" article in its November 2002 newsletter. According to Taubes: \"[T]he CSPI is an advocacy group that has been pushing low-fat diets since the 1970s.\"\n\nIn 2007, Taubes published his book \"Good Calories, Bad Calories: Challenging the Conventional Wisdom on Diet, Weight Control, and Disease\" (published as \"The Diet Delusion\" in the UK). This book examines how a hypothesis — that dietary fat is the cause of obesity and heart disease — became dogma, and claims to show how the scientific method was circumvented so a contestable hypothesis could remain unchallenged. The book uses data and studies compiled from more than a century of dietary research to support what Taubes calls \"the alternative hypothesis.\"\n\nTaubes's hypothesis is that the medical community and the U.S. federal government have relied upon misinterpreted scientific data on nutrition to build the prevailing paradigm about what constitutes healthful eating. Taubes makes the case that — contrary to the conventional wisdom — it is refined carbohydrates that are responsible for heart disease, diabetes, obesity, cancer, and many other \"maladies of civilization\". In the Epilogue to \"Good Calories, Bad Calories\" on page 454, Taubes notes ten \"inescapable\" conclusions, the first of which is, \"Dietary fat, whether saturated or not, is not a cause of obesity, heart disease, or any other chronic disease of civilization.\"\n\nTaubes includes information and studies which indicate that physical exercise increases appetite to a degree that makes it an inefficient tool in weight loss. He tracks the origins of commonly accepted dietary advice and aims to show that information that is filtered to the public often contradicts scientific evidence. On October 19, 2007 Taubes appeared on \"Larry King Live\" to discuss his book. His book was praised as \"raising interesting and valuable points\" by Andrew Weil, a proponent of alternative medicine, while Mehmet Oz and trainer Jillian Michaels who appeared on the same program disagreed with Taubes on many questions.\n\nThe reviews for \"Good Calories, Bad Calories\" have varied. George Bray of the Pennington Biomedical Research Center in Louisiana notes in his review that the book \"...has much useful information and is well worth reading.\" but \"Obese people clearly eat more than do lean ones.\"\nTaubes, in a letter to the editor in the same journal, clarifies some of the comments made by Bray. Taubes notes, \"The hypothesis favored by Bray and a half century of authorities on human obesity is that fat accumulation is fundamentally caused by positive energy balance.\" Taubes responds, \"The alternative hypothesis begins with the fundamental observation that obesity is a disorder of excess fat accumulation and then asks the obvious question, what regulates fat accumulation. This was elucidated by 1965 and has never been controversial. 'Insulin is the principal regulator of fat metabolism'...\"\n\nIn 2007, \"New York Times\" science writer John Tierney cited Taubes's book \"Good Calories, Bad Calories\" and discussed information cascades and the role of physiologist Ancel Keys in widely held beliefs related to diet and fat. Tierney follows Taubes in noting that a 2001 Cochrane meta-analysis of low-fat diets found that they had \"no significant effect on mortality\". Harriet A. Hall, however, criticizes Taubes for selectively quoting the meta-analysis.\n\nTaubes has won the Science in Society Journalism Award of the National Association of Science Writers three times and was awarded an MIT Knight Science Journalism Fellowship for 1996–97. He is a Robert Wood Johnson Foundation independent investigator in health policy.\n\n"}
{"id": "871712", "url": "https://en.wikipedia.org/wiki?curid=871712", "title": "Glacial erratic", "text": "Glacial erratic\n\nA glacial erratic is a piece of rock that differs from the size and type of rock native to the area in which it rests. \"Erratics\" take their name from the Latin word \"errare\" (to wander), and are carried by glacial ice, often over distances of hundreds of kilometres. Erratics can range in size from pebbles to large boulders such as Big Rock () in Alberta.\n\nGeologists identify erratics by studying the rocks surrounding the position of the erratic and the composition of the erratic itself. Erratics are significant because:\n\nThe term \"erratic\" is commonly used to refer to erratic blocks, which Geikie describes as: \"large masses of rock, often as big as a house, that have been transported by glacier-ice, and have been lodged in a prominent position in the glacier valleys or have been scattered over hills and plains. And examination of their mineralogical character leads the identification of their sources…\". In geology, an erratic is material moved by geologic forces from one location to another, usually by a glacier.\n\nErratics are formed by glacial ice erosion resulting from the movement of ice. Glaciers erode by multiple processes: abrasion/scouring, plucking, ice thrusting and glacially-induced spalling. Glaciers crack pieces of bedrock off in the process of plucking, producing the larger erratics. In an abrasion process, debris in the basal ice scrapes along the bed, polishing and gouging the underlying rocks, similar to sandpaper on wood, producing smaller glacial till. In ice thrusting, the glacier freezes to its bed, then as it surges forward, it moves large sheets of frozen sediment at the base along with the glacier. Glacially-induced spalling occurs when ice lens formation with the rocks below the glacier spall off layers of rock, providing smaller debris which is ground into the glacial basal material to become till.\n\nEvidence supports another option for creation of erratics as well, rock avalanches onto the upper surface of the glacier (supraglacial). Rock avalanche–supraglacial transport occurs when the glacier undercuts a rock face, which fails by avalanche onto the upper surface of the glacier. The characteristics of rock avalanche–supraglacial transport includes:\n\nErratics provide an important tool in characterizing the directions of glacier flows, which are routinely reconstructed used on a combination of moraines, eskers, drumlins, meltwater channels, and similar data. Erratic distributions and glacial till properties allow for identification of the source rock from which they derive, which confirms the flow direction, particularly when the erratic source outcrop is unique to a limited locality. Erratic materials may be transported by multiple glacier flows prior to their deposition, which can complicate the reconstruction of the glacial flow.\n\nGlacial ice entrains debris of varying sizes from small particles to extremely large masses of rock. This debris is transported to the coast by glacier ice and released during the production, drift and melting of icebergs. The rate of debris release by ice depends upon the size of the ice mass in which it is carried as well as the temperature of the ocean through which the ice floe passes.\n\nSediments from the late Pleistocene period lying on the floor of the North Atlantic show a series of layers (referred to at Heinrich layers) which contain ice-rafted debris. They were formed between 14,000 & 70,000 years before the present. The deposited debris can be traced back to the origin by both the nature of the materials released and the continuous path of debris release. Some paths extend more than distant from the point at which the ice floes originally broke free.\n\nThe location and altitude of ice-rafted boulders relative to the modern landscape has been used to identify the highest level of water in proglacial lakes (e.g., Lake Musselshell in central Montana) and temporary lakes (e.g., Lake Lewis in Washington state. Ice-rafted debris is deposited when the iceberg strands on the shore and subsequently melts, or drops out of the ice floe as it melts. Hence all erratic deposits are deposited below the actual high water level of the lake; however the measured altitude of ice-rafted debris can be used to estimate the lake surface elevation.\nThis is accomplished by recognizing that on a fresh-water lake, the iceberg floats until the volume of its ice-rafted debris exceeds 5% of the volume of the iceberg. Therefore, a correlation between the iceberg size and the boulder size can be established. For example, diameter boulder can be carried by a high iceberg and could be found stranded at higher elevations than a boulder which requires a high iceberg.\n\nLarge erratics consisting of slabs of bedrock that have been lifted and transported by glacier ice to subsequently be stranded above thin glacial or fluvioglacial deposits are referred to as glacial floes, rafts (schollen) or erratic megablocks. Erratic megablocks have typical length to thickness ratios on the order of 100 to 1. These megablocks may be found partially exposed or completely buried by till and are clearly allochthonus, since they overlay glacial till. Megablocks can be so large that they are mistaken for bedrock until underlying glacial or fluvial sediments are identified by drilling or excavation. Such erratic megablocks greater than in area and in thickness can be found on the Canadian Prairies, Poland, England, Denmark and Sweden. One erratic megablock located in Saskatchewan is (and up to thick). Their sources can be identified by locating the bedrock from which they were separated; several rafts from Poland and Alberta were determined to have been transported over from their source.\n\nIn geology an erratic is any material which is not native to the immediate locale but has been transported from elsewhere. The most common examples of erratics are associated with glacial transport, either by direct glacier-borne transport or by ice rafting. However, other erratics have been identified as the result of kelp holdfasts, which have been documented to transport rocks up to in diameter, rocks entangled in the roots of drifting logs, and even in transport of stones accumulated in the stomachs of pinnipeds during foraging.\n\nDuring the 18th century, erratics were deemed a major geological paradox. Erratics were once considered evidence of a vast flood approximately 10,000 years ago, similar to the legendary floods described in the texts of ancient civilizations throughout the world. Ancient legends of an epic flood come from many cultures including Mesoamerican, Sumerian (Epic of Gilgamesh), Hebrew (Old Testament) and Indian culture. Among others, the Swiss politician, jurist and theologican saw glaciers as a possible solution as early as 1788. However the idea of ice ages and glaciation as a geological force took a while to be accepted. Ignaz Venetz (1788 — 1859), a Swiss engineer, naturalist, and glaciologist was one of the first scientists to recognize glaciers as a major force in shaping the earth.\n\nIn the 19th century, many scientists came to favor erratics as evidence for the end of the Last Glacial Maximum (ice age) 10,000 years ago, rather than a flood. Geologists have suggested that landslides or rockfalls initially dropped the rocks on top of glacial ice. The glaciers continued to move, carrying the rocks with them. When the ice melted, the erratics were left in their present locations.\n\nCharles Lyell's \"Principles of Geology\" (v. 1, 1830) provided an early description of the erratic which is consistent with the modern understanding. Louis Agassiz was the first to scientifically propose that the Earth had been subject to a past ice age. In the same year, he was elected a foreign member of the Royal Swedish Academy of Sciences. Prior to this proposal, Goethe, de Saussure, Venetz, Jean de Charpentier, Karl Friedrich Schimper and others had made the glaciers of the Alps the subjects of special study, and Goethe, Charpentier as well as Schimper had even arrived at the conclusion that the erratic blocks of alpine rocks scattered over the slopes and summits of the Jura Mountains had been moved there by glaciers.\n\nCharles Darwin published extensively on geologic phenomena including the distribution of erratic boulders. In his accounts written during the voyage of , Darwin observed a number of large erratic boulders of notable size south of the Strait of Magellan, Tierra del Fuego and attributed them to ice rafting from Antarctica. Recent research suggests that they are more likely the result of glacial ice flows carrying the boulders to their current locations.\n\nExamples of erratics include:\n\n\nIn the event that glacial ice is \"rafted\" by a flood such as that created when the ice dam broke during the Missoula Floods, the erratics are deposited where the ice finally releases its debris load. One of the more unusual examples is found far from its origin in Idaho at Erratic Rock State Natural Site just outside McMinnville, Oregon. The park includes a specimen, the largest erratic found in the Willamette Valley.\n\n\n\n"}
{"id": "29821734", "url": "https://en.wikipedia.org/wiki?curid=29821734", "title": "Green River Generating Station", "text": "Green River Generating Station\n\nThe Green River Generating Station was a coal-fired power plant owned and operated by Kentucky Utilities, which was removed from service on 30 September 2015. It was located in Muhlenberg County, Kentucky.\n\n\n\n"}
{"id": "898023", "url": "https://en.wikipedia.org/wiki?curid=898023", "title": "Grivna", "text": "Grivna\n\nGrivna was a currency as well as a measure of weight used in Kievan Rus' and other East Slavic countries since the 11th century.\n\nThe word \"grivna\" is derived from from . In Old East Slavic it had the form \"grivĭna\". In modern East Slavic languages it has such forms: \"grivna\", \"hryvnia\", \"hryŭnia\". \n\nThe name of the contemporary currency of Ukraine, \"hryvnia\", is derived from the ancient grivna.\n\nAs its etymology implies the word originally meant a necklace or a torque, however the reason why it has taken the meaning of a unit of weight is unclear. The grivnas that have been found at various archaeological sites are not necklaces but bullions of precious metals, usually silver. The weight and the shape of grivnas were not uniform, but varied by region. The grivnas of Novgorod and Pskov were thin long round-edged or three-edged ingots, while Kievan grivnas has rather the shape of a prolonged rhombus. The material was either gold or silver, but silver was predominant. Originally the weight of a grivna was close to the Roman or Byzantine pound. The weight of the Kievan grivna was around . The Novgorod grivna had the weight and became the basis for monetary systems of North-Eastern Russian principalities and the emerging Russian state.\n\nAlong the \"grivna of silver\" there were the account \"grivna of kuna\". The latter originally signified a certain amount of marten furs (\"kuna\" is the word for marten in slavic languages). Since the 12th century the \"grivna of kuna\" became another unit of weight, but smaller, and signified as well a certain amount of silver coins: 2.5-gram \"nogata\" (from \"naqd\" 'money; a coin') and \"rezan\" ( dirham).\n\nSince the 14th century, when coins started to be minted in North-Eastern Rus (firstly in Moscow), the currency system of silver bullions and furs was becoming obsolete. The grivna became to mean not a weight but rather a partucular number of silver coins called then \"denga\". At the same time as early as the 13th century the word ruble (\"rubl\"') started to be used alongside the word grivna to mean a certain amount of either silver or silver coins. Thus one account ruble was equal to 216 denga coins (each weighted about 0.8 gram). The \"grivna of kuna\" became simply grivna and was equal to 14 dengas. Thus one ruble was equal to 15 new grivnas and 6 denga coins.\n\nThe weight of a denga coin in Moscow and Novgorod was different. In the 15th century the Moscow denga fell as low as 0.4 gram, while the Novgorod denga remained the same. When in Moscow one ruble had been revalued to 200 denga coins, the exchange rate between Moscow and Novgorod denga coins was set to 2 to 1. Thus since the later 15th – the early 16th centuries one account ruble was equal to 100 Novgorod dengas (later known as \"kopeks\") or to 200 Moscow dengas. In this system one grivna was equal to 10 kopeks or 20 dengas. \n\nThis last meaning survived into the 18th–20th centuries when one grivennik or grivenka meant a 10-kopek coin.\n\nThe grivna as a silver bullion currency did not survive, but its meaning as a unit of weight became predominant. In 15th–17th centuries there were two weight grivnas (or \"grivenkas\"): the \"lesser grivna\" of and the \"greater grivna\" of . Since the middle of the 17th century the latter became known as the Russian pound (Фунт, \"funt\"). 40 Russian pounds or 80 lesser grivnas (grivenkas) are equal to one pood.\n\n\n"}
{"id": "58091895", "url": "https://en.wikipedia.org/wiki?curid=58091895", "title": "HFRR", "text": "HFRR\n\nHFRR is a measurement for lubrication of Diesel or heating oil and stands for high frequency reciprocating rig. The value is given in µm, lower is better. The measured value is the diameter of the flattening of the ball after the test.\n\nIt's important because high pressure injection pumps are only lubricated by the fuel itself. Density and viscosity are not sufficient describing the aptitude of the fuel.\n\n"}
{"id": "34321437", "url": "https://en.wikipedia.org/wiki?curid=34321437", "title": "Handcar Regatta", "text": "Handcar Regatta\n\nThe Handcar Regatta, aka The Great West End and Railroad Square Handcar Regatta and Exposition of Mechanical and Artistic Wonders, is a popular handcar race and arts festival that is held in Santa Rosa, CA. It originated in 2008 and is held annually.\n\nInitial funding for the Handcar Regatta in 2008 came from the Santa Rosa Arts District.\n"}
{"id": "3384318", "url": "https://en.wikipedia.org/wiki?curid=3384318", "title": "Institute for Marine Mammal Studies", "text": "Institute for Marine Mammal Studies\n\nThe Institute for Marine Mammal Studies (\"IMMS\") is a major non-profit organization established in 1984 for the education, conservation, and research on marine mammals in the wild and in captivity. It is located in Gulfport, Mississippi, United States of America and has been an active participant of the National Stranding Network since its inception. The Institute is the only organization in the Mississippi-Louisiana-Alabama subregion of the Gulf Coast with the ability to both care for sick and injured marine mammals, and also incorporate programs for conservation, education and research on marine mammals and their environment. Also, every summer an educational camp is held. It is a week long camp, and it in includes a dolphin encounter, the touch pool, and each level does different activities. Some are fun, and some educational on the basis of IMMS's purpose.\n\nThe Institute's Center for Marine Education and Research, located in Gulfport, features a museum with exhibits, aquarium tanks and touch pools. Open by reservation, the tours include dolphin encounters.\n\nThe Institute for Marine Mammal Studies has received a number of grants of several million dollars from the National Oceanic and Atmospheric Administration ,\nThe current director is Dr. Moby Solangi.\n\nIt has been engaged in collaboration with:\n\n\n"}
{"id": "20619418", "url": "https://en.wikipedia.org/wiki?curid=20619418", "title": "It's a Matter of Survival", "text": "It's a Matter of Survival\n\nIt's a Matter of Survival is a 1991 book by Anita Gordon and David Suzuki. Written for the general reader, the book looks ahead 50 years and explores the condition of human society and the environment. Suggestions are given about how to improve the future. The book originated as a radio series aired in 1989 by the Canadian Broadcasting Corporation.\n\n"}
{"id": "23122488", "url": "https://en.wikipedia.org/wiki?curid=23122488", "title": "John H. Adams (NRDC)", "text": "John H. Adams (NRDC)\n\nJohn Hamilton Adams (born 1936) is the founding director and trustee of the Natural Resources Defense Council, founded in 1970. Adams served as executive director and, later, as president of the nonprofit conservation group until 2006. Prior to co-founding NRDC, Adams served as an assistant U.S. attorney in Manhattan. He also served as an adjunct faculty member at New York University's law school.\n\nAdams graduated from Michigan State University and earned a law degree from Duke University in 1962. He was awarded the Presidential Medal of Freedom in 2011.\n\nAdams is currently chair of the board of the Open Space Institute and sits on the boards of numerous other environmental organizations.\n\n\n"}
{"id": "21361315", "url": "https://en.wikipedia.org/wiki?curid=21361315", "title": "Kandadji Dam", "text": "Kandadji Dam\n\nThe Kandadji Dam, when completed, will be a large multipurpose dam on the Niger River. The site is situated near the small town of Kandadji, Tillabéri Department, Tillabéri Region, Niger, 180 km northwest of the capital Niamey. Construction of the dam was begun in August 2008. It is being built by the \"Haut Commissariat à l'Aménagement de la Vallée du Niger\" (High Commission for Niger Valley), a public body under the Primer Minister's Office. The dam will generate hydropower and is aimed at controlling the flow of the Niger River, holding water during the dry season to maintain a minimum flow and making downstream irrigation possible. The project is formally named the \"Kandadji Programme for Ecosystem Regeneration and Niger River Development\" (\"Programme Kandadji de Régénération des Ecosystèmes et de Mise en Valeur du Fleuve Niger\"). In 2008 the dam itself was expected to be completed in 2013. By 2012 the completion date had moved to September 2015. Construction has been slower than expected, with interruptions due to financing problems; as of 2018, completion is expected in 2020.\n\nThe project is a very high-profile project for Niger. According to the Prime Minister at the time of initiating construction, Seyni Oumarou, \"no other development project will have sparked so much long term interest or such high expectations\". The first brick of the dam was laid by the President of Niger, Mamadou Tandja.\n\nThe project was first proposed in the 1970s, when a larger dam had been considered. In 1998 the African Development Bank approved funding for a feasibility study that was conducted by the German consulting firm Lahmeyer. Under the study, an environmental and social diagnosis and an initial environmental and social assessment were conducted. The findings were presented in 2002. In August 2002 the government decided by Decree to go ahead with the project, which was from that time called the Kandadji Ecosystems Regeneration and Niger Valley Development Programme. Subsequently, a detailed assessment of environmental and social impact, including a Population Resettlement Plan and a Local Development Plan, was conducted. The Local Development Plan was designed to facilitate the economic transition of displaced persons in order to restore their standard of living or even enhance it, beyond mere resettlement. The final design of the dam was prepared with financing from the Islamic Development Bank, and that of a irrigation project with financing from the West African Development Bank. In 2005 and 2006 consultations were undertaken as part of the environmental and social assessment, which included participants from the World Wide Fund for Nature and International Union for Conservation of Nature. According to one source, construction of the dam was begun in August 2008. In April 2009 a workshop on benefit sharing from dams in West Africa was held in Niamey organized by the Niger Basin Authority, the International Institute for Environment and Development and the International Union for Conservation of Nature. The workshop recommended to improve the communication towards the people affected by the dam and to pay particular attention to legal processes related to resettlement, and to continue to reflect on a future management structure to equitably share the benefits of the dam. In November 2009 a process to select consultants to accompany the resettlement has been initiated.\n\nAccording to the World Bank, the entire Kandadji Program will be implemented in three phases:\n\nConstruction of the dam itself was contracted to Russian company Zarubezhvodstroy, which signed the construction contract in September 2010. Construction of the dam was relaunched at a ceremony on 23 May 2011, following the election of President Mahamadou Issoufou. The Kandaji Dam is the first object being constructed by a Russian company in Niger. In May 2011, the Director General of Zarubezhvodstroy, OJSC E.V. Gudzenchuk, announced \"For the first time a Russian company is involved in building such a large project in West Africa at the expense of foreign investors. Zarubezhvodstroy has vast experience in the field that would allow us to meet the challenges with confidence and with great professionalism.\"\n\nPlans were announced in June 2011 to relocate 5383 individuals and 770 families who will be displaced by the dam.\n\nThe earth dyke dam will be 8.4 km dam long, creating a reservoir of 1.6 billion m and a regulated discharge of 120 m/s (3.8 km/year) in Niamey. The hydroelectric plant will have a capacity of 130 megawatt, and a 132 kilovolt high voltage line will be built over 188 km to Niamey. Irrigation development will consist of a first phase of 6,000 hectares mainly for the benefit of resettled communities, with a medium-term target in 2034 of 45,000 hectares out of an irrigable potential of 122,000 hectares.\n\nThe expected benefits include increased agricultural production and hydropower generation. Niger imports almost half of its electricity consumption of (2007) from neighboring Nigeria, which itself suffers frequent power cuts. The plant would increase installed capacity in Niger from 240 Megawatt (MW) in 2007 to 370 MW (+55%). Other expected benefits are related to \"drinking water supply, sanitation, improved flood recession cropping, grazing and fishery\".\n\nThe financial costs of the broader project, including the infrastructure for irrigation and drinking water supply, were estimated at US$670 million by one source in 2007. Another source mentions US$942 million in 2011. The contract to build the dam itself, however, is apparently only worth Euro 130million. According to the World Bank, the Kandadji Program (Phase I and Phase II) is expected to cost US$785 million.\n\nFinancing comes from ten sources: the African Development Bank, the Islamic Development Bank, the West African Development Bank, the Saudi Fund for Development, the Kuwait Fund for Arab Economic Development, the OPEC Fund for International Development, the Arab Bank for Economic Development in Africa, the Bank for Investment and Development of the Economic Community of West African States (ECOWAS) and the Government of Niger.\n\nSpecific amounts are as follows, as far as known:\n\n\nFinancing for the hydropower station itself is due to come from a public-private partnership.\n\nNegative social impacts include the resettlement of almost 35,000 people from 15 villages, loss of infrastructure (a national road, boreholes, clinics, schools, mosques, slaughterhouses, markets and grain mills) and loss of about 7,000 ha of agricultural land. According to a 2007 report by UNEP's Dams and Development Project, which itself was a follow-up activity to a report by the World Commission on Dams, the Kandadji project \"serves as a useful example of the projection and estimation of social effects, which appears to have been widely encompassing, covering both negative impacts and benefits\". These impacts were \"projected at an early stage in project planning, enabling issues and potential impacts to be addressed in subsequent planning phases\".\n\nThe project is expected to improve the river's ecology, which has suffered from a 30% decline in river flows since the 1970s. The dam would regulate flows. According to press reports from Nigeria, the project would reduce the river flow to Nigeria by at least 10 percent, thus jeopardizing power production from two existing dams in Nigeria and meaning a \"colossal loss (...) to the agricultural capacity of (Nigerian) states that border the River Niger\". However, according to the 2008 environmental assessment of the project, the \"modifications of the quantities of water flowing into the Niger River as a result of the Kandadji dam will be minimal in Nigeria\". The average loss through evaporation and modification of the Niger River water flows in Nigeria will be low (2.3% at Jebba) and there will be positive impacts by improving the minimum water level in Nigeria.\n\n"}
{"id": "24549091", "url": "https://en.wikipedia.org/wiki?curid=24549091", "title": "List of boiler types, by manufacturer", "text": "List of boiler types, by manufacturer\n\nThere have been a vast number of designs of steam boiler, particularly towards the end of the 19th century when the technology was evolving rapidly. A great many of these took the names of their originators or primary manufacturers, rather than a more descriptive name. Some large manufacturers also made boilers of several types. Accordingly, it is difficult to identify their technical aspects from merely their name. This list presents these known, notable names and a brief description of their main characteristics.\n\n"}
{"id": "17338224", "url": "https://en.wikipedia.org/wiki?curid=17338224", "title": "Loscoe", "text": "Loscoe\n\nLoscoe is a village near Heanor in Derbyshire, England, lying within the civil parish of Heanor and Loscoe. Denby Common and Codnor Breach are outlying hamlets on the western edge of the village.\n\nThe name Loscoe derives from the Old Norse words \"lopt\" (or \"loft\") and \"skógr\", specifically in the phrase \"lopt í skógi\", and means 'loft in a wood' or 'wood with a lofthouse'. It was recorded as \"Loscowe\" in 1277.\n\nLoscoe Manor formed part of the wider Draycott Estate; Richard and William de Draycott were recorded at Loscoe (or Loschowe) in 1401. The manor was demolished in 1704.\n\nIn the 19th and 20th centuries Loscoe's economy was dominated by coal mining, so that pit chimneys and spoil heaps were prominent features of landscape. Three mines operated in the village: Old Loscoe (early 1830s – 1933), Bailey Brook (1847–1938) and Ormonde (1908–1970).\n\nLoscoe was within the ecclesiastical parish of Heanor until 1844, when a new church was built between Loscoe and the neighbouring village of Codnor to the north, and a new joint parish created for them. Loscoe formed its own parish in 1927; initially services were held in the mission church until a new parish church, dedicated to St Luke, was built in 1938.\n\nLoscoe was the site of a landfill gas migration explosion on 24 March 1986. Although there were no fatalities, one house was completely destroyed by the blast and its three occupants injured. The atmospheric pressure on the night of the explosion fell 29 hPa (29 mbar) over a seven-hour period, causing the gas to be released from the ground in much greater quantities than usual. In the four hours before the explosion, which occurred at approximately 6.30 am, the local meteorological office had recorded average falls of 4 hPa (4 mbar) per hour. Several cubic metres of landfill gas (consisting of a 3:2 mixture of methane and carbon dioxide) collected under the ground near the house at 51 Clarke Avenue, and as the gas expanded it flowed into the space beneath the floor, from where it was drawn by convection to the gas central-heating boiler and ignited.\n\nThis incident led (in Britain) to the introduction of key legislation and government guidance, much research into landfill behaviour, and revised best practice at landfill sites. Over time, these were designed to vent gas to the atmosphere, then to burn off methane and eventually, in the most productive sites, use gas turbines to turn the gas into electricity for the national grid.\n\nIn the 2011 census the electoral ward of Heanor and Loscoe (which as well as Loscoe includes the north-western parts of Heanor) had 2,285 dwellings 2,216 households and a population of 5,335. The average age of residents was 40.5 (compared to 39.3 for England as a whole) and 17.9% of residents were aged 65 or over (compared to 16.4% for England as a whole).\n\nBMX racer Dale Holmes was born here on 6 October 1971.\n"}
{"id": "598868", "url": "https://en.wikipedia.org/wiki?curid=598868", "title": "Mad Max Beyond Thunderdome", "text": "Mad Max Beyond Thunderdome\n\nMad Max Beyond Thunderdome (also known as Mad Max 3) is a 1985 Australian dystopian action film directed by George Miller and George Ogilvie, distributed by Warner Bros., and written by Miller and Terry Hayes. In this sequel to \"Mad Max 2: The Road Warrior\", Max (Mel Gibson) is exiled into the desert by the corrupt ruler of Bartertown, Aunty Entity (Tina Turner), and there encounters an isolated cargo cult centered on a crashed Boeing 747 and its deceased captain. The film is the third installment in the \"Mad Max\" film series and the last with Gibson as Max. The series was later given a fourth installment in 2015 with \"\", starring Tom Hardy in the title role.\n\nIn post-apocalyptic Australia, Max Rockatansky crosses the desert in a camel-drawn wagon when he is attacked by a pilot named Jedediah and his son in a Transavia PL-12 Airtruk, stealing his wagon and belongings. Continuing on foot, Max follows their trail to the seedy community of Bartertown. While refused entry, Max is brought before the founder and ruler of Bartertown, the ruthless Aunty Entity. She offers to resupply his vehicle and equipment if he completes a task for her.\n\nAunty explains that Bartertown depends on a crude methane refinery powered by pig feces, which is run by a dwarf called Master and his giant bodyguard Blaster. \"Master Blaster\" holds an uneasy truce with Aunty for control of Bartertown; however, Master has begun to challenge Aunty's leadership. Aunty instructs Max to provoke a confrontation with Blaster in Thunderdome, a gladiatorial arena where conflicts are resolved by a duel to the death. Max enters the refinery to size up Master Blaster and befriends Pig Killer, a convict sentenced to work for slaughtering a pig to feed his family. Max finds his stolen vehicle in Master Blaster's possession, and helps disarm his booby-trapped engine to converse with him. Here he discovers that Blaster is exceptionally strong but extremely sensitive to high-pitched noises.\n\nMax then faces Blaster in the Thunderdome and uses his weakness to gain the upper hand. He refuses to kill him after discovering he has a severe developmental disability. He tells Aunty it was not part of their deal, thus revealing her plot. Master, previously unaware of this arrangement to kill Blaster, is furious and vows to shut down the refinery and, by extension, Bartertown. An enraged Aunty has Blaster executed, Master imprisoned, and Max exiled. He is bound on a horse and sent off in a random direction through the wasteland. When his mount perishes in a sinkhole, Max frees himself and presses on.\n\nNear death, Max is found by a desert dweller named Savannah Nix, who hauls him back to her home, a primitive community of children and teenagers who live in an oasis. The children, survivors of a crashed Boeing 747, were left by their parents who went to find civilization. They believe Max to be the flight captain, G. L. Walker, returned to fix the aeroplane and fly them to civilization. Max denies this and insists that they remain in the relative safety of the oasis, knowing that the only \"civilization\" within reach is Bartertown.\n\nSome of the children, led by Savannah, leave anyway, determined to find the prophesied \"Tomorrow-morrow Land.\" Max stops them by force, but another tribe member, Scrooloose, sets them free during the night and leaves with them. Their leader, Slake M'Thirst, asks Max to go after them, and he agrees, taking a few of the children with him to help. They find Savannah's group in danger but are unable to save one of the children from a sinkhole. With no supplies left, they are forced to head for Bartertown.\n\nThe group sneak in via the underground, and, with Pig Killer's help, free Master and escape in a train-truck, destroying Bartertown's methane refinery in the process. Aunty leads the inhabitants in pursuit, catching up to the train. Max's group slows them down while Scrooloose hijacks one of the pursuing vehicles, which happens to be Max's stolen vehicle. The group comes across Jedediah and his son, and Max coerces Jedediah into helping his group escape with their aeroplane. Max uses his vehicle to clear a path through Aunty's men, allowing the aeroplane to take off and escape, leaving him at Aunty's mercy. Aunty spares his life, having come to respect him, and departs to presumably make good on her vow to rebuild Bartertown.\n\nJedediah flies the children to the coast, where they discover the nuclear-devastated ruins of Sydney. Years later, the children have established a small society of themselves and other lost wanderers in the ruins. Savannah, now leader of the group, recites a nightly story of their journey and the man who saved them, as Max, still alive in the desert, wanders on to places unknown.\n\n\n\"Mad Max Beyond Thunderdome\" was the first \"Mad Max\" film made without producer Byron Kennedy, who was killed in a helicopter crash in 1983 while location scouting for the film. While the film was in development before Kennedy's death, director George Miller was hesitant to continue without his producing partner. \"I was reluctant to go ahead,\" said Miller. \"And then there was a sort of need to – let's do something just to get over the shock and grief of all of that.\" A title card at the end of film reads: \"...For Byron\".\n\nMiller ended up co-directing the film with George Ogilvie, with whom he had worked on the 1983 miniseries \"The Dismissal\". \"I had a lot on my plate,\" said Miller. \"I asked my friend George Ogilvie, who was working on the mini-series, 'Could you come and help me?' But I don't remember the experience because I was doing it to just... You know, I was grieving.\" Together, Miller and Ogilvie used a group workshopping rehearsal technique that they had developed.\n\nExterior location filming took place primarily in the mining town of Coober Pedy, with the set for Bartertown built at an old brickworks (the Brickpit) at Homebush Bay in Sydney's western suburbs and the children's camp shot at the Blue Mountains. \"\"Mad Max Beyond Thunderdome\" proved far more challenging than \"The Road Warrior\",\" said cinematographer Dean Semler. \"We were dealing with more varied environments than before and it was essential that each of the worlds created for the film have a distinctly different look.\"\n\nThe musical score for \"Mad Max Beyond Thunderdome\" was composed by Maurice Jarre, replacing Brian May, who composed the music for the previous two films. The film also contains two songs performed by Tina Turner, \"We Don't Need Another Hero (Thunderdome)\" and \"One of the Living\", with the latter replacing Jarre's opening titles music. A soundtrack album was originally released by Capitol Records in 1985. It includes Turner's \"We Don't Need Another Hero (Thunderdome)\", which reached #1 in Canada, #2 in the US and #3 in the British single charts; it plays over the end credits. \"One of the Living\" was rerecorded for single release, and reached #15 in both Canada and the US, but only #55 in Britain. The song also won a Grammy for Best Rock Vocal. A double CD containing only Jarre's original music was issued in 2010 on Tadlow Music/Silva Screen Records.\n\nAlthough the film's budget was more extravagant than its predecessors', its box office yield was only moderate in comparison. \"Beyond Thunderdome\" grossed A$4,272,802 at the box office in Australia.\n\nCritical reaction to the film was generally positive, although reviewers disagreed as to whether they considered the film the highest or lowest point of the \"Mad Max\" trilogy. Most of the criticism focused on the children in the second half of the film, whom many found too similar to the Lost Boys from the story of Peter Pan. Robert C. Cumbow of \"Slant Magazine\" identifies \"whole ideas, themes and characterizations\" adopted from \"Riddley Walker\", a 1980 post-apocalyptic novel by Russell Hoban. On the other hand, critics praised the Thunderdome scene in particular; film critic Roger Ebert of the \"Chicago Sun-Times\" called the Thunderdome \"the first really original movie idea about how to stage a fight since we got the first karate movies\" and praised the fight between Max and Blaster as \"one of the great creative action scenes in the movies\". Ebert awarded the film 4 stars out of 4 and later placed the film on his list of the 10 best pictures of 1985. \"Variety\" wrote that the film \"opens strong\" and has good acting from Gibson, Turner, and the children.\n\nDespite mostly positive reviews from critics, some fans of the series have criticised the film for being \"Hollywood-ized\" and having a lighter tone than its predecessors.\n\nThe film holds an 80% rating on Rotten Tomatoes based on 49 reviews with an average rating of 6.4/10. The website's consensus reads, \"\"Beyond Thunderdome\" deepens the Mad Max character without sacrificing the amazing vehicle choreography and stunts that made the originals memorable\".\n\nAs with the previous installments of the \"Mad Max\" series, \"Mad Max Beyond Thunderdome\" has influenced popular culture in various regards. The term \"thunderdome\" is now used in various contexts in which its meaning is similar to the sense in which it appears in the film. That is, a contest where the loser suffers a great hardship, though it has also come to mean, more generically, the state of the world following a nuclear apocalypse, or any place where chaos is the norm. Filmmaker Chris Weitz has cited the film as an influence.\n\n"}
{"id": "19669402", "url": "https://en.wikipedia.org/wiki?curid=19669402", "title": "Mark Benson (engineer)", "text": "Mark Benson (engineer)\n\nMark Benson (born Mark Müller) was a Bohemian German engineer, best known as the inventor of a supercritical boiler.\n\nBenson was born in the Sudetenland, and his original name was Müller (he changed his name during World War I to hide his German origin). He emigrated to the United States, then returned to Europe to work for the English Electric Company in Rugby. For \"English Electric\" he designed a relatively small steam generator (3 tons/hr), but with—for the time—very high pressure (supercritical) and without any drum. In 1922 Benson was granted a patent for this type of boiler.\n\nIn 1924, Siemens acquired the right to use Benson's patent, and in 1926–27 built the first large Benson boiler in Berlin-Gartenfeld. Siemens improved the technology and developed it as an internationally acknowledged standard for large steam generators. Since 1933 (until today) Siemens do not manufacture their own Benson boilers any more, but instead license the technology to others.\n\nAfter his patent, Mark Benson did not make any further public appearances, but Siemens continued to use \"Benson\" as a registered trademark for this successful type of boiler, so the name is renowned worldwide in boiler engineering, although relatively little is known about the inventor behind it.\n"}
{"id": "15682825", "url": "https://en.wikipedia.org/wiki?curid=15682825", "title": "Nominal power (photovoltaic)", "text": "Nominal power (photovoltaic)\n\nThe nominal power is the nameplate capacity of photovoltaic (PV) devices, such as solar cells, panels and systems, and is determined by measuring the electric current and voltage in a circuit, while varying the resistance under precisely defined conditions. These \"Standard Test Conditions\" (STC) are specified in standards such as IEC 61215, IEC 61646 and UL 1703; specifically the light intensity is 1000 W/m, with a spectrum similar to sunlight hitting the earth's surface at latitude 35°N in the summer (airmass 1.5), the temperature of the cells being 25 °C. The power is measured while varying the resistive load on the module between an open and closed circuit (between maximum and minimum resistance). The highest power thus measured is the 'nominal' power of the module in watts. This nominal power divided by the light power that falls on a given area of a photovoltaic device (area × 1000 W/m) defines its efficiency, the ratio of the device's electrical output to the incident energy.\n\nThe nominal power is important for designing an installation in order to correctly dimension its cabling and converters. If the available area is limited the solar cell efficiency and with it the nominal power per area (e.g. kW/m) is also relevant. For comparing modules, the price per nominal power (e.g. $/W) is relevant. For a given installation's physical orientation and location the expected annual production (e.g. kWh) per annual production assuming nominal power i.e. the capacity factor is important. With a projected capacity factor the price per projected annual production (e.g. $/kWh) can be estimated for a given installation. Finally, with a projected value of the production, the amortization of the cost of an installation can be estimated.\n\nThe peak power is not the same as the power under actual radiation conditions. In practice, this will be approximately 15-20% lower due to the considerable heating of the solar cells.\nMoreover, in installations where electricity is converted to AC, such as solar power plants, the actual total electricity generation capacity is limited by the inverter, which is usually sized at a lower peak capacity than the solar system for economic reasons. Since the peak DC power is reached only for a few hours each year, using a smaller inverter allows to save money on the inverter while clipping (wasting) only a very small portion of the total energy production. The capacity of the power plant after DC-AC conversion is usually reported in W as opposed to W or W.\n\nThe International Bureau of Weights and Measures, which maintains the SI-standard, states that the physical unit and its symbol should not be used to provide specific information about a given physical quantity and that neither should be the sole source of information on a quantity. Nonetheless, colloquial English sometimes conflates the quantity power and its unit by using the non-SI unit watt-peak and the non-SI symbol W prefixed as within the SI, e.g. kilowatt-peak (kW), megawatt-peak (MW), etc. As such a photovoltaic installation may for example be described as having \"one kilowatt-peak\" in the meaning \"one kilowatt of peak power\". Similarly outside the SI, the peak power is sometimes written as \"P = 1 kW\" as opposed to \"P = 1 kW\". In the context of domestic PV installations, the kilowatt (kW) is the most common unit for peak power, sometimes stated as kW.\n\nThe output of photovoltaic systems varies with the intensity of sunshine and other conditions. The more sun, the more power the PV module will generate. Losses, compared to performance in optimal conditions, will occur due to non-ideal alignment of the module in tilt and/or azimuth, higher temperature, module power mismatch (since panels in a system are connected in series the lowest performing module defines performance of the string it belongs to), soiling and DC to AC conversion. The power a module generates in real conditions can exceed the nominal power when the intensity of sunlight exceeds 1000 W/m (which corresponds roughly to midday in summer in, for example, Germany), or when sun irradiation close to 1000 W/m happens at lower temperatures.\n\nMost countries refer to installed nominal nameplate capacity of PV systems and panels by counting DC power in watt-peak, denoted as W, or sometimes W, as do most manufacturers and organizations of the photovoltaic industry, such as SEIA, SPE or the IEA-PVPS.\n\nHowever, in some places of the world, a system's rated capacity is given after the power output has been converted to AC. These places include Canada, Japan (since 2012), Spain, and some parts of the United States. AC instead of DC is also given for most utility-scale PV power plants using CdTe-technology. The major difference lies in the small percentage (about 5%, according to the IEA-PVPS) of energy lost during the DC-AC conversion. In addition, some grid regulations may limit the output of a PV system to as little as 70% of its nominal DC power (Germany). In such cases, the difference between nominal peak-power and converted AC output can therefore amount to as much as 30%. Because of these two different metrics, international organizations need to reconvert official domestic figures from the above-mentioned countries back to the raw DC output, in order to report coherent global PV-deployment in watt-peak.\n\nIn order to clarify whether the nominal power output (\"watt-peak\", W) is in fact DC or already converted into AC, it is sometimes explicitly denoted as, for example, MW and MW or kW and kW. The converted W is also often written as \"MW (AC)\", \"MWac\" or \"MWAC\". Just as for W, these units are non SI-compliant but widely used. In California, for example, where the rated capacity is given in MW, a loss of 15 percent in the conversion from DC to AC is assumed. This can be extremely confusing not only to non-experts, as the conversion efficiency has been improving to nearly 98 percent, grid regulations may change, some manufactures may differ from the rest of the industry, and countries, such as Japan, may adopt a different metric from one year to the other.\n\nAlthough watt-peak is a convenient measure, and is the standardized number in the photovoltaic industry on which prices, sales and growth numbers are based, it is arguably not the most important number for actual performance. Since a solar panel's job is to generate electric power at minimal cost, the amount of power that it generates under real-life conditions in relation to its cost should be the most important number to evaluate. This \"cost-per-watt\" measure is widely used in the industry.\n\nIt can happen that a panel from brand A and a panel of brand B give exactly the same watt-peak in laboratory test, but their power output is different in a real installation. This difference can be caused by different degradation rates at higher temperatures. At the same time, though brand A can be less productive than brand B it may as well cost less, thus it has a potential of becoming financially advantageous. An alternative scenario can also be true: a more expensive panel may produce so much more power that it will outperform a cheaper panel financially. An accurate analysis of long-term performance versus cost, both initial and on-going, is required to determine which panel may lead the owner to better financial results.\n"}
{"id": "3770910", "url": "https://en.wikipedia.org/wiki?curid=3770910", "title": "Ogham inscription", "text": "Ogham inscription\n\nRoughly 400 known ogham inscriptions are on stone monuments scattered around the Irish Sea, the bulk of them dating to the fifth and sixth centuries. Their language is predominantly Primitive Irish, but a few examples record fragments of the Pictish language. Ogham itself is an Early Medieval form of alphabet or cipher, sometimes known as the \"Celtic Tree Alphabet\".\n\nA number of different numbering schemes are used. The most widespread is CIIC, after R. A. S. Macalister. This covers the inscriptions known by the 1940s. Another numbering scheme is that of the Celtic Inscribed Stones Project, CISP, based on the location of the stones; for example CIIC 1 = CISP INCHA/1. Macalister's (1945) numbers run from 1 to 507, including also Latin and Runic inscriptions, with three additional added in 1949. Ziegler lists 344 Gaelic ogham inscriptions known to Macalister (Ireland and Isle of Man), and seven additional inscriptions discovered later.\n\nThe inscriptions may be divided into \"orthodox\" and \"scholastic\" specimens. \"Orthodox\" inscriptions date to the Primitive Irish period, and record a name of an individual, either as a cenotaph or tombstone, or documenting land ownership. \"Scholastic\" inscriptions date from the medieval Old Irish period up to modern times.\n\nThe vast bulk of the surviving ogham inscriptions stretch in arc from County Kerry (especially Corcu Duibne) in the south of Ireland across to Dyfed in south Wales. The remainder are mostly in south-eastern Ireland, eastern and northern Scotland, the Isle of Man, and England around the Devon/Cornwall border. The vast majority of the inscriptions consists of personal names, probably of the person commemorated by the monument.\n\nIn orthodox inscriptions, the script was carved into the edge (\"droim\" or \"faobhar\") of the stone, which formed the stemline against which individual characters are cut. The text of these \"Orthodox Ogham\" inscriptions is read beginning from the bottom left side of a stone, continuing upward along the edge, across the top and down the right side (in the case of long inscriptions).\n\nMacManus (1991) lists a total of 382 known Orthodox inscriptions. They are found in most counties of Ireland, concentrated in southern Ireland: County Kerry (130), Cork (84), Waterford (48), Kilkenny (14), Mayo (9), Kildare (8), Wicklow and Meath (5 each), Carlow (4), Wexford, Limerick, Roscommon (3 each), Antrim, Cavan, Louth, Tipperary (2 each), Armagh, Dublin, Fermanagh, Leitrim, Londonderry and Tyrone (1 each). Other specimens are known from Wales (ca. 40: Pembrokeshire (16), Breconshire and Carmarthenshire (7 each), Glamorgan (4), Cardiganshire (3), Denbighshire (2), Powys (1), and Caernarvonshire (1)), from England (Cornwall (5) Devon (2), elsewhere (1?)); the Isle of Man (5), and with some doubtful examples from Scotland (2?)\n\nThe vast majority of inscriptions consists of personal names and they use a series of formula words, usually describing the person's ancestry or tribal affiliation. The formula words used are MAQI – 'son' (Modern Irish \"mic\"); MUCOI – 'tribe' or 'sept'; ANM – 'name' (Modern Irish \"ainm\"); AVI – 'descendant' (Modern Irish \"uí\"); CELI – 'follower' or 'devotee' (Modern Irish \"céile\"); NETA – 'nephew' (Modern Irish \"nia\"); KOI – 'here is' (equivalent to Latin HIC IACIT). KOI is unusual in that the K is always written using the first supplementary letter \"Ebad\". In order of frequency the formula words are used as follows:\n\n\nThe nomenclature of the Irish personal names is more interesting than the rather repetitive formulae and reveals details of early Gaelic society, particularly its warlike nature. For example, two of the most commonly occurring elements in the names are CUNA – 'hound' or 'wolf' (Modern Irish \"cú\") and CATTU – 'battle' (Modern Irish \"cath\"). These occur in names such as (300) CUNANETAS – 'Champion of wolves'; (501) CUNAMAGLI – 'prince of wolves'; (107) CUNAGUSSOS – '(he who is) strong as a wolf'; (250) CATTUVVIRR – 'man of battle'; (303) CATABAR – 'chief in battle'; IVACATTOS – 'yew of battle'. Other warlike names include (39) BRANOGENI – 'born of raven'; (428) TRENAGUSU – 'strong of vigour'; and (504) BIVAIDONAS – 'alive like fire'. Elements that are descriptive of physical characteristics are also common, such as (368) VENDUBARI – 'fair-headed'; (75) CASONI – 'curly headed one'; (119) DALAGNI – 'one who is blind'; (46) DERCMASOC – 'one with an elegant eye'; (60) MAILAGNI – 'bald/short haired one' and (239) GATTAGLAN – 'wise and pure'.\n\nOther names indicate a divine ancestor. The god Lugh features in many names such as (4) LUGADDON , (286) LUGUDECA and (140) LUGAVVECCA , while the divine name ERC (meaning either 'heaven or 'cow') appears in names such as (93) ERCAIDANA and (196) ERCAVICCAS . Other names indicate sept or tribal name, such as (156) DOVVINIAS from the \"Corcu Duibne\" sept of the Dingle and Iveragh peninsulas in Co. Kerry (named after a local goddess); (215) ALLATO from the \"Altraige\" of North Kerry and (106) CORIBIRI from the \"Dál Coirpri\" of Co. Cork. Finally of particular interest is the fact that quite a few names denote a relationship to trees, names like (230) MAQI-CARATTINN – 'son of rowan'; (v) MAQVI QOLI – 'son of hazel' and (259) IVOGENI – 'born of yew'.\n\nThe content of the inscriptions has led scholars such as McNeill and Macalister to argue that they are explicitly pagan in nature. They argue that the inscriptions were later defaced by Christian converts, who deliberately attacked them by removing the word MUCOI on account of its supposedly tribal, pagan associations, and adding crosses next to them to Christianize them. Other scholars, such as McManus argue that there is no evidence for this, citing inscriptions such as (145) QRIMITIR RONANN MAQ COMOGANN , where QRIMITIR is a loan word from Latin \"presbyter\" or 'priest'. McManus argues that the supposed vandalism of the inscriptions is simply wear and tear, and due to the inscription stones being reused as building material for walls, lintels, etc. (McManus, §4.9). McManus also argues that the MUCOI formula word survived into Christian manuscript usage. There is also the fact the inscriptions were made at a time when Christianity had become firmly established in Ireland. Whether those who wrote the inscriptions were pagans, Christians, or a mixture of both remains unclear.\n\nIreland has the vast majority of inscriptions, with 330 out of 382. One of the most important collections of orthodox ogham inscriptions in Ireland can be seen in University College Cork (UCC) on public display in 'The Stone Corridor'. The inscriptions were \ncollected by antiquarian Abraham Abell 1783–1851 and were deposited in the Cork Institution before being put on display in UCC. He was a member of the Cuvierian Society of Cork whose members, including John Windele, Fr. Matt Horgan and R.R. Brash, did extensive work in this area in the mid-19th century. Another well-known group of inscriptions can be seen at Dunloe, near Killarney in Co. Kerry. The inscriptions are arranged in a semicircle at the side of the road and are very well preserved.\n\nThe orthodox inscriptions in Wales are noted for containing names of a Latin origin and some names in Brythonic (or early Welsh), and are mostly accompanied by a Latin inscription in the Roman alphabet. Examples of Brythonic names include (446) MAGLOCUNI (Welsh \"Maelgwn\") and (449) CUNOTAMI (Welsh \"cyndaf\"). Wales has the distinction of the only ogham stone inscription that bears the name of an identifiable individual. The stone commemorates Vortiporius, a 6th-century king of Dyfed (originally located in Clynderwen). Wales also has the only ogham inscription known to commemorate a woman. At Eglwys Cymmin (Cymmin church) in Carmarthenshire is the inscription (362) AVITORIGES INIGENA CUNIGNI or 'Avitoriges daughter of Cunigni'. Avitoriges is an Irish name while Cunigni is Brythonic (Welsh \"Cynin\"), reflecting the mixed heritage of the inscription makers. Wales also has several inscriptions which attempt to replicate the supplementary letter or forfeda for P (inscriptions 327 and 409). \n\nEngland has seven or eight ogham inscriptions, five in Cornwall and two in Devon, which are the product of early Irish settlement in the area. A further inscription in Silchester in Hampshire is presumed to be the work of a lone Irish settler. Perhaps surprisingly, Scotland has only three orthodox inscriptions, as the rest are scholastic inscriptions made by the Picts (see below). The Isle of Man has five inscriptions. One of these is the famous inscription at Port St. Mary (503) which reads DOVAIDONA MAQI DROATA or 'Dovaidona son of the Druid'.\n\nThe term 'scholastic' derives from the fact that the inscriptions are believed to have been inspired by the manuscript sources, instead of being continuations of the original monument tradition. Scholastic inscriptions typically draw a line into the stone's surface along which the letters are arranged, rather than using the stone's edge. They begin in the course of the 6th century, and continue into Old and Middle Irish, and even into Modern times. From the High Middle Ages, contemporary to the Manuscript tradition, they may contain Forfeda. The 30 or so Pictish inscriptions qualify as early Scholastic, roughly 6th to 9th century. Some Viking Age stones on Man and Shetland are in Old Norse, or at least contain Norse names.\n\n\n\n\n\n"}
{"id": "30250477", "url": "https://en.wikipedia.org/wiki?curid=30250477", "title": "Olinda Landfill", "text": "Olinda Landfill\n\nThe Olinda Landfill (official name: \"Olinda Alpha Sanitary Landfill\") is a landfill situated in Orange County, California, west of the northern portion of Chino Hills State Park in Carbon Canyon in Olinda neighborhood of Brea City.\n\nFacility size is approximately with about permitted for refuse disposal. The landfill has a processing capacity of 8,000 tons per day, while on average it receives 6,800 tons (cca 85% of capacity). City of Brea (where the landfill is situated) alone provides about 30% of the total daily refuse deposited at the facility.\n\nThe landfill was opened in 1960. The facility is owned by Orange County and it is operated by Orange County Waste & Recycling Department (formerly County of Orange Integrated Waste Management Department). \n\nCurrently the landfill is scheduled to close in December 2021. Plans for postponement of landfill's closure by expansion of its area further into Carbon Canyon just west of Brea Olinda High School were cancelled in 1996 as Land and Water Conservation Fund decided to incorporate adjacent federal lands into Chino Hills State Park, rather than to dedicate it for landfill enlargement. After landfill closure the site will be landscaped to become part of Chino Hills State Park.\n\n\n"}
{"id": "22746690", "url": "https://en.wikipedia.org/wiki?curid=22746690", "title": "Outline of tropical cyclones", "text": "Outline of tropical cyclones\n\nThe following outline is provided as an overview of and topical guide to tropical cyclones:\n\nTropical cyclone – storm system characterized by a large low-pressure center and numerous thunderstorms that produce strong winds and heavy rain. Tropical cyclones strengthen when water evaporated from the ocean is released as the saturated air rises, resulting in condensation of water vapor contained in the moist air. They are fueled by a different heat mechanism than other cyclonic windstorms such as nor'easters, European windstorms, and polar lows. The characteristic that separates tropical cyclones from other cyclonic systems is that at any height in the atmosphere, the center of a tropical cyclone will be warmer than its surroundings; a phenomenon called \"warm core\" storm systems.\n\nTropical cyclones can be described as all of the following:\n\n\n\n\n\n\n\n"}
{"id": "2416505", "url": "https://en.wikipedia.org/wiki?curid=2416505", "title": "Pourbaix diagram", "text": "Pourbaix diagram\n\nIn electrochemistry, a Pourbaix diagram, also known as a potential/pH diagram, E-pH diagram or a pE/pH diagram, maps out possible stable (equilibrium) phases of an aqueous electrochemical system. Predominant ion boundaries are represented by lines. As such a Pourbaix diagram can be read much like a standard phase diagram with a different set of axes. Similarly to phase diagrams, they do not allow for reaction rate or kinetic effects.\n\nThe diagrams are named after Marcel Pourbaix (1904–1998), the Russian-born, Belgian chemist who invented them.\n\nPourbaix diagrams are also known as E-pH diagrams due to the labeling of the two axes. The vertical axis is labeled E for the voltage potential with respect to the standard hydrogen electrode (SHE) as calculated by the Nernst equation. The \"H\" stands for hydrogen, although other standards may be used, and they are for room temperature only.\nThe horizontal axis is labeled pH for the -log function of the H ion activity. \n\nThe lines in the Pourbaix diagram show the equilibrium conditions, that is, where the activities are equal, for the species on each side of that line. On either side of the line, one form of the species will instead be said to be predominant.\n\nIn order to draw the position of the lines with the Nernst equation, the activity of the chemical species at equilibrium must be defined. Usually, the activity of a species is approximated as equal to the concentration (for soluble species) or partial pressure (for gases). The same values should be used for all species present in the system.\n\nFor soluble species, the lines are often drawn for concentrations of 1 M or 10 M. Sometimes additional lines are drawn for other concentrations.\n\nIf the diagram involves the equilibrium between a dissolved species and a gas, the pressure is usually set to P = 1 atm = 101,325 Pa, the minimum pressure required for gas evolution from an aqueous solution at standard conditions.\n\nWhile such diagrams can be drawn for any chemical system, it is important to note that the addition of a metal binding agent (ligand) will often modify the diagram. For instance, carbonate has a great effect upon the diagram for uranium. (See diagrams at right.) The presence of trace amounts of certain species such as chloride ions can also greatly affect the stability of certain species by destroying passivating layers.\n\nIn addition, changes in temperature and concentration of solvated ions in solution will shift the equilibrium lines in accordance with the Nernst equation.\n\nThe diagrams also do not take kinetic effects into account, meaning that species shown as unstable might not react to any significant degree in practice.\n\nA simplified Pourbaix diagram indicates regions of \"Immunity\", \"Corrosion\" and \"Passivity\", instead of the stable species. They thus give a guide to the stability of a particular metal in a specific environment. Immunity means that the metal is not attacked, while corrosion shows that general attack will occur. Passivation occurs when the metal forms a stable coating of an oxide or other salt on its surface, the best example being the relative stability of aluminium because of the alumina layer formed on its surface when exposed to air.\n\nFor the simple case of a thermodynamic system consisting of a metal (M) and water, various reaction equations may be written having the form:\n\nwhere \"r\" and \"r\" are any reactants involving M, hydrogen and oxygen. The equation must be balanced for M, H, O and charge. A standard Gibbs free energy formula_4 is associated with each equation. A base-balanced equation can be converted to an acid-balanced equation using the equilibrium constant for the self-ionization of water, and only acid-balanced equations are considered below.\n\nIn the following, the Nernst slope is used, which has a value of 0.02569... V at STP. When base-10 logarithms are used, ∆\"λ\" = 0.05916... V at STP where \"λ\"=ln[10]. There are three types of line boundaries in a Pourbaix diagram: Vertical, horizontal, and sloped.\n\nWhen no electrons are exchanged (\"n\"=0), the equilibrium between \"r\" and \"r\" is not affected by electrode potential, and the boundary line will be a vertical line with a particular value of pH. The reaction equation may be written:\n\nand the energy balance is written as formula_6 where \"K\" is the equilibrium constant: formula_7. Thus:\n\nor, in base-10 logarithms,\n\nwhich may be solved for the particular value of pH.\n\nFor example consider the iron and water system, and the equilibrium line between the ferric ion Fe ion and hematite FeO. The reaction equation is:\n\nwhich has formula_10. The pH of the vertical line on the Pourbaix diagram is then found to be:\n\nAt STP, for [Fe] = 10, [FeO]= [HO]=1, this yields pH=1.76.\n\nWhen H and OH ions are not involved, the boundary line is horizontal, independent of pH. The reaction equation is written:\n\nThe energy balance is\n\nUsing the definition of electrode potential ∆G=-F E this may be rewritten as a Nernst equation:\n\nor, using base-10 logarithms:\n\nFor the iron and water example, consider the boundary line between Fe and Fe . The reaction equation is:\n\nand since electrons are involved, it has Eo=0.771 V and since H ions are not involved, it is independent of pH. As a function of temperature,\n\nFor both ionic species at formula_17 at STP, formula_18 and the boundary will be a vertical line at \"E\"=0.771. This will vary with temperature.\n\nIn this case, both electrons and H ions are involved and the electrode potential is a function of pH. The reaction equation may be written:\n\nUsing the expressions for the free energy in terms of potentials, the energy balance is given by a Nernst equation:\n\nFor the iron and water example, consider the boundary line between the ferrous ion Fe and hematite FeO. The reaction equation is found to be:\n\nwith formula_21. The equation of the boundary line, expressed in base-10 logarithms will be:\n\nFor [FeO]=[HO]=1 and [Fe]=10, this yields \"E\"=1.0826 - 0.1775 pH.\n\nIn many cases, the possible conditions in a system are limited by the stability region of water. In the Pourbaix diagram for uranium, the limits of stability of water are marked by the two dashed green lines, and the stability region for water falls between these lines.\n\nUnder highly reducing conditions (low E/pE) water will be reduced to hydrogen according to\n\nor\n\nUsing the Nernst equation, setting E = 0 V and the hydrogen gas fugacity (corresponding to activity) at 1, the equation for the lower stability line of water in the Pourbaix diagram will be\n\nat standard temperature and pressure. Below this line, water will be reduced to hydrogen, and it will usually not be possible to pass beyond this line as long as there is still water present to be reduced.\n\nCorrespondingly, under highly oxidizing conditions (high E/pE) water will be oxidized to oxygen gas according to\n\nUsing the Nernst equation as above, but with an E of 1.229 V, gives an upper stability limit of water at\n\nat standard temperature and pressure. Above this line, water will be oxidized to form oxygen gas, and it will usually not be possible to pass beyond this line as long as there is still water present to be oxidized.\n\nPourbaix diagrams have several uses, for example in corrosion studies, geoscience and in environmental studies. Using the Pourbaix diagram correctly will help shed light not only on the nature of the species present in the solution (or sample) but may also help to understand the reaction mechanism. \n\nPourbaix diagrams are widely used to describe the chemical behaviour of chemical species in the hydrosphere. In these cases, pE is used instead of E. \npE is a dimensionless number and can easily be related to E by the equation\n\npE values in environmental chemistry ranges from -12 to 25, since at low or high potentials water will be reduced or oxidized, respectively. In environmental applications, the concentration of dissolved species is usually set to a value between 10 M and 10 M for the creation of the equilibrium lines.\n\n\n\n\n"}
{"id": "31070915", "url": "https://en.wikipedia.org/wiki?curid=31070915", "title": "Principles of Motion Sensing", "text": "Principles of Motion Sensing\n\nSensors able to detect three-dimensional motion have been commercially available for several decades and have been used in automobiles, aircraft and ships. However, initial size, power consumption and price had prevented their mass adoption in consumer electronics. While there are other kinds of motion detector technologies available commercially, there are four principle types of motion sensors which are important for motion processing in the consumer electronics market.\n\nAccelerometers measure linear acceleration and tilt angle. Single and multi-axis accelerometers detect the combined magnitude and direction of linear, rotational and gravitational acceleration. They can be used to provide limited motion sensing functionality. For example, a device with an accelerometer can detect rotation from vertical to horizontal state in a fixed location. As a result, accelerometers are primarily used for simple motion sensing applications in consumer devices such as changing the screen of a mobile device from portrait to landscape orientation. The early generation Apple iPhone and Nintendo Wii incorporated accelerometers.\n\nGyroscopes measure the angular rate of rotational movement about one or more axes. Gyroscopes can measure complex motion accurately in multiple dimensions, tracking the position and rotation of a moving object unlike accelerometers which can only detect the fact that an object has moved or is moving in a particular direction. Further, unlike accelerometers and compasses, gyroscopes are not affected by errors related to external environmental factors such as gravitational and magnetic fields. Hence, gyroscopes greatly enhance the motion sensing capabilities of devices and are used for advanced motion sensing applications in consumer devices such as full gesture and movement detection and simulation in video gaming. The Nintendo Wii MotionPlus accessory and the Nintendo 3DS incorporate gyroscopes.\n\nMagnetic Sensors, commonly referred to as compasses detect magnetic fields and measure their absolute position relative to Earth’s magnetic north and nearby magnetic materials. Information from magnetic sensors can also be used to correct errors from other sensors such as accelerometers. One example of how compass sensors are used in consumer devices is reorienting a displayed map to match up with the general direction a user is facing.\n\nPressure Sensors, also known as barometers measure relative and absolute altitude through the analysis of changing atmospheric pressure. Pressure sensors can be used in consumer devices for sports and fitness or location-based applications where information on elevation can be valuable.\n"}
{"id": "2008215", "url": "https://en.wikipedia.org/wiki?curid=2008215", "title": "Quark model", "text": "Quark model\n\nIn particle physics, the quark model is a classification scheme for hadrons in terms of their valence quarks—the quarks and antiquarks which give rise to the quantum numbers of the hadrons. The quark model underlies \"flavor SU(3)\", or the \"Eightfold Way\", the successful classification scheme organizing the large number of lighter hadrons that were being discovered starting in the 1950s and continuing through the 1960s. It received experimental verification beginning in the late 1960s and is a valid effective classification of them to date. The quark model was independently proposed by physicists Murray Gell-Mann, and\nGeorge Zweig (also see) in 1964. Today, the model has essentially been absorbed as a component of the established quantum field theory of strong and electroweak particle interactions, dubbed the Standard Model.\n\nHadrons are not really \"elementary\", and can be regarded as bound states of their \"valence quarks\" and antiquarks, which give rise to the quantum numbers of the hadrons. These quantum numbers are labels identifying the hadrons, and are of two kinds. One set comes from the Poincaré symmetry—\"J\", where \"J\", \"P\" and \"C\" stand for the total angular momentum, P-symmetry, and C-symmetry, respectively.\n\nThe remaining are flavor quantum numbers such as the isospin, strangeness, charm, and so on. The strong interactions binding the quarks together are insensitive to these quantum numbers, so variation of them leads to systematic mass and coupling relationships among the hadrons in the same flavor multiplet.\n\nAll quarks are assigned a baryon number of ⅓. Up, charm and top quarks have an electric charge of +⅔, while the down, strange, and bottom quarks have an electric charge of −⅓. Antiquarks have the opposite quantum numbers. Quarks are spin-½ particles, and thus fermions. Each quark or antiquark obeys the Gell-Mann−Nishijima formula individually, so any additive assembly of them will as well.\n\nMesons are made of a valence quark−antiquark pair (thus have a baryon number of 0), while baryons are made of three quarks (thus have a baryon number of 1). This article discusses the quark model for the up, down, and strange flavors of quark (which form an approximate flavor SU(3) symmetry). There are generalizations to larger number of flavors.\n\nDeveloping classification schemes for hadrons became a timely question after new experimental techniques uncovered so many of them, that it became clear that they could not all be elementary. These discoveries led Wolfgang Pauli to exclaim \"Had I foreseen that, I would have gone into botany.\" and Enrico Fermi to advise his student Leon Lederman: \"Young man, if I could remember the names of these particles, I would have been a botanist.\" These new schemes earned Nobel prizes for experimental particle physicists, including Luis Alvarez, who was at the forefront of many of these developments. Constructing hadrons as bound states of fewer constituents would thus organize the \"zoo\" at hand. Several early proposals, such as the ones by Enrico Fermi and Chen-Ning Yang (1949), and the Sakata model (1956), ended up satisfactorily covering the mesons, but failed with baryons, and so were unable to explain all the data.\n\nThe Gell-Mann–Nishijima formula, developed by Murray Gell-Mann and Kazuhiko Nishijima, led to the Eightfold way classification, invented by Gell-Mann, with important independent contributions from Yuval Ne'eman, in 1961. The hadrons were organized into SU(3) representation multiplets, octets and decuplets, of roughly the same mass, due to the strong interactions; and smaller mass differences linked to the flavor quantum numbers, invisible to the strong interactions. The Gell-Mann–Okubo mass formula systematized the quantification of these small mass differences among members of a hadronic multiplet, controlled by the explicit symmetry breaking of SU(3).\n\nThe spin- baryon, a member of the ground-state decuplet, was a crucial prediction of that classification. After it was discovered in an experiment at Brookhaven National Laboratory, Gell-Mann received a Nobel prize in physics for his work on the Eightfold Way, in 1969.\n\nFinally, in 1964, Gell-Mann, and, independently, George Zweig, discerned what the Eightfold Way picture encodes. They posited elementary fermionic constituents, unobserved, and possibly unobservable in a free form, underlying and elegantly encoding the Eightfold Way classification, in an economical, tight structure, resulting in further simplicity. Hadronic mass differences were now linked to the different masses of the constituent quarks.\n\nIt would take about a decade for the unexpected nature—and physical reality—of these quarks to be appreciated more fully (See Quarks). Counter-intuitively, they cannot ever be observed in isolation (color confinement), but instead always combine with other quarks to form full hadrons, which then furnish ample indirect information on the trapped quarks themselves. Conversely, the quarks serve in the definition of Quantum chromodynamics, the fundamental theory fully describing the strong interactions; and the Eightfold Way is now understood to be a consequence of the flavor symmetry structure of the lightest three of them.\n\nThe Eightfold Way classification is named after the following fact. If we take three flavors of quarks, then the quarks lie in the fundamental representation, 3 (called the triplet) of flavor SU(3). The antiquarks lie in the complex conjugate representation . The nine states (nonet) made out of a pair can be decomposed into the trivial representation, 1 (called the singlet), and the adjoint representation, 8 (called the octet). The notation for this decomposition is\n\nFigure 1 shows the application of this decomposition to the mesons. If the flavor symmetry were exact (as in the limit that only the strong interactions operate, but the electroweak interactions are notionally switched off), then all nine mesons would have the same mass. However, the physical content of the full theory includes consideration of the symmetry breaking induced by the quark mass differences, and considerations of mixing between various multiplets (such as the octet and the singlet).\n\nN.B. Nevertheless, the mass splitting between the and the is larger than the quark model can accommodate, and this \"– puzzle\" has its origin in topological peculiarities of the strong interaction vacuum, such as instanton configurations.\n\nMesons are hadrons with zero baryon number. If the quark–antiquark pair are in an orbital angular momentum state, and have spin , then\n\nIf \"P\" = (−1), then it follows that \"S\" = 1, thus \"PC\"= 1. States with these quantum numbers are called \"natural parity states\"; while all other quantum numbers are thus called \"exotic\" (for example the state ).\n\n \n\nSince quarks are fermions, the spin-statistics theorem implies that the wavefunction of a baryon must be antisymmetric under exchange of any two quarks. This antisymmetric wavefunction is obtained by making it fully antisymmetric in color, discussed below, and symmetric in flavor, spin and space put together. With three flavors, the decomposition in flavor is\nThe decuplet is symmetric in flavor, the singlet antisymmetric and the two octets have mixed symmetry. The space and spin parts of the states are thereby fixed once the orbital angular momentum is given.\n\nIt is sometimes useful to think of the basis states of quarks as the six states of three flavors and two spins per flavor. This approximate symmetry is called spin-flavor SU(6). In terms of this, the decomposition is\n\nThe 56 states with symmetric combination of spin and flavour decompose under flavor SU(3) into\nwhere the superscript denotes the spin, \"S\", of the baryon. Since these states are symmetric in spin and flavor, they should also be symmetric in space—a condition that is easily satisfied by making the orbital angular momentum \"L\" = 0. These are the ground state baryons.\n\nThe \"S\" =  octet baryons are the two nucleons (, ), the three Sigmas (, , ), the two Xis (, ), and the Lambda (). The \"S\" =  decuplet baryons are the four Deltas (, , , ), three Sigmas (, , ), two Xis (, ), and the Omega ().\n\nMixing of baryons, mass splittings within and between multiplets, and magnetic moments are some of the other questions that the model predicts successfully.\n\nColor quantum numbers are the characteristic charges of the strong force, and are completely uninvolved in electroweak interactions. They were discovered as a consequence of the quark model classification, when it was appreciated that the spin \"S\" =  baryon, the , required three up quarks with parallel spins and vanishing orbital angular momentum. Therefore, it could not have an antisymmetric wave function, (due to the Pauli exclusion principle), unless there were a hidden quantum number. Oscar Greenberg noted this problem in 1964, suggesting that quarks should be para-fermions.\n\nInstead, six months later, Moo-Young Han and Yoichiro Nambu suggested the existence of three triplets of quarks to solve this problem, but flavor and color intertwined in that model--- they did not commute.\n\nThe modern concept of color completely commuting with all other charges and providing the strong force charge was articulated in 1973, by William Bardeen, ,\nand Murray Gell-Mann.\n\nWhile the quark model is derivable from the theory of quantum chromodynamics, the structure of hadrons is more complicated than this model allows. The full quantum mechanical wave function of any hadron must include virtual quark pairs as well as virtual gluons, and allows for a variety of mixings. There may be hadrons which lie outside the quark model. Among these are the \"glueballs\" (which contain only valence gluons), \"hybrids\" (which contain valence quarks as well as gluons) and \"exotic hadrons\" (such as tetraquarks or pentaquarks).\n\n\n"}
{"id": "15970822", "url": "https://en.wikipedia.org/wiki?curid=15970822", "title": "Richard G. Richels", "text": "Richard G. Richels\n\nRichard \"Rich\" Gayle Richels directs global climate change research at the Electric Power Research Institute. Richels received a BS degree in physics from the College of William & Mary. He was awarded MS and PhD degrees in decision science from Harvard University's Division of Applied Sciences.\n\nRichels has served on a number of national and international advisory panels, including committees of the Department of Energy, the Environmental Protection Agency, and the National Research Council. He served as an expert witness at the Department of Energy's hearings on the National Energy Strategy and testified at Congressional hearings on priorities in global climate change research. He was a lead author for the Intergovernmental Panel on Climate Change (IPCC) Second, Third and Fourth Assessment Reports (the IPCC shared the 2007 Nobel Peace Prize with Al Gore) and served on the Synthesis Team for the US National Assessment of Climate Change Impacts on the United States. He currently serves on the Scientific Steering Committee for the US Carbon Cycle Program and the Advisory Committee for Princeton University Carbon Mitigation Initiative. He has served as Editor of the Energy, Environment and National Resources area of the Operations Research Journal. He has also served on the Board of Editors of The Energy Journal and the Journal of Applied Stochastic Models and Data Analysis, and contributed to the Energy Modeling Forum.\n\nRichels is a co-author of \"Buying Greenhouse Insurance - the Economic Costs of Emission Limits\" (with Alan S. Manne), and of \"Economic and environmental choices in the stabilization of atmospheric concentrations\" (with Tom Wigley and Jae Edmonds). Both studies outline an economic approach to climate policy. Richels is a researcher on integrated assessment modelling for climate change, and regularly appears in the media.\n\n"}
{"id": "56778275", "url": "https://en.wikipedia.org/wiki?curid=56778275", "title": "Salt toxicosis", "text": "Salt toxicosis\n\nSalt toxicosis is the overconsumption of salt. The symptoms may include (in the gastrointestinal tract and specifically a human's tract) a swollen tongue, nausea, vomiting, diarrhea, abdominal cramps, and thirst. Neurological effects may include thirst, irritability, weakness, headache, and convulsions. Cerebral edema may also occur, and muscle tremors can also be present. Salt toxicosis also affects many breeds of pets or domesticated animals, such as cats, dogs, horses, cows, and birds. Symptoms for pets may include vomiting, diarrhea, inappetence, lethargy, walking drunk, abnormal fluid accumulation within the body, excessive thirst or urination, potential injury to the kidneys, tremors, seizures, coma, and eventually could lead to death without care.\n\nSalt toxicosis may be caused by the ingestion of salt dough.\n"}
{"id": "4345175", "url": "https://en.wikipedia.org/wiki?curid=4345175", "title": "Spar (mineralogy)", "text": "Spar (mineralogy)\n\nSpar is an old mining or mineralogy term used to refer to crystals that have readily discernible faces. A spar will easily break or cleave into rhomboidal, cubical, or laminated fragments with smooth shiny surfaces. \n\nThe various spar minerals were a historical term among miners and alchemists for any nonmetallic mineral akin to gypsum, known in Old English as spærstān, \"spear stone\", referring to its crystalline projections. Thus, the word spar in mineralogy has the same root as \"spear,\" by way of comparison to gypsum, as a common natural crystal forming in spearlike projections.\n\nAmongst miners the term \"spar\" today is frequently used alone to express any bright crystalline substance. Most frequently, spar describes easily cleaved, lightly colored nonmetallic minerals such as feldspar, calcite or baryte. Baryte (BaSO), the main source of barium, is also called \"heavy spar\" (Greek \"barys\" means \"heavy\"). \nCalcite often forms the dogtooth spar crystals found in vugs and caves.\n\nGenerally, a spar will form underwater, either in a phreatic zone, or below the water table, the essential place where most caves form, or in standing pools, as pool spar. If a cave floods and a pool forms, that submerges stalactites, a formation known as bottlebrushes may form. Mineral component ions in the water, mostly calcite or gypsum, but sometimes even halite, quartz, and fluorite, are deposited through the course of thousands of years, building up on each other.\n\nSometimes, spar will form in the air due to solutions seeping out of the cave's walls or through porous sediments. When grown in the air, it is often made of gypsum or selenite. Sometimes it will form as small needles found in sediments. Others spar can be found on the tips of gypsum chandeliers.\n\n\n"}
{"id": "1564687", "url": "https://en.wikipedia.org/wiki?curid=1564687", "title": "Sulfur monoxide", "text": "Sulfur monoxide\n\nSulfur monoxide is an inorganic compound with formula . It is only found as a dilute gas phase. When concentrated or condensed, it converts to SO (disulfur dioxide). It has been detected in space but is rarely encountered intact otherwise.\n\nThe SO molecule has a triplet ground state similar to O, i.e. each molecule has two unpaired electrons. The S−O bond length of 148.1 pm is similar to that found in lower sulfur oxides (e.g. SO, S−O = 148 pm) but is longer than the S−O bond in gaseous SO (146 pm), SO (143.1 pm) and SO (142 pm).\n\nThe molecule is excited with near infrared radiation to the singlet state (with no unpaired electrons). The singlet state is believed to be more reactive than the ground state triplet state, in the same way that singlet oxygen is more reactive than the triplet oxygen.\n\nProduction of SO as a reagent in organic syntheses has centred on using compounds that \"extrude\" SO. Examples include the decomposition of the relatively simple molecule thiirane 1-oxide: as well as more complex examples, such as a trisulfide oxide, CHSO,\n\nThe SO molecule is thermodynamically unstable, converting initially to SO. \nSO inserts into alkenes, alkynes and dienes producing molecules with three membered rings containing sulfur.\n\nIn the laboratory sulfur monoxide can be produced by treating sulfur dioxide with sulfur vapour in a glow discharge. It has been detected in single bubble sonoluminescence of concentrated sulfuric acid containing some dissolved noble gas.\n\nA chemiluminescence detector for sulfur has been reported that is based on the reactions:\n\nAs a ligand SO can bond in a number different ways:\n\nSulfur monoxide has been detected around Io, one of Jupiter's moons, both in the atmosphere and in the plasma torus. It has also been found in the atmosphere of Venus, in the Hale-Bopp comet and in the interstellar medium.\n\nOn Io, SO is thought to be produced both by volcanic and photochemical routes. The principal photochemical reactions are proposed as follows:\n\nSulfur monoxide has been found in the largest star known, NML Cygni.\n\nSulfur monoxide may have some biological activity, the formation of transient SO in porcine coronary artery has been inferred from the reaction products.\n\nBecause of sulfur monoxide's rare occurrence in our atmosphere and poor stability; it is difficult to fully determine its hazards. But when condensed and compacted, it forms disulfur dioxide, which is relatively toxic and corrosive. This compound is also highly flammable (similar flammability to methane) and when burned produces sulfur dioxide, a poisonous gas.\n\nSulfur dioxide SO in presence of hexamethylbenzene C(CH) can be protonated under superacidic conditions (HF/AsF) to give the non-rigid π-complex C(CH)SO. The SO moiety can essientially move barrierless over the benzene ring. The S-O bond length is 1.424(2) Å.\n\n<chem>C6(CH3)6 + SO2 + 3 HF + 3 AsF5 -> [C6(CH3)6SO] [AsF6]2 + [H3O] [AsF6]</chem>\n\nSO converts to disulfur dioxide (SO). Disulfur dioxide is planar molecule with C symmetry. The S-O bond length is 145.8 pm, shorter than in the monomer, and the S-S bond length is 202.45 pm. The OSS angle is 112.7°. SO has a dipole moment of 3.17 D.\n"}
{"id": "17088944", "url": "https://en.wikipedia.org/wiki?curid=17088944", "title": "Synthetic biodegradable polymer", "text": "Synthetic biodegradable polymer\n\nMany opportunities exist for the application of synthetic biodegradable polymers in the biomedical area particularly in the fields of tissue engineering and controlled drug delivery. Degradation is important in biomedicine for many reasons. Degradation of the polymeric implant means surgical intervention may not be required in order to remove the implant at the end of its functional life, eliminating the need for a second surgery. In tissue engineering, biodegradable polymers can be designed such to approximate tissues, providing a polymer scaffold that can withstand mechanical stresses, provide a suitable surface for cell attachment and growth, and degrade at a rate that allows the load to be transferred to the new tissue. In the field of controlled drug delivery, biodegradable polymers offer tremendous potential either as a drug delivery system alone or in conjunction to functioning as a medical device.\n\nIn the development of applications of biodegradable polymers, the chemistry of some polymers including synthesis and degradation is reviewed below. A description of how properties can be controlled by proper synthetic controls such as copolymer composition, special requirements for processing and handling, and some of the commercial devices based on these materials are discussed.\n\nWhen investigating the selection of the polymer for biomedical applications, important criteria to consider are;\n\nMechanical performance of a biodegradable polymer depends on various factors which include monomer selection, initiator selection, process conditions and the presence of additives. These factors influence the polymers crystallinity, melt and glass transition temperatures and molecular weight. Each of these factors needs to be assessed on how they affect the biodegradation of the polymer. Biodegradation can be accomplished by synthesizing polymers with hydrolytically unstable linkages in the backbone. This is commonly achieved by the use of chemical functional groups such as esters, anhydrides, orthoesters and amides. Most biodegradable polymers are synthesized by ring opening polymerization.\n\nBiodegradable polymers can be melt processed by conventional means such as compression or injection molding. Special consideration must be given to the need to exclude moisture from the material. Care must be taken to dry the polymers before processing to exclude humidity. As most biodegradable polymers have been synthesized by ring opening polymerization, a thermodynamic equilibrium exists between the forward polymerization reaction and the reverse reaction that results in monomer formation. Care needs to be taken to avoid an excessively high processing temperature that may result in monomer formation during the molding and extrusion process. It must be followed carefully\n\nOnce implanted, a biodegradable device should maintain its mechanical properties until it is no longer needed and then be absorbed by the body leaving no trace. The backbone of the polymer is hydrolytically unstable. That is, the polymer is unstable in a water based environment. This is the prevailing mechanism for the polymers degradation. This occurs in two stages.\n\n1. Water penetrates the bulk of the device, attacking the chemical bonds in the amorphous phase and converting long polymer chains into shorter water-soluble fragments. This causes a reduction in molecular weight without the loss of physical properties as the polymer is still held together by the crystalline regions. Water penetrates the device leading to metabolization of the fragments and bulk erosion.\n\n2. Surface erosion of the polymer occurs when the rate at which the water penetrating the device is slower than the rate of conversion of the polymer into water-soluble materials.\n\nBiomedical engineers can tailor a polymer to slowly degrade and transfer stress at the appropriate rate to surrounding tissues as they heal by balancing the chemical stability of the polymer backbone, the geometry of the device, and the presence of catalysts, additives or plasticisers.\n\nBiodegradable polymers are used commercially in both the tissue engineering and drug delivery field of biomedicine. Specific applications include.\n\n\n"}
{"id": "2367828", "url": "https://en.wikipedia.org/wiki?curid=2367828", "title": "Tin(IV) Oxide", "text": "Tin(IV) Oxide\n\nTin(IV) Oxide, also known as stannic oxide, is the inorganic compound with the formula SnO. The mineral form of SnO is called cassiterite, and this is the main ore of tin. With many other names, this oxide of tin is an important material in tin chemistry. It is a colourless, diamagnetic, amphoteric solid.\n\nTin(IV) oxide crystallises with the rutile structure. As such the tin atoms are six coordinate and the oxygen atoms three coordinate. SnO is usually regarded as an oxygen-deficient n-type semiconductor. \n\nHydrous forms of SnO have been described as stannic acid. Such materials appear to be hydrated particles of SnO where the composition reflects the particle size.\n\nTin(IV) oxide occurs naturally. Synthetic tin(IV) oxide is produced by burning tin metal in air. Annual production is in the range of 10 kilotons. SnO is reduced industrially to the metal with carbon in a reverberatory furnace at 1200–1300 °C.\n\nAlthough SnO is insoluble in water, it is amphoteric, dissolving in base and acid. \"Stannic acid\" refers to hydrated tin (IV) oxide, SnO, which is also called \"stannic hydroxide.\"\n\nTin oxides dissolve in acids. Halogen acids attack SnO to give hexahalostannates, such as [SnI]. One report describes reacting a sample in refluxing HI for many hours.\nSimilarly, SnO dissolves in sulfuric acid to give the sulfate:\n\nSnO dissolves in strong base to give \"stannates,\" with the nominal formula NaSnO. Dissolving the solidified SnO/NaOH melt in water gives Na[Sn(OH)], \"preparing salt,\" which is used in the dye industry.\n\nIn conjunction with vanadium oxide, it is used as a catalyst for the oxidation of aromatic compounds in the synthesis of carboxylic acids and acid anhydrides.\n\nTin(IV) oxide has long been used as an opacifier and as a white colorant in ceramic glazes. This has probably led to the discovery of the pigment lead-tin-yellow, which was produced using tin(IV) oxide as a compound. The use of tin(IV) oxide has been particularly common in glazes for earthenware, sanitaryware and wall tiles; see the articles tin-glazing and Tin-glazed pottery. Tin oxide remains in suspension in vitreous matrix of the fired glazes, and, with its high refractive index being sufficiently different from the matrix, light is scattered, and hence increases the opacity of the glaze. The degree of dissolution increases with the firing temperature, and hence the extent of opacity diminishes. Although dependent on the other constituents the solubility of tin oxide in glaze melts is generally low. Its solubility is increased by NaO, KO and BO, and reduced by CaO, BaO, ZnO, AlO, and to a limited extent PbO.\n\nSnO has been used as pigment in the manufacture of glasses, enamels and ceramic glazes. Pure SnO gives a milky white colour; other colours are achieved when mixed with other metallic oxides e.g. VO yellow; CrO pink; and SbO grey blue.\n\nTin(IV) oxide can be used as a polishing powder, sometimes in mixtures also with lead oxide, for polishing glass, jewelery, marble and silver. Tin(IV) oxide for this use is sometimes called as \"putty powder\" or \"jeweler's putty\".\n\nSnO coatings can be applied using chemical vapor deposition, vapour deposition techniques that employ SnCl or organotin trihalides e.g. butyltin trichloride as the volatile agent. This technique is used to coat glass bottles with a thin (<0.1 μm) layer of SnO, which helps to adhere a subsequent, protective polymer coating such as polyethylene to the glass.\n\nThicker layers doped with Sb or F ions are electrically conducting and used in electroluminescent devices.\n\nSnO is used in sensors of combustible gases including carbon monoxide detectors. In these the sensor area is heated to a constant temperature (few hundred °C) and in the presence of a combustible gas the electrical resistivity drops.\nDoping with various compounds has been investigated (e.g. with CuO). Doping with cobalt and manganese, gives a material that can be used in e.g. high voltage varistors. Tin(IV) oxide can be doped with the oxides of iron or manganese.\n\n"}
{"id": "40904005", "url": "https://en.wikipedia.org/wiki?curid=40904005", "title": "Tricosylic acid", "text": "Tricosylic acid\n\nTricosylic acid, or \"tricosanoic acid\", is a 23-carbon long-chain saturated fatty acid with the chemical formula CH(CH)COOH.\n\n"}
{"id": "35676171", "url": "https://en.wikipedia.org/wiki?curid=35676171", "title": "Vegetable oil recycling", "text": "Vegetable oil recycling\n\nVegetable oil recycling is increasingly being carried out to produce a vegetable oil fuel.\nIn the UK, waste cooking oil collection is governed by the environment agency. All waste cooking oil collections need to be carried out by a company registered as a waste carrier by the environment agency. On each collection a waste transfer note needs to the filled out and copies held by both parties for a minimum of 3 years. Waste transfer notes need to contain:\n\nFull company details of who the waste is being transferred to: \n\nWaste transfer notes can be hard paper copies or electronic versions. Here is an example of a waste transfer note currently is use by a UK waste cooking oil company.\n\nOpportunities for businesses and consumers to recycle used cooking oil (\"yellow grease\") has increased. Used cooking oil can be refined into different types of biofuels used for power generation and heating. A significant benefit is that biofuels derived from recycled cooking oil typically burn clean, have a low carbon content and do not produce carbon monoxide. This helps communities to reduce their carbon footprints. The recycling of cooking oil also provides a form of revenue for restaurants, which are sometimes compensated by cooking oil recyclers for their used deep fryer oil. Cooking oil recycling also results in less used oil being disposed of in drains, which can clog sewage lines due to the build-up of fats and has to be collected there as \"brown grease\" by grease traps.\n\nVegetable oil refining is a process to transform vegetable oil into fuel by hydrocracking or hydrogenation. Hydrocracking breaks larger molecules into smaller ones using hydrogen while hydrogenation adds hydrogen to molecules. These methods can be used for production of gasoline, diesel, and propane. The diesel fuel that is produced has various names including green diesel or renewable diesel.\n\nIn the past waste oils were collected by pig farmers as part of food waste from pig swill bins. The grease was skimmed off the swill tanks and sold for further processing, while the remaining swill was processed into pig food.\n"}
{"id": "20466209", "url": "https://en.wikipedia.org/wiki?curid=20466209", "title": "William F. Martin", "text": "William F. Martin\n\nWilliam Martin (born February 16, 1957, Bethesda, Maryland) is an American botanist and microbiologist, currently Head of the Institut für Molekulare Evolution, Heinrich Heine Universität, Düsseldorf.\n\nBorn in Bethesda, Maryland, Martin was educated at Richland College, Dallas, Texas, and Texas A&M University. After working as a carpenter in Dallas, Martin moved to Hannover, Germany, and obtained his university Diploma from Technische Universität Hannover in 1985. Martin's PhD is from Max-Planck-Institut für Züchtungsforschung, Cologne, where he did postdoctoral research, followed by further postdoctoral work at Institut für Genetik, Technische Universität Braunschweig, where he obtained his Habilitation in 1992. In 1999, Martin became full (C4) professor at Universität Düsseldorf.\n\nMartin is a distinguished and sometimes controversial contributor to the field of molecular evolution. He is known particularly for his work on the evolution of the Calvin cycle and plastids including chloroplasts, and, more generally, for contributions to understanding the origin and evolution of eukaryotic cells. Martin is co-author, with Miklos Mueller of Rockefeller University, of the 1998 paper \"The Hydrogen hypothesis for the first eukaryote\". A wealth of subsequent research papers include contributions, independently and with Michael J. Russell of the NASA Jet Propulsion Laboratory, to understanding the geochemical origins of cells and their biochemical pathways. Martin's work is well cited (nearly 30,000 times) and he has an h-index of 84.\n\n\n\n\n"}
{"id": "9095248", "url": "https://en.wikipedia.org/wiki?curid=9095248", "title": "Wood flooring", "text": "Wood flooring\n\nWood flooring is any product manufactured from timber that is designed for use as flooring, either structural or aesthetic. Wood is a common choice as a flooring material and can come in various styles, colors, cuts, and species. Bamboo flooring is often considered a form of wood flooring, although it is made from a grass (bamboo) rather than a timber.\n\nSolid hardwood floors are made of planks milled from a single piece of timber. Solid hardwood floors were originally used for structural purposes, being installed perpendicular to the wooden support beams of a building known as joists or bearers. With the increased use of concrete as a subfloor in some parts of the world, engineered wood flooring has gained some popularity. However, solid wood floors are still common and popular. Solid wood floors have a thicker wear surface and can be sanded and finished more times than an engineered wood floor. It is not uncommon for homes in New England, Eastern Canada, USA, and Europe to have the original solid wood floor still in use today.\nSolid wood flooring is milled from a single piece of timber that is kiln or air dried before sawing. Depending on the desired look of the floor, the timber can be cut in three ways: flat-sawn, quarter-sawn, and rift-sawn. The timber is cut to the desired dimensions and either packed unfinished for a site-finished installation or finished at the factory. The moisture content at time of manufacturing is carefully controlled to ensure the product does not warp during transport and storage.\n\nA number of proprietary features for solid wood floors are available. Many solid woods come with grooves cut into the back of the wood that run the length of each plank, often called 'absorption strips,' that are intended to reduce cupping. Solid wood floors are mostly manufactured thick with a tongue-and-groove for installation.\n\nThis process involves treating the wood by boiling the log in water. After preparation, the wood is peeled by a blade starting from the outside of the log and working toward the center, thus creating a wood veneer. The veneer is then pressed flat with high pressure. This style of manufacturing tends to have problems with the wood cupping or curling back to its original shape. Rotary-peeled engineered hardwoods tend to have a plywood appearance in the grain.\n\nThis process begins with the same treatment process that the rotary peel method uses. However, instead of being sliced in a rotary fashion, with this technique the wood is sliced from the log in much the same manner that lumber is sawn from a log – straight through. The veneers do not go through the same manufacturing process as rotary peeled veneers. Engineered hardwood produced this way tends to have fewer problems with \"face checking\", and also does not have the same plywood appearance in the grain. However, the planks can tend to have edge splintering and cracking because the veneers have been submerged in water and then pressed flat.\n\nInstead of boiling the hardwood logs, in this process they are kept at a low humidity level and dried slowly to draw moisture from the inside of the wood cells. The logs are then sawed in the same manner as for solid hardwood planks. This style of engineered hardwood has the same look as solid hardwood, and does not have any of the potential problems of \"face checking\" that rotary-peel and slice-peel products have, because the product is not exposed to added moisture.\n\nEngineered wood flooring consists of two or more layers of wood adhered together to form a plank. Typically, engineered wood flooring uses a thin layer (lamella) of a more expensive wood bonded to a core constructed from cheaper wood. The increased stability of engineered wood is achieved by running each layer at a 90° angle to the layer above. This stability makes it a universal product that can be installed over all types of subfloors above, below or on grade. Engineered wood is the most common type of wood flooring in Europe and has been growing in popularity in North America.\n\nLaminate and vinyl floors are often confused with engineered wood floors, but are not. Laminate flooring uses an image of wood on its surface, while vinyl flooring is plastic formed to look like wood.\n\nThe several different categories of engineered wood flooring include:\n\nIt is difficult to compare solid wood flooring to engineered wood flooring due to the wide range of quality in both product categories, particularly engineered. Solid wood has some limitations. Recommended maximum widths and lengths are typically 5\" / 127mm wide and 7' / 2100mm long. Solid hardwood is also more prone to \"gapping\" (excessive space between planks), \"crowning\" (convex curving upwards when humidity increases) and \"cupping\" (a concave or \"dished\" appearance of the plank, with the height of the plank along its longer edges being higher than the centre) with increased plank size. Solid wood cannot be used with underfloor radiant heating. However extra care is necessary with the planning and installation of the heating system and the wood flooring, such as limiting the temperature to , avoid sharp temperature fluctuations, utilizing an outdoor thermostat to anticipate heating demands, and monitoring the moisture content for the subfloor before installation.\n\nThere are some characteristics that are common to each category: solid wood is more frequently site-finished, is always in a plank format, is generally thicker than engineered wood, and is usually installed by nailing. Engineered wood is more frequently pre-finished, has bevelled edges, is very rarely site-finished, and is installed with glue or as a floating installation.\n\nEngineered wood flooring has other benefits beyond dimensional stability and universal use. Patented installation systems allow for faster installation and easy replacement of boards. Engineered wood also allows for a floating installation where the planks are not adhered to the subfloor or to each other, further increasing ease of repair and reducing installation time. Engineered flooring is also suitable for underfloor and radiant heating systems.\n\nWood can be manufactured with a variety of different installation systems:\n\n\nThe two most popular modern finishes for wood flooring are oil-modified urethane and water-based polyurethane. Within both categories there are many variations and other names used to describe the finish. Oil-modified urethane and water-based polyurethane also have very different refinishing and maintenance regimes.\n\n\nGenerally, hardwood floors need to be buffed every 3–5 years. The process usually takes about one day. Buffing refers to the process of using a stand up floor buffer. The floor is abraded with 180 grit screen on the buffer. This allows for the new coat of finish to mechanically adhere to the floor. This process works with great results as long as the floor hasn't had any waxes or synthetic cleaners.\n\nSanding the finish off old wood floors and smoothing them out.\n\nSanding provides a method for smoothing an installed floor, compensating for unevenness of the subfloor. Additionally, sanding is used to renew the appearance of older floors. Sanding using successively finer grades of sandpaper is required to ensure even stain penetration when stains are used, as well as to eliminate visible scratches from coarser sandpaper grades used initially. Prior to modern polyurethanes, oils and waxes were used in addition to stains to provide finishes. Beeswax and linseed oil, for example, are both natural crosslinking polymers and harden over time.\n\nPrior to the 20th Century hardwood floors were refinished by scraping. This process revealed undamaged wood but left many shallow gouges in the floor. Using chisels, planes, and cabinet scrapers. Modern methods duplicate this using proprietary machinery.\n\n"}
{"id": "35833668", "url": "https://en.wikipedia.org/wiki?curid=35833668", "title": "Xenonium", "text": "Xenonium\n\nThe xenonium ion, XeH, is an onium compound, consisting of protonated xenon. Although the existence of the xenonium cation itself has not been proven, salts of the fluoroxenonium ion, XeF, are known to exist, for instance fluoroxenonium pentafluoroplatinate (XeFPtF), more commonly known as xenon hexafluoroplatinate.\n"}
