{"id": "6295475", "url": "https://en.wikipedia.org/wiki?curid=6295475", "title": "African American Environmentalist Association", "text": "African American Environmentalist Association\n\nThe Center for Environment, Commerce and Energy( Center ) is a private, public interest group focusing on environmental issues. Its stated aims include protecting the environment, enhancing human, animal and plant ecologies, promoting the efficient use of natural resources and increasing participation in the environmental movement.\n\nThe African American Environmentalist Association( AAEA ) is the outreach arm of the Center.\n\nThe Center describes itself as \"aggressively non-partisan\". It has supported Republican policy positions, and particularly those of President George W. Bush on such issues as stem cell research and nuclear power, but has also expressed support for Democrats including Joseph Lieberman.\n\nThe Center is listed as a member of the Nuclear Fuels Reprocessing Coalition and Norris McDonald is its Co-Chairman. AAEA is listed as a member of the New York Affordable Reliable Electricity Alliance. AAEA maintains the Environmental Justice Blog \n\nThe group was founded by Norris McDonald who remains its president.\n\n"}
{"id": "31843696", "url": "https://en.wikipedia.org/wiki?curid=31843696", "title": "Aluminium foam sandwich", "text": "Aluminium foam sandwich\n\nAluminium foam sandwich (AFS) is a sandwich panel product which is made of two metallic dense face sheets and a metal foam core made of an aluminium alloy. AFS is an engineering structural material owing to its stiffness-to-mass ratio and energy absorption capacity ideal for application such as the shell of a high-speed train.\n\nIn terms of the bonding between face sheets and foam core the processing of AFS is categorised into two ways – ex-situ and in-situ bonding.\n\nEx-situ bonding is achieved by gluing face sheets with an aluminium foam by adhesive bonding, brazing or diffusion bonding. Foams used in this method are either closed-cell or open-cell. When a closed-cell foam is used then it is produced from aluminium alloys either by liquid metal route (e.g. Alporas, Cymat) or by powder metallurgy route. Open-cell foam core is made of aluminium and other metals as well. Face sheets are chosen from a variety of aluminium alloy, and other metals such as steel.\n\nFor in-situ bonded face sheets the core is closed-cell foam. The goal of in-situ bonding is to create a metallic bonding between the foam core and face sheets. This is achieved in three ways. A foamable precursor is expanded between two face sheets. When the liquid foam comes in contact with the solid face sheets a metallic bond is established. This is difficult to realize as the oxidation of both aluminium face sheets and foam prevent forming a sound bonding. There is also a risk of melting the face sheets. This procedure is successful when steel is used as face sheets instead of aluminium, while the foam core is aluminium.\n\nAnother strategy is to rapidly solidify the surface of a foamable molten metal before it can foam into to a dense skin while the interior of the metal evolves to a foam structure. This process yields in an integral-type foam structure. Integral foam sandwich is made of aluminium alloys (AlCu4, AlSi9Cu3) and magnesium alloys (AZ91, AM60). In this process the material for the core and face sheet is the same.\n\nThe third way to achieve in-situ bonding consists of compaction of metal powders together with face sheets. This sandwich-compact assembly goes through several rolling steps to attain desired precursor and face sheet thickness. After which this three-layer composite is heated to transform the core layer into foam. The melting point of the face sheet material is above the melting point of the foamable precursor material. The precursor composition is usually Al-Si, Al-Si-Cu or Al-Si-Mg alloys while the face sheets are 3xxx, 5xxx and 6xxx series aluminium alloys.\n\nIt is possible to manufacture a complicated 3D shape from in-situ bonded AFS. In case of the second type, i.e. integral foam moulding, the desired geometry of the foamed part is achieved by designing the mould inside which the foam is cast.\n\nIn the case of the third type the three-layer composite precursor is reshaped prior to foaming. Heating of such part yields in a 3D shaped foam part. The three-layer composite AFS panels are also reshaped after foaming by forging. If an AFS is made of heat treatable alloys, the strength is further enhanced by age hardening. In order to join two AFS parts or to join an AFS part with a metallic part several joining technologies are employed, such as laser welding, TIG welding, MIG welding, riveting, etc.\n\n"}
{"id": "455907", "url": "https://en.wikipedia.org/wiki?curid=455907", "title": "Astraphobia", "text": "Astraphobia\n\nAstraphobia, also known as astrapophobia, brontophobia, keraunophobia, or tonitrophobia is an abnormal fear of thunder and lightning, a type of specific phobia. It is a treatable phobia that both humans and animals can develop. The term astraphobia is composed of the words ἀστραπή (astrape; lightning) and φόβος (phobos; fear).\n\nA person with astraphobia will often feel anxious during a thunderstorm even when they understand that the threat to them is minimal. Some symptoms are those accompanied with many phobias, such as trembling, crying, sweating, panicked reactions, the sudden feeling of using the bathroom, nausea, the feeling of dread, insertion of the fingers in the ears, and rapid heartbeat. However, there are some reactions that are unique to astraphobia. For instance, reassurance from other people is usually sought, and symptoms worsen when alone. Many people who have astraphobia will look for extra shelter from the storm. They might hide underneath a bed, under the covers, in a closet, in a basement, or any other space where they feel safer. Efforts are usually made to smother the sound of the thunder; the person may cover their ears or curtain the windows.\n\nA sign that someone has astraphobia is a very heightened interest in weather forecasts. An astraphobic person will be alert for news of incoming storms. They may watch the weather on television constantly during rainy bouts and may even track thunderstorms online. This can become severe enough that the person may not go outside without checking the weather first. This can lead to anxiety. In very extreme cases, astraphobia can lead to agoraphobia, the fear of leaving the home.\n\nIn 2007 scientists found astraphobia is the third most prevalent phobia in the US. It can occur in people of any age. It occurs in many children, and should not be immediately identified as a phobia because children naturally go through many fears as they mature. Their fear of thunder and lightning cannot be considered a fully developed phobia unless it persists for more than six months. In this case, the child's phobia should be addressed, for it may become a serious problem in adulthood.\n\nTo lessen a child's fear during thunderstorms, the child can be distracted by games and activities. A bolder approach is to treat the storm as an entertainment; a fearless adult is an excellent role model for children.\n\nThe most widely used and possibly the most effective treatment for astraphobia is exposure to thunderstorms and eventually building an immunity. Cognitive behavioral therapy is also often used to treat astraphobia. The patient will in many cases be instructed to repeat phrases to himself or herself in order to become calm during a storm. Heavy breathing exercises can reinforce this effort.\n\nDogs may exhibit severe anxiety during thunderstorms; between 15 and 30 percent may be affected. Research confirms high levels of cortisol - a hormone associated with stress - affects dogs during and after thunderstorms. Remedies include behavioral therapies such as counter conditioning and desensitization, anti-anxiety medications, and Dog Appeasing Pheromone, a synthetic analogue of a hormone secreted by nursing canine mothers.\n\nStudies have also shown that cats can be afraid of thunderstorms. Whilst it is less common, cats have been known to hide under a table or behind a couch during a thunderstorm.\n\nGenerally if any animal is anxious during a thunderstorm or any similar, practically harmless event (e.g. fireworks display), it is advised to simply continue behaving normally, instead of attempting to comfort animals. Showing fearlessness is, arguably, the best method to \"cure\" the anxiety.\n\n"}
{"id": "26457064", "url": "https://en.wikipedia.org/wiki?curid=26457064", "title": "Binary collision approximation", "text": "Binary collision approximation\n\nThe binary collision approximation (BCA) signifies a method used in ion irradiation physics to enable efficient computer simulation of the penetration depth and \ndefect production by energetic (with kinetic energies in the kilo-electronvolt (keV) range or higher) ions in solids. In the method, the ion is approximated to travel through a material by experiencing a sequence of independent binary collisions with sample atoms (nuclei). Between the collisions, the ion is assumed to travel in a straight path, experiencing electronic stopping power, but losing no energy in collisions with nuclei.\n\nIn the BCA approach, a single collision between the incoming ion and a target atom (nucleus) is treated by solving the classical scattering integral between two colliding particles for the \nimpact parameter of the incoming ion. Solution of the integral gives the scattering angle of the\nion as well as its energy loss to the sample atoms, and hence what the energy is after the collision compared to before it.\nThe scattering integral is defined in the centre-of-mass coordinate system (two particles reduced to one single particle with one interatomic potential) and relates the angle of scatter with the interatomic potential.\n\nIt is also possible to solve the time integral of the collision to know what time has elapsed during the collision. This is necessary at least when BCA is used in the \"full cascade\" mode, see below.\n\nThe energy loss to electrons, i.e. electronic stopping power,\ncan be treated either with impact-parameter dependent electronic stopping models\nby subtracting a stopping power dependent on the ion velocity only between the collisions, or a combination of the two approaches.\n\nThe selection method for the impact parameter divided BCA codes into two main\nvarieties: \"Monte Carlo\" BCA and crystal-BCA codes.\n\nIn the so-called Monte Carlo BCA\napproach the distance to and impact parameter of the next colliding atom is chosen randomly\nfor a probability distribution which depends only on the atomic density of the material.\nThis approach essentially simulates ion passage in a fully amorphous material.\n(Note that some sources call this variety of BCA just Monte Carlo, which is \nmisleading since the name can then be confused with other completely different\nMonte Carlo simulation varieties). SRIM and SDTrimSP are Monte-Carlo BCA codes.\n\nIt is also possible (although more difficult) to implement BCA methods for\ncrystalline materials, such that the moving ion has a defined position in a crystal,\nand the distance and impact parameter to the next colliding atom is determined\nto correspond to an atom in the crystal. In this approach BCA can be used\nto simulate also atom motion during channelling. Codes such as MARLOWE operate with this approach.\n\nThe binary collision approximation can also be extended to simulate \ndynamic composition changes of a material due to prolonged\nion irradiation, i.e. due to ion implantation and sputtering.\n\nAt low ion energies, the approximation of independent collisions between atoms starts to break down.\nThis issue can be to some extent augmented by solving the collision integral for multiple simultaneous collisions.\nHowever, at very low energies (below ~1 keV, for a more accurate estimate see ) \nthe BCA approximation always breaks down, and one should use molecular dynamics \nion irradiation simulation approaches because these can, per design, handle many-body collisions of arbitrarily many atoms. The MD simulations can either follow only the incoming ion (\"recoil interaction approximation\" or RIA )\nor simulate all atoms involved in a collision cascade\n\nThe BCA simulations can be further subdivided by type depending on whether they\nonly follow the incoming ion, or also follow the recoils produced by the ion (\"full cascade mode\", e.g., in the popular BCA code SRIM).\nIf the code does not account for secondary collisions (recoils), the number of defects is then calculated using the Robinson extension of the Kinchin-Pease model.\n\nIf the initial recoil/ion mass is low, and the material where the cascade occurs has a low density (i.e. the recoil-material combination has a low stopping power), the collisions between the initial recoil and sample atoms occur rarely, and can be understood well as a sequence of independent binary collisions between atoms. This kind of a cascade can be theoretically well treated using BCA.\n\nThe BCA simulations give naturally the ion penetration depth, lateral spread and nuclear and electronic deposition energy distributions in space. They can also be used to estimate the damage produced in materials, by using the assumption that any recoil which receives an energy higher than the threshold displacement energy of the material will produce a stable defect.\n\nHowever, this approach should be used with great caution for several reasons. For instance, it does not account for any thermally activated recombination of damage, nor the well known fact that in metals the damage production is for high energies only something like 20% of the Kinchin-Pease prediction. Moreover, this approach only predicts the damage production as if all defects were isolated \nFrenkel pairs, while in reality in many cases collision cascades produce defect clusters or even dislocations as the initial damage state.\nBCA codes can, however, be extended with damage clustering and recombination models that improve on their reliability in this respect.\nFinally, the average threshold displacement energy is not very accurately known in most materials.\n\n\n"}
{"id": "4307230", "url": "https://en.wikipedia.org/wiki?curid=4307230", "title": "Bukken Bruse disaster", "text": "Bukken Bruse disaster\n\nThe \"Bukken Bruse\" disaster was the crash of a flying boat during its landing on 2 October 1948. The Short Sandringham was on a Norwegian domestic flight from Oslo and was landing in the bay adjacent to Hommelvik near the city of Trondheim. The disaster killed 19 people; among the survivors was the philosopher Bertrand Russell.\n\nThe flying boat was a Short Sandringham, registration LN-IAW and named \"Bukken Bruse\" after the fairy tale \"The Three Billy Goats Gruff\". The aircraft, operated by Det Norske Luftfartsselskap (now a part of Scandinavian Airlines System) was en route from Oslo's Fornebu Airport.\n\nThe weather in the area of the landing was poor at the time, and the sea in the bay of Hommelvika was foaming white. When the Sandringham was about to touch down on the water, it was hit by a wind gust; the pilots lost control and the right wing float broke off as it hit the water. The aircraft rolled over to the side and its nose ploughed into the water.\n\nThe fuselage rapidly filled with water. Of the 45 people on board, 19 perished. The survivors were all in the smoking compartment at the back of the cabin, near the emergency exit.\n\nThe 76-year-old philosopher Bertrand Russell was on the flight on his way to give a lecture to the local student society. He was seated at the rear of the smoking compartment. In an interview with Trondheim newspaper \"Adresseavisen\" the day after the crash, he said that he was uncertain of what was happening after the jerk until the aircraft tipped over and water rushed in. In his autobiography he wrote that he had made sure to get a seat in the smoking compartment before the flight, saying that \"If I cannot smoke, I should die\". Russell was hospitalized in a Trondheim hospital.\n\nThe investigation found that the crash was caused by the pilot's loss of control during his attempt to land the Sandringham in a crosswind and rough seas with limited space available.\n\n\n"}
{"id": "18522794", "url": "https://en.wikipedia.org/wiki?curid=18522794", "title": "Bushehr Nuclear Power Plant", "text": "Bushehr Nuclear Power Plant\n\nThe Bushehr Nuclear Power Plant () is a nuclear power plant in Iran southeast of the city of Bushehr, between the fishing villages of Halileh and Bandargeh along the Persian Gulf.\n\nConstruction of the plant was started in 1975 by German companies, but the work was stopped in 1979 after the Islamic revolution of Iran. The site was repeatedly bombed during the Iran–Iraq war. Later, a contract for finishing the plant was signed between Iran and the Russian Ministry for Atomic Energy in 1995, with Russia's Atomstroyexport named as the main contractor. The work was delayed several years by technical and financial challenges as well as by political pressure from the West. After construction was again in danger of being stopped in 2007, a renewed agreement was reached in which the Iranians promised to compensate for rising costs and inflation after completion of the plant. Delivery of nuclear fuel started the same year. The plant started adding electricity to the national grid on 3 September 2011, and was officially opened in a ceremony on 12 September 2011, attended by Russian Energy Minister Sergei Shmatko and head of the Rosatom Sergey Kiriyenko.\n\nThe project is considered unique in terms of its technology, the political environment and the challenging physical climate. It is the first civilian nuclear power plant built in the Middle East. Several research reactors had been built earlier in the Middle East: two in Iraq, two in Israel, one in Syria and three in Iran.\n\nIn August 2013, the head of Russian nuclear regulator Rosatom said that the state company would soon sign documents transferring operational control of the Bushehr nuclear power plant to Iran, and on September 23 of 2013, operational control was transferred.\n\nIn November 2014 Iran and Russia signed an agreement to build two new nuclear reactors at the Bushehr site, with an option of six more at other sites later. Construction formally started on 14 March 2017.\n\nThe facility was the idea of the Shah Mohammad Reza Pahlavi. He wanted a national electrical grid powered by nuclear power plants. Bushehr would be the first plant, and would supply energy to the inland city of Shiraz. In August 1974, the Shah said, \"Petroleum is a noble material, much too valuable to burn... We envision producing, as soon as possible, 23,000 megawatts (MW) of electricity using nuclear plants\".\n\nIn 1975, German , a joint venture of Siemens AG and AEG-Telefunken, signed a contract worth US$4–6 billion to build the pressurized water reactor nuclear power plant. The work was begun in the same year. The two 1,196 MWe reactors, subcontracted to ThyssenKrupp AG, were based on the Convoy design (see on the German Wikipedia) and identical with the second reactor unit of the German Biblis Nuclear Power Plant. The first reactor was to be finished by 1980 and the second one by 1981.\n\nKraftwerk Union was eager to work with the Iranian government because, as its spokesman said in 1976, \"To fully exploit our nuclear power plant capacity, we have to land at least three contracts a year for delivery abroad. The market here is about saturated, and the United States has cornered most of the rest of Europe, so we have to concentrate on the third world.\"\n\nKraftwerk Union fully withdrew from the Bushehr nuclear project in July 1979, after work stopped in January 1979, with one reactor 50% complete, and the other reactor 85% complete. They said they based their action on Iran's non-payment of $450 million in overdue payments. The company had received $2.5 billion of the total contract. Their cancellation came after certainty that the Iranian government would unilaterally terminate the contract themselves, following the 1979 Iranian Revolution, which led to a crisis in Iran's relations with the West. Shortly afterwards, Iraq invaded Iran and the nuclear program was stopped until the end of the war.\n\nIn 1984, Kraftwerk Union did a preliminary assessment to see if it could resume work on the project, but declined to do so while the Iran–Iraq War continued. In April of that year, the U.S. State Department said, \"We believe it would take at least two to three years to complete construction of the reactors at Bushehr.\" The spokesperson also said that the light water power reactors at Bushehr \"are not particularly well-suited for a weapons program.\" The spokesman went on to say, \"In addition, we have no evidence of Iranian construction of other facilities that would be necessary to separate plutonium from spent reactor fuel.\" The reactors were then damaged by multiple Iraqi air strikes from 1984 to 1988, during the Iran–Iraq War.\n\nIn 1990, Iran began to look outwards towards partners for its nuclear program; however, due to a radically different political climate and punitive U.S. economic sanctions, few candidates existed.\n\nA Russian–Iranian intergovernmental outline for construction and operation of two reactor units at Bushehr was signed on 25 August 1992. Two years later, Russian specialists toured the site for the first time to assess the damage done to the partially complete plant by the passage of time and by air raids during the Iran–Iraq War. The final contract between Iran and Russia's Ministry for Atomic Energy (Minatom) was signed on 8 January 1995. Russia's main contractor for the project, Atomstroyexport, would install a V-320 915 MWe VVER-1000 pressurized water reactor into the existing Bushehr I building, with commissioning originally expected in 2001.\n\nThe Bushehr Nuclear Plant project is considered unique in terms of technology, the political environment and the challenging physical climate. Financial problems, inflation, and the need to integrate German and Russian technology have made the project difficult for the participants.\n\nAfter the dissolution of the Soviet Union, the Russian government ended its subsidies to contractors building power plants for foreign customers, putting Atomstroyexport in financial difficulties. Another obstacle was the shortage of Russian engineers and technicians with suitable experience. The last nuclear plant built in the Soviet Union was the No. 6 reactor at Zaporizhzhya in Ukraine, which is why Ukrainian specialists were invited to work in Iran after they had finished the work at Zaporizhzhya.\n\nThe 1995 contract with Iran stipulated that a share of construction and installation jobs would be reserved for Iranian subcontractors. These companies were inexperienced and had been only minimally involved in the German project, which resulted in what should have been a one-year task taking over three years (1995–1997). Due to these difficulties, in 1998 Minatom pushed through an agreement that Atomstroyexport would finish the first reactor on its own. The agreement was signed on 29 August 1998 as an addendum to the main contract.\n\nThe extremely hot and humid climate of the Bushehr area, with significant amounts of brine in the air due to the proximity of the ocean, represented a special challenge for the construction. In such conditions, even stainless steel can rust, and a special painting technology had to be developed to protect the station's structural elements. In the summer the temperatures can reach . While the German companies worked at the site, the workers had a special clause in their contracts to allow them to stop working during the summer heat waves.\n\nGerman engineers had left behind a total of 80,000 pieces of equipment and structural elements, with little technical documentation. The Iranian side insisted that the German hardware must be integrated in the Russian VVER-1000 design. Germany refused to help in the construction, mostly for political reasons, as Iran was under an embargo for nuclear plant components. Therefore, it was decided to take stock of the existing equipment using only Russian expertise.\n\nThe 1998 addendum to the construction contract put the final value of the project at just over $1 billion. After that, the sum was not adjusted for inflation, resulting in funding shortages which almost again halted work.\n\nIn 2001, several items for the NPP—in particular, the footing for the reactor and four 82-ton water tanks—were manufactured on Atommash, Russia's nuclear engineering flagship.\n\nIn response to American and European pressure on Russia, a new revised agreement was reached in September 2006, under which fuel deliveries to Bushehr were scheduled to start in March 2007 and the plant was due to come on stream in September 2007 after years of delays. In February 2007, the work on the site faltered due to funding shortages, and Atomstroyexport reduced the number of employees working on the site from 3,000 to just 800. During subsequent negotiations, Atomstroyexport even contemplated pulling out of the project. In the end, an agreement was reached, under which the Iranians would compensate for the growing cost of equipment and engineering works once the reactor went live. A top Iranian nuclear official claimed that the Russians were deliberately delaying and politicising the project under European and American pressure.\n\nPrior to the contract revision, the price was about a third that of a contemporary reactor, at just over $1 billion, reflecting the year of the original contract and that it was the first post-Soviet nuclear export order. Increased material costs and currency fluctuations had made completion at that price difficult.\n\nAccording to Moscow Defense Brief, until 2005 Washington exerted considerable diplomatic pressure on Russia to stop the project, as the US administrations viewed it as evidence of Russia's indirect support for the alleged Iranian nuclear arms program. The United States also tried to persuade other countries to ban their companies from taking part. For example, Ukraine's Turboatom was to supply a turbine, but cancelled the deal after the US Secretary of State Madeleine Albright's visit to Kiev on 6 March 1998. The United States lifted its opposition to the project in 2005, partly due to the deal signed by Moscow and Tehran, under which spent fuel from the plant would be sent back to Russia.\n\nIn 2007, according to Moscow Defense Brief, Russia made a strategic decision to finish the plant, and in December 2007 started to deliver nuclear fuel to the site. On 20 January 2008 a fourth Russian shipment of nuclear fuel arrived. Russia has pledged to sell 85 tons of nuclear fuel to the plant.\n\nIn March 2009, the head of Russia's state nuclear power corporation Rosatom, Sergei Kiriyenko, announced that Russia had completed the construction of the plant. A series of pre-launch tests were conducted after the announcement.\n\nOn 22 September 2009, it was reported that the first reactor was 96% complete and final testing would begin in the near future. In early October final testing was started. In January 2010, Kiriyenko announced to the public that the Bushehr reactor would be opening in the near-future, declaring 2010 the \"year of Bushehr.\"\nOn 13 August 2010, Russia announced that fuel would be loaded into the plant beginning on 21 August, which would mark the beginning of the plant being considered an active nuclear facility. Within six months after the fuel loading, the plant was planned to be fully operational.\n\nAn official launch ceremony was held on 21 August 2010 as Iran began loading the plant with fuel. At the ceremony, Iranian nuclear chief Alki Akbar Salahei said:\nAlthough they have opposed the project in the past, Western governments now stress that they have no objection to the demonstrably peaceful aspects of Iran's nuclear programme such as Bushehr, according to the BBC. Spokesman of the United States State Department, Darby Holladay, stated that the United States believes the reactor is designed to produce civilian nuclear power and does not view it as a proliferation risk as long as the Russians were responsible for the fuel.\n\nOn 27 November 2010, the head of the Atomic Energy Organization of Iran declared that \"All fuel assemblies have been loaded into the core of the reactor\" and they were hoping that the facility \"will hook up with the national grid in one or two months\".\n\nThe plant is to be operated by Russian specialists. Russia also provides the nuclear fuel for the plant, and spent fuel is sent back to Russia. The Bushehr plant will satisfy about 2% of Iran's projected electricity consumption.\n\nThe former head of Pakistan's Inter-Services Intelligence hailed Iran's launch as a positive move in the Muslim world, and he also said that an anti-Iran campaigns by the US and Israel stems from Iran's Islamic status. \"Bushehr Nuclear Power Plant is a victory for Iran and indicates that Iranians do their best to achieve their peaceful objectives but the US and Israel are not ready to accept this achievement.\"\n\nIn February 2011, Rosatom announced that one of the reactor’s four main cooling pumps, from the original German reactor, had suffered damage. Thoroughly cleaning the reactor of metal particles required the removal of the fuel core, resulting in a startup delay. The reactor achieved a sustained nuclear reaction at 11:12 on 8 May 2011 and ran at a minimum power level for final commissioning tests.\n\nThe plant was connected to the national grid on 3 September 2011, and the official inauguration was held on 12 September. By the inauguration time the plant had the capacity to run at 40% capacity, while the full projected capacity of the first unit is 1,000 megawatts. The opening ceremony was attended by Energy Minister of Russia Sergei Shmatko and head of the Russian Federal Atomic Energy Agency (Rosatom) Sergei Kiriyenko, AEOI Director Fereydoun Abbasi, Iranian Energy Minister Majid Namjou and a number of Iranian MPs.\n\nUnder the terms of Russia–Iran agreement, approved by the International Atomic Energy Agency, Russia will be responsible for operating the plant, supplying the nuclear fuel and managing the spent fuel for the next two or three years before passing full control to Iran. Before the plant will reach full capacity in November, it will be disconnected from the grid for several weeks to make a number of tests.\n\nDirector Fereydoun Abbasi announced on 15 February that the Bushehr nuclear power plant had reached 75 percent of its power generation capacity. Abbasi was quoted \"that hopefully the Bushehr plant will be connected to the national grid at its full capacity in late April.\"\n\nOn 30 August at 18:47 local time, the power unit 1 was brought to 100 percent of its power generation capacity.\n\nIn September 2013, the Bushehr plant began producing power for the power grid. For two years the plant was operated by Iranian staff with the assistance of Russian specialists, after which Iran received sole control of the plant. The first refuelling of the reactor was completed in July 2014.\n\nOn November 11, 2014, Iran and Russia signed an agreement to build two new nuclear reactors at the Bushehr site, with an option of six more at other sites later.\n\nRussia’s State Atomic Energy Corporation, Rosatom, started site preparation of the two unit VVER-1000 nuclear power plant with a combined capacity of 2100 MWe in September 2016. On 14 March 2017 construction formally started. Units 2 and 3 are planned to be completed in 2024 and 2026.\n\nThe total cost of the project is estimated to be over €3 billion including the payments to both Russia and Germany. The original 1995 contract with the 1998 addendum was worth $1 billion and was not adjusted for inflation. Although in 2007 Iran agreed to compensate for the rising costs after the construction is finished, it is regarded that the possibility of the project turning a profit are remote. However, the project allowed the nuclear industry of Russia to preserve its expertise in times when funding was scarce, and until the sector started to receive orders from China and India.\n\nAccording to Moscow Defense Brief, completion of the plant could become an indicator of Russia's credibility in large international high technology projects, and the successful integration of German and Russian technology could help the Russian nuclear industry in its ambitions to partner with foreign companies in building nuclear power plants in Russia and abroad.\n\nSince Bushehr's nuclear reactor has been under construction by different firms and consultants, the constituent parts have also different origins. 24% of the parts are German in origin, 36% are Iranian-made while 40% are Russian-made.\n\nTehran and Moscow have established a joint venture to operate Bushehr because Iran has not yet had enough experience in maintaining such installations. However, Iran may begin almost all operational control of the reactor within two or three years.\n\nA further two reactors of the same type are planned, and a preliminary agreement was made in 2014, though details have still to be agreed. The fourth unit was canceled, though further VVER units may be built elsewhere in Iran.\n\nAn Iranian parliament member proposed paying the Russian women working in Bushehr to cover their heads.\n\nThe Center for Energy and Security Studies, a Moscow-based independent think tank, explained the construction delays of the plant as partly due to a \"shortage of skilled Russian engineering and construction specialists with suitable experience\". It also spoke of \"frequent problems with quality and deadlines”. Aging equipment at the plant has also been a problem and, in February 2011, a 30-year-old German cooling pump broke, sending metal debris into the system. In 2010, the IAEA noted that the facility was understaffed.\n\nLeaders from Gulf Cooperation Council (GCC) countries have expressed fears that a serious nuclear accident at the Bushehr plant would spread radiation throughout the region. Bushehr is closer to six Arab capitals (Kuwait City, Riyadh, Manama, Doha, Abu Dhabi, and Muscat) than it is to Tehran. The government of Oman believes the plant presents no risk to Oman.\n\nAccording to Kuwaiti geologist, Dr.Jassem al-Awadi, the plant is located at the junction of three tectonic plates. However the United States Geological Survey and NASA characterise the geology as near the boundary of two tectonic plates, the Arabian plate and the Eurasian plate. The plant is designed to withstand without serious damage a magnitude 8 earthquake, and survive up to magnitude 9.\n\nIn 2011 there were reports of safety concerns about the Bushehr plant, associated with construction of the plant itself, aging equipment at the plant, and understaffing.\n\nA 2011 Natural Resources Defense Council report that evaluated the seismic hazard to reactors worldwide, as determined by the Global Seismic Hazard Assessment Program data, placed Busheher within the second group of 36 reactors within high seismic hazard areas, at lower risk than 12 reactors within very high seismic hazard areas in Japan and Taiwan.\n\nIran is with Israel one of the two countries in the world with significant nuclear activities not to ratify the 1994 Convention on Nuclear Safety, a system of peer review and mutual oversight, and it has been suggested that nuclear safety in Iran could benefit from Iran and Israel signing the convention.\n\nIn October 2012, the plant had to be shut down to limit damage after stray bolts were found beneath the fuel cells, contradicting Iran's earlier assurances that nothing unexpected had happened and that removing nuclear fuel from the plant was just routine.\n\nTwo diplomats claimed anonymously to press-agency AP, that earthquakes in April and May 2013 had caused a big crack in a wall of at least one of the buildings, the building that contains the reactor core however had no visible damage to it. Although spokesmen in Tehran argued earlier that the nuclear facility in Bushehr had suffered no damage during these earthquakes. The claims made by the anonymous diplomats have been refuted by Rosatom.\n\n\n\n"}
{"id": "40820386", "url": "https://en.wikipedia.org/wiki?curid=40820386", "title": "Būtingė oil terminal", "text": "Būtingė oil terminal\n\nBūtingė oil terminal () is an oil terminal near the village of Būtingė in northern Lithuania. Planned, designed and implemented by Fluor Corporation, it is a part of ORLEN Lietuva (formerly \"Mažeikių Nafta\"). Būtingė has been in operation since July 1999, and is the first major petroleum project that Lithuania implemented after it attained independence in 1990. The facilities can accommodate crude oil exports of 8 million tons and imports to the extent of 6 to 8 million tons. \n\nThe oil terminal is situated in the municipality of Palanga, on the coast of the Baltic Sea, close to the border with Latvia. It lies near the mouth of the Šventoji River. The project, the first of its kind on this coast, sits on 1,239 hectares on the Baltic Sea coast north of the port of Klaipėda.\n\nThe Resolution on the Approval of the Būtingė Oil Terminal Statue defines the legal framework for the oil terminal. The Būtingė facility was planned, designed and implemented by Fluor Corporation. The project was contracted by ORLEN Lietuva for US$300 million. After the EPCM (engineering, procurement, and construction management) part of the project contract was awarded, work started in July 1995 and was completed in July 1999. It became the fastest route for Russian oil exports. In 2001, Būtingė was recorded to be the \"fastest growing route for Russian oil export\".\n\nThe terminal is somewhat controversial because of a fear of oil spills, which have occurred. Protests took place in 1999 after an oil spill, and in November 2001 a 60-ton oil spill took place here, angering environmentalists. \n\nSince July 2006, the Būtingė oil terminal is the only way to supply ORLEN Lietuva with oil, because the Russian partner, state-controlled Lukoil corporation, has cut off the supply through the Druzhba pipeline from Russia. In spite of the cutting off of the supply pipeline by Russia and adverse weather conditions, it is reported that the terminal handled unloading of 9 million tons of crude oil during 2010, a 7% rise over the 2009 figures. It is also reported that the terminal is capable of importing nearly 12 million tons of crude oil every year and tankers have capacity of up to 150,000 tons.\n\nThe refinery was planned and designed as a single-point offshore mooring with a capacity to offload up to 4932 m/h. The mooring is in the form of a floating buoy. There is a pipeline, pumping stations, and an offshore terminal. The facilities are capable of handling 8 million tons of crude oil for exports and 5 to 6 million tons for import. An offshore submarine pipeline measuring in diameter and in length connects to the shore facilities. A pipeline connects to three oil storage tanks which are floating roof tanks for crude oil storage. Pumping stations and a single-point mooring terminal have also been built. Tanks for storing diesel and oil are on the roof. Pumps load crude oil to tankers and transport the same over a distance of to the refinery of ORLEN Lietuva near Mažeikiai.\n\n\n"}
{"id": "3152669", "url": "https://en.wikipedia.org/wiki?curid=3152669", "title": "C1W reactor", "text": "C1W reactor\n\nThe C1W reactor is a nuclear reactor used by the United States Navy to provide electricity generation and propulsion on warships. C1W reactors, like all United States Naval reactors, are pressurized water reactors. The C1W designation stands for:\n\n\nThis type of nuclear propulsion plant was used exclusively on the \"Long Beach\"-class guided missile cruiser, the world's first nuclear-powered cruiser. The C1W was the only nuclear reactor ever explicitly earmarked for a cruiser (two of them, powering two geared turbines) with all subsequent nuclear cruisers powered by \"D\"-class (or destroyer-type) reactors.\n\nThe , commissioned September 1961, was decommissioned May 1995.\n"}
{"id": "4019216", "url": "https://en.wikipedia.org/wiki?curid=4019216", "title": "Charles-Émile Trudeau", "text": "Charles-Émile Trudeau\n\nJoseph Charles-Émile \"Charley\" Trudeau (July 5, 1887 – April 10, 1935) was a French Canadian entrepreneur, father of Pierre Trudeau, 15th Prime Minister of Canada, and grandfather of Justin Trudeau, 23rd and current Prime Minister of Canada.\n\nCharles-Émile Trudeau was born on his family's farm in Saint-Michel-de-Napierville, Quebec, the son of Joseph Trudeau (1848–1919), a semi-literate farmer, and Malvina Cardinal (1849–1931), whose own father was Solime Cardinal (1815–1897), mayor of Saint-Constant, Quebec. Malvina insisted that her sons be given a strong education; her husband agreed to send them to College Sainte-Marie. Trudeau later studied law at the Laval University's campus in Montreal, which in 1919 became the University of Montreal. After a 10-year courtship, he married Grace Elliott (1890–1973), the daughter of a prominent Scots-Quebecer entrepreneur, Philip Armstrong Elliott (1859–1936), and his wife Sarah Sauvé (1857–1899), on May 11, 1915 in Montreal at the original Saint-Louis-de-France Roman Catholic Church on Roy Street at Laval Avenue which was later destroyed by fire in 1933. They would have four children, their first child dying at birth. Charles-Émile Trudeau was considered gregarious, boisterous and extravagant.\n\nTrudeau, a lawyer by training, practised for 10 years with Ernest Bertrand, at that time the Senior Crown Prosecutor, as well as with Charles E. Guérin. Trudeau accumulated a fortune by building a number of gas stations around the Montreal area and a loyalty program known as the Automobile Owners' Association, which by 1932 had 15,000 members patronizing Trudeau's 30 stations. He sold his business to Champlain Oil Products Limited for $1 million, while remaining with Champlain as its general manager. Among his other investments, Trudeau had interests in mining companies. He was a noted baseball enthusiast: he was the largest shareholder and member of the Board of Directors of the Montreal Royals baseball team, and the team's vice-president at the time of his death. He was also vice-president of Montreal's Belmont Park and a prominent philanthropist, including as a benefactor of the Hôpital Sainte-Jeanne d'Arc, for which he also served as director at the time of his death.\n\nPolitically, Trudeau was a strong supporter of the Conservative Party, opposed to Prime Minister William Lyon Mackenzie King. Pierre Trudeau would recall that \"political arguments never lacked liveliness\" between Charles and his friends.\n\nHe died of a heart attack in 1935 in Orlando, Florida, while on the road with the Royals, and was laid to rest at his family vault in St-Rémi-de-Napierville Cemetery. Due to Trudeau's business, Pierre Trudeau himself inherited wealth. Trudeau served as an inspiration to the Prime Minister. As Jim Coutts, Pierre Trudeau's aide, recalled, Trudeau \"talked, at times, of his father, whom he greatly admired, but who was too busy to understand his son's interests or spend much time with him.\" Pierre Trudeau named his third son, Michel Charles Émile Trudeau, after him.\n"}
{"id": "27535205", "url": "https://en.wikipedia.org/wiki?curid=27535205", "title": "Crystallization of polymers", "text": "Crystallization of polymers\n\nCrystallization of polymers is a process associated with partial alignment of their molecular chains. These chains fold together and form ordered regions called lamellae, which compose larger spheroidal structures named spherulites. Polymers can crystallize upon cooling from the melt, mechanical stretching or solvent evaporation. Crystallization affects optical, mechanical, thermal and chemical properties of the polymer. The degree of crystallinity is estimated by different analytical methods and it typically ranges between 10 and 80%, thus crystallized polymers are often called \"semi-crystalline\". The properties of semi-crystalline polymers are determined not only by the degree of crystallinity, but also by the size and orientation of the molecular chains.\n\nPolymers are composed of long molecular chains which form irregular, entangled coils in the melt. Some polymers retain such a disordered structure upon freezing and thus convert into amorphous solids. In other polymers, the chains rearrange upon freezing and form partly ordered regions with a typical size of the order 1 micrometer. Although it would be energetically favorable for the polymer chains to align parallel, such alignment is hindered by the entanglement. Therefore, within the ordered regions, the polymer chains are both aligned and folded. Those regions are therefore neither crystalline nor amorphous and are classified as semicrystalline. Examples of semi-crystalline polymers are linear polyethylene (PE), polyethylene terephthalate (PET), polytetrafluoroethylene (PTFE) or isotactic polypropylene (PP).\n\nWhether or not polymers can crystallize depends on their molecular structure – presence of straight chains with regularly spaced side groups facilitates crystallization. For example, crystallization occurs much easier in isotactic than in the atactic polypropylene form. Atactic polymers crystallize when the side groups are very small, as in polyvinyl and don't crystallize in case of large substituents like in rubber or silicones.\n\nNucleation starts with small, nanometer-sized areas where as a result of heat motion some chains or their segments occur parallel. Those seeds can either dissociate, if thermal motion destroys the molecular order, or grow further, if the grain size exceeds a certain critical value.\n\nApart from the thermal mechanism, nucleation is strongly affected by impurities, dyes, plasticizers, fillers and other additives in the polymer. This is also referred to as heterogeneous nucleation. This effect is poorly understood and irregular, so that the same additive can promote nucleation in one polymer, but not in another. Many of the good nucleating agents are metal salts of organic acids, which themselves are crystalline at the solidification temperature of the polymer solidification.\n\nCrystal growth is achieved by the further addition of folded polymer chain segments and only occurs for temperatures below the melting temperature T and above the glass transition temperature T. Higher temperatures destroy the molecular arrangement and below the glass transition temperature, the movement of molecular chains is frozen. Nevertheless, secondary crystallization can proceed even below T, in the time scale of months and years. This process affects mechanical properties of the polymers and decreases their volume because of a more compact packing of aligned polymer chains.\n\nThe chains interact via various types of the van der Waals forces. The interaction strength depends on the distance between the parallel chain segments and it determines the mechanical and thermal properties of the polymer.\n\nThe growth of the crystalline regions preferably occurs in the direction of the largest temperature gradient and is suppressed at the top and bottom of the lamellae by the amorphous folded parts at those surfaces. In the case of a strong gradient, the growth has a unidirectional, dendritic character. However, if temperature distribution is isotropic and static then lamellae grow radially and form larger quasi-spherical aggregates called spherulites. Spherulites have a size between about 1 and 100 micrometers and form a large variety of colored patterns (see, e.g. front images) when observed between crossed polarizers in an optical microscope, which often include the \"maltese cross\" pattern and other polarization phenomena caused by molecular alignment within the individual lamellae of a spherullite.\n\nThe above mechanism considered crystallization from the melt, which is important for injection molding of plastic components. Another type of crystallization occurs upon extrusion used in making fibers and films.\n\nIn this process, the polymer is forced through, e.g., a nozzle that creates tensile stress which partially aligns its molecules. Such alignment can be considered as crystallization and it affects the material properties. For example, the strength of the fiber is greatly increased in the longitudinal direction, and optical properties show large anisotropy along and perpendicular to the fiber axis. Such anisotropy is more enhanced in presence of rod-like fillers such as carbon nanotubes, compared to spherical fillers. Polymer strength is increased not only by extrusion, but also by blow molding, which is used in the production of plastic tanks and PET bottles. Some polymers which do not crystallize from the melt, can be partially aligned by stretching.\n\nSome elastomers which are amorphous in the unstrained state undergo rapid crystallization upon stretching.\n\nPolymers can also be crystallized from a solution or upon evaporation of a solvent. This process depends on the degree of dilution: in dilute solutions, the molecular chains have no connection with each other and exist as a separate polymer coils in the solution. Increase in concentration which can occur via solvent evaporation, induces interaction between molecular chains and a possible crystallization as in the crystallization from the melt. Crystallization from solution may result in the highest degree of polymer crystallinity. For example, highly linear polyethylene can form platelet-like single crystals with a thickness on the order 10–20 nm when crystallized from a dilute solution. The crystal shape can be more complex for other polymers, including hollow pyramids, spirals and multilayer dendritic structures.\n\nA very different process is precipitation; it uses a solvent which dissolves individual monomers but not the resulting polymer. When a certain degree of polymerization is reached, the polymerized and partially crystallized product precipitates out of the solution. The rate of crystallization can be monitored by a technique which selectively probes the dissolved fraction, such as nuclear magnetic resonance.\n\nWhen polymers crystallize from an isotropic, bulk of melt or concentrated solution, the crystalline lamellae (10 to 20 nm in thickness) are typically organized into a spherulitic morphology as illustrated above. However, when polymer chains are confined in a space with dimensions of a few tens of nanometers, comparable to or smaller than the lamellar crystal thickness or the radius of gyration, nucleation and growth can be dramatically affected. As an example, when a polymer crystallizes in a confined ultrathin layer, the isotropic spherulitic organization of lamellar crystals is hampered and confinement can produce unique lamellar crystal orientations. Sometimes the chain alignment is parallel to the layer plane and the crystals are organized as ‘‘on-edge’’ lamellae. In other cases, \"in-plane\" lamellae with chain orientation perpendicular to the layers are observed.\n\nThe unique crystal orientation of confined polymers imparts anisotropic properties. In one example the large, in-plane polymer crystals reduce the gas permeability of nanolayered films by almost 2 orders of magnitude.\n\nThe fraction of the ordered molecules in polymer is characterized by the degree of crystallinity, which typically ranges between 10% and 80%. Higher values are only achieved in materials having small molecules, which are usually brittle, or in samples stored for long time at temperatures just under the melting point. The latter procedure is costly and is applied only in special cases.\n\nMost methods of evaluating the degree of crystallinity assume a mixture of perfect crystalline and totally disordered areas; the transition areas are expected to amount to several percent. These methods include density measurement, differential scanning calorimetry (DSC), X-ray diffraction (XRD), infrared spectroscopy and nuclear magnetic resonance (NMR). The measured value depends on the method used, which is therefore quoted together with the degree of crystallinity.\n\nIn addition to the above integral methods, the distribution of crystalline and amorphous regions can be visualized with microscopic techniques, such as polarized light microscopy and transmission electron microscopy.\n\n\n\n\n\nThe methods used to determine the degree of crystallinity can be incorporated over time to measure the kinetics of crystallization. The most basic model for polymer crystallization kinetics comes from Hoffman nucleation theory. The crystallization process of polymers does not always obey simple chemical rate equations. Polymers can crystallize through a variety of different regimes and unlike simple molecules, the polymer crystal lamellae have two very different surfaces. The two most prominent theories in polymer crystallization kinetics are the Avrami equation and Lauritzen-Hoffman Growth Theory.\n\nBelow their glass transition temperature, amorphous polymers are usually hard and brittle because of the low mobility of their molecules. Increasing the temperature induces molecular motion resulting in the typical rubber-elastic properties. A constant force applied to a polymer at temperatures above T results in a viscoelastic deformation, i.e., the polymer begins to creep. Heat resistance is thus given for amorphous polymers just below the glass transition temperature.\n\nRelatively strong intermolecular forces in semicrystalline polymers prevent softening even above the glass transition temperature. Their elastic modulus changes significantly only at high (melting) temperature. It also depends on the degree of crystallinity: higher crystallinity results in a harder and more thermally stable, but also more brittle material, whereas the amorphous regions provide certain elasticity and impact resistance. Another characteristic feature of semicrystalline polymers is strong anisotropy of their mechanical properties along the direction of molecular alignment and perpendicular to it.\n\nAbove the glass transition temperature amorphous chains in a semi-crystalline polymer are ductile and are able to deform plastically. Crystalline regions of the polymer are linked by the amorphous regions. Tie molecules prevent the amorphous and crystalline phases from separating under an applied load. When a tensile stress is applied the semi-crystalline polymer first deforms elastically. While the crystalline regions remain unaffected by the applied stress, the molecular chains of the amorphous phase stretch. Then yielding, which signifies the onset of plastic deformation of the crystalline regions, occurs.\n\nThe molecular mechanism for semi-crystalline yielding involves the deformation of crystalline regions of the material via dislocation motion. Dislocations result in coarse or fine slips in the polymer and lead to crystalline fragmentation and yielding. Fine slip is defined as a small amount of slip occurring on a large number of planes. Conversely, coarse slip is a large amount of slip on few planes. The yield stress is determined by the creation of dislocations and their resistance to motion. \n\nAfter yielding, a neck is formed in the amorphous region and propagates down the sample length. During necking, the disordered chains align along the tensile direction, forming an ordered structure that demonstrates strengthening due to the molecular reorientation. The flow stress now increases significantly following neck propagation. Mechanical anisotropy increases and the elastic modulus varies along different directions, with a high modulus observed in the draw direction. Drawn semi-crystalline polymers are the strongest polymeric materials due to the stress-induced ordering of the molecular chains.\n\nOther defects, such as voids, occur in the semi-crystalline polymer under tensile stress and can drive the formation of the neck. The voids can be observed via small angle x-ray scattering. Unlike crazes these voids do not transfer stresses.. Notably, cavitation is not observed under compressive stress or shearing. Evidence suggests that cavitation also impacts the onset of yielding. The voids are associated with the breaking of the amorphous phase. The strength of the crystalline phase determines the importance of cavitation in yielding. If the crystalline structures are weak, they deform easily resulting in yielding. Semi-crystalline polymers with strong crystalline regions resist deformation and cavitation, the formation of voids in the amorphous phase, drives yielding.\n\nAs done in crystalline materials, particles can be added to semi-crystalline polymers to change the mechanical properties. In crystalline materials the addition of particles works to impede dislocation motion and strengthen the material. However, for many semi-crystalline polymers particle fillers weaken the material. It has been suggested that for particles to have a toughening effect in polymers the interparticle matrix ligament thickness must be smaller than a certain threshold. Crystalline polymers polypropylene and polyethylene display particle strengthening.\n\nPlastics are viscoelastic materials meaning that under applied stress, their deformation increases with time (creep). The elastic properties of plastics are therefore distinguished according to the time scale of the testing to short-time behavior (such as tensile test which lasts minutes), shock loading, the behavior under long-term and static loading, as well as the vibration-induced stress.\n\nCrystalline polymers are usually opaque because of light scattering on the numerous boundaries between the crystalline and amorphous regions. The density of such boundaries is lower and thus the transparency is higher either for low (amorphous polymer) or high (crystalline) degree of crystallinity. For example, atactic polypropylene is usually amorphous and transparent while syndiotactic polypropylene, which has crystallinity ~50%, is opaque. Crystallinity also affects dyeing of polymers: crystalline polymers are more difficult to stain than amorphous ones because the dye molecules penetrate much easier through amorphous regions.\n\n"}
{"id": "19889138", "url": "https://en.wikipedia.org/wiki?curid=19889138", "title": "Desiccation tolerance", "text": "Desiccation tolerance\n\nDesiccation tolerance refers to the ability of an organism to withstand or endure extreme dryness, or drought-like conditions. Plants and animals living in arid or periodically arid environments such as temporary streams or ponds may face the challenge of desiccation, therefore physiological or behavioral adaptations to withstand these periods are necessary to ensure survival. In particular, insects occupy a wide range of ecologically diverse niches and, so, exhibit a variety of strategies to avoid desiccation.\n\nIn general, desiccation resistance in insects is measured by the change in mass during dry conditions. The overall mass difference between measurements before and after aridity exposure is attributed to body water loss, as respiratory water loss is generally considered negligible.\n\nThere are three main ways in which insects can increase their tolerance to desiccation: by increasing their total body water content; by reducing the rate of body water loss; and by tolerating a larger proportion of overall water loss from the body. Survival time is determined by initial water content, and can be calculated by dividing water loss tolerance (the maximum amount of water that may be removed without resulting in death) by water loss rate.\n\nInsects with a higher initial body water content have better survival rates during arid conditions than insects with a lower initial body water content. Higher amounts of internal body water lengthen the time necessary to remove the amount of water required to kill the organism. The way in which body water content is increased may differ depending on the species.\n\nThe accumulation of glycogen during the insect larval stage has been linked to increased body water content and is likely a source of metabolic water during dry conditions. Glycogen, a glucose polysaccharide, acts as an oxidative energy source during times of physiological stress. Because it binds up to five times its weight in bulk water, insects with increased levels of body glycogen also have higher amounts of internal water. In general, insects selected for desiccation resistance also exhibit longer larval stages than those sensitive to desiccation. This increase in development time is likely a response to the environment, allowing larvae more time to accumulate glycogen, and therefore more water before eclosion.\n\nAnother possible source contributing to higher levels of initial body water in insects is hemolymph volume. The insect equivalent to blood, hemolymph is the fluid found within the hemocoel, and is the largest pool of extracellular water within the insect body. In the fruit-fly \"Drosophila melanogaster\", flies selected for desiccation resistance also yielded higher amounts of hemolymph. Higher hemolymph volume is linked to an increase in carbohydrates, in particular trehalose, a common sugar found in many plants and animals with high desiccation resistance. \"Drosophila melanogaster\" flies selected for desiccation resistance show a 300% increase in hemolymph volume compared to control flies, correlating to a similar increase in trehalose levels. During periods of aridity, cells dehydrate and draw upon hemolymph stores to replenish intracellular water; therefore, insects with higher levels of this fluid are less prone to desiccation.\n\nInsects may also increase body water content by simply feeding more often. Because sugar is slowly absorbed into the hemolymph at each meal, increasing the frequency at which the insect ingests a sugar source also increases its desiccation tolerance. Furthermore, the crop may also act not only to store food prior to digestion but to provide an additional reservoir for water and sugar.\n\nAnother strategy used to reduce the risk of death by dehydration is to reduce the rate at which water is lost. The three main ways through which insects can lose water are (1) the surface of the body (integument); (2) the tracheae (respiration); and (3) excretion, or waste products. The important feature in reducing water loss in land snails during inactivity is an epiphragm.\n\nThe exoskeleton or integument of insects acts as an impermeable, protective layer against desiccation. It is composed of an outer epicuticle, underlain by an procuticle that itself may be further divided into an exo- and endocuticle. The endocuticle provides the insect with toughness and flexibility and the hard exocuticle serves to protect vulnerable body parts. However, the outer cuticular layer (epicuticle) is a protein-polyphenol complex made up of lipoproteins, fatty acids, and waxy molecules, and is the insect’s primary defense against water loss. Many insect orders secrete an additional cement layer over their wax layer, likely to protect against the abrasion or removal of waxy molecules. This layer is composed of lipids and proteins held together by polyphenolic compounds and is secreted by the dermal glands.\n\nIn general, the rate of water loss in insects is low at moderate temperatures. Once a species-specific critical temperature (Tc) is reached, as temperatures continue to increase, rapid water loss occurs. The “lipid melting model” is used to explain this sudden increase in the rate of water loss. The lipid melting model states that increased cuticular water loss is directly related to the melting of surface lipids. Insects already adapted to more arid environments have a higher Tc; that is, their cuticular properties change and lipid structures melt at a higher critical temperature.\n\nIn some insects, the rate of cuticular water loss is controlled to some extent by the neuroendocrine system. Immediately following head removal, decapitated cockroaches exhibit a large increase in transpiration across the cuticle, leading to severe dehydration. Injection of brain hormones into freshly separated bodies results in a sharp reduction in cuticular water loss.\n\nIn general, insects adapted to arid environments also have an impermeable cuticular membrane that prevents water loss. Therefore, a majority of water lost to the atmosphere occurs via the air-filled tracheae. To help reduce water loss, many insects have outer coverings to their tracheae, or spiracles, which shut when open respiration is unnecessary and prevent water from escaping. Insects at a greater risk for water loss face the challenge of either a depleted oxygen supply or desiccation, leading to an adaptive increase in tracheal volume in order to receive more oxygen.\n\nFollowing feeding, most insects retain enough water to completely hydrate their bodies, excreting the remainder. However, the amount of water excreted differs between species, and depends on the relative humidity and dryness of the environment. For example, Tsetse flies maintained at a high relative humidity, and thus non-arid conditions, excrete fecal matter with approximately 75% water content, whereas Tsetse flies maintained at a low relative humidity, and thus dry conditions, excrete fecal matter with only 35% water content. This adaptation helps minimize water loss in unfavorable conditions and increase chances of survival.\n\nMost insects can tolerate a 30-50% loss of body water; however, insects adapted to dry environments can tolerate a 40-60% loss of body water. Initial body size also plays a large role in how much water loss can be tolerated, and, in general, larger insects can tolerate a larger percentage of body water loss than smaller insects. The female beetle \"Alphitobius diaperinus\", for example, is larger than its male counterpart and can thus tolerate 4% more water loss. It is hypothesized that larger insects have increased lipid reserves, preventing dehydration and desiccation.\n\nIn addition to physiological adaptations that increase desiccation resistance, behavioral responses of insects to arid environments significantly decrease dehydration potential. \"Drosophila melanogaster\" fruit flies, for example, will actively move to areas with higher atmospheric water content when placed in dry environments. Also, the dung beetle buries food in underground chambers, thereby ensuring water and energy sources during periodically dry conditions. Feeding location may also be altered to ensure body hydration. Some caterpillars preferentially feed on the underside of leaves, where microclimate has higher relative humidity. In a highly time-consuming activity such as feeding, these insects significantly reduce their chances of desiccation.\n\nCryptobiosis refers to the state of an organism that has no detectable metabolic activity, resulting from extreme and unfavorable environmental conditions; anhydrobiosis refers to the state of surviving the loss of (almost) all body water. Although this state is commonly observed in invertebrates, only one insect is known to be cryptobiotic (anhydrobiotic), the African chironomid \"Polypedilum vanderplanki\". \"Polypedilum vanderplanki\" undergoes anhydrobiosis, a cryptobiotic state wherein the body is completely dehydrated. The larvae of \"P. vanderplanki\" inhabit rock pools that commonly dry out completely. In response, \"P. vanderplanki\" larvae enter an anhydrobiotic state, during which changes in body osmolarity trigger the production of large amounts of trehalose. Due to its capacity for water replacement and vitrification, the accumulation of trehalose prevents the death of the larvae from water loss.\n"}
{"id": "14178974", "url": "https://en.wikipedia.org/wiki?curid=14178974", "title": "Egil Myklebust", "text": "Egil Myklebust\n\nEgil Myklebust (born 9 June 1942) is a Norwegian businessperson and lawyer. Since 2001 he has been chairman of the board of SAS Group.\n\nBorn in Kvinnherad, Myklebust took a law degree from the University of Oslo in 1967, before starting work with the Norwegian Welfare Services (1968 to 1971). After that he worked at Norsk Hydro from 1971 to 2001, the ten last as Chief Executive Officer. After he retired of CEO of Norsk Hydro he took over as chairman of the board of Norsk Hydro (until 2004) and SAS Group, as well as deputy board chairman of Norske Skog.\n\nHe was also CEO of the Norwegian Employers' Confederation (NAF) from 1987 to 1989, and then of the Confederation of Norwegian Enterprise until 1990, overseeing the 1989 merger. He is a former member of the Steering Committee of the Bilderberg Group.\n\nHe is a fellow of the Norwegian Academy of Technological Sciences.\n"}
{"id": "57976901", "url": "https://en.wikipedia.org/wiki?curid=57976901", "title": "Eidsfossen Hydroelectric Power Station", "text": "Eidsfossen Hydroelectric Power Station\n\nThe Eidsfossen Hydroelectric Power Station ( or \"Eidsfossen kraftstasjon\") is a decommissioned hydroelectric power station in the municipality of Tynset in Hedmark county, Norway.\n\nThe power station is located in the Kvikne Forest (\"Kvikneskogen\"). It utilized a drop of on the Orkla River. The power plant was built to supply electricity to the Røstvangen Mines and built from 1915 to 1917, when it became operational. The plant was decommissioned in 1999.\n\nAn information sign about the power plant has been set up at a rest area along Norwegian National Road 3, and the old dam construction for the plant can be seen from the same route south of Yset.\n\n"}
{"id": "23797261", "url": "https://en.wikipedia.org/wiki?curid=23797261", "title": "Electricity sector in Bangladesh", "text": "Electricity sector in Bangladesh\n\nThe utility electricity sector in Bangladesh has one national grid with an installed capacity of 16,048 MW as of July 2018. Bangladesh's energy sector is booming. Recently Bangladesh started construction of the 2.4-gigawatt (GW) Rooppur Nuclear Power Plant expected to go into operation in 2023. According to the Bangladesh Power Development Board in July 2018, 90 percent of the population had access to electricity. However per capita energy consumption in Bangladesh is considered low.\n\nElectricity is the major source of power for most of the country's economic activities. Bangladesh's total installed electricity generation capacity (including captive power) was 15,351 megawatts (MW) as of January 2017. As of 2015, 92% of the urban population and 67% of the rural population had access to electricity. An average of 77.9% of the population had access to electricity in Bangladesh. Bangladesh will need an estimated 34,000 MW of power by 2030 to sustain its economic growth of over 7 percent.\n\nProblems in Bangladesh's electric power sector include high system losses, delays in completion of new plants, low plant efficiency, erratic power supply, electricity theft, blackouts, and shortages of funds for power plant maintenance. Overall, the country's generation plants have been unable to meet system demand over the past decade.\n\nOn 2 November 2014, electricity was restored after a day-long nationwide blackout. A transmission line from India had failed, which \"led to a cascade of failures throughout the national power grid,\" and criticism of \"old grid infrastructure and poor management.\" However, in a recent root-cause analysis report the investing team has clarified that fault was actually due to a lack in electricity management and poor transmission and distribution health infrastructure that caused the blackout.\n\nAs of 2011, 79 natural gas wells were present in the 23 operational gas fields which produce over 2000 millions of cubic feet of gas per day (MMCFD). It is well short of over 2500 MMCFD that is demanded, a number which is growing by around 7% each year. In fact, more than three-quarters of the nation's commercial energy demand is being met by natural gas. This influential sector caters for around 40% of the power plant feed-stock, 17% of industries, 15% captive power, 11% for domestic and household usage, another 11% for fertilizers, 5% in Compressed natural gas (CNG) activities and 1% for commercial and agricultural uses.\n\nCNG is substituting more that USD 0.8 billion worth of foreign exchange annually and is also used in most vehicles on the road. In addition to CNG, Liquefied Petroleum Gas (LPG) is also demanded at around 0.1 million tons. The nation furthermore demands 3.5 million tons of oil imports in addition to almost 2 million tons of diesel to feed oil-based power plants being planned and built all around the country. The additional petroleum and coal imports are causing a disruption in the GDP by as much as 2% annually. The new purchases are affecting improvement initiatives in other sectors causing reduced export earnings and curtailing employment opportunities. This massive failure in the energy sector is mostly attributed to prolonged negligence, inappropriate implementation, inefficiency and lack of planning. To make matters worse, natural gas reserves are expected to expire by 2020. The only coal mine of the country is in the development stage, the reserve of which is also expected to dry up anywhere from 75 to 80 years after the start of their operations.\n\nEfforts to develop an open-pit coal mine in Phulbari, Dinajpur District, have met with large, violent protests in 2006 because of feared environmental effects, and six people were killed and hundreds injured. At the time, the government closed the project, for which it was working with Asia Energy (now Global Coal Resources). It was encouraged in December 2009 to re-open it by the United States ambassador in private communication. In October 2010 protesters make a week-long march from Phulbari to Dhaka against the mine; a coalition of other groups protested at a Global Coal Resources meeting in London.\n\nBangladesh has 15 MW solar energy capacity through rural households and 1.9 MW wind power in Kutubdia and Feni. Bangladesh has planned to produce 5% of total power generation by 2015 & 10% by 2020 from renewable energy sources like wind, waste & solar energy. The country's prospect of geothermal energy extraction has also been discussed by researchers. Studies carried out by geologists suggested geothermal resources in northwest and southeast region.\n\nThe Ministry of Power and Energy has been mobilising Tk 400 billion ($5.88 billion) to generate 5,000 MW of electricity to reduce load shedding into a tolerable level within next four and half years during the term of the present government. Under the plan, the Bangladesh Power Development Board(PDB) would produce 500 MW gas-fired electricity between July and December 2009 to over come load shedding within December. The PDB would hire furnace-oil based 1,000MW of electricity from private sector from January to June 2010, the plan said. In 2011, the government would install furnace-oil based 800 MW capacity of power plant. \nThe PDB officials would seek suitable place to establish the plant, a senior official of the PDB said. Besides the government would also hire another diesel- or furnace oil-based power plant having capacity of 700 MW in 2012 to keep load shedding into mild level, the official said. However, the government also contemplates to establish four coal-fired-based power plants with capacity of producing 500 MW of electricity each with public and private partnership (PPP) in Rajshahi and Chittagong region. \nThe government has initially tried to create fund of Tk 60 billion ($1 billion) to implement the plan, sources said. The power division has tried to use the government's budgetary allocation of Tk. 20 billion for PPP in this regard, sources added. \"If we can create the fund of Tk. 60 billion, it would be possible also to mobilise Tk 400 billion under ppp to produce 5,000 MW of electricity within four and half years,\" PDB chairman ASM Alamgir Kabir told the New Nation on 29 June 2009. During the meeting, Prime Minister Sheikh Hasina permitted the power division to implement the PDB plan to reduce load shedding up to a tolerable level. Prime Minister's Adviser for Power and Energy Dr Tawfiq-e-Elahi Chowdhury Bir Bikram, State Minister for Power and Energy Shamsul Haque Tuku, Power Division Secretary Md Abul Kalam, PDB chairman ASM Alamgir Kabir were present.\n\nBangladesh has small reserves of oil and coal, but very large natural gas resources. Commercial energy consumption comes mostly from natural gas (around 66%), followed by oil, hydropower, and coal. Non-commercial energy sources, such as wood fuel, and crop residues, are estimated to account for over half of the country's energy consumption.\n\nA 2014 news report stated that:\n\nBangladesh is considered one of the most arousing energy growth nations. More than a third of Bangladesh's 166 million people still have no access to electricity, while the country often is able to produce only some of its 11,500-megawatt generation capacity.\n\nIn generating and distributing electricity, the failure to adequately manage the load leads to extensive load shedding which results in severe disruption in the industrial production and other economic activities. A recent survey reveals that power outages result in a loss of industrial output worth $1 billion a year which reduces the GDP growth by about half a percentage point in Bangladesh. A major hurdle in efficiently delivering power is caused by the inefficient distribution system. It is estimated that the total transmission and distribution losses in Bangladesh amount to one-third of the total generation, the value of which is equal to US $247 million per year.\n\nIn 2011, there were proposals to upgrade the grid technologies to digital smart metering systems and investing in renewable energy technologies to produce 5% of total power generation by 2015 & 10% by 2020, as noted in the National Renewable Energy Policy of 2008. American engineer Sanwar Sunny said that the city should put more effort in zoning areas to encourage more self-reliant subdivisions and higher density housing around subways to be more sustainable, as during peak times load shedding would not affect everyone. It will reduce effects of power cuts and provide stability to the power sector. He proposed that Radio transmitters could be operating remotely in unlicensed radio bands using two way real time communication and transmit coded instructions from the central to the circuit breakers in selected coordinates of the micro grids substations thereby maintain multiple power flow lines with automated control and digital metering. Using this technology, Feed-in tariffs (FIT) would also be possible, as the energy usage could be monitored remotely and private power generation and energy efficient entities could be offered rebates and incentives. \"This will also expedite investments in this sector, create job opportunities for engineering graduates and technicians, and ease pressures on the government\" he said. Think tanks such as Bangladesh Solar Energy Society and Renewable Energy Institute (REI), along with European International Development Government Agencies such as \"Deutsche Gesellschaft für Internationale Zusammenarbeit\" supported this scheme. However, The Secretary of the Ministry of Power, Government of Bangladesh has said that the government has no plans to do so.\n\nBangladesh plans to set up the 2,400 MW power plant, the Ruppur Nuclear Power Plant at Rooppur, Pabna district northwest of the capital Dhaka, by 2018. Planned to go into operation by 2023, it will be the country's first nuclear power plant.\n\n"}
{"id": "11060531", "url": "https://en.wikipedia.org/wiki?curid=11060531", "title": "Electron beam ion trap", "text": "Electron beam ion trap\n\nElectron beam ion trap (EBIT) is an electromagnetic bottle that produces and confines highly charged ions. An EBIT uses an electron beam focused with a powerful magnetic field to ionize atoms to high charge states by successive electron impact.\n\nIt was invented by M. Levine and R. Marrs at LLNL and LBNL.\n\nThe positive ions produced in the region where the atoms intercept the electron beam are tightly confined in their motion by the strong attraction exerted by the negative charge of the electron beam. Therefore, they orbit around the electron beam, crossing it frequently and giving rise to further collisions and ionization. To restrict the ion motion along the direction of the electron beam axis, trapping electrodes carrying positive voltages with respect to a central electrode are used.\n\nThe resulting ion trap can hold ions for many seconds and minutes, and conditions for reaching the highest charge states, up to bare uranium (U) can be achieved in this way.\n\nThe strong charge needed for radial confinement of the ions requires large electron beam currents of tens up to hundreds of milliampere. At the same time, high voltages (up to 200 kilovolts) are used for accelerating the electrons in order to achieve high charge states of the ions.\n\nTo avoid charge reduction of ions by collisions with neutral atoms from which they can capture electrons, the vacuum in the apparatus is usually maintained at UHV levels, with typical pressure values of only 10 torr, (~10 pascal).\n\nEBITs are used to investigate the fundamental properties of highly charged ions e. g. by photon spectroscopy in particular in the context of relativistic atomic structure theory and quantum electrodynamics (QED). Their suitability to prepare and reproduce in a microscopic volume the conditions of high temperature astrophysical plasmas and magnetic confinement fusion plasmas make them very appropriate research tools. Other fields include the study of their interactions with surfaces and possible applications to microlithography. \n\n\n"}
{"id": "31044797", "url": "https://en.wikipedia.org/wiki?curid=31044797", "title": "Endeavour Energy", "text": "Endeavour Energy\n\nEndeavour Energy is the operator of the electrical distribution network for Greater Western Sydney, the Blue Mountains, the Southern Highlands and the Illawarra region of NSW, Australia.\n\nIt was formed from the previously state-owned energy retailer/supplier, Integral Energy, when the retail division of the company, along with the Integral Energy brand, was sold by the NSW Government in 2011 to Origin Energy.\n\nOn June 2017, an Australian-led consortium of institutional investors acquired 50.4% ownership of the rights to management Endeavour Energy’s network assets under a 99-year lease.\n\nThe consortium is led by Macquarie Infrastructure and Real Assets (MIRA), and includes AMP Capital, British Columbia Investment Management Corporation and Qatar Investment Authority.\n\nThe NSW Government retains a 49.6% interest and continues to regulate safety and reliability.\n"}
{"id": "564103", "url": "https://en.wikipedia.org/wiki?curid=564103", "title": "Foolscap folio", "text": "Foolscap folio\n\nFoolscap folio (commonly contracted to foolscap or folio and in short FC) is paper cut to the size of (for \"normal\" writing paper, ). This was a traditional paper size used in Europe and the British Commonwealth, before the adoption of the international standard A4 paper.\n\nA full foolscap paper sheet is actually in size, and a folio sheet of any type is half the standard sheet size or a subdivision of this into halves, quarters and so on.\n\nRing binders or lever arch files designed to hold foolscap folios are often used to hold A4 paper (). The slightly larger size of such a binder offers greater protection to the edges of the pages it contains.\n\nFoolscap was named after the fool's cap and bells watermark commonly used from the fifteenth century onwards on paper of these dimensions. The earliest example of such paper that is firmly dated was made in Germany in 1479. Unsubstantiated anecdotes suggest that this watermark was introduced to England in 1580 by John Spilman, a German who established a papermill at Dartford, Kent. Apocryphally, the Rump Parliament substituted a fool's cap for the royal arms as a watermark on the paper used for the journals of Parliament.\n\nIn Brazil, the paper size is usually named \"folio\", and it is also sometimes called \"ofício II\", a reference to the paper size (which is named \"legal\" but in Portuguese is better known as \"ofício\".\n\nIn Venezuela, the paper size is named \"oficio\". While laws expressly permit any paper size, public offices require all documents to be presented in oficio paper size.\n\nF4 is a paper size . Although metric, based on the A4 paper size, and named to suggest that it is part of the official ISO 216 paper sizes, it is only a \"de facto\" standard. \n\nIt may be referred to as \"foolscap\" or \"folio\" because of its similarity to the traditional foolscap folio size of .\n\nTHE COLLATION a gathering of scholarship from the Folger Library showing image of Foolscap folio watermark\n"}
{"id": "22122416", "url": "https://en.wikipedia.org/wiki?curid=22122416", "title": "Glass transition", "text": "Glass transition\n\nThe glass–liquid transition, or glass transition, is the gradual and reversible transition in amorphous materials (or in amorphous regions within semicrystalline materials), from a hard and relatively brittle \"glassy\" state into a viscous or rubbery state as the temperature is increased. An amorphous solid that exhibits a glass transition is called a glass. The reverse transition, achieved by supercooling a viscous liquid into the glass state, is called vitrification.\n\nThe glass-transition temperature \"T\" of a material characterizes the range of temperatures over which this glass transition occurs. It is always lower than the melting temperature, \"T\", of the crystalline state of the material, if one exists.\n\nHard plastics like polystyrene and poly(methyl methacrylate) are used well below their glass transition temperatures, i.e., when they are in their glassy state. Their \"T\" values are well above room temperature, both at around . Rubber elastomers like polyisoprene and polyisobutylene are used above their \"T\", that is, in the rubbery state, where they are soft and flexible.\n\nDespite the change in the physical properties of a material through its glass transition, the transition is not considered a phase transition; rather it is a phenomenon extending over a range of temperature and defined by one of several conventions. Such conventions include a constant cooling rate () and a viscosity threshold of 10 Pa·s, among others. Upon cooling or heating through this glass-transition range, the material also exhibits a smooth step in the thermal-expansion coefficient and in the specific heat, with the location of these effects again being dependent on the history of the material. The question of whether some phase transition underlies the glass transition is a matter of continuing research.\n\nThe glass transition of a liquid to a solid-like state may occur with either cooling or compression. The transition comprises a smooth increase in the viscosity of a material by as much as 17 orders of magnitude within a temperature range of 500 K without any pronounced change in material structure. The consequence of this dramatic increase is a glass exhibiting solid-like mechanical properties on the timescale of practical observation. This transition is in contrast to the freezing or crystallization transition, which is a first-order phase transition in the Ehrenfest classification and involves discontinuities in thermodynamic and dynamic properties such as volume, energy, and viscosity. In many materials that normally undergo a freezing transition, rapid cooling will avoid this phase transition and instead result in a glass transition at some lower temperature. Other materials, such as many polymers, lack a well defined crystalline state and easily form glasses, even upon very slow cooling or compression. The tendency for a material to form a glass while quenched is called glass forming ability. This ability depends on the composition of the material and can be predicted by the rigidity theory.\n\nBelow the transition temperature range, the glassy structure does not relax in accordance with the cooling rate used. The expansion coefficient for the glassy state is roughly equivalent to that of the crystalline solid. If slower cooling rates are used, the increased time for structural relaxation (or intermolecular rearrangement) to occur may result in a higher density glass product. Similarly, by annealing (and thus allowing for slow structural relaxation) the glass structure in time approaches an equilibrium density corresponding to the supercooled liquid at this same temperature. T is located at the intersection between the cooling curve (volume versus temperature) for the glassy state and the supercooled liquid.\n\nThe configuration of the glass in this temperature range changes slowly with time towards the equilibrium structure. The principle of the minimization of the Gibbs free energy provides the thermodynamic driving force necessary for the eventual change. It should be noted here that at somewhat higher temperatures than T, the structure corresponding to equilibrium at any temperature is achieved quite rapidly. In contrast, at considerably lower temperatures, the configuration of the glass remains sensibly stable over increasingly extended periods of time.\n\nThus, the liquid-glass transition is not a transition between states of thermodynamic equilibrium. It is widely believed that the true equilibrium state is always crystalline. Glass is believed to exist in a kinetically locked state, and its entropy, density, and so on, depend on the thermal history. Therefore, the glass transition is primarily a dynamic phenomenon. Time and temperature are interchangeable quantities (to some extent) when dealing with glasses, a fact often expressed in the time–temperature superposition principle. On cooling a liquid, \"internal degrees of freedom successively fall out of equilibrium\". However, there is a longstanding debate whether there is an underlying second-order phase transition in the hypothetical limit of infinitely long relaxation times.\n\nRefer to the figure on the right plotting the heat capacity as a function of temperature. In this context, \"T\" is the temperature corresponding to point A on the curve. The linear sections below and above \"T\" are colored green. \"T\" is the temperature at the intersection of the red regression lines.\n\nDifferent operational definitions of the glass transition temperature \"T\" are in use, and several of them are endorsed as accepted scientific standards. Nevertheless, all definitions are arbitrary, and all yield different numeric results: at best, values of \"T\" for a given substance agree within a few kelvins. One definition refers to the viscosity, fixing \"T\" at a value of 10 poise (or 10 Pa·s). As evidenced experimentally, this value is close to the annealing point of many glasses.\n\nIn contrast to viscosity, the thermal expansion, heat capacity, shear modulus, and many other properties of inorganic glasses show a relatively sudden change at the glass transition temperature. Any such step or kink can be used to define \"T\". To make this definition reproducible, the cooling or heating rate must be specified.\n\nThe most frequently used definition of \"T\" uses the energy release on heating in differential scanning calorimetry (DSC, see figure). Typically, the sample is first cooled with 10 K/min and then heated with that same speed.\n\nYet another definition of \"T\" uses the kink in dilatometry (a.k.a. thermal expansion). Here, heating rates of are common. Summarized below are \"T\" values characteristic of certain classes of materials.\n\nDry nylon-6 has a glass transition temperature of .\nNylon-6,6 in the dry state has a glass transition temperature of about .\nWhereas polyethene has a glass transition range of \nThe above are only mean values, as the glass transition temperature depends on the cooling rate and molecular weight distribution and could be influenced by additives. For a semi-crystalline material, such as polyethene that is 60–80% crystalline at room temperature, the quoted glass transition refers to what happens to the amorphous part of the material upon cooling.\n\nAs a liquid is supercooled, the difference in entropy between the liquid and solid phase decreases. By extrapolating the heat capacity of the supercooled liquid below its glass transition temperature, it is possible to calculate the temperature at which the difference in entropies becomes zero. This temperature has been named the Kauzmann temperature.\n\nIf a liquid could be supercooled below its Kauzmann temperature, and it did indeed display a lower entropy than the crystal phase, the consequences would be paradoxical. This Kauzmann paradox has been the subject of much debate and many publications since it was first put forward by Walter Kauzmann in 1948.\n\nOne resolution of the Kauzmann paradox is to say that there must be a phase transition before the entropy of the liquid decreases. In this scenario, the transition temperature is known as the \"calorimetric ideal glass transition temperature\" \"T\". In this view, the glass transition is not merely a kinetic effect, i.e. merely the result of fast cooling of a melt, but there is an underlying thermodynamic basis for glass formation. The glass transition temperature:\n\nThe Gibbs-DiMarzio model specifically predicts that a supercooled liquid's configurational entropy disappears in the limit formula_2, where the liquid's existence regime ends, its microstructure becomes identical to the crystal's, and their property curves intersect in a true second-order phase transition. This has never been experimentally verified due to the difficulty of realizing a slow enough cooling rate while avoiding accidental crystallization.\n\nThere are at least three other possible resolutions to the Kauzmann paradox. It could be that the heat capacity of the supercooled liquid near the Kauzmann temperature smoothly decreases to a smaller value. It could also be that a first order phase transition to another liquid state occurs before the Kauzmann temperature with the heat capacity of this new state being less than that obtained by extrapolation from higher temperature. Finally, Kauzmann himself resolved the entropy paradox by postulating that all supercooled liquids must crystallize before the Kauzmann temperature is reached.\n\nSilica (the chemical compound SiO) has a number of distinct crystalline forms in addition to the quartz structure. Nearly all of the crystalline forms involve tetrahedral SiO units linked together by \"shared vertices\" in different arrangements. Si-O bond lengths vary between the different crystal forms. For example, in α-quartz the bond length is , whereas in α-tridymite it ranges from . The Si-O-Si bond angle also varies from 140° in α-tridymite to 144° in α-quartz to 180° in β-tridymite. Any deviations from these standard parameters constitute microstructural differences or variations that represent an approach to an amorphous, vitreous or glassy solid.\nThe transition temperature \"T\" in silicates is related to the energy required to break and re-form covalent bonds in an amorphous (or random network) lattice of covalent bonds. The \"T\" is clearly influenced by the chemistry of the glass. For example, addition of elements such as B, Na, K or Ca to a silica glass, which have a valency less than 4, helps in breaking up the network structure, thus reducing the \"T\". Alternatively, P, which has a valency of 5, helps to reinforce an ordered lattice, and thus increases the \"T\".\n\"T\" is directly proportional to bond strength, e.g. it depends on quasi-equilibrium thermodynamic parameters of the bonds e.g. on the enthalpy \"H\" and entropy \"S\" of configurons – broken bonds: \"T\" = \"H\" / [\"S\" + Rln[(1-\"f\")/ \"f\"] where R is the gas constant and \"f\" is the percolation threshold. For strong melts such as Si\"O\" the percolation threshold in the above equation is the universal Scher-Zallen critical density in the 3-D space e.g. \"f\" = 0.15, however for fragile materials the percolation thresholds are material-dependent and \"f\" « 1. The enthalpy \"H\" and the entropy \"S\" of configurons – broken bonds can be found from available experimental data on viscosity.\n\nIn polymers the glass transition temperature, \"T\", is often expressed as the temperature at which the Gibbs free energy is such that the activation energy for the cooperative movement of 50 or so elements of the polymer is exceeded . This allows molecular chains to slide past each other when a force is applied. From this definition, we can see that the introduction of relatively stiff chemical groups (such as benzene rings) will interfere with the flowing process and hence increase \"T\".\nThe stiffness of thermoplastics decreases due to this effect (see figure.) When the glass temperature has been reached, the stiffness stays the same for a while, i.e., at or near \"E\", until the temperature exceeds \"T\", and the material melts. This region is called the rubber plateau.\n\nIn ironing, a fabric is heated through this transition so that the polymer chains become mobile. The weight of the iron then imposes a preferred orientation. \"T\" can be significantly decreased by addition of plasticizers into the polymer matrix. Smaller molecules of plasticizer embed themselves between the polymer chains, increasing the spacing and free volume, and allowing them to move past one another even at lower temperatures. The addition of nonreactive side groups to a polymer can also make the chains stand off from one another, reducing \"T\". If a plastic with some desirable properties has a \"T\" that is too high, it can sometimes be combined with another in a copolymer or composite material with a \"T\" below the temperature of intended use. Note that some plastics are used at high temperatures, e.g., in automobile engines, and others at low temperatures.\nIn viscoelastic materials, the presence of liquid-like behavior depends on the properties of and so varies with rate of applied load, i.e., how quickly a force is applied. The silicone toy Silly Putty behaves quite differently depending on the time rate of applying a force: pull slowly and it flows, acting as a heavily viscous liquid; hit it with a hammer and it shatters, acting as a glass.\n\nOn cooling, rubber undergoes a \"liquid-glass transition\", which has also been called a \"rubber-glass transition\".\n\nMolecular motion in condensed matter can be represented by a Fourier series whose physical interpretation consists of a superposition of longitudinal and transverse waves of atomic displacement with varying directions and wavelengths. In monatomic systems, these waves are called \"density fluctuations\". (In polyatomic systems, they may also include compositional fluctuations.)\n\nThus, thermal motion in liquids can be decomposed into elementary longitudinal vibrations (or acoustic phonons) while transverse vibrations (or shear waves) were originally described only in elastic solids exhibiting the highly ordered crystalline state of matter. In other words, simple liquids cannot support an applied force in the form of a shearing stress, and will yield mechanically via macroscopic plastic deformation (or viscous flow). Furthermore, the fact that a solid deforms locally while retaining its rigidity – while a liquid yields to macroscopic viscous flow in response to the application of an applied shearing force – is accepted by many as the mechanical distinction between the two.\n\nThe inadequacies of this conclusion, however, were pointed out by Frenkel in his revision of the kinetic theory of solids and the theory of elasticity in liquids. This revision follows directly from the continuous characteristic of the structural transition from the liquid state into the solid one when this transition is not accompanied by crystallization—ergo the supercooled viscous liquid. Thus we see the intimate correlation between transverse acoustic phonons (or shear waves) and the onset of rigidity upon vitrification, as described by Bartenev in his mechanical description of the vitrification process.\n\nThe velocities of longitudinal acoustic phonons in condensed matter are directly responsible for the thermal conductivity that levels out temperature differentials between compressed and expanded volume elements. Kittel proposed that the behavior of glasses is interpreted in terms of an approximately constant \"mean free path\" for lattice phonons, and that the value of the mean free path is of the order of magnitude of the scale of disorder in the molecular structure of a liquid or solid. The thermal phonon mean free paths or relaxation lengths of a number of glass formers have been plotted versus the glass transition temperature, indicating a linear relationship between the two. This has suggested a new criterion for glass formation based on the value of the phonon mean free path.\nIt has often been suggested that heat transport in dielectric solids occurs through elastic vibrations of the lattice, and that this transport is limited by elastic scattering of acoustic phonons by lattice defects (e.g. randomly spaced vacancies).\nThese predictions were confirmed by experiments on commercial glasses and glass ceramics, where mean free paths were apparently limited by \"internal boundary scattering\" to length scales of .\nThe relationship between these transverse waves and the mechanism of vitrification has been described by several authors who proposed that the onset of correlations between such phonons results in an orientational ordering or \"freezing\" of local shear stresses in glass-forming liquids, thus yielding the glass transition.\n\nThe influence of thermal phonons and their interaction with electronic structure is a topic that was appropriately introduced in a discussion of the resistance of liquid metals. Lindemann's theory of melting is referenced, and it is suggested that the drop in conductivity in going from the crystalline to the liquid state is due to the increased scattering of conduction electrons as a result of the increased amplitude of atomic vibration. Such theories of localization have been applied to transport in metallic glasses, where the mean free path of the electrons is very small (on the order of the interatomic spacing).\n\nThe formation of a non-crystalline form of a gold-silicon alloy by the method of splat quenching from the melt led to further considerations of the influence of electronic structure on glass forming ability, based on the properties of the metallic bond.\nOther work indicates that the mobility of localized electrons is enhanced by the presence of dynamic phonon modes. One claim against such a model is that if chemical bonds are important, the nearly free electron models should not be applicable. However, if the model includes the buildup of a charge distribution between all pairs of atoms just like a chemical bond (e.g., silicon, when a band is just filled with electrons) then it should apply to solids.\n\nThus, if the electrical conductivity is low, the mean free path of the electrons is very short. The electrons will only be sensitive to the short-range order in the glass since they do not get a chance to scatter from atoms spaced at large distances. Since the short-range order is similar in glasses and crystals, the electronic energies should be similar in these two states. For alloys with lower resistivity and longer electronic mean free paths, the electrons could begin to sense that there is disorder in the glass, and this would raise their energies and destabilize the glass with respect to crystallization. Thus, the glass formation tendencies of certain alloys may therefore be due in part to the fact that the electron mean free paths are very short, so that only the short-range order is ever important for the energy of the electrons.\n\nIt has also been argued that glass formation in metallic systems is related to the \"softness\" of the interaction potential between unlike atoms. Some authors, emphasizing the strong similarities between the local structure of the glass and the corresponding crystal, suggest that chemical bonding helps to stabilize the amorphous structure.\n\nOther authors have suggested that the electronic structure yields its influence on glass formation through the directional properties of bonds. Non-crystallinity is thus favored in elements with a large number of polymorphic forms and a high degree of bonding anisotropy. Crystallization becomes more unlikely as bonding anisotropy is increased from isotropic metallic to anisotropic metallic to covalent bonding, thus suggesting a relationship between the group number in the periodic table and the glass forming ability in elemental solids.\n\n"}
{"id": "28352346", "url": "https://en.wikipedia.org/wiki?curid=28352346", "title": "Greater Cairo Planning Commission", "text": "Greater Cairo Planning Commission\n\nThe Greater Cairo Planning Commission or GCPC was a planning body for Cairo, Egypt, which was created in 1965. \n\nIt was superseded by the General Organization for Physical Planning (GOPP). The commission was approved by Presidential Decree No. 1093 of 1973.\n\nIts been said the body has often set unrealistic goals such as to \"halve the population of a city\". This government body answers to The Supreme Council for Planning and Urban Development (SCPUD). \n\nMainly the GOPP works with the United Nations Development Program (UNDP). \n\nThe work of the GOPP and all things related to Cairo's urbanization and problems of inequality is the focus of Tadamun, a project by the American University, in Washington DC.\n"}
{"id": "14122476", "url": "https://en.wikipedia.org/wiki?curid=14122476", "title": "Hitra Wind Farm", "text": "Hitra Wind Farm\n\nHitra Wind Farm is a 24-turbine wind farm located in the municipality of Hitra in Trøndelag county, Norway and operated by Statkraft. The farm is located on top of the Elsfjellet plateau in the central part of the island of Hitra, just south of the village of Straum and about west of Sandstad. Until the expansion of the Smøla Wind Farm in 2005, Hitra was the largest wind farm in the country and had total cost of .\n\nEach of the 24 wind turbines can produce of power for a maximum generated power of and an annual production of for the whole farm. The farm was opened on 14 October 2004.\n\nThe Fosen Vind wind farm complex will include the nearby Hitra 2 wind farm.\n\n"}
{"id": "12793281", "url": "https://en.wikipedia.org/wiki?curid=12793281", "title": "Internal circulation reactor", "text": "Internal circulation reactor\n\nThe internal circulation reactor (IC reactor) is a form of anaerobic digester. It is primarily designed to treat wastewater. The IC reactor is an evolution of the UASB and EGSB digestion systems. The digester typically produces biogas with a high concentration methane (c80%). In essence the IC to improve digestion rates and gas yields. The foot print for the IC reactor is therefore typically smaller. However, it is taller due to the increased complexity of the reactor.\n\nThe IC reactor typically comes as part of a two-stage anaerobic digestion system where it is preceded by an acidification and hydrolysis tank. Effluent leaving the IC reactor will often require aerobic treatment to reduce biochemical (BOD) and COD to discharge consent levels.\n\n"}
{"id": "2638911", "url": "https://en.wikipedia.org/wiki?curid=2638911", "title": "Ketura, Israel", "text": "Ketura, Israel\n\nKetura () is a kibbutz in southern Israel. Located north of Eilat in the Aravah Valley, it falls under the jurisdiction of Hevel Eilot Regional Council. In it had a population of .\n\nThe name Ketura was taken from a nearby hill and wadi, and is also the name of the second wife of Abraham (). \n\nKetura was founded in November 1973 by a group of young American Jewish immigrants, most of them members of the Zionist youth movement Young Judaea. Difficulties in the early years frustrated many of the inhabitants of the kibbutz, which caused many of the founders to leave. At the same time, more Young Judaeans joined the community, along with a variety of other immigrants as well as Israel Boy and Girl Scouts Federation graduates. Ketura is in the Southern Arava - Hevel Eilot Regional Council.\n\nToday Ketura has about 150 members and several young families who are candidates to become members. During the year there are about 450 people living on Ketura, members and their families, students in the Arava Institute for Environmental Studies, volunteers from around the world, Arava International Center for Agriculture Training (AICAT) students from around the world, NOAM youth movement members in various programs such as gap year or service year (\"shnat sherut\"), and researchers who come to work in regional institutes.\n\nKetura is unique among kibbutzim for its religious pluralism. Although the kibbutz is not considered a religious kibbutz, Jewish dietary laws (\"kashrut\") and Sabbath rules are observed in the dining room, public areas, and at social and cultural events, and there is a functioning congregation-led egalitarian synagogue. The population of the kibbutz is composed of observant, masorati (moderately observant), and secular members, an unusual situation for a kibbutz. Ketura received the Speaker of the Knesset Prize for religious tolerance as a result of its religious progressiveness.\n\nThe kibbutz is best known for its involvement in ecological activities, mainly its partnership in the local algae factory, Algatech, and its guest house and educational seminar center, Keren Kolot. The solar power industry (see below) has been gaining importance locally.\n\nEconomic cooperation with other kibbutzim in the area includes a regional date-packing plant, Ardom Computing Services, and Ardag, a large fish hatchery near Eilat. Many members work outside the kibbutz in professional positions such as teachers, physical and occupational therapists, researchers, social workers, and more. Ketura also offers accounting and bookkeeping services, with many members working in these positions. A number of members work in the local NGO - The Arava Institute for Environmental Studies (AIES).\n\nAgricultural enterprises of the kibbutz include date orchards.\n\nThe kibbutz is well known for its guest house and educational seminar center — Keren Kolot\n\nThe red rainwater microalgae (\"Haematococcus pluvialis\") are single-cell organisms, part of the oldest group of living organisms. Their long evolution led them to adapt to extreme conditions and to develop survival mechanisms against bacteria and fungi. Haematococcus pluvialis has been cultivated and processed at Ketura since 1998, when the AlgaTechnologies, Ltd. company was established, for their content of astaxanthin, one of the strongest known natural antioxidant substances, considered to benefic to the immune, cardiovascular and nervous systems, to joints and muscles. The main Algatech product, AstaPure, is natural astaxanthin extracted from the algae. It is mainly sold the United States, Japan and Europe - in total, to more than 30 countries, where it is used as a natural ingredient and pigment for use in cosmetics; and as a nutraceutical, including as an ingredient for dietary supplements. Research has proven astaxanthin to have positive health effects on a multitude of organs and body functions, such as: eyesight, skin, physical effort durig sport activities, cognitive abilities, anti-inflammatory effects and so forth. Algatech, to which Kibbutz Ketura is a partner, is considered a leading company in microalgae agriculture and one of the most forward-looking innovators in the field, worldwide.\n\nKetura is part of the Green Kibbutz movement. In addition to promoting awareness, recycling and opening a second-hand store, Ketura planted a community garden and operates a high-tech algae farm. \nMembers of Ketura founded the Arava Institute for Environmental Studies (AIES), which is located at Ketura. The institute promotes regional environmental cooperation between Israelis, Palestinians and residents of neighbouring Arab countries in environmental matters, with a focus on the desert ecosystem.\n\nKetura is a partner in the Arava Power Company (APC), producing electricity from solar panels. There is one 4.95MW field on the kibbutz, Ketura Sun, with a second 40MW field opened in 2015, then the largest in Israel.\n\nThe only surviving example of the Judean date palm, artificially germinated from a 2,000-year-old seed discovered in archaeological excavations, was planted in Ketura and continues to survive there. It was nicknamed 'Methuselah'.\n\n\n"}
{"id": "45206313", "url": "https://en.wikipedia.org/wiki?curid=45206313", "title": "Knappenrode energy museum", "text": "Knappenrode energy museum\n\nThe Knappenrode energy museum is a museum in Hoyerswerda, Saxony Germany.\nThe museum is an Anchor point on the European Route of Industrial Heritage.\nKnappenrode is a monument to brown coal. Around 1914 the natural landscape of heathland and coniferous forest was replaced by this vast open cast brown coal mining operation and briquetting plants. The workers dwelt in a specially-erected housing outside the factory gates. This was a true factory village- the company owned the houses, the store, a guest house, a community centre and a railway station. It provided the village with a company owned cemetery. The workers and families used the factory bath-house so the houses needed no bathroom. When retired, they came back and used the bathhouse on Saturday nights- and this remained a social event.\n\nA briquetting plant was built in 1914. It was called \"\"Eintracht Werke\".It was managed by Joseph Werminghoff. Production began in October 1918, and two other plants were then built. After 1945 the plant was renamed \"Glückauf\"\", some equipment removed and production continued. In 1965 the plant turned out more than one and a half million tons of briquettes. Modernisation was neglected and the plant stagnated and closed in 1993, leaving a legacy of historic machines that form the nucleus of a museum collection.\n\n"}
{"id": "5014863", "url": "https://en.wikipedia.org/wiki?curid=5014863", "title": "Korea Atomic Energy Research Institute", "text": "Korea Atomic Energy Research Institute\n\nThe Korea Atomic Energy Research Institute (KAERI) in Daejeon, South Korea was established in 1959 as the sole professional research-oriented institute for nuclear power in South Korea, and has rapidly built a reputation for research and development in various fields. In 1995 KAERI designed and constructed the nation's first multipurpose research reactor, HANARO based on the Canadian MAPLE design. KAERI is dedicated to finding a wide range of uses for atomic energy. As examples, KAERI developed the world's first radiopharmaceutical \"Milican injection\" for treating liver cancer. \n\nKAERI has made significant contributions to the nation's nuclear technology development. After Korea achieved self-reliance in nuclear core technologies, KAERI have transferred highly developed technologies to local industries for practical applications. The Korea Institute of Nuclear Safety (KINS), responsible for supporting the government in regulatory and licensing works, and the Nuclear Environment Technology Institute, responsible for low and medium level radioactive waste management, are also originally spin-offs from KAERI. KAERI established the present KEPCO E&C (full name: KEPCO Engineering & Construction Company, INC., formerly: KOPEC), responsible for not only the architect engineering works of nuclear power plants, but also for designing nuclear steam supply systems. KAERI also established the present Korea Nuclear Fuel Co., Ltd.(KNFC), responsible for designing and manufacturing PWR as well as PHWR fuels.\n\n"}
{"id": "41774963", "url": "https://en.wikipedia.org/wiki?curid=41774963", "title": "Kouhrang 3 Dam", "text": "Kouhrang 3 Dam\n\nThe Kouhrang 3 Dam (سد کوهرنگ ۳, also known as Birgan dam بیرگان) is an arch dam currently under construction on the Kouhrang River in Chaharmahal and Bakhtiari Province, Iran. It is located about northwest of Dashtak. The purpose of the dam is water supply and river regulation. Upstream of the dam will be the intake for the Kouhrang 3 Tunnel which will transfer water northeast to the Zayandeh River for use in major cities like Isfahan. Sabir Co. was awarded the contract for the dam's construction in February 2011 and construction began that same year. The diversion tunnels for the dam were completed in March 2013. The project is scheduled for completed in 2015.\n\nAs of July 2017, the project was not yet complete, though the tunnel was considered 97% finished, and newly allocated funds were expected to allow imminent completion . It is claimed that construction of the tunnel in difficult geological conditions has led to drying up of springs, and the estimated transfer volume has been reduced from 270-300 to 40-130 million cubic metres per year. \n\n"}
{"id": "42322348", "url": "https://en.wikipedia.org/wiki?curid=42322348", "title": "LIAT Flight 319", "text": "LIAT Flight 319\n\nLIAT Flight 319 was a scheduled international flight from Hewanorra International Airport in Saint Lucia to E. T. Joshua Airport in St. Vincent and the Grenadines. On 3 August 1986, the 19-seater de Havilland Canada DHC-6 Series 310 Twin Otter airliner serving the flight, which was operated by Leeward Islands Air Transport (LIAT), crashed into the Caribbean Sea, resulting in the deaths of its eleven passengers and two aircrew.\n\nThe aircraft involved in the accident was a de Havilland Canada DHC-6 Twin Otter 310, with manufacturer serial number 785, registered as V2-LCJ. This airliner first flew in 1982. The aircraft was powered by two Pratt & Whitney Canada PT6A-27. It was capable of accommodating 19 passengers.\n\nOn Sunday 4 August 1986, LIAT Flight 319 departed from Hewanorra International Airport in St. Lucia, en route to the E. T. Joshua Airport (then called the Arnos Vale airport) in St. Vincent and the Grenadines. On attempting to land at its destination the plane encountered difficulties due to a rainstorm. Two initial attempts were made to land the plane. The plane is believed to have crashed into the sea and sunk in water some deep during its third landing attempt.\n\nNeither the bodies of the passengers and crew, nor the wreckage were discovered. The government of St. Vincent and the Grenadines declared everyone on board perished, after recovery attempts failed to locate any bodies six days after the crash.\n\nSeven of the passengers aboard Flight 319 were Vincentian nationals. There were two Americans, two Italians, one Canadian and one Antiguan.\n"}
{"id": "50948670", "url": "https://en.wikipedia.org/wiki?curid=50948670", "title": "Lake Fúquene", "text": "Lake Fúquene\n\nLake Fúquene is a heart-shaped lake located in the Ubaté-Chiquinquirá Valley, part of the Altiplano Cundiboyacense, in the north of Cundinamarca, Colombia, at the border with Boyacá. The Andean lake, at an average altitude of , was considered sacred in the religion of the Muisca who inhabited the area before the Spanish conquest of the Muisca in the 1530s.\n\nDue to drainage of the waters for agriculture and dairy farming, the lake levels have dropped drastically in recent years and many flora and fauna species have disappeared.\n\nIn the Chibcha language of the Muisca \"Fúquene\" means \"Place of swamps covered with fog\", \"Bed of the fox\" or \"Holy People\", referring to the religious rituals of the Muisca. Muisca means \"people\" in Chibcha.\n\nLake Fúquene, the lake in the Ubaté-Chiquinquirá Valley, one of the four major valleys of the Altiplano Cundiboyacense, was an important ritual lake in the culture of the Muisca. It formed the connection between the territories of the \"zipa\" in the south and \"zaque\" in the north and merchants between the two parts of the Muisca Confederation would pass the lake.\n\nWhen conquistador Gonzalo Jiménez de Quesada and his troops arrived at the lake in 1537, the water level was to higher.\n\nSince 1934 about 70% of the lake surface has been gone; from to . In this time, the lake level has dropped by .\n\nAround 47 bird species visit Lake Fúquene, among them \"Agelaius icterocephalus bogotensis\" and \"Fulica americana\". in 1940, more than 80 fauna species were foraging around the lake, a number reduced to 58 in 2014.\n\nIn and around the lake 248 plant species have been identified. Some of the flora species are \"Scirpus californicus\", \"Typha\", \"Ixobrichus exilis bogotensis\", and \"Alnus jorullensis\". In recent years, 40% of the biodiversity has disappeared in the past 60 years.\n\nIn 2014, around 207,000 inhabitants of the area lived around the lake. Fifty dairy farming industries exist around it, with the most important in Ubaté, Chiquinquirá and Simijaca.\n\n\n\n"}
{"id": "7269616", "url": "https://en.wikipedia.org/wiki?curid=7269616", "title": "Landfill Tax Credit Scheme", "text": "Landfill Tax Credit Scheme\n\nThe Landfill Tax Credit Scheme (LTCS) is a scheme for the distribution of funds generated from Landfill Tax in the United Kingdom. The scheme was established by the Landfill Tax Regulations in 1996.\n\nThe LTCS was designed to help mitigate the effects of landfill upon local communities. It encourages partnerships between landfill operators, their local communities and the voluntary and public sectors. Since 2014, a similar scheme operates in relation to Scottish Landfill Tax.\n"}
{"id": "17747", "url": "https://en.wikipedia.org/wiki?curid=17747", "title": "Lead", "text": "Lead\n\nLead is a chemical element with symbol Pb (from the Latin \"plumbum\") and atomic number 82. It is a heavy metal that is denser than most common materials. Lead is soft and malleable, and has a relatively low melting point. When freshly cut, lead is silvery with a hint of blue; it tarnishes to a dull gray color when exposed to air. Lead has the highest atomic number of any stable element and three of its isotopes each conclude a major decay chain of heavier elements.\n\nLead is a relatively unreactive post-transition metal. Its weak metallic character is illustrated by its amphoteric nature; lead and lead oxides react with acids and bases, and it tends to form covalent bonds. Compounds of lead are usually found in the +2 oxidation state rather than the +4 state common with lighter members of the carbon group. Exceptions are mostly limited to organolead compounds. Like the lighter members of the group, lead tends to bond with itself; it can form chains, rings and polyhedral structures.\n\nLead is easily extracted from its ores; prehistoric people in Western Asia knew of it. Galena, a principal ore of lead, often bears silver, interest in which helped initiate widespread extraction and use of lead in ancient Rome. Lead production declined after the fall of Rome and did not reach comparable levels until the Industrial Revolution. In 2014, annual global production of lead was about ten million tonnes, over half of which was from recycling. Lead's high density, low melting point, ductility and relative inertness to oxidation make it useful. These properties, combined with its relative abundance and low cost, resulted in its extensive use in construction, plumbing, batteries, bullets and shot, weights, solders, pewters, fusible alloys, white paints, leaded gasoline, and radiation shielding.\n\nIn the late 19th century, lead's toxicity was recognized, and its use has since been phased out of many applications. Lead is a toxin that accumulates in soft tissues and bones, it acts as a neurotoxin damaging the nervous system and interfering with the function of biological enzymes. It is particularly problematic in children: even if blood levels are promptly normalized with treatment, neurological disorders, such as brain damage and behavioral problems, may result.\n\nA lead atom has 82 electrons, arranged in an electron configuration of [Xe]4f5d6s6p. The sum of lead's first and second ionization energies—the total energy required to remove the two 6p electrons—is close to that of tin, lead's upper neighbor in the carbon group. This is unusual; ionization energies generally fall going down a group, as an element's outer electrons become more distant from the nucleus, and more shielded by smaller orbitals. The similarity of ionization energies is caused by the lanthanide contraction—the decrease in element radii from lanthanum (atomic number 57) to lutetium (71), and the relatively small radii of the elements from hafnium (72) onwards. This is due to poor shielding of the nucleus by the lanthanide 4f electrons. The sum of the first four ionization energies of lead exceeds that of tin, contrary to what periodic trends would predict. Relativistic effects, which become significant in heavier atoms, contribute to this behavior. One such effect is the inert pair effect: the 6s electrons of lead become reluctant to participate in bonding, making the distance between nearest atoms in crystalline lead unusually long.\n\nLead's lighter carbon group congeners form stable or metastable allotropes with the tetrahedrally coordinated and covalently bonded diamond cubic structure. The energy levels of their outer s- and p-orbitals are close enough to allow mixing into four hybrid sp orbitals. In lead, the inert pair effect increases the separation between its s- and p-orbitals, and the gap cannot be overcome by the energy that would be released by extra bonds following hybridization. Rather than having a diamond cubic structure, lead forms metallic bonds in which only the p-electrons are delocalized and shared between the Pb ions. Lead consequently has a face-centered cubic structure like the similarly sized divalent metals calcium and strontium.\n\nPure lead has a bright, silvery appearance with a hint of blue. It tarnishes on contact with moist air, and takes on a dull appearance, the hue of which depends on the prevailing conditions. Characteristic properties of lead include high density, malleability, ductility, and high resistance to corrosion due to passivation.\nLead's close-packed face-centered cubic structure and high atomic weight result in a density of 11.34 g/cm, which is greater than that of common metals such as iron (7.87 g/cm), copper (8.93 g/cm), and zinc (7.14 g/cm). This density is the origin of the idiom \"to go over like a lead balloon\". Some rarer metals are denser: tungsten and gold are both at 19.3 g/cm, and osmium—the densest metal known—has a density of 22.59 g/cm, almost twice that of lead.\n\nLead is a very soft metal with a Mohs hardness of 1.5; it can be scratched with a fingernail. It is quite malleable and somewhat ductile. The bulk modulus of lead—a measure of its ease of compressibility—is 45.8 GPa. In comparison, that of aluminium is 75.2 GPa; copper 137.8 GPa; and mild steel 160–169 GPa. Lead's tensile strength, at 12–17 MPa, is low (that of aluminium is 6 times higher, copper 10 times, and mild steel 15 times higher); it can be strengthened by adding small amounts of copper or antimony.\n\nThe melting point of lead—at 327.5 °C (621.5 °F)—is very low compared to most metals. Its boiling point of 1749 °C (3180 °F) is the lowest among the carbon group elements. The electrical resistivity of lead at 20 °C is 192 nanoohm-meters, almost an order of magnitude higher than those of other industrial metals (copper at 15.43 nΩ·m; gold 20.51 nΩ·m; and aluminium at 24.15 nΩ·m). Lead is a superconductor at temperatures lower than 7.19 K; this is the highest critical temperature of all type-I superconductors and the third highest of the elemental superconductors.\n\nNatural lead consists of four stable isotopes with mass numbers of 204, 206, 207, and 208, and traces of five short-lived radioisotopes. The high number of isotopes is consistent with lead's atomic number being even. Lead has a magic number of protons (82), for which the nuclear shell model accurately predicts an especially stable nucleus. Lead-208 has 126 neutrons, another magic number, which may explain why lead-208 is extraordinarily stable.\n\nWith its high atomic number, lead is the heaviest element whose natural isotopes are regarded as stable; lead-208 is the heaviest stable nucleus. (This distinction formerly fell to bismuth, with an atomic number of 83, until its only primordial isotope, bismuth-209, was found in 2003 to decay very slowly.) The four stable isotopes of lead could theoretically undergo alpha decay to isotopes of mercury with a release of energy, but this has not been observed for any of them; their predicted half-lives range from 10 to 10 years (at least 10 times the current age of the universe).\n\nThree of the stable isotopes are found in three of the four major decay chains: lead-206, lead-207, and lead-208 are the final decay products of uranium-238, uranium-235, and thorium-232, respectively. These decay chains are called the uranium chain, the actinium chain, and the thorium chain. Their isotopic concentrations in a natural rock sample depends greatly on the presence of these three parent uranium and thorium isotopes. For example, the relative abundance of lead-208 can range from 52% in normal samples to 90% in thorium ores; for this reason, the standard atomic weight of lead is given to only one decimal place. As time passes, the ratio of lead-206 and lead-207 to lead-204 increases, since the former two are supplemented by radioactive decay of heavier elements while the latter is not; this allows for lead–lead dating. As uranium decays into lead, their relative amounts change; this is the basis for uranium–lead dating. Lead-207 exhibits nuclear magnetic resonance, a property that has been used to study its compounds in solution and solid state, including in human body.\nApart from the stable isotopes, which make up almost all lead that exists naturally, there are trace quantities of a few radioactive isotopes. One of them is lead-210; although it has a half-life of only 22.3 years, small quantities occur in nature because lead-210 is produced by a long decay series that starts with uranium-238 (which has been present for billions of years on Earth). Lead-211, -212, and -214 are present in the decay chains of uranium-235, thorium-232, and uranium-238, respectively, so traces of all three of these lead isotopes are found naturally. Minute traces of lead-209 arise from the very rare cluster decay of radium-223, one of the daughter products of natural uranium-235, and the decay chain of neptunium-237, traces of which are produced by neutron capture in uranium ores. Lead-210 is particularly useful for helping to identify the ages of samples by measuring its ratio to lead-206 (both isotopes are present in a single decay chain).\n\nIn total, 43 lead isotopes have been synthesized, with mass numbers 178–220. Lead-205 is the most stable radioisotope, with a half-life of around 1.5 years. The second-most stable is lead-202, which has a half-life of about 53,000 years, longer than any of the natural trace radioisotopes.\n\nBulk lead exposed to moist air forms a protective layer of varying composition. Lead(II) carbonate is a common constituent; the sulfate or chloride may also be present in urban or maritime settings. This layer makes bulk lead effectively chemically inert in the air. Finely powdered lead, as with many metals, is pyrophoric, and burns with a bluish-white flame.\n\nFluorine reacts with lead at room temperature, forming lead(II) fluoride. The reaction with chlorine is similar but requires heating, as the resulting chloride layer diminishes the reactivity of the elements. Molten lead reacts with the chalcogens to give lead(II) chalcogenides.\n\nLead metal resists sulfuric and phosphoric acid but not hydrochloric or nitric acid; the outcome depends on insolubility and subsequent passivation of the product salt. Organic acids, such as acetic acid, dissolve lead in the presence of oxygen. Concentrated alkalis will dissolve lead and form plumbites.\n\nLead shows two main oxidation states: +4 and +2. The tetravalent state is common for the carbon group. The divalent state is rare for carbon and silicon, minor for germanium, important (but not prevailing) for tin, and is the more important of the two oxidation states for lead. This is attributable to relativistic effects, specifically the inert pair effect, which manifests itself when there is a large difference in electronegativity between lead and oxide, halide, or nitride anions, leading to a significant partial positive charge on lead. The result is a stronger contraction of the lead 6s orbital than is the case for the 6p orbital, making it rather inert in ionic compounds. The inert pair effect is less applicable to compounds in which lead forms covalent bonds with elements of similar electronegativity, such as carbon in organolead compounds. In these, the 6s and 6p orbitals remain similarly sized and sp hybridization is still energetically favorable. Lead, like carbon, is predominantly tetravalent in such compounds.\n\nThere is a relatively large difference in the electronegativity of lead(II) at 1.87 and lead(IV) at 2.33. This difference marks the reversal in the trend of increasing stability of the +4 oxidation state going down the carbon group; tin, by comparison, has values of 1.80 in the +2 oxidation state and 1.96 in the +4 state.\n\nLead(II) compounds are characteristic of the inorganic chemistry of lead. Even strong oxidizing agents like fluorine and chlorine react with lead to give only PbF and PbCl. Lead(II) ions are usually colorless in solution, and partially hydrolyze to form Pb(OH) and finally [Pb(OH)] (in which the hydroxyl ions act as bridging ligands), but are not reducing agents as tin(II) ions are. Techniques for identifying the presence of the Pb ion in water generally rely on the precipitation of lead(II) chloride using dilute hydrochloric acid. As the chloride salt is sparingly soluble in water, in very dilute solutions the precipitation of lead(II) sulfide is achieved by bubbling hydrogen sulfide through the solution.\n\nLead monoxide exists in two polymorphs, litharge α-PbO (red) and massicot β-PbO (yellow), the latter being stable only above around 488 °C. Litharge is the most commonly used inorganic compound of lead. There is no lead(II) hydroxide; increasing the pH of solutions of lead(II) salts leads to hydrolysis and condensation.\nLead commonly reacts with heavier chalcogens. Lead sulfide is a semiconductor, a photoconductor, and an extremely sensitive infrared radiation detector. The other two chalcogenides, lead selenide and lead telluride, are likewise photoconducting. They are unusual in that their color becomes lighter going down the group.\nLead dihalides are well-characterized; this includes the diastatide, and mixed halides, such as PbFCl. The relative insolubility of the latter forms a useful basis for the gravimetric determination of fluorine. The difluoride was the first solid ionically conducting compound to be discovered (in 1834, by Michael Faraday). The other dihalides decompose on exposure to ultraviolet or visible light, especially the diiodide. Many lead(II) pseudohalides are known, such as the cyanide, cyanate, and thiocyanate. Lead(II) forms an extensive variety of halide coordination complexes, such as [PbCl], [PbCl], and the [PbCl] chain anion.\n\nLead(II) sulfate is insoluble in water, like the sulfates of other heavy divalent cations. Lead(II) nitrate and lead(II) acetate are very soluble, and this is exploited in the synthesis of other lead compounds.\n\nFew inorganic lead(IV) compounds are known. They are only formed in highly oxidizing solutions and do not normally exist under standard conditions. Lead(II) oxide gives a mixed oxide on further oxidation, PbO. It is described as lead(II,IV) oxide, or structurally 2PbO·PbO, and is the best-known mixed valence lead compound. Lead dioxide is a strong oxidizing agent, capable of oxidizing hydrochloric acid to chlorine gas. This is because the expected PbCl that would be produced is unstable and spontaneously decomposes to PbCl and Cl. Analogously to lead monoxide, lead dioxide is capable of forming plumbate anions. Lead disulfide and lead diselenide are only stable at high pressures. Lead tetrafluoride, a yellow crystalline powder, is stable, but less so than the difluoride. Lead tetrachloride (a yellow oil) decomposes at room temperature, lead tetrabromide is less stable still, and the existence of lead tetraiodide is questionable.\n\nSome lead compounds exist in formal oxidation states other than +4 or +2. Lead(III) may be obtained, as an intermediate between lead(II) and lead(IV), in larger organolead complexes; this oxidation state is not stable, as both the lead(III) ion and the larger complexes containing it are radicals. The same applies for lead(I), which can be found in such radical species.\n\nNumerous mixed lead(II,IV) oxides are known. When PbO is heated in air, it becomes PbO at 293 °C, PbO at 351 °C, PbO at 374 °C, and finally PbO at 605 °C. A further sesquioxide, PbO, can be obtained at high pressure, along with several non-stoichiometric phases. Many of them show defective fluorite structures in which some oxygen atoms are replaced by vacancies: PbO can be considered as having such a structure, with every alternate layer of oxygen atoms absent.\n\nNegative oxidation states can occur as Zintl phases, as either free lead anions, as in BaPb, with lead formally being lead(−IV), or in oxygen-sensitive ring-shaped or polyhedral cluster ions such as the trigonal bipyramidal Pb ion, where two lead atoms are lead(−I) and three are lead(0). In such anions, each atom is at a polyhedral vertex and contributes two electrons to each covalent bond along an edge from their sp hybrid orbitals, the other two being an external lone pair. They may be made in liquid ammonia via the reduction of lead by sodium.\n\nLead can form multiply-bonded chains, a property it shares with its lighter homologs in the carbon group. Its capacity to do so is much less because the Pb–Pb bond energy is over three and a half times lower than that of the C–C bond. With itself, lead can build metal–metal bonds of an order up to three. With carbon, lead forms organolead compounds similar to, but generally less stable than, typical organic compounds (due to the Pb–C bond being rather weak). This makes the organometallic chemistry of lead far less wide-ranging than that of tin. Lead predominantly forms organolead(IV) compounds, even when starting with inorganic lead(II) reactants; very few organolead(II) compounds are known. The most well-characterized exceptions are Pb[CH(SiMe)] and Pb(\"η\"-CH).\n\nThe lead analog of the simplest organic compound, methane, is plumbane. Plumbane may be obtained in a reaction between metallic lead and atomic hydrogen. Two simple derivatives, tetramethyllead and tetraethyllead, are the best-known organolead compounds. These compounds are relatively stable: tetraethyllead only starts to decompose if heated or if exposed to sunlight or ultraviolet light. (Tetraphenyllead is even more thermally stable, decomposing at 270 °C.) With sodium metal, lead readily forms an equimolar alloy that reacts with alkyl halides to form organometallic compounds such as tetraethyllead. The oxidizing nature of many organolead compounds is usefully exploited: lead tetraacetate is an important laboratory reagent for oxidation in organic synthesis, and tetraethyllead was once produced in larger quantities than any other organometallic compound. Other organolead compounds are less chemically stable. For many organic compounds, a lead analog does not exist.\n\nLead's per-particle abundance in the Solar System is 0.121 ppb (parts per billion). This figure is two and a half times higher than that of platinum, eight times more than mercury, and seventeen times more than gold. The amount of lead in the universe is slowly increasing as most heavier atoms (all of which are unstable) gradually decay to lead. The abundance of lead in the Solar System since its formation 4.5 billion years ago has increased by about 0.75%. The solar system abundances table shows that lead, despite its relatively high atomic number, is more prevalent than most other elements with atomic numbers greater than 40.\n\nPrimordial lead—which comprises the isotopes lead-204, lead-206, lead-207, and lead-208—was mostly created as a result of repetitive neutron capture processes occurring in stars. The two main modes of capture are the s- and r-processes.\n\nIn the s-process (s is for \"slow\"), captures are separated by years or decades, allowing less stable nuclei to undergo beta decay. A stable thallium-203 nucleus can capture a neutron and become thallium-204; this undergoes beta decay to give stable lead-204; on capturing another neutron, it becomes lead-205, which has a half-life of around 15 million years. Further captures result in lead-206, lead-207, and lead-208. On capturing another neutron, lead-208 becomes lead-209, which quickly decays into bismuth-209. On capturing another neutron, bismuth-209 becomes bismuth-210, and this beta decays to polonium-210, which alpha decays to lead-206. The cycle hence ends at lead-206, lead-207, lead-208, and bismuth-209.\nIn the r-process (r is for \"rapid\"), captures happen faster than nuclei can decay. This occurs in environments with a high neutron density, such as a supernova or the merger of two neutron stars. The neutron flux involved may be on the order of 10 neutrons per square centimeter per second. The r-process does not form as much lead as the s-process. It tends to stop once neutron-rich nuclei reach 126 neutrons. At this point, the neutrons are arranged in complete shells in the atomic nucleus, and it becomes harder to energetically accommodate more of them. When the neutron flux subsides, these nuclei beta decay into stable isotopes of osmium, iridium, and platinum.\n\nLead is classified as a chalcophile under the Goldschmidt classification, meaning it is generally found combined with sulfur. It rarely occurs in its native, metallic form. Many lead minerals are relatively light and, over the course of the Earth's history, have remained in the crust instead of sinking deeper into the Earth's interior. This accounts for lead's relatively high crustal abundance of 14 ppm; it is the 38th most abundant element in the crust.\n\nThe main lead-bearing mineral is galena (PbS), which is mostly found with zinc ores. Most other lead minerals are related to galena in some way; boulangerite, PbSbS, is a mixed sulfide derived from galena; anglesite, PbSO, is a product of galena oxidation; and cerussite or white lead ore, PbCO, is a decomposition product of galena. Arsenic, tin, antimony, silver, gold, copper, and bismuth are common impurities in lead minerals.\nWorld lead resources exceed two billion tons. Significant deposits are located in Australia, China, Ireland, Mexico, Peru, Portugal, Russia, and the United States. Global reserves—resources that are economically feasible to extract—totaled 88 million tons in 2016, of which Australia had 35 million, China 17 million, and Russia 6.4 million.\n\nTypical background concentrations of lead do not exceed 0.1 μg/m in the atmosphere; 100 mg/kg in soil; and 5 μg/L in freshwater and seawater.\n\nThe modern English word \"lead\" is of Germanic origin; it comes from the Middle English \"leed\" and Old English \"lēad\" (with the macron above the \"e\" signifying that the vowel sound of that letter is long). The Old English word is derived from the hypothetical reconstructed Proto-Germanic \"*lauda-\" (\"lead\"). According to linguistic theory, this word bore descendants in multiple Germanic languages of exactly the same meaning.\n\nThe origin of the Proto-Germanic \"*lauda-\" is not agreed in the linguistic community. One hypothesis suggests it is derived from Proto-Indo-European \"*lAudh-\" (\"lead\"; capitalization of the vowel is equivalent to the macron). Another hypothesis suggests it is borrowed from Proto-Celtic \"*ɸloud-io-\" (\"lead\"). This word is related to the Latin \"plumbum\", which gave the element its chemical symbol \"Pb\". The word \"*ɸloud-io-\" is thought to be the origin of Proto-Germanic \"*bliwa-\" (which also means \"lead\"), from which stemmed the German \"Blei\".\n\nThe name of the chemical element is not related to the verb of the same spelling, which is derived from Proto-Germanic \"*laidijan-\" (\"to lead\").\n\nMetallic lead beads dating back to 7000–6500 BCE have been found in Asia Minor and may represent the first example of metal smelting. At that time lead had few (if any) applications due to its softness and dull appearance. The major reason for the spread of lead production was its association with silver, which may be obtained by burning galena (a common lead mineral). The Ancient Egyptians were the first to use lead minerals in cosmetics, an application that spread to Ancient Greece and beyond; the Egyptians may have used lead for sinkers in fishing nets, glazes, glasses, enamels, and for ornaments. Various civilizations of the Fertile Crescent used lead as a writing material, as currency, and for construction. Lead was used in the Ancient Chinese royal court as a stimulant, as currency, and as a contraceptive; the Indus Valley civilization and the Mesoamericans used it for making amulets; and the eastern and southern African peoples used lead in wire drawing.\n\nBecause silver was extensively used as a decorative material and an exchange medium, lead deposits came to be worked in Asia Minor since 3000 BCE; later, lead deposits were developed in the Aegean and Laurion. These three regions collectively dominated production of mined lead until c. 1200 BCE. Since 2000 BCE, the Phoenicians worked deposits in the Iberian peninsula; by 1600 BCE, lead mining existed in Cyprus, Greece, and Sardinia.\n\nRome's territorial expansion in Europe and across the Mediterranean, and its development of mining, led to it becoming the greatest producer of lead during the classical era, with an estimated annual output peaking at 80,000 tonnes. Like their predecessors, the Romans obtained lead mostly as a by-product of silver smelting. Lead mining occurred in Central Europe, Britain, the Balkans, Greece, Anatolia, and Hispania, the latter accounting for 40% of world production.\n\nLead tablets were commonly used as a material for letters. Lead coffins, cast in flat sand forms, with interchangeable motifs to suit the faith of the deceased were used in ancient Judea.\n\nLead was used for making water pipes in the Roman Empire; the Latin word for the metal, \"plumbum\", is the origin of the English word \"plumbing\". Its ease of working and resistance to corrosion ensured its widespread use in other applications including pharmaceuticals, roofing, currency, and warfare. Writers of the time, such as Cato the Elder, Columella, and Pliny the Elder, recommended lead (or lead-coated) vessels for the preparation of sweeteners and preservatives added to wine and food. The lead conferred an agreeable taste due to the formation of \"sugar of lead\" (lead(II) acetate), whereas copper or bronze vessels could impart a bitter flavor through verdigris formation.\n\nThe Roman author Vitruvius reported the health dangers of lead and modern writers have suggested that lead poisoning played a major role in the decline of the Roman Empire. Other researchers have criticized such claims, pointing out, for instance, that not all abdominal pain is caused by lead poisoning. According to archaeological research, Roman lead pipes increased lead levels in tap water but such an effect was \"unlikely to have been truly harmful\". When lead poisoning did occur, victims were called \"saturnine\", dark and cynical, after the ghoulish father of the gods, Saturn. By association, lead was considered the father of all metals. Its status in Roman society was low as it was readily available and cheap.\n\nDuring the classical era (and even up to the 17th century), tin was often not distinguished from lead: Romans called lead \"plumbum nigrum\" (\"black lead\"), and tin \"plumbum candidum\" (\"bright lead\"). The association of lead and tin can be seen in other languages: the word \"olovo\" in Czech translates to \"lead\", but in Russian the cognate \"олово\" (\"olovo\") means \"tin\". To add to the confusion, lead bore a close relation to antimony: both elements commonly occur as sulfides (galena and stibnite), often together. Pliny incorrectly wrote that stibnite would give lead on heating, instead of antimony. In countries such as Turkey and India, the originally Persian name \"surma\" came to refer to either antimony sulfide or lead sulfide, and in some languages, such as Russian, gave its name to antimony \"(сурьма).\"\n\nLead mining in Western Europe declined after the fall of the Western Roman Empire, with Arabian Iberia being the only region having a significant output. The largest production of lead occurred in South and East Asia, especially China and India, where lead mining grew rapidly.\n\nIn Europe, lead production began to increase in the 11th and 12th centuries, when it was again used for roofing and piping. Starting in the 13th century, lead was used to create stained glass. In the European and Arabian traditions of alchemy, lead (symbol in the European tradition) was considered an impure base metal which, by the separation, purification and balancing of its constituent essences, could be transformed to pure and incorruptible gold. During the period, lead was used increasingly for adulterating wine. The use of such wine was forbidden for use in Christian rites by a papal bull in 1498, but it continued to be imbibed and resulted in mass poisonings up to the late 18th century. Lead was a key material in parts of the printing press, which was invented around 1440; lead dust was commonly inhaled by print workers, causing lead poisoning. Firearms were invented at around the same time, and lead, despite being more expensive than iron, became the chief material for making bullets. It was less damaging to iron gun barrels, had a higher density (which allowed for better retention of velocity), and its lower melting point made the production of bullets easier as they could be made using a wood fire. Lead, in the form of Venetian ceruse, was extensively used in cosmetics by Western European aristocracy as whitened faces were regarded as a sign of modesty. This practice later expanded to white wigs and eyeliners, and only faded out with the French Revolution in the late 18th century. A similar fashion appeared in Japan in the 18th century with the emergence of the geishas, a practice that continued long into the 20th century. The white faces of women \"came to represent their feminine virtue as Japanese women\", with lead commonly used in the whitener.\n\nIn the New World, lead was produced soon after the arrival of European settlers. The earliest recorded lead production dates to 1621 in the English Colony of Virginia, fourteen years after its foundation. In Australia, the first mine opened by colonists on the continent was a lead mine, in 1841. In Africa, lead mining and smelting were known in the Benue Trough and the lower Congo Basin, where lead was used for trade with Europeans, and as a currency by the 17th century, well before the scramble for Africa.\n\nIn the second half of the 18th century, Britain, and later continental Europe and the United States, experienced the Industrial Revolution. This was the first time during which lead production rates exceeded those of Rome. Britain was the leading producer, losing this status by the mid-19th century with the depletion of its mines and the development of lead mining in Germany, Spain, and the United States. By 1900, the United States was the leader in global lead production, and other non-European nations—Canada, Mexico, and Australia—had begun significant production; production outside Europe exceeded that within. A great share of the demand for lead came from plumbing and painting—lead paints were in regular use. At this time, more (working class) people were exposed to the metal and lead poisoning cases escalated. This led to research into the effects of lead intake. Lead was proven to be more dangerous in its fume form than as a solid metal. Lead poisoning and gout were linked; British physician Alfred Baring Garrod noted a third of his gout patients were plumbers and painters. The effects of chronic ingestion of lead, including mental disorders, were also studied in the 19th century. The first laws aimed at decreasing lead poisoning in factories were enacted during the 1870s and 1880s in the United Kingdom.\n\nFurther evidence of the threat that lead posed to humans was discovered in the late 19th and early 20th centuries. Mechanisms of harm were better understood, lead blindness was documented, and the element was phased out of public use in the United States and Europe. The United Kingdom introduced mandatory factory inspections in 1878 and appointed the first Medical Inspector of Factories in 1898; as a result, a 25-fold decrease in lead poisoning incidents from 1900 to 1944 was reported. The last major human exposure to lead was the addition of tetraethyllead to gasoline as an antiknock agent, a practice that originated in the United States in 1921. It was phased out in the United States and the European Union by 2000. Most European countries banned lead paint—commonly used because of its opacity and water resistance—for interiors by 1930.\n\nIn the 1970s, the United States and Western European countries introduced legislation to reduce lead air pollution. The impact was significant: while a study conducted by the Centers for Disease Control and Prevention in the United States in 1976–1980 showed that 77.8% of the population had elevated blood lead levels, in 1991–1994, a study by the same institute showed the share of people with such high levels dropped to 2.2%. The main product made of lead by the end of the 20th century was the lead–acid battery, which posed no direct threat to humans. From 1960 to 1990, lead output in the Western Bloc grew by a third. The share of the world's lead production by the Eastern Bloc increased from 10% to 30%, from 1950 to 1990, with the Soviet Union being the world's largest producer during the mid-1970s and the 1980s, and China starting major lead production in the late 20th century. Unlike the European communist countries, China was largely unindustrialized by the mid-20th century; in 2004, China surpassed Australia as the largest producer of lead. As was the case during European industrialization, lead has had a negative effect on health in China.\n\nProduction of lead is increasing worldwide due to its use in lead–acid batteries. There are two major categories of production: primary from mined ores, and secondary from scrap. In 2014, 4.58 million metric tons came from primary production and 5.64 million from secondary production. The top three producers of mined lead concentrate in that year were China, Australia, and the United States. The top three producers of refined lead were China, the United States, and South Korea. According to the International Resource Panel's Metal Stocks in Society report of 2010, the total amount of lead in use, stockpiled, discarded, or dissipated into the environment, on a global basis, is 8 kg per capita. Much of this is in more developed countries (20–150 kg per capita) rather than less developed ones (1–4 kg per capita).\n\nThe primary and secondary lead production processes are similar. Some primary production plants now supplement their operations with scrap lead, and this trend is likely to increase in the future. Given adequate techniques, lead obtained via secondary processes is indistinguishable from lead obtained via primary processes. Scrap lead from the building trade is usually fairly clean and is re-melted without the need for smelting, though refining is sometimes needed. Secondary lead production is therefore cheaper, in terms of energy requirements, than is primary production, often by 50% or more.\n\nMost lead ores contain a low percentage of lead (rich ores have a typical content of 3–8%) which must be concentrated for extraction. During initial processing, ores typically undergo crushing, dense-medium separation, grinding, froth flotation, and drying. The resulting concentrate, which has a lead content of 30–80% by mass (regularly 50–60%), is then turned into (impure) lead metal.\n\nThere are two main ways of doing this: a two-stage process involving roasting followed by blast furnace extraction, carried out in separate vessels; or a direct process in which the extraction of the concentrate occurs in a single vessel. The latter has become the most common route, though the former is still significant.\n\nFirst, the sulfide concentrate is roasted in air to oxidize the lead sulfide:\n\nAs the original concentrate was not pure lead sulfide, roasting yields not only the desired lead(II) oxide, but a mixture of oxides, sulfates, and silicates of lead and of the other metals contained in the ore. This impure lead oxide is reduced in a coke-fired blast furnace to the (again, impure) metal:\n\nImpurities are mostly arsenic, antimony, bismuth, zinc, copper, silver, and gold. The melt is treated in a reverberatory furnace with air, steam, and sulfur, which oxidizes the impurities except for silver, gold, and bismuth. Oxidized contaminants float to the top of the melt and are skimmed off. Metallic silver and gold are removed and recovered economically by means of the Parkes process, in which zinc is added to lead. Zinc, which is immiscible in lead, dissolves the silver and gold. The zinc solution can be separated from the lead, and the silver and gold retrieved. De-silvered lead is freed of bismuth by the Betterton–Kroll process, treating it with metallic calcium and magnesium. The resulting bismuth dross can be skimmed off.\n\nVery pure lead can be obtained by processing smelted lead electrolytically using the Betts process. Anodes of impure lead and cathodes of pure lead are placed in an electrolyte of lead fluorosilicate (PbSiF). Once electrical potential is applied, impure lead at the anode dissolves and plates onto the cathode, leaving the majority of the impurities in solution. This is a high-cost process and thus mostly reserved for refining bullion containing high percentages of impurities.\n\nIn this process, lead bullion and slag is obtained directly from lead concentrates. The lead sulfide concentrate is melted in a furnace and oxidized, forming lead monoxide. Carbon (as coke or coal gas) is added to the molten charge along with fluxing agents. The lead monoxide is thereby reduced to metallic lead, in the midst of a slag rich in lead monoxide.\n\nAs much as 80% of the lead in very high-content initial concentrates can be obtained as bullion; the remaining 20% forms a slag rich in lead monoxide. For a low-grade feed, all of the lead can be oxidized to a high-lead slag. Metallic lead is further obtained from the high-lead (25–40%) slags via submerged fuel combustion or injection, reduction assisted by an electric furnace, or a combination of both.\n\nResearch on a cleaner, less energy-intensive lead extraction process continues; a major drawback is that either too much lead is lost as waste, or the alternatives result in a high sulfur content in the resulting lead metal. Hydrometallurgical extraction, in which anodes of impure lead are immersed into an electrolyte and pure lead is deposited onto a cathode, is a technique that may have potential.\n\nSmelting, which is an essential part of the primary production, is often skipped during secondary production. It is only performed when metallic lead has undergone significant oxidation. The process is similar to that of primary production in either a blast furnace or a rotary furnace, with the essential difference being the greater variability of yields: blast furnaces produce hard lead (10% antimony) while reverberatory and rotary kiln furnaces produced semisoft lead (3–4% antimony). The Isasmelt process is a more recent method that may act as an extension to primary production; battery paste from spent lead–acid batteries has sulfur removed by treating it with alkali, and is then treated in a coal-fueled furnace in the presence of oxygen, which yields impure lead, with antimony the most common impurity. Refining of secondary lead is similar to that of primary lead; some refining processes may be skipped depending on the material recycled and its potential contamination.\n\nOf the sources of lead for recycling, lead–acid batteries are the most important; lead pipe, sheet, and cable sheathing are also significant.\n\nContrary to popular belief, pencil leads in wooden pencils have never been made from lead. When the pencil originated as a wrapped graphite writing tool, the particular type of graphite used was named \"plumbago\" (literally, \"act for lead\" or \"lead mockup\").\n\nLead metal has several useful mechanical properties, including high density, low melting point, ductility, and relative inertness. Many metals are superior to lead in some of these aspects but are generally less common and more difficult to extract from parent ores. Lead's toxicity has led to its phasing out for some uses.\n\nLead has been used for bullets since their invention in the Middle Ages. It is inexpensive; its low melting point means small arms ammunition and shotgun pellets can be cast with minimal technical equipment; and it is denser than other common metals, which allows for better retention of velocity. Concerns have been raised that lead bullets used for hunting can damage the environment.\n\nLead's high density and resistance to corrosion have been exploited in a number of related applications. It is used as ballast in sailboat keels; its density allows it to take up a small volume and minimize water resistance, thus counterbalancing the heeling effect of wind on the sails. It is used in scuba diving weight belts to counteract the diver's buoyancy. In 1993, the base of the Leaning Tower of Pisa was stabilized with 600 tonnes of lead. Because of its corrosion resistance, lead is used as a protective sheath for underwater cables.\nLead has many uses in the construction industry; lead sheets are used as architectural metals in roofing material, cladding, flashing, gutters and gutter joints, and on roof parapets. Detailed lead moldings are used as decorative motifs to fix lead sheet. Lead is still used in statues and sculptures, including for armatures. In the past it was often used to balance the wheels of cars; for environmental reasons this use is being phased out in favor of other materials.\n\nLead is added to copper alloys, such as brass and bronze, to improve machinability and for its lubricating qualities. Being practically insoluble in copper the lead forms solid globules in imperfections throughout the alloy, such as grain boundaries. In low concentrations, as well as acting as a lubricant, the globules hinder the formation of swarf as the alloy is worked, thereby improving machinability. Copper alloys with larger concentrations of lead are used in bearings. The lead provides lubrication, and the copper provides the load-bearing support.\n\nLead's high density, atomic number, and formability form the basis for use of lead as a barrier that absorbs sound, vibration, and radiation. Lead has no natural resonance frequencies; as a result, sheet-lead is used as a sound deadening layer in the walls, floors, and ceilings of sound studios. Organ pipes are often made from a lead alloy, mixed with various amounts of tin to control the tone of each pipe. Lead is an established shielding material from radiation in nuclear science and in X-ray rooms due to its denseness and high attenuation coefficient. Molten lead has been used as a coolant for lead-cooled fast reactors.\n\nThe largest use of lead in the early 21st century is in lead–acid batteries. The reactions in the battery between lead, lead dioxide, and sulfuric acid provide a reliable source of voltage. The lead in batteries undergoes no direct contact with humans, so there are fewer toxicity concerns. Supercapacitors incorporating lead–acid batteries have been installed in kilowatt and megawatt scale applications in Australia, Japan, and the United States in frequency regulation, solar smoothing and shifting, wind smoothing, and other applications. These batteries have lower energy density and charge-discharge efficiency than lithium-ion batteries, but are significantly cheaper.\n\nLead is used in high voltage power cables as sheathing material to prevent water diffusion into insulation; this use is decreasing as lead is being phased out. Its use in solder for electronics is also being phased out by some countries to reduce the amount of environmentally hazardous waste. Lead is one of three metals used in the Oddy test for museum materials, helping detect organic acids, aldehydes, and acidic gases.\n\nIn addition to being the main application for lead metal, lead-acid batteries are also the main consumer of lead compounds. The energy storage/release reaction used in these devices involves lead sulfate and lead dioxide:\n\nOther applications of lead compounds are very specialized and often fading. Lead-based coloring agents are used in ceramic glazes and glass, especially for red and yellow shades. While lead paints are phased out in Europe and North America, they remain in use in less developed countries such as China or India. Lead tetraacetate and lead dioxide are used as oxidizing agents in organic chemistry. Lead is frequently used in the polyvinyl chloride coating of electrical cords. It can be used to treat candle wicks to ensure a longer, more even burn. Because of its toxicity, European and North American manufacturers use alternatives such as zinc. Lead glass is composed of 12–28% lead oxide, changing its optical characteristics and reducing the transmission of ionizing radiation. Lead-based semiconductors such as lead telluride and lead selenide are used in photovoltaic cells and infrared detectors.\n\nLead has no confirmed biological role. Its prevalence in the human body—at an adult average of 120 mg—is nevertheless exceeded only by zinc (2500 mg) and iron (4000 mg) among the heavy metals. Lead salts are very efficiently absorbed by the body. A small amount of lead (1%) is stored in bones; the rest is excreted in urine and feces within a few weeks of exposure. Only about a third of lead is excreted by a child. Continual exposure may result in the bioaccumulation of lead.\n\nLead is a highly poisonous metal (whether inhaled or swallowed), affecting almost every organ and system in the human body. At airborne levels of 100 mg/m, it is immediately dangerous to life and health. Most ingested lead is absorbed into the bloodstream. The primary cause of its toxicity is its predilection for interfering with the proper functioning of enzymes. It does so by binding to the sulfhydryl groups found on many enzymes, or mimicking and displacing other metals which act as cofactors in many enzymatic reactions. Among the essential metals that lead interacts with are calcium, iron, and zinc. High levels of calcium and iron tend to provide some protection from lead poisoning; low levels cause increased susceptibility.\n\nLead can cause severe damage to the brain and kidneys and, ultimately, death. By mimicking calcium, lead can cross the blood–brain barrier. It degrades the myelin sheaths of neurons, reduces their numbers, interferes with neurotransmission routes, and decreases neuronal growth. In the human body, lead inhibits porphobilinogen synthase and ferrochelatase, preventing both porphobilinogen formation and the incorporation of iron into protoporphyrin IX, the final step in heme synthesis. This causes ineffective heme synthesis and microcytic anemia.\n\nSymptoms of lead poisoning include nephropathy, colic-like abdominal pains, and possibly weakness in the fingers, wrists, or ankles. Small blood pressure increases, particularly in middle-aged and older people, may be apparent and can cause anemia. Several studies, mostly cross-sectional, found an association between increased lead exposure and decreased heart rate variability. In pregnant women, high levels of exposure to lead may cause miscarriage. Chronic, high-level exposure has been shown to reduce fertility in males.\n\nIn a child's developing brain, lead interferes with synapse formation in the cerebral cortex, neurochemical development (including that of neurotransmitters), and the organization of ion channels. Early childhood exposure has been linked with an increased risk of sleep disturbances and excessive daytime drowsiness in later childhood. High blood levels are associated with delayed puberty in girls. The rise and fall in exposure to airborne lead from the combustion of tetraethyl lead in gasoline during the 20th century has been linked with historical increases and decreases in crime levels, a hypothesis which is not universally accepted.\n\nLead exposure is a global issue since lead mining and smelting, and battery manufacturing/disposal/recycling, are common in many countries. Lead enters the body via inhalation, ingestion, or skin absorption. Almost all inhaled lead is absorbed into the body; for ingestion, the rate is 20–70%, with children absorbing a higher percentage than adults.\n\nPoisoning typically results from ingestion of food or water contaminated with lead, and less commonly after accidental ingestion of contaminated soil, dust, or lead-based paint. Seawater products can contain lead if affected by nearby industrial waters. Fruit and vegetables can be contaminated by high levels of lead in the soils they were grown in. Soil can be contaminated through particulate accumulation from lead in pipes, lead paint, and residual emissions from leaded gasoline.\n\nThe use of lead for water pipes is problematic in areas with soft or acidic water. Hard water forms insoluble layers in the pipes whereas soft and acidic water dissolves the lead pipes. Dissolved carbon dioxide in the carried water may result in the formation of soluble lead bicarbonate; oxygenated water may similarly dissolve lead as lead(II) hydroxide. Drinking such water, over time, can cause health problems due to the toxicity of the dissolved lead. The harder the water the more calcium bicarbonate and sulfate it will contain, and the more the inside of the pipes will be coated with a protective layer of lead carbonate or lead sulfate.\n\nIngestion of applied lead-based paint is the major source of exposure for children:\na direct source is chewing on old painted window sills. Alternatively, as the applied dry paint deteriorates, it peels, is pulverized into dust and then enters the body through hand-to-mouth contact or contaminated food, water, or alcohol. Ingesting certain home remedies may result in exposure to lead or its compounds.\n\nInhalation is the second major exposure pathway, affecting smokers and especially workers in lead-related occupations. Cigarette smoke contains, among other toxic substances, radioactive lead-210.\n\nSkin exposure may be significant for people working with organic lead compounds. The rate of skin absorption is lower for inorganic lead.\n\nTreatment for lead poisoning normally involves the administration of dimercaprol and succimer. Acute cases may require the use of disodium calcium edetate, the calcium chelate, and the disodium salt of ethylenediaminetetraacetic acid (EDTA). It has a greater affinity for lead than calcium, with the result that lead chelate is formed by exchange and excreted in the urine, leaving behind harmless calcium.\n\nThe extraction, production, use, and disposal of lead and its products have caused significant contamination of the Earth's soils and waters. Atmospheric emissions of lead were at their peak during the Industrial Revolution, and the leaded gasoline period in the second half of the twentieth century. Lead releases originate from natural sources (i.e., concentration of the naturally occurring lead), industrial production, incineration and recycling, and mobilization of previously buried lead. Elevated concentrations of lead persist in soils and sediments in post-industrial and urban areas; industrial emissions, including those arising from coal burning, continue in many parts of the world, particularly in the developing countries.\n\nLead can accumulate in soils, especially those with a high organic content, where it remains for hundreds to thousands of years. Environmental lead can compete with other metals found in and on plants surfaces potentially inhibiting photosynthesis and at high enough concentrations, negatively affecting plant growth and survival. Contamination of soils and plants can allow lead to ascend the food chain affecting microorganisms and animals. In animals, lead exhibits toxicity in many organs, damaging the nervous, renal, reproductive, hematopoietic, and cardiovascular systems after ingestion, inhalation, or skin absorption. Fish uptake lead from both water and sediment; bioaccumulation in the food chain poses a hazard to fish, birds, and sea mammals.\n\nAntropogenic lead includes lead from shot and sinkers. These are among the most potent sources of lead contamination along with lead production sites. Lead was banned for shot and sinkers in the United States in 2017, although that ban was only effective for a month, and a similar ban is being considered in the European Union.\n\nAnalytical methods for the determination of lead in the environment include spectrophotometry, X-ray fluorescence, atomic spectroscopy and electrochemical methods. A specific ion-selective electrode has been developed based on the ionophore S,S'-methylenebis(N,N-diisobutyldithiocarbamate). An important biomarker assay for lead poisoning is δ-aminolevulinic acid levels in plasma, serum, and urine.\n\nBy the mid-1980s, there was significant decline in the use of lead in industry. In the United States, environmental regulations reduced or eliminated the use of lead in non-battery products, including gasoline, paints, solders, and water systems. Particulate control devices were installed in coal-fired power plants to capture lead emissions. Lead use was further curtailed by the European Union's 2003 Restriction of Hazardous Substances Directive. A large drop in lead deposition occurred in the Netherlands after the 1993 national ban on use of lead shot for hunting and sport shooting: from 230 tonnes in 1990 to 47.5 tonnes in 1995.\n\nIn the United States, the permissible exposure limit for lead in the workplace, comprising metallic lead, inorganic lead compounds, and lead soaps, was set at 50 μg/m over an 8-hour workday, and the blood lead level limit at 5 μg per 100 g of blood in 2012. Lead may still be found in harmful quantities in stoneware, vinyl (such as that used for tubing and the insulation of electrical cords), and Chinese brass. Old houses may still contain lead paint. White lead paint has been withdrawn from sale in industrialized countries, but specialized uses of other pigments such as yellow lead chromate remain. Stripping old paint by sanding produces dust which can be inhaled. Lead abatement programs have been mandated by some authorities in properties where young children live.\n\nLead waste, depending on the jurisdiction and the nature of the waste, may be treated as household waste (in order to facilitate lead abatement activities), or potentially hazardous waste requiring specialized treatment or storage. Lead is released to the wildlife in shooting places and a number of lead management practices, such as stewardship of the environment and reduced public scrutiny, have been developed to counter the lead contamination. Lead migration can be enhanced in acidic soils; to counter that, it is advised soils be treated with lime to neutralize the soils and prevent leaching of lead.\n\nResearch has been conducted on how to remove lead from biosystems by biological means: Fish bones are being researched for their ability to bioremediate lead in contaminated soil. The fungus \"Aspergillus versicolor\" is effective at removing lead ions. Several bacteria have been researched for their ability to remove lead from the environment, including the sulfate-reducing bacteria \"Desulfovibrio\" and \"Desulfotomaculum\", both of which are highly effective in aqueous solutions.\n\n\n\n"}
{"id": "6697721", "url": "https://en.wikipedia.org/wiki?curid=6697721", "title": "List of battery types", "text": "List of battery types\n\nThis page is a list of notable battery types grouped by types of battery.\n\n"}
{"id": "41974096", "url": "https://en.wikipedia.org/wiki?curid=41974096", "title": "Lom Pangar Dam", "text": "Lom Pangar Dam\n\nThe Lom Pangar Dam is an embankment dam with a center gravity dam section currently under construction on the Lom River about north of Bertoua in the East Region of Cameroon. It is located about downstream of the Lom River's confluence with the Pangar River and about upstream of where the Lom joins the Sanaga River. The purpose of the dam is to produce hydroelectric power and to regulate water flows along the Sanaga River. It is potentially part of a larger dam cascade on the Sanaga. \n\nThe African Development Bank issued a US$71.1 million loan for the project in November 2011. The World Bank also approved a US$132 million loan March 2012 and the President of Cameroon, Paul Biya, laid the foundation stone for the dam on 3 August 2012. The European Investment Bank approved a US$39 million loan in October of the same year. China International Water & Electric Corporation is constructing the dam and power plant. A coffer dam to divert the river around the dam foundation was completed in July 2013. The project is expected to be complete in March 2016.\n\n"}
{"id": "38866088", "url": "https://en.wikipedia.org/wiki?curid=38866088", "title": "Mahindra Susten", "text": "Mahindra Susten\n\nMahindra Susten Pvt. Ltd., formerly Mahindra EPC Services Pvt. Ltd. , is part of the USD 19 billion Mahindra Group. A portfolio company under the Cleantech arm of Mahindra Partners, they offer solar solutions spanning On-Grid solutions, EPC (Engineering, Procurement and Construction) and Off-Grid Product solutions.\n\nIn April 2013, Mahindra EPC had its 20 MW solar power project at Bikaner enlisted in the Ministry of New and Renewable Energy's - MNRE (India) merit list for early commissioning for Phase I, Batch II of the National Solar Mission.\n\nOn 2 February 2015, the company was renamed Mahindra Susten. Susten is derived from the words - Sustainability and Enabler.\n\nThe company commenced its services in the year 2011 by making a beginning in the renewable energy space with the turnkey execution of Utility scale, commercial & industrial rooftop Solar PV projects.\n\nIn 2011, the company received the highest CRISIL- MNRE rating of SP1A for off-grid solar PV system.\nThe company has further diversified its business into the telecom tower solarization segment, to provide solar power to towers, which are presently run on diesel.\n\nMahindra Susten has also been named the Utility Solar EPC of the year for 2014 and 2015 by Bridge to India.\n\nWith a cumulative figure of 2449MWp under various stages of execution we are the leading player in the Indian solar energy sector.\n\nMahindra Susten built utility scale and distributed solar PV plants for several notable clients including Softbank, SunEdison, Infosys, JK Tyres, Tech Mahindra and several other notable names. Project sizes vary from 1MWp right up to 250 MWp, across over 20 states in India, with overseas projects in the middle east and Southeast Asia. Some projects include -\n\nMahindra EPC in November 2013, finished installation of a 3.18 MWp solar PV power plant for an Auto Consortium in the state of Tamil Nadu. With an estimated total project capacity of 50 MWp, this group of India's seven leading auto component manufacturers have pledged an investment of over INR 3.25 billion for captive consumption of clean energy.\n\nComprising two separate projects of 10 MW and 20 MW, this installation under the second batch of Phase I of the Jawaharlal Nehru National Solar Mission (JNNSM), was commissioned in February 2013. With an annual generation in excess of 50 million units of energy this installation is expected to generate a carbon offset of nearly 40,000 MT CO annually.\n\nIn January 2013, Mahindra EPC commissioned their 20 MW plant near Bikaner which was then the first installation to have been completed under the Indian government’s JNNSM Phase 1 Batch 2 (JNNSM) initiative. The project utilizes a total of 270,000 thin-film PV modules supplied by First Solar.Spread across an area of 180 acres, the 20MWp solar PV plant is equipped to supply more than 38 million units of energy per year and is expected to displace nearly 30,000 MT of CO annually.\n\nNear Jodhpur, this 5 MW installation holds the distinction of generating a high output per MW with its single axis tracker technology that maximises energy from the sun. Under the Indian government’s Jawaharlal Nehru National Solar Mission (JNNSM) Phase 1 Batch 1 initiative, the plant was the first to get connected to the state’s electrical grid, having been commissioned in January 2012, under 100 days.\n\nThe plant at Lucknow was the first megawatt-scale installation in Uttar Pradesh (northern India), and was connected to the grid in January 2012, with a construction period of 71 days.\n\nThe plant at Hyderabad, was commissioned in just 3 months after its erection. It was commissioned on September 30, 2013. This plant is erected at an expanse of 13 acres land with Heritage foods being client.\n\nThis 6.91 MW plant which started on 15 September near Bap, Rajasthan was commissioned within 5 months.\n\nMahindra Susten has developed a suite of products aimed at increasing the efficiency and throughputs of Solar PV plants across all scales. The most well known product from the company is the MSAT100 solar tracker.\n\nMahindra Susten has been recognised by various independent bodies in renewable energy including -\n\n"}
{"id": "42693399", "url": "https://en.wikipedia.org/wiki?curid=42693399", "title": "Oil Sands Karaoke", "text": "Oil Sands Karaoke\n\nOil Sands Karaoke is a 2013 feature documentary film directed by Charles Wilkinson. The film follows five people working in or around the infamous oil sands of Northern Alberta as they compete in a karaoke contest held at local watering hole Bailey's Pub. The film was produced by Wilkinson and Tina Schliessler, and executive produced by Kevin Eastwood and Knowledge Network's Murray Battle.\n\nAlberta's oil sands project has been called the single most destructive industrial project in human history. \"Oil Sands Karaoke\" focuses on the people who live and work around the oil sands project, whose voices are rarely heard in the debates about the economic value and environmental cost of the project.\n\nAs the five featured workers progress through the stages of the karaoke contest, singing pop favourites from Creedence Clearwater Revival to Britney Spears, they explain through interviews how and why they came to work in the oil industry, and how it has impacted their lives. Some are dismissive of the opinions of \"environmentalists\". Others say they are aware of the destructive impact that the oil industry has on the environment, but without the lucrative salaries available from the oil companies, their debts and financial obligations would be too much to bear. All feel that singing helps relieve the stress of long hours working heavy equipment, or the loneliness of living in a remote industrial town.\n\nDirector Wilkinson believes the vicious tone of the debate over the oil sands has precluded any meaningful discussion. \"There's so much shouting that we don't talk,\" he says. \"...there are human beings involved. We need to talk about this stuff, but we should maybe try to be a bit more polite with each other.\"\n\nDan Debrabandre works as a haul truck driver. The mining truck that he drives, a Caterpillar 797, is one of the biggest motorized vehicles ever invented and can hold up to 500 tons of bitumen-laced dirt. Prior to working in the oil sands, Dan pursued a career as a country singer, but family and financial obligations made him give up on his recording dreams. Dan says he is grateful for all the financial and emotional support his friends and family gave him while he worked on his music, and part of the reason he works a lucrative oil sands job is to pay them back.\n\nBrandy Willier is another haul truck operator from idyllic High Prairie, Alberta. When Brandy was young, she lived on a first nations reserve with her parents, developing a love of singing from listening to her father play guitar. However, Brandy's father died when she was only seven which began a long period of struggle and instability for her and her mother. She credits her truck driving job with giving her life stability, although she finds Fort McMurray to be a lonely place.\n\nMassey Whiteknife is a First Nations entrepreneur who owns the multimillion-dollar ICEIS group of companies in Alberta. Iceis Rain is Massey's alter-ego, a drag queen in thigh-high boots who belts out a memorable cover of \"Purple Rain\". Iceis came to life as part of Massey's recovery from dissociative post-traumatic stress disorder, which he suffered due to violence and abuse in his childhood and teens. Massey believes he was the first gay man to come out in blue-collar Fort McMurray, and his company now sponsors multiple charitable programs, including a drag show, to combat bullying and homophobia.\n\nChad Ellis works in the Suncor plant as a scaffolder. A talented entertainer, he dreams of becoming a full-time singer but realizes that he has to make a secure living somehow. As a child, Chad's religious family prompted him to sing in their church choir. When he was older, he recorded in a basement studio, and eventually began performing opening acts for singers such as Tone Loc. He stopped performing and moved to Fort McMurray after a violent conflict with a partner's ex-boyfriend. He now sings in the local karaoke scene for fun.\n\nJason Sauchuk is a soft-spoken fan of videogames who trained as a computer programmer, but joined his father in the heavy equipment industry after school. While working with his father, he incurred debt supporting a girlfriend with children. His partner turned out to be unfaithful and they separated, and company layoffs cost him his previous job. Now he works as a haul truck driver, a job lucrative enough to help him dig himself out of debt.\n\n\"Oil Sands Karaoke\" had its world premiere on April 26, 2013 at Hot Docs Canadian International Documentary Festival in Toronto. The Western Canadian premiere took place at The Vancouver International Film Festival on October 4, 2013.\n\nThe film also screened at the Calgary International Film Festival, Yorkton Film Festival, Fort Lauderdale International Film Festival, and Available Light Film Festival and had a limited theatrical run in Fort McMurray, Vancouver, Toronto, Ottawa, Winnipeg, and Regina.\n\n\"Oil Sands Karaoke\" had its television broadcast premiere on May 6, 2014 on Knowledge Network. The film had its Ontario broadcast premiere on January 21, 2015 on TVOntario.\n\nThe film was received favourably by several notable documentary critics:\n\nMarsha Lederman of \"The Globe and Mail\" wrote: \"Poignant and beautifully shot, the film takes pains not to judge as it paints a dignified portraits of the boom town and the workers\".\nKatherine Monk wrote in the Vancouver Sun that it has “All the suspense of The Voice, all the emotional conflict of American Idol and all the beauty of The Road.”\nGreg Klymkiw named it one of his Hot Docs Hot Picks for 2013, and called it \"a thing of genuine beauty...quite unlike any documentary about the environment that you'll ever see.\"\nNicholas Gergesha of Point of View Magazine wrote \"...filmmakers Charles Wilkinson and Tina Schliessler generate a meaningful and multifaceted discussion about the environment, the economy and the often-ignored human element in a destructive industry.\"\nThe Huffington Post's Sarah Kurchak lauds Wilkinson as \"a filmmaker dedicated to pushing past all of the misinformation and rhetoric surrounding environmental issues and getting to the heart of the matter...\"\n\nAt the 2014 Yorkton Film Festival, the film received two Golden Sheaf Awards: Best Documentary (Science/Nature/Technology), and Best Director (Non-Fiction).\n\n"}
{"id": "40711344", "url": "https://en.wikipedia.org/wiki?curid=40711344", "title": "Otmar Ebenhoech", "text": "Otmar Ebenhoech\n\nOtmar Ebenhoech is most noted for being the inventor of the Zilla Motor Controller for electric cars. Widely regarded as the most powerful motor controller for electric cars, Otmar's Zilla motor controller has been used in most of the world's fastest electric vehicles.\n\nEbenhoech is a self-taught electrical engineer with more than 25 years of power electronics experience.\n\n"}
{"id": "35280999", "url": "https://en.wikipedia.org/wiki?curid=35280999", "title": "Perovo Solar Park", "text": "Perovo Solar Park\n\nThe Perovo Solar Park is a 100 MWp photovoltaic power station located at Perovo, Simferopol Raion, Crimea. As of July 2012 it is the world's fourth-largest solar farm, and is made up of 440,000 solar panels. It is owned by Activ Solar, and the final 20 MW stage was completed on December 29, 2011.\n\nIn 2009, Ukraine established a feed-in tariff of €0.46 per kilowatt hour until 2030, one of the highest.\n\n"}
{"id": "2451775", "url": "https://en.wikipedia.org/wiki?curid=2451775", "title": "Plutonium(IV) oxide", "text": "Plutonium(IV) oxide\n\nPlutonium(IV) oxide is the chemical compound with the formula PuO. This high melting-point solid is a principal compound of plutonium. It can vary in color from yellow to olive green, depending on the particle size, temperature and method of production.\n\nPuO crystallizes in the fluorite motif, with the Pu centers organized in a face-centered cubic array and oxide ions occupying tetrahedral holes. PuO owes its utility as a nuclear fuel to the fact that vacancies in the octahedral holes allows room for fission products. In nuclear fission, one atom of plutonium splits into two. The vacancy of the octahedral holes provides room for the new product and allows the PuO monolith to retain its structural integrity.\n\nPlutonium dioxide is a stable ceramic material with an extremely low solubility in water and with a high melting point (2,744 °C). The melting point was revised upwards in 2011 by several hundred degrees, based on evidence from rapid laser melting studies which avoid contamination by any container material.\n\nDue to the radioactive alpha decay of plutonium, PuO is warm to the touch. As with all plutonium compounds, it is subject to control under the Nuclear Non-Proliferation Treaty.\n\nPlutonium metal spontaneously oxidizes to PuO in an atmosphere of oxygen. Plutonium dioxide is mainly produced by calcination of plutonium(IV) oxalate, Pu(CO)·6HO, at 300 °C. Plutonium oxalate is obtained during the reprocessing of nuclear fuel as plutonium is dissolved in HNO/HF. Plutonium dioxide can also be recovered from molten-salt breeder reactors by adding sodium carbonate to the fuel salt after any remaining uranium is removed from the salt as its hexafluoride.\n\nPuO, along with UO, is used in MOX fuels for nuclear reactors. Plutonium-238 dioxide is used as fuel for several deep-space spacecraft such as the 'New Horizons' Pluto probe as well as in the Curiosity rover on Mars. The isotope decays by emitting α-particles, which then generate heat (see radioisotope thermoelectric generator). There have been concerns that an accidental re-entry into Earth's atmosphere from orbit might lead to the break-up and/or burn-up of a spacecraft, resulting in the dispersal of the plutonium, either over a large tract of the planetary surface or within the upper atmosphere. However, although at least two spacecraft carrying PuO RTGs have reentered the Earth's atmosphere and burned up (Nimbus B-1 in May 1968 and the Apollo 13 Lunar Module in April 1970), the RTGs from both spacecraft survived reentry and impact intact, and no environmental contamination was noted in either instance; in any case, RTGs since the mid-1960s have been designed to remain intact in the event of reentry and impact, following the 1964 launch failure of Transit 5-BN-3 (the early-generation plutonium-metal RTG on board disintegrated upon reentry and dispersed radioactive material into the atmosphere north of Madagascar, prompting a redesign of all U.S. RTGs then in use or under development).\n\nPhysicist Peter Zimmerman, following up a suggestion by Ted Taylor, demonstrated that a low-yield (1-kiloton) nuclear weapon could be made relatively easily from plutonium oxide. A plutonium-oxide bomb would have a considerably larger critical mass than one made from plutonium metal (almost three times larger, even with the oxide at maximum crystal density; if the oxide were in powder form, as is often encountered, the critical mass would be much higher still), due both to the lower density of plutonium in PuO compared with plutonium metal and to the added inert mass of the oxygen contained.\n\nThe behavior of plutonium oxide in the body varies with the way in which it is taken. Since it is insoluble, when ingested, a very large percentage of it will be eliminated from the body quite rapidly in body wastes.\nIn particulate form, plutonium oxide at a particle size less than 10 micrometers (0.01 mm) is toxic if inhaled, due to its alpha-emission.\n\n\n"}
{"id": "7535882", "url": "https://en.wikipedia.org/wiki?curid=7535882", "title": "Precycling", "text": "Precycling\n\nPrecycling is the practice of reducing waste by attempting to avoid bringing items which will generate waste into home or business. The U.S. Environmental Protection Agency (EPA) also cites that precycling is the preferred method of integrated solid waste management because it cuts waste at its source and therefore trash is eliminated before it is created. According to the EPA, precycling is also characterized as a decision-making process on the behalf of the consumer because it involves making informed judgments regarding a product’s waste implications. The implications that are taken into consideration by the consumer include: whether a product is reusable, durable, or repairable; made from renewable or non-renewable resources; over-packaged; and whether or not the container is reusable.\n\nPrecycling has the ability to build industrial, social, environmental, and economic circumstances that allow for old products to be converted into new resources \nThe concept of ‘precycling’ was coined in 1988 by social marketing executive Maureen O’Rorke in a public waste education campaign for the City of Berkeley.\nThe application of precycling is not limited to large corporations, but can be administered on smaller scales in local communities. The reason precycling is effective on large scales and on small scales stems from the idea that it shares a common language between experts and non-experts, buyers and sellers, economists and environmentalists. However, it is important to consider that waste prevention systems, such as precycling, require the collaborative effort from several working parts. These parts include prevention targets, producer responsibility, householder charging, funding for pilot projects, public involvement, engagement of private and third sectors, and public campaigns that spread awareness.\n\nThe original three-pronged push for waste management is \"Reduce, Reuse, Recycle.\" Precycling emphasizes \"reducing and reusing\", while harnessing and questioning the momentum and popularity of the term \"recycle.\" In addition to this strategy, precycling incorporates four supplementary R’s: Repair, Recondition, Remanufacture and Refuse. Waste is a resource that can be reused, recycled, recovered, or treated. Precycling differs from other singular forms of waste prevention because it encompasses not one behavior, but many.\n\nReduce is a form of precycling that allows for the preservation of natural resources and also saves money on behalf of the manufacturer, the consumer, and the waste manager. Moreover, effective source reduction slows the depletion of environmental resources, prolongs the life of waste management facilities, and makes combustion and landfills safer by removing toxic waste components.\n\nReuse is a form of precycling that reinvents items after their initial life and avoids creating additional waste.\n\nAlthough precycling harnesses the familiarity of the term recycling, it is still important to note the difference between recycling and prevention. Since precycling focuses on the prevention of waste production, this entails that measures are taken before a substance, material, or product has become waste. Whereas recycling is a type of precycling that involves taking action before existing waste is abandoned to nature. Recycling is a process where discarded materials are collected, sorted, processed, and used in the production of new products. Every time a person engages in the act of recycling, they help increase the market and bring the cost down. However, current research from the American Plastics Council states that only 25% of the nation’s recycling capabilities are being utilized.\n\nTraditionally recycling requires large amounts of energy to \"melt down\" and then re-manufacture items. While this may cut down on the amount of trash that is going into landfills, it is not sustainable unless the underlying energy supply is sustainable. In addition, recycling often means downcycling and always involves at least some loss of the original material, so primary extraction is still required to make up the difference. Precycling reduces these problems by using less material in the first place, so less has to be recycled.\n\nRepair is a type of precycling that corrects specified faults in a product, however the quality of a repaired product is inferior to reconditioned or remanufactured items. One survey found that 68% of the respondents believed repairing was not cost efficient and sought alternative methods such as reconditioning or remanufacturing.\n\nReconditioning is a type of precycling that requires the rebuilding of major components to restore a product’s working condition, which is expected to be inferior to the original product.\n\nRemanufacturing is another type of precycling that involves the greatest degree of work content, which results in superior quality of the product. In order to remanufacture a product, it requires a total dismantling of the product and the subsequent restoration and replacement of its parts. Remanufacturing is a preferred method of waste reduction compared to repairing and reconditioning because it preserves the embodied energy that has been used to shape the components of a product for their first life and it only requires 20-25% of the initial energy used in formation.\n\nRefusal to buy certain products due to detrimental impacts on the environment or wasteful packaging is another type of precycling because the rejection of such items paves the way for products that can be reduced, reused, or recycled.\n\nA zero waste approach aims to prevent rather than just reduce accumulated waste. Zero-waste goes beyond recycling to include the whole system, which includes the flow of resources and waste through human society. This “design principle” works to maximize recycling, minimize waste, reduce consumption and ensures that products are reused, repaired or recycled back into nature or the market. This preventative approach is more manageable and effective than incremental approaches that focus on gradually reducing the amount of impact because it is less complex and contains less information, which permits wider public participation.\n\nIn regards to sustainability, the term itself is often associated with resource constraints and maintenance of the status quo rather than growth and prosperity. However, with the implementation of a zero-waste management strategy, sustainable practices can push the status quo in order to create a society that is capable of development, technically and culturally advanced, dynamic in population and production, thoughtful with the use of non-renewable resources, and diverse, democratic, and challenging.\n\nIncreased waste production is often negatively associated with increased economic growth. However, a zero-waste management strategy allows for economic growth that works cohesively with sustainability rather than against it. The implementation of a zero-waste strategy is part of an economic goal-set that aims to create a circular economy. A circular economy refers to a closed-loop socio-economic system that focuses on minimizing wastes while simultaneously maximizing stocks of resources for the economy. This closed-loop design diverts linear (open-loop) waste disposal streams into new raw material streams.\n\nIn a circular economy, one way to minimize waste is through the employment of precycling insurance, which allows for a full range of financed waste prevention opportunities. This type of insurance would set premiums related to the risk of a product ending up as waste, and these premiums would serve to fund actions concerning waste prevention. When establishing a premium for precycling insurance several factors need to calculated: recyclability or biodegradability; provision of infrastructure, habitat or collaborations for the generation of the product from new resources; the ecosystem concentrations of product components above natural levels. The idea of precycling insurance is plausible considering the aim of insurance industries is to avoid losses rather than paying for losses. However, in order for this idea to work, private and third sectors need to be involved and engaged in the issue. In this instance, a third sector refers to small charities and a handful of societal enterprises that coordinate with charity shops.\n\nAccording to the “Extended Producer Responsibility” principle, impacts are substantially determined at the point of design where key decisions are made on materials, production process, and how products are used and disposed of at the end of life-cycle, which falls on the producer. However, in a circular economy there is the recognition that nature’s capacity needs to be maximized through the reprocess of biodegradable wastes produced by industries and human activity. This task is accomplished through the procurement and funding of precycling insurance premiums that invest in systematic preservation of endangered habitats, careful harvesting of biological resources and expansions of productive ecosystems. Additionally, in terms of climate change, precycling insurance offers a flexible alternative to the binding limits on greenhouse gas emissions and international taxation on mineral fuels. In terms of waste management systems, the environment benefits from the reparation of products to the greatest degree because less energy is required and the majority of the original material is kept intact.\n\nThe social structure operating under a circular economy is referred to as a circular society. The aim of a circular society is to create a cooperative culture by means of problem-prevention, resource-availability and fuller participation, with reference to precycling. One critique of this approach, in terms of waste management, is that it is difficult to maintain a cooperative culture within a society because it is constantly evolving and changing.\n\nThere is an increasing public awareness on the need for sustainable production and consumption. One campaign that aimed at raising awareness of precycling focused on whether people’s self-reported behaviors were affected by exposure to precycling advertisements on the radio, television, or in-store flyers. The researchers concluded that the most effective results stemmed from the inclusion of social rewards that invoke an intrinsic motivation to engage in precycling behaviors.\n\nAnother way to raise awareness is through statistics that highlight the potential impacts that can be achieved through waste prevention. For instance, if 70 million Americans bought a half-gallon plastic-coated carton container of milk each week (instead of two quarts), then 41.6 million pounds of paper discards and 5.7 pounds of plastic discards would be reduced annually. This transition from two quarts to a half-gallon would save $145.6 million on packaging each year.\n\nIn order to effectively implement precycling practices and behaviors, the public needs to feel \"enabled\", \"engaged\", \"encouraged\", and \"exemplified\" in their efforts to partake in precycling.\n\nNot only can the average consumer practice precycling, but industries can also participate. Purchasing from parts suppliers, reuse of chemicals, and reduction of unnecessary packaging are some methods. There are some companies and countries that have taken it upon themselves to implement more sustainable practices that align with precycling principles. For instance, Fonterra reduced its packaging through the implementation of bulking, reuse and redesign. Further, Waste Management New Zealand created Recycle New Zealand, which provided a subsidiary focusing on the collection of materials that could be diverted and sorted prior to the operations of reducing, recycling, or recovering. Moving forward, free-trade organizations can further implement precycling practices by exploring this strategy as a new way to reduce regulations and to promote greater industrial freedom of choice.\n\nMoreover, the individual consumer can develop precycling habits by engaging in the following practices and behaviors:\n\nEnviro-shopping is considered shopping with the environment and implements a precycling strategy: \n\nProducts to choose from in accordance with precycling principles:\n\nIn addition to shopping practices that implement precycling principles, there are also behaviors that can be undertaken to prevent waste: \n"}
{"id": "32270185", "url": "https://en.wikipedia.org/wiki?curid=32270185", "title": "Psychic numbing", "text": "Psychic numbing\n\nPsychic numbing is a tendency for individuals or societies to withdraw attention from past experiences that were traumatic, or from future threats that are perceived to have massive consequences but low probability. Psychic numbing can be a response to threats as diverse as financial and economic collapse, the risk of nuclear weapon detonations, pandemics, and global warming. It is also important to consider the neuroscience behind the phenomenon, which gives validation to the observable human behavior. The term has evolved to include both societies as well as individuals, so psychic numbing can be viewed from either a collectivist or an individualist standpoint. Individualist psychic numbing is found in victims of rape and people who suffer from post-traumatic stress disorder.\n\nThe original concept of psychic numbing argued by Robert Jay Lifton was that it manifests itself collectively. This means that a society or a culture adapts this withdrawn attention outlook and collectively applies it to current issues.\n\nLifton's 4 Focal Points:\n\n\nLifton's main area of focus was the Hiroshima bombing during World War II. He broke up his analysis of the bombing into psychological stages that spread at the societal level. Lifton's article, \"Beyond Psychic Numbing: A Call to Awareness\", addressed a concern that was new at the time: nuclear warfare. He argued now that there is a single weapon in the world that can cause so much damage, humans need to be more alert and confront the images of nuclear power and an ever increasing nuclear actuality. There is a societal understanding now that countries can create nuclear weapons; this led to Lifton's coining of the term \"nuclear fundamentalism\".\n\nAll these are argued by Lifton to be beneficial at times, however rather inadequate for helping people feel better about the ubiquity of nuclear weapons and potential warfare. There needs to be a sense of control in order to comprehend the consequences of nuclear warfare as well as strategies to combat the psychological grip it has on individuals.\n\nLifton's final argument regarding hope for the future is that society must take action. He uses Vietnam veterans as a reference point. He has worked with them before and noticed partial changes, while he agrees this is good, society must adapt an awareness that aims to teach and educate as opposed to avoid and withdraw from the potential threats to survival.\n\nPsychic numbing has been associated with post-traumatic stress disorder (PTSD) because they share the same attributes of withdrawal and behavioral changes when presented with a stimuli that triggers a reminder of the traumatic event or with a very intense neutral stimuli. The observable emotional response is not enough to understand the concept of psychic numbing. Therefore, neuroscience and the biological activity that occurs within the brain is employed to give people a better understanding of the thought process of individuals who engage in psychic numbing.\n\nStudies have also focused on the habituation of the rostral anterior cingulate cortex (rACC). The rACC is part of the limbic system, which is responsible for emotional processing. It is hypothesized that the rACC determines the, \"correct allocation of attention based resources to emotionally aversive stimuli\". This means it may play an active role in identifying important behavioral responses necessary to comprehend the consequences of the aversive stimuli. The limbic system also includes areas that are important for memory consolidation. The relationship between all the areas in the limbic system is an area of interest for psychic numbing because it encapsulates two factors that contribute to the phenomenon: emotions and memory. \nThese studies are also a good paradigm for the understanding of psychic numbing because they considers sustained aversive material and how the brain reacts in a habitual manner in an effort to remove the underlying emotional content.\n\nCortisol helps regulate the stress response via the negative feedback loop, which are activated when a person is subjected to specific situations that trigger the relationship between the emotionally charged memories of the traumatic event and the observable autonomic responses.\n\nStress can also be considered a brain-body reaction due to external or internal cues this can include the environment as well as memory. The areas of the brain that communicate with one another are the prefrontal cortex, amygdala, hippocampus, nucleus accumbens, and the hypothalamus. Through a series of feedback processes, the release of specific neurotransmitters as well as neuromodulators occurs.\n\nNorepinephrine (NE) is released by the Locus coeruleus, it is then transferred to the limbic system where much of the memory consolidation and fight or flight responses are facilitated.\n\nAdrenocorticotropin (ACTH) is released from the anterior pituitary, which triggers the release of glucocorticoids from the adrenals. The chronic exposure to stress affects organisms that deal with daily activities and it also interferes with one's coping mechanisms.\n\nOnce the HPA axis is activated, it triggers an increase in glucocorticoids. Once these hormones cross the blood–brain barrier, they interact with other neurotransmitters and change the brain's chemistry as well as structure.\n\nThe process of habituation is important to consider because it is a prevalent variable in the phenomenon of psychic numbing. The constant exposure a society or individual has to a prolonged and sustained aversive stimuli, the emotional magnitude that the stimuli has decreases greatly over time to where it becomes unnoticeable to those who have been surrounded by it for a long period of time. This type of response is seen in Vietnam veterans and rape victims who suffer from PTSD.\n\nAdditionally, studies describe the importance of the rACC and the cingulate cortex for comprehension and the feeling of a painful stimulus. Taiwanese and American researchers recorded brain-wave readings from participants as the researchers observed body parts pricked with a pin, or dabbed with a Q-tip. Half of the subjects were physicians and the other half was a control group. The control group showed clear differences in his or her reactions to the pin-prick in comparison to the Q-tip. The physicians, who previously had experience managing sickness and pain, did not. The authors of the study theorized that the physicians unconsciously numbed their reaction to the pain of the pin-prick due to his or her profession. This may be a beneficial result because physicians need to block out the pain response and use more cognitive resources necessary for being of assistance in a time of need. This further suggests the individual differences people have in regards to psychic numbing and the deviation away from more tragic accounts of rape and PTSD. This type of desensitization is not independent of the participant's lives, instead it is a result of years of experience woven into his or her daily lives, resulting in a numbed response. Figures of areas of the control group's brains showed activation in the rACC, and the physician's brains did not, suggesting there was already habituation.\n\nThe original view of psychic numbing dealt with human extinction and the mass response to potentially life-threatening scenarios. Lifton argued the worry for these events was low and therefore generated an equally low probability of occurrence point of view. This repeated exposure makes humans numb to the possibility that an event of that nature can occur. However, when asked to recall the probability that mass extinction will occur, people have a tendency to think counter-intuitively and rate the probability as high when it is in fact low and behaviorally respond opposite to his or her rating.\n\nAdditionally, much of the individualist view comes from studying the behavioral traits of people who suffer from PTSD. Focus groups, clinical cases, as well as religion play a crucial role in one's ability to cope with the stress of traumatic stimuli. Many studies have been conducted that address the value of these therapeutic interventions as well as their efficacy. There is a strong connection to depersonalization, emotional numbing, as well as dissociation from one's identity. This shows the shift of psychic numbing from a collectivist view to an individualistic view.\n\nRobert Jay Lifton spearheaded the psychic numbing movement and his concentration was on a much larger scale. Psychic numbing is about the way a culture or society withdraws from issues that would otherwise be too overwhelming for the human mind to comprehend. In this respect, psychic numbing is a societal reaction to impending doom, chaos, and ultimately mankind's extinction.\n\nPaul Slovic, a prominent psychologist in the realm of risk, maintains the original interpretation posited by Lifton. Slovic's article, \"Psychic Numbing and Mass Atrocity\", returns to the collectivist model and most notably confronts the value of saving a human's life. The figures to the right denote both arguments for the hypothesized value of saving a human's life as well as the true value of saving a human's life established through Slovic's empirical research.\nSlovic introduced the concept of \"psychophysical numbing\", which is the diminished sensitivity to the value of life and an inability to appreciate loss. Essentially, the \"proportion\" of lives saved is more important than the \"number\" of lives saved. One of Slovic's arguments for this outcome is that people suffer from innumeracy and cannot comprehend the emotional connotation associated with large numbers. The threshold, as stated by Slovic, where people cannot comprehend the emotional magnitude of the loss of life is two, as shown in the figure.\n\nSlovic also points to Weber's law, which states the difference between two stimuli is proportional to the magnitude of the stimuli. Additionally, Weber's law focuses on the just-noticeable difference between the two stimuli. Slovic addressed Weber's law from a different context - he considered the magnitude and value of a human life. Slovic took Weber's law and incorporated prospect theory, which is decision making based on potential gains and losses, not the actual final outcome. Slovic found that when prospect theory and Weber's law are analyzed in regards to human life, the value of saving human lives is greater for a smaller tragedy than for a larger one.\n\nThese are all considered collectivist views of psychic numbing because they encapsulate a general theory of mind held by the majority of citizens in a society. Additionally, these views remain consistent with the original concept of which collective avoidance and attention withdrawal becomes the active state of mind in regards to potential threats of mass extinction.\n\nPsychic numbing, as it shifts away from the collectivist view, is a common characteristic of people who suffer from PTSD. A general definition of psychic numbing is a diminished response to the external world. There are three elements that attribute to psychic numbing: \nThese two mechanisms promote the inability to engage emotionally with a traumatic memory (acceptance), thus impairing the process of recovery.\n\nSusan Gill bridges the disciplines of social psychology and neuropsychology in her analysis of psychic numbing by explaining that there are notable behavioral changes, the most typical trait is being zombie-like and in a \"dead-zone\".\n\n\n\nReligion is also considered to be an internalized coping mechanism. The role of religious values in coping with life-threatening illnesses is another individualistic trait that people use to cope with the behavioral side-effects associated with the diseases. Depersonalization is a very prominent behavioral trait associated with cancer patients. Findings show that people with cancer cope no worse than non-cancer patients. Cancer patients tend to blunt his or her experiences as a means of handling a painful reality. Avoidance and denial are typical tendencies of psychic numbing. Cancer patients also report a self-distancing mechanism, and take on a third-person perspective as a means of dealing with the life-threatening disease. It is argued that putting one's life within a framework of religion is a very important part of the coping process. This religious framework helps the patients understand that some things are out of one's control. As discussed earlier, a lack of control over one's stressful stimuli generates a degree of psychic numbing. However, by putting his or her life-threatening disease within a religious framework takes the mystery out of the disease and adds a sense of control. As discussed earlier, the perceived sense of control as well as actual control are important contributors to adequately coping with psychic numbing.\n\nAs described earlier, research on psychic numbing has suggested that people who become desensitized to suffering may be more adept in dealing with an upsetting or dangerous situation.\n\nMany individuals fail to react affectively to the overwhelming threat of annihilation by nuclear warfare, and in 1987 Thomas C. Wear termed this \"nuclear denial disorder\", a type of psychic numbing. It involves the over-use of a denial defense mechanism, and \"an apathetic business-as-usual attitude toward the threat of nuclear annihilation\".\n"}
{"id": "164318", "url": "https://en.wikipedia.org/wiki?curid=164318", "title": "Quasi-biennial oscillation", "text": "Quasi-biennial oscillation\n\nThe quasi-biennial oscillation (QBO) is a quasiperiodic oscillation of the equatorial zonal wind between easterlies and westerlies in the tropical stratosphere with a mean period of 28 to 29 months. The alternating wind regimes develop at the top of the lower stratosphere and propagate downwards at about per month until they are dissipated at the tropical tropopause. Downward motion of the easterlies is usually more irregular than that of the westerlies. The amplitude of the easterly phase is about twice as strong as that of the westerly phase. At the top of the vertical QBO domain, easterlies dominate, while at the bottom, westerlies are more likely to be found. At the 30mb level, with regards to monthly mean zonal winds, the strongest recorded easterly was 29.55 m/s in November 2005, while the strongest recorded westerly was only 15.62 m/s in June 1995.\n\nIn 1883, the eruption of Krakatoa led to visual tracking of subsequent volcanic ash in the stratosphere. This visual tracking led to the discovery of easterly winds between 25 and 30 km above the surface. The winds were then called the Krakatau easterlies. In 1908, data balloons launched above Lake Victoria in Africa recorded westerly winds in the stratospheric levels of the atmosphere. These findings, at the time, were thought to contradict the 1883 findings. However, the winds that would become known as the QBO were discovered to oscillate between westerly and easterly in the 1950s by researchers at the UK Meteorological Office. The cause of these QBO winds remained unclear for some time. Radiosonde soundings showed that its phase was not related to the annual cycle, as is the case for many other stratospheric circulation patterns. In the 1970s it was recognized by Richard Lindzen and James Holton that the periodic wind reversal was driven by atmospheric waves emanating from the tropical troposphere that travel upwards and are dissipated in the stratosphere by radiative cooling. The precise nature of the waves responsible for this effect was heavily debated; in recent years, however, gravity waves have come to be seen as a major contributor and the QBO is now simulated in a growing number of climate models.\n\nEffects of the QBO include mixing of stratospheric ozone by the secondary circulation caused by the QBO, modification of monsoon precipitation, and an influence on stratospheric circulation in northern hemisphere winter (mediated partly by a change in the frequency of sudden stratospheric warmings). Eastward phases of the QBO often coincide with more sudden stratospheric warmings, a weaker Atlantic jet stream and cold winters in Northern Europe and eastern USA whereas westward phases of the QBO often coincide with mild winters in eastern USA and a strong Atlantic jet stream with mild, wet stormy winters in northern Europe. In addition, the QBO has been shown to affect hurricane frequency during hurricane seasons in the Atlantic and research has also been conducted investigating a possible relationship between ENSO (El Niño–Southern Oscillation) and the QBO.\n\nThe Free University of Berlin supplies a QBO data set that comprises rawinsonde observations from Canton Island, Gan, and Singapore. The plot below shows the QBO during the 1980s.\n\nThe first significant observed deviation from the normal QBO since its discovery in early 1950s was noted beginning in February 2016 when the transition to easterly winds was disrupted by a new band of westerly winds that formed unexpectedly. The lack of a reliable QBO cycle deprives forecasters of a valuable tool. Since the QBO has a strong influence on the North Atlantic Oscillation and thereby north European weather, scientists speculate that the coming winter could be warmer and stormier in that region.\n\nNASA Scientists have been researching to test if the extremely strong El Niño event of 2015/16, climate change, or some other factor might be involved. They are trying to determine if this is more of a once in a generation event, or if this is a sign of the changing climate.\n\n\n"}
{"id": "38938204", "url": "https://en.wikipedia.org/wiki?curid=38938204", "title": "Svend O. Heiberg Memorial Forest", "text": "Svend O. Heiberg Memorial Forest\n\nSvend O. Heiberg Memorial Forest is a research forest located in parts of Onondaga and Cortland counties, and within the towns of Truxton, Preble, Fabius, and Tully in New York State. The forest is named after Svend O. Heiberg, former Associate Dean of Graduate Studies at the State University of New York College of Environmental Science and Forestry (SUNY-ESF).\n\nHeiberg Memorial Forest was established in 1948 with obtained from the New York State Department of Environmental Conservation in exchange for SUNY-ESF's Salamanca Forest in Cattaraugus County. The forest today consists of utilized as a research forest as part of SUNY-ESF's regional campus and includes classrooms, research buildings and other facilities.\n\nThe forest is accessible to the public. Over of trails provide recreation opportunities, including the Heiberg Memorial Forest Trail, a loop that permits hiking and cross-country skiing.\n\nTwo small ponds are available for fishing within Heiberg Memorial Forest. Padget Pond and Sargent Pond are both stocked annually in the fall, with Padget Pond receiving 2,000 fingerling rainbow trout and Sargent Pond receiving 700 fingerling brook trout. Both ponds are accessible via an approximately trail from a parking area on Maple Ridge Road.\n\nCut-your-own Christmas trees, including Douglas fir and balsam fir, are sold at the forest each year.\n\n"}
{"id": "8870608", "url": "https://en.wikipedia.org/wiki?curid=8870608", "title": "Swastika Stone", "text": "Swastika Stone\n\nThe Swastika Stone is a stone adorned with a design that resembles a swastika, located on the Woodhouse Crag on the northern edge of Ilkley Moor in West Yorkshire. The design has a double outline with five curved arms enclosing several so-called 'cup' marks, the like of which can be found on other stones nearby. \n\nThe design is unique in the British Isles, so its close similarity to Camunian rose designs in Italy have led some to theorise that the two are connected. In fact, the troops stationed in Ilkley during Roman occupation were recruited from the Celtic Lingones. This tribe was native to Gaul, but in around 400 BC, some migrated across the Alps to the Adriatic coast. Some believe the Ilkley Lingones were recruited from here rather than from Gaul. It is possible that the Italian Lingones passed through the Valcamonica region at some point, took on the swastika designs they found as part of their tribal symbolism, and carved it on the nearby moor when stationed in Ilkley.\n\n\n \n"}
{"id": "2720320", "url": "https://en.wikipedia.org/wiki?curid=2720320", "title": "Synchroscope", "text": "Synchroscope\n\nIn AC electrical power systems, a synchroscope is a device that indicates the degree to which two systems (generators or power networks) are synchronized with each other.\n\nFor two electrical systems to be synchronized, both systems must operate at the same frequency, and the phase angle between the systems must be zero (and two polyphase systems must have the same phase sequence). Synchroscopes measure and display the frequency difference and phase angle between two power systems. Only when these two quantities are zero is it safe to connect the two systems together. Connecting two unsynchronized AC power systems together is likely to cause high currents to flow, which will severely damage any equipment not protected by fuses or circuit breakers.\n\nThe simplest aid to synchronizing a generator to another system uses lamps wired between similar phases of the two systems; when the lamps stay dark, the voltage and frequency of the two systems are the same and the generator may be connected. However, the accuracy of this approach is low since it is difficult to discern slight phase differences, and the lamps do not show the relative speeds of the two systems. Synchroscopes are instruments that show the relative frequency (speed) difference and the phase angle between the machine to be synchronized and the system voltage. \n\nSince most synchroscopes are connected only to a single phase of the two systems, they cannot assure that the phase sequence is correct. When generators are newly connected to a power system, or temporary connections are used, other means are required to assure both systems have the same phase sequence. Some generators use both a synchroscope and a set of two lamps. If the lamps flash out of sequence, then the phase sequence is incorrect.\n\nSynchroscopes are electrodynamic instruments, which rely on the interaction of magnetic fields to rotate a pointer. In most types, unlike voltmeters and wattmeters, there is no restoring spring torque for the magnetically produced torques to overcome; the pointer system is free to rotate continually. Synchroscopes have a damping vane to smooth out vibration of the moving system. \n\nA polarized-vane synchroscope has a field winding with a phase-shifting network arranged to produce a rotating magnetic field. The field windings are connected to the \"incoming\" machine. A single-phase polarizing winding is connected to the \"running\" system. It is mounted perpendicular to the field winding and produces a magnetic flux that passes through the moving vanes. The moving vanes turn a shaft that carries a pointer moving over a scale. If the frequency of the source connected to the polarizing winding is different from the source connected to the field winding, the pointer rotates continually at a speed proportional to the difference in system frequencies (the beat frequency). The scale is marked to show the direction of rotation corresponding to the \"incoming\" machine running faster than the \"running\" system. When the frequencies match, the moving vanes will rotate to a position corresponding to the phase difference between the two sources. The incoming machine can then be adjusted in speed so that the two systems are in phase agreement. \n\nIn the moving iron instrument, an iron vane is mounted on a shaft along with the pointer. The field winding is a three-phase winding, with the phases connected to both the running and incoming sources through a phase-shifting \"impedor\" network containing resistors, capacitors, and inductors. In this instrument, conceptually the field winding produces two rotating magnetic fields due to the running and incoming sources. The iron vane moves in response to the resultant sum of the two fields. \n\nThe cross-coil synchroscope somewhat resembles a wound-field induction motor. A two-phase rotor winding is connected to the incoming machine source by a phase-shifting network through brushes and slip rings. The stationary field winding is connected to the incoming source. \n\nIn a Weston pattern synchroscope, the moving element is not free to rotate continuously and oscillates back and forth slowly as the two sources are brought into synchronism. The moving pointer is illuminated by a pilot lamp connected to a three-winding transformer fed by both sources. The pointer is only illuminated at the in-phase condition, thereby distinguishing between in-phase and 180-degree out of phase conditions. \n\nAll these instruments use single-phase connections to the running and incoming systems to simplify the wiring. For most systems, synchroscopes are connected through voltage transformers to reduce the machine voltage to around 120 volts to operate the instruments. Synchroscopes operate only over a limited range of frequencies, a few per cent above and below the system nominal frequency. Cross-coil type instruments draw a relatively large amount of power from the systems and are intended for only brief operation. The moving-iron and polarized-vane instruments put less burden on the system and can operate for a longer time without overheating. \n\nElectronic digital systems can measure and display the phase angle difference directly. The display may be a ring of discrete LEDs arranged to simulate the effect of a pointer moving over a scale, with a different color of LED to indicate the \"in phase\" condition. These instruments may also have a relay contact for use by external control circuits, to indicate synchronism.\n\nSynchroscopes are used in any power plant that connects to an outside power grid and also in isolated plants containing more than one generator. Each generator must be synchronized with the others before being connected to the plant bus. If line voltages are unequal when they are connected, a heavy current will flow as each line will attempt to equalize the other, causing damage in the process. \n\nWhen operators of an electric generator wish to connect it to the grid, they first start the generator spinning at a rate approximately equal to the line frequency of the grid with which they plan to connect. The voltage of the generator is then matched with the grid by adjusting the field/armature current. The synchroscope is connected to the power grid and to the generator being started. \n\nIf the generator is turning at a lower frequency than the grid, the synchroscope needle rotates continually in the direction (usually counterclockwise) marked \"slow\" or \"lag\" on the dial to indicate that the generator is running slower than, or lagging behind, the grid. If the generator is running faster than the grid, the needle rotates continually in the opposite direction, marked \"fast\" or \"lead\". Next, the plant operator adjusts the speed of the generator until it is running at precisely the same speed (frequency) as the grid. As the frequency of the generator nears that of the grid, the synchroscope needle slows down and when the frequencies match, the needle stops rotating. \n\nAt this point, there is one more task to perform before the generator can be connected to the grid. Although the generator and the grid are now operating at the same frequency, they are not necessarily at the same position in the rotational cycle as each other. If two electrical networks operating at two different phase angles were to be connected to each other, a fault similar to a short circuit would occur and most likely destroy the generator and damage the grid.\n\nThe position (as opposed to rotation) of the needle on a synchroscope indicates the phase angle between the two systems. The angle between the systems is zero when the synchroscope needle is pointing directly to the line in between the \"slow\" and \"fast\" markings on the dial. (In the picture example in this article, the zero-phase-angle position is straight upwards, at the \"twelve o'clock\" position.) \n\nIf the needle reads \"fast,\" then the plant's generator is slowed down by a very small amount and the needle turns counterclockwise (toward the zero mark). Alternatively, if the needle reads \"slow,\" then the plant operator speeds the generator up slightly, and the needle turns clockwise. Slightly before the needle reaches the zero mark, the plant operator returns the generator to the grid frequency in order to stop the needle when it reaches the zero mark. When the needle is at zero and is not moving, the two systems are synchronized.\n\nOnce the two systems are synchronized, they can be safely connected.\n\nDepending on the application and the circuit design, the breaker is closed when the synchroscope is passing through approximately \"eleven o'clock\", while traveling slowly in the fast direction, allowing time for the circuit breaker to close, and for the incoming generator to come onto the grid as a source. The purpose of this action is to prevent the possibility of the oncoming generator paralleling onto the grid as a load. This has the potential to cause the generator to operate as a motor which can cause damage to the generator and the prime mover (such as a steam turbine or Diesel engine). The machine may be protected from this occurrence by a \"reverse power\" trip.\n\nIn some power plants, a set of lamps may be connected between the generator and system busses (or between the instrument transformers connected to those busses) as a backup to the synchroscope instrument. The lamps flicker at the difference between system and generator frequency. The lamps can be connected to go dark when the phase voltages are identical and in-phase.\n\nIn addition to synchronizing generators to power systems, similar frequency-difference indicating instruments are used on multiengine ships and aircraft to allow the operators to exactly synchronize the speed of engines. This helps reduce the noise and vibration due to slight differences, for example, in the speeds of two propellers on an aircraft. In this application a synchroscope responds to slight speed differences that would not be visible on an engine tachometer. \n\n"}
{"id": "1100595", "url": "https://en.wikipedia.org/wiki?curid=1100595", "title": "Titanium diboride", "text": "Titanium diboride\n\nTitanium diboride (TiB) is an extremely hard ceramic which has excellent heat conductivity, oxidation stability and resistance to mechanical erosion. TiB is also a reasonable electrical conductor, so it can be used as a cathode material in aluminium smelting and can be shaped by electrical discharge machining.\n\nTiB is very similar to titanium carbide, an important base material for cermets, and many of its properties (e.g. hardness, thermal conductivity, electrical conductivity and oxidation resistance) are superior to those of TiC:\n\nWith respect to chemical stability, TiB is more stable in contact with pure iron than tungsten carbide or silicon nitride.\n\nTiB is resistant to oxidation in air at temperatures up to 1100 °C, and to hydrochloric and hydrofluoric acids, but reacts with alkalis, nitric acid and sulfuric acid.\n\nTiB does not occur naturally in the earth. Titanium diboride powder can be prepared by a variety of high-temperature methods, such as the direct reactions of titanium or its oxides/hydrides, with elemental boron over 1000 °C, carbothermal reduction by thermite reaction of titanium oxide and boron oxide, or hydrogen reduction of boron halides in the presence of the metal or its halides. Among various synthesis routes, electrochemical\nsynthesis and solid state reactions have been developed to prepare finer titanium diboride in large quantity. An example of solid state reaction is the borothermic reduction, which can be illustrated by the following reactions:\n\n(1) 2 TiO + BC + 3C → 2 TiB + 4 CO\n\nThe first synthesis route (1), however, cannot produce nanosized powders. Nanocrystalline (5–100 nm) TiB was synthesized using the reaction (2) or the following techniques: \n\nMany TiB applications are inhibited by economic factors, particularly the costs of densifying a high melting point material - the melting point is about 2970 °C, and, thanks to a layer of titanium dioxide that forms on the surface of the particles of a powder, it is very resistant to sintering. Admixture of about 10% silicon nitride facilitates the sintering, though sintering without silicon nitride has been demonstrated as well.\n\nThin films of TiB can be produced by several techniques. The electroplating of TiB layers possess two main advantages compared with physical vapor deposition or chemical vapor deposition: the growing rate of the layer is 200 times higher (up to 5 μm/s) and the inconveniences of covering complex shaped products are dramatically reduced.\n\nCurrent use of TiB appears to be limited to specialized applications in such areas as impact resistant armor, cutting tools, crucibles, neutron absorbers and wear resistant coatings.\n\nTiB is extensively used as evaporation boats for vapour coating of aluminium. It is an attractive material for the aluminium industry as an inoculant to refine the grain size when casting aluminium alloys, because of its wettability by and low solubility in molten aluminium and good electrical conductivity.\n\nThin films of TiB can be used to provide wear and corrosion resistance to a cheap and/or tough substrate.\n\n\n"}
{"id": "2473996", "url": "https://en.wikipedia.org/wiki?curid=2473996", "title": "Ufa train wreck", "text": "Ufa train wreck\n\nThe Ufa train disaster was a railway accident that occurred on 4 June, 1989, in Iglinsky District, Bashkir ASSR, Soviet Union, when an explosion killed 575 people and injured 800 more. It is the deadliest rail disaster in peacetime Soviet Union/Russia.\n\nAt 1:15 local time, two passenger trains of the Kuybyshev Railway carrying vacationers to and from Novosibirsk and a resort in Adler on the Black Sea exploded, from the city of Asha, Chelyabinsk Oblast. A faulty gas pipeline away had unknowingly leaked natural gas liquids (mainly propane and butane), and special weather conditions allowed the gas to accumulate across the lowlands, creating a flammable cloud along part of the Kuybyshev Railway. The explosion occurred after wheel sparks from the two passenger trains heading in opposite directions ignited the flammable cloud. Estimates of the size of the explosion have ranged from 250–300 tons of TNT equivalent to up to 10,000 tons of TNT equivalent. Of the victims, 181 of them were children, and many survivors having received severe burns and brain injuries.\n\nOn the afternoon of June 4, Mikhail Gorbachev, Chairman of the Supreme Soviet of the USSR, and members of the government commission to investigate the accident visited the site. The Chairman of the Commission for Investigation of the accident was Deputy Chairman of the Council of Ministers of the USSR, Gennady Vedernikov.\nThe trial over the accident continued for six years where nine officials were charged, mostly members of Nefteprovodmontazh (the trust that constructed the faulty pipeline) including the chief of the construction and installation department of Nefteprovodmontazh, foremen, and other specific members. The charges were brought under Article 215, part II of the Criminal Code of the RSFSR, where the maximum penalty is five years imprisonment.\n\nThe accident was named after Ufa, the largest city in the Bashkir ASSR, although it occurred about east of the city.\n\nAccording to Dmitry Chernov and Didier Sornette, a number of factors contributed to the disaster.\nAuthorities concealed the risks after the accident.\n\n"}
{"id": "7510188", "url": "https://en.wikipedia.org/wiki?curid=7510188", "title": "Union of Banana Exporting Countries", "text": "Union of Banana Exporting Countries\n\nThe Union of Banana Exporting Countries ( or UPEB) was a cartel of Central and South American banana exporting countries established in 1974, inspired by OPEC. Its aim was to achieve better remuneration from the North American banana trade oligopoly, which consisted of three US companies. UPEB's proposal of an export tax was undermined by the U.S. oligopoly bribing Honduran and Italian officials. The UPEB cartel collapsed when bribes became public. What is referred to as the Bananagate scandal paved the way for the U.S. Congress to create the 1977 Foreign Corrupt Practices Act.\n\nIn 1974, Colombia, Costa Rica, Ecuador, Guatemala, Honduras, Nicaragua, and Panama joined together in an attempt to form a banana-exporting country cartel focusing on exports to the North American market. The Philippines was the only major exporter of bananas to the United States which did not join. The market for banana exports to Europe at this time was quite separate, with mainly former European French and British colonies in the Caribbean supplying European countries.\n\nBanana prices had gone up little in 20 years. A United Nations study had concluded that no more than seventeen cents of each United States dollar spent by North Americans on bananas went to producing countries. At the time the banana trade was highly concentrated with only three US companies participating: United Brands Company (formerly United Fruit), Standard Fruit, and the Del Monte Corporation.\n\nUPEB proposed an export tax of one dollar for every forty-pound box of bananas exported. The companies protested and threatened to withdraw their operations. There was also a glut on the world banana market and Ecuador, the leading producer, refused to enact the tax. Former President of Costa Rica José Figueres stated that Standard Fruit's property should be nationalized if the companies refused to pay the tax. Standard Fruit threatened the new President, Daniel Oduber that if there were any more threats, the company would pull out of Costa Rica. Costa Rica dropped its demand to 25¢ a crate.\n\nIn 1974, Honduras passed a law to raise the tax on banana exports from 25¢ to 50¢ per 40-pound box. Honduras had supplied more than 22% of United Brands Company exports in 1974.\n\nIn 1975, Eli M. Black, the chairman and president of the United Brands Company, jumped to his death from the forty-fourth floor of the Pan Am Building in Manhattan. When the Securities and Exchange Commission (SEC) investigated Black's suicide, it uncovered a scandal that was named \"Bananagate\". United Brands had paid a $1.25 million bribe to Honduran President Oswaldo López Arellano, followed by another $1.25 million the next year. The money was to be put in a Swiss bank account. The operation was managed via the Honduran Minister of the Economy, Abraham Bennaton Ramos. After the bribe the Honduran tax was reduced from fifty cents to twenty-five cents per box. This caused the UPEB cartel to collapse. This reduction saved United Brands Company about $7.5 million in tax payments. In addition it was discovered that United Brands Company had paid another $750,000 in bribes to an Italian official to prevent restrictions on United's banana exports to Italy, beginning in 1970. The SEC determined that none of the bribes could have been paid without the knowledge and approval of Black. While it was not illegal at the time for US companies to bribe officials, it was illegal for companies to hide such bribes from their stockholders.\n\nUnited Brands Company also admitted that it had tried to convince the SEC that the bribes should be kept secret, on the ground that disclosure would hurt the company and its stockholders. The company's Washington law firm, Covington & Burling, asked the U.S. State Department to intervene, arguing that news of the Honduran bribe could harm U.S. relations with that country. The State Department declined.\n\nWhen the bribe was revealed, it provoked the overthrow of the military government in Honduras and this in turn led to the nationalisation of United's railways along with a major divestiture of land by the companies.\n\nOn May 1, 1975, Costa Rica passed a law to raise the tax on banana exports from 25¢ to $1 per 40-pound box. The decree stated that 45¢ of each tax dollar would go to the government and the other 55¢ to subsidize independent banana growers. United Brands' local subsidiary, the Costa Rican Banana Co., then filed a $3 million suit against the government in April 1975, stating that the export levy violated a government guarantee not to tax the company until its contract with the government expired in 1988.\n\nSince its formation, the Union of Banana Exporting Countries has been largely limited to charging a modest tax on corporate banana exports.\n\n"}
{"id": "26957798", "url": "https://en.wikipedia.org/wiki?curid=26957798", "title": "Views on the Kyoto Protocol", "text": "Views on the Kyoto Protocol\n\nThis article is about certain views on the Kyoto Protocol to the United Nations Framework Convention on Climate Change.\n\nA 2007 study by Gupta \"et al.\" assessed the literature on climate change policy which showed no authoritative assessments of the UNFCCC or its Protocol, that assert these agreements have, or will, succeed in fully solving the climate problem. It was assumed that the UNFCCC or its Protocol would not be changed. The Framework Convention and its Protocol, include provisions for future policy actions to be taken.\n\nSome environmentalists have supported the Kyoto Protocol because it is \"the only game in town,\" and possibly because they expect that future emission reduction commitments may demand more stringent emission reductions (Aldy \"et al.\"., 2003, p. 9). Some environmentalists and scientists have criticized the existing commitments for being too weak (Grubb, 2000, p. 5). On the other hand, many economists think that the commitments are stronger than is justified. Particularly in the US, many economists have also been critical of the failure to include quantified commitments for developing countries (Grubb, 2000, p. 31).\n\nThe choice of 1990 as the main base year remains in Kyoto, as it does in the original Framework Convention (UNFCCC). The importance of the choice of base year was discussed by Liverman (2008). According to Liverman (2008), the idea of using historical emissions as a basis for the Kyoto targets was rejected on the basis that good data was not available prior to 1990. Liverman (2008), however, commented that a 1990 base year favours several powerful interests including the UK, Germany and Russia. This is because these countries had high emissions in 1990.\n\nAccording to Liverman (2008), some of the former Soviet satellites wanted a base year to reflect their highest emissions prior to their industrial collapse. A high emissions baseline was an advantage for countries whose emissions had subsequently fallen due to economic collapse. On the other hand, some of the former Soviet countries regard their emissions surplus as compensation for the trauma of economic restructuring.\n\nLiverman (2008) argued that countries, such as the US, made suggestions during negotiations in order to lower their responsibility to cut emissions. These suggestions included the inclusion of carbon sinks (the carbon absorbed annually by forests and other land cover) and having net current emissions as the basis for responsibility, rather than historical emissions.\n\nAnother perspective on negotiations was provided by Grubb (2003). The final days of negotiation of the Protocol saw a clash between the EU and the US and Japan. The EU aimed for flat-rate reductions in the range of 10–15% below 1990 levels, while the US and Japan supported reductions of 0–5%. Countries that had supported differentiation of targets between countries had different ideas on how it should be calculated, and many different indicators were proposed, e.g., targets that were related to GDP, energy intensity (energy use per unit of economic output), and so on. According to Grubb (2003), the only common theme of these indicators was that each proposal suited the interests of the country making the proposal.\n\nAldy \"et al.\" (2003) commented on the Kyoto targets and how they related to economic growth. Considering the growth of some economies and the collapse of others since 1990, the range of implicit targets is much greater than that suggested by the Kyoto targets. According to Aldy \"et al.\" (2003), the US faced a cut of about 30% below \"business-as-usual\" (BAU) emissions (i.e., projected emissions in the absence of measures to limit emissions), which is more stringent than that implied by its Kyoto target (a 7% reduction in emissions compared to 1990 levels). This contrasts with Russia and other Kyoto \"economies in transition\" (EITs), who, according to Aldy \"et al.\" (2003), faced Kyoto targets that allowed substantial increases in their emissions above BAU.\n\nGrubb (2003), however, commented that the US, having per-capita emissions twice that of most other OECD countries, was vulnerable to the suggestion that it had huge potential for making reductions. From this viewpoint, the US was obliged to cut emissions back more than other countries. Grubb (2003) also commented that for two or three years after the Kyoto agreement, the usual economic perspective was that emissions from the EITs would rise sharply as their economies recovered. In reality, however, emissions of the EITs failed to grow as many models had predicted.\n\nIn August 2012, in a speech given at his alma mater, Todd Stern — the US Climate Change envoy — expressed the challenges of the UNFCCC process as follows, “Climate change is not a conventional environmental issue...It implicates virtually every aspect of a state’s economy, so it makes countries nervous about growth and development. This is an economic issue every bit as it is an environmental one.” He went on to explain that the United Nations Framework Convention on Climate Change is a multilateral body concerned with climate change and can be an inefficient system for enacting international policy. Because the framework system includes over 190 countries and because negotiations are governed by consensus, small groups of countries can often block progress.\n\nBaylis \"et al.\" (2011) argued that a successful international climate policy would require additional emission reductions from developing countries such as China and India.\n\nIn September 2012 the Netherlands Environmental Assessment Agency and the European Commission's Joint Research Centre released a detailed study which showed that the 37 main Kyoto nations plus the U.S. (which did not ratify the treaty) have emitted 7.5 per cent less carbon dioxide into the atmosphere in 2010 than in 1990.\n\nThe Bush Administration's rejection of Kyoto could have led to its failure (Grubb, 2002, p. 140). In the view of Grubb (2002), the EU's subsequent decision to support the Protocol was key. Environmental organization the Environmental Defense Fund have been supportive of the Protocol (EDF, 2005). Jonathan Pershing, director of the Climate and Energy Program at the World Resources Institute, stated that the Protocol \"makes it clear that the world takes the global warming problem seriously\" (Pershing, 2005).\n\nThe United Nations has issued reports favoring the Kyoto Protocol. Supporters of Kyoto stated it is a first step towards meeting the ultimate objective of the UNFCCC, which is to prevent dangerous climate change. They state that the Protocol will be revised in order to meet this objective, as is required by UNFCCC Article 4.2(d).\n\nIn 2001, sixteen national science academies stated that ratification of the Protocol represented a \"small but essential first step towards stabilising atmospheric concentrations of greenhouse gases.\" In 2005, the national science academies of the G8 nations and Brazil, China and India made a statement where they \"urged\" all nations to \"take prompt action to reduce the causes of climate change, adapt to its impacts and ensure that the issue is included in all relevant national and international strategies.\" They stated that these actions should be taken in line with UNFCCC principles.\n\nAn international day of action was planned for 3 December 2005, to coincide with the Meeting of the Parties in Montreal. The planned demonstrations were endorsed by the Assembly of Movements of the World Social Forum.\n\nA group of major Canadian corporations also called for urgent action regarding climate change, and have suggested that Kyoto is only a first step.\n\nSome argue the protocol does not go far enough to curb greenhouse emissions (Niue, The Cook Islands, and Nauru added notes to this effect when signing the protocol). Some environmental economists have been critical of the Kyoto Protocol. Many see the costs of the Kyoto Protocol as outweighing the benefits, some believing the standards which Kyoto sets to be too optimistic, others seeing a highly inequitable and inefficient agreement which would do little to curb greenhouse gas emissions.\n\nStavins (2005) criticized the Protocol as doing \"too little, too fast,\" in that it asks for excessively costly short-term reductions in emissions, without determining what should be done over longer timeframes (Stern 2007, p. 478). Over longer timeframes, there is more flexibility to make reductions in line with normal cycles of capital stock replacement. At the time of the Protocol's first commitment period, in 1997, it provided a 15-year window for action. The Protocol does not provide any guidance or formulae linking the action required in the first commitment period to an overall global quantity constraint on emissions, or to a long-term timetable for emissions reductions. In the view of Stern (2007), this lack of a long-term goal, coupled with problems over incentives to comply with emission reduction commitments, prevented the Protocol from providing a credible signal for governments and businesses to make long-term investments.\n\nSome have heavily criticized the Protocol for only setting emission reductions for rich countries, while not setting such commitments for the fast-growing emerging economies, e.g., China and India (Stern 2007, p. 478). Australia (under Prime Minister John Howard) and the US subsequently did not ratify the Protocol, although Australia has since ratified the treaty. A number of other countries have not taken strong steps to implement it. Developing countries did take on obligations under the Protocol, but these were unquantified and allowed climate change to be addressed as part of wider national policies on sustainable development.\n\nIn his 2009 book (\"Storms of my Grandchildren\") and in an open letter to US President Obama, climate scientist James Hansen criticized the Kyoto Protocol for being ineffective.\n\nIn May 2010 the Hartwell Paper was published by the London School of Economics in collaboration with the University of Oxford. This paper was written by 14 academics from various disciplines in the sciences and humanities, and also some policies thinkers, and they argued that after the failure of the 2009 Copenhagen Climate Summit, the Kyoto Protocol crashed and they claimed that it \"has failed to produce any discernable real world reductions in emissions of greenhouse gases in fifteen years.\" They argued that this failure opened an opportunity to set climate policy free from Kyoto and the paper advocates a controversial and piecemeal approach to decarbonization of the global economy. The Hartwell paper proposes that \"the organising principle of our effort should be the raising up of human dignity via three overarching objectives: ensuring energy access for all; ensuring that we develop in a manner that does not undermine the essential functioning of the Earth system; ensuring that our societies are adequately equipped to withstand the risks and dangers that come from all the vagaries of climate, whatever their cause may be.\"\n\nThe overall umbrella and processes of the UNFCCC and the Kyoto Protocol have been criticized for not having achieved the stated goals of reducing the emission of carbon dioxide (the primary culprit blamed for rising global temperatures of the 21st century).\n\nThe flexibility mechanisms that are defined in the Protocol could allow the Annex B countries to meet their emission reduction commitments at a significantly reduced cost (Bashmakov \"et al.\"., 2001, p. 402; Goulder and Pizer, 2006, p. 12). Actual costs will be determined by how individual countries decide to meet their commitments. This can involve the use of the international flexibility mechanisms, but domestic policies can also contribute, such as raising taxes on gasoline or regulatory fines for major polluters.\n\nThe Kyoto Protocol was designed to be efficient and equitable (Toth \"et al.\"., 2001, p. 660), but it has been subject to criticism (Stern, 2007, p. 478). Nordhaus (2001) drew attention to the inefficiencies of the Kyoto Protocol's flexibility mechanisms. Nordhaus explained that meeting the emission reduction commitments specified in the Kyoto-Bonn Accord, using the quantity-type instruments as defined in the Protocol, would be less efficient compared to a situation where price-type instruments were used, e.g., a harmonized carbon tax (comparisons of quantity-type and price-type instruments are included in the carbon tax and emissions trading articles). Nordhaus suggested that given the Protocol's large costs and small benefits, it might be better for it to be redesigned along the lines of a global carbon tax. Other economists such as Gwyn Prins and Steve Rayner, think an entirely different approach needs to be followed than suggested by the Kyoto Protocol.\n\nThe issue of the efficient (or \"optimal\") path for greenhouse gas (GHG) emissions depends on various assumptions (Klein \"et al.\"., 2007). Some of these assumptions, e.g., aggregating impacts across regions and over time, rely on value judgements (Azar, 1998; Fisher \"et al.\"., 2007). In Nordhaus's analysis, the implied emissions path of the Kyoto-Bonn Accord is more aggressive than that suggested in his analysis (Klein \"et al.\"., 2007). In other words, the efficient abatement path for emissions in Nordhaus's analysis, suggests more gradual near-term emissions abatement than that implied by Kyoto's emission reduction commitments. This is a common finding of economic cost-benefit analysis, and is driven by low estimates of marginal (or incremental) climate change damages (the social cost of carbon).\n\nClinton Administration\nVice President Al Gore was a main participant in putting the Kyoto Protocol together in 1997. President Bill Clinton signed the agreement in 1997, but the US Senate refused to ratify it, citing potential damage to the US economy required by compliance. The Senate also balked at the agreement because it excluded certain developing countries, including India and China, from having to comply with new emissions standards.\n\nBush administration\nSimilar objections to the Kyoto Protocol were why the Bush administration refused to sign. They argued the division between Annex 1 and developing countries was unfair, and that both countries needed to reduce their emissions unilaterally. President George W. Bush claimed that the cost of following the Protocols requirements will stress the economy.\n\nAl Gore accused Bush of showing the world \"a stunning display of moral cowardice.\" \"Kyoto's ability to survive the near-fatal attacks of the Bush administration is testimony to the urgency of the climate problem.\" Worldwatch Institute Laurie David, Natural Resources Defense Council said, \"As the world celebrates the global warming pact's debut, Bush continues to pander to the energy industry.\" \n\nObama Administration\nPresident Obama was elected under widespread belief that shortly after arriving in office he would take swift and decisive action to join the world in reducing GHG emissions and therefore helping battle global climate change. According to \"The American\", “Obama was widely expected to quickly pass a Kyoto-style domestic cap-and-trade program for greenhouse gases, positioning America to take the moral high ground in Copenhagen, thus luring (or compelling) China and India to accept emissions targets.\". Signing the Kyoto protocol seemed like the logical first step so it came as a surprise when he rejected the Kyoto protocol for reasons similar to those of former president Bush. According to \"The American\", “the treaty’s fundamental flaws were well understood: It set very ambitious—and costly—targets for the United States while allowing emissions from the developing world to continue to rise unchecked. (And indeed today, despite Kyoto’s ratification, China has become the world’s leading emitter of greenhouse gases.) Americans don’t mind contributing to a solution, but Kyoto asked a lot of sacrifice for little reward.”. President Obama was also expected to represent the U.S in Copenhagen and negotiate terms for the extension of the Kyoto Protocol past 2012.\nYet instead of the U.S. contributing to the development and signing of a Kyoto-like treaty, the U.S. is suggesting extreme modifications of the Kyoto emission management system and precipitating intense debates and clashes over the treaty which will follow Kyoto. Many countries fear these new treaty additions will paralyze negotiations and stop many of the countries currently under the Kyoto Protocol from re-signing as well as stop new countries, like China and India, from signing. “the Obama administration’s proposals could undermine a new global treaty and weaken the world’s ability to stave off the worst effects of climate change.”\n\nMany people feel that the combination of the U.S not signing the Kyoto Protocol (ensuring it will run out in 2012) and the U.S. attempt to change almost the entire architecture of the Kyoto Protocol in Copenhagen means the end of the Kyoto Protocol as we know it and perhaps a new global climate treaty. “If Kyoto is scrapped, it could take several years to negotiate a replacement framework, a delay that could strike a terminal blow at efforts to prevent dangerous climate change. In Europe we want to build on Kyoto, but the US proposal would in effect kill it off. If we have to start from scratch then it all takes time. It could be 2015 or 2016 before something is in place, who knows.\" \n\nThe Kyoto Protocol was a huge leap forward towards an intergovernmental united strategy to reduce GHG’s emissions globally. But it wasn’t without its objections. Some of the main criticisms were against categorizing different countries into annexes, with each annex having its own responsibility for emission reductions based on historic GHG emissions and, therefore, historic contribution to global climate change. “Some of the criticism of the Protocol has been based on the idea of climate justice.\" This has particularly centered on the balance between the low emissions and high vulnerability of the developing world to climate change, compared to high emissions in the developed world.” Other objections were the use of carbon off-sets as a method for a country to reduce its carbon emissions. Although it can be beneficial to balance out one GHG emission by implementing an equal carbon offset, it still doesn’t completely eliminate the original carbon emission and therefore ultimately reduce the amount of GHG’s in the atmosphere.\n\n"}
{"id": "18716212", "url": "https://en.wikipedia.org/wiki?curid=18716212", "title": "Volkswagen Golf Mk6", "text": "Volkswagen Golf Mk6\n\nThe Volkswagen Golf Mk6 (or VW \"Typ 5K or MK VI\") is a compact car, the sixth generation of the Volkswagen Golf and the successor to the Volkswagen Golf Mk5. It was unveiled at the Paris Auto Show in October 2008. Volkswagen released pictures and information on 6 August 2008, prior to the official unveiling. The vehicle was released to the European market in the winter of 2008. Major investments have been made in production efficiency, with a claimed productivity improvement at launch of nearly 20% in comparison with the previous model, and further gains planned for the next twelve months.\n\nAlthough billed as the Mk6, the new model was in effect a thoroughly re-engineered facelift of the previous model. In January 2013, it was superseded by the Volkswagen Golf Mk7.\n\nLike its predecessor, the Mk6 Golf is based on the Volkswagen Group A5 (PQ35) platform. Effectively it is a reskin of the Mk5 rather than an all-new design, it was developed with engineering improvements to shorten the previous model's excessive assembly time, and answered criticisms of that model's cheapened interior quality compared to that of the 1999.5 Mk4.\n\nImprovements in equipment level on the domestic market Golfs include, for the first time in a Golf, the inclusion of air conditioning as standard.\nAdditionally, dual-zone climate control is included in the Autobahn trim for North America.\n\nThe company is talking confidently about launching in Germany during 2009 a BlueMotion low emissions Golf and, in more general terms of possible alternative fuel versions later.\n\nAvailable engines for North American Golf include the 2.5 L I5 engine from the previous Mk5 Rabbit and Mk5 Jetta and the 2.0-litre TDI. GTI version features the 2.0-litre TSI.\n\nWith safety features such as seven standard airbags, (up to nine in Europe, up to eight in the US) and standard Electronic Stability Programme (ESP), the Golf Mk6 has scored 36 out of 37 possible points for occupant protection, giving it a five-star rating by the Euro NCAP crash test agency. It was one of the safest vehicles in its class at the time of its release.\n\nThe new Volkswagen Golf Cabriolet was presented at the 2011 Geneva International Motor Show. The four-seater has a soft top with an electro-hydraulic drive that opens the Golf's top in 9.5 seconds. The top can also be opened or closed during driving at speeds of up to . After a nine years without a convertible Golf, it was the first Cabriolet model under the Golf family since 2002.\n\nThe new VW Golf Cabriolet's styling follows that of its hard-top three-door counterpart, but it differs somewhat with a new rear section, lower profile roof line and more swept-back angle of its front windscreen frame. Bi-xenon headlights are an option. Unlike the regular Golf, the Cabriolet has LED rear lights, which are only available for the R and GTI versions of the hardtop. Safety features include the automatically deploying roll-over bar, front airbags, side head/thorax airbags, knee airbag for the driver and ESP.\n\nThere are six turbocharged direct-injection engines whose power outputs range from to . Four of the petrol engines (TSI) and one diesel (TDI) are available with the DSG dual-clutch gearbox; while three of the engines are available with energy-saving BlueMotion Technology.\n\nIn February 2012, Volkswagen announced that they would build a Cabriolet version of the GTI, powered by a 2.0-liter four-cylinder engine.\n\nAs of October 2016, VW announced that the Golf cabriolet will no longer be sold in the U.K. due to financial reasons.\n\nA facelifted variant Mk5 Golf Variant model was introduced in 2009 as the Mk6, despite carrying the front fascia, interior styling, and the drive line from the new Golf, the underpinnings are based on its fifth-generation predecessor. \nIt is sold in the US as the Jetta SportWagen, in Mexico and Canada as the Golf Wagon and in South America as the Jetta Variant or Vento Variant.\n\nIn December 2008, a facelifted version of the Golf Plus was revealed at the Bologna Motor Show, featuring a revised front end, similar to the Golf Mk6, but still largely retaining the design of the rear end and the interior of the Mk5 based vehicle. In 2014 the Golf Plus was replaced by the MQB based Golf Sportsvan, which was originally shown as the Sportvan concept.\n\nVolkswagen CEO Martin Winterkorn announced Golf Twin Drive plug-in hybrid concept based on Mk5 Golf, which uses 2.0 L I4 turbodiesel and electric motor with lithium-ion batteries. The car can run about 50 kilometres on battery power. The combined power is .\n\nVolkswagen developed the Twin Drive system with eight German partners, and is planning a trial fleet of 20 Golfs outfitted with the system in 2010.\n\nThe production version was expected to be based on new Mk6 Golf, featuring a 1.5 L turbodiesel engine and electric motor, with estimated arrival date of 2015.\n\nThe Golf GTI \"Wörthersee 09\" is a concept car based on the Golf GTI. 2.0-liter TSI. Its engine is rated at , with a 0–100 km/h (0-62 mph) acceleration time of 6.9 seconds and a top speed of . It features a Firespark Metallic red body color with GTI stripes, high-gloss black 19-inch alloy spoke wheels, smoked LED taillights, a lowered chassis and a new sport exhaust. Changes to the interior include aluminum tread plates, brushed aluminum trim and glossy black painted frames around the air vents, red bordered floor mats and black Nappa leather sport seats with red accents and \"Berry White\" leather piping.\n\nThe vehicle was unveiled at the \"Wörthersee GTi-Treffen\" meet in Wörthersee, Austria.\n\nThere was much speculation about this vehicle, with uncertainty surrounding its name. Golf R20 was the most common name used prior to the Frankfurt Motor Show. Once finally unveiled by Volkswagen at the Frankfurt IAA, on 15 September 2009, it was confirmed the R32 replacement would simply be called the Golf R.\n\nThe Golf R is powered by a FSI turbocharged Inline-four engine that produces at 6000 rpm and at 2500-5000 rpm of torque. VW claims the car can get from 0– in 5.5 seconds for DSG equipped models, or 5.7 seconds for cars fitted with a manual transmission.\n\nThe Golf R features these main upgrades over the standard FSI EA113 engine:\n\nThe Golf R employs a familiar, but revised (5th-generation) Haldex 4motion all-wheel drive system.\n\nThe Golf R has many similar styling traits to its Scirocco R sibling and is the first Golf to have LED rear tail lights factory fitted.\n\nIn Australia, Japan, China, America and South Africa the Golf R engine is detuned to suit hotter climate conditions. It is detuned from to and to .\n\nOn 9 December 2010, Volkswagen announced that the Golf R will be available in the United States beginning in 2012. Both two- and four-door versions were offered, and the DSG transmission was not an option. The US version Golf R features a slightly detuned engine producing and . \n\nOn 14 December 2010, Volkswagen announced that the Golf R will be available in Canada beginning in \"early\" 2012. Only a four-door version with six-speed manual transmission was offered. Four colours of the GTI were offered plus the R-exclusive \"Rising Blue\". All options were standard including navigation, sun roof, leather interior, and \"Kessy\" keyless entry.\n\nThe North American versions shipped with incandescent tail lights, identical to the tail lights found on the GTI, instead of the LED tail lights used in the rest of the world.\n\nFollowing Volkswagen's successful 30th anniversary edition GTI , Volkswagen marked the GTI's 35th anniversary by producing the GTI Edition 35.\n\nThe Edition 35 runs an evolution of the Mk5 GTI engine that is also used in the Golf R (see above) but with a reduced boost level to 13psi max (0.9bar), running a K04 turbocharger, enabling its power levels to fit just above the standard Mk6 GTI (which runs a EA888 TSI engine) , but below the Golf R.\n\nThe engine has more in common with the Mk5 Edition 30, Mk5 Pirelli Edition and Mk6 R than the standard Mk6 GTI\n\nStandard fit items to differentiate this model were :\n\n\nIn the United States and Canada, the car was sold as the Volkswagen Golf when it arrived in showrooms in October 2009, dropping the \"Rabbit\" badge that was used for the Golf Mk5. The wagon, a restyled version of the Mk5 and the only Golf model made in Mexico, is sold in Canada as \"Golf Wagon\", but in the United States retains the \"Jetta SportWagen\" designation (while wearing Golf front sheetmetal). North American Golfs will carry over the same engines as the Mk5 (the same 2.5L five-cylinder from the Mk5, the 2.0TDI and the 2.0T) and, while the GTI and TDI continue to offer the six-speed manual transmission, the 2.5 L will re-use the five-speed manual (automatic will be a six-speed tiptronic). The new Golf is also available in Mexico but for the time being only in the wagon configuration that is marketed as Golf SportWagen that became available in early October replacing the Bora Sportwagen with the new Golf's front end.\n\nThe Australian public got their first taste of the new Mk6 at the Melbourne International Motor Show, which began on 27 February 2009. The new Golf was launched around the country at the same time. The Mk6 GTI went on sale from 30 October 2009. On 19 January 2010 the Golf was awarded the 2009 Wheels Car of the Year title, which is acknowledged as the country's most prestigious car award. It was the first time the Golf had been awarded the title since 1976. VW Australia launched the new base model golf with 1.2-litre engine same as the new Polo in September 2010 and went on sale in 2011.\n\nIn South Africa the new Mk6 Golf went on sale in April 2009. The South African version of the GTI went on sale in July 2009.\n\nIn Japan the new Mk6 Golf went on sale in April 2009. The Japanese version of the GTI went on sale in August 2009.\n\nIn China, the Golf Mk6 is made by FAW-VW, and in March 2010 the GTI begins to be built locally. It is the first time the GTI is built in China. The Chinese-Spec Golf GTI uses a different engine than the international one, a 2.0 TSI which produces only , less than the original one. This engine is also used by the VW Magotan.\n\nIn Mexico, the only two versions available until August 2011 were the German-imported 3-door GTI in both 6-speed manual and 6-speed DSG transmissions, and the Mexican-produced Golf SportWagen with a 170 bhp 2.5 L inline 5-cylinder with a 6-speed Tiptronic transmission. In September 2012, a 5-door version in Comfortline trim, with 1.4 L TSI engine with 177 hp and 6-speed manual gearbox imported from Germany was added. Since the end of production is imminent, it will be limited to 4,000 units.\n\nIn Chile, the Golf Mk6 was presented in October 2010 at the XI Salón del Automóvil de Santiago, starting sales immediately. Chile is the first country in South America to sell the Mk6, as a restyled version of the Mk4 is still in production in Brazil for Latin America. The Mk6 is available in Chile with the 1.6 L Petrol engine (101 hp) both in five-speed manual and seven-speed DSG transmissions.\n\nIn India, the Golf Mk6 was rumored to be introduced in 2011 but in a recent interview, Volkswagen Chief Executive Officer said that the plans for introducing a Golf have been suspended, to preserve the success of VW Vento in the Indian market. The Golf, if released, would be similarly priced as the Vento and VW does not want Vento sales to slip. He also stated they may bring in a more localized Golf with the same engine choices as the Vento when numbers stabilize in the near future.\n\nIn auto racing, APR Motorsport has led two MKVI VW GTIs to victory in the Grand-Am Continental Tire Sports Car Challenge Street Tuner (ST) class.\n\nTo commemorate the 35th Anniversary of the Golf GTI, Volkswagen Motorsport entered the 2011 24 Hours Nürburgring with the \"Golf24\". This Golf was equipped with a\n2,500 cc five-cylinder turbo engine with 324 kW (440 PS) and 540 Nm, permanent 4WD and a sequential six-speed gearbox. In the third VLN race of 2011, the Golf24 finished sixth overall, with its best lap only nine seconds slower than the fastest race lap, which was clocked by a Ferrari 458. For the 24 Hours, the team hoped for rain, and jokingly considered wetting the track by aerial firefighting. Eventually, though, neither of the three Golf24s finished the race, with one of them suffering a pit-entry accident and another blowing a gearbox. When the gearbox of the remaining Golf24 started overheating, VW decided to retire it to find out the cause of the gearbox trouble.\n\n\n"}
{"id": "56278061", "url": "https://en.wikipedia.org/wiki?curid=56278061", "title": "Wash copper", "text": "Wash copper\n\nA wash copper, copper boiler or simply copper is a wash house boiler, generally made of galvanised iron, though the best sorts are made of copper. In the inter-war years they came in two types. The first is built into a brickwork furnace and was found in older houses. The second was the free-standing or portable type, it had an enamelled metal exterior that supported the inner can or copper. The bottom part was adapted to hold a gas burner, a high pressure oil or an ordinary wood or coal fire. Superior models could have a drawing-off tap, and a steam-escape pipe that lead into the flue.\nIt was used for domestic laundry. Linen and cotton were placed in the copper and were boiled to whiten them. Clothes were agitated within the copper with a washing dolly, a vertical stick with either a metal cone or short wooden legs on it. After washing, the laundry was dried with a mangle and then line-dried.\n\nMeticulous care was take to avoid rust, and grease. In cases of the latter it could be cleaned with paraffin or soft soap. Water was always put in the copper before it was lit. In the case of solid fuel, a small shovel of hot coals would be brought from the main kitchen fire and coke shovelled on top. \n"}
{"id": "16821404", "url": "https://en.wikipedia.org/wiki?curid=16821404", "title": "Wolfgang Scheffler (inventor)", "text": "Wolfgang Scheffler (inventor)\n\nWolfgang Scheffler (born 1956) is the inventor/promoter of Scheffler Reflectors, large, flexible parabolic reflecting dishes that concentrate sunlight for solar cooking in community kitchens, bakeries, and in the world's first solar-powered crematorium. By early 2008, over 2000 large cookers of his design had been built distributed worldwide including the world's largest solar cooker.\n\nSchaeffler was born in Innsbruck, Austria, and received the Special Recognition Award at the 2006 Nuclear-Free Future Award,\n\n\n"}
