{"id": "22177759", "url": "https://en.wikipedia.org/wiki?curid=22177759", "title": "1990 Wayne County Airport runway collision", "text": "1990 Wayne County Airport runway collision\n\nThe Wayne County Airport runway collision involved the collision of two Northwest Airlines planes in dense fog at Detroit Metropolitan Wayne County Airport on December 3, 1990. It occurred when Flight 1482, a scheduled Douglas DC-9-14 operating from Detroit to Pittsburgh International Airport, taxied onto an active runway by mistake in dense fog and was hit by a departing Boeing 727 operating as Flight 299 to Memphis International Airport. One crew and seven occupants of the DC-9 were killed.\n\nNorthwest 1482 was cleared from the gate towards Runway 03C, but it missed turning onto taxiway Oscar 6 and instead entered the Outer taxiway. To correct the error they were instructed to turn right onto Taxiway Xray but they turned onto the active runway 03C. They realised the mistake and contacted air traffic for instructions who told them to leave the runway immediately, five seconds later (at 13:45 EST) the crew saw a Boeing 727 heading towards them. The Boeing 727 was operating the Northwest 299 flight to Memphis and had just been cleared for take-off. The 727 wing hit the right-hand side of the DC-9 and cut through the fuselage just below the windows until it cut off the DC-9's #2 engine. The DC-9 caught fire and was destroyed; the 727 just had a damaged wing and was later repaired.\n\nThe captain escaped from the aircraft through the left sliding window. 18 people escaped from the aircraft from the left overwing exit. 13 persons got out through the left main boarding door. 4 people jumped from the right service door. The rear jumpseat flight attendant and a passenger died from smoke inhalation in the DC-9's tailcone; the tailcone release was not activated, and later investigation determined that the tailcone release mechanism was mechanically inoperable.\n\nOf the surviving passengers, the NTSB stated that 10 received serious injuries and 23 received minor or no injuries. The three surviving crew members received minor or no injuries. The NTSB added that it did not receive medical records for three passengers who were admitted to a burn center; for the purposes of the report, the NTSB labeled their injuries as serious. The NTSB did not receive medical records for the copilot and 6 passengers who were treated and released from area hospitals; for the purposes of the report the NTSB assumed that they received minor injuries.\n\nThe Douglas DC-9 operating Flight 1482 was registered N3313L built in 1966 and had a total of 62,253 operating hours. The DC-9 was delivered new to Delta before being sold to Northwest predecessor Southern Airways in 1973. The Boeing 727 operating Flight 299 was registered N278US and had been purchased by Northwest in 1975 with a total of 37,310 operating hours. The aircraft was repaired and flew for Northwest until 1995. N278US was flown by Kitty Hawk Aircargo before being scrapped in 2011.\n\nThe accident was investigated by the National Transportation Safety Board, which determined the probable cause of the accident to be:\n\n"}
{"id": "27184621", "url": "https://en.wikipedia.org/wiki?curid=27184621", "title": "Alvarado I", "text": "Alvarado I\n\nAlvarado I is a large solar thermal power station in Alvarado, province of Badajoz, in Extremadura, Spain. Construction on the plant commenced in December 2007 and was completed in July 2009, when commercial operations began. With an installed capacity of , it is one of the largest solar thermal power stations in the world.\n\nThe facility is built on a site with a solar resource of , producing an estimated of electricity per year (an average power of 12 MW). The plant uses parabolic trough technology, and is made up of 768 solar thermal collectors, with an output temperature of , transferred with Biphenyl and Diphenyl oxide heat transfer agents.\n\nA second facility, Alvarado II, is currently on the proposal stage. It is planned to be constructed in the same area as Alvarado I.\n\n"}
{"id": "30528084", "url": "https://en.wikipedia.org/wiki?curid=30528084", "title": "Annual Review of Condensed Matter Physics", "text": "Annual Review of Condensed Matter Physics\n\nThe Annual Review of Condensed Matter Physics is an annual peer-reviewed review journal published by Annual Reviews. It was established in 2010 and covers advances in condensed matter physics and related subjects. The editor-in-chief is James S. Langer (University of California, Santa Barbara). According to the \"Journal Citation Reports\", the journal has a 2016 impact factor of 18.588.\n"}
{"id": "20951850", "url": "https://en.wikipedia.org/wiki?curid=20951850", "title": "Argonne–Northwestern Solar Energy Research Center", "text": "Argonne–Northwestern Solar Energy Research Center\n\nThe Argonne–Northwestern Solar Energy Research Center (ANSER Center) is a joint research program between the Argonne National Laboratory and Northwestern University. Michael R. Wasielewski, Professor of Chemistry at Northwestern founded the ANSER center in 2007 and is its current director. The center's goal is to develop the fundamental understanding, materials, and methods necessary to create efficient and economically viable technologies for solar fuels and electricity production. The union of synthesis, measurement, theory, and engineering allows ANSER to create exceptional new energy conversion systems. As part of its $777 million effort to establish Energy Frontier Research Centers, Grants provided by the US Department of Energy will enable the ANSER \"to analyse photosynthesis for ways to create more efficient photovoltaic cells and create hybrid solar cells that have both organic and inorganic components.\"\n\nThe ANSER Center was established in July 2007 and joins established strengths at Northwestern University (NU) and Argonne National Laboratory (Argonne) with those of senior personnel at Yale University, the University of Illinois at Urbana-Champaign (UIUC), and the University of Chicago (UC) in molecular and nanostructured assemblies, materials, catalysts, and phenomena integral to solar energy conversion and storage.\n\nVision\nThe long-term vision of the ANSER Center is to develop the fundamental understanding, materials and methods necessary to create dramatically more efficient technologies for solar fuels and electricity production. The center plans to achieve this vision by designing and synthesizing new nanoscale architectures and studying them to deepen the understanding of basic solar energy conversion phenomena. The union of synthesis, measurement, theory, and engineering will allow ANSER to create exceptional new energy conversion systems. At the same time, the ANSER Center seeks to create and mentor a technically excellent workforce capable of solving energy-related problems far into the future.\n\nObjective\nThe purpose of multi-disciplinary research carried out by the ANSER Center is to develop a fundamental understanding of the:\n-Interaction of light and charge with molecules and materials \n-Energy levels and electronic structures of molecules and materials \n-Dynamics of photo-induced charge generation, separation, and transport with unparalleled temporal and spatial resolution \n-Interfaces at which charge generation, separation, transport, and selective chemical reactions occur \n-Properties of unique materials, from self-assembling, bio-inspired materials for hydrogen fuel production from water to transparent conductors, and nanostructured hard and soft materials for solar electricity generation\n\nEducation and Outreach\nThe ANSER Center works closely with the NU-based National Center for Learning and Teaching in Nanoscale Science and Engineering (NCLT) to develop outreach programs to the science education community. NCLT participants include Argonne and UIUC, among others as primary partners. ANSER holds joint summer programs with NCLT in the area of undergraduate solar cell and nanotechnology research, professional development, summer research for science teachers, and year-round research with faculty members from partnering minority institutions. Web-based educational materials on solar energy conversion and Web podcasts on topics in the field of solar energy conversion are currently under development. These will be made available broadly to the general public and the K-16 educational establishment.\n\n"}
{"id": "200612", "url": "https://en.wikipedia.org/wiki?curid=200612", "title": "Automotive aerodynamics", "text": "Automotive aerodynamics\n\nAutomotive aerodynamics is the study of the aerodynamics of road vehicles. Its main goals are reducing drag and wind noise, minimizing noise emission, and preventing undesired lift forces and other causes of aerodynamic instability at high speeds. Air is also considered a fluid in this case. For some classes of racing vehicles, it may also be important to produce downforce to improve traction and this cornering abilities.\n\nThe frictional force of aerodynamic drag increases significantly with vehicle speed. As early as the 1920s engineers began to consider automobile shape in reducing aerodynamic drag at higher speeds. By the 1950s German and British automotive engineers were systematically analyzing the effects of automotive drag for the higher performance vehicles. By the late 1960s scientists also became aware of the significant increase in sound levels emitted by automobiles at high speed. These effects were understood to increase the intensity of sound levels for adjacent land uses at a non-linear rate. Soon highway engineers began to .design roadways to consider the speed effects of aerodynamic drag produced sound levels, and automobile manufacturers considered the same factors in vehicle design.\n\nAn aerodynamic automobile will integrate the wheel arcs and lights into the overall shape to reduce drag. It will be streamlined; for example, it does not have sharp edges crossing the wind stream above the windshield and will feature a sort of tail called a fastback or Kammback or liftback.\nNote that the Aptera 2e, the Loremo, and the Volkswagen 1-litre car try to reduce the area of their back.\nIt will have a flat and smooth floor to support the Venturi effect and produce desirable downwards aerodynamic forces. - is used for cooling, combustion, and for passengers, then reaccelerated by a nozzle and then ejected under the floor.\nFor mid and rear engines air is decelerated and pressurized in a diffuser, loses some pressure as it passes the engine bay, and fills the slipstream. These cars need a seal between the low pressure region around the wheels and the high pressure around the gearbox.\nThey all have a closed engine bay floor.\nThe suspension is either streamlined (Aptera) or retracted.\nDoor handles, the antenna, and roof rails can have a streamlined shape. The side mirror can only have a round fairing as a nose.\nAir flow through the wheel-bays is said to increase drag (German source) though race cars need it for brake cooling and many cars emit the air from the radiator into the wheel bay.\n\nAutomotive aerodynamics differs from aircraft aerodynamics in several ways. First, the characteristic shape of a road vehicle is much less streamlined compared to an aircraft. Second, the vehicle operates very close to the ground, rather than in free air. Third, the operating speeds are lower (and aerodynamic drag varies as the square of speed). Fourth, a ground vehicle has fewer degrees of freedom than an aircraft, and its motion is less affected by aerodynamic forces. Fifth, passenger and commercial ground vehicles have very specific design constraints such as their intended purpose, high safety standards (requiring, for example, more 'dead' structural space to act as crumple zones), and certain regulations.\n\nAutomotive aerodynamics is studied using both computer modelling and wind tunnel testing. For the most accurate results from a wind tunnel test, the tunnel is sometimes equipped with a rolling road. This is a movable floor for the working section, which moves at the same speed as the air flow. This prevents a boundary layer from forming on the floor of the working section and affecting the results.\n\nDrag coefficient (C) is a commonly published rating of a car's aerodynamic smoothness, related to the shape of the car. Multiplying C by the car's frontal area gives an index of total drag. The result is called \"drag area\", and is listed below for several cars. The width and height of curvy cars lead to gross overestimation of frontal area. These numbers use the manufacturer's frontal area specifications from the Mayfield Company unless noted. Drag area figures that do not reflect drag coefficient and frontal area figures from independent aerodynamic testing (e.g. drag areas based on manufacturer-reported figures or educated speculation) are indicated with an asterisk (*).\n\nDownforce describes the downward pressure created by the aerodynamic characteristics of a car that allows it to travel faster through a corner by holding the car to the track or road surface. Some elements to increase vehicle downforce will also increase drag.\nIt is very important to produce a good downward aerodynamic force because it affects the car's speed and traction.\n\n"}
{"id": "59041972", "url": "https://en.wikipedia.org/wiki?curid=59041972", "title": "Azerishiq", "text": "Azerishiq\n\nThe history of Azerishiq OJSC has also been formed in Baku with the history of electricity. The first power plant in Baku was installed in 1895 in the \"Bakinski dock\" on Bayil highway. In 1903, the number of power stations reached 70.\n\nIn 1880, the cruise ship company \"Qafqaz and Mercury\" in the Volga River and the Caspian Sea had installed new electric lanterns at the passenger port in Baku.\n\nOn January 21, 1899, the Baku Branch of the Berlin Joint Stock Company \"Elektricheskaya Sila\" was established in the city, which was a branch of Siemens Galske's 1886 Electricity Lighting Society. This firm was involved in financing, design and survey works, construction, equipment and supplies.\n\nOne of the members of the Executive Board of the Baku Branch of the \"Electricheskie Sila\" was millionaire Haji Zeynalabdin Taghiyev. The founders of the society were Baron Vrangel, graphic I. Golenishev-Kutuzov-Tolstoy, and real civil consultant V. Golubev.\n\nAlong with foreign investment, the share of local investment increased by Haji Zeynalabdin Taghiyev, Musa Nagiyev, Isa Bey Hacinski, Shamsi Asadullayev, Murtuza Mukhtarov and others.\n\nThe Elektrieskaya Sila joint stock company has been engaged in the preparation of hiring laboratories, conducting correspondence with various organizations, oil owners, businessmen, the city administration, and hiring laborers and inviting specialists before starting construction. At the beginning of 1900 the management of the Baku department prepared a report compiled by figures and calculations. Immediately after that, Siemens and Galske started building Bibi-Heybat - Bayil Nose and Beliy Gorod's second power plant.\n\nAt the beginning of July 1901, Bibi-Heybat Power Station was tested, and a week later the station was put into operation. One year later, the Beliy Gorod power plant was commissioned to supply oil to Sabunchu and to the oil refineries in Chorniy-Gorod.\n\nMore than 50% of the electricity used by the Nobel Brothers' Association and Baron Rothschild's \"Caspian-Black Sea Oil Industry and Commodity Society\".\n\nIn March 1906, two 8.1 km voltage lines were constructed from the power station in Beliy Gorod to Balakhani oil filed.\n\nIn 1916, 1638 of 3750 bore mining functioning in Absheron were electrified.\n\nThe next development took place in 1909-1920. At the same time, air and cable networks were strengthened. More than 60 transformer and distribution points were set up in Balakhani, Ramana and Surakhani districts. In 1913, Bibi-Heybat had to be expanded, as the station's reserves were exhausted. At that time, an agreement was reached to join the 50 wells of \"Oleum i Born\" company.\n\nBaku electricity grid has been operating in the following structures since 1920:\n\n\nThe construction phase of the work, the construction of large semi-substations, transmission lines, and production facilities has been widening since the 1970s.\n\nOn October 20, 2000 the first turn of Baku-Heating Center No. 1 is put into operation.\n\nAfter restoration of Bakielektrikshebeke's activity in 2006, an order was issued to allocate funds from the Presidential Reserve Fund for the development and investment in this area in accordance with modern standards.\n\nBy the decree signed by President on February 10, 2015, the name of Bakielectricshebeke OJSC changed into Azerishiq OJSC. Balababa Rzayev appointed as president of Azerishiq. Functions of Azerenerji OJSC including all its property and electric energy supply equipment was transferred to Azerishiq from The Cabinet of Ministers.\n\nIn 2015, Azerishiq prepared “Power distribution Modernization Project” with the financial help of World Bank. The aim of the project is development and modernization of the distribution network, improvement of reliable power supply, and enhance efficient energy.\n\nAzerishiq OJSC signed a loan agreement with Asian Development Bank (ADB) on 22 July 2016, in the framework of “Power Distribution Enhancement Investment Program – Tranche 1”.  In 2016, ADB approved 750-million-dollar loan facility for the development of power reliability in Azerbaijan. By this agreement rehabilitation of distribution network substations and lines and installation of modern customer services will be realized.\n\nAzerenerji\n\n"}
{"id": "12869729", "url": "https://en.wikipedia.org/wiki?curid=12869729", "title": "Backstay insulator", "text": "Backstay insulator\n\nBackstay insulators, when used as a pair, are devices which allow for the electrical isolation of a section of wire on a yacht (e.g. the backstay) so that it can be used as an antenna for a single sideband (SSB) radio.\n\nSince these insulators form part of the rigging, not only must they not leak current, but they must also be strong and durable enough not to fail mechanically under the sometimes tough load conditions experienced in sailing.\n\nManufacturers include Hi-MOD, Norseman-Gibb and Sta-Lok. Each design is slightly different, but all share the common characteristics of having two attachment points set back-to-back and separated by some insulating material. \n\nThe Hi-MOD system has been designed in such a way that if the insulating material (typically some sort of plastic) were to fail mechanically, the fitting would retain structural integrity, keeping the wire from separating even when it stops functioning as an insulator.\n"}
{"id": "42099008", "url": "https://en.wikipedia.org/wiki?curid=42099008", "title": "Bath Cabinet Makers", "text": "Bath Cabinet Makers\n\nBath Cabinet Makers Ltd. traded for sixty-seven years (1892–1959) in a city, Bath, Somerset, England, with a history of furniture-making. Under management of Charles A Richter (1876–1945) until 1934, its work was regularly illustrated in \"The Studio\" and the company soon began to receive international prizes. A variety of styles was produced, from Parisian-inspired versions of 'Adam' to Art Nouveau, Art Deco, Arts and Crafts and streamlined Modern in a huge range of woods, solid and veneer. Important contracts included furniture and fittings for Cunard's luxury liners, the Queen Mary and Queen Elizabeth. A proportion of its output was mass-produced for cheaper markets although the workmanship was always of a high standard.\n\nBuilt in 1895, the factory on Bellots Road, Twerton was one of the largest and best equipped in the country. Bath Timber Supply Ltd and Bath Guild of Handicraft and Design were set up in the 1920s to support Bath Cabinet Makers. George Montague Elwood was responsible for many of the Art Nouveau pieces around 1899–1900, but most of Bath Cabinet Makers's furniture was designed by the Richter brothers, Charles Augustus (1867–1946), Herbert Davis (1874–1955) and their team. Charles Richter became president of the National Federation of Furniture Trades and was appointed to Lord Gorell's Commission on improving the standard of art in industry. In JC Rogers' Modern English Furniture (1930) he is one of forty-two designers listed beside the better-known Barnsleys and Edwin Lutyens.\n\nBath Cabinet Makers owed its existence to a strike at F and A Norris Brothers' Bath's Albion Cabinet Works in December 1891. The following year, Charles Richter, an employee at Albion, launched the Bath and West Co-operative Cabinet Makers Ltd. The intention was determinedly idealistic; men needed jobs and the city provided enterprise. Shareholders were represented by a committee five members, one of whom was the influential Cedric Chivers from the bookbinding family. Richter was elected general manager the following month, and work began in rented accommodation.\n\nIn 1892 the name was contracted to The Bath Cabinet Makers Ltd. The next year, Charles Richter walked out, objecting to the Shareholders' reluctance to expand. Two years later the Society called him back as managing director, with Herbert Davis Richter Head of the Design Department. Herbert Davis Richter's drawings were reproduced in all the relevant leading architectural journals. In 1895 the brothers collaborated with Messrs Silcock and Reay on the design of a distinctive new building. In 1900, the firm won five medals at the Paris World Exhibition.\n\nPrior to World War I, Bath Cabinet Makers furniture was on constant display in London stores such as Maples and Harrods.\nWhile Herbert Davis Richter left Bath Cabinet Makers in 1906 to become a painter, Charles Richter's hope of early retirement were interrupted by the war. The factories were converted to manufacture aircraft parts, to be restored to panelling, joinery and high-class furniture when the war ended. The family interest was extended when Herbert Davis Richter's wife, Gertrude, and Charles Richter's sister, Florence Schottler, launched The Guild of Handicraft and Design to make soft furnishings for large contracts coming in from America, India and Germany. Further recognition was earned at the British Empire Exhibition at Wembley of 1924 and the Paris Exhibition of 1925. CAR's elder son Ian joined the firm in the early 1920s and became managing director in 1934. He produced some fine wood carvings that were used in the setting of BCM furniture, many on the Queen Elizabeth. The 1930s depression affected demand for luxury furniture but Charles Richter managed to keep his firm afloat.\n\nWilliam Morris considered that machines were responsible for bad design. As handwork was necessarily time-consuming, his furniture was too expensive for the very people he wanted to supply. In contrast, Charles Richter, a committed socialist and natural progressive, deplored asking men to perform arduous tasks that could easily be accomplished by machine. In Bath Cabinet Makers's early days, he set up an Education Committee and ran games and dramatic clubs. Acquainted with GB Shaw, he asked the playwright down to Bath for a performance of Caesar and Cleopatra.\n\nIn 1959 the firm was taken over by Yatton Furniture, its name and the goodwill lasted for more than a century. Plagiarism had been a continual battle. From the outset Bath Cabinet Makers's prolific output and range of styles led to pirating by other companies. This has led to much of their work being attributed to other firms. Current research into Wylie & Lochhead and Bath Cabinet Makers reveals that prestigious museums throughout the country have believed that Bath Cabinet Makers furniture was made by the Scottish cabinet-making firm.\n\nThe company became part of the Christie-Tyler furniture group and in 1986 was bought out by Ken Fullalove, one of their directors.\n\n\n"}
{"id": "52636", "url": "https://en.wikipedia.org/wiki?curid=52636", "title": "Boiling", "text": "Boiling\n\nBoiling is the rapid vaporization of a liquid, which occurs when a liquid is heated to its boiling point, the temperature at which the vapour pressure of the liquid is equal to the pressure exerted on the liquid by the surrounding atmosphere. There are two main types of boiling ; nucleate boiling where small bubbles of vapour form at discrete points, and critical heat flux boiling where the boiling surface is heated above a certain critical temperature and a film of vapor forms on the surface. Transition boiling is an intermediate, unstable form of boiling with elements of both types. The boiling point of water is 100 °C or 212 °F but is lower with the decreased atmospheric pressure found at higher altitudes.\n\nBoiling water is used as a method of making it potable by killing microbes that may be present. The sensitivity of different micro-organisms to heat varies, but if water is held at 70 °C (158 °F) for ten minutes, many organisms are killed, but some are more resistant to heat and require one minute at the boiling point of water.\n\nBoiling is also used in cooking. Foods suitable for boiling include vegetables, starchy foods such as rice, noodles and potatoes, eggs, meats, sauces, stocks, and soups. As a cooking method, it is simple and suitable for large-scale cookery. Tough meats or poultry can be given a long, slow cooking and a nutritious stock is produced. Disadvantages include loss of water-soluble vitamins and minerals. Commercially prepared foodstuffs are sometimes packed in polythene sachets and sold as \"boil-in-the-bag\" products.\n\n\"Nucleate boiling\" is characterized by the growth of bubbles or pops on a heated surface, which rises from discrete points on a surface, whose temperature is only slightly above the liquids. In general, the number of nucleation sites are increased by an increasing surface temperature.\n\nAn irregular surface of the boiling vessel (i.e., increased surface roughness) or additives to the fluid (i.e., surfactants and/or nanoparticles) can create additional nucleation sites, while an exceptionally smooth surface, such as plastic, lends itself to superheating. Under these conditions, a heated liquid may show boiling delay and the temperature may go somewhat above the boiling point without boiling.\n\nAs the boiling surface is heated above a critical temperature, a film of vapor forms on the surface. Since this vapor film is much less capable of carrying heat away from the surface, the temperature rises very rapidly beyond this point into the transition boiling regime. The point at which this occurs is dependent on the characteristics of boiling fluid and the heating surface in question.\n\n\"Transition boiling\" may be defined as the unstable boiling, which occurs at surface temperatures between the maximum attainable in nucleate and the minimum attainable in film boiling.\n\nThe formation of bubbles in a heated liquid is a complex physical process which often involves cavitation and acoustic effects, such as the broad-spectrum hiss one hears in a kettle not yet heated to the point where bubbles boil to the surface.\n\nIf a surface heating the liquid is significantly hotter than the liquid then film boiling will occur, where a thin layer of vapor, which has low thermal conductivity, insulates the surface. This condition of a vapor film insulating the surface from the liquid characterizes \"film boiling\".\n\nAs a method of disinfecting water, bringing it to its boiling point at , is the oldest and most effective way since it does not affect the taste, it is effective despite contaminants or particles present in it, and is a single step process which eliminates most microbes responsible for causing intestine related diseases. According to WolframAlpha, water's boiling point rests at around 100.3 degrees celcius, when at an elevation of 0. In places having a proper water purification system, it is recommended only as an emergency treatment method or for obtaining potable water in the wilderness or in rural areas, as it cannot remove chemical toxins or impurities.\n\nThe elimination of micro-organisms by boiling follows first-order kinetics—at high temperatures, it is achieved in less time and at lower temperatures, in more time. The heat sensitivity of micro-organisms varies, at , Giardia species (causes Giardiasis) can take ten minutes for complete inactivation, most intestine affecting microbes and \"E. coli\" (gastroenteritis) take less than a minute; at boiling point, \"Vibrio cholerae\" (cholera) takes ten seconds and hepatitis A virus (causes the symptom of jaundice), one minute. Boiling does not ensure the elimination of all micro-organisms; the bacterial spores Clostridium can survive at but are not water-borne or intestine affecting. Thus for human health, complete sterilization of water is not required.\n\nThe traditional advice of boiling water for ten minutes is mainly for additional safety, since microbes start getting eliminated at temperatures greater than and bringing it to its boiling point is also a useful indication that can be seen without the help of a thermometer, and by this time, the water is disinfected. Though the boiling point decreases with increasing altitude, it is not enough to affect the disinfecting process.\n\n\"Boiling\" is the method of cooking food in boiling water or other water-based liquids such as stock or milk. Simmering is gentle boiling, while in poaching the cooking liquid moves but scarcely bubbles.\n\nThe boiling point of water is typically considered to be 100 °C or 212 °F. Pressure and a change in the composition of the liquid may alter the boiling point of the liquid. For this reason, high elevation cooking generally takes longer since boiling point is a function of atmospheric pressure. In Denver, Colorado, USA, which is at an elevation of about one mile, water boils at approximately 95 °C or 203 °F. Depending on the type of food and the elevation, the boiling water may not be hot enough to cook the food properly. Similarly, increasing the pressure as in a pressure cooker raises the temperature of the contents above the open air boiling point.\n\nSome science suggests adding a water-soluble substance, such as salt or sugar also increases the boiling point. This is called boiling-point elevation. At palatable concentrations of salt, the effect is very small, and the boiling point elevation is difficult to notice and this is why experiments to prove this are considered inconclusive. However, while making thick sugar syrup, such as for Gulab Jamun, one will notice boiling point elevation. Due to variations in composition and pressure, the boiling point of water is almost never exactly 100 °C, but rather close enough for cooking.\n\nFoods suitable for boiling include vegetables, starchy foods such as rice, noodles and potatoes, eggs, meats, sauces, stocks, and soups.\n\nBoiling has several advantages. It is safe and simple, and it is appropriate for large-scale cookery. Older, tougher, cheaper cuts of meat and poultry can be made digestible. Nutritious, well-flavored stock is produced. Also, maximum color and nutritive value is retained when cooking green vegetables, provided boiling time is kept to the minimum.\n\nOn the other hand, there are several disadvantages. There is a loss of soluble vitamins from foods to the water (if the water is discarded). Boiling can also be a slow method of cooking food.\n\nBoiling can be done in several ways: The food can be placed into already rapidly boiling water and left to cook, the heat can be turned down and the food can be simmered or the food can also be placed into the pot, and cold water may be added to the pot. This may then be boiled until the food is satisfactory.\n\nWater on the outside of a pot, i.e., a wet pot, increases the time it takes the pot of water to boil. The pot will heat at a normal rate once all excess water on the outside of the pot evaporates.\n\nBoiling is also often used to remove salt from certain foodstuffs, such as bacon if a less saline product is required.\n\nAlso known as \"boil-in-bag\", this involves heating or cooking ready-made foods sealed in a thick plastic bag. The bag containing the food, often frozen, is submerged in boiling water for a prescribed time. The resulting dishes can be prepared with greater convenience as no pots or pans are dirtied in the process. Such meals are available for camping as well as home dining.\n\nAt any given temperature, all the molecules in a liquid do not have the same kinetic energy. Some high energy particles on the liquid surface may have enough energy to escape the intermolecular forces of attraction of the liquid and become a gas. This is called evaporation. \n\nEvaporation only happens on the surface while boiling happens throughout the liquid.\nWhen a liquid reaches its boiling point bubbles of gas form in it which rise into the surface and burst into the air. This process is called boiling. If the boiling liquid is heated more strongly the temperature does not rise but the liquid boils more quickly.\n\nThis distinction is exclusive to the liquid-to-gas transition; any transition directly from solid to gas is always referred to as sublimation regardless of whether it is at its boiling point or not.\n\n\n"}
{"id": "47098092", "url": "https://en.wikipedia.org/wiki?curid=47098092", "title": "Brandåa Hydroelectric Power Station", "text": "Brandåa Hydroelectric Power Station\n\nThe Brandåa Hydroelectric Power Station () is a hydroelectric power station in the municipality of Rindal in Møre og Romsdal county, Norway. It is a run-of-river hydro power station utilizing a drop of in some tributaries of the Surna River. Permission was granted for construction in 2006 and the plant came into operation in 2009. It is operated by Svorka Produksjon AS. It operates at an installed capacity of , with an average annual production of about 15.8 GWh.\n"}
{"id": "52835254", "url": "https://en.wikipedia.org/wiki?curid=52835254", "title": "Center for Year 2000 Strategic Stability", "text": "Center for Year 2000 Strategic Stability\n\nThe Center for Year 2000 Strategic Stability was a joint operation of the United States and Russian Federation designed to provide mutual assurance that neither nation was launching a nuclear first strike against the other during the transition from the year 1999 to the year 2000. The program arose out of concerns the Year 2000 problem might generate false positives in each nation's nuclear attack early warning systems.\n\nThe center came online December 30, 1999 and was closed January 15, 2000. It operated from Peterson Air Force Base.\n"}
{"id": "34754523", "url": "https://en.wikipedia.org/wiki?curid=34754523", "title": "Chorzów Power Station", "text": "Chorzów Power Station\n\nChorzów power station is a thermal power plant located in Chorzów, Silesian Voivodeship, Poland. It has been in operation since 1898, since 2003 under the name \"Elcho\".\n\nCurrently (2012), the plant produces electrical power (generating capacity of 204 MW) as well as heat (500 MW) for district heating, based on hard coal.\n\n\n"}
{"id": "47754883", "url": "https://en.wikipedia.org/wiki?curid=47754883", "title": "Conical refiner", "text": "Conical refiner\n\nThe conical refiner is a machine used in the refining of pulp in the papermaking process. It may also be referred to as a Jordan refiner, after the American inventor Joseph Jordan who patented the device in 1858.\n\nThe conical refiner is a chamber with metal bars mounted around the inside of the container. The material to be refined is pumped into the chamber at high-pressure rate in order to create an abrasive effect as the material is forced through the machine, abraided by the metal bars. At the opposite end of the chamber the resulting pulp is pumped out.\n"}
{"id": "35450358", "url": "https://en.wikipedia.org/wiki?curid=35450358", "title": "Crnogorski Elektroprenosni Sistem", "text": "Crnogorski Elektroprenosni Sistem\n\nCrnogorski Elektroprenosni Sistem AD (MNSE: PREN) (CGES; former name Prenos AD; meaning: Montenegrin Electrical Transmission System) is an electric power transmission system operator located in Podgorica, Montenegro. It is a member of European Network of Transmission System Operators for Electricity. AD stands for Akcionersko Drustvo, or Joint Stock Company. \n\nIn 2009, the company broke away from EPCG and partly privatized, with 43.7% stake in the company acquired by the Italian utility company A2A. 22% stake is owned by Italian electricity transmission company Terna.\n\nCGES and Terna are planning to build a 1,000 MW submarine cable between Tivat and Pescara. The cable to be operational by 2015.\n\nThe European Bank for Reconstruction and Development is preparing a €65 million syndicated loan for the company. The loan would be used for the construction of a new substation at Lastva, and a new line from Lastva to Pljevlja to be connected to the Italy–Montenegro interconnector.\n\n"}
{"id": "87598", "url": "https://en.wikipedia.org/wiki?curid=87598", "title": "Date palm", "text": "Date palm\n\nPhoenix dactylifera, commonly known as date or date palm, is a flowering plant species in the palm family, Arecaceae, cultivated for its edible sweet fruit. Although its place of origin is unknown because of long cultivation, it probably originated from the Fertile Crescent region straddling between Egypt and Mesopotamia. The species is widely cultivated across Northern Africa, The Middle East, The Horn of Africa and South Asia, and is naturalized in many tropical and subtropical regions worldwide. \"P. dactylifera\" is the type species of genus \"Phoenix\", which contains 12–19 species of wild date palms, and is the major source of commercial production.\n\nDate trees typically reach about in height, growing singly or forming a clump with several stems from a single root system. Date fruits (dates) are oval-cylindrical, 3–7 cm (1.2–2.8 in) long, and about an inch (2.5 cm) in diameter, ranging from bright red to bright yellow in color, depending on variety. They are very sweet, containing about 75 percent of sugar when dried.\n\nDates have been a staple food of the Middle East and the Indus Valley for thousands of years. There is archaeological evidence of date cultivation in Arabia from the 6th millennium BCE. The total annual world production of dates amounts to 8.5 million metric tons, countries of the Middle East and North Africa being the largest producers.\n\nThe species name \"dactylifera\" \"date-bearing\" comes from the Greek words \"daktylos\" (δάκτυλος), which means \"date\" (also \"finger\"), and \"fero\" (φέρω), which means \"I bear\". The fruit is known as a date. The fruit's English name (through Old French), as well as the Latin both come from the Greek word for \"finger\", \"dáktulos\", because of the fruit's elongated shape.\n\nFossil records show that the date palm has existed for at least 50 million years.\n\nDates have been a staple food of the Middle East and the Indus Valley for thousands of years. There is archaeological evidence of date cultivation in eastern Arabia between 5530 and 5320 calBC. They are believed to have originated around what is now Iraq, and have been cultivated since ancient times from Mesopotamia to prehistoric Egypt. The Ancient Egyptians used the fruits to make date wine, and ate them at harvest.\n\nThere is archeological evidence of date cultivation in Mehrgarh around 7000 BCE, a Neolithic civilization in what is now western Pakistan. Evidence of cultivation is continually found throughout later civilizations in the Indus Valley, including the Harappan period 2600 to 1900 BCE.\n\nIn Ancient Rome the palm fronds used in triumphal processions to symbolize victory were most likely those of \"Phoenix dactylifera\". The date palm was a popular garden plant in Roman peristyle gardens, though it would not bear fruit in the more temperate climate of Italy. It is recognizable in frescoes from Pompeii and elsewhere in Italy, including a garden scene from the House of the Wedding of Alexander.\n\nIn later times, traders spread dates around South West Asia, northern Africa, and Spain. Dates were introduced into Mexico and California by the Spaniards in 1765, around Mission San Ignacio.\n\nA date palm cultivar, probably what used to be called Judean date palm, is renowned for its long-lived orthodox seed, which successfully sprouted after accidental storage for 2000 years. The upper survival time limit of properly stored seeds remains unknown.\n\nDate trees typically reach about in height, growing singly or forming a clump with several stems from a single root system. The leaves are long, with spines on the petiole, and pinnate, with about 150 leaflets. The leaflets are long and wide. The full span of the crown ranges from .\n\nThe date palm is dioecious, having separate male and female plants. They can be easily grown from seed, but only 50% of seedlings will be female and hence fruit bearing, and dates from seedling plants are often smaller and of poorer quality. Most commercial plantations thus use cuttings of heavily cropping cultivars. Plants grown from cuttings will fruit 2–3 years earlier than seedling plants.\n\nDates are naturally wind pollinated, but in both traditional oasis horticulture and in the modern commercial orchards they are entirely pollinated manually. Natural pollination occurs with about an equal number of male and female plants. However, with assistance, one male can pollinate up to 100 females. Since the males are of value only as pollinators, this allows the growers to use their resources for many more fruit-producing female plants. Some growers do not even maintain any male plants, as male flowers become available at local markets at pollination time. Manual pollination is done by skilled labourers on ladders, or by use of a wind machine. In some areas such as Iraq the pollinator climbs the tree using a special climbing tool that wraps around the tree trunk and the climber's back (called تبلية in Arabic) to keep him attached to the trunk while climbing.\n\nDate fruits are oval-cylindrical, long, and diameter, and when ripe, range from bright red to bright yellow in colour, depending on variety. Dates contain a single stone about long and thick. Three main cultivar groups of date exist: soft (e.g. 'Barhee', 'Halawy', 'Khadrawy', 'Medjool'), semi-dry (e.g. 'Dayri', 'Deglet Noor', 'Zahdi'), and dry (e.g. 'Thoory'). The type of fruit depends on the glucose, fructose, and sucrose content.\n\nIn 2009, a team of researchers at the Weill Cornell Medical College in Qatar published a draft version of the date palm genome (Khalas variety).\n\nDates are an important traditional crop in Iraq, Arabia, and north Africa west to Morocco. Dates (especially Medjool and Deglet Noor) are also cultivated in America in southern California, Arizona and southern Florida in the United States and in Sonora and Baja California in Mexico.\n\nDate palms can take 4 to 8 years after planting before they will bear fruit, and start producing viable yields for commercial harvest between 7 and 10 years. Mature date palms can produce of dates per harvest season, although they do not all ripen at the same time so several harvests are required. In order to get fruit of marketable quality, the bunches of dates must be thinned and bagged or covered before ripening so that the remaining fruits grow larger and are protected from weather and pests such as birds.\nDate palms require well-drained deep sandy loam soils with pH 8-11. The soil should have the ability to hold the moisture. The soil should also be free from calcium carbonate.\n\nA large number of date cultivars are grown. The most important are:\n\n\nThe Gaza Strip, especially Deir al-Balah (\"Village of Dates\"), is known for its exceptionally sweet red dates.\n\nA major palm pest, the red palm beetle (\"Rhynchophorus ferrugineus\") currently poses a significant threat to date production in parts of the Middle East as well as to iconic landscape specimens throughout the Mediterranean world.\n\nIn the 1920s, eleven healthy Madjool palms were transferred from Morocco to the United States where they were tended by members of the Chemehuevi tribe in a remote region of Nevada. Nine of these survived and in 1935, cultivars were transferred to the \"U.S. Date Garden\" in Indio, California. Eventually this stock was reintroduced to Africa and led to the U.S. production of dates in Yuma, Arizona and the Bard Valley in California.\n\nDry or soft dates are eaten out-of-hand, or may be pitted and stuffed with fillings such as almonds, walnuts, pecans, candied orange and lemon peel, tahini, marzipan or cream cheese. Pitted dates are also referred to as \"stoned dates\". Partially dried pitted dates may be glazed with glucose syrup for use as a snack food. Dates can also be chopped and used in a range of sweet and savory dishes, from tajines (tagines) in Morocco to puddings, ka'ak (types of Arab cookies) and other dessert items. Date nut bread, a type of cake, is very popular in the United States, especially around holidays. Dates are also processed into cubes, paste called \"'ajwa\", spread, date syrup or \"honey\" called \"dibs\" or \"rub\" in Libya, powder (date sugar), vinegar or alcohol. Vinegar made from dates is a traditional product of the Middle East. Recent innovations include chocolate-covered dates and products such as sparkling date juice, used in some Islamic countries as a non-alcoholic version of champagne, for special occasions and religious times such as Ramadan. When Muslims break fast in the evening meal of Ramadan, it is traditional to eat a date first.\n\nReflecting the maritime trading heritage of Britain, imported chopped dates are added to, or form the main basis of a variety of traditional dessert recipes including sticky toffee pudding, Christmas pudding and date and walnut loaf. They are particularly available to eat whole at Christmas time. Dates are one of the ingredients of HP Sauce, a popular British condiment.\n\nDates can also be dehydrated, ground and mixed with grain to form a nutritious stockfeed.\n\nIn Southeast Spain (where a large date plantation exists including UNESCO-protected Palmeral of Elche) dates (usually pitted with fried almond) are served wrapped in bacon and shallow fried.\n\nIn Israel date syrup, termed \"silan\", is used while cooking chicken and also for sweet and desserts, and as a honey substitute.\n\nDates are one of the ingredients of Jallab, a Middle-Eastern fruit syrup.\n\nIn Pakistan, a viscous, thick syrup made from the ripe fruits is used as a coating for leather bags and pipes to prevent leaking.\n\nDates provide a wide range of essential nutrients, and are a very good source of dietary potassium. The sugar content of ripe dates is about 80%; the remainder consists of protein, fiber, and trace elements including boron, cobalt, copper, fluorine, magnesium, manganese, selenium, and zinc. The glycemic index for three different varieties of dates are 35.5 (khalas), 49.7 (barhi), and 30.5 (bo ma'an).\n\nThe caffeic acid glycoside 3-O-caffeoylshikimic acid (also known as dactylifric acid) and its isomers, are enzymic browning substrates found in dates.\n\nDate seeds are soaked and ground up for animal feed. Their oil is suitable for use in soap and cosmetics. Date palm seeds contain 0.56–5.4% lauric acid. They can also be processed chemically as a source of oxalic acid. Date seeds are also ground and used in the manner of coffee beans, or as an additive to coffee.\nExperimental studies have shown that feeding mice with the aqueous extract of date pits exhibit anti-genotoxic and reduce DNA damage induced by N-nitroso-N-methylurea.\n\nStripped fruit clusters are used as brooms. Recently the floral stalks have been found to be of ornamental value in households.\n\nApart from \"P. dactylifera\", wild date palms such as \"Phoenix sylvestris\" and \"Phoenix reclinata\", depending on the region, can be also tapped for sap.\n\nDate palm leaves are used for Palm Sunday in the Christian religion. In North Africa, they are commonly used for making huts. Mature leaves are also made into mats, screens, baskets and fans. Processed leaves can be used for insulating board. Dried leaf petioles are a source of cellulose pulp, used for walking sticks, brooms, fishing floats and fuel. Leaf sheaths are prized for their scent, and fibre from them is also used for rope, coarse cloth, and large hats. The leaves are also used as a lulav in the Jewish holiday of Sukkot.\n\nYoung date leaves are cooked and eaten as a vegetable, as is the terminal bud or heart, though its removal kills the palm. The finely ground seeds are mixed with flour to make bread in times of scarcity. The flowers of the date palm are also edible. Traditionally the female flowers are the most available for sale and weigh . The flower buds are used in salad or ground with dried fish to make a condiment for bread.\n\nDates are mentioned more than 50 times in the Bible and 20 times in the Qur'an. In Islamic culture, dates and yogurt or milk are traditionally the first foods consumed for Iftar after the sun has set during Ramadan.\n\nThe date palm represents the provincial tree of Balochistan (Pakistan) (unofficial).\n\nIn the Quran, Allah instructs \"Maryām\" (the Virgin Mary) to eat dates when she gives birth to Isa (Jesus); and, similarly, they are recommended to pregnant women.\n\n\"Phoenix dactylifera\" held great significance in early Judaism and subsequently in Christianity, in part because the tree was heavily cultivated as a food source in ancient Israel.\nIn the Bible palm trees are referenced as symbols of prosperity and triumph. In Psalm 92:12 \"The righteous shall flourish like the palm tree\". Palm branches occurred as iconography in sculpture ornamenting the Second Jewish Temple in Jerusalem, on Jewish coins, and in the sculpture of synagogues. They are also used as ornamentation in the Feast of the Tabernacles. Palm branches were scattered before Jesus as he entered Jerusalem on Palm Sunday.\n\n"}
{"id": "46405497", "url": "https://en.wikipedia.org/wiki?curid=46405497", "title": "Demand-based switching", "text": "Demand-based switching\n\nDemand-based switching (DBS) is a computer technology term which refers to the process of using software to optimize the use of hardware resources.\n\nIntel uses demand-based switching power management technology to control power voltage consumption at different states of a computer's operations. DBS routines select a minimum clock speed of the microprocessor appropriate to the workload which specific tasks being performed by the computer place on the processor. This results in less electricity being consumed, both by the processor and by fans counteracting excess heat output. \n\nIntel's processor technology takes advantage of DBS techniques. AMD processors uses a similar process, which the company calls \"Power Now\".\n\nDemand-based switching is also sometimes used in route-caching routines in local area networks to ensure efficient packet switching and traffic flow. Software DBS algorithms are frequently used in Linux servers.\n"}
{"id": "46679172", "url": "https://en.wikipedia.org/wiki?curid=46679172", "title": "Deployable Tactical Engagement System", "text": "Deployable Tactical Engagement System\n\nThe Deployable Tactical Engagement System is a training device manufactured by SAAB used by the British Army. It consists of an infrared projector mounted on the SA80 and the Vektor R4, and a harness with receptors to receive the beams to simulate hits when firing blank ammunition.\n\n\n"}
{"id": "10663407", "url": "https://en.wikipedia.org/wiki?curid=10663407", "title": "Diablo Foothills Regional Park", "text": "Diablo Foothills Regional Park\n\nDiablo Foothills Regional Park is a regional park of the East Bay Regional Park District. It is located in Contra Costa County, in the East Bay region of northern California.\n\nThe park lies in the Diablo Foothills of the northern Diablo Range, west of Mount Diablo and Mount Diablo State Park. The closest city is Walnut Creek. \n\nDiablo Foothills Regional Park is bordered by: Castle Rock Regional Recreation Area on the east, and Shell Ridge Open Space to the north. Together, these three parks provide of parkland for visitors to enjoy. \n\n\n"}
{"id": "17904301", "url": "https://en.wikipedia.org/wiki?curid=17904301", "title": "Eolica Grǎdina Wind Farm", "text": "Eolica Grǎdina Wind Farm\n\nThe Eolica Grădina Wind Farm is a proposed wind power project in Grădina, Constanţa County, Romania. It consists of two individual wind farms connected together. It will have 31 individual wind turbines with a nominal output of around 2 MW which will deliver up to 62 MW of power, enough to power over 41,000 homes, with a capital investment required of approximately US$75 million.\n"}
{"id": "17147022", "url": "https://en.wikipedia.org/wiki?curid=17147022", "title": "European Nuclear Society", "text": "European Nuclear Society\n\nSince being founded in 1975, the European Nuclear Society (ENS) has grown to become the largest society in Europe for science, engineering and research in support of the nuclear industry. ENS’s membership consists of national nuclear societies from 22 European countries, plus Israel. Within the membership there are also stakeholder representatives for nuclear technology and research businesses, with around 60 corporate members. \nENS exists to promote the advancement of peaceful uses of nuclear energy on an international level, encouraging networking between countries and facilitating meetings to support global communication on scientific and technical affairs. ENS also supports education and training in engineering, promotes international standardisation in the nuclear industry, coordinates the activities of the member organisations and develops the expertise and capability needed for the future of the industry. \nOne of ENS’s activities is organising conferences and workshops, providing a platform for international forums to exchange knowledge, experience, ideas and scientific developments.\n\nThe current president of the European Nuclear Society is Noël Camarcat.\n\nThe ENS is member of the International Nuclear Societies Council (INSC).\n\nThe ENS Young Generation Network (YGN) has been active across the society’s member countries since 1995 when ENS supported a proposal from Jan Runermark, the then President-elect of ENS, to spread the Young Generation Network (YGN) to all its member countries. Five objectives ensure that YGN members are working towards a common goal, these are:\n\nYGN membership is available to anybody working in the nuclear industry, as well as fields of nuclear academia and research.\n\nThe European Nuclear Young Generation Forum (ENYGF) is a biennial international event, held since 2005 by the Young Generation Network (YGN) as part of the European Nuclear Society. The forum alternates with the International Youth Nuclear Congress (IYNC) and is held in a different location in Europe each time.\n\nThe aim of the event is to provide a platform for learning and networking for young professionals in all areas of nuclear application. It provides a chance to enhance international communication as well as sharing technical advances and knowledge, learning from experience and discussing best practice as well as considering social and political aspects of the nuclear industry.\n\nThe forum involves:\n\nEach forum has a number of central focuses, around which the speakers, lectures, presentations and workshops are based. In 2011, the forum in Prague focused on the topics of nuclear safety and severe accidents, education and training, new build projects and ITER and fusion. At the 2015 forum in Paris the main focus points were nuclear efficiency and nuclear and the environment.\n\nFollowing the success of IYNC conferences which began in the year 2000, the ENS-YGN decided to create the ENYGF 2005 and host the inaugural event in the city Zagreb, Croatia. Following this, the ENS-YGN elected cities to host the event every two years, the host locations to date have been:\n\nThe events are organized by an executive committee from the selected country. This executive committee can acquire assistance from delegates of other countries who chose to collaborate. All the committee members have a common goal which is to further the ENS-YGN mission and help to create a global community of nuclear professionals.\n\n"}
{"id": "2120902", "url": "https://en.wikipedia.org/wiki?curid=2120902", "title": "FreedomCAR and Vehicle Technologies", "text": "FreedomCAR and Vehicle Technologies\n\nThe FreedomCAR and Vehicle Technologies (FCVT) is a U.S. national Office of Energy Efficiency and Renewable Energy program developing more energy efficient and environmentally friendly highway transportation technologies that will enable the U.S to use less petroleum. It is currently run by Michael Berube. The long-term aim is to develop \"leap frog\" technologies that will provide Americans with greater freedom of mobility and energy security, while lowering costs and reducing impacts on the environment.\n\nThe Office of FreedomCAR and Vehicle Technologies (FCVT) is in the Department of Energy (DoE).\n\nThe Clean Cities Program is part of the Office of Energy Efficiency and Renewable Energy's FreedomCAR & Vehicle Technologies Program.\n\nThe mission of Clean Cities is to advance the nation's economic, environmental, and energy security by supporting local decisions to adopt practices that contribute to the reduction of petroleum consumption. Clean Cities carries out this mission through a network of more than 80 volunteer coalitions, which develop public and private partnerships to promote alternative fuels and vehicles, fuel blends, fuel economy, hybrid vehicles, and idle reduction.\n\nThe goal of the FreedomCAR and Fuel Partnership is the development of emission- and petroleum-free cars and light trucks. The Partnership focuses on the high-risk research needed to develop the necessary technologies, such as fuel cells and advanced hybrid propulsion systems, to provide a full range of affordable cars and light trucks that are free of foreign oil and harmful emissions — and that do not sacrifice freedom of mobility and freedom of vehicle choice.\n\nTo address the research and development needs of commercial vehicles, the goal of the 21st Century Truck Partnership is for USA trucks and buses to safely and cost-effectively move larger volumes of freight and greater numbers of passengers while emitting little or no pollution, with dramatic reduction in dependence on imported petroleum.\n\nIn 2007 DoE announced that it will invest nearly $20 million in plug-in hybrid electric vehicle (PHEV) research. PHEVs have the potential to displace a large amount of gasoline by delivering up to 40 miles of electric range without recharging—a distance that includes most daily roundtrip commutes. Five projects will be cost-shared with the United States Advanced Battery Consortium (USABC), allowing up to $38 million for battery research and development. The five lithium ion battery companies selected for the projects include:\n\n\nThe projects will focus on developing batteries and cells for 10- and 40-mile range PHEVs and building small cells to test new cathode materials.\n\nIn addition, the University of Michigan will receive nearly $2 million to explore the future of PHEVs in a two-year study conducted with DOE's Pacific Northwest National Laboratory (PNNL), General Motors, Ford Motor Company, and DTE Energy. The study will evaluate how PHEVs would share the power grid with other energy needs; monitor the American public's view of PHEVs and their driving behavior in such vehicles; assess the reduction of greenhouse gas emissions; and identify how automakers can optimize PHEV design to increase performance and reduce cost. See the DOE press release, the PNNL press Release, and the Draft Plug-In Hybrid Electric Vehicle R&D Plan on the FreedomCAR and Vehicle Technologies Program Web site.\n\nA number of other efforts are also aiming to advance PHEV technologies. In early September, Google.org—the philanthropic arm of Google Inc.—offered $10 million to for-profit companies that are working to advance PHEV technologies. Meanwhile, California's Pacific Gas and Electric Company (PG&E) announced that it is working with Tesla Motors to study the remote control of the charging of electric vehicles. Such \"smart charging\" could allow a utility to vary the electric charging load on its system in response to intermittent energy sources. In effect, electric vehicles would serve as a large energy storage system that utilities could direct energy to at times when ample supplies are available and the load on the electrical grid is low.\n\nAlso DoE and China's Ministry of Science and Technology (MOST) signed a five-year agreement in September 2007 to support the large-scale deployment of electric and hybrid-electric vehicles in both countries.\n\nWith the hydrogen-focused FCVT, whose goal is decades away, the Bush Administration was criticized for ignoring any intermediate-term solutions, while funding it largely with monies redirected from other renewable-energy and energy-efficiency programs. As Ashok Gupta, the lead energy economist at the Natural Resources Defense Council, put it, \"The FreedomCAR is really about Bush's freedom to do nothing about cars today.\"\n\nThe Department of Energy's congressional budget request for 2010 budget cuts funding for fuel cell technologies by 60% to US$70 million. Secretary of Energy Steven Chu's presentation portrays this as \"moving away from funding vehicular hydrogen fuel cells to technologies with more immediate promise.\"\n\n\n\n"}
{"id": "9020096", "url": "https://en.wikipedia.org/wiki?curid=9020096", "title": "Garce", "text": "Garce\n\nA garce is an obsolete unit of measurement. \n\nIn India, a garce was a unit of dry volume approximately equal to 5,244 litres (149 US bushels). In Sri Lanka, it was approximately 5,084.8 litres (144.29447 US bushels). \n\nA garce was also a unit of mass in Sri Lanka approximately equal to 4,198.518 kg (4198.518 lb). After metrication by both countries in the mid-20th century, the unit became obsolete.\n\n"}
{"id": "52304809", "url": "https://en.wikipedia.org/wiki?curid=52304809", "title": "Grounding transformer", "text": "Grounding transformer\n\nA grounding transformer or earthing transformer is a type of auxiliary transformer used in three-phase electric power systems to provide a ground path to either an ungrounded wye or a delta-connected system. Grounding transformers are part of an earthing system of the network. They let three-phase (delta connected) systems accommodate phase-to-neutral loads by providing a return path for current to a neutral. \n\nGrounding transformers are typically used to:\n\n\nGrounding transformers most commonly incorporate a single winding transformer with a zigzag winding configuration, but may also be created with a wye-delta winding transformer. Neutral grounding transformers are very common on generators in power plants and wind farms. Neutral grounding transformers are sometimes applied on high-voltage (sub-transmission) systems, such as at 33 kV, where the circuit would otherwise not have a ground; for example, if a system is fed by a delta-connected transformer. The grounding point of the transformer may be connected through a resistor to limit the fault current on the system in the event of a line-to-ground fault. \n"}
{"id": "14683625", "url": "https://en.wikipedia.org/wiki?curid=14683625", "title": "Göttelborn Solar Park", "text": "Göttelborn Solar Park\n\nGottelborn Solar Park () is a 8.4-MW photovoltaic power station located in Göttelborn, in Quierschied municipality, Germany. The power plant was constructed by City Solar in two stages. The first stage was completed in August, 2004, followed by the second stage three years later in November 2007.\n\nThe first stage of the plant includes 23,500 solar modules from the French manufacturer \"Photowatt\" at an estimated efficiency of 14%, with a nominal power output of 4 MW and occupies a total area of The construction of the second stage required another 50,000 PV modules.\n\n\n"}
{"id": "242674", "url": "https://en.wikipedia.org/wiki?curid=242674", "title": "Hall effect sensor", "text": "Hall effect sensor\n\n\"\n\nA Hall effect sensor is a transducer that varies its output voltage in response to a magnetic field. Hall effect sensors are used for proximity switching, positioning, speed detection, and current sensing applications.\n\nIn a Hall effect sensor, a thin strip of metal has a current applied along it. In the presence of a magnetic field, the electrons in the metal strip are deflected toward one edge, producing a voltage gradient across the short side of the strip (perpendicular to the feed current). Hall effect sensors have an advantage over inductive sensors in that, while inductive sensors respond to a changing magnetic field which induces current in a coil of wire and produces voltage at its output, Hall effect sensors can detect static (non-changing) magnetic fields.\n\nIn its simplest form, the sensor operates as an analog transducer, directly returning a voltage. With a known magnetic field, its distance from the Hall plate can be determined. Using groups of sensors, the relative position of the magnet can be deduced.\n\nFrequently, a Hall sensor is combined with threshold detection so that it acts as and is called a switch. Commonly seen in industrial applications such as the pictured pneumatic cylinder, they are also used in consumer equipment; for example some computer printers use them to detect missing paper and open covers. They can also be used in computer keyboards, an application that requires ultra-high reliability.\n\nHall sensors are commonly used to time the speed of wheels and shafts, such as for internal combustion engine ignition timing, tachometers and anti-lock braking systems. They are used in brushless DC electric motors to detect the position of the permanent magnet. In the pictured wheel with two equally spaced magnets, the voltage from the sensor will peak twice for each revolution. This arrangement is commonly used to regulate the speed of disk drives.\n\nA Hall probe contains an indium compound semiconductor crystal such as indium antimonide, mounted on an aluminum backing plate, and encapsulated in the probe head. The plane of the crystal is perpendicular to the probe handle. Connecting leads from the crystal are brought down through the handle to the circuit box.\n\nWhen the Hall probe is held so that the magnetic field lines are passing at right angles through the sensor of the probe, the meter gives a reading of the value of magnetic flux density (B). A current is passed through the crystal which, when placed in a magnetic field has a \"Hall effect\" voltage developed across it. The Hall effect is seen when a conductor is passed through a uniform magnetic field. The natural electron drift of the charge carriers causes the magnetic field to apply a Lorentz force (the force exerted on a charged particle in an electromagnetic field) to these charge carriers. The result is what is seen as a charge separation, with a buildup of either positive or negative charges on the bottom or on the top of the plate. The crystal measures 5 mm square. The probe handle, being made of a non-ferrous material, has no disturbing effect on the field.\n\nA Hall probe should be calibrated against a known value of magnetic field strength. For a solenoid the Hall probe is placed in the center.\n\nWhen a beam of charged particles passes through a magnetic field, forces act on the particles and the beam is deflected from a straight path. The flow of electrons through a conductor form a beam of charged carriers. When a conductor is placed in a magnetic field perpendicular to the direction of the electrons, they will be deflected from a straight path. As a consequence, one plane of the conductor will become negatively charged and the opposite side will become positively charged. The voltage between these planes is called the Hall voltage.\n\nWhen the force on the charged particles from the electric field balances the force produced by magnetic field, the separation of them will stop. If the current is not changing, then the Hall voltage is a measure of the magnetic flux density. Basically, there are two kinds of Hall effect sensors. One is linear which means the output of voltage linearly depends on magnetic flux density; the other is called threshold which means there will be a sharp decrease of output voltage at each magnetic flux density.\n\nThe key factor determining sensitivity of Hall effect sensors is high electron mobility. As a result, the following materials are especially suitable for Hall effect sensors:\n\nHall effect sensors are linear transducers. As a result, such sensors require a linear circuit for processing of the sensor's output signal. Such a linear circuit:\n\nIn some cases the linear circuit may cancel the offset voltage of Hall effect sensors. Moreover, AC modulation of the driving current may also reduce the influence of this offset voltage.\n\nHall effect sensors with linear transducers are commonly integrated with digital electronics. This enables advanced corrections to the sensor's characteristics (e.g. temperature coefficient corrections) and digital interfacing to microprocessor systems. In some solutions of IC Hall effect sensors a DSP is used, which provides for more choices among processing techniques.\n\nThe Hall effect sensor interfaces may include input diagnostics, fault protection for transient conditions, and short/open circuit detection. It may also provide and monitor the current to the Hall effect sensor itself. There are precision IC products available to handle these features.\n\nA Hall effect sensor may operate as an electronic switch.\n\nIn the case of linear sensor (for the magnetic field strength measurements), a Hall effect sensor:\n\nHall effect sensors provide much lower measuring accuracy than fluxgate magnetometers or magnetoresistance-based sensors. Moreover, Hall effect sensors drift significantly, requiring compensation.\n\nSensing the presence of magnetic objects (connected with the position sensing) is the most common industrial application of Hall effect sensors, especially those operating in the switch mode (on/off mode). The Hall effect sensors are also used in the brushless DC motor to sense the position of the rotor and to switch the transistors in the right sequence.\n\nSmartphones use hall sensors to determine if the Flip Cover accessory is closed. See Galaxy S4 Accessories.\n\nHall effect sensors may be utilized for contactless measurements of DC current in current transformers. In such a case the Hall effect sensor is mounted in the gap in magnetic core around the current conductor. As a result, the DC magnetic flux can be measured, and the DC current in the conductor can be calculated.\n\nThe Hall sensor is used in some automotive fuel level indicators. The main principle of operation of such indicator is position sensing of a floating element. This can either be done by using a vertical float magnet or a rotating lever sensor. \n\nDeveloped by Everett A. Vorthmann and Joeseph T. Maupin for Micro Switch (a division of Honeywell) in 1969, the switch was known to still be in production until as late as 1990.The key-switches have been tested to have a lifetime of over 30 billion keypresses, and also has dual open-collector outputs for reliability. The Honeywell Hall effect switch is most famously used in the Space-cadet keyboard, a keyboard used on LISP machines.\n"}
{"id": "11647747", "url": "https://en.wikipedia.org/wiki?curid=11647747", "title": "Household electricity approach", "text": "Household electricity approach\n\nThe Household Electricity Approach to measuring the size of the underground economy or black market of a country exploits the presumed relationship between household electrical consumption and a country's GDP. It assumes that undeclared economic activity still needs to use resources, such as electricity, to function. Since electricity consumption is generally well known it can be used as an indicator of economic activity that is not otherwise declared.\nThe household electricity approach was developed by Maria Lacko as a method to determine the size of the hidden economy in a country. Lacko’s primary focus within this approach was directed at the relationship between the household electrical consumption and Gross Domestic Product (GDP) of a country using regression analysis. Her research in this area was particularly focused on developing methodologies that would help to more accurately determine the prevalence of the hidden economy in transitional countries such as the former Soviet bloc countries.\n\nLacko’s work received its basis from two other works. The first of these works, developed in 1995, is the method of Dobozi and Pohl. These researchers had suggested that aggregate economic activity and electrical power consumption were closely related (Lacko 2000, p. 347). In fact, from their observations, electrical consumption and GDP elasticity were close to a one-to-one ratio (Lacko 1999, p. 143). This was true in the case of countries under a market economy; however, it did not appear to be the case for former Soviet bloc countries.\n\nThe works of Daniel Kaufman and Aleksandr Kaliberda followed a similar path as Istvan Dobozi and Gerhard Pohl's work. Kaufman and Kaliberda developed a method that considered the growth rate of the formal market's GDP and the growth of electrical consumption (Lacko 2000, p. 123). It was evident, as noted by Dobozi and Pohl, that change within the GDP resulted in lockstep changes with electrical consumption for market economies; however, Kaufman and Kaliberda also noted that the former Soviet bloc countries did not seem to maintain this consistency. The researchers suggested that the transitional nature of these countries' economic development created a break in the consistency between GDP and electrical consumption (Lacko 2000, p. 350). Kaufman and Kaliberda adapted their approach to allow for the calculation of this inconsistency between electrical activity and GDP.\n\nLacko disagreed with the previous methods use of aggregate electrical consumption as the primary source of calculations to determine the extent of the hidden economy (Lacko 1999, p. 164). Additionally, Lacko expressed concerns with the assumption of a constant electrical intensification (Lacko 1999, p. 164). The household electricity approach was developed as an alternative (Lacko 1999, pp. 142–143).\n\nThe household electricity approach follows the general idea that electrical consumption and GDP can help to estimate the size of a country's hidden market; however, the household electricity approach makes several diversions from the previous works for enhanced utility, particularly for transitional countries. The first of these was the decision to limit the concept of the informal market. Lacko limits the informal market to non-registered activities that consume household electricity. This excludes hidden activities such as bribes and many illegal activities (Lacko 1998, p. 132). By doing this, Lacko limited the magnitude of the data collecting process. Lacko also chose not to measure national electrical consumption; instead, the effort was centered on household electrical consumption (Lacko 2000, p. 361). This, in particular, would capture businesses within the informal market that were operating from a homestead. These businesses have been considered to be a traditional and rather large component of the informal economies of Eastern Europe. Additionally, Lacko presumed that household electrical consumption would not be as dramatically affected by structural changes caused by transitional experiences such as those of the former Soviet bloc countries.\n\nLacko’s method begins with the basic premise that each household’s electrical consumption should be associated with a portion of the informal market (Lacko 1999, p. 161).This is determined by using time-series cross sections of each country. Within this method there are three proxy variables to be studied: tax/GDP ratio, the inactive/active labor ratio and the ratio of public social welfare expenditures (Lacko 2000, p. 362). For Lacko’s original study the parameters were focused around estimates of cross-sections from nineteen OECD countries in 1990, nineteen OECD countries in 1989 and panel data for 1989-1990(Lacko 2000, p. 362). The final determinization was completed by subtracting residential electrical consumption from the actual amount of electrical consumption (Lacko 2000, p. 362).\n\n 1nE + I = α1nC + αG + αQ + αH + α\n\nwhere:\n\nAfter the total electricity consumption of households has been determined, the next step is to proceed to find the informal economy’s contribution to the GDP of a country (Lacko 1998, p. 140). To create this index, Lacko had to determine a way to calculate how much GDP is produced by one unit of electricity (Lacko 1998, p. 140). This was done by taking known estimations of a market economy and making comparisons with this to another approach (Lacko 1998, p. 140).\n\nThe household electricity approach does not require predetermined weights as had been established in previous approaches utilizing electrical consumption to determine the extent of the hidden economy (Lacko 1999, p. 149). Instead the weights of the different causes can be determined during the estimation. By the use of residential electrical consumption, Lacko's approach allows for an accurate measure of market economies as well as transitional economies approaches utilizing electrical consumption to determine the extent of the hidden economy.\n\nA disadvantage of the household electricity approach is that it is limited in its scope of study. The range of the study can only include those parts of the hidden economy that utilize household electricity (Lacko 1999, p. 150).\n\nThe primary criticism for the household electricity approach, as well as other electrical consumption approaches, centers around the assumptions made regarding the stability of the consistency of electrical consumption with GDP. Critics suggest that levels of stability can be altered significantly by the omission of such basic factors as shifts in the weather (Hanousek and Palda 2004, p. 14). The authors of electrical consumption approaches have admittedly been aware of the weakness of their assumptions and have made attempts to control for factors that would make electrical consumption inconsistent with GDP; however, critics do not see these attempts as being adequate enough (Hanousek and Palda 2006, p. 709).\n\n"}
{"id": "43689013", "url": "https://en.wikipedia.org/wiki?curid=43689013", "title": "Katiyabaaz", "text": "Katiyabaaz\n\nKatiyabaaz (English : \"Electricity thief\" however this fails to capture the pun in the Hindi word Katiyabaaz), released under the alternate title Powerless for English-speaking audiences, is a 2014 Indian Hindi documentary film directed by Deepti Kakkar and Fahad Mustafa about the problem of power theft in Kanpur. Released in India on 22 August 2014, the film is shot in Kanpur city, which faces long power cuts, giving rise to the profession of Loha Singh, a local electricity thief or \"katiyabaaz\" in localities like Chaman Ganj. He provides illegal electricity connections to people, while Ritu Maheshwari, MD of KESCo, Kanpur Electricity Supply Company, tries to tackle the issue of rampant electricity theft.\n\nThe film was premiered at the Berlin International Film Festival 2013 and later won the Best Film in the India Gold Section at the 15th Mumbai Film Festival. At the 61st National Film Awards the film won the ward for Best Investigative Film. \"Katiyabaaz\" premiered on American television on Independent Lens - PBS on 3 November 2014.\n\n\"Katiyabaaz\" is a story of Kanpur's electricity crisis, resulting in loadshedding. Power cuts of up to 15 hours a day, cause great trouble to residents and factories alike. This gap in supply and demand becomes the bedrock of local electricity thieves like Loha Singh, who provide illegal power connection to people, by plugging into official supply through live wires. However such free connection causes heavy financial losses to the power supply company, whose MD struggles to fight the menace of power theft, and local fixers. The film follows Loha Singh, an electricity thief, and Ritu Maheshwari an official with Kanpur Electricity Supply Company.\n\nThe film was made on a small budget of and had music by fusion rock band Indian Ocean who composed and sang the song Kanpoora for the film. The film was shot over a period of nearly two years, with a crew of 10-12 people. Instead of staying at hotels, the crew rented a bungalow and furnished it, which was economical.\n\nThe film's co-director, Fahad Mustafa, originally from Kanpur, researched the subject for six months before he started filming. However, they came across Loha Singh, the \"katiyabaaz\" (electricity thief) around whom the film is based, only after the shooting had already started, and another \"katiyabaaz\" had backed out in the last moment. Loha Singh, himself was initially apprehensive about allowing himself be filmed, as he thought it to be a sting operation on his work or the crew to be of the \"Dabangg\" film series. The rumour about the latter, drew large crowds to filming locations, hampering production. The fact that some of the crew were foreigners also created much curiosity. Gradually Loha Singh and the locals became comfortable with the film crew. The crew shot candid conversations, several individual stories and the crippling effects of electricity crisis in the area on the common man, local industries as well as small business owners.\n\nAfter its premiere at the Berlin International Film Festival 2013, the film traveled to various film festivals including the Tribeca Film Festival, the Melbourne International Film Festival, the Motovun Film Festival and the London Raindance Film Festival.\n\nThe film received backing for commercial released when Phantom Films, co-owned by filmmaker Anurag Kashyap, Vikramaditya Motwane and Vikas Bahl, with funding from international sources, signed on to present the film. In end July, The film's trailer was released by director-producer Anurag Kashyap in Mumbai. The film was commercially released on 22 August 2014. It had a limited release across 50 screens in cities like Mumbai, Lucknow, Pune, Bangalore, Hyderabad and Kanpur.\n\nThe film was very well received by both international and well as national press. The largest German national paper, Süddeutsche Zeitung gave \"Katiyabaaz\" a fantastic review after its premiere at the Berlin International Film Festival. According to Tom Brook from BBC's Talking Movies, \"the filmmakers very effectively bring what could be rather dry subject to life\". Aarti Virani wrote in \"The New York Times\" that the film was \"a jarring glimpse at India’s rampant energy crisis\". Abhimanyu Das wrote an extensive article about the film, Creatures of Light and Darkness in the Caravan magazine.\n\nDeepanjana Pal of \"Firstpost\" called the film a \"beautifully-shot documentary\". Leading film critics gave it glowing reviews. Rajeev Masand called it a \"Slice of Life\" film. Anupama Chopra referred to it as a \"sad love letter to Kanpur\". Mihir Fadnavis reviewed the film for DNA India, where he called it \"more hilarious, insightful and gorgeous than a feature film\". Mumbai's leading lifestyle website, Mumbai Boss, called \"Katiyabaaz\" a \"crackling documentary!\"\n\nOn 28 August 2014, the Government of Uttar Pradesh exempted the film from entertainment tax, which also directed engineers of state power department to watch the film and \"draw inspiration to stop illegal connections\".\n\n"}
{"id": "12315666", "url": "https://en.wikipedia.org/wiki?curid=12315666", "title": "Kori Nuclear Power Plant", "text": "Kori Nuclear Power Plant\n\nThe Kori Nuclear Power Plant (Korean: 고리원자력발전소, Hanja: 古里原子力發電所) is a South Korean nuclear power plant located in Kori, a suburban village in Busan. It is owned and operated by Korea Hydro & Nuclear Power, a subsidiary of KEPCO. The first reactor began commercial operation in 1978.\n\nAn expansion of the plant begun in 2006 added four new Korean-sourced reactors, the so-called Shin Kori reactors. The first pair of Shin Kori reactors are of the OPR-1000 design, while the second two are the APR-1400 design. By November 2010 the first was online and the rest undergoing trials or construction. approval of operation of reactor 4 is expected in the first half of 2017. Two further APR-1400 reactors, known as Shin Kori 5 and Shin Kori 6 have started construction in April 2017 and September 2018, respectively. \n\n all reactors on site are pressurized water reactors.\n\nKori 1 was shutdown in June 2017 in advance of decommissioning beginning in 2022 after its spent nuclear fuel is removed.\n\nOn February 9, 2012, during a refueling outage, loss of off-site power (LOOP) occurred and emergency diesel generator (EDG) 'B' failed to start while EDG 'A' was out of service for scheduled maintenance, resulting in a station blackout (SBO). Off-site power was restored 12 minutes after the SBO condition began. \nThe LOOP was caused by a human error during a protective relay test of the main generator. The EDG 'B' failing to start was caused by the failure of the EDG air start system. Further investigation revealed that the utility did not exercise proper control of electrical distribution configuration to ensure the availability of the Station Auxiliary Transformer (SAT) while conducting test on the Unit Auxiliary Transformer (UAT).\nAfter restoring off-site power through the SAT, the operators eventually recovered shutdown cooling by restoring power to a residual heat removal pump. During the loss of shutdown cooling for 19 minutes, the reactor coolant maximum temperature in the hot leg increased from 37℃ to 58.3℃ (approximately 21.3℃ rise), and the spent fuel pool temperature slightly increased from 21℃ to 21.5℃.\nThere was no adverse effect on the plant safety as a result of this event, no radiation exposure to the workers, and no release of radioactive materials to the environment. However, inconsistent with the requirements, the licensee did not report the SBO event to the regulatory body in a timely manner and did not declare the \"alert\" status of the event in accordance with the plant emergency plan. The licensee reported this event to the regulatory body about a month after the event had occurred.\n\nOn 2 October 2012 at 8:10 a.m. Shingori 1 was shut down after a warning signal indicated a malfunction in the control rod system. An investigation is currently underway to verify the exact cause of the problem.\n\nIn June 2013 Kori 2 was shutdown, and Kori 1 ordered to remain offline, until safety-related control cabling with forged safety certificates is replaced. Control cabling installed in the APR-1400s under construction failed flame and other tests, so need to be replaced delaying construction by up to a year.\n\nIn October 2013 cable installed in Shin Kori 3 failed safety tests, including flame tests. Replacement with U.S. manufactured cable has delayed the startup of the plant, which eventually entered commercial operation 3 years late.\n\nIn the recently released movie Pandora, the Kori Nuclear Power Plant is a main scene in the movie. The movie touches on the dangers of nuclear energy in South Korea, and if it were to go wrong.\n\n\n"}
{"id": "48213543", "url": "https://en.wikipedia.org/wiki?curid=48213543", "title": "Lassajavre Hydroelectric Power Station", "text": "Lassajavre Hydroelectric Power Station\n\nThe Lassajavre Hydroelectric Power Station ( or \"Lassajavrre kraftverk\") is a hydroelectric power station in the municipality of Kvænangen in Troms county, Norway. The plant utilizes a drop between Lake Abo (, ) and Lake Lassa (, ). Lake Abo is regulated at a level between and , and Lake Lassa serves as the reservoir for the Småvatna Hydroelectric Power Station. The Lassajavre plant also utilizes water from Lake Mollis (, ) and Lake Sarves (, ). The plant came into operation in 1977. It has a Francis turbine and operates at an installed capacity of , with an average annual production of about 30 GWh. The plant is controlled by Kvænangen Kraftverk AS, with a 48.2% share owned by Troms Kraft.\n"}
{"id": "13563473", "url": "https://en.wikipedia.org/wiki?curid=13563473", "title": "Malvalic acid", "text": "Malvalic acid\n\nMalvalic acid is a cyclopropene fatty acid found in baobab seed oil and cottonseed oil. The cyclopropene ring is thought to be one of the causes of abnormalities that develop in animals that ingest cottonseed oil. Refining processes, such as hydrogenation, oil can remove or destroy malvalic acid.\n\nThe biosynthesis of malvalic acid starts with oleic acid, an 18-carbon monounsaturated fatty acid, leading to sterculic acid. An α-oxidation reaction removes one carbon from the chain to form the 17-carbon-chain structure of malvalic acid.\n\nWilson et al. demonstrated the co-occurrence of malvalic acid and the corresponding cyclopropane acids in several types of seeds. He suggested that methylene addition to oleic acid gave rise to dihydrosterculic acid, which was desaturated to sterculic acid, and that 8-heptadecenoic acid was similarly the precursor of dihydromalvalic acid and malvalic acid. Smith and Bu'Lock showed that in Hibiscus seedlings the chains of sterculic and malvalic acids, but not the ring methylene carbon, were derived from acetate. They showed that the labeling pattern in malvalic acid was the same as that in sterculic acid minus the carboxyl carbon. They explained the shortening by α oxidation occurring during the biogenesis of malvalic acid. Hooper and Law demonstrated that the ring methylene carbon of both cyclopropane and cyclopropene acids was derived from the methyl group of methionine in Hibiscus, and suggested from the distribution of label that the pathway was oleic → dihydrosterculic → sterculic acid.\n"}
{"id": "43525001", "url": "https://en.wikipedia.org/wiki?curid=43525001", "title": "Mattress coil", "text": "Mattress coil\n\nMattress coils, also known as mattress springs, are coil springs used in a mattress. Coils are primarily used in the core (support layer) of innerspring mattresses, which is their original use. In recent years small \"micro-coils\" have started being used in the upholstery (comfort layer) of mattresses, primarily with a coil core (\"coil-on-coil\" construction), but sometimes with other core types.\n\nMattress coils were introduced in the mid-late 19th century, and remain popular in the 21st century, particularly in the United States.\n\nThere are four types of mattress coils. A key desiderata is \"response range\", meaning the change in firmness as the spring is compressed – initially soft, to conform to the body, then hard, to provide support. In increasing order of response range and cost, the types are:\n\n\nWhile coil springs were invented in the 15th century, they were not used in mattresses until the mid-late 19th century, following the use of upholstery coil springs in furniture and carriages.\n\nMicrocoils were introduced in the early 21st century, and are a small part of the market.\n\nThe bed coil spring was patented by Louis Andrew Vargha. Some modern feedback on coils within mattresses cast aspersions on \nsome of its attributes such as abrasion on coils eventually culminating into prodding, and the audibility of the coils, as it may decrease privacy for intimate moments such as sexual activity.\n\nThe mattress coil market is quite concentrated – the leading suppliers are Leggett & Platt (founded 1883) of Carthage, Missouri and HSM Solutions (formally Hickory Springs, founded 1944) of Hickory, North Carolina; others include Spinks Springs (founded 1840) of Leeds, United Kingdom and Subiñas (founded 1959) of Biscay, Spain.. Raha mattresses are the leading mattress manufacturers in Gulf region. Cloudnine mattress is the luxury segment of Poly Products-manufacturer of Raha mattresses.\n\n"}
{"id": "14553538", "url": "https://en.wikipedia.org/wiki?curid=14553538", "title": "Minister for Energy (Australia)", "text": "Minister for Energy (Australia)\n\nThe Minister for Energy is an Australian Government Cabinet position with the duties of serving the people of Australia by developing a more prosperous and sustainable Australia by leading and coordinating the mitigation of greenhouse gas emissions, promotion of energy efficiency, adaptation to climate change and shaping of global solutions.\n\nThe Hon. Angus Taylor MP was appointed as Energy Minister by the Governor-General on 28 August 2018.\n\nThe position of Energy Minister previously had responsibility for the Department of Climate Change and Energy Efficiency under the Rudd and Gillard Government. The precursor department was led by the Secretary, Blair Comley PSM who was responsible to the Minister for Climate Change and Energy Efficiency, the Honourable Greg Combet AM MP. The minister was assisted by the Parliamentary Secretary for Climate Change and Energy Efficiency, the Honourable Mark Dreyfus QC MP. The Clean Energy Regulator was a statutory authority formed 2 April 2012, which was part of the department.\n\nOn 25 March 2013, responsibility for Climate Change passed to the newly formed Department of Industry, Innovation, Climate Change, Science, Research and Tertiary Education, and the duties of the Ministry of Energy passed to the Department of Resources, Energy and Tourism. After the 7 September 2013 Australian federal election the responsibility for Energy passed to the Minister for Industry, Innovation and Science under the Abbott Government. Following the Australia federal election of 2 July 2016, responsibilities were passed to the Minister of the Environment and Energy under the Turnbull Government. Following the appointment of Scott Morrison as Prime Minister, Josh Frydenberg was elevated to Treasurer of Australia, whereby Frydenberg's previous ministerial positions were separated, with Melissa Price as Minister of the Environment and Angus Taylor as Minister for Energy.\n\nThe department deals with:\n\n\n"}
{"id": "11232730", "url": "https://en.wikipedia.org/wiki?curid=11232730", "title": "Montalto di Castro Nuclear Power Station", "text": "Montalto di Castro Nuclear Power Station\n\nThe Montalto di Castro nuclear power station was a nuclear power plant at Montalto di Castro in Italy. Consisting of two BWR units each of 982 MWe, it was approaching completion in 1988 when the Italian government decided to close all nuclear plants as a result of the 1987 referendum. It never operated.\n\nIts area and some of the already built structures are now used by the fossil-fuel power station \"Alessandro Volta\", the biggest power station in Italy.\n\nThe nuclear power plant has two units:\n\n"}
{"id": "38200003", "url": "https://en.wikipedia.org/wiki?curid=38200003", "title": "Muppandal Wind Farm", "text": "Muppandal Wind Farm\n\nThe Muppandal Wind Farm is India's largest operational onshore wind farm. This project located in Kanyakumari district, Tamil Nadu. The project was developed by Tamil Nadu Energy Development Agency. Its installed capacity is 1,500 MW, which makes it one of world's largest operational onshore wind farms.\n\n"}
{"id": "640878", "url": "https://en.wikipedia.org/wiki?curid=640878", "title": "National parks of Russia", "text": "National parks of Russia\n\nThere are currently 48 national parks in Russia, a list of which is given below. Together they cover approximately .\n\nThe oldest parks in Russia are Sochinsky and Losiny Ostrov (1983); Samarskaya Luka (1984); Mariy Chodra (1985); Bashkiriya, Prielbrusye, Pribaykalsky, and Zabaykalsky (1986).\n\nAccording to the law on the protected areas of Russia, national parks are areas of land and water devoted to nature protection, ecological education, and scientific research. They contain sites of particular ecological, historical and aesthetic value. Regulated tourism is permitted.\nThe area of each park is divided into zones according to various functions. There should be a strictly protected area managed as a zapovednik, and also recreational and buffer zones in which economic activity is allowed, such as tourism, traditional land use, and benign forms of agriculture and forestry. The strictly protected function is sometimes fulfilled by a neighbouring official zapovednik; for instance, Barguzin Zapovednik adjoins Zabaykalsky National Park on the east side of Lake Baikal.\nIn 2001 Vodlozersky National Park received UNESCO Biosphere Reserve status, followed by Smolenskoye Poozerye and Ugra National Park in 2002, and two others (Valdaysky and Kenozersky) in 2004. The newest park is Bikin National Park, created in late 2015.\n\nThe national parks are currently the responsibility of the Ministry of Natural Resources and Environment (Russia).\n\n\n"}
{"id": "40598200", "url": "https://en.wikipedia.org/wiki?curid=40598200", "title": "New York State Association for Reduction, Reuse and Recycling", "text": "New York State Association for Reduction, Reuse and Recycling\n\nThe New York State Association for Reduction, Reuse and Recycling is an organization which seeks to promotes use of recycling throughout New York State. It promotes a wide variety of techniques for reuse of resources, and also assists local communities who wish to expand and develop their recycling activities.\n\n"}
{"id": "19445663", "url": "https://en.wikipedia.org/wiki?curid=19445663", "title": "Oceanic dispersal", "text": "Oceanic dispersal\n\nOceanic dispersal is a type of biological dispersal that occurs when terrestrial organisms transfer from one land mass to another by way of a sea crossing. Often this occurs via large rafts of floating vegetation such as are sometimes seen floating down major rivers in the tropics and washing out to sea, occasionally with animals trapped on them. Dispersal via such a raft is sometimes referred to as a \"rafting event\".\n\nColonization of land masses by plants can also occur via long-distance oceanic dispersal of floating seeds.\n\nRafting has played an important role in the colonization of isolated land masses by mammals. Prominent examples include Madagascar, which has been isolated for ~120 million years (Ma), and South America, which was isolated for much of the Cenozoic. Both land masses, for example, appear to have received their primates by this mechanism. According to genetic evidence, the common ancestor of the lemurs of Madagascar appears to have crossed the Mozambique Channel by rafting between 50 and 60 Ma ago. Likewise, the New World monkeys are thought to have originated in Africa and rafted to South America by the Oligocene, when the continents were much closer than they are today. Madagascar also appears to have received its tenrecs (25–42 Ma ago), nesomyid rodents (20–24 Ma ago) and euplerid carnivorans (19–26 Ma ago) by this route and South America its caviomorph rodents (over 30 Ma ago). Simian primates (ancestral to monkeys) and hystricognath rodents (ancestral to caviomorphs) are believed to have previously rafted from Asia to Africa about 40 Ma ago.\n\nAmong reptiles, several iguanid species in the South Pacific have been hypothesized to be descended from iguanas that rafted from Central or South America (an alternative theory involves dispersal of a putative now-extinct iguana lineage from Australia or Asia). Similarly, a number of clades of American geckos seem to have rafted over from Africa during both the Paleogene and Neogene. Skinks of the related genera \"Mabuya\" and \"Trachylepis\" also apparently both floated across the Atlantic from Africa to South America and Fernando de Noronha, respectively, during the last 9 Ma. Skinks from the same group have also rafted from Africa to Cape Verde, Madagascar, the Seychelles, the Comoros and Socotra. (Among lizards, skinks and geckos seem especially capable of surviving long transoceanic journeys.) Surprisingly, even burrowing amphisbaenians and blind snakes appear to have rafted from Africa to South America.\n\nAn example of a bird that is thought to have reached its present location by rafting is the weak-flying South American hoatzin, whose ancestors apparently floated over from Africa.\n\nColonization of groups of islands can occur by an iterative rafting process sometimes called island hopping. Such a process appears to have played a role, for example, in the colonization of the Caribbean by mammals of South American origin (including caviomorphs and monkeys).\n\nA remarkable example of iterative rafting has been proposed for spiders of the genus \"Amaurobioides\". Members of this genus inhabit coastal sites and build silken cells which they seal at high tide; however, they do not balloon. DNA sequence analysis suggests that ancestors of the genus dispersed from southern South America to South Africa about 10 million years (Ma) ago, where the most basal clade is found; subsequent rafting events then took the genus eastward with the Antarctic Circumpolar Current to Australia, then to New Zealand and finally to Chile by about 2 Ma ago. Another example among spiders is the species \"Moggridgea rainbowi\", the only Australian member of a genus otherwise endemic to Africa, with a divergence date of 2 to 16 Ma ago.\n\nHowever, oceanic dispersal of terrestrial species may not always take the form of rafting; in some cases, swimming or simply floating may suffice. Tortoises of the genus \"Chelonoidis\" arrived in South America from Africa in the Oligocene; they were probably aided by their ability to float with their heads up, and to survive up to six months without food or fresh water. South American tortoises then went on to colonize the West Indies and Galápagos Islands. The dispersal of anthracotheres from Asia to Africa about 40 Ma ago, and the much more recent dispersal of hippos (relatives and probably descendants of anthracotheres) from Africa to Madagascar may have occurred by floating or swimming.\n\nThe first documented example of colonization of a land mass by rafting occurred in the aftermath of hurricanes Luis and Marilyn in the Caribbean in 1995. A raft of uprooted trees carrying fifteen or more green iguanas was observed by fishermen landing on the east side of Anguilla – an island where they had never before been recorded. The iguanas had apparently been caught on the trees and rafted two hundred miles across the ocean from Guadeloupe, where they are indigenous. Examination of the weather patterns and ocean currents indicated that they had probably spent three weeks at sea before landfall. This colony began breeding on the new island within two years of its arrival.\n\nThe advent of human civilization has created opportunities for organisms to raft on floating artifacts, which may be more durable than natural floating objects. This phenomenon was noted following the 2011 Tōhoku tsunami in Japan, with about 300 species found to have been carried on debris by the North Pacific Current to the west coast of North America (although no colonizations have been detected thus far).\n\n\n"}
{"id": "351287", "url": "https://en.wikipedia.org/wiki?curid=351287", "title": "Ogee", "text": "Ogee\n\nAn ogee ( ) is a curve (often used in moulding), shaped somewhat like an S, consisting of two arcs that curve in opposite senses, so that the ends are parallel. It is a kind of sigmoid curve.\n\nThe term has uses in architecture, mathematics, and fluid mechanics, as well as marine construction, clock design and plastic surgery.\n\nOgee is also written O.G.. This long-standing variant may have originated from a mis-hearing of the spoken word \"ogee\" as an abbreviation. Nevertheless, the quasi-abbreviation is often seen in print within the millwork trade.\n\nIn architecture, the principal use of the term is to describe an arch composed of two ogees, mirrored left-to-right and meeting at an apex. Ogee arches were a feature of English Gothic architecture in the later thirteenth century.\n\nA building's surface detailing (indoors or out) may have a moulding with an ogee-shaped profile, consisting (going from low to high) of a concave arc flowing into a convex arc, with vertical ends; if the lower curve is convex and higher one concave, this is known as a Roman ogee, although frequently the terms are used as if they are interchangeable and for a variety of other shapes. Alternative names for such a true Roman ogee moulding include \"cyma reversa\" and \"talon\".\n\nThe cyma reversa form occurs in antiquity. For example, in ancient Persia, the Tomb of Cyrus featured the cyma reversa. The cyma reversa is also evident in ancient Greek architecture, and takes its name from the cymatium.\nThe ogee shape is one of the characteristics of the Gothic style of architecture, especially decorative elements in the 14th and 15th century late Gothic styles called Flamboyant in France and Decorated in England. Ogee windows and arches were introduced to European cities from the Middle East. The ogee curve is an analogue of a \"cyma curve\", the difference being that a cyma has horizontal rather than vertical ends.\n\nThe ogee and Roman ogee profiles are used in decorative moulding, often framed between mouldings with a square section. As such it is part of the standard classical decorative vocabulary, adopted from architrave and cornice mouldings of the Ionic order and Corinthian order. An ogee is also often used in the \"crown moulding\" frequently found at the top of a piece of case furniture, or for capping a baseboard or plinth, or where a wall meets the ceiling. An ogee moulding may be run in plaster or wood, or cut in stone or brickwork.\n\nOgee is also a mathematical term, meaning an inflection point.\n\nIn fluid mechanics, the term is used for an ogee-shaped aerodynamic profile. For example, a wing may have ogee profile, particularly on supersonic aircraft such as the Concorde. Also, the downstream face of a dam spillway is usually formed in an ogee curve to minimize water pressure.\n\nAn \"ogee washer\" is a heavy washer with a large bearing surface used in marine timber construction to prevent bolt heads or nuts from sinking into the face of timbers. The term ogee is used due to the ogee shape in radial symmetry around the centre. Due to the size and shape, they are generally manufactured as a cast iron product in accordance with ASTM A47 or A48.\n\nAn \"ogee clock\" is a common kind of weight-driven 19th-century pendulum clock in a simplified Gothic taste, made in the United States for a mantelpiece or to sit upon a wall bracket. It is rectangular, with ogee-profile moulding that frames a central glass door that protects the clock face and the pendulum. The weights fall inside the ogee moulding supported by pulleys and hidden from view. The door usually carries a painted scene in the area beneath the face. Ogee clocks are one of the most commonly encountered varieties of American antique clocks. The design is usually attributed to Chauncey Jerome.\n\nIn aesthetic facial surgery, the term is used to describe the malar or cheekbone prominence transitioning into the mid-cheek hollow. The aim of a mid-face rejuvenation is to restore the ogee curve and enhance the cheekbones. This enhancement is also commonly a part of a routine facelift.\n\nIn distillation, an ogee is the bubble-shaped chamber of a pot still that connects the swan neck to the pot. It allows distillate to expand, condense, and fall back into the pot.\n\n\n\n\n"}
{"id": "35593797", "url": "https://en.wikipedia.org/wiki?curid=35593797", "title": "Osa de la Vega Solar Plant", "text": "Osa de la Vega Solar Plant\n\nOsa de la Vega Solar Plant is a 30 MW solar photovoltaic power plant located in the Province of Cuenca (Spain).\n\n"}
{"id": "22826298", "url": "https://en.wikipedia.org/wiki?curid=22826298", "title": "Oxxio", "text": "Oxxio\n\nOxxio is an electricity and natural gas utility located in Rotterdam, Netherlands. It is a subsidiary of Eneco Energie.\n\nOxxio serves about 800,000 customers in the Netherlands. It is the fourth largest supplier and the largest of the companies that entered the market since the energy market liberalisation in 2000.\n\nIn 2005, Centrica acquired Oxxio. In March 2011, Oxxio was acquired by Eneco Energie for €72 million.\n\n"}
{"id": "8253417", "url": "https://en.wikipedia.org/wiki?curid=8253417", "title": "Plasma modeling", "text": "Plasma modeling\n\nPlasma Modeling refers to solving equations of motion that describe the state of a plasma. It is generally coupled with Maxwell's Equations for electromagnetic fields or Poisson's Equation for electrostatic fields. There are several main types of plasma models: single particle, kinetic, fluid, hybrid kinetic/fluid, gyrokinetic and as system of many particles.\n\nThe single particle model describes the plasma as individual electrons and ions moving in imposed (rather than self-consistent) electric and magnetic fields. The motion of each particle is thus described by the Lorentz Force Law.\nIn many cases of practical interest, this motion can be treated as the superposition of a relatively fast circular motion around a point called the guiding center and a relatively slow drift of this point.\n\nThe kinetic model is the most fundamental way to describe a plasma, resultantly producing a distribution function\nwhere the independent variables formula_2 and formula_3 are position and velocity, respectively.\nA kinetic description is achieved by solving the Boltzmann equation or, when the correct description of long-range Coulomb interaction is necessary, by the Vlasov equation which contains self-consistent collective electromagnetic field, or by the Fokker-Planck equation, in which approximations have been used to derive manageable collision terms. The charges and currents produced by the distribution functions self-consistently determine the electromagnetic fields via Maxwell's equations.\n\nTo reduce the complexities in the kinetic description, the fluid model describes the plasma based on macroscopic quantities (velocity moments of the distribution such as density, mean velocity, and mean energy). The equations for macroscopic quantities, called fluid equations, are obtained by taking velocity moments of the Boltzmann equation or the Vlasov equation. The fluid equations are not closed without the determination of transport coefficients such as mobility, diffusion coefficient, averaged collision frequencies, and so on. To determine the transport coefficients, the velocity distribution function must be assumed/chosen. But this assumption can lead to a failure of capturing some physics.\n\nAlthough the kinetic model describes the physics accurately, it is more complex (and in the case of numerical simulations, more computationally intensive) than the fluid model. The hybrid model is a combination of fluid and kinetic models, treating some components of the system as a fluid, and others kinetically.\n\nIn the gyrokinetic model, which is appropriate to systems with a strong background magnetic field, the kinetic equations are averaged over the fast circular motion of the gyroradius. This model has been used extensively for simulation of tokamak plasma instabilities (for example, the GYRO and Gyrokinetic ElectroMagnetic codes), and more recently in astrophysical applications.\n\nQuantum methods are not yet very common in plasma modeling. They can be used to solve unique modeling problems; like situations where other methods do not apply. They involve the application of Quantum Field Theory to plasma. In these cases, the electric and magnetic fields made by particles are modeled like a field; A web of forces. Particles that move, or are removed from the population push and pull on this web of forces, this field. The mathematical treatment for this involves Lagrangian mathematics.\n\n\n\n"}
{"id": "25179", "url": "https://en.wikipedia.org/wiki?curid=25179", "title": "Quark", "text": "Quark\n\nA quark () is a type of elementary particle and a fundamental constituent of matter. Quarks combine to form composite particles called hadrons, the most stable of which are protons and neutrons, the components of atomic nuclei. Due to a phenomenon known as \"color confinement\", quarks are never directly observed or found in isolation; they can be found only within hadrons, which include baryons (such as protons and neutrons) and mesons. For this reason, much of what is known about quarks has been drawn from observations of hadrons.\n\nQuarks have various intrinsic properties, including electric charge, mass, color charge, and spin. They are the only elementary particles in the Standard Model of particle physics to experience all four fundamental interactions, also known as \"fundamental forces\" (electromagnetism, gravitation, strong interaction, and weak interaction), as well as the only known particles whose electric charges are not integer multiples of the elementary charge.\n\nThere are six types, known as \"flavors\", of quarks: up, down, strange, charm, bottom, and top. Up and down quarks have the lowest masses of all quarks. The heavier quarks rapidly change into up and down quarks through a process of particle decay: the transformation from a higher mass state to a lower mass state. Because of this, up and down quarks are generally stable and the most common in the universe, whereas strange, charm, bottom, and top quarks can only be produced in high energy collisions (such as those involving cosmic rays and in particle accelerators). For every quark flavor there is a corresponding type of antiparticle, known as an antiquark, that differs from the quark only in that some of its properties (such as the electric charge) have equal magnitude but opposite sign.\n\nThe quark model was independently proposed by physicists Murray Gell-Mann and George Zweig in 1964. Quarks were introduced as parts of an ordering scheme for hadrons, and there was little evidence for their physical existence until deep inelastic scattering experiments at the Stanford Linear Accelerator Center in 1968. Accelerator experiments have provided evidence for all six flavors. The top quark, first observed at Fermilab in 1995, was the last to be discovered.\n\nThe Standard Model is the theoretical framework describing all the currently known elementary particles. This model contains six flavors of quarks (), named up (), down (), strange (), charm (), bottom (), and top (). Antiparticles of quarks are called \"antiquarks\", and are denoted by a bar over the symbol for the corresponding quark, such as for an up antiquark. As with antimatter in general, antiquarks have the same mass, mean lifetime, and spin as their respective quarks, but the electric charge and other charges have the opposite sign.\n\nQuarks are spin- particles, implying that they are fermions according to the spin–statistics theorem. They are subject to the Pauli exclusion principle, which states that no two identical fermions can simultaneously occupy the same quantum state. This is in contrast to bosons (particles with integer spin), of which any number can be in the same state. Unlike leptons, quarks possess color charge, which causes them to engage in the strong interaction. The resulting attraction between different quarks causes the formation of composite particles known as \"hadrons\" (see \"Strong interaction and color charge\" below).\n\nThe quarks that determine the quantum numbers of hadrons are called \"valence quarks\"; apart from these, any hadron may contain an indefinite number of virtual \"sea\" quarks, antiquarks, and gluons, which do not influence its quantum numbers. There are two families of hadrons: baryons, with three valence quarks, and mesons, with a valence quark and an antiquark. The most common baryons are the proton and the neutron, the building blocks of the atomic nucleus. A great number of hadrons are known (see list of baryons and list of mesons), most of them differentiated by their quark content and the properties these constituent quarks confer. The existence of \"exotic\" hadrons with more valence quarks, such as tetraquarks () and pentaquarks (), was conjectured from the beginnings of the quark model but not discovered until the early 21st century.\n\nElementary fermions are grouped into three generations, each comprising two leptons and two quarks. The first generation includes up and down quarks, the second strange and charm quarks, and the third bottom and top quarks. All searches for a fourth generation of quarks and other elementary fermions have failed, and there is strong indirect evidence that no more than three generations exist. Particles in higher generations generally have greater mass and less stability, causing them to decay into lower-generation particles by means of weak interactions. Only first-generation (up and down) quarks occur commonly in nature. Heavier quarks can only be created in high-energy collisions (such as in those involving cosmic rays), and decay quickly; however, they are thought to have been present during the first fractions of a second after the Big Bang, when the universe was in an extremely hot and dense phase (the quark epoch). Studies of heavier quarks are conducted in artificially created conditions, such as in particle accelerators.\n\nHaving electric charge, mass, color charge, and flavor, quarks are the only known elementary particles that engage in all four fundamental interactions of contemporary physics: electromagnetism, gravitation, strong interaction, and weak interaction. Gravitation is too weak to be relevant to individual particle interactions except at extremes of energy (Planck energy) and distance scales (Planck distance). However, since no successful quantum theory of gravity exists, gravitation is not described by the Standard Model.\n\nSee the table of properties below for a more complete overview of the six quark flavors' properties.\n\nThe quark model was independently proposed by physicists Murray Gell-Mann and George Zweig in 1964. The proposal came shortly after Gell-Mann's 1961 formulation of a particle classification system known as the \"Eightfold Way\"—or, in more technical terms, SU(3) flavor symmetry, streamlining its structure. Physicist Yuval Ne'eman had independently developed a scheme similar to the Eightfold Way in the same year. An early attempt at constituent organization was available in the Sakata model.\n\nAt the time of the quark theory's inception, the \"particle zoo\" included, amongst other particles, a multitude of hadrons. Gell-Mann and Zweig posited that they were not elementary particles, but were instead composed of combinations of quarks and antiquarks. Their model involved three flavors of quarks, up, down, and strange, to which they ascribed properties such as spin and electric charge. The initial reaction of the physics community to the proposal was mixed. There was particular contention about whether the quark was a physical entity or a mere abstraction used to explain concepts that were not fully understood at the time.\n\nIn less than a year, extensions to the Gell-Mann–Zweig model were proposed. Sheldon Lee Glashow and James Bjorken predicted the existence of a fourth flavor of quark, which they called \"charm\". The addition was proposed because it allowed for a better description of the weak interaction (the mechanism that allows quarks to decay), equalized the number of known quarks with the number of known leptons, and implied a mass formula that correctly reproduced the masses of the known mesons.\n\nIn 1968, deep inelastic scattering experiments at the Stanford Linear Accelerator Center (SLAC) showed that the proton contained much smaller, point-like objects and was therefore not an elementary particle. Physicists were reluctant to firmly identify these objects with quarks at the time, instead calling them \"partons\"—a term coined by Richard Feynman. The objects that were observed at SLAC would later be identified as up and down quarks as the other flavors were discovered. Nevertheless, \"parton\" remains in use as a collective term for the constituents of hadrons (quarks, antiquarks, and gluons).\n\nThe strange quark's existence was indirectly validated by SLAC's scattering experiments: not only was it a necessary component of Gell-Mann and Zweig's three-quark model, but it provided an explanation for the kaon () and pion () hadrons discovered in cosmic rays in 1947.\n\nIn a 1970 paper, Glashow, John Iliopoulos and Luciano Maiani presented the so-called GIM mechanism to explain the experimental non-observation of flavor-changing neutral currents. This theoretical model required the existence of the as-yet undiscovered charm quark. The number of supposed quark flavors grew to the current six in 1973, when Makoto Kobayashi and Toshihide Maskawa noted that the experimental observation of CP violation could be explained if there were another pair of quarks.\n\nCharm quarks were produced almost simultaneously by two teams in November 1974 (see November Revolution)—one at SLAC under Burton Richter, and one at Brookhaven National Laboratory under Samuel Ting. The charm quarks were observed bound with charm antiquarks in mesons. The two parties had assigned the discovered meson two different symbols, and ; thus, it became formally known as the meson. The discovery finally convinced the physics community of the quark model's validity.\n\nIn the following years a number of suggestions appeared for extending the quark model to six quarks. Of these, the 1975 paper by Haim Harari was the first to coin the terms \"top\" and \"bottom\" for the additional quarks.\n\nIn 1977, the bottom quark was observed by a team at Fermilab led by Leon Lederman. This was a strong indicator of the top quark's existence: without the top quark, the bottom quark would have been without a partner. However, it was not until 1995 that the top quark was finally observed, also by the CDF and DØ teams at Fermilab. It had a mass much larger than had been previously expected, almost as large as that of a gold atom.\nFor some time, Gell-Mann was undecided on an actual spelling for the term he intended to coin, until he found the word \"quark\" in James Joyce's book \"Finnegans Wake\":\nThe word \"quark\" itself is a Slavic borrowing in German and denotes a dairy product, but is also a colloquial term for ″rubbish″. Gell-Mann went into further detail regarding the name of the quark in his book \"The Quark and the Jaguar\":\nZweig preferred the name \"ace\" for the particle he had theorized, but Gell-Mann's terminology came to prominence once the quark model had been commonly accepted.\n\nThe quark flavors were given their names for several reasons. The up and down quarks are named after the up and down components of isospin, which they carry. Strange quarks were given their name because they were discovered to be components of the strange particles discovered in cosmic rays years before the quark model was proposed; these particles were deemed \"strange\" because they had unusually long lifetimes. Glashow, who co-proposed charm quark with Bjorken, is quoted as saying, \"We called our construct the 'charmed quark', for we were fascinated and pleased by the symmetry it brought to the subnuclear world.\" The names \"bottom\" and \"top\", coined by Harari, were chosen because they are \"logical partners for up and down quarks\". In the past, bottom and top quarks were sometimes referred to as \"beauty\" and \"truth\" respectively, but these names have somewhat fallen out of use. While \"truth\" never did catch on, accelerator complexes devoted to massive production of bottom quarks are sometimes called \"beauty factories\".\n\nQuarks have fractional electric charge values – either (−) or (+) times the elementary charge (e), depending on flavor. Up, charm, and top quarks (collectively referred to as \"up-type quarks\") have a charge of + e, while down, strange, and bottom quarks (\"down-type quarks\") have − e. Antiquarks have the opposite charge to their corresponding quarks; up-type antiquarks have charges of − e and down-type antiquarks have charges of + e. Since the electric charge of a hadron is the sum of the charges of the constituent quarks, all hadrons have integer charges: the combination of three quarks (baryons), three antiquarks (antibaryons), or a quark and an antiquark (mesons) always results in integer charges. For example, the hadron constituents of atomic nuclei, neutrons and protons, have charges of 0 e and +1 e respectively; the neutron is composed of two down quarks and one up quark, and the proton of two up quarks and one down quark.\n\nSpin is an intrinsic property of elementary particles, and its direction is an important degree of freedom. It is sometimes visualized as the rotation of an object around its own axis (hence the name \"\"), though this notion is somewhat misguided at subatomic scales because elementary particles are believed to be point-like.\n\nSpin can be represented by a vector whose length is measured in units of the reduced Planck constant \"ħ\" (pronounced \"h bar\"). For quarks, a measurement of the spin vector component along any axis can only yield the values +\"ħ\"/2 or −\"ħ\"/2; for this reason quarks are classified as spin- particles. The component of spin along a given axis – by convention the \"z\" axis – is often denoted by an up arrow ↑ for the value + and down arrow ↓ for the value −, placed after the symbol for flavor. For example, an up quark with a spin of + along the \"z\" axis is denoted by u↑.\n\nA quark of one flavor can transform into a quark of another flavor only through the weak interaction, one of the four fundamental interactions in particle physics. By absorbing or emitting a W boson, any up-type quark (up, charm, and top quarks) can change into any down-type quark (down, strange, and bottom quarks) and vice versa. This flavor transformation mechanism causes the radioactive process of beta decay, in which a neutron () \"splits\" into a proton (), an electron () and an electron antineutrino () (see picture). This occurs when one of the down quarks in the neutron () decays into an up quark by emitting a virtual boson, transforming the neutron into a proton (). The boson then decays into an electron and an electron antineutrino.\n\nBoth beta decay and the inverse process of \"inverse beta decay\" are routinely used in medical applications such as positron emission tomography (PET) and in experiments involving neutrino detection.\nWhile the process of flavor transformation is the same for all quarks, each quark has a preference to transform into the quark of its own generation. The relative tendencies of all flavor transformations are described by a mathematical table, called the Cabibbo–Kobayashi–Maskawa matrix (CKM matrix). Enforcing unitarity, the approximate magnitudes of the entries of the CKM matrix are:\nwhere \"V\" represents the tendency of a quark of flavor \"i\" to change into a quark of flavor \"j\" (or vice versa).\n\nThere exists an equivalent weak interaction matrix for leptons (right side of the W boson on the above beta decay diagram), called the Pontecorvo–Maki–Nakagawa–Sakata matrix (PMNS matrix). Together, the CKM and PMNS matrices describe all flavor transformations, but the links between the two are not yet clear.\n\nAccording to quantum chromodynamics (QCD), quarks possess a property called \"color charge\". There are three types of color charge, arbitrarily labeled \"blue\", \"green\", and \"red\". Each of them is complemented by an anticolor – \"antiblue\", \"antigreen\", and \"antired\". Every quark carries a color, while every antiquark carries an anticolor.\n\nThe system of attraction and repulsion between quarks charged with different combinations of the three colors is called strong interaction, which is mediated by force carrying particles known as \"gluons\"; this is discussed at length below. The theory that describes strong interactions is called quantum chromodynamics (QCD). A quark, which will have a single color value, can form a bound system with an antiquark carrying the corresponding anticolor. The result of two attracting quarks will be color neutrality: a quark with color charge \"ξ\" plus an antiquark with color charge −\"ξ\" will result in a color charge of 0 (or \"white\" color) and the formation of a meson. This is analogous to the additive color model in basic optics. Similarly, the combination of three quarks, each with different color charges, or three antiquarks, each with anticolor charges, will result in the same \"white\" color charge and the formation of a baryon or antibaryon.\n\nIn modern particle physics, gauge symmetries – a kind of symmetry group – relate interactions between particles (see gauge theories). Color SU(3) (commonly abbreviated to SU(3)) is the gauge symmetry that relates the color charge in quarks and is the defining symmetry for quantum chromodynamics. Just as the laws of physics are independent of which directions in space are designated \"x\", \"y\", and \"z\", and remain unchanged if the coordinate axes are rotated to a new orientation, the physics of quantum chromodynamics is independent of which directions in three-dimensional color space are identified as blue, red, and green. SU(3) color transformations correspond to \"rotations\" in color space (which, mathematically speaking, is a complex space). Every quark flavor \"f\", each with subtypes \"f\", \"f\", \"f\" corresponding to the quark colors, forms a triplet: a three-component quantum field which transforms under the fundamental representation of SU(3). The requirement that SU(3) should be local – that is, that its transformations be allowed to vary with space and time – determines the properties of the strong interaction. In particular, it implies the existence of eight gluon types to act as its force carriers.\n\nTwo terms are used in referring to a quark's mass: \"current quark mass\" refers to the mass of a quark by itself, while \"constituent quark mass\" refers to the current quark mass plus the mass of the gluon particle field surrounding the quark. These masses typically have very different values. Most of a hadron's mass comes from the gluons that bind the constituent quarks together, rather than from the quarks themselves. While gluons are inherently massless, they possess energy – more specifically, quantum chromodynamics binding energy (QCBE) – and it is this that contributes so greatly to the overall mass of the hadron (see mass in special relativity). For example, a proton has a mass of approximately 938 MeV/c, of which the rest mass of its three valence quarks only contributes about 9 MeV/c; much of the remainder can be attributed to the field energy of the gluons. See Chiral symmetry breaking.\nThe Standard Model posits that elementary particles derive their masses from the Higgs mechanism, which is associated to the Higgs boson. It is hoped that further research into the reasons for the top quark's large mass of ~173 GeV/c, almost the mass of a gold atom, might reveal more about the origin of the mass of quarks and other elementary particles.\n\nQuarks are treated as zero-dimensional point-like entities of zero size in QCD; the lack of any detectable size in experiments puts an upper bound on their size of 10^-4 the size of a proton, i.e. less than 10^-19 metres \n\nThe following table summarizes the key properties of the six quarks. Flavor quantum numbers (isospin (\"I\"), charm (\"C\"), strangeness (\"S\", not to be confused with spin), topness (\"T\"), and bottomness (\"B\"′)) are assigned to certain quark flavors, and denote qualities of quark-based systems and hadrons. The baryon number (\"B\") is + for all quarks, as baryons are made of three quarks. For antiquarks, the electric charge (\"Q\") and all flavor quantum numbers (\"B\", \"I\", \"C\", \"S\", \"T\", and \"B\"′) are of opposite sign. Mass and total angular momentum (\"J\"; equal to spin for point particles) do not change sign for the antiquarks.\n\nAs described by quantum chromodynamics, the strong interaction between quarks is mediated by gluons, massless vector gauge bosons. Each gluon carries one color charge and one anticolor charge. In the standard framework of particle interactions (part of a more general formulation known as perturbation theory), gluons are constantly exchanged between quarks through a virtual emission and absorption process. When a gluon is transferred between quarks, a color change occurs in both; for example, if a red quark emits a red–antigreen gluon, it becomes green, and if a green quark absorbs a red–antigreen gluon, it becomes red. Therefore, while each quark's color constantly changes, their strong interaction is preserved.\n\nSince gluons carry color charge, they themselves are able to emit and absorb other gluons. This causes \"asymptotic freedom\": as quarks come closer to each other, the chromodynamic binding force between them weakens. Conversely, as the distance between quarks increases, the binding force strengthens. The color field becomes stressed, much as an elastic band is stressed when stretched, and more gluons of appropriate color are spontaneously created to strengthen the field. Above a certain energy threshold, pairs of quarks and antiquarks are created. These pairs bind with the quarks being separated, causing new hadrons to form. This phenomenon is known as \"color confinement\": quarks never appear in isolation. This process of hadronization occurs before quarks, formed in a high energy collision, are able to interact in any other way. The only exception is the top quark, which may decay before it hadronizes.\n\nHadrons contain, along with the \"valence quarks\" () that contribute to their quantum numbers, virtual quark–antiquark () pairs known as \"sea quarks\" (). Sea quarks form when a gluon of the hadron's color field splits; this process also works in reverse in that the annihilation of two sea quarks produces a gluon. The result is a constant flux of gluon splits and creations colloquially known as \"the sea\". Sea quarks are much less stable than their valence counterparts, and they typically annihilate each other within the interior of the hadron. Despite this, sea quarks can hadronize into baryonic or mesonic particles under certain circumstances.\n\nUnder sufficiently extreme conditions, quarks may become deconfined and exist as free particles. In the course of asymptotic freedom, the strong interaction becomes weaker at higher temperatures. Eventually, color confinement would be lost and an extremely hot plasma of freely moving quarks and gluons would be formed. This theoretical phase of matter is called quark–gluon plasma. The exact conditions needed to give rise to this state are unknown and have been the subject of a great deal of speculation and experimentation. A recent estimate puts the needed temperature at kelvin. While a state of entirely free quarks and gluons has never been achieved (despite numerous attempts by CERN in the 1980s and 1990s), recent experiments at the Relativistic Heavy Ion Collider have yielded evidence for liquid-like quark matter exhibiting \"nearly perfect\" fluid motion.\n\nThe quark–gluon plasma would be characterized by a great increase in the number of heavier quark pairs in relation to the number of up and down quark pairs. It is believed that in the period prior to 10 seconds after the Big Bang (the quark epoch), the universe was filled with quark–gluon plasma, as the temperature was too high for hadrons to be stable.\n\nGiven sufficiently high baryon densities and relatively low temperatures – possibly comparable to those found in neutron stars – quark matter is expected to degenerate into a Fermi liquid of weakly interacting quarks. This liquid would be characterized by a condensation of colored quark Cooper pairs, thereby breaking the local SU(3) symmetry. Because quark Cooper pairs harbor color charge, such a phase of quark matter would be color superconductive; that is, color charge would be able to pass through it with no resistance.\n\n\n\n"}
{"id": "16033621", "url": "https://en.wikipedia.org/wiki?curid=16033621", "title": "Smoky Hills Wind Farm", "text": "Smoky Hills Wind Farm\n\nThe Smoky Hills Wind Farm (Phase I & Phase II) is a 250 megawatt (MW) wind farm in Lincoln and Ellsworth Counties, 140 miles west of Topeka in Kansas, north of Ellsworth. The farm is operated by Enel Green Power. Highway K-14 and Interstate 70 pass through parts of the wind farm, with clear views of many of the wind turbines. The project uses 56 Vestas V80 1.8 MW wind turbines and produces enough electricity to power some 37,000 average Kansas homes annually. , phase II is under construction with 99 GE 1.5 MW wind turbines for an additional 148.5 MW, to bring the total nameplate capacity to 249.3 MW. \nPhase II was completed and began commercial operation in December 2008.\n\n\n"}
{"id": "55140131", "url": "https://en.wikipedia.org/wiki?curid=55140131", "title": "Sundilla Barrage", "text": "Sundilla Barrage\n\nSundilla Barrage is an under construction irrigation project located at Sundilla Village, Kamanpur Mandal, Peddapalli district in Telangana State, India.\nThis is one of the 3 barrages proposed in Kaleshwaram Project which envisages construction of three barrages between Yellampally & Medigadda.\n\nProposed Sundilla Barrage details:\n\nSundilla is a Village in ramagiri Mandal in peddapalli District of Telangana State, India. It belongs to Telangana region . It is located 38 KM towards East from District head quarters peddapalli. 11 KM from Kamanpoor. \n\nSundilla Pin code is 505209 and postal head office is Scab . \n\nSriram Nagar ( 4 KM ) , Jawahar Nagar ( 4 KM ) , Medhari Basthi Godavarikhani ( 4 KM ) , Lb Nagar ( 4 KM ) , Medhari Basthi Laxmi Nagar ( 4 KM ) are the nearby Villages to Sundilla. Sundilla is surrounded by Jaipur Mandal towards North , Ramagundam Mandal towards west , Manthani Mandal towards South , Mancherial Mandal towards North . \n\nRamagundam , Mancherial , Mandamarri , Bellampalle are the near by Cities to Sundilla. \n\nThis Place is in the border of the Karimnagar District and Adilabad District. Adilabad District Jaipur is North towards this place .\nDemographics of Sundilla\n\nTelugu is the Local Language here. Total population of Sundilla is 3318 .Males are 1689 and Females are 1,629 living in 748 Houses. Total area of Sundilla is 1068 hectares. \nPolitics in Sundilla\n\nTDP , TRS , PRAP , INC are the major political parties in this area. \nPolling Stations /Booths near Sundilla\n\n1)Stambampalli Pk \n2)Sundilla \n3)Sundilla \n4)Mulugupalli \n5)Jallaram \nHOW TO REACH Sundilla\n\nBy Road\n\nRamagundam is the Nearest Town to Sundilla. Road connectivity is there from Ramagundam to Sundilla.\nBy Rail\n\nThere is no railway station near to Sundilla in less than 10 km. How ever there are railway Stations from Near By town Ramagundam. are the railway Stations near to Ramagundam. You can reach from Ramagundam to Sundilla by road after . \nColleges near Sundilla\n\nPragathi Jr College, Kalvacherla\nAddress : Kalvacherla\nPragathi Degree College\nAddress : H.no.3--47/1; Kalvacherla(v); Via Centenary Colony; Kamanpur (m); Karimnagar A Dist.\nSchools in Sundilla\n\nZphs Sundilla\nAddress : sundilla , kamanpoor , karimnagar , Andhra Pradesh . PIN- 505209 , Post - Scab\nViveka Vardhani High Scho\nAddress : sundilla , kamanpoor , karimnagar , Andhra Pradesh . PIN- 505209 , Post - Scab\n\nSundilla Barrage foundation was laid by First Chief Minister of Telangana, K.Chandrashekar Rao on 02 May 2016.\n\nThe project started by Telangana government as part of the Kaleshwaram Lift Irrigation Schema to irrigate the of new land and stabilize the of existing irrigated land.\n\n"}
{"id": "7972359", "url": "https://en.wikipedia.org/wiki?curid=7972359", "title": "Sunshower (commercial product)", "text": "Sunshower (commercial product)\n\nSeveral commercial products share the name Sunshower.\n\nMade by outdoors equipment producer Stearns Inc., the \"Sun Shower\" is an insulated bag that uses solar energy to heat water held within. Once heated, the user can take a shower, using the attached tubing and nozzle. Models vary, with different volumes, pressurizers, etc. Stearns also sells a variety of \"Sun Shower\" branded accessories, such as bio-degradable soap and inflatable shower stalls.\n\nIn addition, Dutch company Sunshower B.V. makes a combination shower/tanning booth branded \"The Sunshower\".\n\n"}
{"id": "13440300", "url": "https://en.wikipedia.org/wiki?curid=13440300", "title": "Too cheap to meter", "text": "Too cheap to meter\n\nToo cheap to meter describes a commodity so inexpensive that it is cheaper and less bureaucratic to simply provide it for a flat fee or even free and make a profit from associated services. It can also refer to services which it would cost more to itemize bills for the service than it costs to provide the service in the first place, thus it being simpler and less expensive to just provide it in a bundle along with other services.\n\nAlthough sometimes attributed to Walter Marshall, a pioneer of nuclear power in the United Kingdom, the phrase was coined by Lewis Strauss, then chairman of the United States Atomic Energy Commission, who in a 1954 speech to the National Association of Science Writers said:\n\n\"Our children will enjoy in their homes electrical energy too cheap to meter... It is not too much to expect that our children will know of great periodic regional famines in the world only as matters of history, will travel effortlessly over the seas and under them and through the air with a minimum of danger and at great speeds, and will experience a lifespan far longer than ours, as disease yields and man comes to understand what causes him to age.\"\nIt is often assumed that Strauss' prediction was a reference to conventional uranium fission nuclear reactors. Indeed, only ten days prior to his “Too Cheap To Meter” speech, Strauss was present for the groundbreaking of the Shippingport Atomic Power Station where he predicted that, \"industry would have electrical power from atomic furnaces in five to fifteen years.\" However, Strauss was possibly referring to hydrogen fusion power and Project Sherwood, which was conducting secret research on developing practical fusion power plants.\n\nStrauss gave no public hint at the time that he was referring to fusion reactors, because of the classified nature of Project Sherwood, and the press naturally took his prediction regarding cheap electricity to apply to conventional fission reactors. However, the U.S. Atomic Energy Commission itself, in testimony to the U.S. Congress only months before, lowered the expectations for fission power, projecting only that the costs of reactors could be brought down to about the same as those for conventional sources.\n\nStrauss viewed hydrogen fusion as the ultimate power source. He was eager to develop the technology as quickly as possible and urged the Project Sherwood researchers to make rapid progress, even suggesting a million-dollar prize to the individual or team that succeeded first. However Strauss was not optimistic about the rapid commercialisation of fusion power. In August 1955 after fusion research was made public, he cautioned \"there has been nothing in the nature of breakthroughs that would warrant anyone assuming that this [fusion power] was anything except a very long range — and I would accent the word ‘very’ — prospect.\"\n\nNo evidence has been found in Strauss’s archived papers to indicate fusion was the secret subject of his speech.\n\n\n"}
{"id": "842236", "url": "https://en.wikipedia.org/wiki?curid=842236", "title": "Torque density", "text": "Torque density\n\nTorque density is a measure of the torque-carrying capability of a mechanical component. It is the ratio of torque capability to volume and is expressed in units of torque per volume. Torque density is a system property since it depends on the design of each element of the component being examined and their interconnection. \n\nTorque density is useful during the concept evaluation stage of mechanical designs, especially in power train design problems. Typically, it will be one of many factors used to assign potential success measures to each concept. For example, in the upgrade of a drive train for a set of rolls in a rolling mill, space is often dictated by the configuration of current components. There may be several types of devices that can perform the function of an existing component that must be replaced. The relative torque densities of the devices may be an important determinant for which design is ultimately selected, although it will often compete with other factors such as cost, ease of maintenance, time to install, operating costs and potential failure modes.\n\nIn SI units, torque density is expressed in joules per cubic metre or equivalently newton-metres per cubic metre (though dimensionally equivalent to the pascal, that is usually not used for this purpose). Small amounts can be expressed in newton-millimetres per cubic millimetre. \n\nIn U.S. customary units, torque density is expressed in foot-pounds force per cubic foot, or inch-pounds force per cubic inch or ounce-force inches per cubic inch.\n"}
{"id": "7273059", "url": "https://en.wikipedia.org/wiki?curid=7273059", "title": "Value of lost load", "text": "Value of lost load\n\nThe Value of Lost Load (VoLL) is the estimated amount that customers receiving electricity with firm contracts would be willing to pay to avoid a disruption in their electricity service. The value of these losses can be expressed as a customer damage function (CDF). A CDF is defined as:\n\nBased on the calculated outage cost, a CDF can be obtained for various customer groups. Typically, there are three distinct groups of customers: residential, small and medium commercial/industry and large commercial/industrial. Figure 1 below illustrates the incremental CDFs of these three groups.\n\nThe CDF relates the magnitude of customer losses (per kW interrupted) for a given duration of a power outage. While the general shapes of all three curves are similar, the magnitude of loss varies dramatically depending on the customer’s size. Based on VoLL data from an EGAT survey in March and April 2000, it was estimated that the customers’ costs in the first hour for residential customers was Baht 11.45/kW. For large commercial/industrial (C/I) and small & medium C/I customers, the cost in the first hour was Baht 29.55/kW and Baht 89.50 /kW respectively. Further research from EPRI indicates that residential customers’ cost tend to peak at USD 1.50/kW in the first hour and falls of to USD 0.46/kW in subsequent hours. On the other hand, large C/I and small & medium C/I suffer much higher losses of USD 10/kW and USD 38/kW respectively in the first hour. This falls to USD 4/kW and USD 9/kW respectively in the subsequent hours.\n\nThe CDF predicts the loss per interrupted kW based on factors that influence the outage. The CDF is usually calculated based on defined market segments such as residential, commercial, and industrial. This is done because there are large variations of costs across the utility market segments. However, in a large area it is a normal practice that the interruption cost is aggregated to represent a general picture of the load losses. The aggregated interruption cost is called the composite CDF.\n\n"}
{"id": "3427200", "url": "https://en.wikipedia.org/wiki?curid=3427200", "title": "Yb:LuVO4", "text": "Yb:LuVO4\n\nYb:LuVO (Ytterbium-doped Lutetium Vanadate)is an active laser medium. The peak absorption cross section for the pi-polarization is 8.42×10 cm² at 985 nm, and the stimulated emission cross section at 1020 nm is 1.03×10 cm².\n\n\n"}
