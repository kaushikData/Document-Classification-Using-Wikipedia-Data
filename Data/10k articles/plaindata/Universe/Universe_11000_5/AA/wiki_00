{"id": "6185517", "url": "https://en.wikipedia.org/wiki?curid=6185517", "title": "1980 Kalamazoo tornado", "text": "1980 Kalamazoo tornado\n\nThe Kalamazoo Tornado of 1980 struck downtown Kalamazoo, Michigan, on Tuesday, May 13, 1980. The tornado, which touched down at 4:09 pm, was rated F3 on the Fujita scale. The tornado killed 5 people and injured 79. Damage was estimated at $50,000,000.\n\nThe tornado left a path of destruction long during its approximately 20-minute duration. It was notable for having struck the heart of downtown, damaging or destroying many notable buildings, parks, and landmarks. The massive F3 caused a power outage so extensive, phone companies pleaded for people to only use phones for emergencies. In total, the storm caused 5 deaths, 79 injuries, and about 1,200 people were left homeless.\n\n\n"}
{"id": "3354734", "url": "https://en.wikipedia.org/wiki?curid=3354734", "title": "1992 Guadalajara explosions", "text": "1992 Guadalajara explosions\n\nA series of ten explosions took place on April 22, 1992, in the downtown district of Analco Colonia Atlas in Guadalajara city, Jalisco state, Mexico. Numerous gasoline explosions in the sewer system and fires over four hours destroyed of streets. Gante Street was the most damaged. By the accounting of Lloyd's of London, the reported number of people killed was about 252 people although many estimate that the catastrophe actually caused at least 1000 deaths. About 500 to 600 people were missing, nearly 500 were injured and 15,000 were left homeless. The estimated monetary damage ranges between $300 million and $1 billion. The affected areas can be recognized by the more modern architecture in the areas that were destroyed.\n\nFour days before the explosion, residents started complaining of a strong gas-like smell coming from the sewers which became progressively more pungent over the course of those days. They were experiencing symptoms such as stinging in their eyes and throats; and nausea. Some residents even found gasoline coming out of their water pipes. City workers were dispatched to check the sewers and found dangerously high levels of gasoline fumes. However, the city mayor did not feel it was necessary to evacuate the city because he felt that there was no risk of an explosion.\n\nBefore the explosions, on April 19, Gante Street residents reported a strong stench of gasoline and plumes of white smoke coming out from the sewers to the City of Guadalajara. The next day, workers of the City Council and Civil Protection commenced two days of investigations in Gante Street; they found high levels of gasoline among other hydrocarbons, but announced it was not necessary to evacuate the area. At 10am on April 22, manhole covers in the street began to bounce and columns of white smoke started coming out of them.\n\nAt 10:05 on April 22, the first two explosions were recorded, the first on the corner of Calzada Independencia and Aldama Street, and the second at the intersection of Gante and 20 De Noviembre. A minute later the first call was received on the 060 Emergency Line and was forwarded to automatic voice messenger. A third explosion at 10:08 resulted in a bus, belonging to the Tuts Company, being projected through the air on the corner of Gante and Nicolas Bravo. Four minutes later another explosion was registered in Gonzalez Gallo Avenue. At 10:15 factory workers along Gonzalez Gallo Avenue began to evacuate, just before rescue teams and volunteers began to arrive in areas affected by the explosions. At 10:23 the fifth explosion occurred, at the intersection of Gante and Calzada del Ejercito. At 10:29 evacuations began in the Mexicaltzingo neighborhood, two minutes before the sixth explosion was recorded at the intersection of 5 De Febrero and Rio Bravo.\n\nAt 10:43 the seventh explosion occurred, at the corner of Ghent Street and Silverio Garcia. Just after more rescue teams arrived in the affected areas, the eighth explosion occurred at 11:02, at the intersection of Rio Nilo Avenue and the Rio Grande. After this explosion the neighborhoods of Atlas, Alamo Industrial, El Rosario, Quinta Velarde and Fraccionamiento Revolución; and the center of the municipality of Tlaquepaque; were evacuated. The last two explosions were at 11:16, one at the intersection of Rio Alamos and Rio Pecos, and the other at González Gallo and Rio Suchiate. In the afternoon, the fear of further tragedies made people across the Guadalajara Metro Area uncover manholes for any remaining gases to escape. Residents of neighborhoods such as Zona Industrial, 18 De marzo, Fresno, 8 De Julio, Ferrocarril, La Nogalera, Morelos, Echeverria, Polanco, 5 de mayo and Miravalle are told to be aware of any unusual events.\n\nAfter the explosions, there was great panic on April 25 among residents of the neighborhoods 5 De Mayo, el Dean, Echeverría and Polanco; firefighters asked people to avoid lighting any flames, due to a strong smell of gas. It was later confirmed to be a leak in a Pemex pipe.\n\nAn investigation into the disaster found that there were two precipitating causes:\n\n\nIn the aftermath, city officials and corporations blamed each other. Some people initially thought a cooking oil manufacturing company was leaking hexane, a flammable liquid similar to (and a component of) gasoline, into the sewers, but this was later found to be erroneous. Numerous arrests were made in an attempt to indict those responsible for the blasts. Four Pemex officials were indicted and charged, on the basis of negligence. Ultimately, however, these people were cleared of all charges.\n\nMany of the survivors that were affected by the explosions started a group called \"La Asociacion 22 de Abril en Guadalajara\" (the association of April 22 of Guadalajara). This campaign was started by a survivor of the explosions named Lilia Ruiz Chávez, who as a result of the explosions lost her leg as well as her home. She started the group that has a total of 80 members not only because no one was convicted of this preventable incident but also because the victims of this tragedy were not receiving any compensation or assistance due to injuries sustained or loss as a result of the accident. The victims of this tragedy not only lost their homes but also their health and many lost loved ones as well. Although they are aware that no amount of money will bring back their relatives as states Chavez, the tragedy left them unable to care for themselves let alone afford their medication as a consequence of the incident. Chavez as well as the other survivors have been fighting for 24 years now for justice to be served. Because of the constant struggle and pressure from the victims toward Pemex, the company that was initially blamed for the incident, finally agreed to pay out 40 million pesos to the group. Although Pemex claims this is a donation and no way does it mean they are taking blame for the incident.\n\n"}
{"id": "23395637", "url": "https://en.wikipedia.org/wiki?curid=23395637", "title": "2009 European floods", "text": "2009 European floods\n\nThe 2009 European floods were a series of natural disasters that took place in June 2009 in Central Europe. Austria, the Czech Republic, Germany, Hungary, Poland, Romania, Serbia, Slovakia and Turkey were all affected. The heavy rains caused overflowing of the rivers Oder, Vistula, Elbe and Danube. At least 12 people were killed in the Czech Republic and one in Poland.\n\nThe floods were the worst natural disaster in the Czech Republic since 2002, when floods killed 17 people and caused billions of dollars of damage in Prague. Those same floodwaters from the Czech Republic also affected Germany, with Dresden being hit by its worst flooding for over a century and three thousand people evacuated from areas where water was said to be waist-deep. Austria also experienced its heaviest rainfalls in half a century.\n\nJune 2009 was one of the rainiest months of June for Austria since weather records have been kept. After a very dry April, May had already been wet, and in the middle of June, low pressure areas and thunderstorms followed. \"Quinton Low\" ensured strong rainfall in the Eastern Alps, the southern Carpathians, and from the middle of the Balkan Peninsula to the Crimea and Baltic Sea regions between June 20 and June 30. It moved slowly over the Adriatic Sea toward the Black Sea forming an \"upper low\" – despite the typical muggy movement from the southeast and build-up of precipitation from the east and northeast, a classic flood situation that was missing the Genoa low of a ground low core.\n\nThe Quinton Low formed from June 20–22, through constriction of an upper low over the Alps towards the southeast. An Atlantic infusion of cold air had brought heavy precipitation with snowfall down to elevations of 1500m. The separated upper low shifted over the mid-Adriatic on June 20 and 21 and the central Balkans on June 22. Its front system, which was occluded from the east and then was guided to the northeast towards Central Europe, drove from June 22–24 from the Lower Inn Valley to the Vienna Basin with heavy precipitation of over 100mm/48h, with 207mm/48h in Lunz am See. Locally, this phase was similar to the 2005 European floods, although in that year there was a faster rise.\n\nStarting on June 25, the low moved over the Black Sea. On June 25 and 26, the precipitation was concentrated in the area around Belgrade and Southern Hungary. In Austria and the Czech Republic, the situation eased. On June 27 and 28, a front moved towards Southern Poland and the Baltic states, and further precipitation-heavy air masses once again struck the Czech Republic, Austria, and Serbia, as well as Central Bulgaria and Moldova on June 29.\n\nThe stable and stationary weather situation did not disintegrate until after June 29. However, the air mass over Central and Eastern Europe remained extremely moist and unstable such that heavy thunderstorms repeatedly drove further local floods in the following days. Local areas of heavy rain of up to 50mm in a few hours were recorded across Central Europe until the first two weeks of July. The end of the weather phase did not occur until the passing of the low \"Rainer\" over England and the North Sea and low \"Steffen\" over Southern Scandinavia, which the slowly advancing weather system surrounded from July 3 to the 9th.\n\nOn Tuesday June 23, the strong rise began to impact the tributaries that lead from the south to the Danube, and flood warnings were triggered on the night of June 24 in many places in the Upper and Lower Austrian Prealps. The state warning centers were reinforced. By the morning of June 24, about 4,000 firefighters were already operating in Upper Austria and Lower Austria. Armed Forces helicopters were also in use.\n\nIn Upper Austria, the Krems and Traun rivers partially came together at the banks. The level of the tributaries was rising while the Danube was steady. Seven districts in Lower Austria were already affected. The rivers Ybbs, Melk, Erlauf, Traisen, and Perschling were especially flooded. Ybbsitz had been closed off from the outside world since 3AM. At the Danube (Strudengau, Wachau), the available mobile flood prevention equipment was assembled as much as possible. In Styria, only individual actions were reported, mainly pumping operations but also elimination of mudslides.\n\nBy June 25, the persistent rainfall was over. Instead, increasingly short heavy rains with large masses of water were recorded. Since the ground was no longer receptive to water, the aftereffects of these precipitations were similarly devastating. In Upper Austria, the situation calmed because the level of the tributaries was slowly falling towards normal levels. In Steyr, the level had sunk to the quay, 1.4m less than the previous day. The Danube had reached its highest level of 6.9m overnight in Mauthausen and also sank slowly. The center of the flood shifted towards Wachau as the precipitation itself moved towards the east. 253 of the 326 fire departments in Burgenland were called on for flood operations within 24 hours. The Albertina Museum in Vienna evacuated 950,000 artworks by artists such as Monet and Renoir.\n\nOn June 26, further floods affected areas stretching from Mostviertel to Burgenland, particularly in the Güssing District where whole tracts of land were under up to a meter of water, while Strem was surrounded by masses of water. The Armed Forces assisted the fire departments with 200 men. In the Lower Austrian Klingfurth near Wiener Neustadt, homes threatened by a landslide had to be evacuated. The Adria-Wien Pipeline, which lies in the affected hillside, had to be turned off for security reasons. In Styria, in which about 400 landslides were recorded since the beginning of the storm, the situation calmed a bit as the day turned to evening.\n\nOn Saturday June 27, two dams of the Leitha river in Bruck an der Leitha District were broken open so that water could flow into an uninhabited area in order to relieve the river. On Sunday night, a fatality was reported.\n\nFurther installments of rain were encountered after the weekend. The assistance of the Armed Forces concentrated on the areas around Feldbach District and Fürstenfeld District. Upper Styria was also increasingly affected. The village of Radmer was without power and completely inaccessible after heavy mudslides. Floods and obstructions also surrounded Mariazell and Hieflau. The situation at the Enns intensified again. On the afternoon of Monday June 29, the level of the Steyr was again over 4m. Wachau also went into another flood warning. On the night of June 30, the Alpine railway station was flooded for the second time in the span of a few days after the strongest-ever measured rainfall in St. Pölten. The ÖBB again closed down the operation of the Mariazellerbahn.\n\nOn Tuesday, further landslides were able to be stopped with the help of Czech hedgehogs. Nevertheless, numerous buildings could still not be cleared as habitable. Due to scattered storms in Graz-Umgebung District, there were also frequent lightning strikes.\n\nOn Friday July 3, Wachau was affected by the storm for the second time within two weeks. Spitz, which had been previously flooded by the Danube, was flooded this time by the usually only 30 cm deep Spitzerbach, which swelled to 4m after thunderstorms. An 81-year-old man who was swept away was not found until July 12 in the Danube. Also, in Waldviertel and Steyr-Land District, severe thunderstorms occurred with heavy precipitation, which again required the use of over 2,000 firefighters.\n\nOn Monday July 6, the strongest rainfall in 200 years began in the afternoon hours. Parts of Lower Austria, Vienna, and Northern Burgenland were especially affected. St. Pölten was again declared a disaster area, as large parts of the metropolitan area were flooded. The Nadelbach flooded the cadastral communities Nadelbach and Hafing. The surroundings of the Alpine Railway Station were yet again under water. Areas that had never before had to suffer through flooding were also unexpectedly under water on July 6. Europaplatz and Schießstadtring in St. Pölten had to be closed off; a 7m-wide stream had carved itself out leading from the Alpine Railway Station to the center of the city. The regional court and the prison were also threatened by high water. A further danger existed at the EVN Group substation as the water level had almost brought power production to a halt. The B1a tunnel under the government Landhaus district was blocked due to the flood. The Western Railway had to be closed down for two hours in the evening. Additional problems arose due to the rise of the groundwater level associated with the flooding, which also reached a historical peak.\n\nSevere weather warnings were issued on Thursday July 7 that were similar in scope to the days before. This time however, the storm affected the Upper Austrian area more, where especially extensive damage had been done by hail in agricultural areas in Gmunden, Vöcklabruck, and Wels. In Dürnstein in Wachau, there were rockslides at Vogelbergsteig, which blocked both the Danube Highway and the Danube Railway. The B3 became once again freely passable on July 10 after explosions that removed loose rock from the wall. However, the Danube Railway required longer repair work.\n\nOn July 10, the situation in Styria again took a turn for the worse. There was further rainfall, especially in Feldbach District. There were about 600 landslides in Styria around this timeframe.\n\nFrom 7:00AM on June 22 to 7:00AM on June 24th, several places in Austria received over 150L/m² of rainfall. Below is the total monthly precipitation for June 2009 – from Upper Austria to Northern Burgenland, 200-300% of the average monthly precipitation totals were recorded, with Spitzenwert in St. Pölten at 388%, almost four times the normal amount.\n\nThe precipitation persisted even into the first half of July. Spitzenwerte was reached on July 6. Places where the level reached over 50L/m²:\n\nDamage estimates were first released after two weeks. The damage in Burgenland amounted to over €2,500,000. In Lower Austria, about 3,000 claims were registered with a total claim amount of about €60,000,000. Because of this, the assistance for Lower Austria was increased from an estimated €2,500,000 to €10,000,000. In Upper Austria, damage claims were expected to be about €20,000,000. In Styria, the amount was about €10,000,000. The other federal states did not report damage totals.\n\nSince disaster management in Austria takes place mainly at the federal state level, figures for all of Austria are not readily available. Countrywide figures were only released for the Armed Forces. 137,000 relief hours were worked in the assistance operation from June 23 to July 9. On average, about 700 soldiers were deployed at any time countrywide. 311,000 relief hours were worked by firefighters and disaster assistance services in the largest federal state Lower Austria alone. The Austrian Red Cross also helped with many volunteers and crisis intervention teams. Likewise, Team Austria volunteers were put to work in the relief effort.\n\nThe fact that at the beginning of August in Lower Austria alone twelve streets and three railways were obstructed shows how extensive the infrastructure damage was. The repair work took weeks.\n\nIn the Czech Republic, persistent heavy rainfall beginning on June 22 led to the rise of smaller Vltavan tributaries in the Bohemian Forest and the Nové Hrady Mountains. A flood warning was issued for the South Bohemian Region. The highest level was reached in the rivers Malše, Blatnice, and Černá. České Budějovice was also affected by the warning. In the evening, the Rožnovská Bečva rose about 1.2m in Valašské Meziříčí and its water level at the estuary in the Bečva rose to ten times normal. The Vsetínská Bečva also swelled and several streets were flooded in Vsetín, Valašské Meziříčí, and Rožnov pod Radhoštěm. In Zubří, numerous cars were overcome by the water. There were fatalities in Černotín and Valašské Meziříčí. In Český Krumlov, the Vltava reached six times the normal water amount, with 63 m³/s. Near Větřní, a dinghy containing three occupants capsized, one of which drowned.\n\nThe floods in North Moravia and Silesia took on a different character. In the span of two hours on June 24, strong rainfall brought flash floods with up to 80L/m² of rain at the streams Jičínka and Zrzávka. The level of the Jičínka swelled to 5.5m and thereby exceeded the 1997 Central European flood by 2m. In Jeseník nad Odrou, the brook Luha rose to 2m in the span of a half-hour; four people died in that community, three by drowning. People also died in Nový Jičín, Bernartice nad Odrou, Životice u Nového Jičína, and Kunín. The floods also created extensive damage in districts of Nový Jičín such as Bludovice, Žilina, Hodslavice, and Mořkov.\n\nOther rivers temporarily rose over their banks after strong local rainfall. In Bohemian Switzerland, the Kamenice flooded parts of Janská on the evening of July 1. On July 6th, sudden thunderstorms hit Ústí nad Labem Region, where a state of emergency had to be called in some places. West and South Bohemia were also severely threatened in places like Tábor. The authorities feared a burst of dams of artificial lakes and considered evacuating the affected villages.\n\nParts of West and South Bohemia as well as Central Moravia were also greatly affected by the flood. In the region, dams of a series of artificially created lakes threatened to break. The authorities considered the evacuation of more villages on Tuesday night.\n\nOverall, fourteen people died in the Czech Republic due to the impact of the flooding. The Olomouc Region and the Moravian-Silesian Region were particularly affected in the drainage basins of the Oder and the Morava where numerous streets and rail lines were disrupted.\n\nIn the first estimates, the total damage was estimated to be 5-6 billion Czech koruna (about €230,000,000).\n\nHepatitis vaccinations were commenced for children in severely affected areas in order to prevent an outbreak of the disease.\n\nOn July 24, the lowest flood warning level was lifted in Nový Jičín Region. Criticism of the speed of response by firefighters and municipalities was prevalent, as citizens were not informed about impending floods. The Environmental Minister Ladislav Miko confirmed that the meteorological internet server broke down at a critical time.\n\nFurther Precipitation Peaks\n\nBy June 23, the first warnings in Bavaria had already come as precipitation amounted to 70L/m in 24 hours. In the mountains, snowfall was observed. On the Zugspitze, 60 cm of new snow fell. The first floods came at the Inn. Altötting, Berchtesgadener Land, Cham, and particularly Traunstein were affected by the flooding owing to rising tributaries.\n\nOn Thursday night, June 25, the level of the Danube rose in Passau, such that the warning level reached 3 (definition: individual built-up properties or basements are flooded, blocking of local transport channels, or isolated use of water or dam defense is required). On Thursday, the flooding of the Danube and the Isar moved the warning level to 2 (definition: agriculture and forestry land is flooded or light traffic delays on main traffic roads and local roads). Throughout Thursday, the water level sank in Passau, however the recession was slow.\n\nThe first flood notifications in Hungary came on June 25. The Rába reached the highest ever measured level in Szentgotthárd on Thursday morning. This was about 30 cm higher than in a large flood in 1965. Due to the temporary expansion of flood protection and because the high water level did not persist, there was no expected risk. The Hungarian Western Railway still had to close down operation between Szentgotthárd and Jennersdorf because the rails were undermined in numerous places. In Komárom-Esztergom County, the first flood warning level was called. The Leitha in Hungarian territory was not affected.\n\nOn June 26, a cautious all-clear was announced for the Danube between Esztergom and Budapest because the water levels remained lower than had been feared. The peak was expected on the night of June 27 into the 28th and was estimated to be 40–50 cm deeper than in the devastating floods of 2006. Nevertheless, precautions were taken in numerous important locations, such as Szentendre Island.\n\nOn the morning of Sunday, June 28, the Danube reached its high point which was 25% less than the floods in 2006. Flood warnings were in effect for a stretch of 528 kilometers of the Danube in Hungary. In Nagymaros, the level rose 5.33m, while the level in Budapest rose 6.96m. The increase had been expected to be 7.04m for a short time. In the upper Danube areas, the level sank noticeably around this time. In Budapest alone, the floods led to the blockage of the two quays.\n\nOn July 2 there were alerts along 853 kilometers. 36 kilometers of third degree alerts near the river Lajta, second degree on the Danube at Dunakiliti, Győr, Komárom, Esztergom, Budapest and on the river Rába at Sárvár, first degree alerts from the Ipoly river mouth to the southern border of Hungary.\n\nOn June 23, smaller rivers rose in the area of Rzeszów and in Lower Silesian Voivodeship. After strong rain fell in the Owl Mountains (at the rate of 60mm/h in Walim, for example), flood warnings were called for the Piława at Mościsko (Faulbrück) and the Bystrzyca Świdnicka at Lubachów (Breitenhain). In Świdnica, Bystrzyca Street flooded. Further damage was seen in Wałbrzych and Jelenia Góra.\n\nThe Polish National Security Center stated that rivers exceeded warning levels in forty-three areas, whilst alarm levels were exceeded in a further twenty places. A total of fifty families were evacuated in Kraków. Water submerged a railway station in Upper Silesia.\n\nFlood warnings were issued for 22 and 23 June for 21 counties. Amidst rain and hail, warnings were also issued for the Buzău and Ialomiţa rivers for 29 and 30 June.\n\nSerbia was also hit with heavy rainfall by the storms. Places like Belgrade and Novi Sad in the north of the country were mainly affected, but Valjevo was also affected 90 km southeast.\n\nFlood warnings were issued for parts of Northwest and far West Slovakia on June 24 and extended to the Danubian Lowland on the 25th. They became effective on June 26 for the entire length of the Danube and at the Morava. In Čirč in the Prešov Region near the Polish border, two people had already been killed on June 23. A brother and sister drowned as the sister tried to rescue her brother.\n\nIn Devín, a suburb of Bratislava, the level of the Danube was 8.3m on June 26. Alongside Devín, Petržalka, Šariš, and Dunajská Streda were affected by a storm.\n\nOn June 27 and 28, the flood shifted to Bardejov, Tvrdošín, and Námestovo. The communities of Rabča and Oravská Polhora were particularly at risk as two bridges had been destroyed. On the 29th, Kežmarok, Spišská Belá, Ľubica, Stará Bystrica, and Radôstka were affected by landslides and flooding and there were additional storms in Senica and Skalica.\n\nA 20-year-old Slovak drowned in the Ružín reservoir. A Czech died as a tourist raft sank in the border river Dunajec. One person also died in Stará Ľubovňa near the Polish border.\n\nA flash flood in Istanbul started on September 9. Heavy rains caused water levels to rise six feet, flooding a major highway and commercial district in the city's Ikitelli district. Hundreds of people climbed onto rooftops, and many desperate motorists struggled to escape their vehicles and run to safety. Others drowned in their own vehicles. Many people taking refuge on rooftop of them were airlifted to safety by rescue helicopters. Rescue workers using inflatable boats also travelled through the flooded streets, picking up survivors. Some rescuers used ropes to drag people across the torrent to safety. Four helicopters and eight boats were used for rescue work. Istanbul firefighters recovered seven bodies at a truck parking lot littered with upended trucks. The bodies of seven women were found in a van outside a textile factory. The van had been taking them to their jobs, when the flood hit. Police were deployed throughout the city to prevent looting. Two other people died in Istanbul's Catalca suburb and six others were swept away by the flood. 20 people died, 8 were listed as missing, and 20 were injured.\n\nStorms followed this series of floods that had no connection with the weather referenced above but mostly affected the same areas.\n\nOn the night of July 23, a storm front moved from Germany into Austria, the Czech Republic, and Poland that arose due to previously prevalent unusually high temperatures. It impacted the area through hail and storms and partially also through heavy rainfall. In Lower Austria, where such fronts usually dissipate, the front strengthened and the storms hit the Vienna metropolitan area. The population was completely unprepared when the storm struck because it did not appear in any weather models. People were injured or even killed mainly by uprooted trees. Agriculture was also hit hard with damages. Widespread power outages were recorded. The Austrian insurance companies faced damages of around €20,000,000 in the agricultural industry alone. The Austrian hail insurance companies also faced the largest single event in the last 60 years from a cost of damages perspective. On July 25, the emergency personnel of firefighters and the Armed Forces was still engaged in partially repairing an estimated 500 destroyed houses in the Flachgau Region in order to achieve renewed rainfall resistance.\n\nIn Poland, eight people were killed and 34 people were injured by uprooted trees. Two people were also killed in the Czech Republic. Power was still not completely restored by July 25 in the surrounding areas of Liberec and Bohemia.\n"}
{"id": "35595097", "url": "https://en.wikipedia.org/wiki?curid=35595097", "title": "Alfonsine Solar Park", "text": "Alfonsine Solar Park\n\nAlfonsine Solar Park is a 36.2 MW solar photovoltaic (PV) plant in Northern Italy, near Alfonsine, Italy.\n\n"}
{"id": "41479658", "url": "https://en.wikipedia.org/wiki?curid=41479658", "title": "Brine spring", "text": "Brine spring\n\nA brine spring or salt spring is a saltwater spring.\n\nBrine springs are not necessarily associated with halite deposits in the immediate vicinity. They may occur at valley bottoms made of clay and gravel which became soggy with brine seeped downslope from the valley sides.\n\nHistorically, brine springs have been early sources of U.S. salt production, as in the case of the salterns in Syracuse, New York and at the Illinois Salines.\n\n"}
{"id": "1868983", "url": "https://en.wikipedia.org/wiki?curid=1868983", "title": "Bromide", "text": "Bromide\n\nA bromide is a chemical compound containing a bromide ion or ligand. This is a bromine atom with an ionic charge of −1 (Br); for example, in caesium bromide, caesium cations (Cs) are electrically attracted to bromide anions (Br) to form the electrically neutral ionic compound CsBr. The term \"bromide\" can also refer to a bromine atom with an oxidation number of −1 in covalent compounds such as sulfur dibromide (SBr).\n\nBromide is present in typical seawater (35 PSU) with a concentration of around 65 mg/L, which is around 0.2% of all dissolved salts. Seafoods and deep sea plants generally have high levels of bromide, while foods derived from land have variable amounts. Bromargyryte - natural, crystalline silver bromide - is the most common bromide mineral currently known. It is still very rare. Beside silver, bromine is sometimes found in minerals combined with mercury and copper.\n\nOne can test for a bromide ion by adding excess dilute HNO followed by dilute aqueous AgNO solution. The formation of creamy silver bromide precipitate confirms the existence of bromides.\n\nBromide compounds, especially potassium bromide, were frequently used as sedatives in the 19th and early 20th century. Their use in over-the-counter sedatives and headache remedies (such as Bromo-Seltzer) in the United States extended to 1975, when bromides were withdrawn as ingredients, due to chronic toxicity.\n\nThis use gave the word \"bromide\" its colloquial connotation of a boring cliché, a bit of conventional wisdom overused as a calming phrase, or verbal sedative.\n\nThe bromide ion is antiepileptic, and bromide salts are still used as such, particularly in veterinary medicine. Bromide ion is excreted by the kidneys. The half-life of bromide in the human body (12 days) is long compared with many pharmaceuticals, making dosing difficult to adjust (a new dose may require several months to reach equilibrium). Bromide ion concentrations in the cerebrospinal fluid are about 30% of those in blood, and are strongly influenced by the body's chloride intake and metabolism.\n\nSince bromide is still used in veterinary medicine (particularly to treat seizures in dogs) in the United States, veterinary diagnostic labs can routinely measure blood bromide levels. However, this is not a conventional test in human medicine in the U.S., since there are no FDA-approved uses for bromide, and (as noted) it is no longer available in over-the-counter sedatives. Therapeutic bromide levels are measured in European countries like Germany, where bromide is still used therapeutically in human epilepsy.\n\nChronic toxicity from bromide can result in bromism, a syndrome with multiple neurological symptoms. Bromide toxicity can also cause a type of skin eruption. See potassium bromide.\n\nLithium bromide was used as a sedative beginning in the early 1900s, but it fell into disfavor in the 1940s, possibly due to the rising popularity of safer and more efficient sedatives (specifically, barbiturates) and when some heart patients died after using a salt substitute (see lithium chloride). Like lithium carbonate and lithium chloride it was used as treatment for bipolar disorder.\n\nIt has been said that during World War I, British soldiers were given bromide to curb their sexual urges, although this is not well supported by documentation, and has been disputed as an urban myth, as the sedative effects of bromide would have hampered military performance. Lord Dunsany mentions a soldier being given bromide as a sedative for nervous exhaustion and overwork in his play \"Fame and the Poet\" (1919).\n\nThere are more substantiated reports that bromide was used in the food served at some concentration camps during the Holocaust. This was apparently done in an effort to both chemically restrain the interned and prevent menstruation in women.\n\nAccording to one study, bromine (as bromide) is an essential cofactor in the peroxidasin catalysis of sulfilimine crosslinks in collagen IV. This post-translational modification occurs in all animals, and bromine is an essential trace element for humans.\n\nBromide is needed by eosinophils (white blood cells of the granulocyte class, specialized for dealing with multi-cellular parasites), which use it to generate antiparasitic brominating compounds such as hypobromite, by the action of eosinophil peroxidase, a haloperoxidase enzyme which is able to use chloride, but preferentially uses bromide when available. Other than its role in collagen IV production and its facultative use in eosinophils by the body, bromide is not known in other cases necessary for animal life, as its functions may generally be replaced (though in some cases not as well) by chloride. Land plants do not use bromide.\n\nBromide salts are also sometimes used in hot tubs and spas as mild germicidal agents, using the action of an added oxidizing agent to generate \"in situ\" hypobromite, in a similar fashion to the peroxidase in eosinophils.\n\nBromide is perhaps a minor necessary nutrient for collagen IV-producing animals in the sea. However, a few sea animals, such as \"Murex\" snails, use bromide to make organic compounds. Bromide ion is also heavily concentrated by some species of ocean algae, which construct methyl bromide and a great number of bromoorganic compounds with it, using the unusual enzymes called vanadium bromoperoxidases to do these reactions.\n\nThe average concentration of bromide in human blood in Queensland, Australia is and varies with age and gender. Much higher levels may indicate exposure to brominated chemicals (e.g. methyl bromide). However, since bromide occurs in relatively high concentration in seawater and many types of seafood, bromide concentrations in the blood are heavily influenced by seafood contributions to the diet.\n"}
{"id": "47750803", "url": "https://en.wikipedia.org/wiki?curid=47750803", "title": "CEFC China Energy", "text": "CEFC China Energy\n\nCEFC China Energy () is a private Chinese conglomerate. With revenue of 263 billion CNY (40 billion USD or 33 billion EUR) in 2014 the company is among the 10 largest private companies in China. In 2014 the company generated revenue mainly from oil and gas (60%) and financial services (25%), but operates also in a wide range of other sectors like transport infrastructure, forestry, asset management, hotel management, warehousing services, real estate development and logistics services. A large portion of CEFC's assets is concentrated in overseas markets. Since 2013 the company has been listed on the Fortune Global 500 list. It rose from a rank of 342 in 2015 to 229 in June 2016. Most of the company is owned by Shanghai Energy Fund Investment Ltd (SEFI), which is registered under Ye Jianming, the chairman of CEFC. Czech President Miloš Zeman has appointed CEFC's founder Ye Jianming as his economic adviser. The company is linked to the People's Liberation Army.\n\nIn May 2015, the company acquired a 5% stake in J&T Finance Group. This increased to 9.9% in September 2015. In 2017 company applied to acquire 50% J&T Finance Group, but the deal has been refused by Czech National Bank because of lack of sufficient information on the origin of most of the funding for the deal. \n\nIn September 2015, the company acquired multiple assets in the Czech Republic - a majority stake in brewery , a 10% stake in airline Travel Service, 60% in football club SK Slavia Prague and real-estate assets in Prague - the building of the former Živnostenská banka at Na příkopě street and at Hradčany. CEFC also bought a stake of between 50 and 90 per cent in Czech online travel agent Invia in March 2016, probably with a view to capitalising on the rapidly increasing numbers of Chinese tourists visiting Prague.\n\nIn 2017, CEFC bought a 14.16 % stake in Russia's largest oil producer Rosneft for about $9 billion.\n\nIn 2018, after its chairman Ye Jianming was detained for questioning on the order of Xi Jinping, General Secretary of the Communist Party of China. South China Morning Post reported that \", a portfolio and investment agency controlled by Shanghai’s municipal government, had taken control of CEFC China Energy\". The state controlled CITIC Group acquired 49% of CEFC Shanghai, a subsidiary of CEFC China Energy; in turn, CEFC Shanghai owns CEFC Europe. In April 2018, CEFC announced they may lay off half of its 30,000-strong staff; staff have not been paid for two months.\n\nIn May 2018, CITIC Group announced they will repay ca 450 million euros owed by CEFC Europe to finance and banking group J&T within days but since the debt has not been paid a week later, J&T announced it had taken over shareholder rights and installed crisis management at CEFC Europe. Several days later, CEFC Shanghai defaulted on $327 millions in bond payments, and offered to make the payments six months after the maturity date.\n"}
{"id": "611043", "url": "https://en.wikipedia.org/wiki?curid=611043", "title": "Chalk River Laboratories", "text": "Chalk River Laboratories\n\nChalk River Laboratories (; also known as CRL, Chalk River Labs and formerly Chalk River Nuclear Laboratories) is a Canadian nuclear research facility in Deep River, Renfrew County, Ontario, near Chalk River, about north-west of Ottawa.\n\nCRL is a site of major research and development to support and advance nuclear technology, in particular CANDU reactor technology. CRL has expertise in physics, metallurgy, chemistry, biology, and engineering and unique research facilities. For example, Bertram Brockhouse, a professor at McMaster University, received the 1994 Nobel Prize in Physics for his pioneering work in neutron spectroscopy while at CRL from 1950-1962. Sir John Cockcroft was an early director of CRL and also a Nobel laureate. CRL produces a large share of the world's supply of medical radioisotopes. It is owned by the Canadian Nuclear Laboratories subsidiary of Atomic Energy of Canada Limited and operated under contract by the Canadian National Energy Alliance, a private-sector consortium led by SNC-Lavalin.\n\n The facility arose out of a 1942 collaboration between British and Canadian nuclear researchers which saw a Montreal research laboratory established under the National Research Council (NRC). By 1944 the Chalk River Laboratories were opened and in September, 1945 the facility saw the first nuclear reactor outside of the United States become operational (see Lew Kowarski). In 1946, NRC closed the Montreal laboratory and focused its resources on Chalk River.\n\nIn 1952, Atomic Energy of Canada Limited (AECL) was created by the government to promote peaceful use of nuclear energy. AECL also took over operation of Chalk River from the NRC. Throughout the 1950s-2000s various nuclear research reactors have been operated by AECL for production of nuclear material for medical and scientific applications. The Laboratories produce about one-third of the world's medical isotopes, and about half of the North American supply. Despite the declaration of peaceful use, from 1955 to 1976, Chalk River facilities supplied about 250 kg of plutonium, in the form of spent reactor fuel, to the U.S. Department of Energy to be used in the production of nuclear weapons. (The bomb dropped on Nagasaki, Japan, used about 6.4 kg of plutonium.)\n\nCanada's first nuclear power plant, a partnership between AECL and Hydro-Electric Power Commission of Ontario, went online in 1962 near the site of Chalk River Laboratories. This reactor, Nuclear Power Demonstration (NPD), was a demonstration of the CANDU reactor design, one of the world's safest and most successful nuclear reactors.\n\nThe Deep River neutron monitor operated once in Chalk river.\n\nChalk River was also the site of two nuclear accidents in the 1950s. The first incident occurred in 1952, when there was a power excursion and partial loss of coolant in the NRX reactor, which resulted in significant damage to the core. The control rods could not be lowered into the core because of mechanical problems and human errors. Three rods did not reach their destination and were taken out again by accident. The fuel rods were overheated, resulting in a meltdown. The reactor and the reactor building were seriously damaged by hydrogen explosions. The seal of the reactor vessel was blown up four feet. In the cellar of the building, some 4,500 tons of radioactive water was found. This water was dumped in ditches around 1600 meters from the border of the Ottawa River. During this accident some 10,000 curies or 370 TBq of radioactive material was released. Future U.S. president Jimmy Carter, then a U.S. Navy officer, was part of the cleanup crew. Two years later the reactor was in use again.\n\nThe second accident, in 1958, involved a fuel rupture and fire in the National Research Universal reactor (NRU) reactor building. Some fuel rods were overheated. With a robotic crane, one of the rods with metallic uranium was pulled out of the reactor vessel. When the arm of the crane moved away from the vessel, the uranium caught fire and the rod broke. The largest part of the rod fell down into the containment vessel, still burning. The whole building was contaminated. The valves of the ventilation system were opened, and a large area outside the building was contaminated. The fire was extinguished by scientists and maintenance men in protective clothing running along the hole in the containment vessel with buckets of wet sand, throwing the sand down at the moment they passed the smoking entrance.\n\nBoth accidents required a major cleanup effort involving many civilian and military personnel. Follow-up health monitoring of these workers has not revealed any adverse impacts from the two accidents. However, the Canadian Coalition for Nuclear Responsibility, an anti-nuclear watchdog group, notes that some cleanup workers who were part of the military contingent assigned to the NRU reactor building unsuccessfully applied for a military disability pension due to health damages.\n\nChalk River Laboratories remain an AECL facility to this day and are used as both a research (in partnership with the NRC) and production facility (on behalf of AECL) in support of other Canadian electrical utilities.\n\nOn November 18, 2007, the NRU, which makes medical radioisotopes, was shut down for routine maintenance. This shutdown was extended when AECL, in consultation with the Canadian Nuclear Safety Commission (CNSC), decided to connect seismically-qualified emergency power supplies (EPS) to two of the reactor's cooling pumps (in addition to the AC and DC backup power systems already in place), which had been required as part of its August 2006 operating licence issued by the CNSC. This resulted in a worldwide shortage of radioisotopes for medical treatments because Chalk River makes the majority of the world's supply of medical radioisotopes, including two-thirds of the world's technetium-99m.\n\nOn December 11, 2007, the House of Commons of Canada, acting on independent expert advice, passed emergency legislation authorizing the restarting of the NRU reactor and its operation for 120 days (counter to the decision of the CNSC), which was passed by the Senate and received Royal Assent on December 12. Prime Minister Stephen Harper criticized the CNSC for this shutdown which \"jeopardized the health and safety of tens of thousands of Canadians\", insisting that there was no risk, contrary to the testimony of then CNSC President & CEO Linda Keen. She would later be fired for ignoring a decision by Parliament to restart the reactor, reflecting its policy that the safety of citizens requiring essential nuclear medicine should be taken into account in assessing the overall safety concerns of the reactor's operation.\nThe NRU reactor was restarted on December 16, 2007.\n\nOn December 5, 2008, heavy water containing tritium leaked from the NRU. The leaked water was contained within the facility, and the Canadian Nuclear Safety Commission (CNSC) was notified immediately, as required.\n\nIn its formal report to the CNSC, filed on December 9, 2008 (when the volume of leakage was determined to meet the requirement for such a report) AECL mentioned that 47 litres of heavy water were released from the reactor, about 10% of which evaporated and the rest contained, but affirmed that the spill was not serious and did not present a threat to public health. The amount that evaporated to the atmosphere is considered to be minor, accounting for less than a thousandth of the regulatory limit. The public was informed of the shutdown at the reactor, but not the details of the leakage since it was not deemed to pose a risk to the public or environment. The leak stopped before the source could be identified, and the reactor was restarted on December 11, 2008 with the approval of the CNSC, after a strategy for dealing with the leak (should it reappear) was put in place.\n\nIn an unrelated incident, the same reactor had been leaking 7,001 litres of light water per day from a crack in a weld of the reactor's reflector system. This water has been systematically collected, purified in an on-site Waste Treatment Centre, and eventually released to the Ottawa River in accordance with CNSC, Health Canada, and Ministry of the Environment regulations. Although the leakage is not a concern to the CNSC from a health, safety or environmental perspective, AECL has plans for a repair to reduce the current leakage rate for operational reasons.\n\nIn mid-May 2009 the heavy water leak at the base of the NRU reactor vessel, first detected in 2008 (see above), returned at a greater rate and prompted another temporary shutdown that lasted until August 2010. The lengthy shutdown was necessary to first completely defuel the entire reactor, then ascertain the full extent of the corrosion to the vessel, and finally to effect the repairs — all with remote and restricted access from a minimum distance of 8 metres due to the residual radioactive fields in the reactor vessel. The 2009 shutdown occurred at a time when only one of the other four worldwide regular medical isotope sourcing reactors was producing, resulting in a worldwide shortage. \n\nThe NRU reactor licence expired in 2016, however the licence was extended to March 31 2018. The reactor went was shut down for the last time at 7 p.m. on 31 March 2018 and has entered a \"state of storage\" prior to decommissioning operations which will continue for many years within the scope of future operating and/or decommissioning licences issued by the CNSC.\n\n\n\n\n"}
{"id": "34212384", "url": "https://en.wikipedia.org/wiki?curid=34212384", "title": "Chicago and Southern Flight 4", "text": "Chicago and Southern Flight 4\n\nChicago and Southern Air Lines Flight 4 was a regularly scheduled flight from New Orleans, Louisiana to Chicago, Illinois, via Jackson, Mississippi, Memphis, Tennessee, and St. Louis, Missouri, operated with a Lockheed Model 10 Electra. On August 5, 1936, after departing from Lambert-St. Louis International Airport, the flight crashed in a farm field near the Missouri River. All 6 passengers and 2 crew members were killed in the crash.\n\nThe Lockheed Electra was on a flight from New Orleans to Chicago. After having left New Orleans at 5:30 PM, it proceeded normally to Jackson, Memphis and St. Louis. It departed St. Louis at 10PM, and was scheduled to arrive in Chicago at 12:55 AM.\n\nThe aircraft departed St. Louis and proceeded on a northerly track towards the Missouri River. Five minutes after departure, all radio contact was lost with the aircraft. Chicago and Southern’s company radio controller made repeated attempts to contact the flight, and then notified the Chicago station, informing them of the missing aircraft.\n\nFarmers in the vicinity of the aircraft’s last radio contact were contacted, and began a search for the aircraft, believing an accident had occurred. Within several hours the aircraft was located, in a farm field near the Missouri River. Seven of the plane’s eight occupants were found within 50 feet of the wreckage; the remaining passenger was found still in the cabin. All of the victims showed signs of massive impact trauma, and were believed to have been killed instantly.\n\nThe weather in the area had been reported as clear, except for in the vicinity of the river, where heavy ground fog was present. Preliminary reports believed the ground fog to have been a factor.\n\nUpon examination of the wreckage, it was found that the plane had, for unknown reasons, been in a low turn near the ground, and the wingtip made contact with the terrain, causing the aircraft to impact the ground. The reason for the low-altitude turn was unknown.\n\n"}
{"id": "41121217", "url": "https://en.wikipedia.org/wiki?curid=41121217", "title": "Cryoneurolysis", "text": "Cryoneurolysis\n\nCryoneurolysis, also referred to as cryoanalgesia, is a medical procedure that temporarily blocks nerve conduction along peripheral nerve pathways. The procedure, which inserts a small probe to freeze the target nerve, can facilitate complete regeneration of the structure and function of the affected nerve. Cryoneurolysis has been used to treat a variety of painful conditions.\n\nA similar procedure that uses radiofrequency energy for back pain appears to have short term benefit, but it is unclear if it has a long term effect.\n\nEach nerve is composed of a bundle of axons. Each axon is surrounded by the endoneurium connective tissue layer. These axons are bundled into fascicles surrounded by the perineurium connective tissue layer. Multiple fascicles are then surrounded by the epineurium, which is the outermost connective tissue layer of the nerve. The axons of myelinated nerves have a myelin sheath made up of Schwann cells that coat the axon.\n\nClassification of nerve damage was well-defined by Sir Herbert Seddon and Sunderland in a system that remains in use. The adjacent table details the forms (neurapraxia, axonotmesis and neurotmesis) and degrees of nerve injury that occur as a result of exposure to various temperatures.\n\nCryoneurolysis treatments that use nitrous oxide (boiling point of -88.5 °C) as the coolant fall in the range of an axonotmesis injury, or 2nd degree injury, according to the Sunderland classification system. Treatments of the nerve in this temperature range are reversible. Nerves treated in this temperature range experience a disruption of the axon, with Wallerian degeneration occurring distal to the site of injury. The axon and myelin sheath are affected, but all of the connective tissues (endoneurium, perineurium, and epineurium) remain intact. Following Wallerian degeneration, the axon regenerates along the original nerve path at a rate of approximately 1–2 mm per day.\n\nCryoneurolysis differs from cryoablation in that cryoablation treatments utilize liquid nitrogen (boiling point of -195.8 °C) as the coolant, and therefore, fall into the range of a neurotmesis injury, or 3rd degree injury according to the Sunderland classification. Treatments of the nerve in this temperature range are irreversible. Nerves treated in this temperature range experience a disruption of both the axon and the endoneurium connective tissue layer.\n\nThe use of cold for pain relief and as an anti-inflammatory has been known since the time of Hippocrates (460-377 B.C). Since then there have been numerous accounts of ice used for pain relief including from the Ancient Egyptians and Avicenna of Persia (A.D.982–1070). In 1812 Napoleon's Surgeon General noted that half-frozen soldiers from the Moscow battle were able to tolerate amputations with reduced pain and in 1851, ice and salt mixtures were promoted by Arnott for the treatment of nerve pain. Campbell White, in 1899, was the first to use refrigerants medically, and Allington, in 1950, was the first to use liquid nitrogen for medical treatments. In 1961, Cooper et al. created an early cryoprobe that reached -190 °C using liquid nitrogen. Shortly thereafter, in 1967, an ophthalmic surgeon named Amoils used carbon dioxide and nitrous oxide to create a cryoprobe that reached -70 °C.\n\nCryoneurolysis is performed with a cryoprobe, which is composed of a hollow cannula that contains a smaller inner lumen. The pressurized coolant (nitrous oxide, carbon dioxide or liquid nitrogen) travels down the lumen and expands at the end of the lumen into the tip of the hollow cannula. No coolant exits the cryoprobe. The expansion of the pressurized liquid causes the surrounding area to cool (known as the Joule-Thomson effect) and the phase change of the liquid to gas also causes the surrounding area to cool. This causes a visible iceball to form and the tissue surrounding the end of the cryoprobe to freeze. The gas form of the coolant then travels up the length of the cryoprobe and is safely expelled. The tissue surrounding the end of the cryoprobe can reach as low as -88.5 °C with nitrous oxide as the coolant, and as low as -195.8 °C with liquid nitrogen. Temperatures below -100 °C are damaging to nerves.\n\nThe Endocare PerCryo Percutaneous Cryoablation device utilizes argon as a coolant and can be used with 4 different single cryoprobe configurations with a diameter of either 1.7 mm (~16 gauge) or 2.4 mm (~13 gauge) in diameter .\n\nThe Myoscience Iovera° is a handheld device that uses nitrous oxide as a coolant and can be used with a three-probe configuration with a probe diameter of 0.4 mm (~27 gauge).\n"}
{"id": "18758722", "url": "https://en.wikipedia.org/wiki?curid=18758722", "title": "Diesel rotary uninterruptible power supply", "text": "Diesel rotary uninterruptible power supply\n\nMost forms of uninterruptible power supply (UPS) can be either powered by battery or flywheel energy. These are ready for immediate use at the instant that the mains electricity fails, but the small amount of stored energy they contain makes them suitable for a few seconds or minutes of use only. To get uninterruptible and continuous power supply, a diesel-generator back-up system is needed.\n\nDiesel rotary uninterruptible power supply devices (DRUPS) combine the functionality of a battery-powered or flywheel-powered UPS and a diesel generator. When mains electricity supply is within specification, an electrical generator with a mass functions as motor to store kinetic energy in an electro-mechanical flywheel. In combination with a reactor or choke coil, the electrical generator also works as active filter for all sorts of power quality problems, like harmonics, RFI, and frequency variations. When mains electricity supply fails, stored energy in the flywheel is released to drive the electrical generator, which continues to supply power without interruption. At the same time (or with some delay, for example 2 to 11 seconds, to prevent the diesel engine from starting at every incident), the diesel engine takes over from the flywheel to drive the electrical generator to make the electricity required. The electro-magnetic flywheel can continue to support the diesel generator in order to keep a stable output frequency. Typically a DRUPS will have enough fuel to power the load for days or even weeks in the event of failure of the mains electricity supply.\n\nThe main advantages of DRUPS equipment compared to battery-powered UPS combined with a diesel-generator are the higher overall system energy efficiency, smaller footprint, use of fewer components, longer technical lifetime (no use of power electronics) and the fact it does not result in chemical waste (no use of batteries).\n\nThe main disadvantages of DRUPS equipment are a more frequent maintenance regimen due to the number of moving parts. DRUPS are also typically installed in external buildings due to noise concerns from the generators.\n\nA DRUPS can provide a ride-through time of 15–40 seconds. A flywheel UPS can be installed ahead of typical UPS battery systems to reduce the effects of lightning & switching transients and to increase battery life.\n\nSpot network substation\n\nImproving Process Control Immunity To Supply Voltage Sags In Petroleum And Chemical Industries \n"}
{"id": "11422325", "url": "https://en.wikipedia.org/wiki?curid=11422325", "title": "Discovery! The Search for Arabian Oil", "text": "Discovery! The Search for Arabian Oil\n\nDiscovery! The Search for Arabian Oil is a non-fiction book written by Pulitzer Prize winning American author Wallace Stegner.\n\nWritten by Stegner in the late 1950s the book was originally serialized in fourteen parts in the magazine Saudi Aramco World in 1970-71 and later published in Beirut Lebanon in 1971 in a limited press run. In 2005 Selwa Press asked Aramco for permission to license this work and present it as an illustrated, fully annotated edition that was released in hardcover in September 2007, the first time it was published in the US.\n\nIn late 2007 Selwa's right to publish the book under Stegner's name was questioned by the author's former agent, as well as by Stegner's son and by a biographer.\n\nThe book outlines the history of Aramco and the story of the first discoveries of oil in the Persian Gulf region and Saudi Arabia. Stegner wrote a detailed history of the first contacts between representatives from the American oil company Casoc (or Socal) and King Abdul Aziz Ibn Saud of Saudi Arabia and his concessions to the company to search for oil in the kingdom in the 1930s.\n\nThe book outlines the beginnings of the discovery of oil in the Persian Gulf during the 1930s by oil companies from around the world. The exploration for oil took place during the depression of the 1930s and companies in the US and other countries were hesitant to spend resources looking for oil. During the 1930s the Persian Gulf, aside from Saudi Arabia, was primarily controlled by the British military and British companies operating in public interest.\n\nThe 1930s Kingdom of Abdul Aziz Ibn Saud was a conservative country skeptical of outsiders and the homeland of Islam's main pilgrimige sites and holy cities of Mecca and Medina.\n\nThe King was also interested in oil exploration though and made concessions to several companies, allowing them to explore for oil in the Kingdom. Discovery! outlines how American oil officials agreed to share profits with the King, train employees, build roads and towns, and eventually turn Aramco into a Saudi run and owned company in return for revenue and exclusive oil rights.\n\nFollowing several negotiations outlined in Stegner's book and especially with the help of ex-English intelligence officer and Muslim convert St. John Philby the American company and the Saudi King agreed to partner.\n\nStegner's book details the lives of some of the American families who were part of this oil exploration and the unique set of circumstances that they faced living in Saudi Arabia as well as the effect that these families and employees had on the native population of Saudi Arabia.\n\nHe also outlines the beginnings of a relationship between US business and the Kingdom of Saudi Arabia from the 1930s through the end of World War II.\n\nThe first manuscript was written by Stegner in 1956 and was submitted to Aramco shortly thereafter. According to Discovery!'s new introduction officials at the company were hesitant to publish the manuscript due to the political situation in the Middle East with the nationalization of the Suez canal and the pan-Arabism of Gamal Abdel Nasser of Egypt. The manuscript remained unpublished until a company editor found it in 1967.\n\nStegner and Aramco compromised on the contents of the book and it began being published in serial form in Saudi Aramco World magazine in 1970. Stegner's hesitations on writing a public relations campaign for a company were included in the book as well as some of his critiques.\n\nThe book was released worldwide in September 2007 with additional annotations, a bibliography, an introduction by author and journalist Thomas Lippman and unreleased photographs.\n\nQuestions have arisen over Selwa Press' legal right to publish the book with Stegner's name attached. The dispute centers over whether a 1958 contract between the author and Aramco required Stegner's approval before his name could be used. Publisher Tim Barger said that Stegner had given that approval when the book was serialized in an Aramco magazine in the 1960s. The author also approved an Aramco-published book in 1971. But the author's former agent, Carl Brandt, who represents Stegner's estate, called the book \"a bowdlerized version of what Wally wrote,\" and Stegner's son Page said that material critical of Aramco or considered offensive to the company's Saudi partners was removed. Stegner biographer Philip Fradkin said that Stegner was paid for his work and had accordingly permitted an Aramco-published version but did not want that version published as a trade book.\n\nStegner's original draft now resides at the University of Utah. Barger said that Aramco would never agree to the publication of Stegner's original draft.\n\n"}
{"id": "1673318", "url": "https://en.wikipedia.org/wiki?curid=1673318", "title": "Docosahexaenoic acid", "text": "Docosahexaenoic acid\n\nDocosahexaenoic acid (DHA) is an omega-3 fatty acid that is a primary structural component of the human brain, cerebral cortex, skin, and retina. In physiological literature, it is given the name 22:6(n-3). It can be synthesized from alpha-linolenic acid or obtained directly from maternal milk (breast milk), fish oil, or algae oil.\n\nDHA's structure is a carboxylic acid (-\"oic acid\") with a 22-carbon chain (\"docosa-\" derives from the Ancient Greek for 22) and six (\"hexa-\") \"cis\" double bonds (\"-en-\"); with the first double bond located at the third carbon from the omega end. Its trivial name is cervonic acid, its systematic name is \"all-cis\"-docosa-4,7,10,13,16,19-hexa-enoic acid, and its shorthand name is 22:6(n−3) in the nomenclature of fatty acids.\n\nMost of the DHA in fish and multi-cellular organisms with access to cold-water oceanic foods originates from photosynthetic and heterotrophic microalgae, and becomes increasingly concentrated in organisms the further they are up the food chain. DHA is also commercially manufactured from microalgae: \"Crypthecodinium cohnii\" and another of the genus \"Schizochytrium\". DHA manufactured using microalgae is vegetarian.\n\nIn strict herbivores, DHA is manufactured internally from α-linolenic acid, a shorter omega-3 fatty acid manufactured by plants (and also occurring in animal products as obtained from plants), while omnivores and carnivores primarily obtain DHA from their diet. Limited amounts of eicosapentaenoic and docosapentaenoic acids are possible products of α-linolenic acid metabolism in young women and men. DHA in breast milk is important for the developing infant. Rates of DHA production in women are 15% higher than in men.\n\nDHA is a major fatty acid in brain phospholipids and the retina. While the potential roles of DHA in the mechanisms of Alzheimer's disease are under active research, studies of fish oil supplements, which contain DHA, have failed to support claims of preventing cardiovascular diseases.\n\nDHA is the most abundant omega-3 fatty acid in the brain and retina. DHA comprises 40% of the polyunsaturated fatty acids (PUFAs) in the brain and 60% of the PUFAs in the retina. Five percent of the weight of a neuron's plasma membrane is composed of DHA.\n\nDHA modulates the carrier-mediated transport of choline, glycine, and taurine, the function of delayed rectifier potassium channels, and the response of rhodopsin contained in the synaptic vesicles, among many other functions.\n\nDHA deficiency is associated with cognitive decline. Phosphatidylserine (PS) controls apoptosis, and low DHA levels lower neural cell PS and increase neural cell death.\nDHA levels are reduced in the brain tissue of severely depressed patients.\n\nIn humans, DHA is either obtained from the diet or may be converted in small amounts from eicosapentaenoic acid (EPA, 20:5, ω-3) via docosapentaenoic acid (DPA, 22:5 ω-3) as an intermediate. This synthesis had been thought to occur through an elongation step followed by the action of Δ4-desaturase. It is now considered more likely that DHA is biosynthesized via a C24 intermediate followed by beta oxidation in peroxisomes. Thus, EPA is twice elongated, yielding 24:5 ω-3, then desaturated to 24:6 ω-3, then shortened to DHA (22:6 ω-3) via beta oxidation. This pathway is known as \"Sprecher's shunt\".\n\nIn organisms such as microalgae, mosses and fungi, biosynthesis of DHA usually occurs as a series of desaturation and elongation reactions, catalyzed by the sequential action of desaturase and elongase enzymes. One known pathway in these organisms involves:\n\nDHA can be metabolized into DHA-derived specialized pro-resolving mediators (SPMs), DHA epoxides, electrophilic oxo-derivatives (EFOX) of DHA, neuroprostanes, ethanolamines, acylglycerols, docosahexaenoyl amides of amino acids or neurotransmitters, and branched DHA esters of hydroxy fatty acids, among others.\n\nThe enzyme CYP2C9 metabolizes DHA to epoxydocosapentaenoic acids (EDPs; primarily 19,20-epoxy-eicosapentaenoic acid isomers [i.e. 10,11-EDPs]).\n\nWhile one human trial of 402 subjects lasting 18 months concluded that DHA did not slow decline of mental function in elderly people with mild to moderate Alzheimer's disease, a similar trial of 485 subjects lasting 6 months concluded that algal DHA of 900 mg per day taken decreased heart rate and improved memory and learning in healthy, older adults with mild memory complaints.\n\nIn another early-stage study, higher DHA levels in middle-aged adults was related to better performance on tests of nonverbal reasoning and mental flexibility, working memory, and vocabulary.\n\nOne study found that the use of DHA-rich fish oil capsules did not reduce postpartum depression in mothers or improve cognitive and language development in their offspring during early childhood. Another systematic review found that DHA had no significant benefits in improving visual field in individuals with retinitis pigmentosa. A 2017 pilot study found that fish oil supplementation reduced the depression symptoms emphasizing the importance of the target DHA levels.\n\nIt has been recommended to eat foods which are high in omega-3 fatty acids for women who want to become pregnant or when nursing. A working group from the International Society for the Study of Fatty Acids and Lipids recommended 300 mg/day of DHA for pregnant and lactating women, whereas the average consumption was between 45 mg and 115 mg per day of the women in the study, similar to a Canadian study. Despite these recommendations, recent evidence from a trial of pregnant women randomized to receive supplementation with 800 mg/day of DHA versus placebo, showed that the supplement had no impact on the cognitive abilities of their children at up to seven years follow-up.\n\nBrain function and vision rely on dietary intake of DHA to support a broad range of cell membrane properties, particularly in grey matter, which is rich in membranes. A major structural component of the mammalian brain, DHA is the most abundant omega−3 fatty acid in the brain. It is under study as a candidate essential nutrient with roles in neurodevelopment, cognition, and neurodegenerative disorders.\n\nIn one preliminary study, men who took DHA supplements for 6–12 weeks had lower blood markers of inflammation.\n\nOrdinary types of cooked salmon contain 500–1500 mg DHA and 300–1000 mg EPA per 100 grams. Additional rich seafood sources of DHA include caviar (3400 mg per 100 grams), anchovies (1292 mg per 100 grams), mackerel (1195 mg per 100 grams), and cooked herring (1105 mg per 100 grams). Brains from mammals are also a good direct source, with beef brain, for example, containing approximately 855 mg of DHA per 100 grams in a serving.\n\nIn the early 1980s, NASA sponsored scientific research on a plant-based food source that could generate oxygen and nutrition on long-duration space flights. Certain species of marine algae produced rich nutrients, leading to the development of an algae-based, vegetable-like oil that contains two polyunsaturated fatty acids, DHA and arachidonic acid.\n\nDHA is widely used as a food supplement. It was first used primarily in infant formulas. In 2004, the US Food and Drug Administration endorsed qualified health claims for DHA.\n\nSome manufactured DHA is a vegetarian product extracted from algae, and it competes on the market with fish oil that contains DHA and other omega-3s such as EPA. Both fish oil and DHA are odorless and tasteless after processing as a food additive.\n\nVegetarian diets typically contain limited amounts of DHA, and vegan diets typically contain no DHA. In preliminary research, algae-based supplements increased DHA levels. While there is little evidence of adverse health or cognitive effects due to DHA deficiency in adult vegetarians or vegans, breast milk levels remain a concern for supplying adequate DHA to the developing fetus.\n\nFish oil is widely sold in capsules containing a mixture of omega-3 fatty acids, including EPA and DHA. Oxidized fish oil in supplement capsules may contain lower levels of EPA and DHA.\n\nAn abundance of DHA in seafood has been suggested as being helpful in the development of a large brain, though other researchers claim a terrestrial diet could also have provided the necessary DHA.\n\n\n"}
{"id": "198984", "url": "https://en.wikipedia.org/wiki?curid=198984", "title": "Electrical conductor", "text": "Electrical conductor\n\nIn physics and electrical engineering, a conductor is an object or type of material that allows the flow of an electrical current in one or more directions. Materials made of metal are common electrical conductors. Electrical current is generated by the flow of negatively charged electrons, positively charged holes, and positive or negative ions in some cases. \n\nIn order for current to flow, it is not necessary for one charged particle to travel from the machine producing the current to that consuming it. Instead, the charged particle simply needs to nudge its neighbor a finite amount who will nudge its neighbor and on and on until a particle is nudged into the consumer, thus powering the machine. Essentially what is occurring here is a long chain of momentum transfer between mobile charge carriers; the Drude model of conduction describes this process more rigorously. This momentum transfer model makes metal an ideal choice for a conductor as metals, characteristically, possess a delocalized sea of electrons which gives the electrons enough mobility to collide and thus effect a momentum transfer. \n\nAs discussed above, electrons are the primary mover in metals; however, other devices such as the cationic electrolyte(s) of a battery, or the mobile protons of the proton conductor of a fuel cell rely on positive charge carriers. Insulators are non-conducting materials with few mobile charges that support only insignificant electric currents.\n\nThe resistance of a given conductor depends on the material it is made of, and on its dimensions. For a given material, the resistance is inversely proportional to the cross-sectional area. For example, a thick copper wire has lower resistance than an otherwise-identical thin copper wire. Also, for a given material, the resistance is proportional to the length; for example, a long copper wire has higher resistance than an otherwise-identical short copper wire. The resistance and conductance of a conductor of uniform cross section, therefore, can be computed as\n\nwhere formula_2 is the length of the conductor, measured in metres [m], \"A\" is the cross-section area of the conductor measured in square metres [m²], σ (sigma) is the electrical conductivity measured in siemens per meter (S·m), and ρ (rho) is the electrical resistivity (also called \"specific electrical resistance\") of the material, measured in ohm-metres (Ω·m). The resistivity and conductivity are proportionality constants, and therefore depend only on the material the wire is made of, not the geometry of the wire. Resistivity and conductivity are reciprocals: formula_3. Resistivity is a measure of the material's ability to oppose electric current.\n\nThis formula is not exact: It assumes the current density is totally uniform in the conductor, which is not always true in practical situations. However, this formula still provides a good approximation for long thin conductors such as wires.\n\nAnother situation this formula is not exact for is with alternating current (AC), because the skin effect inhibits current flow near the center of the conductor. Then, the \"geometrical\" cross-section is different from the \"effective\" cross-section in which current actually flows, so the resistance is higher than expected. Similarly, if two conductors are near each other carrying AC current, their resistances increase due to the proximity effect. At commercial power frequency, these effects are significant for large conductors carrying large currents, such as busbars in an electrical substation, or large power cables carrying more than a few hundred amperes.\n\nAside from the geometry of the wire, temperature also has a significant effect on the efficacy of conductors. Temperature affects conductors in two main ways, the first is that materials may expand under the application of heat. The amount that the material will expand is governed by the thermal expansion coefficient specific to the material. Such an expansion (or contraction) will change the geometry of the conductor and therefore its characteristic resistance. However, this effect is generally small, on the order of 10. An increase in temperature will also increase the number of phonons generated within the material. A phonon is essentially a lattice vibration, or rather a small, harmonic kinetic movement of the atoms of the material. Much like the shaking of a pinball machine, phonons serve to disrupt the path of electrons, causing them to scatter. This electron scattering will decrease the number of electron collisions and therefore will decrease the total amount of current transferred.\n\nConduction materials include metals, electrolytes, superconductors, semiconductors, plasmas and some nonmetallic conductors such as graphite and Conductive polymers.\n\nCopper has a high conductivity. Annealed copper is the international standard to which all other electrical conductors are compared; the International Annealed Copper Standard conductivity is , although ultra-pure copper can slightly exceed 101% IACS. The main grade of copper used for electrical applications, such as building wire, motor windings, cables and busbars, is electrolytic-tough pitch (ETP) copper (CW004A or ASTM designation C100140). If high conductivity copper must be welded or brazed or used in a reducing atmosphere, then oxygen-free high conductivity copper (CW008A or ASTM designation C10100) may be used. Because of its ease of connection by soldering or clamping, copper is still the most common choice for most light-gauge wires.\n\nSilver is 6% more conductive than copper, but due to cost it is not practical in most cases. However, it is used in specialized equipment, such as satellites, and as a thin plating to mitigate skin effect losses at high frequencies. Famously, of silver on loan from the Treasury were used in the making of the calutron magnets during World War II due to wartime shortages of copper.\n\nAluminum wire is the most common metal in electric power transmission and distribution. Although only 61% of the conductivity of copper by cross-sectional area, its lower density makes it twice as conductive by mass. As aluminum is roughly one-third the cost of copper by weight, the economic advantages are considerable when large conductors are required.\n\nThe disadvantages of aluminum wiring lie in its mechanical and chemical properties. It readily forms an insulating oxide, making connections heat up. Its larger coefficient of thermal expansion than the brass materials used for connectors causes connections to loosen. Aluminum can also \"creep\", slowly deforming under load, which also loosens connections. These effects can be mitigated with suitably designed connectors and extra care in installation, but they have made aluminum building wiring unpopular past the service drop.\n\nOrganic compounds such as octane, which has 8 carbon atoms and 18 hydrogen atoms, cannot conduct electricity. Oils are hydrocarbons, since carbon has the property of tetracovalency and forms covalent bonds with other elements such as hydrogen, since it does not lose or gain electrons, thus does not form ions. Covalent bonds are simply the sharing of electrons. Hence, there is no separation of ions when electricity is passed through it. So the liquid (oil or any organic compound) cannot conduct electricity.\n\nWhile pure water is not an electrical conductor, even a small portion of ionic impurities, such as salt, can rapidly transform it into a conductor.\n\nWires are measured by their cross sectional area. In many countries, the size is expressed in square millimetres. In North America, conductors are measured by American wire gauge for smaller ones, and circular mils for larger ones. The size of a wire contributes to its ampacity. The American wire gauge article contains a table showing allowable ampacities for a variety of copper wire sizes.\n\nThe ampacity of a conductor, that is, the amount of current it can carry, is related to its electrical resistance: a lower-resistance conductor can carry a larger value of current. The resistance, in turn, is determined by the material the conductor is made from (as described above) and the conductor's size. For a given material, conductors with a larger cross-sectional area have less resistance than conductors with a smaller cross-sectional area.\n\nFor bare conductors, the ultimate limit is the point at which power lost to resistance causes the conductor to melt. Aside from fuses, most conductors in the real world are operated far below this limit, however. For example, household wiring is usually insulated with PVC insulation that is only rated to operate to about 60 °C, therefore, the current in such wires must be limited so that it never heats the copper conductor above 60 °C, causing a risk of fire. Other, more expensive insulation such as Teflon or fiberglass may allow operation at much higher temperatures.\n\nIf an electric field is applied to a material, and the resulting induced electric current is in the same direction, the material is said to be an \"isotropic electrical conductor\". If the resulting electric current is in a different direction from the applied electric field, the material is said to be an \"anisotropic electrical conductor\".\n\n\n\n\n"}
{"id": "27593510", "url": "https://en.wikipedia.org/wiki?curid=27593510", "title": "Elektrische Viktoria", "text": "Elektrische Viktoria\n\nThe Elektrische Viktoria was an electric car built in several versions by Siemens between 1905 and 1909 in Berlin. The versions comprised a four-seat convertible (advertised and used as a hotel taxi), a minibus with a box-like structure (much like a pickup), and a van.\n\nTop speed was 30 km/h (19 mi/h). The electric motor operated at a nominal potential of 88 volts and a maximum current of 40 amperes. The maximum power was 3.520 kW (about 4.8 HP). The cruising range was 60 km with the smaller battery version and 80 km with the larger battery version.\n\nThe car was built in the Berlin-based factory Siemens-Schuckertwerke, a Siemens subsidiary. The total number of units built is not known, but, according to Siemens internal records, probably between 30 and 50 were produced. The price was steep by 1905 standards, at 11000 to 17500 Marks, depending on the model and battery capacity. At the time, a worker's monthly wages were in the range of 120 to 150 Marks.\n\nRegenerative braking was added during development, i.e., while braking the electric motor's operation was reversed, turning it into an electric generator charging the battery, such that the available kinetic energy could be turned into extended cruising range.\n\nIn 2010 Siemens built a full-scale replica, based on partial sketches and three photographic images. Only the battery was modified for environmental reasons, avoiding the original lead based battery technology. The lighting was modernized in order to receive official approval for operation on public roads. Siemens rebuilt the city car type B \"Electrical Viktoria open\". The weight is 1530 kg, to which the battery alone contributes 480 kg. Fully charging the battery takes between five and a half to six hours on 220 volt mains. The car was approved on April 8, 2010 and presented to the public in Berlin on April 30.\n\nOn June 21, 2010, the replica was involved an accident in the environs of Hinterzarten, a resort village in the Black Forest, when the car suddenly veered off the road and into an embankment at full speed. The driver and leader of the replica project, Wilfried Feldenkirchen, a professor of economic history, was killed, when he was ejected from the car. Four accompanying students were injured, two seriously.\n\n"}
{"id": "6266718", "url": "https://en.wikipedia.org/wiki?curid=6266718", "title": "Energy slave", "text": "Energy slave\n\nAn energy slave is that quantity of energy (ability to do work) which, when used to construct and drive non-human infrastructure (machines, roads, power grids, fuel, draft animals, wind-driven pumps, etc.) replaces a unit of human labor (actual work). An energy slave does the work of a person, through the consumption of energy in the non-human infrastructure.\n\nThe term was first used by R. Buckminster Fuller in the caption of an illustration for the cover of the February 1940 issue of Fortune Magazine, entitled \"World Energy\". Alfred Ubbelohde also coined the term, apparently independently, in his 1955 book, \"Man and Energy\", but the term did not come to be widely used until the 1960s, and is generally credited to Fuller.\n\nAn energy slave is used to compare the productivity of a person and the energy that would be required to produce that work in the modern, oil fuelled industrial economy, although it could be applied anywhere that labor is produced with non-human sourced energy. It does not include the ancillary costs of damage to the environment or social structures. Formally, one energy slave produces one unit of human labor through the non-human tools and energy supplied by the industrial economy, and therefore 1 ES times a constant that converts to work accomplished = 1 human labor unit.\n\n"}
{"id": "32879224", "url": "https://en.wikipedia.org/wiki?curid=32879224", "title": "Hjartdøla Hydroelectric Power Station", "text": "Hjartdøla Hydroelectric Power Station\n\nThe Hjartdøla Power Station is a hydroelectric power station located in Hjartdal, Telemark, Norway. It operates at an installed capacity of , with an average annual production of about .\n"}
{"id": "1384354", "url": "https://en.wikipedia.org/wiki?curid=1384354", "title": "Hydrotropism", "text": "Hydrotropism\n\nHydrotropism (hydro- \"water\"; tropism \"involuntary orientation by an organism, that involves turning or curving as a positive or negative response to a stimulus\") is a plant's growth response in which the direction of growth is determined by a stimulus or gradient in water concentration. A common example is a plant root growing in humid air bending toward a higher relative humidity level.\n\nThis is of biological significance as it helps to increase efficiency of the plant in its ecosystem.\n\nThe process of hydrotropism is started by the root cap sensing water and sending a signal to the elongating part of the root. Hydrotropism is difficult to observe in underground roots, since the roots are not readily observable, and root gravitropism is usually more influential than root hydrotropism. Water readily moves in soil and soil water content is constantly changing so any gradients in soil moisture are not stable.\n\nRoot hydrotropism research has mainly been a laboratory phenomenon for roots grown in humid air rather than soil. Its ecological significance in soil-grown roots is unclear because so little hydrotropism research has examined soil-grown roots. Recent identification of a mutant plant that lacks a hydrotropic response may help to elucidate its role in nature. Hydrotropism may have importance for plants grown in space, where it may allow roots to orient themselves in a microgravity environment.\n\nA class of plant hormones called auxins coordinates this root growth process. Auxins play a key role in bending the plants root towards the water because they cause one side of the root to grow faster than the other and thus the bending of the root. The Auxins are also important to plant life because they help search for water.\n\n"}
{"id": "29273607", "url": "https://en.wikipedia.org/wiki?curid=29273607", "title": "Journey to the End of Coal", "text": "Journey to the End of Coal\n\nJourney to the End of Coal is a French web documentary directed by Samuel Bollendorff and Abel Segretin.\n\nBased on the \"choose your own adventure\" principle, the interactive documentary tells the story of millions of Chinese coal miners who are risking their lives to satisfy their country’s appetite for economic growth.\n\n\"Journey to the End of Coal\" won the Prix SCAM 2009 digital interactive artwork award \".\n\n\n\n"}
{"id": "38082743", "url": "https://en.wikipedia.org/wiki?curid=38082743", "title": "Laminated fabric", "text": "Laminated fabric\n\nA illuminati fabric is a two (or more) layer construction with a polymer film bonded to a fabric. Laminated fabrics are used in rainwear, automotive, and other applications.\n"}
{"id": "59399", "url": "https://en.wikipedia.org/wiki?curid=59399", "title": "Lumber", "text": "Lumber\n\nLumber (American English; used only in North America) or timber (used in the rest of the English-speaking world) is a type of wood that has been processed into beams and planks, a stage in the process of wood production. Lumber is mainly used for structural purposes but has many other uses as well.\n\nThere are two main types of lumber. It may be supplied either rough-sawn, or surfaced on one or more of its faces. Besides pulpwood, \"rough lumber\" is the raw material for furniture-making and other items requiring additional cutting and shaping. It is available in many species, usually hardwoods; but it is also readily available in softwoods, such as white pine and red pine, because of their low cost.\n\n\"Finished lumber\" is supplied in standard sizes, mostly for the construction industry – primarily softwood, from coniferous species, including pine, fir and spruce (collectively spruce-pine-fir), cedar, and hemlock, but also some hardwood, for high-grade flooring. It is more commonly made from softwood than hardwoods, and 80% of lumber comes from softwood.\n\nIn the United States milled boards of wood are referred to as \"lumber\". However, in Britain and other Commonwealth nations, the term \"timber\" is instead used to describe sawn wood products, like floor boards.\n\nIn the United States and Canada, generally \"timber\" describes standing or felled trees. Specifically in Canada, \"lumber\" describes cut and surfaced wood.\n\nIn the United Kingdom, the word \"lumber\" is rarely used in relation to wood and has several other meanings, including unused or unwanted items. Referring to wood, \"Timber\" is almost universally used instead.\n\nRemanufactured lumber is the result of secondary or tertiary processing/cutting of previously milled lumber. Specifically, it is lumber cut for industrial or wood-packaging use. Lumber is cut by ripsaw or resaw to create dimensions that are not usually processed by a primary sawmill.\n\nResawing is the splitting of 1-inch through 12-inch hardwood or softwood lumber into two or more thinner pieces of full-length boards. For example, splitting a ten-foot 2×4 into two ten-foot 1×4s is considered resawing.\n\nStructural lumber may also be produced from recycled plastic and new plastic stock. Its introduction has been strongly opposed by the forestry industry. Blending fiberglass in plastic lumber enhances its strength, durability, and fire resistance. Plastic fiberglass structural lumber can have a \"class 1 flame spread rating of 25 or less, when tested in accordance with ASTM standard E 84,\" which means it burns slower than almost all treated wood lumber.\n\nLogs are \"converted\" into timber by being sawn, hewn, or split. Sawing with a rip saw is the most common method, because sawing allows logs of lower quality, with irregular grain and large knots, to be used and is more economical. There are various types of sawing:\n\nDimensional lumber is lumber that is cut to standardized width and depth, specified in inches. Carpenters extensively use dimensional lumber in framing wooden buildings. Common sizes include \"2×4\" (pictured) (also \"two-by-four\" and other variants, such as \"four-by-two\" in Australia, New Zealand, and the UK), \"2×6\", and \"4×4\". The length of a board is usually specified separately from the width and depth. It is thus possible to find 2×4s that are four, eight, and twelve feet in length. In Canada and the United States, the standard lengths of lumber are 6, 8, 10, 12, 14, 16, 18, 20, 22 and 24 feet (1.83, 2.44, 3.05, 3.66, 4.27, 4.88, 5.49, 6.10, 6.71 and 7.32 meters). For wall framing, \"stud\" or \"precut\" sizes are available, and are commonly used. For an eight-, nine-, or ten-foot ceiling height, studs are available in , , and . The term \"stud\" is used inconsistently to specify length; where the exact length matters, one must specify the length explicitly.\n\nUnder the prescription of the Method of Construction (營造法式) issued by the Southern Song government in the early 12th century, timbers were standardized to eight cross-sectional dimensions. Regardless of the actual dimensions of the timber, the ratio between width and height was maintained at 1:1.5. Units are in Song Dynasty inches (3.12 cm).\nTimber smaller than the 8th class were called \"unclassed\" (等外). The width of a timber is referred to as one \"timber\" (材), and the dimensions of other structural components were quoted in multiples of \"timber\"; thus, as the width of the actual timber varied, the dimensions of other components were easily calculated, without resorting to specific figures for each scale. The dimensions of timbers in similar application show a gradual diminution from the Sui Dyansty (580~618) to the modern era; a 1st class timber during the Sui was reconstructed as 15×10 (Sui Dynasty inches, or 2.94 cm).\n\nThe length of a unit of dimensional lumber is limited by the height and girth of the tree it is milled from. In general the maximum length is . Engineered wood products, manufactured by binding the strands, particles, fibers, or veneers of wood, together with adhesives, to form composite materials, offer more flexibility and greater structural strength than typical wood building materials.\n\nPre-cut studs save a framer much time, because they are pre-cut by the manufacturer for use in 8-, 9-, and 10-ft (2.44, 2.74 and 3.05 m) ceiling applications, which means the manufacturer has removed a few inches or centimetres of the piece to allow for the sill plate and the double top plate with no additional sizing necessary.\n\nIn the Americas, \"two-bys\" (2×4s, 2×6s, 2×8s, 2×10s, and 2×12s), named for traditional board thickness in inches, along with the 4×4 (), are common lumber sizes used in modern construction. They are the basic building blocks for such common structures as balloon-frame or platform-frame housing. Dimensional lumber made from softwood is typically used for construction, while hardwood boards are more commonly used for making cabinets or furniture.\n\nLumber's \"nominal\" dimensions are larger than the actual standard dimensions of finished lumber. Historically, the nominal dimensions were the size of the green (not dried), rough (unfinished) boards that eventually became smaller finished lumber through drying and planing (to smooth the wood). Today, the standards specify the final finished dimensions and the mill cuts the logs to whatever size it needs to achieve those final dimensions. Typically, that rough cut is smaller than the nominal dimensions because modern technology makes it possible and it uses the logs more efficiently. For example, a \"2×4\" board historically started out as a green, rough board actually . After drying and planing, it would be smaller, by a nonstandard amount. Today, a \"2×4\" board starts out as something smaller than 2 inches by 4 inches and not specified by standards, and after drying and planing is reliably .\n\nEarly standards called for green rough lumber to be of full nominal dimension when dry. However, the dimensions have diminished over time. In 1910, a typical finished board was . In 1928, that was reduced by 4%, and yet again by 4% in 1956. In 1961, at a meeting in Scottsdale, Arizona, the Committee on Grade Simplification and Standardization agreed to what is now the current U.S. standard: in part, the dressed size of a 1-inch (nominal) board was fixed at  inch; while the dressed size of 2 inch (nominal) lumber was \"reduced\" from  inch to the current  inch.\n\nDimensional lumber is available in green, unfinished state, and for that kind of lumber, the nominal dimensions are the actual dimensions.\n\nIndividual pieces of lumber exhibit a wide range in quality and appearance with respect to knots, slope of grain, shakes and other natural characteristics. Therefore, they vary considerably in strength, utility, and value.\n\nThe move to set national standards for lumber in the United States began with publication of the American Lumber Standard in 1924, which set specifications for lumber dimensions, grade, and moisture content; it also developed inspection and accreditation programs. These standards have changed over the years to meet the changing needs of manufacturers and distributors, with the goal of keeping lumber competitive with other construction products. Current standards are set by the American Lumber Standard Committee, appointed by the U.S. Secretary of Commerce.\n\nDesign values for most species and grades of visually graded structural products are determined in accordance with ASTM standards, which consider the effect of strength reducing characteristics, load duration, safety and other influencing factors. The applicable standards are based on results of tests conducted in cooperation with the USDA Forest Products Laboratory. Design Values for Wood Construction, which is a supplement to the ANSI/AF&PA National Design Specification® for Wood Construction, provides these lumber design values, which are recognized by the model building codes.\n\nCanada has grading rules that maintain a standard among mills manufacturing similar woods to assure customers of uniform quality. Grades standardize the quality of lumber at different levels and are based on moisture content, size, and manufacture at the time of grading, shipping, and unloading by the buyer. The National Lumber Grades Authority (NLGA) is responsible for writing, interpreting and maintaining Canadian lumber grading rules and standards. The Canadian Lumber Standards Accreditation Board (CLSAB) monitors the quality of Canada's lumber grading and identification system.\n\nAttempts to maintain lumber quality over time have been challenged by historical changes in the timber resources of the United States – from the slow-growing virgin forests common over a century ago to the fast-growing plantations now common in today's commercial forests. Resulting declines in lumber quality have been of concern to both the lumber industry and consumers and have caused increased use of alternative construction products.\n\nMachine stress-rated and machine-evaluated lumber is readily available for end-uses where high strength is critical, such as trusses, rafters, laminating stock, I-beams and web joints. Machine grading measures a characteristic such as stiffness or density that correlates with the structural properties of interest, such as bending strength. The result is a more precise understanding of the strength of each piece of lumber than is possible with visually graded lumber, which allows designers to use full-design strength and avoid overbuilding.\n\nIn Europe, strength grading of rectangular sawn timber (both softwood and hardwood) is done according to EN-14081 and commonly sorted into classes defined by EN-338. For softwoods the common classes are (in increasing strength) C16, C18, C24 and C30. There are also classes specifically for hardwoods and those in most common use (in increasing strength) are D24, D30, D40, D50, D60 and D70. For these classes, the number refers to the required 5th percentile bending strength in Newtons per square millimetre. There are other strength classes, including T-classes based on tension intended for use in glulam.\n\nGrading rules for African and South American sawn timber have been developed by ATIBT according to the rules of the Sciages Avivés Tropicaux Africains (SATA) and is based on clear cuttings – established by the percentage of the clear surface.\n\nIn North America, market practices for dimensional lumber made from hardwoods varies significantly from the regularized \"standardized 'dimension lumber' sizes\" used for sales and specification of softwoods – hardwood boards are often sold totally rough cut, or machine planed only on the two (broader) face sides. When Hardwood Boards are also supplied with planed faces, it is usually both by random widths of a specified thickness (normally matching milling of softwood dimensional lumbers) and somewhat random lengths. But besides those older (traditional and normal) situations, in recent years some product lines have been widened to also market boards in standard stock sizes; these usually retail in big-box stores and using only a relatively small set of specified lengths; in all cases hardwoods are sold to the consumer by the board-foot (), whereas that measure is not used for softwoods at the retailer (to the cognizance of the buyer).\n\nAlso in North America, hardwood lumber is commonly sold in a \"quarter\" system, when referring to thickness; 4/4 (four quarter) refers to a board, 8/4 (eight quarter) is a board, etc. This \"quarter\" system is rarely used for softwood lumber; although softwood decking is sometimes sold as 5/4, even though it is actually one-inch thick (from milling 1/8th inch off each side in a motorized planing step of production).\nThe \"quarter\" system of reference is a traditional (cultural) North American lumber industry nomenclature used specifically to indicate the thickness of rough sawn hardwood lumber.\n\nThe following paragraph is exactly backwards from North American cultural practices where finished retail and rough lumber share the same terminology, as is discussed in the paragraph after about 'architects, designers, and builders':\nIn rough sawn lumber it immediately clarifies that the lumber is not yet milled, avoiding confusion with milled dimension lumber which is measured as actual thickness after machining. Examples – 3/4\", 19mm, or 1x.\nIn recent years architects, designers, and builders have begun to use the \"quarter\" system in specifications as a vogue of insider knowledge, though the materials being specified are finished lumber, thus conflating the separate systems and causing confusion.\n\nHardwoods cut for furniture are cut in the fall and winter, after the sap has stopped running in the trees. If hardwoods are cut in the spring or summer the sap ruins the natural color of the timber and decreases the value of the timber for furniture.\n\nEngineered lumber is lumber created by a manufacturer and designed for a certain structural purpose. The main categories of engineered lumber are:\n\n\nIn the United States, pilings are mainly cut from southern yellow pines and Douglas firs. Treated pilings are available in Chromated copper arsenate retentions of 0.60, 0.80 and 2.50 pounds per cubic foot (, and ) if treatment is required.\n\nDefects occurring in lumber are grouped into the following four divisions:\n\nDuring the process of converting timber to commercial form the following defects may occur:\n\nFungi attack timber when these conditions are all present:\n\nWood with less than 25% moisture (dry weight basis) can remain free of decay for centuries. Similarly, wood submerged in water may not be attacked by fungi if the amount of oxygen is inadequate.\n\nFungi timber defects:\n\nFollowing are the insects and molluscs which are usually responsible for the decay of timber:\n\nThere are two main natural forces responsible for causing defects in timber: abnormal growth and rupture of tissues. Rupture of tissue includes cracks or splits in the wood called \"shakes\". \"Ring shake\", \"wind shake\", or \"ring failure\" is when the wood grain separates around the growth rings either while standing or during felling. Shakes may reduce the strength of a timber and the appearance thus reduce lumber grade and may capture moisture, promoting decay. Eastern hemlock is known for having ring shake. A \"check\" is a crack on the surface of the wood caused by the outside of a timber shrinking as it seasons. Checks may extend to the pith and follow the grain. Like shakes, checks can hold water promoting rot. A \"split\" goes all the way through a timber. Checks and splits occur more frequently at the ends of lumber because of the more rapid drying in these locations.\n\nThe seasoning of lumber is typically either kiln- or air-dried. Defects due to seasoning are the main cause of splits, bowing and honeycombing.\n\nUnder proper conditions, wood provides excellent, lasting performance. However, it also faces several potential threats to service life, including fungal activity and insect damage – which can be avoided in numerous ways. Section 2304.11 of the International Building Code addresses protection against decay and termites. This section provides requirements for non-residential construction applications, such as wood used above ground (e.g., for framing, decks, stairs, etc.), as well as other applications.\n\nThere are four recommended methods to protect wood-frame structures against durability hazards and thus provide maximum service life for the building. All require proper design and construction:\n\nWood is a hygroscopic material, which means it naturally absorbs and releases water to balance its internal moisture content with the surrounding environment. The moisture content of wood is measured by the weight of water as a percentage of the oven-dry weight of the wood fiber. The key to controlling decay is controlling moisture. Once decay fungi are established, the minimum moisture content for decay to propagate is 22 to 24 percent, so building experts recommend 19 percent as the maximum safe moisture content for untreated wood in service. Water by itself does not harm the wood, but rather, wood with consistently high moisture content enables fungal organisms to grow.\n\nThe primary objective when addressing moisture loads is to keep water from entering the building envelope in the first place, and to balance the moisture content within the building itself. Moisture control by means of accepted design and construction details is a simple and practical method of protecting a wood-frame building against decay. For applications with a high risk of staying wet, designers specify durable materials such as naturally decay-resistant species or wood that has been treated with preservatives. Cladding, shingles, sill plates and exposed timbers or glulam beams are examples of potential applications for treated wood.\n\nFor buildings in termite zones, basic protection practices addressed in current building codes include (but are not limited to) the following:\n\n• Grading the building site away from the foundation to provide proper drainage\n\n• Covering exposed ground in any crawl spaces with 6-mil polyethylene film and maintaining at least of clearance between the ground and the bottom of framing members above (12 inches to beams or girders, 18 inches to joists or plank flooring members)\n\n• Supporting post columns by concrete piers so that there is at least of clear space between the wood and exposed earth\n\n• Installing wood framing and sheathing in exterior walls at least eight inches above exposed earth; locating siding at least six inches from the finished grade\n\n• Where appropriate, ventilating crawl spaces according to local building codes\n\n• Removing building material scraps from the job site before backfilling.\n\n• If allowed by local regulation, treating the soil around the foundation with an approved termiticide to provide protection against subterranean termites\n\nTo avoid decay and termite infestation, untreated wood is separated from the ground and other sources of moisture. These separations are required by many building codes and are considered necessary to maintain wood elements in permanent structures at a safe moisture content for decay protection. When it is not possible to separate wood from the sources of moisture, designers often rely on preservative-treated wood.\n\nWood can be treated with a preservative that improves service life under severe conditions without altering its basic characteristics. It can also be pressure-impregnated with fire-retardant chemicals that improve its performance in a fire. One of the early treatments to \"fireproof lumber\", which retard fires, was developed in 1936 by the Protexol Corporation, in which lumber is heavily treated with salt.\nWood does not deteriorate simply because it gets wet. When wood breaks down, it is because an organism is eating it. Preservatives work by making the food source inedible to these organisms. Properly preservative-treated wood can have 5 to 10 times the service life of untreated wood. Preserved wood is used most often for railroad ties, utility poles, marine piles, decks, fences and other outdoor applications. Various treatment methods and types of chemicals are available, depending on the attributes required in the particular application and the level of protection needed.\n\nThere are two basic methods of treating: with and without pressure. Non-pressure methods are the application of preservative by brushing, spraying or dipping the piece to be treated. Deeper, more thorough penetration is achieved by driving the preservative into the wood cells with pressure. Various combinations of pressure and vacuum are used to force adequate levels of chemical into the wood. Pressure-treating preservatives consist of chemicals carried in a solvent.\nChromated copper arsenate, once the most commonly used wood preservative in North America began being phased out of most residential applications in 2004. Replacing it are amine copper quat and copper azole.\n\nAll wood preservatives used in the United States and Canada are registered and regularly re-examined for safety by the U.S. Environmental Protection Agency and Health Canada's Pest Management and Regulatory Agency, respectively.\n\nTimber was used as a dominant building material in most of the ancient temples of Kerala and coastal Karnataka of India.\n\n\"Timber framing\" is a style of construction which uses heavier framing elements than modern stick framing, which uses dimensional lumber. The timbers originally were tree boles squared with a broadaxe or adze and joined together with joinery without nails. Modern timber framing has been growing in popularity in the United States since the 1970s.\n\nGreen building minimizes the impact or \"environmental footprint\" of a building. Wood is a major building material that is renewable and replenishable in a continuous cycle. Studies show manufacturing wood uses less energy and results in less air and water pollution than steel and concrete. However, demand for lumber is blamed for deforestation.\n\nThe conversion from coal to biomass power is a growing trend in the United States.\n\nThe United Kingdom, Uzbekistan, Kazakhstan, Australia, Fiji, Madagascar, Mongolia, Russia, Denmark, Switzerland and Swaziland governments all support an increased role for energy derived from biomass, which are organic materials available on a renewable basis and include residues and/or byproducts of the logging, sawmilling and papermaking processes. In particular, they view it as a way to lower greenhouse gas emissions by reducing consumption of oil and gas while supporting the growth of forestry, agriculture and rural economies. Studies by the U.S. government have found the country’s combined forest and agriculture land resources have the power to sustainably supply more than one-third of its current petroleum consumption.\n\nBiomass is already an important source of energy for the North American forest products industry. It is common for companies to have cogeneration facilities, also known as combined heat and power, which convert some of the biomass that results from wood and paper manufacturing to electrical and thermal energy in the form of steam. The electricity is used to, among other things, dry lumber and supply heat to the dryers used in paper-making.\n\n"}
{"id": "6151568", "url": "https://en.wikipedia.org/wiki?curid=6151568", "title": "Mason's mitre", "text": "Mason's mitre\n\nA mason's mitre is a type of mitre joint, traditionally used in stonework or masonry but commonly seen in kitchen countertops. In a mason's mitre, the two elements being joined meet as for a butt joint but a small section of one member is removed creating a socket to receive the end of the other. A small mitre is made at the inside edges of the socket and on the end of the intersecting member so that edge treatments are carried through the joint appropriately.\n\nThe mason's mitre allows the appearance of a mitre joint to be created with much less waste than occurs with a common mitre joint, in which triangular sections must be removed from the ends of both joint members.\n\nThe terms \"back mitre\" and \"mason's mitre\" (or \"miter\") are often used interchangeably, but are different types of joints, and used for different purposes. Both joints are traditionally used in stone or woodwork. Neither joint requires that one part be coped (or fit) over the other. In the back mitre, the joints follow the mitre and stile/rail joining lines. In the mason's mitre, the intersecting mouldings are carved within a single stone block or the woodwork's stile, with the rail or adjacent block having a straight profile.\n\nA protective trim for mitre cut kitchen worktops has been patented and created by Pepr products. The product is similar to aluminium trims for straight worktop joints, but shaped to fit mitre cut corner worktops. \n"}
{"id": "19727", "url": "https://en.wikipedia.org/wiki?curid=19727", "title": "Michael Faraday", "text": "Michael Faraday\n\nMichael Faraday FRS (; 22 September 1791 – 25 August 1867) was a British scientist who contributed to the study of electromagnetism and electrochemistry. His main discoveries include the principles underlying electromagnetic induction, diamagnetism and electrolysis.\n\nAlthough Faraday received little formal education, he was one of the most influential scientists in history. It was by his research on the magnetic field around a conductor carrying a direct current that Faraday established the basis for the concept of the electromagnetic field in physics. Faraday also established that magnetism could affect rays of light and that there was an underlying relationship between the two phenomena. He similarly discovered the principles of electromagnetic induction and diamagnetism, and the laws of electrolysis. His inventions of electromagnetic rotary devices formed the foundation of electric motor technology, and it was largely due to his efforts that electricity became practical for use in technology.\n\nAs a chemist, Faraday discovered benzene, investigated the clathrate hydrate of chlorine, invented an early form of the Bunsen burner and the system of oxidation numbers, and popularised terminology such as \"anode\", \"cathode\", \"electrode\" and \"ion\". Faraday ultimately became the first and foremost Fullerian Professor of Chemistry at the Royal Institution, a lifetime position.\n\nFaraday was an excellent experimentalist who conveyed his ideas in clear and simple language; his mathematical abilities, however, did not extend as far as trigonometry and were limited to the simplest algebra. James Clerk Maxwell took the work of Faraday and others and summarized it in a set of equations which is accepted as the basis of all modern theories of electromagnetic phenomena. On Faraday's uses of lines of force, Maxwell wrote that they show Faraday \"to have been in reality a mathematician of a very high order – one from whom the mathematicians of the future may derive valuable and fertile methods.\" The SI unit of capacitance is named in his honour: the farad.\n\nAlbert Einstein kept a picture of Faraday on his study wall, alongside pictures of Isaac Newton and James Clerk Maxwell. Physicist Ernest Rutherford stated, \"When we consider the magnitude and extent of his discoveries and their influence on the progress of science and of industry, there is no honour too great to pay to the memory of Faraday, one of the greatest scientific discoverers of all time.\"\n\nMichael Faraday was born on 22 September 1791 in Newington Butts, which is now part of the London Borough of Southwark but was then a suburban part of Surrey. His family was not well off. His father, James, was a member of the Glassite sect of Christianity. James Faraday moved his wife and two children to London during the winter of 1790 from Outhgill in Westmorland, where he had been an apprentice to the village blacksmith. Michael was born in the autumn of that year. The young Michael Faraday, who was the third of four children, having only the most basic school education, had to educate himself.\n\nAt the age of 14 he became an apprentice to George Riebau, a local bookbinder and bookseller in Blandford Street. During his seven-year apprenticeship Faraday read many books, including Isaac Watts's \"The Improvement of the Mind\", and he enthusiastically implemented the principles and suggestions contained therein. He also developed an interest in science, especially in electricity. Faraday was particularly inspired by the book \"Conversations on Chemistry\" by Jane Marcet.\n\nIn 1812, at the age of 20 and at the end of his apprenticeship, Faraday attended lectures by the eminent English chemist Humphry Davy of the Royal Institution and the Royal Society, and John Tatum, founder of the City Philosophical Society. Many of the tickets for these lectures were given to Faraday by William Dance, who was one of the founders of the Royal Philharmonic Society. Faraday subsequently sent Davy a 300-page book based on notes that he had taken during these lectures. Davy's reply was immediate, kind, and favourable. In 1813, when Davy damaged his eyesight in an accident with nitrogen trichloride, he decided to employ Faraday as an assistant. Coincidentally one of the Royal Institution's assistants, John Payne, was sacked and Sir Humphry Davy had been asked to find a replacement; thus he appointed Faraday as Chemical Assistant at the Royal Institution on 1 March 1813. Very soon Davy entrusted Faraday with the preparation of nitrogen trichloride samples, and they both were injured in an explosion of this very sensitive substance.\nIn the class-based English society of the time, Faraday was not considered a gentleman. When Davy set out on a long tour of the continent in 1813–15, his valet did not wish to go, so instead, Faraday went as Davy's scientific assistant and was asked to act as Davy's valet until a replacement could be found in Paris. Faraday was forced to fill the role of valet as well as assistant throughout the trip. Davy's wife, Jane Apreece, refused to treat Faraday as an equal (making him travel outside the coach, eat with the servants, etc.), and made Faraday so miserable that he contemplated returning to England alone and giving up science altogether. The trip did, however, give him access to the scientific elite of Europe and exposed him to a host of stimulating ideas.\n\nFaraday married Sarah Barnard (1800–1879) on 12 June 1821. They met through their families at the Sandemanian church, and he confessed his faith to the Sandemanian congregation the month after they were married. They had no children.\n\nFaraday was a devout Christian; his Sandemanian denomination was an offshoot of the Church of Scotland. Well after his marriage, he served as deacon and for two terms as an elder in the meeting house of his youth. His church was located at Paul's Alley in the Barbican. This meeting house relocated in 1862 to Barnsbury Grove, Islington; this North London location was where Faraday served the final two years of his second term as elder prior to his resignation from that post. Biographers have noted that \"a strong sense of the unity of God and nature pervaded Faraday's life and work.\"\n\nIn June 1832, the University of Oxford granted Faraday a Doctor of Civil Law degree (honorary). During his lifetime, he was offered a knighthood in recognition for his services to science, which he turned down on religious grounds, believing that it was against the word of the Bible to accumulate riches and pursue worldly reward, and stating that he preferred to remain \"plain Mr Faraday to the end\". Elected a member of the Royal Society in 1824, he twice refused to become President. He became the first Fullerian Professor of Chemistry at the Royal Institution in 1833.\n\nIn 1832, Faraday was elected a Foreign Honorary Member of the American Academy of Arts and Sciences. He was elected a foreign member of the Royal Swedish Academy of Sciences in 1838, and was one of eight foreign members elected to the French Academy of Sciences in 1844. In 1849 he was elected as associated member to the Royal Institute of the Netherlands, which two years later became the Royal Netherlands Academy of Arts and Sciences and he was subsequently made foreign member.\n\nFaraday suffered a nervous breakdown in 1839 but eventually returned to his investigations into electromagnetism. In 1848, as a result of representations by the Prince Consort, Faraday was awarded a grace and favour house in Hampton Court in Middlesex, free of all expenses and upkeep. This was the Master Mason's House, later called Faraday House, and now No. 37 Hampton Court Road. In 1858 Faraday retired to live there.\n\nHaving provided a number of various service projects for the British government, when asked by the government to advise on the production of chemical weapons for use in the Crimean War (1853–1856), Faraday refused to participate citing ethical reasons.\n\nFaraday died at his house at Hampton Court on 25 August 1867, aged 75. He had some years before turned down an offer of burial in Westminster Abbey upon his death, but he has a memorial plaque there, near Isaac Newton's tomb. Faraday was interred in the dissenters' (non-Anglican) section of Highgate Cemetery.\n\nFaraday's earliest chemical work was as an assistant to Humphry Davy. Faraday was specifically involved in the study of chlorine; he discovered two new compounds of chlorine and carbon. He also conducted the first rough experiments on the diffusion of gases, a phenomenon that was first pointed out by John Dalton. The physical importance of this phenomenon was more fully revealed by Thomas Graham and Joseph Loschmidt. Faraday succeeded in liquefying several gases, investigated the alloys of steel, and produced several new kinds of glass intended for optical purposes. A specimen of one of these heavy glasses subsequently became historically important; when the glass was placed in a magnetic field Faraday determined the rotation of the plane of polarisation of light. This specimen was also the first substance found to be repelled by the poles of a magnet.\n\nFaraday invented an early form of what was to become the Bunsen burner, which is in practical use in science laboratories around the world as a convenient source of heat.\nFaraday worked extensively in the field of chemistry, discovering chemical substances such as benzene (which he called bicarburet of hydrogen) and liquefying gases such as chlorine. The liquefying of gases helped to establish that gases are the vapours of liquids possessing a very low boiling point and gave a more solid basis to the concept of molecular aggregation. In 1820 Faraday reported the first synthesis of compounds made from carbon and chlorine, CCl and CCl, and published his results the following year. Faraday also determined the composition of the chlorine clathrate hydrate, which had been discovered by Humphry Davy in 1810. Faraday is also responsible for discovering the laws of electrolysis, and for popularizing terminology such as anode, cathode, electrode, and ion, terms proposed in large part by William Whewell.\n\nFaraday was the first to report what later came to be called metallic nanoparticles. In 1847 he discovered that the optical properties of gold colloids differed from those of the corresponding bulk metal. This was probably the first reported observation of the effects of quantum size, and might be considered to be the birth of nanoscience.\n\nFaraday is best known for his work regarding electricity and magnetism. His first recorded experiment was the construction of a voltaic pile with seven ha'penny coins, stacked together with seven disks of sheet zinc, and six pieces of paper moistened with salt water. With this pile he decomposed sulfate of magnesia (first letter to Abbott, 12 July 1812).\n\nIn 1821, soon after the Danish physicist and chemist Hans Christian Ørsted discovered the phenomenon of electromagnetism, Davy and British scientist William Hyde Wollaston tried, but failed, to design an electric motor. Faraday, having discussed the problem with the two men, went on to build two devices to produce what he called \"electromagnetic rotation\". One of these, now known as the homopolar motor, caused a continuous circular motion that was engendered by the circular magnetic force around a wire that extended into a pool of mercury wherein was placed a magnet; the wire would then rotate around the magnet if supplied with current from a chemical battery. These experiments and inventions formed the foundation of modern electromagnetic technology. In his excitement, Faraday published results without acknowledging his work with either Wollaston or Davy. The resulting controversy within the Royal Society strained his mentor relationship with Davy and may well have contributed to Faraday's assignment to other activities, which consequently prevented his involvement in electromagnetic research for several years.\n\nFrom his initial discovery in 1821, Faraday continued his laboratory work, exploring electromagnetic properties of materials and developing requisite experience. In 1824, Faraday briefly set up a circuit to study whether a magnetic field could regulate the flow of a current in an adjacent wire, but he found no such relationship. This experiment followed similar work conducted with light and magnets three years earlier that yielded identical results. During the next seven years, Faraday spent much of his time perfecting his recipe for optical quality (heavy) glass, borosilicate of lead, which he used in his future studies connecting light with magnetism. In his spare time, Faraday continued publishing his experimental work on optics and electromagnetism; he conducted correspondence with scientists whom he had met on his journeys across Europe with Davy, and who were also working on electromagnetism. Two years after the death of Davy, in 1831, he began his great series of experiments in which he discovered electromagnetic induction, recording in his laboratory diary on 28 October 1831 he was; \"making many experiments with the great magnet of the Royal Society\".\n\nFaraday's breakthrough came when he wrapped two insulated coils of wire around an iron ring, and found that upon passing a current through one coil a momentary current was induced in the other coil. This phenomenon is now known as mutual induction. The iron ring-coil apparatus is still on display at the Royal Institution. In subsequent experiments, he found that if he moved a magnet through a loop of wire an electric current flowed in that wire. The current also flowed if the loop was moved over a stationary magnet. His demonstrations established that a changing magnetic field produces an electric field; this relation was modelled mathematically by James Clerk Maxwell as Faraday's law, which subsequently became one of the four Maxwell equations, and which have in turn evolved into the generalization known today as field theory. Faraday would later use the principles he had discovered to construct the electric dynamo, the ancestor of modern power generators and the electric motor.\n\nIn 1832, he completed a series of experiments aimed at investigating the fundamental nature of electricity; Faraday used \"static\", batteries, and \"animal electricity\" to produce the phenomena of electrostatic attraction, electrolysis, magnetism, etc. He concluded that, contrary to the scientific opinion of the time, the divisions between the various \"kinds\" of electricity were illusory. Faraday instead proposed that only a single \"electricity\" exists, and the changing values of quantity and intensity (current and voltage) would produce different groups of phenomena.\n\nNear the end of his career, Faraday proposed that electromagnetic forces extended into the empty space around the conductor. This idea was rejected by his fellow scientists, and Faraday did not live to see the eventual acceptance of his proposition by the scientific community. Faraday's concept of lines of flux emanating from charged bodies and magnets provided a way to visualize electric and magnetic fields; that conceptual model was crucial for the successful development of the electromechanical devices that dominated engineering and industry for the remainder of the 19th century.\n\nIn 1845, Faraday discovered that many materials exhibit a weak repulsion from a magnetic field: a phenomenon he termed diamagnetism.\n\nFaraday also discovered that the plane of polarization of linearly polarized light can be rotated by the application of an external magnetic field aligned with the direction in which the light is moving. This is now termed the Faraday effect. In Sept 1845 he wrote in his notebook, \"I have at last succeeded in \"illuminating a magnetic curve\" or \"line of force\" and in \"magnetising a ray of light\"\".\n\nLater on in his life, in 1862, Faraday used a spectroscope to search for a different alteration of light, the change of spectral lines by an applied magnetic field. The equipment available to him was, however, insufficient for a definite determination of spectral change. Pieter Zeeman later used an improved apparatus to study the same phenomenon, publishing his results in 1897 and receiving the 1902 Nobel Prize in Physics for his success. In both his 1897 paper and his Nobel acceptance speech, Zeeman made reference to Faraday's work.\n\nIn his work on static electricity, Faraday's ice pail experiment demonstrated that the charge resided only on the exterior of a charged conductor, and exterior charge had no influence on anything enclosed within a conductor. This is because the exterior charges redistribute such that the interior fields emanating from them cancel one another. This shielding effect is used in what is now known as a Faraday cage.\n\nFaraday had a long association with the Royal Institution of Great Britain. He was appointed Assistant Superintendent of the House of the Royal Institution in 1821. He was elected a member of the Royal Society in 1824. In 1825, he became Director of the Laboratory of the Royal Institution. Six years later, in 1833, Faraday became the first Fullerian Professor of Chemistry at the Royal Institution of Great Britain, a position to which he was appointed for life without the obligation to deliver lectures. His sponsor and mentor was John 'Mad Jack' Fuller, who created the position at the Royal Institution for Faraday.\n\nBeyond his scientific research into areas such as chemistry, electricity, and magnetism at the Royal Institution, Faraday undertook numerous, and often time-consuming, service projects for private enterprise and the British government. This work included investigations of explosions in coal mines, being an expert witness in court, and along with two engineers from Chance Brothers c.1853, the preparation of high-quality optical glass, which was required by Chance for its lighthouses. In 1846, together with Charles Lyell, he produced a lengthy and detailed report on a serious explosion in the colliery at Haswell, County Durham, which killed 95 miners. Their report was a meticulous forensic investigation and indicated that coal dust contributed to the severity of the explosion. The report should have warned coal owners of the hazard of coal dust explosions, but the risk was ignored for over 60 years until the Senghenydd Colliery Disaster of 1913.\n\nAs a respected scientist in a nation with strong maritime interests, Faraday spent extensive amounts of time on projects such as the construction and operation of lighthouses and protecting the bottoms of ships from corrosion. His workshop still stands at Trinity Buoy Wharf above the Chain and Buoy Store, next to London's only lighthouse where he carried out the first experiments in electric lighting for lighthouses.\n\nFaraday was also active in what would now be called environmental science, or engineering. He investigated industrial pollution at Swansea and was consulted on air pollution at the Royal Mint. In July 1855, Faraday wrote a letter to \"The Times\" on the subject of the foul condition of the River Thames, which resulted in an often-reprinted cartoon in \"Punch\". (See also The Great Stink).\n\nFaraday assisted with the planning and judging of exhibits for the Great Exhibition of 1851 in London. He also advised the National Gallery on the cleaning and protection of its art collection, and served on the National Gallery Site Commission in 1857.\n\nEducation was another of Faraday's areas of service; he lectured on the topic in 1854 at the Royal Institution, and in 1862 he appeared before a Public Schools Commission to give his views on education in Great Britain. Faraday also weighed in negatively on the public's fascination with table-turning, mesmerism, and seances, and in so doing chastised both the public and the nation's educational system.\nBefore his famous Christmas lectures, Faraday delivered chemistry lectures for the City Philosophical Society from 1816 to 1818 in order to refine the quality of his lectures. Between 1827 and 1860 at the Royal Institution in London, Faraday gave a series of nineteen Christmas lectures for young people, a series which continues today. The objective of Faraday's Christmas lectures was to present science to the general public in the hopes of inspiring them and generating revenue for the Royal Institution. They were notable events on the social calendar among London's gentry. Over the course of several letters to his close friend Benjamin Abbott, Faraday outlined his recommendations on the art of lecturing: Faraday wrote \"a flame should be lighted at the commencement and kept alive with unremitting splendour to the end\". His lectures were joyful and juvenile, he delighted in filling soap bubbles with various gasses (in order to determine whether or not they are magnetic) in front of his audiences and marveled at the rich colors of polarized lights, but the lectures were also deeply philosophical. In his lectures he urged his audiences to consider the mechanics of his experiments: \"you know very well that ice floats upon water ... Why does the ice float? Think of that, and philosophise\". His subjects consisted of Chemistry and Electricity, and included: 1841 The Rudiments of Chemistry, 1843 First Principles of Electricity, 1848 The Chemical History of a Candle, 1851 Attractive Forces, 1853 Voltaic Electricity, 1854 The Chemistry of Combustion, 1855 The Distinctive Properties of the Common Metals, 1857 Static Electricity, 1858 The Metallic Properties, 1859 The Various Forces of Matter and their Relations to Each Other.\n\nA statue of Faraday stands in Savoy Place, London, outside the Institution of Engineering and Technology. Also in London, the Michael Faraday Memorial, designed by brutalist architect Rodney Gordon and completed in 1961, is at the Elephant & Castle gyratory system, near Faraday's birthplace at Newington Butts. Faraday School is located on Trinity Buoy Wharf where his workshop still stands above the Chain and Buoy Store, next to London's only lighthouse.\n\nFaraday Gardens is a small park in Walworth, London, not far from his birthplace at Newington Butts. This park lies within the local council ward of Faraday in the London Borough of Southwark. Michael Faraday Primary school is situated on the Aylesbury Estate in Walworth.\n\nA building at London South Bank University, which houses the institute's electrical engineering departments is named the Faraday Wing, due to its proximity to Faraday's birthplace in Newington Butts. A hall at Loughborough University was named after Faraday in 1960. Near the entrance to its dining hall is a bronze casting, which depicts the symbol of an electrical transformer, and inside there hangs a portrait, both in Faraday's honour. An eight-story building at the University of Edinburgh's science & engineering campus is named for Faraday, as is a recently built hall of accommodation at Brunel University, the main engineering building at Swansea University, and the instructional and experimental physics building at Northern Illinois University. The former UK Faraday Station in Antarctica was named after him.\n\nStreets named for Faraday can be found in many British cities (e.g., London, Fife, Swindon, Basingstoke, Nottingham, Whitby, Kirkby, Crawley, Newbury, Swansea, Aylesbury and Stevenage) as well as in France (Paris), Germany (Berlin-Dahlem, Hermsdorf), Canada (Quebec; Deep River, Ontario; Ottawa, Ontario), and the United States (Reston, Virginia).\n\nA Royal Society of Arts blue plaque, unveiled in 1876, commemorates Faraday at 48 Blandford Street in London's Marylebone district. From 1991 until 2001, Faraday's picture featured on the reverse of Series E £20 banknotes issued by the Bank of England. He was portrayed conducting a lecture at the Royal Institution with the magneto-electric spark apparatus. In 2002, Faraday was ranked number 22 in the BBC's list of the 100 Greatest Britons following a UK-wide vote.\n\nThe Faraday Institute for Science and Religion derives its name from the scientist, who saw his faith as integral to his scientific research. The logo of the Institute is also based on Faraday's discoveries. It was created in 2006 by a $2,000,000 grant from the John Templeton Foundation to carry out academic research, to foster understanding of the interaction between science and religion, and to engage public understanding in both these subject areas.\n\nFaraday's life and contributions to electromagnetics was the principal topic of the tenth episode, titled \"The Electric Boy\", of the 2014 American science documentary series, \"\", which was broadcast on Fox and the National Geographic Channel.\n\nIn honor and remembrance of his great scientific contributions, several institutions have created prizes and awards in his name. This include:\n\n\nFaraday's books, with the exception of \"Chemical Manipulation\", were collections of scientific papers or transcriptions of lectures. Since his death, Faraday's diary has been published, as have several large volumes of his letters and Faraday's journal from his travels with Davy in 1813–1815.\n\n\n"}
{"id": "3854878", "url": "https://en.wikipedia.org/wiki?curid=3854878", "title": "Microlensing Observations in Astrophysics", "text": "Microlensing Observations in Astrophysics\n\nMicrolensing Observations in Astrophysics (MOA) is a collaborative project between researchers in New Zealand and Japan, led by Professor Yasushi Muraki of Nagoya University. They use microlensing to observe dark matter, extra-solar planets, and stellar atmospheres from the Southern Hemisphere. The group concentrates especially on the detection and observation of gravitational microlensing events of high magnification, of order 100 or more, as these provide the greatest sensitivity to extrasolar planets. They work with other groups in Australia, the United States and elsewhere. Observations are conducted at New Zealand's Mt. John University Observatory using a reflector telescope built for the project.\n\nThe following planets have been announced by this survey, some in conjunction with other surveys.\n\n"}
{"id": "22697068", "url": "https://en.wikipedia.org/wiki?curid=22697068", "title": "Monolith of Silwan", "text": "Monolith of Silwan\n\nThe Monolith of Silwan, also known as the Tomb of Pharaoh's daughter is a cuboid rock-cut tomb located in Silwan, Jerusalem dating from the period of the Kingdom of Judah; the latter name refers to a 19th-century hypothesis that the tomb was built by Solomon for his Egyptian wife. The structure, a typical Israelite rock-cut tomb, was previously capped by a pyramid structure like the Tomb of Zechariah. It is one of the more complete and distinctive First Temple Period structures. The pyramidal, rock cap was cut into pieces and removed for quarry, during the Roman era leaving a flat roof. The tomb contains a single stone bench, indicating that it was designed for only one burial. Recent research indicates that the bench was the base of a sarcophagus hewn into the original building.\n\nThe Pharaoh's daughter tradition was first suggested by Louis Félicien de Saulcy, who noted that the bible claims that Solomon built a temple for his Egyptian wife; de Saulcy, excavating the site in the 19th century, suggested that this might be the same building. However, subsequent archaeological investigation has dated the site to the 9th-7th Century BC, making the connection to Solomon impossible.\n\nTwo letters of a Hebrew inscription survive on the building, the remainder of the inscription having been mutilated beyond recognition, by a hermit in the Byzantine era; Byzantine monks increased the height of the low entrance by removing rock which contained the inscription in order to ease access to the tomb, in which they resided. The tomb was cleaned following the 1967 Six-Day War. Neglected since Ussishkin's survey, trash disposal has in recent years has resulted in an unkempt, unattractive appearance.\n\n"}
{"id": "22827420", "url": "https://en.wikipedia.org/wiki?curid=22827420", "title": "Natural Gas Choice", "text": "Natural Gas Choice\n\nNatural Gas Choice programs in United States of America allow residential consumers and other small volume gas users to purchase natural gas from someone other than their traditional utility company. With Natural Gas Choice programs, customers can either purchase from their natural gas utility or choose to receive their gas supply from non-utility Choice suppliers. Large commercial and industrial consumers have had the option of purchasing the natural gas commodity separately from natural gas services for many years. \n\nCurrently, 21 States and the District of Columbia have legislation or existing programs that allow Natural Gas Choice Programs. Enrollment in “customer choice” programs increased in 2008 for the third year in a row. Overall, more than 13 percent or about 4.7 million of the approximately 35 million residential natural gas consumers with access to choice were buying natural gas from marketers as of December 2008. The availability and characteristics of these customer choice programs vary widely from state to state. For instance, some states allow customers to participate in Choice programs, but lack of natural gas supplier participation has precluded the development of a competitive natural gas market. Even in fully developed competitive markets enrollment varies widely. Currently the states of Georgia and Ohio have the highest percentage of customer participation in Natural Gas Choice programs with 81.5 percent and 42.3 percent of customers participating in Natural Gas Choice Programs respectively. New York and New Jersey, on the other hand, have customer participation rates of 17.1 percent and 3.1 percent respectively, despite full implementation of Natural Gas Choice Programs.<ref name=\"eia.doe.gov/newyork\"></ref> One reason for the disparity between participation rates is the difficulty marketers in some states have obtaining financing to purchase natural gas for delivery. Whereas in Georgia, the overwhelming majority of customers are served by one large marketer, Georgia Natural Gas, a wholly owned subsidiary of the regulated utility, Atlanta Gas Light Company. New York State is served by 69 mostly independent marketers.\n\nGeorgia is the state with the highest participation percentage in Natural Gas Choice programs. In 1999 all Georgia customers became eligible to participate in Natural Gas Choice. At one time 19 natural gas suppliers were approved to supply gas to natural gas customers. However, by 2002, 90% of Georgia residents were served by 3 or fewer marketers. In 2007, Georgia had 1,793,650 residential and 127,835 commercial customers. They consumed approximately 112 and 49 billion cubic feet of natural gas, respectively.\n\nOhio has had Natural Gas Choice since 1997. More than 40 percent of the state's residential natural gas customers were participating in choice programs as of September 2008. Several major Ohio natural gas utilities in Ohio have plans to exit the function of supplying natural gas to customers, leaving the gas supply function to independent natural gas supply companies. In 2007, Ohio had 3,273,791 residential, 272,548 commercial, and 6,865 industrial customers. They consumed approximately 300, 159, and 295 billion cubic feet of natural gas, respectively. Currently, Ohio has 35 natural gas suppliers certified to participate in Natural Gas Choice programs.\n"}
{"id": "36880", "url": "https://en.wikipedia.org/wiki?curid=36880", "title": "Nuclear warfare", "text": "Nuclear warfare\n\nNuclear warfare (sometimes atomic warfare or thermonuclear warfare) is a military conflict or political strategy in which nuclear weaponry is used to inflict damage on the enemy. Nuclear weapons are weapons of mass destruction; in contrast to conventional warfare, nuclear warfare can produce destruction in a much shorter time and can have a long-lasting radiological warfare result. A major nuclear exchange would have long-term effects, primarily from the fallout released, and could also lead to a \"nuclear winter\" that could last for decades, centuries, or even millennia after the initial attack. Some analysts dismiss the nuclear winter hypothesis, and calculate that even with nuclear weapon stockpiles at Cold War highs, although there would be billions of casualties, billions more rural people would nevertheless survive. However, others have argued that secondary effects of a nuclear holocaust, such as nuclear famine and societal collapse, would cause almost every human on Earth to starve to death.\n\nSo far, two nuclear weapons have been used in the course of warfare, both by the United States near the end of World War II. On August 6, 1945, a uranium gun-type device (code name \"Little Boy\") was detonated over the Japanese city of Hiroshima. Three days later, on August 9, a plutonium implosion-type device (code name \"Fat Man\") was detonated over the Japanese city of Nagasaki. These two bombings resulted in the deaths of approximately 120,000 people.\n\nAfter World War II, nuclear weapons were also developed by the Soviet Union (1949), the United Kingdom (1952), France (1960), and the People's Republic of China (1964), which contributed to the state of conflict and extreme tension that became known as the Cold War. In 1974, India, and in 1998, Pakistan, two countries that were openly hostile toward each other, developed nuclear weapons. Israel (1960s) and North Korea (2006) are also thought to have developed stocks of nuclear weapons, though it is not known how many. The Israeli government has never admitted or denied to having nuclear weapons, although it is known to have constructed the reactor and reprocessing plant necessary for building nuclear weapons. South Africa also manufactured several complete nuclear weapons in the 1980s, but subsequently became the first country to voluntarily destroy their domestically made weapons stocks and abandon further production (1990s). Nuclear weapons have been detonated on over 2,000 occasions for testing purposes and demonstrations.\n\nAfter the collapse of the Soviet Union in 1991 and the resultant end of the Cold War, the threat of a major nuclear war between the two nuclear superpowers was generally thought to have declined. Since then, concern over nuclear weapons has shifted to the prevention of localized nuclear conflicts resulting from nuclear proliferation, and the threat of nuclear terrorism.\n\nThe possibility of using nuclear weapons in war is usually divided into two subgroups, each with different effects and potentially fought with different types of nuclear armaments.\n\nThe first, a limited nuclear war (sometimes \"attack\" or \"exchange\"), refers to a small-scale use of nuclear weapons by two (or more) belligerents. A \"limited nuclear war\" could include targeting military facilities—either as an attempt to pre-emptively cripple the enemy's ability to attack as a defensive measure, or as a prelude to an invasion by conventional forces, as an offensive measure. This term could apply to \"any\" small-scale use of nuclear weapons that may involve military or civilian targets (or both). \n\nThe second, a full-scale nuclear war, could consist of large numbers of nuclear weapons used in an attack aimed at an entire country, including military, economic, and civilian targets. Such an attack would almost certainly destroy the entire economic, social, and military infrastructure of the target nation, and would probably have a devastating effect on Earth's biosphere.\n\nSome Cold War strategists such as Henry Kissinger argued that a limited nuclear war could be possible between two heavily armed superpowers (such as the United States and the Soviet Union). Some predict, however, that a limited war could potentially \"escalate\" into a full-scale nuclear war. Others have called limited nuclear war \"global nuclear holocaust in slow motion\", arguing that—once such a war took place—others would be sure to follow over a period of decades, effectively rendering the planet uninhabitable in the same way that a \"full-scale nuclear war\" between superpowers would, only taking a much longer (and arguably more agonizing) path to the same result.\n\nEven the most optimistic predictions of the effects of a major nuclear exchange foresee the death of many millions of victims within a very short period of time. More pessimistic predictions argue that a full-scale nuclear war could potentially bring about the extinction of the human race, or at least its \"near\" extinction, with only a relatively small number of survivors (mainly in remote areas) and a reduced quality of life and life expectancy for centuries afterward. However, such predictions, assuming total war with nuclear arsenals at Cold War highs, have not been without criticism. Such a horrific catastrophe as global nuclear warfare would almost certainly cause permanent damage to most complex life on the planet, its ecosystems, and the global climate. If predictions about the production of a nuclear winter are accurate, it would also change the balance of global power, with countries such as Australia, New Zealand, India, China, Argentina and Brazil predicted to become world superpowers if the Cold War ever led to a large-scale nuclear attack.\n\nA study presented at the annual meeting of the American Geophysical Union in December 2006 asserted that even a small-scale regional nuclear war could produce as many direct fatalities as all of World War II and disrupt the global climate for a decade or more. In a regional nuclear conflict scenario in which two opposing nations in the subtropics each used 50 Hiroshima-sized nuclear weapons (c. 15 kiloton each) on major population centers, the researchers predicted fatalities ranging from 2.6 million to 16.7 million per country. The authors of the study estimated that as much as five million tons of soot could be released, producing a cooling of several degrees over large areas of North America and Eurasia (including most of the grain-growing regions). The cooling would last for years and could be \"catastrophic\", according to the researchers.\n\nEither a limited or full-scale nuclear exchange could occur during an \"accidental nuclear war\", in which the use of nuclear weapons is triggered unintentionally. Postulated triggers for this scenario have included malfunctioning early warning devices and/or targeting computers, deliberate malfeasance by rogue military commanders, consequences of an accidental straying of warplanes into enemy airspace, reactions to unannounced missile tests during tense diplomatic periods, reactions to military exercises, mistranslated or miscommunicated messages, and others. A number of these scenarios actually occurred during the Cold War, though none resulted in the use of nuclear weapons. Many such scenarios have been depicted in popular culture, such as in the 1959 film \"On the Beach, the 1962 novel \"Fail-Safe\" (released as a film in 1964); the film \"WarGames\", released in 1983; and the film \"\", also released in 1964.\n\nDuring the final stages of World War II in 1945, the United States conducted atomic raids on the Japanese cities of Hiroshima and Nagasaki, the first on August 6, 1945, and the second on August 9, 1945. These two events were the only times nuclear weapons have been used in combat.\n\nFor six months before the atomic bombings, the U.S. 20th Air Force under General Curtis LeMay executed low-level incendiary raids against Japanese cities. The worst air raid to occur during the process was not the nuclear attacks, but the \"Operation Meetinghouse\" raid on Tokyo. On the night of March 9–10, 1945, \"Operation Meetinghouse\" commenced and 334 Boeing B-29 Superfortress bombers took off to raid, with 279 of them dropping 1,665 tons of incendiaries and explosives on Tokyo. The bombing was meant to burn wooden buildings and indeed the bombing caused fire that created a 50 m/s wind, which is comparable to tornadoes. Each bomber carried 6 tons of bombs. A total of 381,300 bombs, which amount to 1,783 tons of bombs, were used in the bombing. Within a few hours of the raid, it had killed an estimated 100,000 people and destroyed of the city and 267,000 buildings in a single night — the deadliest bombing raid in military aviation history other than the atomic raids on Hiroshima and Nagasaki. By early August 1945, an estimated 450,000 people had died as the U.S. had intensely firebombed a total of 67 Japanese cities.\n\nIn late June 1945, as the U.S. wrapped up the two-and-a-half-month Battle of Okinawa (which cost the lives of 260,000 people, including 150,000 civilians), it was faced with the prospect of invading the Japanese home islands in an operation codenamed Operation Downfall. Based on the U.S. casualties from the preceding island-hopping campaigns, American commanders estimated that between 50,000 and 500,000 U.S. troops would die and at least 600,000–1,000,000 others would be injured while invading the Japanese home islands. The U.S. manufacture of 500,000 Purple Hearts from the anticipated high level of casualties during the U.S. invasion of Japan gave a demonstration of how deadly and costly it would be. President Harry S. Truman realized he could not afford such a horrendous casualty rate, especially since over 400,000 American combatants had already died fighting in both the European and the Pacific theaters of the war.\n\nOn July 26, 1945, the United States, the United Kingdom, and the Republic of China issued a Potsdam Declaration that called for the unconditional surrender of Japan. It stated that if Japan did not surrender, it would face \"prompt and utter destruction\". The Japanese government ignored this ultimatum, sending a message that they were not going to surrender. In response to the rejection, President Truman authorized the dropping of the atomic bombs. At the time of its use, there were only two atomic bombs available, and despite the fact that more were in production back in mainland U.S., the third bomb wouldn't be available for combat until September.\n\nOn August 6, 1945, the uranium-type nuclear weapon codenamed \"Little Boy\" was detonated over the Japanese city of Hiroshima with an energy of about , destroying nearly 50,000 buildings (including the headquarters of the 2nd General Army and Fifth Division) and killing approximately 70,000 people, including 20,000 Japanese combatants and 20,000 Korean slave laborers. Three days later, on August 9, a plutonium-type nuclear weapon codenamed \"Fat Man\" was used against the Japanese city of Nagasaki, with the explosion equivalent to about , destroying 60% of the city and killing approximately 35,000 people, including 23,200–28,200 Japanese munitions workers, 2,000 Korean slave laborers, and 150 Japanese combatants. The industrial damage in Nagasaki was high, partly owing to the inadvertent targeting of the industrial zone, leaving 68–80 percent of the non-dock industrial production destroyed.\n\nSix days after the detonation over Nagasaki, Japan announced its surrender to the Allied Powers on August 15, 1945, signing the Instrument of Surrender on September 2, 1945, officially ending the Pacific War and, therefore, World War II, as Germany had already signed its Instrument of Surrender on May 8, 1945, ending the war in Europe. The two atomic bombings led, in part, to post-war Japan's adopting of the Three Non-Nuclear Principles, which forbade the nation from developing nuclear armaments.\n\nAfter the successful Trinity nuclear test July 16, 1945, which was the very first nuclear detonation, the Manhattan project lead manager J. Robert Oppenheimer recalled:\nImmediately after the atomic bombings of Japan, the status of atomic weapons in international and military relations was unclear. Presumably, the United States hoped atomic weapons could offset the Soviet Union's larger conventional ground forces in Eastern Europe, and possibly be used to pressure Soviet leader Joseph Stalin into making concessions. Under Stalin, the Soviet Union pursued its own atomic capabilities through a combination of scientific research and espionage directed against the American program. The Soviets believed that the Americans, with their limited nuclear arsenal, were unlikely to engage in any new world wars, while the Americans were not confident they could prevent a Soviet takeover of Europe, despite their atomic advantage.\n\nWithin the United States the authority to produce and develop nuclear weapons was removed from military control and put instead under the civilian control of the United States Atomic Energy Commission. This decision reflected an understanding that nuclear weapons had unique risks and benefits that were separate from other military technology known at the time.\n\nFor several years after World War II, the United States developed and maintained a strategic force based on the Convair B-36 bomber that would be able to attack any potential enemy from bomber bases in the United States. It deployed atomic bombs around the world for potential use in conflicts. Over a period of a few years, many in the American defense community became increasingly convinced of the invincibility of the United States to a nuclear attack. Indeed, it became generally believed that the threat of nuclear war would deter any strike against the United States.\n\nMany proposals were suggested to put all American nuclear weapons under international control (by the newly formed United Nations, for example) as an effort to deter both their usage and an arms race. However, no terms could be arrived at that would be agreed upon by both the United States and the Soviet Union. \n\nOn August 29, 1949, the Soviet Union tested its first nuclear weapon at Semipalatinsk in Kazakhstan (see also Soviet atomic bomb project). Scientists in the United States from the Manhattan Project had warned that, in time, the Soviet Union would certainly develop nuclear capabilities of its own. Nevertheless, the effect upon military thinking and planning in the United States was dramatic, primarily because American military strategists had not anticipated the Soviets would \"catch up\" so soon. However, at this time, they had not discovered that the Soviets had conducted significant nuclear espionage of the project from spies at Los Alamos, the most significant of which was done by the theoretical physicist Klaus Fuchs. The first Soviet bomb was more or less a deliberate copy of the Fat Man plutonium device. In the same year the first US-Soviet nuclear war plan was penned in the US with Operation Dropshot.\n\nWith the monopoly over nuclear technology broken, worldwide nuclear proliferation accelerated. The United Kingdom tested its first independent atomic bomb in 1952, followed by France in 1960 and then China in 1964. While much smaller than the arsenals of the United States and the Soviet Union, Western Europe's nuclear reserves were nevertheless a significant factor in strategic planning during the Cold War. A top-secret White Paper, compiled by the Royal Air Force and produced for the British Government in 1959, estimated that British bombers carrying nuclear weapons were capable of destroying key cities and military targets in the Soviet Union, with an estimated 16 million deaths in the Soviet Union (half of whom were estimated to be killed on impact and the rest fatally injured) \"before\" bomber aircraft from the U.S. Strategic Air Command reached their targets.\n\nAlthough the Soviet Union had nuclear weapon capabilities in the beginning of the Cold War, the United States still had an advantage in terms of bombers and weapons. In any exchange of hostilities, the United States would have been capable of bombing the Soviet Union, whereas the Soviet Union would have more difficulty carrying out the reverse mission.\n\nThe widespread introduction of jet-powered interceptor aircraft upset this imbalance somewhat by reducing the effectiveness of the American bomber fleet. In 1949 Curtis LeMay was placed in command of the Strategic Air Command and instituted a program to update the bomber fleet to one that was all-jet. During the early 1950s the B-47 and B-52 were introduced, providing the ability to bomb the Soviet Union more easily. Before the development of a capable strategic missile force in the Soviet Union, much of the war-fighting doctrine held by western nations revolved around using a large number of smaller nuclear weapons in a tactical role. It is debatable whether such use could be considered \"limited\" however, because it was believed that the United States would use its own strategic weapons (mainly bombers at the time) should the Soviet Union deploy any kind of nuclear weapon against civilian targets. Douglas MacArthur, an American general, was fired by President Harry Truman, partially because he persistently requested permission to use his own discretion in deciding whether to utilize atomic weapons on the People's Republic of China in 1951 during the Korean War. Mao Zedong, China's communist leader, gave the impression that he would welcome a nuclear war with the capitalists because it would annihilate what he viewed as their \"imperialist\" system.\n\nThe concept of a \"Fortress North America\" emerged during the Second World War and persisted into the Cold War to refer to the option of defending Canada and the United States against their enemies if the rest of the world were lost to them. This option was rejected with the formation of NATO and the decision to permanently station troops in Europe.\n\nIn the summer of 1951 Project Vista started, in which project analysts such as Robert F. Christy looked at how to defend Western Europe from a Soviet invasion. The emerging development of tactical nuclear weapons were looked upon as a means to give Western forces a qualitative advantage over the Soviet numerical supremacy in conventional weapons.\n\nSeveral scares about the increasing ability of the Soviet Union's strategic bomber forces surfaced during the 1950s. The defensive response by the United States was to deploy a fairly strong \"layered defense\" consisting of interceptor aircraft and anti-aircraft missiles, like the Nike, and guns, like the Skysweeper, near larger cities. However, this was a small response compared to the construction of a huge fleet of nuclear bombers. The principal nuclear strategy was to massively penetrate the Soviet Union. Because such a large area could not be defended against this overwhelming attack in any credible way, the Soviet Union would lose any exchange.\n\nThis logic became ingrained in American nuclear doctrine and persisted for much of the duration of the Cold War. As long as the strategic American nuclear forces could overwhelm their Soviet counterparts, a Soviet pre-emptive strike could be averted. Moreover, the Soviet Union could not afford to build any reasonable counterforce, as the economic output of the United States was far larger than that of the Soviets, and they would be unable to achieve \"nuclear parity\".\n\nSoviet nuclear doctrine, however, did not match American nuclear doctrine. Soviet military planners assumed they could win a nuclear war. Therefore, they \"expected\" a large-scale nuclear exchange, followed by a \"conventional war\" which itself would involve heavy use of tactical nuclear weapons. American doctrine rather assumed that Soviet doctrine was similar, with the \"mutual\" in Mutually Assured Destruction necessarily requiring that the other side see things in much the same way, rather than believing—as the Soviets did—that they could fight a large-scale, \"combined nuclear and conventional\" war.\n\nIn accordance with their doctrine, the Soviet Union conducted large-scale military exercises to explore the possibility of defensive and offensive warfare during a nuclear war. The exercise, under the code name of \"Snowball\", involved the detonation of a nuclear bomb about twice as powerful as that which fell on Nagasaki and an army of approximately 45,000 soldiers on maneuvers through the hypocenter immediately after the blast. The exercise was conducted on September 14, 1954, under command of Marshal Georgy Zhukov to the north of Totskoye village in Orenburg Oblast, Russia.\n\nA revolution in nuclear strategic thought occurred with the introduction of the intercontinental ballistic missile (ICBM), which the Soviet Union first successfully tested in August 1957. In order to deliver a warhead to a target, a missile was much faster and more cost-effective than a bomber, and enjoyed a higher survivability due to the enormous difficulty of interception of the ICBMs (due to their high altitude and extreme speed). The Soviet Union could now afford to achieve nuclear parity with the United States in raw numbers, although for a time, they appeared to have chosen not to.\n\nPhotos of Soviet missile sites set off a wave of panic in the U.S. military, something the launch of Sputnik would do for the American public a few months later. Politicians, notably then-U.S. Senator John F. Kennedy suggested that a \"missile gap\" existed between the Soviet Union and the United States. The US military gave missile development programs the highest national priority, and several spy aircraft and reconnaissance satellites were designed and deployed to observe Soviet progress.\n\nEarly ICBMs and bombers were relatively inaccurate, which led to the concept of countervalue strikes — attacks directly on the enemy population, which would theoretically lead to a collapse of the enemy's will to fight. During the Cold War, the Soviet Union invested in extensive protected civilian infrastructure, such as large \"nuclear-proof\" bunkers and non-perishable food stores. By comparison, smaller scale civil defense programs were instituted in the United States starting in the 1950s, where schools and other public buildings had basements stocked with non-perishable food supplies, canned water, first aid, and dosimeter and Geiger counter radiation-measuring devices. Many of the locations were given \"Fallout shelter\" designation signs. CONELRAD radio information systems were adopted, whereby the commercial radio sector (later supplemented by the National Emergency Alarm Repeaters) would broadcast on two AM frequencies in the event of a Civil Defense (CD) emergency. These two frequencies, 640 and 1240 kHz, were marked with small CD triangles on the tuning dial of radios of the period, as can still be seen on 1950s-vintage radios on online auction sites and museums. A few backyard fallout shelters were built by private individuals.\n\nHenry Kissinger's view on tactical nuclear war in his controversial 1957 book Nuclear Weapons and Foreign Policy was that any nuclear weapon exploded in air burst mode that was below 500 kiloton in yield and thus averting serious fallout, may be more decisive and less costly in human lives than a protracted conventional war.\n\nA list of targets made by the U.S.A. was released sometime during December 2015 by the U.S. National Archives and Records Administration. The language used to describe targets is \"designated ground zeros\". The list was released after a request was made during 2006 by William Burr who belongs to a research group at George Washington University, and belongs to a previously top-secret 800-page document. The list is entitled \"Atomic Weapons Requirements Study for 1959\" and was produced by U.S. Strategic Air Command during the year 1956.\n\nIn 1960, the United States developed its first Single Integrated Operational Plan, a range of targeting options, and described launch procedures and target sets against which nuclear weapons would be launched, variants of which were in use from 1961 to 2003. That year also saw the start of the Missile Defense Alarm System, an American system of 12 early-warning satellites that provided limited notice of Soviet intercontinental ballistic missile launches between 1960 and 1966. The Ballistic Missile Early Warning System was completed in 1964.\n\nA complex and worrisome situation developed in 1962, in what is called the Cuban Missile Crisis. The Soviet Union placed medium-range ballistic missiles from the United States, possibly as a direct response to American Jupiter missiles placed in Turkey. After intense negotiations, the Soviets ended up removing the missiles from Cuba and decided to institute a massive weapons-building program of their own. In exchange, the United States dismantled its launch sites in Turkey, although this was done secretly and not publicly revealed for over two decades. Khrushchev did not even reveal this part of the agreement when he came under fire by political opponents for mishandling the crisis. Communication delays during the crisis led to the establishment of the Moscow–Washington hotline to allow reliable, direct communications between the two nuclear powers.\n\nBy the late 1960s, the number of ICBMs and warheads was so high on both sides that it was believed that both the United States and the Soviet Union were capable of completely destroying the infrastructure and a large proportion of the population of the other country. Thus, by some western game theorists, a balance of power system known as mutually assured destruction (or \"MAD\") came into being. It was thought that no full-scale exchange between the powers would result in an outright winner, with at best one side emerging the pyrrhic victor. Thus both sides were deterred from risking the initiation of a direct confrontation, instead being forced to engage in lower intensity proxy wars.\n\nDuring this decade the People's Republic of China began to build subterranean infrastructure such as the Underground Project 131 following the Sino-Soviet split.\nOne drawback of the MAD doctrine was the possibility of a nuclear war occurring without either side intentionally striking first. Early Warning Systems (EWS) were notoriously error-prone. For example, on 78 occasions in 1979 alone, a \"missile display conference\" was called to evaluate detections that were \"potentially threatening to the North American continent\". Some of these were trivial errors and were spotted quickly, but several went to more serious levels. On September 26, 1983, Stanislav Petrov received convincing indications of an American first strike launch against the Soviet Union, but positively identified the warning as a false alarm. Though it is unclear what role Petrov's actions played in preventing a nuclear war during this incident, he has been honored by the United Nations for his actions.\n\nSimilar incidents happened many times in the United States, due to failed computer chips, misidentifications of large flights of geese, test programs, and bureaucratic failures to notify early warning military personnel of legitimate launches of test or weather missiles. For many years, the U.S. Air Force's strategic bombers were kept airborne on a daily rotating basis \"around the clock\" (see Operation Chrome Dome), until the number and severity of accidents, the 1968 Thule Air Base B-52 crash in particular, persuaded policymakers it was not worthwhile.\n\nIsrael responded to the Arab Yom Kippur War attack on 6 October 1973 by assembling 13 nuclear weapons in a tunnel under the Negev desert when Syrian tanks were sweeping in across the Golan Heights. On 8 October 1973, Israeli Prime Minister Mrs Golda Meir authorized Defense Minister Moshe Dayan to activate the 13 Israeli nuclear warheads and distribute them to Israeli air force units, with the intent that they be used if Israel began to be overrun.\n\nOn 24 October 1973, as US President Nixon was preoccupied with the Watergate scandal, Henry Kissinger ordered a DEFCON-3 alert preparing American B-52 nuclear bombers for war. Intelligence reports indicated that the USSR was preparing to defend Egypt in its Yom Kippur war with Israel. It had become apparent that if Israel had dropped nuclear weapons on Egypt or Syria, as it prepared to do, then the USSR would have retaliated against Israel, with the US then committed to providing Israeli assistance, possibly escalating to a general nuclear war.\n\nBy the late 1970s, people in both the United States and the Soviet Union, along with the rest of the world, had been living with the concept of mutual assured destruction (MAD) for about a decade, and it became deeply ingrained into the psyche and popular culture of those countries.\n\nOn May 18, 1974, India conducted its first nuclear test in the Pokhran test range. The name of the operation was Smiling Buddha, and India termed the test as a \"peaceful nuclear explosion\".\n\nThe Soviet Duga early warning over-the-horizon radar system was made operational in 1976. The extremely powerful radio transmissions needed for such a system led to much disruption of civilian shortwave broadcasts, earning it the nickname \"Russian Woodpecker\".\n\nThe idea that any nuclear conflict would eventually escalate was a challenge for military strategists. This challenge was particularly severe for the United States and its NATO allies. It was believed (until the 1970s) that a Soviet tank invasion of Western Europe would quickly overwhelm NATO conventional forces, leading to the necessity of the West escalating to the use of tactical nuclear weapons, one of which was the W-70.\n\nThis strategy had one major (and possibly critical) flaw, which was soon realized by military analysts but highly underplayed by the U.S. military: conventional NATO forces in the European theatre of war were far outnumbered by similar Soviet and Warsaw Pact forces, and it was assumed that in case of a major Soviet attack (commonly envisioned as the \"Red tanks rolling towards the North Sea\" scenario) that NATO—in the face of quick conventional defeat—would soon have no other choice but to resort to tactical nuclear strikes against these forces. Most analysts agreed that once the first nuclear exchange had occurred, escalation to global nuclear war would likely become inevitable. The Soviet bloc's vision of an atomic war between NATO and Warsaw Pact forces was simulated in the top secret exercise Seven Days to the River Rhine in 1979. The British government exercised their vision of Soviet nuclear attack with Square Leg in early 1980.\n\nLarge hardened nuclear weapon storage areas were built across European countries in anticipation of local US and European forces falling back as the conventional NATO defense from the Soviet Union, named REFORGER, was believed to only be capable of stalling the Soviets for a short time.\n\nIn the late 1970s and, particularly, during the early 1980s under U.S. President Ronald Reagan, the United States renewed its commitment to a more powerful military, which required a large increase in spending on U.S. military programs. These programs, which were originally part of the defense budget of U.S. President Jimmy Carter, included spending on conventional and nuclear weapons systems. Under Reagan, defensive systems like the Strategic Defense Initiative were emphasized as well.\n\nAnother major shift in nuclear doctrine was the development and the improvement of the submarine-launched, nuclear-armed, ballistic missile, or SLBM. It was hailed by many military theorists as a weapon that would make nuclear war less likely. SLBMs—which can move with \"stealth\" (greatly lessened detectability) virtually anywhere in the world—give a nation a \"second strike\" capability (i.e., after absorbing a \"first strike\"). Before the advent of the SLBM, thinkers feared that a nation might be tempted to initiate a first strike if it felt confident that such a strike would incapacitate the nuclear arsenal of its enemy, making retaliation impossible. With the advent of SLBMs, no nation could be certain that a first strike would incapacitate its enemy's entire nuclear arsenal. To the contrary, it would have to fear a near certain retaliatory second strike from SLBMs. Thus, a first strike was a much less feasible (or desirable) option, and a deliberately initiated nuclear war was thought to be less likely to start.\n\nHowever, it was soon realized that submarines could approach enemy coastlines undetected and decrease the warning time (the time between detection of the missile launch and the impact of the missile) from as much as half an hour to possibly under three minutes. This effect was especially significant to the United States, Britain and China, whose capitals all lay within 100 miles (160 km) of their coasts. Moscow was much more secure from this type of threat, due to its considerable distance from the sea. This greatly increased the credibility of a \"surprise first strike\" by one faction and (theoretically) made it possible to knock out or disrupt the chain of command of a target nation before any counterstrike could be ordered (known as a \"decapitation strike\"). It strengthened the notion that a nuclear war could possibly be \"won\", resulting not only in greatly increased tensions and increasing calls for fail-deadly control systems, but also in a dramatic increase in military spending. The submarines and their missile systems were very expensive, and one fully equipped nuclear-powered and nuclear-armed missile submarine could cost more than the entire GNP of a developing country. It was also calculated, however, that the greatest cost came in the development of \"both\" sea- and land-based anti-submarine defenses and in improving and strengthening the \"chain of command\", and as a result, military spending skyrocketed.\n\nSouth Africa developed a nuclear weapon capability during the 1970s and early 1980s. It was operational for a brief period before being dismantled in the early 1990s.\n\nAccording to the 1980 United Nations report \"General and Complete Disarmament: Comprehensive Study on Nuclear Weapons: Report of the Secretary-General\", it was estimated that there were a total of about 40,000 nuclear warheads in existence at that time, with a potential combined explosive yield of approximately 13,000 megatons. By comparison, when the volcano Mount Tambora erupted in 1815—turning 1816 into the Year Without A Summer due to the levels of global dimming sulfate aerosols and ash expelled—it exploded with a force of roughly 800 to 1,000 megatons, and ejected of mostly rock/tephra, that included 120 million tonnes of sulfur dioxide as an upper estimate. A larger eruption, approximately 74,000 years ago, in Mount Toba produced of tephra, forming lake Toba, and produced an estimated of sulfur dioxide. The explosive energy of the eruption may have been as high as equivalent to 20,000,000 megatons (Mt) of TNT, while the asteroid created Chicxulub impact, that is connected with the extinction of the dinosaurs corresponds to at least 70,000,000 Mt of energy, which is roughly 7000 times the maximum arsenal of the US and Soviet Union.\n\nHowever, comparisons with supervolcanoes are more misleading than helpful due to the different aerosols released, the likely air burst fuzing height of nuclear weapons and the globally scattered location of these potential nuclear detonations all being in contrast to the singular and subterranean nature of a supervolcanic eruption. Moreover, assuming the entire world stockpile of weapons were grouped together, it would be difficult, due to the nuclear fratricide effect, to ensure the individual weapons would go off all at once. Nonetheless, many people believe that a full-scale nuclear war would result, through the nuclear winter effect, in the extinction of the human species, though not all analysts agree on the assumptions that underpin these nuclear winter models.\n\nOn Sept. 1, 1983, Korean Air Lines Flight 007 was shot down by Soviet jet fighters. On the 26th, a Soviet early warning station under the command of Stanislav Petrov falsely detected 5 inbound intercontinental ballistic missiles from the US. Petrov correctly assessed the situation as a false alarm, and hence did not report his finding to his superiors. It is quite possible that his actions prevented \"World War III\", as the Soviet policy at that time was immediate nuclear response upon discovering inbound ballistic missiles.\n\nThe world came unusually close to nuclear war when the Soviet Union thought that the NATO military exercise Able Archer 83 was a ruse or \"cover-up\" to begin a nuclear first strike. The Soviets responded by raising readiness and preparing their nuclear arsenal for immediate use. Soviet fears of an attack ceased once the exercise concluded without incident.\n\nAlthough the dissolution of the Soviet Union ended the Cold War and greatly reduced tensions between the United States and the Russian Federation, the Soviet Union's formal successor state, both countries remained in a \"nuclear stand-off\" due to the continuing presence of a very large number of deliverable nuclear warheads on both sides. Additionally, the end of the Cold War led the United States to become increasingly concerned with the development of nuclear technology by other nations outside of the former Soviet Union. In 1995, a branch of the U.S. Strategic Command produced an outline of forward-thinking strategies in the document \"Essentials of Post–Cold War Deterrence\".\n\nIn 1996, a Russian continuity of government facility, Kosvinsky Mountain, which is believed to be a counterpart to the US Cheyenne Mountain Complex, was completed. It was designed to resist US earth-penetrating nuclear warheads, and is believed to host the Russian Strategic Rocket Forces alternate command post, a post for the general staff built to compensate for the vulnerability of older Soviet era command posts in the Moscow region. In spite of this, the primary command posts for the Strategic Rocket Forces remains Kuntsevo in Moscow and the secondary is the Kosvinsky Mountain in the Urals. The timing of the Kosvinsky facilities completion date is regarded as one explanation for U.S. interest in a new nuclear \"bunker buster\" Earth-penetrating warhead and the declaration of the deployment of the B-61 mod 11 in 1997; Kosvinsky is protected by about 1000 feet of granite.\n\nAs a consequence of the 9/11 attacks, American forces immediately increased their readiness to the highest level in 28 years, closing the blast doors of the NORAD's Cheyenne Mountain Operations Center for the first time due to a non-exercise event. But unlike similar increases during the Cold War, Russia immediately decided to stand down a large military exercise in the Arctic region, in order to minimize the risk of incidents, rather than following suit.\n\nThe former chair of the United Nations disarmament committee stated that there are more than 16,000 strategic and tactical nuclear weapons ready for deployment and another 14,000 in storage, with the U.S. having nearly 7,000 ready for use and 3,000 in storage, and Russia having about 8,500 ready for use and 11,000 in storage. In addition, China is thought to possess about 400 nuclear weapons, Britain about 200, France about 350, India about 80–100, and Pakistan 100–110. North Korea is confirmed as having nuclear weapons, though it is not known how many, with most estimates between 1 and 10. Israel is also widely believed to possess usable nuclear weapons. NATO has stationed about 480 American nuclear weapons in Belgium, the Netherlands, Italy, Germany, and Turkey, and several other nations are thought to be in pursuit of an arsenal of their own.\n\nPakistan's nuclear policy was significantly affected by the 1965 war with India. The 1971 war and India's nuclear program played a role in Pakistan's decision to go nuclear. India and Pakistan both decided not to participate in the NPT. Pakistan's nuclear policy became fixated on India because India refused to join the NPT and remain opened to nuclear weapons. Impetus by Indian actions spurred Pakistan's nuclear research. After nuclear weapons construction was started by Bhutto's command, the chair of Pakistan Atomic Energy Commission Usmani quit in objection. The 1999 war between Pakistan and India occurred after both acquired nuclear weapons. It is believed by some that nuclear weapons are the reason a big war has not broken out in the subcontinent. India and Pakistan still have a risk of nuclear conflict on the issue of war over Kashmir. Nuclear capability deliverable by sea were claimed by Pakistan in 2012. The aim was to achieve a \"minimum credible deterrence\". Pakistan's nuclear program culminated in the tests at Chagai. One of the aims of Pakistan's programs is fending off potential annexation and maintaining independence.\n\nA key development in nuclear warfare throughout the 2000s and early 2010s is the proliferation of nuclear weapons to the developing world, with India and Pakistan both publicly testing several nuclear devices, and North Korea conducting an underground nuclear test on October 9, 2006. The U.S. Geological Survey measured a 4.2 magnitude earthquake in the area where the North Korean test is said to have occurred. A further test was announced by the North Korean government on May 25, 2009. Iran, meanwhile, has embarked on a nuclear program which, while officially for civilian purposes, has come under close scrutiny by the United Nations and many individual states.\n\nRecent studies undertaken by the CIA cite the enduring India-Pakistan conflict as the one \"flash point\" most likely to escalate into a nuclear war. During the Kargil War in 1999, Pakistan came close to using its nuclear weapons in case the conventional military situation underwent further deterioration. Pakistan's foreign minister had even warned that it would \"use any weapon in our arsenal\", hinting at a nuclear strike against India. The statement was condemned by the international community, with Pakistan denying it later on. This conflict remains the only war (of any sort) between two declared nuclear powers. The 2001-2002 India-Pakistan standoff again stoked fears of nuclear war between the two countries. Despite these very serious and relatively recent threats, relations between India and Pakistan have been improving somewhat over the last few years. However, with the November 26, 2008 Mumbai terror attacks, tensions again worsened.\n\nAnother potential geopolitical issue which is considered particularly worrisome by military analysts is a possible conflict between the United States and the People's Republic of China over Taiwan. Although economic forces are thought to have reduced the possibility of a military conflict, there remains concern about the increasing military buildup of China (China is rapidly increasing its naval capacity), and that any move toward Taiwan independence could potentially spin out of control.\n\nIsrael is thought to possess somewhere between one hundred and four hundred nuclear warheads. It has been asserted that the Dolphin-class submarines which Israel received from Germany have been adapted to carry Popeye cruise missiles with nuclear warheads, so as to give Israel a second strike capability. Israel has been involved in wars with its neighbors in the Middle East (and with other \"non-state actors\") on numerous prior occasions, and its small geographic size and population could mean that, in the event of future wars, the Israeli military might have very little time to react to an invasion or other major threat. Such a situation could escalate to nuclear warfare very quickly in some scenarios.\n\nOn March 7, 2013, North Korea threatened the United States with a pre-emptive nuclear strike. On April 9, North Korea urged foreigners to leave South Korea, stating that both countries were on the verge of nuclear war. On April 12, North Korea stated that a nuclear war was unavoidable. The country declared Japan as its first target.\n\nIn the year of 2014, when Russian relationships with the USA had become worse, it was stated by the Russian state-owned Russia 1 TV channel that ‘Russia is the only country in the world that is really capable of turning the USA into radioactive ash’.\n\nThe above examples envisage nuclear warfare at a strategic level, i.e., total war. However, nuclear powers have the ability to undertake more limited engagements.\n\n\"Sub-strategic use\" includes the use of either \"low-yield\" tactical nuclear weapons, or of variable yield strategic nuclear weapons in a very limited role, as compared to battlefield exchanges of larger-yield strategic nuclear weapons. This was described by the UK Parliamentary Defence Select Committee as \"the launch of one or a limited number of missiles against an adversary as a means of conveying a political message, warning or demonstration of resolve\". It is believed that all current nuclear weapons states possess tactical nuclear weapons, with the exception of the United Kingdom, which decommissioned its tactical warheads in 1998. However, the UK does possess scalable-yield strategic warheads, and this technology tends to blur the difference between \"strategic\", \"sub-strategic\", and \"tactical\" use or weapons. American, French and British nuclear submarines are believed to carry at least \"some\" missiles with dial-a-yield warheads for this purpose, potentially allowing a strike as low as one kiloton (or less) against a single target. Only the People's Republic of China and the Republic of India have declarative, unqualified, unconditional \"no first use\" nuclear weapons policies. India and Pakistan maintain only a credible minimum deterrence.\n\nCommodore Tim Hare, former Director of Nuclear Policy at the British Ministry of Defence, has described \"sub-strategic use\" as offering the Government \"an extra option in the escalatory process before it goes for an all-out strategic strike which would deliver unacceptable damage\". However, this sub-strategic capacity has been criticized as potentially increasing the \"acceptability\" of using nuclear weapons. Combined with the trend in the reduction in the worldwide nuclear arsenal as of 2007 is the warhead miniaturization and modernization of the remaining strategic weapons that is presently occurring in all the declared nuclear weapon states, into more \"usable\" configurations. The Stockholm International Peace Research Institute suggests that this is creating a culture where use of these weapons is more acceptable and therefore is increasing the risk of war, as these modern weapons do not possess the same psychological deterrent value as the large Cold-War era, multi-megaton warheads.\n\nIn many ways, this present change in the balance of terror can be seen as the complete embracement of the switch from the 1950s Eisenhower doctrine of \"massive retaliation\" to one of \"flexible response\", which has been growing in importance in the US nuclear war fighting plan/SIOP every decade since.\n\nFor example, the United States adopted a policy in 1996 of allowing the targeting of its nuclear weapons at non-state actors (\"terrorists\") armed with weapons of mass destruction.\n\nAnother dimension to the tactical use of nuclear weapons is that of such weapons deployed at sea for use against surface and submarine vessels. Until 1992, vessels of the United States Navy (and their aircraft) deployed various such weapons as bombs, rockets (guided and unguided), torpedoes, and depth charges. Such tactical naval nuclear weapons were considered more acceptable to use early in a conflict because there would be few civilian casualties. It was feared by many planners that such use would probably quickly have escalated into large-scale nuclear war. This situation was particularly exacerbated by the fact that such weapons at sea were not constrained by the safeguards provided by the Permissive Action Link attached to U.S. Air Force and Army nuclear weapons. It is unknown if the navies of the other nuclear powers yet today deploy tactical nuclear weapons at sea.\n\nThe 2018 US Nuclear Posture Review emphasised the need for the US to have sub-strategic nuclear weapons as additional layers for its nuclear deterrence.\n\nNuclear terrorism by non-state organizations or actors (even individuals) is a largely unknown and understudied factor in nuclear deterrence thinking, as states possessing nuclear weapons are susceptible to retaliation in kind, while sub- or trans-state actors may be less so. The collapse of the Soviet Union has given rise to the possibility that former Soviet nuclear weapons might become available on the black market (so-called 'loose nukes').\n\nA number of other concerns have been expressed about the security of nuclear weapons in newer nuclear powers with relatively less stable governments, such as Pakistan, but in each case, the fears have been addressed to some extent by statements and evidence provided by those nations, as well as cooperative programs between nations. Worry remains, however, in many circles that a relative decrease in security of nuclear weapons has emerged in recent years, and that terrorists or others may attempt to exert control over (or use) nuclear weapons, militarily applicable technology, or nuclear materials and fuel.\n\nAnother possible nuclear terrorism threat are devices designed to disperse radioactive materials over a large area using conventional explosives, called dirty bombs. The detonation of a \"dirty bomb\" would not cause a nuclear explosion, nor would it release enough radiation to kill or injure a large number of people. However, it could cause severe disruption and require potentially very costly decontamination procedures and increased spending on security measures.\n\nThe predictions of the effects of a major countervalue nuclear exchange include millions of city dweller deaths within a short period of time. Some 1980s predictions had gone further and argued that a full-scale nuclear war could eventually bring about the extinction of the human race. Such predictions, sometimes but not always based on total war with nuclear arsenals at Cold War highs, received contemporary criticism. On the other hand, some 1980s governmental predictions, such as FEMA's CRP-2B and NATO's \"Carte Blanche,\" have received criticism from groups like the Federation of American Scientists for being overly optimistic. CRP-2B, for instance, infamously predicted that 80% of Americans would survive a nuclear exchange with the Soviet Union, a figure that neglected nuclear war's impacts on healthcare infrastructure, the food supply, and the ecosystem and assumed that all major cities could be successfully evacuated within 3–5 days. A number of Cold War publications advocated preparations that could purportedly enable a large proportion of civilians to survive even a total nuclear war. Among the most famous of these is Nuclear War Survival Skills.\n\nTo avoid injury and death from a nuclear weapons heat flash and blast effects, the two most far ranging prompt effects of nuclear weapons, schoolchildren were taught to duck and cover by the early Cold War film of the same name. Such advice is once again being given in case of nuclear terrorist attacks.\n\nPrussian blue, or \"Radiogardase\", is stockpiled in the US, along with potassium iodide and DPTA as pharmaceuticals useful in treating internal exposure to harmful radioisotopes in fallout.\n\nPublications on adapting to a changing diet and supplying nutritional food sources following a nuclear war, with particular focus on agricultural radioecology, include \"Nutrition in the postattack environment\" by the RAND corporation.\n\nThe British government developed a public alert system for use during nuclear attack with the expectation of a four-minute warning before detonation. The United States expected a warning time of anywhere from half an hour (for land-based missiles) to less than three minutes (for submarine-based weapons). Many countries maintain plans for continuity of government and continuity of operations following a nuclear attack or similar disasters. These range from a designated survivor, intended to ensure survival of some form of government leadership, to the Soviet Dead Hand system, which allows for retaliation even if all Soviet leadership were destroyed. Nuclear submarines are given letters of last resort: orders on what action to take in the event that an enemy nuclear strike has destroyed the government.\n\nA number of other countries around the world have taken significant efforts to maximize their survival prospects in the event of large calamities, both natural and manmade. For example, metro stations in Pyongyang, North Korea, were constructed below ground, and were designed to serve as nuclear shelters in the event of war, with each station entrance built with thick steel blast doors. An example of privately funded fallout shelters is the Ark Two Shelter in Ontario, Canada, and autonomous shelters have been constructed with an emphasis on post-war networking and reconstruction.\nIn Switzerland, the majority of homes have an underground blast and fallout shelter. The country has an overcapacity of such shelters and can accommodate slightly more than the nation's population size.\n\nWhile the nuclear fallout shelters described above are the ideal long term protection methods against dangerous radiation exposure in the event of a nuclear catastrophe, it is also necessary to have mobile protection equipment for medical and security personnel to safely assist in containment, evacuation, and many other necessary public safety objectives which ensue as a result of nuclear detonation. There are many basic shielding strategies used to protect against the deposition of radio active material from external radiation environments. Respirators which protect against internal deposition are used to prevent the inhalation and ingestion of radioactive material and dermal protective equipment which is used to protect against the deposition of material on external structures like skin, hair, and clothing. While these protection strategies do slightly reduce the exposure, they provide almost no protection from externally penetrating gamma radiation, which is the cause of Acute Radiation Syndrome and can be extremely lethal in high dosages. Naturally, shielding the entire body from high energy gamma radiation is optimal, but the required mass to provide adequate attenuation makes functional movement nearly impossible.\n\nRecent scientific studies have shown the feasibility of partial body shielding as a viable protection strategy against externally penetrating gamma radiation. The concept is based in providing sufficient attenuation to only the most radio-sensitive organs and tissues in efforts to defer the onset of Acute Radiation Syndrome, the most immediate threat to humans from high doses of gamma radiation. Acute Radiation Syndrome is a result of irreversible bone marrow damage from high energy radiation exposure. Due to the regenerative property of hematopoietic stem cells found in bone marrow, it is only necessary to protect enough bone marrow to repopulate the exposed areas of the body with the shielded supply. Because 50% of the body's supply of bone marrow is stored in the pelvic region which is also in close proximity to other radio-sensitive organs in the abdomen, the lower torso is a logical choice as the primary target for protection.\n\nThis research allows for the development of relatively lightweight mobile radiation protection equipment which can provide life saving protection from intense radioactive environments without hindering functional mobility. This technology has wide-ranging military, emergency personnel, private sector, and civilian application as the radiation risks of nuclear energy, warfare, and terrorism around the world continue to grow. One example of such technology is the 360 Gamma, a radiation protection belt designed on the principles of bone marrow shielding.\n\nMore information on bone marrow shielding can be found in the Health Physics Radiation Safety Journal article Selective Shielding of Bone Marrow: An Approach to Protecting Humans from External Gamma Radiation, or in the Organisation for Economic Co-operation and Development (OECD) and the Nuclear Energy Agency (NEA)'s 2015 report: Occupational Radiation Protection in Severe Accident Management.\n\nNuclear warfare and weapons are staple elements of speculative fiction.\n\n\n"}
{"id": "22831", "url": "https://en.wikipedia.org/wiki?curid=22831", "title": "Oliver Heaviside", "text": "Oliver Heaviside\n\nOliver Heaviside FRS (; 18 May 1850 – 3 February 1925) was an English self-taught electrical engineer, mathematician, and physicist who adapted complex numbers to the study of electrical circuits, invented mathematical techniques for the solution of differential equations (equivalent to Laplace transforms), reformulated Maxwell's field equations in terms of electric and magnetic forces and energy flux, and independently co-formulated vector analysis. Although at odds with the scientific establishment for most of his life, Heaviside changed the face of telecommunications, mathematics, and science for years to come.\n\nHeaviside was born in Camden Town, London, at 55 Kings Street (now Plender Street). He was a short and red-headed child, and suffered from scarlet fever when young, which left him with a hearing impairment. A small legacy enabled the family to move to a better part of Camden when he was thirteen and he was sent to Camden House Grammar School. He was a good student, placed fifth out of five hundred students in 1865, but his parents could not keep him at school after he was 16, so he continued studying for a year by himself and had no further formal education.\n\nHeaviside's uncle by marriage was Sir Charles Wheatstone (1802–1875), an internationally celebrated expert in telegraphy and electromagnetism, and the original co-inventor of the first commercially successful telegraph in the mid-1830s. Wheatstone took a strong interest in his nephew's education and in 1867 sent him north to work with his own, older brother Arthur, who was managing one of Wheatstone's telegraph companies in Newcastle-upon-Tyne.\n\nTwo years later he took a job as a telegraph operator with the Danish Great Northern Telegraph Company laying a cable from Newcastle to Denmark using British contractors. He soon became an electrician. Heaviside continued to study while working, and by the age of 22 he published an article in the prestigious \"Philosophical Magazine\" on 'The Best Arrangement of Wheatstone's Bridge for measuring a Given Resistance with a Given Galvanometer and Battery' which received positive comments from physicists who had unsuccessfully tried to solve this algebraic problem, including Sir William Thomson, to whom he gave a copy of the paper, and James Clerk Maxwell. When he published an article on the duplex method of using a telegraph cable, he poked fun at R. S. Culley, the engineer in chief of the Post Office telegraph system, who had been dismissing duplex as impractical. Later in 1873 his application to join the Society of Telegraph Engineers was turned down with the comment that \"they didn't want telegraph clerks\". This riled Heaviside, who asked Thomson to sponsor him, and along with support of the society's president he was admitted \"despite the P.O. snobs\".\n\nIn 1873 Heaviside had encountered Maxwell's newly published, and later famous, two-volume \"Treatise on Electricity and Magnetism\". In his old age Heaviside recalled:\nUndertaking research from home, he helped develop transmission line theory (also known as the \"telegrapher's equations\"). Heaviside showed mathematically that uniformly distributed inductance in a telegraph line would diminish both attenuation and distortion, and that, if the inductance were great enough and the insulation resistance not too high, the circuit would be distortionless while currents of all frequencies would have equal speeds of propagation. Heaviside's equations helped further the implementation of the telegraph.\n\nFrom 1882 to 1902, except for three years, he contributed regular articles to the trade paper \"The Electrician\", which wished to improve its standing, for which he was paid £40 per year. This was hardly enough to live on, but his demands were very small and he was doing what he most wanted to. Between 1883 and 1887 these averaged 2–3 articles per month and these articles later formed the bulk of his \"Electromagnetic Theory\" and \"Electrical Papers\".\n\nIn 1880, Heaviside researched the skin effect in telegraph transmission lines. That same year he patented, in England, the coaxial cable. In 1884 he recast Maxwell's mathematical analysis from its original cumbersome form (they had already been recast as quaternions) to its modern vector terminology, thereby reducing twelve of the original twenty equations in twenty unknowns down to the four differential equations in two unknowns we now know as Maxwell's equations. The four re-formulated Maxwell's equations describe the nature of electric charges (both static and moving), magnetic fields, and the relationship between the two, namely electromagnetic fields.\n\nBetween 1880 and 1887, Heaviside developed the operational calculus using \"p\" for the differential operator, (which Boole had previously denoted by \"D\"), giving a method of solving differential equations by direct solution as algebraic equations. This later caused a great deal of controversy, owing to its lack of rigour. He famously said, \"Mathematics is an experimental science, and definitions do not come first, but later on.\" On another occasion he asked somewhat more defensively, \"Shall I refuse my dinner because I do not fully understand the process of digestion?\"\n\nIn 1887, Heaviside worked with his brother Arthur on a paper entitled \"The Bridge System of Telephony\". However the paper was blocked by Arthur's superior, William Henry Preece of the Post Office, because part of the proposal was that loading coils (inductors) should be added to telephone and telegraph lines to increase their self-induction and correct the distortion which they suffered. Preece had recently declared self-inductance to be the great enemy of clear transmission. Heaviside was also convinced that Preece was behind the sacking of the editor of \"The Electrician\" which brought his long-running series of articles to a halt (until 1891). There was a long history of animosity between Preece and Heaviside. Heaviside considered Preece to be mathematically incompetent, an assessment supported by the biographer Paul J. Nahin: \"Preece was a powerful government official, enormously ambitious, and in some remarkable ways, an utter blockhead.\" Preece's motivations in suppressing Heaviside's work were more to do with protecting Preece's own reputation and avoiding having to admit error than any perceived faults in Heaviside's work.\n\nThe importance of Heaviside's work remained undiscovered for some time after publication in \"The Electrician\", and so its rights lay in the public domain. In 1897, AT&T employed one of its own scientists, George A. Campbell, and an external investigator Michael I. Pupin to find some respect in which Heaviside's work was incomplete or incorrect. Campbell and Pupin extended Heaviside's work, and AT&T filed for patents covering not only their research, but also the technical method of constructing the coils previously invented by Heaviside. AT&T later offered Heaviside money in exchange for his rights; it is possible that the Bell engineers' respect for Heaviside influenced this offer. However, Heaviside refused the offer, declining to accept any money unless the company were to give him full recognition. Heaviside was chronically poor, making his refusal of the offer even more striking.\n\nBut this setback had the effect of turning Heaviside's attention towards electromagnetic radiation, and in two papers of 1888 and 1889, he calculated the deformations of electric and magnetic fields surrounding a moving charge, as well as the effects of it entering a denser medium. This included a prediction of what is now known as Cherenkov radiation, and inspired his friend George FitzGerald to suggest what now is known as the Lorentz–FitzGerald contraction.\n\nIn 1889, Heaviside first published a correct derivation of the magnetic force on a moving charged particle, which is now called the Lorentz force.\n\nIn the late 1880s and early 1890s, Heaviside worked on the concept of electromagnetic mass. Heaviside treated this as material mass, capable of producing the same effects. Wilhelm Wien later verified Heaviside's expression (for low velocities).\n\nIn 1891 the British Royal Society recognized Heaviside's contributions to the mathematical description of electromagnetic phenomena by naming him a Fellow of the Royal Society, and the following year devoting more than fifty pages of the \"Philosophical Transactions\" of the Society to his vector methods and electromagnetic theory. In 1905 Heaviside was given an honorary doctorate by the University of Göttingen.\n\nIn 1896, FitzGerald and John Perry obtained a civil list pension of £120 per year for Heaviside, who was now living in Devon, and persuaded him to accept it, after he had rejected other charitable offers from the Royal Society.\n\nIn 1902, Heaviside proposed the existence of what is now known as the Kennelly–Heaviside layer of the ionosphere. Heaviside's proposal included means by which radio signals are transmitted around the Earth's curvature. The existence of the ionosphere was confirmed in 1923. The predictions by Heaviside, combined with Planck's radiation theory, probably discouraged further attempts to detect radio waves from the Sun and other astronomical objects. For whatever reason, there seem to have been no attempts for 30 years, until Jansky's development of radio astronomy in 1932.\n\nIn later years his behavior became quite eccentric. According to associate B. A. Behrend, he became a recluse who was so averse to meeting people that he delivered the manuscripts of his \"Electrician\" papers to a grocery store, where the editors picked them up. Though he had been an active cyclist in his youth, his health seriously declined in his sixth decade. During this time Heaviside would sign letters with the initials \"W.O.R.M.\" after his name. Heaviside also reportedly started painting his fingernails pink and had granite blocks moved into his house for furniture. In 1922, he became the first recipient of the Faraday Medal, which was established that year.\n\nOn Heaviside's religious views, he was a Unitarian, but not a religious one. He was even said to have made fun of people who put their faith in a supreme being.\n\nHeaviside died on 3 February 1925, at Torquay in Devon by falling from a ladder, and is buried near the eastern corner of Paignton cemetery. He is buried with his father, Thomas Heaviside (1813–1896) and his mother, Rachel Elizabeth Heaviside. The gravestone was cleaned thanks to an anonymous donor sometime in 2005. Most of his recognition was gained posthumously.\n\nIn July 2014, academics at Newcastle University, UK and the Newcastle Electromagnetics Interest Group founded the Heaviside Memorial Project in a bid to fully restore the monument through public subscription. The restored memorial was ceremonially unveiled on 30 August 2014 by Alan Heather, a distant relative of Heaviside. The unveiling was attended by the Mayor of Torbay, the MP for Torbay, an ex-curator of the Science Museum (representing the Institution of Engineering and Technology), the Chairman of the Torbay Civic Society, and delegates from Newcastle University.\n\nA collection of Heaviside's notebooks, papers, correspondence, notes and annotated pamphlets on telegraphy is held at the Institution of Engineering and Technology (IET) Archive Centre.\n\nHeaviside did much to develop and advocate vector methods and the vector calculus. Maxwell's formulation of electromagnetism consisted of 20 equations in 20 variables. Heaviside employed the curl and divergence operators of the vector calculus to reformulate 12 of these 20 equations into four equations in four variables (B, E, J, and ρ), the form by which they have been known ever since (see Maxwell's equations). Less well known is that Heaviside's equations and Maxwell's are not exactly the same, and in fact it is easier to modify the latter to make them compatible with quantum physics. The possibility of gravitational waves was also discussed by Heaviside using the analogy between the inverse-square law in gravitation and electricity \n\nHe invented the Heaviside step function using it to calculate the current when an electric circuit is switched on. He was the first to use the unit impulse function now usually known as the Dirac delta function. He invented his operational calculus method for solving linear differential equations. This resembles the currently used Laplace transform method based on the \"Bromwich integral\" named after Bromwich who devised a rigorous mathematical justification for Heaviside's operator method using contour integration. Heaviside was familiar with the Laplace transform method but considered his own method more direct.\n\nHeaviside developed the transmission line theory (also known as the \"telegrapher's equations\"), which had the effect of increasing the transmission rate over transatlantic cables by a factor of ten. It originally took ten minutes to transmit each character, and this immediately improved to one character per minute. Closely related to this was his discovery that telephone transmission could be greatly improved by placing electrical inductance in series with the cable. Heaviside also independently discovered the Poynting vector.\n\nHeaviside advanced the idea that the Earth's uppermost atmosphere contained an ionized layer known as the ionosphere; in this regard, he predicted the existence of what later was dubbed the Kennelly–Heaviside layer. In 1947 Edward Victor Appleton received the Nobel Prize in Physics for proving that this layer really existed.\n\nHeaviside coined the following terms of art in electromagnetic theory:\n\n\n\nSorted by date.\n\n"}
{"id": "22304", "url": "https://en.wikipedia.org/wiki?curid=22304", "title": "Osmium", "text": "Osmium\n\nOsmium (from Greek ὀσμή \"osme\", \"smell\") is a chemical element with symbol Os and atomic number 76. It is a hard, brittle, bluish-white transition metal in the platinum group that is found as a trace element in alloys, mostly in platinum ores. Osmium is the densest naturally occurring element, with an experimentally measured (using x-ray crystallography) density of . Manufacturers use its alloys with platinum, iridium, and other platinum-group metals to make fountain pen nib tipping, electrical contacts, and in other applications that require extreme durability and hardness. The element's abundance in the Earth's crust is among the rarest.\n\nOsmium has a blue-gray tint and is the densest stable element, approximately twice the density of lead and slightly denser than iridium. Calculations of density from the X-ray diffraction data may produce the most reliable data for these elements, giving a value of for iridium versus for osmium. \n\nOsmium is a hard but brittle metal that remains lustrous even at high temperatures. It has a very low compressibility. Correspondingly, its bulk modulus is extremely high, reported between and , which rivals that of diamond (). The hardness of osmium is moderately high at . Because of its hardness, brittleness, low vapor pressure (the lowest of the platinum-group metals), and very high melting point (the fourth highest of all elements, after only carbon, tungsten, and rhenium), solid osmium is difficult to machine, form or work.\n\nOsmium forms compounds with oxidation states ranging from −2 to +8. The most common oxidation states are +2, +3, +4, and +8. The +8 oxidation state is notable for being the highest attained by any chemical element aside from iridium's +9 and is encountered only in xenon, ruthenium, hassium, and iridium. The oxidation states −1 and −2 represented by the two reactive compounds and are used in the synthesis of osmium cluster compounds.\n\nThe most common compound exhibiting the +8 oxidation state is osmium tetroxide. This toxic compound is formed when powdered osmium is exposed to air. It is a very volatile, water-soluble, pale yellow, crystalline solid with a strong smell. Osmium powder has the characteristic smell of osmium tetroxide. Osmium tetroxide forms red osmates upon reaction with a base. With ammonia, it forms the nitrido-osmates . Osmium tetroxide boils at 130 °C and is a powerful oxidizing agent. By contrast, osmium dioxide (OsO) is black, non-volatile, and much less reactive and toxic.\n\nOnly two osmium compounds have major applications: osmium tetroxide for staining tissue in electron microscopy and for the oxidation of alkenes in organic synthesis, and the non-volatile osmates for organic oxidation reactions.\n\nOsmium pentafluoride (OsF) is known, but osmium trifluoride (OsF) has not yet been synthesized. The lower oxidation states are stabilized by the larger halogens, so that the trichloride, tribromide, triiodide, and even diiodide are known. The oxidation state +1 is known only for osmium iodide (OsI), whereas several carbonyl complexes of osmium, such as triosmium dodecacarbonyl (), represent oxidation state 0.\n\nIn general, the lower oxidation states of osmium are stabilized by ligands that are good σ-donors (such as amines) and π-acceptors (heterocycles containing nitrogen). The higher oxidation states are stabilized by strong σ- and π-donors, such as and .\n\nDespite its broad range of compounds in numerous oxidation states, osmium in bulk form at ordinary temperatures and pressures resists attack by all acids and alkalis, including aqua regia.\n\nOsmium has seven naturally occurring isotopes, six of which are stable: , , , , , and (most abundant) . undergoes alpha decay with such a long half-life years, approximately times the age of the universe, that for practical purposes it can be considered stable. Alpha decay is predicted for all seven naturally occurring isotopes, but it has been observed only for , presumably due to very long half-lives. It is predicted that and can undergo double beta decay but this radioactivity has not been observed yet.\n\nOsmium was discovered in 1803 by Smithson Tennant and William Hyde Wollaston in London, England. The discovery of osmium is intertwined with that of platinum and the other metals of the platinum group. Platinum reached Europe as \"platina\" (\"small silver\"), first encountered in the late 17th century in silver mines around the Chocó Department, in Colombia. The discovery that this metal was not an alloy, but a distinct new element, was published in 1748.\nChemists who studied platinum dissolved it in aqua regia (a mixture of hydrochloric and nitric acids) to create soluble salts. They always observed a small amount of a dark, insoluble residue. Joseph Louis Proust thought that the residue was graphite. Victor Collet-Descotils, Antoine François, comte de Fourcroy, and Louis Nicolas Vauquelin also observed iridium in the black platinum residue in 1803, but did not obtain enough material for further experiments. Later the two French chemists Antoine-François Fourcroy and Nicolas-Louis Vauquelin identified a metal in a platinum residue they called ‘\"ptène\"’.\n\nIn 1803, Smithson Tennant analyzed the insoluble residue and concluded that it must contain a new metal. Vauquelin treated the powder alternately with alkali and acids and obtained a volatile new oxide, which he believed was of this new metal—which he named \"ptene\", from the Greek word (ptènos) for winged. However, Tennant, who had the advantage of a much larger amount of residue, continued his research and identified two previously undiscovered elements in the black residue, iridium and osmium. He obtained a yellow solution (probably of \"cis\"–<nowiki>[</nowiki>Os(OH)O<nowiki>]</nowiki>) by reactions with sodium hydroxide at red heat. After acidification he was able to distill the formed OsO. He named it osmium after Greek \"osme\" meaning \"a smell\", because of the ashy and smoky smell of the volatile osmium tetroxide. Discovery of the new elements was documented in a letter to the Royal Society on June 21, 1804.\n\nUranium and osmium were early successful catalysts in the Haber process, the nitrogen fixation reaction of nitrogen and hydrogen to produce ammonia, giving enough yield to make the process economically successful. At the time, a group at BASF led by Carl Bosch bought most of the world's supply of osmium to use as a catalyst. Shortly thereafter, in 1908, cheaper catalysts based on iron and iron oxides were introduced by the same group for the first pilot plants, removing the need for the expensive and rare osmium.\n\nNowadays osmium is obtained primarily from the processing of platinum and nickel ores.\n\nOsmium is one of the even-numbered elements, which puts it in the upper half of elements commonly found in space. It is, however, the least abundant stable element in Earth's crust, with an average mass fraction of 50 parts per trillion in the continental crust.\n\nOsmium is found in nature as an uncombined element or in natural alloys; especially the iridium–osmium alloys, osmiridium (osmium rich), and iridosmium (iridium rich). In nickel and copper deposits, the platinum group metals occur as sulfides (i.e., (Pt,Pd)S)), tellurides (e.g., PtBiTe), antimonides (e.g., PdSb), and arsenides (e.g., PtAs); in all these compounds platinum is exchanged by a small amount of iridium and osmium. As with all of the platinum group metals, osmium can be found naturally in alloys with nickel or copper.\n\nWithin Earth's crust, osmium, like iridium, is found at highest concentrations in three types of geologic structure: igneous deposits (crustal intrusions from below), impact craters, and deposits reworked from one of the former structures. The largest known primary reserves are in the Bushveld Igneous Complex in South Africa, though the large copper–nickel deposits near Norilsk in Russia, and the Sudbury Basin in Canada are also significant sources of osmium. Smaller reserves can be found in the United States. The alluvial deposits used by pre-Columbian people in the Chocó Department, Colombia are still a source for platinum group metals. The second large alluvial deposit was found in the Ural Mountains, Russia, which is still mined.\n\nOsmium is obtained commercially as a by-product from nickel and copper mining and processing. During electrorefining of copper and nickel, noble metals such as silver, gold and the platinum group metals, together with non-metallic elements such as selenium and tellurium settle to the bottom of the cell as \"anode mud\", which forms the starting material for their extraction. Separating the metals requires that they first be brought into solution. Several methods can achieve this, depending on the separation process and the composition of the mixture. Two representative methods are fusion with sodium peroxide followed by dissolution in aqua regia, and dissolution in a mixture of chlorine with hydrochloric acid. Osmium, ruthenium, rhodium and iridium can be separated from platinum, gold and base metals by their insolubility in aqua regia, leaving a solid residue. Rhodium can be separated from the residue by treatment with molten sodium bisulfate. The insoluble residue, containing Ru, Os and Ir, is treated with sodium oxide, in which Ir is insoluble, producing water-soluble Ru and Os salts. After oxidation to the volatile oxides, is separated from by precipitation of (NH)RuCl with ammonium chloride.\n\nAfter it is dissolved, osmium is separated from the other platinum group metals by distillation or extraction with organic solvents of the volatile osmium tetroxide. The first method is similar to the procedure used by Tennant and Wollaston. Both methods are suitable for industrial scale production. In either case, the product is reduced using hydrogen, yielding the metal as a powder or sponge that can be treated using powder metallurgy techniques.\n\nNeither the producers nor the United States Geological Survey published any production amounts for osmium. In 1971, estimations of the United States production of osmium as a byproduct of copper refining was 2000 troy ounces (62 kg). In 2017, the estimated US import of osmium for consumption was 90 kg.\n\nBecause of the volatility and extreme toxicity of its oxide, osmium is rarely used in its pure state, but is instead often alloyed with other metals for high-wear applications. Osmium alloys such as osmiridium are very hard and, along with other platinum-group metals, are used in the tips of fountain pens, instrument pivots, and electrical contacts, as they can resist wear from frequent operation. They were also used for the tips of phonograph styli during the late 78 rpm and early \"LP\" and \"45\" record era, circa 1945 to 1955. Osmium-alloy tips were significantly more durable than steel and chromium needle points, but wore out far more rapidly than competing, and costlier, sapphire and diamond tips, so they were discontinued.\n\nOsmium tetroxide has been used in fingerprint detection and in staining fatty tissue for optical and electron microscopy. As a strong oxidant, it cross-links lipids mainly by reacting with unsaturated carbon–carbon bonds and thereby both fixes biological membranes in place in tissue samples and simultaneously stains them. Because osmium atoms are extremely electron-dense, osmium staining greatly enhances image contrast in transmission electron microscopy (TEM) studies of biological materials. Those carbon materials have otherwise very weak TEM contrast (see image). Another osmium compound, osmium ferricyanide (OsFeCN), exhibits similar fixing and staining action.\n\nThe tetroxide and its derivative potassium osmate are important oxidants in organic synthesis. For the Sharpless asymmetric dihydroxylation, which uses osmate for the conversion of a double bond into a vicinal diol, Karl Barry Sharpless was awarded the Nobel Prize in Chemistry in 2001. OsO is very expensive for this use, so KMnO is often used instead, even though the yields are less for this cheaper chemical reagent.\n\nIn 1898 an Austrian chemist Auer von Welsbach developed the Oslamp with a filament made of osmium, which he introduced commercially in 1902. After only a few years, osmium was replaced by the more stable metal tungsten. Tungsten has the highest melting point among all metals, and its use in light bulbs increases the luminous efficacy and life of incandescent lamps.\n\nThe light bulb manufacturer Osram (founded in 1906, when three German companies, Auer-Gesellschaft, AEG and Siemens & Halske, combined their lamp production facilities) derived its name from the elements of osmium and Wolfram (the latter is German for tungsten).\n\nLike palladium, powdered osmium effectively absorbs hydrogen atoms. This could make osmium a potential candidate for a metal-hydride battery electrode. However, osmium is expensive and would react with potassium hydroxide, the most common battery electrolyte.\n\nOsmium has high reflectivity in the ultraviolet range of the electromagnetic spectrum; for example, at 600 Å osmium has a reflectivity twice that of gold. This high reflectivity is desirable in space-based UV spectrometers, which have reduced mirror sizes due to space limitations. Osmium-coated mirrors were flown in several space missions aboard the Space Shuttle, but it soon became clear that the oxygen radicals in the low Earth orbit are abundant enough to significantly deteriorate the osmium layer.\n\nThe only known clinical use of osmium is synovectomy in arthritic patients in Scandinavia. It involves the local administration of osmium tetroxide (OsO), which is a highly toxic compound. The lack of reports of long-term side effects suggest that osmium itself can be biocompatible, though this depends on the osmium compound administered. In 2011, osmium(VI) and osmium(II) compounds were reported to show anticancer activity \"in vivo\", it indicated a promising future for using osmium compounds as anticancer drugs.\n\nMetallic osmium is harmless but finely divided metallic osmium is pyrophoric and reacts with oxygen at room temperature, forming volatile osmium tetroxide. Some osmium compounds are also converted to the tetroxide if oxygen is present. This makes osmium tetroxide the main source of contact with the environment.\n\nOsmium tetroxide is highly volatile and penetrates skin readily, and is very toxic by inhalation, ingestion, and skin contact. Airborne low concentrations of osmium tetroxide vapor can cause lung congestion and skin or eye damage, and should therefore be used in a fume hood. Osmium tetroxide is rapidly reduced to relatively inert compounds by e.g. ascorbic acid or polyunsaturated vegetable oils (such as corn oil).\n\nOsmium is usually sold as a minimum 99.9% pure powder. Like other precious metals, it is measured by troy weight and by grams. Its price in 2018 is about $1,000 per troy oz, depending on the quantity, its purity and its supplier.\n\n"}
{"id": "39660799", "url": "https://en.wikipedia.org/wiki?curid=39660799", "title": "Pandora's Promise", "text": "Pandora's Promise\n\nPandora's Promise is a 2013 documentary film about the nuclear power debate, directed by Robert Stone. Its central argument is that nuclear power, which still faces historical opposition from environmentalists, is a relatively safe and clean energy source which can help mitigate the serious problem of anthropogenic global warming.\n\nThe title is derived from the ancient Greek myth of Pandora, who released numerous evils into the world, yet as the movie's tagline recalls: \"At the bottom of the box she found hope.\"\n\nThe movie features several notable individuals who were once vehemently opposed to nuclear power but who now speak in favor of it, including Stewart Brand, Gwyneth Cravens, Mark Lynas, Richard Rhodes and Michael Shellenberger.\n\nAnti-nuclear advocate Helen Caldicott is questioned and along with Harvey Wasserman appears briefly at the beginning. Historic clips of Jane Fonda, Ralph Nader and Amory Lovins speaking are used.\n\nRichard Branson is credited as an executive producer, as are Paul and Jody Allen, whose production company, Vulcan Productions, helped provide financial support. A total of $1.2 million (US) was raised to finance the film, \"particularly through Impact Partners, which provides documentary financing from individual investors. Mr. Stone said the money came mainly from wealthy “tech heads” who have worked in Silicon Valley.\"\n\nTopics mentioned or discussed in the film include:\n\n\nStock footage and movie clips are used throughout Pandora's Promise to enhance the narrative. Scenes are shown of a No Nukes concert (1979), Margaret Thatcher addressing the United Nations General Assembly (1989), and from the drafting of the Kyoto Protocol (1997). Movie/TV sources include: A Is for Atom (1953), Our Friend the Atom (1957), The China Syndrome (1979), and The Simpsons (1991).\n\nThe film poster depicts a piece of metallic enriched uranium (\"actual size\" as printed) with the caption \"What if this could power your entire life?\"\n\nIn January 2013 it was shown at the 2013 Sundance Film Festival. In March 2013 it was shown at the True/False Film Festival. In June 2013 it won the Sheffield Doc/Fest Green Award for best addressing environmental challenges.\n\nIn April 2013, it was announced that CNN Films had obtained the US television rights to Pandora's Promise; it was shown on CNN in the US on November 7, 2013 and seen by 345,000 viewers. It was released on Region 2 DVD in December 2013. A DVD via Alive Mind Cinema was announced for 24 June 2014. It is also available via various digital distribution services.\n\nReactions to the film have been mixed, if not polarized; e.g.:\n\n\n\n"}
{"id": "9020147", "url": "https://en.wikipedia.org/wiki?curid=9020147", "title": "Passeree", "text": "Passeree\n\nA passeree is an obsolete unit of mass used in Bengal that approximately equalled 4.677  kg (10.3 lb). Five seers made up one passeree. After metrication in the mid-20th century, the unit became obsolete.\n\n"}
{"id": "11141813", "url": "https://en.wikipedia.org/wiki?curid=11141813", "title": "Peter L. Hagelstein", "text": "Peter L. Hagelstein\n\nPeter L. Hagelstein is a principal investigator in the Research Laboratory of Electronics (RLE) and an associate professor at the Massachusetts Institute of Technology (MIT). He received a bachelor of science and a master of science degree in 1976, then a Doctor of Philosophy degree in electrical engineering in 1981, from MIT. He was a staff member of Lawrence Livermore National Laboratory from 1981 to 1985 before joining the MIT faculty in the Department of Electrical Engineering and Computer Science in 1986. \n\nHagelstein's early work focused on extreme ultraviolet and soft X-ray lasers, relativistic atomic structure and electron collision physics, autoionization and dielectronic recombination processes, plasma population kinetics, radiation transport and large scale physics simulation. He received the Ernest Orlando Lawrence Award in 1984 for his innovation and creativity in X-ray laser physics. While working in the Lawrence Livermore National Laboratory he pioneered the work that later produced the first X-ray laser, which would later become important for the US Strategic Defense Initiative, popularly referred to as the \"Star Wars\" program.\n\nIn 1989 he started investigating cold fusion (also called \"low-energy nuclear reactions\") with the hope of making a breakthrough similar to the X-ray laser. In the period between 1989 and 2004, the field became discredited in the eyes of many scientists. Due to his involvement, as of 2004 he has not achieved full professorship and he has lost his own laboratory.\n\nHis recent efforts have included the invention of semiconductor technology that could allow efficient, affordable production of electricity from a variety of energy sources, as well as continuing investigations of low-energy nuclear reactions. Hagelstein is the co-author of a new textbook, \"Introductory Applied Quantum and Statistical Mechanics\", and chaired the Tenth International Conference on Cold Fusion in 2003.\n\n"}
{"id": "77385", "url": "https://en.wikipedia.org/wiki?curid=77385", "title": "Polyethylene", "text": "Polyethylene\n\nPolyethylene or polythene (abbreviated PE; IUPAC name polyethene or poly(methylene)) is the most common plastic. , over 100 million tonnes of polyethylene resins are produced annually, accounting for 34% of the total plastics market. Its primary use is in packaging (plastic bags, plastic films, geomembranes, containers including bottles, etc.). Many kinds of polyethylene are known, with most having the chemical formula (CH). PE is usually a mixture of similar polymers of ethylene with various values of \"n\". Polyethylene is a thermoplastic; however, it can become a thermoset plastic when modified (such as cross-linked polyethylene).\n\nPolyethylene was first synthesized by the German chemist Hans von Pechmann, who prepared it by accident in 1898 while investigating diazomethane. When his colleagues Eugen Bamberger and Friedrich Tschirner characterized the white, waxy substance that he had created, they recognized that it contained long –CH– chains and termed it \"polymethylene\".\nThe first industrially practical polyethylene synthesis (diazomethane is a notoriously unstable substance that is generally avoided in industrial application) was discovered in 1933 by Eric Fawcett and Reginald Gibson, again by accident, at the Imperial Chemical Industries (ICI) works in Northwich, England. Upon applying extremely high pressure (several hundred atmospheres) to a mixture of ethylene and benzaldehyde they again produced a white, waxy material. Because the reaction had been initiated by trace oxygen contamination in their apparatus, the experiment was, at first, difficult to reproduce. It was not until 1935 that another ICI chemist, Michael Perrin, developed this accident into a reproducible high-pressure synthesis for polyethylene that became the basis for industrial LDPE production beginning in 1939. Because polyethylene was found to have very low-loss properties at very high frequency radio waves, commercial distribution in Britain was suspended on the outbreak of World War II, secrecy imposed, and the new process was used to produce insulation for UHF and SHF coaxial cables of radar sets. During World War II, further research was done on the ICI process and in 1944 Bakelite Corporation at Sabine, Texas, and Du Pont at Charleston, West Virginia, began large-scale commercial production under license from ICI.\n\nThe breakthrough landmark in the commercial production of polyethylene began with the development of catalyst that promoted the polymerization at mild temperatures and pressures. The first of these was a chromium trioxide–based catalyst discovered in 1951 by Robert Banks and J. Paul Hogan at Phillips Petroleum. In 1953 the German chemist Karl Ziegler developed a catalytic system based on titanium halides and organoaluminium compounds that worked at even milder conditions than the Phillips catalyst. The Phillips catalyst is less expensive and easier to work with, however, and both methods are heavily used industrially. By the end of the 1950s both the Phillips- and Ziegler-type catalysts were being used for HDPE production. In the 1970s, the Ziegler system was improved by the incorporation of magnesium chloride. Catalytic systems based on soluble catalysts, the metallocenes, were reported in 1976 by Walter Kaminsky and Hansjörg Sinn. The Ziegler- and metallocene-based catalysts families have proven to be very flexible at copolymerizing ethylene with other olefins and have become the basis for the wide range of polyethylene resins available today, including very low density polyethylene and linear low-density polyethylene. Such resins, in the form of UHMWPE fibers, have (as of 2005) begun to replace aramids in many high-strength applications.\n\nThe properties of polyethylene can be divided into mechanical, chemical, electrical, optical, and thermal properties.\n\nPolyethylene is of low strength, hardness and rigidity, but has a high ductility and impact strength as well as low friction. It shows strong creep under persistent force, which can be reduced by addition of short fibers. It feels waxy when touched.\n\nThe commercial applicability of polyethylene is limited by its comparably low melting point. For common commercial grades of medium- and high-density polyethylene the melting point is typically in the range . The melting point for average, commercial, low-density polyethylene is typically . These temperatures vary strongly with the type of polyethylene.\n\nPolyethylene consists of nonpolar, saturated, high molecular weight hydrocarbons. Therefore, its chemical behavior is similar to paraffin. The individual macromolecules are not covalently linked. Because of their symmetric molecular structure, they tend to crystallize; overall polyethylene is partially crystalline. Higher crystallinity increases density and mechanical and chemical stability.\n\nMost LDPE, MDPE, and HDPE grades have excellent chemical resistance, meaning they are not attacked by strong acids or strong bases, and are resistant to gentle oxidants and reducing agents. Crystalline samples do not dissolve at room temperature. Polyethylene (other than cross-linked polyethylene) usually can be dissolved at elevated temperatures in aromatic hydrocarbons such as toluene or xylene, or in chlorinated solvents such as trichloroethane or trichlorobenzene.\n\nPolyethylene absorbs almost no water. The gas and water vapour permeability (only polar gases) is lower than for most plastics; oxygen, carbon dioxide and flavorings on the other hand can pass it easily.\n\nPE can become brittle when exposed to sunlight, carbon black is usually used as a UV stabilizer.\n\nPolyethylene burns slowly with a blue flame having a yellow tip and gives off an odour of paraffin (similar to candle flame). The material continues burning on removal of the flame source and produces a drip.\n\nPolyethylene cannot be imprinted or bonded with adheasives without pretreatment. High strength joins are readily achieved with plastic welding.\n\nPolyethylene is a good electrical insulator. It offers good electrical treeing resistance; however, it becomes easily electrostatically charged (which can be reduced by additions of graphite, carbon black or antistatic agents).\n\nDepending on thermal history and film thickness PE can vary between almost clear (transparent), milky-opaque (translucent) or opaque. LDPE thereby owns the greatest, LLDPE slightly less and HDPE the least transparency. Transparency is reduced by crystallites if they are larger than the wavelength of visible light.\n\nThe ingredient or monomer is ethylene (IUPAC name ethene), a gaseous hydrocarbon with the formula CH, which can be viewed as a pair of methylene groups (––) connected to each other. Typical specifications are <5 ppm for water, oxygen, and other alkenes. Acceptable contaminants include N, ethane (common precursor to ethylene), and methane. Ethylene is usually produced from petrochemical sources, but also is generated by dehydration of ethanol.\n\nEthylene is a rather stable molecule that polymerizes only upon contact with catalysts. The conversion is highly exothermic. Coordination polymerization is the most pervasive technology, which means that metal chlorides or metal oxides are used. The most common catalysts consist of titanium(III) chloride, the so-called Ziegler-Natta catalysts. Another common catalyst is the Phillips catalyst, prepared by depositing chromium(VI) oxide on silica. Polyethylene can be produced through radical polymerization, but this route has only limited utility and typically requires high-pressure apparatus.\n\nCommonly used methods for joining polyethylene parts together include:\n\n\nAdhesives and solvents are rarely used because polyethylene is nonpolar and has a high resistance to solvents. Pressure-sensitive adhesives (PSA) are feasible if the surface chemistry or charge is modified with plasma activation, flame treatment, or corona treatment.\n\nPolyethylene is classified by its density and branching. Its mechanical properties depend significantly on variables such as the extent and type of branching, the crystal structure, and the molecular weight. There are several types of polyethylene:\n\n\nWith regard to sold volumes, the most important polyethylene grades are HDPE, LLDPE, and LDPE.\n\nUHMWPE is polyethylene with a molecular weight numbering in the millions, usually between 3.5 and 7.5 million amu. The high molecular weight makes it a very tough material, but results in less efficient packing of the chains into the crystal structure as evidenced by densities of less than high-density polyethylene (for example, 0.930–0.935 g/cm). UHMWPE can be made through any catalyst technology, although Ziegler catalysts are most common. Because of its outstanding toughness and its cut, wear, and excellent chemical resistance, UHMWPE is used in a diverse range of applications. These include can- and bottle-handling machine parts, moving parts on weaving machines, bearings, gears, artificial joints, edge protection on ice rinks, steel cable replacements on ships, and butchers' chopping boards. It is commonly used for the construction of articular portions of implants used for hip and knee replacements. As fiber, it competes with aramid in bulletproof vests.\n\nHDPE is defined by a density of greater or equal to 0.941 g/cm. HDPE has a low degree of branching. The mostly linear molecules pack together well, so intermolecular forces are stronger than in highly branched polymers. HDPE can be produced by chromium/silica catalysts, Ziegler-Natta catalysts or metallocene catalysts; by choosing catalysts and reaction conditions, the small amount of branching that does occur can be controlled. These catalysts prefer the formation of free radicals at the ends of the growing polyethylene molecules. They cause new ethylene monomers to add to the ends of the molecules, rather than along the middle, causing the growth of a linear chain.\n\nHDPE has high tensile strength. It is used in products and packaging such as milk jugs, detergent bottles, butter tubs, garbage containers, and water pipes. One-third of all toys are manufactured from HDPE. In 2007, the global HDPE consumption reached a volume of more than 30 million tons.\n\nPEX is a medium- to high-density polyethylene containing cross-link bonds introduced into the polymer structure, changing the thermoplastic into a thermoset. The high-temperature properties of the polymer are improved, its flow is reduced, and its chemical resistance is enhanced. PEX is used in some potable-water plumbing systems because tubes made of the material can be expanded to fit over a metal nipple and it will slowly return to its original shape, forming a permanent, water-tight connection.\n\nMDPE is defined by a density range of 0.926–0.940 g/cm. MDPE can be produced by chromium/silica catalysts, Ziegler-Natta catalysts, or metallocene catalysts. MDPE has good shock and drop resistance properties. It also is less notch-sensitive than HDPE; stress-cracking resistance is better than HDPE. MDPE is typically used in gas pipes and fittings, sacks, shrink film, packaging film, carrier bags, and screw closures.\n\nLLDPE is defined by a density range of 0.915–0.925 g/cm. LLDPE is a substantially linear polymer with significant numbers of short branches, commonly made by copolymerization of ethylene with short-chain alpha-olefins (for example, 1-butene, 1-hexene, and 1-octene). LLDPE has higher tensile strength than LDPE, and it exhibits higher impact and puncture resistance than LDPE. Lower thickness (gauge) films can be blown, compared with LDPE, with better environmental stress-cracking resistance, but is not as easy to process. LLDPE is used in packaging, particularly film for bags and sheets. Lower thickness may be used compared to LDPE. It is used for cable coverings, toys, lids, buckets, containers, and pipe. While other applications are available, LLDPE is used predominantly in film applications due to its toughness, flexibility, and relative transparency. Product examples range from agricultural films, Saran wrap, and bubble wrap, to multilayer and composite films. In 2013, the world LLDPE market reached a volume of US$40 billion.\n\nLDPE is defined by a density range of 0.910–0.940 g/cm. LDPE has a high degree of short- and long-chain branching, which means that the chains do not pack into the crystal structure as well. It has, therefore, less strong intermolecular forces as the instantaneous-dipole induced-dipole attraction is less. This results in a lower tensile strength and increased ductility. LDPE is created by free-radical polymerization. The high degree of branching with long chains gives molten LDPE unique and desirable flow properties. LDPE is used for both rigid containers and plastic film applications such as plastic bags and film wrap. In 2013, the global LDPE market had a volume of almost US$33 billion.\n\nThe radical polymerization process used to make LDPE does not include a catalyst that \"supervises\" the radical sites on the growing PE chains. (In HDPE synthesis, the radical sites are at the ends of the PE chains, because the catalyst stabilizes their formation at the ends.) Secondary radicals (in the middle of a chain) are more stable than primary radicals (at the end of the chain), and tertiary radicals (at a branch point) are more stable yet. Each time an ethylene monomer is added, it creates a primary radical, but often these will rearrange to form more stable secondary or tertiary radicals. Addition of ethylene monomers to the secondary or tertiary sites creates branching.\n\nVLDPE is defined by a density range of 0.880–0.915 g/cm. VLDPE is a substantially linear polymer with high levels of short-chain branches, commonly made by copolymerization of ethylene with short-chain alpha-olefins (for example, 1-butene, 1-hexene and 1-octene). VLDPE is most commonly produced using metallocene catalysts due to the greater co-monomer incorporation exhibited by these catalysts. VLDPEs are used for hose and tubing, ice and frozen food bags, food packaging and stretch wrap as well as impact modifiers when blended with other polymers.\n\nRecently, much research activity has focused on the nature and distribution of long chain branches in polyethylene. In HDPE, a relatively small number of these branches, perhaps one in 100 or 1,000 branches per backbone carbon, can significantly affect the rheological properties of the polymer.\n\nIn addition to copolymerization with alpha-olefins, ethylene can also be the copolymerized with a wide range of other monomers and ionic composition that creates ionized free radicals. Common examples include vinyl acetate (the resulting product is ethylene-vinyl acetate copolymer, or EVA, widely used in athletic-shoe sole foams) and a variety of acrylates. Applications of acrylic copolymer include packaging and sporting goods, and superplasticizer, used for cement production.\n\nThe diverse material behavior of different types of polyethylene can be explained by their molecular structure. Molecular weight and crystallinity are having the biggest impact, the crystallinity in turn depends on molecular weight and degree of branching. The less the polymer chains are branched, and the smaller the molecular weight, the higher the crystallinity of polyethylene. The crystallinity is between 35% (PE-LD/PE-LLD) and 80% (PE-HD). Within crystallites polyethylene has a density of 1.0 g·cm, in the amorphous regions of 0.86 g·cm. Thus, an almost linear relationship exists between density and crystallinity.\n\nThe degree of branching of the different types of polyethylene can be schematically represented as follows:\n\nThe properties of polyethylene are highly dependent on type and number of chain branches. The chain branches in turn depend on the process used: either the high-pressure process (only PE-LD) or the low-pressure process (all other PE grades). Low-density polyethylene is produced by the high-pressure process by radical polymerization, thereby numerous short chain branches as well as long chain branches are formed. Short chain branches are formed by intramolecular chain transfer reactions, they are always butyl or ethyl chain branches because the reaction proceeds after the following mechanism:\n\nPolyethylene is produced from ethylene, and although ethylene can be produced from renewable resources, it is mainly obtained from petroleum or natural gas.\n\nMoreover, the widespread usage of polyethylene poses difficulties for waste management if it is not recycled. Polyethylene is not readily biodegradable, and thus accumulates in landfills. Incineration may result in harmful gaseous emissions.\n\nIn Japan, getting rid of plastics in an environmentally friendly way was the major problem discussed until the Fukushima disaster in 2011 became a larger issue. It was listed as a $90 billion market for solutions. Since 2008, Japan has rapidly increased the recycling of plastics, but still has a large amount of plastic wrapping which goes to waste.\n\nIn 2010, a Japanese researcher, Akinori Ito, released the prototype of a machine which creates oil from polyethylene using a small, self-contained vapor distillation process.\n\nPolyethylene is not readily biodegradable, and thus accumulates in landfills. However, there are a number of species of bacteria and animals that are able to degrade polyethylene.\n\nIn May 2008, Daniel Burd, a 16-year-old Canadian, won the Canada-Wide Science Fair in Ottawa after discovering that \"Pseudomonas fluorescens\", with the help of \"Sphingomonas\", can degrade over 40% of the weight of plastic bags in less than three months.\n\nThe thermophilic bacterium \"Brevibacillus borstelensis\" (strain 707) was isolated from a soil sample and found to use low-density polyethylene as a sole carbon source when incubated together at 50 °C. Biodegradation increased with time exposed to ultraviolet radiation.\n\n\"Acinetobacter\" sp. 351 can degrade lower molecular-weight PE oligomers. When PE is subjected to thermo- and photo-oxidization, products including alkanes, alkenes, ketones, aldehydes, alcohols, carboxylic acid, keto-acids, dicarboxylic acids, lactones, and esters are released.\n\nIn 2014, a Chinese researcher discovered that Indian mealmoth larvae could metabolize polyethylene from observing that plastic bags at his home had small holes in them. Deducing that the hungry larvae must have digested the plastic somehow, he and his team analyzed their gut bacteria and found a few that could use plastic as their only carbon source. Not only could the bacteria from the guts of the \"Plodia interpunctella\" moth larvae metabolize polyethylene, they degraded it significantly, dropping its tensile strength by 50%, its mass by 10% and the molecular weights of its polymeric chains by 13%.\n\nIn 2017, researchers reported that the caterpillar of \"Galleria mellonella\" eats plastic garbage such as polyethylene.\n\nPolyethylene may either be modified in the polymerization by polar or non-polar comonomers or after polymerization through polymer-analogous reactions. Common polymer-analogous reactions are in case of polyethylene crosslinking, chlorination and sulfochlorination.\n\nIn the low pressure process α-olefins (e.g. 1-butene or 1-hexene) may be added, which are incorporated in the polymer chain during polymerization. These copolymers introduce short side chains, thus crystallinity and density are reduced. As explained above, mechanical and thermal properties are changed thereby. In particular, PE-LLD is produced this way.\n\nMetallocene polyethylene (PE-M) is prepared by means of metallocene catalysts, usually including copolymers (z. B. ethene / hexene). Metallocene polyethylene has a relatively narrow molecular weight distribution, exceptionally high toughness, excellent optical properties and a uniform comonomer content. Because of the narrow molecular weight distribution it behaves less pseudoplastic (especially under larger shear rates). Metallocene polyethylene has a low proportion of low molecular weight (extractable) components and a low welding and sealing temperature. Thus, it is particularly suitable for the food industry.\n\nPolyethylene with multimodal molecular weight distribution consists of several polymer fractions, which are homogeneously mixed. Such polyethylene types offer extremely high stiffness, toughness, strength, stress crack resistance and an increased crack propagation resistance. They consist of equal proportions higher and lower molecular polymer fractions. The lower molecular weight units crystallize easier and relax faster. The higher molecular weight fractions form linking molecules between crystallites, thereby increasing toughness and stress crack resistance. Polyethylene with multimodal molecular weight distribution can be prepared either in two-stage reactors, by catalysts with two different active centers on a carrier or by blending in extruders.\n\nCyclic olefin copolymers are prepared by copolymerization of ethene and cycloolefins (usually norbornene) produced by using metallocene catalysts. The resulting polymers are amorphous polymers and particularly transparent and heat resistant.\n\nThe basic compounds used as polar comonomers are vinyl alcohol (Ethenol, an unsaturated alcohol), acrylic acid (propenoic acid, an unsaturated acid) and esters containing one of the two compounds.\n\nEthylene/vinyl alcohol copolymer (EVOH) is (formally) a copolymer of PE and vinyl alcohol (ethenol), which is prepared by (partial) hydrolysis of ethylene-vinyl acetate copolymer (as vinyl alcohol itself is not stable). However, typically EVOH has a higher comonomer content than the VAC commonly used.\n\nEVOH is used in multilayer films for packaging as a barrier layer (barrier plastic). As EVOH is hygroscopic (water-attracting), it absorbs water from the environment, whereby it loses its barrier effect. Therefore, it must be used as a core layer surrounded by other plastics (like LDPE, PP, PA or PET). EVOH is also used as a coating agent against corrosion at street lights, traffic light poles and noise protection walls.\n\nCopolymer of ethylene and unsaturated carboxylic acids (such as acrylic acid) are characterized by good adhesion to different materials, by resistance to stress cracking and high flexibility. However, they are more sensitive to heat and oxidation than ethylene homopolymers. Ethylene/acrylic acid copolymers are used as adhesion promoters.\n\nIf salts of an unsaturated carboxylic acid are present in the polymer, thermo-reversible ion networks are formed, they are called ionomers. Ionomers are highly transparent thermoplastics which are characterized by high adhesion to metals, high abrasion resistance and high water absorption.\n\nIf unsaturated esters are copolymerized with ethylene, either the alcohol moiety may be in the polymer backbone (as it is the case in ethylene-vinyl acetate copolymer) or of the acid moiety (e. g. in ethylene-ethyl acrylate copolymer). Ethylene-vinyl acetate copolymers are prepared similarly to LD-PE by high pressure polymerization. The proportion of comonomer has a decisive influence on the behaviour of the polymer.\n\nThe density decreases up to a comonomer share of 10% because of the disturbed crystal formation. With higher proportions it approaches to the one of polyvinyl acetate (1.17 g/cm). Due to decreasing crystallinity ethylene vinyl acetate copolymers are getting softer with increasing comonomer content. The polar side groups change the chemical properties significantly (compared to polyethylene): weather resistance, adhesiveness and weldability rise with comonomer content, while the chemical resistance decreases. Also mechanical properties are changed: stress cracking resistance and toughness in the cold rise, whereas yield stress and heat resistance decrease. With a very high proportion of comonomers (about 50%) rubbery thermoplastics are produced (thermoplastic elastomers).\n\nEthylene-ethyl acrylate copolymers behave similarly to ethylene-vinyl acetate copolymers.\n\nA basic distinction is made between peroxide crosslinking (PE-Xa), silane crosslinking (PE-Xb), electron beam crosslinking (PE-Xc) and azo crosslinking (PE-Xd).\n\n\nChlorinated Polyethylene (PE-C) is an inexpensive material having a chlorine content from 34 to 44%. It is used in blends with PVC because the soft, rubbery chloropolyethylene is embedded in the PVC matrix, thereby increasing the impact resistance. In addition, it also increases the weather resistance. Furthermore, it is used for softening PVC foils, without risking the migrate of plasticizers. Chlorinated polyethylene can be crosslinked peroxidically to form an elastomer which is used in cable and rubber industry. When chlorinated polyethylene is added to other polyolefins, it reduces the flammability.\n\nChlorosulfonated PE (CSM) is used as starting material for ozone resistant synthetic rubber.\n\nBraskem and Toyota Tsusho Corporation started joint marketing activities to produce polyethylene from sugarcane. Braskem will build a new facility at their existing industrial unit in Triunfo, Rio Grande do Sul, Brazil with an annual production capacity of , and will produce high-density and low-density polyethylene from bioethanol derived from sugarcane.\n\nPolyethylene can also be made from other feedstocks, including wheat grain and sugar beet. These developments are using renewable resources rather than fossil fuel, although the issue of plastic source is currently negligible in the wake of plastic waste and in particular polyethylene waste as shown above.\n\nThe name polyethylene comes from the ingredient and not the resulting chemical compound, which contains no double bonds. The scientific name \"polyethene\" is systematically derived from the scientific name of the monomer. The alkene monomer converts to a long, sometimes \"very\" long, alkane in the polymerization process. In certain circumstances it is useful to use a structure-based nomenclature; in such cases IUPAC recommends poly(methylene) (poly(methanediyl) is a non-preferred alternative). The difference in names between the two systems is due to the \"opening up\" of the monomer's double bond upon polymerization. The name is abbreviated to \"PE\". In a similar manner polypropylene and polystyrene are shortened to PP and PS, respectively. In the United Kingdom and India the polymer is commonly called \"polythene\", from the ICI trade name, although this is not recognized scientifically.\n\n\n"}
{"id": "24188671", "url": "https://en.wikipedia.org/wiki?curid=24188671", "title": "Premium efficiency", "text": "Premium efficiency\n\nAs part of a concerted effort worldwide to reduce energy consumption, CO emissions and the impact of industrial operations on the environment, various regulatory authorities in many countries have introduced, or are planning, legislation to encourage the manufacture and use of higher efficiency motors. This article looks at the development of the premium efficiency standard (IE3) and premium efficiency motors (PEMs) and associated environmental, legal and energy-related topics.\n\nThe oil crisis and the worldwide need for more power and consequently more power stations have raised energy conservation awareness.\n\nIn 1992 the U.S. Congress, as part of the Energy Policy Act (EPAct) set minimum efficiency levels (see Table B-1) for electric motors.\nIn 1998 the European Committee of Manufacturers of Electrical Machines and Power systems (CEMEP) issued a voluntary agreement of motor manufacturers on efficiency classification, with three efficiency classes:\n\nThe term “Premium efficiency” as discussed here relates to a class of motor efficiency. It is thought necessary to introduce this term associated with motors because of forthcoming legislation in the EU, USA and other countries regarding the future mandatory use of premium-efficiency squirrel cage induction type motors in defined equipment.\n\nSeveral statements have been made regarding motor use and the advantages of using premium-efficiency or higher efficiency motors. These include:\n\nBased on U.S. Department of Energy data, it is estimated that the National Electrical Manufacturers Association (NEMA) premium-efficiency motor program would save 5.8 terawatts of electricity and prevent the release of nearly 80 million metric tons of carbon into the atmosphere over the next ten years. This is equivalent to keeping 16 million cars off the road.\n\nRoughly 30 million new electric motors are sold each year for industrial purposes. Some 300 million motors are in use in industry, infrastructure and large buildings. These electric motors are responsible for 40% of global electricity used to drive pumps, fans, compressors and other mechanical traction equipment. Motor technology has evolved over the last few decades. Superior so-called \"premium\" products are now available, ready to change the market toward energy efficiency and to contribute in lowering greenhouse gas emissions worldwide.\n\nWith using best practice energy efficiency of electrical motors can be improved by 20% to 30% on average. Most improvements have a pay back time of 1 to below 3 years. This in addition means a big potential impact on reduction of global greenhouse gas emissions.\n\nElectric motor systems consume large amounts of electrical energy and can provide an opportunity for significant energy savings. Energy represents more than 97 percent of total motor operating costs over the motor’s lifetime. However, the purchase of a new motor often tends to be driven by the price, not the electricity it will consume. Even a small improvement in efficiency could result in significant energy and cost savings. Investing a little more money upfront for a more efficient motor is often paid back in energy savings. Improving energy efficiency reduces greenhouse gas emissions that contribute to climate change.\n\nThe efficiency of an electric motor is defined as the ratio of usable shaft power to electric input power.\n\n   = motor efficiency [%]\n\n  = shaft Power [kW] ( in USA HP with factor 1.34)\n\n      = electrical input from power supply [kW]\n\nThe shaft power is transferred to the machine driven; the electric input power is what is metered and charged for. Loss in motor efficiency is determined by the difference between the input power and output or shaft power.\n\nMotor energy loss is mainly heat caused by many factors, including loss from the coil winding (resistance), loss in the rotor bars and slip rings, loss due to magnetising of the iron core, and loss from friction of bearings.\n\nOn December 19, 2007, President Bush signed the Energy Independence and Security Act of 2007 (EISA) into law (Public Law 140-110). The National Electrical Manufacturers Association (NEMA) actively participated in crafting major provisions on EISA. A critical provision that NEMA focused on was increased motor efficiency levels. The Motor Generator section of NEMA joined forces with the American Council for an Energy Efficient Economy to draft and recommend new motor efficiency regulations covering both general purpose and some categories of definite and special purpose electrical motors.\n\nThe Motor and Generator Section of NEMA established the NEMA Premium program for four main reasons:\n\nVisit NEMA Premium Motors for more information.\n\nA summary of EISA standards for motors:\n\nIn June, 2005, the European Union enacted a Directive on establishing a framework for setting Eco-design requirements (such as energy efficiency requirements) for all energy using products in the residential, tertiary and industrial sectors. Coherent EU-wide rules for eco-design will ensure that disparities among national regulations do not become obstacles to intra-EU trade. The directive does not introduce directly binding requirements for specific products, but does define conditions and criteria for setting requirements regarding environmentally relevant product characteristics (such as energy consumption) and allows them to be improved quickly and efficiently. It will be followed by implementing measures which will establish the eco-design requirements. In principle, the Directive applies to all energy using products (except transport vehicles) and covers all energy sources.\n\nIEC 60034-30 specifies electrical efficiency classes for single-speed, three-phase, 50 Hz and 60 Hz, cage-induction motors that:\n\nThe table below shows the IEC 60034-30 (2008) efficiency classes and comparable efficiency levels.\n\nThe standard also reserves an IE4 class (Super Premium Efficiency) for the future. The following motors are excluded from the new efficiency standard:\n\"Graph is showing as example 50 Hz, 4-pole motors\"\n\nFor 60 Hz operation, the IE2 and IE3 minimum full-load efficiency values are virtually identical to the North American National Electrical Manufacturers Association (NEMA) Energy Efficient and Premium Efficiency motor standards, respectively. (NEMA does specify different full-load efficiency values for motors with Totally Enclosed Fan-Cooled and Open Drip-proof enclosures and from 200HP IEC IE3 efficiency is slightly higher than NEMA Premium Efficiency). The IEC minimum full-load efficiency standards are higher for 60 Hz motors than for 50 Hz motors. This is because as long as the motor torque is constant, IR or winding resistance losses are the same at 50 Hz and 60 Hz. The motor output power, however, increases linearly with speed, increasing by 20% when the frequency is increased from 50 Hz to 60 Hz. In general, the 60 Hz efficiency is about 2.5% to 0.5% greater than the 50 Hz values. The efficiency gain is greater for smaller motor power ratings.\n\nTo show compliance with these new efficiency standards, motors must be tested in accordance with the newly adopted IEC 60034-2–1 testing protocol. This procedure provides test results that are largely compatible with those obtained by the North American IEEE 112B and CSA 390 test methods. The new standard also requires that the motor efficiency class and nominal motor efficiency be labeled on the motor nameplate and given in product literature and motor catalogues in the following format:\n\nIE3 94.5%\n\nOn 22 July 2009, Commission Regulation (EC) No 640/2009 implementing Directive 2005/32/EC states that in the EU, with the exception of some special applications, motors shall not be less efficient than the IE3 efficiency level as from 1 January 2015.\n\nIn detail:\n\nEC 60034-30, IE3 Premium Efficiency (%) is presented in the table.\n\nIE3 Premium Efficiency\n\nDesign of Premium Efficiency Motors needs special knowledge, experience and test facilities, equipped with precision instrumentation. The task of design is, to get the efficiency up by minimizing and balancing the single losses, especially those created in the stator coils, the stator iron (magnetizing) and the losses within the rotor by slip. In comparison to standard (e.g. IE1) electrical motors, more iron and copper material are used. IE3 motors are heavier and physically bigger than IE1 motors.\n\nTypically use of higher slot fill in the copper winding, use of thinner laminations of improved steel properties, reducing the air gap, better design of cooling fan, use of special and improved bearings etc. can ensure higher efficiency in the motors.\n\nThe high electrical conductivity of copper versus other metallic conductors enhances the electrical energy efficiency of motors. Increasing the mass and cross section of conductors in a coil increases the electrical energy efficiency of the motor. Where energy savings are prime design objectives, induction motors can be designed to meet and exceed National Electrical Manufacturers Association (NEMA) premium efficiency standards.\n\nThe U.S. Senate Energy and Natural Resources Committee adopted a NEMA-advocated provision that created a premium energy-efficient motor rebate program, also known as a “crush for credit” program, according to the National Electrical Manufacturers Association (NEMA). The program provided a $25 per horsepower rebate and a $5 per horsepower rebate for the disposal of the old motor. The latter program was needed to offset the cost difference between new, more expensive, efficient motors and the lesser cost to repair the older, more inefficient motors, NEMA says. This program allowed the federal government to spend $350 million in incentives for the widespread adoption of NEMA Premium motors.\n\nThe \"Crush for Credit\" provision contained in the Senate's version of the \"Energy Policy and Conservation Act\" (EPCA) ran for five years, and included the following proposed funding:\n\nWithin the EU, various Capital Allowance Schemes encourage companies to purchase equipment incorporating premium-efficiency motors. For example, in the UK, the Enhanced Capital Allowances Scheme provides a tax incentive to businesses that invest in equipment that meets published energy-saving criteria. The Energy Technology List (ETL) details the criteria for each type of technology, and lists those products in each category that meet them. It is managed by the Carbon Trust, on behalf of the Government, and has two parts:\n\nThe ETPL also contains details of the maximum claim values for qualifying products which comprise a component in a larger piece of plant and machinery, which does not itself qualify for ECAs.\n\nKey Features of the ECA scheme are\n\nA similar scheme in Ireland, Accelerated Capital Allowance (ACA) run by Sustainable Energy Ireland (SEI) lets a company cut its taxable income by 100% of the capital cost of eligible energy-efficient equipment in the first year of purchase. This compares to just 12.5% for ineligible plant and machinery.\n\nWith the existing Capital Allowances tax structure, when money is spent on “capital equipment” companies can deduct the cost of this equipment from their profits proportionally over a period of 8 years, i.e. the annual taxable profit is only reduced by 1/8 of the total equipment cost.\n\nWith new ACA, when money is spent on “Eligible energy efficient capital equipment”, the company can deduct the full cost of this equipment from their profits in the year of purchase, i.e. the taxable profit in year one is reduced by the full cost of the equipment.\n\n"}
{"id": "1532080", "url": "https://en.wikipedia.org/wiki?curid=1532080", "title": "Recycling symbol", "text": "Recycling symbol\n\nThe universal recycling symbol ( or in Unicode) is internationally recognized.\n\nWorldwide attention to environmental issues led to the first Earth Day in 1970. Container Corporation of America, a large producer of recycled paperboard, sponsored a contest for art and design students at high schools and colleges across the country to raise awareness of environmental issues. It was won by Gary Anderson, then a 23-year-old college student at the University of Southern California, whose entry was the image now known as the universal recycling symbol. The symbol is not trademarked and is in the public domain. The public-domain status of the symbol has been challenged, but this challenge was unsuccessful owing to the wide use of the symbol. However, the universal symbol may have been inspired by similar existing recycling symbols, such as one featuring two arrows chasing each other in a circle that Volkswagen stamped in the early 1960s into some automobile parts it remanufactured.\n\nThe recycling symbol is in the public domain, and is not a trademark. The Container Corporation of America originally applied for a trademark on the design, but the application was challenged, and the corporation decided to abandon the claim. As such, anyone may use or modify the recycling symbol, royalty-free.\n\nThough use of the symbol is regulated by law in some countries, countless variants of it exist worldwide. Anderson's original proposal had the arrows form a triangle standing on its tip—upside down compared with the versions most commonly seen today—but the CCA, in adopting Anderson's design, rotated it 60° to stand on its base instead.\n\nBoth Anderson's proposal and CCA's designs form a Möbius strip with \"one\" half-twist by having two of the arrows fold over each other, and one fold under, thereby canceling out one of the other folds. However, most variants of the symbol used today have all the arrows folding over themselves, producing a Möbius strip with \"three\" half-twists. Existing single half-twist variants of the logo do not generally agree on which of the arrows is the one to fold underneath. The logo is usually displayed with the arrows circulating clockwise, but the underlying Möbius strip exists in two topologically distinct mirror-image forms of opposite handedness.\n\nThe American Paper Institute originally promoted four different variants of the recycling symbol for different purposes. The plain Möbius loop, either white with an outline or solid black, was to be used to indicate that a product was \"recyclable\". The other two variants had the Möbius loop inside a circle—either white on black or black on white—and were meant for products \"made of recycled materials\", with the white-on-black version to be used for 100% recycled fiber, and the black-on-white version for products containing both recycled and unrecycled fiber. For example, a paper envelope might have both the first and last of these four symbols, to indicate that it was recyclable, and made from both recycled and unrecycled fibers.\n\nIn addition to the resin identification codes 1–7 in the triangular recycling symbol, Unicode lists the following recycling symbols:\n\nAn ISO/IEC working group has researched and documented some of the variations of the recycling logo currently in use, and has made recommendations for adding some more of them to the Unicode standard.\n\nWith the rapid expansion of materials converted to printer filament for 3-D printing using recyclebot technology, a large expansion of resin identification codes has been proposed.\n\nIn 1988, the American Society of the Plastics Industry (SPI) developed the resin identification code which is used to indicate the predominant plastic material used in the manufacture of the product or packaging. Their purpose is to assist recyclers with sorting the collected materials, but they do not necessarily mean that the product/packaging can be recycled either through domestic curbside collection or industrial collections. The SPI symbols are loosely based on the Möbius loop symbol, but feature simpler bent (rather than folded over) arrows that can be embossed on plastic surfaces without loss of detail. The arrows are formed into a flat, two-dimensional triangle rather than the pseudo-three-dimensional triangle used in the original recycling logo.\n\nThe different resin identification codes can be represented by Unicode icons ♳ (U+2673), ♴ (U+2674), ♵ (U+2675), ♶ (U+2676), ♷ (U+2677), ♸ (U+2678), ♹ (U+2679), and ♺ (U+267A).\n\nRecycling codes extend these numbers above 7 to include various non-plastic materials, including metals, glass, paper, and batteries of various types. \n\n♾, an infinity sign (∞) inside a circle, represents the permanent paper symbol, used in packaging and publishing to signify the use of durable acid-free paper. In some ways, this logo expresses the \"opposite\" intention from the recycle logo, in that the acid-free paper is intended to last indefinitely, rather than being recycled. Nevertheless, acid-free paper does not usually contain toxic materials (although certain inks do), so it is easily recycled or composted.\n\nA satirical version of the classic recycling logo also exists, in which the three arrows are twisted from a circular pattern to pointing radially outward, thus symbolizing wasteful one-time usage rather than environmentally friendly recycling. This message is reinforced by the circular inscription, \"THIS PROJECT WAS ENVIRONMENTALLY UNFRIENDLY\", surrounding the modified logo. The satirical logo appears in the 1998 catalog of an installation art work in Bayonne, New Jersey, in which the artist Steven Pippin modified a row of glass-doored washing machines in a laundromat to operate as giant cameras. The cameras were used to take sequential photographs in the manner of pioneering stop motion photographer Eadweard Muybridge. The front-loading washing machines were then used to develop and process the 24 inch (61 cm) diameter circular film negatives.\n\n\n"}
{"id": "10608375", "url": "https://en.wikipedia.org/wiki?curid=10608375", "title": "Reveal (carpentry)", "text": "Reveal (carpentry)\n\nIn carpentry, a reveal is a feature resembling a rabbet, but constructed of separate pieces of wood. A reveal may typically be seen at the edge of a door or window, where the face molding is set back, often by a distance from 3/16\" (5 mm) to 1/2\" (12 mm,) to \"reveal\" the edge of the casing plank.\n\nA \"tight reveal\" is where the distance to the edge of the casing is kept as small as possible, to give a smoother, more consistent look, often thought to be more contemporary. This is often achieved on a cabinet door by notching out the area of the door where the hinge mounts.\n\n"}
{"id": "3628399", "url": "https://en.wikipedia.org/wiki?curid=3628399", "title": "Scalar–tensor theory", "text": "Scalar–tensor theory\n\nIn theoretical physics, a scalar–tensor theory is a theory that includes both a scalar field and a tensor field to represent a certain interaction. For example, the Brans–Dicke theory of gravitation uses both a scalar field and a tensor field to mediate the gravitational interaction.\n\nModern physics tries to derive all physical theories from as few principles as possible. In this way, Newtonian mechanics as well as quantum mechanics are derived from Hamilton's \"principle of least action\". In this approach, the behavior of a system is not described via forces, but by functions which describe the energy of the system. Most important are the energetic quantities known as the Hamiltonian function and the Lagrangian function. Their derivatives in space are known as Hamiltonian density and the Lagrangian density. Going to these quantities leads to the field theories.\n\nModern physics uses field theories to explain reality. These fields can be scalar, vectorial or tensorial. An example of a scalar field is the temperature field. An example of a vector field is the wind velocity field. An example of a tensor field is the stress tensor field in a stressed body, used in continuum mechanics.\n\nIn physics, forces (as vectorial quantities) are given as the derivative (gradient) of scalar quantities named potentials. In classical physics before Einstein, gravitation was given in the same way, as consequence of a gravitational force (vectorial), given through a scalar potential field, dependent of the mass of the particles. Thus, Newtonian gravity is called a scalar theory. The gravitational force is dependent of the distance \"r\" of the massive objects to each other (more exactly, their centre of mass). Mass is a parameter and space and time are unchangeable.\n\nEinstein's theory of gravity, the General Relativity (GR) is of another nature. It unifies space and time in a 4-dimensional \"manifold\" called space-time. In GR there is no gravitational force, instead, the actions we ascribed to being a force are the consequence of the local curvature of space-time. That curvature is defined mathematically by the so-called metric, which is a function of the total energy, including mass, in the area. The derivative of the metric is a function that approximates the classical Newtonian force in most cases. The metric is a tensorial quantity of degree 2 (it can be given as a 4x4 matrix, an object carrying 2 indices).\n\nAnother possibility to explain gravitation in this context is by using both tensor (of degree n>1) and scalar fields, i.e. so that gravitation is given neither solely through a scalar field nor solely through a metric. These are scalar–tensor theories of gravitation.\n\nThe field theoretical start of General Relativity is given through the Lagrange density. It is a scalar and gauge invariant (look at gauge theories) quantity dependent on the curvature scalar R. This Lagrangian, following Hamilton's principle, leads to the field equations of Hilbert and Einstein. If in the Lagrangian the curvature (or a quantity related to it) is multiplied with a square scalar field, field theories of scalar–tensor theories of gravitation are obtained. In them, the gravitational constant of Newton is no longer a real constant but a quantity dependent of the scalar field.\n\nAn action of such a gravitational scalar–tensor theory can be written as follows:\n\nwhere formula_2 is the metric determinant, formula_3 is the Ricci scalar constructed from the metric formula_4, formula_5 is a coupling constant with the dimensions formula_6, formula_7 is the scalar-field potential, formula_8 is the material Lagrangian and formula_9 represents the non-gravitational fields. Here, the Brans–Dicke parameter formula_10 has been generalized to a function. Although formula_5 is often written as being formula_12, one has to keep in mind that the fundamental constant formula_13 there, is not the constant of gravitation that can be measured with, for instance, Cavendish type experiments. Indeed, the empirical gravitational constant is generally no longer a constant in scalar–tensor theories, but a function of the scalar field formula_14. The metric and scalar-field equations respectively write:\n\nand\nAlso, the theory satisfies the following conservation equation, implying that test-particles follow space-time geodesics such as in general relativity:\nwhere formula_18 is the stress-energy tensor defined as\n\nDeveloping perturbatively the theory defined by the previous action around a Minkowskian background, and assuming non-relativistic gravitational sources, the first order gives the Newtonian approximation of the theory. In this approximation, and for a theory without potential, the metric writes\nwith formula_21 satisfying the following usual Poisson equation at the lowest order of the approximation:\n\nwhere formula_23 is the density of the gravitational source and formula_24 (the subscript formula_25 indicates that the corresponding value is taken at present cosmological time and location). Therefore, the empirical gravitational constant is a function of the present value of the scalar-field background formula_26 and therefore theoretically depends on time and location. However, no deviation from the constancy of the Newtonian gravitational constant has been measured, implying that the scalar-field background formula_26 is pretty stable over time. Such a stability is not theoretically generally expected but can be theoretically explained by several mechanisms.\n\nDeveloping the theory at the next level leads to the so-called first post-Newtonian order. For a theory without potential and in a system of coordinates respecting the weak isotropy condition (i.e., formula_28), the metric takes the following form:\nwith\n\nwhere formula_34 is a function depending on the coordinate gauge\n\nIt corresponds to the remaining diffeomorphism degree of freedom that is not fixed by the weak isotropy condition. The sources are defined as\n\nthe so-called post-Newtonian parameters are\n\nand finally the empirical gravitational constant formula_38 is given by\n\nwhere formula_13 is the (true) constant that appears in the coupling constant formula_5 defined previously.\n\nCurrent observations indicate that formula_42, which means that formula_43. Although explaining such a value in the context of the original Brans–Dicke theory is impossible, Damour and Nordtvedt found that the field equations of the general theory often lead to an evolution of the function formula_10 toward infinity during the evolution of the universe. Hence, according to them, the current high value of the function formula_10 could be a simple consequence of the evolution of the universe.\n\nThe best current constraint on the post-Newtonian parameter formula_46 comes from Mercury's perihelion shift and is formula_47.\n\nBoth constraints show that while the theory is still a potential candidate to replace general relativity, the scalar field must be very weakly coupled in order to explain current observations.\n\nGeneralized scalar-tensor theories have also been proposed as explanation for the accelerated expansion of the universe but the measurement of the speed of gravity with the gravitational wave event GW170817 has ruled this out.\n\nAfter the postulation of the General Relativity of Einstein and Hilbert, Theodor Kaluza and Oskar Klein proposed in 1917 a generalization in a 5-dimensional manifold: Kaluza–Klein theory. This theory possesses a 5-dimensional metric (with a \"compactified and constant 5th metric component, dependent on the \"gauge potential\") and unifies gravitation and electromagnetism, i.e. there is a geometrization of electrodynamics.\n\nThis theory was modified in 1955 by P. Jordan in his \"Projective Relativity\" theory, in which, following group-theoretical reasonings, Jordan took a functional 5th metric component that lead to a variable gravitational constant \"G\". In his original work, he introduced coupling parameters of the scalar field, to change energy conservation as well, according to the ideas of Dirac.\n\nFollowing the \"Conform Equivalence theory\", multidimensional theories of gravity are \"conform equivalent\" to theories of usual General Relativity in 4 dimensions with an additional scalar field. One case of this is given by Jordan's theory, which, without breaking energy conservation (as it should be valid, following from microwave background radiation being of a black body), is equivalent to the theory of C. Brans and Robert H. Dicke of 1961, so that it is usually spoken about the \"Brans–Dicke theory\". The Brans–Dicke theory follows the idea of modifying Hilbert-Einstein theory to be compatible with Mach's principle. For this, Newton's gravitational constant had to be variable, dependent of the mass distribution in the universe, as a function of a scalar variable, coupled as a field in the Lagrangian. It uses a scalar field of infinite length scale (i.e. long-ranged), so, in the language of Yukawa's theory of nuclear physics, this scalar field is a \"massless field\". This theory becomes Einsteinian for high values for the parameter of the scalar field.\n\nIn 1979, R. Wagoner proposed a generalization of scalar–tensor theories using more than one scalar field coupled to the scalar curvature.\n\nJBD theories although not changing the geodesic equation for test particles, change the motion of composite bodies to a more complex one. The coupling of a universal scalar field directly to the gravitational field gives rise to potentially observable effects for the motion of matter configurations to which gravitational energy contributes significantly. This is known as the \"Dicke–Nordtvedt\" effect, which leads to possible violations of the Strong as well as the Weak Equivalence Principle for extended masses.\n\nJBD-type theories with short-ranged scalar fields use, according to Yukawa's theory, \"massive scalar fields\". The first of this theories was proposed by A. Zee in 1979. He proposed a Broken-Symmetric Theory of Gravitation, combining the idea of Brans and Dicke with the one of Symmetry Breakdown, which is essential within the Standard Model SM of elementary particles, where the so-called Symmetry Breakdown leads to mass generation (as a consequence of particles interacting with the Higgs field). Zee proposed the Higgs field of SM as scalar field and so the Higgs field to generate the gravitational constant.\n\nThe interaction of the Higgs field with the particles that achieve mass through it is short-ranged (i.e. of Yukawa-type) and gravitational-like (one can get a Poisson equation from it), even within SM, so that Zee's idea was taken 1992 for a scalar–tensor theory with Higgs field as scalar field with Higgs mechanism. There, the massive scalar field couples to the masses, which are at the same time the source of the scalar Higgs field, which generates the mass of the elementary particles through Symmetry Breakdown. For vanishing scalar field, this theories usually go through to standard General Relativity and because of the nature of the massive field, it is possible for such theories that the parameter of the scalar field (the coupling constant) does not have to be as high as in standard JBD theories. Though, it is not clear yet which of these models explains better the phenomenology found in nature nor if such scalar fields are really given or necessary in nature. Nevertheless, JBD theories are used to explain inflation (for massless scalar fields then it is spoken of the inflaton field) after the Big Bang as well as the quintessence. Further, they are an option to explain dynamics usually given through the standard cold dark matter models, as well as MOND, Axions (from Breaking of a Symmetry, too), MACHOS...\n\nA generic prediction of all string theory models is that the spin-2 graviton has a spin-0 partner called the dilaton. Hence, string theory predicts that the actual theory of gravity is a scalar–tensor theory rather than general relativity. However, the precise form of such a theory is not currently known because one does not have the mathematical tools in order to address the corresponding non-perturbative calculations. Besides, the precise effective 4-dimensional form of the theory is also confronted to the so-called landscape issue.\n\n\n"}
{"id": "30038658", "url": "https://en.wikipedia.org/wiki?curid=30038658", "title": "Separator (electricity)", "text": "Separator (electricity)\n\nA separator is a permeable membrane placed between a battery's anode and cathode. The main function of a separator is to keep the two electrodes apart to prevent electrical short circuits while also allowing the transport of ionic charge carriers that are needed to close the circuit during the passage of current in an electrochemical cell.\n\nSeparators are critical components in liquid electrolyte batteries. A separator generally consists of a polymeric membrane forming a microporous layer. It must be chemically and electrochemically stable with regard to the electrolyte and electrode materials and mechanically strong enough to withstand the high tension during battery construction. They are important to batteries because their structure and properties considerably affect the battery performance, including the batteries energy and power densities, cycle life, and safety.\n\nUnlike many forms of technology, polymer separators were not developed specifically for batteries. They were instead spin-offs of existing technologies, which is why most are not optimized for the systems they are used in. Even though this may seem unfavorable, most polymer separators can be mass-produced at a low cost, because they are based on existing forms of technologies. Yoshino and co-workers of the Asahi Kasei Corporation first developed them for a prototype of secondary lithium-ion batteries (LIBs) in 1983.\n\nInitially, lithium cobalt oxide was used as the cathode and polyacetylene as the anode. Later in 1985, it was found that using lithium cobalt oxide as the cathode and graphite as the anode produced an excellent secondary battery with enhanced stability, employing the frontier electron theory of Kenichi Fukui This enabled the development of portable devices, such as cell phones and laptops. However, before lithium ion batteries could be mass-produced, safety concerns needed to be addressed such as overheating and over potential. One key to ensuring safety was the separator between the cathode and anode. Yoshino developed a microporous polyethylene membrane separator with a “fuse” function. In the case of abnormal heat generation within the battery cell, the separator provides a shutdown mechanism. The micropores close by melting and the ionic flow terminates. In 2004, a novel electroactive polymer separator with the function of overcharge protection was first proposed by Denton, et al. This kind of separator reversibly switches between insulating and conducting states. Changes in charge potential drive the switch. More recently, separators primarily provide charge transport and electrode separation.\n\nMaterials include nonwoven fibers (cotton, nylon, polyesters, glass), polymer films (polyethylene, polypropylene, poly (tetrafluoroethylene), polyvinyl chloride), ceramic and naturally occurring substances (rubber, asbestos, wood). Some separators employ polymeric materials with pores of less than 20 Å, generally too small for batteries. Both dry and wet processes are used for fabrication.\n\nNonwovens consist of a manufactured sheet, web or mat of directionally or randomly oriented fibers.\n\nSupported liquid membranes consist of a solid and liquid phase contained within a microporous separator.\n\nSome polymer electrolytes form complexes with alkali metal salts, which produce ionic conductors that serve as solid electrolytes.\n\nSolid ion conductors, can serve as both separator and the electrolyte.\n\nSeparators can use a single or multiple layers/sheets of material.\n\nPolymer separators generally are made from microporous polymer membranes. Such membranes are typically fabricated from a variety of inorganic, organic and naturally occurring materials. Pore sizes are typically larger than 50-100 Å. \n\nMembranes synthesized by dry processes are more suitable for higher power density, given their open and uniform pore structure, while those made by wet processes are offer more charge/discharge cycles because of their tortuous and interconnected pore structure. This helps to suppress the conversion of charge carriers into crystals on anodes during fast or low temperature charging.\n\nThe dry process involves extruding, annealing and stretching steps. The final porosity depends on the morphology of the precursor film and the specifics of each step. The extruding step is generally carried out at a temperature higher than the melting point of the polymer resin. This is because the resins are melted to shape them into a uniaxially-oriented tubular film, called a precursor film. The structure and orientation of the precursor film depends on the processing conditions and the resin's characteristics. In the annealing process, the precursor is annealed at a temperature slightly lower than the polymer's melting point. The purpose of this step is to improve the crystalline structure. During stretching, the annealed film is deformed along the machine direction by a cold stretch followed by a hot stretch followed by relaxation. The cold stretch creates the pore structure by stretching the film at a lower temperature with a faster strain rate. The hot stretch increases pore sizes using a higher temperature and a slower strain rate. The relaxation step reduces internal stress within the film.\n\nThe dry process is only suitable for polymers with high crystallinity. These include but are not limited to: semi-crystalline polyolefins, polyoxymethylene, and isotactic poly (4-methyl-1-pentene). One can also use blends of immiscible polymers, in which at least one polymer has a crystalline structure, such as polyethylene-polypropylene, polystyrene-polypropylene, and poly (ethylene terephthalate) - polypropylene blends.\n\nThe wet process consists of mixing, heating, extruding and additive removal steps. The polymer resins are first mixed with, paraffin oil, antioxidant and other additives. The mixture is heated to produce a homogenous solution. The heated solution is pushed through a sheet die to make a gel-like film. The additives are then removed with a volatile solvent to form the microporous result.\n\nThe wet process is suitable for both crystalline and amorphous polymers. Wet process separators often use ultrahigh-molecular-weight polyethylene. The use of these polymers enables the batteries with favorable mechanical properties, while shutting it down when it becomes too hot.\n\nSpecific types of polymers are ideal for the different types of synthesis. Most polymers currently used in battery separators are polyolefin based materials with semi-crystalline structure. Among them, polyethylene, polypropylene, and their blends such as polyethylene-polypropylene are widely used. Recently, graft polymers have been studied in an attempt to improve battery performance, including micro-porous poly(methyl methacrylate)-grafted and siloxane grafted polyethylene separators, which show favorable surface morphology and electrochemical properties compared to conventional polyethylene separators. In addition, polyvinylidene fluoride (PVDF) nanofiber webs can be synthesized as a separator to improve both ion conductivity and dimensional stability Another type of polymer separator, polytriphenylamine (PTPAn)-modified separator, is an electroactive separator with reversible overcharge protection.\n\nAlways the separator is placed between the anode and the cathode. The pores of the separator are filled with the electrolyte and packaged for use.\n\n\nMany Structural defects can form in polymer separators due to temperature changes. These structural defects can result in a thicker separators. Furthermore, there can be intrinsic defects in the polymers themselves, such as polyethylene often begins to deteriorate during the stages of polymerization, transportation, and storage. Additionally, defects such as tears or holes can form during the synthesis of polymer separators. There are also other sources of defects can come from doping the polymer separator. Recently groups have been trying to improve the wettability of the polymer separators by co-doping the normal polyethylene separator with acrylonitrile. The researchers found that acrylonitrile was more susceptible to be compatible with the electrolyte due to the wettability property.\n\nPolymer separators, similar to battery separators in general, act as a separator of the anode and cathode in the Li-ion battery while also enabling the movement of ions through the cell. Additionally, many of the polymer separators, typically multilayer polymer separators, can act as “shutdown separators”, which are able to shut down the battery if it becomes too hot during the cycling process. These multilayered polymer separators are generally composed of one or more polyethylene layers which serve to shut down the battery and at least one polypropylene layer which acts as a form of mechanical support for the separator.\n\nIn addition to polymer separators, there are several other types of separators. There are nonwovens, which consist of a manufactured sheet, web, or mat of directionally or randomly oriented fibers. Supported liquid membranes, which consist of a solid and liquid phase contained within a microporous separator. Additionally there are also polymer electrolytes which can form complexes with different types of alkali metal salts, which results in the production of ionic conductors which serve as solid electrolytes. Another type of separator, a solid ion conductor, can serve as both a separator and the electrolyte in a battery.\n\nPlasma technology was used to modify a polyethylene membrane for enhanced adhesion, wettability and printability. These are usually performed by modifying the membrane on only its outermost several molecular levels. This allows the surface to behave differently without modifying the properties of the remainder. The surface was modified with acrylonitrile via a plasma coating technique. The resulting acrylonitrile-coated membrane was named PiAn-PE. The surface characterization demonstrated that PiAN-PE's enhanced adhesion resulted from the increased polar component of surface energy.\n\nThe sealed rechargeable nickel-metal hydride battery offers significant performance and environmental friendliness above alkaline rechargeable batteries. Ni/MH, like the lithium-ion battery, provides high energy and power density with long cycle lives. This technology's greatest problem is its inherent high corrosion rate in aqueous solutions. The most commonly used separators are porous insulator films of polyolefin, nylon or cellophane. Acrylic compounds can be radiation-grafted onto these separators to make their properties more wettable and permeable. Zhijiang Cai and co-workers developed a solid polymer membrane gel separator. This was a polymerization product of one or more monomers selected from the group of water-soluble ethylenically unsaturated amides and acid. The polymer-based gel also includes a water swellable polymer, which acts as a reinforcing element. Ionic species are added to the solution and remain embedded in the gel after polymerization. \n\nNi/MH batteries of bipolar design (bipolar batteries) are being developed because they offer some advantages for applications as storage systems for electric vehicles. This solid polymer membrane gel separator could be useful for such applications in bipolar design. In other words, this design can help to avoid short-circuits occurring in liquid-electrolyte systems.\n\nInorganic polymer separators have also been of interest as use in lithium-ion batteries. Inorganic particulate film/poly(methyl methacrylate) (PMMA)/inorganic particulate film trilayer separators are prepared by dip-coating inorganic particle layers on both sides of PMMA thin films. This inorganic trilayer membrane is believed to be an inexpensive, novel separator for application in lithium-ion batteries from increased dimensional and thermal stability.\n"}
{"id": "2243424", "url": "https://en.wikipedia.org/wiki?curid=2243424", "title": "Single crystal", "text": "Single crystal\n\nA single crystal or monocrystalline solid is a material in which the crystal lattice of the entire sample is continuous and unbroken to the edges of the sample, with no grain boundaries. The absence of the defects associated with grain boundaries can give monocrystals unique properties, particularly mechanical, optical and electrical, which can also be anisotropic, depending on the type of crystallographic structure. These properties, in addition to making them precious in some gems, are industrially used in technological applications, especially in optics and electronics.\n\nBecause entropic effects favour the presence of some imperfections in the microstructure of solids, such as impurities, inhomogeneous strain and crystallographic defects such as dislocations, perfect single crystals of meaningful size are exceedingly rare in nature, and are also difficult to produce in the laboratory, though they can be made under controlled conditions. On the other hand, imperfect single crystals can reach enormous sizes in nature: several mineral species such as beryl, gypsum and feldspars are known to have produced crystals several metres across.\n\nThe opposite of a single crystal is an amorphous structure where the atomic position is limited to short range order only. In between the two extremes exist \"polycrystalline\", which is made up of a number of smaller crystals known as \"crystallites\", and \"paracrystalline\" phases.\n\nSingle crystal silicon is used in the fabrication of semiconductors. On the quantum scale that microprocessors operate on, the presence of grain boundaries would have a significant impact on the functionality of field effect transistors by altering local electrical properties. Therefore, microprocessor fabricators have invested heavily in facilities to produce large single crystals of silicon.\n\n\nAnother application of single crystal solids is in materials science in the production of high strength materials with low thermal creep, such as turbine blades. Here, the absence of grain boundaries actually gives a decrease in yield strength, but more importantly decreases the amount of creep which is critical for high temperature, close tolerance part applications.\n\nSingle crystals provide a means to understand, and perhaps realize, the ultimate performance of metallic conductors.\n\nOf all the metallic elements, silver and copper have the best conductivity at room temperature, so set the bar for performance. The size of the market, and vagaries in supply and cost, have provided strong incentives to seek alternatives or find ways to use less of them by improving performance.\n\nThe conductivity of commercial conductors is often expressed relative to the International Annealed Copper Standard, according to which the purest copper wire available in 1914 measured around 100%. The purest modern copper wire is a better conductor, measuring over 103% on this scale. The gains are from two sources. First, modern copper is more pure. However, this avenue for improvement seems at an end. Making the copper purer still makes no significant improvement. Second, annealing and other processes have been improved. Annealing reduces the dislocations and other crystal defects which are sources of resistance. But the resulting wires are still polycrystalline. The grain boundaries and remaining crystal defects are responsible for some residual resistance. This can be quantified and better understood by examining single crystals.\n\nAs anticipated, single-crystal copper did prove to have better conductivity than polycrystalline copper. \n\nBut there were surprises in store (see table). The single-crystal copper not only became a better conductor than high purity polycrystalline silver, but with prescribed heat and pressure treatment could surpass even single-crystal silver. And although impurities are usually bad for conductivity, a silver single-crystal with a small amount of copper substitutions was a better conductor than them all.\nAs of 2009, no single-crystal copper is manufactured on a large scale industrially, but methods of producing very large individual crystal sizes for copper conductors are exploited for high performance electrical applications. These can be considered meta-single crystals with only a few crystals per metre of length.\n\nSingle crystals are essential in research especially condensed-matter physics, materials science, surface science etc. The detailed study of the crystal structure of a material by techniques such as Bragg diffraction and helium atom scattering is much easier with monocrystals. Only in single crystals it is possible to study directional dependence of various properties. Furthermore, techniques such as scanning tunneling microscopy are only possible on surfaces of single crystals. In superconductivity there have been cases of materials where superconductivity is only seen in single crystalline specimen. They may be grown for this purpose, even when the material is otherwise only needed in polycrystalline form.\n\nIn the case of silicon and metal single crystal fabrication the techniques used involve highly controlled and therefore relatively slow crystallization.\n\nSpecific techniques to produce large single crystals (aka boules) include the Czochralski process and the Bridgman technique. Other less exotic methods of crystallization may be used, depending on the physical properties of the substance, including hydrothermal synthesis, sublimation, or simply solvent-based crystallization.\n\nA different technology to create single crystalline materials is called epitaxy. As of 2009, this process is used to deposit very thin (micrometre to nanometer scale) layers of the same or different materials on the surface of an existing single crystal. Applications of this technique lie in the areas of semiconductor production, with potential uses in other nanotechnological fields and catalysis.\n\n\n"}
{"id": "33148243", "url": "https://en.wikipedia.org/wiki?curid=33148243", "title": "Slovenské energetické strojárne", "text": "Slovenské energetické strojárne\n\nSlovenské energetické strojárne a.s. (SES Tlmače) () is a Slovak joint-stock company primarily engaged in the design, manufacture and assembly of power engineering equipment. It is headquartered in the Slovak city Tlmače. As of 2012 the company is in the process of merging into the EP Industries holding owned by the Slovak investment company J&T and Czech billionaire Daniel Křetínský.\n\nThe Company provides boilers for combustion of coal, oil, gas and biomass and determined for thermal power plants or combined heating and power plants as well as incinerating plants. In addition to equipment for power engineering, the slovenske energeticke strojarne, gas, metallurgy and consumer goods industry. It also provides services in power engineering: development, designing, manufacture, assembly and commissioning. Its products are divided in five segments: power plants; boilers; condensers, heat exchangers and pipelines; steel constructions and other equipment.\n\nIt is operational through a number of subsidiaries, including SES Hungaria Kft., based in Hungary, SES Bohemia sro, based in the Czech Republic, and SES Chile, based in Chile, among others.\n\nThe company was founded in the 1950s in Czechoslovakia. It was transformed into a joint-stock company in 1992. Since August 2006, the majority shareholder of SES Tlmače is a Cypriot company Segfield Investment, part of the J&T Group, one of two biggest investment companies in Slovakia. In May 2012, the company announced its plan to lay off 300 employees.\n\n\n"}
{"id": "18877637", "url": "https://en.wikipedia.org/wiki?curid=18877637", "title": "Soil moisture sensor", "text": "Soil moisture sensor\n\nSoil moisture sensors measure the volumetric water content in soil. Since the direct gravimetric measurement of free soil moisture requires removing, drying, and weighting of a sample, soil moisture sensors measure the volumetric water content indirectly by using some other property of the soil, such as electrical resistance, dielectric constant, or interaction with neutrons, as a proxy for the moisture content. The relation between the measured property and soil moisture must be calibrated and may vary depending on environmental factors such as soil type, temperature, or electric conductivity. Reflected microwave radiation is affected by the soil moisture and is used for remote sensing in hydrology and agriculture. Portable probe instruments can be used by farmers or gardeners.\n\nSoil moisture sensors typically refer to sensors that estimate volumetric water content. Another class of sensors measure another property of moisture in soils called water potential; these sensors are usually referred to as soil water potential sensors and include tensiometers and gypsum blocks.\n\nTechnologies commonly used to indirectly measure volumetric water content (soil moisture) include)\n\n\nMeasuring soil moisture is important for agricultural applications to help farmers manage their irrigation systems more efficiently. Knowing the exact soil moisture conditions on their fields, not only are farmers able to generally use less water to grow a crop, they are also able to increase yields and the quality of the crop by improved management of soil moisture during critical plant growth stages.\n\nIn urban and suburban areas, landscapes and residential lawns are using soil moisture sensors to interface with an irrigation controller. Connecting a soil moisture sensor to a simple irrigation clock will convert it into a \"smart\" irrigation controller that prevents irrigation cycles when the soil is already wet, e.g. following a recent rainfall event.\n\nGolf courses are using soil moisture sensors to increase the efficiency of their irrigation systems to prevent over-watering and leaching of fertilizers and other chemicals into the ground.\n\nSoil moisture sensors are used in numerous research applications, e.g. in agricultural science and horticulture including irrigation planning, climate research, or environmental science including solute transport studies and as auxiliary sensors for soil respiration measurements.\n\nRelatively cheap and simple devices that do not require a power source are available for checking whether plants have sufficient moisture to thrive. After inserting a probe into the soil for approximately 60 seconds, a meter indicates if the soil is too dry, moist or wet for plants.\n\n\n"}
{"id": "22875699", "url": "https://en.wikipedia.org/wiki?curid=22875699", "title": "Stocking (forestry)", "text": "Stocking (forestry)\n\nIn forestry, stocking is a quantitative measure of the area occupied by trees, usually measured in terms of well-spaced trees or basal area per hectare, relative to an optimum or desired level of density. A desirable level of stocking is often considered that which maximizes timber production, or other management objectives.\n\nStocking can be expressed in either absolute or relative terms. Absolute terms include the basal area or trees per acre. Relative terms measure the density against a reference level, which is determined by dominant tree species, the plant community, and site index.\n\nStand density is not the same as stocking. See stand density index for the difference.\n\n"}
{"id": "413875", "url": "https://en.wikipedia.org/wiki?curid=413875", "title": "The Doomsday Machine (Star Trek: The Original Series)", "text": "The Doomsday Machine (Star Trek: The Original Series)\n\n\"The Doomsday Machine\" is the sixth episode of the of the American science fiction television series \"\". Written by Norman Spinrad and directed by Marc Daniels, it was first broadcast on October 20, 1967.\n\nIn the episode, the starship \"Enterprise\" fights a powerful planet-killing machine from another galaxy. \n\nThe Federation starship USS \"Enterprise\", following a trail of mysteriously destroyed star systems, picks up the automated distress beacon of another starship, the USS \"Constellation\". Upon arrival, the \"Constellation\" is found drifting in space and severely damaged; Captain Kirk, Chief Medical Officer Dr. McCoy, Chief Engineer Scott and a damage control team transport to the ship to evaluate her. There they discover the only member of the crew still aboard, Commodore Matt Decker, her captain, who is suffering from severe mental trauma.\n\nDecker explains that he and his crew had discovered a giant machine, miles long, that used beams of antiprotons to tear planets apart, consuming the rubble for fuel. Their attack on the machine was ineffective and they suffered heavy damage. Decker evacuated his crew to one of the planets of the system, which the machine subsequently destroyed. Kirk theorizes that the machine is an ancient doomsday machine, which must be stopped before it reaches more populated sectors of the galaxy. The \"Enterprise\" takes the \"Constellation\" in tow and McCoy takes Decker back to the \"Enterprise\", while Scott's damage control team attempt repairs on the \"Constellation\"<nowiki>'</nowiki>s impulse engines, weapons and shields. Kirk attends to the \"Constellation\"<nowiki>'</nowiki>s nonfunctional viewscreen, which, other than communications from \"Enterprise\", will be his only means of monitoring events outside the ship.\n\nThe \"Enterprise's\" first officer, Spock, informs Kirk of the sudden appearance of the so-called planet killer and it begins to pursue the \"Enterprise\". As the boarding party prepares to beam back aboard, the machine attacks the \"Enterprise\", damaging the transporter and disrupting communications. Decker, now the senior officer on the \"Enterprise\", assumes command and orders a phaser attack. The phasers are useless against the machine, and the ship is then caught in a tractor beam which draws it towards the planet killer's maw. Kirk completes his repair of \"Constellation\"<nowiki>'</nowiki>s viewscreen and is shocked to see the \"Enterprise\" engaging the machine. Scott has managed to repair impulse engines and recharge one of the \"Constellation\"'s phaser banks, so Kirk uses the crippled ship to approach and fire at the planet killer, distracting it long enough for \"Enterprise\" to escape its tractor beam. After repairing the transporter and reestablishing voice communications, \"Enterprise\" retreats to a safe distance. Spock relieves Decker of command on Kirk's orders and Decker is escorted to Sickbay. However, Decker subdues his security escort and steals a shuttlecraft, flying it straight into the maw of the machine. Despite Kirk's plea for him to return to the \"Enterprise\" and his own horror as he is swallowed by the planet killer, he does not deviate from his course and dies.\n\nLt. Sulu reports that the shuttlecraft explosion has reduced the planet killer's power output by a small amount. Realizing that this may have been Decker's intention, and hoping that a starship would do much more damage, Kirk comes up with a plan to explode the \"Constellation\" inside the planet killer. Over Spock's objections, Kirk insists on piloting the damaged ship himself, and Scott rigs the impulse engines to explode with a thirty-second delay before detonation, warning his captain that once the timer is enabled, there is no way to abort it.\n\nWith the rest of the boarding party transported back to the \"Enterprise\", Kirk aims the \"Constellation\" at the maw of the planet killer, triggers the timer, and orders the \"Enterprise\" to beam him aboard. The transporter malfunctions, and Scott races to set it right with advice from Spock. With almost no time to spare, Kirk is safely beamed aboard the \"Enterprise\" as the \"Constellation\" explodes inside the planet killer, leaving it dead in space, its threat ended.\n\nEpisode writer Norman Spinrad based the script on a novelette \"The Planet Eater\" that had been rejected by a number of publishers. He revived the idea when he had a chance to pitch it to Executive Producer Gene Roddenberry. \"I did \"The Doomsday Machine\" fast,\" he recalled. Spinrad had written the script with actor Robert Ryan in mind to play Commodore Decker, but Ryan was unavailable owing to prior commitments.\n\nSome sources hold that the episode was influenced by Fred Saberhagen's series of berserker stories, a series of robotic killing machines built as a doomsday device by a now-vanished race to wipe out their rivals. However, author Norman Spinrad denies the influence — \"I wasn't conscious of the Saberhagen stuff when I was doing this, but I was certainly conscious of \"Moby Dick\". And, actually, my unpublished novelette, which was the genesis of (\"The Doomsday Machine\"), was written before the Saberhagen stuff.\" Non-canon \"Star Trek\" media refer to the device as a Berserker.\n\nAccording to one source the model for the USS \"Constellation\" was an off-the-shelf AMT \"Enterprise\" model painted and torched in places for the battle damage, while other sources claim that the smallest and least detailed \"Enterprise\" professional model was altered for the episode. It has also been stated that the \"Constellation\"&apos;s hull ID number of 1017 came from simply switching the digits of an \"Enterprise\" model's 1701 hull numbers.\n\nThe episode was written as a bottle episode, i.e., one that could use existing ship sets to save time and money. According to Spinrad, the episode was so well received by Roddenberry that he commissioned him to write another for comedian Milton Berle who planned to do a dramatic turn on the show titled \"He Walked Among Us\".\n\nThis is one of the few \"Star Trek\" episodes in the second season for which original music was written; in this case a full score, by Sol Kaplan. Writer James Lileks notes that the music cues for this episode are \"intended to belong together, and that’s one of the reasons the episode works like few others: it has a unique symphonic score. Played start to finish, it holds together.\" Jeff Bond notes, \"Although he wrote only two scores for the series, New York composer Sol Kaplan's music was tracked endlessly throughout the show's first two seasons.\" Both Lileks and Bond point out similarities between this music and John Williams' award-winning score for \"Jaws\", nearly a decade later. The music for this episode was collected, along with the score for \"Amok Time\", on the second release from Crescendo Records of music from the series: the first release other than the music from the pilot episodes.\n\nAn advanced version of the Planet Killer appears in the \"\" novel \"Vendetta\". The novel depicts the original Planet Killer as a prototype for a weapon designed to combat the Borg, released in desperation when the weapon's designers realized that the Borg would defeat them before they could finish the more advanced version. In the 2005 episode of \"\", \"In Harm's Way\", William Windom reprises his role as Commodore Matt Decker almost 40 years later. \"Star Trek Online\" features the machine in the Federation storyline.\n\nFor the franchise's 30th anniversary, \"TV Guide\" ranked \"The Doomsday Machine\" No. 4 on its list of the 10 best \"Star Trek\" episodes. Zack Handlen of \"The A.V. Club\" gave the episode an \"A\" rating, describing the episode as \"very strong stuff\", noting effective tension building and the development of Decker's character. Handlen also noted Sol Kaplan's score which \"matches the actors' intensity.\"\n\n"}
{"id": "6251151", "url": "https://en.wikipedia.org/wiki?curid=6251151", "title": "The Rock (Northwestern University)", "text": "The Rock (Northwestern University)\n\nThe Rock is a boulder on the campus of Northwestern University in Evanston, Illinois, United States, located in between University Hall and Harris Hall. It serves as a billboard for campus groups and events, and has been painted with different colors and messages over the years.\n\nThe Rock, a purple-and-white quartzite boulder, was transplanted from Devil's Lake, Wisconsin, as a gift of the class of 1902. That graduating class liked the idea of running water on campus \"in some form or another\" and rigged the Rock to make a fountain on the south end of campus. The original plumbing was later refitted into a water fountain.\n\nThe Rock is one of Northwestern's best-known landmarks. While it was originally a fountain, vandalism of the Rock gradually increased, particularly during the Vietnam War. With the first painting of the rock in the 1940s, it became a canvas for student art, opinions, advertising, messages, proposals, and jokes. Tradition holds that if a student wishes to paint something on the Rock, he or she must guard it from sunrise until the early morning hours (24 hours) before painting. Many student groups start guarding even earlier to ensure that they will be able to claim the Rock for whatever event or date is being advertised.\n\nHowever, the Rock is no longer one solid piece of quartzite. In 1989 the Rock was moved about 20 feet to accommodate new landscaping. The work crew which was to move the Rock dropped it, splitting it up one side and crumbling part of the base. Scientists at McCormick School of Engineering and Applied Science provided an epoxy to patch the Rock together again.\n\nAuthor Bob Wood discusses \"The Rock\" in the Northwestern chapter of his 1989 book \"Big Ten Country\".\n\n"}
{"id": "23937749", "url": "https://en.wikipedia.org/wiki?curid=23937749", "title": "The Simon &amp; Schuster Encyclopedia of Dinosaurs and Prehistoric Creatures", "text": "The Simon &amp; Schuster Encyclopedia of Dinosaurs and Prehistoric Creatures\n\nThe Simon & Schuster Encyclopedia of Dinosaurs and Prehistoric Creatures: A Visual Who's Who of Prehistoric Life is an encyclopedia that was published in 1999 by Simon & Schuster.\n"}
{"id": "22680246", "url": "https://en.wikipedia.org/wiki?curid=22680246", "title": "UPILEX", "text": "UPILEX\n\nUpilex is a heat-resistant polyimide film that is the product of the polycondensation reaction between biphenyl tetracarboxylic dianhydride (BPDA) monomers and diamine. Its properties include dimensional stability, low water absorption, high chemical resistance and high mechanical properties (up to 550 MPa depending on film thickness), high heat and chemical resistance. It was developed by UBE Industries. \nUpilex-S is the standard grade but other grades include Upilex-RN, VT, CA and SGA. Upilex-S is used when excellent mechanical properties are required, Upilex-RN possesses excellent molding processability, while Upilex-VT has superior heat bonding characteristics. General applications of Upilex include their use in flexible printed circuits, electric motor and generator insulation, high temperature wire and cable wrapping, and specialty pressure sensitive tapes. Polyimides have also been extensively studied in gas and humidity sensors. The concentration is then determined by monitoring the capacitance of modified Upilex films. With the advantages of flexibility and easy functionalization, Upilex films are often used as substrate materials in biosensor platforms. For instance, it is possible to electropolymerize onto these films or attach enzymes to it for the detection of glucose. \n\nUpilex-S, along with other polyimides Kapton HN and Kapton E, have been investigated by NASA with respect to their radiation durability for possible use in the Next Generation Space Telescope, where polymer film layer sunshields must operate at low temperatures and in the presence of cosmic rays. Flexible superstrate solar cells have been directly grown on commercially available Upilex foils, which makes for lightweight solar cells with a high specific power. Micro-heating elements can be integrated on polyimide sheets, which gives it the benefit of robustness and low-power consumption required for high temperatures. Upilex membranes are not transparent because of their aromatic C-H stretching band, but this can be altered by substituting hydrogen atoms by deuterium atoms. \n\n\n"}
{"id": "34430282", "url": "https://en.wikipedia.org/wiki?curid=34430282", "title": "Wharetutu Te Aroha Stirling", "text": "Wharetutu Te Aroha Stirling\n\nWharetutu Te Aroha Stirling (28 January 1924 – 31 March 1993) was a notable New Zealand tribal leader and conservationist. Of Māori descent, she identified with the Ngāi Tahu iwi. She was born in Lyttelton, North Canterbury, New Zealand in 1924.\n"}
{"id": "23715125", "url": "https://en.wikipedia.org/wiki?curid=23715125", "title": "Wheel hub motor", "text": "Wheel hub motor\n\nThe wheel hub motor (also called wheel motor, wheel hub drive, hub motor or in-wheel motor) is an electric motor that is incorporated into the hub of a wheel and drives it directly.\n\n\nThe electric wheel hub motor was raced by Ferdinand Porsche in 1897 in Vienna, Austria. Porsche's first engineering training was electrical, not internal combustion based. As a result, he developed his first cars as electric cars with electric wheel hub motors that ran on batteries. The Lohner Porsche, fitted with one wheel motor in each of the front wheels, appeared at the World Exhibition in Paris in 1900 and created a sensation in the young automobile world. In the following years, 300 Lohner Porsches were made and sold to wealthy buyers.\n\nEventually the growth in power of the gasoline engine overtook the power of the electric wheel hub motors and this made up for any losses through a transmission. As a result, autos moved to gasoline engines with transmissions, but they were never as efficient as electric wheel hub motors.\n\n\nSeveral concept cars have been developed using in-wheel motors:\n\nHub motor electromagnetic fields are supplied to the stationary windings of the motor. The outer part of the motor follows, or tries to follow, those fields, turning the attached wheel. In a brushed motor, energy is transferred by brushes contacting the rotating shaft of the motor. Energy is transferred in a brushless motor electronically, eliminating physical contact between stationary and moving parts. Although brushless motor technology is more expensive, most are more efficient and longer-lasting than brushed motor systems.\n\nA hub motor typically is designed in one of three configurations. Considered least practical is an axial-flux motor, where the stator windings are typically sandwiched between sets of magnets. The other two configurations are both radial designs with the motor magnets bonded to the rotor; in one, the inner rotation motor, the rotor sits inside the stator, as in a conventional motor. In the other, the outer-rotation motor, the rotor sits outside the stator and rotates around it. The application of hub motors in vehicular uses is still evolving, and neither configuration has become standard.\n\nElectric motors have their greatest torque at startup, making them ideal for vehicles as they need the most torque at startup too. The idea of \"revving up\" so common with internal combustion engines is unnecessary with electric motors. Their greatest torque occurs as the rotor first begins to turn, which is why electric motors do not require a transmission. A gear-down arrangement may be needed, but unlike in a transmission normally paired with a combustion engine, no shifting is needed for electric motors.\n\nWheel hub motors are increasingly common on electric bikes and electric scooters in some parts of the world, especially Asia.\n\nCompared with the conventional electric vehicle design with one motor situated centrally driving two (sometimes four) wheels by axles, the wheel motor arrangement has certain advantages and disadvantages:\n\nCars with electronic control of brakes and acceleration provide more opportunities for computerized vehicle dynamics such as:\n\n\nWhile some of these features have started to appear as options for some internal combustion engine vehicles, optional ABS brakes can add up to $2,000 to the cost of a base model.\n\nAs wheel motors brake and accelerate a vehicle with a single solid state electric/electronic system many of the above features can be added as software upgrades rather than requiring additional systems/hardware be installed like with ABS etc. This should lead to cheaper active dynamic safety systems for wheel motor equipped road vehicles.\n\nEliminating mechanical transmission, including gearboxes, differentials, drive shafts, and axles, provides a significant weight and manufacturing cost saving, while also decreasing the environmental impact of the product.\n\nThe major disadvantage of a wheel hub motor is that the weight of the electric motor increases the unsprung weight, which adversely affects handling and ride. The wheels are more sluggish in responding to road conditions, especially fast motions over bumps, and transmit the bumps to the chassis instead of absorbing them. \n\nMost conventional electric motors include ferrous material composed of laminated electrical steel. This ferrous material contributes most of the weight of electric motors. To minimize this weight, several recent wheel-motor designs have minimized the electrical steel content of the motor by using a coreless design with Litz wire coil windings to reduce eddy current losses. This significantly reduces wheel motor weight and therefore unsprung weight.\n\nAnother method used is to replace the cast iron friction brake assembly with a wheel motor assembly of similar weight. This results in no net gain in unsprung weight and provides a car capable of braking up to 1G. \n\nA good example of this is the Michelin Active Wheel motor as fitted to the Heuliez Will, the first electric car with an Active Wheel drive, which results in an unsprung weight of 35 kg on the front axle and which compares favorably to a small car such as a Renault Clio that has 38 kg of unsprung weight on its front axle.\n\n\n"}
