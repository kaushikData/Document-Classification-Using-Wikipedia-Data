{"id": "31214401", "url": "https://en.wikipedia.org/wiki?curid=31214401", "title": "Akkuyu Nuclear Power Plant", "text": "Akkuyu Nuclear Power Plant\n\nThe Akkuyu Nuclear Power Plant () is a nuclear power plant under development at Akkuyu, in Büyükeceli, Mersin Province, Turkey. It will be the country's first nuclear power plant.\n\nIn May 2010, Russia and Turkey signed an agreement that a subsidiary of Rosatom — Akkuyu NGS Elektrik Uretim Corp. (APC: Akkuyu Project Company) — would build, own, and operate a power plant at Akkuyu comprising four 1,200 MW VVER units. The agreement was ratified by the Turkish Parliament in July 2010.\nEngineering and survey work started at the site in 2011. \n\nIn 2013, Russian nuclear construction company Atomstroyexport (ASE) and Turkish construction company Ozdogu signed the site preparation contract for the proposed Akkuyu nuclear power plant. The contract includes excavation work at the site.\n\nThe official launch ceremony took place in April 2015. Major construction started in March 2018, and the first unit is expected to become operational in 2023. The other three units are expected to be complete by 2025.\nFinancing is provided by Russian investors, with 93% from a Rosatom subsidiary. Up to 49% of shares may be sold later to other investors. Potential investors are Turkish companies Park Teknik and Elektrik Üretim.\n\nTurkish Electricity Trade and Contract Corporation (TETAS) has guaranteed the purchase of 70% power generated from the first two units and 30% from the third and fourth units over a 15-year power purchase agreement. Electricity will be purchased at a price of 12.35 US cents per kW·h and the remaining power will be sold in the open market by the producer.\n\nThe most important objection is that Büyükeceli and the surrounding coastline may lose its touristic potential after the realization of the project. Büyükeceli residents are also worried that the already low population of the town may further decrease and the town may lose its township status. \nHowever, the president of the township's commercial counsel Alper Gursoy also added that nuclear energy is necessary for Turkey's economy and that the construction of such a large plant may benefit the town economically.\n\nOn 17 April 2011 a human chain was formed in Mersin to protest the decision. It was planned that there would be 30 locations to form chains along the highway connecting Mersin to Akkuyu. But the participation was higher than the expected and several of these chains were merged with. The east end of the chain was in Mersin midtown and it reached some west along the highway uninterrupted. Also the settlements at the west including the district centers of Silifke and Erdemli as well as Büyükeceli, the town nearest to construction site participated. \"\"The earthquake and tsunami in Japan proved how dangerous nuclear technology\" is,\" said Sabahat Aslan, a spokesperson for the Mersin Anti-Nuclear Platform. “\"We organized this protest to say ‘no’ to nuclear power plants, which will put future generations in danger\".”\n\nOn 12 January 2015, it was reported that the signatures of specialists on a government-sanctioned environmental impact report had been forged. The specialists had resigned six months prior to its submission, and the contracting company had then made unilateral changes to the report. The revelation sparked protest in North Nicosia. The construction of the Akkuyu plant is controversial in Cyprus, due to its close proximity to the island.\n\nOn 9 December 2015, the news agency Reuters reported that Rosatom stopped construction work at the power plant and that Turkey was assessing other potential candidates for the project. But Rosatom and the Turkish Energy and Natural Resource Ministry promptly refuted the statement. Despite tensions mounted between Russia and Turkey, due to the Turkish downing of Russian Airplane on November 24 (2015), Russian President Vladimir Putin stated that the decision to continue is purely a commercial one. A source told RIA Novosti that the company set up to construct the nuclear plant continued its operations in Turkey.\n"}
{"id": "2213942", "url": "https://en.wikipedia.org/wiki?curid=2213942", "title": "Anderson localization", "text": "Anderson localization\n\nIn condensed matter physics, Anderson localization (also known as strong localization) is the absence of diffusion of waves in a \"disordered\" medium. This phenomenon is named after the American physicist P. W. Anderson, who was the first to suggest that electron localization is possible in a lattice potential, provided that the degree of randomness (disorder) in the lattice is sufficiently large, as can be realized for example in a semiconductor with impurities or defects.\n\nAnderson localization is a general wave phenomenon that applies to the transport of electromagnetic waves, acoustic waves, quantum waves, spin waves, etc. This phenomenon is to be distinguished from weak localization, which is the precursor effect of Anderson localization (see below), and from Mott localization, named after Sir Nevill Mott, where the transition from metallic to insulating behaviour is \"not\" due to disorder, but to a strong mutual Coulomb repulsion of electrons. It is shown that strong disorder can be employed to obtain high-quality wavefront due to the Anderson localization phenomenon in a .\n\nIn the original Anderson tight-binding model, the evolution of the wave function \"ψ\" on the \"d\"-dimensional lattice Z is given by the Schrödinger equation\n\nwhere the Hamiltonian \"H\" is given by\n\nwith \"E\" random and independent, and potential \"V\"(\"r\") falling off as \"r\" at infinity. For example, one may take \"E\" uniformly distributed in [−\"W\",   +\"W\"], and\n\nStarting with \"ψ\" localised at the origin, one is interested in how fast the probability distribution formula_4 diffuses. Anderson's analysis shows the following:\n\n\n\nThe phenomenon of Anderson localization, particularly that of weak localization, finds its origin in the wave interference between multiple-scattering paths. In the strong scattering limit, the severe interferences can completely halt the waves inside the disordered medium.\n\nFor non-interacting electrons, a highly successful approach was put forward in 1979 by Abrahams \"et al.\" This scaling hypothesis of localization suggests that a disorder-induced metal-insulator transition (MIT) exists for non-interacting electrons in three dimensions (3D) at zero magnetic field and in the absence of spin-orbit coupling. Much further work has subsequently supported these scaling arguments both analytically and numerically (Brandes \"et al.\", 2003; see Further Reading). In 1D and 2D, the same hypothesis shows that there are no extended states and thus no MIT. However, since 2 is the lower critical dimension of the localization problem, the 2D case is in a sense close to 3D: states are only marginally localized for weak disorder and a small spin-orbit coupling can lead to the existence of extended states and thus an MIT. Consequently, the localization lengths of a 2D system with potential-disorder can be quite large so that in numerical approaches one can always find a localization-delocalization transition when either decreasing system size for fixed disorder or increasing disorder for fixed system size. \nMost numerical approaches to the localization problem use the standard tight-binding Anderson Hamiltonian with onsite-potential disorder. Characteristics of the electronic eigenstates are then investigated by studies of participation numbers obtained by exact diagonalization, multifractal properties, level statistics and many others. Especially fruitful is the transfer-matrix method (TMM) which allows a direct computation of the localization lengths and further validates the scaling hypothesis by a numerical proof of the existence of a one-parameter scaling function. Direct numerical solution of Maxwell equations to demonstrate Anderson localization of light has been implemented (Conti and Fratalocchi, 2008).\nRecent work has shown that a non-interacting Anderson localized system can become many-body localized even in the presence of weak interactions. This result has been rigorously proven in 1D, while perturbative arguments exist even for two and three dimensions. \n\nTwo reports of Anderson localization of light in 3D random media exist up to date (Wiersma \"et al.\", 1997 and Storzer \"et al.\", 2006; see Further Reading), even though absorption complicates interpretation of experimental results (Scheffold \"et al.\", 1999). Anderson localization can also be observed in a perturbed periodic potential where the transverse localization of light is caused by random fluctuations on a photonic lattice. Experimental realizations of transverse localization were reported for a 2D lattice (Schwartz \"et al.\", 2007) and a 1D lattice (Lahini \"et al.\", 2006). Transverse Anderson localization of light has also been demonstrated in an optical fiber medium (Karbasi \"et al.\", 2012) and a biological medium (Choi \"et al.\", 2018), and has also been used to transport images through the fiber (Karbasi \"et al.\", 2014). It has also been observed by localization of a Bose–Einstein condensate in a 1D disordered optical potential (Billy \"et al.\", 2008; Roati \"et al.\", 2008). Anderson localization of elastic waves in a 3D disordered medium has been reported (Hu \"et al.\", 2008). The observation of the MIT has been reported in a 3D model with atomic matter waves (Chabé \"et al.\", 2008). The MIT, associated with the nonpropagative electron waves has been reported in a cm sized crystal (Ying \"et al.\", 2016) Random lasers can operate using this phenomenon.\n\nStandard diffusion has no localization property, being in disagreement with quantum predictions. However, it turns out that it is based on approximation of the principle of maximum entropy, which says that the probability distribution which best represents the current state of knowledge is the one with largest entropy. This approximation is repaired in Maximal Entropy Random Walk, also repairing the disagreement: it turns out to lead to exactly the quantum ground state stationary probability distribution with its strong localization properties.\n\n\n"}
{"id": "30044843", "url": "https://en.wikipedia.org/wiki?curid=30044843", "title": "Benicia Refinery", "text": "Benicia Refinery\n\nThe Benicia Refinery is an oil refinery located near the San Francisco Bay Area city of Benicia, California. The refinery is owned by Valero Energy Corporation.\n\nThe refinery was built in 1968 for ExxonMobil. Valero purchased the property in 2000\n"}
{"id": "34026390", "url": "https://en.wikipedia.org/wiki?curid=34026390", "title": "Billion cubic metres of natural gas", "text": "Billion cubic metres of natural gas\n\nBillion cubic metres of natural gas (abbreviated: bcm) is a measure of natural gas production and trade. Depending of implied standards, this measure may represent different value of energy content. According to the standard defined by the International Energy Agency, it corresponds in average to of energy in the case of Russian natural gas and of energy in the case of Qatar's natural gas.\n\nAccording to the standard defined by the International Energy Agency, the gas physical volume is used, which is measured at the temperature of at atmospheric pressure. According to the Russian standard, the gas volume is measured at . That means that 1 billion cubic metres of natural gas by the International Energy Agency standard is equivalent to 1.017 billion cubic metres of natural gas by the Russian standard.\n\nSome other organizations use an energy equivalent-based standards. BP uses a standard which is equivalent to per billion cubic metres. Cedigaz uses a standard which is equivalent to per billion cubic metres.\n"}
{"id": "53208331", "url": "https://en.wikipedia.org/wiki?curid=53208331", "title": "Bio-ink", "text": "Bio-ink\n\nBioinks are substances made of living cells that can be used for 3D printing of complex tissue models. Bioinks are materials that mimic an extracellular matrix environment to support the adhesion, proliferation, and differentiation of living cells. Bioinks distinguish themselves from traditional biomaterials such as hydrogels, polymer networks, and foam scaffolds due to their ability to be deposited as filaments during an additive manufacturing process. Additionally, unlike traditional additive manufacturing materials such as thermoplastic polymers, ceramics, and metals which require the use of harsh solvents, cross-linking modalities and high temperatures to be printed, bioinks are processed under much milder conditions. These mild conditions are necessary to preserve compatibility with living cells, and prevent degradation of bioactive molecules and macroproteins. These bioinks are often adopted from existing hydrogel biomaterials and derived from natural polymers such as gelatins, alginates, fibrin, chitosan, and hyaluronic acids that are sensitive to their processing conditions.\n\nUnlike the thermoplastics that are often utilized in traditional 3D printing, the chain entanglements and ionic interactions within the hydrogel-like bioink rather than temperature dominate shape fidelity. The natural derivation of many bioinks often results in a high water content and sensitivity to harsh processing conditions. Therefore, bioink filaments are often deposited at or below human body temperature and under mild conditions to preserve bioink printability. Additional considerations must be taken into account when printing bioinks blended with a cell suspension due to the need to preserve cell viability.\n\nDifferences from traditional 3D printing materials\n\n\nBioink compositions and chemistries are often inspired and derived from existing hydrogel biomaterials. However, these hydrogel biomaterials were often developed to be easily pipetted and cast into well plates and other molds. Altering the composition of these hydrogels to permit filament formation is necessary for their translation as bioprintable materials. However, the unique properties of bioinks offer new challenges in characterizing material printability. Unlike traditional 3D printing materials such as thermoplastics that are essentially 'fixed' once they are printed, bioinks are a dynamic system due to their high water contains and often non-crystalline structure. The shape fidelity of the bioink after filament deposition must also be characterized. Finally, the printing pressure and nozzle diameter must be taken into account to minimize the shear stresses placed on the bioink and on any cells within the bioink during the printing process. Too high shear forces may damage or lyse cells, adversely affecting cell viability.\n\nImportant considerations in printability include:\n\n\nAlginate is a naturally derived biopolymer from the cell wall of brown algae that has been widely used as a biomaterial. Alginates are particularly suitable for bioprinting due to their mild cross-linking conditions via incorporation of divalent ions such as calcium. These materials have been adopted as bioinks through increasing their viscosity. Additionally, these alginate-based bioinks can be blended with other materials such as nanocellulose for application in tissues such as cartilage.\n\nGelatin has been widely utilized as a biomaterial for engineered tissues. The formation of gelatin scaffolds is dictated by the physical chain entanglements of the material which forms a gel at low temperatures. However, at physiological temperatures, the viscosity of gelatin drops significantly. Methacrylation of gelatin is a common approach for the fabrication of gelatin scaffolds that can be printed and maintain shape fidelity at physiological temperature.\n\nDecellularized extracellular matrix based bioinks can be derived from nearly any mammalian tissue. However, often organs such as heart, muscle, cartilage, bone, and fat are decellularized, lyophilized, and pulverized, to created a soluble matrix that can then be formed into gels. These bioinks possess several advantages over other materials due to their derivation from mature tissue. These materials consist of a complex mixture of ECM structural and decorating proteins specific to their tissue origin. Therefore, dECM-derived bioinks are particularly tailored to provide tissue-specific cues to cells. Often these bioinks are cross-linked through thermal gelation or chemical cross-linking such as through the use of riboflavin.\n\nPluronics have been utilized in printing application due to their unique gelation properties. Below physiological temperatures, the pluronics exhibit low viscosity. However, at physiological temperatures, the pluronics form a gel. However, the formed gel is dominated by physical interactions. A more permanent pluronic-based network can be formed through the modification of the pluronic chain with acrylate groups that may be chemically cross-linked.\n"}
{"id": "24872330", "url": "https://en.wikipedia.org/wiki?curid=24872330", "title": "Biophotovoltaic", "text": "Biophotovoltaic\n\nBiophotovoltaic is an adjective used to define a device in which a fraction of the electrons produced during the oxidation of water by photosynthesis are transferred onto an anode and then to a cathode where an electrically driven process takes place.\n\nFor information about the technology, see biological photovoltaics.\n"}
{"id": "1089240", "url": "https://en.wikipedia.org/wiki?curid=1089240", "title": "Bisulfide", "text": "Bisulfide\n\nBisulfide (systematically named sulfanide and hydrogen(sulfide)(1−)) is an inorganic anion with the chemical formula HS (also written as SH). It contributes no color to bisulfide salts, and its salts may have a distinctive putrid smell. It is classified as a strong base, bisulfide solutions are corrosive and attack the skin.\n\nBisulfide is the simplest thiolate. It is an important chemical reagent and industrial chemical, mainly used in textiles, synthetic flavors, coloring brasses, and iron control.\n\nA variety of salts are known, including sodium hydrosulfide and potassium hydrosulfide. Ammonium hydrosulfide, a component of \"stink bombs\" has not been isolated as a pure solid. Some compounds described as salts of the sulfide dianion contain primarily hydrosulfide. For example, the hydrated form of sodium sulfide, nominally with the formula NaS, is better described as NaSH · NaOH.\n\nAqueous bisulfide absorbs light at around 230 nm in the UV/VIS spectrum. Research groups have used field spectrometers to measure the absorption due to bisulfide (and hence its concentration) continuously in the ocean and in sewage.\nBisulfide is sometimes confused with the disulfide dianion, S, or S–S.\n\nThe sulfanidyl segment (–S) in thiolates such as bisulfide can assimilate a proton by recombination:\n\nBecause of this capture of a proton (H), bisulfide has basic character. In aqueous solution, it has a primary p\"K\" value of 6.9. Its conjugate acid is hydrogen sulfide (). However, bisulfide's basicity stems from its behavior as an Arrhenius base. A 1.0 M solution containing spectator-only counter ions, has a basic pH, indicating that most of the bisulfide is unassociated.\n\nBisulfide undergoes the typical chemical reactions of a thiolate. Upon treatment with a standard acid, it converts to hydrogen sulfide and metal salt. With strong acids, it can be doubly protonated to give . Oxidation of bisulfide gives sulfate. When strongly heated, bisulfide salts decompose to produce sulfide salts and hydrogen sulfide.\n\nAt physiological pH, hydrogen sulfide is usually fully ionized to bisulfide (HS) so in biochemical settings, \"hydrogen sulfide\" is often used to mean, bisulfide or hydrosulfide. Hydrosulfide has been identified as the third gasotransmitter along with nitric oxide and carbon monoxide. Its specific role and direct interaction with signaling molecules is the subject of ongoing research.\n\nSH is a soft anionic ligand that forms complexes with most metal ions. Examples include [Au(SH)] and (CH)Ti(SH), derived from gold(I) chloride and titanocene dichloride, respectively.\n\nBisulfide salts are corrosive to skin and must, therefore, be handled with appropriate care, since it can cause skin burns, permanent eye damage, and irritation to the mucous membranes. Latex gloves offer no protection, so specially resistant gloves, such as those made of nitrile rubber, are worn when handling its salts. Due to incompatibilities, it is recommended to keep bisulfide salts away from acids, peroxides, zinc, aluminum, copper and its alloys.\n\n"}
{"id": "24963294", "url": "https://en.wikipedia.org/wiki?curid=24963294", "title": "Chicago Pile-5", "text": "Chicago Pile-5\n\nChicago Pile-5 (CP-5) was the last of the line of Chicago Pile research reactors which started with CP-1 in 1942. The first reactor built on the Argonne National Laboratory-East site, it operated from 1954-1979.\n\nCP-5 was a thermal-neutron reactor using enriched uranium as fuel and heavy water as coolant and as a neutron moderator. It produced neutrons for use in research. The reactor had an output rating of 5 megawatts.\n\nCleanup and decommissioning of the site of CP-5 was started in 1991 completed in 2000. The cleanup process included removal of all contaminated equipment and spent fuel, decontamination of the reactor vessel and associated plumbing, and removal of the spent fuel pool, reactor internals and the hot cell liner. The accessible areas of the structure have been certified as having radiation levels equivalent to background radiation.\n\n"}
{"id": "21193733", "url": "https://en.wikipedia.org/wiki?curid=21193733", "title": "Council of European Energy Regulators", "text": "Council of European Energy Regulators\n\nThe Council of European Energy Regulators (CEER) is a \"not-for-profit\" organisation in which Europe’s national energy regulators voluntarily cooperate to protect consumer interests and to facilitate the creation of a single, competitive and sustainable internal market for gas and electricity in Europe.\n\nIn March 2000, ten national energy regulatory authorities voluntarily signed a \"Memorandum of Understanding\" for the establishment of the Council of European Energy Regulators (CEER). The CEER’s objective is to facilitate cooperation among Europe’s energy regulators in promoting a single-EU electricity and gas market. In 2003 the CEER was formally established as a \"not-for-profit association\" under Belgian law, with its own Brussels-based Secretariat. The CEER represents 36 members - the national energy regulators from the EU Member States, Iceland and Norway as CEER Members, and the regulators of Switzerland, Montenegro, Bosnia and Herzegovina, Georgia, Kosovo, Moldova and the Republic of Macedonia as Observers.\n\nThe CEER works closely with the Agency for the Cooperation of Energy Regulators (ACER). ACER is a European Community body with legal personality. ACER became fully operational on 3 March 2011. Its seat is in Ljubljana, Slovenia.\n\nCEER seeks to facilitate the creation of a single, competitive, efficient and sustainable market for gas and electricity in Europe.\n\nSome other objectives:\n\nThe CEER acts as a platform for cooperation, information exchange and assistance between national energy regulators and is their interface at European level with the EU Institutions.\n\nThe CEER establishes expert views for discussion with the European Commission (in particular DG TREN, DG Competition and DG Research) and seeks to provide the necessary elements for the development of regulation in the fields of electricity and gas.\n\nThe CEER also strives to share regulatory experience worldwide through its links with similar regional energy regulatory associations. CEER has taken the lead role in developing the International Energy Regulation Network (IERN) web platform to facilitate the global exchange and analysis of information concerning electricity and natural gas market regulation.\n\nCEER membership is open to the national energy regulatory authorities of the European Union and the European Economic Area (EEA). The CEER has now 36 members, including energy regulators in the 28 EU-Member States plus Iceland and Norway - as well as 7 observers - the energy regulators from Switzerland, Montenegro, Moldova, Bosnia and Herzegovina, Kosovo, Georgia and the Republic of Macedonia.\n\n\n\n"}
{"id": "29820620", "url": "https://en.wikipedia.org/wiki?curid=29820620", "title": "East Bend Generating Station", "text": "East Bend Generating Station\n\nThe East Bend Generating Station is a coal-fired power plant owned and operated by Duke Energy near Rabbit Hash, Kentucky. It is located 10 miles west of Florence, Kentucky. The closest city is Rising Sun, Indiana, which lies to the northwest, across the Ohio River. Originally planned for four units, only unit no. 2 was built and is in commission.\n\n\n\n"}
{"id": "681582", "url": "https://en.wikipedia.org/wiki?curid=681582", "title": "Effective field theory", "text": "Effective field theory\n\nIn physics, an effective field theory is a type of approximation, or effective theory, for an underlying physical theory, such as a quantum field theory or a statistical mechanics model. An effective field theory includes the appropriate degrees of freedom to describe physical phenomena occurring at a chosen length scale or energy scale, while ignoring substructure and degrees of freedom at shorter distances (or, equivalently, at higher energies). Intuitively, one averages over the behavior of the underlying theory at shorter length scales to derive what is hoped to be a simplified model at longer length scales. Effective field theories typically work best when there is a large separation between length scale of interest and the length scale of the underlying dynamics. Effective field theories have found use in particle physics, statistical mechanics, condensed matter physics, general relativity, and hydrodynamics. They simplify calculations, and allow treatment of dissipation and radiation effects.\n\nPresently, effective field theories are discussed in the context of the renormalization group (RG) where the process of \"integrating out\" short distance degrees of freedom is made systematic. Although this method is not sufficiently concrete to allow the actual construction of effective field theories, the gross understanding of their usefulness becomes clear through an RG analysis. This method also lends credence to the main technique of constructing effective field theories, through the analysis of symmetries. If there is a single mass scale M in the \"microscopic\" theory, then the effective field theory can be seen as an expansion in 1/M. The construction of an effective field theory accurate to some power of 1/M requires a new set of free parameters at each order of the expansion in 1/M. This technique is useful for scattering or other processes where the maximum momentum scale k satisfies the condition k/M≪1. Since effective field theories are not valid at small length scales, they need not be renormalizable. Indeed, the ever expanding number of parameters at each order in 1/M required for an effective field theory means that they are generally not renormalizable in the same sense as quantum electrodynamics which requires only the renormalization of two parameters.\n\nThe best-known example of an effective field theory is the Fermi theory of beta decay. This theory was developed during the early study of weak decays of nuclei when only the hadrons and leptons undergoing weak decay were known. The typical reactions studied were:\n\nThis theory posited a pointlike interaction between the four fermions involved in these reactions. The theory had great phenomenological success and was eventually understood to arise from the gauge theory of electroweak interactions, which forms a part of the standard model of particle physics. In this more fundamental theory, the interactions are mediated by a flavour-changing gauge boson, the W. The immense success of the Fermi theory was because the W particle has mass of about 80 GeV, whereas the early experiments were all done at an energy scale of less than 10 MeV. Such a separation of scales, by over 3 orders of magnitude, has not been met in any other situation as yet.\n\nAnother famous example is the BCS theory of superconductivity. Here the underlying theory is of electrons in a metal interacting with lattice vibrations called phonons. The phonons cause attractive interactions between some electrons, causing them to form Cooper pairs. The length scale of these pairs is much larger than the wavelength of phonons, making it possible to neglect the dynamics of phonons and construct a theory in which two electrons effectively interact at a point. This theory has had remarkable success in describing and predicting the results of experiments on superconductivity.\n\nGeneral relativity itself is expected to be the low energy effective field theory of a full theory of quantum gravity, such as string theory or Loop Quantum Gravity. The expansion scale is the Planck mass.\nEffective field theories have also been used to simplify problems in General Relativity, in particular in calculating the gravitational wave signature of inspiralling finite-sized objects. The most common EFT in GR is \"Non-Relativistic General Relativity\" (NRGR), which is similar to the post-Newtonian expansion. Another common GR EFT is the Extreme Mass Ratio (EMR), which in the context of the inspiralling problem is called EMRI.\n\nPresently, effective field theories are written for many situations.\n\n\n"}
{"id": "26337757", "url": "https://en.wikipedia.org/wiki?curid=26337757", "title": "Energy in Moldova", "text": "Energy in Moldova\n\nEnergy in Moldova describes energy and electricity production, consumption and import in Moldova.\n\nMoldova lacks domestic sources of fossil energy and must import substantial amounts of petroleum, coal, natural gas, and other energy resources.\n\nRenewable energy is used in country primarily for electricity generation or heating. The projected share of renewable energy in 2020 in the gross final consumption of energy is 20%.\n\nMoldova imports all of its supplies of petroleum, coal, and natural gas, largely from Russia.\n\nMoldova was an observer to the treaty establishing Energy Community from the outset (2006). Following its interest in full membership, the European Commission was mandated to carry out accession negotiations with Moldova in 2007. In December 2009, the Energy Community Ministerial Council decided on the accession, but made it conditional to amendment of Moldova's gas law. Moldova joined the Energy Community as a full-fledged member in March 2010.\n\nMoldova, together with the other contracting parties, has the following tasks and obligations:\n\nThe Energy Community acquis communautaire consists of roughly 25 legal acts. It includes key EU legal acts in the area of electricity, gas, oil, environment, energy efficiency, renewable energy resources and statistics. The treaty envisages that the main principles of EU competition policy are also applicable. The timeline for transposition and implementation is laid down by the treaty or by a Ministerial Council decision.\n\nMoldova is a partner country of the EU INOGATE energy programme, which has four key topics: enhancing energy security, convergence of member state energy markets on the basis of EU internal energy market principles, supporting sustainable energy development, and attracting investment for energy projects of common and regional interest.\n\n"}
{"id": "23495083", "url": "https://en.wikipedia.org/wiki?curid=23495083", "title": "Environmental issues in the United Kingdom", "text": "Environmental issues in the United Kingdom\n\nThis page lists the issues that the United Kingdom currently has that are related to the environment, such as pollution and contamination.\n\nAccording to Lord Stern of Brentford, the flooding and storms in UK in 2014 were clear signs of climate change. Author of the 2006 Stern Review said 2013–2014 weather is part of international pattern and demonstrates urgent need to cut carbon emissions.\n\nRoyal Mail rubber band\nEverything\n\nFood waste in the United Kingdom\n\n"}
{"id": "58055766", "url": "https://en.wikipedia.org/wiki?curid=58055766", "title": "Environmentally-friendly red light flare", "text": "Environmentally-friendly red light flare\n\nAn environmentally-friendly red-light flare was a pyrotechnic (firework) flare which used lithium-based formulations that emitted red light. A flare is used for signaling, illumination, or defensive countermeasures in civilian or military applications. It is based on a non-hygroscopic (not absorbing air) dilithium nitrogen-rich salt that served as an oxidizer and red colorant. The U.S. Army Research Laboratory and the Ludwig Maximilian Institution were credited as the research facilities for developing this product announced in January 2018.\n\nAs of 2018, this is the first documented red-light flare compound that is based on lithium and does not contain any perchlorates, halogenated materials, or strontium-based materials. This formulation was assessed as having high color quality. To achieve the red-light emission from the flare, the authors report a formulation mixture of powdered magnesium and hexamine as fuels, nitrocellulose, an epoxy binder system, and lithium-based nitrogen salts as the oxidizer and color agent. When burned, users could observe a cool burning flame emitting a deep red color.\n\nWhen the flares are burned, a chemical reaction involving strontium chloride (SrCl) occurs. SrCl emits the red color after the flare is ignited. This chemical compound is known as a metastable molecular emitter, meaning, it is not stable at low temperatures but stable in excited high-temperature combustion processes.\n\nBefore 2018, the formulations for red-light emitting pyrotechnic formulations included powdered metal fuels like magnesium, aluminum, strontium nitrate and perchlorate oxidizers, as well as carbon-based chlorinated organic materials such as poly(vinyl) chloride.\n\nIn 2014, the EPA made a decision to develop regulations on the amount of strontium present in drinking water. Strontium had been detected in 99% of all public U.S. water systems and at levels of concern in 7%. The agency reported that strontium is potentially harmful to human health. This chemical replaces calcium in the bone, interferes with bone strength, and affects skeletal development. The U.S. military training grounds were not included in the above study; therefore, the presence or percentage of strontium in their water systems were unknown. However, strontium was identified to be present in the red flares and signaling fireworks available in 2014. Due to these finding, the developers of the environmentally friendly red-light flare concluded the development of the environmentally safe flares were a necessity for users.\n"}
{"id": "8810570", "url": "https://en.wikipedia.org/wiki?curid=8810570", "title": "Eolo Car", "text": "Eolo Car\n\nEolo is the first compressed air car invented by Guy Nègre and built by Motor Development International (MDI) which has licensed the patent for the construction to Eolo International (in Italy to Eolo Italia). It was unveiled during the 2001 Bologna Motor Show car and bike fair. An attempt to put it into production ran out of steam in 2003.\n\nThe car utilizes air expansion as an energy source by releasing compressed air from tanks with an extremely cold internal temperature and high pressure, about 300 Bar. The resulting air expansion is used to move a piston or turbine attached to a transmission.\n\nThe Eolo car uses electricity to re-fill the compressed air tanks, taking about 6 hours.\n\n\nIt is claimed to be a zero-emissions vehicle. The only problem is the recharging, but if the energy is produced solely via renewable resources such as wind, geothermal power or solar power, the emission is zero. On the other hand, most electricity worldwide is made by burning coal, oil or natural gas, or from nuclear energy.\n\nProduction should have begun in 2003 in Broni (Italy), but for unspecified problems MDI company was unable to build or sell it in the Italian-European market, or indeed anywhere. The 90 employees, who were supposed to begin production, were from 2003 to 2005 under the \"cassa integrazione\" law (an Italian law which provides, through state benefits, the payroll to employees who, for special reasons due to the employers, are unable to perform their jobs) then fired.\n\nThough the prototype was a complete success (the engine was even sold as a power generator with 0 emissions) the selling of this car is said to be artificially postponed or cancelled due to undeclared reasons.\n\nThere have been several attempts to interview and have a declaration from the Eolo Italia president, but up to now no one has been successful.\n\n\n"}
{"id": "428937", "url": "https://en.wikipedia.org/wiki?curid=428937", "title": "Geode", "text": "Geode\n\nGeodes (derived from the Greek word \"γεώδης\" meaning \"Earth like\") are geological secondary formation within sedimentary and volcanic rocks. Geodes are hollow, vaguely circular rocks, in which masses of mineral matter (which may include crystals) are secluded. The crystals are formed by the filling of vesicles in volcanic and sub-volcanic rocks by minerals deposited from hydrothermal fluids; or by the dissolution of syn-genetic concretions and partial filling by the same, or other minerals precipitated from genetic water, groundwater or hydrothermal fluids.  \n\nGeodes can form in any cavity, but the term is usually reserved for more or less rounded formations in igneous and sedimentary rocks. They can form in gas bubbles in igneous rocks, such as vesicles in basaltic lava; or, as in the American Midwest, in rounded cavities in sedimentary formations. After rock around the cavity hardens, dissolved silicates and/or carbonates are deposited on the inside surface. Over time, this slow feed of mineral constituents from groundwater or hydrothermal solutions allows crystals to form inside the hollow chamber. Bedrock containing geodes eventually weathers and decomposes, leaving them present at the surface if they are composed of resistant material such as quartz. \n\nWhen cut in half, visible bands corresponding to varied stages of precipitation may at times show patterns that reveal points of fluid entry into the cavity and/or varied colors corresponding to changes in chemistry.\n\nGeode banding and coloration is the result of variable impurities. Iron oxides will impart rust hues to siliceous solutions, such as the commonly observed iron-stained quartz. Most geodes contain clear quartz crystals, while others have purple amethyst crystals. Still others can have agate, chalcedony, or jasper banding or crystals such as calcite, dolomite, celestite, etc. There is no easy way of telling what the inside of a geode holds until it is cut open or broken apart. However, geodes from a particular area are usually similar in appearance.\n\nGeodes and geode slices are sometimes dyed with artificial colors. Samples of geodes with unusual colors or highly unlikely formations have usually been synthetically altered.\n\nGeodes are common in some formations in the United States (mainly in Indiana, Iowa, Missouri, western Illinois, Kentucky, and Utah). They also are common in Brazil, Namibia, and Mexico. Geodes are also abundant in the Mendip Hills in Somerset, England, where they are known locally as \"Potato Stones.\"\n\nIn 2000 a team of geologists found a cave filled with giant gypsum crystals in an abandoned silver mine near Almería, Spain. The cavity, which measures 1.8 × 1.7 meters and is 8 meters in length, would be the largest crystal cave ever found. The entrance of the cave has been blocked by five tons of rocks, and is under police protection (to prevent looters from entering). According to geological models, the cave was formed during the Messinian salinity crisis 6 million years ago, when the Mediterranean sea evaporated and left thick layers of salt sediment). The cave is currently not accessible to tourists.\n\nThe world's largest known crystal cave or vug is Crystal Cave, a celestine geode 35 feet (10.7 m) in diameter at its widest point, located near the village of Put-in-Bay, Ohio, on South Bass Island in Lake Erie.\n\n\n\n"}
{"id": "37937659", "url": "https://en.wikipedia.org/wiki?curid=37937659", "title": "Gibraltar Electricity Authority", "text": "Gibraltar Electricity Authority\n\nGibraltar Electricity Authority is an agency under the Government of Gibraltar responsible for regulating the Gibraltar electricity market. The authority was created on 28 March 2003 under the Gibraltar Electricity Authority Act 2003. Its responsibility is to generate, distribute and supply electricity to the civilian population of Gibraltar.\n\nIn 1890, the Colonial Government of Gibraltar commissioned Welsh electrical engineer William Henry Preece (1834 – 1913) to \"enquire into the propriety of introducing electric light\" into the territory. On 15 September 1896, construction of the King’s Bastion Power Station, based in the old King's Bastion, was started with the help of a loan raised under the Electric Light Ordinance of 1892. The first demonstration of electric lighting in Gibraltar was conducted in April 1897. The Electric Light department was established on 9 March 1898.\n\nThe Government of Gibraltar passed an act in the House of Assembly on 28 March 2003 to establish the Gibraltar Electricity Authority to regulate electricity supply for the civilian population.\n"}
{"id": "40038649", "url": "https://en.wikipedia.org/wiki?curid=40038649", "title": "Hybrid switchgear module", "text": "Hybrid switchgear module\n\nA hybrid switchgear is one that combines the components of traditional air-insulated switchgear (AIS) and SF gas-insulated switchgear (GIS) technologies. It is characterized by a compact and modular design, which encompasses several different functions in one module.\n\nHigh-voltage switchgears have been traditionally distinguished according to the medium used to extinguish the arc. In the case of the hybrid switchgear modules, this device developed during last 90’s uses two different types of technologies: one to extinguish the arc and the other to connect to the other equipment of the high voltage substation, for pursuing the goal of maximizing the advantages of the already existing technologies. The hybrid module typically utilizes gas-insulated switchgear components and conventional air-insulated bushings for connecting to the busbar.\n\nThe term module refers to the fact that the equipment itself is a combination of different standard substation components in a single assembly. The integration allows to reduce the overall substation footprint from 50% to more than 70% when compared to substation realized using conventional air insulated equipment.\nAn hybrid module can incorporate:\n\nThe high voltage live parts (circuit breaker, disconnector and earthing switch) are encapsulated in a grounded aluminum tank, filled with pressurized sulfur hexafluoride (SF) gas, which means that the disconnector contacts will likely not require any maintenance during the product life, thus increasing the availability of the substation and the safety of the operators.\n\nThis modular approach to the construction of the substations is based on flexibility and customizability. The hybrid module can be used for extension or substitution in any traditional substation which uses an air-insulated busbar. This allows to configure the module with the components that are required by substation’s architecture and scope of supply. Vice versa, it is also possible to install traditional air-insulated equipment in a hybrid substation.\n"}
{"id": "18549302", "url": "https://en.wikipedia.org/wiki?curid=18549302", "title": "Iran Air Flight 291", "text": "Iran Air Flight 291\n\nIran Air Flight 291 was a flight that crashed on January 21, 1980. The flight, carried on a Boeing 727-86, was making a domestic flight from Mashad Airport to Tehran-Mehrabad Airport in Iran. At 1911h local time, the aircraft, registered as EP-IRD, collided with the Alborz Mountains, north of Tehran, during its approach to Tehran-Mehrabad runway 29 in foggy and snowy weather conditions. All 8 crew members and 120 passengers died in the incident, and the plane was destroyed. At the time, Iran Air Flight 291 was the deadliest aircraft disaster in Iranian history.\n\nInvestigators concluded that the probable cause of the crash was believed to be an inoperable instrument landing system and ground radar. The head of Iran's Civil Aviation Authority and five other officials were charged with manslaughter as a result of the crash of Flight 291.\n"}
{"id": "56508300", "url": "https://en.wikipedia.org/wiki?curid=56508300", "title": "Karura Hydroelectric Power Station", "text": "Karura Hydroelectric Power Station\n\nKarura Hydroelectric Power Station, commonly referred to as Karura Power Station, also Karura Dam, is a planned hydropower station in Kenya.\n\nThe power station would be located across River Tana, in Embu County, sandwiched between Kindaruma Hydroelectric Power Station upstream and Kiambere Hydroelectric Power Station downstream. Karura Power Station, is about downstream of Kindaruma Power Station. This location is approximately , by road, north-east of Nairobi, the capital and largest city of Kenya.\n\nThe power station is a run of river, hydropower installation, with capacity of 67 Megawatts. The design calls for the waters of River Tana to be diverted through a \"dug-out channel\" and then delivered to the power-generation site, thereby reducing the \"displacement of communities\". Kenya Electricity Generating Company (KenGen), a company, owned 70 percent by the government of Kenya, is the developer and owner of this power station.\n\nThe development, decided upon circa 2012, is being developed to stabilize the national electricity grid with increased hydro-power, in view of the increased intermittent sources in the country's energy mix, including solar and wind. Feasibility and ESIA studies were conducted in the 2009 to 2012 time-frame. Karura and Mutonga were two locations that were identified as potential sites for hydro-power station development.\n\n, the development was entering the tendering process, after which the construction cost and timeline would be determined.\n\n\n"}
{"id": "48494017", "url": "https://en.wikipedia.org/wiki?curid=48494017", "title": "Lakdhanavi Power Station", "text": "Lakdhanavi Power Station\n\nThe Lakdhanavi Power Station (also sometimes referred to as the Lakdhanavi Sapugaskanda Power Station) is a thermal power station built in Sapugaskanda, Sri Lanka. Operated by , it is one of three power stations in the Sapugaskanda region, the other two being the government-owned Sapugaskanda Power Station, and the Asia Power Sapugaskanda Power Station.\n\n"}
{"id": "4904260", "url": "https://en.wikipedia.org/wiki?curid=4904260", "title": "Log house moulder", "text": "Log house moulder\n\nA log house moulder is a machine to prepare logs to be suitable for building a log home. In general, the logs are first sawn to a square beam, then the moulder makes the groove. Often fitted to a portable sawmill that enables direct profiling of round or squared logs. The log house moulder is usually powered by electricity, but for portable sawmills they are sometimes using a chainsaw as power head. One of the more common, especially in Europe, is the\nLogosol log house moulder.\n\nOther type of log house moulder is a log through-pass machine. Through-pass log home moulders are highly productive and mighty machines able to turn truck load of logs into house logs during a work shift. Barked or debarked green or dry logs are fed into such machine one after other on one side and the machine processes logs, turning them into profiled roundish or squarish house logs, taken from outfeed of the machine. Such log home milling machine can shape logs into different profiles: Swedish cope, Tongue&groove, D-log, bevel-edged logs, etc.\nOne of moulders of through-pass type are Woodlandia' Rotary Log Moulders (USA, Canada, Russia)\n"}
{"id": "3609527", "url": "https://en.wikipedia.org/wiki?curid=3609527", "title": "Lomer–Cottrell junction", "text": "Lomer–Cottrell junction\n\nIn materials science, a Lomer–Cottrell junction is a particular configuration of dislocations.\n\nWhen two perfect dislocations encounter along a slip plane, each perfect dislocation can split into two Shockley partial dislocations: a leading dislocation and a trailing dislocation. When the two leading Shockley partials combine, they form a separate dislocation with a burgers vector that is not in the slip plane. This is the Lomer–Cottrell dislocation. It is sessile and immobile in the slip plane, acting as a barrier against other dislocations in the plane. The trailing dislocations pile up behind the Lomer–Cottrell dislocation, and an ever greater force is required to push additional dislocations into the pile-up.\n\nex. FCC lattice along {111} slip planes\n\nCombination of leading dislocations:\n\nThe resulting dislocation is along the crystal face, which is not a slip plane in FCC at room temperature.\n\nLomer–Cottrell dislocation\n"}
{"id": "25983365", "url": "https://en.wikipedia.org/wiki?curid=25983365", "title": "Mabey Group", "text": "Mabey Group\n\nThe Mabey Group is a British-based group of engineering companies, which specialises in bridging, steel fabrication, plant hire and construction products. In 2008, the company was listed in the \"Sunday Times\" Top Track 250 list of Britain's top 250 mid-market private companies by turnover.\n\nFounded by Bevil Mabey in 1923, he expanded the company quickly after World War II by buying up spare Bailey bridges from the British Army.\n\nExpanded through acquisition, parts of the group were founded over 150 years ago. The group is still wholly family owned. With an administrative headquarters in Twyford, Berkshire, the group employs over 1,000 people in 40 locations and has an annualised turnover of £100 million. In excess of 90% of the company's production is exported to over 115 countries for use either in permanent or temporary bridging solutions.\n\nThe Mabey Group has made regular donations to the local Conservative party in Wokingham. John Redwood, the Wokingham MP, was chairman of an associated investment company until March 2008.\n\n\nIn its 2008 results, Mabey Group admitted publicly that it may have paid bribes to the regime of Saddam Hussein in order to win business in Iraq, under the Oil-for-Food Programme. In a retrospective United Nations report, it was alleged that Mabey paid a $202,000 (£101,000) kickback between 2001 and 2003, and was handed a $3.6m contract.\n\nIn 2009, in a case brought by the SFO, the company plead guilty to the charge of \"sought to influence decision makers in public contracts in Jamaica and Ghana between 1993 and 2001\" at Westminster magistrates court.\n\nIn July 2012, Mabey Bridge became the first organisation in the UK to pass an independent audit to become accredited to BS 10500: 2011 Specification for an Anti-bribery Management System - a management standard developed by the BSI Group in response to the Bribery Act 2010. In 2012 the director of the Serious Fraud Office described Mabey Bridge as \"leading the way in implementing controls and procedures to ensure it is able to trade ethically in high risk jurisdictions\".\n\nOn 5 October 2012, Mabey Bridge won both \"Company of the Year\" and \"Company Showing Exceptional Growth\" categories at the Monmouthshire Business Awards.\n\nOn 18 October 2012, Mabey Bridge won the \"Manufacturer of the Year\" award at the Insider Media \"Made in Wales\" awards. Sponsored by Barclays Bank, one unnamed judge is quoted as saying the company had \"Great story, great products, of which Wales should be proud.\" The other companies shortlisted were SPTS Technologies, The Royal Mint and Sony UK Technology Centre.\n\n\n"}
{"id": "20320864", "url": "https://en.wikipedia.org/wiki?curid=20320864", "title": "Maple Landmark Woodcraft", "text": "Maple Landmark Woodcraft\n\nMaple Landmark Woodcraft is a wooden products manufacturer located in Middlebury, Vermont. Founded in 1979 by Michael Rainville, the business is known for crafting American-made wooden toys, games, and gifts. Notable product lines include the NameTrains Wooden Railway System, Montgomery Schoolhouse, and Schoolhouse Naturals.\n\nMike Rainville first came to woodworking as a hobby when he was 11. At that time, his mother, Pat, told him that, “he needed to find something to do.” Rainville’s grandparents had a history of working with their hands, specifically woodworking and farming, so there were always materials around to utilize. Rainville made his first items, spools and bobbin holders, in his parents’ basement in Lincoln, Vermont, using some spare wood, a coping saw, and a sanding block. As time progressed, he started making cribbage boards which are still being made today. Local craft fairs provided him with income to purchase new equipment and materials. By 1979, Rainville had established his first wholesale relationship.\n\nRainville continued making product as he worked his way through Clarkson University, frequently returning to Lincoln on weekends. After graduating in 1984, he set about constructing a new woodshop of sufficient size for his now-full-time business. The name “Maple Landmark Woodcraft” was also adopted. This name was an extension of Maple Landmark Homestead, the family maple sugaring business and dairy farm.\n\nIn 1987, Maple Landmark acquired Troll’s Toy Workshop of Barnet, Vermont. This addition brought in many alphabet-themed products, including letter cars, blocks, and signage letters. The company quickly grew to warrant more full-time employees.\n\nThe product line evolved over the following decade, adding items such as trivets, ornaments, and the first NameTrains, a derivative line of the Troll’s Toy Workshop line alphabet letter car line. Originally finished with a clear coat, the NameTrains rapidly increased in popularity. As more retailers expressed interest in having colored letters, a non-toxic color dye stain was developed and the first colored NameTrains appeared on the market in 1994.\n\nProduction of these new products made space tight in the Lincoln facility by late 1994. With no room to expand, the decision was made to build a new shop in Middlebury, Vermont that would have easier access to raw materials and a retail space for visitors to shop for products year-round. Maple Landmark moved into the new shop on Exchange Street in Middlebury in 1996. The original woodshop still exists in Lincoln, though mostly used for storage, and is usually referred to as “the Old Shop.”\n\nWith the need to keep up with product demand, both in quantity and quality, investments were made in lasers and additional CNC routers. These machines allowed for more production in less labor-intensive manners. The lasers also gave Maple Landmark the ability to add graphic designs to products, creating the option to do custom work alongside regular production work.\n\nMore products and more machines required the enlargement of the Middlebury factory to in 1999.\n\nIn 2001, Maple Landmark purchased Montgomery Schoolhouse of Montgomery, Vermont, another long-established Vermont-based wooden toy producer. The acquisition was inspired by Rainville’s desire to not see the Montgomery Schoolhouse name, products, and history lost and forgotten. All operations were consolidated in Middlebury and, moving forward, products were redesigned to be more efficiently produced. Through the changes, the names and integrity of the products lines were maintained.\n\nThe economic downturn in the early-2000s impacted business as toys, games, and gifts were often bought with discretionary income. Low growth continued until the summer of 2007 when products from other countries and manufacturers were being recalled for child health and safety reasons. These recalls boosted Maple Landmark's business in late 2007 and 2008 with consumers looking for products and companies that they could trust. Simultaneously, Maple Landmark Woodcraft developed the Schoolhouse Naturals line of products, featuring simple engraved wooden toys without any finishes. This product line was popular among consumers that were particularly concerned about chemicals.\n\nIn January 2009, Maple Landmark created a wooden souvenir train for the United States presidential inauguration following the election of Barack Obama in 2008.\n\nIn an effort to stay flexible and innovative, Maple Landmark purchased several printers that allow for full color printing on wood. These additions allowed for more colorful and intricate designs, both in standard and custom product.\n\nIn January 2013, Maple Landmark created a wooden souvenir limousine for the United States presidential inauguration following the reelection of Barack Obama in 2012.\n\nIn 2014, Adam Rainville, Mike's older son, returned to the business after studying at Clarkson University.\n\nIn 2016, a addition was completed on the Middlebury factory, bringing the total to . The three-year project allowed for more production and packing and shipping space.\n\nThe Vermont Small Business Administration named Mike Rainville the Vermont Small Business Person of the Year for 2017. Also in 2017, Andrew Rainville, Mike's younger son, returned to the business after studying at Rensselaer Polytechnic Institute.\n\nMaple Landmark crafts a wide variety of wooden products from toys, to games, to gifts. Some product lines include NameTrains, Wooden Railway System, Hang-A-Name, Montgomery Schoolhouse, Schoolhouse Naturals, Solace, and Peterson Birds.\nMaple Landmark is affiliated with many industry and regional organizations such as the Vermont Wood Manufacturer's Association, Wood Products Manufacturing Association, American Specialty Toy Retailing Association (ASTRA), Vermont Chamber of Commerce, Vermont Attractions Association, and Addison County Chamber of Commerce.\n"}
{"id": "30836303", "url": "https://en.wikipedia.org/wiki?curid=30836303", "title": "Marshall JCM800", "text": "Marshall JCM800\n\nThe JCM800 series (Models 1959, 1987, 2203, 2204, 2210 and 2205) is a line of guitar amplifiers made by Marshall Amplification. The series was introduced in 1981. Although models 1959 and 1987 had been in production since 1965 and the 2203 and 2204 had been in production since 1975, they were redesigned and introduced as JCM800 amplifiers in '81. The JCM800 amplifiers became a staple of 1980s hard rock and heavy metal bands.\n\nIn 1981, Marshall finally reached the end of its 15-year distribution deal with Rose-Morris, which had severely limited its potential to sell amplifiers outside England; Rose-Morris tagged 55% onto the sticker price for exported models. The JCM800 was the first series produced after the contract expired. The name comes from Jim Marshall's initials, \"J.C.M.\", coupled with the meaningless \"800\" from the number plate on his car. It was later noted that \"800\" stood for the decade. For example, the JCM900 was released in 1990 and the JCM2000 was released in 2000.\n\nThe series included head amplifiers with matching cabinets, as well as combos, and was produced until the 1990s. It quickly became a very successful amplifier, and ubiquitous amongst hard rock and heavy metal bands.\n\nThese were the second series of Marshalls equipped with a master volume, which allowed for more distortion at lower volumes. Compared to the earlier \"Master Volume\" series, they offered some advantages, including the possibility to be patched internally and linked with other amplifiers. The first JCM800s were in fact Master Volume amplifiers (Models 2203 and 2204, at 100 and 50 watts respectively), repackaged in new boxes with new panels. Soon, however, the Model 2210 appeared on the market. These were equipped with two channels, which could be activated via a foot switch, allowing for separate lead and rhythm sounds. They also had an effects loop and reverb, also a first for Marshall.\n\nInitially, users complained that the amplifiers (used with the standard Marshall cabinets) sounded flat compared to the older Marshalls, until it was discovered (by accident) that the fault was with the speakers: The new cabs had been equipped with a new kind of Celestion speakers. Marshall quickly reverted to the older Celestions. Still, some users prefer the pre-JCM800 amplifiers, claiming that those have a warmer, less \"brittle\" sound.\n\nThe amplifier was equipped with EL34 valves (tubes) for amps sold in the UK and 6550 tubes for amps exported to the United States. The JCM800 is considered a \"hot\" amplifier because it has more gain stages than comparable amplifiers, and in \"lead\" mode (in the \"high\" input), an extra triode provides extra gain to the pre-amplifier, which \"made for one hot rock amp\".\n\n"}
{"id": "28833512", "url": "https://en.wikipedia.org/wiki?curid=28833512", "title": "Michael Grimm (politician)", "text": "Michael Grimm (politician)\n\nMichael Gerard Grimm (born February 7, 1970) is an American businessman, convicted felon, Marine Corps veteran and politician who represented New York in the United States Congress from 2011 to 2015. Grimm represented New York's 13th congressional district during his first term, after which he represented New York's 11th congressional district. Both districts consisted of Staten Island and parts of Brooklyn. Grimm is a member of the Republican Party, and during his time in office was the only Republican to represent a significant portion of New York City.\n\nOn April 28, 2014, Grimm was charged by federal authorities with 20 counts of fraud, federal tax evasion, and perjury. On December 23, 2014, he pleaded guilty to a single count of felony tax fraud, and \"acknowledged committing perjury, hiring illegal immigrants, and committing wire fraud\". After initially vowing to retain his seat, Grimm announced on December 30, 2014, that he would resign from Congress effective January 5, 2015. On May 5, 2015, Daniel M. Donovan, Jr. won the special election to replace Grimm. On July 17, 2015, Grimm was sentenced to eight months in prison for tax evasion. He began his prison term on September 22, 2015 after a brief delay for medical treatments.\n\nOn October 1, 2017, Grimm launched a campaign to attempt to win back his old House seat in New York's 11th District. On June 26, 2018, he lost in the Republican primary.\n\nGrimm was raised as a Catholic in Queens, New York, the son of Petrina (née Castronova) and Gerard Grimm. He is of German, Irish, and Sicilian descent. He graduated from Archbishop Molloy High School in 1988.\n\nGrimm entered active duty with the U.S. Marine Corps in 1989. He received a combat promotion to corporal, and was awarded the Combat Action Ribbon, Navy Unit Commendation, the Meritorious Unit Commendation, among other awards.\n\nGrimm received a BBA in accounting from Baruch College in 1994. He transferred to the U.S. Marine Corps Reserve and was discharged from service in 1997. He received a Juris Doctor \"(magna cum laude\") from New York Law School in 2002.\n\nGrimm entered the FBI as a clerk in 1991. In 1995, he entered the FBI Academy in Quantico Station, Virginia. He graduated as a special agent and was certified to become an undercover agent. He transitioned into undercover agent work, eventually working in the FBI Gambino Squad, and was assigned to the inside activities of Peter Gotti, John Gotti's brother. Grimm worked for the FBI as an agent for 9 years.\n\nIn 2011, Evan Ratliff, writing for \"The New Yorker\", reported that Grimm had been the subject of an internal investigation into allegations that he abused his authority as a FBI agent in a nightclub in 1999. At the time of the\" New Yorker\" report, the New York City Police Department and U.S. Justice Department had not released documents regarding the alleged incident. Grimm stated that the incident had been fully investigated and that he had been cleared of all allegations.\n\nDuring his time with the FBI, Grimm spent two years posing as a small-cap stockbroker, uncovering white-collar criminals on Wall Street. According to Grimm, the firm was involved in money laundering, making false trades, and manipulating stocks. After building a strong case for two years, he and the firm's partners were arrested together, at which point the police informed the group that they had been infiltrated by an undercover agent. Grimm stated in 2011 that he has long been aware of the possibility that people may try to take revenge on him. He left the FBI in 2006, citing his exhaustion from working long hours.\n\nBefore joining the FBI, Grimm worked for a year for Whale Securities, an investment banking firm. Shortly before leaving the bureau, Grimm invested in a luxury Texas development.\n\nIn 2006, Grimm founded a small health food restaurant in Manhattan called Healthalicious. He co-owned and served as principal and chief executive officer of Austin Refuel Transport, an Austin, Texas-based bio-fuel company. As of 2011, Grimm owned 28% of the company, although he is no longer involved in daily operations nor is he CEO. In July 2011, the \"New York Daily News\" reported that Austin Refuel Transport had received 11 safety violations in two U.S. Department of Transportation checkups. Grimm's spokesman said that he now \"has no authority or managerial role in the daily activities of the company. He is simply a silent investor.\"\n\nGrimm launched his campaign for the 13th New York Congressional District seat on January 23, 2010. He was endorsed by former NYC mayor Rudy Giuliani as well as Guy Molinari, a former U.S. Representative and Staten Island Borough President. He was also endorsed by the Conservative Party of New York State. He was challenged by Michael Allegretti who was endorsed by former six-term U.S. Representative Vito Fossella, the Staten Island Republican Party, State Senator Andrew Lanza, and State Assemblyman Lou Tobacco. Allegretti worked for the nonprofit Climate Group and cited his relationships with NYC Mayor Michael R. Bloomberg and former British Prime Minister Tony Blair. Grimm chose not to contest the Staten Island's party endorsement because of their \"corrupt political culture\" and \"sham convention.\"\n\nGrimm's primary win was divisive for the Republican Party leadership, which favored Allegretti. His campaign gained national attention from the Tea Party and the National Republican Congressional Committee, which contributed $90,000 to Grimm's campaign. He received endorsements from high-profile Republicans, including Giuliani, John McCain, Sarah Palin, and former President George H.W. Bush, who applauded his service in the Gulf War.\n\nGrimm faced incumbent Michael McMahon in the general election. On October 12, the \"Staten Island Advance\" reported that it had been receiving emails from the McMahon campaign attacking Grimm's business credentials. The emails claimed that Grimm's real-estate and restaurant investments were failures despite Grimm's repeated insistence that they were successful. Grimm reportedly admitted in an interview with the \"Staten Island Advance\" that his former restaurant in Manhattan, Healthalicious, had been on the verge of bankruptcy, forcing him to sell his stake in it. A major difference between the two candidates was the issue of the U.S. economic stimulus package, which the \"Advance\" called the \"starkest contrast\" among the two candidates. Grimm stated that the stimulus was a \"huge waste\" of taxpayer money and ineffective in generating job creation and economic recovery, whereas McMahon cited improvements in the state budget and renovations on the Staten Island Expressway and the Saint George Ferry Terminal as direct successes of the stimulus.\n\nOn November 2, 2010, Grimm defeated McMahon in the race, 51% to 48%. The \"Advance\" reported that Grimm won in large part due to his political signs, which became popular among his supporters. They stated, \"McMahon raised my property taxes 18.5%\".\n\nAfter redistricting, Grimm's district was renumbered the 11th District. He was challenged by Democrat Mark Murphy, a former aide to New York City Public Advocate Bill de Blasio. Grimm won reelection to a second term, 53%–46%.\n\nIn 2014 Grimm received the backing of the Staten Island Republican party and the Independence Party, who called him \"'a truly independent voice' for his constituents.\" He faced Democratic Party nominee Domenic Recchia in the general election. Grimm was endorsed by the Association of Flight Attendants-CWA, the International Union of Painters and Allied Trades, the United Transportation Union, and the Humane Society Legislative Fund.\nGrimm defeated Recchia on election night, November 5, 2014.\n\nOn October 1, 2017, Grimm launched a campaign for reelection to his old House seat in New York's 11th District. On May 30, 2018, President Donald Trump endorsed incumbent Representative Dan Donovan. Donovan defeated Grimm in the June 26 Republican primary, 63.9% to 36.1%.\n\nDuring a Sean Hannity interview of all freshmen Republican members, Representative-Elect Grimm took exception to being asked if he was a conservative. He replied that he was \"American first\" and that \"we have become way too polarized,\" indicating a desire for compromise with Democrats. Grimm did not join the Tea Party Caucus in the House, instead joining the more moderate Republican Main Street Partnership.\n\nGrimm was appointed to the House Financial Services Committee, which the \"Staten Island Advance\" considered a major opportunity for Grimm to influence the debate on financial reform. Roughly 70,000 of his constituents were involved in financial services, making this a vital issue for his political profile.\n\nGrimm introduced legislation that would prohibit potential whistle-blowers from receiving a cash reward from the Securities and Exchange Commission unless they report wrongdoing to their employers before reporting it to the SEC.\n\nGrimm voted for the fiscal cliff compromise bill that permanently extended most of the Bush tax cuts.\n\nAfter the 2011 shooting of Gabrielle Giffords, Grimm voiced support for \"security-based situational awareness training\", including how to spot suspicious people, when to run for an exit, and how to keep guards at close range. Grimm also said congressmen should consider carrying firearms. House Leader John Boehner called his suggestions an \"excellent idea\" and indicated that security would be a major focus for Congress in 2011.\n\nGrimm voted in favor of the Pain-Capable Unborn Child Protection Act, a bill banning abortions after the 20th week of fertilization.\n\nGrimm voted to repeal the Patient Protection and Affordable Care Act in the House, as he had promised during his campaign. He was called \"hypocritical\" by several Democrats for enrolling in the congressional health-care plan.\n\nGrimm has expressed support for immigration reform and was one of six Republicans to vote against an amendment that would have resumed deportation of \"Dreamers\".\n\nGrimm was appointed to the House Republican Israel Caucus in January 2011, serving as co-chair. In February 2011, as House Republicans were pushing for deep cuts in discretionary spending, Grimm wrote a letter to Eric Cantor saying he would vote against any budget that reduced aid to Israel. Grimm was also named chair of the House Republican Policy Committee's Task Force on Foreign Policy. \n\nGrimm opposed a military strike on the Assad regime in Syria, stating, \"I am no longer convinced that a U.S. strike on Syria will yield a benefit to the United States that will not be greatly outweighed by the extreme cost of war.\"\n\nAccording to a January 27, 2012, \"New York Times \"article, several followers of Orthodox Rabbi Yoshiyahu Yosef Pinto said Grimm's campaign had accepted questionable donations. Three of Pinto's followers reportedly said that Grimm or Ofer Biton, a top aide of Pinto's, had told them that the campaign would find a way to accept donations that were over the legal limit. Grimm stated, \"Any suggestion that I was involved in any activities that may run afoul of the campaign finance laws is categorically false and belied by my life of public service protecting and enforcing the laws of this country.\"\n\nIn June 2013, Grimm stated that he believed water fees should be waived for survivors of Hurricane Sandy who had been displaced from their homes. Under New York City's Department of Environmental Protection rules, all homeowners are subject to a minimum charge of $1.19 per day, even if a home uses no water during a given period. Residents who had been displaced from their homes for long periods of time received water bills over $500 for damaged, vacant properties. Grimm called the bills \"ridiculous,\" saying, \"That's $500 these people could use to replace a washer or dryer or refrigerator swept out to sea during Sandy.\"\n\nOn January 28, 2014, NY1-TV political reporter Michael Scotto was interviewing Grimm in a balcony hallway of the U.S. Capitol building about the recently concluded 2014 State of the Union Address. He then tried to question Grimm about a campaign finance investigation. Grimm said he would not discuss the investigation. As Scotto started to mention the investigation again, Grimm walked off. Scotto then turned to the camera and implied that Grimm did not want to face the issue on camera. Grimm then threatened Scotto, saying that he would \"break [Scotto] in half,\" as well as threatening to throw Scotto over the balcony.\n\nGrimm issued a statement defending his behavior, saying that he was annoyed by what he called a \"disrespectful cheap shot\" from Scotto. The next day, Grimm contacted Scotto to offer an apology for his behavior, which Scotto deemed sincere. Grimm also issued a written apology, saying, \"I shouldn't have allowed my emotions to get the better of me and lose my cool.\" An unnamed former staffer for Grimm and NY1-TV political director Bob Hardt reported that Grimm had behaved in a similar manner to other reporters on previous occasions.\n\nIn early 2014, Grimm and Bill Cassidy cosponsored the Homeowner Flood Insurance Affordability Act. In March 2014, the bill was passed by the U.S. Senate and signed into law by President Obama. The law repealed exponential increases in flood-insurance rates for homeowners in flood-prone areas, preventing \"skyrocketing\" flood insurance premiums for 5.5 million Americans.\n\nAccording to \"Politico\", in April 2014, Grimm became \"the first sitting House Republican to stop denying the science that humans cause climate change.\" Grimm stated, \"The majority of respected scientists say that it's conclusive, the evidence is clear. So I don't think the jury is out.\"\n\n\n\nIn August 2012, the office of the United States Attorney for the Eastern District of New York said it was investigating Grimm's 2010 campaign. In November 2012, the House Ethics Committee decided to inquire into the campaign but agreed to \"defer consideration\" of it at the Department of Justice's request.\n\nOn January 10, 2014, the FBI arrested Diana Durand on charges that she had illegally donated more than $10,000 to Grimm's 2010 campaign. Durand allegedly gave the campaign $4,800, the legal limit, but then used straw donors to donate more than $10,000 illegally. The FBI also charged Durand with lying to federal agents about the matter. Grimm denied any wrongdoing. In September 2014, Durand pleaded guilty to making illegal contributions to Grimm's 2010 campaign.\n\nThe investigation, which originally focused on Grimm's 2010 fundraising, branched out to include Grimm's prior business dealings. On April 25, 2014, Grimm's attorney was advised by the U.S. Attorney's office that his client would be indicted on criminal charges related to Healthalicious. On April 28, prosecutors unsealed a 20-count indictment charging that Grimm and others concealed over $1 million of the restaurant's sales and wages from both the U.S. federal government and the State of New York. Grimm surrendered to the FBI that morning. Grimm pleaded not guilty to all charges and was released on $400,000 bond. He told reporters that he not only had every intention of fighting the charges, but also of staying in office and running for a third term.\n\nOn December 23, 2014, less than two months after winning reelection, Grimm pleaded guilty to one charge of felony tax evasion. He admitted to under-reporting Healthalicious's revenues by over $900,000 over four years and to filing false tax returns based on that under-reported income. He also admitted to using the under-reported receipts to pay restaurant expenses, as well as to make under-the-table cash payments to employees. As part of the plea bargain, the other charges were dropped, but Grimm admitted to two of the offenses in the original indictment: knowingly employing people ineligible to work in the United States and lying in a 2013 deposition. The crimes to which he pleaded guilty carried a prison sentence of up to 30 months.\n\nAt first Grimm admitted making mistakes, but told a reporter he would \"absolutely not\" resign. But on December 29, 2014, it was reported that after discussing the matter with House Speaker John Boehner, Grimm had changed his mind and would decline to take his seat for a third term. He resigned from Congress on January 5, 2015. A special election to replace him was held on May 5, 2015, and Staten Island District Attorney Daniel Donovan, a Republican, was elected to the seat.\n\nOn July 17, 2015, U.S. District Judge Pamela K. Chen suggested that Grimm's moral compass \"needs some reorientation\" and sentenced him to eight months in prison. He surrendered on September 22, 2015, after a brief delay for medical treatment. He was released on May 20, 2016, after serving seven months.\n\nHad Grimm not resigned, his role in Congress would have likely been very limited. Longstanding House rules state that a member convicted of a felony should not take part in floor votes or committee work until the House Ethics Committee reviews the matter. Although there is no constitutional rule barring a convicted felon from voting, Boehner and the Republican leadership would have strongly discouraged Grimm from doing so, and the House Ethics Committee has indicated in the past that convicted felons can be disciplined if they do take part in committee or floor votes.\n\nGrimm lives on Staten Island. He is divorced with no children.\n\n\n"}
{"id": "5324495", "url": "https://en.wikipedia.org/wiki?curid=5324495", "title": "Mixed acid fermentation", "text": "Mixed acid fermentation\n\nMixed acid fermentation is the biological process by which a six-carbon sugar e.g. glucose is converted into a complex and variable mixture of acids. It is an anaerobic fermentation reaction that is common in bacteria. It is characteristic for members of the Enterobacteriaceae, a large family of Gram-negative bacteria that includes \"E. coli\".\n\nThe mixture of end products produced by mixed acid fermentation includes lactate, acetate, succinate, formate, ethanol and the gases H and CO. The formation of these end products depends on the presence of certain key enzymes in the bacterium. The proportion in which they are formed varies between different bacterial species. The mixed acid fermentation pathway differs from other fermentation pathways, which produce fewer end products in fixed amounts. The end products of mixed acid fermentation can have many useful applications in biotechnology and industry. For instance, ethanol is widely used as a biofuel. Therefore, multiple bacterial strains have been metabolically engineered in the laboratory to increase the individual yields of certain end products. This research has been carried out primarily in \"E. coli\" and is ongoing.\n\n\"E. coli\" use fermentation pathways as a final option for energy metabolism, as they produce very little energy in comparison to respiration. \nMixed acid fermentation in \"E. coli\" occurs in two stages. These stages are outlined by the biological database for \"E. coli\", EcoCyc.\n\nThe first of these two stages is a glycolysis reaction. Under anaerobic conditions, a glycolysis reaction takes place where glucose is converted into pyruvate:\n\n      glucose → 2 pyruvate\n\nThere is a net production of 2 ATP and 2 NADH molecules per molecule of glucose converted. ATP is generated by substrate-level phosphorylation. NADH is formed from the reduction of NAD.\n\nIn the second stage, pyruvate produced by glycolysis is converted to one or more end products via the following reactions. In each case, both of the NADH molecules generated by glycolysis are reoxidized to NAD. Each alternative pathway requires a different key enzyme in \"E. coli\". After the variable amounts of different end products are formed by these pathways, they are secreted from the cell.\n\nPyruvate produced by glycolysis is converted to lactate. This reaction is catalysed by the enzyme lactate dehydrogenase (LDHA).\n\n      pyruvate + NADH + H → lactate + NAD\n\nPyruvate is converted into acetyl-coenzyme A (acetyl-CoA) by the enzyme pyruvate dehydrogenase. This acetyl-CoA is then converted into acetate in \"E. coli\", whilst producing ATP by substrate-level phosphorylation. Acetate formation requires two enzymes: phosphate acetyltransferase and acetate kinase. \n      acetyl-CoA + phosphate → acetyl-phosphate + CoA \n\n      acetyl-phosphate + ADP → acetate + ATP\n\nEthanol is formed in \"E. coli\" by the reduction of acetyl coenzyme A using NADH. This two-step reaction requires the enzyme alcohol dehydrogenase (ADHE).\n\n      acetyl-CoA + NADH + H → acetaldehyde + NAD + CoA\n\n      acetaldehyde + NADH + H → ethanol + NAD\n\nFormate is produced by the cleavage of pyruvate. This reaction is catalysed by the enzyme pyruvate-formate lyase (PFL), which plays an important role in regulating anaerobic fermentation in \"E. coli\".\n\n      pyruvate + CoA → acetyl-CoA + formate\n\nSuccinate is formed in \"E. coli\" in several steps.\n\nPhosphoenolpyruvate (PEP), a glycolysis pathway intermediate, is carboxylated by the enzyme PEP carboxylase to form oxaloacetate. \nThis is followed by the conversion of oxaloacetate to malate by the enzyme malate dehydrogenase. Fumarate hydratase then catalyses the dehydration of malate to produce fumarate.\n\n      phosphoenolpyruvate + HCO → oxaloacetate + phosphate\n\n      oxaloacetate + NADH + H → malate + NAD\n\n      malate → fumarate + H0\n\nThe final reaction in the formation of succinate is the reduction of fumarate. It is catalysed by the enzyme fumarate reductase.\n\n      fumarate + NADH + H → succinate + NAD\n\nThis reduction is an anaerobic respiration reaction in \"E. coli\", as it uses electrons associated with NADH dehydrogenase and the electron transport chain. ATP is generated by using an electrochemical gradient and ATP synthase. This is the only case in the mixed acid fermentation pathway where ATP is not produced via substrate-level phosphorylation.\n\nVitamin K, also known as menaquinone, is very important for electron transport to fumarate in \"E. coli\".\n\nFormate can be converted to hydrogen gas and carbon dioxide in \"E. coli\". This reaction requires the enzyme formate-hydrogen lyase. It can be used to prevent the conditions inside the cell becoming too acidic.\n\n      formate → H and CO\n\nThe methyl red (MR) test can detect whether the mixed acid fermentation pathway occurs in microbes when given glucose. A pH indicator is used that turns the test solution red if the pH drops below 4.4. If the fermentation pathway has taken place, the mixture of acids it has produced will make the solution very acidic and cause a red colour change.\n\nThe Methyl red test belongs to a group known as the IMViC tests.\n\nMultiple bacterial strains have been metabolically engineered to increase the individual yields of end products formed by mixed acid fermentation. For instance, strains for the increased production of ethanol, lactate, succinate and acetate have been developed due to the usefulness of these products in biotechnology. \nThe major limiting factor for this engineering is the need to maintain a redox balance in the mixture of acids produced by the fermentation pathway.\n\nEthanol is the most commonly used biofuel and can be produced on large scale via fermentation. The maximum theoretical yield for the production of ethanol was achieved around 20 years. A plasmid that carried the pyruvate decarboxylase and alcohol dehydrogenase genes from the bacteria \"Z.mobilis\" was used by scientists. This was inserted into \"E. coli\" and resulted in an increased yield of ethanol. The genome of this \"E. coli\" strain, KO11, has more recently been sequenced and mapped.\n\nThe \"E. coli\" strain W3110 was genetically engineered to generate 2 moles of acetate for every 1 mole of glucose that undergoes fermentation. This is known as a homoacetate pathway.\n\nLactate can be used to produce a bioplastic called Polylactic acid (PLA). The properties of PLA depend on the ratio of the two optical isomers of lactate (D-lactate and L-lactate). D-lactate is produced by mixed acid fermentation in \"E. coli.\" Early experiments engineered the E.coli strain RR1 to produce either one of the two optical isomers of lactate.\n\nLater experiments modified the \"E. coli strain\" KO11, originally developed to enhance ethanol production. Scientists were able to increase the yield of D-lactate from fermentation by performing several deletions.\n\nIncreasing the yield of succinate from mixed acid fermentation was first done by overexpressing the enzyme PEP carboxylase. This produced a succinate yield that was approximately 3 times greater than normal. Several experiments using a similar approach have followed.\n\nAlternative approaches have altered the redox and ATP balance to optimize the succinate yield.\n\nThere are a number of other fermentation pathways that occur in microbes. All these pathways begin by converting pyruvate, but their end products and the key enzymes they require are different. \nThese pathways include:\n\n"}
{"id": "33820444", "url": "https://en.wikipedia.org/wiki?curid=33820444", "title": "Monatomic gas", "text": "Monatomic gas\n\nIn physics and chemistry, monatomic is a combination of the words \"mono\" and \"atomic\", and means \"single atom\". It is usually applied to gases: a monatomic gas is one in which atoms are not bound to each other. All chemical elements will be monatomic in the gas phase at sufficiently high temperatures. The thermodynamic behavior of monatomic gas is extremely simple when compared to polyatomic gases because it is free of any rotational or vibrational energy.\n\nThe only chemical elements that are stable single atom molecules at standard temperature and pressure (STP) are the noble gases. These are helium, neon, argon, krypton, xenon and radon. Noble gases have a full outer valence shell making them rather non-reactive species. While these elements have been described historically as completely inert, chemical compounds have been synthesized with all but neon and helium.\n\nWhen grouped together with the homonuclear diatomic gases such as nitrogen (N), the noble gases are called \"elemental gases\" or \"molecular gases\" to distinguish them from molecules that are also chemical compounds.\n\nMonatomic hydrogen comprises about 75% of the elemental mass of the universe.\n\nThe motion of a monatomic gas is translation (electronic excitation is not important at room temperature). Thus in an adiabatic process, monatomic gases have an idealised \"γ\"-factor (\"C\"/\"C\") of 5/3, as opposed to 7/5 for ideal diatomic gases where rotation (but not vibration at room temperature) also contributes. Also, for ideal monatomic gases: \nwhere \"R\" is the gas constant.\n"}
{"id": "57969764", "url": "https://en.wikipedia.org/wiki?curid=57969764", "title": "Mortality in the early modern age", "text": "Mortality in the early modern age\n\nThe early modern age saw various economic changes as well as several significant diseases that have affected the mortality rates. Data collection during this time was not consistent or broadly recorded and there have been efforts to reconstruct plausible statistics. Mortality rates vary on geographic location, social environment, and cultural values. There were also gender differences in the mortality rates, leading to an excess mortality rate in urban areas and in the female population. A main cause of death was stillbirth, which could be attributed to, but not limited to, maternal infections, birth complications, and congenital anomalies. Another contributing factor to the mortality rate was food insecurity and shortages as well as unemployment, both of which varied per region. A final factor was violence, which occurred mainly due to structural or systemic violence; however, violence since the 12th century has been steadily falling.\n\nData from the early modern age was not accurately or consistently collected. However, there have been a number of studies and reconstructed statistics from this era, particularly on children and women. There has not been any empirical research published and the only information has been theoretical as there has been insufficient data and sources. It was also common for many statistics to go unreported; this is especially true regarding unmarried women. Models and theoretic equations need to take into account \"social, economic, cultural, geographical, and even climatological variables\" in order to accurately reflect the statistics of the time.\n\nOne study, the Eurasia Project, has shown that boys, especially those under one year, had a higher mortality rate during childhood than girls, but the mortality rate for men and women were about equal. It has also been shown that there is a higher male mortality than female mortality rate during the time of famine. Male mortality has also been linked to \"economic modernization and urbanization ... especially for cardiovascular disease\".\n\nWomen faced increased mortality during childbirth as pregnancy and childbirth compromised the mother's immune system, with the most common causes of death being puerperal fever, toxemia, and hemorrhage. These dangers suggest an association to the excess female mortality, especially considering that women had to compete more for resources as they had no property rights and had a lower ranking in the household hierarchy. The average age of childbearing differed between Asia and Europe with an average difference of five years, which would affect cross-cultural data collection. Children born to mothers 35 years or older had a higher risk of mortality than children born to younger mothers. linking a mother's health and a child's survival.\n\nFemale infants and children often had a higher mortality rate, especially in times of food insecurity, compared to male infants and children. However, a maternal presence worked as a protective factor for children. regardless of age or gender.\n\nFood insecurity and shortages were common throughout this time period and were matched with the high food prices and high unemployment rate. This is shown through the differences in mortality rates between the lower and upper class, with poor infants being up to two times more likely to die than their wealthier counterparts. In 17th century Europe, it was common that at least one in five children from the same family would die before the age of one. Because of this high rate, it was common for there to be a large amount of children in one family so that there would be a higher rate of survival. Especially among poorer families, having multiple children was common in order to ensure there would be children to contribute to the family later on.\n\nDuring the early modern era, house calls were common. If the patient was female, the doctor, commonly an upper class male, would typically be summoned by a male family member who wound remain throughout the examination. The physician and male family member would then discuss the diagnosis and treatment plan without the female's input. This practice reinforced and perpetuated social hierarchies and patriarchal values.\n\nFood shortages and insecurity were leading concerns in the 18th century, especially in Europe, and these were exacerbated by reduced harvests yields. Disease was another leading cause of death, with rats and fleas being the common carriers of disease, specifically plagues, during this era.\n\nThe Black Death was a plague that affected much of the world, originating in Asia and spreading to Europe through diseased fleas and rats. This epidemic has been reported to have been the cause of death for approximately \"60% of the European population\".\n\nDuring the end of the 19th century, there was a plague, known as the Modern Plague, that started in China and spread to different cities through ports, reportedly causing roughly ten million deaths. This plague affected Asia, the Americas, and Africa and lasted into the 20th century. There were also epidemics that occurred locally and did not spread to national levels, notably in 18th century England. These local epidemics included fevers, dysentery, smallpox, starvation, typhoid fever, under-nutrition, cholera, malaria.\n\nBy the end of the era, disease and malnutrition were no longer the main leading causes of death.\n"}
{"id": "20657883", "url": "https://en.wikipedia.org/wiki?curid=20657883", "title": "Mount Storm Wind Farm", "text": "Mount Storm Wind Farm\n\nThe Mount Storm Wind Farm is located 120 miles west of Washington, D.C. in Grant County, West Virginia. The wind farm includes 132 Gamesa G80 wind turbines each with a two megawatt (MW) capacity along 12 miles of the Allegheny Front. Construction of the wind farm began in 2006 and the project is now fully operational, generating up to 264 MW of electricity for the mid-Atlantic power grid.\n\nNedpower Mount Storm, LLC is a joint venture between Shell and Dominion Resources, founded in 2007.\n\nPlans for the farm were first announced in 2001, when U.S. Wind Force filed for a permit with the West Virginia Public Service Commission to build a 166 turbine wind farm, which would have been the largest wind farm east of the Mississippi River. The project's backers hoped that the first turbines would be operational by late 2002 with the rest of the facility coming online in 2003, but opponents quickly raised objections, arguing that the project would threaten birds and diminish home values in the surrounding area.\n\nIn May 2002, the Public Service Commission approved U.S. Wind Force's permit application without any significant opposition. The company also reached an agreement with the AFL-CIO to use union labor in the construction of the facility. At the hearings for the permit, speakers in favor of the project included Walt Helmick, a member of the West Virginia Senate, Jeff Barger, the County Commissioner of Grant County, and Steve White a union leader. A study by the U.S. Fish and Wildlife Service concluded that the project posed little danger to local birds, clearing the way for construction.\n\n"}
{"id": "28269015", "url": "https://en.wikipedia.org/wiki?curid=28269015", "title": "Nature Iraq", "text": "Nature Iraq\n\nNature Iraq (Arabic, طبيعة العراق) is Iraq's first and only environmental conservation group. It is an Iraqi non-governmental organization, accredited to the United Nations Environment Programme (UNEP) and affiliated to BirdLife International. They seek to protect, restore, and preserve Iraq’s natural environment and the rich cultural heritage that depends upon it. They conduct major work in sustainable development, biodiversity, and water resources. Nature Iraq was founded in 2003 by Azzam Alwash, an Iraqi refugee and engineer in the United States who returned to Iraq following the 2003 invasion of Iraq.\n\nThe Key Biodiversity Areas (KBA) Program was initiated by Nature Iraq in partnership with the Iraqi Ministry of Environment and BirdLife International and other international advisory groups and included extensive field survey work from 2004 to 2010 to identify areas of the country that are globally important for their biological diversity. Eighty-two sites have been identified as KBAs in Iraq.\n\nAdobe House was built to demonstrate alternative, low-cost and sustainable building methods that could be applied to alternative housing in the marshland areas.\n\nThe Darwin Project conducts plants and birds’ surveys, creates biodiversity and land use maps, facilitate practical field training courses and an online course for developing professionals, conducts educational activities with school children, creates field guides and other educational resources for conservation managers. \n\nWetlands Restoration has been ongoing. Nature Iraq has successfully re-created some of Iraq's freshwater marshes in the central part of the country. \n\nThe Blue Horizons Laboratories is a private lab offering environmental lab services that was initially started by Nature Iraq. \n\nWaterkeepers Iraq was a program originally started by Nature Iraq but registered as an independent non-governmental organization in 2014. It advocates and works to protect the rivers, streams and waterways of Iraq and supports local communities in the sustainable use of these natural resources. Waterkeepers Iraq is affiliated with the international Waterkeeper Alliance. And is the first waterkeeper organization in the Middle East. \n\n\n"}
{"id": "1381798", "url": "https://en.wikipedia.org/wiki?curid=1381798", "title": "Nuclear Decommissioning Authority", "text": "Nuclear Decommissioning Authority\n\nThe Nuclear Decommissioning Authority (NDA) is a non-departmental public body of the Department for Business, Energy and Industrial Strategy, formed by the Energy Act 2004. It evolved from the Coal and Nuclear Liabilities Unit of the Department of Trade and Industry. It came into existence during late 2004, and took on its main functions on 1 April 2005. Its purpose is to deliver the decommissioning and clean-up of the UK’s civil nuclear legacy in a safe and cost-effective manner, and where possible to accelerate programmes of work that reduce hazard. The NDA does not directly manage the UK's nuclear sites. It oversees the work through contracts with specially designed companies known as Site Licence Companies. The NDA determines the overall strategy and priorities for managing decommissioning.\n\nAlthough the NDA itself only employs 300 staff, its annual budget is £3.2 billion. The vast majority of the NDA budget is spent through contracts with Site Licence Companies, who also sub contract to other companies which provide special services. The NDA aims to do this by introducing innovation and contractor expertise through a series of competitions similar to the model that has been used in the United States.\n\nIn April 2017, the NDA lost a legal case in the Supreme Court regarding the procurement of a sizeable contract for the decommissioning of 12 different Magnox nuclear facilities when EnergySolutions EU Ltd. (now called ATK Energy EU Ltd.) challenged a decision in connection with ATK’s unsuccessful bid. In February 2018 the UK parliament's Public Accounts Committee (PAC) concluded that the NDA had \"dramatically under-estimated\" costs and \"completely failed\" in the procurement and management of the Magnox Ltd contract, which was one of the highest value contracts let by the government. An independent inquiry into the deal was set up.\n\nThe main objectives of NDA are to:\n\n\nResponsibility for operating the sites has been restructured into five Site Licence Companies (SLCs). The management of the SLCs is contracted out to different Parent Body Organisations (PBOs), which are owned by private companies.\n\n\nOn its creation, the NDA also took over ownership of Direct Rail Services, the rail freight operating company set up by BNFL in 1995 to transport nuclear materials.\n\nThe NDA is also the owner of International Nuclear Services, which operates services on behalf of the NDA for the management and transportation of nuclear fuels.\n\nThe NDA is also the owner of Radioactive Waste Management Ltd (RWM), which is responsible for implementing a geological disposal facility in the UK and provide radioactive waste management solutions.\n\nIn February 2017 a national archive for the UK civil nuclear industry, named Nucleus, was opened in Wick, Caithness, Scotland.\n\nIn 2005 the cost of decommissioning these sites was planned at £55.8 billion, with Sellafield requiring £31.5 billion. However, in 2006 the NDA reported that the cost of cleaning up existing waste was higher than previously thought, and gave a new estimated decommissioning cost of about £72 billion over a 100-year period. In 2008 estimated decommissioning costs increased to £73.6 billion, or after taking account of discount rates, £44.1 billion. A 2006 estimate foresaw £14bn of offsetting income from reprocessing fuel at Sellafield. In 2009 the NDA sold land near three existing reactor sites for expected new nuclear power stations, for over £200m.\n\nIn 2013, a critical Public Accounts Committee report stated that the private consortium managing Sellafield has failed to reduce costs and delays. Between 2005 and 2013 the annual costs of operating Sellafield increased from £900 million to about £1.6 billion. The estimated lifetime undiscounted cost of dealing with the Sellafield site increased to £67.5 billion. Bosses were forced to apologise after projected clean-up costs passed the £70 billion mark in late 2013. In 2014, the undiscounted decommissioning cost estimate for Sellafield was increased to £79.1 billion, and by 2015 to £117.4 billion. The annual operating cost will be £2 billion in 2016.\n\nIn 2006, the then Secretary of State for Trade and Industry announced his support for a National Nuclear Laboratory (NNL) to be based on the British Technology Centre at Sellafield and Nexia Solutions. The NDA, as the owner of Sellafield site and the funder of majority of research required across the nuclear estate, was involved establishing the NNL in 2009. The NNL complements other initiatives to develop a sustainable workforce such as the National Skills Academy for Nuclear (NSAN) network, including the development of Energus in West Cumbria, alongside complementary research and development facilities such as the Dalton Nuclear Institute.\n\n"}
{"id": "23234", "url": "https://en.wikipedia.org/wiki?curid=23234", "title": "Paleozoic", "text": "Paleozoic\n\nThe Paleozoic (or Palaeozoic) Era (; from the Greek \"palaios\" (παλαιός), \"old\" and \"zoe\" (ζωή), \"life\", meaning \"ancient life\") is the earliest of three geologic eras of the Phanerozoic Eon. It is the longest of the Phanerozoic eras, lasting from , and is subdivided into six geologic periods (from oldest to youngest): the Cambrian, Ordovician, Silurian, Devonian, Carboniferous, and Permian. The Paleozoic comes after the Neoproterozoic Era of the Proterozoic Eon and is followed by the Mesozoic Era.\n\nThe Paleozoic was a time of dramatic geological, climatic, and evolutionary change. The Cambrian witnessed the most rapid and widespread diversification of life in Earth's history, known as the Cambrian explosion, in which most modern phyla first appeared. Arthropods, molluscs, fish, amphibians, synapsids and diapsids all evolved during the Paleozoic. Life began in the ocean but eventually transitioned onto land, and by the late Paleozoic, it was dominated by various forms of organisms. Great forests of primitive plants covered the continents, many of which formed the coal beds of Europe and eastern North America. Towards the end of the era, large, sophisticated diapsids and synapsids were dominant and the first modern plants (conifers) appeared.\n\nThe Paleozoic Era ended with the largest extinction event in the history of Earth, the Permian–Triassic extinction event. The effects of this catastrophe were so devastating that it took life on land 30 million years into the Mesozoic Era to recover. Recovery of life in the sea may have been much faster.\n\nThe Paleozoic era began and ended with supercontinents and in between were the rise of mountains along the continental margins, and flooding and draining of shallow seas between. At its start, the supercontinent Pannotia broke up. Paleoclimatic studies and evidence of glaciers indicate that central Africa was most likely in the polar regions during the early Paleozoic. During the early Paleozoic, the huge continent Gondwana () formed or was forming. By mid-Paleozoic, the collision of North America and Europe produced the Acadian-Caledonian uplifts, and a subduction plate uplifted eastern Australia. By the late Paleozoic, continental collisions formed the supercontinent of Pangaea and resulted in some of the great mountain chains, including the Appalachians, Ural Mountains, and mountains of Tasmania.\n\nThere are six periods in the Paleozoic Era: Cambrian, Ordovician, Silurian, Devonian, Carboniferous (alternatively subdivided into the Mississippian Period and the Pennsylvanian Period), and the Permian.\n\nThe Cambrian spans from 541 million years to 485 million years and is the first period of the Paleozoic era of the Phanerozoic. The Cambrian marked a boom in evolution in an event known as the Cambrian explosion in which the largest number of creatures evolved in any single period of the history of the Earth. Creatures like algae evolved, but the most ubiquitous of that period were the armored arthropods, like trilobites. Almost all marine phyla evolved in this period. During this time, the supercontinent Pannotia begins to break up, most of which later became the supercontinent Gondwana.\n\nThe Ordovician spanned from approximately 485 million years to approximately 443 million years ago. The Ordovician was a time in Earth's history in which many of the biological classes still prevalent today evolved, such as primitive fish, cephalopods, and coral. The most common forms of life, however, were trilobites, snails and shellfish. More importantly, the first arthropods went ashore to colonize the empty continent of Gondwana. By the end of the Ordovician, Gondwana was at the south pole, early North America had collided with Europe, closing the Atlantic Ocean. Glaciation of Africa resulted in a major drop in sea level, killing off all life that had established along coastal Gondwana. Glaciation may have caused the Ordovician–Silurian extinction events, in which 60% of marine invertebrates and 25% of families became extinct, and is considered the first mass extinction event and the second deadliest.\n\nThe Silurian spanned from 443 to 416 million years ago. The Silurian saw the rejuvenation of life as the Earth recovered from the previous glaciation. This period saw the mass evolution of fish, as jawless fish became more numerous, jawed fish evolved, and the first freshwater fish evolved, though arthropods, such as sea scorpions, were still apex predators. Fully terrestrial life evolved, including early arachnids, fungi, and centipedes. The evolution of vascular plants (Cooksonia) allowed plants to gain a foothold on land. These early plants are the forerunners of all plant life on land. During this time, there were four continents: Gondwana (Africa, South America, Australia, Antarctica, Siberia), Laurentia (North America), Baltica (Northern Europe), and Avalonia (Western Europe). The recent rise in sea levels allowed many new species to thrive in water.\n\nThe Devonian spanned from 416 million years to 359 million years ago. Also known as \"The Age of the Fish\", the Devonian featured a huge diversification of fish, including armored fish like \"Dunkleosteus\" and lobe-finned fish which eventually evolved into the first tetrapods. On land, plant groups diversified incredibly in an event known as the Devonian Explosion when plants made lignin allowing taller growth and vascular tissue: the first trees evolved, as well as seeds. This event also diversified arthropod life, by providing them new habitats. The first amphibians also evolved, and the fish were now at the top of the food chain. Near the end of the Devonian, 70% of all species became extinct in an event known as the Late Devonian extinction, which was the Earth's second mass extinction event.\n\nThe Carboniferous spanned from 359 million to 299 million years ago. During this time, average global temperatures were exceedingly high; the early Carboniferous averaged at about 20 degrees Celsius (but cooled to 10 °C during the Middle Carboniferous). Tropical swamps dominated the Earth, and the lignin stiffened trees grew to greater heights and number. As the bacteria and fungi capable of eating the lignin had not yet evolved, their remains were left buried, which created much of the carbon that became the coal deposits of today (hence the name \"Carboniferous\"). Perhaps the most important evolutionary development of the time was the evolution of amniotic eggs, which allowed amphibians to move farther inland and remain the dominant vertebrates for the duration of this period. Also, the first reptiles and synapsids evolved in the swamps. Throughout the Carboniferous, there was a cooling trend, which led to the Permo-Carboniferous glaciation or the Carboniferous Rainforest Collapse. Gondwana was glaciated as much of it was situated around the south pole.\n\nThe Permian spanned from 299 to 252 million years ago and was the last period of the Paleozoic Era. At the beginning of this period, all continents joined together to form the supercontinent Pangaea, which was encircled by one ocean called Panthalassa. The land mass was very dry during this time, with harsh seasons, as the climate of the interior of Pangaea was not regulated by large bodies of water. Diapsids and synapsids flourished in the new dry climate. Creatures such as Dimetrodon and Edaphosaurus ruled the new continent. The first conifers evolved, and dominated the terrestrial landscape. Near the end of the Permian, however, Pangaea grew drier. The interior was desert, and new species such as Scutosaurus and Gorgonopsids filled it. Eventually they disappeared, along with 95% of all life on Earth, in a cataclysm known as \"The Great Dying\", the third and most severe mass extinction.\n\nGeologically, the Paleozoic started shortly after the breakup of the supercontinent Pannotia. Throughout the early Paleozoic, that landmass was broken into a substantial number of continents. Towards the end of the era, the continents gathered together into a supercontinent called Pangaea, which included most of the Earth's land area.\n\nThe earliest two periods, the Ordovician and Silurian, were warm greenhouse periods, with the highest sea levels of the Paleozoic (200 m above today's); the warm climate was interrupted only by a cool period, the Early Palaeozoic Icehouse, culminating in the Huronian glaciation, at the end of the Ordovician.\n\nThe early Cambrian climate was probably moderate at first, becoming warmer over the course of the Cambrian, as the second-greatest sustained sea level rise in the Phanerozoic got underway. However, as if to offset this trend, Gondwana moved south, so that, in Ordovician time, most of West Gondwana (Africa and South America) lay directly over the South Pole. The early Paleozoic climate was also strongly zonal, with the result that the \"climate\", in an abstract sense, became warmer, but the living space of most organisms of the time—the continental shelf marine environment—became steadily colder. However, Baltica (Northern Europe and Russia) and Laurentia (eastern North America and Greenland) remained in the tropical zone, while China and Australia lay in waters which were at least temperate. The early Paleozoic ended, rather abruptly, with the short, but apparently severe, late Ordovician ice age. This cold spell caused the second-greatest mass extinction of Phanerozoic time. Over time, the warmer weather moved into the Paleozoic Era.\n\nThe middle Paleozoic was a time of considerable stability. Sea levels had dropped coincident with the ice age, but slowly recovered over the course of the Silurian and Devonian. The slow merger of Baltica and Laurentia, and the northward movement of bits and pieces of Gondwana created numerous new regions of relatively warm, shallow sea floor. As plants took hold on the continental margins, oxygen levels increased and carbon dioxide dropped, although much less dramatically. The north–south temperature gradient also seems to have moderated, or metazoan life simply became hardier, or both. At any event, the far southern continental margins of Antarctica and West Gondwana became increasingly less barren. The Devonian ended with a series of turnover pulses which killed off much of middle Paleozoic vertebrate life, without noticeably reducing species diversity overall.\n\nThere are many unanswered questions about the late Paleozoic. The Mississippian (early Carboniferous Period) began with a spike in atmospheric oxygen, while carbon dioxide plummeted to new lows. This destabilized the climate and led to one, and perhaps two, ice ages during the Carboniferous. These were far more severe than the brief Late Ordovician ice age; but, this time, the effects on world biota were inconsequential. By the Cisuralian Epoch, both oxygen and carbon dioxide had recovered to more normal levels. On the other hand, the assembly of Pangaea created huge arid inland areas subject to temperature extremes. The Lopingian Epoch is associated with falling sea levels, increased carbon dioxide and general climatic deterioration, culminating in the devastation of the Permian extinction.\n\nWhile macroscopic plant life appeared early in the Paleozoic Era and possibly late in the Neoproterozoic Era of the earlier eon. Plants mostly remained aquatic until sometime in the Silurian and Devonian Periods, about 420 million years ago, when they began to transition onto dry land. Terrestrial flora reached its climax in the Carboniferous, when towering lycopsid rainforests dominated the tropical belt of Euramerica. Climate change caused the Carboniferous Rainforest Collapse which fragmented this habitat, diminishing the diversity of plant life in the late Carboniferous and Permian.\n\nA noteworthy feature of Paleozoic life is the sudden appearance of nearly all of the invertebrate animal phyla in great abundance at the beginning of the Cambrian. The first vertebrates appeared in the form of primitive fish, which greatly diversified in the Silurian and Devonian Periods. The first animals to venture onto dry land were the arthropods. Some fish had lungs, and powerful bony fins that in the late Devonian, 367.5 million years ago, allowed them to crawl onto land. The bones in their fins eventually evolved into legs and they became the first tetrapods, , and began to develop lungs. Amphibians were the dominant tetrapods until the mid-Carboniferous, when climate change greatly reduced their diversity. Later, reptiles prospered and continued to increase in number and variety by the late Permian.\n\n\n\n"}
{"id": "13828980", "url": "https://en.wikipedia.org/wiki?curid=13828980", "title": "Pedro Cubero", "text": "Pedro Cubero\n\nPedro Cubero Sebastián (El Frasno, Spain, 1645 – p.1700) was a Spanish priest, best known for his travel around the world from 1670 to 1679. Taking in account his world circumnavigation and his journeys across Europe he was undoubtedly one of the most widely traveled men in his time.\n\nPedro Cubero was born in the village of El Frasno, near to Calatayud, in the Spanish region of Aragón. He studied in Zaragoza and Salamanca, up to his ordination as a priest in Zaragoza, and soon afterwards went to Rome, where he joined the Propaganda Fide congregation.\n\nIn accordance with his missionary work, he undertook in 1670 a journey to East Asia, that eventually led him to complete an eastwards around the world trip. The journey is specially memorable as for the first time in History a considerable part of the way was done overland, through Western and Eastern Europe, Western and Central Asia and North America. So, he preceded Gemelli Careri who undertook a similar voyage twenty years later.\n\nActually, he visited Paris, Venice, Istanbul, Warsaw (he attended there the enthronement of John III Sobieski), Vilna, Moscow (where he met Nicolae Milescu, who acted as Cubero's interpreter), Astrakhan, Isfahan, Bandar Abbass, Surat, Goa, Colombo, Mylapore, Malacca, Philippines, Moluccas, Acapulco, Veracruz, Havana and eventually Cádiz, among many other places.\n\nWhile sailing from Colombo to Mylapore Cubero was captured by Malabar pirates and enslaved in the Maldive Islands for a few months. In Malacca, he was put in jail by the Dutch Governor, accused of publicly preaching Catholicism. \n\nOnce in the Philippines, a Spanish colony, he realized that he was not very welcomed, as he did not belong to any of the Religious Orders that monopolized the missionary work. While in Manila he suffered the big earthquake of November 29, 1677. He went for a while to Tidore, despite the recent withdrawal of the Spanish forces there, and it is not clear if he actually entered China although anyway he dedicated three very detailed chapters of his \"Peregrinación del Mundo\" to China, Tartary and the Chinese-Tartarian wars.\n\nAs he felt somehow passed over in the Philippines, he eventually decided to proceed to New Spain. He crossed the Pacific Ocean in the 1678 sailing of the Manila galleon, that time a carrack named \"San Antonio de Padua\" commanded by Don Felipe Montemayor y Prado. The navigation started in Cavite on 24 June, they caught sight of the American land on 5 December in latitude North of 29 degrees and docked in Acapulco on 8 January 1679. Only 192 people were alive, several of them dying, out of more than 400 that had begun the voyage.\nIn New Spain he again did not feel himself useful, and decided to return to Spain, this time crossing the Atlantic Ocean.\nHe finally reached Madrid in January 1680, just in time to attend the celebrations of the arrival of Maria Luisa of Orléans, recently married to King Charles II of Spain.\n\nHe wrote the account of his adventures around the world in a very objective, detailed and interesting book, Peregrinación del mundo (\"World's peregrination\"), first published in Madrid in 1680. An extended second edition was brought out in 1682 in Naples, by then a Spanish possession.\n\nLater on Cubero went again to Rome, and was appointed by the Holy See \"Apostolic confessor\" of the Army of Leopold I, Holy Roman Emperor and King of Hungary, in the Great Turkish War. There he witnessed the 1686 siege of Buda. He then traveled to other European countries, and in 1697 published a second book, \"Segunda Peregrinación ...\", that gathered together his European experiences.\n\n\n\n"}
{"id": "27213579", "url": "https://en.wikipedia.org/wiki?curid=27213579", "title": "Photo-erosion", "text": "Photo-erosion\n\nPhoto-erosion is the dispersion of the outer layers of a prestellar core by the ionizing radiation of a nearby star.\n\nThis erosion prevents the accretion of these outer layers around the protostar at the centre of the core; and this, in turn, prevents the protostar from becoming a fully fledged star. The protostar instead becomes a brown dwarf or planetary-mass object.\n"}
{"id": "636219", "url": "https://en.wikipedia.org/wiki?curid=636219", "title": "Pressure vessel", "text": "Pressure vessel\n\nA pressure vessel is a container designed to hold gases or liquids at a pressure substantially different from the ambient pressure.\n\nPressure vessels can be dangerous, and fatal accidents have occurred in the history of their development and operation. Consequently, pressure vessel design, manufacture, and operation are regulated by engineering authorities backed by legislation. For these reasons, the definition of a pressure vessel varies from country to country.\n\nDesign involves parameters such as maximum safe operating pressure and temperature, safety factor, corrosion allowance and minimum design temperature (for brittle fracture). Construction is tested using nondestructive testing, such as ultrasonic testing, radiography, and pressure tests. Hydrostatic tests use water, but pneumatic tests use air or another gas. Hydrostatic testing is preferred, because it is a safer method, as much less energy is released if a fracture occurs during the test (water does not rapidly increase its volume when rapid depressurization occurs, unlike gases like air, which fail explosively).\n\nIn most countries, vessels over a certain size and pressure must be built to a formal code. In the United States that code is the ASME Boiler and Pressure Vessel Code (BPVC). These vessels also require an authorized inspector to sign off on every new vessel constructed and each vessel has a nameplate with pertinent information about the vessel, such as maximum allowable working pressure, maximum temperature, minimum design metal temperature, what company manufactured it, the date, its registration number (through the National Board), and ASME's official stamp for pressure vessels (U-stamp). The nameplate makes the vessel traceable and officially an ASME Code vessel.\n\nThe earliest documented design of pressure vessels was described in 1495 in the book by Leonardo da Vinci, the Codex Madrid I, in which containers of pressurized air were theorized to lift heavy weights underwater. However, vessels resembling those used today did not come about until the 1800s, when steam was generated in boilers helping to spur the industrial revolution. However, with poor material quality and manufacturing techniques along with improper knowledge of design, operation and maintenance there was a large number of damaging and often fatal explosions associated with these boilers and pressure vessels, with a death occurring on a nearly daily basis in the United States. Local providences and states in the US began enacting rules for constructing these vessels after some particularly devastating vessel failures occurred killing dozens of people at a time, which made it difficult for manufacturers to keep up with the varied rules from one location to another and the first pressure vessel code was developed starting in 1911 and released in 1914, starting the ASME Boiler and Pressure Vessel Code (BPVC). In an early effort to design a tank capable of withstanding pressures up to , a diameter tank was developed in 1919 that was spirally-wound with two layers of high tensile strength steel wire to prevent sidewall rupture, and the end caps longitudinally reinforced with lengthwise high-tensile rods. The need for high pressure and temperature vessels for petroleum refineries and chemical plants gave rise to vessels joined with welding instead of rivets (which were unsuitable for the pressures and temperatures required) and in the 1920s and 1930s the BPVC included welding as an acceptable means of construction, and welding is the main means of joining metal vessels today.\n\nThere have been many advancements in the field of pressure vessel engineering such as advanced non-destructive examination, phased array ultrasonic testing and radiography, new material grades with increased corrosion resistance and stronger materials, and new ways to join materials such as explosion welding (to attach one metal sheet to another, usually a thin corrosion resistant metal like stainless steel to a stronger metal like carbon steel), friction stir welding (which attaches the metals together without melting the metal), advanced theories and means of more accurately assessing the stresses encountered in vessels such as with the use of Finite Element Analysis, allowing the vessels to be built safer and more efficiently. Today vessels in the USA require BPVC stamping but the BPVC is not just a domestic code, many other countries have adopted the BPVC as their official code. There are, however, other official codes in some countries (some of which rely on portions of and reference the BPVC), Japan, Australia, Canada, Britain, and Europe have their own codes. Regardless of the country nearly all recognize the inherent potential hazards of pressure vessels and the need for standards and codes regulating their design and construction.\n\nPressure vessels can theoretically be almost any shape, but shapes made of sections of spheres, cylinders, and cones are usually employed. A common design is a cylinder with end caps called heads. Head shapes are frequently either hemispherical or dished (torispherical). More complicated shapes have historically been much harder to analyze for safe operation and are usually far more difficult to construct.\n\nTheoretically, a spherical pressure vessel has approximately twice the strength of a cylindrical pressure vessel with the same wall thickness, and is the ideal shape to hold internal pressure. However, a spherical shape is difficult to manufacture, and therefore more expensive, so most pressure vessels are cylindrical with 2:1 semi-elliptical heads or end caps on each end. Smaller pressure vessels are assembled from a pipe and two covers. For cylindrical vessels with a diameter up to 600 mm (NPS of 24 in), it is possible to use seamless pipe for the shell, thus avoiding many inspection and testing issues, mainly the nondestructive examination of radiography for the long seam if required. A disadvantage of these vessels is that greater diameters are more expensive, so that for example the most economic shape of a , pressure vessel might be a diameter of and a length of including the 2:1 semi-elliptical domed end caps.\n\nMany pressure vessels are made of steel. To manufacture a cylindrical or spherical pressure vessel, rolled and possibly forged parts would have to be welded together. Some mechanical properties of steel, achieved by rolling or forging, could be adversely affected by welding, unless special precautions are taken. In addition to adequate mechanical strength, current standards dictate the use of steel with a high impact resistance, especially for vessels used in low temperatures. In applications where carbon steel would suffer corrosion, special corrosion resistant material should also be used.\n\nSome pressure vessels are made of composite materials, such as filament wound composite using carbon fibre held in place with a polymer. Due to the very high tensile strength of carbon fibre these vessels can be very light, but are much more difficult to manufacture. The composite material may be wound around a metal liner, forming a composite overwrapped pressure vessel.\n\nOther very common materials include polymers such as PET in carbonated beverage containers and copper in plumbing.\n\nPressure vessels may be lined with various metals, ceramics, or polymers to prevent leaking and protect the structure of the vessel from the contained medium. This liner may also carry a significant portion of the pressure load.\n\nPressure Vessels may also be constructed from concrete (PCV) or other materials which are weak in tension. Cabling, wrapped around the vessel or within the wall or the vessel itself, provides the necessary tension to resist the internal pressure. A \"leakproof steel thin membrane\" lines the internal wall of the vessel. Such vessels can be assembled from modular pieces and so have \"no inherent size limitations\". There is also a high order of redundancy thanks to the large number of individual cables resisting the internal pressure.\n\nThe very small cylindrical vessel making the body of a (cigarette) lighter filled with liquid butane (about 2 bar pressure, according to temperature) are often oval (1 x 2 cm ... 1.3 x 2.5 cm) in cross section, but sometimes circular. The oval versions are hold in form by one or two tension struts that seem to be incomplete lengthwise separation walls.\n\n\nThe typical circular-cylindrical high pressure gas cylinders for permanent gases (that do not liquify at storing pressure, like air, oxygen, nitrogen, hydrogen, argon, helium) have been manufactured by hot forging by pressing and rolling to get a seamless steel vessel.\n\nWorking pressure of cylinders for use in industry, skilled craft, diving and medicine had a standardized working pressure (WP) of only 150 bars in Europe until about 1950. Since about 1975 until now the standard pressure is 200 bar. Firemen need slim (and lightweight) cylinders to move in confined spaces, about 1995 cylinders for 300 bar WP came up – first in pure steel.\n\nThe push to lighter weight lead to different generations of composite (fiber and matrix, over a liner) cylinders that are more easily damageable by a hit from outside. Wall thickness helps to resist. Therefore composite cylinders – fire fighting is an important market – usually are built for 300 bar.\n\nHydraulic (filled with water) testing pressure is – since ever – usually 50 % higher than the working pressure.\n\nUntil 1990 all high pressure cylinders produced had a conical (tapered) thread to fit the accordingly manufactured cylinder valves. Two types dominate until now the full metal cylinders in industrial use from 0.2 to 50 litre volume. To screw in the valve a hight torque of typically 200 Nm is necessary for the bigger (23 mm?) thread has to be applied and 100 Nm for the smaller (17 mm?) one. Until round 1950 still hemp has been used as sealant, later a thin sheet of lead pressed to a hat with a hole on top. To avoid lead since about 2005/2010 PTFE-band is used.\n\nA conical thread is simple construction but it needs a high torque and leads to high radial forces in the neck. All Cylinders built for 300 bar WP, all diving cylinders and all composite cylinders use cylindrical threads. Either 25 x 1.5 mm or – rather for smaller cylinders – the smaller 18 x 1,5 mm. These connections are sealed by an elastomer O-ring pressed by the gas, have a bed-stop and need only about 20 Nm torque compatible with all 3 types of composite cylinders.\n\nTo classify the different making principles of composite cylinders 4 types are defined.\n\n\nType 2 and 3 cylinders came up around 1995. Type 4 cylinders are commercially available at least from 2016 on.\n\nLeak before burst describes a pressure vessel designed such that a crack in the vessel will grow through the wall, allowing the contained fluid to escape and reducing the pressure, prior to growing so large as to cause fracture at the operating pressure.\n\nMany pressure vessel standards, including the ASME Boiler and Pressure Vessel Code and the AIAA metallic pressure vessel standard, either require pressure vessel designs to be leak before burst, or require pressure vessels to meet more stringent requirements for fatigue and fracture if they are not shown to be leak before burst.\n\nAs the pressure vessel is designed to a pressure, there is typically a safety valve or relief valve to ensure that this pressure is not exceeded in operation.\n\nPressure vessel closures are pressure retaining structures designed to provide quick access to pipelines, pressure vessels, pig traps, filters and filtration systems. Typically pressure vessel closures allow maintenance personnel.\n\nPressure vessels are used in a variety of applications in both industry and the private sector. They appear in these sectors as industrial compressed air receivers and domestic hot water storage tanks. Other examples of pressure vessels are diving cylinders, recompression chambers, distillation towers, pressure reactors, autoclaves, and many other vessels in mining operations, oil refineries and petrochemical plants, nuclear reactor vessels, submarine and space ship habitats, pneumatic reservoirs, hydraulic reservoirs under pressure, rail vehicle airbrake reservoirs, road vehicle airbrake reservoirs, and storage vessels for liquified gases such as ammonia, chlorine, and LPG (propane, butane).\n\nA unique application of a pressure vessel is the passenger cabin of an airliner: the outer skin carries both the aircraft maneuvering loads and the cabin pressurization loads.\n\nDepending on the application and local circumstances, alternatives to pressure vessels exist. Examples can be seen in domestic water collection systems, where the following may be used:\n\nNo matter what shape it takes, the minimum mass of a pressure vessel scales with the pressure and volume it contains and is inversely proportional to the strength to weight ratio of the construction material (minimum mass decreases as strength increases).\n\nPressure vessels are held together against the gas pressure due to tensile forces within the walls of the container. The normal (tensile) stress in the walls of the container is proportional to the pressure and radius of the vessel and inversely proportional to the thickness of the walls. Therefore, pressure vessels are designed to have a thickness proportional to the radius of tank and the pressure of the tank and inversely proportional to the maximum allowed normal stress of the particular material used in the walls of the container.\n\nBecause (for a given pressure) the thickness of the walls scales with the radius of the tank, the mass of a tank (which scales as the length times radius times thickness of the wall for a cylindrical tank) scales with the volume of the gas held (which scales as length times radius squared). The exact formula varies with the tank shape but depends on the density, ρ, and maximum allowable stress σ of the material in addition to the pressure P and volume V of the vessel. (See below for the exact equations for the stress in the walls.)\n\nFor a sphere, the minimum mass of a pressure vessel is\n\nwhere:\n\nOther shapes besides a sphere have constants larger than 3/2 (infinite cylinders take 2), although some tanks, such as non-spherical wound composite tanks can approach this.\n\nThis is sometimes called a \"bullet\" for its shape, although in geometric terms it is a capsule.\n\nFor a cylinder with hemispherical ends,\nwhere\n\nIn a vessel with an aspect ratio of middle cylinder width to radius of 2:1,\n\nIn looking at the first equation, the factor PV, in SI units, is in units of (pressurization) energy. For a stored gas, PV is proportional to the mass of gas at a given temperature, thus\n\nThe other factors are constant for a given vessel shape and material. So we can see that there is no theoretical \"efficiency of scale\", in terms of the ratio of pressure vessel mass to pressurization energy, or of pressure vessel mass to stored gas mass. For storing gases, \"tankage efficiency\" is independent of pressure, at least for the same temperature.\n\nSo, for example, a typical design for a minimum mass tank to hold helium (as a pressurant gas) on a rocket would use a spherical chamber for a minimum shape constant, carbon fiber for best possible formula_10, and very cold helium for best possible formula_11.\n\nStress in a shallow-walled pressure vessel in the shape of a sphere is\nwhere formula_13 is hoop stress, or stress in the circumferential direction, formula_14 is stress in the longitudinal direction, \"p\" is internal gauge pressure, \"r\" is the inner radius of the sphere, and \"t\" is thickness of the sphere wall. A vessel can be considered \"shallow-walled\" if the diameter is at least 10 times (sometimes cited as 20 times) greater than the wall depth.\nStress in a shallow-walled pressure vessel in the shape of a cylinder is\n\nwhere:\n\nAlmost all pressure vessel design standards contain variations of these two formulas with additional empirical terms to account for variation of stresses across thickness, quality control of welds and in-service corrosion allowances.\nAll formulae mentioned above assume uniform distribution of membrane stresses across thickness of shell but in reality, that is not the case. Deeper analysis is given by Lame's theory. The formulae of pressure vessel design standards are extension of Lame's theory by putting some limit on ratio of inner radius and thickness.\n\nFor example, the ASME Boiler and Pressure Vessel Code (BPVC) (UG-27) formulas are:\nSpherical shells: Thickness has to be less than 0.356 times inner radius\n\nCylindrical shells: Thickness has to be less than 0.5 times inner radius\n\nwhere \"E\" is the joint efficient, and all others variables as stated above.\n\nThe factor of safety is often included in these formulas as well, in the case of the ASME BPVC this term is included in the material stress value when solving for pressure or thickness.\n\nWound infinite cylindrical shapes optimally take a winding angle of 54.7 degrees, as this gives the necessary twice the strength in the circumferential direction to the longitudinal.\n\nPressure vessels are designed to operate safely at a specific pressure and temperature, technically referred to as the \"Design Pressure\" and \"Design Temperature\". A vessel that is inadequately designed to handle a high pressure constitutes a very significant safety hazard. Because of that, the design and certification of pressure vessels is governed by design codes such as the ASME Boiler and Pressure Vessel Code in North America, the Pressure Equipment Directive of the EU (PED), Japanese Industrial Standard (JIS), CSA B51 in Canada, Australian Standards in Australia and other international standards like Lloyd's, Germanischer Lloyd, Det Norske Veritas, Société Générale de Surveillance (SGS S.A.), Lloyd’s Register Energy Nederland (formerly known as Stoomwezen) etc.\n\nNote that where the pressure-volume product is part of a safety standard, any incompressible liquid in the vessel can be excluded as it does not contribute to the potential energy stored in the vessel, so only the volume of the compressible part such as gas is used.\n\n\n\n\n"}
{"id": "1434618", "url": "https://en.wikipedia.org/wiki?curid=1434618", "title": "Propane refrigeration", "text": "Propane refrigeration\n\nPropane refrigeration is a type of compression refrigeration. Propane (R290) has been used successfully in industrial refrigeration for many years, and is emerging as an increasingly viable alternative for homes and businesses. Propane's operating pressures and temperatures are well suited for use in air conditioning equipment, but because of propane’s flammability, great care is required in the manufacture, installation and servicing of equipment that uses it as a refrigerant.\n\nPropane that is supplied for general use – such as in barbeques and patio heaters – is not suitable for use in refrigeration systems because it can contain high levels of contaminants, including moisture and unsaturated hydrocarbons. Only propane produced specifically for use in refrigeration systems – with a purity of at least 98.5% and moisture content below 10ppm (by weight) – should be used.\n\nWith a global warming potential (GWP) of 3 and an ozone depletion potential (ODP) of 0, R-290 is of very little threat to the environment. The Environmental Protection Agency (EPA) has listed R-290 as an acceptable refrigerant substitute under its Significant New Alternatives Policy (SNAP), and recently exempted it from the venting prohibition in Section 608 of the Clean Air Act.\n"}
{"id": "23373071", "url": "https://en.wikipedia.org/wiki?curid=23373071", "title": "Pseudospark switch", "text": "Pseudospark switch\n\nThe pseudospark switch, also known as a cold-cathode thyratron due to the similarities with regular thyratrons, is a gas-filled tube capable of high speed switching. Advantages of pseudospark switches include the ability to carry reverse currents (up to 100%), low pulse, high lifetime, and a high current rise of about 10 A/sec. In addition, since the cathode is not heated prior to switching, the standby power is approximately one order of magnitude lower than in thyratrons. However, pseudospark switches have undesired plasma phenomena at low peak currents. Issues such as current quenching, chopping, and impedance fluctuations occur at currents less than 2-3 kA while at very high peak currents (20-30 kA) a transition to a metal vapor arc occurs which leads to erosion of the electrodes. Pseudospark switches are functionally similar to triggered spark gaps.\n\nA pseudospark switch's electrodes (cathode and anode) have central holes approximately 3 to 5 mm in diameter. Behind the cathode and anode lie a hollow cathode and hollow anode, respectively. The electrodes are separated by an insulator. A low pressure (less than 50 Pa) \"working gas\" (typically hydrogen) is contained between the electrodes.\n\nWhile a pseudospark switch is generally fairly simple in construction, engineering a switch for higher lifetimes is more difficult. One method of extending the lifetime is to create a multichannel pseudospark switch to distribute the current and as a result, decrease the erosion. Another method is to simply use cathode materials more resistant to erosion.\n\nTypical electrode materials include copper, nickel, tungsten/rhenium, molybdenum, tantalum, and ceramic materials. Tantalum, however, cannot be used with hydrogen due to chemical erosion affecting the lifetime adversely. Of the metals, tungsten and molybdenum are commonly used, though molybdenum electrodes show issues with reignition behavior. Several papers which compare electrode materials claim tungsten is the most suitable of the metal electrodes tested. Some ceramic materials such as silicon carbide and boron carbide have proven to be excellent electrode materials as well, with lower erosion rates than tungsten in certain cases.\n\nIn a pseudospark discharge a breakdown is first triggered between the electrodes by applying a voltage. The gas then breaks down as a function of the pressure, distance, and voltage. An \"ionization avalanche\" then occurs producing a homogeneous discharge plasma confined to the central regions of the electrodes.\n\nIn the figure above, the various stages of the pseudospark discharge can be seen. Stage (I) is the triggering or low current phase. The discharges in both stage (II), the hollow cathode phase, and stage (III), the borehole phase, are capable of carrying currents of several hundred amps. The transition from the borehole phase to the high current phase (IV) is very fast, characterized by a sudden jump in switch impedance. The last phase (V) only occurs for currents of several 10 kA and is unwelcome as it results in high erosion rates.\n\n\n\n"}
{"id": "12623930", "url": "https://en.wikipedia.org/wiki?curid=12623930", "title": "Pyrotechnic initiator", "text": "Pyrotechnic initiator\n\nA pyrotechnic initiator (also initiator or igniter) is a device containing a pyrotechnic composition used primarily to ignite other, more difficult-to-ignite materials, e.g. thermites, gas generators, and solid-fuel rockets. The name is often used also for the compositions themselves.\n\nPyrotechnic initiators are often controlled electrically (called electro-pyrotechnic initiators), e.g. using a heated bridgewire or a \"bridge resistor\". They are somewhat similar to blasting caps or other detonators, but they differ in that there is no intention to produce a shock wave. An example of such pyrotechnic initiator is an electric match.\n\nThe energetic material used, often called pyrogen, is usually a pyrotechnic composition made of a fuel and oxidizer, where the fuel produces a significant amount of hot particles that cause/promote the ignition of the desired material.\n\nInitiator compositions are similar to flash powders, but they differ in burning speed, as explosion is not intended, and have intentionally high production of hot particles. They also tend to be easier to ignite than thermites, with which they also share similarities.\n\nCommon oxidizers used are potassium perchlorate and potassium nitrate. Common fuels used are titanium, titanium(II) hydride, zirconium, zirconium hydride, and boron. The size of the fuel particles is determined to produce hot particles with the required burning time. \n\nMore exotic materials can be used, e.g. carboranes. \n\nFor special applications, pyrophoric igniters can be used which burst into flame in contact with air. Triethylborane was used as an igniter for the Lockheed SR-71 jet engines.\n\nOne of the most common initiators is ZPP, or zirconium – potassium perchlorate – a mixture of metallic zirconium and potassium perchlorate. It is also known as the NASA Standard Initiator. It yields rapid pressure rise, generates little gas, emits hot particles when ignited, is thermally stable, has long shelf life, and is stable under vacuum. It is sensitive to static electricity.\n\nAnother common igniter formula is BPN, BKNO3, or boron – potassium nitrate, a mixture of 25% boron and 75% potassium nitrate by weight. It is used e.g. by NASA. It is thermally stable, stable in vacuum, and its burn rate is independent of pressure.\n\nIn comparison with black powder, BPN burns significantly hotter and leaves more of solid residues, therefore black powder is favored for multiple-use systems.\n\nBPN's high temperature makes it suitable for uses where rapid and reproducible initiation is critical, e.g. for airbags, rocket engines, and decoy flares. It is however relatively expensive. \n\nBPN can be also used as an ingredient of solid rocket propellants. \n\nBPN can be ignited by a laser. A semiconductor laser of at least 0.4 watts output can be used for ignition in vacuum. \n\nOther mixtures encountered are aluminium-potassium perchlorate and titanium-aluminium-potassium perchlorate. \n\nMetal hydride-oxidizer mixtures replace the metal with its corresponding hydride. They are generally safer to handle than the corresponding metal-oxidizer compositions. During burning they also release hydrogen, which can act as a secondary fuel. Zirconium hydride, titanium hydride, and boron hydride are commonly used.\n\nZHPP (zirconium hydride – potassium perchlorate) is a variant of ZPP that uses zirconium hydride instead of pure zirconium. It is significantly safer to handle than ZPP. \n\nTHPP (titanium hydride potassium perchlorate) is a mixture of titanium(II) hydride and potassium perchlorate. It is similar to ZHPP. Like ZHPP, it is safer to handle than titanium-potassium perchlorate. \n\nFormation of an intermetallic compound can be a strongly exothermic reaction, usable as an initiator.\n\nTitanium-boron composition is one of the hottest pyrotechnic reactions in common usage. It is solid-state, gasless. It can be used as a pyrotechnic initiator or for heating confined gas to perform mechanical work. \n\nNickel-aluminium laminates can be used as electrically initiated pyrotechnic initiators. NanoFoil is such material, commercially available.\n\nPalladium-clad aluminium wires can be used as a fuse wire, known as Pyrofuze. The reaction is initiated by heat, typically supplied by electric current pulse. The reaction begins at 600 °C, the melting point of aluminium, and proceeds violently to temperature of 2200–2800 °C. The reaction does not need presence of oxygen, and the wire is consumed. \n\nPyrofuze comes as a solid wire of different diameters (from 0.002\" to 0.02\"), braided wire, ribbon, foil, and granules. Palladium, platinum, or palladium alloyed with 5% ruthenium can be used together with aluminium. Pyrofuze bridgewires can be used in squibs and electric matches. Pyrofuze foils can be used for e.g. sealing of various dispensers or fire extinguishing systems. Palladium-magnesium composition can also be used, but is not commercially available or not at least as common. \n\nBNCP, (\"cis\"-bis-(5-nitrotetrazolato)tetraminecobalt(III) perchlorate) is another common initiator material. It is relatively insensitive. It undergoes deflagration to detonation transition in a relatively short distance, allowing its use in detonators. Its burning byproducts are of relatively little harm to environment. It can be ignited by a laser diode.\n\nLead azide (Pb(N), or PbN) is occasionally used in pyrotechnic initiators.\n\nOther materials sensitive to heat can be used as well, e.g. HMTD, tetrazene explosive, lead mononitro-resorcinates, lead dinitro-resorcinates, and lead trinitro-resorcinates. \n\n"}
{"id": "23158290", "url": "https://en.wikipedia.org/wiki?curid=23158290", "title": "Racing Green Endurance", "text": "Racing Green Endurance\n\nRacing Green Endurance (RGE) is a student-led project at Imperial College London to demonstrate the potential of zero emission cars. The team drove 26,000 km down the Pan-American Highway starting from north Alaska in July 2010, this was filmed by the documentary maker Claudio Von Planta.\n\nSustainability - Electric vehicles have the potential to realise a sustainable transport future, without depleting valuable resources for future generations. The RGE project aims to demonstrate this while pushing the boundaries of electric vehicle (EV) technology. \nEducation - The team want to help encourage the next generation of scientists and engineers through the outreach program. They plan to use the RGE project as an exhilarating example of where maths and science can take you. \nAdventure - The Radical SR\"Zero\" aims to be the world’s most focused, fun-to-drive alternative propulsion vehicle. By taking on this epic journey, they hope to add a sense of excitement and get people interested in electric vehicles.\n\nRGE was sponsored an SR8 rolling chassis by Radical Sportscars to convert into a road legal electric sportscar. The electric SR8, dubbed the SR\"Zero\", was designed and built in just 7 months with components donated by many other companies. \nOn May 21, 2010, the car drove for the first time, but subsequent problems with electromagnetic interference (EMI) put the car back in the garage for several days work to rectify the problem. However, by the end of April the car had been successfully track tested up to a limited speed of 100 mph (160 km/h).\nOn April 29, 2010 the car passed the Individual Vehicle Assessment (IVA), and so is road legal in the UK and abroad. The SR\"Zero\" now has the largest battery pack by energy storage out of any known road legalised vehicle in the UK.\n\nIn July 2010 the team took the 400 bhp SR\"Zero\" all 26,000 km of the Pan-American Highway, educating and raising awareness along the way. Part of the mission is to dispel any worries about the range of electric cars. On the days of full driving the batteries will be drained 2/3, charged 1/3 and then depleted ready for an overnight charge. \nThe journey lasted roughly three months, stopping at all major cities along the route to showcase the car and technology.\n\nThe public were encouraged to get involved wherever possible. Suggestions regarding places to visit on the trip, places to showcase the car, useful contacts, or even personal favours were all greatly appreciated via Twitter or email.\n\nRacing Green Endurance was born as a spin-off from Imperial Racing Green in late 2008. Imperial Racing Green is an undergraduate teaching project to design and build fuel cell/electric hybrid racing cars, involving around 100 students from 8 departments within the university. The students are now designing and building the third generation of fuel cell powered racers.\n\n"}
{"id": "44761531", "url": "https://en.wikipedia.org/wiki?curid=44761531", "title": "Seam (unit)", "text": "Seam (unit)\n\nA seam is an obsolete unit of volume or mass in the United Kingdom\n\nThe \"Oxford English Dictionary\" includes definitions of a seam as:\n\n\nCardarelli asserts that it was equal to .\n\n"}
{"id": "9311774", "url": "https://en.wikipedia.org/wiki?curid=9311774", "title": "Slash (logging)", "text": "Slash (logging)\n\nIn forestry, slash, or slashings are coarse and fine woody debris generated during logging operations or through wind, snow or other natural forest disturbances. Slash generated during logging operations may increase fire hazard, and some North American states have passed laws requiring the treatment of logging slash. Logging slash can be chipped and used (for example) in the production of electricity or heat in cogeneration power-plants.\n\nWhere logging takes place on soft ground, loggers can use the branches and tops of trees as part of the timber-harvesting process to provide a track for forest machines.\nUsing slash in this manner reduces ground damage.\n\n\n"}
{"id": "7101410", "url": "https://en.wikipedia.org/wiki?curid=7101410", "title": "Solar shingle", "text": "Solar shingle\n\nSolar shingles, also called photovoltaic shingles, are solar panels designed to look like and function as conventional roofing materials, such as asphalt shingle or slate, while also producing electricity. Solar shingles are a type of solar energy solution known as building-integrated photovoltaics (BIPV).\n\nThere are several varieties of solar shingles, including shingle-sized solid panels that take the place of a number of conventional shingles in a strip, semi-rigid designs containing several silicon solar cells that are sized more like conventional shingles, and newer systems using various thin-film solar cell technologies that match conventional shingles both in size and flexibility. There are also products using a more traditional number of silicon solar cells per panel reaching as much as 100 watts DC rating per shingle.\n\nSolar shingles are manufactured by several companies but the three main manufacturers of solar roof shingles are RGS Energy, SolarCity, and CertainTeed. Other active companies in the US include SunTegra Solar Roof Systems, and Atlantis Energy Systems (asphalt and slate systems).\n\nSolar shingles became commercially available in 2005. In a 2009 interview with Reuters, a spokesperson for the Dow Chemical Company estimated that their entry into the solar shingle market would generate $5 billion in revenue by 2015 and $10 billion by 2020. Dow solar shingles, known as the POWERHOUSE Solar System, first became available in Colorado, in October 2011. The POWERHOUSE Solar System continues to live on in its 3 generation iteration, and has exclusively been licensed to RGS Energy for commercialization. In October 2016, Tesla entered the solar shingle space in a joint venture with SolarCity.\n\nSolar shingles are photovoltaic modules, capturing sunlight and transforming it into electricity. Most solar shingles are and can be stapled directly to the roofing cloth. When applied they have a strip of exposed surface. Different models of shingles have different mounting requirements. Some can be applied directly onto roofing felt intermixed with regular asphalt shingles while others may need special installation.\n\nSome early manufacturers used solar thin-film technologies, such as CIGS to produce electricity, which are less common in the solar industry than silicon-based cells. Current manufacturers, such as RGS Energy, CertainTeed, and SunTegra, have chosen to use the industry-standard monocrystalline or polycrystalline silicon solar cells in their POWERHOUSE 3.0, Apollo II, and SunTegra Shingle, respectively. The installation methods for some solar shingle solutions can be easier than traditional panel installations because they avoid the need to locate rafters and install with a process much more similar to asphalt shingles than standard solar panels.\n\nSolar shingled roofs tend to have a deep, dark, purplish-blue or black color, and therefore look similar to other roofs in most situations. Tesla Solar has developed shingles in several styles to better match traditional roofs. Homeowners may prefer solar shingles because they avoid having large panels on their roofs. Coming in 2018 Tesla will offer shingles in slate and Tuscan styles, these are the first of the solar shingles which look the same as a slate or Tuscan style roof but still provide solar power. They also have been \"Test video for the highest (class 4) hail rating, filmed at 2,500 frames per second. Each 2\" hailstone is travelling 100 mph on impact.\" which shows how these new options are also safer in disasters than tradition materials.\n\nThe cost of solar shingles can range from $3.75 per watt up to $12.00 per watt installed depending on the manufacturer, technology used, and system size. As of Q3 of 2015, the average cost of a traditional, roof-mounted residential solar panel installation in the United States was just above $3.50 per watt, according to the Solar Energy Industry Association. While solar shingles are typically more expensive to install than traditional solar panels, some companies in recent years since 2014 have made strides to lessen the gap between the installed cost of going solar with panels versus going solar with shingles.\n\nAccording to Dow Chemical Company reports, a typical residential install consisting of 350 solar shingles can cost at least $20,000; however, federal and state incentives depending on the location might significantly bring down the cost.\n\nSolar contractors typically offer homeowners a full-service price for solar installation, which includes equipment purchasing, permit preparation and filing, registration with the local utility company, workmanship warranties, and complete on-site installation. Because photovoltaic solutions produce power in the form of direct current (DC) and the standard in homes is alternating current (AC), all grid-connected solar installations include an inverter to convert DC to AC.\n\nAs of 2015, companies offering solar shingles in the United States included CertainTeed, Forward Inc., SunTegra Solar Roof Systems, and Atlantis Energy Systems (asphalt and slate systems). \n\nIn January 2018, Tesla announced, after testing on employees' roofs, that it would begin installing the Tesla Solar Roof on commercial customers' homes \"within the next few months\".\n\nRGS Energy announced in October 2017 that they will be offering the third generation POWERHOUSE modules in 2018 after obtaining UL Certification.\n\n\n"}
{"id": "3655251", "url": "https://en.wikipedia.org/wiki?curid=3655251", "title": "Sprung mass", "text": "Sprung mass\n\nSprung mass (or sprung weight), in a vehicle with a suspension, such as an automobile, motorcycle, or a tank, is the portion of the vehicle's total mass that is supported by the suspension, including in most applications approximately half of the weight of the suspension itself. The sprung mass typically includes the body, frame, the internal components, passengers, and cargo, but does not include the mass of the components at the other end of the suspension components (including the wheels, wheel bearings, brake rotors, calipers, and/or continuous tracks (also called caterpillar tracks), if any), which are part of the vehicle's unsprung mass.\n\nThe larger the ratio of sprung mass to unsprung mass, the less the body and vehicle occupants are affected by bumps, dips, and other surface imperfections such as small bridges. However, a large sprung mass to unsprung mass ratio can also be deleterious to vehicle control.\n"}
{"id": "31413530", "url": "https://en.wikipedia.org/wiki?curid=31413530", "title": "ThYme (database)", "text": "ThYme (database)\n\nThYme (Thioester-active enzYme) is database of enzymes constituting the fatty acid synthesis and polyketide synthesis cycles.\n\n\n"}
