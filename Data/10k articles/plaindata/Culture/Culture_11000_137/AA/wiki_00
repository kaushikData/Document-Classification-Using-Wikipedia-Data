{"id": "2027044", "url": "https://en.wikipedia.org/wiki?curid=2027044", "title": "A. C. Grayling", "text": "A. C. Grayling\n\nAnthony Clifford Grayling (; born 3 April 1949), usually known as A. C. Grayling, is a British philosopher and author. He was born in Northern Rhodesia (now Zambia) and spent most of his childhood there and in Malawi. In 2011 he founded and became the first Master of New College of the Humanities, an independent undergraduate college in London. Until June 2011, he was Professor of Philosophy at Birkbeck, University of London, where he taught from 1991. He is also a supernumerary fellow of St Anne's College, Oxford.\n\nGrayling is the author of about 30 books on philosophy, biography, history of ideas, human rights and ethics, including \"The Refutation of Scepticism\" (1985), \"The Future of Moral Values\" (1997), \"Wittgenstein\" (1992), \"What Is Good?\" (2000), \"The Meaning of Things\" (2001), \"The Good Book\" (2011), \"The God Argument\" (2013), \"The Age of Genius: The Seventeenth Century and the Birth of the Modern Mind\" (2016) and \"Democracy and its Crises\" (2017).\n\nHe was a Trustee of the London Library and a Fellow of the World Economic Forum, and is a Fellow of the Royal Society of Literature and a Fellow of the Royal Society of Arts. For a number of years he was a columnist on \"The Guardian\" newspaper, and presented the BBC World Service series \"Exchanges at the Frontier\" on science and society. He has lectured in the United States, Canada, Australia, Ireland, Singapore and Spain. In 2013 he was awarded the Forkosch Literary Prize, and in 2015 he received the Bertrand Russell Award.\n\nGrayling was a director and contributor at \"Prospect Magazine\" from its foundation until 2016. He is a Vice-President of Humanists UK and Honorary Associate of the National Secular Society, and Patron of the Defence Humanists. His main academic interests lie in epistemology, metaphysics, and philosophical logic and he has published works in these subjects. His political affiliations lie on the centre-left, and he has defended human rights and politically liberal values in print and by activism. He is associated in Britain with other new atheists. He frequently appears in British media discussing philosophy and public affairs.\n\nGrayling was born and raised in Luanshya, Northern Rhodesia (now Zambia), within the British expatriate enclave, and raised there and in Nyasaland (now Malawi) where his father worked for the Standard Bank. He attended several boarding schools, including Falcon College in Southern Rhodesia (now Zimbabwe), from which he ran away after being regularly caned. His first exposure to philosophical writing was at the age of twelve, when he found an English translation of the \"Charmides\", one of Plato's dialogues, in a local library. At age fourteen, he read G. H. Lewes's \"Biographical History of Philosophy\" (1846), which confirmed his ambition to study philosophy; he said it \"superinduced order on the random reading that had preceded it, and settled my vocation\".\n\nGrayling had two elder siblings, sister Jennifer and brother John. When he was 19 years old, his elder sister Jennifer was murdered in Johannesburg. She had been born with brain damage, and after brain surgery to alleviate it at the age of 20 had experienced personality problems that led to emotional difficulties and a premature marriage. She was found dead in a river shortly after the marriage; she had been stabbed. When her parents went to identify her, her mother—already ill—had a heart attack and died. Grayling said he dealt with his grief by becoming a workaholic.\n\nAfter moving to England in his teens, he spent three years at the University of Sussex, but said that although he applauded their intention to educate generalists, he wished to be a scholar, so in addition to his BA from Sussex, he also completed one in philosophy as a University of London external student. He went on to obtain an MA from Sussex, then attended Magdalen College, Oxford, where he was taught by P. F. Strawson and A. J. Ayer, obtaining his doctorate in 1981 for a thesis on \"Epistemological Scepticism and Transcendental Arguments\".\n\nGrayling lectured in philosophy at St Anne's College, Oxford, before taking up a post in 1991 at Birkbeck, University of London, where in 1998 he became reader in philosophy, and in 2005 professor. In addition to his work on Berkeley, philosophical logic, the theory of knowledge, and the history of ideas, the latter including (as chief editor) the four-volume \"The Continuum Encyclopedia of British Philosophy\", he wrote and edited several pedagogical works in philosophy, including \"An Introduction to Philosophical Logic\" (3rd ed., 1999) and the two volumes \"Philosophy: A Guide Through the Subject\" (1995) and \"Philosophy: Further Through the Subject\" (1998).\n\nIn his philosophical work, Grayling connected solutions to the problem of scepticism in epistemology with the questions about assertibility and the problem of meaning in the philosophy of language and logic. A principal theme in his work is that considerations of metaphysics, which relate to what exists, has to be kept separate from the two connected questions of the relation of thought to its objects in the variety of domains over which thought ranges, and the mastery of discourses about those domains, where a justificationist approach is required.\n\nGrayling resigned from Birkbeck in June 2011 to found and become the first master of New College of the Humanities, an independent undergraduate college in London. He is a Supernumerary Fellow of St Anne's College, Oxford. He was a judge on the Man Booker prize 2003 and Chairman of the Judges for the 2014 Man Booker Prize. He has also been a judge on the Wellcome Trust Book Prize and the Art Fund prize.\n\nGrayling was appointed Commander of the Order of the British Empire (CBE) in the 2017 New Year Honours for services to philosophy.\n\nFor Grayling, work on technical problems is only one aspect of philosophy. Another aspect, one which has been at the centre of philosophy's place in history, has more immediate application to daily life: the questions of ethics, which revolve upon what Grayling calls the great Socratic question, 'How should one live?'. In pursuit of what he describes as 'contributing to the conversation society has with itself about possibilities for good lives in good societies.' Grayling writes widely on contemporary issues, including war crimes, the legalisation of drugs, euthanasia, secularism, and human rights. He has articulated positions on humanist ethics and on the history and nature of concepts of liberty as applied in civic life. In support of his belief that the philosopher should engage in public debate, he brings these philosophical perspectives to issues of the day in his work as a writer and as a commentator on radio and television.\n\nAmong his contributions to the discussion about religion in contemporary society he argues that there are three separable, though naturally connected debates:\nOn this last point, Grayling's view is that for historical reasons religions have an inflated place in the public domain out of all proportion to the numbers of their adherents or their intrinsic merits, so that their voice and influence is amplified disproportionately: with the result that they can distort such matters as public policy (e.g. on abortion) and science research and education (e.g. stem cells, teaching of evolution). He argues that winning the metaphysical and ethical debates is already abating the problems associated with (c) in more advanced Western societies, even the US. He sees his own major contribution as being the promotion of understanding of humanist ethics deriving from the philosophical tradition.\n\nBetween 1999 and 2002 Grayling wrote a weekly column in \"The Guardian\" called \"The Last Word\", on a different topic every week. In these columns, which also formed the basis of a series of books for a general readership, commencing with \"The Meaning of Things\" in 2001, Grayling made the basics of philosophy available to the layperson. He is a regular contributor to \"The Guardian's\" \"Comment is free\" group blog, and writes columns for, among others, the \"Prospect\" and \"New Scientist\" magazines.\n\nGrayling is accredited with the United Nations Human Rights Council, and is a patron of Humanists UK, an Honorary Associate of the National Secular Society, patron of the Defence Humanists, was a Trustee of the London Library, and a board member of the Society of Authors and an Honorary Patron of The Philosophy Foundation, a charity whose aim is to bring philosophy to the wider community, and particularly to disadvantaged schools. In 2003 he was a Booker Prize judge and Chairman of the Judges for the 2014 Man Booker Prize. In 2005, Grayling debated with Christian philosopher William Lane Craig on whether God can exist in an evil world.\n\nGrayling's book on the , \"Among the Dead Cities: Was the Allied Bombing of Civilians in WWII a Necessity or a Crime?\" (2006) was well-received as a contribution to the debate on the ethics of war. In September 2010, Grayling was one of 55 public figures who sent a letter to \"The Guardian\" expressing their opposition to Pope Benedict XVI's state visit to the UK. In August 2014, Grayling was one of 200 public figures who were signatories to a letter to \"The Guardian\" opposing Scottish independence in the run-up to September's referendum on that issue.\n\nA. C. Grayling was one of the contributors to the book, \"We Are One: A Celebration of Tribal Peoples\", released in October 2009. The book explores the cultures of peoples around the world, portraying both their diversity and the threats they face. Other contributors included not only western writers, such as Laurens van der Post, Noam Chomsky, Claude Lévi-Strauss, but also indigenous people, such as Davi Kopenawa Yanomami and Roy Sesana. The royalties from the sale of this book go to the indigenous rights organisation, Survival International.\n\nGrayling lives in Peckham with his wife, novelist Katie Hickman. They have a daughter, Madeleine, and a stepson, Luke, who both attend boarding schools. Grayling also has two adult children from his first marriage, Jolyon and Georgina.\n\n\n"}
{"id": "56377158", "url": "https://en.wikipedia.org/wiki?curid=56377158", "title": "ASL interpreting", "text": "ASL interpreting\n\nAmerican Sign Language (ASL) is a language that uses signs, facial expressions, and body postures to communicate ideas. ASL is a rich, complex language on par with spoken languages, and employs rules of phonology, syntax, morphology, etc. using manual/visual modes of communication, where spoken languages rely on the oral/aural modes of communication. ASL is used by deaf and hard-of-hearing people in the North American continent, often as their primary language.\n\nLanguage interpretation is defined by the International Standards Organization (ISO) as the following: \"Rendering a spoken or signed message into another spoken or signed language, preserving the register and meaning of the source language content.\" ASL interpreters must understand the subject matter at hand, be able to reliably and fluently transmit the information without bias, and be accustomed to navigating any kind of social situation. ASL interpreting is a multifaceted job, requiring management of linguistic, interpersonal, and environmental issues.\n\nTraining for ASL interpreters is highly varied, as are the education and certifications required for employment. Career and medical support for ASL interpreters has become a topic of concern and study in the last several years, in response to a high rate of interpreter burnout that has led to a shortage of ASL interpreters across the United States.\n\nASL interpreters work in a large variety of environments, including medical, legal, educational, mental health, vocational, and other environments. Interpreting is often viewed as a practice profession (other examples include law, teaching, counseling, medicine, etc.), which requires careful judgement of interpersonal and environmental factors as well as expertise in the skills of the profession itself. The interpreter must be able to understand the concepts they are seeing and hearing, perform the mental translation, and communicate them effectively in the second language. Although the interpreter usually intends to be in the background of the conversation and not contribute beyond interpretation, overcoming differences between the languages often requires them to make judgements which might alter the flow of communication. As with any two languages, ASL and English do not have a one-to-one word correspondence, meaning interpreters cannot simply translate word-for-word. They must determine how to effectively communicate what one interlocutor means, rather than strictly what they say, to the other. Sometimes these judgement calls and various linguistic barriers cause the interpreters to affect the flow of conversation. For example: if a medical professional asks a patient if they are \"sexually active,\" the interpretation can become complicated, because while the English phrase makes no overt reference to a partner or a specific act, in ASL it is very difficult to discuss sexual activity without reference to a partner or act. Consequently, the interpretation from English to ASL may result in the patient responding in dialogue rather than with the \"yes/no\" answer that the doctor might be expecting.\n\nOften, interpreters must manage situations in which the interlocuters' comments include connotations that may be lost on the other party, and the interpreter is left with the decision of how to convey those connotations, or whether they even have the authority to do so. For example, a doctor may ask an interpreter to relay to the patient, \"There is nothing more we can do for you. We're going to make you as comfortable as we can.\" While the literal meaning of the expression is easily conveyed, the interpreter would be aware that the euphemistic nature of this phrase in English might be lost on the deaf patient. Thus, the interpreter would put in the position of bluntly telling the patient that they are going to die. In a situation such as this, the interpreter may elect to discuss the interpretive difficulty with the doctor and allow the doctor the opportunity to communicate with the patient more directly and less euphemistically. The interpreter must not only be able to recognize the linguistic barrier in this situation, but also must be aware of the interpersonal factors involved in the situation and the limitations of their role.\n\nDegree programs in ASL Interpreting are available at colleges, universities, and technical schools across the country, ranging from associate degrees to master's degrees. In addition, interpreters work with mentors, attend workshops, and get certifications to become more adept, gain experience, and open additional career opportunities. In recent years, much research has gone into discerning whether ASL interpreters have access to adequate, specialized, real-world training and career support systems to ensure success and protect against interpreter burnout. Many studies note interpreter reports of frustration with training that proved inadequate to deal with real-world problems, and a lack of professional support.\n\nA variety of factors contribute to stress for the interpreter: variable working conditions, expectations, and even understanding of the interpreter's role and responsibilities can all play a part. Often, interpreters are party to emotional or traumatizing experiences because they are needed to interpret in those situations, with no outlet for dealing with their internal reactions to them. Interpreters also experience physical stress, often in the form of cumulative trauma disorders such as carpal tunnel syndrome that may require them to take time off work to recuperate.\n\nInterpreting ASL as a profession carries a variety of demands. Robyn Dean and Robert Pollard, in applying control-demand theory to the profession, identify four categories of demands:\n\n\nThe relative lack of interpreter post-graduate training does little to prepare interpreters to deal with the varied demands above, which each may be prominent depending on the present interpreting job. Heller et al. (1986), Swartz (1999), and Watson (1987) (cited in Dean and Pollard 2001) all agree that this environment is a large contributor to interpreter burnout and, by extension, the current shortage of ASL interpreters in the United States. However, steps are being taken by several entities, including the Conference of Interpreter Trainers (CIT) and the Registry of Interpreters for the Deaf (RID), to create and adopt standards by which training programs can be judged. Laurie Swabey and Karen Malcolm's book \"In Our Hands: Educating Healthcare Interpreters\" (2012) discusses the specific difficulties that interpreters face in medical fields. The book covers issues that arise in mental health interpreting, the risks of vicarious trauma, explorations of authentic interactions to aid in discourse training, etc. \"Topics in Signed Language Interpreting: Theory and Practice\", edited by Terry Janzen (2005), covers, among other things, the issues that arise with simultaneous interpretation, ethics and professionalism as they relate to interpreting, and a Deaf community perspective on best practices for interpreters. Still, a cohesive standard for postgraduate training and career support for ASL interpreters has yet to materialize.\n"}
{"id": "56504758", "url": "https://en.wikipedia.org/wiki?curid=56504758", "title": "Art Workers News and Art &amp; Artists", "text": "Art Workers News and Art &amp; Artists\n\nArt Workers News, also known as Art & Artists, was the highly influential artist-run publication of the Foundation for the Community of Artists (FCA), an organization that grew out of the National Art Workers Community (a splinter group of the Art Workers’ Coalition). From 1971 to 1989, the publication was the paper of record for the world of working artists. Its circulation reached a high of 40 thousand subscribers.\nOriginally a four-page newsletter, \"Art Workers News\" grew into a monthly newspaper. During the early 1980s, FCA changed the publication’s name to \"Art&Artists\" and made it a bi-monthly.\n\nRather than reviewing shows, AWN/A&A focused on topics central to the lives of working artists in the 1970s and ’80s, (and continuing today): artist housing, health hazards, business practices, health insurance, women’s issues, issues affecting artists of color, law and the arts and censorship were impacting the daily life of artists. The publication featured, as well, contemporary theories and philosophies in the arts, general news articles, a select number of book reviews, commentaries, editorials and special issues.\n\nThe special issues were wide-ranging, reflecting the times and the interests of the editors and writers who were involved at a given time over the course of its existence.\n\nSpecial issues included: “Art Against Apartheid.” “Art and Sports,” “Are There Too Many Artists?,” “Tilted Arc by Richard Serra,” \"Museums,\" and “Artists Against US Intervention in Central America.”\n\n\"Art Workers News\" was also the publication of record for the Comprehensive Employment Act (CETA) Artists Program in New York City and documented the work of artists in all media associated with the project.\n\n\"AWN/A&A\" produced 160 issues over eighteen years. Editors and production staff were volunteers; writers and photographers were paid (minimally) in accordance with the belief that people, including artists and writers, deserved to be paid for their work. The journal newspaper gave voice to many artists, critics and journalists who were prominent in the cultural milieu of its time, as well as to younger professionals at the start of their careers.\n\nMany of the original newsprint issues and some microfiche editions are catalogued in libraries across the U.S., Canada and Australia. The Fales Library at New York University has most of the volumes, and is a source for researchers, artists, art historians, students and scholars. Gwen Allen, a professor at San Francisco State University includes additional information about the publication in her book, \"Artists’ Magazines: An Alternative Space for Art.\"\n\nElliott Barowitz, painter, media artist and writer was the long-time Executive Editor of the journal and remains keeper of its archives; Senior and Associate Editors, and frequent contributors included artists Walter Thompson, Blaise Tobia and Virginia Maksymowicz; artist/photographer Walter Weissman, and arts writer, Daniel Grant.\n\nThe list of contributors to the publication is long and distinguished. It includes men and women early in their careers who went on to become extremely well known writers, artists, editors, curators and critics. Among them are: Lawrence Alloway, Benny Andrews, Lori Antonacci, Dore Ashton, Rudolf Baranik, Jane Barowitz, Gregory Battcock, Pamela Bickart, Bernie Brown, Eva Cockcroft, Tad Crawford, Jimmie Durham, Saunders Ellis, Josephine Gear, Eunice Golden, Leon Golub, Adam Gopnik, Alex Gross, John Hanhardt, Michael Harrington, Stephanie Harrington, Baird Jones, Marc Kostabi, Barbara Kruger, Tuli Kupferberg, Donald Kuspit, Peter Leggieri, Lucy Lippard, Gerald Marzorati, Carl Methfessel, Michael McCann, Cynthia Navaretta, Barbara Nessim, Susan Ortega, Howardina Pindell, Mel Rosenthal, Larry Rosing, Laurin Raiken, Lee Rosenbaum, Barnaby Ruhe, Nancy St. Paul, Irving Sandler, Jacqueline Skyles, Stephen S’soreff, Juan Sanchez, Nancy Spero, May Stevens, Ted Striggles, Marcia Tucker, Judd Tully, David Troy, Allan Wallach, Tim Yohn, and many others.\n\nAlberto, Alexander and Stimson, Blake, \"Conceptual Art: A Critical Anthology\", Cambridge, MA: MIT Press, 1999\n\nAllen, Gwen, \"Artists’ Magazines: An Alternative Space for Art\", Cambridge, MA: MIT Press, 2011\n\nBryan-Wilson, Julia, \"Art Workers: Radical Practice in the Vietnam War Era\", University of California Press, 2011\n\nKostelanetz, Richard, \"A Dictionary of the Avant Gardes\", New York, NY: Rutledge, 2011\n\nSkiles, Jacqueline, “The National Art Workers' Community: Still Struggling,” \"Art Journal\", Volume 34, Issue 4, 1975\n"}
{"id": "49961869", "url": "https://en.wikipedia.org/wiki?curid=49961869", "title": "Bazin (bread)", "text": "Bazin (bread)\n\nBazin (, pronounced , is an unleavened bread in the cuisine of Libya prepared with barley, water and salt. Bazin is prepared by boiling barley flour in water and then beating it to create a dough using a \"magraf\", which is a unique stick designed for this purpose. The dough may then be placed in a pan and allowed time to harden, after which it is baked or steamed. The salt contributes to the hardness of the bazin. Bazin may have a paste-like and hardened texture. It may also be prepared using whole wheat flour, olive oil and pepper as ingredients.\n\nBazeen is typically served with a tomato sauce, eggs, potatoes and mutton. This preparation method involves shaping the dough into the shape of a pyramid or dome, after which it may be served with a tomato-based soup or meat and potato stew poured atop and/or around it and garnished with hard-boiled eggs. A raw egg may also be placed in the hot soup. \"Aseeda\" is a dish prepared using bazin, honey, date syrup and butter or oil. Bazin may also be accompanied with a cooked pumpkin and tomato sauce mixture.\n\nWhen consumed, bazin may be \"crumpled and eaten with the fingers.\" It is typically eaten using the right hand, and may be consumed communally. Bazin has been described as a traditional dish and as a national dish of Libya.\n\nBazeen sauce may be prepared by frying mutton (preferably shoulder or leg) with chopped onions, turmeric, salt, chilli powder, helba (fenugreek), sweet paprika, black pepper and tomato paste. Broad beans, lentils and potatoes may also be added. The sauce, eggs, potatoes and meat are arranged around the dough dome. The dish is typically served with lemon and fresh or pickled (imsaiyar) chillies.\n\nThe old way of making bazeen is to form the dough into palm-size cakes and cook in water in a special copper pot called a qidir. The barley cakes, having become solid, are then broken up in the pot with a large, flat, wooden ladle and mixed to form one large piece. Nowadays, a blender is often used, or the dough is cooked immediately in water like a pudding.\n\n\n"}
{"id": "13499700", "url": "https://en.wikipedia.org/wiki?curid=13499700", "title": "Benin literature", "text": "Benin literature\n\nLiterature in Benin had a strong oral tradition long before French became the dominant language.\n\nFélix Couchoro wrote the first Beninese novel, \"L'Esclave\" in 1929.\n\n\n"}
{"id": "55972086", "url": "https://en.wikipedia.org/wiki?curid=55972086", "title": "Burmese clothing", "text": "Burmese clothing\n\nClothing in Myanmar varies depending on the ethnicity, geography, climate and cultural traditions of the people of each region of Myanmar (Burma). The most widely recognized Burmese national costume is the \"longyi\", which is worn by both males and females nationwide. Burmese clothing also features great diversity in terms of textiles, weaves, fibers, colours and materials, including velvet, silk, lace, muslin, and cotton.\n\nIn the pre-colonial era, sumptuary laws called \"yazagaing\" dictated life and consumption for Burmese subjects in the Konbaung kingdom, everything from the style of one's house to clothing suitable to one’s social standing from regulations concerning funerary ceremonies and the coffin to be used to usage of various speech forms based on rank and social status. In particular, sumptuary laws in the royal capital were exceedingly strict and the most elaborate in character. Sumptuary regulations regarding dress and ornamentation were carefully observed. Designs with the peacock insignia were strictly reserved for the royal family and long-tailed hip-length \"htaingmathein\" jackets and surcoats were reserved for officials. Velvet sandals were worn exclusively by royals. Gold anklets were worn only by the royal children. Silk cloth, brocaded with gold and silver flowers and animal figures were only permitted to be worn by members of the royal family and ministers’ wives. Adornment with jewels and precious stones was similarly regulated. Usage of \"hinthapada\" (), a vermilion dye made from cinnabar was regulated.\n\nDuring the British colonial era, Burmese nationalists associated traditional clothing, in particular \"Yaw longyi\" (), a type of longyi from the Yaw region, and \"pinni taikpon\" (), a fawn-coloured collarless jacket, with anti-colonialism and nationalist sentiment, because of a clampdown in the 1920s over increasing dissent. Wearing \"traditional\" clothing was seen as a mode of passive resistance among the Burmese. The female sarong (\"htamein\") became shorter, no longer extending to the feet, but to the ankles, and the length of the sarong's top decreased to reveal more waistline. This period also saw the introduction of a sheer muslin blouse for women, revealing a corset-like lace bodice called \"za bawli\" (). British rule nonetheless influenced hair fashion and clothing. Cropped short hair, called \"bo ke\" () replaced long hair as the norm among Burmese men. Similarly, women began wearing hairstyles like \"amauk\" (), consisting of crested bangs curled at the top, with the traditional hair bun ().\n\nThe national costume of Myanmar is the \"longyi\" (, ), an ankle-length wraparound skirt worn by both males and females. The \"longyi\" in its modern form was popularized during the British colonial period, replacing the traditional \"paso\" worn by men and \"htamein\" worn by women in pre-colonial times. The pre-colonial \"htamein\" features a broad train called \"yethina\" (ရေသီနား) and is only seen in modern times as wedding attire or a dance costume. Similarly, the pre-colonial \"paso\" is only commonly worn during stage performances, including dances and anyeint performances.\n\nThe indigenous Burmese pattern, called \"acheik\" (; ), features intricate waves interwoven with bands of horizontal stripes, embellished with arabesque designs. \"Acheik\" is also known as \"luntaya\" (; ), which literally means a \"hundred shuttles,\" referring to the time-consuming, expensive, and complex process of weaving this pattern, which requires using numerous individual shuttles, each wound with a different color of silk. \"Acheik\" weaving originates in Amarapura, and became popular during the Konbaung dynasty.\n\nFor business and formal occasions, Bamar men wear a Manchu Chinese jacket called a \"taikpon eingyi\" (, ) over an English collar shirt. This costume was popularized during the colonial era.\n\nBurmese women wear blouses called \"eingyi\" ( ). There are two prevalent styles of \"eingyi\": \"yinzi\" () buttoned at the front, or \"yinbon\" (), buttoned at the side. For formal and religious occasions, Burmese women typically don a shawl.\n\nThe most formal rendition of Myanmar's national costume for females includes a buttonless tight-fitting hip-length jacket called \"htaingmathein\" (), sometimes with flared bottoms and embroidered sequins. \"Htaingmathein\" in Burmese literally means \"does not gather while sitting,\" referring to the fact that the tight-fitting jacket does not crumple up when sitting. This jacket was popular among the aristocratic classes during the Konbaung dynasty, and is now most commonly worn by females as wedding attire, or as traditional dance costume. The \"htaingmathein\" is worn over a bodice called \"yinkhan\" (, ). Historically, the \"htaingmathein\" also had a pair of pendulous appendages on both sides called \"kalano\" ().\n\nThe Burmese national costume for men includes a turban called \"gaung baung\" (, ), which is worn for formal functions. During the colonial era, the \"gaung baung\" was streamlined as an article of Burmese attire. The design of the modern Burmese \"gaung baung\" emerged in the mid-1900s and is called \"maung kyetthayay\" (). It is a ready-made \"gaung baung\" made of cloth wrapped in a rattan frame and can be worn like a hat is worn.\n\nBoth genders wear velvet sandals called \"gadiba phanat\" (‌, also called \"Mandalay phanat\") as formal footwear.\n\nThe various ethnic groups of Myanmar all have distinct clothing and textile traditions.\n\n"}
{"id": "54731434", "url": "https://en.wikipedia.org/wiki?curid=54731434", "title": "Cameroon Press Photo Archive", "text": "Cameroon Press Photo Archive\n\nThe Cameroon Press Photo Archive (CPPA-B) is a photographic archive located in Buea, the regional capital of the South West Region of Cameroon. It holds around 120,000 negatives and 14,000 proof sheets (templates on which up to 16 contact prints were mounted for the purpose of reference) in total, granting a unique view of Anglophone Cameroon's history for the time period 1955 to 2000. Between 2013 and 2015, African Photography Initiatives digitized 25,000 negatives and all 14,000 proof sheets. A copy of the digitized material is in the possession of the Ministry of Communication, the authority in charge of the photo archive. The CPPA-B is considered an endangered archive.\n\nThe CPPA-B was founded in 1954 by the British colonial administration when Southern Cameroons was granted quasi regional status and started operating in November 1955. The person responsible for the setting up of the archives (more precisely the Photo Section within the Southern Cameroons Information Service) was Emmanuel Moanga Mbwaye (1928-2016) who had trained as a photographer in the Colonial Film Unit while working with the Cameroon Development Cooperation (C.D.C.) which had been formed in 1947 with the objective of developing and running plantations of tropical crops in Cameroon. Mbwaye worked alone from the early years but was joined in 1961 by Scott Fominyam. The latter was an assistant-photographer to Mbwaye and, in 1974, was transferred to Bamenda to set up the North West regional office of the Photographic Section. Mbwaye was frequently sent out of office to cover events. Scheduling clashes meant he was unable to effectively do the work alone and this necessitated the contracting of studio photographers such as Batanwi Photos (South West in Victoria now Limbe) and CC Sports (North West in Bamenda). The mandate of the photographers of the Press Photo Agency was to follow any governmental or otherwise socially relevant events throughout its territory (today's Northwest and Southwest Regions).\n\nThe activities of the Photographic Section continued after 1961 when it became the West Cameroon Photographic Section (part of the Federal Republic) and thereafter, under the United Republic of Cameroon (formed after a referendum in 1972). The photographers working for the Information Service produced not only photographs but also movies, which were subsequently shown by mobile cinemas units in rural and urban areas all over the territory. These movies' primary purpose was the information and education of the population about matters such as health, hygiene or the importance of schooling. These photographers were also responsible for covering the Presidents' and Prime Minister's activities as well as any official events of public interest. From its inception and through the 1980s the Photographic Division was active and able to preside directly over all the phases of photo production, from shooting to development and print.\n\nThe first photographer of the Information Service, Emmanuel Moanga Mbwaye, retired in 1987 after being transferred to the Cinematography Division in 1983. Until his retirement, the Photographic Division was well-staffed overall: one librarian, several photographers and two persons in the darkroom worked there full-time. None of these were replaced after retirement. As a result, the photographic archives have been left with progressively fewer staff and remained practically abandoned at the beginning of 2001, when the last photographer retired.\n\nSince 2001, the CPPA-B has been permanently closed. Under such conditions, photographic archives are at constant risk as they are exposed to factors of deterioration such as humidity, termite infestation and air pollution.\n\nThe premises of the CPPA-B is part of the old administrative centre of Buea Town and located in an old wooden colonial building. The administrative organ responsible for the management of the CPPA-B is the Ministry of Communication whose Regional Delegation's office is nearby. The building next to the CPPA-B hosts the National Archives Buea, which is under the authority of the Ministry of Arts and Culture. With the abolition of the Federal system in 1975, Cameroon's national archives were centralised in Yaoundé, the capital of the United Republic of Cameroon. The photographs (negatives, contact prints and proof sheets) which are kept in the CPPA-B cover the years from November 1955 to 2000. With the retirement of the last photographer who worked in that service in 2001, the CPPA-B was locked down and abandoned. Some renovations of the exterior were carried out on the building just a few days before the celebration of the 50th anniversary of the reunification of Anglophone and Francophone Cameroon in February 2014. Inside the building itself, however, nothing was done. In its present state, the CPPA-B lacks the building integrity, security, fire protection, and air quality control that are basic requirements for a long-term archive.\n\nDue to the rigorous system of archiving put in place by the British administration in the mid-50s, which was maintained by the archive's librarian, Martha Mosinga, after independence, the contents of the CPPA-B are in relatively good shape. However, under the present climatic conditions the holdings are jeopardised by high humidity and temperatures. The Archives contain approximately 120,000 negatives, 14,000 proof sheets (templates on which up to 16 contact prints were mounted for the purpose of reference) and 12 register books. Generally, approximately 500 negatives that are packed in paper envelopes are stored in small wooden boxes. Some of the negatives in the CPPA-B present visual evidence of events such as, among many others, the Governor General's tour of the Southern Cameroons in December 1957, the Premier's arrival from the UNO Conference in New York City on 16 March 1959, United Nations Secretary General Dag Hammarskjöld's arrival at Tiko airport from Yaoundé, views of Victoria's Barclays Bank building, and the Commonwealth Youth Sunday Celebrations in Buea and Victoria.\n\nTo gain access to the Press Photo Archives in Buea one is required to write an application to the corresponding authorities. There are no hard copies of photographic prints as the archives contain only negatives and proof sheets. There is no equipment to print the negatives. It is also difficult to access the material that was digitised by African Photography Initiatives with support from the British Library's Endangered Archives Program and the Swiss Federal Office of Culture. With the support of a team six Cameroonians and in collaboration with the Ministry of Communication between 2013 and 2015, over 25,000 negatives and 14,000 proof sheets were digitised, a database established and conservation measures carried out. There is a pending offer of the British Library to make the digitised material available on their website but permission by the Ministry of Communication had not been granted by early 2017. Bamenda and Buea Universities have requested copies but no permission for this was yet forthcoming.\n\nThis impasse resulted in the Yaoundé Declaration of November 9, 2016 through which African Photography Initiatives and other subscribers intended to generate a greater understanding of the value of photographs and films and analogue as well as digital archives for the studies in historic, human and social sciences. The declaration calls on the government and other stakeholders in Cameroon to make every effort in order to protect and make accessible for public use the country's photographic and cinematographic heritage. As a first step, the Yaoundé Declaration recommends the recognition of the CPPA-B and the National Photo Library Yaoundé as cultural property as intended in the law on Cultural Heritage in Cameroon from 18 April 2013.\n\n"}
{"id": "2937476", "url": "https://en.wikipedia.org/wiki?curid=2937476", "title": "Clothes valet", "text": "Clothes valet\n\nClothes valet, also called men's valet, valet stand and \"suit stand\", is an item of furniture on which clothes, particularly men's suits, may be hung. Typical features of valets include trouser hangers, jacket hangers, shoe bars, and a tray organizer for miscellaneous, day-to-day objects like wallets and keys. Some also feature jewelry boxes.\n\nAn electric clothes valet is used to warm clothes before dressing; it includes a timer to prevent overheating.\n\nIn the United States, the term is frequently used to refer to a non-freestanding cabinet or tray for holding small personal items such as watches, cuff links, keys, or a cell phone. In this sense, it is a men's jewelry box.\n\n"}
{"id": "42102863", "url": "https://en.wikipedia.org/wiki?curid=42102863", "title": "Committee to Ratify the Massachusetts State Equal Rights Amendment", "text": "Committee to Ratify the Massachusetts State Equal Rights Amendment\n\nFounded in 1975, the Committee to Ratify the Massachusetts State Equal Rights Amendment sought to replace the Massachusetts State ERA Coalition and carry out the mission of ratifying the Equal Rights Amendment. The Committee to Ratify the Massachusetts State Equal Rights Amendment replaced the Massachusetts State ERA Coalition because, as a coalition, the organization could not legally raise funds for any cause. The campaign created by the Committee ended with success at the ratification of the Equal Rights Amendment.\n\nThe Committee then became the ERA Implementation Project, which lobbied for reconciliation of existing laws with the ERA vis a vis legislation.\n"}
{"id": "24782516", "url": "https://en.wikipedia.org/wiki?curid=24782516", "title": "Computational musicology", "text": "Computational musicology\n\nComputational musicology is defined as the study of music with computational modelling and simulation. It saw its beginning in the 1950s and originally did not use computers, but more of statistical and mathematical methods. Nowadays computational musicology depends mostly on complex algorithms to either go through vast amounts of information or produce music using given parameters. Several alternative names and subdisciplines of the field include mathematical music theory, computer music, systematic musicology, music information retrieval, computational musicology, digital musicology, sound and music computing and music informatics.\n\nLejaren Hiller acted as one of the foremost pioneers by creating one of the first musical compositions with a computer in 1957. In the 1960s research continued using statistical and mathematical methods, and started to use computers in an increasing manner as their capabilities grew. 1970s and 1980s were especially significant times for computational musicology as many discoveries were made. Since then the field has suffered a general lack of interest.\n\nMost of the work in computational musicology is done with computers that run specifically designed programs. Commonly they employ the theory and methods statistical science, mathematics and music theory. Comprehension of the physics of hearing and sound are also required in analysis of raw audio data.\n\nOne of the earliest applications in computational musicology was the creation and use of musical databases. Input, usage and analysis of large amounts of data can be very troublesome using manual methods while usage of computers can make such tasks considerably easier.\n\nDifferent computer programs have been developed to analyze musical data. Data formats vary from standard notation to raw audio. Analysis of formats that are based on storing all properties of each note, for example MIDI, were used originally and are still among the most common methods. Significant advances in analysis of raw audio data have been made only recently.\n\nDifferent algorithms can be used to both create complete compositions and improvise music. One of the methods by which a program can learn improvisation is analysis of choices a human player makes while improvising. Artificial neural networks are used extensively in such applications.\n\nOne developing sociomusicological theory in computational musicology is the \"Discursive Hypothesis\" proposed by Kristoffer Jensen and David G. Hebert, which suggests that \"because both music and language are cultural discourses (which may reflect social reality in similarly limited ways), a relationship may be identifiable between the trajectories of significant features of musical sound and linguistic discourse regarding social data.\" According to this perspective, analyses of \"big data\" may improve our understandings of how particular features of music and society are interrelated and change similarly across time, as significant correlations are increasingly identified within the musico-linguistic spectrum of human auditory communication.\n\nStrategies from computational musicology are recently being applied for analysis of music in various parts of the world. For example, professors affiliated with the Birla Institute of Technology in India have produced studies of harmonic and melodic tendencies (in the raga structure) of Hindustani classical music.\n\nRISM's (Répertoire International des Sources Musicales) database is one of the world's largest music databases, containing over 700,000 references to musical manuscripts. Anyone can use its search engine to find compositions.\n\nThe Centre for History and Analysis of Recorded Music (CHARM) has developed the Mazurka Project, which offers \"downloadable recordings . . . analytical software and training materials, and a variety of resources relating to the history of recording.\"\n\n\n"}
{"id": "1134268", "url": "https://en.wikipedia.org/wiki?curid=1134268", "title": "Corsage", "text": "Corsage\n\nA corsage is a small bouquet of flowers worn on a woman's dress or around her wrist for a formal occasion. Traditionally, they are given to her by her date. Today, corsages are most commonly seen at homecomings, proms, and similar formal events.\n\nSometimes incorrectly called \"corsages\", flowers worn by men are called buttonholes or boutonnières. At school events such as homecoming or prom, the couple traditionally coordinates the corsage and boutonnière with one other, signifying that the couple is paired together and separating themselves from other guests or groups.\n\nAlthough today the term \"corsage\" refers to any small bouquet of flowers that a woman wears, the tradition of wearing them pinned to clothing dates as far back as Ancient Greece, when small bunches of fragrant flowers and herbs were worn at weddings to ward off evil spirits. During the 16th and 17th centuries, corsages and boutonnieres may have been a part of daily life to prevent disease and to ward off evil spirits, but over time, they became special-occasion pieces.\n\nThe word \"corsage\" comes from the French term \"bouquet de corsage\", meaning \"a bouquet of the bodice\" which was traditionally worn by women to weddings and funerals. Eventually, the term shortened to \"corsage\". In the early 19th century, corsages were regarded as a courting gift and were often given at formal dances. Traditionally, the gentleman would bring a gift of flowers for his date's parents and would select one of the flowers to give to his date, which would then be carried or attached to her clothing, usually on the shoulder. During the 1950s, some corsages were made with fruit and would be seen on hats for decoration. As dress styles changed, pinning the corsage to the dress became impractical, and wrist corsages became the norm. \n\nToday's corsages are still very similar to those made in previous decades, although they are much smaller now. It is still customary for a male to give his female date a corsage when attending a formal dance, but they are also sometimes given to a daughter attending a formal event by her parents or worn by the mothers and grandmothers of the bride and groom at a wedding. Flowers used should be complementary in color to the attire, and corsages and boutonnières should be coordinated to indicate that a couple is attending the event together. Corsages are often dried and pressed to be preserved as mementos.\n\nWhen attending a school formal or prom, providing a corsage for a prom date signifies consideration and generosity, as the corsage is meant to symbolize and honor the person wearing it. Corsages are usually worn around a prom date's wrist; alternatively, they may be pinned on her dress or a modified nosegay can be carried in her hand. The colors of the flowers are usually chosen to complement the dress or to add color to the couple, creating a unifying look. Prom couples may wish to go together to choose the flowers for a custom-made corsage or boutonnière. Traditionally, the male presents a corsage or nosegay to the female as a gift, while the female would provide the boutonnière and pin it on the male's shirt or jacket.\n\nCorsages can be made from a single flower or a small bunch of flowers, and a variety of flowers can be used. The following table shows some of the main flowers and accents used to create a custom-made corsage and that can be included in a nosegay and boutonnière.\nThe style and design of a corsage may vary depending on the event. Younger generations tend to use wrist corsages, which may vary in style and size depending on the wearer. The more traditional option is a corsage pinned on the shoulder of a woman's dress. This style often gets confused with a boutonnière. The main difference is the size and the number of flowers used.\n\nIf a wrist corsage is chosen for an event, it can be made using wire and floral tape or floral glue. The wire method is recommended for pin-on corsages because the wire will support the stems or flower bulbs. Glue can be added to hold the flowers together if the wire and tape are not sufficient.\n\n"}
{"id": "143364", "url": "https://en.wikipedia.org/wiki?curid=143364", "title": "Culture hero", "text": "Culture hero\n\nA culture hero is a mythological hero specific to some group (cultural, ethnic, religious, etc.) who changes the world through invention or discovery. A typical culture hero might be credited as the discoverer of fire, or agriculture, songs, tradition, law or religion, and is usually the most important legendary figure of a people, sometimes as the founder of its ruling dynasty.\n\nIn some cultures, there are dualistic myths, featuring two culture heroes arranging the world in a complementary manner. Dualistic cosmologies are present in all inhabited continents and show great diversity: they may feature culture heroes, but also demiurges (exemplifying dualistic creation myths in the latter case), or other beings; the two heroes may compete or collaborate; they may be conceived as neutral or contrasted as good versus evil; be of the same importance or distinguished as powerful versus weak; be brothers (even twins) or be not relatives at all.\n\nIn many cultures the trickster and the culture hero are combined. To illustrate, Prometheus, in Greek mythology, stole fire from the gods to give it to humans as did Māui in Polynesian mythology.\n\nIn many Native American mythologies and beliefs, the coyote spirit stole fire from the gods (or stars or sun) and is more of a trickster than a culture hero. Natives from the Southeastern United States typically saw a rabbit trickster/culture hero, and Pacific Northwest native stories often feature a raven in this role: in some stories, Raven steals fire from his uncle Beaver and eventually gives it to humans. The Western African trickster spider Ananse is also widely disseminated. In Norse mythology, Odin (yet another trickster deity) is said to have stolen the mead of poetry from Jotunheim and is credited as the discoverer of the runes. \n\n\n"}
{"id": "8509684", "url": "https://en.wikipedia.org/wiki?curid=8509684", "title": "Curriki", "text": "Curriki\n\nCurriki is an online, free, open education service. Curriki is structured as a nonprofit organization to provide open educational resources primarily in support of K-12 education. Curricula and instructional materials are available at the Curriki website to teachers, professional educators, students, lifelong learners, and parents. The majority of the resources on the Curriki site fall under a Creative Commons license. Educational materials are provided by the Curriki community and are peer-reviewed for quality and adherence to standards.\n\nThe name Curriki is a portmanteau of the words \"curriculum\" and \"wiki\".\n\nCurriki's model is to develop curricula through community contributors, and to deliver curricula and open educational resources globally. Anyone with access to the Internet can contribute and use the material found on Curriki to teach themselves or others. Since the materials, which include digital textbooks, learning videos, and interactive resources, are provided in open source, they can be adapted as needed to particular requirements inside or outside of the classroom.\n\nCurriki was founded by Sun Microsystems in March 2004 as the Global Education & Learning Community (GELC). In 2006, Sun spun GELC off as an independent 501(c)(3) nonprofit to focus on building a repository of curricula and to create an online community for this repository. The organization changed its name to Curriki in 2006.\n\nCurriki has over 350,000 educator, parent, and student members, and has garnered over 8.5 million visits from around the world. Curriki has received a number of awards, and has also given out a number of awards over the past several years; a partial list can be found at the Curriki website. Kim Jones serves as Curriki's CEO.\n\nIn September 2017, Curriki partnered with AT&T in order to come up with interactive math assessments tools, with which students would be given real-time feedback.\n"}
{"id": "7571029", "url": "https://en.wikipedia.org/wiki?curid=7571029", "title": "De spectaculis", "text": "De spectaculis\n\nDe Spectaculis, also known as On the Spectacles or The Shows, is a surviving moral and ascetic treatise by Tertullian. Written somewhere between 197-202, the work looks at the moral legitimacy and consequences of Christians attending the circus, theatre, or amphitheatre.\n\nTertullian argues that human enjoyment can be an offence to God. His view of these public entertainments is that they are a misuse of God's creation and a perversion of the gifts God has given to man. He supports his claim by reminding the reader that these shows and spectacles derived from pagan ritual rites (the Liberalia, the Consualia, the Equiria, the Bacchanalia, etc.). This means that the events derive from idolatry. Of key concern was that the \"show always leads to spiritual agitation\". By attending and partaking in the event, man is subject to strong excitements, which are aroused due to natural lapses, which create passionate desire. Additionally, Tertullian writes that that which is not permissible to say or do should not be permissible to see or hear.\n\nFriedrich Nietzsche, in \"On the Genealogy of Morality\" (Essay 1, Section 15), uses Tertullian's words to highlight the resemblance of Christian worship to circus-going: \"In place of athletes, we have our martyrs; if we crave blood, we have the blood of Christ...\" To those addicted to the pleasure of pagan spectacles Tertullian tried to show that Christianity offers far superior spectacles. For this reason he spoke of the Second Coming, the resurrection of the saints, New Jerusalem, and of “what no eye has seen, nor ear heard, nor the human heart conceived” (), but the spectacle on which he enlarged most was the Last Judgement and the ensuing punishment of the enemies of Christ:\n\nSuch an expression of joy over the ruin of the damned finds no match in the other works of early Christians. However, it must be taken into account that in an earlier chapter of the treatise Tertullian wrote that “the innocent can find no pleasure in another’s sufferings: he rather mourns that a brother has sinned so heinously as to need a punishment so dreadful.” This passage is hard--if not impossible--to reconcile with the one quoted before and it is therefore debatable what Tertullian's real sentiments regarding the damned were.\n\n"}
{"id": "2955590", "url": "https://en.wikipedia.org/wiki?curid=2955590", "title": "Dignitas (Roman concept)", "text": "Dignitas (Roman concept)\n\nDignitas is a Latin word referring to a unique, intangible, and culturally subjective social concept in the ancient Roman mindset. The word does not have a direct translation in English. Some interpretations include \"dignity\", which is a \"derivation\" from \"dignitas\", and \"prestige\" or \"charisma\".\n\nWith respect to ancient Rome, \"dignitas\" was regarded as the sum of the personal clout and influence that a male citizen acquired throughout his life. When weighing the \"dignitas\" of a particular individual, factors such as personal reputation, moral standing, and ethical worth had to be considered, along with the man's entitlement to respect and proper treatment.\n\nAuthors who had used \"dignitas\" extensively in their writings and oratories include Cicero, Julius Caesar, Tacitus, and Livy. The most prolific user was Cicero, who initially related it to the established term \"auctoritas\" (authority). These two words were highly associated, with the latter defined as the expression of a man's \"dignitas\".\n\nThe cultivation of \"dignitas\" in ancient Rome was extremely personal. Men of all classes, most particularly noblemen of consular families, were highly protective and zealous of this asset. This is because every man who took on a higher political office during the Roman Republic considered \"dignitas\" as comprising much more than just his dignity. It referred to his \"good name\" (his past and present reputation, achievement, standing, and honor). Its importance within the hierarchical classes of Roman society meant many historical figures would kill, commit suicide (e.g. Mark Antony), or enter exile in order to preserve their \"dignitas\".\n\nThe personal significance of one's \"dignitas\" had encouraged several conflicts in ancient Rome. Florus claimed that the stubbornness of Cato the Younger had driven Pompeius Magnus to prepare defenses in order to build up his \"dignitas\". Cicero wrote that Caesar valued his status so greatly that he did not want anyone to be his equal in \"dignitas\". Aulus Hirtius had written that Marcus Claudius Marcellus, who was one of the instigators of Caesar’s recall from Gaul, had attempted to build all of his own reputation on his success on turning people’s feelings against Caesar. Whether the exact term was used much during these times is unknown; however, the concept of \"dignitas\" was certainly influential and worth fighting for.\n\nOver the course of ancient Roman history, \"dignitas\" had never taken on all of the aforementioned descriptions simultaneously. The term took on different meanings over time, adjusting for the gradually changing viewpoints of society, politicians, and the various authors.\n\nYears after Caesar's death, his heir Augustus rejected the contemporary meaning of \"dignitas\". Augustus found the related term \"auctoritas\" to be a suitable alternative.\n\nIn 46 BC, Cicero cited the ambiguous nature of the concept of \"dignitas\". He wrote, \"And so I have, if loyal feeling for the state and winning good men's approval of those loyal feelings is all that \"dignitas\" amounts to; but if in \"dignitas\" you include the power of translating those loyal feelings into action or of defending them with complete freedom, then \"ne vestigium quidem ullum est reliquum nobis dignitatis\" [not even a trace is left to us of our dignity].\"\n\nWhen paired with the term \"otium\", the word \"dignitas\" took on a different meaning. Cicero did not consider himself worthy of having \"dignitas\" alone because he felt that—by turning his back on the Roman public—he had neglected the duty of one whose life had normally exemplified the concept. He then altered the definition to mean \"[lifetime] impact,\" to better describe his unique status. By this time, Cicero's political life had ended, and he labeled his past political influence as his \"dignitas\", and his present standing as \"otium\".\n\n\n"}
{"id": "5269198", "url": "https://en.wikipedia.org/wiki?curid=5269198", "title": "European Medical Writers Association", "text": "European Medical Writers Association\n\nThe European Medical Writers Association (EMWA) was established in 1992 in Brussels, Belgium, as a professional organisation for European medical writers, whether working freelance or in-house at pharmaceutical companies or medical communications companies. Between 1992 and 1998, EMWA was the European chapter of the American Medical Writers Association.\n\nThe aim of EMWA is to provide a forum to promote standards of excellence in medical writing by furthering the professional development of members and increasing awareness of medical writing throughout Europe.\n\nEMWA now has over 800 members from 27 countries, and includes academics and professionals working in-house or freelance for pharmaceutical and medical communications companies, research institutes and in the field of scientific journalism. EMWA has an extensive professional development programme, and runs workshops and other educational and social events at bi-annual conferences, one in Spring and the other in Autumn, both in European locations. EMWA also publishes a journal, \"The Write Stuff\", four times a year. In 2012, the journal changed its name to \"Medical Writing\" and began being published by Maney Publishing. Since the beginning of 2016, the journal is now once again self-published and printed by Hastings; feature articles are now open access.\n\nThe strategic objectives of EMWA are to build the profession of medical writing, to expand its membership-base, to streamline and enhance its organisational structure and processes and to provide a forum for its members in which they can share their expertise.\n\n\n"}
{"id": "1826280", "url": "https://en.wikipedia.org/wiki?curid=1826280", "title": "False relation", "text": "False relation\n\nA false relation (also known as cross-relation, non-harmonic relation) is the name of a type of dissonance that sometimes occurs in polyphonic music, most commonly in vocal music of the Renaissance. \nThe term describes i) a \"chromatic contradiction\" between two notes sounding simultaneously, (or in close proximity), in two different voices or parts or ii) in music written before 1600, the occurrence of a tritone between two notes of adjacent chords.\n\nIn the above example, a chromatic false relation occurs in two adjacent voices sounding at the same time (shown in red). The tenor voice sings G while the bass sings G momentarily beneath it, producing the clash of an augmented unison.\n\nIn this instance, the false relation is less pronounced: the contradicting E (soprano voice) and E (bass voice) (diminished octave) do not sound simultaneously. Here the false relation occurs because the top voice is descending in a minor key, and therefore takes the notes of the melodic minor scale descending (the diatonic sixth degree). The bass voice ascends and therefore makes use of the ascending melodic minor scale (the raised sixth degree).\n\nFalse relation is in this case desirable since this chromatic alteration follows a melodic idea, the rising 'melodic minor'. In such cases false relations must occur between different voices, as it follows that they cannot be produced by the semitones that occur diatonically in a mode or scale of any kind. This horizontal approach to polyphonic writing reflects the practices of composers in the Renaissance and Tudor periods, particularly in vocal composition, but it is also seen, for example, in the hexachord fantasies of William Byrd (for keyboard). Indeed, vocal music from this era does not often have these accidentals notated in the manuscript (see Musica ficta); experienced singers would have decided whether or not they were appropriate in a given musical context.\n\nMany composers from the late 16th century onwards however began using the effect deliberately as an expressive device in their word setting. This practice continued well into the Romantic era, and can be heard in the music of Mozart and Chopin, for example.\n\n\n"}
{"id": "52584897", "url": "https://en.wikipedia.org/wiki?curid=52584897", "title": "Fashion in Barcelona", "text": "Fashion in Barcelona\n\nToday, more fashion capitals exist than the original “Big Four” of London, Paris, Milan, and New York from the 20th century. Although the “Big Four” remain the most elite, other cities have developed into smaller fashion centers. The history of fashion in Barcelona begins in the early 20th century with the rise of the textile industry and spans through today with its current concentration on fast fashion. With various popular fashion districts and a handful of notable fashion events each year, Barcelona has proved itself as a major city for fashion. According to the Global Language Monitor, which ranks world fashion capitals, Barcelona ranks as #5.\n\nThe beginning of Barcelona as a capital for fashion can be traced back to the beginning of the 20th century when Barcelona’s prosperous textile industry allowed the city’s designers to produce some of the finest garments of the day. Various designers contributed to Barcelona’s rise as a fashion capital including French haute couture designer Jeanne Lanvin who first learned the art of dressmaking in the Catalan capital city. Later, in 1929, she opened a branch of her store in Barcelona, demonstrating her belief that Barcelona was a meaningful fashion city. Another notable development for fashion in Barcelona came with Pedro Rodriguez who opened his first store, a Parisian-style salon, in Barcelona in 1919. Further, one of the most important events of the early 20th century in relation to Barcelona’s growth as a fashion capital includes the Barcelona International Exposition of 1929 where the world-famous designer Cristóbal Balenciaga first established himself.\n\nRodriguez and Balenciaga would continue to become the leading Spanish fashion designers of their time. Additionally, in the 1920s multiple textile warehouses emerged including , El Dique Flotante and La física, offering haute couture pieces. The combination of Barcelona’s link to Paris, the strong Catalan textile industry, and the local embroidery industries lent to Barcelona’s emergence as a noteworthy city of fashion.\n\nDuring the Second Republic (1931-1936), Barcelona hosted several fashion shows, but the Spanish Civil War (1936-1939) stopped all fashion development in Barcelona. After the war, the growth of the fashion industry resumed. In the 1940s the “Cinco Grandes” (Pedro Rodriguez, Manuel Pertegaz, Asunción Bastida, Santa Eulalia and El Dique Flotante) appeared in the world of fashion. This group was able to gain support from Francisco Franco’s military dictatorship that was interested in Spanish exports. This allowed Catalan fashion to continue to develop.\n\nIn 1963, Spanish textile manufacturers and clothing companies created the Moda del Sol union under the leadership of designer José María Fillol in order to present new, innovative textiles in the form of clothing. From 1967 to 1974, Vogue devoted 17 pages to Moda del Sol twice per year, helping Catalan designers to become internationally recognized. In line with the style of “Moda del Sol” came the rise of prêt-à-porter, or ready-to-wear, fashion in the place of haute couture during the 1960s. Early designers who took part in this initiative in Barcelona include Santa Eulàlia, Sant Patrick, Margarita Nuez, and Marisol Bofill. Notable prêt-à-porter designers of the 1970s include Toni Miró and Antonio Balado.\n\nThe end of 20th century brought the beginning of various fast fashion chains. Fast fashion refers to designs that quickly move from the runway to stores at affordable prices. The first Zara opened in La Coruña, Galicia, Spain (under the name of “Zorba”) in 1975 and expanded throughout Spain until its first international store opened in Porto, Portugal in 1988. In the 1990s, Zara’s parent company, Inditex, bought Barcelona brands Massimo Dutti and Stradivarius. Additionally, Barcelona-born Mango opened its first store on Passeig de Gràcia in 1984. Throughout the end of the century, Barcelona continued to grow as a fashion capital and various fashion franchises continued to open stores in the Catalan capital city.\n\nIn the 21st century, Barcelona has emerged as one of the top 10 fashion capitals in the world, ranking as #5 in 2015 according to the Global Language Monitor. In 2014, the region in which Barcelona is located, Catalonia, was home to 1,700 fashion businesses that employed 100,000 people and generated 13 billion euros (about 13.8 billion USD) per year.\n\nThis neighborhood is Barcelona’s most posh fashion district that offers luxury brands including Chanel, Valentino, Hermes, and Burberry. It also includes the mass-market stores such as Zara, Mango, H&M, and Desigual. Additionally, the Spanish luxury label, Loewe, can also be found in Passeig de Gràcia. With ornate buildings designed by the famous modernist artists Antoni Gaudí, Josep Puig i Cadafalch, and Lluís Domènech i Montaner lining the streets of Passeig de Gràcia, tourists and locals alike can enjoy shopping near Barcelona's most iconic architecture.\n\nLocated off of Plaça de Catalunya, Portal de L’Angel is the second largest shopping district, after Passeig de Gràcia, and provides shoppers with a large number of department stores. El Corte Inglés, Zara, Bershka, Pull&Bear, Mango, and other fashion franchises can be found here.\n\nThis fashion avenue runs parallel with Passeig de Gràcia and offers a more unique set of options. La Rambla is home to primarily independent stores and can be described as more “bourgeois” than Passeig de Gràcia. With a rich history as Barcelona's largest area for markets, La Rambla is a place where shopping meets culture and shoppers can feel Barcelona's old charm and new style. However, watch out for pickpockets. La Rambla is known as the number one place for pickpockets in the world.\n\n080 Barcelona is Barcelona’s bi-annual Fashion Week in which designers display their most recent collections to the public. Over the course of five days, there are 40 fashion parades that give both buyers and the general public the opportunity to see the latest trends. Currently, internationalization is at the focus of the event in order to present local designers to the world and to ensure Barcelona remains a top city for fashion. 080 gives Barcelona the opportunity to show its culture of fashion to the world.\n\nThe Shopping Night Barcelona (TSNB), founded in 2010, offers shoppers the opportunity to stay out until 1:00am to shop in the Passeig de Gràcia neighborhood at the beginning of December. Many stores offer promotions and sales aimed at attracting holiday shoppers. Additionally, traffic is blocked off so that shoppers can easily move through the streets, enjoying the stores as well as the festive events such as street food booths, local concerts, and other performances. In 2015, TSNB brought 85,000 shoppers to Passeig de Gràcia.\n\nFounded in 2013, Barcelona Fashion Summit offers an annual meeting point that brings together Spanish fashion executives to learn and discuss trends in the industry. The forum offers important information regarding how companies can grow and succeed in the world of fashion. Regarded as the leading event for fashion professionals in Barcelona, Barcelona Fashion Summit provides attendees with conferences, round tables, and networking events crucial for those that want to advance in the industry.\n\nBarcelona's long history of innovation lends itself to a wide selection of Barcelona-born fashion brands. From the Mango of 1984 to the more recent Bimba Lola of 2006, Barcelona is a city that breeds design.\n\n"}
{"id": "417899", "url": "https://en.wikipedia.org/wiki?curid=417899", "title": "Flag of Bhutan", "text": "Flag of Bhutan\n\nThe national flag of Bhutan () is one of the national symbols of Bhutan. The flag is based upon the tradition of the Drukpa Lineage of Tibetan Buddhism and features Druk, the Thunder Dragon of Bhutanese mythology. The basic design of the flag by Mayum Choying Wangmo Dorji dates to 1947. A version was displayed in 1949 at the signing of the Indo-Bhutan Treaty. A second version was introduced in 1956 for the visit of Druk Gyalpo Jigme Dorji Wangchuk to eastern Bhutan; it was based upon photos of its 1949 predecessor and featured a white Druk in place of the green original.\n\nThe Bhutanese subsequently redesigned their flag to match the measurements of the flag of India, which they believed fluttered better than their own. Other modifications such as changing the red background color to orange led to the current design, in use since 1969. The National Assembly of Bhutan codified a code of conduct in 1972 to formalize the flag's design and establish protocol regarding acceptable flag sizes and conditions for flying the flag.\n\nHistorically Bhutan is known by numerous names, but the Bhutanese call the country \"Druk\" after the name of the Bhutanese thunder dragon. This tradition dates to 1189 when Tsangpa Gyare Yeshe Dorje, founder of the Drukpa lineage of Tibetan Buddhism, was in Phoankar (Tibet) where he reportedly witnessed the Namgyiphu valley glowing with rainbow and light. Considering this an auspicious sign, he entered the valley to choose a site for the construction of a monastery, whereupon he heard three peals of thunder – a sound produced by the \"druk\" (dragon) according to popular Bhutanese belief. The monastery that Tsangpa Gyare built that year was named \"Druk Sewa Jangchubling\", and his school of teaching became known as Druk. The Druk school later split into three lineages. One of these three, \"Drukpa\", was founded by Tsangpa Gyare's nephew and spiritual heir Önrey Dharma Sengye and afterward spread throughout Bhutan. The nation itself would also later become known as \"Druk.\" This legend offers one explanation for how the symbolism of the dragon came to form the basis of the national flag of Bhutan. An alternative hypothesis maintains that the notion of symbolizing sovereign and state in the form of a dragon emerged in neighboring China and was adopted by the rulers of Bhutan as a symbol of royalty in the early 20th century.\n\nThe current flag is divided diagonally from the lower hoist-side corner, with the upper triangle yellow and the lower triangle orange. Centred along the dividing line is a large black and white dragon facing away from the hoist side. The dragon is holding a \"norbu\", or jewel, in each of its claws. The background colours of the flag, yellow and orange, are identified as Pantone 116 and 165 respectively. Equivalents of these shades and the white of the Druk are specified by various other codes according to particular matching systems as indicated below.\n\nThe dimensions of the flag must maintain a 3:2 ratio. The following sizes have been declared standard by the Government of Bhutan:\n\nAccording to \"The Legal Provisions of the National Flag of the Kingdom of Palden Drukpa as Endorsed in Resolution 28 of the 36th Session of the National Assembly held on June 8, 1972\", and as restated in the Constitution of 2008, the yellow signifies civil tradition and temporal authority as embodied in the \"Druk Gyalpo\", the Dragon King of Bhutan, whose royal garb traditionally includes a yellow kabney (scarf). The orange half signifies Buddhist spiritual tradition, particularly the Drukpa Kagyu and Nyingma schools. Druk, the Thunder Dragon, spreads equally over the line between the colors. The placement of Druk in the center of the flag over the dividing line between the flag's two colors signifies the equal importance of both civic and monastic traditions in the Kingdom of Druk (Bhutan) and evokes the strength of the sacred bond between sovereign and people. The white color of Druk signifies the purity of inner thoughts and deeds that unite all the ethnically and linguistically diverse peoples of Bhutan. The jewels held in Druk's claws represent Bhutan's wealth and the security and protection of its people, while the dragon's snarling mouth symbolizes Bhutanese deities' commitment to the defense of Bhutan.\n\nThe Centre for Bhutan Studies, an independent Bhutanese research centre, in 2002 issued a paper (henceforth the \"CBS document\") that is the only readily available account from Bhutan of the historical development of the national flag. The document draws heavily on first-hand accounts obtained through interviews with individuals personally involved in the creation and modification of the flag in Bhutan, from the late 1940s until the adoption of the current flag around 1970. This report is therefore a significant primary source for information about the history of the Bhutanese flag. But in the description of the flag from 1949, the document is not in complete accord with photos of the flag (as discussed below), making it difficult to interpret some of the document's assertions. As a record, however, of the few primary sources remaining – namely, the people involved in the flag's history and the handful of existing government records – it represents a valuable source of information about the otherwise poorly documented evolution of the Bhutanese flag.\n\nThe CBS document states that the first national flag was designed upon the request of Jigme Wangchuck, the second Druk Gyalpo of the 20th-century Kingdom of Bhutan, and was introduced in 1949 during the signing of the Indo-Bhutan Treaty. While the document does not provide an illustration of the original design, black-and-white photographs taken at this historic event provide images of the first Bhutanese flag at the ceremony.\n\nThe design of the flag is credited to Mayeum Choying Wongmo Dorji in 1947. Lharip Taw Taw, one of the few painters available to the royal court at the time, is said to have embroidered the flag. Druk was colored green in accordance with traditional and religious references to \"yu druk ngonm\" (), or \"turquoise druk.\" Today, a modern reproduction of this historic original (with several significant changes influenced by the modern flag) is displayed behind the throne in the National Assembly Hall in Thimphu.\n\nAccording to the CBS document, the original Bhutanese flag was a bicolour square flag divided diagonally from the lower hoist to the upper fly. The field of yellow extended from the hoist to the upper fly, and the red field extended from the fly end to the lower hoist. In the centre of the flag, at the convergence of the yellow and red fields, is a green Druk, located parallel to the bottom edge and facing the fly.\n\nHowever, the CBS document does not illustrate the early versions of the flag and its description of the 1949 flag is not entirely consistent with the photos surviving from 1949. It describes the flag as \"square\", while the proportions of the flag in the photographs appear closer to 4:5. The document describes the dragon as \"facing the fly end\", while the dragon visible in the photos faces the hoist. The dragon is described as \"parallel to the fly\" (meaning, according to a diagram in the document, parallel to the length along the bottom edge of the flag), while the dragon in the photos appears to have a slightly rising vertical slant. The dragon is described as \"green\", but the shade in the photos, if indeed green, must be very pale. \n\nWestern flag books until after 1970 generally show the Bhutanese flag closely resembling the 1949 photos.\n\nThe second version of the national flag was developed in 1956 for the visit of the third Druk Gyalpo Jigme Dorji Wangchuk to eastern Bhutan. During the trip the Druk Gyalpo's Secretariat began to use flags of a new design based upon a photograph of the first national flag of 1949, with the colour of the dragon changed from green to white. The retinue of the Druk Gyalpo included a convoy consisting of over one hundred ponies; a small version of the flag was placed on the saddle of every tenth pony, and a large flag approximately in size was flown in the camp every evening, hoisted to the sound of a bugle.\n\nBeginning in the late 1950s, Dasho Shingkhar Lam, former Secretary to Jigme Dorji Wangchuck and Sixth Speaker of the National Assembly (1971–74), was requested by the king to make several modifications to the flag; he is responsible for its current design, which has remained unchanged since 1969. The king was reportedly dissatisfied that the early square Bhutanese flags did not flutter like the rectangular Indian flag displayed on the visit of an Indian official to the country. The standard measurements of the flag of Bhutan were thereafter altered to resemble the flag of India, which was 9 feet by 6 feet.\n\nIn another change, the dragon, which had formerly been placed in a roughly horizontal position in the center of the flag, was repositioned to spread out over the diagonal dividing line between the background colours. This change sought to avoid having the dragon \"face the earth\" when the flag was hanging limp. Bhutanese artist Kilkhor Lopen Jada painted a new design for the druk in which the curves of the dragon's body are relaxed to create a somewhat longer and more gently undulating shape.\n\nThe CBS document states that the king ordered the colour of the lower half changed from red to orange \"sometime in 1968 or 69.\"\n\nThe Bhutanese flag was flown abroad beside another nation's flag for the first time in 1961 during a state visit to India by Jigme Dorji Wangchuck. This visit inaugurated a new level of relations between the two countries.\n\nOn 8 June 1972 the National Assembly of Bhutan approved Resolution 28, bringing into effect National Flag Rules drafted by the Cabinet. The rules have eight provisions covering the description and symbolism of the flag's colouring, fields and design elements. Other rules relate to the size of the flag as well as flag protocol including the appropriate places and occasions for flying the flag and who may display the flag on cars. In general, the flag is given as much respect as the Bhutanese state and the head of state. As in the United States Flag Code, no other flags must be placed higher than the Bhutanese flag, the flag cannot be used as a cover or drape (with some exceptions) and the flag must not touch the ground. Other provisions include prohibitions on including the design in other objects or in a logo. Exceptionally, the flag may be used to drape coffins, but only those of high-ranking state officials such as ministers or military personnel.\n\nThe 1972 rules also provide that \"every dzongkhag [district headquarters] will hoist the national flag. Where there are no dzongkhag, the national flag will be hoisted in front of the office of the main government officer\". \n\nOfficials above the rank of minister are allowed to fly the flag at their residence provided they do not live near the capital. The tradition of flying the national flag in front of government offices had not existed in Bhutan prior to 1968 but was decreed standard practice by the Druk Gyalpo after his Secretariat was moved from the city of Taba to Tashichho Dzong in that year. The only flag day prescribed in the 1972 rules is National Day, which is held annually on December 17. National Day commemorates the crowning of Ugyen Wangchuck as the first king of Bhutan on December 17, 1907.\n\n"}
{"id": "47488580", "url": "https://en.wikipedia.org/wiki?curid=47488580", "title": "Foso (feast)", "text": "Foso (feast)\n\nFoso, fosso or posso is a ritual feast celebration among the Minahasa people of North Sulawesi, Indonesia. Described as a \"feast of merit\", the host of the event would accumulate prestige and gain status.\n"}
{"id": "11086287", "url": "https://en.wikipedia.org/wiki?curid=11086287", "title": "Gayab", "text": "Gayab\n\nGayab () () is a 2004 Indian Hindi supernatural thriller film directed by Prawaal Raman, and produced by Ram Gopal Varma. It stars Tusshar Kapoor and Antara Mali as the lead protagonists. The film became a moderate box office success and was remade in Tamil as Jithan.\n\nVishnu Prasad (Tusshar Kapoor) who is an unappreciated nerd. His mother nags him and his father ignores him. He is in love with his neighbour Mohini (Antara Mali), but she already has a boyfriend - Sameer (Raman Trikha). Vishnu sees Mohini in a cafe with Sameer. As Sameer goes to get drinks, Mohini's eyes meet Vishnu's. A shy and nervous Vishnu accidentally winks at Mohini which angers Sameer into hitting him. Vishnu bursts into tears. Sad and depressed from his life he goes to a beach.\n\nAngry at God for the life He has given him, Vishnu asks the statue to make him disappear from the world as no one likes him. When he reaches home, he discovers that God took his wish literally and turned him invisible. Excited and happy Vishnu gets many opportunities to spy on Mohini and get her boyfriend in trouble. He realises that he cannot wear any other clothes than the ones he was wearing on the day he received the boon because those were the only clothes that turned invisible with him. When Vishnu sees his father is worried about him and also because of a nagging wife, he tells his father about his secret and calms him down. He plays the role of an invisible ghost to teach his mother a lesson. His mother gets scared thinking that the ghost is of her late Father-in-law and faints. Vishnu thinks that he needs money to impress Mohini. So he robs a bank and brings her all the cash but Mohnini is shocked and terrified. Vishnu decides to tells her everything. Mohini flies in a rage and tells Vishnu to leave her alone as she is in love with Sameer.\n\nAlone and heartbroken Vishnu gets drunk and wanders the streets. The media makes up incredible stories after the bank robbery done by an \"invisible force\" and they try to get more information. The police department takes action and tries to hunt down the \"invisible-man\". Sameer decides to leave town with Mohini before Vishnu comes back looking for them again but they are unable to do so. So they go into hiding and Vishnu demands that the police bring him Mohini or else he will wreak havoc throughout the city.\n\nHe also threatens them by comically disturbing the streets and a portion of the city. The police finds Mohini and pleads with her to help them find and kill Vishnu before he becomes an invisible murderer and a threat to the whole nation. Mohini agrees to help in their mission and goes to an abandoned building to meet Vishnu, as demanded by him. As Mohini diverts Vishnu's attention by involving him in a conversation, the cops surround the place to capture him. Vishnu tells Mohini that he has been wrong all along and that he has always loved her. He tells her that he has realised that loving her doesn't mean that he has control over her life. Mohini is struck by his words and realises that he is not a bad person.\n\nShe decides to save his life and tells him to run away as the cops are already in the building. Vishnu runs for his life and dives into a river as the cops shoot him. Minutes later Vishnu's clothes(now visible) are the only things to surface. But his body is not found. Vishnu is presumed dead by the police and media. A few days later Sameer and Mohini find Vishnu again on the side of the same river in which he supposedly drowned. Vishnu apologises to them for whatever wrong he did and decides to lead a normal life. Vishnu is arrested and faces trial. Guilty of his acts he spends a short time in jail and is later released. Many months later, Vishnu is recognised by the nation as a hero and he has helped the police solve several cases while still leading an invisible but normal life.\n\n"}
{"id": "37748388", "url": "https://en.wikipedia.org/wiki?curid=37748388", "title": "Guiron le Courtois", "text": "Guiron le Courtois\n\nGuiron le Courtois is a character in Arthurian legend, a knight-errant and one of the central figures in the French romance known as \"Palamedes\", with later versions named \"Guiron le Courtois\" and the \"Compilation\" of Rustichello da Pisa. In the course of his adventures he becomes the companion of Danyn the Red, Lord of the Castle of Malaonc, whose wife, the Lady of Malaonc, is the most beautiful woman in Britain. Guiron and the lady fall in love, but the courteous knight remains loyal to his friend Danyn. Later both knights fall in love with the lady Bloye, but this time Guiron triumphs, though the couple are imprisoned and the story continues with the adventures of their son, also named Guiron.\n\nThe \"Palamedes\", \"Guiron\" \"Compilation\" texts originating in 1235-1240, create new adventures around the Tristan and Lancelot-Grail legends by going back to the heroes of the previous generation. Uterpandragon, father of Arthur is still alive, and so are the fathers of Erec and Tristan. The title refers to the Saracen knight Palamedes, whose father Esclabor also plays a role. Some versions identify Palamedes as one of the central figures, but Guiron le Courtois and Meliodas are the most important characters. Later versions including the early 16th-century printed editions produced in Paris, are divided into two parts, with the first entitled \"Meliadus de Leonnoys\" and the second \"Gyron le Courtoys\".\n\n\n"}
{"id": "24088730", "url": "https://en.wikipedia.org/wiki?curid=24088730", "title": "Göttinger Hainbund", "text": "Göttinger Hainbund\n\nThe Göttinger Hainbund (\"Grove League of Göttingen\") was a German literary group in the late 18th century, nature-loving and classified as part of the \"Sturm und Drang\" movement.\n\nIt was by means of a midnight ritual in an oaken grove that the \"Göttinger Hainbund\" was founded on 12 September 1772 by Johann Heinrich Voss, Ludwig Christoph Heinrich Hölty, Johann Martin Miller, Gottlieb Dieterich von Miller, Johann Friedrich Hahn and Johann Thomas Ludwig Wehrs, in the university town of Göttingen. The members knew one other through their presence at the University of Göttingen or through their contributions to the \"Göttinger Musenalmanach\", a literary annual founded by Heinrich Christian Boie in 1770.\n\nTheir evident delight in wilderness and untamed Nature (as a counterweight to the rationalism of the Enlightenment) is what scholars use to connect them to \"Sturm und Drang\", although not all commentators agree on who influenced whom, and in what way.\n\nIn the poetry of the 48-year-old Friedrich Gottlieb Klopstock they found their ideal. Their respect for him ran parallel to their disdain for Christoph Martin Wieland's jesting poetry, which they saw as frivolous, Frenchified work. On 2 July 1773, they celebrated Klopstock's birthday:\n\nWieland was untroubled and responded generously, referring to the members of the \"Hainbund\", in a letter to Friedrich Heinrich Jacobi, as \"well-meaning\" youngsters without experience of the world. In fact, by 1779, Voss was counted among Wieland's friends.\n\nThe term \"Hainbund\" refers to Klopstock's ode \"Der Hügel und der Hain\" (\"The Hill and the Grove\", 1767), which contrasts citified Ancient Greek artistic ideals (symbolised by Mount Parnassus) with the simple rural virtue of the German bard. The two literary predecessors, \"Poet\" and \"Barde\", vie for the allegiance of the modern \"Dichter\". The \"Poet\" condemns the \"voice of coarse Nature\", but the \"Barde\" wins by emphasizing the closer spiritual connection he holds with the living German, and the \"Dichter\" exclaims:\n\nAnother father figure (although not a member) was Gottfried August Bürger. He and Hölty are known as the inventors of the German \"Kunstballade\" (\"art ballad\").\n\nOn Sunday, 18 September 1774, Klopstock passed through the city and paid them a visit. He had intended to leave early the next morning, but transportation was difficult to find, and to their delight he spent nearly the whole of the Monday in their company.\n\nIn 1775, most of its members having completed their education, the \"Hainbund\" gradually broke up as they returned to their home cities.\n\n\n\n\n"}
{"id": "1745301", "url": "https://en.wikipedia.org/wiki?curid=1745301", "title": "Internal colonialism", "text": "Internal colonialism\n\nInternal colonialism is a notion of structural political and economic inequalities between regions within a state. The term is used to describe the uneven effects of economic development on a regional basis, otherwise known as \"uneven development\", and to describe the exploitation of minority groups within a wider society. This is held to be similar to the relationship between metropole and colony, in colonialism proper. The term used to describe the distinct separation of the dominant core, from the periphery in an empire (Howe, 2002). It was created to describe the \"blurred\" lines between geographically close locations that are clearly different in terms of culture (Howe, 2002, p. 18). Some other factors that separate the core from the periphery are: language, religion, physical appearance, types and levels of technology, and sexual behaviour (Howe, 2002, p. 19).\n\nAccording to Nicholas Thomas, who draws on the work of Michel Foucault, modernity can be understood as a colonialist project, wherein \"societies internal to Western nations, and those they possessed, administered and reformed elsewhere\"; and were framed as objects to be surveyed and regulated (Thomas, 1994: 4). The cultural and integrative nature of 'internal colonialism' is understood as a project of modernity, and has been explored by Robert Peckham, in relation to the formation of a 'national' modern Greek culture during the nineteenth century, when Greece gained independence from the Ottoman Empire (Peckham, 2004).\n\nThe first known use of the concept 'internal colonialism' was in 1957, in a book by Leo Marquard, regarding South Africa. However, widespread use followed the publication of an article on Mexico by Pablo González Casanova in 1965. Gonzalez Casanova was both critiqued by, and influenced Andre Gunder Frank, who further theorised internal colonialism as a form of \"uneven development\". Sergio Salvi, a poet, essayist, and historian of minority languages, used the term \"internal colonies\" in the cultural sense in \"Le nazioni proibite: Guida a dieci colonie interne dell'Europa occidentale\" (\"The forbidden nations: Guide to ten internal colonies of western Europe\") (1973), among which he included Catalonia, Scotland, Brittany and Occitania. Other pivotal works on the subject were published during the mid-1970s by Harold Wolpe and Michael Hechter. Adolf Hitler mentions the concept of Internal colonization in his book Mein Kampf of 1925, chapter 4, as a wrong way of tackling the problems that come with the increase of population of a nation. He states that \"The limitation to a definite small area of soil, inherent in internal colonization... leads to an exceedingly unfavorable politicomilitary situation in the nation in question.\"\n\nAn internal colony supposedly produces wealth for the benefit of those areas most closely associated with the state, usually the capital area. \n\nThe main difference between neocolonialism and internal colonialism is the source of exploitation. In the former, the control comes from outside the nation-state, while in the latter it comes from within. Robert Blauner is regarded as the developer of the 'Internal Colonialism Theory'. \n\nA common topic amongst postcolonial writers was their description of feelings, such as schizophrenia (Howe, 2002, 20): being torn between local tradition and global modernity (Howe, 2002).\n\nAfghanistan is an example of internal colonialism affecting state-building, as M Nazif Sharani argues \"the incessantly centralizing state policies and practices of internal colonialism, generally aided and abetted by old colonialist powers... produced a cumulatively negative impact on state-building efforts in Afghanistan.\" The international security scholar, Dipali Mukhopadhya, considers the presence of warlordism in the Afghan periphery to be a concern for the development of the political economy, with the 2007 World Bank Report highlighting weak institutional links between provincial offices and relationships with the central government poorly defined.\n\nOne of the exceptions of internal colonialism as the subsistence of 'blurred lines' between the core and periphery is French Algeria. There were clearly distinct features separating the core from the periphery. \"The core was Christian, French-speaking, light-skinned, and comparatively prosperous\" (Howe, 2002, 19). The other side was Muslim, Arabic/ Berber-speaking, and significantly poorer (Howe, 2002). The grey section of French Algeria, was the large Jewish population which did not belong in either the core or periphery, in terms of common cultural factors (Howe, 2002).\n\nJohn Conway documented the Internal Colonialism of Western Canadian Provinces by Central Canada in his Book \"The Rise of the New West\". Cited were issues with the National Energy Program, the Crow Rate and Equalization payments in Canada amongst others. See also Western alienation in Canada.\n\nAn example of internal colonialism is Ireland (Howe, 2002). Ireland was formerly a part of the United Kingdom (Howe, 2002). \"It was far more common and apparently easier, to think of oneself as British \"and\" Irish\" (Howe, 2002, 20). It was increasingly more difficult to choose between the two (Howe, 2002).\n\nIn the Philippines, non-Manilans have often expressed that the affairs of the country—whether political, economic but most importantly cultural including linguistic—are imposed from the Manilan core on the peripheral rest of the country due to Tagalist nationalism. This has been articulated in a Cebuano saying, which goes, \"Walay dahong mahulog sa atong nasod nga dili mananghid sa Malakanyang,\" translated as \"Not a leaf may fall in our country without Malacañang's permission.\" It is also ominous that certain personalities have called for the political isolation, overthrow and outright assassination of those who are opposed to the current core–periphery relationship.\n\nSri Lanka is a very good example of internal colonialism:\n\nInternational Dimensions of the Ethnic Conflict in Sri Lanka, Prof John P. Neelsen (Tuebingen University, Germany), 20th European Conference on Modern South Asian Studies, 8–11 July 2008: \"A shortcoming in international law as to internal colonialism and the right to self-determination renders the current types of international intervention not just inadequate to contribute to a negotiated solution of ethnic conflicts, but tends to inflame them.\"\nPower Sharing as Peace Structure: The Case of Sri Lanka, IICP Working Paper, No. 2, 2005, Johan Galtung, Professor of Peace Studies: ‘’External Colonialism: Democracy :: Internal Colonialism: Human Rights’’\n\nNational Liberation Movements in Global Context, Dr. Jeff Sluka, Massey University, New Zealand \nProceedings of the Conference on 'Tamils in New Zealand', July 1996 - Wellington, New Zealand. \nThis situation, where a state exploits and oppresses peoples and regions within their own boundaries much the way the European colonial powers used to exploit and oppress foreign colonies, has been described as \"internal colonialism\" (Hechter 1975). Sri Lanka is an example of this. Many Third World peoples found that after \"independence\" they had simply traded one set of oppressors (white) for another (brown and black). The result is that today many Third World states, most of them the direct or indirect result of national liberation wars themselves, are now fighting against national liberation movements within their borders.\n\nFourth World Colonialism, Indigenous Minorities And Tamil Separatism In Sri Lanka, Bryan Pfaffenberger (Virginia University), Bulletin of Concerned Asian Scholars, Vol. 16, 1984:\n\"Despite the withdrawal of colonial power from Third World countries, forms of oppression that might well be termed \"colonial\" still persist in many of them — the oppression wrought by nationalist Third World governments whose regimes fail to respect the rights of indigenous minorities. For ethnic and regional minorities in many Third World countries, the arrogance and injustice of these governments matches — and often exceeds — those of the departed European colonial regime. The island nation Sri Lanka presents a case in point. Little public investment appears to reach the Tamil lands….\"\n\nFor internal colonization of the kingdom of Thailand, refer to articles on Monthon and on Thaification. There is a posited link between internal colonialism and ethnic rebellion in Thailand.\n\n\n"}
{"id": "28990838", "url": "https://en.wikipedia.org/wiki?curid=28990838", "title": "Japanese urban legend", "text": "Japanese urban legend\n\nThe former rarely include the fantastica \"yokai\" of earlier Japanese superstition, but are mostly based on \"onryo\" (Japanese ghosts (yūrei) who have become vengeful spirits and take their aggression out on any who cross their path). Modern urban legends tend to include Japanese schools and, similar to the \"yokai\" legends, incorporate cautionary tales into their stories, warning people not to bully others, walk home late at night, or talk to strangers. Although there are non-supernatural urban legends in Japan's cities, such as the secret Tokyo tunnels or the corpse-washing job rumour, this article deals with both the natural \"and\" supernatural legends of modern Japan.\n\nOn 16 December 1932, the Shirokiya Department Store fire in Tokyo resulted in 14 deaths. During the fire, many saleswomen in kimono were forced onto the roof of the eight-story building. Rumors later spread that some of these women refused to jump into the safety nets held by firefighters on the ground. Traditionally, women did not wear undergarments with kimono, and they were afraid they would be exposed and ashamed if they jumped. As a result, they died. This news attracted attention from as far away as Europe. It has been alleged that in the aftermath of the fire, department store management ordered saleswomen to wear panties or other underwear with their kimono, and the trend spread.\n\nContrary to this belief, Shoichi Inoue, a professor of Japanese customs and architecture at the International Research Center for Japanese Studies, has denied the story of the ambivalent women with fatal modesty. According to Inoue, most people were saved by firemen, and the story of women who preferred to die with their modesty intact was fabricated for Westerners. The story has been prevalent in many reference books, even some published by the Fire Fighting Agency. Moreover, it is generally believed in Japan that the Shirokiya Department Store fire was a catalyst for the change in fashion customs, specifically the trend toward wearing Western-style panties, though there is no evidence to substantiate the belief.\n\nIt was rumored that the Sony Corporation installed a device in all of its electronic products that caused them to fail soon after their warranties expired, an illegal form of planned obsolescence.\n\nThis has never been substantiated and while it is unlikely that Sony would explicitly add expiration devices to their hardware, the \"Sony Timer\" has also been taken to mean that Sony manufactures devices to withstand just enough use to necessitate a new line. At the annual shareholders meeting in 2007, then president Ryoji Chubachi said that he was aware of the term \"Sony Timer\".\n\nIn 1986, Kleenex released three Japanese commercials for their tissues, featuring a woman dressed in a white toga-like dress and a child dressed as a Japanese ogre, sitting on straw. Each advert had the song \"It's a Fine Day\" by Jane & Barton playing in the background. Many viewers found the advertisement disturbing. Some complaints claimed the music sounded like a German curse, although the lyrics are in English. Because of its unnerving ambiance, several rumours began to circulate about the cast, such as with the crew meeting untimely deaths through accidents and the lead actress Keiko Matsuzaka either dying, being institutionalized or becoming pregnant with a demon child.\n\nSimilar urban legends: Set problems on \"The Exorcist\".\n\nIn Inokashira Park, Tokyo, there is a lake where visitors can rent rowing boats. It is believed that if a couple rides on a boat together, their relationship will end. The legend is connected to a local shrine dedicated to Benzaiten. She is believed to be very jealous and causes the break-ups of those who ride on the boats.\n\nThe Red Room story is an internet legend about a pop-up that appears on the victim's computer. The image simply shows a door and a recorded voice asks \"Do you like - \". Even if the pop-up is closed, it will repeatedly reappear until the voice finally completes the question: \"Do you like the red room?\"Even after still trying to close it, it will not close out. Those who have seen the pop-up are found dead, their walls painted red in their own blood. The legend began with a flash animation of a boy being cursed after encountering the pop-up, but gained notoriety when it was found that the schoolgirl who committed the Sasebo slashing in 2004 had the video as a bookmark.\n\nSimilar urban legends: Kata Lata Kulu Email\n\nThe Curse of the Colonel (\"Kāneru Sandāsu no Noroi\") is supposedly suffered by the Hanshin Tigers baseball team and cited as the cause of their poor performance in the Japan Championship Series. In 1985, fans of the Hanshin Tigers celebrated their team's first and only victory of the series and, in their excitement, threw a statue of Colonel Sanders (the founder and mascot of Kentucky Fried Chicken) into the Dōtonbori River. Since the incident, the team has yet to win the Championship again, and some fans believed the team would never do so again until the statue was recovered.\n\nThe statue was finally discovered in the Dōtonbori River on March 10, 2009. Divers who recovered the statue at first thought it was a large barrel and, shortly after, a human corpse, but Hanshin fans on the scene were quick to identify it as the upper portion of the long-lost Colonel. The right hand and lower body were found the next day, but the statue is still missing its glasses and left hand.\n\nSimilar Legends: Curse of the Bambino; Curse of the Billy Goat\n\nAka Manto is a spirit who haunts bathrooms, usually the last toilet stall in a women's or girls' bathroom. Some versions describe him as wearing a mask to cover his extremely handsome face, which had caused him stalking problems in life. When the unlucky victim is on the toilet, a mysterious voice will ask them if they want red paper or blue paper. If you answer red paper, you are killed violently and drenched in blood. If you ask for blue, you are strangled or bled dry, leaving your face/skin blue. Attempting to ask for any other colour of paper will result in hands appearing (sometimes coming out of the toilet you are sitting on) that will drag you into the fires of Hell. In other versions the ghost will simply ask you if you want a red vest and will then rip the skin from your back. He could also ask you if you want a red or blue cloak. The only answer that will spare the person is to refuse anything he offers. In another version, prompting an answer of yellow caused him to attempt drowning you in the toilet.\n\nThis story concerns a lone taxi driver making his way along a road at night. Legend goes that a person will suddenly appear from the darkness and hail the taxi. The person will sit in the back of the car and will ask to be taken to a place the driver has never heard of. When the driver mentions this, he is assured that he will be given directions. The passenger then feeds the driver increasingly complex directions which leads them down streets and alleys, through many towns and even in some instances all the way from the city to the countryside. After traveling this distance and still seeming no closer to any destination, the driver becomes uneasy. He turns around to the back seat to ask the passenger exactly where they are – but he is shocked to find that the passenger has vanished. The taxi driver turns back to the steering wheel, only to drive off the edge of a cliff and die.\n\nSimilar Urban Legends: Killer in the backseat and the Vanishing hitchhiker\n\nGozu (Ox-head), also known as Cow Head, is a Japanese urban legend about a fictional story called 'Cow Head'. This relates to the hanging of any symbolic cow decorations as well as actual bovine skeletal remains. Supposedly the Cow Head story is so horrifying that people who read or hear it are overcome with fear so great that they tremble violently for days on end until they die. One variation involves a teacher who tells a bored group of school children the story, resulting in the children and teacher becoming catatonic and losing their memory. Other variations include the detail that no one is able to retell the story since they die after hearing it. Rumors say that only fragments are left of the story. One such fragment is about a town that got cursed after they ate the Cow Head.\n\nThe Cow Head story was rumored to be an unpublished piece from sci-fi writer Sakyo Komatsu, but there is no evidence to link the author to the legend. A Ukrainian folktale called Cow's Head exists, about a woman who receives good fortune by offering food and shelter to a disembodied cow's head that visits her one night, A Gion Matsuri folktale called Somin Shorai exists, about a poor but charitable person who receives good fortune by saving a tourist Gozu Tennō (牛頭天王) who was looking for a place to stay the night on his journey, as well as a 2003 film called \"Gozu\", directed by Takashi Miike, neither of which are linked to the legend.\n\nJinmenken are dogs with human faces that supposedly appear at night in Japanese urban areas and run along highways at extremely high speeds. The jinmenken can talk, but reports say that they will either be rude or will ask to be left alone. Unlike most Japanese urban legends, the human-faced dog is not widely known to kill those unlucky enough to meet it. They are said to be escaped scientific experiments or the spirits of road crash victims.\n\nThere is speculation that witnesses who say they have met a jinmenken have actually come across Japanese macaques, which accounts for the quadrupedal movement, dog-like fur, human face and the human-like noises the jinmenken can supposedly make.\n\nSimilar Urban Legends: The Black Dog\n\nKokkuri is a Japanese version of a ouija board, which became popular during the Meiji era. Rather than using a store-bought board with letters and a planchette, 'players' write down hiragana characters and place their fingers on a coin, before asking 'Kokkuri-san' a question. This is a popular game in high schools and, similar to the western ouija board, rumours and legends surround it.\n\nSome include Kokkuri-san only telling players the date of their death, while others say you can ask Kokkuri-san anything, but you must finish the game correctly, either by saying goodbye to Kokkuri-san before leaving the table or by disposing of the kokkuri game utensils within a certain time limit, such as spending the coin or using up the ink in the pen used to write the hiragana. Failure to do so will result in misfortune or death for the players.\n\nSimilar Urban Legends: Ouija Board\n\nChildren walking alone at night may encounter a woman wearing a surgical mask. This is not an unusual sight in Japan, as people wear them to protect others from their colds or sicknesses. The woman will stop the child and ask, \"Am I beautiful?\" If they say \"no\", she kills them with a pair of scissors she always carries. If they say \"yes\", the woman removes her mask to reveal her mouth has been slit from ear to ear. The Kuchisake-onna will then ask, \"How about now?\" Regardless of whether the child answers yes or no at this point, the woman will kill them: If they say no, they are cut in half; if they say yes, she cuts their mouths to be exactly like hers. To escape the Kuchisake-onna, you can answer her second question with \"You're average\" or \"So-so\", which will confuse her so that you can escape. Alternatively, you can throw fruit or sweets at her feet, which she will pick up, thus giving the victim a chance to run. One other option is to ask her if you are pretty: She will also get confused and leave. And a fourth possibility is to say you have to meet up with your husband/your wife and she will excuse herself and leave.\n\nSimilar Urban Legends: The Hook and Bunny Man\n\nThe Teke Teke is the ghost of a young woman who was pushed onto a railway line and was cut in half by the oncoming train. Now a vengeful spirit, she carries a scythe and travels on either her hands or elbows, dragging her upper torso making a scratching or \"teke teke\" sound. If she encounters anyone at night and the victim is not fast enough, she will slice them in half at the torso to mimic her own disfigurement and they will sometimes become Teke Tekes themselves. Versions of the legend include a school boy walking home at night and spotting a beautiful girl standing by a windowsill resting on her elbows. When she notices him, she jumps out of the window and onto the pavement in front of him, revealing herself to be no more than an upper torso; she then cuts the boy in two. This urban legend has inspired a Japanese horror movie of the same name.\n\nToire no Hanako-san is a famous legend associated with Japanese elementary schools. The story tells of an omnipresent ghost who is thought to be the spirit of a student who committed suicide due to excessive bullying. However, the entity is also known to appear for no apparent reason. Hanako-san is a popular legend in elementary schools in Japan and supposedly haunts the fourth stall of the girls' bathroom. Characterized by a pair of stark gleaming eyes, the spirit scares any person who sets eyes on it. Not known to be malevolent or vicious, Hanako-san is simply an eerie entity that only scares its victims.\n\nSimilar Urban Legends: Bloody Mary\n\nKunekune is a modern urban myth concerning a distant apparition seen on widely extended rice or barley fields on hot summer days. It is described as an indiscernible white object, like a big, slender paper strip, or a white, loose textile sheet, that shimmers and wiggles as if moved by a strong gust of wind, even on windless days. It is claimed that anyone who tries to get a closer look at it is driven insane or dies when touching it. First reports of the Kunekune appeared on several internet websites at the same time. It is most likely that the Kunekune is based on local Japanese ghost stories about scarecrows coming to life at night (or when someones stares at them too often), or , or Snake worship like . Thus, the alleged encounters of Kunekune seem to be a misinterpretation of a scarecrow wiggling slightly in the wind or misinterpretation of a wick drains planted to drain water from inner ground to robust the soft ground.\n\nUrban legends are popular in Japan and are often used in movies, anime and manga, suggesting their endurance in the common imagination.\n\nKuchisake-onna\n\n\nHanako-san of the Toilet\n\n\nTeketeke\n\n\nOther\n\n\n\nSeveral horror manga works, usually anthologies, contain the urban legends listed in this article, along with some more obscure rumours and original stories.\n\nKuchi-sake Onna Manga\n\nOther legends\n\n\n\n\n\n"}
{"id": "29644283", "url": "https://en.wikipedia.org/wiki?curid=29644283", "title": "List of linguistic rights in African constitutions", "text": "List of linguistic rights in African constitutions\n\nLinguistic rights in Africa are stated in constitutions which differ by country. These constitutions usually state the national language(s) and/or official language(s), and may or may not explicitly allow for other languages in the country. Most of the linguistic rights stated here are negative rights, which grant freedom of usage of own language and prevent discrimination based on language.\n\nConstitution as adopted on 19 November 1976.\n\nConstitution as adopted on 2 December 1990.\n\nConstitution as adopted on 30 September 1966.\n\nConstitution as adopted on 2 June 1991.\n\nConstitution as consolidated on 18 March 2005\n\nConstitution as adopted on 18 January 1996.\n\nConstitution as adopted on 25 September 1992.\n\nConstitution as adopted on 31 March 1996.\n\nConstitution as adopted on 15 March 1992.\n\nConstitution as adopted on 18 February 2006.\n\nConstitution as adopted on 4 September 1992.\n\nConstitution as adopted on 11 September 1971.\n\nConstitution as amended on 17 January 1995.\n\nConstitution as adopted on 23 May 1997.\n\nConstitution as adopted on 8 December 1994.\n\nConstitution as adopted on 28 April 1992.\n\nConstitution as proposed on 6 May 2010.\n\nConstitution as adopted on 2 April 1993.\n\nConstitution as adopted on 6 January 1986.\n\nConstitution as adopted on 16 May 1994.\n\nConstitution as adopted on 27 February 1992.\n\nConstitution as adopted on 12 March 1968.\n\nConstitution as adopted on 21 January 2005.\n\nConstitution as adopted on February 1990.\n\nConstitution as adopted on 18 July 1999.\n\nConstitution as adopted on 29 May 1999.\n\nConstitution as adopted on 26 May 2003.\n\nConstitution as adopted on 7 January 2001.\n\nConstitution as adopted on 18 June 1993.\n\nConstitution as amended on 1 October 1991.\n\nConstitution as adopted on 8 May 1996.\n\nConstitution as adopted on 1 July 1998.\n\nConstitution as adopted on 26 July 2005\n\nConstitution as adopted on 1 June 1959\n\nConstitution as adopted on 8 October 1995.\n\nChapter 1, Article 3 of the constitution of the Sahrawi Arab Democratic Republic stipulates that the sole official language of Western Sahara shall be standard Arabic. In practice, Spanish is used as a working language by some Sahrawi media. The vernacular language spoken by nearly all Sahrawis, however, is Hassaniya Arabic.\n\nConstitution as adopted on 24 August 1991.\n\nConstitution as amended on 1 February 2007\n\n"}
{"id": "4990252", "url": "https://en.wikipedia.org/wiki?curid=4990252", "title": "MFA Program for Poets &amp; Writers", "text": "MFA Program for Poets &amp; Writers\n\nThe MFA Program for Poets & Writers at the University of Massachusetts Amherst is a graduate creative writing program.\n\nThe MFA Program for Poets & Writers was founded in 1963 and is part of the English Department at the University of Massachusetts Amherst.\n\nThe MFA for Poets and Writers at the University of Massachusetts Amherst is a three-year program dedicated to writing workshops and the completion of a book-length manuscript in prose or poetry. For more than fifty years the MFA for Poets and Writers has been a place for writers to concentrate on their work and to write their books.\n\nThe program sponsors regular readings by creative writers and poets through its Visiting Writers Series. Recent visitors to the MFA Program for Poets & Writers include Julie Iromuanya, Matthew Zapruder, CAConrad, Colin Barrett, Sarah Ladipo Manyika, Sally Wen Mao, Christine Schutt, Hoa Nguyen, Martín Espada, and more.\n\nMFA students in the graduate creative writing program work with the \"Juniper Summer Writing Institute\", the \"Juniper Institute for Literary Arts\", jubilat, and other opportunities in applied literary arts.\n\n\n\n\n\n\n\n\n\n\nThe faculty at this graduate creative writing program have received many awards, including the Pulitzer Prize, the National Book Award, the PEN/Faulkner Award for Fiction, the Pushcart Prize, and the Lavan Younger Poet Award from the Academy of American Poets. MFA faculty have also received many fellowships from organizations such as the National Endowment for the Arts and The John Simon Guggenheim Memorial Foundation.\n\n\nLiterary Magazines, Journals and websites run by current and former students \n\n"}
{"id": "26504149", "url": "https://en.wikipedia.org/wiki?curid=26504149", "title": "Magonia (mythology)", "text": "Magonia (mythology)\n\nMagonia is the name of the cloud realm whence felonious aerial sailors were said to have come according to the polemical treatise by Carolingian bishop Agobard of Lyon in 815, where he argues against weather magic. The treatise is titled \"De Grandine et Tonitruis\" (\"On Hail and Thunder\").\n\nThe inhabitants of this realm were said to travel the clouds in ships and worked with Frankish \"tempestarii\" (\"tempest-raisers\" or weather-magi) to steal grain from the fields during (magically raised) storms.\n\nAgobard's works were lost until 1605, when a manuscript was discovered in Lyons and published by Papirius Masson, and again by Baluze in 1666. For later editions see August Potthast, \"Bibliotheca Historica Medii Aevi\". The life of Agobard in Ebert's \"Allgemeine Geschichte der Literatur des Mittelalters im Abendlande\" (1880), Band ii., is still the best one to consult. For further indications see A. Molinier, \"Sources de l'histoire de France\", i. p. 235.\n\nMagonia is featured in Jacques Vallee's book \"Passport to Magonia\", which explores the link between modern UFO visitations and reports from antiquity of contact with these \"space beings\" where he quotes Agobard's description.\n\nMaria Dahvana Headley's young adult novel \"Magonia\" also references the mythological realm.\n"}
{"id": "894486", "url": "https://en.wikipedia.org/wiki?curid=894486", "title": "Master of Fine Arts", "text": "Master of Fine Arts\n\nA Master of Fine Arts (MFA or M.F.A.) \nis a creative degree in fine arts, including visual arts, creative writing, graphic design, photography, filmmaking, dance, theatre, other performing arts, and in some cases, theatre management or arts administration. \nIt is a graduate degree that typically requires two to three years of postgraduate study after a bachelor's degree, though the term of study varies by country or university. The MFA is a terminal degree. Coursework is primarily of an applied or performing nature with the program often culminating in a major work or performance.\n\nEntry to an MFA program generally requires a bachelor's degree prior to admission, but many institutions do not require that an undergraduate major be exactly the same as the MFA field of study. The most important admissions requirement has often been a sample portfolio of artworks or a performance audition.\n\nThe Master of Fine Arts differs from the Master of Arts in that the MFA, while still an academic program, centers around professional artistic practice in the particular field, whereas programs leading to the MA usually center on the scholarly, academic, or critical study of the field. Additionally, in the United States, an MFA is typically recognized as a terminal degree for practitioners of visual art, design, dance, photography, theatre, film/video, new media, and creative writing—meaning that it is considered the highest degree in its field, and is the qualification to become a professor at the university level in these disciplines. \n\n"}
{"id": "3095681", "url": "https://en.wikipedia.org/wiki?curid=3095681", "title": "Mauger (Jamaican Patois term)", "text": "Mauger (Jamaican Patois term)\n\nMawga , the Jamaican Patois word for 'meagre', is a term used in rural Jamaica for a thin woman. In Jamaica, plumpness is considered to be important or vital to good health. The desired body is plump, full of vital bodily fluids, and the flow of substances through the body is maintained, both of which are contributing factors to good health. Any disruption in this flow or lack of bodily fluids is considered to be unhealthy and contributes to sickness. Being thin is associated with bad health, and is a factor which affects social relationships. According to Elis J. Sobo, \"A slim person, especially a slim woman, is called mawga - meagre and powerless - as if not alive at all, and like a mummy or an empty husk, far beyond that powerfully dangerous state of decay. A thin, dry body reveals a person's non-nurturant nature and his or her lack of social commitment\" (p.262).\n\nBeing plump is associated with good social relationships, and thin person (mauger) is associated with bad social relationships. With this, unkindness and infertility are associated with a thin person. Food practices in the kitchen, as mentioned before, can give away a person's personality by use of food. For example, ones who do not use salt in their cooking are considered to be mean, as salt is associated with plumpness, meaning good health and good social relationships with others. Another example would be the purchase of store-bought foods. \n\n\n"}
{"id": "1994999", "url": "https://en.wikipedia.org/wiki?curid=1994999", "title": "Melodic expectation", "text": "Melodic expectation\n\nIn music cognition and musical analysis, the study of melodic expectation considers the engagement of the brain's predictive mechanisms in response to music. For example, if the ascending musical partial octave \"do-re-mi-fa-sol-la-ti-...\" is heard, listeners familiar with Western music will have a strong expectation to hear or provide one more note, \"do\", to complete the octave.\n\nMelodic expectation can be considered at the esthesic level, in which case the focus lies on the listener and its response to music. It can be considered at the neutral level, in which case the focus switches to the actual musical content, such as the \"printed notes themselves\". At the neutral level, the observer may consider logical implications projected onto future elements by past elements or derive statistical observations from information theory.\n\nThe notion of melodic expectation has prompted the existence of a corpus of studies in which authors often choose to provide their own terminology in place of using the literature's. This results in an important number of different terms that all point towards the phenomenon of musical expectation:\n\n\nExpectation can also be found mentioned in relation to concepts originating from the field of information theory such as entropy.\nHybridization of information theory and humanities results in the birth of yet other notions, particularly variations upon the notion of entropy modified for the need of description of musical content.\n\nConsideration of musical expectation can be sorted into four trends.\n\n\nLeonard Meyer's \"Emotion and Meaning in Music\" is the classic text in music expectation. Meyer's starting point is the belief that the experience of music (as a listener) is derived from one's emotions and feelings about the music, which themselves are a function of relationships within the music itself. Meyer writes that listeners bring with them a vast body of musical experiences that, as one listens to a piece, conditions one's response to that piece as it unfolds. Meyer argued that music's evocative power derives from its capacity to generate, suspend, prolongate, or violate these expectations.\n\nMeyer models listener expectation in two levels. On a perceptual level, Meyer draws on Gestalt psychology to explain how listeners build mental representations of auditory phenomena. Above this raw perceptual level, Meyer argues that learning shapes (and re-shapes) one's expectations over time.\n\nNarmour's (1992) Implication-Realization (I-R) Model is a detailed formalization based on Meyer's work on expectation. A fundamental difference between Narmour's models and most theories of expectation lies in the author's conviction according to which a genuine theory should be formulated in falsifiable terms. According to Narmour, prior knowledge of musical expectation is based too heavily upon percepts, introspection and internalization, which bring insoluble epistemological problems. The theory focuses on how \"implicative intervals\" set up expectations for certain \"realizations\" to follow. The I-R model includes two primary factors: proximity and direction. Lerdahl extended the system by developing a tonal pitch space and adding a stability factor (based on Lerdahl's prior work) and a mobility factor.\n\nMainly developed at IRISA since 2011 by Frédéric Bimbot and Emmanuel Deruty, the system & contrast or S&C model of implication derives from the two fundamental hypotheses underlying the I-R model. It is rooted in Narmour's conviction according to which any model of expectation should be expressed in logical, falsifiable terms. It operates at the neutral level and differs from the I-R model in several regards:\n\n\nMargulis's 2005 model further extends the I-R model. First, Margulis added a melodic attraction factor, from some of Lerdahl's work. Second, while the I-R model relies on a single (local) interval to establish an implication (an expectation), Margulis attempts to model intervalic (local) expectation as well as more deeply schematic (global) expectation. For this, Margulis relies on Lerdahl's and Jackendoff's GTTM to provide a time-span reduction. At each hierarchical level (a different time scale) in the reduction, Margulis applies her model. These separate levels of analysis are combined through averaging, with each level weighted according to values derived from the time-span reduction. Finally, Margulis's model is explicit and realizable, and yields quantitative output. The output - melodic expectation at each time instant - is a single function of time.\n\nMargulis's model describes three distinct types of listener reactions, each derived from listener-experienced \"tension\":\n"}
{"id": "16662212", "url": "https://en.wikipedia.org/wiki?curid=16662212", "title": "Micro Ventures", "text": "Micro Ventures\n\nMicro Ventures is an educational part live action, part animated series created by Hanna-Barbera Productions which originally aired as a four-minute segment on \"The Banana Splits Adventure Hour\". It ran for only four episodes from November 9, 1968 to December 21, 1968 on NBC and featured actors superimposed with animated microorganisms.\n\nIn each episode, Professor Carter and his two teenage kids, Mike and Jill, use a shrinking machine to shrink themselves and their dune buggy to miniature size to explore and experience the world from the perspective of an insect.\n\n\n"}
{"id": "55641459", "url": "https://en.wikipedia.org/wiki?curid=55641459", "title": "Minority language broadcasting", "text": "Minority language broadcasting\n\nMinority language broadcasting comprises radio and television programmes for both national (including indigenous) and foreign minorities in their respective languages.\n\nUnder treaties like the European Charter for Regional or Minority Languages (Art. 11 and 7(1)d) states are obliged to encourage broadcasting in national minorities' languages.\n\nSome examples:\n"}
{"id": "24796807", "url": "https://en.wikipedia.org/wiki?curid=24796807", "title": "Modular art", "text": "Modular art\n\nModular art is art created by joining together standardized units (modules) to form larger, more complex compositions. In some works the units can be subsequently moved, removed and added to – that is, \"modulated\" – to create a new work of art, different from the original or ensuing configurations.\n\nHistorically, alterable objects of art have existed since the Renaissance, for example, in the Triptych \"The Garden of Earthly Delights\" by Hieronymus Bosch or in the so-called \"alterable altarpieces\", such as the Isenheim Altarpiece by Matthias Grünewald, or Albrecht Dürer's Paumgartner altarpiece, where changing motifs could be revised in accord with the changing themes of the ecclesiastical calendar.\n\nBeginning in the first half of the 20th century, a number of contemporary artists sought to incorporate kinetic techniques into their work in an attempt to overcome what they saw as the predominantly static nature of art. Alexander Calder's mobiles are among the most widely known demonstrations of physical dynamism in the visual arts, in which form has the potential to continually vary through perpetual motion, sometimes even without the agency of the human hand. Jean Tinguely's efforts to create a self-destructive art machine constitute perhaps the ultimate expression of art's mutability, in this case by taking the form of its total eradication. Victor Vasarely postulated in his \"Manifest Jaune\" in 1955 in Paris that works of art should feature the properties of being multiplicable and repeatable in series. More recently, the notion that visual art need not be conceived solely in terms of perpetually fixed objects is embodied in performance and installation art by virtue of their unfolding and temporary qualities. \n\nModularity enters the modern artistic repertory largely through the disciplines of industrial design and architecture. Belgian architect Louis Herman De Koninck led a team of countrymen in creating one of the first modular product systems in their Cubex kitchen series of 1932. The series consisted of standardized and industrially produced components that could be combined and arrayed in limitless combinations to accommodate almost any size kitchen. New York designer Gilbert Rohde crafted several lines of modular casework for the Herman Miller Corporation in the 1930s and 40s; like De Koninck, Rohde standardized the units in dimensions, materials and configurations to facilitate mass production and interchangeability. His Executive Office Group (EOG) line, launched in 1942, was a similarly ground-breaking systems approach to office furniture. Just a year before Eero Saarinen and Charles Eames had jointly produced a suite of modular domestic furniture for the Red Lion Company, a result of a competition held by the Museum of Modern Art in New York. In 1950 Herman Miller brought out the EAS Storage Unit series by Charles and Ray Eames, a very successful modular shelving and wall unit system that remains in production today.\n\nThe module enjoys a long history in the realm of architecture. In antiquity architects utilized the module primarily as a unit of measurement guiding the proportions of plan and elevation. The Roman author and architect Vitruvius deployed the modular method in his descriptions of the classical orders and the composition of buildings in his treatise \"Ten Books on Architecture\", the only complete text on architecture to survive from antiquity. Architects of the Renaissance perpetuated the Vitruvian system in their resurrection of the classical orders, a tradition which continues to the present day. Among modern architects, the module is frequently employed as a design and planning tool.\n\nArchitecture and modular sculpture intersected starting in the 1950s in the work of Norman Carlberg, Erwin Hauer and Malcolm Leland. All three received commissions to design perforated architectural screens built out of repetitive modular motives cast in concrete. Non-structural, the screens were used on building exteriors to divide space, filter light and create visual interest. Their work has come to be described as Modular Constructivism, reflecting both its compositional methodology and its architectural context. Each created stand-alone modular-themed sculptures into the 1960s and after as well.\n\nRobert Rauschenberg's \"White Painting\" of 1951; consisting of just four equal white squares, with its geometry of interlocking forms, is among the earliest statements of modularity as an autonomous subject of art. Rauschenberg explored this theme that same year in a three- and seven-panel format; the linear array of rectangular panels in these versions suggests their potentially infinite replication. The cool abstraction of these canvases presages the emergence of modularity as a full-fledged topic of Minimalist art in the 1960s. Tony Smith, Sol LeWitt, Dan Flavin and Donald Judd are among this school's most prolific exponents during the period. In particular, the work of Smith is key to understanding the transformation of modularity from a compositional and production tool into a broadly investigated artistic theme in its own right.\n\nSmith began his career as an architectural designer. To further his education he apprenticed himself on some projects by Frank Lloyd Wright for a couple of years starting in 1938. From Wright he learned to utilize modular systems in generating architectural designs in two-dimensional plans as well as in three-dimensional applications, such as the development of building sections and interior built-ins. As an architect, Wright himself was part of a centuries-old continuum stretching back through Vitruvius to Greco-Roman antiquity in which the module was utilized to proportion built and sculpted form. In the case of Wright, the interest in modular design also may have derived from his familiarity with modular practice in traditional Japanese architecture.\n\nWright's Hanna House of 1937 is a clear example of the master's facility with modern modular design in multiple dimensions. Its striking angled forms are built up from the individual hexagonal modules that define the floor plan and various vertical elements. Wright's use of the hexagon here is by no means an arbitrary aesthetic choice, but an example of how he rooted his architecture in nature by drawing from its forms and principles – the interlocking hexagonal cells of the bee's honeycomb being nature's most perfect representation of modular design. Not surprisingly, this project is sometimes referred to as the \"Honeycomb House\".\n\nSmith would employ the hexagon and other elemental geometries in his own architectural practice and again in the sculpture he began to fabricate in the early 1960s. Freed from the programmatic and extensive structural requirements of his architectural work, Smith's sculptures are three-dimensional extrusions of modular form with no ostensible pragmatic purpose beyond aesthetic contemplation.\n\nSignificantly, Smith himself did not manually fabricate the final version of his sculptures. Instead, he outsourced their production to skilled ironworkers in foundries and industrial facilities, who worked off his drawings and models to manufacture the designs. In part this reflects Smith's training as an architect, who customarily designs and documents but does not construct his art. It further reinforces the idea of modular art as a generative system in which the arrangement of pre-determined formal units – rather than wholesale imaginative invention – defines the creative act. Finally, it is consistent with the notion implicit in modularity that the supply of modules in a modular system must be infinite, that is, that they be industrially rather than artisanally produced, for the system to be realized. (Bees in a honeycomb are essentially operating as an industrial enterprise insofar as the production of cells is without end.)\n\nThe work of Smith and the minimalist school constitute the most far-ranging exploration of modularity in art before the millennium. However, neither it nor the explorations of movable and alterable art in the preceding centuries synthesized the two central features of modular art. Mobiles and other kinetic pieces were not modular, and the modular work of the mid-century Minimalist artists was, with a few exceptions, not changeable.\n\nA school of thought coming out of the United States emphasizes modular art's alignment with the post-industrial character of 21st century culture and its contrast with traditional notions of art. Core characteristics of post-industrialism, as largely defined by the theorist Daniel Bell in his 1973 book \"The Coming of Post-Industrial Society\", include the emergence of a service economy in place of a manufacturing one; the social and economic pre-eminence of the creative, professional and technical classes; the central place of theoretical knowledge as a font of innovation; the strong influence of technology on daily life; and high levels of urbanization.\n\nModular art appears to synchronize perfectly with several of these criteria. For example, its manual changeability opens up the possibility of co-creative art, in which the collector or user collaborates with the originating modular artist to jointly determine the appearance of the work of art. This presupposes the existence of creative people capable of and interested in serving such a role – a demographic evolution that was already underway in Bell's time and that has since been studied in works like Richard Florida's \"Rise of the Creative Class\" (2002).\n\nCo-creation is closely associated with mass customization, a production model that combines the opportunity for individual personalization with mass production. Modular art and mass customization share a commonality in their synthesis of two opposing qualities. On the one hand, as previously stated the very concept of modularity implies a limitless supply of identical modules such as only industrial production can provide; on the other hand, the ability of the individual to re-arrange these modules in the work of art based on aesthetic criteria re-injects a subjective and purely human dimension into the creative act.\n\nMass customization is itself only made possible with the advent of computers and a type of software known as a configurator. A configurator is a software tool used by the buyer to configure a product from the options made available by the vendor. Applied to the purpose of composing a work of modular art onscreen, it can greatly facilitate the design of a modular assembly by allowing the user to study multiple design options more quickly and in far greater depth than by using analog methods. Once the design is established a computer file is then sent over the air to a manufacturing facility where robotically controlled equipment produces the object according to its specifications. Not only does this computer-aided manufacturing (CAM) allow for the customization of mass-produced objects, it also enables a much higher level of precision and fit – qualities critical for modules to be physically joined together. Bell's identification of technology as a central axis of post-industrial life is underscored in the intertwining of the digital with the physical realization of modular art.\n\nIn Europe, where the 1960s Minimalist school of modular art was often seen as a principally American phenomenon, the discussion of modularity often focuses on its changeability. For example, the mutability of art is a core principle of Arte Povera, a contemporaneous movement that emerged in Italy which holds that works of art \"should not be seen as fixed entities\", but as objects of change and movement to \"include time and space in a new manner. At stake is the issue of transferring the phenomenology of human experience\" into the arts.\n\nMore recently, the artist Leda Luss Luyken has produced modular paintings, composed of movable painted panels set in steel frames. Luss Luyken has dubbed her work \"ModulArt\". In her work, changing the configuration of a modular painting constitutes a form of motion, offering the spectator alternative views and alternative interpretations, and thus aligning the work more closely than a static object to the dynamism of physical human experience. Art historian and theorist Denys Zacharopoulos called this \"a new way of motion in painting\". The concept of modular art allows the user to de-compose and to re-compose a work of art that is already completed by re-arranging its parts, thus providing numerous possibilities for ever newer pictures not yet imagined. The original painting can be re-contextualized ad libitum and ad infinitum.\n\nWorking in the 1950-60s in Manchester (UK), American artist Mitzi Cunliffe developed sculptures consisting of multiple blocks about twelve inches square which she put together in a variety of combinations to give a sculptured effect on a large scale. She referred to them as \"modular sculptures\". The University of Manchester and the University of Manchester Institute of Science and Technology (UMIST) acquired some of these works, although there are no references to them in published accounts of her work.\n\nSculptor and ceramicist Malcolm Leland designed in 1954 a similar modular sculpture system based on a single 23-inch tall module that could be stacked vertically by means of a centering pin; the module has a generally biomorphic, curvilinear outline that yields an undulating silhouette when multiple modules are placed on top of each other. The technique of stacking repetitive elements in the round recalls Brancusi's \"Endless Column\" of 1938.\n\nStarting in the 1970s, Leland's contemporary Norman Carlberg produced groups of square framed prints which he placed together on a wall in a tight grid, each print conceived as an independent module. The viewer is then invited to rotate or reposition them to generate new composite images. The abstract quality of the prints enhanced the creative possibilities of their re-orientation insofar as they are non-directional and geometrically inter-related.\n\nGreek-born conceptual artist Leda Luss Luyken, who was initially trained as an architect, has been exploring modularity in the medium of painting since the 1990s. In her work standardized canvas panels are mounted as modules onto a steel frame within which they can be moved and rotated.\n\nIn the U.S. Moshé Elimelech creates what he has called \"Cubic Constructions\". These are multiple groupings of approximately three-inch cubes set inside pockets in a framed shadow box. On each cube he applies paint in fields of bright color and abstract pattern with precise, controlled brush strokes. Like Carlsberg, Elimelech then invites the viewer to reposition any or all of the cubes to display one of their six sides, each of which is painted in a different pattern. Exhibiting since the 1980s, Elimelech shows primarily in California galleries, and has work represented in several museum design stores as well.\n\nAnother portfolio of interactive modular art comes out of Studio for A.R.T. and Architecture, a New York-based firm headed by Donald Rattner. Rattner has designed modular art in the media of wall sculpture, rotational paintings, tapestries, artist's wallpapers and artist's books. To bring his work and those of other \"modulartists\" to the marketplace, Rattner founded A.R.T. (art-rethought), an art storefront focused on co-creative and modular work. In his writings Rattner has emphasized the post-industrial aspect of the most recent trends in modular art, coining the term \"New Industrialism\" to denote mass customization, production on demand, open innovation, co-creative design, tele-fabrication, robotics and other computer-driven technologies that are re-defining how things are made in the global marketplace.\n\nModularity in music can be seen as bringing two key elements of musical composition and film into the world of painting: variation of a theme and movement of and within a picture. For this very reason the contemporary composer Minas Borboudakis has dedicated the third part of his trilogy ROAI III for piano and electronics to the modular methodology.\n\nItalian composer and arts theoretician Stefano Vagnini has developed a theory of open-source composition based on modular aggregation. The concept of a musical work of art being something closed, limited and immobile disappears in favor of a process of numerous aggregations that allow a composition to become infinite in principle. Several such compositions were performed in Europe, South America, Asia and in North America and discussed through conferences in Europe. The approach is being academically discussed at the University of West Georgia and the Carrollton Cultural Arts Centre in the USA. Writer, painter, and art theorist Gian Ruggero Manzoni described the modularity of Vagnini's compositions as “circular like the existence, his works are not finished, but merely stimulus for new voices”. \n\n\n\n"}
{"id": "21217", "url": "https://en.wikipedia.org/wiki?curid=21217", "title": "Native Americans in the United States", "text": "Native Americans in the United States\n\nNative Americans, also known as American Indians, Indigenous Americans and other terms, are the indigenous peoples of the United States, except Hawaii. There are over 500 federally recognized tribes within the US, about half of which are associated with Indian reservations. The term \"American Indian\" excludes Native Hawaiians and some Alaska Natives, while Native Americans (as defined by the US Census) are American Indians, plus Alaska Natives of all ethnicities. Native Hawaiians are not counted as Native Americans by the US Census, instead being included in the Census grouping of \"Native Hawaiian and other Pacific Islander.\"\n\nThe ancestors of modern Native Americans arrived in what is now the United States at least 15,000 years ago, possibly much earlier, from Asia via Beringia. A vast variety of peoples, societies and cultures subsequently developed. Native Americans were greatly affected by the European colonization of the Americas, which began in 1492, and their population declined precipitously due to introduced diseases, warfare, and slavery. After the founding of the United States, many Native American peoples were subjected to warfare, removals and one-sided treaties, and they continued to suffer from discriminatory government policies into the 21st century. Since the 1960s, Native American self-determination movements have resulted in changes to the lives of Native Americans, though there are still many contemporary issues faced by Native Americans. Today, there are over five million Native Americans in the United States, 78% of whom live outside reservations. \n\nWhen the United States was created, established Native American tribes were generally considered semi-independent nations, as they generally lived in communities separate from British settlers. The federal government signed treaties at a government-to-government level until the Indian Appropriations Act of 1871 ended recognition of independent native nations, and started treating them as \"domestic dependent nations\" subject to federal law. This law did preserve the rights and privileges agreed to under the treaties, including a large degree of tribal sovereignty. For this reason, many (but not all) Native American reservations are still independent of state law for this reason, and actions of tribal citizens on these reservations are subject only to tribal courts and federal law.\n\nThe Indian Citizenship Act of 1924 granted U.S. citizenship to all Native Americans born in the United States who had not yet obtained it. This emptied the \"Indians not taxed\" category established by the United States Constitution, allowed natives to vote in state and federal elections, and extended the Fourteenth Amendment protections granted to people \"subject to the jurisdiction\" of the United States. However, some states continued to deny Native Americans voting rights for several decades. Bill of Rights protections do not apply to tribal governments, except for those mandated by the Indian Civil Rights Act of 1968.\n\nSince the end of the 15th century, the migration of Europeans to the Americas has led to centuries of population, cultural, and agricultural transfer and adjustment between Old and New World societies, a process known as the Columbian exchange. As most Native American groups had historically preserved their histories by oral traditions and artwork, the first written sources of the conflict were written by Europeans.\nEthnographers commonly classify the indigenous peoples of North America into ten geographical regions with shared cultural traits, called cultural areas. Some scholars combine the Plateau and Great Basin regions into the Intermontane West, some separate Prairie peoples from Great Plains peoples, while some separate Great Lakes tribes from the Northeastern Woodlands. The ten cultural areas are as follows:\n\n\nAt the time of the first contact, the indigenous cultures were quite different from those of the proto-industrial and mostly Christian immigrants. Some Northeastern and Southwestern cultures, in particular, were matrilineal and operated on a more collective basis than the Europeans were familiar with. The majority of Indigenous American tribes maintained their hunting grounds and agricultural lands for use of the entire tribe. Europeans at that time had patriarchal cultures and had developed concepts of individual property rights with respect to land that were extremely different. The differences in cultures between the established Native Americans and immigrant Europeans, as well as shifting alliances among different nations in times of war, caused extensive political tension, ethnic violence, and social disruption. Even before the European settlement of what is now the United States, Native Americans suffered high fatalities from contact with new European diseases, to which they had not yet acquired immunity; the diseases were endemic to the Spanish and other Europeans, and spread by direct contact and likely through pigs that escaped from expeditions. Smallpox epidemics are thought to have caused the greatest loss of life for indigenous populations. William M Denevan, noted author and Professor Emeritus of Geography at the University of Wisconsin-Madison, said on this subject in his essay \"The Pristine Myth: The Landscape of the Americas in 1492\"; \"The decline of native American populations was rapid and severe, probably the greatest demographic disaster ever. Old World diseases were the primary killer. In many regions, particularly the tropical lowlands, populations fell by 90 percent or more in the first century after the contact. \"\n\nEstimates of the pre-Columbian population of what today constitutes the U.S. vary significantly, ranging from William M Denevan's 3.8 million in his 1992 work \"The Native Population of the Americas in 1492\", to 18 million in Henry F Dobyns's \"Their Number Become Thinned\" (1983). Henry F Dobyns' work, being the highest single point estimate by far within the realm of professional academic research on the topic, has been criticized for being \"politically motivated\". Perhaps Dobyns' most vehement critic is David Henige, a bibliographer of Africana at the University of Wisconsin, whose \"Numbers From Nowhere\" (1998) is described as \"a landmark in the literature of demographic fulmination.\" \"Suspect in 1966, it is no less suspect nowadays,\" Henige wrote of Dobyns's work. \"If anything, it is worse.\"\n\nAfter the thirteen colonies revolted against Great Britain and established the United States, President George Washington and Henry Knox conceived of the idea of \"civilizing\" Native Americans in preparation for assimilation as U.S. citizens. Assimilation (whether voluntary, as with the Choctaw, or forced) became a consistent policy through American administrations. During the 19th century, the ideology of manifest destiny became integral to the American nationalist movement. Expansion of European-American populations to the west after the American Revolution resulted in increasing pressure on Native American lands, warfare between the groups, and rising tensions. In 1830, the U.S. Congress passed the Indian Removal Act, authorizing the government to relocate Native Americans from their homelands within established states to lands west of the Mississippi River, accommodating European-American expansion. This resulted in the ethnic cleansing of many tribes, with the brutal, forced marches coming to be known as The Trail of Tears.\n\nAs American expansion reached into the West, settler and miner migrants came into increasing conflict with the Great Basin, Great Plains, and other Western tribes. These were complex nomadic cultures based on (introduced) horse culture and seasonal bison hunting. They carried out resistance against United States incursion in the decades after the end of the Civil War and the completion of the Transcontinental Railroad in a series of Indian Wars, which were frequent up until the 1890s and continued into the 20th century. Over time, the United States forced a series of treaties and land cessions by the tribes and established reservations for them in many western states. U.S. Indian agents encouraged Native Americans to adopt European-style farming and similar pursuits, but European-American agricultural technology of the time was inadequate for the often dry reservation lands, leading to mass starvation. In 1924, Native Americans who were not already U.S. citizens were granted citizenship by Congress.\n\nContemporary Native Americans have a unique relationship with the United States because they may be members of nations, tribes, or bands with sovereignty and treaty rights. Cultural activism since the late 1960s has increased political participation and led to an expansion of efforts to teach and preserve indigenous languages for younger generations and to establish a greater cultural infrastructure: Native Americans have founded independent newspapers and online media, recently including First Nations Experience, the first Native American television channel; established Native American studies programs, tribal schools, and universities, and museums and language programs; and have increasingly been published as authors in numerous genres.\n\nThe terms used to refer to Native Americans have at times been controversial. The ways Native Americans refer to themselves vary by region and generation, with many older Native Americans self-identifying as \"Indians\" or \"American Indians\", while younger Native Americans often identify as \"Indigenous\" or \"Aboriginal\". The term \"Native American\" has not traditionally included Native Hawaiians or certain Alaskan Natives, such as Aleut, Yup'ik, or Inuit peoples. By comparison, the indigenous peoples of Canada are generally known as First Nations.\n\nIt is not definitively known how or when the Native Americans first settled the Americas and the present-day United States. The prevailing theory proposes that people migrated from Eurasia across Beringia, a land bridge that connected Siberia to present-day Alaska during the Ice Age, and then spread southward throughout the Americas over the subsequent generations. Genetic evidence suggests at least three waves of migrants arrived from Asia, with the first occurring at least 15 thousand years ago. These migrations may have begun as early as 30,000 years ago and continued through to about 10,000 years ago, when the land bridge became submerged by the rising sea level caused by the ending of the last glacial period. These early inhabitants, called Paleoamericans, soon diversified into many hundreds of culturally distinct nations and tribes.\n\nThe pre-Columbian era incorporates all period subdivisions in the history and prehistory of the Americas before the appearance of significant European influences on the American continents, spanning the time of the original settlement in the Upper Paleolithic period to European colonization during the Early Modern period. While technically referring to the era before Christopher Columbus' voyages of 1492 to 1504, in practice the term usually includes the history of American indigenous cultures until they were conquered or significantly influenced by Europeans, even if this happened decades or even centuries after Columbus' initial landing.\n\nNative American cultures are not normally included in characterizations of advanced stone age cultures as \"Neolithic,\" which is a category that more often includes only the cultures in Eurasia, Africa, and other regions. The archaeological periods used are the classifications of archaeological periods and cultures established in Gordon Willey and Philip Phillips' 1958 book \"Method and Theory in American Archaeology\". They divided the archaeological record in the Americas into five phases; see Archaeology of the Americas.\n\nNumerous Paleoindian cultures occupied North America, with some arrayed around the Great Plains and Great Lakes of the modern United States and Canada, as well as adjacent areas to the West and Southwest. According to the oral histories of many of the indigenous peoples of the Americas, they have been living on this continent since their genesis, described by a wide range of traditional creation stories. Other tribes have stories that recount migrations across long tracts of land and a great river, believed to be the Mississippi River. Genetic and linguistic data connect the indigenous people of this continent with ancient northeast Asians. Archeological and linguistic data has enabled scholars to discover some of the migrations within the Americas.\n\nThe Clovis culture, a megafauna hunting culture, is primarily identified by the use of fluted spear points. Artifacts from this culture were first excavated in 1932 near Clovis, New Mexico. The Clovis culture ranged over much of North America and also appeared in South America. The culture is identified by the distinctive Clovis point, a flaked flint spear-point with a notched flute, by which it was inserted into a shaft. Dating of Clovis materials has been by association with animal bones and by the use of carbon dating methods. Recent reexaminations of Clovis materials using improved carbon-dating methods produced results of 11,050 and 10,800 radiocarbon years B.P. (roughly 9100 to 8850 BCE).\nThe Folsom Tradition was characterized by the use of Folsom points as projectile tips and activities known from kill sites, where slaughter and butchering of bison took place. Folsom tools were left behind between 9000 BCE and 8000 BCE.\n\nNa-Dené-speaking peoples entered North America starting around 8000 BCE, reaching the Pacific Northwest by 5000 BCE, and from there migrating along the Pacific Coast and into the interior. Linguists, anthropologists, and archaeologists believe their ancestors comprised a separate migration into North America, later than the first Paleo-Indians. They migrated into Alaska and northern Canada, south along the Pacific Coast, into the interior of Canada, and south to the Great Plains and the American Southwest. Na-Dené-speaking peoples were the earliest ancestors of the Athabascan-speaking peoples, including the present-day and historical Navajo and Apache. They constructed large multi-family dwellings in their villages, which were used seasonally. People did not live there year-round, but for the summer to hunt and fish, and to gather food supplies for the winter.\n\nSince the 1990s, archeologists have explored and dated eleven Middle Archaic sites in present-day Louisiana and Florida at which early cultures built complexes with multiple earthwork mounds; they were societies of hunter-gatherers rather than the settled agriculturalists believed necessary according to the theory of Neolithic Revolution to sustain such large villages over long periods. The prime example is Watson Brake in northern Louisiana, whose 11-mound complex is dated to 3500 BCE, making it the oldest, dated site in North America for such complex construction. It is nearly 2,000 years older than the Poverty Point site. Construction of the mounds went on for 500 years until the site was abandoned about 2800 BCE, probably due to changing environmental conditions.\n\nThe Oshara Tradition people lived from 700-1000 B.C CE. They were part of the Southwestern Archaic Tradition centered in north-central New Mexico, the San Juan Basin, the Rio Grande Valley, southern Colorado, and southeastern Utah.\n\nPoverty Point culture is a Late Archaic archaeological culture that inhabited the area of the lower Mississippi Valley and surrounding Gulf Coast. The culture thrived from 2200 BCE to 700 BCE, during the Late Archaic period. Evidence of this culture has been found at more than 100 sites, from the major complex at Poverty Point, Louisiana (a UNESCO World Heritage Site) across a range to the Jaketown Site near Belzoni, Mississippi.\n\nThe Formative, Classic and post-Classic stages are sometimes incorporated together as the Post-archaic period, which runs from 1000 BCE onward. Sites & cultures include: Adena, Old Copper, Oasisamerica, Woodland, Fort Ancient, Hopewell tradition and Mississippian cultures.\n\nThe Woodland period of North American pre-Columbian cultures refers to the time period from roughly 1000 BCE to 1000 CE in the eastern part of North America. The Eastern Woodlands cultural region covers what is now eastern Canada south of the Subarctic region, the Eastern United States, along to the Gulf of Mexico. The Hopewell tradition describes the common aspects of the culture that flourished along rivers in the northeastern and midwestern United States from 100 BCE to 500 CE, in the Middle Woodland period. The Hopewell tradition was not a single culture or society, but a widely dispersed set of related populations. They were connected by a common network of trade routes, This period is considered a developmental stage without any massive changes in a short period, but instead having a continuous development in stone and bone tools, leather working, textile manufacture, tool production, cultivation, and shelter construction.\n\nThe indigenous peoples of the Pacific Northwest Coast were of many nations and tribal affiliations, each with distinctive cultural and political identities, but they shared certain beliefs, traditions, and practices, such as the centrality of salmon as a resource and spiritual symbol. Their gift-giving feast, potlatch, is a highly complex event where people gather in order to commemorate special events. These events include the raising of a Totem pole or the appointment or election of a new chief. The most famous artistic feature of the culture is the Totem pole, with carvings of animals and other characters to commemorate cultural beliefs, legends, and notable events.\nThe Mississippian culture was a mound-building Native American civilization archeologists date from approximately 800 CE to 1600 CE, varying regionally. It was composed of a series of urban settlements and satellite villages (suburbs) linked together by a loose trading network, the largest city being Cahokia, believed to be a major religious center. The civilization flourished from the southern shores of the Great Lakes at Western New York and Western Pennsylvania in what is now the Eastern Midwest, extending south-southwest into the lower Mississippi Valley and wrapping easterly around the southern foot of the Appalachians barrier range into what is now the Southeastern United States.\n\nNumerous pre-Columbian societies were sedentary, such as the Pueblo peoples, Mandan, Hidatsa and others, and some established large settlements, even cities, such as Cahokia, in what is now Illinois. The Iroquois League of Nations or \"People of the Long House\" was a politically advanced, democratic society, which is thought by some historians to have influenced the United States Constitution, with the Senate passing a resolution to this effect in 1988. Other historians have contested this interpretation and believe the impact was minimal, or did not exist, pointing to numerous differences between the two systems and the ample precedents for the constitution in European political thought.\n\nAfter 1492, European exploration and colonization of the Americas revolutionized how the Old and New Worlds perceived themselves. Many of the first major contacts were in Florida and the Gulf coast by Spanish explorers.\n\nFrom the 16th through the 19th centuries, the population of Indians sharply declined. Most mainstream scholars believe that, among the various contributing factors, epidemic disease was the overwhelming cause of the population decline of the Native Americans because of their lack of immunity to new diseases brought from Europe. It is difficult to estimate the number of pre-Columbian Native Americans who were living in what is today the United States of America. Estimates range from a low of 2.1 million to a high of 18 million (Dobyns 1983). By 1800, the Native population of the present-day United States had declined to approximately 600,000, and only 250,000 Native Americans remained in the 1890s. Chicken pox and measles, endemic but rarely fatal among Europeans (long after being introduced from Asia), often proved deadly to Native Americans. In the 100 years following the arrival of the Spanish to the Americas, large disease epidemics depopulated large parts of the eastern United States in the 16th century.\n\nThere are a number of documented cases where diseases were deliberately spread among Native Americans as a form of biological warfare. The most well-known example occurred in 1763, when Sir Jeffery Amherst, Commander-in-Chief of the Forces of the British Army, wrote praising the use of smallpox-infected blankets to \"extirpate\" the Indian race. Blankets infected with smallpox were given to Native Americans besieging Fort Pitt. The effectiveness of the attempt is unclear.\nIn 1634, Fr. Andrew White of the Society of Jesus established a mission in what is now the state of Maryland, and the purpose of the mission, stated through an interpreter to the chief of an Indian tribe there, was \"to extend civilization and instruction to his ignorant race, and show them the way to heaven.\" Fr. Andrew's diaries report that by 1640, a community had been founded which they named St. Mary's, and the Indians were sending their children there \"to be educated among the English.\" This included the daughter of the Piscataway Indian chief Tayac, which exemplifies not only a school for Indians, but either a school for girls, or an early co-ed school. The same records report that in 1677, \"a school for humanities was opened by our Society in the centre of [Maryland], directed by two of the Fathers; and the native youth, applying themselves assiduously to study, made good progress. Maryland and the recently established school sent two boys to St. Omer who yielded in abilities to few Europeans, when competing for the honor of being first in their class. So that not gold, nor silver, nor the other products of the earth alone, but men also are gathered from thence to bring those regions, which foreigners have unjustly called ferocious, to a higher state of virtue and cultivation.\"\n\nThrough the mid-17th century the Beaver Wars were fought over the fur trade between the Iroquois and the Hurons, the northern Algonquians, and their French allies. During the war the Iroquois destroyed several large tribal confederacies, including the Huron, Neutral, Erie, Susquehannock, and Shawnee, and became dominant in the region and enlarged their territory.\n\nIn 1727, the Sisters of the Order of Saint Ursula founded Ursuline Academy in New Orleans, which is currently the oldest continuously operating school for girls and the oldest Catholic school in the United States. From the time of its foundation, it offered the first classes for Native American girls, and would later offer classes for female African-American slaves and free women of color.\nBetween 1754 and 1763, many Native American tribes were involved in the French and Indian War/Seven Years' War. Those involved in the fur trade tended to ally with French forces against British colonial militias. The British had made fewer allies, but it was joined by some tribes that wanted to prove assimilation and loyalty in support of treaties to preserve their territories. They were often disappointed when such treaties were later overturned. The tribes had their own purposes, using their alliances with the European powers to battle traditional Native enemies. Some Iroquois who were loyal to the British, and helped them fight in the American Revolution, fled north into Canada.\n\nAfter European explorers reached the West Coast in the 1770s, smallpox rapidly killed at least 30% of Northwest Coast Native Americans. For the next eighty to one hundred years, smallpox and other diseases devastated native populations in the region. Puget Sound area populations, once estimated as high as 37,000 people, were reduced to only 9,000 survivors by the time settlers arrived en masse in the mid-19th century.\n\nSmallpox epidemics in 1780–82 and 1837–38 brought devastation and drastic depopulation among the Plains Indians. By 1832, the federal government established a smallpox vaccination program for Native Americans (\"The Indian Vaccination Act of 1832\"). It was the first federal program created to address a health problem of Native Americans.\n\nWith the meeting of two worlds, animals, insects, and plants were carried from one to the other, both deliberately and by chance, in what is called the Columbian Exchange. In the 16th century, Spaniards and other Europeans brought horses to Mexico. Some of the horses escaped and began to breed and increase their numbers in the wild. As Native Americans adopted use of the animals, they began to change their cultures in substantial ways, especially by extending their nomadic ranges for hunting. The reintroduction of the horse to North America had a profound impact on Native American culture of the Great Plains.\n\nKing Philip's War, also called Metacom's War or Metacom's Rebellion, was the last major armed conflict between Native American inhabitants of present-day southern New England and English colonists and their Native American allies from 1675 to 1676. It continued in northern New England (primarily on the Maine frontier) even after King Philip was killed, until a treaty was signed at Casco Bay in April 1678.\n\nSome European philosophers considered Native American societies to be truly \"natural\" and representative of a golden age known to them only in folk history.\n\nDuring the American Revolution, the newly proclaimed United States competed with the British for the allegiance of Native American nations east of the Mississippi River. Most Native Americans who joined the struggle sided with the British, based both on their trading relationships and hopes that colonial defeat would result in a halt to further colonial expansion onto Native American land. The first native community to sign a treaty with the new United States Government was the Lenape.\n\nIn 1779 the Sullivan Expedition was carried out during the American Revolutionary War against the British and the four allied nations of the Iroquois. George Washington gave orders that made it clear he wanted the Iroquois threat completely eliminated:\n\nThe British made peace with the Americans in the Treaty of Paris (1783), through which they ceded vast Native American territories to the United States without informing or consulting with the Native Americans.\n\nThe United States was eager to expand, develop farming and settlements in new areas, and satisfy land hunger of settlers from New England and new immigrants. The national government initially sought to purchase Native American land by treaties. The states and settlers were frequently at odds with this policy.\n\nUnited States policy toward Native Americans continued to evolve after the American Revolution. George Washington and Henry Knox believed that Native Americans were equals but that their society was inferior. Washington formulated a policy to encourage the \"civilizing\" process. Washington had a six-point plan for civilization which included:\n\nIn the late 18th century, reformers starting with Washington and Knox, supported educating native children and adults, in efforts to \"civilize\" or otherwise assimilate Native Americans to the larger society (as opposed to relegating them to reservations). The Civilization Fund Act of 1819 promoted this civilization policy by providing funding to societies (mostly religious) who worked on Native American improvement.\n\nThe population was reduced by 90% during the 19th century—from more than 200,000 in the early 19th century to approximately 15,000 at the end of the century, mostly due to disease. Epidemics swept through California Indian Country, such as the 1833 malaria epidemic. The population went into decline as a result of the Spanish authorities forcing Native Californians to live in the missions where they contracted diseases from which they had little immunity. Dr. Cook estimates that 15,250 or 45% of the population decrease in the Missions was caused by disease. Two epidemics of measles, one in 1806 and the other in 1828, caused many deaths. The mortality rates were so high that the missions were constantly dependent upon new conversions.[21] During the California Gold Rush, many natives were killed by incoming settlers as well as by militia units financed and organized by the California government. Some scholars contend that the state financing of these militias, as well as the US government's role in other massacres in California, such as the Bloody Island and Yontoket Massacres, in which up to 400 or more natives were killed in each massacre, constitutes a campaign of genocide against the native people of California.\n\nAs American expansion continued, Native Americans resisted settlers' encroachment in several regions of the new nation (and in unorganized territories), from the Northwest to the Southeast, and then in the West, as settlers encountered the Native American tribes of the Great Plains. East of the Mississippi River, an intertribal army led by Tecumseh, a Shawnee chief, fought a number of engagements in the Northwest during the period 1811–12, known as Tecumseh's War. During the War of 1812, Tecumseh's forces allied themselves with the British. After Tecumseh's death, the British ceased to aid the Native Americans south and west of Upper Canada and American expansion proceeded with little resistance. Conflicts in the Southeast include the Creek War and Seminole Wars, both before and after the Indian Removals of most members of the Five Civilized Tribes.\n\nIn the 1830s, President Andrew Jackson signed the Indian Removal Act of 1830, a policy of relocating Indians from their homelands to Indian Territory and reservations in surrounding areas to open their lands for non-native settlements. \n\nThis resulted in the Trail of Tears.\nIn July 1845, the New York newspaper editor John L. O'Sullivan coined the phrase, \"Manifest Destiny\", as the \"design of Providence\" supporting the territorial expansion of the United States. Manifest Destiny had serious consequences for Native Americans, since continental expansion for the United States took place at the cost of their occupied land. A justification for the policy of conquest and subjugation of the indigenous people emanated from the stereotyped perceptions of all Native Americans as \"merciless Indian savages\" (as described in the United States Declaration of Independence). The Indian Appropriations Act of 1851 set the precedent for modern-day Native American reservations through allocating funds to move western tribes onto reservations since there were no more lands available for relocation.\n\nNative American nations on the plains in the west continued armed conflicts with the U.S. throughout the 19th century, through what were called generally Indian Wars. Notable conflicts in this period include the Dakota War, Great Sioux War, Snake War and Colorado War. Expressing the frontier anti-Indian sentiment, Theodore Roosevelt believed the Indians were destined to vanish under the pressure of white civilization, stating in an 1886 lecture:\n\nAmong the most notable events during the wars was the Wounded Knee Massacre in 1890. In the years leading up to it the U.S. government had continued to seize Lakota lands. A Ghost Dance ritual on the Northern Lakota reservation at Wounded Knee, South Dakota, led to the U.S. Army's attempt to subdue the Lakota. The dance was part of a religious movement founded by the Northern Paiute spiritual leader Wovoka that told of the return of the Messiah to relieve the suffering of Native Americans and promised that if they would live righteous lives and perform the Ghost Dance properly, the European American colonists would vanish, the bison would return, and the living and the dead would be reunited in an Edenic world. On December 29 at Wounded Knee, gunfire erupted, and U.S. soldiers killed up to 300 Indians, mostly old men, women, and children.\n\nNative Americans served in both the Union and Confederate military during the American Civil War. At the outbreak of the war, for example, the minority party of the Cherokees gave its allegiance to the Confederacy, while originally the majority party went for the North. Native Americans fought knowing they might jeopardize their independence, unique cultures, and ancestral lands if they ended up on the losing side of the Civil War. 28,693 Native Americans served in the Union and Confederate armies during the Civil War, participating in battles such as Pea Ridge, Second Manassas, Antietam, Spotsylvania, Cold Harbor, and in Federal assaults on Petersburg. A few Native American tribes, such as the Creek and the Choctaw, were slaveholders and found a political and economic commonality with the Confederacy. The Choctaw owned over 2,000 slaves.\n\nIn the 19th century, the incessant westward expansion of the United States incrementally compelled large numbers of Native Americans to resettle further west, often by force, almost always reluctantly. Native Americans believed this forced relocation illegal, given the Treaty of Hopewell of 1785. Under President Andrew Jackson, United States Congress passed the Indian Removal Act of 1830, which authorized the President to conduct treaties to exchange Native American land east of the Mississippi River for lands west of the river.\n\nAs many as 100,000 Native Americans relocated to the West as a result of this Indian removal policy. In theory, relocation was supposed to be voluntary and many Native Americans did remain in the East. In practice, great pressure was put on Native American leaders to sign removal treaties. The most egregious violation, the Trail of Tears, was the removal of the Cherokee by President Jackson to Indian Territory. The 1864 deportation of the Navajos by the U.S. government occurred when 8,000 Navajos were forced to an internment camp in Bosque Redondo, where, under armed guards, more than 3,500 Navajo and Mescalero Apache men, women, and children died from starvation and disease.\n\nIn 1817, the Cherokee became the first Native Americans recognized as U.S. citizens. Under Article 8 of the 1817 Cherokee treaty, \"Upwards of 300 Cherokees (Heads of Families) in the honest simplicity of their souls, made an election to become American citizens\".\n\nFactors establishing citizenship included:\n\nAfter the American Civil War, the Civil Rights Act of 1866 states, \"that all persons born in the United States, and not subject to any foreign power, excluding Indians not taxed, are hereby declared to be citizens of the United States\".\n\nIn 1871, Congress added a rider to the Indian Appropriations Act, signed into law by President Ulysses S. Grant, ending United States recognition of additional Native American tribes or independent nations, and prohibiting additional treaties.\n\nAfter the Indian wars in the late 19th century, the government established Native American boarding schools, initially run primarily by or affiliated with Christian missionaries. At this time, American society thought that Native American children needed to be acculturated to the general society. The boarding school experience was a total immersion in modern American society, but it could prove traumatic to children, who were forbidden to speak their native languages. They were taught Christianity and not allowed to practice their native religions, and in numerous other ways forced to abandon their Native American identities.\n\nBefore the 1930s, schools on the reservations provided no schooling beyond the sixth grade. To obtain more, boarding school was usually necessary. Small reservations with a few hundred people usually sent their children to nearby public schools. The \"Indian New Deal\" of the 1930s closed many of the boarding schools, and downplayed the assimilationist goals. The Indian Division of the Civilian Conservation Corps operated large-scale construction projects on the reservations, building thousands of new schools and community buildings. Under the leadership of John Collier the BIA brought in progressive educators to reshape Indian education. The Bureau of Indian Affairs (BIA) by 1938 taught 30,000 students in 377 boarding and day schools, or 40% of all Indian children in school. The Navajo largely opposed schooling of any sort, but the other tribes accepted the system. There were now high schools on larger reservations, educating not only teenagers but also an adult audience. There were no Indian facilities for higher education. They deemphasized textbooks, emphasized self-esteem, and started teaching Indian history. They promoted traditional arts and crafts of the sort that could be conducted on the reservations, such as making jewelry. The New Deal reformers met significant resistance from parents and teachers, and had mixed results. World War II brought younger Indians in contact with the broader society through military service and work in the munitions industries. The role of schooling was changed to focus on vocational education for jobs in urban America.\n\nSince the rise of self-determination for Native Americans, they have generally emphasized education of their children at schools near where they live. In addition, many federally recognized tribes have taken over operations of such schools and added programs of language retention and revival to strengthen their cultures. Beginning in the 1970s, tribes have also founded colleges at their reservations, controlled, and operated by Native Americans, to educate their young for jobs as well as to pass on their cultures.\n\nOn August 29, 1911, Ishi, generally considered to have been the last Native American to live most of his life without contact with European-American culture, was discovered near Oroville, California.\n\nIn 1919, the United States under President Woodrow Wilson granted citizenship to all Native Americans who had served in World War I. Nearly 10,000 men had enlisted and served, a high number in relation to their population. Despite this, in many areas Native Americans faced local resistance when they tried to vote and were discriminated against with barriers to voter registration.\n\nOn June 2, 1924, U.S. President Calvin Coolidge signed the Indian Citizenship Act, which made all Native Americans born in the United States and its territories American citizens. Prior to passage of the act, nearly two-thirds of Native Americans were already U.S. citizens, through marriage, military service or accepting land allotments. The Act extended citizenship to \"all non-citizen Indians born within the territorial limits of the United States.\"\n\nCharles Curtis, a Congressman and longtime US Senator from Kansas, was of Kaw, Osage, Potawatomi, and European ancestry. After serving as a United States Representative and being repeatedly re-elected as United States Senator from Kansas, Curtis served as Senate Minority Whip for 10 years and as Senate Majority Leader for five years. He was very influential in the Senate. In 1928 he ran as the vice-presidential candidate with Herbert Hoover for president, and served from 1929 to 1933. He was the first person with significant Native American ancestry and the first person with acknowledged non-European ancestry to be elected to either of the highest offices in the land.\n\nAmerican Indians today in the United States have all the rights guaranteed in the U.S. Constitution, can vote in elections, and run for political office. Controversies remain over how much the federal government has jurisdiction over tribal affairs, sovereignty, and cultural practices.\n\nMid-century, the Indian termination policy and the Indian Relocation Act of 1956 marked a new direction for assimilating Native Americans into urban life.\n\nThe census counted 332,000 Indians in 1930 and 334,000 in 1940, including those on and off reservations in the 48 states. Total spending on Indians averaged $38 million a year in the late 1920s, dropping to a low of $23 million in 1933, and returning to $38 million in 1940.\n\nSome 44,000 Native Americans served in the United States military during World War II: at the time, one-third of all able-bodied Indian men from eighteen to fifty years of age. Described as the first large-scale exodus of indigenous peoples from the reservations since the removals of the 19th century, the men's service with the U.S. military in the international conflict was a turning point in Native American history. The overwhelming majority of Native Americans welcomed the opportunity to serve; they had a voluntary enlistment rate that was 40% higher than those drafted.\n\nTheir fellow soldiers often held them in high esteem, in part since the legend of the tough Native American warrior had become a part of the fabric of American historical legend. White servicemen sometimes showed a lighthearted respect toward Native American comrades by calling them \"chief\". The resulting increase in contact with the world outside of the reservation system brought profound changes to Native American culture. \"The war\", said the U.S. Indian Commissioner in 1945, \"caused the greatest disruption of Native life since the beginning of the reservation era\", affecting the habits, views, and economic well-being of tribal members. The most significant of these changes was the opportunity—as a result of wartime labor shortages—to find well-paying work in cities, and many people relocated to urban areas, particularly on the West Coast with the buildup of the defense industry.\n\nThere were also losses as a result of the war. For instance, a total of 1,200 Pueblo men served in World War II; only about half came home alive. In addition, many more Navajo served as code talkers for the military in the Pacific. The code they made, although cryptologically very simple, was never cracked by the Japanese.\n\nMilitary service and urban residency contributed to the rise of American Indian activism, particularly after the 1960s and the occupation of Alcatraz Island (1969–1971) by a student Indian group from San Francisco. In the same period, the American Indian Movement (AIM) was founded in Minneapolis, and chapters were established throughout the country, where American Indians combined spiritual and political activism. Political protests gained national media attention and the sympathy of the American public.\n\nThrough the mid-1970s, conflicts between governments and Native Americans occasionally erupted into violence. A notable late 20th-century event was the Wounded Knee incident on the Pine Ridge Indian Reservation. Upset with tribal government and the failures of the federal government to enforce treaty rights, about 300 Oglala Lakota and AIM activists took control of Wounded Knee on February 27, 1973.\n\nIndian activists from around the country joined them at Pine Ridge, and the occupation became a symbol of rising American Indian identity and power. Federal law enforcement officials and the national guard cordoned off the town, and the two sides had a standoff for 71 days. During much gunfire, one United States Marshal was wounded and paralyzed. In late April, a Cherokee and local Lakota man were killed by gunfire; the Lakota elders ended the occupation to ensure no more lives were lost.\n\nIn June 1975, two FBI agents seeking to make an armed robbery arrest at Pine Ridge Reservation were wounded in a firefight, and killed at close range. The AIM activist Leonard Peltier was sentenced in 1976 to two consecutive terms of life in prison in the FBI deaths.\n\nIn 1968, the government enacted the Indian Civil Rights Act. This gave tribal members most of the protections against abuses by tribal governments that the Bill of Rights accords to all U.S. citizens with respect to the federal government. In 1975, the U.S. government passed the Indian Self-Determination and Education Assistance Act, marking the culmination of fifteen years of policy changes. It resulted from American Indian activism, the Civil Rights Movement, and community development aspects of President Lyndon Johnson's social programs of the 1960s. The Act recognized the right and need of Native Americans for self-determination. It marked the U.S. government's turn away from the 1950s policy of termination of the relationship between tribes and the government. The U.S. government encouraged Native Americans' efforts at self-government and determining their futures. Tribes have developed organizations to administer their own social, welfare and housing programs, for instance. Tribal self-determination has created tension with respect to the federal government's historic trust obligation to care for Indians; however, the Bureau of Indian Affairs has never lived up to that responsibility.\n\nNavajo Community College, now called Diné College, the first tribal college, was founded in Tsaile, Arizona, in 1968 and accredited in 1979. Tensions immediately arose between two philosophies: one that the tribal colleges should have the same criteria, curriculum and procedures for educational quality as mainstream colleges, the other that the faculty and curriculum should be closely adapted to the particular historical culture of the tribe. There was a great deal of turnover, exacerbated by very tight budgets. In 1994, the U.S. Congress passed legislation recognizing the tribal colleges as land-grant colleges, which provided opportunities for large-scale funding. Thirty-two tribal colleges in the United States belong to the American Indian Higher Education Consortium. By the early 21st century, tribal nations had also established numerous language revival programs in their schools.\n\nIn addition, Native American activism has led major universities across the country to establish Native American studies programs and departments, increasing awareness of the strengths of Indian cultures, providing opportunities for academics, and deepening research on history and cultures in the United States. Native Americans have entered academia; journalism and media; politics at local, state and federal levels; and public service, for instance, influencing medical research and policy to identify issues related to American Indians.\n\nIn 2009, an \"apology to Native Peoples of the United States\" was included in the defense appropriations act. It states that the U.S. \"apologizes on behalf of the people of the United States to all Native Peoples for the many instances of violence, maltreatment, and neglect inflicted on Native Peoples by citizens of the United States.\"\n\nIn 2013, jurisdiction over persons who were not tribal members under the Violence Against Women Act was extended to Indian Country. This closed a gap which prevented arrest or prosecution by tribal police or courts of abusive partners of tribal members who were not native or from another tribe.\n\nMigration to urban areas continued to grow with 70% of Native Americans living in urban areas in 2012, up from 45% in 1970 and 8% in 1940. Urban areas with significant Native American populations include Minneapolis, Denver, Albuquerque, Phoenix, Tucson, Chicago, Oklahoma City, Houston, New York City, Los Angeles, and Rapid City. Many lived in poverty. Racism, unemployment, drugs and gangs were common problems which Indian social service organizations such as the Little Earth housing complex in Minneapolis attempted to address. Grassroots efforts to support urban Indigenous populations have also taken place, as in the case of Bringing the Circle Together in Los Angeles.\n\nThe 2010 Census showed that the U.S. population on April 1, 2010, was 308.7 million. Out of the total U.S. population, 2.9 million people, or 0.9 percent, reported American Indian or Alaska Native alone. In addition, 2.3 million people, or another 0.7 percent, reported American Indian or Alaska Native in combination with one or more other races. Together, these two groups totaled 5.2 million people. Thus, 1.7 percent of all people in the United States identified as American Indian or Alaska Native, either alone or in combination with one or more other races.\n\nThe definition of American Indian or Alaska Native used in the 2010 census:\n\nAccording to Office of Management and Budget, \"American Indian or Alaska Native\" refers to a person having origins in any of the original peoples of North and South America (including Central America) and who maintains tribal affiliation or community attachment.\n\nThe 2010 census permitted respondents to self-identify as being of one or more races. Self-identification dates from the census of 1960; prior to that the race of the respondent was determined by opinion of the census taker. The option to select more than one race was introduced in 2000. If American Indian or Alaska Native was selected, the form requested the individual provide the name of the \"enrolled or principal tribe\". \n\nThe census counted 248,000 Indians in 1890, 332,000 in 1930 and 334,000 in 1940, including those on and off reservations in the 48 states. Total spending on Indians averaged $38 million a year in the late 1920s, dropping to a low of $23 million in 1933, and returning to $38 million in 1940.\n78% of Native Americans live outside a reservation. Full-blood individuals are more likely to live on a reservation than mixed-blood individuals. The Navajo, with 286,000 full-blood individuals, is the largest tribe if only full-blood individuals are counted; the Navajo are the tribe with the highest proportion of full-blood individuals, 86.3%. The Cherokee have a different history; it is the largest tribe with 819,000 individuals, and it has 284,000 full-blood individuals.\n\nAs of 2012, 70% of American Indians live in urban areas, up from 45% in 1970 and 8% in 1940. Urban areas with significant Native American populations include Minneapolis, Denver, Phoenix, Tucson, Chicago, Oklahoma City, Houston, New York City, and Los Angeles. Many live in poverty. Racism, unemployment, drugs and gangs are common problems which Indian social service organizations such as the Little Earth housing complex in Minneapolis attempt to address.\n\nAccording to 2003 United States Census Bureau estimates, a little over one third of the 2,786,652 Native Americans in the United States live in three states: California at 413,382, Arizona at 294,137 and Oklahoma at 279,559.\n\nIn 2010, the U.S. Census Bureau estimated that about 0.8% of the U.S. population was of American Indian or Alaska Native descent. This population is unevenly distributed across the country. Below, all fifty states, as well as the District of Columbia and Puerto Rico, are listed by the proportion of residents citing American Indian or Alaska Native ancestry, based on the 2010 U.S. Census.\nIn 2006, the U.S. Census Bureau estimated that about less than 1.0% of the U.S. population was of Native Hawaiian or Pacific Islander descent. This population is unevenly distributed across twenty-six states. Below, are the twenty-six states that had at least 0.1%. They are listed by the proportion of residents citing Native Hawaiian or Pacific Islander ancestry, based on 2006 estimates:\n\nBelow are numbers for U.S. citizens self-identifying to selected tribal grouping, according to the 2000 U.S. census.\n\nThere are 573 federally recognized tribal governments in the United States. These tribes possess the right to form their own governments, to enforce laws (both civil and criminal) within their lands, to tax, to establish requirements for membership, to license and regulate activities, to zone, and to exclude persons from tribal territories. Limitations on tribal powers of self-government include the same limitations applicable to states; for example, neither tribes nor states have the power to make war, engage in foreign relations, or coin money (this includes paper currency).\n\nMany Native Americans and advocates of Native American rights point out that the U.S. federal government's claim to recognize the \"sovereignty\" of Native American peoples falls short, given that the United States wishes to govern Native American peoples and treat them as subject to U.S. law. Such advocates contend that full respect for Native American sovereignty would require the U.S. government to deal with Native American peoples in the same manner as any other sovereign nation, handling matters related to relations with Native Americans through the Secretary of State, rather than the Bureau of Indian Affairs. The Bureau of Indian Affairs reports on its website that its \"responsibility is the administration and management of of land held in trust by the United States for American Indians, Indian tribes, and Alaska Natives\". Many Native Americans and advocates of Native American rights believe that it is condescending for such lands to be considered \"held in trust\" and regulated in any fashion by other than their own tribes, whether the U.S. or Canadian governments, or any other non-Native American authority.\n\nAs of 2000, the largest groups in the United States by population were Navajo, Cherokee, Choctaw, Sioux, Chippewa, Apache, Blackfeet, Iroquois, and Pueblo. In 2000, eight of ten Americans with Native American ancestry were of mixed ancestry. It is estimated that by 2100 that figure will rise to nine out of ten.\n\nIn addition, there are a number of tribes that are recognized by individual states, but not by the federal government. The rights and benefits associated with state recognition vary from state to state.\n\nSome tribal groups have been unable to document the cultural continuity required for federal recognition. The Muwekma Ohlone of the San Francisco bay area are pursuing litigation in the federal court system to establish recognition. Many of the smaller eastern tribes, long considered remnants of extinct peoples, have been trying to gain official recognition of their tribal status. Several tribes in Virginia and North Carolina have gained state recognition. Federal recognition confers some benefits, including the right to label arts and crafts as Native American and permission to apply for grants that are specifically reserved for Native Americans. But gaining federal recognition as a tribe is extremely difficult; to be established as a tribal group, members have to submit extensive genealogical proof of tribal descent and continuity of the tribe as a culture.\nIn July 2000, the Washington State Republican Party adopted a resolution recommending that the federal and legislative branches of the U.S. government terminate tribal governments. In 2007, a group of Democratic Party congressmen and congresswomen introduced a bill in the U.S. House of Representatives to \"terminate\" the Cherokee Nation. This was related to their voting to exclude Cherokee Freedmen as members of the tribe unless they had a Cherokee ancestor on the Dawes Rolls, although all Cherokee Freedmen and their descendants had been members since 1866.\n\nAs of 2004, various Native Americans are wary of attempts by others to gain control of their reservation lands for natural resources, such as coal and uranium in the West.\n\nIn the state of Virginia, Native Americans face a unique problem. Until 2017 Virginia previously had no federally recognized tribes but the state had recognized eight. This is related historically to the greater impact of disease and warfare on the Virginia Indian populations, as well as their intermarriage with Europeans and Africans. Some people confused the ancestry with culture, but groups of Virginia Indians maintained their cultural continuity. Most of their early reservations were ended under the pressure of early European settlement.\n\nSome historians also note the problems of Virginia Indians in establishing documented continuity of identity, due to the work of Walter Ashby Plecker (1912–1946). As registrar of the state's Bureau of Vital Statistics, he applied his own interpretation of the one-drop rule, enacted in law in 1924 as the state's Racial Integrity Act. It recognized only two races: \"white\" and \"colored\".\n\nPlecker, a segregationist, believed that the state's Native Americans had been \"mongrelized\" by intermarriage with African Americans; to him, ancestry determined identity, rather than culture. He thought that some people of partial black ancestry were trying to \"pass\" as Native Americans. Plecker thought that anyone with any African heritage had to be classified as colored, regardless of appearance, amount of European or Native American ancestry, and cultural/community identification. Plecker pressured local governments into reclassifying all Native Americans in the state as \"colored\", and gave them lists of family surnames to examine for reclassification based on his interpretation of data and the law. This led to the state's destruction of accurate records related to families and communities who identified as Native American (as in church records and daily life). By his actions, sometimes different members of the same family were split by being classified as \"white\" or \"colored\". He did not allow people to enter their primary identification as Native American in state records. In 2009, the Senate Indian Affairs Committee endorsed a bill that would grant federal recognition to tribes in Virginia.\n\nTo achieve federal recognition and its benefits, tribes must prove continuous existence since 1900. The federal government has maintained this requirement, in part because through participation on councils and committees, federally recognized tribes have been adamant about groups' satisfying the same requirements as they did.\n\nNative American struggles amid poverty to maintain life on the reservation or in larger society have resulted in a variety of health issues, some related to nutrition and health practices. The community suffers a vulnerability to and disproportionately high rate of alcoholism.\n\nIn a study conducted in 2006–2007, non-Native Americans admitted they rarely encountered Native Americans in their daily lives. While sympathetic toward Native Americans and expressing regret over the past, most people had only a vague understanding of the problems facing Native Americans today. For their part, Native Americans told researchers that they believed they continued to face prejudice, mistreatment, and inequality in the broader society.\n\nFederal contractors and subcontractors, such as businesses and educational institutions, are legally required to adopt equal opportunity employment and affirmative action measures intended to prevent discrimination against employees or applicants for employment on the basis of \"color, religion, sex, or national origin\". For this purpose, a Native American is defined as \"A person having origins in any of the original peoples of North and South America (including Central America), and who maintains a tribal affiliation or community attachment\". However, self-reporting is permitted: \"Educational institutions and other recipients should allow students and staff to self-identify their race and ethnicity unless self-identification is not practicable or feasible.\"\n\nSelf-reporting opens the door to \"box checking\" by people who, despite not having a substantial relationship to Native American culture, innocently or fraudulently check the box for Native American.\n\nAmerican Indian activists in the United States and Canada have criticized the use of Native American mascots in sports, as perpetuating stereotypes.\n\nThere has been a steady decline in the number of secondary school and college teams using such names, images, and mascots. Some tribal team names have been approved by the tribe in question, such as the Seminole Tribe of Florida's approving use of their name for the teams of Florida State University.\n\nAmong professional teams, only the NBA's Golden State Warriors discontinued use of Native American-themed logos in 1971. Controversy has remained regarding teams such as the NFL's Washington Redskins, whose name is considered to be a racial slur, and MLB's Cleveland Indians, whose usage of a caricature called Chief Wahoo has also faced protest.\n\nNative Americans have been depicted by American artists in various ways at different periods. A number of 19th- and 20th-century United States and Canadian painters, often motivated by a desire to document and preserve Native culture, specialized in Native American subjects. Among the most prominent of these were Elbridge Ayer Burbank, George Catlin, Seth Eastman, Paul Kane, W. Langdon Kihn, Charles Bird King, Joseph Henry Sharp, and John Mix Stanley.\n\nIn the 20th century, early portrayals of Native Americans in movies and television roles were first performed by European Americans dressed in mock traditional attire. Examples included \"The Last of the Mohicans\" (1920), \"Hawkeye and the Last of the Mohicans\" (1957), and \"F Troop\" (1965–67). In later decades, Native American actors such as Jay Silverheels in \"The Lone Ranger\" television series (1949–57) came to prominence. Roles of Native Americans were limited and not reflective of Native American culture. By the 1970s some Native American film roles began to show more complexity, such as those in \"Little Big Man\" (1970), \"Billy Jack\" (1971), and \"The Outlaw Josey Wales\" (1976), which depicted Native Americans in minor supporting roles.\n\nFor years, Native people on U.S. television were relegated to secondary, subordinate roles. During the years of the series \"Bonanza\" (1959–1973), no major or secondary Native characters appeared on a consistent basis. The series \"The Lone Ranger\" (1949–1957), \"Cheyenne\" (1955–1963), and \"Law of the Plainsman\" (1959–1963) had Native characters who were essentially aides to the central white characters. This continued in such series as \"How the West Was Won\". These programs resembled the \"sympathetic\" yet contradictory film \"Dances With Wolves\" of 1990, in which, according to Ella Shohat and Robert Stam, the narrative choice was to relate the Lakota story as told through a Euro-American voice, for wider impact among a general audience.\nLike the 1992 remake of \"The Last of the Mohicans\" and \"\" (1993), \"Dances with Wolves\" employed a number of Native American actors, and made an effort to portray Indigenous languages.\n\nIn 2009 \"We Shall Remain\" (2009), a television documentary by Ric Burns and part of the \"American Experience\" series, presented a five-episode series \"from a Native American perspective\". It represented \"an unprecedented collaboration between Native and non-Native filmmakers and involves Native advisors and scholars at all levels of the project\". The five episodes explore the impact of King Philip's War on the northeastern tribes, the \"Native American confederacy\" of Tecumseh's War, the U.S.-forced relocation of Southeastern tribes known as the Trail of Tears, the pursuit and capture of Geronimo and the Apache Wars, and concludes with the Wounded Knee incident, participation by the American Indian Movement, and the increasing resurgence of modern Native cultures since.\n\nNative Americans are often known as Indians or American Indians. The term \"Native American\" was introduced in the United States in preference to the older term \"Indian\" to distinguish the indigenous peoples of the Americas from the people of India, and to avoid negative stereotypes associated with the term \"Indian\". Many indigenous Americans, however, prefer the term \"American Indian\" and many tribes include the word Indian in their formal title.\n\nCriticism of the neologism \"Native American\" comes from diverse sources. Russell Means, an American Indian activist, opposed the term \"Native American\" because he believed it was imposed by the government without the consent of American Indians. He has also argued that the use of the word \"Indian\" derives not from a confusion with India but from a Spanish expression \"en Dios\" meaning \"in God\" (and a near-homophone of the Spanish word for \"Indians\", \"indios\").\n\nA 1995 U.S. Census Bureau survey found that more Native Americans in the United States preferred \"American Indian\" to \"Native American\". Most American Indians are comfortable with \"Indian\", \"American Indian\", and \"Native American\", and the terms are often used interchangeably. The traditional term is reflected in the name chosen for the National Museum of the American Indian, which opened in 2004 on the Mall in Washington, D.C.\n\nGambling has become a leading industry. Casinos operated by many Native American governments in the United States are creating a stream of gambling revenue that some communities are beginning to leverage to build diversified economies. Although many Native American tribes have casinos, the impact of Native American gaming is widely debated. Some tribes, such as the Winnemem Wintu of Redding, California, feel that casinos and their proceeds destroy culture from the inside out. These tribes refuse to participate in the gambling industry.\n\nNumerous tribes around the country have entered the financial services market including the Otoe-Missouria, Tunica-Biloxi, and the Rosebud Sioux. Because of the challenges involved in starting a financial services business from scratch, many tribes hire outside consultants and vendors to help them launch these businesses and manage the regulatory issues involved.\nSimilar to the tribal sovereignty debates that occurred when tribes first entered the gaming industry, the tribes, states, and federal government are currently in disagreement regarding who possesses the authority to regulate these e-commerce business entities.\n\nProsecution of serious crime, historically endemic on reservations, was required by the 1885 Major Crimes Act, 18 U.S.C. §§1153, 3242, and court decisions to be investigated by the federal government, usually the Federal Bureau of Investigation, and prosecuted by United States Attorneys of the United States federal judicial district in which the reservation lies.\n\nA December 13, 2009 \"New York Times\" article about growing gang violence on the Pine Ridge Indian Reservation estimated that there were 39 gangs with 5,000 members on that reservation alone. Navajo country recently reported 225 gangs in its territory.\n\nAs of 2012, a high incidence of rape continued to impact Native American women and Alaskan native women. According to the Department of Justice, 1 in 3 Native women have suffered rape or attempted rape, more than twice the national rate. About 46 percent of Native American women have been raped, beaten, or stalked by an intimate partner, according to a 2010 study by the Centers for Disease Control. According to Professor N. Bruce Duthu, \"More than 80 percent of Indian victims identify their attacker as non-Indian\".\n\nToday, other than tribes successfully running casinos, many tribes struggle, as they are often located on reservations isolated from the main economic centers of the country. The estimated 2.1 million Native Americans are the most impoverished of all ethnic groups. According to the 2000 Census, an estimated 400,000 Native Americans reside on reservation land. While some tribes have had success with gaming, only 40% of the 562 federally recognized tribes operate casinos. According to a 2007 survey by the U.S. Small Business Administration, only 1% of Native Americans own and operate a business.\n\nSocial statistics highlight the challenges faced by Native American communities: highest teen suicide rate of all minorities at 18.5 per 100,000, highest rate of teen pregnancy, highest high school drop-out rate at 54%, lowest per capita income, and unemployment rates between 50% and 90%.\n\nThe barriers to economic development on Native American reservations have been identified by Joseph Kalt and Stephen Cornell of the Harvard Project on American Indian Economic Development at Harvard University, in their report: \"What Can Tribes Do? Strategies and Institutions in American Indian Economic Development\" (2008), are summarized as follows:\n\nA major barrier to development is the lack of entrepreneurial knowledge and experience within Indian reservations. \"A general lack of education and experience about business is a significant challenge to prospective entrepreneurs\", was the report on Native American entrepreneurship by the Northwest Area Foundation in 2004. \"Native American communities that lack entrepreneurial traditions and recent experiences typically do not provide the support that entrepreneurs need to thrive. Consequently, experiential entrepreneurship education needs to be embedded into school curricula and after-school and other community activities. This would allow students to learn the essential elements of entrepreneurship from a young age and encourage them to apply these elements throughout life\". \"Rez Biz\" magazine addresses these issues.\n\nHistorical trauma is described as collective emotional and psychological damage throughout a person's lifetime and across multiple generations. Examples of historical trauma can be seen through the Wounded Knee Massacre of 1890, where over 200 unarmed Lakota were killed, and the Dawes Allotment Act of 1887, when American Indians lost four-fifths of their land.\n\nAmerican Indian youth have higher rates of substance and alcohol abuse deaths than the general population. Many American Indians can trace the beginning of their substance and alcohol abuse to a traumatic event related to their offender's own substance abuse. A person's substance abuse can be described as a defense mechanism against the user's emotions and trauma. For American Indians alcoholism is a symptom of trauma passed from generation to generation and influenced by oppressive behaviors and policies by the dominant Euro-American society. Boarding schools were made to \"Kill the Indian, Save the man\". Shame among American Indians can be attributed to the hundreds of years of discrimination.\n\nAmerican Indians do not view mind, body, and soul as separate from each other or themselves as the Western worldview does. American Indians believe all is connected and related to each other. American Indian psychologists have been asked to use mental health practices that cultivate American Indian values rather than using conventional ways of counseling. The Wellbriety Movement creates a space for American Indians to learn how to reconnect with their culture by using culturally specific principles to become and remain sober. Some examples are burning sage, cedar, and sweetgrass as a means to cleanse physical and spiritual spaces, verbally saying prayers and singing in one's own tribal language, and participating in tribal drum groups and ceremonies as part of meetings and gatherings.\n\nThe culture of Pre-Columbian North America is usually defined by the concept of the culture area, namely a geographical region where shared cultural traits occur. The northwest culture area, for example shared common traits such as salmon fishing, woodworking, large villages or towns and a hierarchical social structure. \n\nThough cultural features, language, clothing, and customs vary enormously from one tribe to another, there are certain elements which are encountered frequently and shared by many tribes. Early European American scholars described the Native Americans as having a society dominated by clans.\n\nEuropean colonization of the Americas had a major impact on Native American culture through what is known as the Columbian exchange. The Columbian exchange, also known as the Columbian interchange, was the widespread transfer of plants, animals, culture, human populations, technology, and ideas between the Americas and the Old World in the 15th and 16th centuries, following Christopher Columbus's 1492 voyage. The Columbian exchange generally had a destructive impact on Native American culture through disease, and a 'clash of cultures', whereby European values of private property, the family, and labor, led to conflict, appropriation of traditional communal lands and slavery. \n\nThe impact of the Columbian exchange was not entirely negative however. For example, the re-introduction of the horse to North America allowed the Plains Indian to revolutionize their way of life by making hunting, trading, and warfare far more effective, and to greatly improve their ability to transport possessions and move their settlements. \n\nThe Great Plains tribes were still hunting the bison when they first encountered the Europeans. The Spanish reintroduction of the horse to North America in the 17th century and Native Americans' learning to use them greatly altered the Native Americans' culture, including changing the way in which they hunted large game. Horses became such a valuable, central element of Native lives that they were counted as a measure of wealth.\n\nThe Na-Dené, Algic, and Uto-Aztecan families are the largest in terms of number of languages. Uto-Aztecan has the most speakers (1.95 million) if the languages in Mexico are considered (mostly due to 1.5 million speakers of Nahuatl); Na-Dené comes in second with approximately 200,000 speakers (nearly 180,000 of these are speakers of Navajo), and Algic in third with about 180,000 speakers (mainly Cree and Ojibwe). Na-Dené and Algic have the widest geographic distributions: Algic currently spans from northeastern Canada across much of the continent down to northeastern Mexico (due to later migrations of the Kickapoo) with two outliers in California (Yurok and Wiyot); Na-Dené spans from Alaska and western Canada through Washington, Oregon, and California to the U.S. Southwest and northern Mexico (with one outlier in the Plains). Several families consist of only 2 or 3 languages. Demonstrating genetic relationships has proved difficult due to the great linguistic diversity present in North America. Two large (super-) family proposals, Penutian and Hokan, look particularly promising. However, even after decades of research, a large number of families remain.\n\nA number of English words have been derived from Native American languages.\n\nTo counteract a shift to English, some Native American tribes have initiated language immersion schools for children, where a native Indian language is the medium of instruction. For example, the Cherokee Nation initiated a 10-year language preservation plan that involved raising new fluent speakers of the Cherokee language from childhood on up through school immersion programs as well as a collaborative community effort to continue to use the language at home. This plan was part of an ambitious goal that, in 50 years, will result in 80% or more of the Cherokee people being fluent in the language. The Cherokee Preservation Foundation has invested $3 million in opening schools, training teachers, and developing curricula for language education, as well as initiating community gatherings where the language can be actively used. Formed in 2006, the Kituwah Preservation & Education Program (KPEP) on the Qualla Boundary focuses on language immersion programs for children from birth to fifth grade, developing cultural resources for the general public and community language programs to foster the Cherokee language among adults.\n\nThere is also a Cherokee language immersion school in Tahlequah, Oklahoma, that educates students from pre-school through eighth grade. Because Oklahoma's official language is English, Cherokee immersion students are hindered when taking state-mandated tests because they have little competence in English. The Department of Education of Oklahoma said that in 2012 state tests: 11% of the school's sixth-graders showed proficiency in math, and 25% showed proficiency in reading; 31% of the seventh-graders showed proficiency in math, and 87% showed proficiency in reading; 50% of the eighth-graders showed proficiency in math, and 78% showed proficiency in reading. The Oklahoma Department of Education listed the charter school as a Targeted Intervention school, meaning the school was identified as a low-performing school but has not so that it was a Priority School. Ultimately, the school made a C, or a 2.33 grade point average on the state's A-F report card system. The report card shows the school getting an F in mathematics achievement and mathematics growth, a C in social studies achievement, a D in reading achievement, and an A in reading growth and student attendance. \"The C we made is tremendous,\" said school principal Holly Davis, \"[t]here is no English instruction in our school's younger grades, and we gave them this test in English.\" She said she had anticipated the low grade because it was the school's first year as a state-funded charter school, and many students had difficulty with English. Eighth graders who graduate from the Tahlequah immersion school are fluent speakers of the language, and they usually go on to attend Sequoyah High School where classes are taught in both English and Cherokee.\n\nAn early crop the Native Americans grew was squash. Other early crops included cotton, sunflower, pumpkins, tobacco, goosefoot, knotgrass, and sump weed.\n\nAgriculture in the southwest started around 4,000 years ago when traders brought cultigens from Mexico. Due to the varying climate, some ingenuity was needed for agriculture to be successful. The climate in the southwest ranged from cool, moist mountains regions, to dry, sandy soil in the desert. Some innovations of the time included irrigation to bring water into the dry regions and the selection of seed based on the traits of the growing plants that bore them.\n\nIn the southwest, they grew beans that were self-supported, much like the way they are grown today. In the east, however, they were planted next to corn in order for the vines to be able to \"climb\" the cornstalks.\n\nThe most important crop the Native Americans raised was maize. It was first started in Mesoamerica and spread north. About 2,000 years ago it reached eastern America. This crop was important to the Native Americans because it was part of their everyday diet; it could be stored in underground pits during the winter, and no part of it was wasted. The husk was made into art crafts, and the cob was used as fuel for fires.\n\nBy 800 CE the Native Americans had established three main crops—beans, squash, and corn—called the three sisters.\n\nThe agriculture gender roles of the Native Americans varied from region to region. In the southwest area, men prepared the soil with hoes. The women were in charge of planting, weeding, and harvesting the crops. In most other regions, the women were in charge of doing everything, including clearing the land. Clearing the land was an immense chore since the Native Americans rotated fields frequently. There is a tradition that Squanto showed the Pilgrims in New England how to put fish in fields to act like a fertilizer, but the truth of this story is debated.\n\nNative Americans did plant beans next to corn; the beans would replace the nitrogen which the corn took from the ground, as well as using corn stalks for support for climbing. Native Americans used controlled fires to burn weeds and clear fields; this would put nutrients back into the ground. If this did not work, they would simply abandon the field to let it be fallow, and find a new spot for cultivation.\n\nEuropeans in the eastern part of the continent observed that Native Americans cleared large areas for cropland. Their fields in New England sometimes covered hundreds of acres. Colonists in Virginia noted thousands of acres under cultivation by Native Americans.\n\nNative Americans commonly used tools such as the hoe, maul, and dibber. The hoe was the main tool used to till the land and prepare it for planting; then it was used for weeding. The first versions were made out of wood and stone. When the settlers brought iron, Native Americans switched to iron hoes and hatchets. The dibber was a digging stick, used to plant the seed. Once the plants were harvested, women prepared the produce for eating. They used the maul to grind the corn into mash. It was cooked and eaten that way or baked as corn bread.\n\nTraditional Native American ceremonies are still practiced by many tribes and bands, and the older theological belief systems are still held by many of the native people. These spiritualities may accompany adherence to another faith, or can represent a person's primary religious identity. While much Native American spiritualism exists in a tribal-cultural continuum, and as such cannot be easily separated from tribal identity itself, certain other more clearly defined movements have arisen among \"traditional\" Native American practitioners, these being identifiable as \"religions\" in the prototypical sense familiar in the industrialized Western world.\n\nTraditional practices of some tribes include the use of sacred herbs such as tobacco, sweetgrass or sage. Many Plains tribes have sweatlodge ceremonies, though the specifics of the ceremony vary among tribes. Fasting, singing and prayer in the ancient languages of their people, and sometimes drumming are also common.\n\nThe Midewiwin Lodge is a traditional medicine society inspired by the oral traditions and prophesies of the Ojibwa (Chippewa) and related tribes.\n\nAnother significant religious body among Native peoples is known as the Native American Church. It is a syncretistic church incorporating elements of Native spiritual practice from a number of different tribes as well as symbolic elements from Christianity. Its main rite is the peyote ceremony. Prior to 1890, traditional religious beliefs included Wakan Tanka. In the American Southwest, especially New Mexico, a syncretism between the Catholicism brought by Spanish missionaries and the native religion is common; the religious drums, chants, and dances of the Pueblo people are regularly part of Masses at Santa Fe's Saint Francis Cathedral. Native American-Catholic syncretism is also found elsewhere in the United States. (e.g., the National Kateri Tekakwitha Shrine in Fonda, New York, and the National Shrine of the North American Martyrs in Auriesville, New York).\n\nThe eagle feather law (Title 50 Part 22 of the Code of Federal Regulations) stipulates that only individuals of certifiable Native American ancestry enrolled in a federally recognized tribe are legally authorized to obtain eagle feathers for religious or spiritual use. The law does not allow Native Americans to give eagle feathers to non-Native Americans.\n\nGender roles are differentiated in many Native American tribes. Many Natives have historically defied colonial expectations of sexuality and gender, and continue to do so in contemporary life.\n\nWhether a particular tribe is predominantly matrilineal or patrilineal, often both sexes have some degree of decision-making power within the tribe. Many Nations, such as the Haudenosaunee Five Nations and the Southeast Muskogean tribes, have matrilineal or Clan Mother systems, in which property and hereditary leadership are controlled by and passed through the maternal lines. In these Nations, the children are considered to belong to the mother's clan. In Cherokee culture, women own the family property. When traditional young women marry, their husbands may join them in their mother's household.\n\nMatrilineal structures enable young women to have assistance in childbirth and rearing, and protect them in case of conflicts between the couple. If a couple separates or the man dies, the woman has her family to assist her. In matrilineal cultures the mother's brothers are usually the leading male figures in her children's lives; fathers have no standing in their wife and children's clan, as they still belong to their own mother's clan. Hereditary clan chief positions pass through the mother's line and chiefs have historically been selected on recommendation of women elders, who also could disapprove of a chief.\n\nIn the patrilineal tribes, such as the Omaha, Osage, Ponca, and Lakota, hereditary leadership passes through the male line, and children are considered to belong to the father and his clan. In patrilineal tribes, if a woman marries a non-Native, she is no longer considered part of the tribe, and her children are considered to share the ethnicity and culture of their father.\n\nIn patriarchal tribes, gender roles tend to be rigid. Men have historically hunted, traded and made war while, as life-givers, women have primary responsibility for the survival and welfare of the families (and future of the tribe). Women usually gather and cultivate plants, use plants and herbs to treat illnesses, care for the young and the elderly, make all the clothing and instruments, and process and cure meat and skins from the game. Some mothers use cradleboards to carry an infant while working or traveling. In matriarchal and egalitarian nations, the gender roles are usually not so clear-cut, and are even less so in the modern era.\n\nAt least several dozen tribes allowed polygyny to sisters, with procedural and economic limits.\n\nLakota, Dakota, and Nakota girls are encouraged to learn to ride, hunt and fight. Though fighting in war has mostly been left to the boys and men, occasionally women have fought as well - both in battles and in defense of the home - especially if the tribe was severely threatened.\n\nNative American leisure time led to competitive individual and team sports. Jim Thorpe, Joe Hipp, Notah Begay III, Chris Wondolowski, Jacoby Ellsbury, Joba Chamberlain, Kyle Lohse, Sam Bradford, Jack Brisco, Tommy Morrison, Billy Mills, Angel Goodrich, Shoni Schimmel, and Kyrie Irving are well known professional athletes.\nNative American ball sports, sometimes referred to as lacrosse, stickball, or baggataway, were often used to settle disputes, rather than going to war, as a civil way to settle potential conflict. The Choctaw called it \"isitoboli\" (\"Little Brother of War\"); the Onondaga name was \"dehuntshigwa'es\" (\"men hit a rounded object\"). There are three basic versions, classified as Great Lakes, Iroquoian, and Southern.\n\nThe game is played with one or two rackets or sticks and one ball. The object of the game is to land the ball in the opposing team's goal (either a single post or net) to score and to prevent the opposing team from scoring on your goal. The game involves as few as 20 or as many as 300 players with no height or weight restrictions and no protective gear. The goals could be from around apart to about ; in lacrosse the field is . A Jesuit priest referenced stickball in 1729, and George Catlin painted the subject.\n\nCurrently in the WNBA, there are 2 women who are of Native ancestry and enrolled in federally recognized tribes.\n\nAngel Goodrich, Cherokee, was selected in the third round of the WNBA draft (29th pick overall) by the Tulsa Shock. At the time she was the highest-drafted Native American player in the history of the WNBA. During the 2013–14 off-season, she played for Chevakata Vologda in the Russian Premier League.[10] In 2014, she completed her second and final season for the Shock. In 2015, she was picked up on waivers by the Seattle Storm\n\nShoni Schimmel, Confederated Tribes of the Umatilla Indian Reservation, is an American professional basketball player. She was an All-American college player at the University of Louisville and a first round draft pick of the WNBA's Atlanta Dream. She also earned recognition as the 2014 WNBA All-Star Game Most Valuable Player on July 19, 2014, in Phoenix, Arizona.[7]\n\nChunkey was a game that consisted of a stone-shaped disk that was about 1–2 inches in diameter. The disk was thrown down a corridor so that it could roll past the players at great speed. The disk would roll down the corridor, and players would throw wooden shafts at the moving disk. The object of the game was to strike the disk or prevent your opponents from hitting it.\nJim Thorpe, a Sauk and Fox Native American, was an all-round athlete playing football and baseball in the early 20th century. Future President Dwight Eisenhower injured his knee while trying to tackle the young Thorpe. In a 1961 speech, Eisenhower recalled Thorpe: \"Here and there, there are some people who are supremely endowed. My memory goes back to Jim Thorpe. He never practiced in his life, and he could do anything better than any other football player I ever saw.\"\n\nIn the 1912 Olympics, Thorpe could run the 100-yard dash in 10 seconds flat, the 220 in 21.8 seconds, the 440 in 51.8 seconds, the 880 in 1:57, the mile in 4:35, the 120-yard high hurdles in 15 seconds, and the 220-yard low hurdles in 24 seconds. He could long jump 23 ft 6 in and high-jump 6 ft 5 in. He could pole vault , put the shot , throw the javelin , and throw the discus . Thorpe entered the U.S. Olympic trials for the pentathlon and the decathlon.\n\nLouis Tewanima, Hopi people, was an American two-time Olympic distance runner and silver medalist in the 10,000 meter run in 1912. He ran for the Carlisle Indian School where he was a teammate of Jim Thorpe. His silver medal in 1912 remained the best U.S. achievement in this event until another Indian, Billy Mills, won the gold medal in 1964. Tewanima also competed at the 1908 Olympics, where he finished in ninth place in the marathon.[1]\n\nEllison Brown, of the Narragansett people from Rhode Island, better known as \"Tarzan\" Brown, won two Boston Marathons (1936, 1939) and competed on the United States Olympic team in the 1936 Olympic Games in Berlin, Germany, but did not finish due to injury. He qualified for the 1940 Olympic Games in Helsinki, Finland, but the games were canceled due to the outbreak of World War II.\n\nBilly Mills, a Lakota and USMC officer, won the gold medal in the 10,000 meter run at the 1964 Tokyo Olympics. He was the only American ever to win the Olympic gold in this event. An unknown before the Olympics, Mills finished second in the U.S. Olympic trials.\n\nBilly Kidd, part Abenaki from Vermont, became the first American male to medal in alpine skiing in the Olympics, taking silver at age 20 in the slalom in the 1964 Winter Olympics at Innsbruck, Austria. Six years later at the 1970 World Championships, Kidd won the gold medal in the combined event and took the bronze medal in the slalom.\n\nTraditional Native American music is almost entirely monophonic, but there are notable exceptions. Native American music often includes drumming or the playing of rattles or other percussion instruments but little other instrumentation. Flutes and whistles made of wood, cane, or bone are also played, generally by individuals, but in former times also by large ensembles (as noted by Spanish conquistador de Soto). The tuning of modern flutes is typically pentatonic.\n\nPerformers with Native American parentage have occasionally appeared in American popular music such as Rita Coolidge, Wayne Newton, Gene Clark, Buffy Sainte-Marie, Blackfoot, Tori Amos, Redbone (members are also of Mexican descent), and CocoRosie. Some, such as John Trudell, have used music to comment on life in Native America. Other musicians such as R. Carlos Nakai, Joanne Shenandoah and Robert \"Tree\" Cody integrate traditional sounds with modern sounds in instrumental recordings, whereas the music by artist Charles Littleleaf is derived from ancestral heritage as well as nature. A variety of small and medium-sized recording companies offer an abundance of recent music by Native American performers young and old, ranging from pow-wow drum music to hard-driving rock-and-roll and rap. In the International world of ballet dancing Maria Tallchief was considered America's first major prima ballerina, and was the first person of Native American descent to hold the rank. along with her sister Marjorie Tallchief both became star ballerinas.\n\nThe most widely practiced public musical form among Native Americans in the United States is that of the pow-wow. At pow-wows, such as the annual Gathering of Nations in Albuquerque, New Mexico, members of drum groups sit in a circle around a large drum. Drum groups play in unison while they sing in a native language and dancers in colorful regalia dance clockwise around the drum groups in the center. Familiar pow-wow songs include honor songs, intertribal songs, crow-hops, sneak-up songs, grass-dances, two-steps, welcome songs, going-home songs, and war songs. Most indigenous communities in the United States also maintain traditional songs and ceremonies, some of which are shared and practiced exclusively within the community.\n\nThe Iroquois, living around the Great Lakes and extending east and north, used strings or belts called \"wampum\" that served a dual function: the knots and beaded designs mnemonically chronicled tribal stories and legends, and further served as a medium of exchange and a unit of measure. The keepers of the articles were seen as tribal dignitaries.\n\nPueblo peoples crafted impressive items associated with their religious ceremonies. \"Kachina\" dancers wore elaborately painted and decorated masks as they ritually impersonated various ancestral spirits. \nPueblo people are particularly noted for their traditional high-quality pottery, often with geometric designs and floral, animal and bird motifs. Sculpture was not highly developed, but carved stone and wood fetishes were made for religious use. Superior weaving, embroidered decorations, and rich dyes characterized the textile arts. Both turquoise and shell jewelry were created, as were formalized pictorial arts. \n\nNavajo spirituality focused on the maintenance of a harmonious relationship with the spirit world, often achieved by ceremonial acts, usually incorporating sandpainting. For the Navajo the sand painting is not merely a representational object, but a dynamic spiritual entity with a life of its own, which helped the patient at the centre of the ceremony re-establish a connection with the life force. These vivid, intricate, and colorful sand creations were erased at the end of the healing ceremony. \n\nThe Native American arts and crafts industry brings in more than a billion in gross sales annually.\n\nNative American art comprises a major category in the world art collection. Native American contributions include pottery, paintings, jewellery, weavings, sculpture, basketry, and carvings. Franklin Gritts was a Cherokee artist who taught students from many tribes at Haskell Institute (now Haskell Indian Nations University) in the 1940s, the \"Golden Age\" of Native American painters. The integrity of certain Native American artworks is protected by the Indian Arts and Crafts Act of 1990, that prohibits representation of art as Native American when it is not the product of an enrolled Native American artist. Attorney Gail Sheffield and others claim that this law has had \"the unintended consequence of sanctioning discrimination against Native Americans whose tribal affiliation was not officially recognized.\" Native artists such as Jeanne Rorex Bridges (Cherokee) who are not enrolled run the risk of fines or imprisonment if they continue to sell their art while affirming their Indian heritage.\n\nThe Inuit, or Eskimo, prepared and buried large amounts of dried meat and fish. Pacific Northwest tribes crafted seafaring dugouts long for fishing. Farmers in the Eastern Woodlands tended fields of maize with hoes and digging sticks, while their neighbors in the Southeast grew tobacco as well as food crops. On the Plains, some tribes engaged in agriculture but also planned buffalo hunts in which herds were driven over bluffs.\n\nDwellers of the Southwest deserts hunted small animals and gathered acorns to grind into flour with which they baked wafer-thin bread on top of heated stones. Some groups on the region's mesas developed irrigation techniques, and filled storehouses with grain as protection against the area's frequent droughts.\n\nIn the early years, as these native peoples encountered European explorers and settlers and engaged in trade, they exchanged food, crafts, and furs for blankets, iron and steel implements, horses, trinkets, firearms, and alcoholic beverages.\n\nInterracial relations between Native Americans, Europeans, and Africans is a complex issue that has been mostly neglected with \"few in-depth studies on interracial relationships\". Some of the first documented cases of European/Native American intermarriage and contact were recorded in Post-Columbian Mexico. One case is that of Gonzalo Guerrero, a European from Spain, who was shipwrecked along the Yucatan Peninsula, and fathered three Mestizo children with a Mayan noblewoman. Another is the case of Hernán Cortés and his mistress La Malinche, who gave birth to another of the first multi-racial people in the Americas.\n\nEuropean impact was immediate, widespread, and profound already during the early years of colonization and nationhood. Europeans living among Native Americans were often called \"white indians\". They \"lived in native communities for years, learned native languages fluently, attended native councils, and often fought alongside their native companions\".\n\nEarly contact was often charged with tension and emotion, but also had moments of friendship, cooperation, and intimacy. Marriages took place in English, Spanish, and French colonies between Native Americans and Europeans. Given the preponderance of men among the colonists in the early years, generally European men married or had relationships with Native American women.\nThere was fear on both sides, as the different peoples realized how different their societies were. The whites regarded the Indians as \"savage\" because they were not Christian. They were suspicious of cultures which they did not understand. The Native American author, Andrew J. Blackbird, wrote in his \"History of the Ottawa and Chippewa Indians of Michigan\" (1897), that white settlers introduced some immoralities into Native American tribes. Many Indians suffered because the Europeans introduced alcohol and the whiskey trade resulted in alcoholism among the people, who were alcohol-intolerant.\n\nBlackbird wrote:\n\nThe U.S. government had two purposes when making land agreements with Native Americans: to open it up more land for white settlement, and to ease tensions between whites and Native Americans by forcing the Native Americans to use the land in the same way as did the whites—for subsistence farms. The government used a variety of strategies to achieve these goals; many treaties required Native Americans to become farmers in order to keep their land. Government officials often did not translate the documents which Native Americans were forced to sign, and native chiefs often had little or no idea what they were signing.\nFor a Native American man to marry a white woman, he had to get consent of her parents, as long as \"he can prove to support her as a white woman in a good home\". In the early 19th century, the Shawnee Tecumseh and blonde hair, blue-eyed Rebbecca Galloway had an interracial affair. In the late 19th century, three European-American middle-class women teachers at Hampton Institute married Native American men whom they had met as students.\n\nAs European-American women started working independently at missions and Indian schools in the western states, there were more opportunities for their meeting and developing relationships with Native American men. For instance, Charles Eastman, a man of European and Lakota descent whose father sent both his sons to Dartmouth College, got his medical degree at Boston University and returned to the West to practice. He married Elaine Goodale, whom he met in South Dakota. He was the grandson of Seth Eastman, a military officer from Maine, and a chief's daughter. Goodale was a young European-American teacher from Massachusetts and a reformer, who was appointed as the U.S. superintendent of Native American education for the reservations in the Dakota Territory. They had six children together.\n\nThe majority of Native American tribes did practice some form of slavery before the European introduction of African slavery into North America, but none exploited slave labor on a large scale. Most Native American tribes did not barter captives in the pre-colonial era, although they sometimes exchanged enslaved individuals with other tribes in peace gestures or in exchange for their own members. When Europeans arrived as colonists in North America, Native Americans changed their practice of slavery dramatically. Native Americans began selling war captives to Europeans rather than integrating them into their own societies as they had done before. As the demand for labor in the West Indies grew with the cultivation of sugar cane, Europeans enslaved Native Americans for the Thirteen Colonies, and some were exported to the \"sugar islands\". The British settlers, especially those in the southern colonies, purchased or captured Native Americans to use as forced labor in cultivating tobacco, rice, and indigo. Accurate records of the numbers enslaved do not exist because vital statistics and census reports were at best infrequent.. Scholars estimate tens to hundreds of thousands of Native Americans may have been enslaved by the Europeans, being sold by Native Americans themselves or Europeans. \nSlaves became a caste of people who were foreign to the English (Native Americans, Africans and their descendants) and non-Christians. The Virginia General Assembly defined some terms of slavery in 1705:\n\nThe slave trade of Native Americans lasted only until around 1750. It gave rise to a series of devastating wars among the tribes, including the Yamasee War. The Indian Wars of the early 18th century, combined with the increasing importation of African slaves, effectively ended the Native American slave trade by 1750. Colonists found that Native American slaves could easily escape, as they knew the country. The wars cost the lives of numerous colonial slave traders and disrupted their early societies. The remaining Native American groups banded together to face the Europeans from a position of strength. Many surviving Native American peoples of the southeast strengthened their loose coalitions of language groups and joined confederacies such as the Choctaw, the Creek, and the Catawba for protection. Even after the Indian Slave Trade ended in 1750 the enslavement of Native Americans continued in the west, and also in the Southern states mostly through kidnappings.\n\nNative American women were at risk for rape whether they were enslaved or not; during the early colonial years, settlers were disproportionately male. They turned to Native women for sexual relationships. Both Native American and African enslaved women suffered rape and sexual harassment by male slaveholders and other white men.\n\nAfrican and Native Americans have interacted for centuries. The earliest record of Native American and African contact occurred in April 1502, when Spanish colonists transported the first Africans to Hispaniola to serve as slaves.\nSometimes Native Americans resented the presence of African Americans. The \"Catawaba tribe in 1752 showed great anger and bitter resentment when an African American came among them as a trader\". To gain favor with Europeans, the Cherokee exhibited the strongest color prejudice of all Native Americans. Because of European fears of a unified revolt of Native Americans and African Americans, the colonists tried to encourage hostility between the ethnic groups: \"Whites sought to convince Native Americans that African Americans worked against their best interests.\" In 1751, South Carolina law stated:\n\nIn addition, in 1758 the governor of South Carolina James Glen wrote:\n\nEuropeans considered both races inferior and made efforts to make both Native Americans and Africans enemies. Native Americans were rewarded if they returned escaped slaves, and African Americans were rewarded for fighting in the late 19th-century Indian Wars.\n\n\"Native Americans, during the transitional period of Africans becoming the primary race enslaved, were enslaved at the same time and shared a common experience of enslavement. They worked together, lived together in communal quarters, produced collective recipes for food, shared herbal remedies, myths and legends, and in the end they intermarried.\" Because of a shortage of men due to warfare, many tribes encouraged marriage between the two groups, to create stronger, healthier children from the unions.\n\nIn the 18th century, many Native American women married freed or runaway African men due to a decrease in the population of men in Native American villages. Records show that many Native American women bought African men but, unknown to the European sellers, the women freed and married the men into their tribe. When African men married or had children by a Native American woman, their children were born free, because the mother was free (according to the principle of \"partus sequitur ventrem\", which the colonists incorporated into law).\n\nWhile numerous tribes used captive enemies as servants and slaves, they also often adopted younger captives into their tribes to replace members who had died. In the Southeast, a few Native American tribes began to adopt a slavery system similar to that of the American colonists, buying African American slaves, especially the Cherokee, Choctaw, and Creek. Though less than 3% of Native Americans owned slaves, divisions grew among the Native Americans over slavery. Among the Cherokee, records show that slave holders in the tribe were largely the children of European men that had shown their children the economics of slavery. As European colonists took slaves into frontier areas, there were more opportunities for relationships between African and Native American peoples.\n\nIn the 2010 Census, nearly 3 million people indicated that their race was Native American (including Alaska Native). Of these, more than 27% specifically indicated \"Cherokee\" as their ethnic origin. Many of the First Families of Virginia claim descent from Pocahontas or some other \"Indian princess\". This phenomenon has been dubbed the \"Cherokee Syndrome\". Across the US, numerous individuals cultivate an opportunistic ethnic identity as Native American, sometimes through Cherokee heritage groups or Indian Wedding Blessings.\n\nMany tribes, especially those in the Eastern United States, are primarily made up of individuals with an unambiguous Native American identity, despite being predominantly of European ancestry. More than 75% of those enrolled in the Cherokee Nation have less than one-quarter Cherokee blood, and the current Principal Chief of the Cherokee Nation, Bill John Baker, is 1/32 Cherokee, amounting to about 3%.\n\nHistorically, numerous Native Americans assimilated into colonial and later American society, e.g. through adopting English and converting to Christianity. In many cases, this process occurred through forced assimilation of children sent off to special boarding schools far from their families. Those who could pass for white had the advantage of white privilege Today, after generations of racial whitening through hypergamy, many Native Americans are visually indistinguishable from White Americans, unlike mestizos in the United States, who may in fact have little or no non-indigenous ancestry.\n\nNative Americans are more likely than any other racial group to practice racial exogamy, resulting in an ever-declining proportion of indigenous blood among those who claim a Native American identity. Some tribes will even resort to disenrollment of tribal members unable to provide scientific \"proof\" of Native ancestry, usually through a Certificate of Degree of Indian Blood. Disenrollment has become a contentious issue in Native American reservation politics.\n\nIntertribal mixing was common among many Native American tribes prior to European contact, as they would adopt captives taken in warfare. Individuals often had ancestry from more than one tribe, particularly after tribes lost so many members from disease in the colonial era and after. Bands or entire tribes occasionally split or merged to form more viable groups in reaction to the pressures of climate, disease and warfare.\n\nA number of tribes traditionally adopted captives into their group to replace members who had been captured or killed in battle. Such captives were from rival tribes and later were taken from raids on European settlements. Some tribes also sheltered or adopted white traders and runaway slaves, and others owned slaves of their own. Tribes with long trading histories with Europeans show a higher rate of European admixture, reflecting years of intermarriage between Native American women and European men, often seen as advantageous to both sides. A number of paths to genetic and ethnic diversity among Native Americans have occurred.\n\nIn recent years, genetic genealogists have been able to determine the proportion of Native American ancestry carried by the African-American population. The literary and history scholar Henry Louis Gates, Jr., had experts on his TV programs who discussed African-American ancestry. They stated that 5% of African Americans have at least 12.5% Native American ancestry, or the equivalent to one great-grandparent, which may represent more than one distant ancestor. A greater percentage could have a smaller proportion of Indian ancestry, but their conclusions show that popular estimates of Native American admixture may have been too high. More recent genetic testing research of 2015, have found varied ancestries which show different tendencies by region and sex of ancestors. Though DNA testing is limited these studies found that on average, African Americans have 73.2-82.1% West African, 16.7%-29% European, and 0.8–2% Native American genetic ancestry, with large variation between individuals.\n\nDNA testing is not sufficient to qualify a person for specific tribal membership, as it cannot distinguish among Native American tribes; however some tribes such as the Meskwaki Nation require a DNA test in order to enroll in the tribe.\n\nNative American identity has historically been based on culture, not just biology, as many American Indian peoples adopted captives from their enemies and assimilated them into their tribes. The Indigenous Peoples Council on Biocolonialism (IPCB) notes that:\n\n\"Native American markers\" are not found solely among Native Americans. While they occur more frequently among Native Americans, they are also found in people in other parts of the world.\n\nGeneticists state:\n\nNot all Native Americans have been tested; especially with the large number of deaths due to disease such as smallpox, it is unlikely that Native Americans only have the genetic markers they have identified [so far], even when their maternal or paternal bloodline does not include a [known] non-Native American.\n\nTo receive tribal services, a Native American must be a certified (or enrolled) member of a federally recognized tribal organization. Each tribal government makes its own rules for eligibility of citizens or tribal members. Among tribes, qualification for enrollment may be based upon a required percentage of Native American \"blood\" (or the \"blood quantum\") of an individual seeking recognition, or documented descent from an ancestor on the Dawes Rolls or other registers. But, the federal government has its own standards related to who qualifies for services available to certified Native Americans. For instance, federal scholarships for Native Americans require the student both to be enrolled in a federally recognized tribe \"and\" to be of at least one-quarter Native American descent (equivalent to one grandparent), attested to by a Certificate of Degree of Indian Blood (CDIB) card issued by the federal government.\n\nSome tribes have begun requiring genealogical DNA testing of individuals' applying for membership, but this is usually related to an individual's proving parentage or direct descent from a certified member. Requirements for tribal membership vary widely by tribe. The Cherokee require documented direct genealogical descent from a Native American listed on the early 1906 Dawes Rolls. Tribal rules regarding recognition of members who have heritage from multiple tribes are equally diverse and complex.\n\nTribal membership conflicts have led to a number of legal disputes, court cases, and the formation of activist groups. One example of this are the Cherokee Freedmen. Today, they include descendants of African Americans once enslaved by the Cherokees, who were granted, by federal treaty, citizenship in the historic Cherokee Nation as freedmen after the Civil War. The modern Cherokee Nation, in the early 1980s, passed a law to require that all members must prove descent from a Cherokee Native American (not Cherokee Freedmen) listed on the Dawes Rolls, resulting in the exclusion of some individuals and families who had been active in Cherokee culture for years.\n\nSince the census of 2000, people may identify as being of more than one race. Since the 1960s, the number of people claiming Native American ancestry has grown significantly and by the 2000 census, the number had more than doubled. Sociologists attribute this dramatic change to \"ethnic shifting\" or \"ethnic shopping\"; they believe that it reflects a willingness of people to question their birth identities and adopt new ethnicities which they find more compatible.\n\nThe author Jack Hitt writes:\n\nThe journalist Mary Annette Pember notes that identifying with Native American culture may be a result of a person's increased interest in genealogy, the romanticization of the lifestyle, and a family tradition of Native American ancestors in the distant past. There are different issues if a person wants to pursue enrollment as a member of a tribe. Different tribes have different requirements for tribal membership; in some cases persons are reluctant to enroll, seeing it as a method of control initiated by the federal government; and there are individuals who are 100% Native American but, because of their mixed tribal heritage, do not qualify to belong to any individual tribe. Pember concludes:\n\nThe genetic history of indigenous peoples of the Americas primarily focuses on human Y-chromosome DNA haplogroups and human mitochondrial DNA haplogroups. \"Y-DNA\" is passed solely along the patrilineal line, from father to son, while \"mtDNA\" is passed down the matrilineal line, from mother to offspring of both sexes. Neither recombines, and thus Y-DNA and mtDNA change only by chance mutation at each generation with no intermixture between parents' genetic material. Autosomal \"atDNA\" markers are also used, but differ from mtDNA or Y-DNA in that they overlap significantly. Autosomal DNA is generally used to measure the average continent-of-ancestry genetic admixture in the entire human genome and related isolated populations.\n\nThe genetic pattern indicates Indigenous Americans experienced two very distinctive genetic episodes; first with the initial-peopling of the Americas, and secondly with European colonization of the Americas. The former is the determinant factor for the number of gene lineages, zygosity mutations and founding haplotypes present in today's Indigenous Amerindian populations.\n\nHuman settlement of the New World occurred in stages from the Bering sea coast line, with an initial 15,000 to 20,000-year layover on Beringia for the small founding population. The micro-satellite diversity and distributions of the Y lineage specific to South America indicates that certain Amerindian populations have been isolated since the initial colonization of the region. The Na-Dené, Inuit and Indigenous Alaskan populations exhibit haplogroup Q-M242 (Y-DNA) mutations, however, that are distinct from other indigenous Amerindians, and that have various mtDNA and atDNA mutations. This suggests that the paleo-Indian migrants into the northern extremes of North America and Greenland were descended from a later, independent migrant population.\n\nGovernment\n\nOrganizations and media\n\nAcademic collections and other resources\n"}
{"id": "17753000", "url": "https://en.wikipedia.org/wiki?curid=17753000", "title": "Oldisleben I", "text": "Oldisleben I\n\nOldisleben I is an archeological site of the Eemian interglacial period located north of Weimar in the Oldisleben municipality, Germany. Findings at the site include some of the earliest known engravings on portable objects of bone, ivory and stone, dating back between \n135,000 and 80,000 BP.\n\n"}
{"id": "235876", "url": "https://en.wikipedia.org/wiki?curid=235876", "title": "Ouroboros", "text": "Ouroboros\n\nThe Ouroboros or uroborus () is an ancient symbol depicting a serpent or dragon eating its own tail. Originating in ancient Egyptian iconography, the ouroboros entered western tradition via Greek magical tradition and was adopted as a symbol in Gnosticism and Hermeticism and most notably in alchemy. The term derives from , from οὐρά (\"oura\"), \"tail\" + βορά (\"bora\"), \"food\", from βιβρώσκω (\"bibrōskō\"), \"I eat\".\n\nThe first known appearance of the ouroboros motif is in the Enigmatic Book of the Netherworld, an ancient Egyptian funerary text in KV62, the tomb of Tutankhamun, in the 14th century BC. The text concerns the actions of the god Ra and his union with Osiris in the underworld. In an illustration from this text, two serpents, holding their tails in their mouths, coil around the head, neck, and feet of an enormous god, who may represent the unified Ra-Osiris. Both serpents are manifestations of the deity Mehen, who in other funerary texts protects Ra in his underworld journey. The whole divine figure represents the beginning and the end of time.\n\nThe ouroboros appears elsewhere in Egyptian sources, where, like many Egyptian serpent deities, it represents the formless disorder that surrounds the orderly world and is involved in that world's periodic renewal. The symbol persisted in Egypt into Roman times, when it frequently appeared on magical talismans, sometimes in combination with other magical emblems. The 4th-century AD Latin commentator Servius was aware of the Egyptian use of the symbol, noting that the image of a snake biting its tail represents the cyclical nature of the year.\n\nThe famous ouroboros drawing from the early alchemical text, \"The Chrysopoeia of Cleopatra\" (Κλεοπάτρης χρυσοποιία), probably originally dating to third century Alexandria but first known in a tenth century copy, encloses the words \"hen to pan\" (ἓν τὸ πᾶν), \"the all is one\". Its black and white halves may perhaps represent the Gnostic duality of existence, leading some to see it as an analog of the Taoist yin and yang symbol. The chrysopoeia ouroboros of Cleopatra the Alchemist is one of the oldest images of the ouroboros to be linked with the legendary \"opus\" of the alchemists, the philosopher's stone.\n\nAs a symbol of the eternal unity of all things, the cycle of birth and death from which the alchemist sought release and liberation, it was familiar to the alchemist and physician Sir Thomas Browne. In his \"A Letter to a Friend\", a medical treatise full of case-histories and witty speculations upon the human condition, he wrote of it:\n\nIn Gnosticism, a serpent biting its tail symbolized eternity and the soul of the world. The Gnostic \"Pistis Sophia\" (c. 400 AD) describes the ouroboros as a twelve-part dragon surrounding the world with his tail in his mouth.\n\nIn Norse mythology, the ouroboros appears as the serpent Jörmungandr, one of the three children of Loki and Angrboda, which grew so large that it could encircle the world and grasp its tail in its teeth. In the legends of Ragnar Lodbrok, such as \"Ragnarssona þáttr\", the Geatish king Herraud gives a small lindworm as a gift to his daughter Þóra Town-Hart after which it grows into a large serpent which encircles the girl's bower and bites itself in the tail. The serpent is slain by Ragnar Lodbrok who marries Þóra. Ragnar later has a son with another woman named Kráka and this son is born with the image of a white snake in one eye. This snake encircled the iris and bit itself in the tail, and the son was named Sigurd Snake-in-the-Eye.\n\nIt is a common belief among indigenous people of the tropical lowlands of South America that waters at the edge of the world-disc are encircled by a snake, often an anaconda, biting its own tail.\n\nOuroboros symbolism has been used to describe the Kundalini. According to the medieval \"Yoga-kundalini Upanishad\", \"The divine power, Kundalini, shines like the stem of a young lotus; like a snake, coiled round upon herself she holds her tail in her mouth and lies resting half asleep as the base of the body\" (1.82).\n\nStorl (2004) also refers to the ouroboros image in reference to the \"cycle of samsara\".\n\nSwiss psychologist Carl Jung saw the ouroboros as an archetype and the basic mandala of alchemy. Jung also defined the relationship of the ouroboros to alchemy:\n\nThe Jungian psychologist Erich Neumann writes of it as a representation of the pre-ego \"dawn state\", depicting the undifferentiated infancy experience of both mankind and the individual child.\n\nThe German organic chemist August Kekulé described the eureka moment when he realized the structure of benzene, after he saw a vision of Ouroboros:\n\nI was sitting, writing at my text-book; but the work did not progress; my thoughts were elsewhere. I turned my chair to the fire and dozed. Again the atoms were gamboling before my eyes. This time the smaller groups kept modestly in the background. My mental eye, rendered more acute by the repeated visions of the kind, could now distinguish larger structures of manifold conformation: long rows, sometimes more closely fitted together; all twining and twisting in snake-like motion. But look! What was that? One of the snakes had seized hold of its own tail, and the form whirled mockingly before my eyes. As if by a flash of lightning I awoke; and this time also I spent the rest of the night in working out the consequences of the hypothesis.\n\nThe genus of the armadillo girdled lizard, \"Ouroborus cataphractus\", takes its name from the animal's defensive posture: curling into a ball and holding its own tail in its mouth.\n\nNotes\n\nBibliography\n\n"}
{"id": "45695593", "url": "https://en.wikipedia.org/wiki?curid=45695593", "title": "Plantà", "text": "Plantà\n\nThe plantá (which comes from the verb \"to plant\"; in Valencian, \"plantà\") is the act of erecting a Falla or bonfire monument, in the Fallas or the Bonfires of Saint John, festivals held respectively in March and June in different localities of the community of Valencia (Spain).The plantà is currently considered the exact moment when the falla or bonfire is completely finished and ready to be visited, with all its \"ninots\" (human figures made of combustible materials, such as cardboard or wood, which has a critical or mocking nature), posters and a variety of features (lights, matted grass, interpretive signs...).\n\nIn the Fallas of Valencia, the plantá takes place on March 15, when all the Falla monuments must be positioned correctly. The reason is that the jury appointed by the Central Fallera committee has to go to the next day to assess the falla. Formerly, the plantà began and ended the same day but, due to the complexity of the monuments and the fact that the makers of Fallas are responsible for several Fallas monuments at the same time, it usually begins a few days before. The burning of the Falla or cremá is carried out four days later, on the night of March 19.\n\nIn the Bonfires of Saint John which are celebrated in the city of Alicante, the plantá takes place on June 20. As in Valencia, the next day the jury visits each bonfire before later awarding the prizes in each category. The cremá also takes place four days later, on the night of June 24 to 25.\n\n"}
{"id": "4605119", "url": "https://en.wikipedia.org/wiki?curid=4605119", "title": "Punga (mythology)", "text": "Punga (mythology)\n\nIn Māori mythology, Punga is a supernatural being, the ancestor of sharks, lizards, rays, and all deformed, ugly things. All ugly and strange animals are Punga's children. Hence the saying \"Te aitanga a Punga\" (the offspring of Punga) used to describe an ugly person.\n\nPunga is a son of Tangaroa, the god of the sea, and when Tāwhirimātea (god of storms) made war against his brothers after they separated Rangi and Papa (sky and earth), the two sons of Punga, Ikatere and Tū-te-wehiwehi, had to flee for their lives. Ikatere fled to the sea, and became the ancestor of certain fishes, while Tū-te-wehiwehi took refuge in the forest, and became the ancestor of lizards.\n\nAs is appropriate for a son of Tangaroa, Punga's name has a maritime origin - in the Māori language, 'punga' means 'anchor stone' - in tropical Polynesia, related words refer to coral stone, also used as an anchor (Craig 1989:219, Tregear 1891:374).\n\nAccording to some versions, Punga is the son of Rangi-potiki (father sky) and Papatūānuku (mother earth) and a twin brother to Here. In a version of the epic of Tāwhaki attributed by White to the Ngāti Hau tribe, Punga is named as a brother of Karihi and Hemā; however, in many versions, he is a cousin of the brothers Karihi and Tāwhaki (Craig 1989:219, Tregear 1891:374, White 1887:95, 125).\n\nIn some Hawaiian stories, Hema and Punga are sons of Aikanaka and Hinahanaiakamalama (Tregear 1891:374).\n\n"}
{"id": "25172837", "url": "https://en.wikipedia.org/wiki?curid=25172837", "title": "Race and sports", "text": "Race and sports\n\nIssues related to race and sports have been examined by scholars for a long time. Among these issues are racial discrimination in sports as well as the observation that there are overrepresentations and underrepresentations of different races in different sports.\n\nMost of the sprinters who run less than 10 seconds are of West African descent, with the majority being of Afro-Caribbean and African-American descent. Namibian (formerly South-West Africa) Frankie Fredericks became the first man of non-West African heritage to achieve the feat in 1991 and in 2003 Australia's Patrick Johnson (who has Irish and Indigenous Australian heritage) became the first sub-10-second runner without an African background.\n\nIn 2010, Frenchman Christophe Lemaitre became the first white European under ten seconds (although Poland's Marian Woronin had unofficially surpassed the barrier with a time of 9.992 seconds in 1984). In 2011, Zimbabwean Ngonidzashe Makusha became the 76th man to break the barrier, yet only the fourth man not of West African descent. No sprinter from South Asia, East Africa or North Africa has officially achieved this feat. In 2015 Su Bingtian of China became the first ethnic East Asian athlete to officially break the 10 second barrier and British athlete Adam Gemili – who is of mixed Iranian and Moroccan descent – became the first athlete with either North African or Middle Eastern heritage to break the ten second barrier.\n\nSome studies have claimed that biological factors may be largely responsible for the disproportionate success in sprinting events enjoyed by athletes of West African descent. Chief among these is a preponderance of natural fast twitch muscle fibers, which aid in quicker reaction times. Scientists have concluded that elite-level sprinting is virtually impossible in the absence of the ACTN3 protein, a \"speed gene\" most common among persons of West African descent that renders fast twitch muscle fibers fast. Top sprinters of differing ancestry, such as Christophe Lemaitre, are believed to be exceptions in that they too likely have the genes favourable for sprinting.\n\nMany Nilotic groups also excel in long and middle distance running. Jon Entine has argued that this sporting prowess stems from their exceptional running economy. This in turn is a function of slim body morphology and slender legs, a preponderance of slow twitch muscle fibers, a low heart rate gained from living at high-altitude, as well as a culture of running to school from a young age. A study by Pitsiladis et al. (2006) questioning 404 elite distance runners from Kenya found that 76% of the international-class respondents hailed from the Kalenjin ethnic group and that 79% spoke a Nilotic language.\n\nJoseph L. Graves argues that Kenyan athletes from the African Great Lakes region who have done well in long distance running all have come from high-altitude areas, whereas those from low-altitude areas do not perform particularly well. He also argues that Koreans and Ecuadorians from high-altitude areas compete well with Kenyans in long-distance races. This suggests that it is the fact of having trained in a high altitude, combined with possible local level physiological adaptations to high-altitude environments that is behind the success in long distance running, not race. Similarly, Graves argues that while it is superficially true that most of the world recordholders in the 100-metre dash are of West African heritage, they also all have partial genetic heritage from Europe and Native America, they have also all trained outside of West Africa, and West African nations have not trained any top-level runners. Graves says these factors make it impossible to say to which degree the success is best attributed to genetic or to environmental factors.\n\nVarious individuals, including scholars and sportswriters, have commented on the apparent overrepresentations and underrepresentations of different races in different sports. African Americans accounted for 75% of players in the National Basketball Association (NBA) near the end of 2008. According to the latest National Consortium for Academics and Sports equality report card, 65% of National Football League players were African Americans. However, in 2008, about 8.5% of Major League Baseball players were African American (who make up about 13% of the US population, 6.5% male, no women play in MLB), and 29.1% were Hispanics of any race (compared with about 16% of the US population). In 2015, only about 5% of the National Hockey League (NHL) players are black or of mixed black heritage.\n\nNCAA sports have mirrored the trends present in American professional sports. During the 2005–2006 season, black males comprised 46.9 percent of NCAA Football Bowl Subdivision (FBS) and 58.9 percent of NCAA Division I basketball. The NCAA statistics show a strong correlation between percentage of black athletes within a sport and the revenue generated by that sport. For example, University of North Carolina's 2007–2008 men's basketball team (the team was 59% black relative to the 3.7% black population of the institution as a whole) generated $17,215,199 in revenue, which comprised 30 percent of the school's athletic revenue for the year. Given NCAA rules prohibiting the payment of players, some have come to see the structure of NCAA athletics as exploitative of college athletes. Some believe that since black athletes comprise a high percentage of athletes in high revenue college sports (FBS football and Division I Men's basketball), they are therefore the biggest losers in this arrangement. Billy Hawkins argues that \"the control over the Black male's body and profiting off its physical expenditure is in the hands of White males.\" His position refers to a very high percentage of Division I universities controlled by white administrations that prosper greatly from the free labor produced by the revenue sports that are heavily populated by black athletes. This claim is substantiated by statistics, such as the 2005–2006 NCAA Division I Men's Basketball Tournament in which games started, and minutes played for black athletes were over double that of their white counterparts, with 68.7 percent of scoring in the tournament coming from black players.\n\n\"Black athletic superiority\" is the theory that black people possess certain traits that are acquired through genetic and/or environmental factors that allow them to excel over other races in athletic competition. Whites are more likely to hold these views; however, some blacks and other racial affiliations do as well. A 1991 poll in the United States indicated that half of the respondents agreed with the belief that \"blacks have more natural physical ability\".\n\nVarious theories regarding racial differences of black and white people and their possible effect on sports performance have been put forth since the later part of the nineteenth century by professionals in many different fields. In the United States, attention to the subject faded over the first two decades of the twentieth century as black athletes were eliminated from white organized sport and segregated to compete among themselves on their own amateur and professional teams. Interest in the subject was renewed after the 1932 Summer Olympics in Los Angeles and Jesse Owens's record-breaking performances at the 1935 Big Ten Track Championships.Regarding Jesse Owen’s impressive four-gold medal performance in the following 1936 Olympics, the then U.S head coach remarked that “The Negro excels. It was not long ago that his ability to sprint and jump was a life-and-death matter to him in the jungle. His muscles are pliable, and his easy going disposition is a valuable aid to the mental and physical relaxation that a runner and jumper must have.”\n\nIn 1971, African-American sociologist Harry Edwards wrote: \"The myth of the black male's racially determined, inherent physical and athletic superiority over the white male, rivals the myth of black sexual superiority in antiquity.\"Later in 2003, in \"The Journal of Blacks in Higher Education,\" the JBHE Foundation published an article where they pushed back against this idea of a “black gene” leading to black superiority in athletics, a concept referred to here as “Racist Theory”. The JBHE contended that “If there is a “black gene” that leads to athletic prowess, why then do African Americans, 90 percent of whom have at least one ancestor, outperform blacks from African nations in every sport except long distance running?”  \n\nJohn Milton Hoberman, a historian and Germanic studies professor at the University of Texas at Austin, has acknowledged that disparities in certain athletic performances exist. He has asserted that there is no evidence to confirm the existence of \"black athletic superiority\".\n\nIn the United States, East Asians are stereotyped as being physically and athletically inferior to other races. This has led to much discrimination in the recruitment process of professional American sports, which contributes to Asian American athletes being highly underrepresented in the majority of professional sports teams (a fact that has been noted by many sources). Professional basketball player Jeremy Lin believed that one of the reasons why he wasn't drafted by a NBA team was his race. This belief has been reiterated by sports writer Sean Gregory of \"Time magazine\" and NBA commissioner David Stern. In 2012, despite making up 6% of nation's population Asian American athletes only represented 2% of the NFL, 1.9% of the MLB and less than 1% of the NBA and NHL. Brandon Yip was the only player of Chinese descent playing professional hockey in the NHL in 2011. Basketball should be a sport that's noted for the fact that it has one of the lowest amounts of Asian athletes being represented despite the fact that the sport's color barrier was broken by an Asian American athlete back in 1947 named Wataru Misaka who was the first American racial minority to play in the NBA.\n\nIn American sports, there are and has been a higher representation of Asian American athletes who are of mixed racial heritage in comparison to those of full racial heritage such as the case with former football player Roman Gabriel who was the first Asian-American to start as an NFL quarterback. Another fact to note is that majority of Asian American athletes who are currently drafted/recruited to compete professionally tend to be in sports that require little to no contact.\n\nThe idea among Chinese people that \"genetic differences\" cause \"Asian athletes\" to be \"slower at sprinting\" than \"their American, African or European rivals\" is \"widely accepted\". The \"People's Daily\", a Chinese newspaper, wrote that Chinese are \"suited\" to sports that draw upon \"agility and technique\", such as table tennis, badminton and gymnastics. The newspaper said that Chinese people have \"congenital shortcomings\" and \"genetic differences\" that meant that they are disadvantaged at \"purely athletic events\" when competing against \"black and white athletes\". The success of hurdler Liu Xiang was explained by the hurdles event requiring technique which fit with the stereotype that Chinese are disciplined and intelligent.\n\nLi Aidong, a researcher with the China Institute of Sports Science, said that sports coaches believed that Chinese athletes could have success in long jumping, high jumping and race walking. However, Li doubted that Chinese could compete in \"pure sprinting\", although there did not exist any \"credible scientific studies\" which supported the idea that \"Asians\" were disadvantaged in \"sprinting\". Professional sprinters Su Bingtian of China and Yoshihide Kiryū of Japan have contradicted this view of East Asians struggling to achieve quick footspeed, as both have broken the 10-second barrier in the 100 m and Su has ranked in the top five all-time fastest runners over 60 metres.\n\nA 1994 examination of 32 English sport/exercise science textbooks found that seven suggested that there are biophysical differences due to race that might explain differences in sports performance, one expressed caution with the idea, and the other 24 did not mention the issue.\n\nIn \"Stuck in the Shallow End: Education, Race, and Computing\", UCLA researcher Jane Margolis outlines the history of segregation in swimming in the United States to show how blacks have been affected up to the present day by inadequate access to swimming facilities and lessons. Margolis asserts that physiological differences between ethnic groups are relatively minor and says: \"In most cases of segregation, stereotypes and belief systems about different ethnic gender groups' genetic make-up and physical abilities (and inabilities) emerge to rationalize unequal access and resulting disparities.\" According to Margolis, views regarding \"buoyancy problems\" of African Americans are merely part of folklore which have been passed down from generation to generation. Joan Ferrante, a professor of sociology at Northern Kentucky University, suggests that geographic location, financial resources, and the influence of parents, peers, and role models are involved in channeling individuals of certain races towards particular sports and away from others.\n\nElite athletic capacity has also been correlated with differing patterns of haplogroup inheritance. Moran et al. (2004) observed that among Y-DNA (paternal) clades borne by elite endurance athletes in Ethiopia, the E*, E3*, K*(xP), and J*(xJ2) are positively correlated with elite athletic endurance performance, whereas the haplogroup E3b1 is significantly less frequent among the elite endurance athletes.\n\nCiting haplogroup data from various previous studies, Ahmetov and Fedotovskaya (2012) report that the mtDNA (maternal) haplogroups I, H, L0, M*, G1, N9, and V have been positively correlated with elite athletic endurance performance, whereas the mtDNA haplogroups L3*, B, K, J2, and T are negatively correlated with athletic endurance performance. Japanese sprinters were also found to have a higher distribution of the mtDNA F.\n\nThe baseball color line, which included separate Negro league baseball, was one example of racial segregation in the United States.\n\nIn the United States, a study found that a form of racial discrimination exists in NBA basketball, as white players received higher salaries than do blacks related to actual performance. Funk says this may be due to viewer discrimination. Viewership increases when there is greater participation by white players, which means higher advertising incomes. This explains much of the salary gap.\n\nResearchers have looked at other evidence for sports consumer discrimination. One method is comparing the price of sports memorabilia, such as baseball cards. Another is looking at fan voting for all-star teams. Still another is looking at willingness to attend sporting events. The evidence is mixed, with some studies finding bias against blacks and others not. A bias, if it exists, may be diminishing and possibly disappearing, according to a study on fan voting for baseball all-star teams.\n\nDebuting with the Brooklyn Dodgers in 1947, Jackie Robinson was the first black Major League Baseball player of the modern era.\n\nThe under-representation of blacks in U.S. baseball ended during the early years of the civil rights movement. The representation of different races in Major League Baseball has been increasing since 1947 according to Mark Armour and Daniel R Levitt of the Society for American Baseball Research. According to their research, African American representation reached its peak in 1984 when it reached 18.4%. However, the African American representation has been steadily decreasing since that point. As of 2016, the African American representation was down to 6.7%.\n\nAccording to Armour and Levitt, the Latino representation has been steadily increasing since 1947. That year, the representation was only at 0.7%. Since that time, the Latino representation in baseball has increased substantially. As of 2016, the Latino representation was at 27.4%.\n\nAsian American representation in baseball has been much less abundant throughout the game’s history according to Armour and Levitt. Their representation in the Major League did not get over 1% until 1999 when their representation was at 1.2%. While the representation is increasing, it is doing so significantly slower than the other races. As of 2016 Asian American representation was only at 2.1%, a small increase from 1999.\n\nAccording to Armour and Levitt, Whites make up the largest portion of the different races represented in the Major League. However, their representation has been steadily declining as the African American, Asian, and Latino representation has been steadily on the rise. The Society for American Baseball research shows that white representation was at 98.3% in 1947. Since then, representation has decreased to 63.7% in 2016.\n\nIn a journal titled Using Giddens's Structuration Theory to Examine the Waning Participation of African Americans in Baseball, it says “Numerous studies have shown that African-American youths are more likely than Whites to be encouraged and even directed to play basketball over other sports.\"\n\nAlthough Japanese-American Wataru Misaka broke the National Basketball Association's color barrier in the 1947–48 season when he played for the New York Knicks, 1950 is recognized as the year the NBA integrated. That year African-American players joined several teams; they included Chuck Cooper with the Boston Celtics, Nat \"Sweetwater\" Clifton with the New York Knicks, and Earl Lloyd with the Washington Bullets.\n\nBlack players participated in the National Football League from its inception in 1920; however, there were no African-American players from 1933 to 1946. There is a great deal of speculation as to why this “gentleman’s agreement”, as it became to be called, was implemented during this era. Some argue that it was purely because of the Great Depression. Jobs were difficult to come by, and thus race relations became increasingly strained as African-Americans, and other minorities, became perceived as “threats”. Finally, in 1946, the Los Angeles Rams broke this unofficial “agreement” and drafted Kenny Washington along with Woody Strode in the same year. The final NFL team to break this agreement was the Washington Redskins, who signed Bobby Mitchell in 1962.\n\nIn October 2018, George Taliaferro, the first African American who played in NFL died at the age of 91. While George was the first African American drafted to play in the NFL, the first African American would not be drafted as the Quarterback until 1953, when Willie Thrower was drafted to play with the Chicago Bears. It wouldn’t be for another 14 years, 1967, until the first African American, Emlen Tunnell, would be elected for the NFL Hall of Fame.\n\nIn 1961, the \"Caucasians only\" clause was struck from the Professional Golfers' Association of America constitution. \n\nThroughout the game’s history, golf has not included many African-American players.They were often denied the opportunity to golf. However, many found a way to play the game anyway. According to an article by the African-American Registry titled African-Americans and Golf, a Brief History, “the Professional Golf Association of America (PGA) fought hard and until 1961, successfully maintained its all-white status. Black golfers (then) created their own organization of touring professionals.”\n\nTiger Woods has had a major impact on the game of golf, especially among minorities. The article, African-Americans and Golf, a Brief History, states “With the assent of Tiger Woods and his golf game comes an increased interest and participation from young minorities in the game. He himself envisions this impacting in the next ten years as they come of age and develop physically as well.\" Woods hopes minority participation will continue to increase in the future.\n\nAfrican American participation in golf has been increasing. In a journal titled African American Culture and Physical Skill Development Programs: The Effect on Golf after Tiger Woods, it says “Smith (1997) reported data from a National Golf Foundation (NDF) study in the United States indicating there are 676,000 African-American golfers (27% of the 24.7 million golfers).\"\n\nAs African-American participation increased, Asian participation in professional golf has also increased. According to an article by Golfweek titled Record Number of Asian Golfers Compete for Masters Glory, there were 10 golfers which was a tournament record. \n\nAccording to the article Where are all the black golfers? Nearly two decades after Tiger Woods’ arrival, golf still struggles to attract minorities, As of 2013 there were 25.7 million golfers which are composed of 20.3 million whites, 3.1 million Hispanics, 1.3 million African-Americans, and 1 million Asian-Americans. The lack of diversity is still very apparent in golf today.\n\nReferring to quarterbacks, head coaches, and athletic directors, Kenneth L. Shropshire of the Wharton School of the University of Pennsylvania has described the number of African Americans in \"positions of power\" as \"woefully low\". In 2000, 78% of players in the NBA were black, but only 33% of NBA officials were minorities. The lack of minorities in positions of leadership has been attributed to racial stereotypes as well \"old boy networks\" and white administrators networking within their own race. In 2003, the NFL implemented the Rooney Rule, requiring teams searching for a new head coach to interview at least one minority candidate.\n\nSimilar to the discrepancy between participation and leadership of blacks in American professional sports leagues, NCAA sports also have had a low percentage of administrators and coaches relative to the number of athletes. For example, during the 2005–2006 academic year, high revenue NCAA sports (basketball and football) had 51 percent black student athletes, whereas only 17 percent of head coaches in the same high revenue sports were black Also, in the same 2005–2006 year, only 5.5 percent of athletic directors at Division I \"PWIs\" (Primarily White Institutions), were black. Terry Bowden, a notable white Division I football coach, suggests that the reason many university presidents will not hire black coaches is \"because they are worried about how alumni and donors will react.\" Bowden also refers to the \"untapped talent\" existing within the ranks of assistant coaches in Division I football. The data backs up this claim, with 26.9 percent of Division I assistant coaches during the 2005-06 year in men's revenue sports being black, a notably higher percentage than of head coaches. In terms of administrative positions, they have been concentrated largely in the hands of whites. As recently as 2009, 92.5 percent of university presidents in the FBS were white, 87.5 percent of athletic directors were white, and 100 percent of the conference commissioners were white. Despite these statistics, black head coaches have become more prevalent at the FBS level. As of 2012, there are now 15 black head coaches in FBS football, including now 3 in the SEC, a conference that did not hire its first black head coach until 2003.\n\nIn 1960, the Houston Oilers implemented a policy at Jeppesen Stadium to segregate the black fans from the white fans. Clem Daniels, Art Powell, Bo Roberson, and Fred Williamson of the Oakland Raiders refused to play in a stadium that had segregated seating. The 1963 game against the New York Jets was relocated to a different stadium.\n\nThe use of Native American names and imagery for sport mascots or in franchise memorabilia is an issue of ongoing discussion and controversy in American sports, as some Native American representatives have objected to such use without explicit negotiation and permission.\n\nAccording to William Jeynes, a professor of education at California State University, Long Beach, the gathering at the first Thanksgiving in the United States was an attempt to create racial harmony through games and sporting contests that included running, shooting and wrestling. Huping Ling, a professor of history at Truman State University, has asserted that the participation of Chinese students in sports helped break local stereotypes in the St. Louis area during the 1920s.This history of racial tension in the competition between whites and minority groups shows an attempt to prove the humanity, equality, and even occasionally their superiority on the playing field. By doing so, groups of minorities hoped that sports would serve as a source for racial pride that would eventually lead to upward social mobility. However, as early as 1984, criticism has been levied against these ideas. Sports sociologist Harry Edwards openly criticized African Americans as being “co-conspirators” in their own children’s exploitation by the white dominated sports establishment. Despite the the perception of a white dominated sports establishment, research has shown that there is greater emphasis on sports as a potential career path in the African American community compared to the White community. Edwards continued by arguing that placing so much emphasis on sports achievement as a way for minority groups, specifically referring to African Americans, to achieve some level of prominence is de-emphasizing the importance of intellectual pursuits. Despite the conflicting perceptions of sports as a harmonizing instrument, many researchers still believe that not much has changed to alleviate the racially tense landscape many believe to be inherent in current day society. \n\nRacial remarks have been made about athletes of color throughout history. Radio host Don Imus described the Rutgers University women's basketball team as \"nappy-headed hos\" on his radio program \"Inmus in the Morning\" in 2007. Later on he proclaimed that the match-up between Rutgers and their opponents looked like a showdown of the \"jigaboos versus the wannabes.\" \n\nIn 1988 sports commentator Jimmy \"the Greek\" Snyder proclaimed his theory on why Black Americans are more athletic than White Americans:\n\n\"The black is a better athlete to begin with because he's been bred to be that way, because of his high thighs and big thighs that goes up into his back, and they can jump higher and run faster because of their bigger thighs and he's bred to be the better athlete because this goes back all the way to the Civil War when during the slave trade … the slave owner would breed his big black to his big woman so that he could have a big black kid …\"\n\nSnyder was later fired by CBS. \n\nSherman Maxwell was the first African American sports broadcaster. He began his career in 1929 on WNJ radio. He was known as \"the voice of Newark\". \n\nThe US-set films \"Hoosiers\" and \"Rudy\" have been described as memorializing the \"golden age of sports\" as a time of white prevalence and dominance, while \"Glory Road\" showed a white coach helping to dissolve the color barrier in college basketball.\n\n\"Invictus\" deals with the subject of the Rugby World Cup in post-apartheid South Africa.\n\nInequality in sport for the Aboriginal Australians exists due to material barriers. A 2007 report by the Australian Human Rights Commission suggested that fear of \"racial vilification\" was partly responsible for the under-representation of Aboriginal and other ethnic groups in Australian sports.\n\nIn South Africa, black representation on the cricket and rugby national sports teams is ensured via the introduction of quotas.\n\nDiscussions of race and sports in the United States, where the two subjects have always been intertwined in American history, have focused to a great extent on African Americans. Depending on the type of sport and performance level, African Americans are reported to be over- or under-represented. African Americans compose the highest percentage of the minority groups active at the professional level, but are among those who show the lowest participation overall.\n\nIn 2013, while 2.8% of full-time degree-pursuing undergraduates were black men, the group comprised 57% of college football teams, and 64% of men's basketball players. While blacks predominate in football and basketball, whites predominate in all other regulated sports.\n\nA 2001 study indicated that black high school students play harder than white students, because the former were more likely to perceive sports as a venue to success. The study denies that racial characteristics, per se, is a factor in success in sports.\n\nFor all races and sports, from 3.3% (basketball) to 11.3% (ice hockey) are successful in making the transition from high school varsity to an NCAA team. From .8% (men's ice hockey) to 9.4% (baseball) successfully transition from NCAA to professional teams. Therefore, the overall success rate of high school athletes progressing to professional athletes was from .03% (men and women's basketball) to .5% (baseball). The annual number of NCAA athletes drafted into professional sports annually varied from seven (men's ice hockey) to 678 (baseball).\n\nUnlike black athletes, blacks as a group have not perceived sports as an important venue to prosperity.\nThere are higher participation rates by blacks as well as higher numbers of people in non-athletic endeavor, such as policy, teaching, physicians, lawyers, engineers, and architects.\n\nAthletics have been increasingly subsidized by tuition. Only one in eight of the 202 Division I colleges actually netted more money than they spent on athletics between the years 2005 and 2010. At the few money making schools, football and sometimes basketball sales support the school's other athletic programs. The amount spent on an athlete in one of the six highest-profile football conferences, on average, is six times more than the amount spent to educate the non-athlete. Spending per student varied from $10,012 to $19,225; cost per athlete varied from $41,796 to $163,931.\n\n\n\n"}
{"id": "158691", "url": "https://en.wikipedia.org/wiki?curid=158691", "title": "Radical Faeries", "text": "Radical Faeries\n\nThe Radical Faeries are a loosely affiliated worldwide network and countercultural movement seeking to redefine queer consciousness through secular spirituality. Sometimes deemed a form of modern Paganism, the movement also adopts elements from anarchism and environmentalism.\n\nRejecting hetero-imitation, the Radical Faerie movement began during the 1970s sexual revolution among gay men in the United States. The movement has expanded in tandem with the larger gay rights movement, challenging commercialization and patriarchal aspects of modern LGBT life while celebrating eclectic constructs and rituals. Faeries tend to be fiercely independent, anti-establishment, and community-focused.\n\nThe Radical Faerie movement was founded in California in 1979 by gay activists Harry Hay, Mitch Walker, John Burnside, and Don Kilhefner, who wanted to create an alternative to what they saw as the assimilationist attitude of the mainstream U.S. gay community. Influenced by the legacy of the counterculture of the 1960s, they held the first Spiritual Conference for Radical Fairies in Arizona in September 1979. From there, various regional Faerie Circles were formed, and other large rural gatherings organized. Although Walker and Kilhefner broke from Hay in 1980, the movement continued to grow, having expanded into an international network soon after the second Faerie gathering in 1980.\n\nToday Radical Faeries embody a wide range of genders, sexual orientations, and identities. Sanctuaries and gatherings are generally open to all, though several gatherings still focus on the particular spiritual experience of man-loving men co-creating temporary autonomous zones. Faerie sanctuaries adapt rural living and environmentally sustainable concepts to modern technologies as part of creative expression. Radical Faerie communities are sometimes inspired by indigenous, native or traditional spiritualities, especially those that incorporate genderqueer sensibilities.\n\nHay's biographer Stuart Timmons described the Faeries as a \"mixture of a political alternative, a counter-culture, and a spirituality movement.\" Peter Hennan asserted that the Faeries contained elements of \"Marxism, feminism, paganism, Native American and New Age spirituality, anarchism, the mythopoetic men's movement, radical individualism, the therapeutic culture of self-fulfillment and self-actualization, earth-based movements in support of sustainable communities, spiritual solemnity coupled with a camp sensibility, gay liberation and drag.\" \n\nThe Radical Faerie movement was a reaction against the social emptiness that many gay men felt was present both in the heterosexual establishment and the assimilationist gay community. As one Faerie commented, in his opinion mainstream gay culture was \"an oppressive parody of straight culture\", taking place primarily in bars and not encouraging people to \"form bonds or care for each other\". In contrast, the Faeries \"live their sexuality in a way that is very connected to the earth.\"\nFaeries represent the first spiritual movement to be both \"gay centered and gay engendered\", where gayness is central to the idea, rather than in addition to, or incidental to a pre-existing spiritual tradition. The Radical Faerie exploration of the \"gay spirit\" is central, and that it is itself the source of spirituality, wisdom, and initiation. Founding Faerie Mitch Walker claims that \"because of its indigenous, gay-centered nature, the Radical Faerie movement pioneers a new seriousness about gayness, its depth and potential, thereby heralding a new stage in the meaning of Gay Liberation.\"\n\nIn keeping with hippie, neopagan, and eco-feminist trends of the time, gatherings were held out-of-doors in natural settings. To this end, distinct Radical Faerie communities have created sanctuaries that are \"close to the land\".\n\nIn her study of the Pagan movement in the U.S., journalist Margot Adler noted that the Faeries placed a great emphasis on the \"transformative power of play\", believing that playful behavior had a role within ritual that could lead to an altered state of consciousness. In keeping with this, they were often the \"public anarchists\" at Pagan events, challenging the formalized ritual structures propagated by other Pagans; at one event in the 1980s, a group of Faeries stood at the entrance to the ritual circle, calling out \"Attention! No spontaneity! We're the spontaneity police!\" as a way of parodying what they saw as formalised trends within Pagan ritual. Adler also noted similar trends within other Pagan groups, such as the Reformed Druids of North America and the Erisian movement.\n\nBefore the Radical Faeries were started or there was any talk about the faeries, there had been many studies done by psychologists and other scientists on gay religion. The Radical Faerie movement emerged from the counterculture of the 1960s, which had created a wider cultural drift and encouraged greater experimentation in spiritual matters throughout the English-speaking world, in particular in United States, Australia, Canada and Western Europe. There were some gay-oriented spiritual movements that preceded the Radical Faeries; in 1976, the gay activist and writer Arthur Evans founded \"the Faery Circle\" in his Haight Street apartment in San Francisco, in which he and twelve other gay men followed a form of gay-oriented contemporary Paganism devoted to the god Dionysus. Evans would go on to publish his ideas on the spiritual history of gay men in the gay magazines \"Out\" and \"Fag Rag\" and the book \"Witchcraft and the Gay Counterculture\" (1978). Evans' work would be cited as an influence on a number of Radical Faeries. Another influence was the Whole Earth Catalog, an American counterculture catalog published by Stewart Brand between 1968 and 1972, and occasionally thereafter, until 1998; the catalogs listed all sorts of products for sale that were useful for a creative or self-sustainable lifestyle. Another key influence was the RFD Collective, which had been founded in Iowa in 1974. Encouraging a back-to-the-land ethos among gay men, it critiqued the \"adamant heterosexuality\" of existing rural magazines and so began publishing \"RFD: A Magazine for Country Faggots\". Gay rights activist Harry Hay had first published an article in \"RFD\" in 1975, which he had devoted to his recently deceased mother.\n\nThe Radical Faerie movement was founded by a cabal of three gay men: Harry Hay, Don Kilhefner, and Mitch Walker. Hay was a veteran of gay rights activism, having been a longstanding activist in the Communist Party USA prior to becoming a founding member of the Mattachine Society in 1950. After being publicly exposed as a Marxist in 1953, Hay stepped down from the Society's leadership, shortly before the other founders were forced to resign by more conservative members. Hay continued his involvement in gay activism, involving himself in the foundation of the Los Angeles branch of the Gay Liberation Front (GLF) in 1969, before leaving this to move to New Mexico. Walker was from a middle-class Jewish household in Hawthorne, California, and went on to study psychology at UCLA, focusing on Jungian psychology. For his master's thesis at Lone Mountain College he proposed a gay sex guide containing historical information and psychological reassurance; the concept was rejected by the faculty committee but was subsequently published as \"Men Loving Men: A Gay Sex Guide and Consciousness Book\" (1977). Describing himself as \"a gay shaman\", he was subsequently introduced to Hay in 1976.\n\nRaised into an Amish-Mennonite community, Kilhefner had studied at Howard University where he joined the anti-Vietnam War movement and the Student Nonviolent Coordinating Committee. After university, he spent time in Ethiopia with the Peace Corps before joining the Peace and Freedom Party and becoming a leading figure in the GLF from 1969 to 1971. As the GLF evolved into the L.A. Gay Community Services Center, Kilhefner became its first executive director. As it grew, it sought the support of wealthy gay people to finance its social work and public relations, with Kilhefner being concerned at its increasingly assimilationist stance and taking a leave of absence in 1976. He proceeded to enter into a retreat run by Baba Ram Dass, where he got into an extended conversation with Hay in May 1978.\n\nIn Autumn 1978, the therapist Betty Berzon invited the three men to lead a workshop on \"New Breakthroughs in the Nature of How We Perceive Gay Consciousness\" at the annual conference of the Gay Academic Union, held at the University of Southern California in Los Angeles. This event convinced Hay and his partner John Burnside that they should leave their home in New Mexico and move to Los Angeles, where they settled into a 1920s house on the eastern edge of Hollywood. The three then decided to organise an outdoor conference at which they could teach other gay men about their ideas regarding gay consciousness. Kilhefner identified an ideal location from an advert in \"The Advocate\"; the Sri Ram Ashram was a gay-friendly spiritual retreat in the desert near Benson, Arizona, owned by an American named Swami Bill. Hay, Kilhefner, and Walker visited to check its suitability, and although Hay disliked Bill and didn't want to use the site, the others insisted.\nTheir conference, set for Labor Day 1979, was to be called the \"Spiritual Conference for Radical Fairies\", with the term \"Radical Faerie\" having been coined by Hay. The term \"Radical\" was chosen to reflect both political extremity and the idea of \"root\" or \"essence\", while the term \"Faerie\" was chosen in reference both to the immortal animistic spirits of European folklore and to the fact that \"fairy\" had become a pejorative slang term for gay men. Initially, Hay rejected the term \"movement\" when discussing the Radical Faeries, considering it to instead be a \"way of life\" for gay males, and he began referring to it as a \"not-movement\". In organising the event, Hay handled the political issues, Burnside the logistics and mechanics, Kilhefner the budgetary and administrative side, and Walker was to be its spiritual leader. A flier advertising the event was released which proclaimed that gays had a place in the \"paradigm shift\" of the New Age, and quoted Mark Satin and Aleister Crowley alongside Hay; these fliers were sent out to gay and leftist bookstores as well as gay community centres and health food stores.\n\nAround 220 men turned up to the event, despite the fact that the Ashram could only accommodate around 75. Hay gave a welcoming speech in which he outlined his ideas regarding Subject-SUBJECT consciousness, calling on those assembled to \"throw off the ugly green frogskin of hetero-imitation to find the shining Faerie prince beneath\". Rather than being referred to as \"workshops\", the events that took place were known as \"Faerie circles\", and were on such varied subjects as massage, nutrition, local botany, healing energy, the politics of gay enspiritment, English country dancing, and auto-fellatio. Those assembled took part in spontaneous rituals, providing invocations to spirits and performing blessings and chants, with most participants discarding the majority of their clothes, instead wearing feathers, beads, and bells, and decorating themselves in rainbow makeup. Many reported feeling a change of consciousness during the event, which one person there described as \"a four day acid trip – without the acid!\". On the final night of the gathering, they put together a performance of the Symmetricon, an invention of Burnside's, while Hay gave a farewell speech.\n\nAfter Hay and the others returned to Los Angeles, they received messages of thanks from various participants, many of whom asked when the next Faerie gathering would be. Hay decided to found a Faerie circle in Los Angeles that met at their house, which became known as \"Faerie Central\", devoting half their time to serious discussion and the other half to recreation, in particular English circle dancing. As more joined the circle, they began meeting in West Hollywood's First Presbyterian Church and then the olive grove atop the hill at Barnsdall Park; however they found it difficult to gain the same change of consciousness that had been present at the rural gathering. The group began to discuss what the Faerie movement was developing into; Hay encouraged them to embark on political activism, using Marxism and his Subject-SUBJECT consciousness theory as a framework for bringing about societal change. Others however wanted the movement to focus on spirituality and exploring the psyche, lambasting politics as part of \"the straight world\". Another issue of contention was over what constituted a \"Faery\"; Hay had an idealized image of what someone with \"gay consciousness\" thought and acted like, and turned away some prospective members of the Circle because he disagreed with their views. One prospective member, the gay theatre director John Callaghan, joined the circle in February 1980, but was soon ejected by Hay after he voiced concern about hostility toward heterosexuals among the group.\n\nThe second Faerie gathering took place in August 1980 in Estes Park near Boulder, Colorado. Twice as long and almost twice as large as the first, it became known as Faery Woodstock. It also exhibited an increasing influence from the U.S. Pagan movement, as Faeries incorporated elements from Evans' \"Witchcraft and the Gay Counterculture\" and Starhawk's \"The Spiral Dance\" into their practices. At that gathering, Dennis Melba'son presented a shawl that he had created with a crocheted depiction of the Northwest European Iron Age deity Cernunnos on it; the shawl became an important symbol of the Faeries, and would be sent from gathering to gathering over subsequent decades. There, Hay publicly revealed the founding trio's desire for the creation of a permanent residential Faerie community, where they could grow their own crops and thus live self-sustainably. This project would involve setting up a non-profit corporation to purchase property under a community land tryst with tax-exempt status. They were partly inspired by a pre-existing gay collective in rural Tennessee, Short Mountain. The gathering was also attended by an increasing number of men from outside of America, particularly Canada, but also from Australia, Norway, France and Germany, many of whom returned to their countries of origin to establish Faerie communes, such as the Wellington Boot, Common Ground etc. in Australia.\nThere was some antagonism between Hay and Walker from the beginning of their venture, in part stemming from personality differences. It was made worse by their differing approaches to Jungian psychology; Walker saw analytical psychology as central to his world view and believed that it could be utilised to aid the gay movement, whereas Hay was disdainful of it. As the Los Angeles Circle grew, Kilhefner also became annoyed with Hay over the latter's tendency to dominate conversations both in and out of the Circle, as well as his proselytizing attitude. In 1980 Walker secretly formed the \"Faerie Fascist Police\" to combat \"Faerie fascism\" and \"power-tripping\" within the Faeries. He specifically targeted Hay: \"I recruited people to spy on Harry and see when he was manipulating people, so we could undo his undermining of the scene.\"\n\nAt a winter 1980 gathering in southern Oregon designed to discuss acquiring land for a Faerie sanctuary, a newcomer to the group, coached by Walker, confronted Harry about the power dynamics within the core circle. In the ensuing conflict, the core circle splintered. Plans for the land sanctuary stalled and a separate circle formed. The core circle made an attempt to reconcile, but at a meeting that came to be known as \"Bloody Sunday\", Kilhefner quit, accusing Hay and Burnside of \"power tripping\", while Walker resigned. Walker and Kilhefner formed a new Los Angeles-based gay spiritual group called Treeroots which promoted a form of rural gay consciousness associated with Jungian psychology and ceremonial magic. However, despite the division among its founders, the Radical Faerie movement continued to grow, largely as a result of its egalitarian structure, with many participants being unaware of the squabbles. Hay himself continued to be welcomed at gatherings, coming to be seen as an elder statesman in the movement.\n\nThe first Faerie gathering in Australia was held in January 1981, at Tony Newman's Whole Earth Dream Farm near Ourimbah (established in 1974), inspired by the reporting of the second Faerie gathering in Colorado by RFD, and held in conjunction with Sydney's Gay Men's Rap, although this first gathering did not generate any ongoing Faerie activity. A subsequent and unconnected Faerie gathering was held on 9–12 April 1982, at Mandala, a gay spiritual commune established near Uki in Northern NSW in 1974 by David Johnstone. This second gathering included Faeries who had attended the second and third gatherings in the United States, and led to continued growth of the Radical Faeries in Australia, and repeated attempts to establish Faerie communes, such as Common Ground (Clarence River Valley), and eventually the ongoing commune Faerieland, near Nimbin, NSW.\n\nGuided by Mica Kindman, Lloyd Fair, Cass Brayton, and Will Roscoe, the San Francisco Faerie Circle had formed a non-profit corporation under the name of NOMENUS (varyingly interpreted as \"No Men Us\", \"No Menace\", and \"No Menus\"), supported by Hay. They raised enough money to put a down payment on some land from a 1983 gathering in Napa, however decided against forming a self-sufficient community, instead choosing to purchase a smaller piece of land that could be stationed by a few caretakers and which could house regular gatherings. In 1987 they purchased Magdalene Farm – a 80-acre property near Grant's Pass, Oregon – from George Jalbert, who has unsuccessfully hoped to establish his own rural gay commune there over the preceding decade.\n\nThroughout the 1980s the Radical Faerie movement had spread out from the United States and had gatherings in Canada, Australia, the United Kingdom, and Italy, as well as Folleterre in France.\n\nBlack Leather Wings is an organization for spiritual gay leathermen, mostly Pagans, and is a circle within the Radical Faeries. The San Francisco South of Market Leather History Alley consists of four works of art along Ringold Alley honoring leather culture; it opened in 2017. One of the works of art is metal bootprints along the curb which honor 28 people (including Mark Thompson, among other things a co-founder of Black Leather Wings, and Alexis Sorel, co-founder of The 15 and Black Leather Wings member), who were an important part of the leather communities of San Francisco.\n\nRural land or urban buildings where Faeries come together to live a communal life are called sanctuaries, which may host gatherings from time to time. Faerie spirit has sparked dedicated groups to develop and maintain sanctuaries internationally.\n\n\nFaeries also collaborate with friends in non-sanctuary, non-Faerie spaces, including Work Hard Stay Hard in rural Tennessee or Queer Magic in urban Oregon.\n\nMay Day was a spring time fertility ritual that the Radical Faeries did at sanctuary events to bring in the spring.\n\nParticipants at the 1979 Faerie gathering helped establish the Sisters of Perpetual Indulgence in San Francisco that same year.\n\nFaeries were a contributing influence to John Cameron Mitchell's film \"Shortbus\", including the casting of performance artist Justin Vivian Bond.\n\n\"Queer as Folk\" episode \"Stand Up for Ourselves\" features a storyline where the characters Emmett and Michael attend a rural gathering to discover their \"inner Faerie.\"\n\n\n\n\n"}
{"id": "43005267", "url": "https://en.wikipedia.org/wiki?curid=43005267", "title": "Rise of the Tomb Raider", "text": "Rise of the Tomb Raider\n\nRise of the Tomb Raider is an action-adventure video game developed by Crystal Dynamics. It is the sequel to the 2013 video game, \"Tomb Raider\", and the eleventh entry in the \"Tomb Raider\" series. The game was released by Microsoft Studios for Xbox One and Xbox 360 in 2015. Square Enix released the game for Microsoft Windows and PlayStation 4 in 2016. \n\nIts story follows Lara Croft as she ventures into Siberia in search of the legendary city of Kitezh while battling the paramilitary organization Trinity, which intends to uncover the city's promise of immortality. Lara must traverse the environment and combat enemies with firearms and stealth as she explores semi-open hubs. In these hubs she can raid challenge tombs to unlock new rewards, complete side missions, and scavenge for resources which can be used to craft useful materials. \n\nDevelopment of \"Rise of the Tomb Raider\" closely followed the conclusion of development of the 2013 reboot. Player feedback was considered during development, with the team reducing the number of quick time events and introducing more puzzles and challenge tombs. The team traveled to several locations in Turkey, including Cappadocia, Istanbul and Ephesus, to design Kitezh. Camilla Luddington returned to provide voice and motion-capture work for Lara. Powered by the Foundation engine, the game was also developed by Eidos Montreal and Nixxes Software.\n\n\"Rise of the Tomb Raider\" was announced at E3 2014 by Microsoft Studios. It was revealed as a timed exclusive for Microsoft at Gamescom 2014, which sparked player outrage and widespread criticism from the gaming press and community. The game was critically acclaimed, with critics praising its graphics, gameplay, and characterization; however, some reviewers felt that it did not take enough risks. By November 2017, the game had sold nearly seven million copies. Several downloadable story and content additions have been released for digital purchase. A sequel, \"Shadow of the Tomb Raider\", was released in September 2018.\n\n\"Rise of the Tomb Raider\" is a third-person action-adventure game in which players control Lara Croft, who is on a quest to discover the legendary city of Kitezh. Combat is a major gameplay mechanic; Lara has a large variety of weapons at her disposal (including assault rifles, shotguns, and pistols), some of which have an alternate firing mode. Players may also utilize stealth to progress through portions of the game, using bows and arrows to take out enemies, creating distractions to draw enemy attention away from Lara, or hiding in bushes to evade enemies. Lara can use the environment to fight enemies, shooting explosive barrels, tearing down rope-wrapped structures with rope arrows, or ambushing enemies from high ground. She can also use her pickaxe and combat knife to engage in melee combat with enemies. Completing objectives and side content and eliminating enemies give players experience points (XP). When players collect sufficient XP they level up, receiving a skill point, which can be spent on the game's three skill trees: brawler, hunter and survivor. Brawler enhances Lara's efficiency with weapons, giving her abilities such as retrieving arrows from corpses and a steady aim, as well as boosting her resilience against attack and unlocks new combat skills, such as dodge kill. Hunter gives her an advantage when dealing with the environments and animals. Survivor covers a wide range of skills such as creating incendiary bombs and setting booby traps. Lara learns new languages, enabling her to discover relics (such as coins) which can be traded for new equipment.\nThe game has semi-open hubs for players to explore. In the hubs are items for Lara to collect, including crafting materials and survival caches. These items and collectibles such as relics and documents can be revealed to players using Survival Instinct, a vision mode which highlights items of interest. By collecting the materials, players can craft items with the game's crafting menu; Lara can craft ammunition, poisoned arrows (using death-cap mushrooms), and Molotov cocktails and hand grenades from cans and bottles. The open areas are filled with wildlife, which can be hunted to collect more resources. Players can discover and explore challenge tombs for new skills and outfits. Lara's outfit, which affects her combat performance, can be changed at base camps. The camps allow Lara to change her weapon loadouts, which is where she chooses one of each weapon type she will wield for example choosing which type of bow (Makeshift Longbow or Ancient Horn Bow) or pistol (Semi-Auto Pistol or Heavy Pistol), and are fast travel points which allow players to explore a previously-searched area. The game has side missions and challenges which may give players new equipment, and players navigate intricate environments to progress. Lara can use her pickaxe to climb cliff-like surfaces (such as glaciers) and her rope arrows to create ziplines to access difficult-to-reach areas, and can climb trees and swim. Players solve puzzles during the game, in its main campaign and optional content. The puzzles, based on in-game physics, often connect; players must solve connecting puzzles to solve a larger one.\n\nUnlike the 2013 \"Tomb Raider\" reboot, \"Rise of the Tomb Raider\" lacks a multiplayer mode. It introduces Expeditions, which allow players to replay the game with new constraints and requirements. The game has four modes: Chapter Replay, Chapter Replay Elite, Score Attack, and Remnant Resistance. Chapter Replay and Chapter Replay Elite allow players to replay any level, and Elite allows them to bring already-acquired skills and weapons to the level. Score Attack introduces score combo chains to the game. Remnant Resistance allows players to create custom scenarios, which can be shared with other players. By completing Expeditions, players earn credits which can then be used to purchase digital collectible cards to modify the gameplay. Common cards may be used only once, and foil cards can be used repeatedly. The cards can also be purchased in microtransactions.\n\nOne year after the events of \"Tomb Raider\", archaeologist Lara Croft is struggling to explain her experience of the supernatural on Yamatai and is experiencing posttraumatic stress disorder. Looking for answers, she turns to her late father's research on the lost city of Kitezh and the promise of immortality. His partner, Ana, attempts to warn her that his obsession with Kitezh drove him to ruin and suicide. Lara ignores her and organizes an expedition to Syria, hoping to uncover the tomb of the Prophet of Constantinople, who is a key figure in the Kitezh legend. The tomb is empty, and Lara is interrupted by Trinity—an ancient order of knights turned paramilitary organization investigating the supernatural—and their leader, Konstantin. As she flees, Lara discovers a symbol etched into the tomb which she links to a book on Russian religious history in her father's study at the Croft manor. A Trinity assassin infiltrates the manor and steals the book, prompting Lara and her friend Jonah to go to Siberia. They are separated by an avalanche while climbing a mountain, and Lara is forced to continue alone.\n\nShe discovers that Trinity has made a Soviet-era mine a base of operations in their search for Kitezh. Lara is caught trying to retrieve the book, and is imprisoned with Ana. Konstantin forces her to reveal what she knows by slowly strangling Ana in front of her, but Lara cannot provide useful information. Ana then reveals herself as Trinity's spy, who manipulated her father. She and Konstantin interrogate Lara about the Divine Source, an artifact believed to bestow immortality. Lara escapes and helps Jacob, a stranger who leads her through the mines after she agrees to aid him and his people against Trinity. Jacob is revealed as leader of the Remnant, descendants of the Prophet's followers, and warns her that the Divine Source is not what she expects it to be.\n\nKonstantin's forces repeatedly attack the Remnant, justifying the slaughter as God's will. However, Lara discovers that Ana is dying and seeks the Divine Source to save herself. Jacob and Lara decide that the only way to protect the Divine Source is to retrieve it before Trinity can. Lara recovers the Atlas, an artifact which is a map of Kitezh. She is reunited with Jonah, and they locate the path into the city. Konstantin, aware of Jonah's presence, followed him in the hope of finding Lara. Trinity ambushes them, and Konstantin stabs Jonah and takes the Atlas. Lara brings Jonah to Jacob, who heals him and reveals that he is the Prophet, given immortality by the Divine Source.\n\nWith Trinity advancing on the glacier which looms over Kitezh, Lara is forced to enter the city on a dangerous path. She meets the Deathless Ones, the city's immortal guardians. Reading journals written by a Trinity agent, Lara realizes the truth of Jacob's warning: the Divine Source bestows immortality at the cost of one's self. The Remnant attack the Deathless Ones, giving Lara time to reach the heart of the city. She meets Konstantin, who is blocking the path, and critically wounds him. Before he dies, he says that Lara's father did not commit suicide but was murdered by Trinity. Lara is too late to prevent Ana from retrieving the Divine Source, but Ana is overwhelmed by its power and Lara destroys it. The Deathless Ones perish, and Jacob's immortality is lost. Happy that his death has finally come, he thanks Lara and peacefully disintegrates.\n\nJacob's daughter, Sofia, leads the Remnant. Jonah recovers from his wounds and joins Lara in planning their next expedition, with Lara vowing to investigate more of the world's mysteries and thwart Trinity's plans. In a post-credits scene, two weeks before Lara and Jonah leave Siberia, Lara asks Ana if she killed her father. Ana denies it, admitting that Trinity gave her the order. She is then killed by a sniper, who asks his unseen superior about killing Lara and is ordered to stand down.\n\nIn the \"Baba Yaga\" downloadable content, Lara investigates a disturbance in the Soviet mine. After fighting off a Trinity patrol she finds a young girl, Nadia, hiding in a sawmill. Nadia confides in Lara about her search for her grandfather, Ivan. Ivan disappeared while trying to enter the Wicked Vale, a valley reportedly haunted by Baba Yaga, a witch in Slavic folklore. Ivan blames the witch for the death of his wife, and wants to kill her. Lara is skeptical about Baba Yaga's existence but, since Nadia is injured, agrees to enter the Wicked Vale and find Ivan.\n\nIn the Vale, Lara is exposed to a rare pollen with potent hallucinogenic properties. After stumbling through a forest where she is tormented by visions of her father's suicide, she meets Baba Yaga and a pack of demonic wolves. Lara narrowly escapes with her life and finds herself in a small, Soviet-era outpost. She unearths evidence of a secret Soviet biological-weapons project which attempted to harness the pollen, which abruptly ended when the researchers—including Serafima, a biochemist imprisoned in a nearby gulag—succumbed to the hallucinations.\n\nLara deduces that Serafima weaponized the pollen, developed an antidote and kept her research secret from the military. With Nadia's help, Lara synthesizes a basic antidote from Serafima's recipe and returns to the Wicked Vale. Resisting the effects of the pollen, Lara finds the injured Ivan at the entrance to Baba Yaga's lair.\n\nUnable to leave the Wicked Vale while Baba Yaga controls it, Lara battles the witch under the pollen's influence and destroys its source. Baba Yaga is revealed as Serafima, who was led to believe that her husband, Ivan, and daughter were dead and used the pollen to become Baba Yaga and torment her captors. With Ivan, Serafima and Nadia reunited, Lara leaves the Wicked Vale.\n\nIn the \"Cold Darkness Awakened\" content, Lara enters a decommissioned Soviet weapons bunker which has been breached by a Trinity patrol. Trinity has inadvertently released an unstable pathogen into the air, which causes the people it infects to regress to a zombie-like state. Men are particularly vulnerable, since the virus stimulates testosterone and adrenaline production. The pathogen was created to create an army of unstoppable super-soldiers by a Soviet researcher, all of whose experiments failed. He died in the facility after accidentally releasing the pathogen, proud that he had created a weapon to defend his homeland. With Sofia and Nadia providing support from a helicopter, Lara tries to find the source of the pathogen before an enormous cloud is released into the atmosphere and contaminates the Remnant valley.\n\nThe women plan to channel the pathogen from three towers into the central tower, detonating it and burning off the toxin. Lara shuts down each tower, collecting equipment, rescuing female prisoners and eliminating waves of the infected Trinity soldiers before entering the core tower. While fighting off the infected soldiers, she triggers a catastrophic explosion and jumps from the tower to Nadia and Sofia's helicopter. Nadia and Lara watch the explosion as they fly to safety. Although the resulting fire burns the remaining pathogen, documents found in the facility indicate that the release was no accident; Trinity reactivated the facility to acquire a sample of the pathogen, and an agent of Trinity escaped with it before the bunker was destroyed.\n\n\"Blood Ties\" begins with Lara reading a note from her uncle, who says that since her mother disappeared he is the rightful owner of the Croft estate. With trees working their way into the side of the house and the roof caving in, Lara's childhood home desperately needs repair. She finds her father's safe and searches the manor for its combination, hoping to find his will and thus prove her ownership. She finds artifacts from her past, and finally figures out the combination; however, the safe contains no proof of her ownership. Lara find her mother's tomb under the main staircase, proof of her death. With both her parents proven dead, their property passes to her and she moves back in.\n\n\"Lara's Nightmare\" is similar to \"Blood Ties\", with Lara's uncle unwilling to give her the manor. She fights off hordes of zombies and skulls before finding the master key. Lara kills a large skull in the main hallway, ending her nightmare.\n\n\"Rise of the Tomb Raider\" was developed by Crystal Dynamics, with Eidos Montreal providing support. Development of the game began two weeks after the team finished polishing the 2013 reboot. It was led by Noah Hughes and Brian Horton, the franchise's creative and game directors respectively. Rhianna Pratchett returned as the game's writer, and Camilla Luddington reprised her role as protagonist Lara Croft. Bobby Tahouri, known for his work on \"Game of Thrones\", composed the soundtrack. Development was completed on 9 October 2015, with Crystal Dynamics confirming that the game was declared gold (indicating that it was being prepared for duplication and release).\n\nOne of the game's intentions was to craft a more \"personal\" experience for players, and the team wanted to explore the journey in which Lara becomes the tomb raider. She becomes determined to uncover more myths, and convinces the world that they are real at the end of the 2013 reboot; this became her major driving force in the sequel. Although Lara must still struggle to survive, she is more confident and competent. The team tried to find a balance, making Lara more experienced and competent but vulnerable in crisis and appealing to players. They hoped that in the story, players could see Lara's character progression. To indicate her hunger for knowledge, the team adjusted the collectibles; players would learn a new language, unlocking new content and upgrades. The new crafting system reflects Lara's resourcefulness, and her ability to use the environment against her enemies highlights her intelligence.\n\nRhianna Pratchett found \"Rise of the Tomb Raider\" more difficult to write than the 2013 reboot, figuring out Lara's initial mental state and character introduction. Its cast was significantly smaller than the reboot, so more screen time could be given to each character. To help establish the game's tone and visuals, Crystal Dynamics developed a \"rippomatic\" (a collection of movie scenes). Films included \"\", which inspired the team about the game's stealth mechanic; \"\", whose protagonist (Sarah Connor) and Lara Croft are \"burdened with a truth that no one believes\". \"The Edge\" and \"The Grey\" inspired game scenes in which Lara fought bears and wolves. \"Hanna\" and \"The Descent\" inspired the game's bows, arrows and pickaxe, and \"Aliens vs. Predator\" and \"The Day After Tomorrow\" helped the team conceive the game's tundra setting.\n\nThey worked on improving the story's pacing, which Horton thought as important as the story itself. Several features with gameplay potential but not fitting its context, such as vehicles and an early scene in which Lara battled enemies in a jeep, were cut. The team listened to player feedback about the original game and made gameplay adjustments, such as reducing the number of quick time events, expanding the hunting system, and increasing the significance of traversing and stealth. Cinematic moments and action scenes, designed by an internal team known as OMS (\"oh my shit\"), were retained in the sequel. The theme of survival remained the story's core, with the team modifying gameplay accordingly; the expanded crafting system required players to use the environments more. However, Crystal Dynamics avoided making it a survival game; the team felt that it would discourage player exploration. Like its predecessor, \"Rise of the Tomb Raider\" has a structure similar to metroidvania; the team wanted players to feel that Siberia is a living, dynamic world, and the game not merely a long sequence of events. According to design director Michael Brinker, the team decided to make the game less \"grindy\" than other titles; players would not be forced to complete any optional content. The skill-upgrades system was overhauled to include more player options.\n\nAfter the developers listened to player feedback, the game emphasized tomb-raiding more than its predecessors. According to Hughes, the team analyzed some of the older \"Tomb Raider\" titles and distilled their best features while incorporating the reboot's physics-based puzzles. They intended to add more ancient tombs, making players feel like real discoverers and inspiring awe. The tombs were made larger than the reboot, and water puzzles (featured in older \"Tomb Raider\" games) were included. The puzzles were often interconnected, with the team adopting a nested-puzzle approach. Optional tombs were made more meaningful, giving players unique skills and items rather than just experience points. The difficulty of each tomb slowly increases as players progress.\n\nThe game world was designed to reflect Lara's distorted mental state, and the team introduced the concept of \"ominous beauty\" to achieve this. The color scheme was vibrant, reflecting the game's large scale. The team was inspired by other video games and fine art, including Russian realists. They traveled to Yosemite National Park and several locations in Turkey, including Cappadocia, Istanbul and Ephesus, researching Byzantine culture and Greek architecture to design Syria and Kitezh. The team took six months to create the game's snow technology (such as snow tracks and avalanches), which helped increase player immersion in the game. To add variety to its landscape, the team introduced the Oasis (with a dramatically-different look from Siberia).\n\nBobby Tahouri's primary goal in composing the game's music was to support its narrative. Tahouri spoke to Crystal Dynamics in 2012 and contracted to write the score in late 2013, delighted to have more composition time than previous projects. He listened to the earlier games' soundtracks to \"immerse [himself] in the \"Tomb Raider\" world\". The soundtrack was recorded in Nashville by a 52-piece string-and-brass orchestra, including cello, woodwinds, dulcimer and a handpan developed by Saraz Musical Instruments. The Siberian music features an instrument similar to a gusli and low-pitched male singing. Dynamic Percussion System middleware creates music as the game is played. Crystal Dynamics signed Karen O and guitarist David Pajo to produce the game's theme song, \"I Shall Rise\".\n\nCamilla Luddington voiced Lara and provided motion capture at a Los Angeles studio over a two-year period. According to the actress, one of the greatest challenges in voicing Lara was having to \"yell over wind and snow\". Luddington trained for the role, with experts teaching her how to hold the weapons. The team wanted to ensure that Lara's first game for the eighth generation of video game consoles looked good. Spraying Mova fluorescent paint on Luddington's face, they obtained 7,000 points of reference. The team had difficulty developing Lara from motion capture, finding Luddington's footage too realistic, and tried to give the young Lara \"subtle\" facial expressions. They focused on Lara's physical details in cutscenes, where her muscles tensed as she climbed or her skin became blotchy from the cold. The studio used pose-based deformers to sculpt Lara's \"exact shape\" as she moved. The team also used wrinkle maps, allowing more natural, realistic movement for the character.\n\n\"Rise of the Tomb Raider\" was powered by the Foundation in-house game engine. The team used global illumination and physics-based rendering to create light and shadows. They used a Horizon WYSIWYG editor, editing text and graphics in a form closely resembling the finished product. The team adopted a \"kit-bashing technique\", quickly assembling a level with modules and rebuilding it until they were satisfied. To improve the game's graphical fidelity, the team partnered with Nixxes Software (which ported the Xbox 360 version).\n\nOn 1 August 2013, Square Enix Europe executive Phil Rogers announced that a new \"Tomb Raider\" game was in development for the eighth generation of video game consoles. Microsoft announced the game during an E3 2014 press conference, with a scheduled late-2015 release. At Gamescom 2014, the company said that \"Rise of the Tomb Raider\" would be an exclusive for its Xbox series of video-game platforms, including Xbox 360 and Xbox One; according to Microsoft Studios executive Phil Spencer, it would be a timed exclusive similar to Microsoft's deal with Capcom and Crytek on \"Dead Rising 3\" and \"\" (in which both were released for Microsoft Windows). This sparked player outrage from players (since \"Tomb Raider\" had a longer history with PlayStation), who blamed franchise owner Square Enix for the decision. Microsoft's calling the game \"exclusive on Xbox for holiday 2015\" caused confusion among the gaming press and players. Rogers explained in 2015 that the Microsoft timed exclusivity was primarily due to the company's strong support for the 2013 reboot. Crystal Dynamics head Darrell Gallagher said that the partnership could help the team \"deliver the best game that [they] can\". Rogers called the arrangement a \"natural\" evolution and a \"tough\" decision. \n\n\"Rise of the Tomb Raider\" was released on 10 November 2015, and the Windows version was released on 28 January 2016. Microsoft Studios was the game's publisher for Xbox 360 and Xbox One. An 18-issue comic series, \"Tomb Raider\", began publication in early 2014. Produced by Dark Horse Comics and written by Pratchett and Gail Simone, the comics bridged the gap between the 2013 reboot and \"Rise of the Tomb Raider\" and explained the absence of some secondary characters in the sequel. Microsoft released a \"Rise of the Tomb Raider\" Xbox One bundle, including an Xbox One console, a code for \"\" and the game. A collector's edition included a 12-inch statue of Lara, a steelbook, a jade necklace and a replica of Lara's journal. A season pass included the base game, additional outfits, weapons and expedition cards, and access to downloadable content. GameStop preorders had exclusive access to the Holy Fire Card Pack, which can be used in the game's expeditions mode. Microsoft live-streamed a Survival Billboard marketing event on Twitch.tv. Eight contestants standing in front of a Southwark Street billboard were subjected to different harsh weather conditions, which were voted by Twitch's viewers. The contestant enduring the weather longest received a \"\"Tomb Raider\"-themed trip\" Players could earn in-game rewards by participating (and interacting with) Twitch live-streaming in expedition mode.\n\nThe game was supported by downloadable content, and its first post-launch update was released on 4 December 2015. It introduced an endurance mode, with elements of a survival game as Lara hunts and crafts items while facing hidden dangers and environmental hazards. The first story add-on, \"Baba Yaga: The Temple of the Witch\", was released on 26 January 2016 for Xbox One. \"Cold Darkness Awakened\", the third DLC, introduced a horde mode in which Lara fights waves of infected enemies. A \"Rise of the Tomb Raider: 20th Year Celebration\" edition was released for PlayStation 4 on 11 October 2016. The edition (developed by Nixxes Software and Crystal Dynamics) adds several new features, including a classic outfit inspired by \"Tomb Raider III\"; cooperative gameplay for endurance mode; \"Blood Ties\", a combat-free mode in which Lara explores the Croft manor; and \"Lara's Nightmare\", in which players fight infected enemies in the manor. The DLC was free of charge to season-pass holders. To promote the \"20th Year Celebration\" edition, the marketing team hung a jeep from the side of a building in Times Square. \"Blood Ties\" supported PlayStation VR when \"20th Year Celebration\" was released, and Oculus Rift and HTC Vive were supported on 6 December 2017. Feral Interactive released the game for macOS and Linux in April 2018.\n\n\"Rise of the Tomb Raider\" received \"generally positive reviews\" according to review aggregator Metacritic.\n\nThe game's graphics were praised by critics. Kimberly Wallace of \"Game Informer\" called them \"stunning\" and praised Crystal Dynamics for creating detailed environments for players to explore, although she noted several frame rate issues. Spencer Campbell of \"Electronic Gaming Monthly\" agreed, describing the areas as \"gorgeous\" and noting that every location in the game looked unique. Justin Towell of GamesRadar praised the game's presentation and appreciated its animation, noting that it was a AAA production. Steven Hansen of \"Destructoid\" called it one of the best-looking games on the market, although he considered some of the lighting unrealistic.\n\nWallace praised the story for several memorable moments, although she thought it was predictable except for the ending scene. She liked the writers' decision to explore the relationship between Lara and her father and with Trinity, which she found interesting. Campbell criticized the story for being simple and formulaic; it \"took too many cues\" from \"Raiders of the Lost Ark\", and its characters were undeveloped and forgettable. Mike Mahardy of GameSpot wrote that the story was emotional and the characters grounded and believable; its mysticism \"makes sense within the world they occupy\", and he called the story tragic but uplifting. Towell praised the story for several surprising moments and was largely impressed by the voice acting, although he was disappointed that the story was so similar to the 2013 reboot. Peter Paras of Game Revolution singled out Luddington's performance as Lara, saying that she \"imbues the character with a sense of wonderment and determination\". Lucy O'Brien of IGN called Lara an \"endearing\" character driven by \"complex ambitions\", and described the game's villains as \"strong\".\n\nWallace found \"Rise of the Tomb Raider\" combat entertaining overall, and enjoyed the stealth section. She liked the upgrade trees (which accommodate different styles of play), but found later combat sections repetitious. Campbell called the stealth section satisfyingly challenging, and enjoyed the range of player choices. He noted the combat's more-strategic nature, due to its larger arsenal. Mahardy called the combat \"superb\", praising the game for giving players the freedom to experiment with gameplay mechanics. He found the resource-gathering tedious, but the crafting system well-executed. Towell liked the game's combat and stealth, comparing it to \"\" and noting that Lara often felt like a \"cold-blooded killer\" due to the abundance of combat. He felt that there were too many items to collect. O'Brien found some combat sections uninspired, but the new crafting abilities made them more enjoyable. She called the stealth component enjoyable but redundant. Although Hansen liked the addition of stealth, he said that \"Rise\" did not address the problems with the 2013 reboot (in which Lara was too violent, causing narrative dissonance).\n\nWallace praised the game's abundant side content, finding it intriguing enough to lure her away from the main story. She liked the Metroidvania world design, and the large hubs encouraged her to explore. Wallace enjoyed the expanded tombs and the puzzles, which were deeper and more intricate than those in the previous game. Campbell praised its hunting mechanic, which enhanced the game world. He wrote that the narrative shortcomings were balanced by gameplay complexity, particularly the optional tomb puzzles. Mahardy praised the open hubs' \"waterfall structure\", where every player action may unlock new possibilities; however, Towell found the hubs filled with aimless, unappealing content. O'Brien called the challenge tombs the game's highlight (paying homage to the older \"Tomb Raider\" games), despite its shortage of puzzles. Hansen found much of the content \"open world busywork\", which he compared to the \"Assassin's Creed\" game series. Paras wrote that the expedition mode was a \"real treat\"; Oli Welsh of Eurogamer criticized it, saying that there was no reason for the mode to exist other than to please YouTubers and generate revenue from microtransactions.\n\nWallace called \"Rise of the Tomb Raider\" \"better in every way\" than the 2013 reboot, and said that the game had high replayability. Campbell was disappointed by the story, but considered the game an overall improvement on its predecessor. Towell called the game a \"safe sequel\" which took few risks, but had a successful formula; O'Brien agreed that it succeeded in refining its predecessor's formula. Hansen found much of the game's content bloated; although it was an improvement, he criticized it for not fixing many of the original's shortcomings. According to Paras, the \"Tomb Raider\" franchise surpassed gaming classics such as \"Resident Evil 4\" and \"\" after 20 years with \"Rise of the Tomb Raider\".\n\nSome gaming journalists were concerned about \"Rise of the Tomb Raider\" sales, since it was released on the same day as \"Fallout 4\" (a highly-anticipated game from Bethesda Game Studios, which also had Microsoft as its marketing partner). However, Microsoft believed that the games would not compete with one another. It was the fourth-bestselling game in the UK and Ireland in its week of release, debuting at number four in the UK retail software sales chart (behind \"Fallout 4\", \"\" and \"FIFA 16\"). However, the game did not sell well enough in the month after its release to appear on the NPD Group chart. According to Square Enix, its initial commercial performance was \"solid\"; game director Brian Horton and Microsoft executive Aaron Greenberg said that Microsoft Studios and Square Enix were satisfied with the game's sales. Digitally, the Windows version sold three times better than the Xbox One version in the first month of release. The game had sold over one million copies by the end of 2015, \nand nearly seven million copies by November 2017.\n\nOn 15 March 2018, \"Shadow of the Tomb Raider\" was confirmed by Square Enix. It is the third game in the rebooted origin story. Eidos Montreal replaced Crystal Dynamics as the game's lead developer. It was released worldwide on PlayStation 4, Xbox One, and Microsoft Windows on 14 September 2018.\n"}
{"id": "28373011", "url": "https://en.wikipedia.org/wiki?curid=28373011", "title": "Seamus Ross", "text": "Seamus Ross\n\nSeamus Ross (November 12, 1957) is a digital humanities and digital curation academic and researcher based in Canada.\n\nSeamus Ross was born 12 November 1957, the son of James Francis Ross, a philosopher, and Kathleen Fallon Ross, a nurse. After graduating from the William Penn Charter School, he earned his A.B. (1979) from Vassar College (United States), his M.A. (1982) from the University of Pennsylvania (USA), and his D.Phil. (1992) from the University of Oxford (UK).\n\nSeamus Ross is Professor at the iSchool at the University of Toronto, also known as the Faculty of Information and from 2009 through 2015 he served as the School's Dean. During 2016, he is Visiting Professor at the School of Information Sciences and Technology, Athens University of Economics and Business (Athens, GR), and Interim Director of the McLuhan Centre for Culture and Technology at the University of Toronto. Before joining Toronto, he was Professor of Humanities Informatics and Digital Curation and Founding Director of HATII (Humanities Advanced Technology and Information Institute) (1997–2009) at the University of Glasgow. He was one of the founders of and served as Associate Director of the Digital Curation Centre (2004–9) in the UK, and was Principal Director of ERPANET and Digital Preservation Europe (DPE) and a co-principal investigator such projects as the DELOS Digital Libraries Network of Excellence, Planets and the Digicult Forum. From the beginning of 1990 through 1996, Ross was Assistant Secretary (Information Technology) at the British Academy in London.\n\nRoss's scholarly research has focused on digital humanities, digital preservation, digital curation, digitisation, digital repositories, emulation, digital archaeology, semantic extraction and genre classification, and cultural heritage informatics. See for instance his study of digital archaeology, his examination of digital preservation and archival science, and his introduction to digital preservation, \"Changing Trains at Wigan\". He promotes a diversity in ways of making scholarship available to broader audiences and was instrumental in the creation of the Digiman Series through Digital Preservation Europe, Digital Preservation and Nuclear Disaster: An Animation,\n\nIn March 2016, Ross was elected a Corresponding Fellow of the Royal Society of Edinburgh, Scotland's national academy of science and letters.\n\n\n"}
{"id": "5824713", "url": "https://en.wikipedia.org/wiki?curid=5824713", "title": "Self-healing material", "text": "Self-healing material\n\nSelf-healing materials are artificial or synthetically-created substances which have the built-in ability to automatically repair damage to themselves without any external diagnosis of the problem or human intervention. Generally, materials will degrade over time due to fatigue, environmental conditions, or damage incurred during operation. Cracks and other types of damage on a microscopic level have been shown to change thermal, electrical, and acoustical properties of materials, and the propagation of cracks can lead to eventual failure of the material. In general, cracks are hard to detect at an early stage, and manual intervention is required for periodic inspections and repairs. In contrast, self-healing materials counter degradation through the initiation of a repair mechanism which responds to the micro-damage. Some self-healing materials are classed as smart structures, and can adapt to various environmental conditions according to their sensing and actuation properties.\n\nAlthough the most common types of self-healing materials are polymers or elastomers, self-healing covers all classes of materials, including metals, ceramics, and cementitious materials. Healing mechanisms vary from an instrinsic repair of the material to the addition of a repair agent contained in a microscopic vessel. For a material to be strictly defined as autonomously self-healing, it is necessary that the healing process occurs without human intervention. Self-healing polymers may, however, activate in response to an external stimulus (light, temperature change, etc.) to initiate the healing process.\n\nA material which can intrinsically correct damage caused by normal usage could prevent costs incurred by material failure and lower costs of a number of different industrial processes through longer part lifetime, and reduction of inefficiency caused by degradation over time.\n\nThe ancient Romans used a form of lime mortar that has been found to have self-healing properties. Geologist Marie Jackson and her colleagues have recreated the type of mortar used in Trajan's Market and other Roman structures such as the Pantheon and the Colosseum and studied its response to cracking. The Romans mixed a particular type of volcanic ash called Pozzolane Rosse, from the Alban Hills volcano, with quicklime and water. They used it to bind together decimeter-sized chunks of tuff, an aggregate of volcanic rock.\nAs a result of Pozzolanic activity as the material cured, the lime interacted with other chemicals in the mix and was replaced by crystals of a calcium aluminosilicate mineral called Strätlingite. Crystals of platey strätlingite grow in the cementitious matrix of the material including the interfacial zones where cracks would tend to develop. This ongoing crystal formation holds together the mortar and the coarse aggregate, countering crack formation and resulting in a material that has lasted for 1,900 years.\n\nRelated processes in concrete have been studied microscopically since the 19th century.\n\nSelf healing materials only emerged as a widely recognized field of study in the 21st century. The first international conference on self-healing materials was held in 2007. The field of self-healing materials is related to biomimetic materials as well as to other novel materials and surfaces with the embedded capacity for self-organization, such as the self-lubricating and self-cleaning materials.\n\nPlants and animals have the capacity to seal and heal wounds. In all plants and animals examined, firstly a self-sealing phase and secondly a self-healing phase can be identified. In plants, the rapid self-sealing prevents the plants from desiccation and from infection by pathogenic germs. This gives time for the subsequent self-healing of the injury which in addition to wound closure also results in the (partly) restoration of mechanical properties of the plant organ. Based on a variety of self-sealing and self-healing processes in plants, different functional principles were transferred into bio-inspired self-repairing materials. The connecting link between the biological model and the technical application is an abstraction describing the underlying functional principle of the biological model which can be for example an analytical model or a numerical model. In cases where mainly physical-chemical processes are involved a transfer is especially promising. \nThere is evidence in the academic literature of these biomimetic design approaches being used in the development of self-healing systems for polymer composites.\nThe DIW structure from above can be used to essentially mimic the structure of skin. Toohey \"et al.\" did this with an epoxy substrate containing a grid of microchannels containing dicyclopentadiene (DCPD), and incorporated Grubbs' catalyst to the surface. This showed partial recovery of toughness after fracture, and could be repeated several times because of the ability to replenish the channels after use. The process is not repeatable forever, because the polymer in the crack plane from previous healings would build up over time.\nInspired by rapid self-sealing processes in the twining liana Aristolochia macrophylla and related species (pipevines) a biomimetic PU-foam coating for pneumatic structures was developed. With respect to low coating weight and thickness of the foam layer maximum repair efficiencies of 99.9% and more have been obtained. Other role models are latex bearing plants as the weeping fig (Ficus benjamina), the rubber tree (Hevea brasiliensis) and spurges (Euphorbia spp.), in which the coagulation of latex is involved in the sealing of lesions. Different self-sealing strategies for elastomeric materials were developed showing significant mechanical restoration after a macroscopic lesion.\n\nIn the last century, polymers became a base material in everyday life for products like plastics, rubbers, films, fibres or paints. This huge demand has forced to extend their reliability and maximum lifetime, and a new design class of polymeric materials that are able to restore their functionality after damage or fatigue was envisaged. These polymer materials can be divided into two different groups based on the approach to the self-healing mechanism: intrinsic or extrinsic.\nAutonomous self-healing polymers follow a three-step process very similar to that of a biological response. In the event of damage, the first response is triggering or actuation, which happens almost immediately after damage is sustained. The second response is transport of materials to the effected area, which also happens very quickly. The third response is the chemical repair process. This process differs depending on the type of healing mechanism that is in place (e.g., polymerization, entanglement, reversible cross-linking). These self-healing materials can be classified in three different ways: capsule based, vascular, and intrinsic. While similar in some ways, these three ways differ in the ways that response is hidden or prevented until actual damage is sustained.\n\nFrom a molecular perspective, traditional polymers yield to mechanical stress through cleavage of sigma bonds. While newer polymers can yield in other ways, traditional polymers typically yield through homolytic or heterolytic bond cleavage. The factors that determine how a polymer will yield include: type of stress, chemical properties inherent to the polymer, level and type of solvation, and temperature.\nFrom a macromolecular perspective, stress induced damage at the molecular level leads to larger scale damage called microcracks. A microcrack is formed where neighboring polymer chains have been damaged in close proximity, ultimately leading to the weakening of the fiber as a whole.\n\nPolymers have been observed to undergo homolytic bond cleavage through the use of radical reporters such as DPPH (2,2-diphenyl-1-picrylhydrazyl) and PMNB (pentamethylnitrosobenzene.) When a bond is cleaved homolytically, two radical species are formed which can recombine to repair damage or can initiate other homolytic cleavages which can in turn lead to more damage.\n\nPolymers have also been observed to undergo heterolytic bond cleavage through isotope labeling experiments. When a bond is cleaved heterolytically, cationic and anionic species are formed which can in turn recombine to repair damage, can be quenched by solvent, or can react destructively with nearby polymers.\n\nCertain polymers yield to mechanical stress in an atypical, reversible manner. Diels-Alder-based polymers undergo a reversible cycloaddition, where mechanical stress cleaves two sigma bonds in a retro Diels-Alder reaction. This stress results in additional pi-bonded electrons as opposed to radical or charged moieties.\n\nSupramolecular polymers are composed of monomers that interact non-covalently. Common interactions include hydrogen bonds, metal coordination, and van der Waals forces. Mechanical stress in supramolecular polymers causes the disruption of these specific non-covalent interactions, leading to monomer separation and polymer breakdown.\n\nIn intrinsic systems, the material is inherently able to restore its integrity. While extrinsic approaches are generally autonomous, intrinsic systems often require an external trigger for the healing to take place (such as thermo-mechanical, electrical, photo-stimuli, etc.). It is possible to distinguish among 5 main intrinsic self-healing strategies. The first one is based on reversible reactions, and the most widely used reaction scheme is based on Diels-Alder (DA) and retro-Diels-Alder (rDA) reactions. Another strategy achieves the self-healing in thermoset matrices by incorporating meltable thermoplastic additives. A temperature trigger allows the redispertion of thermoplastic additives into cracks, giving rise to mechanical interlocking. Polymer interlockings based on dynamic supramolecular bonds or ionomers represent a third and fourth scheme. The involved supramolecular interactions and ionomeric clusters are generally reversible and act as reversible cross-links, thus can equip polymers with self-healing ability. Finally, an alternative method for achieving intrinsic self-healing is based on molecular diffusion.\n\nReversible systems are polymeric systems that can revert to the initial state whether it is monomeric, oligomeric, or non-cross-linked. Since the polymer is stable under normal condition, the reversible process usually requires an external stimulus for it to occur. For a reversible healing polymer, if the material is damaged by means such as heating and reverted to its constituents, it can be repaired or \"healed\" to its polymer form by applying the original condition used to polymerize it.\n\nAmong the examples of reversible healing polymers, the Diels-Alder (DA) reaction and its retro-Diels-Alder (RDA) analogue seems to be very promising due to its thermal reversibility. In general, the monomer containing the functional groups such as furan or maleimide form two carbon-carbon bonds in a specific manner and construct the polymer through DA reaction. This polymer, upon heating, breaks down to its original monomeric units via RDA reaction and then reforms the polymer upon cooling or through any other conditions that were initially used to make the polymer. During the last few decades, two types of reversible polymers have been studied: (i) polymers where the pendant groups, such as furan or maleimide groups, cross-link through successive DA coupling reactions; (ii) polymers where the multifunctional monomers link to each other through successive DA coupling reactions.\n\nIn this type of polymer, the polymer forms through the cross linking of the pendant groups from the linear thermoplastics. For example, Saegusa \"et al.\" have shown the reversible cross-linking of modified poly(\"N\"-acetylethyleneimine)s containing either maleimide or furancarbonyl pendant moideties. The reaction is shown in Scheme 3. They mixed the two complementary polymers to make a highly cross-linked material through DA reaction of furan and maleimide units at room temperature, as the cross-linked polymer is more thermodynamically stable than the individual starting materials. However, upon heating the polymer to 80 °C for two hours in a polar solvent, two monomers were regenerated via RDA reaction, indicating the breaking of polymers. This was possible because the heating energy provided enough energy to go over the energy barrier and results in the two monomers. Cooling the two starting monomers, or damaged polymer, to room temperature for 7 days healed and reformed the polymer. \n\nThe reversible DA/RDA reaction is not limited to furan-meleimides based polymers as it is shown by the work of Schiraldi \"et al.\" They have shown the reversible cross-linking of polymers bearing pendent anthracene group with maleimides. However, the reversible reaction occurred only partially upon heating to 250 °C due to the competing decomposition reaction.\n\nIn these systems, the DA reaction takes place in the backbone itself to construct the polymer, not as a link. For polymerization and healing processes of a DA-step-growth furan-maleimide based polymer (3M4F) were demonstrated by subjecting it to heating/cooling cycles. Tris-maleimide (3M) and tetra-furan (4F) formed a polymer through DA reaction and, when heated to 120 °C, de-polymerized through RDA reaction, resulting in the starting materials. Subsequent heating to 90–120 °C and cooling to room temperature healed the polymer, partially restoring its mechanical properties through intervention. The reaction is shown in Scheme 4. \nThe thiol-based polymers have disulfide bonds that can be reversibly cross-linked through oxidation and reduction. Under reducing condition, the disulfide (SS) bridges in the polymer breaks and results in monomers, however, under oxidizing condition, the thiols (SH) of each monomer forms the disulfide bond, cross-linking the starting materials to form the polymer. Chujo \"et al.\" have shown the thiol-based reversible cross-linked polymer using poly(\"N\"-acetylethyleneimine). (Scheme 5) \nA soft poly(urea-urethane) network uses the metathesis reaction in aromatic disulphides to provide room-temperature self-healing properties, without the need for external catalysts. This chemical reaction is naturally able to create covalent bonds at room temperature, allowing the polymer to autonomously heal without an external source of energy. Left to rest at room temperature, the material mended itself with 80 percent efficiency after only two hours and 97 percent after 24 hours.\nIn 2014 a polyurea elastomer-based material was shown to be self-healing, melding together after being cut in half, without the addition of catalysts or other chemicals. The material also include inexpensive commercially available compounds. The elastomer molecules were tweaked, making the bonds between them longer. The resulting molecules are easier to pull apart from one another and better able to rebond at room temperature with almost the same strength. The rebonding can be repeated. Stretchy, self-healing paints and other coatings recently took a step closer to common use, thanks to research being conducted at the University of Illinois. Scientists there have used \"off-the-shelf\" components to create a polymer that melds back together after being cut in half, without the addition of catalysts or other chemicals.\n\nThe urea-urethane polymers however have glassy transition temperatures below 273 K therefore at room temperature they are gels and their tensile strength is low. To optimize the tensile strength the reversible bonding energy, or the polymer length must be increased to increase the degree of covalent or mechanical interlocking respectively. However, increase polymer length inhibits mobility and thereby impairs the ability for polymers to re-reversibly bond. Thus at each polymer length an optimal reversible bonding energy exists.\n\nIn extrinsic systems, the healing chemistries are separated from the surrounding polymer in microcapsules or vascular networks, which after material damage/cracking release their content into the crack plane, reacting and allowing the restoration of material functionalities. \nThese systems can be further subdivided in several categories. While capsule-based polymers sequester the healing agents in little capsules that only release the agents if they are ruptured, vascular self-healing materials sequester the healing agent in capillary type hollow channels which can be interconnected one dimensionally, two dimensionally, or three dimensionally. After one of these capillaries is damaged, the network can be refilled by an outside source or another channel that was not damaged. Intrinsic self-healing materials do not have a sequestered healing agent but instead have a latent self-healing functionality that is triggered by damage or by an outside stimulus. Extrinsic self-healing materials can achieve healing efficiencies over 100% even when the damage is large.\n\nCapsule-based systems have in common that healing agents are encapsulated into suitable microstructures that rupture upon crack formation and lead to a follow up process in order to restore the materials' properties. If the walls of the capsule are created too thick, they may not fracture when the crack approaches, but if they are too thin, they may rupture prematurely. \nIn order for this process to happen at room temperature, and for the reactants to remain in a monomeric state within the capsule, a catalyst is also imbedded into the thermoset. The catalyst lowers the energy barrier of the reaction and allows the monomer to polymerize without the addition of heat. The capsules (often made of wax) around the monomer and the catalyst are important to maintain separation until the crack facilitates the reaction.\nIn the capsule-catalyst system, the encapsulated healing agent is released into the polymer matrix and reacts with the catalyst, already present in the matrix. \nThere are many challenges in designing this type of material. First, the reactivity of the catalyst must be maintained even after it is enclosed in wax. Additionally, the monomer must flow at a sufficient rate (have low enough viscosity) to cover the entire crack before it is polymerized, or full healing capacity will not be reached. Finally, the catalyst must quickly dissolve into the monomer in order to react efficiently and prevent the crack from spreading further.\n\nThis process has been demonstrated with dicyclopentadiene (DCPD) and Grubbs' catalyst (benzylidene-bis(tricyclohexylphosphine)dichlororuthenium). Both DCPD and Grubbs' catalyst are imbedded in an epoxy resin. The monomer on its own is relatively unreactive and polymerization does not take place. When a microcrack reaches both the capsule containing DCPD and the catalyst, the monomer is released from the core–shell microcapsule and comes in contact with exposed catalyst, upon which the monomer undergoes ring opening metathesis polymerization (ROMP). The metathesis reaction of the monomer involves the severance of the two double bonds in favor of new bonds. The presence of the catalyst allows for the energy barrier (energy of activation) to be lowered, and the polymerization reaction can proceed at room temperature. The resulting polymer allows the epoxy composite material to regain 67% of its former strength.\n\nGrubbs' catalyst is a good choice for this type of system because it is insensitive to air and water, thus robust enough to maintain reactivity within the material. Using a live catalyst is important to promote multiple healing actions. The major drawback is the cost. It was shown that using more of the catalyst corresponded directly to higher degree of healing. Ruthenium is quite costly, which makes it impractical for commercial applications.\n\nIn contrast, in multicapsule systems both the catalyst and the healing agent are encapsulated in different capsules. In a third system, called latent functionality, a healing agent is encapsulated, that can react with the polymerizer component that is present in the matrix in the form of residual reactive functionalities. In the last approach (phase separation), either the healing agent or the polymerizer is phase-separated in the matrix material.\n\nThe same strategies can be applied in 1D, 2D and 3D vascular based systems.\n\nFor the first method, fragile glass capillaries or fibers are imbedded within a composite material. (Note: this is already a commonly used practice for strengthening materials. See Fiber-reinforced plastic.) The resulting porous network is filled with monomer. When damage occurs in the material from regular use, the tubes also crack and the monomer is released into the cracks. Other tubes containing a hardening agent also crack and mix with the monomer, causing the crack to be healed. There are many things to take into account when introducing hollow tubes into a crystalline structure. First to consider is that the created channels may compromise the load bearing ability of the material due to the removal of load bearing material. Also, the channel diameter, degree of branching, location of branch points, and channel orientation are some of the main things to consider when building up microchannels within a material. Materials that don’t need to withstand much mechanical strain, but want self-healing properties, can introduce more microchannels than materials that are meant to be load bearing. There are two types of hollow tubes: discrete channels, and interconnected channels.\n\nDiscrete channels can be built independently of building the material and are placed in an array throughout the material. When creating these microchannels, one major factor to take into account is that the closer the tubes are together, the lower the strength will be, but the more efficient the recovery will be. A sandwich structure is a type of discrete channels that consists of tubes in the center of the material, and heals outwards from the middle. The stiffness of sandwich structures is high, making it an attractive option for pressurized chambers. For the most part in sandwich structures, the strength of the material is maintained as compared to vascular networks. Also, material shows almost full recovery from damage.\n\nInterconnected networks are more efficient than discrete channels, but are harder and more expensive to create. The most basic way to create these channels is to apply basic machining principles to create micro scale channel grooves. These techniques yield channels from 600–700 micrometers. This technique works great on the two-dimensional plane, but when trying to create a three-dimensional network, they are limited.\n\nThe Direct Ink Writing (DIW) technique is a controlled extrusion of viscoelastic inks to create three-dimensional interconnected networks. It works by first setting organic ink in a defined pattern. Then the structure is infiltrated with a material like an epoxy. This epoxy is then solidified, and the ink can be sucked out with a modest vacuum, creating the hollow tubes.\n\nThrough dissolving a linear polymer inside a solid three-dimensional epoxy matrix, so that they are miscible to each other, the linear polymer becomes mobile at a certain temperature When carbon nanotubes are also incorporated into epoxy material, and a direct current is run through the tubes, a significant shift in sensing curve indicates permanent damage to the polymer, thus ‘sensing’ a crack. When the carbon nanotubes sense a crack within the structure, they can be used as thermal transports to heat up the matrix so the linear polymers can diffuse to fill the cracks in the epoxy matrix. Thus healing the material.\n\nA different approach was suggested by Prof. J. Aizenberg from Harvard University, who suggested to use Slippery Liquid-Infused Porous Surfaces (SLIPS), a porous material inspired by the carnivorous pitcher plant and filled with a lubricating liquid immiscible with both water and oil. SLIPS possess self-healing and self-lubricating properties as well as icephobicity and were successfully used for many purposes.\n\nOrganic threads (such as polylactide filament for example) are stitched through laminate layers of fiber reinforced polymer, which are then boiled and vacuumed out of the material after curing of the polymer, leaving behind empty channels than can be filled with healing agents.\n\nMethods for the implementation of self-healing functionality into filled composites and fibre reinforced polymers (FRPs) are almost exclusively based on extrinsic systems and thus can be broadly classified into two approaches; discrete capsule-based systems and continuous vascular systems. In contrast to non-filled polymers, the success of an intrinsic approach based on bond reversibility has yet to be proven in FRPs. \nTo date, self-healing of FRPs has mostly been applied to simple structures such as flat plates and panels. There is however a somewhat limited application of self-healing in flat panels, as access to the panel surface is relatively simple and repair methods are very well established in industry. Instead, there has been a strong focus on implementing self-healing in more complex and industrially relevant structures such as T-Joints and Aircraft Fuselages.\n\nThe creation of a capsule-based system was first reported by White et al. in 2001, and this approach has since been adapted by a number of authors for introduction into fibre reinforced materials. This method relies on the release of an encapsulated healing agent into the damage zone, and is generally a once off process as the functionality of the encapsulated healing agent cannot be restored. Even so, implemented systems are able to restore material integrity to almost 100% and remain stable over the material lifetime.\n\nA vascular or fibre-based approach may be more appropriate for self-healing impact damage in fibre-reinforced polymer composite materials. \nIn this method, a network of hollow channels known as vascules, similar to the blood vessels within human tissue, are placed within the structure and used for the introduction of a healing agent. During a damage event cracks propagate through the material and into the vascules causing them to be cleaved open. A liquid resin is then passed through the vascules and into the damage plane, allowing the cracks to be repaired. Vascular systems have a number of advantages over microcapsule based systems, such as the ability to continuously deliver large volumes of repair agents and the potential to be used for repeated healing. The hollow channels themselves can also be used for additional functionality, such as thermal management and structural health monitoring. A number of methods have been proposed for the introduction of these vascules, including the use of hollow glass fibres (HGFs), \n\nCoatings allow the retention and improvement of bulk properties of a material. They can provide protection for a substrate from environmental exposure. Thus, when damage occurs (often in the form of microcracks), environmental elements like water and oxygen can diffuse through the coating and may cause material damage or failure. Microcracking in coatings can result in mechanical degradation or delamination of the coating, or in electrical failure in fibre-reinforced composites and microelectronics, respectively. As the damage is on such a small scale, repair, if possible, is often difficult and costly. Therefore, a coating that can automatically heal itself (“self-healing coating”) could prove beneficial by automatic recovering properties (such as mechanical, electrical and aesthetic properties), and thus extending the lifetime of the coating. The majority of the approaches that are described in literature regarding self-healing materials can be applied to make “self-healing” coatings, including microencapsulation and the introduction of reversible physical bonds such as hydrogen bonding, ionomers\nLiquid metal microdroplets have also been suspended within silicone elastomer to create stretchable electrical conductors that maintain electrical conductivity when damaged, mimicking the resilience of soft biological tissue. The most common application of this technique is proven in polymer coatings for corrosion protection. Corrosion protection of metallic materials is of significant importance on an economical and ecological scale. To prove the effectiveness of microcapsules in polymer coatings for corrosion protection, researchers have encapsulated a number of materials. These materials include isocyanates monomers such as DCPD GMA epoxy resin, linseed oil and tung oil. By using the aforementioned materials for self healing in coatings, it was proven that microencapsulation effectively protects the metal against corrosion and extends the lifetime of a coating.\n\nCementitious materials have existed since the Roman era. These materials have a natural ability to self-heal, which was first reported by the French Academy of Science in 1836. This ability can be improved by the integration of chemical and biochemical strategies.\n\nAutogenous healing is the natural ability of cementitious materials to repair cracks. This ability is principally attributed to further hydration of unhydrated cement particles and carbonation of dissolved calcium hydroxide. Cementitious materials in fresh-water systems can autogenously heal cracks up to 0.2 mm over a period of 7 weeks.\n\nSelf-healing of cementitious materials can be achieved through the reaction of certain chemical agents. Two main strategies exist for housing these agents, namely capsules and vascular tubes. These capsules and vascular tubes, once ruptured, release these agents and heal the crack damage. Studies have mainly focused on improving the quality of these housings and encapsulated materials in this field.\n\nThe self-healing ability of concrete has been improved by the incorporation of bacteria, which can induce calcium carbonate precipitation through their metabolic activity. These precipitates can build up and form an effective seal against crack related water ingress. Jonkers et al. first incorporated bacteria within cement paste for the development of self-healing concrete. It was found that the bacteria directly added to the paste only remained viable for 4 months. Later studies saw Jonkers use expanded clay particles and Van Tittlelboom use glass tubes, to protect the bacteria inside the concrete. Other strategies to protect the bacteria have also since been reported.\n\nGenerally, ceramics are superior in strength to metals at high temperatures, however, they are brittle and sensitive to flaws, and this brings into question their integrity and reliability as structural materials.\n<chem>M_{\\mathit n+1}AX_\\mathit{n}</chem> phase ceramics, also known as MAX Phases, can autonomously heal crack damage by an intrinsic healing mechanism. Micro cracks caused by wear or thermal stress are filled with oxides formed from the MAX phase constituents, commonly the A-element, during high temperature exposure to air.\nCrack gap filling was first demonstrated for TiAlC by oxidation at 1200 °C in air. TiAlC and CrAlC have also demonstrated said ability, and more ternary carbides and nitrides are expected to be able to autonomously self-heal. The process is repeatable up to the point of element depletion, distinguishing MAX phases from other self-healing materials that require external healing agents (extrinsic healing) for single crack gap filling. Depending on the filling-oxide, improvement of the initial properties such as local strength can be achieved.\nOn the other hand, mullite, alumina and zirconia do not have the ability to heal intrinsically, but could be endowed with self-healing capabilities by embedding second phase components into the matrix. Upon cracking, these particles are exposed to oxygen, and in the presence of heat, they react to form new materials which fill the crack gap under volume expansion.\nThis concept has been proven using SiC to heal cracks in an Alumina matrix, and further studies have investigated the high temperature strength, and the static and cyclic fatigue strength of the healed part. The strength and bonding between the matrix and the healing agent are of prime importance and thus govern the selection of the healing particles.\n\nWhen exposed for long times to high temperatures and moderate stresses, metals exhibit premature and low-ductility creep fracture, arising from the formation and growth of cavities. Those defects coalesce into cracks which ultimately cause macroscopic failure. Self-healing of early stage damage is thus a promising new approach to extend the lifetime of the metallic components. In metals, self-healing is intrinsically more difficult to achieve than in most other material classes, due to their high melting point and, as a result, low atom mobility. Generally, defects in the metals are healed by the formation of precipitates at the defect sites that immobilize further crack growth.\nImproved creep and fatigue properties have been reported for underaged aluminium alloys compared to the peak hardening Al alloys, which is due to the heterogeneous precipitation at the crack tip and its plastic zone. The first attempts to heal creep damage in steels were focused on the dynamic precipitation of either Cu or BN at the creep-cavity surface. Cu precipitation has only a weak preference for deformation-induced defects as a large fraction of spherical Cu precipitates is simultaneously formed with the matrix. \nRecently, gold atoms were recognized as a highly efficient healing agents in Fe-based alloys. A defect-induced mechanism is indicated for the Au precipitation, i.e. the Au solute remains dissolved until defects are formed. Autonomous repair of high-temperature creep damage was reported by alloying with a small amount of Au. Healing agents selectively precipitate at the free surface of a creep cavity, resulting in pore filling. For the lower stress levels up to 80% filling of the creep cavities with Au precipitates is achieved resulting in a substantial increase in creep life time. Work to translate the concept of creep damage healing in simple binary or ternary model systems to real multicomponent creep steels is ongoing.\n\nRecently, a several classes of organic dyes are discovered that self-heal after photo-degradation when doped in PMMA and other polymer matrices. This is also knows as reversible photo-degradation. It was shown that, unlike common process like molecular diffusion, the mechanism is caused by dye-polymer interaction.\n\nSelf-healing epoxies can be incorporated on to metals in order to prevent corrosion.\nA substrate metal showed major degradation and rust formation after 72 hours of exposure. But after being coated with the self-healing epoxy, there was no visible damage under SEM after 72 hours of same exposure.\n\nNumerous methodologies for the assessment of self-healing capabilities have been developed for each material class (Table 1).\n\nHence, when self-healing is assessed, different parameters need to be considered: type of stimulus (if any), healing time, maximum amount of healing cycles the material can tolerate, and degree of recovery, all whilst considering the material's virgin properties.\nThis typically takes account of relevant physical parameters such as tensile modulus, elongation at break, fatigue-resistance, barrier properties, colour and transparency.\nThe self-healing ability of a given material generally refers to the recovery of a specific property relative to the virgin material, designated as the self-healing efficiency. The self-healing efficiency can be quantified by comparing the respective experimental value obtained for the undamaged virgin sample (\"f\") with the healed sample (\"f\") (eq. )\n\nIn a variation of this definition that is relevant to extrinsic self-healing materials, the healing efficiency takes into consideration the modification of properties caused by introducing the healing agent. Accordingly, the healed sample property is compared to that of an undamaged control equipped with self-healing agent f (equation ).\nFor a certain property Pi of a specific material, an optimal self-healing mechanism and process is characterized by the full restoration of the respective material property after a suitable, normalized damaging process. For a material where 3 different properties are assessed, it should be determined 3 efficiencies given as \"ƞ\"(\"P\"), \"ƞ\"(\"P\") and \"ƞ\"(\"P\").\nThe final average efficiency based on a number n of properties for a self-healing material is accordingly determined as the harmonic mean given by equation . The harmonic mean is more appropriate than the traditional arithmetic mean, as it is less sensitive to large outliers.\n\nAt least two companies are attempting to bring the newer applications of self-healing materials to the market. Arkema, a leading chemicals company, announced in 2009 the beginning of industrial production of self-healing elastomers. As of 2012, Autonomic Materials Inc., had raised over three million US dollars.\n"}
{"id": "29379", "url": "https://en.wikipedia.org/wiki?curid=29379", "title": "Shiva (Judaism)", "text": "Shiva (Judaism)\n\nShiva (, literally \"seven\") is the week-long mourning period in Judaism for first-degree relatives. The ritual is referred to as \"sitting shiva.\" Traditionally, there are five stages of mourning in Judaism. Shiva is considered the third stage, and lasts for seven days. Following the initial period of despair and lamentation immediately after the death, shiva embraces a time when individuals discuss their loss and accept the comfort of others. It is required to observe shiva for parents, spouses, children, and/or siblings who have died. It is not required to observe shiva for an individual who was less than thirty days old at the time of death. At the funeral, mourners wear an outer garment or ribbon that is torn during the procession in a ritual known as \"keriah\". This garment is worn throughout the entirety of shiva. Typically, the seven days begin immediately after the deceased has been buried. Following burial, mourners assume the \"halakhic\" status of \"avel\" (). It is necessary for the burial spot to be entirely covered with earth in order for shiva to commence. This state lasts for the entire duration of shiva. During the period of shiva, mourners remain at home. Friends and family visit those in mourning in order to give their condolences and provide comfort. The process, though dating back to biblical times, mimics the natural way an individual confronts and overcomes grief. Shiva allows for the individual to express their sorrow, discuss the loss of a loved one, and slowly re-enter society.\n\nThe word \"shiva\" comes from the Hebrew word \"shiv'ah\" (). Historical and biblical accounts depict multi-day periods of mourning, time set aside strictly for observing and expressing grief. There are many instances mentioned which describe the traditional Judaic process of mourning known as \"shiva\".\n\n\n¶\"16 And Moses diligently inquired for the goat of the sin-offering, and, behold, it was burnt; and he was angry with Eleazar and with Ithamar, the sons of Aaron that were left, saying: 17 'Wherefore have ye not eaten the sin-offering in the place of the sanctuary, seeing it is most holy, and He hath given it you to bear the iniquity of the congregation, to make atonement for them before the LORD? 18 Behold, the blood of it was not brought into the sanctuary within; ye should certainly have eaten it in the sanctuary, as I commanded.' 19 And Aaron spoke unto Moses: 'Behold, this day have they offered their sin-offering and their burnt-offering before the LORD, and there have befallen me such things as these; and if I had eaten the sin-offering to-day, would it have been well-pleasing in the sight of the LORD? 20 And when Moses heard that, it was well-pleasing in his sight.\"\n\nThe process of mourning begins with the first stage, otherwise known as Aninut. During this time, individuals experience the initial shock of their loss. Often times emotions associated with the period of Aninut include anger, denial, and disbelief. This is the most extreme period of mourning, and it is at this time in which the keriah, or the rending of the garments, is performed. The stage commences from the moment the individual dies until the end of the funeral. Following Aninut is shiva, in which the mourners delve into seven days dedicated towards remembrance of the deceased individual. Throughout shiva, individuals are instructed to take a break from their routines in order to focus on their loss as well. Following shiva is the stage of mourning known as sheloshim. During this period, mourning proceeds for thirty days following the burial. The first seven days of sheloshim is the period of shiva, however sheloshim continues on after shiva has ended. After the intense period of shiva, which is mainly contained to the home, sheloshim allows individuals to leave their residences and begin to interact with others again. Sheloshim encourages individuals to begin to partake in social relations in order to slowly ease back into normal daily activities. Through the final stage, yahrzeit or yizkor, the twelve month period of mourning ceases and yearly remembrance ceremonies are held for the individual who had died.\n\nThe period of shiva mourning commences immediately after the burial; the remainder of the day is considered to be the first day of shiva, even though it is only a partial day. On the seventh day (e.g., on Monday, if the first day was Tuesday), shiva ends in the morning after shacharit prayers (if no public services are held on the morning of the seventh day, a service is conducted in the home of the mourner); thus, the seventh day is again a partial day. The sheloshim period of mourning continues until the end of morning services on the 30th day, 23 days after the end of shiva; as with shiva, the two partial days at the beginning and end are counted as full days. \n\nReligious holidays during shiva and sheloshim require the traditional rules to be bent slightly. Because Judaism embraces the holidays with joy, the sadness and grief associated with mourning are meant to be set aside until the holiday concludes. Typically, if an individual dies before the beginning of a holiday, the holiday removes the observance of shiva or sheloshim. The days of the holiday are counted towards the days of mourning, and the rules enforced during mourning are revoked in order to encourage the celebration of a holiday. If a death occurred during the holiday or unknowingly, mourning commences after the holiday ends. In other situations, if the entirety of shiva has been observed prior to the start of a holiday, the holiday will cancel the observance of sheloshim, signifying the fulfillment of this period of mourning.\n\nDuring Shabbat, private mourning continues, while public mourning is suspended. Individuals are permitted to wear shoes and leave their home to partake in public prayer services. In order to prepare for Shabbat, individuals are allowed to interrupt shiva for up to one hour and fifteen minutes in order to cook, dress, and perform other tasks. If this is not enough time to do so, in certain situations there may be two and a half hours allotted for such.\n\nDuring Passover, any days in observance of shiva before the start will equate to seven when the holiday begins. Since Passover is celebrated for eight days, any mourning prior will total to fifteen days when holiday ends, leaving only fifteen days of observance of sheloshim.\n\nDuring Shavuot, any days in observance of shiva before the start will equate to seven when the holiday begins. The first day of Shavuot equates to seven days. The second day of Shavuot is considered the fifteenth day, leaving only fifteen days left of observance of sheloshim.\n\nDuring Succot, any days in observance of shiva before the start will equate to seven when the holiday begins. Since Succot is observed for seven days, any mourning prior will total to fourteen days when the holiday ends. Shemini Atzeret is considered the eighth day of Succot, and equates to seven days of mourning. Simchat Torah is considered the twenty-second day of mourning, leaving only eight days of observance of sheloshim.\n\nDuring Rosh Hashanah, any days in observance of shiva before the start will equate to seven days when the holiday begins. Yom Kippur following Rosh Hashanah, will symbolize the end of mourning, and the end of both shiva and sheloshim.\n\nDuring Yom Kippur, any days in observance of shiva before the start will equate to seven days when the holiday begins. Succot, following Yom Kippur, will symbolize the end of mourning, and the end of both shiva and sheloshim.\n\nIf the death occurs during Yom Tov, shiva does not begin until the burial is completed. Burial may not take place on Yom Tov, but can during the intermediate days of Succot or Passover, otherwise known as Chol HaMoed.\n\nIf a burial occurs on Chol HaMoed of Passover, shiva does not begin until after the Yom Tov is completed. In the Diaspora, where most Yom Tovim are observed for two days, mourning does not take place on the second day, but the day is still counted as one of the days of shiva.\n\nThere are many traditions that are upheld in order to observe shiva. Throughout this time, mourners are required to stay at home and refrain from engaging with the social world.\n\nAfter hearing of the death of a close relative, Jewish beliefs and traditions instruct individuals to tear their clothing as the primary expression of grief. The process of tearing the garment is known as \"keriah\". Upon tearing the clothing, the mourner recites a blessing which describes \"the true Judge\" as God. This blessing reminds mourners to acknowledge that God has taken the life of a close relative, and is seen as the first step in the acceptance of grief. The garment is torn over the heart if the individual who died was a parent, or over the chest on the right side if the individual who died was another relative. The torn article of clothing is worn throughout the period of shiva, the only exception being on Shabbat.\n\nAfter being near or around the deceased, it is ancient custom to wash yourself, or at minimum wash hands, as a means of purification. After a funeral, or visitation to a cemetery, individuals are required to wash hands as a mark of spiritual transition through water. During shiva, it is especially mandatory to do so before entering the home. There are many different origins of this tradition, however typically the act is associated with symbolic cleansing, the idea being that death is impure in a spiritual sense. Within Judaism, the living is thought to emphasize value of life rather than focus on death. When washing hands after visiting the deceased, it is custom to not pass the cup of water used from person to person. The reason behind this stems from the beliefs and hopes of stopping the tragedy where it began, rather than allowing it to continue from person to person as symbolized by the passing of the cup.\n\nThe first meal which should be eaten after the funeral is known as the \"seudat havra'ah\" (). Traditionally, mourners should be served the meal of condolences by neighbors. The act of preparing such meal is considered to be a mitzvah. Though being the tradition, if the meal of condolences is unable to be prepared by a neighbor, extended family may do so, and in the last case the mourner themselves may prepare the meal. It was seen that many times following the death of a loved one, individuals who were in mourning possessed a death wish and often times attempted to undergo starvation. The meal given to them upon returning home provided warmth in order to lessen such wishes. In order to be deemed the meal of condolences, the food selections must contain several specific dishes. An example of this is bread, which is symbolic for the staff of life. Aside from this, the meal must contain hardboiled eggs, cooked vegetables, and coffee or tea. Often times wine is allowed to be served as well. The only time the meal of condolences is not served occurs when there is no public observance of mourning or if the individual who died did so due to suicide.\n\nWithin Judaism, candles are symbolic of special events throughout life. They are lit during major holidays, during shabbat, and during the process of mourning candles are required to burn for the entirety of shiva. Prior to the death of Rabbi Judah Hanasi in the thirteenth century, he instructed that a light should be kept burning. During shiva, the candle represents the deceased. The light is symbolic of the human being, the wick and flame are representative of the body and soul respectively, as well as their connection with one another. Traditionally, candles are required to be made of either oil or paraffin and are not allowed to be electric. The candle is ideally burned in the home of the deceased, however exceptions can be made. Regardless, however, candles should be in the presence of those observing shiva. During major holidays, the candle may be moved in order to lessen the feeling of mourning and focus on the joyous occasion at hand.\n\nIndividuals who are in mourning, or in a shiva home, are required to cover mirrors from the time an individual dies until the end of shiva. There are several reasons as to why Judaism requires this. The first reason may stem from the idea that man was created in the image of God. In doing so, man acquires the same dignity and value as God. When a creation of God dies, this lessens His image. The death of human beings disrupts the connection between the living man and living God. Since the purpose of mirrors is to reflect such image, they are covered during mourning. A second reason as to why mirrors are covered in Judaism branches from contemplation of ones relationship with God during the death of a loved one. At this time, individuals are instructed to focus on grief and mourning rather than themselves. In order to prevent selfish thoughts, all mirrors are covered within the homes of mourners. A third reason which depicts why mirrors should be covered comes from the law which states that an individual may not stand directly in front of an image or worship one. Therefore, mirrors and pictures are hidden during mourning.\n\nLeather shoes are not permitted to be worn during the observance of shiva. The reasoning behind this involves a lack of luxury. Without leather shoes, an individual is able to concentrate on mourning and the deeper meaning of life. However, exceptions to this rule include pregnant women. and those with ailments of the feet. Aside from those observing shiva or sheloshim, guests and individuals who are not should refrain from wearing leather shoes in the home of mourners as well.\n\nSimilar to the idea of wearing leather shoes, hygiene and personal grooming fall under the idea of the task being done for pleasure. Such acts are prohibited during the observation of shiva or sheloshim as they are seen as actions done for physical comfort. However, there is a fine line which separates grooming for hygienic reasons and for comfort. Therefore, in order to prevent grooming for comfort individuals who are mourning are instructed to only bathe separate parts of the body, head, and face. On top of this, cold or cool water is recommended. The use of cosmetics are not allowed as this constitutes as an act done for comfort and pleasure. However, the exception to this rule being a woman who is a bride, engaged to be married, dating to be married, or feels as though the use of makeup is necessary.\n\n\"Sitting\" shiva refers to the act of sitting on low stools during times of mourning. As mentioned in the Book of Job, upon mourning, Job's friends \"sat down with him upon the ground seven days and seven nights\". Therefore originally, individuals who were observing a period of mourning were required to turn couches or beds over and sit on the ground. After time, modifications towards this rule were made. The \"Halakhah\" states that an individual is required to sit on low stools, or on the floor. The individual partakes in sitting on a low stool in order to signify their lack of concern for personal comfort during their time of mourning.\n\nThe best place for the observance of shiva to take place is within the home of the deceased individual. However, if observance in the home of the deceased is not permitted or is unable to be done, the second best place is in the home of a relative close to the deceased. During the observance of shiva, individuals are not permitted to leave the premises, however, there are certain exceptions to this rule. Exceptions include, not having enough room to house every individual observing, the loss of another loved one, and the inability to conduct services in the home. If an individual mourning is allowed to leave the home, they must do so without disturbing others and never alone.\n\nPraying in the home of a mourner is done in order to demonstrate respect for the grieving individual as well as the deceased. Even as early as 1790, the Hebra Maarib beZemanah Oheb Shalom was founded in order to provide mourners observing shiva with a minyan. During 1853 in London, the Hebrath Menachem Abelim Hesed Ve Emeth was constructed to accomplish a similar goal. Throughout history, prayers during mourning have been important. However during shiva, the prayers change slightly.\n\nDuring the process of mourning, Kaddish is typically recited. Rather than losing faith in the religion, Jewish traditions require those who have experienced the loss of a loved one to publicly assert their faith in God. This is typically done in front of a minyan. The recitation of Kaddish is done in order to protect the dignity and merit of the individual who died within God's eyes. Judaism believes that prior to a soul's entry into heaven, a maximum of twelve months is required in order for even the worst soul to be purified. Though the entirety of mourning lasts for twelve months, Kaddish is only recited for eleven months so as to not imply the soul required an entire twelve months of purification.\n\nTraditionally the true mourner's prayer is known as \"El Molai Rachamim\" in Ashkenazi literature and \"Hashkavah\" in Sephardic literature. Often times the mourner's prayer is mistaken for Kaddish. The recitation of the mourner's prayer is done for the soul of an individual who has died. The prayer itself is an appeal for the soul of the deceased to be given proper rest. Typically recitation of this prayer is done at the graveside during burial, during the unveiling of the tombstone, as well as at remembrances services during Yom Kippur, Shmini Atzeret, the final day of Passover, and the final day of Shavuot. If the recitation is done as an individual commemoration, the prayer contains the name of the individual who died. However, if the recitation is done in the presence of a group, the prayer will contain a description of the individual who died.\n\nThe recitation of the mourner's prayer is done differently depending on the gender of the one for whom is said.\n\nIf the mourner's prayer is recited on behalf of a woman, the following text is recited:\n\nIf the mourner's prayer is recited on behalf of a man, the following text is recited:\n\nA minyan is traditionally a quorum of ten or more adult males. Often times in Conservative or Reform communities, a minyan is composed of a mix of ten or more adult males and females. During shiva, a minyan will gather at the home of those in mourning for services. The services are similar to those held at a synagogue. During shiva, however, certain prayers or verses are either added or omitted. During the days that the Torah is read in a synagogue, it is likewise read at the shiva home. An effort is made by the community to lend a Torah scroll to the mourner for this purpose.\n\nAddition of \"Psalm XLIX\" - Redemption of the Soul \n\nOmission of \"Pitum Haketoret\" \n\nOmission of \"Tachanun\" and/or \"Nephilat Appayim\" \n\nSubstitution of \"Psalm XVI\" for \"Psalm XLIX\" during the omission of \"Tachanun\" \n\nOmission of \"Psalm XX\" \n\nOmission of \"The Priestly Benediction (Number VI: 24-26)\" \n\nOmission of the six Psalms before Friday night services\n\nOmission of \"Psalm XC: 17\" verse: \"And let the graciousness of the Lord our God be upon us: establish thou also upon us the work of our hands, yea, the work of our hands establish thou it\" \n\nSpices are omitted from use in the home of a mourner during Havdalah (the end of shabbat) \n\n\n"}
{"id": "5188359", "url": "https://en.wikipedia.org/wiki?curid=5188359", "title": "The Cabinet of Dr. Caligari (2005 film)", "text": "The Cabinet of Dr. Caligari (2005 film)\n\nThe Cabinet of Dr. Caligari is a 2005 American horror film directed by David Lee Fisher who also co-wrote the film's screenplay, and is a remake of the 1920 silent film of the same name. It was released in the U.S. at the ScreamFest Film Festival on October 22, where it won three prizes: the Audience Choice Award, Best Cinematography and Best Special Effects.\n\nThe plot is largely similar to that of the original film with extra dialogue scenes. The film tells the story of the deranged Dr. Caligari and his faithful sleepwalking Cesare and their connection to a string of murders in a German mountain village, Holstenwall. The movie features a \"frame story\" in which the body of the plot is presented as a flashback, as told by Francis.\n\nThe narrator, Francis, and his friend Alan visit a carnival in the village where they see Dr. Caligari and Cesare, whom the doctor is displaying as an attraction. Caligari brags that Cesare can answer any question he is asked. When Alan asks Cesare how long he has to live, Cesare tells Alan that he will die tomorrow at dawn — a prophecy which turns out to be fulfilled.\n\nFrancis, along with his girlfriend Jane, investigate Caligari and Cesare, which eventually leads to Jane's kidnapping by Cesare. Caligari orders Cesare to kill Jane, but the hypnotized slave refuses after her beauty captivates him. He carries Jane out of her house, leading Jane's father and brother on a chase. Cesare is stabbed to death after being pursued by Jane's brother, and Francis discovers that Caligari had created an illusion of Cesare to distract him.\n\nFrancis discovers that \"Caligari\" is the head of the local insane asylum, and with the help of his colleagues discovers that he is obsessed with the story of a medieval Dr. Caligari, who used a somnambulist to murder people as a traveling act. After being confronted with the dead Cesare, Caligari breaks down, reveals his mania and is imprisoned in his own asylum.\n\nThe \"twist ending\" reveals that Francis' flashback is his fantasy: The man he claims is Caligari is indeed his doctor in the asylum, who, after this revelation of the source of his patient's delusion, claims to be able to cure him.\n\n\nThe film was released on DVD by Image on June 5, 2007.\n\nOn Rotten Tomatoes, the film holds an approval rating of 43% based on , with a weighted average rating of 5/10. \nOn Metacritic, which assigns a normalized rating to reviews, the film has a weighted average score of 62 out of 100, based on 5 critics, indicating \"Generally favorable reviews\". Neil Genzlinger from the New York Times noted that Fisher did manage to \"out-disoriented the original\", although he felt it wasn't in the way the director intended. Genzlinger concluded his review by calling the film \"Scary, disturbing, intriguing, all at once\" TV Guide's Maitland McDonagh awarded the film 3/5 stars, commending Hopkins, Kraal, and Jones' performances as well as the digital recreation of the original film's artificial backdrops.\nR. Emmet Sweeney from The Village Voice gave the film a negative review, writing, \"Although technically impressive, the remake is dramatically inert, as the set becomes a motionless backdrop to theatrical line readings instead of a pulsing manifestation of diseased minds. It’s Caligari embalmed. The plot is followed to the letter, and as Cesare, Doug Jones displays a wounded sensitivity that honors Conrad Veidt’s celebrated turn. But there’s nothing here to keep you from renting Robert Wiene’s timeless masterpiece instead.\" Ed Gonzalez from Slant Magazine offered similar criticism, stating that the director's determination to recreate the original film, resulted in revealing the original's \"unsophisticated storytelling and limited feeling\".\n\n"}
{"id": "29923416", "url": "https://en.wikipedia.org/wiki?curid=29923416", "title": "The Hussaini Encyclopedia", "text": "The Hussaini Encyclopedia\n\nThe Hussaini Encyclopedia (Arabic - دائرة المعارف الحسينية - \"Dāʾirat al-maʿārif al-Ḥusaynīyah\") is a one-of-a-kind encyclopedia in Arabic, completely themed on the third Holy Imam, Husayn ibn Ali, his biography, thought and way of conduct, as well as on the social circle of personalities around him and also of places, chronicles and various other related subjects. This encyclopedia consisted of 700 volumes and well over 95 million words. Sheikh Mohammed Sadiq Al-Karbassi, author of the voluminous Arabic encyclopedia dedicated to Imam al-Hussain started his work by establishing the Hussaini Center for Research in London in 1993. The Hussaini Encyclopedia is a historic study of al-Hussain which provides a heritage owing to its impact on all events, particularly the aftermath of battle of Karbala with its impact being observed in recent times.\n\nIn 1987, Al-Karbassi planned to work on the Hussaini Encyclopedia and established the Hussaini Center for Research in London in 1993. The encyclopedia is completely themed on Imam Al-Hussain His inspiration to start this work was by him who \"does not speak out of his own fancy\" (The Star 53-3 – i.e. the Islamic prophet Mohammed) when he declared: \"Hussain is from me and I am from Hussain\". And this work has penetrated the barriers of time, place, language and identity in searching and conveying pieces of information related to the Cause of Imam Al-Hussain.\n\nIt covers many different aspects and things which are related to Hussain Ibn Ali, these include: Al-Hussain in the Quran, The Hussaini Biography, Al-Hussain and Legislation, The Dreams, Visions and Interpretations, Glossary of Al-Hussain's Partisans, Glossary of Hashemite Partisans of Al-Hussain, Historical Investigations in the Hussaini uprising, Imam Al-Hussain's Uprising – Emergence and Confirmation of History, Al-Hussain's Life Story, History of the Shrines, 'Ziyara' (holy 'visits' to and prayers) at Al-Hussaini Shrines, Anthology of the First to Fifteenth Hijra Century poetry, Arabic, Persian, Urdu, Turkish, English, Albanian, Oriental and Occidental Poetry.\n\nThe Hussain Encyclopedia is in Arabic but some parts have been translated into different languages such as: English, Persian, Urdu and Pashto. It now consists of over 700 volumes and will over 95 million words, these numbers are expected to continue growing.\n\nThis is in principle individual work; however the author has had assistance from people such as researchers, poets, men-of-letters and journalists.\n\nTo avoid misunderstanding, the title of the Encyclopedia has been registered in the international languages.\n\nSome of the Hussaini Encyclopedia are available as online books.\n\nThe Hussaini Encyclopedia is Available in many Libraries;\n\nBodleian Libraries of the University of Oxford.\n\nMar'ashi Najafi library, Qom.\n\nCambridge University Library.\n\nThe National Library of Scotland.\n\nThe Library of Trinity College, Dublin.\n\nThe National Library of Wales.\n\nHusayn ibn Ali, the grandson of Muhammad and son of Ali & Fatimah; the third Holy Imam of Shia Muslims, who is also known as the Martyr of Martyrs, was killed on Friday, 10th Muharram, 61 Hijri in the Battle of Kerbela, the place is situated at present day Iraq. This day is more commonly known as the Day of Ashura. He was massacred along with some followers, friends, relatives, and his family members by the army of Yazid ibn Mu'awiya, through this promised immolation the faith of Islam was rescued. Yazid's attempt to mold the doctrine of faith and planned to have it endorsed by pledge of allegiance from Hussain Ibn Ali became void by this sacrifice.\n\nThe author of The Hussaini Encyclopedia Sheikh Mohammed Sadiq Al-Karbassi was born 20th Oct, 1947 (5th ZilHijjah 1366 in the Holy City of Kerbela, Iraq. He comes from a well-educated family and graduated from established academic institutions of Kerbela, Najaf, Teheran and Qum. Al-Karbassi has lived in Iraq, Iran, The Lebanon, and Syria; he now resides in the United Kingdom. Sheikh Al-Karbassi has founded, or took part in founding, some forty institutions and has practiced teaching, authorship, research and imamate, along with practicing the teaching Islamic bodies of knowledge in different cultural metropolitan cities. His work exceeds hundreds, with his work being published in various magazines and articles and his biography has been cited in numerous reference books. His self-fulfilment is in the Hussaini Encyclopedia, work on this commenced on the eve of the eleventh of Muharram, 1408 H, the 5th of September 1987. He has never ceased his work since then.\n\nThe Hussaini Centre for Research was established in London in 1993 (1414 H), Sheikh Mohammed Sadiq Mohammed Al-Karbassi used his home as the first base, and foundation for research as his office. There he welcomed politicians and journalists to his home. The centre has relocated to its current location in 2003.\nThe Hussaini Centre Registered Charity in the UK. No: 1106596, under the title \"The Hussaini Charitable Trust\".\n\nThe centre has a hall for general meetings, with rooms for studying, researching and translating texts. The centre receives many students looking to use its growing private library, which contains over 25,000 titles, specializing on topics of different scholars, with texts and archives in many languages.\n\nThe centre stands alone when it comes to holding an entire specialized department containing handwritten and rare documents on different scientific and philosophical topics; the documents in this specialized department hold important historical and scientific value, some being hundreds of years old.\n\nThe centre continuously receives awards and nominations, for science and academic studies. The centre has also been the recipient of highly regarded certificates and given the approval of many researchers on science and knowledge. They have visited the centre on countless occasions to dwell upon and answer many questions regarding science and the development of life.\n\nThe centre continuously tries to answer the queries of various university students and researchers, using the knowledge of Sheikh Al-Karbassi, and centre's personal library. Many university professors from around the world's universities, notably the UK, Canada, and Germany, have requested their students to study the centre's publications and documents.\n\nThe centre has strong relationships and works on many projects regarding science and culture with other global establishments, universities and colleges; including relations with academic professors and lecturers in: Algeria, Australia, Bahrain, Canada, China, Cyprus, France, Iran, Iraq, Italy, Kuwait, Lebanon, Norway, Palestine, Russia, Saudi Arabia, South Africa, Sweden, Switzerland, Syria, Tajikistan, the United Kingdom, the United States of America, and many other countries.\n\nThe most notable work of the Hussaini Centre for Research would be the production of The Hussaini Encyclopedia itself, which consists of more than 700 hand written books (drafts) and 105 books published so far. The encyclopedia itself is mainly about Imam Hussain, and anything connected to Imam Hussain is also mentioned and written about in this great encyclopedia.\n\nThe author has observed certain methodical principles in structuring this Encyclopedia which he believes must be adhered to for any desired achievement connected to any work. Below are a few of the things which he followed in producing The Hussaini Encyclopedia:\n\n- In view of facilitation, classification and good order, every section is divided into main chapters, and each chapter is divided into subsections. All materials are headed, numbered and marked which could assist the task of the reader, researcher and critic. For avoiding ambiguity, all texts are marked by phonetic signs when necessary.\n\n- In The Hussaini Encyclopedia each volume is followed by some selected verses from the Quran which give praise to Allah, his Messenger (Mohammed), and his family (Ahlul Bayt). Each volume is also followed by Hadiths narrated from both sects of Islam which relate to the Cause of Imam Al-Hussain.\n\n- Every important chapter or section is coupled with a three-line rhyme-prose supplication that consists of praising The Creator, praying for the Seal of prophets and saying Peace be Upon Him and on his noble family. These lines amount to about a hundred different supplications on a single subject.\n\n- Each chapter or section has an introduction, and each chapter or section ends up with a conclusion where a summary of topics is states. Each volume ends with a concise summary of topics from that volume. These informative conclusions have been worked by scholarly personalities of different ethnic, religious and sectarian identities.\n\n- The information in the Encyclopedia is of reviewed work and comes free of prejudice. It's not set from an assumption and then supporting evidence searched for.\n\n- Anything of uncertainty has been explained in the margins where plenty of space is left for text and commentaries.\n\nBelow are a list of things The Hussaini Encyclopedia hopes to achieve:\n\n\n"}
{"id": "10944830", "url": "https://en.wikipedia.org/wiki?curid=10944830", "title": "Worship Jamz", "text": "Worship Jamz\n\nWorship Jamz is a series of albums featuring popular songs sung by children. It can be seen as a Christian version of Kidz Bop, which is produced by the same company, Razor & Tie.\n\n\n\nAll songs arranged, produced, and mixed by Rick Altizer, except tracks 6, 13, 16 arranged and produced by Jim Frazier.\n\n\n\n\n\n"}
{"id": "22632609", "url": "https://en.wikipedia.org/wiki?curid=22632609", "title": "Writing Workshop", "text": "Writing Workshop\n\nWriting Workshop is a method of writing instruction that developed from the early work of Donald Graves, Donald Murray, and other teacher/researchers who found that coaching students to write for a variety of audiences and purposes was more effective than traditional writing instruction. This approach has been popularized by Lucy Calkins and others involved in the Reading and Writing Project at Columbia University in New York City, New York. (Calkins, L (2006). \"A Guide to The Writing Workshop, Grades 3-5\". Portsmouth, NH: First Hand). This method of instruction focuses on the goal of fostering lifelong writers. It is based upon four principles: students will write about their own lives, they will use a consistent writing process, they will work in authentic ways, and they will develop independence as writers. \n\nWriting Workshop is designed for use in all grade levels. Each grade level has specific units of study tailored to meet developmental and curricular needs. Students have a large amount of choice in their topic and style of writing. The teacher acts as a mentor author, modeling writing techniques and conferring with students as they move through the writing process. Direct writing instruction takes place in the form of a mini-lesson at the beginning of each workshop and is followed by a minimum of 45 minutes of active writing time. Each workshop ends with a sharing of student work.\n\nEstablishing a consistent writing process that the students work through is one of the main principles of the Writing Workshop. Each student moves through the process at his or her own rate, however it is best to set a deadline for each step so that each writing unit is completed in a timely manner. \n\nPossible timeline for workshop: \n\n\n1. Signal the beginning of Writing Workshop\n2. Direct, explicit mini-lesson (See mini-lesson information below).<br>3. Writing time\n4. Sharing of student work\n\nMini-lessons should be about 10–15 minutes in length. Not all proponents of writing workshop include a mini-lesson, however, as some approaches incorporate the instruction into small-group or individual conferences. Calkins, however, recommends following the same structure each time: make a connection to a previous lesson, teach a new writing technique, and have the students practice the technique right there with your guidance.\n\nPossible Mini-lesson topics are:\n\nLucy Calkins (1994) has described conferring as, “the heart of our teaching” (p. 189) in the Writing Workshop. Conferring in the Writing Workshop takes place during the time when students are actively writing. The teacher circulates around the room, meeting with individual students or student groups to discuss their writing progress. The conferences are often short, typically lasting anywhere from two to seven minutes (Ray, 2001, p. 158). Calkins (1994) has described a three-step process for facilitating these conferences: “research, decide, teach” (p. 224). The teacher begins the conference by asking probing, open-ended questions to ascertain the student’s current focus in his/her writing work. Once the teacher has identified an area of need, the teaching can begin. The teaching often includes critical feedback for the student, a short time in which the student and teacher practice the new skill or strategy, and a link to how the new skill or strategy will improve the child’s future work as a writer (Anderson, 2000, p. 26). Another component of the conference is record keeping. The teacher, and sometimes also the student, can make anecdotal notes about the content of the conference. This will allow the teacher to refer back to previous notes and monitor students’ growth as writers.\n\n“The interesting thing is that in teaching writing, we often unmask our own processes in readers and writers, thinking aloud in front of our kids so they can learn how good readers and writers think about texts\" (Calkins, Hartman, White, 2005, p. 62). The teacher knows it is important while facilitating the start of the conference to begin with a positive comment about the student’s writing piece. One way to get better on forming instructional needs is to take time to look at “student work outside of class time and thinking about the decision you might make for this student” (Calkins, Hartman, White, 2005, p. 62). Peter Elbow pioneered thinking about feedback through workshop approaches. \n\nInternational Writing Project instructors Allen Koshewa and Elly Tobin emphasize that teaching students how to respond to each other's work is also crucial. They recommend that a peer response session include providing feedback on the overall message, citing at least one strong point about the writing or its potential, and inviting the author to present concerns or questions.\n\nAlthough the National Writing Project and other organizations promoting workshop approaches favor an organic approach rather than a scripted one, the writing workshop approach has increasingly been commercialized. Lucy Calkins and her colleagues from The Reading and Writing Project at Teachers College have recently written a new guide called \"A Curricular Plan for the Writing Workshop\" (Heinemann, 2011). This aligns the units of study she has recommended in the past with the new Common Core State Standards.“ This curriculum reflects the genres for writing that are spelled out by the Common Core Standards and gives children several opportunities to write in those genres: narrative, persuasive, informational, and poetry.“ (p. 2 A Curricular Plan for the Writing Workshop). The new units demonstrate more of a focus on informational, persuasive writing, and revision than the original unit plan developed by Calkins. Written by grade level, this resource takes the school year month by month and guides teachers towards instructing with a balance of narrative and nonfiction writing. Minilesson ideas, additional resources and celebrations are discussed as well, with a focus towards “lifting the level of student work” in every unit.\n\nWebsites for additional information: \nBooks\n\n"}
