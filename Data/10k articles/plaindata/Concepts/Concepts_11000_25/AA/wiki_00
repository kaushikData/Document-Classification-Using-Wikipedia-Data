{"id": "40754984", "url": "https://en.wikipedia.org/wiki?curid=40754984", "title": "Antecedent (behavioral psychology)", "text": "Antecedent (behavioral psychology)\n\nAn antecedent is a stimulus that cues an organism to perform a learned behavior. When an organism perceives an antecedent stimulus, it behaves in a way that maximizes reinforcing consequences and minimizes punishing consequences. This might be part of complex, interpersonal communication.\n\nAntecedent stimuli (paired with reinforcing consequences) activate centers of the brain involved in motivation, while antecedent stimuli that have been paired with punishing consequences activate brain centers involved in fear.\n"}
{"id": "37937138", "url": "https://en.wikipedia.org/wiki?curid=37937138", "title": "Barrier analysis", "text": "Barrier analysis\n\nBarrier analysis is a rapid assessment tool used in behavior change projects. The purpose of barrier analysis is to identify behavioral determinants, so that more effective behavior change, communication messages, strategies, and supporting activities can be developed. Barrier analysis is a relatively easy approach that can be conducted in a short period of time, allowing implementers to quickly make decisions based on the findings. This method has been used in 38 countries by 34 organizations. The training manual is available in English, Spanish, French, and Arabic.\n\nBarrier analysis was developed in 1990 by Tom Davis, MPH (an independent consultant formerly with Food for the Hungry) based on the health belief model and the theory of reasoned action. Since then, it has been adopted by at least 34 organizations working in 45 countries around the world to study determinants of behaviors related to child survival, food security, sexual and reproductive health, city planning, and other areas. The methodology has continued to evolve as it has been tested in different settings. It has primarily been used for international development, although it has also been used and taught in the developed world as well (e.g. by the Baltimore City Government for analysis of trash can use, Feed the Children and Hunger Free NYC to look at participation in the USDA summer meals program, and the Honey Bee Health Coalition).\n\nBarrier analysis can be used at the start of a behavior change program to determine key messages and activities for intervention. It can also be used in an ongoing program, focusing on behaviors that have not changed in order to understand what is stopping a it from happening.\n\nThe purpose of barrier analysis is to identify determinants of behavior change among a specific target audience. The four most commonly found determinants are self-efficacy, social norms, positive consequences, and negative consequences. Typically researchers interview 45 \"Doers\" (people who already practice the behavior) and 45 \"Non-doers\" (people who do not practice the behavior) and compare the responses. A difference of 15% or greater between the two interviewee categories is considered statistically significant. Such [\"statistically significant\"] determinants have a less than 5% probability of being due to chance.\n\n"}
{"id": "930376", "url": "https://en.wikipedia.org/wiki?curid=930376", "title": "Consistent life ethic", "text": "Consistent life ethic\n\nThe consistent life ethic, or the consistent ethic of life is an ideology that opposes abortion, capital punishment, assisted suicide, and euthanasia. Adherents are opposed, at the very least, to unjust war, while some adherents also profess pacifism, or opposition to all war. The term was popularized in 1983 by the Catholic Cardinal Joseph Bernardin to express an ideology based on the premise that all human life is sacred and should be protected by law.\n\nThe phrase \"consistent ethic of life\" was used as far back as a 1971 speech delivered by then-Archbishop Humberto Medeiros of Boston.\n\nIn 1971, Roman Catholic pacifist Eileen Egan coined the phrase \"seamless garment\" to describe a holistic reverence for life. The phrase is a Bible reference from John 19:23 to the seamless robe of Jesus, which his executioners did not tear apart. The seamless garment philosophy holds that issues such as abortion, capital punishment, militarism, euthanasia, social injustice, and economic injustice all demand a consistent application of moral principles that value the sacredness of human life. \"The protection of life\", said Egan, \"is a seamless garment. You can't protect some life and not others.\" Her words were meant to challenge those members of the pro-life movement who were in favor of capital punishment.\n\nCardinal Joseph Bernardin of Chicago helped publicize the consistent life ethic idea in 1983. Initially, Bernardin spoke out against nuclear war and abortion. However, he quickly expanded the scope of his view to include all aspects of human life. In one of the first speeches given on the topic at Fordham University, Bernardin said: \"The spectrum of life cuts across the issues of genetics, abortion, capital punishment, modern warfare and the care of the terminally ill.\" Bernardin said that although each of the issues was distinct, nevertheless the issues were linked since the valuing and defending of (human) life were, he believed, at the center of both issues. Bernardin told an audience in Portland, Oregon: \"When human life is considered 'cheap' or easily expendable in one area, eventually nothing is held as sacred and all lives are in jeopardy.\"\n\nBernardin drew his stance from New Testament principles, specifically of forgiveness and reconciliation, yet he argued that neither the themes nor the content generated from those themes were specifically Christian. By doing this, Bernardin attempted to create a dialogue with others who were not necessarily aligned with Christianity.\n\nBernardin and other advocates of this ethic sought to form a consistent policy that would link abortion, capital punishment, economic injustice, euthanasia, and unjust war. Bernardin sought to unify conservative Catholics (who opposed abortion) and liberal Catholics (who opposed capital punishment) in the United States. By relying on fundamental principles, Bernardin also sought to coordinate work on several different spheres of Catholic moral theology. In addition, Bernardin argued that since the 1950s the church had moved against its own historical, casuistic exceptions to the protection of life. \"To summarize the shift succinctly, the presumption against taking human life has been strengthened and the exceptions made ever more restrictive.\"\n\nThe non-profit organization Consistent Life Network, founded in 1987 as the Seamless Garment Network, promotes adherence to the ethic through education and non-violent action. Individual endorsers belonging to the Consistent Life Network organization include Father Daniel Berrigan, theologian Harvey Cox, \"Village Voice\" columnist Nat Hentoff, Father Theodore Hesburgh, actress Patricia Heaton, \"L'Arche\" founder Jean Vanier, death penalty activist Sister Helen Prejean, pro-life activist Abby Johnson, author Ken Kesey, Archbishop of Canterbury Rowan Williams and Nobel Peace Prize laureates Mairead Corrigan Maguire and Adolfo Pérez Esquivel. Rachel MacNair, for ten years (1994–2004) President of Feminists for Life, a pro-life organization, is the director of the Institute for Integrated Social Analysis, the research arm of Consistent Life Network.\n\nIn the US, several groups have promoted the \"consistent ethic of life\" approach, including the United States Conference of Catholic Bishops, Democrats for Life of America, and the American Solidarity Party, a Christian Democratic political organization. Groups without a religious orientation that support the ideology include Democrats for Life of America, the Pro-Life Alliance of Gays and Lesbians (PLAGAL), and All Our Lives (a pro-contraception feminist group), all of which are members of the Consistent Life Network. Other secular groups supporting a consistent ethic of life position include Rehumanize International (formerly known as Life Matters Journal) and New Wave Feminists. Other prominent authors who have written in support of the consistent life ethic include Frank Pavone, James Martin, John Dear, Ron Sider Tony Campolo, Joel Hunter, Wendell Berry, and Shane Claiborne.\n\nAccording to Michael Leach, \"If one contends, as we do, that the right of every fetus to be born should be protected by civil law and supported by civil consensus, then our moral, political and economic responsibilities do not stop at the moment of birth.\" This viewpoint was emphasized by Pope John Paul II in his 1995 encyclical, \"Evangelium Vitae\" (Gospel of Life). This book-length document outlined the Pope's emphasis on fostering a culture of life based on the New Testament and the life of Jesus. Specifically, he emphasized the value and inviolability of human life, from conception until natural death.\n\nRather than \"thinking of a pregnant women and her fetus as being adversaries battling over exclusive rights, the right of a woman to control her body versus the right of the fetus to live long enough to control hers\", a consistent life ethic would view both as valuable and important, and seek to provide both all the support they needed to live and live well.\n\nTraditionally, arguments for the death penalty focus on the idea that it: 1) deters further violence; 2) enacts just retribution on the criminal, effectively gaining a sense of justice for society and those affected by the crime; 3) seeks to reform other criminals with the threat of such severe punishment and; 4) protects society from those criminals which the government has deemed to be the most heinous.\n\nBernardin and some other consistent life ethic advocates recognize the right of the state to use capital punishment. However, they reject the necessity of this type of punishment for many reasons, arguing that there are more appropriate and effective ways for the state to defend its people. Many consistent life ethic advocates call for a total abolition of the death penalty. The consistent ethic's opposition to capital punishment is rooted in the conviction that an atmosphere of respect for life must pervade a society, and resorting to the death penalty does not support this attitude. Adherents argue that the result of the death penalty – removing the criminal from society, enacting justice on the criminal, and bringing about feelings of revenge for those affected and the greater society – do not necessarily have to be accomplished by taking a life.\n\nOne out-spoken anti-death penalty activist is Sister Helen Prejean. Her books \"Dead Man Walking\" and \"The Death of Innocents: An Eyewitness Account to Wrongful Executions\" are autobiographical accounts of the time she spent ministering to death row inmates. Another notable independent Catholic anti-death penalty organization is Priests for Life.\n\nBernardin understood the consistent life ethic as implying a societal responsibility to provide adequate health care for all, especially the poor.\n\nAccording to Ron Hamel...a moral vision constituted by the consistent ethic of life sensitizes one to procedures, technological developments, and aspects of the health care system that fail to promote or do not adequately promote human dignity and do not sufficiently enhance human life. ...it is not sufficient to only oppose euthanasia, but one must also be concerned about and address those factors that give rise to euthanasia and find ever better ways to care for the dying and ensure the dying the opportunity to forgo treatment and to live their lives fully while dying.\n\nAs such, appeals to the consistent life ethic have been made in support of universal health care. \n\nThe consistent life ethic has been invoked to include care for immigrants and refugees. While not directly appealing to the consistent life ethic, other Catholics have sought to apply the \"pro-life\" ethic to the issue of immigration.\n\nOne criticism made of the consistent life ethic position is that it inadvertently helped provide \"cover\" or support for politicians who supported legalized abortion or wanted to minimize this issue, a circumstance that Bernardin himself both recognized and deplored.\nA critic of Joseph Bernardin, George Weigel rejected the claims that the consistent life ethic had been created to cover up for abortion rights, saying that Bernardin was \"a committed pro-lifer\".\n\nArchbishop José Gómez of Los Angeles criticized the \"seamless garment\" approach in 2016 because in his view it results in \"a mistaken idea that all issues are morally equivalent.\"\n\n\n\n\n"}
{"id": "17323301", "url": "https://en.wikipedia.org/wiki?curid=17323301", "title": "Critical vocabulary", "text": "Critical vocabulary\n\nA critical vocabulary is a formal terminology related to one or more branches of critical theory. Although it may be considered a type of jargon, it is predominantly used by academics and is not slang. The word \"critical\", as used in the term \"critical vocabulary\", takes on two meanings: \"of essential importance\" and \"of or pertaining to critics or criticism.\" Thus, the vocabulary is of essential importance to the critical theory that employs it and is used by that critical theory in order to produce criticism.\n\nUnlike the term \"jargon\", the term \"critical vocabulary\" is seldom used as a collective noun. It is typically preceded by the definite or indefinite article. When speaking about more than one critical theory, it is used in the plural (i.e. \"the critical vocabularies of postmodern studies\").\n\nSeveral people have criticized critical vocabularies as tools of alienation or obfuscation. Also there have been assertions that the relatively recent proliferation of critical vocabularies has resulted in redundancy of both terms and ideas. See the Pitfalls section under jargon.\n\n\n"}
{"id": "13240808", "url": "https://en.wikipedia.org/wiki?curid=13240808", "title": "Curriculum-based measurement", "text": "Curriculum-based measurement\n\nCurriculum-based measurement, or CBM, is also referred to as a general outcomes measures (GOMs) of a student's performance in either basic skills or content knowledge.\n\nCBM began in the mid 1970s with research headed by Stan Deno at the University of Minnesota. Over the course of 10 years, this work led to the establishment of measurement systems in reading, writing, and spelling that were: (a) easy to construct, (b) brief in administration and scoring, (c) had technical adequacy (reliability and various types of validity evidence for use in making educational decisions), and (d) provided alternate forms to allow time series data to be collected on student progress. This focus in the three language arts areas eventually was expanded to include mathematics, though the technical research in this area continues to lag that published in the language arts areas. An even later development was the application of CBM to middle-secondary areas: Espin and colleagues at the University of Minnesota developed a line of research addressing vocabulary and comprehension (with the maze) and by Tindal and colleagues at the University of Oregon developed a line of research on concept-based teaching and learning.\n\nEarly research on the CBM quickly moved from monitoring student progress to its use in screening, normative decision-making, and finally benchmarking. Indeed, with the implementation of the No Child Left Behind Act in 2001, and its focus on large-scale testing and accountability, CBM has become increasingly important as a form of standardized measurement that is highly related to and relevant for understanding student's progress toward and achievement of state standards.\n\nProbably the key feature of CBM is its accessibility for classroom application and implementation. It was designed to provide an experimental analysis of the effects from interventions, which includes both instruction and curriculum. This is one of the most important conundrums to surface on CBM: To evaluate the effects of a curriculum, a measurement system needs to provide an independent \"audit\" and not be biased to only that which is taught. The early struggles in this arena referred to this difference as mastery monitoring (curriculum-based which was embedded in the curriculum and therefore forced the metric to be the number (and rate) of units traversed in learning) versus experimental analysis which relied on metrics like oral reading fluency (words read correctly per minute) and correct word or letter sequences per minute (in writing or spelling), both of which can serve as GOMs. In mathematics, the metric is often digits correct per minute. N.B. The metric of CBM is typically rate-based to focus on \"automaticity\" in learning basic skills.\n\nThe most recent advancements of CBM have occurred in three areas. First, they have been applied to students with low incidence disabilities. This work is best represented by Zigmond in the Pennsylvania Alternate Assessment and Tindal in the Oregon and Alaska Alternate Assessments. The second advancement is the use of generalizability theory with CBM, best represented by the work of John Hintze, in which the focus is parceling the error term into components of time, grade, setting, task, etc. Finally, Yovanoff, Tindal, and colleagues at the University of Oregon have applied Item Response Theory (IRT) to the development of statistically calibrated equivalent forms in their progress monitoring system.\n\nCurriculum-based measurement emerged from behavioral psychology and yet several behaviorists have become disenchanted with the lack of the dynamics of the process.\n\n\n"}
{"id": "1285569", "url": "https://en.wikipedia.org/wiki?curid=1285569", "title": "De-escalation", "text": "De-escalation\n\nDe-escalation refers to behavior that is intended to escape escalations of conflicts. It may also refer to approaches in conflict resolution. Escalations of commitment are often hard from spiraling out of proportions without specific measures being taken.\n\nDe-escalation is aimed at calmly communicating with an agitated client in order to understand, manage and resolve their concerns. Ultimately, these actions should help reduce the client’s agitation and potential for future aggression or violence. An inadequate intervention, or one occurring too late, may leave staff needing to utilize coercive measures to manage an aggressive or violent client. Coercive measures, such as chemical or mechanical restraints and seclusion, are damaging to the therapeutic relationship and harmful to clients and staff. \n\nDespite the importance of de-escalation in promoting a non-coercive psychiatric environment, a review of the literature conducted by Mavandadi, Bieling and Madsen (2016) identified only 19 articles that defined or provided a model of de-escalation. Articles converge on a number of themes (i.e. de-escalation should involve safely, calmly and empathetically supporting the client with their concerns). Hankin et al.’s (2011) review of four de-escalation studies reflected the somewhat unclear state of de-escalation research. Their review settled on eight goals, seven elements, 15 general techniques and 15 other techniques divided into three subheadings. Furthermore, a valiant attempt to synthesize the various models and definitions was conducted by Price & Baker (2012). Thematic analysis of 11 eligible studies converged on seven themes: three related to staff skills (e.g. empathetic concern, calm appearance and gentle tone of voice) and four related to the process of intervening (e.g. establish rapport, maintain safety, problem solve and set limits). The available literature provides clinical descriptions of effective de-escalation based on qualitative data and professional observations. However, these thematic analyses need to be supported by more objective data; one hallmark of such objectivity would be an empirical scale or quantitative measure of de-escalation.\n\n1. Valuing the client: Provides genuine acknowledgement that the client’s concerns are valid, important and will be addressed in a meaningful way.\n\n2. Reducing fear: Listens actively to the client and offers genuine empathy while suggesting that the client’s situation has the potential for positive future change.\n\n3. Inquiring about client’s queries and anxiety: Can communicate a thorough understanding of the client’s concerns, and works to uncover\nthe root of the issue.\n\n4. Providing guidance to the client: Suggests multiple ways to the help the client with their current concerns and recommends preventative measures.\n\n5. Working out possible agreements: Takes responsibility for the client’s care and concludes the encounter with an agreed-upon short-term solution and a long-term action plan.\n\n6. Remaining calm: Maintains a calm tone of voice and steady pace that is appropriate to the client’s feelings and behaviour.\n\n7. Risky: Maintains a moderate distance from the client to ensure safety, but does not appear guarded and fearful.\n\nSee: \nMavandadi, V.; Bieling, P. J.; Madsen, V. (2016-08-01). \"Effective ingredients of verbal de-escalation: validating an English modified version of the 'De-Escalating Aggressive Behaviour Scale'\". Journal of Psychiatric and Mental Health Nursing. 23 (6-7): 357–368. doi:10.1111/jpm.12310. ISSN 1365-2850\n\nStarting around 2015, after facing criticism after numerous high-profile killings of civilians by police officers, some police forces in the US adopted de-escalation training, designed to reduce the risk of confrontations turning violent or deadly for anyone involved.\n\nThe FIRST STEP Act prison reform bill mandates de-escalation training, especially for \"incidents that involve the unique needs of individuals who have a mental illness or cognitive deficit.\"\n\nThis often involves techniques such as taking a time-out, and deflecting the conversation to individuals in the group who are less passionately involved. This is commonly used by Fee Team in mental health nursing practice. It is also used as an anger management tool to remove tension between two participants in a conflictual relationship or intervention.\n\n"}
{"id": "8366559", "url": "https://en.wikipedia.org/wiki?curid=8366559", "title": "Difference theory", "text": "Difference theory\n\nDifference theory has roots in the studies of John Gumperz, who examined differences in cross-cultural communication. While difference theory deals with cross-gender communication, the male and female genders are often presented as being two separate cultures, hence the relevance of Gumperz's studies. In her development of the difference theory, Deborah Tannen drew on the work of Daniel Maltz and Ruth Borker, in particular their 1982 paper, \"A Cultural Approach to Male-Female Miscommunication\", which itself drew on the work of Gumperz. Mary Talbot makes reference to the term \"gender-specific culture\" in her critique of the difference theory, and this idea of genders being culturally separated is embodied by the 1992 publication \"Men Are from Mars, Women Are from Venus\". Difference theory is often compared with dominance theory and deficit theory, and together with the more contemporary dynamic theory they make up four of the theories most widely referred to and compared in the study of language and gender.\n\nThe reason for the popularity of Tannen's book \"You Just Don't Understand\", and the resultant popularisation of difference theory, is generally attributed to the style of Tannen's work, in which she adopts a neutral position on differences in genderlect by making no value-judgements about use of language by either gender. Talbot comments that this means the book provides explanations for domestic disputes without \"pointing the finger\" at anyone.\n\nDifference theory as postulated by Tannen is generally summarised into six categories, each of which pairs contrasting uses of language by males and females.\n\nTannen states that, for men, the world is a competitive place in which conversation and speech are used to build status, whereas for women the world is a network of connections, and that they use language to seek and offer support. In demonstrating this, Tannen uses the example of her husband and herself, who at one point had jobs in different cities. She remarks that whenever someone commented on this, she interpreted it as being an offer of sympathy or support. Her husband, on the other hand, took such comments as being criticisms and attempts to put him down. Tannen remarks that this displays the different approaches that women and men take in terms of status and support. Furthermore, men are also more likely to interrupt to get their point across and hence gain status.\n\nWomen seek comfort and sympathy for their problems, whilst men will seek a solution to the problem.\n\nTannen states that men's conversation is message-oriented, i.e. based upon communicating information. For women, conversation is much more important for building relationships and strengthening social links.\n\nMen will use direct imperatives (\"close the door\", \"switch on the light\") when speaking to others. Women encourage the use of superpolite forms, however (\"let's\", \"would you mind if ...?\").\n\nTannen asserts that most women avoid conflict in language at all costs, and instead attempt to resolve disagreements without any direct confrontation, to maintain positive connection and rapport. Men, on the other hand, are more likely to use confrontation as a way of resolving differences and thereby negotiating status. Tannen supports this view by making reference to the work of Walter J. Ong, whose 1981 publication, \"Fighting for Life\", asserts that \"expressed adversativeness\" is more an element of male culture than female culture. Tannen stresses that both forms of communication are valid ways of creating involvement and forming bonds.\n\nDifference theory asserts that in general men favour independence, while women are more likely to seek intimacy. Tannen demonstrates this with the example of a husband making a decision without consulting his wife. She theorises that he does so because he doesn't want to feel a loss of independence that would come from saying, \"Let me consult this with my wife first.\" Women, by contrast, like to demonstrate that they have to consult with their partner, as this is seen to be proof of the intimacy of the relationship. Tannen asserts that women, seeing the world as a network of connections and relationships, view intimacy as key to achieving consensus and avoiding the appearance of superiority, whereas men, who are more likely to view the world in terms of status, see independence as being key to establishing their status. Tannen also clarifies that while both men and women seek independence and intimacy, men tend to be focused on the former, while women tend to focus on the latter.\n\nGeneral criticisms are that Tannen's observations are largely anecdotal and cannot be said for all conjugal conversations, let alone mixed-gender interactions as a whole.\n\n\n"}
{"id": "4553564", "url": "https://en.wikipedia.org/wiki?curid=4553564", "title": "Dining in", "text": "Dining in\n\nDining in is a formal military ceremony for members of a company or other unit, which includes a dinner, drinking, and other events to foster camaraderie and \"esprit de corps\".\n\nThe United States Army, the United States Navy, the United States Coast Guard, and the United States Air Force refer to this event as a dining in or dining-in. The United States Marine Corps refers to it as mess night. Other names include regimental dinner, guest night, formal mess dinner, and band night.\n\nThe dining in is a formal event for all unit members, male and female; though some specialized mess nights can be officer- or enlisted-only. The unit chaplain is usually also invited, if an invocation is needed. A unit's dining-in consists of only the members of the unit, with the possible exception of the guest(s) of honor. An optional formal dinner, known as the dining-out may include spouses and other guests. The dining-out follows the same basic rules of the dining-in, but is often tailored to minimize some of the military traditions and be more approachable to civilian guests.\n\nThe practice of dining in is thought to have formally begun in 16th-century England, in monasteries and universities; though some records indicate that militaries have held formal dinners as far back as the Roman Legions. The Vikings held formal ceremonies to honor and celebrate battles and heroes. During the 18th century, the British Army incorporated the practice of formal dining into their regimental mess system. Customs and rules of the mess were soon institutionalized rules, known as the \"Queen's Regulations\". The mess night or \"Dining in\" became a tradition in all British regiments. The Americans, taking many of their traditions from the British military, held mess nights in the 18th and 19th century, but the tradition waned after the Civil War.\n\nDining in took a temporary halt in the Navy and Marine Corps when Navy Secretary Josephus Daniels imposed prohibition of alcoholic drink, but soon the tradition was restored. During World War II, the custom was revived in the U.S. military, initially in the US Army Air Forces 8th Air Force, which was based in Britain. AAFOfficers were invited to participate in British military hosted Mess Nights and then were obligated to reciprocate.\n\nA Formal function is one at which all mess members may be required to attend and Service Personnel are on official duty.\n\nThe entitlements for official functions are as follows:\n\n12 Formal Functions per annum. Generally these are 2 x seasonal balls and 10 x other functions (e.g. Mess Dinners) as agreed by mess committees.\n\n6 Formal Functions per annum. Generally these are 2 x seasonal balls and 4 x other functions (e.g. Mess Dinners) as agreed by mess committees.\n\nThe port\ndecanters are to be placed at pre-determined places and in front of the President and Vice President. The President and Vice President will remove the stoppers simultaneously and pass the decanters in a clockwise direction/to the left. Wine stewards are to follow the decanters round the table with a jug of water, filling the glass of any diner who declines port or madeira. The glasses of the President and Vice President will be filled last, after which they are to re-stop the decanters. All stewards may then be required to leave the dining room before the President calls upon the Vice President to propose the Loyal Toast. It should be remembered that whilst the Army and RAF stand for the Loyal Toast, the RN remain seated. Also, whilst passing the port, the RN would ensure the decanter does not leave the table whilst in the RAF; it is passed from hand to hand without touching the table. In the Army, it will depend on the traditions of the Regiment.\n\nBy the late 18th century, the British Army's \"mess night\" developed formal rules, as a result of troops being stationed in remote areas. Officers elected mess committees to conduct their meals. Towards the latter part of the 19th century, attending officers were expected to adhere to the rigid etiquette of Victorian-era society.\n\nIn modern times it is sometimes known as a \"regimental dinner\".\n\nRoyal Navy officers have the privilege of remaining seated when toasting the Sovereign. Some sources state that this privilege was granted by William IV. A popular story states that Charles II was on board his namesake ship \"Royal Charles\" and had bumped his head on the low overhead of the wardroom when he stood up to reply a toast that had been drunk to him. He stated that henceforth, naval officers would never again rise to toast a British sovereign. In 1964, Queen Elizabeth II extended the privilege to the Royal Marines in honour of their 300th anniversary.\n\nThe custom of \"dining in\" to welcome new officers and \"dining out\" to farewell retiring officers originated with the British, although the term came about much later. It has been discontinued in some countries such as the United States but is still practised by the Royal Navy.\n\nThe traditional toasts after dinner for ships at sea are shown below. On certain days, an alternative toast is available but the first one is most usual.\n\nSunday ‘Absent friends’ or ‘Absent friends and those at sea’ \n\nMonday ‘Our ship at sea’ or ‘Our native land’ \n\nTuesday ‘Our Sailors’ \n\nWednesday ‘Ourselves’ (as no one is likely to concern themselves with our welfare)’ or ‘Ourselves – Our swords’ \n\nThursday ‘A bloody war or a sickly season’ \n\nFriday ‘A willing foe and sea room’ ‘Fox hunting and old port’ \n\nSaturday ‘Our Families’\n\nFor Trafalgar Night Mess Dinners, the routine varies slightly from a normal dinner night. When the main course is about to be served, the Baron of Beef is first paraded around the table behind a drummer. Similarly, before commencing the service of the sweet, the Ships of the Line are also paraded around the table in a similar fashion to the Beef. The toasts used at dinner on Trafalgar Night are:\n\nThe Royal Air Force inherited many mess traditions from the British Army as a former corps. These customs were notably passed on the US Army Air Forces during World War II as British and American crew served alongside one another in close quarters.\n\nPortions of the event tend to become quite humorous in nature, while others remain somber. Etiquette requires a diner to know what is appropriate at any given time.\n\nThe dining in follows established protocols. After a brief cocktail period of 30 to 45 minutes, the presiding officer, known as the \"President of the Mess\", announces, \"Please be seated.\" The group will then retire to the dining area to be seated.\n\nAfter tasting the meat (usually beef), the President will declare it \"tasty and fit for human consumption\", after which the meal will be served to the diners. After the dessert is finished, the President will invite the chief steward to bring forth wine and/or punch to be served, and toasting will begin. After the toasts have concluded, the floor will be opened to the levying of fines. The president and the guest of honor will have the opportunity to speak if they so desire. After this, the mess is often then returned to an open cocktail hour, and then the evening concludes with final honors.\n\nFormal toasts are the heart of the formal dining in. A junior officer, known as \"Mr/Madam Vice\", proposes a toast to the guests, at which the guests remain seated. After this, various parties will offer toasts to the Commander in Chief, to the heads of state of a visiting or host nations, to their branch of service, to the units, and to the fallen members of the military.\n\nNotice that the United States does not have a king, queen, or Prime Minister, and that the commander in chief and President are the same person.\nThe final and most solemn toast is always to fallen comrades. Often this tribute is marked with a table setting dedicated to those military members killed, captured, or missing in action.\n\nSome unusual forms of toasting are common to the U.S. and Canadian traditions. In the Toronto Scottish Regiment, for example, a loyal toast to the regiment's Colonel-in-Chief (Currently the Prince of Wales) is performed standing with one foot on the chair and one foot on the dining table, facing a portrait of the C-in-C and drinking after the piper has played. Others, particularly Scottish regiments, perform toasts in the same way with one foot on a chair and one on the table. This is a frequent form of toasting in the United States Marine Corps as well. In the Scottish form, the glass is raised, lowered, brought out, and brought in, as the words of the toast, usually including some form of \"Up\", \"Down\", \"To you\", \"To me\", are recited, and finally drunk to the cry \"Drink it up!\" or similar.\n\nViolations of the formal etiquette of the dining in are \"punished\", generally with fines. The following are examples of what could be considered \"Violations of the Mess\": \n\nAt some mess nights, violators of the mess are obliged to publicly drink from a grog bowl in front of the mess attendees. The grog is sometimes contained in a toilet bowl, consisting of various alcoholic beverages mixed together. As a more disgusting effect, the grog may also contain floating solids, such as meatballs, raw oysters, or Tootsie Rolls. The tradition of drinking grog originated with the British Navy. Grog consisted of the regulation rum ration diluted with water to discourage binge drinking. In modern times, grog comes in two varieties: alcoholic and non-alcoholic, the latter of which may contain anything that will make it less appealing to the taste, including hot sauce. For additional effect, the drinker may be required to drink from a boot.\n\nIn addition to visiting the grog bowl and paying fines, violators may be sentenced to sing songs, tell jokes, do pushups, or perform menial tasks to entertain the mess. In most cases, when a violator has been identified, he or she is given the opportunity to provide a rebuttal or defense for the violation, which rarely results in the violator being excused for the offense, and usually only results in more punishment.\n\nTraditionally, all fines collected throughout the night are split amongst the stewards that served the attendees as a token of appreciation for their efforts. The fines can also be used to pay for the drinks consumed, while some units have used the Mess Night as a fund raiser (often to pay for a ball).\n\nMembers of the mess may also be singled out for some good-natured ribbing and teasing. In some units, members go out of their way to be picked on, often wearing obvious uniform violations, such as crowns, tiaras, eye-patches, bowties and cummerbunds of the wrong color, and other items that have no place on any military uniform (although it is common for US Artillerymen to wear red socks, suspenders and even bowties, in a nod to tradition at the expense of uniform regulations). Some will attempt to leave sabotaging evidence on or around others they wish to see fined, so care must be taken to not be the butt of a joke.\n\nNavy and Marine traditions also include that no diner may leave the hall to use the restroom without permission until Mr. Vice suggests that the company \"shed a tear for Lord Admiral Nelson\", a reference to the fact that his body was preserved in a barrel of brandy after his death at Trafalgar.\n\nMost Messes attempt to furnish the night with military music and marches, with live bands if possible, or recorded music. Depending on how formal the ceremony is, the diners may be required to march to their seats.\n\nIn recent times, Marines have established a variant of the mess in a \"field environment\", substituting in mess dress for utilities and combat equipment (to include camouflage facepaint), canteen cups, and tentage, while still retaining the formal nature of the ceremony.\n\n\n"}
{"id": "29052228", "url": "https://en.wikipedia.org/wiki?curid=29052228", "title": "Döbereiner's triads", "text": "Döbereiner's triads\n\nIn the history of the periodic table, Dobereiner's triads were an early attempt to sort the elements into some logical order by their physical properties. In 1817, a letter reported Johann Wolfgang Dobereiner's observations of the alkaline earths; namely, that strontium had properties that were intermediate to those of calcium and barium. By 1829, Dobereiner had found other groups of three elements (hence \"triads\") whose physical properties were similarly related. He also noted that some quantifiable properties of elements (e.g. atomic weight and density) in a triad followed a trend whereby the value of the middle element in the triad would be exactly or nearly predicted by taking the arithmetic mean of values for that property of the other two elements.\n"}
{"id": "1685298", "url": "https://en.wikipedia.org/wiki?curid=1685298", "title": "Erie doctrine", "text": "Erie doctrine\n\nThe \"Erie\" doctrine is a fundamental legal doctrine of civil procedure in the United States which mandates that a federal court sitting in diversity jurisdiction (or in general, when hearing state law claims in contexts like supplemental jurisdiction or adversarial proceedings in bankruptcy) must apply state substantive law to resolve claims under state law.\n\nThe doctrine follows from the Supreme Court landmark decision in \"Erie Railroad Co. v. Tompkins\" (1938). The case overturned \"Swift v. Tyson\", which allowed federal judges sitting in a state to ignore the common law local decisions of state courts in the same state, in cases based on diversity jurisdiction.\n\nThere are two main objectives of the \"Erie\" decision: (1) to discourage forum shopping among litigants, and (2) to avoid inequitable administration of the laws. Broadly speaking, the second objective is sometimes referred to as \"vertical uniformity\" and is rooted in the idea that in a given state, the outcome of the litigation should not be grossly different just because a litigant filed a claim in a state court rather than a federal court or vice versa.\n\nThe \"Erie\" doctrine today applies regardless of how the federal court may hear a state claim. Whether the federal court encounters a state law issue in diversity jurisdiction, supplemental jurisdiction, or bankruptcy jurisdiction, the federal court must honor state common law when deciding state law issues.\n\nIn effect, when the U.S. Constitution does not control and Congress has not legislated (or cannot legislate) on a topic, then the laws of the states necessarily govern and state judge-made rules are equally binding on the federal courts as state statutes.\n\nThe federal court must determine if either 1) state law is clear as to the case in controversy, or 2) if not, then has the state's highest court ruled specifically on a similar case. If so, the state law or court ruling must be followed. But if not, then the federal court must determine how the state's highest court would potentially rule on a matter: for example, it may look to state appellate courts to see how they ruled, and if the state chose not to hear further appeals, the federal court could determine that the high court agreed with the appellate courts. The determination is called an Erie guess, though the term \"guess\" is a misnomer as the federal court must make a reasoned determination in its ruling.\n\nAlternatively though, the court may elect to certify the question to the state's highest court for a ruling on state law in the matter. Some states, however, do not allow Federal District Courts to certify questions, only the Supreme Court or Federal Circuit Courts of Appeals.\n\nThe \"Erie\" case involved a fundamental question of federalism and the jurisdiction of federal courts in the United States. In 1789, the Congress passed a law still in effect today called the Rules of Decision Act (), which states that the laws of a state furnish the rules of decision for a federal court sitting in that state. Thus, a federal court in Texas, hearing a case based on diversity (as opposed to a federal question), has to follow the laws of the applicable state in resolving a case before it.\n\nThe Supreme Court's decision in \"Swift v. Tyson\" had defined the laws of the state as meaning only laws passed by legislatures of that state (though Justice Joseph Story writing for the court suggested that federal courts should pay special attention to how the \"local tribunals\" of a state would resolve a dispute). Thus, on issues of \"general common law,\" a federal court was free to ignore decisions by a state's highest court.\n\nThe decision in \"Swift\" resulted in inconsistent judicial rulings in the same state on the same legal issue depending on whether a plaintiff brought a case in state or federal court. In one case, for example, \"Black and White Taxicab Co. v. Brown and Yellow Taxicab Co.\" 276 U.S. 518 (1928), the Brown and Yellow Cab Company, a Kentucky corporation, sought to create a business association with the Louisville and Nashville Railroad, where Brown and Yellow would have a monopoly on soliciting passengers of the railroad, effectively eliminating the competition, the Black and White Cab Co. Such an agreement was illegal under Kentucky common law, as interpreted by Kentucky's highest court. Brown and Yellow dissolved itself, reincorporated in Tennessee, and executed the agreement there, where such an agreement was legal, bringing suit against Black and White in a Kentucky federal court to prevent them from soliciting passengers. The federal court upheld the agreement, citing \"Swift\", and arguing that under general federal common law, the agreement was valid. If Brown and Yellow had brought suit in a Kentucky state court, the agreement would not have been upheld.\n\nThe decision in \"Erie\" involved a railroad accident. The plaintiff, Tompkins, was walking alongside Erie's railroad tracks in Pennsylvania when a train passed. An open door struck him and knocked him under the train, severing his arm. In most states, Tompkins could sue for negligence of the railroad and recover monetary damages for his loss. In Pennsylvania, however, Tompkins would have been considered a trespasser. He was not to recover for an ordinary negligence claim in the state court of Pennsylvania, because under the law of that state, a claimant had to show \"wanton\" negligence on part of the Defendant to recover.\n\nThus, Tompkins brought his case in federal court to avoid the unfavorable state law. He subsequently won. However, on appeal the Supreme Court held, in an opinion drafted by Justice Brandeis, that such decisions and inconsistent rulings based on a general federal common law were unconstitutional, and that decisions by a state supreme court were \"laws\" that federal courts were bound to follow under the \"Rule of Decision Act\". Brandeis noted that the Court felt that \"Swift\" allowed federal courts to make unconstitutional modifications of the substantive law of a state. He noted that it violated the right to equal protection under the law, although he did not mean it in the sense of the Fourteenth Amendment. The Court overturned \"Swift\" on its own initiative, since the parties in \"Erie\" did not ask the Court to do so.\n\nSeveral later cases have added to the vague \"Erie\" decision (Brandeis cited no provision of the Constitution that \"Swift\" violated, although theoretically it might have violated the Tenth Amendment's reservation of powers to the state). Speaking generally, there are two approaches in determining whether a federal court will apply a state law: (1) the \"Hanna\" & Rules Enabling Act approach, per when there is a Federal Rule of Civil Procedure and statute that conflicts with a state law; and (2) the \"Byrd\"-\"Erie\" approach when there is not a conflict between a state and federal practice.\n\nThis approach suggests that unless there is a major countervailing federal policy that trumps the state practice, if ignoring the state law would lead to forum shopping by plaintiffs and unequal administration of the laws (like in \"Yellow Cab\" above), the court should apply the state law. In \"Byrd v. Blue Ridge Rural Electrical Cooperative, Inc.\", the Court decided that the federal policy allocating responsibilities between judge and jury, as embodied in the 7th Amendment of the US Constitution, outweighed the state rule requiring a judge to decide whether an employer was immune from suit. The main goal of the \"Erie\" decision was to prevent \"forum-shopping,\" a practice where plaintiffs choose a legal forum simply because of the probability of a more favorable ruling. The main problem with the decision is that sometimes there is simply no state law or practice on which a federal court may defer. Federal judges are left to guess how a state court would rule on a given legal question, and a state court is in no way bound by a federal decision interpreting their own state law.\n\nJustice Frankfurter in \"Guaranty Trust Co. v. York\", summarizes the main point of Erie differently... \n\nIn essence, the intent of that decision was to ensure that, in all cases where a federal court is exercising jurisdiction solely because of the diversity of citizenship of the parties, the outcome of the litigation in the federal court should be substantially the same, so far as legal rules determine the outcome of a litigation, as it would be if tried in a State court... \n\nThis suggests that Erie's main goal was to achieve equal protection under the law. One way that equal protection is intentionally disregarded would be through \"forum shopping,\" but the reduction of inequality was the main target of the doctrine.\n\nUnder the approach in \"Hanna v. Plumer\", the federal court of a state hearing a case based on diversity jurisdiction should apply state law in the event of conflict between state and federal law if the state law deals with substantive rights of state citizens. The Supreme Court has defined substantive rights as, \"rights conferred by the law to be protected and enforced by the adjective law of judicial procedure.\" An example of a substantive right would be a state law on fraud, which may vary widely in composition depending on the jurisdiction. If the state law is merely procedural, or relating merely to the form and mode of judicial operations, then the federal court does not have to apply the conflicting state law. However, the substance-procedure distinction is a generality as the Court rejected any test based upon \"litmus paper criterion.\" Thus, a choice between state and federal law must be made with reference to the underlying policy of the \"Erie\" decision. The Court announced a modification of the \"outcome-determinative\" test in \"York\", whereby the test must be applied in light of the twin aims of \"Erie,\" which are the discouragement of forum-shopping and avoidance of inequitable administration of the laws. Under this rule, state procedural law would not supplant federal procedural law if the differences in the outcome are nonsubstantial or trivial, fail to raise Equal Protection concerns, and are unlikely to influence the choice of forum.\n\nA recent Supreme Court case that addressed the \"Erie\" problem is \"Gasperini v. Center for Humanities\", . \"Gasperini\" is a post-\"Hanna\" decision addressing a conflict between state and federal law for review of jury verdicts. The plaintiff, a well-known artist and photographer from New York, sued a New York museum in federal court in New York, for damages arising from the loss of some photographs and slides he had loaned the museum. A jury found in his favor and awarded damages. The defendant appealed, and the U.S. Court of Appeals for the Second Circuit reduced the damages award on appeal. Gasperini appealed to the U.S. Supreme Court.\n\nThe New York state provision, a \"tort reform\" measure, allowed reviewing appellate courts to overturn a jury verdict if it \"deviates materially from what would be reasonable compensation.\" Pursuant to this law, the Second Circuit applied the state's appellate standard of review. However, the Supreme Court stated that federal courts, bound by the reexamination clause of the Seventh Amendment, could overturn a jury's finding of fact only if it \"shocked the conscience.\"\n\nThe Supreme Court could have resolved the case by reading the Seventh Amendment broadly, and treating it as controlling in federal court. However, instead, the Court opted for what can be described as a compromise, holding that the federal court should apply the state's lower standard of review, but in a way that would not run afoul of the Seventh Amendment: instead of the federal appeals court reviewing the jury finding, the trial judge would assume the role.\n\n\"Gasperini\", and another recent \"Erie\"-area case, \"Semtek International Inc. v. Lockheed Martin Corp.\", have shown \"Erie\" has gone in a newer and even more complicated direction than the previous controlling cases, and that instead of selecting either federal or state law for a case, the federal court may be required to somehow blend federal and state law, depending on the issue. This is quite frustrating for those who wish to have a black-letter rule that will point them to the answer. However, the possibility of blending in \"Erie\" does not open up an infinitude of possibilities. In both \"Gasperini\" and \"Semtek\", the common thread is that the blending is done in a way that is calculated to advance the aims of \"Erie\" (and \"York\"): non-discrimination between litigants, and discouragement of forum shopping.\n"}
{"id": "35789777", "url": "https://en.wikipedia.org/wiki?curid=35789777", "title": "Fair trade bananas", "text": "Fair trade bananas\n\nFair trade bananas are bananas produced in partnership with an alternative trade organization which focuses on increasing the price paid to small banana growers and the wages of agricultural workers. This is not a commercial brand, but a marketing strategy. Fair trade is based on higher prices paid by consumers that allow an equitable distribution of gains from trade over the chain partners.\n\nThere are many of organizations involved in producing fair trade bananas; for example, an organization called Banafair began importing uncertified/unlabeled fair trade bananas into Germany in the mid-1980s (from 500 to 1 000 tonnes annually). In 1997 Fair Trade Labeling Organizations International (FLO) was established in Bonn, Germany to consolidate various labeling initiatives and establish worldwide standards for fair trade bananas. The first fair trade labelled bananas imported to Germany were by TransFair in April 1998.\n\nFair Trade Labeling Organizations International, (now renamed Fair Trade International), is a large importer whose bananas bear the International FairTrade Certification Mark. FLO-CERT is the international body that inspects the farms to ensure they meet the proper social and environmental according to Fair Trade international standards.\n\nFive companies control about 80% of the conventional banana trade. This situation, plus the intervention of various governments, has kept the price paid to banana growers and wages to workers a small percentage of the supermarket price. Examples of this effect are the banana wars; the formation of the United Fruit Company (now Chiquita Brands Intl.); the Bananagate bribery scandal; military coups to establish and maintain banana republics. There is ongoing industry conflict with unions.\n\nFLO has different standards for small banana farms and larger banana plantations. To be eligible to display a Fair Trade Certification Mark, small farmers must create a panel of both workers and management to determine the best use of the fair trade premiums. Revenues to banana farmers must be equally shared between the working members of the cooperative or association.\n\nOn larger plantations, the premiums can only be used for improving working and living conditions. Forced labor and labor of children under 16 years of age is prohibited, as is dangerous work. Young adults 16 years of age or older must not work so many hours that they have no time for education. Workers must be allowed to join a union, and be paid at least regional industry average or minimum wage.\n\nAlthough fair trade banana workers’ wages are not significantly above industry averages, they receive wage related benefits which increase their overall livelihood. However, many small banana farmers barely make living wages themselves, and the restriction of premiums to community development projects may prevent them from covering basic living expenses.\n\nMonetary premiums are paid for fair trade banana growers to improve their communities. In 2013, FairTrade Certified banana producers receive a FairTrade Minimum Premium of $1 US dollar per 18.14 kilogram box of bananas to invest in community projects. FairTrade farmers are guaranteed a minimum price to help cover the costs of sustainable production, but the price differs between regions and is subject to market fluctuations in the sustainable cost of agricultural production. Although FairTrade minimum prices vary, FairTrade Minimum premiums do not. Both FairTrade prices and premiums are set at the same level for FairTrade certified plantations and small farms.\n\nThe agricultural production of bananas on a large scale often uses more pesticides (and fungicides, fertilizers) than any other fresh fruit commodity. Fair Trade banana production promotes sustainable farming practices, but these result in a higher supermarket price which some consumers are willing to pay for ethical reasons.\n\nBecause the banana trade is a large world-wide business, a number of studies have been carried out on various aspects of the fair trade banana market, including political ecology, tariffs and quotas, price competition, organic growing, and retail price wars.\n\nFair trade certification programs have been criticized on several grounds. Griffiths has challenged the ethics of fair trade labels in the fair trade debate, and, in the Journal of Business Ethics, has pointed out instances in which negative research is not published and academics choose only successful coops or fair trade organizations for study. In the Dominican Republic, Shreck found minimum pricing, and exclusivity of certification worsened socioeconomic disparity within farming communities, and limited access for non-certified farmers to the market. Furthermore, Shrek found that the standards of certification programs prioritized market interests over farmer rights and well-being. Frank has argued that fair trade initiatives do not generally foster an empowering partnership between consumers and farmers.\n\n\n"}
{"id": "38824009", "url": "https://en.wikipedia.org/wiki?curid=38824009", "title": "Feminist digital humanities", "text": "Feminist digital humanities\n\nFeminist Digital Humanities is a more recent development in the field of Digital Humanities as a whole. Feminist Digital Humanities has risen partly due to recent criticism of the propensity of Digital Humanities to further patriarchal or hegemonic discourses in the Academy. Some of the research in feminist digital humanities centres on the exclusion of women from histories of technology and the use of technology to promote feminist scholarship. Feminist Digital Humanities emphasizes the role of women, feminists, and cyberfeminists in technology, overturning ideas such as “Men invented the Internet”, as written in a June 2012 New York Times article.\n\nA list of women in the digital humanities begun by Jacqueline Wernimont makes available a compendium of women working in the field.\n\nMedia Theorist Lisa Nakamura notes that \"[as] women of color acquire an increasing presence online, their particular interests which spring directly from gender and racial identifications, that is to say, those identities associated with a physical body off-line, are being addressed.\" Likewise, Science and Technology Studies professor Donna Haraway has also pioneered specifically feminist approaches to the study of digital humanities.\n\nThis intervention is notably crystallized in the work of FemTechNet, \"an activated network of scholars, artists, and students who work on, with, and at the borders of technology, science and feminism in a variety of fields including STS, Media and Visual Studies, Art, Women’s, Queer, and Ethnic Studies\". FemTechNet has collaborated on a number of projects that reflect the aims of Feminist Digital Humanities, including Wikistorming, DOCC: Distributed Open Collaborative Course, and video dialogues. Their methods emphasize distribution through networks to connect diverse institutions, nations, and fields.\n\nProfessors of Digital Humanities, Bethany Nowviskie and Miriam Posner have blogged about the structures in place that have kept women from engaging in digital humanities. There have been efforts to increase the racial representations within the field as well. These feminist digital humanities projects include #transformDH, That Camp Theory, Critical Code Studies, and Crunk Feminist Collective. Black Girls Code is a project that has recently garnered attention, with founder Kimberly Bryant receiving a Standing O-vation presented by Toyota and Oprah Winfrey.\n\nOne goal of feminist literary scholars has been to increase the scope of women's literary works in visible archives. The Orlando Project and The Women Writers Project are two early projects that undertook the task of filling in the gaps that existed in literary history in the 1980s. Both efforts sought to use the electronic format \"to overcome the problems of inaccessibility and scarcity which had rendered women’s writing invisible for so long.\"\nOne critique of a content-oriented approach to combating the marginalization of women's literary works is that it's simply not enough to add content to a system that is built upon a patriarchal methodology. \"Literary scholars who depend on archival or rare book materials still confront, whether they acknowledge it or not, the legacy of an institutional form through which patriarchal power exercised the authority to determine value, classification, and access.\"\n\n"}
{"id": "11224528", "url": "https://en.wikipedia.org/wiki?curid=11224528", "title": "Gift basket", "text": "Gift basket\n\nA gift basket, or fruit basket is typically a gift delivered to the recipient at their home or workplace. A variety of gift baskets exist: some contain fruit; while others might contain dry or canned foods such as tea, crackers and jam; or the basket might include a combination of fruit and dried good items. Gourmet gift baskets typically include exotic fruit, and often include quality cheese and wine, as well as other nonfood items. Gift baskets are often sent for special occasions—such as holidays—or as a thank-you or congratulations gift.\n\nA fruit bouquet is a fruit arrangement in the form of bouquet. The fruit is cut in the shape of flowers and leaves, and is arranged in the container with the help of sticks. A complete arrangement looks like a bouquet of flowers. Typically, a fruit bouquet is delivered to the recipient at their home or workplace.\n\nOften these bouquets will be made to suit the recipients' needs, such as diabetic, vegan, vegetarian, gluten intolerance or wheat intolerance. Common fruit bouquet items include apples, artichokes, avocados, bananas, cheeses, grapes, lychees, mangoes, oranges, papayas, pineapples, pomegranates, strawberries, and Chocolates.\n\n\n\n\n\n"}
{"id": "191300", "url": "https://en.wikipedia.org/wiki?curid=191300", "title": "Glossary of Buddhism", "text": "Glossary of Buddhism\n\nSome Buddhist terms and concepts lack direct translations into English that cover the breadth of the original term. Below are given a number of important Buddhist terms, short definitions, and the languages in which they appear. In this list, an attempt has been made to organize terms by their original form and give translations and synonyms in other languages along with the definition.\n\nLanguages and traditions dealt with here:\n\n\n"}
{"id": "724710", "url": "https://en.wikipedia.org/wiki?curid=724710", "title": "Gravitas", "text": "Gravitas\n\nGravitas was one of the Roman virtues, along with \"pietas\", \"dignitas\", and \"virtus\", that were particularly appreciated in leaders. Evidence shows that it was most likely influenced by the Greek virtue of \"Arete\". It may be translated variously as weight, seriousness, dignity, and importance and connotes a certain substance or depth of personality. It also conveys a sense of responsibility and commitment to the task. In the British education system, \"gravitas\" was seen as one of the pillars of the moral formation of the English gentleman during the Victorian and Edwardian eras.\n\nIn the UK House of Commons, the quality is known as \"bottom\".\n\n"}
{"id": "1707053", "url": "https://en.wikipedia.org/wiki?curid=1707053", "title": "Habitat destruction", "text": "Habitat destruction\n\nHabitat destruction is the process by which natural habitat is rendered incapable of supporting its native species. In this process, the organisms that previously used the site are displaced or destroyed, reducing biodiversity. Habitat destruction by human activity is mainly for the purpose of harvesting natural resources for industrial production and urbanization. Clearing habitats for agriculture is the principal cause of habitat destruction. Other important causes of habitat destruction include mining, logging, trawling, and urban sprawl. Habitat destruction is currently ranked as the primary cause of species extinction worldwide. It is a process of natural environmental change that may be caused by habitat fragmentation, geological processes, climate change or by human activities such as the introduction of invasive species, ecosystem nutrient depletion, and other human activities.\n\nThe terms habitat loss and habitat reduction are also used in a wider sense, including loss of habitat from other factors, such as water and noise pollution.\n\nIn the simplest term, when a habitat is destroyed, the plants, animals, and other organisms that occupied the habitat have a reduced carrying capacity so that populations decline and extinction becomes more likely. Perhaps the greatest threat to organisms and biodiversity is the process of habitat loss. Temple (1986) found that 82% of endangered bird species were significantly threatened by habitat loss. Most amphibian species are also threatened by habitat loss, and some species are now only breeding in modified habitat. Endemic organisms with limited ranges are most affected by habitat destruction, mainly because these organisms are not found anywhere else within the world, and thus have less chance of recovering. Many endemic organisms have very specific requirements for their survival that can only be found within a certain ecosystem, resulting in their extinction. Extinction may also take place very long after the destruction of habitat, a phenomenon known as extinction debt. Habitat destruction can also decrease the range of certain organism populations. This can result in the reduction of genetic diversity and perhaps the production of infertile youths, as these organisms would have a higher possibility of mating with related organisms within their population, or different species. One of the most famous examples is the impact upon China's giant panda, once found across the nation. Now it is only found in fragmented and isolated regions in the southwest of the country, as a result of widespread deforestation in the 20th century.\n\nBiodiversity hotspots are chiefly tropical regions that feature high concentrations of endemic species and, when all hotspots are combined, may contain over half of the world’s terrestrial species. These hotspots are suffering from habitat loss and destruction.\nMost of the natural habitat on islands and in areas of high human population density has already been destroyed (WRI, 2003). Islands suffering extreme habitat destruction include New Zealand, Madagascar, the Philippines, and Japan. South and East Asia — especially China, India, Malaysia, Indonesia, and Japan — and many areas in West Africa have extremely dense human populations that allow little room for natural habitat. Marine areas close to highly populated coastal cities also face degradation of their coral reefs or other marine habitat. These areas include the eastern coasts of Asia and Africa, northern coasts of South America, and the Caribbean Sea and its associated islands.\n\nRegions of unsustainable agriculture or unstable governments, which may go hand-in-hand, typically experience high rates of habitat destruction. Central America, Sub-Saharan Africa, and the Amazonian tropical rainforest areas of South America are the main regions with unsustainable agricultural practices and/or government mismanagement.\n\nAreas of high agricultural output tend to have the highest extent of habitat destruction. In the U.S., less than 25% of native vegetation remains in many parts of the East and Midwest. Only 15% of land area remains unmodified by human activities in all of Europe.\n\nTropical rainforests have received most of the attention concerning the destruction of habitat. From the approximately 16 million square kilometers of tropical rainforest habitat that originally existed worldwide, less than 9 million square kilometers remain today. The current rate of deforestation is 160,000 square kilometers per year, which equates to a loss of approximately 1% of original forest habitat each year.\n\nOther forest ecosystems have suffered as much or more destruction as tropical rainforests. Farming and logging have severely disturbed at least 94% of temperate broadleaf forests; many old growth forest stands have lost more than 98% of their previous area because of human activities. Tropical deciduous dry forests are easier to clear and burn and are more suitable for agriculture and cattle ranching than tropical rainforests; consequently, less than 0.1% of dry forests in Central America's Pacific Coast and less than 8% in Madagascar remain from their original extents.\nPlains and desert areas have been degraded to a lesser extent. Only 10-20% of the world's drylands, which include temperate grasslands, savannas, and shrublands, scrub, and deciduous forests, have been somewhat degraded. But included in that 10-20% of land is the approximately 9 million square kilometers of seasonally dry-lands that humans have converted to deserts through the process of desertification. The tallgrass prairies of North America, on the other hand, have less than 3% of natural habitat remaining that has not been converted to farmland.\n\nWetlands and marine areas have endured high levels of habitat destruction. More than 50% of wetlands in the U.S. have been destroyed in just the last 200 years. Between 60% and 70% of European wetlands have been completely destroyed. In the United Kingdom, there has been an increase in demand for coastal housing and tourism which has caused a decline in marine habitats over the last 60 years. The rising sea levels and temperatures have caused soil erosion, coastal flooding, and loss of quality in the UK marine ecosystem. About one-fifth (20%) of marine coastal areas have been highly modified by humans. One-fifth of coral reefs have also been destroyed, and another fifth has been severely degraded by overfishing, pollution, and invasive species; 90% of the Philippines’ coral reefs alone have been destroyed. Finally, over 35% of the mangrove ecosystems worldwide have been destroyed.\n\nHabitat destruction through natural processes such as volcanism, fire, and climate change is well documented in the fossil record. One study shows that habitat fragmentation of tropical rainforests in Euramerica 300 million years ago led to a great loss of amphibian diversity, but simultaneously the drier climate spurred on a burst of diversity among reptiles.\n\nHabitat destruction caused by humans includes land conversion from forests, etc. to arable land, urban sprawl, infrastructure development, and other anthropogenic changes to the characteristics of land. Habitat degradation, fragmentation, and pollution are aspects of habitat destruction caused by humans that do not necessarily involve over destruction of habitat, yet result in habitat collapse. Desertification, deforestation, and coral reef degradation are specific types of habitat destruction for those areas (deserts, forests, coral reefs).\n\nGeist and Lambin (2002) assessed 152 case studies of net losses of tropical forest cover to determine any patterns in the proximate and underlying causes of tropical deforestation. Their results, yielded as percentages of the case studies in which each parameter was a significant factor, provide a quantitative prioritization of which proximate and underlying causes were the most significant. The proximate causes were clustered into broad categories of agricultural expansion (96%), infrastructure expansion (72%), and wood extraction (67%). Therefore, according to this study, forest conversion to agriculture is the main land use change responsible for tropical deforestation. The specific categories reveal further insight into the specific causes of tropical deforestation: transport extension (64%), commercial wood extraction (52%), permanent cultivation (48%), cattle ranching (46%), shifting (slash and burn) cultivation (41%), subsistence agriculture (40%), and fuel wood extraction for domestic use (28%). One result is that shifting cultivation is not the primary cause of deforestation in all world regions, while transport extension (including the construction of new roads) is the largest single proximate factor responsible for deforestation.\n\nRising global temperatures, caused by the greenhouse effect, contribute to habitat destruction, endangering various species, such as the polar bear. Melting ice caps promote rising sea levels and floods which threaten natural habitats and species globally.\n\nWhile the above-mentioned activities are the proximal or direct causes of habitat destruction in that they actually destroy habitat, this still does not identify why humans destroy habitat. The forces that cause humans to destroy habitat are known as \"drivers\" of habitat destruction. Demographic, economic, sociopolitical, scientific and technological, and cultural drivers all contribute to habitat destruction.\n\nDemographic drivers include the expanding human population; rate of population increase over time; spatial distribution of people in a given area (urban versus rural), ecosystem type, and country; and the combined effects of poverty, age, family planning, gender, and education status of people in certain areas. Most of the exponential human population growth worldwide is occurring in or close to biodiversity hotspots. This may explain why human population density accounts for 87.9% of the variation in numbers of threatened species across 114 countries, providing indisputable evidence that people play the largest role in decreasing biodiversity. The boom in human population and migration of people into such species-rich regions are making conservation efforts not only more urgent but also more likely to conflict with local human interests. The high local population density in such areas is directly correlated to the poverty status of the local people, most of whom lacking an education and family planning.\n\nFrom the Geist and Lambin (2002) study described in the previous section, the underlying driving forces were prioritized as follows (with the percent of the 152 cases the factor played a significant role in): economic factors (81%), institutional or policy factors (78%), technological factors (70%), cultural or socio-political factors (66%), and demographic factors (61%). The main economic factors included commercialization and growth of timber markets (68%), which are driven by national and international demands; urban industrial growth (38%); low domestic costs for land, labor, fuel, and timber (32%); and increases in product prices mainly for cash crops (25%). Institutional and policy factors included formal pro-deforestation policies on land development (40%), economic growth including colonization and infrastructure improvement (34%), and subsidies for land-based activities (26%); property rights and land-tenure insecurity (44%); and policy failures such as corruption, lawlessness, or mismanagement (42%). The main technological factor was the poor application of technology in the wood industry (45%), which leads to wasteful logging practices. Within the broad category of cultural and sociopolitical factors are public attitudes and values (63%), individual/household behavior (53%), public unconcern toward forest environments (43%), missing basic values (36%), and unconcern by individuals (32%). Demographic factors were the in-migration of colonizing settlers into sparsely populated forest areas (38%) and growing population density—a result of the first factor—in those areas (25%).\n\nThere are also feedbacks and interactions among the proximate and underlying causes of deforestation that can amplify the process. Road construction has the largest feedback effect, because it interacts with—and leads to—the establishment of new settlements and more people, which causes a growth in wood (logging) and food markets. Growth in these markets, in turn, progresses the commercialization of agriculture and logging industries. When these industries become commercialized, they must become more efficient by utilizing larger or more modern machinery that often has a worse effect on the habitat than traditional farming and logging methods. Either way, more land is cleared more rapidly for commercial markets. This common feedback example manifests just how closely related the proximate and underlying causes are to each other.\n\nHabitat destruction vastly increases an area's vulnerability to natural disasters like flood and drought, crop failure, spread of disease, and water contamination. On the other hand, a healthy ecosystem with good management practices will reduce the chance of these events happening, or will at least mitigate adverse impacts.\n\nAgricultural land can actually suffer from the destruction of the surrounding landscape. Over the past 50 years, the destruction of habitat surrounding agricultural land has degraded approximately 40% of agricultural land worldwide via erosion, salinization, compaction, nutrient depletion, pollution, and urbanization. Humans also lose direct uses of natural habitat when habitat is destroyed. Aesthetic uses such as birdwatching, recreational uses like hunting and fishing, and ecotourism usually rely upon virtually undisturbed habitat. Many people value the complexity of the natural world and are disturbed by the loss of natural habitats and animal or plant species worldwide.\n\nProbably the most profound impact that habitat destruction has on people is the loss of many valuable ecosystem services. Habitat destruction has altered nitrogen, phosphorus, sulfur, and carbon cycles, which has increased the frequency and severity of acid rain, algal blooms, and fish kills in rivers and oceans and contributed tremendously to global climate change. One ecosystem service whose significance is becoming better understood is climate regulation. On a local scale, trees provide windbreaks and shade; on a regional scale, plant transpiration recycles rainwater and maintains constant annual rainfall; on a global scale, plants (especially trees from tropical rainforests) from around the world counter the accumulation of greenhouse gases in the atmosphere by sequestering carbon dioxide through photosynthesis. Other ecosystem services that are diminished or lost altogether as a result of habitat destruction include watershed management, nitrogen fixation, oxygen production, pollination (see pollinator decline), waste treatment (i.e., the breaking down and immobilization of toxic pollutants), and nutrient recycling of sewage or agricultural runoff.\n\nThe loss of trees from the tropical rainforests alone represents a substantial diminishing of the earth’s ability to produce oxygen and use up carbon dioxide. These services are becoming even more important as increasing carbon dioxide levels is one of the main contributors to global climate change.\n\nThe loss of biodiversity may not directly affect humans, but the indirect effects of losing many species as well as the diversity of ecosystems in general are enormous. When biodiversity is lost, the environment loses many species that perform valuable and unique roles in the ecosystem. The environment and all its inhabitants rely on biodiversity to recover from extreme environmental conditions. When too much biodiversity is lost, a catastrophic event such as an earthquake, flood, or volcanic eruption could cause an ecosystem to crash, and humans would obviously suffer from that. Loss of biodiversity also means that humans are losing animals that could have served as biological control agents and plants that could potentially provide higher-yielding crop varieties, pharmaceutical drugs to cure existing or future diseases or cancer, and new resistant crop varieties for agricultural species susceptible to pesticide-resistant insects or virulent strains of fungi, viruses, and bacteria.\n\nThe negative effects of habitat destruction usually impact rural populations more directly than urban populations. Across the globe, poor people suffer the most when natural habitat is destroyed, because less natural habitat means fewer natural resources per capita, yet wealthier people and countries simply have to pay more to continue to receive more than their per capita share of natural resources.\n\nAnother way to view the negative effects of habitat destruction is to look at the opportunity cost of destroying a given habitat. In other words, what are people losing out on by taking away a given habitat? A country may increase its food supply by converting forest land to row-crop agriculture, but the value of the same land may be much larger when it can supply natural resources or services such as clean water, timber, ecotourism, or flood regulation and drought control.\n\nThe rapid expansion of the global human population is increasing the world’s food requirement substantially. Simple logic dictates that more people will require more food. In fact, as the world’s population increases dramatically, agricultural output will need to increase by at least 50%, over the next 30 years. In the past, continually moving to new land and soils provided a boost in food production to meet the global food demand. That easy fix will no longer be available, however, as more than 98% of all land suitable for agriculture is already in use or degraded beyond repair.\n\nThe impending global food crisis will be a major source of habitat destruction. Commercial farmers are going to become desperate to produce more food from the same amount of land, so they will use more fertilizers and show less concern for the environment to meet the market demand. Others will seek out new land or will convert other land-uses to agriculture. Agricultural intensification will become widespread at the cost of the environment and its inhabitants. Species will be pushed out of their habitat either directly by habitat destruction or indirectly by fragmentation, degradation, or pollution. Any efforts to protect the world’s remaining natural habitat and biodiversity will compete directly with humans’ growing demand for natural resources, especially new agricultural lands.\n\nIn most cases of tropical deforestation, three to four underlying causes are driving two to three proximate causes. This means that a universal policy for controlling tropical deforestation would not be able to address the unique combination of proximate and underlying causes of deforestation in each country. Before any local, national, or international deforestation policies are written and enforced, governmental leaders must acquire a detailed understanding of the complex combination of proximate causes and underlying driving forces of deforestation in a given area or country. This concept, along with many other results of tropical deforestation from the Geist and Lambin study, can easily be applied to habitat destruction in general. Governmental leaders need to take action by addressing the underlying driving forces, rather than merely regulating the proximate causes. In a broader sense, governmental bodies at a local, national, and international scale need to emphasize the following:\n\n\n"}
{"id": "3517209", "url": "https://en.wikipedia.org/wiki?curid=3517209", "title": "Hiranyagarbha", "text": "Hiranyagarbha\n\nHiraṇyagarbha (Sanskrit: हिरण्यगर्भः ; literally the 'golden womb' or 'golden egg', poetically translated as 'universal germ') is the source of the creation of universe or the manifested cosmos in Vedic philosophy, as well as an avatar of Vishnu in the Bhagavata Purana. It finds mention in one hymn of the Rigveda (RV 10.121), known as the Hiraṇyagarbha Sūkta, suggesting a single creator deity (verse 8: \"\", Griffith: \"He is the God of gods, and none beside him.\"), identified in the hymn as Prajāpati. The concept of the \"golden womb\" is again mentioned in the Vishvakarman Sūkta (RV 10.82).\n\nThe Upanishad calls it the Soul of the Universe or Brahman, and elaborates that Hiraṇyagarbha floated around in emptiness and the darkness of the non-existence for about a year, and then broke into two halves which formed the \"Svarga\" and the \"Pṛthvi\".\n\nIn classical Purāṇic Hinduism, Hiraṇyagarbha is the term used in the Vedanta for the \"creator\". Hiraṇyagarbha is also Brahmā, so called because he was born from a golden egg (Manu Smṛti 1.9), while the Mahābhārata calls it the Manifest.\n\nHiraṇyagarbha is also a sacrifice, where it is known as Hiraṇyagarbha Yagna. This sacrifice was performed by the founder of the Rashtrakuta dynasty, Dantidurga, to confer Kshatriyahood on himself, as he was not born a Kshatriya but wanted to overthrow his Chalukya overlord to set up the Rashtrakuta empire, and in olden days, the Caste System in India was very prevalent and he was not accepted by the people as their King, until he conferred Kshatriyahood upon himself.\n\nSome classical yoga traditions consider Hiraṇyagarbha as the originator of yoga, though this may also be a name for Rishi Kapila.\n\nMatsya Purāṇa (2.25-30) gives an account of initial creation. After Mahāprālaya, the great dissolution of the Universe, there was darkness everywhere. Everything was in a state of sleep. There was nothing, either moving or static. Then Svayambhu, self-manifested Being arose, which is a form beyond senses. It created the primordial waters first and established the seed of creation into it. The seed turned into a golden womb, Hiraṇyagarbha. Then Svayambhu entered in the egg.\n\nThe Nārāyaṇa Sūkta exclaims that everything that is, visible or invisible, all this is pervaded by Nārāyaṇa within and without.\n\nThe Īśvara Upaniṣad says that the universe is pervaded by Īśvara (God), who is both within and without it. He is the moving and the unmoving, He is far and near, He is within all these and without all these.\n\nThe Vedānta Sūtra further states that Brahman is That from Whom this Universe proceeds, in Whom it subsists, and to Whom, in the end, it returns.\n\nThe Saṃkhya school holds that there are only two primary principles, Puruṣa and Prākṛti, and creation is only a manifestation or evolution of the constituents of Prākṛti due to the action of Puruṣa's Consciousness.\n\nThe Bhagavata states that Nārāyaṇa alone was in the beginning, who was the pious of principles of creation, sustenance, and dissolution (also known as the Hindu Trinity of Brahmā, Viṣṇu and Shiva) - the Supreme Hari, multi-headed, multi-eyed, multi-footed, multi-armed, multi-limbed. This was the Supreme Seed of all creation, subtler than the subtlest, greater than the greatest, larger than the largest, and more magnificent than even the best of all things, more powerful, than even the wind and all the gods, more resplendent than the Sun and the Moon, and more internal than even the mind and the intellect. He is the Creator, the Supreme. The term can also mean as He who, having become first the Creator, has come to be considered as the womb of all objects.\n\nThe Hiraṇyagarbha Sūkta of the Rigveda declares that God manifested Himself in the beginning as the Creator of the Universe, encompassing all things, including everything within Himself, the collective totality, as it were, of the whole of creation, animating it as the Supreme Intelligence.\n\n<poem>\nहिरण्यगर्भः समवर्तताग्रे भूतस्य जातः पतिरेकासीत ।\nस दाधार पृथ्वीं ध्यामुतेमां कस्मै देवायहविषा विधेम ॥\"\nhiraṇyagarbhaḥ samavartatāgre bhūtasya jātaḥ patirekāsīta |\nsa dādhāra pṛthvīṃ dhyāmutemāṃ kasmai devāyahaviṣā vidhema ||\n\nय आत्मदा बलदा यस्य विश्व उपासते प्रशिषं यस्यदेवाः ।\nयस्य छायाऽमृतं यस्य मृत्युः कस्मै देवाय हविषा विधेम ॥\nya ātmadā baladā yasya viśva upāsate praśiṣaṃ yasyadevāḥ |\nyasya chāyāmṛtaṃ yasya martyuḥ kasmai devāyahaviṣā vidhema ||\n\nयः प्राणतो निमिषतो महित्वैक इद्राजा जगतो बभूव ।\nय ईशे अस्य द्विपदश्चतुष्पदः कस्मै देवाय हविषाविधेम ॥\nyaḥ prāṇato nimiṣato mahitvaika idrājā jagato babhūva |\nya īśe asya dvipadaścatuṣpadaḥ kasmai devāya haviṣāvidhema ||\n\nयस्येमे हिमवन्तो महित्वा यस्य समुद्रं रसया सहाहुः ।\nयस्येमाः परदिशो यस्य बाहू कस्मै देवाय हविषाविधेम ॥\nyasyeme himavanto mahitvā yasya samudraṃ rasayā sahāhuḥ |\nyasyemāḥ paradiśo yasya bāhū kasmai devāya haviṣāvidhema ||\n\nयेन द्यौरुग्रा पृथ्वी च दृढा येन स्वस्तभितं येननाकः ।\nयो अन्तरिक्षे रजसो विमानः कस्मै देवाय हविषा विधेम ॥\nyena dayaurugrā parthivī ca darḻhā yena sava satabhitaṃ yenanākaḥ |\nyo antarikṣe rajaso vimānaḥ kasmai devāyahaviṣā vidhema ||\n\nयं करन्दसी अवसा तस्तभाने अभ्यैक्षेतां मनसारेजमाने ।\nयत्राधि सूर उदितो विभाति कस्मै देवायहविषा विधेम ॥\nyaṃ karandasī avasā tastabhāne abhyaikṣetāṃ manasārejamāne |\nyatrādhi sūra udito vibhāti kasmai devāyahaviṣā vidhema ||\n\nआपो ह यद बर्हतीर्विश्वमायन गर्भं दधानाजनयन्तीरग्निम ।\nततो देवानां समवर्ततासुरेकःकस्मै देवाय हविषा विधेम ॥\nāpo ha yada barhatīrviśvamāyana garbhaṃ dadhānājanayantīragnima |\ntato devānāṃ samavartatāsurekaḥkasmai devāya haviṣā vidhema ||\n\nयश्चिदापो महिना पर्यपश्यद दक्षं दधानाजनयन्तीर्यज्ञम ।\nयो देवेष्वधि देव एक आसीत कस्मैदेवाय हविषा विधेम ॥\nyaścidāpo mahinā paryapaśyada dakṣaṃ dadhānājanayantīryajñama |\nyo deveṣvadhi deva eka āsīta kasmaidevāya haviṣā vidhema ||\n\nमा नो हिंसीज्जनिता यः पर्थिव्या यो वा दिवंसत्यधर्मा जजान ।\nयश्चापश्चन्द्रा बर्हतीर्जजानकस्मै देवाय हविषा विधेम ॥\nmā no hiṃsījjanitā yaḥ parthivyā yo vā divaṃsatyadharmā jajāna |\nyaścāpaścandrā barhatīrjajānakasmai devāya haviṣā vidhema ||\n\nप्रजापते नत्वदेतान्यन्यो विश्वा जातानि परिताबभूव ।\nयत्कामास्ते जुहुमस्तन्नो अस्तु वयं स्याम पतयोरयीणाम् ॥\nparajāpate na tavadetānyanyo viśvā jātāni pari tābabhūva |\nyatkāmāste juhumastana no astu vayaṃ sayāma patayorayīṇāma ||\n\n</poem>\n\nIn the beginning was the Divinity in his splendour, manifested as the sole Lord of land, skies, water, space and that beneath and He upheld the earth and the heavens.\n\nWho is the deity we shall worship with our offerings?\n\nIt is that who bestows soul-force and vigor, whose guidance all men invoke, the Devas invoke whose shadow is immortal life and death.\n\nWho is the deity we shall worship with our offerings?\n\nIt is that who by His greatness became the One King of the breathing and the seeing, who is the Lord of man and bird and beast.\n\nWho is the deity we shall worship with our offerings?\n\nIt is that through whose glory the snow-clad mountains rose, and the ocean spread with the river, they say. His arms are the quarters of the sky.\n\nWho is the deity we shall worship with our offerings ?\n\nIt is that through whom the heaven is strong and the earth firm, who has steadied the light and the sky's vault, and measured out the sphere of clouds in the mid-region.\n\nWho is the deity we shall worship with our offering?\n\nIt is that to whom heaven and earth, placed in the light by his grace, look up, radiant with the mind while over them the sun, rising, brightly shines.\n\nWho is the deity we shall worship with our offerings?\n\nWhen the mighty waters came, carrying the universal germ, producing the flame of life, then dwelt there in harmony the One Spirit of the Devas.\n\nWho is the deity we shall worship with our offerings?\n\nIt is that who in its might surveyed the waters, conferring skill and creating worship - That, the God of gods, the One and only One.\n\nWho is the deity we shall worship with our offerings?\n\nMother of the world - may that not destroy us who with Truth as his Law made the heavens and produced waters, vast and beautiful.\n\nWho is the deity we shall worship with our offerings?\n\nLord of creation! No one other than thee pervades all these that have come into being.\n\nMay that be ours, for which our prayers rise, may we be masters of many treasures!\n\n-- (RV 10:121) Ralph T. H. Griffith\n\n1. HIRANYAGARBHA was present at the beginning ;\nwhen born, he was the sole lord of created beings; he\nupheld this earth and heaven,\n\n-let us offer worship with\nan oblation to the divine KA.\n\n2. (To him) who is the giver of soul, the giver of strength,\nWhose commands all (beings), even the gods obey, Whose\nshadow is immortality, whose (shadow) is death,\n\n-let us offer worship with an oblation to the divine KA.\n\n3. (To him) who, by his greatness, has verily become\nthe sole king of the breathing and seeing world, who rules\nover this aggregate of two-footed and four-footed beings,-\n\nlet us offer Worship with an oblation to the divine KA.\n\n4. Through whose greatness these snow-clad (moun-\ntains exist), whose property men call the ocean with the\nrivers, whose are these quarters of space, whose are the\ntwo arms,\n\n--let us offer worship with an oblation to the\ndivine KA.\n\n5. By whom the sky was made profound and the earth\nsolid, by Whom heaven and the solar sphere were fixed,\nwho was the measure of the water in the firmament,-\n\nlet us offer worship with an oblation to the divine KA.\n\n6. Whom heaven and earth established by his pro-\ntection, and, shining brightly, regarded with their mind,\nin whom the risen sun shines forth,\n\n-let us offer worship\nwith an oblation to the divine KA.\n\n7. When the vast waters overspread the universe\ncontaining the germ and giving birth to AGNI, then was\nproduced the one breath of the gods,\n\n-let us offer worship\nwith an oblation to the divine KA.\n\n8. He who by his might beheld the waters all around\ncontaining the creative power and giving birth to sacrifice,\nhe who among the gods was the one supreme god,-\n\nlet us offer worship with an oblation to the divine KA.\n\n9. May he do us no harm who is the parent of the\n-earth, or who the unerring support (of the world) begat\nthe heaven, and who generated the vast and delightful\nwaters,\n\n-let us offer worship with an oblation to the\ndivine KA.\n\n10. No other than thou, PRAJAPATI, hast given existence to all these beings ; may that object of our desires\nfor which we sacrifice to thee be ours, may we be the\npossessors of riches.\n\n"}
{"id": "63334", "url": "https://en.wikipedia.org/wiki?curid=63334", "title": "Ineffability", "text": "Ineffability\n\nIneffability is concerned with ideas that cannot or should not be expressed in spoken words (or language in general), often being in the form of a taboo or incomprehensible term. This property is commonly associated with philosophy, aspects of existence, and similar concepts that are inherently \"too great\", complex or abstract to be communicated adequately. A typical example is the name of God in Judaism, written as YHWH but substituted with \"the Lord\" or \"HaShem\" (the name) when reading.\n\nIn addition, illogical statements, principles, reasons and arguments may be considered intrinsically ineffable along with impossibilities, contradictions and paradoxes. Terminology describing the nature of experience cannot be conveyed properly in dualistic symbolic language; it is believed that this knowledge is only held by the individual from which it originates. Profanity and vulgarisms can easily and clearly be stated, but by those who believe they should not be said, they are considered ineffable. Thus, one method of describing something that is ineffable is by using apophasis, i.e. describing what it is \"not\", rather than what it \"is\". The architect Le Corbusier described his design for the interior of the Chapel of Notre Dame du Haut at Ronchamp as \"L'espace indicible\" translated to mean 'ineffable space', a spiritual experience which was difficult to describe.\n\n"}
{"id": "201087", "url": "https://en.wikipedia.org/wiki?curid=201087", "title": "Interaction", "text": "Interaction\n\nInteraction is a kind of action that occur as two or more objects have an effect upon one another. The idea of a two-way effect is essential in the concept of interaction, as opposed to a one-way causal effect. A closely related term is interconnectivity, which deals with the interactions of interactions within systems: combinations of many simple interactions can lead to surprising emergent phenomena. \"Interaction\" has different tailored meanings in various sciences. Changes can also involve interaction.\n\nCasual examples of interaction outside science include:\n\nIn physics, a fundamental interaction (depending on the nature of the interaction, it might also be called a fundamental force) is a process by which elementary particles interact with each other. An interaction is often described as a physical field, and is mediated by the exchange of gauge bosons between particles. For example, the interaction of charged particles takes place through the mediation of electromagnetic fields, whereas beta decay occurs by means of the weak interaction. An interaction is fundamental when it cannot be described in terms of other interactions. There are four known fundamental interactions in nature: The electromagnetic, strong, weak and gravitational interactions. The weak and electromagnetic interactions are unified in electroweak theory, which is unified with the strong force in the standard model.\n\nInteractions between atoms and molecules:\n\nIn molecular biology, the knowledge on gene/protein interaction among themselves and with their metabolites is referred to as molecular pathways.\n\nIn medicine, most medications can be safely used with other medicines, but particular combinations of medicines need to be monitored for interactions, often by the pharmacist. Interactions between medications fall generally into one of two main categories:\n\nIn terms of efficacy, there can be three types of interactions between medications: additive, synergistic, and antagonistic.\n\nGeneticists work with a number of different genetic interaction modes to characterize how the combination of two mutations affect (or does not affect) the phenotype:\nnoninteractive, synthetic, asynthetic, suppressive, epistatic, conditional, additive, single-nonmonotonic and double-nonmonotonic.\nFurther characterizations is enhancement interaction and nonadditive interaction. Biosemioticists investigate sign-mediated interactions within and between organisms that underlie syntactic, pragmatic and semantic rules.\n\nThe word epistasis is also used for genetic interaction in some contexts.\n\nIn sociology, social interaction is a dynamic, changing sequence of social actions between individuals (or groups) who modify their actions and reactions due to the actions by their interaction partner(s). Social interactions can be differentiated into accidental, repeated, regular, and regulated. Social interactions form the basis of social relations.\n\nIn statistics, an interaction is a term in a statistical model in which the effect of two, or more, variables is not simply additive.\n\nIf we were examining the effect of two variables, gender and premature birth, on health outcomes, we would describe any difference in health outcome scores between genders as a main effect. Similarly any difference in scores of full term/premature birth would be described as a main effect. The presence of an interaction effect implies that the effect of gender on health outcome varies as a function of premature birth status.\n\nIn media, interactivity is a feature of the media in question and as digital technology becomes more accessible to the masses interest in interactivity is increasing and becoming a cultural trend especially in the arts.\n\n\n\nl\n"}
{"id": "22587083", "url": "https://en.wikipedia.org/wiki?curid=22587083", "title": "Interception Modernisation Programme", "text": "Interception Modernisation Programme\n\nThe Interception Modernisation Programme (IMP) is a UK government initiative to extend the government's capabilities for lawful interception and storage of communications data. It has been widely reported that the IMP's eventual goal is to store details of all UK communications data in a central database.\n\nThe proposal is similar to the NSA Call Database (MAINWAY) established by GCHQ's American counterpart NSA and the Titan traffic database established by the Swedish National Defence Radio Establishment.\n\nIn 2008 plans were being made to collect data on all phone calls, emails, chatroom discussions and web-browsing habits as part of the IMP, thought likely to require the insertion of 'thousands' of black box probes into the country’s computer and telephone networks. The proposals were expected to be included in the Communications Data Bill 2008. The \"giant database\" would include telephone numbers dialed, the websites visited and addresses to which e-mails are sent \"but not the content of e-mails or telephone conversations.\" Chris Huhne, the Liberal Democrat Home affairs spokesman said: \"The government's Orwellian plans for a vast database of our private communications are deeply worrying.\"\n\nThe Home Office denied reports that a prototype of the IMP had already been built.\n\nReports in April 2009 suggest that the government has changed its public stance to one of using legal measures to compel communications providers to store the data themselves, and making it available for government to access, with then Home Secretary Jacqui Smith stating that \"there are absolutely no plans for a single central store.\"\n\nThe new plans are thought to involve spending £2bn on paying ISPs to install deep packet inspection equipment within their own networks, and obliging them to perform the cross-correlation and profiling of their users' behaviour themselves, in effect achieving the original goals of the IMP by different means.\n\nA detailed analysis was published by the Policy Engagement Network of the London School of Economics on 16 June 2009. The All Party Privacy Group held a hearing on IMP in the House of Commons on 1 July 2009.\n\nThe UK's new coalition government has apparently revived the IMP in their recent Strategic Defence and Security Review. The new version of the IMP is known as the Communications Capabilities Development Programme.\n\n\n"}
{"id": "22733610", "url": "https://en.wikipedia.org/wiki?curid=22733610", "title": "J. Ernest Wilkins Sr.", "text": "J. Ernest Wilkins Sr.\n\nJesse Ernest Wilkins Sr. (February 1, 1894 – January 19, 1959) was a U.S. lawyer, labor leader, undersecretary in the Eisenhower administration and both the first African-American to be appointed to a sub-cabinet position in the United States Government and the first to attend White House cabinet-level meetings.\n\nAfter a public falling-out with the president and his administration, Wilkins was dismissed from his post by Eisenhower, and then went on to join the U.S. Civil Rights Commission in 1958.\n\nWilkins studied mathematics at the University of Illinois and then attended the University of Chicago Law School in the 1920s, becoming one of its first-ever black graduates. He graduated with a PhD at age 20, a member of its Phi Beta Kappa Society and then practiced law locally for several years.\n\nIn 1954, Wilkins was appointed by President Dwight D. Eisenhower as Undersecretary of Labor for International Labor Affairs (UL-ILA), thus becoming the first black to attend White House cabinet level meetings in the absence of his superior, Labor Secretary James Mitchell. Wilkins had previously served the Eisenhower administration as acting chairman of the \"President's Committee on Government Contracts\" at the request of Val Washington.\n\nDuring his tenure with the administration he was a member of \"Equality Committee\", working with Frederic Murrow, Val Washington, Joseph Douglas, James Nabrit Jr. and Samuel Pierce. Still earlier he had been a member of Eisenhower's President's Committee on Governmental Employment Policy (PCGEP) board when he was with the Labor Department.\n\nAfter a public falling-out with the administration, Wilkins was dismissed from his post by President Eisenhower, and then went on to join the U.S. Civil Rights Commission in 1958. During a later election campaign, John F. Kennedy was quick to note that when Wilkins had been fired he had been replaced by the son of one of the Republican Party's outspoken anti-civil rights advocates.\n\nWhile investigating charges that black voting rights had been violated, his work with the six-member Civil Rights Commission was hampered in Montgomery, Alabama when he was refused accommodation at the hotel where the other commission members were staying. He subsequently found a room for himself at Maxwell Air Force Base. When the commission tried to subpoena county voting records, they discovered that then-Circuit Judge George Wallace had seized the records, and was threatening to jail any commission member who would interfere in his jurisdiction.\n\nIn 1953, Wilkins became the first African American to serve on the nine-member Judicial Council of the Methodist Church, when he was elected its secretary. The body is Methodism's nominal and administrative head.\n\nFrom 1954 to 1957, Wilkins served as U.S. representative on the governing body of the International Labour Organization. In 1959, Wilkins also became the first African-American president of the Judicial Council of the Methodist Church.\n\nWilkins married Lucille Robinson (b. 1899 (?) - d. November 1964, Brooklyn, N.Y., aged 65), who taught school in Chicago, was secretary to the women's division of the Methodist Church, and who also practiced law with her husband for 33 years.\n\nTogether they raised three sons: J. Ernest Wilkins Jr., who achieved fame as a mathematician and nuclear scientist; John Robinson Wilkins, who attended University of Wisconsin at the age of 14, Harvard Law School at 19, was elected to the \"Harvard Law Review\", and went on to serve President Kennedy as general council for the Agency for International Development (AID); and Julian B. Wilkins, who practiced general and corporate law.\n\nWilkins, the son of a Missouri Baptist preacher, also served as the Grand Polemarch (national president) of Kappa Alpha Psi Fraternity, Inc. Wilkins died as a result of a heart attack in Washington, D.C., in late January 1959, at the age of 64.\n\nIn 2010 Wilkins's granddaughter, Carolyn Marie Wilkins, a Professor at the Berklee College of Music in Boston, wrote of her grandfather and her family more generally in her biography \"Damn Near White: An African American Family's Rise from Slavery to Bittersweet Success\".\n\n"}
{"id": "55787707", "url": "https://en.wikipedia.org/wiki?curid=55787707", "title": "John Hervey Wheeler", "text": "John Hervey Wheeler\n\nJohn Hervey Wheeler (January 1, 1908 – July 6, 1978) was an African American bank president, businessman, civil rights leader, and educator based in North Carolina. Throughout his life, Wheeler was recognized for his accomplishments by various institutions across the country. John H. Wheeler started as a bank teller at Mechanics and Farmers Bank, and worked his way up to become the bank's president in 1952. In the 1960s, Wheeler became increasingly active in United States politics, carrying several White House positions appointed by Presidents John F. Kennedy, Richard Nixon, and Lyndon B. Johnson.\n\nJohn H. Wheeler was born on the campus of Kittrell College in 1908, to John Leonidas and Margaret Hervey Wheeler. In 1935, he married, Serena Warren Wheeler and they subsequently had two children, Warren and Julia. Wheeler died in 1978. In 2017, a bill was introduced into congress to rename the courthouse in Durham, North Carolina the \"John Hervey Wheeler United States Courthouse\" in recognition of his achievements.\n\nJohn H. Wheeler began his academic career at Morehouse College in 1925. He graduated summa cum laude with a Bachelor of Arts degree in 1929. In 1947, Wheeler graduated from the law school at the North Carolina College for Negroes (now North Carolina Central University). He was also an active member of Omega Psi Phi fraternity, Beta Phi chapter. Beginning as a teller at the Mechanics and Farmers Bank in 1929, he rose to become president of the bank in 1952.\n\nThe activism and leadership of John H. Wheeler thrived in the 1950s and 1960s. He was heavily involved in politics and education through various positions within the federal government and on various boards of trustees for institutions like Morehouse College, Atlanta University, Lincoln Hospital, and the National Scholarship Service for Negro Students. During his time serving in the White House, Wheeler devoted his time to the development of low-income housing, focused on race relations, and the elimination of poverty. He had working relationships with a number of United States presidents, John F. Kennedy, Richard Nixon, and Lyndon B. Johnson, who invited him to assist in drafting the Civil Rights Act of 1964. In 1956, John H. Wheeler was also the first African-American to bring an integration suit in the state of North Carolina.\n\nJohn H. Wheeler was an active member of the United Negro College Fund, where he attended several meetings and convocations for decades. In March 1966 at the UNCF Role of Business Convocation, Wheeler delivered a powerful speech concerning the need for more training and opportunities for African-American scholars. Through UNCF, Wheeler was able to advocate for the need of higher educational opportunities for the black community.\n\n\n\n"}
{"id": "51310100", "url": "https://en.wikipedia.org/wiki?curid=51310100", "title": "Katrin Hattenhauer", "text": "Katrin Hattenhauer\n\nKatrin Hattenhauer (born 10 November 1968 in Nordhausen, Thueringen) is a German painter and civil rights activist. In the late 1980s she was a member of the GDR-opposition movement. On 4 September 1989 she demonstrated \"For an Open Country with Free People\", marking the beginning of the Monday demonstrations in Leipzig. Her paintings and social sculptures have been exhibited in Europe.\n\nKatrin Hattenhauer was not allowed to sit the Abitur, Germany's secondary-school examinations. Upon completing her school education she worked as a puppeteer at the local theatre in her home town [Nordhausen]. She moved on to working for the Wittenberg research centre of the East-German churches and completed an internship at the Zionsparish in Dresden. In 1988 she took up her studies at the church run theological university in Leipzig. However, due to her increased political activity – among other things she had distributed pamphlets for a demonstration in January 1989 - the GDR government pressured the church to force her to leave the university, which she ultimately did. Katrin Hattenhauer was an active member of the ‘Arbeitskreis Gerechtigkeit’ (Working Committee Justice), an independent Leipzig-based opposition group that was part of the network ‘Initiative Frieden und Menschenrechte’ (Initiative Peace and Human Rights). Moreover, she was active in the Monday Peaceprayers at the Nikolaichurch, which were coordinated by pastor Christoph Wonneberger.\n\nTogether with the former songwriter Jochen Läßig, who had been ex-matriculated from the theological university Leipzig due to his political activity, she organised the first street music festival in the city centre of Leipzig. The festival took place on 10 June 1989. However, the festival had been illegal and numerous contributors, visitors, and pedestrians were arrested. Importantly, the street festival was the first occasion in the GDR on which passers-by solidarised themselves with political dissidents.\n\nThe Stasi (Staatsicherheitsdienst, state security service) maintained the operational identity check (Operative Personenkontrolle) 'Meise' (Tit) for the surveillance of Katrin Hattenhauer. Yet, despite the regular Stasi-interrogations and an order that prevented her from earning a living almost entirely, she continued to commit herself to political change in the GDR. She went on hunger strike at the Thomas-church Leipzig and criticised the constitutional capacity of the SED directly and openly. Referring to Vaclav Havel she called for the 'bond-slaves' in a system of paternalism' to 'renounce resignation in the society': 'We pray for wisdom and courage, so that what is limited to narrowness and prison for so many may become our home country again'.\n\nOn 4 September 1989 she initiated, together with Gesine Oltmanns, a demonstration in front of the Nikolaichurch, after the Monday Peace Prayer held there. Both women had prepared four banners, had smuggled them into the church circumventing their surveillants from the Stasi. Coming out into the public square the two women then unfolded their banner that called for 'Für ein offenes Land mit freien Menschen' (For an Open Country with Free People), while more activists followed them with the other banners.\n\nAbout 50 activists and 250 people who wanted to emigrate from the GDR joined behind them in a first attempt to move on demonstrating, some shouting 'we want to get out', others 'we stay'. Western TV teams, which had been allowed into Leipzig to cover the fair, had secretly been informed that something would be happening in front of the church. Thus, the footage of the demonstration became the lead story in West-Germany´s TV-news, carrying the pictures of this first Mondaydemonstration into every household in East-Germany. Eventually, Stasimen tore down the banners and wrestled down the women but no one was arrested before the cameras since the GDR feared the publicity.\n\nOn the following Monday, 11 September, Katrin Hattenhauer was targeted demonstrating on Nikolaisquare and arrested together with other protesters and put in the Stasi-prison at Leipzig Beethoven Strasse, where she was imprisoned until 13.10.1089. In prison she was kept in solitary confinement for most of the time and interrogated brutally. Yet, on each following Monday more and more people joined the Mondaydemonstrations in Leipzig, contributing decisively to the eventual downfall of the GDR regime. Regular services and public vigils in different cities of the GDR called for the release of the unjustly imprisoned. Thus, focal points of protest developed, accelerating the democratic revolution.\nKatrin Hattenhauer was well known in opposition-circles and church-groups in the GDR, she had participated in the Oecomenical Convention and taken part in trans-regional ecological seminars. She was the Leipzig contact person to the ecological library (Umweltbibliothek) a meeting point of the opposition groups in East-Berlin.\n\nIn 1991 she helped to establish the Archiv Bürgerbewegung Leipzig (The Archiv Bürgerbewegung received the German National Award in 2015), working on the board. On 8 October 2000 she and Jochen Läßig, another dissident, opened the \"Lichtfest\" (Festival of Light) in Leipzig, speaking in front of 200.000 people to remember the crucial turning point in 1989. On 7 November 2014 Katrin Hattenhauer spoke at Germany's ceremonial act, celebrating the 25 year anniversary of the fall of the wall and German reunification at the Brandenburg Gate. There, she addressed the younger generation, urging them to 'take their freedom and live their dreams. The touring exhibition 'Revolution is female' recognizes her and other women's contributions to the Peaceful Revolution 1989.\n\nKatrin Hattenhauer often comments on the Peaceful Revolution 1989 and questions of German unity. Similarly, she speaks on radio, TV and frequently at schools, answering questions about civil courage. She is serving on the board of the Kreisau-Initiative and on the historical commission of the Krzyzowa/Kreisau foundation in Poland. In October 2015 she initiated an open letter of former East-German dissidents to Angela Merkel, supporting a policy of open borders for refugees who seek political asylum. The letter was published by the Deutsche Welle in English, French, Russian and Spanish.\n\nShe has got one son and is living together with her husband in Berlin and Oxford.\n\nIn the wake of the Peaceful Revolution Katrin Hattenhauer became an artist. Her first exhibition \"Magical Theatre\" was opened in her flat in Leipzig on 9.December 1989. She has had exhibitions in numerous places in Europe and in the United States. The secretary-general of the biennial national Protestant gathering (Deutscher Evangelischer Kirchentag), Ellen Ueberschär, described her art as follows: \"Hattenhauer´s art is not GDR-art, not art of the GDR, it is an answer to the GDR, it is the 'even though' of an art that says 'Yes' to freedom against all odds.” Her figurative paintings focus on human emotion, freedom, and civil engagement. The late Freya von Moltke wrote about her: In the time before and around 1989, Katrin Hattenhauer has dared to demand freedom and has experienced what that can mean for the personal future. Stemming from this experience her paintings express great courage and joy in life.\" Katrin Hattenhauer, continually works with young people, using her art to approach questions of personal freedom and civil courage. In the last years Katrin Hattenhauer has turned towards and focused on installation art addressing various political and societal topics. \"Lichtgestalten\" about role models, Mannheim 2012, \"Müllwiese\" (Rubbish Meadow) Hamburg shed and artistic light on the pollution of the oceans through plastic waste, while 'Über das Verschwinden (On Disappearing), London and Leipzig, raised awareness of the murder of political dissidents. At the moment she is linked with the Social Sculpture Unit, Brookes University Oxford.\n\nKatrin Hattenhauer was awarded the Officer´s Cross of the German Order of Merit.\n\n\n\n\n\nExcerpt: \"The Rebels - Regime Change in East Germany\", a film by M. Martin and B. Claudy, Deutsche Welle broadcast in English, Arabian, Spanish, German on 17 October 2014\n\n"}
{"id": "35376387", "url": "https://en.wikipedia.org/wiki?curid=35376387", "title": "Kentucky Inventory of Mindfulness Skills", "text": "Kentucky Inventory of Mindfulness Skills\n\nThe Kentucky Inventory of Mindfulness Skills (KIMS) is a 39-item self-report measuring Mindfulness on four scales: i.\"Observing\", ii.\"Describing\", iii.\"Act With Awareness\", and iv.\"Accept Without Judgment\". It was developed at Kentucky University by Baer, Smith, & Allen in 2004. A short, 20-item version of it (KIMS-Short) was developed in Germany in 2011 and enables researchers to replicate the basic factor structure. However KIMS-Short shows the \"Observing\" subscale as comprising two different but strongly correlated factors depending on whether the observed stimuli are internal or external. Good support has been found for the model of four correlated factors, and the scales have been found to be both highly internally consistent and sensitive to change through Mindfulness-Based Cognitive Therapy. \n\nThe four scales have been positively correlated with social activity.\n"}
{"id": "6376221", "url": "https://en.wikipedia.org/wiki?curid=6376221", "title": "Landlord harassment", "text": "Landlord harassment\n\nLandlord harassment is the willing creation, by a landlord or his agents, of conditions that are uncomfortable for one or more tenants in order to induce willing abandonment of a rental contract. Such a strategy is often sought because it avoids costly legal expenses and potential problems with eviction. This kind of activity is common in regions where rent control laws exist, but which do not allow the direct extension of rent-controlled prices from one tenancy to the subsequent tenancy, thus allowing landlords to set higher prices. Landlord harassment carries specific legal penalties in some jurisdictions, but enforcement can be very difficult or even impossible in many circumstances. However, when a crime is committed in the process and motives similar to those described above are subsequently proven in court, then those motives may be considered an aggravating factor in many jurisdictions, thus subjecting the offender(s) to a stiffer sentence.\n\nVarious methods may be employed in cases of landlord harassment, such as, but not limited to the following:\n\nAt common law tenants were entitled to the \"quiet enjoyment\" of leased premises. American common law has also adopted the \"warranty of habitability\" which ensures that residential premises remain in repair.\n\nIn the United Kingdom and the Commonwealth, the Human Rights Act may provide a basis to establish what is fair and reasonable between tenant and landlord. The right to private and family life, and the right to enjoy one's possessions, are enshrined in this law. The right to an effective remedy and the right to express oneself freely should give the tenant the confidence to seek timely and reasonable resolution should they be suffering or under duress. Although human rights legislation is generally only enforceable against public bodies, it provides a framework of reasonability.\n\nDepending on the specific circumstances, United Kingdom legislation such as the Public Order Act 1986 and the Fraud Act 2006 may provide specific remedies. Both common law and public order legislation makes it an offence for persons to behave wrongfully in a dwelling e.g. breach of the peace. Fraud legislation makes it an offence for a person to make a wrongful or forced gain (monetary or other) personally or for the body they represent.\n\nMany local jurisdictions have very specific landlord-tenant legislation that sets out the duties of the landlord, a breach of which may be considered \"harassment\". For example, in California, Civil Code Section 1954, limits the landlord's right of entry, and in New Mexico, there is an extensive \"Owner-Resident Relations Act\"\n\nThe conduct of business inside or at a dwelling must depend upon the reasonableness and willingness of the parties. If a landlord desires to inspect the dwelling at reasonable intervals and at reasonable times, it is advisable to have this in a contract proper--- Regardless, the purpose of the inspection must be clear, and the conduct of the inspection must be properly regulated. The purpose of any inspection is surely to ensure the integrity and good maintenance of the property, and the adherence to the agreement that exists between landlord and tenant. Entry into a dwelling does not give the landlord the right to gather information on, or to investigate, or interfere with, the privacy of the tenant. If the tenant is not comfortable dealing with the landlord or agent, then the tenant may wish to appoint a representative or friend. In either case, a simple and sensible record should be made.\n\nThe time taken to carry out the task should be reasonable. The tenant may not wish to conduct business inside a dwelling, and can reasonably ask the landlord to meet or transact business at an alternate place or address.\n\nFor example, the landlord (or agent) may attend at the premises to carry out an inspection which will normally take only a matter of minutes. The parties may then agree to exchange a simple written statement of facts, and then meet at a neutral place to discuss the matter or remedy.\n\nIn carrying out repairs, replacements and other work, the landlord should make reasonable efforts to limit the frequency of entries to those actually necessary to accomplish the work. For the sake of retention of one’s tenants and the avoidance of strife during tenancy, the keys to exercise of the right to entry are as follows. 1. Enter as infrequently as possible. 2. Always give ample notice and, if possible, allow rescheduling of the entry at least once to accommodate the tenant. 3. Always enter with a clearly defined objective in mind, and notify the tenant of it unless there is a strong reason not to do so.\n\nLegally, even a rented home is the tenant's castle, and the landlord does not have an unlimited right of access. Once an individual has rented an apartment, they have legal possession of it for the duration of their tenancy. The landlord must give the tenant reasonable notice, before he can enter the tenant's private home.\n\nOriginally, in an agricultural society, the law expected the landlord to rent the property to a tenant and then leave the tenant alone. It gave the landlord no right of access, but also no responsibility for repairs. The modern urban tenancy, especially in a multi-unit building with many building-wide systems, has forced that law to change. The landlord now has an obligation to make repairs and gets a right of access for that purpose. But that does not supersede the tenant's rights to privacy and to \"quiet enjoyment\" of the premises.\n\nOne of the most common landlord-tenant disputes involves access for making repairs. State Sanitary Codes require tenants to allow the landlord \"reasonable access\" at reasonable times to repair code violations. What is \"reasonable\", however, is the subject of frequent disputes. A tenant may insist on giving the landlord access only by appointment, but they must be reasonable about scheduling appointments. To give an extreme example, since the landlord usually must schedule tradespeople during the normal working day, it is not reasonable for the tenant to insist that the plumber can only come in on Sunday evening. Plumbers, carpenters, painters, and other tradesmen sometimes operate on unpredictable or busy schedules, so if they fail to keep appointments, tenants are encouraged to document the missed appointment in writing to the landlord, in a letter or e-mail, and keep a copy. Because some landlords may use lack of access as an excuse, tenants are also encouraged to keep scheduled appointments and maintain a good written record of their efforts to allow the landlord access to their property to make the desired repairs. In addition, because of documented cases of tradesmen stealing property, making long-distance phone calls, or committing other abuses while making repairs, tenants are also urged to make sure that the landlord or a representative be with repairmen at all times when they are in the tenant's property during the tenant's absence.\n\nHousing courts can often be helpful in mediating disputes over access. The tenant's credibility in court will be improved if he or she has consistently cooperated reasonably with the landlord's need for access, and has documented their cooperation with careful record-keeping. If necessary, with a particularly difficult landlord, the tenant may benefit from asking a witness to observe interactions, and later testify about the landlord's conduct.\n\nMany leases give the landlord certain entry rights. For example, under Massachusetts General Laws, ch.186, §15B, a rental agreement may only provide for the following rights to access:\n\nThe landlord may also enter the premises in accordance with a court order or if the tenant appears to have abandoned the premises. If a lease allows the landlord to enter for any other reason, that provision is illegal and void. In addition, the landlord's right to inspect the premises or to show them to a prospective purchaser does not mean that he or she can do it twice every day; the tenant can limit inspections to reasonable frequency. Unless the lease provides that the tenant must give the landlord a key to their property, the landlord has no right to one. The fact that a lease allows the landlord a right to enter for certain purposes also does not mean that the landlord may enter a private residence at any time without an appointment.\n\nThe right of the landlord to enter if the tenant appears to have abandoned the premises sometimes causes a problem when tenants are moving out. The tenant may have moved out most of their furniture and intend to return to pick up the last few things and clean up the apartment before turning in the keys. If the landlord believes the tenant has vacated the premises, however, he or she may come in ahead of the tenant, remove the remaining property, and attempt to charge the tenant for the \"mess\" they left. To avoid this situation, tenants are encouraged to be clear with landlords about plans to vacate, and to do so in writing. In one documented case, a tenant came back from his vacation and found someone else living in his apartment, with his furniture stored in the cellar. He wasn't behind on his rent, but he had been away for a while, and the landlord concluded that he had abandoned the apartment. To preclude any perception of abandonment, a tenant who is going out of town may benefit from informing his or her landlord of the trip, preferably in writing. If the tenant is away for an extended time, does not pay the rent, and does not respond to inquiries from the landlord, a court may find the landlord justified in concluding that the tenant has abandoned the property.\n\nA landlord cannot try to evict a tenant, raise the rent, or change the terms of tenancy because the tenant has complained in writing to the landlord, or to any government agency, regarding conditions. The landlord also cannot retaliate in this fashion because a tenant has organized or joined a tenant union, or engaged in certain other protected activities. Within six months after a tenant has engaged in any of these protected activities, any act by the landlord of raising the rent, attempting eviction (except for non-payment), or making any change in any of the terms of tenancy is presumed to be a retaliation. This means that in any court proceeding, the burden will be on the landlord to prove that he or she is not retaliating against the tenant. In order to defeat a retaliation claim, a landlord must convince the court that he or she took the action for reasons independent of the tenant's protected action, and that he or she would have done the same thing at the same time even if the tenant hadn't engaged in the protected activity. If the landlord waits until six months after protected actions, retaliation may still be found, but the burden of proof is on the tenant.\n\nIf a landlord is found to be retaliating, he or she will not be able to evict the tenant, who may also be awarded damages from the landlord of one to three months' rent plus attorney's fees. The landlord also cannot willfully deprive the tenant of heat, hot water, gas, electricity, lights, water, or refrigeration service. Nor can the landlord lock out the tenant or remove him/her from their apartment without going through the proper court procedure. The tenant can ask the court to issue a restraining order, file a criminal complaint against the landlord, or sue him/her for money damages and attorney's fees. Because of these options for recourse, it may be to the tenant's advantage to complain about code violations in writing before the landlord issues a notice of an eviction or a rent increase. If a tenant attempts to claim retaliation, but did not complain about violations until after he or she received notice from the landlord, the tenant will be found to have no valid claim. The court will not find that the landlord was retaliating against the tenant for an action he or she had not yet taken.\n\nConsumer protection laws also provide some protection against landlord harassment in some states. One such statute is Chapter 93A of the Massachusetts General Laws, commonly called the \"Consumer Protection Law\". Like the Federal Trade Commission Act on which it is based, and similar \"baby FTC\" laws in other states, it prohibits the use of any unfair and deceptive acts and practices in the conduct of any trade or business. Housing rental is generally considered to be a trade or business, and the Massachusetts Attorney General has issued regulations which define unfair and deceptive acts or practices in the rental housing field. Practices defined as unfair include failure by the landlord to disclose, to a tenant or prospective tenant, any fact of the disclosure of which may have influenced the latter not to enter into the transaction. Also defined as an unfair practice is any violation of any law meant to protect consumers, and any act which is oppressive or otherwise unconscionable in any respect. While the Consumer Protection Law provides some protections for tenants. If a landlord is the owner-occupant of a two-family or three-family house and owns no other rental property, he or she is not considered to be engaged in a trade or business, and is not subject to this law.\n\n\n"}
{"id": "2418652", "url": "https://en.wikipedia.org/wiki?curid=2418652", "title": "Last clear chance", "text": "Last clear chance\n\nThe last clear chance is a doctrine in the law of torts that is employed in contributory negligence jurisdictions. Under this doctrine, a negligent plaintiff can nonetheless recover if he is able to show that the defendant had the last opportunity to avoid the accident. Though the stated rationale has differed depending on the court adopting the doctrine, the underlying idea is to mitigate the harshness of the contributory negligence rule. The defendant can also use this doctrine as a defense. If the plaintiff has the last clear chance to avoid the accident, the defendant will not be liable.\n\nThe Restatement (Second) of Torts explains the doctrine in detail as follows:\n\n"}
{"id": "10228970", "url": "https://en.wikipedia.org/wiki?curid=10228970", "title": "Living High and Letting Die", "text": "Living High and Letting Die\n\nLiving High and Letting Die: Our Illusion of Innocence is a philosophical book by Peter K. Unger, published in 1996.\n\nInspired by Peter Singer's 1971 essay \"Famine, Affluence, and Morality,\" Unger argues that for people in the developed world to live morally, they are morally obliged to make sacrifices to help mitigate human suffering and premature death in the third world, and further that it is acceptable (and morally right) to lie, cheat, and steal to mitigate suffering.\n\nUnger argues that the intuitive moral judgments most people have of several hypothetical moral scenarios, \"The Shallow Pond\", \"The Vintage Sedan\", and \"The Envelope\", are inconsistent.\n\nUnger presents the hypothetical case of \"The Vintage Sedan\": \n\nNot truly rich, your one luxury in life is a vintage Mercedes sedan that, with much time, attention, and money, you've restored to mint condition... One day, you stop at the intersection of two small country roads, both lightly traveled. Hearing a voice screaming for help, you get out and see a man who's wounded and covered with a lot of his blood. Assuring you that his wound is confined to one of his legs, the man also informs you that he was a medical student for two full years. And, despite his expulsion for cheating on his second year final exams, which explains his indigent status since, he's knowledgeably tied his shirt near the wound as to stop the flow. So, there's no urgent danger of losing his life, you're informed, but there's great danger of losing his limb. This can be prevented, however, if you drive him to a rural hospital fifty miles away. \"How did the wound occur?\" you ask. An avid bird-watcher, he admits that he trespassed on a nearby field and, in carelessly leaving, cut himself on rusty barbed wire. Now, if you'd aid this trespasser, you must lay him across your fine back seat. But, then, your fine upholstery will be soaked through with blood, and restoring the car will cost over five thousand dollars. So, you drive away. Picked up the next day by another driver, he survives but loses the wounded leg.\n\nUnger reports that most people respond strongly that abandoning the hitchhiker is abominable behavior, and he contrasts this near-universal harsh judgment with the lenient judgments most people give to \"The Envelope\":\n\nIn your mailbox, there's something from (the U.S. Committee for) UNICEF. After reading it through, you correctly believe that, unless you soon send in a check for $100, then, instead of each living many more years, over thirty more children will die soon.\n\nUnger argues that the factors that distinguish The Envelope from The Vintage Sedan, in which morality compels us to make a sacrifice, are not morally significant, using thought experiments such as variations on the trolley problem to illustrate his point. Unger contends that psychological factors obscure the moral questions, and that our moral intuitions about problems such as these provide an inconsistent window into our true moral values.\n\nUnger conspicuously indicates that the author's royalties from the sales of this book go to UNICEF and to Oxfam America.\n\nBarry Smith and Berit Brogaard (writing under the pseudonym of Nicola Bourbaki) argue in their \"Living High and Letting Die\", that Unger's argument undermines one central approach to the defense of abortion advanced by Judith Jarvis Thomson in her famous Violinist (thought experiment):\nImagine that your body has become attached, without your permission, to that of a sick violinist. The violinist is a human being. He will die if you detach him. Such detachment seems, nonetheless, to be morally permissible. Thomson argues that an unwantedly pregnant woman is in an analogous situation. Her argument is considered by many to have established the moral permissibility of abortion even under the assumption that the foetus is a human being. \nFollowing the strategy adopted by Unger, Smith and Brogaard point to a number of scenarios in which a woman's right to decide what happens in and to her body seems to be outweighed by the right to life of the violinist.\n\n\n\n"}
{"id": "31366108", "url": "https://en.wikipedia.org/wiki?curid=31366108", "title": "Lubachevsky–Stillinger algorithm", "text": "Lubachevsky–Stillinger algorithm\n\nLubachevsky-Stillinger (compression) algorithm (LS algorithm, LSA, or LS protocol) is a numerical procedure suggested by F. H. Stillinger and B.D. Lubachevsky that simulates or imitates a physical process of compressing an assembly of hard particles. As the LSA may need thousands of arithmetic operations even for a few particles, it is usually carried out on a digital computer.\n\nA physical process of compression often involves a contracting hard boundary of the container, such as a piston pressing against the particles. The LSA is able to simulate such a scenario. However, the LSA was originally introduced in the setting without a hard boundary where the virtual particles were \"swelling\" or expanding in a fixed, finite virtual volume with periodic boundary conditions. The absolute sizes of the particles were increasing but particle-to-particle relative sizes remained constant. In general, the LSA can handle an external compression and an internal particle expansion, both occurring simultaneously and possibly, but not necessarily, combined with a hard boundary. In addition, the boundary can be mobile.\n\nIn a final, compressed, or \"jammed\" state, some particles are not jammed, they are able to move within \"cages\" formed by their immobile, jammed neighbors and the hard boundary, if any. These free-to-move particles are not an artifact, or pre-designed, or target feature of the LSA, but rather a real phenomenon. The simulation revealed this phenomenon, somewhat unexpectedly for the authors of the LSA. Frank H. Stillinger coined the term \"rattlers\" for the free-to-move particles, because if one physically shakes a compressed bunch of hard particles, the rattlers will be rattling.\n\nIn the \"pre-jammed\" mode when the density of the configuration is low and when the particles are mobile, the compression and expansion can be stopped, if so desired. Then the LSA, in effect, would be simulating a granular flow. Various dynamics of the instantaneous collisions can be simulated such as: with or without a full restitution, with or without tangential friction.\nDifferences in masses of the particles can be taken into account. It is also easy and sometimes proves useful to \"fluidize\" a jammed configuration, by decreasing the sizes of all or some of the particles. Another possible extension of the LSA is replacing the hard collision force potential (zero outside the particle, infinity at or inside) with a piece-wise constant force potential. The LSA thus modified would approximately simulate molecular dynamics with continuous\nshort range particle-particle force interaction. External force fields, such as gravitation, can be also introduced, as long as the inter-collision motion of each particle can be represented by a simple one-step calculation.\n\nUsing LSA for spherical particles of different sizes and/or for jamming in a non-commeasureable size container proved to be a useful technique for generating and studying micro-structures formed under conditions of a crystallographic defect or a geometrical frustration It should be added that the original LS protocol was designed primarily for spheres of same or different sizes.\n\nAny deviation from the spherical (or circular in two dimensions) shape, even a simplest one, when spheres are replaced with ellipsoids (or ellipses in two dimensions), causes thus modified LSA to slow down substantially.\nBut as long as the shape is spherical, the LSA is able to handle particle assemblies in tens to hundreds of thousands\non today's (2011) standard personal computers. Only a very limited experience was reported\nin using the LSA in dimensions higher than 3.\n\nThe state of particle jamming is achieved via simulating a granular flow. The flow is rendered as a discrete event simulation, the events being particle-particle or particle-boundary collisions. Ideally, the calculations should have been\nperformed with the infinite precision. Then the jamming would have occurred ad infinitum. In practice, the precision is finite as is the available resolution of representing the real numbers in the computer memory, for example, a double-precision resolution. The real calculations are stopped when inter-collision runs of the non-rattler particles become\nsmaller than an explicitly or implicitly specified small threshold. For example, it is useless to continue the calculations when inter-collision runs are smaller than the roundoff error.\n\nThe LSA is efficient in the sense that the events are processed essentially in an event-driven fashion, rather than in a \ntime-driven fashion. This means almost no calculation is wasted on computing or maintaining the positions and velocities\nof the particles between the collisions. Among the event-driven algorithms intended for the same task of simulating granular flow, like, for example, the algorithm of D.C. Rapaport, the LSA is distinguished by a simpler data structure and data handling.\n\nFor any particle at any stage of calculations the LSA keeps record of only two events: an old, already processed committed event, which comprises the committed event time stamp, the particle state (including position and velocity), and, perhaps, the \"partner\" which could be another particle or boundary identification, the one with which the particle collided in the past,\nand a new event proposed for a future processing with a similar set of parameters. The new event is not committed. The maximum of the committed old event times must never exceed the minimum of the non-committed new event times.\n\nNext particle to be examined by the algorithm has the current minimum of new event times. At examining the chosen particle,\nwhat was previously the new event, is declared to be the old one and to be committed, whereas the next new event is being scheduled, with its new time stamp, new state, and new partner, if any. As the next new event for a particle is being set,\nsome of the neighboring particles may update their non-committed new events to better account for the new information.\n\nAs the calculations of the LSA progress, the collision rates of particles may and usually do increase. Still the LSA successfully approaches the jamming state as long as those rates remain comparable among all the particles, except for the rattlers. (Rattlers experience consistently low collision rates. This property allows one to detect rattlers.) However, \nit is possible for a few particles, even just for a single particle, to experience a very high collision rate along the approach to a certain simulated time. The rate will be increasing without a bound in proportion to the rates of collisions in the rest of the particle ensemble. If this happens, then the simulation will be stuck in time, it won't be able to progress toward the state of jamming.\n\nThe stuck-in-time failure can also occur when simulating a granular flow without particle compression or expansion. This failure mode was recognized by the practitioners of granular flow simulations as an \"inelastic collapse\" because it often occurs in such simulations when the restitution coefficient in collisions is low (i.e. inelastic). The failure is not specific to only the LSA algorithm. Techniques to avoid the failure have been proposed.\n\nThe LSA was a by-product of an attempt to find a fair measure of speedup in parallel simulations. The Time Warp parallel simulation algorithm by David Jefferson was advanced as a method to simulate asynchronous spatial interactions of fighting units in combat models on a parallel computer. Colliding particles models offered similar simulation tasks with spatial interactions of particles but clear of the details that are non-essential for exposing the simulation techniques. The speedup was presented as the ratio of the execution time on a uniprocessor over that on a multiprocessor, when executing the same parallel Time Warp algorithm. Boris D. Lubachevsky noticed that such a speedup assessment might be faulty because executing a parallel algorithm for a task on a uniprocessor is not necessarily the fastest way to perform the task on such a machine. The LSA was created in an attempt to produce a faster uniprocessor simulation and hence to have a more fair assessment of the parallel speedup. Later on, a parallel simulation algorithm,\ndifferent from the Time Warp, was also proposed, that, when run on a uniprocessor, reduces to the LSA.\n\n"}
{"id": "23022330", "url": "https://en.wikipedia.org/wiki?curid=23022330", "title": "Maitreya (Theosophy)", "text": "Maitreya (Theosophy)\n\nIn Theosophy, the Maitreya or Lord Maitreya is an advanced spiritual entity and high-ranking member of a hidden Spiritual Hierarchy, the so-called \"Masters of the Ancient Wisdom\". According to Theosophical doctrine, one of the Hierarchy's functions is to oversee the evolution of humankind; in accord with this function the Maitreya is said to hold the so-called \"Office of the World Teacher\". Theosophical texts posit that the purpose of this Office is to facilitate the transfer of knowledge about the true constitution and workings of Existence to humankind. Humanity is thereby assisted on its presumed cyclical, but ever progressive, evolutionary path. Reputedly, one way the knowledge transfer is accomplished is by Maitreya occasionally manifesting or incarnating in the physical realm; the manifested entity then assumes the role of \"World Teacher\" of Humankind.\n\nThe Theosophical concept of Maitreya has many similarities to the earlier Maitreya doctrine in Buddhism. However, they differ in important aspects. The Theosophical Maitreya has been assimilated or appropriated by a variety of quasi-theosophical and non-theosophical New Age and Esoteric groups and movements.\n\nThe first mention of the Maitreya in a Theosophical context occurs in the 1883 work \"Esoteric Buddhism\" by Alfred Percy Sinnett (1840–1921), an early Theosophical writer. The concepts described by Sinnett were amended, elaborated on, and greatly expanded in \"The Secret Doctrine\", a book originally published 1888. The work was the magnum opus of Helena Blavatsky (1831–1891), one of the founders of the Theosophical Society and of contemporary Theosophy. In it, the messianic Maitreya is linked to both Buddhist and Hindu religious traditions. In the same work Blavatsky asserted that there have been, and will be, multiple messianic (or messianic-like) instances in human history. These successive appearances of \"emissarie[s] of Truth\" are according to Blavatsky part of the unceasing oversight of Earth and of its inhabitants by a hidden Spiritual Hierarchy, the so-called \"Masters of the Ancient Wisdom\".\n\nFollowing Blavatsky's writings on the subject, other Theosophists progressively elaborated on the Spiritual Hierarchy. Its members are presented as guardians and guides of Earth's total evolutionary process, known in Theosophical cosmology as the doctrine of \"Planetary Rounds\". According to Theosophists, evolution includes an occult or spiritual component that is considered of a higher order of importance than the related physical evolution. The Hierarchy presumably consists of spiritual entities at various evolutionary stages – these stages correspond to ever increasing ranks within the Hierarchy. Lower ranks are populated by individuals who can function more or less normally on the physical plane, while in the highest known rankings are highly evolved beings of the purest spiritual essence and consciousness.\n\nAccording to the Theosophical exposition, in the current stage of Planetary Evolution the position of Maitreya in Earth's Hierarchy is that of the so-called \"Boddhisatva\", originally a Buddhist concept. Since this position is thought to be at an exalted state, the Maitreya may have no direct or sustained contact with the physical realm. At this evolutionary level he is below only two other beings in the current Hierarchy: at its apex, the Sanat Kumara, (also referred to as \"The Lord of the World\"), followed by the Buddha; as such the Maitreya is held in high reverence and regard by Theosophists. He is additionally described as having among other duties overall responsibility for humanity's development, including its education, civilization, and religion.\n\nBlavatsky held that members of the Hierarchy, often called \"the Masters\" or \"the Mahātmās\" in Theosophical literature, were the ultimate guides of the Theosophical Society. The Society itself was said to be the result of one of the \"impulses\" from the Hierarchy. These \"impulses\" are believed to be a regular occurrence. Furthermore, Blavatsky commented in her widely read 1889 work \"The Key to Theosophy\" on the next impulse, the \"effort of the XXth century\" which would involve another \"torch bearer of Truth\". In this effort the Theosophical Society was poised to possibly play a major role. More information regarding the future \"impulse\" was the purview of the Theosophical Society's \"Esoteric Section\" which was founded by Blavatsky and was originally led by her. Its members had access to occult instruction and more detailed knowledge of the \"inner order\" and mission of the Society, and of its reputed hidden guides.\n\nBlavatsky also elaborated on a so-called \"Christ Principle\", which in her view corresponds to the spiritual essence of every human being. After Blavatsky’s death in 1891 influential Theosophist Charles Webster Leadbeater (1854–1934), whose knowledge on occult matters was highly respected by the Society's leadership, formulated a Christology in which he identified Christ with the Theosophical representation of the Buddhist deity Maitreya. He maintained that an aspect of Maitreya was the prototype for the \"Christ Principle\" described by Blavatsky. Leadbeater believed that \"Maitreya-as-Christ\" had previously manifested on Earth, often through specially prepared people who acted as the entity's \"vehicles\". The manifested Maitreya then assumed the role of World Teacher, dispensing knowledge regarding underlying truths of Existence. This knowledge, which according to Theosophists eventually crystallized in religious, scientific and cultural practices, had been reputedly disseminated to groups as small as a few carefully selected Initiates and as large as Humanity as a whole.\n\nIn Theosophical texts, the Maitreya is said to have had numerous manifestations or incarnations: in the theorized ancient continent of Atlantis; as a Hierophant in Ancient Egypt; as the Hindu deity Krishna; as a high priest in Ancient India; and as Christ during the three years of the Ministry of Jesus.\n\nAnnie Besant (1847–1933), another well-known and influential Theosophist (and future President of the Society) had also developed an interest in this area of Theosophy. In the decades of the 1890s and 1900s, along with Leadbeater (who became a close associate) and others, she became progressively convinced that the \"next impulse\" from the Hierarchy would happen sooner than Blavatsky's timetable. These Theosophists came to believe it would involve the imminent reappearance of Maitreya as World Teacher, a monumental event in the Theosophical scheme of things. Besant had started commenting on the possible imminent arrival of the next \"emissary\" in 1896, several years before her assumption of the Society's presidency in 1907. By 1909 the \"coming\" Teacher was a main topic of her lectures and writings.\n\nAfter Besant became President of the Society the belief in Maitreya's imminent manifestation took on considerable weight. The subject was widely discussed and became a commonly held expectation among Theosophists. However, not all Theosophical Society members accepted Leadbeater's and Besant's ideas on this; the dissidents charged them with straying from Theosophical orthodoxy and, along with other concepts developed by the two, Leadbeater's and Besant's writings on the Maitreya were derisively labeled \"Neo-Theosophy\" by their opponents. The Adyar (India)-based international leadership of the Society eventually overcame the protests and by the late-1920s the organization had stabilized, but in the meantime additional World Teacher-related trouble was brewing.\n\nIn 1909 Leadbeater encountered fourteen-year-old Jiddu Krishnamurti (1895–1986) near the Theosophical Society headquarters at Adyar, and came to believe the boy was a suitable candidate for the \"vehicle\" of the expected World Teacher. Soon after, Leadbeater placed Krishnamurti under his and the Society's wing. In late 1909 Besant, by then President of the Society and head of its Esoteric Section, admitted Krishnamurti into both; in March 1910 she became his legal guardian. Krishnamurti was subsequently groomed extensively for his expected role as the future World Teacher, and a new organization, the Order of the Star in the East, was formed in 1911 to support him in this mission. The project received widespread publicity and enjoyed worldwide following, chiefly among Theosophists. However it also encountered opposition within and without the Theosophical Society, and led to years of upheaval, serious splits within the Society, and doctrinal schisms in Theosophy. The German branch of Theosophy led by Rudolf Steiner seceded from the movement and became the Anthroposophical Society. Additional negative repercussions occurred in 1929, when Krishnamurti repudiated the role the Theosophists expected him to fulfill, and completely disassociated himself from the \"World Teacher Project\"; soon after he severed ties with the Society and Theosophy in general. These events reputedly prompted Leadbeater to declare, \"the Coming [of the Maitreya] has gone wrong\", and damaged Theosophical organizations and the overall standing of Theosophy.\n\nFollowing the Krishnamurti debacle, major Theosophical organizations and writers became increasingly muted, at least publicly, on the subject of the reappearance of Maitreya and on the possible next \"impulse\" from the Spiritual Hierarchy. However the concepts of World Teacher, of a hidden Spiritual Hierarchy, and of Masters of Occult Wisdom as described in Theosophical literature, continued to have vocal supporters. These were found among Theosophical Society members and increasingly, among near-theosophical and non-theosophical New Age adherents.\n\nA major proponent was Alice Bailey (1880–1949), who left the Theosophical Society in the 1920s to establish the quasi-theosophical \"Arcane School\". She expanded Leadbeater's work and his Christology, and referred to Maitreya as the \"Cosmic Christ\", claiming his Second Coming would occur sometime after the year 2025.\n\nThe Theosophical Maitreya also holds a prominent position in the so-called \"Ascended Master Teachings\". These encompass original Theosophical literature, as well as later additions and interpretations by various non-Theosophical commentators and groups – such as the I AM Activity, and Elizabeth Clare Prophet (1939–2009); however, the validity of this later commentary has been disputed by Theosophical writers.\n\nBenjamin Creme (1922-2016), a follower of Alice Bailey and founder of Share International, an organization whose doctrines have similarities with those of mainstream Theosophy, is a later promoter of the Maitreya. In 1975 Creme claimed to have started to telepathically channel the Maitreya. Creme stated that Maitreya communicated to him that he had decided to return to Earth earlier than 2025. Other claimed communications from the Maitreya followed, and Creme eventually announced that Maitreya materialized a physical body for himself in early 1977 in the Himalayas and then moved to London. Creme has made a number of extraordinary statements and predictions based on reputed telepathic messages from the Maitreya that have failed to come true; as a result he has been considered a figure of amusement in the press.\n\n\n"}
{"id": "27940157", "url": "https://en.wikipedia.org/wiki?curid=27940157", "title": "Marginal factor cost", "text": "Marginal factor cost\n\nIn microeconomics, the marginal factor cost (MFC) is the increment to total costs paid for a factor of production resulting from a one-unit increase in the amount of the factor employed. It is expressed in currency units per incremental unit of a factor of production (input), such as labor, per unit of time. In the case of the labor input, for example, if the wage rate paid is unaffected by the number of units of labor hired, the marginal factor cost is identical to the wage rate. However, if hiring another unit of labor drives up the wage rate that must be paid to all existing units of labor employed, then the marginal cost of the labor factor is higher than the wage rate paid to the last unit because it also includes the increment to the rates paid to the other units.\n\nThus for any factor the MFC is the change in total amount paid for all units of that factor divided by the change in the quantity of that factor employed.\n\nA firm that wants to optimize its profits hires each factor up to the point at which its marginal factor cost equals its marginal revenue product (MFC=MRP).\n"}
{"id": "201112", "url": "https://en.wikipedia.org/wiki?curid=201112", "title": "Mario Bunge", "text": "Mario Bunge\n\nMario Augusto Bunge (; ; born September 21, 1919) is an Argentine philosopher, philosopher of science and physicist who is mainly active in Canada.\n\nBunge was born on September 21, 1919 in Buenos Aires (Argentina). His mother, Marie Müser, was a German nurse who left Germany just before the beginning of World War I. His father, Augusto Bunge, also of some German descent, was an Argentinian physician and socialist legislator. Mario, who was the couple's only child, was raised without any religious education, and enjoyed a happy and stimulating childhood in the outskirts of Buenos Aires.\n\nBunge has four children: Carlos F. and Mario A. J. (with ex-wife Julia), and Eric R. and Silvia A., with his present wife, the Argentinian mathematician Marta Cavallo.\nMario and Marta live in Montreal.\n\nBunge began his studies at the National University of La Plata, graduating with a Ph.D. in physico-mathematical sciences in 1952. He was professor of theoretical physics and philosophy, 1956–1966, first at La Plata then at University of Buenos Aires. He was, until his recent retirement at age 90, the Frothingham Professor of Logic and Metaphysics at McGill University in Montreal, where he had been since 1966.\n\nBunge's students include Roger Angel, David Blitz, Mike Dillinger, Andrés Kálnay, Jean-Pierre Marquis, Dan A. Seni, Héctor Vucetich, and Miguel A. Quintanilla.\n\nBunge is a prolific intellectual, having written more than 400 papers and 80 books, notably his monumental \"Treatise on Basic Philosophy\" in 8 volumes (1974–1989), a comprehensive and rigorous study of those philosophical aspects Bunge takes to be the core of modern philosophy: semantics, ontology, epistemology, philosophy of science and ethics. Here, Bunge develops a comprehensive scientific outlook which he then applies to the various natural and social sciences.\n\nHis thinking embodies global systemism, emergentism, rationalism, scientific realism, materialism and consequentialism. Bunge has repeatedly and explicitly denied being a logical positivist, and has written on metaphysics. In the political arena, Bunge has defined himself as a \"left-wing liberal\" and democratic socialist, in the tradition of John Stuart Mill and José Ingenieros. He is also a supporter of the Campaign for the Establishment of a United Nations Parliamentary Assembly, an organisation which advocates for democratic reform in the United Nations, and the creation of a more accountable international political system.\n\nPopularly, he is known for his remarks considering psychoanalysis as an example of pseudoscience. He has also freely criticized the ideas of well known scientists and philosophers such as Karl Popper, Richard Dawkins, Stephen Jay Gould, and Daniel Dennett.\n\nIn his review of \"Between Two Worlds: Memoirs of a Philosopher-Scientist\", James Alcock sees in Bunge \"a man of exceedingly high confidence who has lived his life guided by strong principles about truth, science, and justice\" and one who is \"[impatient] with muddy thinking\".\n\nMario Bunge has been distinguished with twenty one honorary doctorates and four honorary professorships by universities from both the Americas and Europe. Bunge is a fellow of the American Association for the Advancement of Science (1984–) and of the Royal Society of Canada (1992–). In 1982 he was awarded the \"Premio Príncipe de Asturias\" (Prince of Asturias Award), in 2009 the Guggenheim Fellowship, and in 2014 the Ludwig von Bertalanffy Award in Complexity Thinking.\n\n\n\n\n"}
{"id": "11164833", "url": "https://en.wikipedia.org/wiki?curid=11164833", "title": "Mike Rice Jr.", "text": "Mike Rice Jr.\n\nMichael Thomas Rice Jr. (born February 13, 1969) is an American college basketball coach, formerly the head men's basketball coach at Robert Morris University and later Rutgers University. He is the son of former college basketball coach and Portland Trail Blazers announcer Mike Rice. In 2009, he helped lead Robert Morris to its first NCAA Tournament since 1992. Rice gained national attention in 2013, when ESPN aired Rutgers practice videos showing the coach verbally and physically abusing players. Rice was fired the next day. He resides in Little Silver, New Jersey.\n\nRice was born in Pittsburgh, Pennsylvania, to Kathy and Mike Rice. He attended Boardman High School in Boardman, Ohio where he was a three year starter as a basketball guard. He was a three-year starter for the Fordham University basketball team from 1988 to 1991 and was captain of the team his senior year when Fordham went to the National Invitation Tournament. He received a bachelor's degree in communication. After graduation he was an assistant coach at several programs including Fordham 1991–1994; Marquette University 1994–1997; Niagara University 1997–1998; Chicago State University 1998–2001; St. Joseph's University 2004–2006; and University of Pittsburgh 2006–2007. In addition he was associated with the Hoop Group in Neptune, New Jersey from 2001 to 2004 where he was director of the Eastern Invitational Basketball Camp.\n\nIn 2007, he became head coach at Robert Morris University, and in 2010 he became head coach of Rutgers University.\n\nOn December 13, 2012, Rice was suspended three games without pay and fined $50,000 for abusive behavior toward his players. The suspension came after athletic director Tim Pernetti obtained video footage from a practice during either Rice's first or second season at Rutgers, at which Rice was seen throwing basketballs at players' heads and cursing at them. Assistant coach David Cox led the team during Rice's suspension. As part of the suspension, Rice was not only banned from any contact with his players or going on recruiting visits, but was banned from coming onto campus altogether. Pernetti characterized the suspension as \"a complete removal from the program,\" but stated that Rice would return to Rutgers for the 2013-14 season pending a review of his behavior.\n\nThe situation changed dramatically on April 2, 2013, when ESPN's \"Outside the Lines\" aired several hours of video from Rice's practices. According to ESPN, the video, provided to Pernetti by then-assistant coach Eric Murdock, showed Rice berating, pushing, kicking, cursing, using homophobic slurs, and throwing basketballs at players during practices. Murdock said that he first told Pernetti about the abuse in the summer of 2012, but Pernetti took no action until he and other Rutgers officials saw the video in December. Murdock claims he was fired in July for reporting the abuse, and sued Rutgers for wrongful termination. An independent investigation found that there was insufficient evidence to support Murdock's claims that Rice created a hostile work environment. It also found the video was not in context, since it depicted practices from Rice's first year at Rutgers. However, it did find that Rice's actions brought \"shame and disgrace\" to Rutgers–on paper, grounds to fire Rice for cause regardless of the merits of Murdock's claims. Pernetti later said that his gut feeling had been to fire Rice on the spot, but ultimately concluded that Rutgers policy would not justify a firing.\n\nThe video touched off a nationwide outcry, with New Jersey Governor Chris Christie condemning Rice's behavior, and State Assembly Speaker Sheila Oliver among many demanding that Rice be fired. The next day, Rutgers fired Rice as head coach. According to \"The (Newark) Star-Ledger\", the move came after school president Robert Barchi saw the video for the first time, although he had signed off on Pernetti's decision to suspend Rice in December. When Barchi saw the video, he called in Pernetti and told him that Rice had to leave immediately. Barchi held Pernetti responsible for the debacle, and forced Pernetti's resignation two days later.\n\nIn a post-mortem of the circumstances leading to Rice's firing, \"The New York Times\" reported that Rutgers officials were so focused on whether Rice created a hostile work environment for his assistants that they ignored \"the larger question\" of whether Rice's behavior toward his players in and of itself demanded his firing.\n"}
{"id": "49062", "url": "https://en.wikipedia.org/wiki?curid=49062", "title": "Moral absolutism", "text": "Moral absolutism\n\nMoral absolutism is an ethical view that all actions are intrinsically right or wrong. Stealing, for instance, might be considered to be always immoral, even if done for the well-being of others (e.g., stealing food to feed a starving family), and even if it does in the end promote such a good. Moral absolutism stands in contrast to other categories of normative ethical theories such as consequentialism, which holds that the morality (in the wide sense) of an act depends on the consequences or the context of the act.\n\nMoral absolutism is not the same as moral universalism. Universalism holds merely that what is right or wrong is independent of custom or opinion (as opposed to moral relativism), but not necessarily that what is right or wrong is independent of context or consequences (as in absolutism). Moral universalism is compatible with moral absolutism, but also positions such as consequentialism. Louis Pojman gives the following definitions to distinguish the two positions of moral absolutism and universalism:\n\nEthical theories which place strong emphasis on rights and duty, such as the deontological ethics of Immanuel Kant, are often forms of moral absolutism, as are many religious moral codes.\n\nMoral absolutism may be understood in a strictly secular context, as in many forms of deontological moral rationalism. However, many religions have morally absolutist positions as well, regarding their system of morality as deriving from divine commands. Therefore, they regard such a moral system as absolute, (usually) perfect, and unchangeable. Many secular philosophies also take a morally absolutist stance, arguing that absolute laws of morality are inherent in the nature of human beings, the nature of life in general, or the universe itself. For example, someone who believes absolutely in nonviolence considers it wrong to use violence even in self-defense.\n\nCatholic philosopher Thomas Aquinas never explicitly addresses the Euthyphro dilemma, but draws a distinction between what is good or evil in itself and what is good or evil because of God's commands, with unchangeable moral standards forming the bulk of natural law. Thus he contends that not even God can change the Ten Commandments, adding, however, that God \"can\" change what individuals deserve in particular cases, in what might look like special dispensations to murder or steal.\n"}
{"id": "474299", "url": "https://en.wikipedia.org/wiki?curid=474299", "title": "Moral hierarchy", "text": "Moral hierarchy\n\nA moral hierarchy is a hierarchy by which actions are ranked by their morality, with respect to a moral code. \n\nIt also refers to a relationship – such as teacher/pupil or guru/disciple – in which one party is taken to have greater moral awareness than the other; or to the beneficial hierarchy of parent/child or doctor/patient.\n\nKohlberg's stages of moral development have been read as creating a hierarchy of increasing moral complexity, ranging from the premoral at the bottom, through the midrange of conventionalism, up to the apex of self-selected morality.\n\nIn similar fashion, Robin Skynner viewed moral ideas (such as the 'myths' of Charis Katakis) as being interpretable at different levels, depending on the degree of mental health attained; while Eric Berne saw the three ego states of Parent/Adult/Child as falling naturally into a moral hierarchy universally respected in both time and place.\n\nDante's universe was structured in a hierarchy of moral sins and moral virtues, the stratified circles of Hell reaching down for example from the self-indulgent sins at the higher levels, to those of violence below, and the fraudulent at the bottom.\n\nThe Confucian concept of a moral hierarchy traditionally served as a check on arbitrary power in China.\n\nArguably at least, the concept of a moral hierarchy still influences China's view of its place in the world today.\n\nCritics charge that the notion of a moral hierarchy is untenable in cases spanning multiple cultures, because moral codes are not equal but different, and therefore there is no way of showing that certain codes are superior to others.\n\nProponents of Kohlberg argue against such a relativistic view of morality, however, by pointing to cross-cultural evidence from more than 30 societies supporting the concept of a hierarchy of levels of moral complexity.\n"}
{"id": "22140979", "url": "https://en.wikipedia.org/wiki?curid=22140979", "title": "Nonkilling", "text": "Nonkilling\n\nNonkilling refers to the absence of killing, threats to kill, and conditions conducive to killing in human society. Even though the use of the term in the academic world refers mostly to the killing of human beings, it is sometimes extended to include the killing of animals and other forms of life. This is also the case for the traditional use of the term \"nonkilling\" (or \"non-killing\") as part of Buddhist ethics, as expressed in the first precept of the Pancasila, and in similar terms throughout world spiritual traditions. (See ). Significantly, \"nonkilling\" has also been used recently in the \"Charter for a World without Violence\" approved by the 8th World Summit of Nobel Peace Laureates.\n\nIn analysis of its causes, nonkilling encompasses the concepts of peace (absence of war and conditions conducive to war), nonviolence (psychological, physical, and structural), and ahimsa (noninjury in thought, word and deed). Not excluding any of the latter, nonkilling provides a distinct approach characterized by the measurability of its goals and the open-ended nature of its realization. While the usage of terms such as \"nonviolence\" and \"peace\" often follow the classical form of argument through abstract ideas leading to passivity, killing (and its opposite, nonkilling), it can be quantified and related to specific causes by following a public health perspective (prevention, intervention and post-traumatic transformation toward the progressive eradication of killing).\n\nOn the other hand, nonkilling does not set any predetermined path for the achievement of a killing-free society in the same way as some ideologies and spiritual traditions that foster the restraint from the taking of life do. As an open-ended approach it appeals to infinite human creativity and variability, encouraging continuous explorations in the fields of education, research, social action and policy making, by developing a broad range of scientific, institutional, educational, political, economic and spiritual alternatives to human killing. Also, in spite of its specific focus, nonkilling also tackles broader social issues.\n\nIn relation to psychological aggression, physical assault, and torture intended to terrorize by manifest or latent threat to life, nonkilling implies removal of their psychosocial causes. In relation to killing of humans by socioeconomic structural conditions that are the product of direct lethal reinforcement as well as the result of diversion of resources for purposes of killing, nonkilling implies removal of lethality-linked deprivations. In relation to threats to the viability of the biosphere, nonkilling implies absence of direct attacks upon life-sustaining resources as well as cessation of indirect degradation associated with lethality. In relation to forms of accidental killing, nonkilling implies creation of social and technological conditions conducive to their elimination.\n\nIn a broad conception, nonkilling opposes aggression, assassination, autogenocide, contract killing, corporate manslaughter, cultural genocide, capital punishment, democide, domestic killings, ethnic cleansing, ethnocide, femicide, feticide, gendercide, genocide, honor killing, ritual killings, infanticide, linguicide, mass murder, murder–suicide, omnicide, policide, politicide, regicide, school shootings, structural violence, suicide, terrorism, thrill killing, tyrannicide, violence, war, and other forms of killing, direct, indirect or structural.\n\nIn his book \"Nonkilling Global Political Science\", Glenn D. Paige estimated that less than 0.5 percent of all humans that ever existed actually killed other humans. Also, anthropological evidence points out that in certain societies and cultures killing is down to statistically insignificant levels. As humans lived exclusively as hunter-gatherers — a form of existence that epitomizes the attributes of a nonkilling society — for 99 percent of their existence, it is also apparent that levels of violence and killing have also been very low during most of the history of \"Homo sapiens sapiens\".\n\n\n"}
{"id": "1586691", "url": "https://en.wikipedia.org/wiki?curid=1586691", "title": "Pain and pleasure", "text": "Pain and pleasure\n\nSome philosophers, such as Jeremy Bentham, Baruch Spinoza, and Descartes, have hypothesized that the feelings of pain (or suffering) and pleasure are part of a continuum.\n\nThere is strong evidence of biological connections between the neurochemical pathways used for the perception of both pain and pleasure, as well as other psychological rewards.\n\nFrom a stimulus-response perspective, the perception of physical pain starts with the nociceptors, a type of physiological receptor that transmits neural signals to the brain when activated. These receptors are commonly found in the skin, membranes, deep fascias, mucosa, connective tissues of visceral organs, ligaments and articular capsules, muscles, tendons, periosteum, and arterial vessels. Once stimuli are received, the various afferent action potentials are triggered and pass along various fibers and axons of these nociceptive nerve cells into the dorsal horn of the spinal cord through the dorsal roots. A neuroanatomical review of the pain pathway, \"Afferent pain pathways\" by Almeida, describes various specific nociceptive pathways of the spinal cord: spinothalamic tract, spinoreticular tract, spinomesencephalic tract, spinoparabrachial tract, spinohypothalamic tract, spinocervical tract, postsynaptic pathway of the spinal column.\n\nActivity in many parts of the brain is associated with pain perception. Some of the known parts for the ascending pathway include the thalamus, hypothalamus, midbrain, lentiform nucleus, somatosensory cortices, insular, prefrontal, anterior and parietal cingulum. Then, there are also the descending pathways for the modulation of pain sensation. One of the brainstem regions responsible for this is the periaqueductal gray of the midbrain, which both relieves pain by behavior as well as inhibits the activity of the nociceptive neurons in the dorsal horn of the spinal cord. Other brainstem sites, such as the parabrachial nucleus, the dorsal raphe, locus coeruleus, and the medullary reticular formation also mediate pain relief and use many different neurotransmitters to either facilitate or inhibit activity of the neurons in the dorsal horn. These neurotransmitters include noradrenaline, serotonin, dopamine, histamine, and acetylcholine.\n\nPleasure can be considered from many different perspectives, from physiological (such as the hedonic hotspots that are activated during the experience) to psychological (such as the study of behavioral responses towards reward). Pleasure has also often been compared to, or even defined by many neuroscientists as, a form of alleviation of pain.\n\nPleasure has been studied in the systems of taste, olfaction, auditory (musical), visual (art), and sexual activity. Well known hedonic hotspots involved in the processing of pleasure include the nucleus accumbens, posterior ventral pallidum, amygdala, other cortical and subcortical regions. \nThe prefrontal and limbic regions of the neocortex, particularly the orbitofrontal region of the prefrontal cortex, anterior cingulate cortex, and the insular cortex have all been suggested to be pleasure causing substrates in the brain.\n\nOne approach to evaluating the relationship between pain and pleasure is to consider these two systems as a reward-punishment based system. When pleasure is perceived, one associates it with reward. When pain is perceived, one associates with punishment. Evolutionarily, this makes sense, because often, actions that result in pleasure or chemicals that induce pleasure work towards restoring homeostasis in the body. For example, when the body is hungry, the pleasure of rewarding food to one-self restores the body back to a balanced state of replenished energy. Like so, this can also be applied to pain, because the ability to perceive pain enhances both avoidance and defensive mechanisms that were, and still are, necessary for survival.\n\nThe neural systems to be explored when trying to look for a neurochemical relationship between pain and pleasure are the opioid and dopamine systems. The opioid system is responsible for the actual experience of the sensation, whereas the dopamine system is responsible for the anticipation or expectation of the experience. Opioids work in the modulation of pleasure or pain relief by either blocking neurotransmitter release or by hyperpolarizing neurons by opening up a potassium channel which effectively temporarily blocks the neuron.\n\nIt has been suggested as early as 4th century BC that pain and pleasure occurs on a continuum. Aristotle claims this antagonistic relationship in his \"Rhetoric\":\n\nHe describes pain and pleasure very much like a push-pull concept; human beings will move towards something that causes pleasure and will move away from something that causes pain.\n\nOn an anatomical level, it can be shown the source for the modulation of both pain and pleasure originates from neurons in the same locations, including the amygdala, the pallidum, and the nucleus accumbens. Not only have Leknes and Tracey, two leading neuroscientists in the study of pain and pleasure, concluded that pain and reward processing involve many of the same regions of the brain, but also that the functional relationship lies in that pain decreases pleasure and rewards increase analgesia, which is the relief from pain.\n\nThomas Szasz, the late Professor of Psychiatry Emeritus at the State University of New York Health Science Center in Syracuse, New York, explored how pain and pleasure are not opposites ends of a spectrum in his 1957 book, \"Pain and Pleasure -a study of bodily feelings\".\n\nSzasz notes that although we often refer to pain and pleasure as opposites in such a way, that this is incorrect; we have receptors for pain, but none in the same way for pleasure; and so it makes sense to ask \"where is the pain?\" but not \"where is the pleasure?\". With this vantage point established, the author delves into the topics of metaphorical pain and of legitimacy, of power relations, and of communications, and of myriad others.\n\nWhether or not pain and pleasure are indeed on a continuum, it still remains scientifically supported that parts of the neural pathways for the two perceptions overlap. There is also scientific evidence that one may have opposing effects on the other. So why would it be evolutionarily advantageous to human beings to develop a relationship between the two perceptions at all?\n\nSouth African neuroscientists presented evidence that there was a physiological link on a continuum between pain and pleasure in 1980. First, the Neuroscientists, Gillman and Lichtigfeld demonstrated that there were two endogenous endorphin systems, one pain producing and the other pain relieving. A short time later they showed that these two systems might also be involved in addiction, which is initially pursued, presumably for the pleasure generating or pain relieving actions of the addictive substance. Soon after they provided evidence that the endorphins system was involved in sexual pleasure.\n\nDr. Kringelbach suggests that this relationship between pain and pleasure would be evolutionarily efficient, because it was necessary to know whether or not to avoid or approach something for survival. According to Dr. Norman Doidge, the brain is limited in the sense that it tends to focus on the most used pathways. Therefore, having a common pathway for pain and pleasure could have simplified the way in which human beings have interacted with the environment (Dr. Morten Kringelbach, personal communication, October 24, 2011).\n\nLeknes and Tracey offer two theoretical perspectives to why a relationship could be evolutionarily advantageous.\n\nThe opponent-process theory is a model that views two components as being pairs that are opposite to each other, such that if one component is experienced, the other component will be repressed. Therefore, an increase in pain should bring about a decrease in pleasure, and a decrease in pain should bring about an increase in pleasure or pain relief. This simple model serves the purpose of explaining the evolutionarily significant role of homeostasis in this relationship. This is evident since both seeking pleasure and avoiding pain are important for survival. Leknes and Tracey provide an example:\n\nThey then suggest that perhaps a common currency for which human beings determine the importance of the motivation for each perception can allow them to be weighed against each other in order to make a decision best for survival.\n\nThe Motivation-Decision Model, suggested by Fields, is centered around the concept that decision processes are driven by motivations of highest priority. The model predicts that in the case that there is anything more important than pain for survival will cause the human body to mediate pain by activating the descending pain modulation system described earlier. Thus, it is suggested that human beings have developed the unconscious ability to endure pain or sometimes, even relieve pain if it can be more important for survival to gain a larger reward. It may have been more advantageous to link the pain and pleasure perceptions together to be able to reduce pain to gain a reward necessary for fitness, such as childbirth. Like the opponent-process theory, if the body can induce pleasure or pain relief to decrease the effect of pain, it would allow human beings to be able to make the best evolutionary decisions for survival.\n\nThe following neurological and/or mental diseases have been linked to forms of pain or anhedonia: schizophrenia, depression, addiction, cluster headache, chronic pain.\n\nA great deal of what is known about pain and pleasure today primarily comes from studies conducted with rats and primates.\n\nDeep brain stimulation involves the electrical stimulation of deep brain structures by electrodes implanted into the brain. The effects of this neurosurgery has been studied in patients with Parkinson's disease, tremors, dystonia, epilepsy, depression, obsessive-compulsive disorder, Tourette's syndrome, cluster headache and chronic pain. A fine electrode is inserted into the targeted area of the brain and secured to the skull. This is attached to a pulse generator which is implanted elsewhere on the body under the skin. The surgeon then turns the frequency of the electrode to the voltage and frequency desired. Deep brain stimulation has been shown in several studies to both induce pleasure or even addiction as well as ameliorate pain. For chronic pain, lower frequencies (about 5–50 Hz) have produced analgesic effects, whereas higher frequencies (about 120–180 Hz) have alleviated or stopped pyramidal tremors in Parkinson's patients.\n\nThere is still further research necessary into how and why exactly DBS works. However, by understanding the relationship between pleasure and pain, procedures like these can be used to treat patients suffering from a high intensity or longevity of pain. So far, DBS has been recognized as a treatment for Parkinson's disease, tremors, and dystonia by the Food and Drug Administration (FDA).\n\n\n\n"}
{"id": "3114567", "url": "https://en.wikipedia.org/wiki?curid=3114567", "title": "Periodic Report of the United States of America to the United Nations Committee Against Torture", "text": "Periodic Report of the United States of America to the United Nations Committee Against Torture\n\nThe Periodic Report of the United States of America to the United Nations Committee Against Torture is periodically submitted by the United States government, through the State Department, to the United Nations Committee Against Torture. In October 2005, the report focused on the detention of suspects in the War on Terror, including those held in Guantánamo Bay. This particular Periodic Report is significant as the first official response of the U.S. government to allegations that prisoners are mistreated in Guantánamo Bay and in Afghanistan. The report denies those allegations. The report does not address detainees held by the Central Intelligence Agency.\n\nThe original text for the report is available:\n\n"}
{"id": "9023420", "url": "https://en.wikipedia.org/wiki?curid=9023420", "title": "Platonia (philosophy)", "text": "Platonia (philosophy)\n\nIn Julian Barbour's book \"\", Platonia is the name given to his hypothetic entity of a timeless realm containing every possible \"Now\" or momentary configuration of the universe.\n\nThe term can also be applied more generally to the \"world of Forms\" or \"Plato's heaven\" in Platonic metaphysics, and to the \"ultimate ensemble\" in Max Tegmark's variation of multiverse theory.\n\n\n"}
{"id": "29420095", "url": "https://en.wikipedia.org/wiki?curid=29420095", "title": "Potential person", "text": "Potential person\n\nIn philosophy and bioethics, potential (future) person (in plural, sometimes termed potential people) has been defined as an entity which is not currently a person but which is capable of developing into a person, given certain biologically and/or technically possible conditions. The term unconceived has also been used in a similar sense, but does not necessarily include the capability of being conceived or developing into a person.\n\nIn 1977, Canadian Philosopher Mary Anne Warren discussed various definitions for \"potential people\". Most simply, a \"potential person\" could be defined as the currently existing genetic material that will constitute them, such as a sexually viable egg and sperm cell taken together, also when still being located in separate places. Potential people may also be defined from reproductive capability, which also includes the presence of other necessary factors for becoming a person, such as the availability of a womb to grow in, the will and means of parents to conceive, or even the care after birth to raise the individual into a complete sentient being. Thus the progression towards existence of a potential person usually lies mainly in the maturation of previous people to develop the will and ability to become potential parents. \n\nIn this sense, destroying sperm cells, for instance, does not significantly reduce the number of potential persons, because, provided the will and other means to conceive a person remains the same, there is still the possibility to extract the genetic information from remaining sperm cells or, theoretically, even from somatic cells such as skin cells (by somatic cell nuclear transfer). Actually, in this sense, for a man that intends to conceive only two children, the billions on sperm cells he produces throughout his lifetime may, taken together, still only be regarded as a contributing factor to a maximum of two potential persons. \n\nIf including the will to conceive as a necessary component of a potential person, the mere certain decision of a woman to not let an embryo grow inside her uterus may be regarded as sufficient to disqualify that embryo as a potential person, because a will that is strong enough would make that woman turn to even unsafe abortion, and a certain future abortion makes it certain that there won't be a necessary uterus for the embryo to grow inside to become a person. \n\nStrangely, in such a view, an act of a woman in changing her mind from abortion to proceeding with the pregnancy may be regarded as creating a potential person rather than saving the life of one, but other views may be applied once the beginning of actual human personhood has been reached. When taking this view to a larger scale, a population that is very intent on reproducing can be expected to constitute a larger number of potential persons than a population refusing to reproduce, all other factors being equal. When there is only one or a few factors absent to constitute a potential person, that entity may still be termed \"a potential person except for...\", but the ensuing arguments from this may differ.\n\nThe people of the twenty-fifth century have been taken as an example of potential persons, because, although their particular gametes or embryos do not currently exist, there is reproductive capability of the currently living people and resources to make the future existence of those people possible. The mere likelihood of future existence is usually regarded as sufficient to apply the term, as there is a risk that, for example, the people of the twenty-fifth century will never exist because of an event of human extinction. \n\nThe beginning of human personhood, where a potential person is instead regarded as a proper person, is a concept currently debated by religion and philosophy. However, there could theoretically be no beginning of \"potential\" human personhood because it is dependent on the reproductive capability of the previous generation, which, in turn, is dependent on the reproductive capability of the generation before that etc. etc.\n\nIt has been argued that the mere potential of becoming a person confers moral rights on a prima facie basis, or by holding that they are really in some sense actuals. On the other hand, there is the opinion that the potential itself is not of significance.\n\nAmong views that reject a prima facie right to potential people, there are, on one hand, claims that potential people are non-actuals and cannot be either benefited or harmed. Also, there are views that, although a potential person has no value in the present, the rightfulness of actions that we make today are still dependent on how they will affect such people in the future, and that we have moral obligations for future generations. An argument for such a view is in finding it logical that the value of an action can be seen as equivalent to the total instrumental value at any time of the chain of events that that action started, which in turn can be seen as equivalent to the total intrinsic value of whatever ends-in-themselves are generated or benefited at the end of that chain of events. For example, a remote friend has a baby, and is about to conceive another, and, for example, happiness is taken as the end-in-itself and receiving a toy is taken as an instrument to it, then, the yet unconceived baby may not be regarded as currently having ethic value, in contrast to the existing baby, but nevertheless, the instrumental value in the action of posting a toy to either of them can be regarded as equivalent, because either alternative would generate equal amount of intrinsic value in the form of happiness in the future, with some modification for, for example, the risk of failing to conceive again, and the burden for the post office or parent in storing the toy until, at least, birth. In such a view, it is uncertain to which extent a lesser probability of becoming a person affects the moral value of that potential person, putting uncertainty to claiming, for example, that a potential person with 50% probability of becoming a person should be treated as having 50% the value of an actual person.\n\nEven among views that the rightfulness of current actions depend on how they will affect yet non-existent people, there may still be differences regarding the justification of bringing people into existence in the first place, or the prevention of it.\n\nA major factor in this issue is whether ends-in-themselves are generally regarded to optimally be maximized or minimized on a total basis or as an average among the people (such as, for example, total versus average utilitarism). A view that favors maximizing an end-in-itself on a total basis may consider it beneficial to have more people brought into existence by the motivation that there are more people to generate it. On the other hand, a view that favors maximizing an end-in-itself on an average basis has suggested that the benefit or harm in an action that supports or prevents bringing a potential person into existence depends on whether that person, on average, will constitute or generate more or less end-in-itself than the average. For example, if happiness is regarded as the end-in-itself, then, it has been claimed to be morally objectionable to bring a potential person into existence that is predicted to be very unhappy.\n\nAnother factor that has been suggested is the possible positive or negative value of nonexistence, which can be regarded as weighting against or adding to the values of existence when considering the rightfulness of bringing potential people into existence. \n\nThe personal opinion on the value of bringing potential people into existence may be a major factor in many issues, including:\n\nFrom a view that favors the act of bringing people into existence, it has been argued that avoidance from conceiving a child when there are prerequisites for raising it is comparable to causing the death of one. Also, it has been argued that contraception, and even the decision not to procreate at all could be regarded as immoral on a similar basis as abortion. However, holding value in potential persons does not necessarily decrease support for abortion rights. It has been regarded as justified to induce abortion of a severely disabled fetus in favor for conceiving a new child. However, a major reason that has been given to be cautious about performing abortion with such motivation is the fact that the likelihood of successfully bringing the new child into existence is substantially lower, as the parents may separate, one of them may become sterile, or they may change their minds about having children. A comparable situation is the abortion of an unintended pregnancy in favor for conceiving a new child later in better conditions.\n\n"}
{"id": "147885", "url": "https://en.wikipedia.org/wiki?curid=147885", "title": "Power (social and political)", "text": "Power (social and political)\n\nIn social science and politics, power is the ability to influence or outright control the behaviour of people. The term \"authority\" is often used for power perceived as legitimate by the social structure. Power can be seen as evil or unjust, this sort of primitive exercise of power is historically endemic to humans, however as social beings the same concept is seen as good and as something inherited or given for exercising humanistic objectives that will help, enable and move people. In general, it is derived by the factors of interdependence between two entities and the environment. In business, the ethical instrumentality of power is achievement, and as such it is a zero-sum game. In simple terms it can be expressed as being \"upward\" or \"downward\". With downward power, a company's superior influences subordinates for attaining organizational goals. When a company exerts upward power, it is the subordinates who influence the decisions of their leader or leaders.\n\nThe use of power need not involve force or the threat of force (coercion). On one side, it closely resembles what egalitarian and consensual nations (Denmark, Netherlands, Norway, Sweden) might term as \"influence,\" contrasted with the extreme what some authors identify as \"intimidation\" in capitalist nations, a means by which power is used. An example of using power without oppression is the concept \"soft power,\" as compared to hard power.\n\nMuch of the recent sociological debate about power revolves around the issue of its means to enablein other words, power as a means to make social actions possible as much as it may constrain or prevent them. The philosopher Michel Foucault saw power as a structural expression of \"a complex strategic situation in a given social setting\" that requires both constraint and enablement.\n\nSocial psychologists John R. P. French and Bertram Raven, in a now-classic study (1959), developed a schema of sources of power by which to analyse how power plays work (or fail to work) in a specific relationship.\n\nAccording to French and Raven, power must be distinguished from influence in the following way: power is that state of affairs which holds in a given relationship, A-B, such that a given influence attempt by A over B makes A's desired change in B more likely. Conceived this way, power is fundamentally \"relative\" – it depends on the specific understandings A and B each apply to their relationship, and requires B's recognition of a quality in A which would motivate B to change in the way A intends. A must draw on the 'base' or combination of bases of power appropriate to the relationship, to effect the desired outcome. Drawing on the wrong power base can have unintended effects, including a reduction in A's own power.\n\nFrench and Raven argue that there are five significant categories of such qualities, while not excluding other minor categories. Further bases have since been adduced – in particular by Gareth Morgan in his 1986 book, \"Images of Organization\".\n\nAlso called \"positional power,\" it is the power of an individual because of the relative position and duties of the holder of the position within an organization. Legitimate power is formal authority delegated to the holder of the position. It is usually accompanied by various attributes of power such as a uniform, a title, or an imposing physical office.\n\nReferent power is the power or ability of individuals to attract others and build loyalty. It is based on the charisma and interpersonal skills of the power holder. A person may be admired because of specific personal trait, and this admiration creates the opportunity for interpersonal influence. Here the person under power desires to identify with these personal qualities, and gains satisfaction from being an accepted follower. Nationalism and patriotism count towards an intangible sort of referent power. For example, soldiers fight in wars to defend the honor of the country. This is the second least obvious power, but the most effective. Advertisers have long used the referent power of sports figures for products endorsements, for example. The charismatic appeal of the sports star supposedly leads to an acceptance of the endorsement, although the individual may have little real credibility outside the sports arena. Abuse is possible when someone that is likable, yet lacks integrity and honesty, rises to power, placing them in a situation to gain personal advantage at the cost of the group's position. Referent power is unstable alone, and is not enough for a leader who wants longevity and respect. When combined with other sources of power, however, it can help a person achieve great success.\n\nExpert power is an individual's power deriving from the skills or expertise of the person and the organization's needs for those skills and expertise. Unlike the others, this type of power is usually highly specific and limited to the particular area in which the expert is trained and qualified. When they have knowledge and skills that enable them to understand a situation, suggest solutions, use solid judgment, and generally out perform others, then people tend to listen to them. When individuals demonstrate expertise, people tend to trust them and respect what they say. As subject matter experts, their ideas will have more value, and others will look to them for leadership in that area.\n\nReward power depends on the ability of the power wielder to confer valued material rewards, it refers to the degree to which the individual can give others a reward of some kind such as benefits, time off, desired gifts, promotions or increases in pay or responsibility. This power is obvious but also ineffective if abused. People who abuse reward power can become pushy or be reprimanded for being too forthcoming or 'moving things too quickly'. If others expect to be rewarded for doing what someone wants, there's a high probability that they'll do it. The problem with this basis of power is that the rewarder may not have as much control over rewards as may be required. Supervisors rarely have complete control over salary increases, and managers often can't control promotions all by themselves. And even a CEO needs permission from the board of directors for some actions. So when somebody uses up available rewards, or the rewards don't have enough perceived value to others, their power weakens. (One of the frustrations of using rewards is that they often need to be bigger each time if they're to have the same motivational impact. Even then, if rewards are given frequently, people can become satiated by the reward, such that it loses its effectiveness).\n\nCoercive power is the application of negative influences. It includes the ability to demote or to withhold other rewards. The desire for valued rewards or the fear of having them withheld that ensures the obedience of those under power. Coercive power tends to be the most obvious but least effective form of power as it builds resentment and resistance from the people who experience it. Threats and punishment are common tools of coercion. Implying or threatening that someone will be fired, demoted, denied privileges, or given undesirable assignments – these are characteristics of using coercive power. Extensive use of coercive power is rarely appropriate in an organizational setting, and relying on these forms of power alone will result in a very cold, impoverished style of leadership. This is a type of power is commonly seen in fashion industry by coupling with legitimate power, it is referred in the industry specific literature's as \"glamorization of structural domination and exploitation.\"\n\nAccording to Laura K. Guerrero and Peter A. Andersen in \"Close encounters: Communication in Relationships\":\n\nGame theory, with its foundations in the Walrasian theory of rational choice, is increasingly used in various disciplines to help analyze power relationships. One rational choice definition of power is given by Keith Dowding in his book \"Power\".\n\nIn rational choice theory, human individuals or groups can be modelled as 'actors' who choose from a 'choice set' of possible actions in order to try to achieve desired outcomes. An actor's 'incentive structure' comprises (its beliefs about) the costs associated with different actions in the choice set, and the likelihoods that different actions will lead to desired outcomes.\n\nIn this setting we can differentiate between:\n\nThis framework can be used to model a wide range of social interactions where actors have the ability to exert power over others. For example, a 'powerful' actor can take options away from another's choice set; can change the relative costs of actions; can change the likelihood that a given action will lead to a given outcome; or might simply change the other's beliefs about its incentive structure.\n\nAs with other models of power, this framework is neutral as to the use of 'coercion'. For example: a threat of violence can change the likely costs and benefits of different actions; so can a financial penalty in a 'voluntarily agreed' contract, or indeed a friendly offer.\n\nIn the Marxist tradition, the Italian writer Antonio Gramsci elaborated the role of ideology in creating a cultural hegemony, which becomes a means of bolstering the power of capitalism and of the nation-state. Drawing on Niccolò Machiavelli in The Prince, and trying to understand why there had been no Communist revolution in Western Europe, while it was claimed there had been one in Russia, Gramsci conceptualised this hegemony as a centaur, consisting of two halves. The back end, the beast, represented the more classic, material image of power, power through coercion, through brute force, be it physical or economic. But the capitalist hegemony, he argued, depended even more strongly on the front end, the human face, which projected power through 'consent'. In Russia, this power was lacking, allowing for a revolution. However, in Western Europe, specifically in Italy, capitalism had succeeded in exercising \"consensual\" power, convincing the working classes that their interests were the same as those of capitalists. In this way revolution had been avoided.\n\nWhile Gramsci stresses the significance of ideology in power structures, Marxist-feminist writers such as Michele Barrett stress the role of ideologies in extolling the virtues of family life. The classic argument to illustrate this point of view is the use of women as a 'reserve army of labour'. In wartime it is accepted that women perform masculine tasks, while after the war the roles are easily reversed. Therefore, according to Barrett, the destruction of capitalist economic relations is necessary but not sufficient for the liberation of women.\n\nTarnow considers what power hijackers have over air plane passengers and draws similarities with power in the military. He shows that power over an individual can be amplified by the presence of a group. If the group conforms to the leader's commands, the leader's power over an individual is greatly enhanced while if the group does not conform the leader's power over an individual is nil.\n\nFor Michel Foucault, the real power will always rely on the ignorance of its agents. No single human, group nor single actor runs the dispositif (machine or apparatus) but power is dispersed through the apparatus as efficiently and silently as possible, ensuring its agents to do whatever is necessary. It is because of this action that power is unlikely to be detected that it remains elusive to 'rational' investigation. Foucault quotes a text reputedly written by political economist Jean Baptiste Antoine Auget de Montyon, entitled \"Recherches et considérations sur la population de la France\" (1778), but turns out to be written by his secretary Jean-Baptise Moheau (1745–1794) and by emphasizing Biologist Jean-Baptiste Lamarck who constantly refers to Milieus as a plural adjective and sees into the milieu as an expression as nothing more than water air and light confirming the genus within the milieu, in this case the human species, relates to a function of the population and its social and political interaction in which both form an artificial and natural milieu. This milieu(both artificial and natural) appears as a target of intervention for power according to Foucault which is radically different from the previous notions on sovereignty, territory and disciplinary space inter woven into from a social and political relations which function as a species (biological species).\n\nFoucault originated and developed the concept of \"docile bodies\" in his book \"Discipline and Punish.\" He writes, \"A body is docile that may be subjected, used, transformed and improved. \" Foucault claims that there is a shift, during the 18th century, in which political power changed. Instead of using corporeal punishment in order to convince people to adhere to the laws of the day, Foucault says power becomes internalized during this period. Instead of watching someone be drawn and quartered in a public space, political power is exerted on individuals in a way that compels them to obey laws and rules on their own - without this show of force. He builds on the ideas of Jeremy Bentham regarding the Panopticon in which prison inmates are compelled to behave and control themselves because they might be in the view of the prison guard. The physical shape of the Panopticon creates a situation in which the prison guard need not be present for this to happen, because the mere possibility of the presence of the guard compels the prisoners to behave. Foucault takes this theory and makes it generalize to everyday life. He claims that this kind of surveillance is constant in modern society, and the populous at large enacts it. Therefore, everyone begins to control themselves and behave according to society's rules and norms.\n\nFeminist philosophers took up Foucault's ideas regarding docile bodies and applied them to the different ways men and women are socialized to use their bodies. For one example, philosopher Sandra Bartky says in her essay, \"\"Foucault, Femininity, and the Modernization of Patriarchal Power\" that “The disciplinary techniques through which the ‘docile bodies’ of women are constructed aim at a regulation that is perpetual and exhaustive - a regulation of the body’s size and contours, its appetite, posture, gestures and general comportment in space, and the appearance of each of its visible parts.\" Bartky theorizes that there is a specific and relentless pressure on women when it comes to bodily movements and comportment; this \"docility\" manifests as women make themselves smaller, groom themselves in ways that make them appear more feminine, and control their bodily movements in order to be as minimally obtrusive as possible. She also cites diet, exercise, and skin care, among other processes, as sites in which the feminine body is made docile.\n\nStewart Clegg proposes another three-dimensional model with his \"circuits of power\" theory. This model likens the production and organizing of power to an electric circuit board consisting of three distinct interacting circuits: episodic, dispositional, and facilitative. These circuits operate at three levels, two are macro and one is micro. The \"episodic circuit\" is the micro level and is constituted of irregular exercise of power as agents address feelings, communication, conflict, and resistance in day-to-day interrelations. The outcomes of the episodic circuit are both positive and negative. The \"dispositional circuit\" is constituted of macro level rules of practice and socially constructed meanings that inform member relations and legitimate authority. The \"facilitative circuit\" is constituted of macro level technology, environmental contingencies, job design, and networks, which empower or disempower and thus punish or reward, agency in the episodic circuit. All three independent circuits interact at \"obligatory passage points\" which are channels for empowerment or disempowerment.\n\nJK Galbraith summarizes the types of power as being \"condign\" (based on force), \"compensatory\" (through the use of various resources) or \"conditioned\" (the result of persuasion), and their sources as \"personality\" (individuals), \"property\" (their material resources) and \"organizational\" (whoever sits at the top of an organisational power structure).\n\nGene Sharp, an American professor of political science, believes that power depends ultimately on its bases. Thus a political regime maintains power because people accept and obey its dictates, laws and policies. Sharp cites the insight of Étienne de La Boétie.\n\nSharp's key theme is that power is not monolithic; that is, it does not derive from some intrinsic quality of those who are in power. For Sharp, political power, the power of any state – regardless of its particular structural organization – ultimately derives from the subjects of the state. His fundamental belief is that any power structure relies upon the subjects' obedience to the orders of the ruler(s). If subjects do not obey, leaders have no power.\n\nHis work is thought to have been influential in the overthrow of Slobodan Milosevic, in the 2011 Arab Spring, and other nonviolent revolutions.\n\nBjörn Kraus deals with the epistemological perspective upon power regarding the question about possibilities of interpersonal influence by developing a special form of constructivism (named relational constructivism). Instead of focussing on the valuation and distribution of power, he asks first and foremost what the term can describe at all. Coming from Max Weber's definition of power, he realizes that the term of power has to be split into \"instructive power\" and \"destructive power\". More precisely, instructive power means the chance to determine the actions and thoughts of another person, whereas destructive power means the chance to diminish the opportunities of another person. How significant this distinction really is, becomes evident by looking at the possibilities of rejecting power attempts: Rejecting instructive power is possible – rejecting destructive power is not. By using this distinction, proportions of power can be analyzed in a more sophisticated way, helping to sufficiently reflect on matters of responsibility. This perspective permits to get over an \"either-or-position\" (either there is power, or there isn't), which is common especially in epistemological discourses about power theories, and to introduce the possibility of an \"as well as-position\".\n\nThe idea of \"unmarked categories\" originated in feminism. The theory analyzes the culture of the powerful. The powerful comprise those people in society with easy access to resources, those who can exercise power without considering their actions. For the powerful, their culture seems obvious; for the powerless, on the other hand, it remains out of reach, élite and expensive.\n\nThe \"unmarked category\" can form the identifying mark of the powerful. The unmarked category becomes the standard against which to measure everything else. For most Western readers, it is posited that if a protagonist's race is not indicated, it will be assumed by the reader that the protagonist is Caucasian; if a sexual identity is not indicated, it will be assumed by the reader that the protagonist is heterosexual; if the gender of a body is not indicated, will be assumed by the reader that it is male; if a disability is not indicated, it will be assumed by the reader that the protagonist is able bodied, just as a set of examples.\n\nOne can often overlook unmarked categories. Whiteness forms an unmarked category not commonly visible to the powerful, as they often fall within this category. The unmarked category becomes the norm, with the other categories relegated to deviant status. Social groups can apply this view of power to race, gender, and disability without modification: the able body is the neutral body.\n\nThe term 'counter-power' (sometimes written 'counterpower') is used in a range of situations to describe the countervailing force that can be utilised by the oppressed to counterbalance or erode the power of elites. A general definition has been provided by the anthropologist David Graeber as 'a collection of social institutions set in opposition to the state and capital: from self-governing communities to radical labor unions to popular militias'. Graeber also notes that counter-power can also be referred to as 'anti-power' and 'when institutions [of counter-power] maintain themselves in the face of the state, this is usually referred to as a 'dual power' situation'. Tim Gee, in his 2011 book \"Counterpower: Making Change Happen\", put forward a theory that those disempowered by governments' and elite groups' power can use \"counterpower\" to counter this. In Gee's model, \"counterpower\" is split into three categories: \"idea counterpower\", \"economic counterpower\", and \"physical counterpower\".\n\nAlthough the term has come to prominence through its use by participants in the global justice/anti-globalization movement of the 1990s onwards, the word has been used for at least 60 years; for instance Martin Buber's 1949 book 'Paths in Utopia' includes the line 'Power abdicates only under the stress of counter-power'.\n\n\nRecent experimental psychology suggests that the more power one has, the less one takes on the perspective of others, implying that the powerful have less empathy. Adam Galinsky, along with several coauthors, found that when those who are reminded of their powerlessness are instructed to draw Es on their forehead, they are 3 times more likely to draw them such that they are legible to others than those who are reminded of their power. Powerful people are also more likely to take action. In one example, powerful people turned off an irritatingly close fan twice as much as less powerful people. Researchers have documented the bystander effect: they found that powerful people are three times as likely to first offer help to a \"stranger in distress\".\n\nA study involving over 50 college students suggested that those primed to feel powerful through stating 'power words' were less susceptible to external pressure, more willing to give honest feedback, and more creative.\n\n\"Power is defined as a possibility to influence others.\"\n\nThe use of power has evolved from centuries. Gaining prestige, honor and reputation is one of the central motives for gaining power in human nature. Power also relates with empathy gaps because it limits the interpersonal relationship and compares the power differences. Having power or not having power can cause a number of psychological consequences. It leads to strategic versus social responsibilities. Research experiments were done as early as 1968 to explore power conflict.\n\nEarlier, research proposed that increased power relates to increased rewards and leads one to approach things more frequently. In contrast, decreased power relates to more constraint, threat and punishment which leads to inhibitions. It was concluded that being powerful leads one to successful outcomes, to develop negotiation strategies and to make more self-serving offers.\n\nLater, research proposed that differences in power lead to strategic considerations. Being strategic can also mean to defend when one is opposed or to hurt the decision-maker. It was concluded that facing one with more power leads to strategic consideration whereas facing one with less power leads to a social responsibility.\n\nBargaining games were explored in 2003 and 2004. These studies compared behavior done in different power given situations.\n\nIn an \"ultimatum game\", the person in given power offers an ultimatum and the recipient would have to accept that offer or else both the proposer and the recipient will receive no reward.\n\nIn a \"dictator game\", the person in given power offers a proposal and the recipient would have to accept that offer. The recipient has no choice of rejecting the offer.\n\nThe dictator game gives no power to the recipient whereas the ultimatum game gives some power to the recipient. The behavior observed was that the person offering the proposal would act less strategically than would the one offering in the ultimatum game. Self-serving also occurred and a lot of pro-social behavior was observed.\n\nWhen the counterpart recipient is completely powerless, lack of strategy, social responsibility and moral consideration is often observed from the behavior of the proposal given (the one with the power).\n\nAbusive power and control (or controlling behaviour or coercive control) involve the ways in which abusers gain and maintain power and control over victims for abusive purposes such as psychological, physical, sexual, or financial abuse. Such abuse can have various causes - such as personal gain, personal gratification, psychological projection, devaluation, envy or just for the sake of it - as the abuser may simply enjoy exercising power and control.\n\nControlling abusers may use multiple tactics to exert power and control over their victims. The tactics themselves are psychologically and sometimes physically abusive. Control may be helped through economic abuse, thus limiting the victim's actions as they may then lack the necessary resources to resist the abuse. Abusers aim to control and intimidate victims or to influence them to feel that they do not have an equal voice in the relationship.\n\nManipulators and abusers may control their victims with a range of tactics, including:\n\n\nThe vulnerabilities of the victim are exploited, with those who are particularly vulnerable being most often selected as targets. Traumatic bonding can occur between the abuser and victim as the result of ongoing cycles of abuse in which the intermittent reinforcement of reward and punishment fosters powerful emotional bonds that are resistant to change, as well as a climate of fear. An attempt may be made to normalise, legitimise, rationalise, deny, or minimise the abusive behaviour, or to blame the victim for it.\n\nOther often-used strategies include isolation, gaslighting, mind games, lying, disinformation, propaganda, destabilisation and divide-and-rule. Manipulators may ply victims with alcohol or drugs to help disorientate them.\n\nCertain personality-types feel particularly compelled to control other people.\n\nIn everyday situations people use a variety of power tactics to push or prompt people into particular action. There are plenty of examples of power tactics that are quite common and employed every day. Some of these tactics include bullying, collaboration, complaining, criticizing, demanding, disengaging, evading, humor, inspiring, manipulating, negotiating, socializing, and supplicating. These power tactics can be classified along three different dimensions:\n\nPeople tend to vary in their use of power tactics, with different types of people opting for different tactics. For instance, interpersonally oriented people tend to use soft and rational tactics. Machiavellians, however, tend to use nonrational tactics. Moreover, extroverts use a greater variety of power tactics than do introverts. People will also choose different tactics based on the group situation, and based on whom they are trying to influence. People also tend to shift from soft to hard tactics when they face resistance.\n\nBecause power operates both relationally and reciprocally, sociologists speak of the balance of power between parties to a relationship: all parties to all relationships have \"some\" power: the sociological examination of power concerns itself with discovering and describing the relative strengths: equal or unequal, stable or subject to periodic change. Sociologists usually analyse relationships in which the parties have relatively equal or nearly equal power in terms of \"constraint\" rather than of power. Thus 'power' has a connotation of unilateralism. If this were not so, then all relationships could be described in terms of 'power', and its meaning would be lost. Given that power is not innate and can be granted to others, to acquire power you must possess or control a form of power currency.\n\nPower changes those in the position of power and those who are targets of that power.\n\nDeveloped by D. Keltner and colleagues, approach/inhibition theory assumes that having power and using power alters psychological states of individuals. The theory is based on the notion that most organisms react to environmental events in two common ways. The reaction of \"approach\" is associated with action, self-promotion, seeking rewards, increased energy and movement. \"Inhibition\", on the contrary, is associated with self-protection, avoiding threats or danger, vigilance, loss of motivation and an overall reduction in activity.\n\nOverall, approach/inhibition theory holds that power promotes approach tendencies, while reduction in power promotes inhibition tendencies.\n\n\n\nA number of studies demonstrate that harsh power tactics (e.g. punishment (both personal and impersonal), rule-based sanctions, and non-personal rewards) are less effective than soft tactics (expert power, referent power, and personal rewards). It is probably because harsh tactics generate hostility, depression, fear, and anger, while soft tactics are often reciprocated with cooperation. Coercive and reward power can also lead group members to lose interest in their work, while instilling a feeling of autonomy in one’s subordinates can sustain their interest in work and maintain high productivity even in the absence of monitoring.\n\nCoercive influence creates conflict that can disrupt entire group functioning. When disobedient group members are severely reprimanded, the rest of the group may become more disruptive and uninterested in their work, leading to negative and inappropriate activities spreading from one troubled member to the rest of the group. This effect is called \"Disruptive contagion or ripple effect\" and it is strongly manifested when reprimanded member has a high status within a group, and authority’s requests are vague and ambiguous.\n\nCoercive influence can be tolerated when the group is successful, the leader is trusted, and the use of coercive tactics is justified by group norms. Furthermore, coercive methods are more effective when applied frequently and consistently to punish prohibited actions.\n\nHowever, in some cases, group members chose to resist the authority’s influence. When low-power group members have a feeling of shared identity, they are more likely to form a \"Revolutionary Coalition\", a subgroup formed within a larger group that seeks to disrupt and oppose the group’s authority structure. Group members are more likely to form a revolutionary coalition and resist an authority when authority lacks referent power, uses coercive methods, and asks group members to carry out unpleasant assignments. It is because these conditions create \"reactance\", a complex emotional and cognitive reaction that occurs when individuals feel that their freedom to make choices has been threatened or eliminated. When reactance occurs, individuals strive to reassert their sense of freedom by affirming their authority.\n\nHerbert Kelman identified three basic, step-like reactions that people display in response to coercive influence: compliance, identification, and internalization. This theory explains how groups convert hesitant recruits into zealous followers over time.\n\nAt the stage of \"compliance,\" group members comply with authority’s demands, but personally do not agree with them. If authority does not monitor the members, they will probably not obey.\n\n\"Identification\" occurs when the target of the influence admires and therefore imitates the authority, mimics authority’s actions, values, characteristics, and takes on behaviours of the person with power. If prolonged and continuous, identification can lead to the final stage – internalization.\n\nWhen \"internalization\" occurs, individual adopts the induced behaviour because it is congruent with his/her value system. At this stage, group members no longer carry out authority orders but perform actions that are congruent with their personal beliefs and opinions. Extreme obedience often requires internalization.\n\nPower literacy refers to how one perceives power, how it is formed and accumulates, and the structures that support it and who is in control of it. Education can be helpful for heightening power literacy. In a 2014 TED talk Eric Liu notes that \"we don't like to talk about power\" as \"we find it scary\" and \"somehow evil\" with it having a \"negative moral valence\" and states that the pervasiveness of power illiteracy causes a concentration of knowledge, understanding and clout. Joe L. Kincheloe describes a \"cyber-literacy of power\" that is concerned with the forces that shape knowledge production and the construction and transmission of meaning, being more about engaging knowledge than \"mastering\" information, and a \"cyber-power literacy\" that is focused on transformative knowledge production and new modes of accountability.\n\n"}
{"id": "22202480", "url": "https://en.wikipedia.org/wiki?curid=22202480", "title": "Propellant depot", "text": "Propellant depot\n\nAn orbital propellant depot is a cache of propellant that is placed in orbit around Earth or another body to allow spacecraft or the transfer stage of the spacecraft to be fueled in space. It is one of the types of space resource depot that have been proposed for enabling infrastructure-based space exploration.\nMany different depot concepts exist depending on the type of fuel to be supplied, location, or type of depot which may also include a propellant tanker that delivers a single load to a spacecraft at a specified orbital location and then departs. In-space fuel depots are not necessarily located near or at a space station.\n\nPotential users of in-orbit refueling and storage facilities include space agencies, defense ministries and communications satellite or other commercial companies.\n\nSatellite servicing depots would extend the lifetime of satellites that have nearly consumed all of their orbital maneuvering fuel and are likely placed in a geosynchronous orbit. The spacecraft would conduct a space rendezvous with the depot, or \"vice versa\", and then transfer propellant to be used for subsequent orbital maneuvers. In 2011, Intelsat showed interest in an initial demonstration mission to refuel several satellites in geosynchronous orbit, but all plans have been since scrapped.\n\nA low earth orbit (LEO) depot's primary function would be to provide propellant to a transfer stage headed to the moon, Mars, or possibly a geosynchronous orbit. Since all or a fraction of the transfer stage propellant can be off-loaded, the separately launched spacecraft with payload and/or crew could have a larger mass or use a smaller launch vehicle. With a LEO depot or tanker fill, the size of the launch vehicle can be reduced and the flight rate increased—or, with a newer mission architecture where the beyond-Earth-orbit spacecraft also serves as the second stage, can facilitate much larger payloads—which may reduce the total launch costs since the fixed costs are spread over more flights and fixed costs are usually lower with smaller launch vehicles. A depot could also be placed at Earth-Moon Lagrange point 1 (EML-1) or behind the Moon at EML-2 to reduce costs to travel to the moon or Mars. Placing a depot in Mars orbit has also been suggested.\n\nFor rockets and space vehicles, propellants usually take up 2/3 or more of their total mass.\n\nLarge upper-stage rocket engines generally use a cryogenic fuel like liquid hydrogen and liquid oxygen (LOX) as an oxidizer because of the large specific impulse possible, but must carefully consider a problem called \"boil off\". The boil off from only a few days of delay may not allow sufficient fuel for higher orbit injection, potentially resulting in a mission abort. Lunar or Mars missions will require weeks to months to accumulate tens of thousands to hundreds of thousands of kilograms of propellant, so additional equipment may be required on the transfer stage or the depot to mitigate boiloff.\n\nNon-cryogenic, earth-storable liquid rocket propellants including RP-1 (kerosene), hydrazine and nitrogen tetroxide (NTO), and mildly cryogenic, space-storable propellants like liquid methane and liquid oxygen, can be kept in liquid form with less boiloff than the cryogenic fuels, but also have lower specific impulse. Additionally, gaseous or supercritical propellants such as those used by ion thrusters include xenon, argon, and bismuth.\n\nEx-NASA administrator Mike Griffin commented at the 52nd AAS Annual Meeting in Houston, November 2005, that \"at a conservatively low government price of $10,000/kg in LEO, 250 MT of fuel for two missions per year is worth $2.5 B, at government rates.\"\n\nIf one assumes that a 130 metric tonne launch vehicle could be flown twice a year for $2.5B, the price is about $10,000/kg.\n\nIn the depot-centric architecture, the depot is filled by tankers, and then the propellant is transferred to an upper stage prior to orbit insertion, similar to a gas station filled by tankers for automobiles. By using a depot, the launch vehicle size can be reduced and the flight rate increased. Since the accumulation of propellant may take many weeks to months, careful consideration must be given to boiloff mitigation.\n\nIn simple terms, a passive cryogenic depot is a transfer stage with stretched propellant tanks, additional insulation, and a sun shield. In one concept, hydrogen boiloff is also redirected to reduce or eliminate liquid oxygen boiloff and then used for attitude control, power, or reboost. An active cryogenic depot is a passive depot with additional power and refrigeration equipment/cryocoolers to reduce or eliminate propellant boiloff. Other active cryogenic depot concepts include electrically powered attitude control equipment to conserve fuel for the end payload.\n\nIn the heavy lift architecture, propellant, which can be two thirds or more of the total mission mass, is accumulated in fewer launches and possibly shorter time frame than the depot centric architecture. Typically the transfer stage is filled directly and no depot is included in the architecture. For cryogenic vehicles and cryogenic depots, additional boiloff mitigation equipment is typically included on the transfer stage, reducing payload fraction and requiring more propellant for the same payload unless the mitigation hardware is expended.\n\nHeavy lift advocates state that the total mass to orbit required for a mission can actually increase because of the need to launch more propellant tanks and boil-off mitigation hardware. Heavy launch vehicles are not developed, so these costs are added to the trade, rather than using existing smaller rockets. Heavy lift advocates question the cost model for propellant depots and cite the need for development and demonstration.\n\nDepot advocates claim this increase in mission mass would be offset by a decrease in the cost per launch and the elimination of the fixed costs of the heavy lift launch vehicle when not required in a given time frame. Further, long life components including insulation, power and cryocoolers could be placed on the depot and not expended, further reducing the mass per mission and hence costs.\n\nHeavy Lift is compared with using Commercial Launch and Propellant Depots in this power point by Dr. Alan Wilhite given at FISO Telecon.\n\nBoth theoretical studies and funded development projects that are currently underway aim to provide insight into the feasibility of propellant depots. Studies have shown that a depot-centric architecture with smaller launch vehicles could be less expensive than a heavy-lift architecture over a 20-year time frame. The cost of large launch vehicles is so high that a depot able to hold the propellant lifted by two or more medium-sized launch vehicles may be cost effective and support more payload mass on beyond-Earth orbit trajectories.\n\nIn a 2010 NASA study, an additional flight of an Ares V heavy launch vehicle was required to stage a US government Mars reference mission due to 70 tons of boiloff, assuming 0.1% boiloff/day for hydrolox propellant. The study clearly identified the need to decrease the design boiloff rate by an order of magnitude or more.\n\nApproaches to the design of low Earth orbit (LEO) propellant depots were also discussed in the 2009 Augustine report to NASA, which \"examined the [then] current concepts for in-space refueling.\" The report determined there are essentially two approaches to refueling a spacecraft in LEO:\nBoth approaches were considered feasible with 2009 spaceflight technology, but anticipated that significant further engineering development and in-space demonstration would be required before missions could depend on the technology. Both approaches were seen to offer the potential of long-term life-cycle savings.\n\nBeyond theoretical studies, since at least 2016, SpaceX has undertaken funded development of an interplanetary set of technologies called the Interplanetary Transport System (ITS). While the system consists of a combination of several elements that are considered by SpaceX to be key to making long-duration beyond Earth orbit (BEO) spaceflights possible by reducing the cost per ton delivered to Mars by multiple orders of magnitude over what NASA approaches have achieved,\nrefilling of propellants in orbit is one of the four key elements. In a novel mission architecture, the SpaceX design intends to enable the long-journey spacecraft to expend most all of its propellant load during the launch to low Earth orbit while it serves as the second stage of the launch vehicle, and then—after refilling on orbit by an \"ITS tanker\"—provide the significant amount of energy necessary to put the spacecraft onto an interplanetary trajectory. The \"ITS tanker\" is designed to transport approximately of propellant to low Earth orbit.\n\nA second propellant tanker concept is underway. United Launch Alliance (ULA) has a proposed Advanced Cryogenic Evolved Stage (ACES) tanker—a concept that dates back to work by Boeing in 2006, sized to transport up to of propellant—in early design with first flight planned for no earlier than 2023, with initial usage as a propellant tanker potentially beginning in the mid-2020s.\n\nBecause a large portion of a rocket is propellant at time of launch, proponents point out several advantages of using a propellant depot architecture. Spacecraft could be launched unfueled and thus require less structural mass, or the depot tanker itself could serve as the second-stage on launch when it is reusable. An on-orbit market for refueling may be created where competition to deliver propellant for the cheapest price takes place, and it may also enable an economy of scale by permitting existing rockets to fly more often to refuel the depot. If used in conjunction with a mining facility on the moon, water or propellant could be exported back to the depot, further reducing the cost of propellant. An exploration program based on a depot architecture could be cheaper and more capable, not needing a specific rocket or a heavy lift such as the SLS to support multiple destinations such as the Moon, Lagrange points, asteroids, and Mars.\n\nNASA studies in 2011 showed cheaper and faster alternatives than the Heavy Lift Launch System and listed the following advantages:\n\nPropellant depots were proposed as part of the Space Transportation System (along with nuclear \"tugs\" to take payloads from LEO to other destinations) in the mid-1960s.\n\nIn October 2009, the Air Force and United Launch Alliance (ULA) performed an experimental on-orbit demonstration on a modified Centaur upper stage on the DMSP-18 launch to improve \"understanding of propellant settling and slosh, pressure control, RL10 chilldown and RL10 two-phase shutdown operations.\" \"The light weight of DMSP-18 allowed of remaining LO and LH propellant, 28% of Centaur’s capacity,\" for the on-orbit demonstrations. The post-spacecraft mission extension ran 2.4 hours before executing the deorbit burn.\n\nNASA's Launch Services Program is working on an ongoing slosh fluid dynamics experiments with partners called CRYOTE. ULA is also currently planning additional in-space laboratory experiments to further develop cryogenic fluid management technologies using the Centaur upper stage after primary payload separation. Named CRYOTE, or CRYogenic Orbital TEstbed, it will be a testbed for demonstrating a number of technologies needed for cryogenic propellant depots, with several small-scale demonstrations planned for 2012-2014.\n, ULA says this mission could launch as soon as 2012 if funded.\nThe ULA CRYOTE small-scale demonstrations are intended to lead to a ULA large-scale cryo-sat flagship technology demonstration in 2015.\n\nThe Future In-Space Operations (FISO) Working Group, a consortium of participants from NASA, industry and academia, discussed propellant depot concepts and plans on several occasions in 2010,\nwith presentations of optimal depot locations for human space exploration beyond low Earth orbit,\na proposed simpler (single vehicle) first-generation propellant depot\nand six important propellant-depot-related technologies for reusable cislunar transportation.\n\nNASA also has plans to mature techniques for enabling and enhancing space flights that use propellant depots in the \"CRYOGENIC Propellant STorage And Transfer (CRYOSTAT) Mission\". The CRYOSTAT vehicle is expected to be launched to LEO in 2015.\n\nThe CRYOSTAT architecture comprises technologies in the following categories:\n\nThe \"Simple Depot\" mission was proposed by NASA in 2011 as a potential first PTSD mission, with launch no earlier than 2015, on an Atlas V 551. \"Simple Depot\" would utilize the \"used\" (nearly-emptied) Centaur upper stage LH2 tank for long-term storage of LO2 while LH2 will be stored in the Simple Depot LH2 module, which is launched with only ambient-temperature gaseous Helium in it. The SD LH2 tank was to be diameter and long, in volume, and store 5 mT of LH2. \"At a useful mixture ratio (MR) of 6:1 this quantity of LH2 can be paired with 25.7 mT of LO2, allowing for 0.7 mT of LH2 to be used for vapor cooling, for a total useful propellant mass of 30 mT. ... the described depot will have a boil-off rate of approaching 0.1 percent per day, consisting entirely of hydrogen.\"\n\nIn September 2010, ULA released a \"Depot-Based Space Transportation Architecture\" concept to propose propellant depots that could be used as way-stations for other spacecraft to stop and refuel—either in low Earth orbit (LEO) for beyond-LEO missions, or at Lagrangian point for interplanetary missions—at the AIAA Space 2010 conference. The concept proposes that waste gaseous hydrogen—an inevitable byproduct of long-term liquid hydrogen storage in the radiative heat environment of space—would be usable as a monopropellant in a solar-thermal propulsion system. The waste hydrogen would be productively utilized for both orbital stationkeeping and attitude control, as well as providing limited propellant and thrust to use for orbital maneuvers to better rendezvous with other spacecraft that would be inbound to receive fuel from the depot.\nAs part of the Depot-Based Space Transportation Architecture, ULA has proposed the Advanced Common Evolved Stage (ACES) upper stage rocket. ACES hardware is designed from the start to as an in-space propellant depot that could be used as way-stations for other rockets to stop and refuel on the way to beyond-LEO or interplanetary missions, and to provide the high-energy technical capacity for the cleanup of space debris.\n\nIn August 2011, NASA made a significant contractual commitment to the development of propellant depot technology by funding four aerospace companies to \"define demonstration missions that would validate the concept of storing cryogenic propellants in space to reduce the need for large launch vehicles for deep-space exploration.\"\nThese study contracts for storing/transferring cryogenic propellants and cryogenic depots were signed with Analytical Mechanics Associates, Boeing, Lockheed Martin and Ball Aerospace. Each company will receive under the contract.\n\nThe Chinese Space Agency (CNSA) performed its first satellite-to-satellite on-orbit refueling test in June 2016.\n\nThere are a number of design issues with propellant depots, as well as several tasks that have not, to date, been tested in space for on-orbit servicing missions. The design issues include propellant settling and transfer, propellant usage for attitude control and reboost, the maturity of the refrigeration equipment/cryocoolers, and the power and mass required for reduced or zero boiloff depots with refrigeration.\n\nTransfer of liquid propellants in microgravity is complicated by the uncertain distribution of liquid and gasses within a tank. Propellant settling at an in-space depot is thus more challenging than in even a slight gravity field. ULA plans to use the DMSP-18 mission to flight-test centrifugal propellant settling as a cryogenic fuel management technique that might be used in future propellant depots. The proposed Simple Depot PTSD mission utilizes several techniques to achieve adequate settling for propellant transfer.\n\nIn the absence of gravity, propellant transfer is somewhat more difficult, since liquids can float away from the inlet.\n\nAs part of the Orbital Express mission in 2007, hydrazine propellant was successfully transferred between two single-purpose designed technology demonstration spacecraft. The Boeing servicing spacecraft ASTRO transferred propellant to the Ball Aerospace serviceable client spacecraft NEXTSat. Since no crew were present on either spacecraft, this was reported as the first autonomous spacecraft-to-spacecraft fluid transfer.\n\nAfter propellant has been transferred to a customer the depot's tanks will need refilling. Organizing the construction and launch of the tanker rockets bearing the new fuel is the responsibility of the propellant depot's operator. Since space agencies like NASA hope to be purchasers rather than owners, possible operators include the aerospace company that constructed the depot, manufacturers of the rockets, a specialist space depot company, or an oil/chemical company that refines the propellant. By using several tanker rockets the tankers can be smaller than the depot and larger than the spacecraft they are intended to resupply. Short range chemical propulsion tugs belonging to the depot may be used to simplify docking tanker rockets and large vehicles like Mars Transfer Vehicles.\n\nTransfers of propellant between the LEO depot, reachable by rockets from Earth, and the deep space ones such as the Lagrange Points and Phobos depots can be performed using Solar electric propulsion (SEP) tugs.\n\nTwo missions are currently under development or proposed to support propellant depot refilling. In addition to refueling and servicing geostationary communications satellites with the fuel that is initially launched with the MDA Space Infrastructure Servicing vehicle, the SIS vehicle is being designed to have the ability to orbitally maneuver to rendezvous with a replacement fuel canister after transferring the of fuel in the launch load, enabling further refueling of additional satellites after the initial multi-satellite servicing mission is complete.\nThe proposed Simple Depot cryogenic PTSD mission utilizes \"remote berthing arm and docking and fluid transfer ports\" both for propellant transfer to other vehicles, as well as for refilling the depot up to the full 30 tonne propellant capacity.\n\nS.T. Demetriades proposed a method for refilling by collecting atmospheric gases. Moving in low Earth orbit, at an altitude of around 120 km, Demetriades' proposed depot extracts air from the fringes of the atmosphere, compresses and cools it, and extracts liquid oxygen. The remaining nitrogen is used as propellant for a nuclear-powered magnetohydrodynamic engine, which maintains the orbit, compensating for atmospheric drag. This system was called “PROFAC” (PROpulsive Fluid ACcumulator). There are, however, safety concerns with placing a nuclear reactor in low Earth orbit.\n\nDemetriades' proposal was further refined by Christopher Jones and others In this proposal, multiple collection vehicles accumulate propellent gases at around 120 km altitude, later transferring them to a higher orbit. However, Jones' proposal does require a network of orbital power-beaming satellites, to avoid placing nuclear reactors in orbit.\n\nAsteroids can also be processed to provide liquid oxygen.\n\nPropellant depots in LEO are of little use for transfer between two low earth orbits when the depot is in a different orbital plane than the target orbit. The delta-v to make the necessary plane change is typically extremely high. On the other hand, depots are typically proposed for exploration missions, where the change over time of the depot's orbit can be chosen to align with the departure vector. This allows one well-aligned departure time minimizing fuel use that requires a very precisely-timed departure. Less efficient departure times from the same depot to the same destination exist before and after the well-aligned opportunity, but more research is required to show whether the efficiency falls off quickly or slowly. By contrast, launching directly in only one launch from the ground without orbital refueling or docking with another craft already on orbit offers daily launch opportunities though it requires larger and more expensive launchers.\n\nThe restrictions on departure windows arise because low earth orbits are susceptible to significant perturbations; even over short periods they are subject to nodal regression and, less importantly, precession of perigee. Equatorial depots are more stable but also more difficult to reach.\n\nHowever, it is possible to do a three-burn orbital transfer which includes a plane change, and which wastes very little propellant to reach almost any final trajectory.\n\nBoil-off of cryogenic propellants in space may be mitigated by both technological solutions as well as system-level planning and design.\nFrom a technical perspective: for a propellant depot with passive insulation system to effectively store cryogenic fluids, boil-off caused by heating from solar and other sources must be mitigated, eliminated, or used for economic purposes. For non-cryogenic propellants, boil-off is not a significant design problem.\n\nBoil off rate is governed by heat leakage and by the quantity of propellant in the tanks. With partially filled tanks, the percentage loss is higher. Heat leakage depends on surface area, while the original mass of propellant in the tanks depends on volume. So by the cube-square law, the smaller the tank, the faster the liquids will boil off.\nSome propellant tank designs have achieved a liquid hydrogen boil off rate as low as approximately 0.13% per day (3.8% per month) while the much higher temperature cryogenic fluid of liquid oxygen would boil off much less, about 0.016% per day (0.49% per month).\n\nIt is possible to achieve zero boil-off (ZBO) with cryogenic propellant storage using an active thermal control system. Tests conducted at the NASA Lewis Research Center's Supplemental Multilayer Insulation Research Facility (SMIRF) over the summer of 1998 demonstrated that a hybrid thermal control system could eliminate boiloff of cryogenic propellants. The hardware consisted of a pressurized 50-ft³ (ca. 1416 litres) tank insulated with multi-layer insulation (MLI) of 34 layers, a condenser, and a Gifford-McMahon (GM) cryocooler that has a cooling capacity of 15 to 17.5 watt (W). Liquid hydrogen was the test fluid. The test tank was installed into a vacuum chamber, simulating space vacuum.\nIn 2001, a cooperative effort by NASA's Ames Research Center, Glenn Research Center, and Marshall Space Flight Center (MSFC) was implemented to develop zero-boiloff concepts for in-space cryogenic storage. Main program element was a large-scale, zero-boiloff demonstration using the MSFC multipurpose hydrogen test bed (MHTB) - 18.10 m3 LH2 tank (about 1300 kg of H2). A commercial cryocooler was interfaced with an existing MHTB spray bar mixer and insulation system in a manner that enabled a balance between incoming and extracted thermal energy.\n\nAnother NASA study in June 2003 for conceptual Mars mission showed mass savings over traditional, passive- only cryogenic storage when mission durations are 5 days in LEO for oxygen, 8.5 days for methane and 64 days for hydrogen. Longer missions equate to greater mass savings. Cryogenic xenon saves mass over passive storage almost immediately. When power to run the ZBO is already available, the break-even mission durations are even shorter, e.g. about a month for hydrogen. The larger the tank, the fewer days in LEO when ZBO has reduced mass.\n\nIn addition to technical solutions to the challenge of excessive boil-off of cryogenic rocket propellants, system-level solutions have been proposed. From a systems perspective, reductions in the standby time of the LH2 cryogenic storage in order to achieve, effectively, a just in time (JIT) delivery to each customer, matched with the balanced refinery technology to split the long-term storable feedstock—water—into the stoichiometric LOX/LH2 necessary, is theoretically capable of achieving a system-level solution to boil-off. Such proposals have been suggested as supplementing good technological techniques to reduce boil-off, but would not replace the need for efficient technological storage solutions.\n\nUnited Launch Alliance (ULA) has proposed a cryogenic depot which would use a conical sun shield to protect the cold propellants from solar and Earth radiation. The open end of the cone allows residual heat to radiate to the cold of deep space, while the closed cone layers attenuates the radiative heat from the Sun and Earth.\n\nOther issues are hydrogen embrittlement, a process by which some metals (including iron and titanium) become brittle and fracture following exposure to hydrogen. The resulting leaks makes storing cryogenic propellants in zero gravity conditions difficult.\n\nIn the early 2010s, several in-space refueling projects got under-way. Two private initiatives and a government-sponsored test mission were in some level of development or testing .\n\nThe NASA Robotic Refueling Mission was launched in 2011 and successfully completed a series of robotically-actuated propellant transfer experiments on the exposed facility platform of the International Space Station in January 2013.\n\nThe set of experiments included a number of propellant valves, nozzles and seals similar to those used on many satellites and a series of four prototype tools that could be attached to the distal end of a Space Station robotic arm. Each tool was a prototype of \"devices that could be used by future satellite servicing missions to refuel spacecraft in orbit. RRM is the first in-space refueling demonstration using a platform and fuel valve representative of most existing satellites, which were never designed for refueling. Other satellite servicing demos, such as the U.S. military's Orbital Express mission in 2007, transferred propellant between satellites with specially-built pumps and connections.\"\n\n, a small-scale refueling demonstration project for reaction control system (RCS) fluids is under development. Canada-based MDA Corporation announced in early 2010 that they were designing a single spacecraft that would refuel other spacecraft in orbit as a satellite-servicing demonstration. \"The business model, which is still evolving, could ask customers to pay per kilogram of fuel successfully added to their satellite, with the per-kilogram price being a function of the additional revenue the operator can expect to generate from the spacecraft’s extended operational life.\"\n\nThe plan is that the fuel-depot vehicle would maneuver to an operational communications satellite, dock at the target satellite’s apogee-kick motor, remove a small part of the target spacecraft’s thermal protection blanket, connect to a fuel-pressure line and deliver the propellant. \"MDA officials estimate the docking maneuver would take the communications satellite out of service for about 20 minutes.\"\n\n, MDA has secured a major customer for the initial demonstration project. Intelsat has agreed to purchase one-half of the propellant payload that the MDA spacecraft would carry into geostationary orbit. Such a purchase would add somewhere between two and four years of additional service life for up to five Intelsat satellites, assuming 200 kg of fuel is delivered to each one.\n, the spacecraft could be ready to begin refueling communication satellites by 2015.\n, no customers have signed up for an MDA refueling mission.\n\nCompetitive design alternatives to in-space RCS fuel transfer exist. It is possible to bring additional propellant to a space asset, and utilize the propellant for attitude control or orbital velocity change, without ever transferring the propellant to the target space asset.\n\nThe ViviSat Mission Extension Vehicle, also under development since the early 2010s, illustrates one alternative approach that would connect to the target satellite similarly to MDA SIS, via the kick motor, but will not transfer fuel. Rather, the Mission Extension Vehicle will use \"its own thrusters to supply attitude control for the target.\"\nViviSat believes their approach is more simple and can operate at lower cost than the MDA propellant transfer approach, while having the technical ability to dock with and service a greater number (90 percent) of the approximately 450 geostationary satellites in orbit.\n, no customers have signed up for a ViviSat-enabled mission extension.\n\nIn 2015, Lockheed Martin proposed the Jupiter space tug. If built, Jupiter would operate in low Earth orbit shuttling cargo carriers to and from the International Space Station, remaining on orbit indefinitely, and refueling itself from subsequent transport ships carrying later cargo carrier modules.\n\n\n\n"}
{"id": "19115227", "url": "https://en.wikipedia.org/wiki?curid=19115227", "title": "Psychomotor learning", "text": "Psychomotor learning\n\nPsychomotor learning is the relationship between cognitive functions and physical movement. Psychomotor learning is demonstrated by physical skills such as movement, coordination, manipulation, dexterity, grace, strength, speed—actions which demonstrate the fine motor skills, such as use of precision instruments or tools.\n\nBehavioral examples include driving a car, throwing a ball, and playing a musical instrument. In psychomotor learning research, attention is given to the learning of coordinated activity involving the arms, hands, fingers, and feet, while verbal processes are not emphasized.\n\nWhen learning psychomotor skills, individuals progress through the cognitive stages, the associative stage, and the autonomic stage. The cognitive stage is marked by awkward slow and choppy movements that the learner tries to control. The learner has to think about each movement before attempting it. In the associative stage, the learner spends less time thinking about every detail, however, the movements are still not a permanent part of the brain. In the autonomic stage, the learner can refine the skill through practice, but no longer needs to think about the movement.\n\n\nWhen an individual learns physical movements, this leads to changes in the motor cortex. The more practiced a movement is, the stronger the neural encoding becomes. Psychomotor learning is not limited to the motor cortex, however.\n\n"}
{"id": "5241800", "url": "https://en.wikipedia.org/wiki?curid=5241800", "title": "Recognition primed decision", "text": "Recognition primed decision\n\nRecognition-primed decision (RPD) is a model of how people make quick, effective decisions when faced with complex situations. In this model, the decision maker is assumed to generate a possible course of action, compare it to the constraints imposed by the situation, and select the first course of action that is not rejected. RPD has been described in diverse groups including Whitewater kayaking Trauma nurses, fireground commanders, chess players, commercial Whitewater river guides and stock market traders. It functions well in conditions of time pressure, and in which information is partial and goals poorly defined. The limitations of RPD include the need for extensive experience among decision-makers (in order to correctly recognize the salient features of a problem and model solutions) and the problem of the failure of recognition and modeling in unusual or misidentified circumstances. It appears to be a valid model for how human decision-makers make decisions.\n\nThe RPD model identifies a reasonable reaction as the first one that is immediately considered. RPD combines two ways of developing a decision; the first is recognizing which course of action makes sense, and the second, evaluating the course of action through imagination to see if the actions resulting from that decision make sense. However, the difference of being experienced or inexperienced plays a major factor in the decision-making processes. \n\nRPD reveals a critical difference between experts and novices when presented with recurring situations. Experienced people will generally be able to come up with a quicker decision because the situation may match a prototypical situation they have encountered before. Novices, lacking this experience, must cycle through different possibilities, and tend to use the first course of action that they believe will work. The inexperienced also have the tendencies of using trial and error through their imagination.\n\nThere are three variations in RPD strategy. In Variation 1, decision makers recognize the situation as typical: a scenario where both the situational detail and the detail of relevant courses of action are known. Variation 1 is therefore essentially an “If… then…” reaction. A given situation will lead to an immediate course of action as a function of the situation's typicality. More experienced decision makers are more likely to have the knowledge of both prototypical situations and established courses of action that is required for an RPD strategy to qualify as Variation 1. \n\nVariation 2 occurs when the decision maker diagnoses an unknown situation to choose from a known selection of courses of action. Variation 2 takes the form of “If (???)… then…,” a phrase which implies the decision maker's specific knowledge of available courses of action but lack of knowledge regarding the parameters of the situation. In order to prevent situational complications and the accrual of misinformation, the decision maker models possible details of the situation carefully and then chooses the most relevant known course of action. Experienced decision makers are more likely to correctly model the situation, and are thus more likely to more quickly choose more appropriate courses of action.\n\nIn Variation 3, the decision maker is knowledgeable of the situation but unaware of the proper course of action. The decision maker therefore implements a mental trial and error simulation to develop the most effective course of action. Variation 3 takes the form of “If… then… (???)” wherein the decision maker models outcomes of new or uncommon courses of action. The decision maker will cycle through different courses of action until a course of action appears appropriate to the goals and priorities of the situation. Due to the time constraint fundamental to the RPD model, the decision maker will choose the first course of action which appears appropriate to the situation. Experienced decision makers are likely to develop a viable course of action more quickly because their expert knowledge can rapidly be used to disqualify inappropriate courses of action.\n\nRecognition primed decision making is highly relevant to the leaders or officers of organizations that are affiliated with emergency services such as fire fighters, search and rescue units, police, and other emergency services. It is applied to both the experienced and the inexperienced, and how they manage their decision making processes. The Recognition primed decision making model is developed as samples for organizations on how important decisions can affect important situations which may either save lives or take lives. The model developed can be used as a study for organizations to fill in the gaps and to determine which type of RPD variation is more applicable to the organization.\n\n\n"}
{"id": "6797677", "url": "https://en.wikipedia.org/wiki?curid=6797677", "title": "Regular semigroup", "text": "Regular semigroup\n\nIn mathematics, a regular semigroup is a semigroup \"S\" in which every element is regular, i.e., for each element \"a\", there exists an element \"x\" such that \"axa\" = \"a\". Regular semigroups are one of the most-studied classes of semigroups, and their structure is particularly amenable to study via Green's relations.\n\nRegular semigroups were introduced by J. A. Green in his influential 1951 paper \"On the structure of semigroups\"; this was also the paper in which Green's relations were introduced. The concept of \"regularity\" in a semigroup was adapted from an analogous condition for rings, already considered by John von Neumann. It was Green's study of regular semigroups which led him to define his celebrated relations. According to a footnote in Green 1951, the suggestion that the notion of regularity be applied to semigroups was first made by David Rees.\n\nThe term inversive semigroup (French: demi-groupe inversif) was historically used as synonym in the papers of Gabriel Thierrin (a student of Paul Dubreil) in the 1950s, and it is still used occasionally.\n\nThere are two equivalent ways in which to define a regular semigroup \"S\":\nTo see the equivalence of these definitions, first suppose that \"S\" is defined by (2). Then \"b\" serves as the required \"x\" in (1). Conversely, if \"S\" is defined by (1), then \"xax\" is an inverse for \"a\", since \"a\"(\"xax\")\"a\" = \"axa\"(\"xa\") = \"axa\" = \"a\" and (\"xax\")\"a\"(\"xax\") = \"x\"(\"axa\")(\"xax\") = \"xa\"(\"xax\") = \"x\"(\"axa\")\"x\" = \"xax\".\n\nThe set of inverses (in the above sense) of an element \"a\" in an arbitrary semigroup \"S\" is denoted by \"V\"(\"a\"). Thus, another way of expressing definition (2) above is to say that in a regular semigroup, \"V\"(\"a\") is nonempty, for every \"a\" in \"S\". The product of any element \"a\" with any \"b\" in \"V\"(\"a\") is always idempotent: \"abab\" = \"ab\", since \"aba\" = \"a\".\n\n\nA regular semigroup in which idempotents commute is an inverse semigroup, or equivalently, every element has a \"unique\" inverse. To see this, let \"S\" be a regular semigroup in which idempotents commute. Then every element of \"S\" has at least one inverse. Suppose that \"a\" in \"S\" has two inverses \"b\" and \"c\", i.e.,\nThen\nSo, by commuting the pairs of idempotents \"ab\" & \"ac\" and \"ba\" & \"ca\", the inverse of \"a\" is shown to be unique. Conversely, it can be shown that any inverse semigroup is a regular semigroup in which idempotents commute.\n\nThe existence of a unique pseudoinverse implies the existence of a unique inverse, but the opposite is not true. For example, in the symmetric inverse semigroup, the empty transformation Ø does not have a unique pseudoinverse, because Ø = Ø\"f\"Ø for any transformation \"f\". The inverse of Ø is unique however, because only one \"f\" satisfies the additional constraint that \"f\" = \"f\"Ø\"f\", namely \"f\" = Ø. This remark holds more generally in any semigroup with zero. Furthermore, if every element has a unique pseudoinverse, then the semigroup is a group, and the unique pseudoinverse of an element coincides with the group inverse.\n\nRecall that the principal ideals of a semigroup \"S\" are defined in terms of \"S\", the \"semigroup with identity adjoined\"; this is to ensure that an element \"a\" belongs to the principal right, left and two-sided ideals which it generates. In a regular semigroup \"S\", however, an element \"a\" = \"axa\" automatically belongs to these ideals, without recourse to adjoining an identity. Green's relations can therefore be redefined for regular semigroups as follows:\n\nIn a regular semigroup \"S\", every formula_4- and formula_5-class contains at least one idempotent. If \"a\" is any element of \"S\" and α is any inverse for \"a\", then \"a\" is formula_4-related to \"αa\" and formula_5-related to \"aα\".\n\nTheorem. Let \"S\" be a regular semigroup, and let \"a\" and \"b\" be elements of \"S\". Then\n\nIf \"S\" is an inverse semigroup, then the idempotent in each formula_4- and formula_5-class is unique.\n\nSome special classes of regular semigroups are:\nThe class of generalised inverse semigroups is the intersection of the class of locally inverse semigroups and the class of orthodox semigroups.\n\nAll inverse semigroups are orthodox and locally inverse. The converse statements do not hold.\n\n\n\n"}
{"id": "39004", "url": "https://en.wikipedia.org/wiki?curid=39004", "title": "Robert Broom", "text": "Robert Broom\n\nRobert Broom FRS FRSE (30 November 1866, Paisley – 6 April 1951) was a Scottish South African doctor and paleontologist. He qualified as a medical practitioner in 1895 and received his DSc in 1905 from the University of Glasgow.\n\nFrom 1903 to 1910 he was professor of zoology and geology at Victoria College, Stellenbosch, South Africa, and subsequently he became keeper of vertebrate paleontology at the South African Museum, Cape Town.\n\nBroom was born at 66 Back Sneddon Street in Paisley, the son of John Broom, a designer of calico prints and Paisley shawls, and Agnes Hunter Shearer.\n\nIn 1893 he married Mary Baird Baillie.\n\nIn his medical studies at the University of Glasgow Broom specialised in midwifery. After graduating in 1895 he travelled to Australia, supporting himself by practising medicine. He settled in South Africa in 1897, just prior to the South African War. From 1903 to 1910 he was professor of Zoology and Geology at Victoria College, Stellenbosch (later Stellenbosch University), but was forced out of this position for promoting belief in evolution. He established a medical practice in the Karoo region of South Africa, an area rich in Therapsid fossils. Based on his continuing studies of these fossils and mammalian anatomy he was made a Fellow of the Royal Society in 1920. Following the discovery of the Taung child he became interested in the search for human ancestors and commenced work on much more recent fossils from the dolomite caves north-west of Johannesburg, particularly Sterkfontein Cave (now part of the Cradle of Humankind World Heritage Site). As well as describing many mammalian fossils from these caves he identified several hominin fossils, the most complete of which was an Australopithecine skull, nicknamed Mrs Ples, and a partial skeleton that indicated that Australopithecines walked upright.\n\nBroom died in Pretoria, South Africa in 1951.\n\nBroom was first known for his study of mammal-like reptiles. After Raymond Dart's discovery of the Taung Child, an infant australopithecine, Broom's interest in paleoanthropology was heightened. Broom's career seemed over and he was sinking into poverty, when Dart wrote to Jan Smuts about the situation. Smuts, exerting pressure on the South African government, managed to obtain a position for Broom in 1934 with the staff of the Transvaal Museum in Pretoria as an Assistant in Palaeontology.\n\nIn the following years, he and John T. Robinson made a series of spectacular finds, including fragments from six hominins in Sterkfontein, which they named \"Plesianthropus transvaalensis\", popularly called Mrs. Ples, but which was later classified as an adult \"Australopithecus africanus\", as well as more discoveries at sites in Kromdraai and Swartkrans. In 1937, Broom made his most famous discovery of \"Paranthropus robustus\". These discoveries helped support Dart's claims for the Taung species.\n\nThe remainder of Broom's career was devoted to the exploration of these sites and the interpretation of the many early hominin remains discovered there. For his volume, \"The South Africa Fossil Ape-Men, The Australopithecinae\", in which he proposed the Australopithecinae subfamily, Broom was awarded the Daniel Giraud Elliot Medal from the National Academy of Sciences in 1946. He continued to write to the very last. Shortly before his death he finished a monograph on the Australopithecines and remarked to his nephew:\n\nBroom was a nonconformist and was deeply interested in the paranormal and spiritualism; he was a critic of Darwinism and materialism. Broom was a believer in spiritual evolution. In his book \"The Coming of Man: Was it Accident or Design?\" (1933) he claimed that \"spiritual agencies\" had guided evolution as animals and plants were too complex to have arisen by chance. According to Broom, there were at least two different kinds of spiritual forces, and psychics are capable of seeing them. Broom claimed there was a plan and purpose in evolution and that the origin of \"Homo sapiens\" is the ultimate purpose behind evolution. According to Broom \"Much of evolution looks as if it had been planned to result in man, and in other animals and plants to make the world a suitable place for him to dwell in.\"\n\nAfter discovering the skull of Mrs. Ples, Broom was asked if he excavated at random, Broom replied that spirits had told him where to find his discoveries.\n\nAmong hundreds of articles contributed by him to scientific journals, the most important include:\n\nBooks\n\n\n\n"}
{"id": "24714543", "url": "https://en.wikipedia.org/wiki?curid=24714543", "title": "Schedule for Affective Disorders and Schizophrenia", "text": "Schedule for Affective Disorders and Schizophrenia\n\nThe Schedule for Affective Disorders and Schizophrenia (SADS) is a collection of psychiatric diagnostic criteria and symptom rating scales originally published in 1978. It is organized as a semi-structured diagnostic interview. The structured aspect is that every interview asks screening questions about the same set of disorders regardless of the presenting problem; and positive screens get explored with a consistent set of symptoms. These features increase the sensitivity of the interview and the inter-rater reliability (or reproducibility) of the resulting diagnoses. The SADS also allows more flexibility than fully structured interviews: Interviewers can use their own words and rephrase questions, and some clinical judgment is used to score responses. There are three versions of the schedule, the regular SADS, the lifetime version (SADS-L) and a version for measuring the change in symptomology (SADS-C). Although largely replaced by more structured interviews that follow diagnostic criteria such as DSM-IV and DSM-5, and specific mood rating scales, versions of the SADS are still used in some research papers today.\n\nThe diagnoses covered by the interview include schizophrenia, schizoaffective disorder, major depressive disorder, bipolar disorder, anxiety disorders and a limited number of other fairly common diagnoses.\n\nThe SADS was developed by the same group of rearchers as the Research Diagnostic Criteria (RDC). While the RDC is a list of diagnostic criteria for psychiatric disorders, the SADS interview allows diagnoses based on RDC criteria to be made, and also rates subject's symptoms and level of functioning.\n\nThe K-SADS (or Kiddie-SADS) is a version of the SADS adapted for school-aged children of 6–18 years. There are various different versions of the K-SADS, each varying slightly in terms of disorders and specific symptoms covered, as well as the scale range used. All of the variations are still semi-structured interviews, giving the interviewer more flexibility about how to phrase and probe items, while still covering a consistent set of disorders.\n\nThe K-SADS-E (Epidemiological version) was developed for epidemiological research. It focused on current issues and episodes only. Most of the items used a four point rating scale.\n\nThe K-SADS-PL (Present and Lifetime version) is administered by interviewing the parent(s), the child, and integrating them into a summary rating that includes parent report, child report, and clinical observations during the interview. The interview covers both present issues (i.e., the reason the family is seeking an evaluation) as well as past episodes of the disorders. Most items use a three point rating scale for severity (not present, subthreshold, and threshold—which combines both moderate and severe presentations). It has been used with preschool as well as school-aged children. A 2009 working draft removed all reference to the DSM-III-R criteria (which were replaced with the publication of the DSM-IV in 1994) and made some other modifications. A DSM-5 version is being prepared and validated.\n\nThe WASH-U K-SADS (Washington University version) added items to the depression and mania modules and used a six point severity rating for severity.\n\n"}
{"id": "4763634", "url": "https://en.wikipedia.org/wiki?curid=4763634", "title": "Sense of wonder", "text": "Sense of wonder\n\nA sense of wonder is an intellectual and emotional state frequently invoked in discussions of science fiction.\n\nThis entry focuses on one specific use of the phrase \"sense of wonder.\" This phrase is widely used in contexts that have nothing to do with science fiction. The following relates to the use of \"sense of wonder\" within the context of science fiction. In \"Brave New Words: The Oxford Dictionary of Science Fiction\" the term \"sense of wonder\" is defined as follows:\nJon Radoff has characterised a sense of wonder as an emotional reaction to the reader suddenly confronting, understanding, or seeing a concept new in the context of new information.\n\nIn the introductory section of his essay 'On the Grotesque in Science Fiction', Istvan Csicsery-Ronay Jr., Professor of English, DePauw University, states:\n\nJohn Clute and Peter Nicholls associate the experience with that of the \"conceptual breakthrough\" or \"paradigm shift\" (Clute & Nicholls 1993). In many cases, it is achieved through the recasting of previous narrative experiences in a larger context. It can be found in short scenes (e.g., in \"\", it can be found, in a small dose, inside the line \"That's no moon; it's a space station.\") and it can require entire novels to set up (as in the final line to Iain Banks's \"Feersum Endjinn\".)\n\nGeorge Mann defines the term as “the sense of inspired awe that is aroused in a reader when the full implications of an event or action become realized, or when the immensity of a plot or idea first becomes known;” and he associates the term with the Golden Age of SF and the pulp magazines prevalent at the time. One of the major writers of the Golden Age, Isaac Asimov, agreed with this association: in 1967 commenting on the changes occurring in SF he wrote,\n\nNuminous is defined in this encyclopedia as that which arouses \"spiritual or religious emotion\" or is \"mysterious or awe-inspiring\".\n\nGeorge Mann suggests that this ‘sense of wonder’ is associated only with science fiction as distinct from science fantasy, stating:\n\nHowever, the editor and critic David Hartwell sees SF’s ‘sense of wonder’ in more general terms, as ”being at the root of the excitement of science fiction.” He continues:\n\nTo say that science fiction is in essence a religious literature is an overstatement, but one that contains truth. SF is a uniquely modern incarnation of an ancient tradition: the tale of wonder. Tales of miracles, tales of great powers and consequences beyond the experience of people in your neighborhood, tales of the gods who inhabit other worlds and sometimes descend to visit ours, tales of humans traveling to the abode of the gods, tales of the uncanny: all exist now as science fiction.\n\nAcademic criticism of science fiction literature (Robu 1988) identifies the idea of the sublime described by Edmund Burke and Immanuel Kant—infinity, immensity, \"delightful horror\"—as a key to understanding the concept of \"sense of wonder\" in science fiction. For example, Professor of English at the University of Iowa, Brooks Landon says:\n\nEdward James quotes from Aldiss and Wingrove’s history of science fiction in support of the above suggestion as to the origin of the ‘sense of wonder’ in SF, as follows:\n\nPaul K. Alkon in his book \"Science Fiction before 1900. Imagination Discovers Technology\" makes a similar point:\n\nAlkon concludes that \"science fiction ever since [the 19th century] has been concerned as often to elicit strong emotional responses as to maintain a rational basis for its plots. Far from being mutually exclusive, the two aims can reinforce each other ...\",\n\nEdward James, in a section of his book entitled ‘The Sense of Wonder’ says on this point of the origin of the 'sense of wonder' in SF:\n\nJames goes on to explore the same point as made by David Hartwell in his book \"Age of Wonders\" (and quoted above) as regards the relationship of the ‘sense of wonder’ in SF to religion or the religious experience. He states that,\n\nAs an example James takes the short story ‘The Nine Billion Names of God’ by Arthur C. Clarke. He explains:\n\nIt is appropriate that Edward James chooses a story by Arthur C. Clarke to make the point. One critic is of the opinion that Clarke \"has dedicated his career to evoking a \"sense of wonder\" at the sublime spaces of the universe ...\" Editor and SF researcher Mike Ashley agrees:\n\nKathryn Cramer in her essay ‘On Science and Science Fiction’ also explores the relationship of SF’s ‘sense of wonder’ to religion, stating that “the primacy of the sense of wonder in science fiction poses a direct challenge to religion: Does the wonder of science and the natural world as experienced through science fiction replace religious awe?”\n\nHowever, as Brooks Landon shows, not all 'sense of wonder' needs to be so closely related to the classical sense of the Sublime. Commenting on the story 'Twilight' by John W. Campbell he says:\nPerhaps the single most famous example of \"sensawunda\" in all of science fiction involves a neologism, from the work of A. E. van Vogt (Moskowitz 1974):\n\nDespite the attempts above to define and illustrate the 'sense of wonder' in SF, Csicsery-Ronay Jr. argues that \"unlike most of the other qualities regularly associated with the genre, the sense of wonder resists critical commentary.\" The reason he suggests is that,\n\nNevertheless, despite this \"resistance to critical commentary,\" the 'sense of wonder' has \"a well-established pedigree in art, separated into two related categories of response: the expansive sublime and the intensive grotesque.\" Csicsery-Ronay Jr. explains the difference between these two categories as follows::\n\nLater in this same essay the author argues that \"the sublime and the grotesque are in such close kinship that they are shadows of each other,\" and that \"it is not always easy to distinguish the two, and the grotesque of one age easily becomes the sublime of another.\" He gives as an example the android (T-1000) in the second 'Terminator' film \"\", saying that \"the T-1000, like so many liminal figures in sf, is almost simultaneously sublime and grotesque. Its fascinating shape-shifting would be the object of sublime awe were it not for its sadistic violation of mundane flesh\n\nThere is no doubt that the term 'sense of wonder' is used and understood by readers of SF without the need of explanation or elaboration. For example, SF author and critic David Langford reviewing an SF novel in the New York Review of Science Fiction was able to write \"I suppose it's all a frightfully mordant microcosm of human aspirations, but after so much primitive carnage, the expected multiversal sense-of-wonder jolt comes as a belated infodump rather than ...\"\n\nJack Williamson in 1991 said that the New Wave did not last in science fiction because it \"failed to move people. I'm not sure if this failure was due to its pessimistic themes or to people feeling the stuff was too pretentious. But it never really grabbed hold of people's imaginations\".\n\nSharona Ben-Tov in her book \"The Artificial Paradise: Science Fiction and American Reality\" explores science-fiction's (SF) 'sense of wonder' from a feminist perspective. Her book is a \"thought-provoking work of criticism that provides a new and interesting perspective on some basic elements in science fiction,\" including the 'sense of wonder'. In his review of Ben-Tov’s work for the SF critical journal \"Extrapolation\" David Dalgleish, quoting from the text, points out that,\n\n\n\n"}
{"id": "45007059", "url": "https://en.wikipedia.org/wiki?curid=45007059", "title": "Victor Brombert", "text": "Victor Brombert\n\nVictor Henri Brombert (born, November 11, 1923) is an American scholar of nineteenth and twentieth century literature, the Henry Putnam University Professor at Princeton University.\n\nBrombert was born in Berlin in 1923 into a well-to-do Russian-Jewish family that had fled Russia at the outbreak of the Revolution and settled in Leipzig. When Hitler came to power in Germany, the family left for Paris, and Brombert received his secondary education at the Lycée Janson-de-Sailly. As the German army advanced on Paris in 1940, the family fled to the unoccupied zone under the control of the Vichy government and a year later, in 1941, escaped via Spain to the United States.\n\nIn May 1943 Brombert was drafted into the U.S. army. Due to his fluency in French, German, and Russian he was placed in a special unit, composed chiefly of refugees from Nazi-occupied European countries, that was trained in front-line military intelligence at Camp Ritchie, Maryland, and featured in a documentary film \"The Ritchie Boys\".\n\nIn 1944 he took part in the Normandy landings with the 2nd Armored Division at Omaha Beach and also saw action with the 28th Infantry Division in the Battle of the Bulge. After the war, Brombert studied at Yale University, where he received a B.A. in 1948 and a Ph.D. in Romance Languages and Literatures in 1953. As a graduate student, he was awarded a Fulbright Fellowship (1950–51) to study in Rome, adding Italian to the languages in which he has native fluency. He is married to Beth Archer Brombert, a translator from French and Italian, and the author of the biographies \"Cristina: Portraits of a Princess\" and \"Édouard Manet: Rebel in a Frock Coat\". The Bromberts have two children, Lauren and Marc.\n\nOn completion of his graduate studies Brombert joined the Yale Department of Romance Languages and Literatures. He was appointed Benjamin F. Barge Professor in 1968 and was chair of his Department from 1964 to 1973. In 1975 he moved to Princeton, where he had been appointed Henry Putnam University Professor and was affiliated with the Departments of Comparative Literature and Romance Languages and Literatures. At Princeton, he was also Director of Princeton's Christian Gauss Seminars in Criticism and chairman of its Council of the Humanities. He entered emeritus status in 1999.\n\nBrombert has been a visiting professor at many universities in the U.S. and Europe: the University of California (Berkeley), the Johns Hopkins University, Columbia University, New York University, the University of Colorado, the Scuola Normale Superiore (Pisa, Italy), the Collège de France (Paris), the University of Bologna, the University of Puerto Rico.\n\nBrombert has held fellowships from the American Council of Learned Societies (1967) and from the Guggenheim Foundation (1954–55; 1970). He was Phi Beta Kappa Visiting Scholar in 1986-87 and 1989–90, and a scholar-in-residence at the Rockefeller Foundation in Bellagio, Italy in 1975 and in 1990. He was elected to the American Academy of Arts and Sciences in 1974, and to the American Philosophical Society in 1987. He holds honorary degrees from the University of Chicago (Doctor of Humane Letters, 1981) and the University of Toronto (Doctor of Laws, 1997). In 1985 he was awarded the Wilbur Cross Medal of the Yale Alumni Association for \"distinguished achievements in scholarship, teaching, academic administration, and public service.” In France, he was honored with the Médaille Vermeil de la Ville de Paris \" (1985) and was made \"Commandeur des Palmes Académiques\" (2008) and \"Chevalier de la Légion d’Honneur\" (2009).\n\nIn 1988-89 he served as president of the Modern Language Association.\n\nBrombert’s work is primarily on 19th and 20th century French literature, and also on the history of ideas; the theory of literary criticism; and comparative studies of Italian, Russian, and German narrative writers. In addition to his books, he has contributed to edited volumes and written journal articles on French writers from Pascal to Malraux, Sartre, and Camus, and on many non-French writers: Dostoevsky, Gogol, Tolstoy; Büchner, Max Frisch, Kafka, Thomas Mann; Giorgio Bassani, Primo Levi, Italo Svevo; J. M. Coetzee, Virginia Woolf.\n\nBrombert is also the author of a memoir, \"Trains of Thought: Memories of a Stateless Youth\" (New York: W.W. Norton, 2002; paperback, Anchor Books, 2004). He is currently working on a sequel, to be entitled \"The Sabbatical Years\".\nIn the words of a reviewer in \"The Wall Street Journal\" (December 27, 2013), “Victor Brombert...has been for more than 50 years one of the glories of humanistic scholarship at Yale and Princeton. Though a generation younger than scholarly patriarchs like Erich Auerbach and Leo Spitzer, Mr. Brombert has nonetheless shown himself comparably learned and cosmopolitan in his studies...”\n\nPrincipal Works of Literary Criticism:\n\n\nas Editor:\n\n\n"}
{"id": "934627", "url": "https://en.wikipedia.org/wiki?curid=934627", "title": "World3 nonrenewable resource sector", "text": "World3 nonrenewable resource sector\n\nThe world3 nonrenewable resource sector is the portion of the world3 model that simulates the nonrenewable resources. The World3 model was a simulation of human interaction with the environment designed in the 1970s to predict population and living standards over the course of the next 100 years. The nonrenewable resource sector of the world3 model was used to calculate the cost and usage rates of nonrenewable resources. In the context of this model, nonrenewable resources were resources that there is a finite amount of on Earth, such as iron ore, oil, or coal. This model assumes that regardless of how much money is spent on extraction, there is a finite limit for the amount of nonrenewable resources that can be extracted.\n\nThe model combines all possible nonrenewable resources into one aggregate variable, nonrenewable_resources. This combines both energy resources and non-energy resources. Examples of nonrenewable energy resources would include oil and coal. Examples of material nonrenewable resources would include aluminum and zinc. This assumption allows costless substitution between any nonrenewable resource. The model ignores differences between discovered resources and undiscovered resources.\n\nThe model assumes that as greater percentages of total nonrenewable resources are used, the amount of effort used to extract the nonrenewable resources will increase. \nThe way this cost is done is as a variable fraction_of_capital_allocated_to_obtaining_resources, or abbreviated fcaor. The way this variable is used is in the equation that calculates industrial output. Basically, it works as effective_output = industrial_capital*other_factors*(1-fcaor). This causes the amount of resources expended to depend on the amount of industrial capital, and not on the amount of resources consumed.\n\nThe consumption of nonrenewable resources is determined by a nonlinear function of the per capita industrial output. The higher the per capita industrial output, the higher the nonrenewable resource consumption.\n\nThe fraction of capital allocated to obtaining resources is dependent only on the nonrenewable_resource_fraction_remaining, or abbreviated nrfr. This variable is the current amount of non-renewable resources divided by the initial amount of non-renewable resources available. As such nrfr starts out as 1.0 and decreases as world3 runs. Fraction of capital allocated to obtaining resources is dependent on nrfr as interpolated values from the following table:\n\nQualitatively, this basically states that the relative amount of non-renewable resources decreases, the amount capital required to extract the resources increases. To more deeply examine this table requires examining the equation that it comes from, effective_output = industrial_capital*other_factors*(1-fcaor) So, if industrial capital and the other factors (described in the capital sector) are the same, then 1 unit of the effective capital when nrfr is 1.0 the effective output is 0.95 (= 1.0 * ( 1 - 0.05)). So, when nrfr is 0.5, the effective output is 0.90 (= 1.0 * (1 - 0.10)). Another useful way to look at this equation is to reverse it and see how much effective capital is required to get 1 unit of effective output (i.e. effective_output / (1 - fcaor) = effective_capital). So, when nrfr is 1.0, the effective capital required for 1 unit of effective output is 1.053 (=1.0/(1-0.05)), and when nrfr is 0.3, the effective capital required is 2 (=1.0/(1-0.5)). Lastly is looking at the relative cost required for obtaining the resources. This based on the fact that it requires 1/19 of a unit of effective capital extra when the nrfr is 1.0. So, (effective capital required - 1.0) / (1 / 19) will give the relative cost of obtaining the resources compared to the cost of obtaining them when nrfr was 1.0. For example, when nrfr is 0.3, the effective capital required is 2.0, and 1.0 of that is for obtaining resources. So, the cost of obtaining the resources is (2.0 - 1.0) / ( 1 / 19) or 1.0*19 or 19 times the cost when nrfr was 1.0. Here is a table showing these calculations for all the values:\n\nThe world3 model does not directly link industrial output to resource utilization. Instead, the industrial output per capita is calculated, and that is used to determine resource usage per capita. This is then multiplied by the total population to determine the total resource consumption. \nPer capita resource utilization multiplier (PCRUM) and Industrial Output per Capita (IOPC)\n\n"}
