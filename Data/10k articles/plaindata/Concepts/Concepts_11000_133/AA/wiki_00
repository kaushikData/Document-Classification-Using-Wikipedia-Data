{"id": "53695544", "url": "https://en.wikipedia.org/wiki?curid=53695544", "title": "Access to public information in Cyprus", "text": "Access to public information in Cyprus\n\nAccess to public information and freedom of information (FOI) refer to the right of access to information held by public bodies also known as \"right to know\". Access to public information is considered of fundamental importance for the effective functioning of democratic systems, as it enhances governments' and public officials' accountability, boosting people participation and allowing their informed participation into public life. The fundamental premise of the right of access to public information is that the information held by governmental institutions is in principle public and may be concealed only on the basis of legitimate reasons which should be detailed in the law.\n\nThe right of access to information in Cyprus is guaranteed in constitutional provisions on freedom of expression but the legal framework is seriously flawed, with no law on access to information in the Southern Republic of Cyprus of the country and a law that falls below Council of Europe standards in the Northern part of Cyprus. The right to access to public information is provided in different ways in the two parts of the island, in which Cyprus is \"de facto\" divided.\n\nAs to 2011, a research by the Open Cyprus Project showed that there was a level of 75% of administrative silence island-wide, in response to information requests. Over half of the respondents to this survey stated that, in practice, access to key documents is not possible.\n\nSince late 2013, a draft law on the Right to Access Public Information is being discussed in the Parliament of the (Southern) Republic of Cyprus. \n\nOn 22 December 2017 the law has finally been approved (Law number 184(I)/2017).\n\nThe right to access public information is granted by Article No. 24 of the Constitution of Northern Cyprus. Even if the Constitutional article echoes Article No. 10 of the European Convention on Human Rights (ECHR), experts say that the possibilities to restrict the fundamental right of access to public information are provided in an overbroad manner. Specifically, Article No. 10 (2) ECHR says that the conditions and restrictions imposed on the right to freedom of expression have to be “necessary in a democratic society”. Instead, even if the Constitution of Northern Cyprus- under Article No. 24- provides for a test of whether a restriction to such a right is necessary, it does not specify the key qualification of being necessary in a democratic society, as required by Article 10 of the ECHR.\n\nThe relevant laws regulating the right to access public information in the Northern part of Cyprus are: the Right to Access Information Law No. 12 of 2006; the Public Officials Law No. 7 of 1979; the State Procurement Regulation; the Rules and Procedures of the Parliament and the Personal Data Protection Act No. 89 of 2007.\n\nThe Right to Access Information Law obliges “public bodies” to process all information requests, regardless of the means by which they are submitted.\n\nA 2011 research recommends that, with regard to the Access to Information Law in the Northern part of the country, the scope of the law should be extended to all classes of information held by public bodies. Also, according to experts, an implementing regulation should be approved, clarifying the administrative procedure to request and receive information. Finally, the Access to Information Assessment Commission foreseen by the law has not been appointed yet.\n\nThe Cypriot government couldn't sign or ratify the 2009 Council of Europe Convention on Access to Official Documents as it did not have a transparency law that meets the Convention’s minimum standard. Until 2017, Cyprus was the only country in Europe, other than Luxembourg, without a law guaranteeing the right of access to information.. But as of 2018, the law has been published (Law 184(I)/2017)\n\nThe relevant laws with regard to the right to access public information are the following:\nAccording to experts, these non-specific laws that might grant access to some classes of information, such as environmental information or archives, require amendments to comply with the basic international and European standards.\n\nSince April 2014, the Republic of Cyprus has been holding public consultations aimed at drafting a Freedom of Information Law, which as to 2017 has to be enacted. In October 2015, the Cypriot Justice Minister Ionas Nicolaou expressed his commitment to adopt a strong access to information (Freedom of Information) law that will be “one of the best in the European Union”.\n\nAgain, in February 2017, the association Access Info Europe has addressed the Cypriot Parliament asking to review such a draft. In particular, Access Info Europe advocated for the removal of the fees for making information requests and for cutting down the possible 60 days extension for complex requests which has been included in the draft. Moreover, according to Access Info, also the regime of possible exceptions needs to be reviewed. Currently, the draft includes absolute exceptions, with no public interest test. Furthermore, under the international and European transparency standards, when disclosure of information is denied requesters must be given clear reasons as to why the exception has been applied.\n\nIn March 2017, the recommendations elaborated by Access Info Europe were sent to the Cypriot Parliament Legal Committee.\n\nSince March 2015, Citizen Service Centres have been established all over the island in order to provide multiple services as an alternative channel for dealing with public agencies/organizations. They work through a single 4-digit number (1434) which citizens can call in order to obtain information with respect to approximately 90 services offered by the CSCs, such as eligibility criteria for submitting an application, documents that need to be submitted, fees charged etc. Through this Call Centre, citizens can also submit applications for 18 services relating to the issuing of specific documents/licenses/certificates etc.\n\n"}
{"id": "8286430", "url": "https://en.wikipedia.org/wiki?curid=8286430", "title": "Adaptive algorithm", "text": "Adaptive algorithm\n\nAn adaptive algorithm is an algorithm that changes its behavior at the time it is run, based on information available and on \"a priori\" defined reward mechanism (or criterion). Such information could be the story of recently received data, information on the available computational resources, or other run-time acquired (or \"a priori\" known) information related to the environment in which it operates.\n\nAmong the most used adaptive algorithms is the Widrow-Hoff’s least mean squares (LMS), which represents a class of stochastic gradient-descent algorithms used in adaptive filtering and machine learning. In adaptive filtering the LMS is used to mimic a desired filter by finding the filter coefficients that relate to producing the least mean square of the error signal (difference between the desired and the actual signal).\n\nFor example, stable partition, using no additional memory is \"O\"(\"n\" lg \"n\") but given \"O\"(\"n\") memory, it can be \"O\"(\"n\") in time. As implemented by the C++ Standard Library, codice_1 is adaptive and so it acquires as much memory as it can get (up to what it would need at most) and applies the algorithm using that available memory. Another example is adaptive sort, whose behavior changes upon the presortedness of its input.\n\nAn example of an adaptive algorithm in radar systems is the constant false alarm rate (CFAR) detector.\n\nIn machine learning and optimization, many algorithms are adaptive or have adaptive variants, which usually means that the algorithm parameters are automatically adjusted according to statistics about the optimisation thus far (e.g. the rate of convergence). Examples include adaptive simulated annealing, adaptive coordinate descent, AdaBoost, and adaptive quadrature.\n\nIn data compression, adaptive coding algorithms such as Adaptive Huffman coding or Prediction by partial matching can take a stream of data as input, and adapt their compression technique based on the symbols that they have already encountered.\n\nIn signal processing, the Adaptive Transform Acoustic Coding (ATRAC) codec used in MiniDisc recorders is called \"adaptive\" because the window length (the size of an audio \"chunk\") can change according to the nature of the sound being compressed, to try to achieve the best-sounding compression strategy.\n\n"}
{"id": "2849785", "url": "https://en.wikipedia.org/wiki?curid=2849785", "title": "Anguish", "text": "Anguish\n\nAnguish is derived from the Latin word angustiae, meaning extreme pain, distress or anxiety. The feeling of suffering from anguish is typically preceded by a tragedy or event that has a profound meaning to the being in question. Anguish can be felt physically or mentally (often referred to as emotional distress). Anguish is also a term used in philosophy, often as a translation from the Latin word for \"angst\". It is a paramount feature of existentialist philosophy, in which anguish is often understood as the experience of an utterly free being in a world with zero absolutes (existential despair). In the theology of Kierkegaard, it refers to a being with total free will who is in a constant state of spiritual fear that his freedom will lead him to fall short of the standards that God has laid out for them.\n\nA study done at the University of Princeton’s Center for the Study of Brain, Mind, and Behavior suggests that the presence of the emotion influences the decisions made. The study uses a functional magnetic resonance imaging machine to measure the brain waves of a subject when put into a difficult position. In this particular session, the subject was presented with a situation where she had to decide the fate of five people versus one person by the flip of a switch, and then decide the fate of five people versus one person by the physical acting of condemning a man to his death. The results of the fMRI stated that the decision of death by switch was easier than the decision of physically pushing a man to his death. It is theorized that the participant is being subjected to the emotion of anguish when faced with future possibility of physical condemning another person and therefore the brain enforces an “emotional block” to encourage the cessation of this behavior.\n\nAnguish is made up of fear, distress, anxiety and panic. These stressors cause an enormous amount of dissonance, which could then lead to issues of mental health. While taken literally anguish may be defined as a physical event, but it may be extrapolated to an event of one’s psyche. It has been found that the anguish of a significant change in the way a young student lives (i.e. their new responsibilities, being on their own, multiple deadlines etc.) has contributed to significantly increased rates of college students suffering from anxiety and depression.\n\nMusic has a particular way of eliciting emotions into its listeners. The notes heard by one person may have a different connotation than another person hearing the same notes. Upon hearing a song, symphony, or sonnet filled with anguish, one might begin to reflect upon their own life and experiences that coincide with the notes, thereby bringing repressed memories beyond subconscious to our salient mind.\n\nKierkegaard views anguish as the same as suffering. Everyone wants to find the \"truth\" but it takes anguish and suffering to \"appropriate\" the truth. Kierkegaard put it this way in 1847 and 1850. \n\nIn the teachings of Sartre, anguish is seen when an utterly captured being realizes the unpredictability of his or her action. For example, when walking along a cliff, you would feel anguish to know that you have the freedom to throw yourself down to your imminent death.\n"}
{"id": "367577", "url": "https://en.wikipedia.org/wiki?curid=367577", "title": "Antipodal point", "text": "Antipodal point\n\nIn mathematics, the antipodal point of a point on the surface of a sphere is the point which is diametrically opposite to it — so situated that a line drawn from the one to the other passes through the center of the sphere and forms a true diameter.\n\nThis term applies to opposite points on a circle or any n-sphere.\n\nAn antipodal point is sometimes called an antipode, a back-formation from the Greek loan word \"antipodes\", which originally meant \"opposite the feet\".\n\nIn mathematics, the concept of \"antipodal points\" is generalized to spheres of any dimension: two points on the sphere are antipodal if they are opposite \"through the centre\"; for example, taking the centre as origin, they are points with related vectors v and −v. On a circle, such points are also called diametrically opposite. In other words, each line through the centre intersects the sphere in two points, one for each ray out from the centre, and these two points are antipodal.\n\nThe Borsuk–Ulam theorem is a result from algebraic topology dealing with such pairs of points. It says that any continuous function from \"S\" to R maps some pair of antipodal points in \"S\" to the same point in R. Here, \"S\" denotes the \"n\"-dimensional sphere in (\"n\" + 1)-dimensional space (so the \"ordinary\" sphere is \"S\" and a circle is \"S\").\n\nThe antipodal map \"A\" : \"S\" → \"S\", defined by \"A\"(\"x\") = −\"x\", sends every point on the sphere to its antipodal point. It is homotopic to the identity map if \"n\" is odd, and its degree is (−1).\n\nIf one wants to consider antipodal points as identified, one passes to projective space (see also projective Hilbert space, for this idea as applied in quantum mechanics).\n\nAn antipodal pair of a convex polygon is a pair of 2 points admitting 2 infinite parallel lines being tangent to both points included in the antipodal without crossing any other line of the convex polygon.\n\n"}
{"id": "35626853", "url": "https://en.wikipedia.org/wiki?curid=35626853", "title": "Bertrand–Edgeworth model", "text": "Bertrand–Edgeworth model\n\nIn microeconomics, the Bertrand–Edgeworth model of price-setting oligopoly looks at what happens when there is a homogeneous product (i.e. consumers want to buy from the cheapest seller) where there is a limit to the output of firms which they are willing and able to sell at a particular price. This differs from the Bertrand competition model where it is assumed that firms are willing and able to meet all demand. The limit to output can be considered as a physical capacity constraint which is the same at all prices (as in Edgeworth’s work), or to vary with price under other assumptions.\n\nJoseph Louis François Bertrand (1822–1900) developed the model of Bertrand competition in oligopoly. This approach was based on the assumption that there are at least two firms producing a homogenous product with constant marginal cost (this could be constant at some positive value, or with zero marginal cost as in Cournot). Consumers buy from the cheapest seller. The Bertrand–Nash equilibrium of this model is to have all (or at least two) firms setting the price equal to marginal cost. The argument is simple: if one firm sets a price above marginal cost then another firm can undercut it by a small amount (often called \"epsilon undercutting\", where epsilon represents an arbitrarily small amount) so that the equilibrium is zero (this is sometimes called the Bertrand paradox).\n\nThe Bertrand approach assumes that firms are willing and able to supply all demand: there is no limit to the amount that they can produce or sell. Francis Ysidro Edgeworth considered the case where there is a limit to what firms can sell (a capacity constraint): he showed that if there is a fixed limit to what firms can sell, then there may exist no pure-strategy Nash equilibrium (this is sometimes called the Edgeworth paradox).\n\nMartin Shubik developed the Bertrand–Edgeworth model to allow for the firm to be willing to supply only up to its profit maximizing output at the price which it set (under profit maximization this occurs when marginal cost equals price). He considered the case of strictly convex costs, where marginal cost is increasing in output. Shubik showed that if a Nash equilibrium exists, it must be the perfectly competitive price (where demand equals supply, and all firms set price equal to marginal cost). However, this can only happen if market demand is infinitely elastic (horizontal) at the competitive price. In general, as in the Edgeworth paradox, no pure-strategy Nash equilibrium will exist. Huw Dixon showed that in general a mixed strategy Nash equilibrium will exist when there are convex costs. Dixon’s proof used the Existence Theorem of Partha Dasgupta and Eric Maskin. Under Dixon's assumption of (weakly) convex costs, marginal cost will be non-decreasing. This is consistent with a cost function where marginal cost is flat for a range of outputs, marginal cost is smoothly increasing, or indeed where there is a kink in total cost so that marginal cost makes a discontinuous jump upwards.\n\nThere have been several responses to the non-existence of pure-strategy equilibrium identified by Francis Ysidro Edgeworth and Martin Shubik. Whilst the existence of mixed-strategy equilibrium was demonstrated by Huw Dixon, it has not proven easy to characterize what the equilibrium actually looks like. However, Allen and Hellwig were able to show that in a large market with many firms, the average price set would tend to the competitive price.\n\nIt has been argued that non-pure strategies are not plausible in the context of the Bertrand–Edgworth model. Alternative approaches have included:\n\n\n"}
{"id": "30780965", "url": "https://en.wikipedia.org/wiki?curid=30780965", "title": "Bidirectional transformation", "text": "Bidirectional transformation\n\nIn computer programming, bidirectional transformations (bx) are programs in which a single piece of code can be run in several ways, such that the same data are sometimes considered as input, and sometimes as output. For example, a bx run in the forward direction might transform input I into output O, while the same bx run backward would take as input versions of I and O and produce a new version of I as its output.\n\nBidirectional model transformations are an important special case in which a model is input to such a program.\n\nSome bidirectional languages are \"bijective\". The bijectivity of a language is a severe restriction of its bidirectionality, because a bijective language is merely relating two different ways to present the very same information.\n\nMore general is a lens language, in which there is a distinguished forward direction (\"get\") that takes a concrete input to an abstract output, discarding some information in the process: the concrete state includes all the information that is in the abstract state, and usually some more. The backward direction (\"put\") takes a concrete state and an abstract state and computes a new concrete state. Lenses are required to obey certain conditions to ensure sensible behaviour.\n\nThe most general case is that of symmetric bidirectional transformations. Here the two states that are related typically share some information, but each also includes some information that is not included in the other.\n\nBidirectional transformations can be used to:\n\n\nA bidirectional program which obeys certain round-trip laws is called a lens.\n\n\n\n"}
{"id": "32524935", "url": "https://en.wikipedia.org/wiki?curid=32524935", "title": "Cebuana Lhuillier", "text": "Cebuana Lhuillier\n\nCebuana Lhuillier Pawnshop, commonly known as Cebuana, is a Philippine-based pawnshop, and the flagship brand of PJ Lhuillier Group of Companies. Jean Henri Lhuillier is the current President of CEO of Cebuana.\nCebuana Lhuillier is a non-banking financial institution provides pawn-brokering, money remittance, insurance, bills payment, remit-to-account, corporate payout, collections, and e-loading services.\n\nCebuana Lhuillier Pawnshop began with four pawnshop outlets in Metro Manila in the mid-1980s.\n\nIn 1968, Henry Lhuillier's son, Philippe Jones Lhuillier went forth and opened the first Lhuillier pawnshop at Libertad Street in Pasay under the trade name Agencia Cebuana.\n\nIt traces its roots in Cebu, where then French Consul to the Philippines, Henry Lhuillier established his first chain of Agencias in 1935. Throughout the 70’s and 80’s, Philippe Jones Lhuillier opened more agencias in Metro Manila.\n\nThe company pursued further nationwide expansion in 1987 and adopted the trade name, “Cebuana Lhuillier,” which it still carries to this day.\nIn 1998, Philippe Jones Lhuillier was appointed the Philippine Ambassador to Italy. Philippe Jones Lhuillier’s son, Jean Henri Lhuillier, took the helm and became Cebuana Lhuillier Pawnshop’s President and Chief Executive Officer in the same year.\n\nJean Henri Lhuillier introduced in Cebuana Lhuillier Pawnshop’s auxiliary services remittance, insurance, bills payment, money changer, e-load, remit-to-account, corporate payput, and collections service.\n\nIt also became the first pawnshop and money remittance company to offer a membership rewards program for its loyal clients through the 24k card loyalty program in 2010. On the following year, Cebuana Lhuillier branches hit the 1,500 mark. The 24k loyalty card also had its 2,500,000th member in 2012, and just recently reached five million members in 2014. In the same year, Cebuana Lhuillier started to reach out to potential customers to areas with limited access through its Cebuana Lhuillier On Wheels.\n\nCebuana Lhuillier Pawnshop, through its President and CEO Jean Henri Lhuillier, is involved in sports development particularly basketball, softball, and tennis. Cebuana Lhuillier Pawnshop owns a team in the PBA D-League, the Cebuana Lhuillier Gems. CL is also organized tennis tournaments such as Cebuana Lhuillier Age Group Tennis.\n\nJean Henri Lhuillier is the manager of the Philippine Davis Cup Team, Chairman of the Board of the Philippine Tennis Association (PhilTA), and is the president of Amateur Softball Association of the Philippines (governed by the International Softball Federation).\n\nCebuana Lhuillier also has its own foundation, the Cebuana Lhuillier Foundation Inc., which conducts medical missions, relief operations for disaster-stricken areas, and feedings programs. It also has a nationwide scholarship program and Alternative Learning System Community Learning Centers.\n\n"}
{"id": "29171044", "url": "https://en.wikipedia.org/wiki?curid=29171044", "title": "Collapsus", "text": "Collapsus\n\nCollapsus is a project that combines animation, interactive fiction, and documentary film. This story follows how the impending energy crisis affects ten young people, while international powers battle with political dissension and a fearful population during transition from Fossil fuel to alternative fuels. Set in the near future, Collapsus was initialized to raise awareness of the global issue of peak oil.\n\nThe project combines Video blogging, interactive maps, fictional newscasts, live action footage, and animation to immerse the player in the narrative, an example of Transmedia storytelling. The project requires the player to access and assess additional information and make decisions about the world's energy production at both a national and global scale.\n\nCollapsus was developed by Submarine Channel, with the Dutch public broadcaster VPRO, who produced the associated Energy Transition documentary the project is based on. Collapsus is directed by Tommy Pallotta, who produced A Scanner Darkly (film) and Waking Life.\n\nCollapsus blends live action and the rotoscoping animation technique, co-developed by Pallotta, and used in Waking Life and A Scanner Darkly (film).\n"}
{"id": "1678406", "url": "https://en.wikipedia.org/wiki?curid=1678406", "title": "Communalism (South Asia)", "text": "Communalism (South Asia)\n\nCommunalism is a term used in South Asia to denote attempts to construct religious or ethnic identity, incite strife between people identified as different communities, and to stimulate communal violence between those groups. It derives from history, differences in beliefs, and tensions between the communities.\n\nThe term communalism was constructed by the British colonial authorities as it wrestled to manage violence between religious, ethnic and disparate groups in its colonies, particularly Africa and South Asia, in early 20th century.\n\nCommunalism is not unique to South Asia. It is found in Africa, the Americas, Asia, Europe and Australia.\n\nCommunalism is a significant social issue in Bangladesh, India, Pakistan and Sri Lanka.\n\nThe term came into use in early 20th century during the British colonial rule, where the rulers saw India divided into several communities and attempted to placate separate \"communal\" interests. The Hindu Mahasabh and the All-India Muslim League represented such communal interests, whereas Indian National Congress represented an overarching \"nationalist\" vision. In the run up to independence in 1947, communalism and nationalism came to be competing ideologies and led to the division of British India into the Republics of India and Pakistan. The bloody Partition violence gave a clear sense to every one what communalism leads to, and it has since been frowned upon in India.\n\nCommunal conflicts between religious communities, especially Hindus and Muslims, have been a recurring occurrence in independent India, occasionally leading to serious inter-communal violence.\n\n\nExamples of communalist violence, with strong motivations based on religious identity include:\nIncidents of \"communal violence\" cannot clearly be separated by incidents of [[terrorism]]. \"Communal violence\" tends to refer to mob killings, while terrorism describes concerted attacks by small groups of militants (see [[definition of terrorism]]). See also .\n\n\n\n\n[[Category:Hate crime|Communal violence]]\n[[Category:Political terminology in India]]\n[[Category:Social issues in India]]\n[[Category:Religion and violence]]\n[[Category:Sectarian violence]]"}
{"id": "5664", "url": "https://en.wikipedia.org/wiki?curid=5664", "title": "Consciousness", "text": "Consciousness\n\nConsciousness is the state or quality of awareness or of being aware of an external object or something within oneself. It has been defined variously in terms of sentience, awareness, qualia, subjectivity, the ability to experience or to feel, wakefulness, having a sense of selfhood or soul, the fact that there is something \"that it is like\" to \"have\" or \"be\" it, and the executive control system of the mind. Despite the difficulty in definition, many philosophers believe that there is a broadly shared underlying intuition about what consciousness is. As Max Velmans and Susan Schneider wrote in \"The Blackwell Companion to Consciousness\": \"Anything that we are aware of at a given moment forms part of our consciousness, making conscious experience at once the most familiar and most mysterious aspect of our lives.\"\n\nWestern philosophers, since the time of Descartes and Locke, have struggled to comprehend the nature of consciousness and identify its essential properties. Issues of concern in the philosophy of consciousness include whether the concept is fundamentally coherent; whether consciousness can ever be explained mechanistically; whether non-human consciousness exists and if so how it can be recognized; how consciousness relates to language; whether consciousness can be understood in a way that does not require a dualistic distinction between mental and physical states or properties; and whether it may ever be possible for computing machines like computers or robots to be conscious, a topic studied in the field of artificial intelligence.\n\nThanks to developments in technology over the past few decades, consciousness has become a significant topic of interdisciplinary research in cognitive science, with significant contributions from fields such as psychology, anthropology, neuropsychology and neuroscience. The primary focus is on understanding what it means biologically and psychologically for information to be present in consciousness—that is, on determining the neural and psychological correlates of consciousness. The majority of experimental studies assess consciousness in humans by asking subjects for a verbal report of their experiences (e.g., \"tell me if you notice anything when I do this\"). Issues of interest include phenomena such as subliminal perception, blindsight, denial of impairment, and altered states of consciousness produced by alcohol and other drugs, or spiritual or meditative techniques.\n\nIn medicine, consciousness is assessed by observing a patient's arousal and responsiveness, and can be seen as a continuum of states ranging from full alertness and comprehension, through disorientation, delirium, loss of meaningful communication, and finally loss of movement in response to painful stimuli. Issues of practical concern include how the presence of consciousness can be assessed in severely ill, comatose, or anesthetized people, and how to treat conditions in which consciousness is impaired or disrupted. The degree of consciousness is measured by standardized behavior observation scales such as the Glasgow Coma Scale.\n\nThe origin of the modern concept of consciousness is often attributed to John Locke's \"Essay Concerning Human Understanding\", published in 1690. Locke defined consciousness as \"the perception of what passes in a man's own mind\". His essay influenced the 18th-century view of consciousness, and his definition appeared in Samuel Johnson's celebrated \"Dictionary\" (1755).\n\"Consciousness\" (French: \"conscience\") is also defined in the 1753 volume of Diderot and d'Alembert's Encyclopédie, as \"the opinion or internal feeling that we ourselves have from what we do.\" \n\nThe earliest English language uses of \"conscious\" and \"consciousness\" date back, however, to the 1500s. The English word \"conscious\" originally derived from the Latin \"conscius\" (\"con-\" \"together\" and \"scio\" \"to know\"), but the Latin word did not have the same meaning as our word—it meant \"knowing with\", in other words \"having joint or common knowledge with another\". There were, however, many occurrences in Latin writings of the phrase \"conscius sibi\", which translates literally as \"knowing with oneself\", or in other words \"sharing knowledge with oneself about something\". This phrase had the figurative meaning of \"knowing that one knows\", as the modern English word \"conscious\" does. In its earliest uses in the 1500s, the English word \"conscious\" retained the meaning of the Latin \"conscius\". For example, Thomas Hobbes in \"Leviathan\" wrote: \"Where two, or more men, know of one and the same fact, they are said to be Conscious of it one to another.\" The Latin phrase \"conscius sibi\", whose meaning was more closely related to the current concept of consciousness, was rendered in English as \"conscious to oneself\" or \"conscious unto oneself\". For example, Archbishop Ussher wrote in 1613 of \"being so conscious unto myself of my great weakness\". Locke's definition from 1690 illustrates that a gradual shift in meaning had taken place.\n\nA related word was \"\", which primarily means moral conscience. In the literal sense, \"conscientia\" means knowledge-with, that is, shared knowledge. The word first appears in Latin juridical texts by writers such as Cicero. Here, \"conscientia\" is the knowledge that a witness has of the deed of someone else. René Descartes (1596–1650) is generally taken to be the first philosopher to use \"conscientia\" in a way that does not fit this traditional meaning. Descartes used \"conscientia\" the way modern speakers would use \"conscience\". In \"Search after Truth\" (\"\", Amsterdam 1701) he says \"conscience or internal testimony\" (\"conscientiâ, vel interno testimonio\").\n\nThe dictionary meanings of the word \"consciousness\" extend through several centuries and several associated related meanings. These have ranged from formal definitions to definitions attempting to capture the less easily captured and more debated meanings and usage of the word.\n\nOne formal definition indicating the range of these related meanings is given in \"Webster's Third New International Dictionary\" stating that \"consciousness\" is:\n\nThe Cambridge Dictionary defines consciousness as \"\"the state of understanding and realizing something.\"\nThe Oxford Living Dictionary defines consciousness as \"The state of being aware of and responsive to one's surroundings.\", \"A person's awareness or perception of something.\" and \"The fact of awareness by the mind of itself and the world.\"\"\n\nMost definitions include awareness, but some include a more general state of being.\n\nThe philosophy of mind has given rise to many stances regarding consciousness. The \"Routledge Encyclopedia of Philosophy\" in 1998 defines consciousness as follows:\nIn a more skeptical definition of \"consciousness\", Stuart Sutherland has exemplified some of the difficulties in fully ascertaining all of its cognate meanings in his entry for the 1989 version of the \"Macmillan Dictionary of Psychology\":\nMost writers on the philosophy of consciousness have been concerned with defending a particular point of view, and have organized their material accordingly. For surveys, the most common approach is to follow a historical path by associating stances with the philosophers who are most strongly associated with them, for example Descartes, Locke, Kant, etc. An alternative is to organize philosophical stances according to basic issues.\n\nPhilosophers and non-philosophers differ in their intuitions about what consciousness is. While most people have a strong intuition for the existence of what they refer to as consciousness, skeptics argue that this intuition is false, either because the concept of consciousness is intrinsically incoherent, or because our intuitions about it are based in illusions. Gilbert Ryle, for example, argued that traditional understanding of consciousness depends on a Cartesian dualist outlook that improperly distinguishes between mind and body, or between mind and world. He proposed that we speak not of minds, bodies, and the world, but of individuals, or persons, acting in the world. Thus, by speaking of \"consciousness\" we end up misleading ourselves by thinking that there is any sort of thing as consciousness separated from behavioral and linguistic understandings. More generally, many philosophers and scientists have been unhappy about the difficulty of producing a definition that does not involve circularity or fuzziness.\n\nMany philosophers have argued that consciousness is a unitary concept that is understood intuitively by the majority of people in spite of the difficulty in defining it. Others, though, have argued that the level of disagreement about the meaning of the word indicates that it either means different things to different people (for instance, the objective versus subjective aspects of consciousness), or else is an umbrella term encompassing a variety of distinct meanings with no simple element in common.\n\nNed Block proposed a distinction between two types of consciousness that he called \"phenomenal\" (P-consciousness) and \"access\" (A-consciousness). P-consciousness, according to Block, is simply raw experience: it is moving, colored forms, sounds, sensations, emotions and feelings with our bodies' and responses at the center. These experiences, considered independently of any impact on behavior, are called qualia. A-consciousness, on the other hand, is the phenomenon whereby information in our minds is accessible for verbal report, reasoning, and the control of behavior. So, when we perceive, information about what we perceive is access conscious; when we introspect, information about our thoughts is access conscious; when we remember, information about the past is access conscious, and so on. Although some philosophers, such as Daniel Dennett, have disputed the validity of this distinction, others have broadly accepted it. David Chalmers has argued that A-consciousness can in principle be understood in mechanistic terms, but that understanding P-consciousness is much more challenging: he calls this the hard problem of consciousness.\n\nSome philosophers believe that Block's two types of consciousness are not the end of the story. William Lycan, for example, argued in his book \"Consciousness and Experience\" that at least eight clearly distinct types of consciousness can be identified (organism consciousness; control consciousness; consciousness \"of\"; state/event consciousness; reportability; introspective consciousness; subjective consciousness; self-consciousness)—and that even this list omits several more obscure forms.\n\nThere is also debate over whether or not a-consciousness and p-consciousness always co-exist or if they can exist separately. Although p-consciousness without a-consciousness is more widely accepted, there have been some hypothetical examples of A without P. Block for instance suggests the case of a “zombie” that is computationally identical to a person but without any subjectivity. However, he remains somewhat skeptical concluding \"I don’t know whether there are any actual cases of A-consciousness without P-consciousness, but I hope I have illustrated their conceptual possibility.\" \n\nMental processes (such as consciousness) and physical processes (such as brain events) seem to be correlated: but what is the basis of this connection and correlation between what seem to be two very different kinds of processes?\n\nThe first influential philosopher to discuss this question specifically was Descartes, and the answer he gave is known as Cartesian dualism. Descartes proposed that consciousness resides within an immaterial domain he called res cogitans (the realm of thought), in contrast to the domain of material things, which he called res extensa (the realm of extension). He suggested that the interaction between these two domains occurs inside the brain, perhaps in a small midline structure called the pineal gland.\n\nAlthough it is widely accepted that Descartes explained the problem cogently, few later philosophers have been happy with his solution, and his ideas about the pineal gland have especially been ridiculed. However, no alternative solution has gained general acceptance. Proposed solutions can be divided broadly into two categories: dualist solutions that maintain Descartes' rigid distinction between the realm of consciousness and the realm of matter but give different answers for how the two realms relate to each other; and monist solutions that maintain that there is really only one realm of being, of which consciousness and matter are both aspects. Each of these categories itself contains numerous variants. The two main types of dualism are substance dualism (which holds that the mind is formed of a distinct type of substance not governed by the laws of physics) and property dualism (which holds that the laws of physics are universally valid but cannot be used to explain the mind). The three main types of monism are physicalism (which holds that the mind consists of matter organized in a particular way), idealism (which holds that only thought or experience truly exists, and matter is merely an illusion), and neutral monism (which holds that both mind and matter are aspects of a distinct essence that is itself identical to neither of them). There are also, however, a large number of idiosyncratic theories that cannot cleanly be assigned to any of these schools of thought.\n\nSince the dawn of Newtonian science with its vision of simple mechanical principles governing the entire universe, some philosophers have been tempted by the idea that consciousness could be explained in purely physical terms. The first influential writer to propose such an idea explicitly was Julien Offray de La Mettrie, in his book \"Man a Machine\" (\"L'homme machine\"). His arguments, however, were very abstract. The most influential modern physical theories of consciousness are based on psychology and neuroscience. Theories proposed by neuroscientists such as Gerald Edelman and Antonio Damasio, and by philosophers such as Daniel Dennett, seek to explain consciousness in terms of neural events occurring within the brain. Many other neuroscientists, such as Christof Koch, have explored the neural basis of consciousness without attempting to frame all-encompassing global theories. At the same time, computer scientists working in the field of artificial intelligence have pursued the goal of creating digital computer programs that can simulate or embody consciousness.\n\nA few theoretical physicists have argued that classical physics is intrinsically incapable of explaining the holistic aspects of consciousness, but that quantum theory may provide the missing ingredients. Several theorists have therefore proposed quantum mind (QM) theories of consciousness. Notable theories falling into this category include the holonomic brain theory of Karl Pribram and David Bohm, and the Orch-OR theory formulated by Stuart Hameroff and Roger Penrose. Some of these QM theories offer descriptions of phenomenal consciousness, as well as QM interpretations of access consciousness. None of the quantum mechanical theories has been confirmed by experiment. Recent publications by G. Guerreshi, J. Cia, S. Popescu, and H. Briegel could falsify proposals such as those of Hameroff, which rely on quantum entanglement in protein. At the present time many scientists and philosophers consider the arguments for an important role of quantum phenomena to be unconvincing.\n\nApart from the general question of the \"hard problem\" of consciousness, roughly speaking, the question of how mental experience arises from a physical basis, a more specialized question is how to square the subjective notion that we are in control of our decisions (at least in some small measure) with the customary view of causality that subsequent events are caused by prior events. The topic of free will is the philosophical and scientific examination of this conundrum.\n\nMany philosophers consider experience to be the essence of consciousness, and believe that experience can only fully be known from the inside, subjectively. But if consciousness is subjective and not visible from the outside, why do the vast majority of people believe that other people are conscious, but rocks and trees are not? This is called the problem of other minds. It is particularly acute for people who believe in the possibility of philosophical zombies, that is, people who think it is possible in principle to have an entity that is physically indistinguishable from a human being and behaves like a human being in every way but nevertheless lacks consciousness. Related issues have also been studied extensively by Greg Littmann of the University of Illinois. and Colin Allen a professor at Indiana University regarding the literature and research studying artificial intelligence in androids.\n\nThe most commonly given answer is that we attribute consciousness to other people because we see that they resemble us in appearance and behavior; we reason that if they look like us and act like us, they must be like us in other ways, including having experiences of the sort that we do. There are, however, a variety of problems with that explanation. For one thing, it seems to violate the principle of parsimony, by postulating an invisible entity that is not necessary to explain what we observe. Some philosophers, such as Daniel Dennett in an essay titled \"The Unimagined Preposterousness of Zombies\", argue that people who give this explanation do not really understand what they are saying. More broadly, philosophers who do not accept the possibility of zombies generally believe that consciousness is reflected in behavior (including verbal behavior), and that we attribute consciousness on the basis of behavior. A more straightforward way of saying this is that we attribute experiences to people because of what they can \"do\", including the fact that they can tell us about their experiences.\n\nThe topic of animal consciousness is beset by a number of difficulties. It poses the problem of other minds in an especially severe form, because non-human animals, lacking the ability to express human language, cannot tell us about their experiences. Also, it is difficult to reason objectively about the question, because a denial that an animal is conscious is often taken to imply that it does not feel, its life has no value, and that harming it is not morally wrong. Descartes, for example, has sometimes been blamed for mistreatment of animals due to the fact that he believed only humans have a non-physical mind. Most people have a strong intuition that some animals, such as cats and dogs, are conscious, while others, such as insects, are not; but the sources of this intuition are not obvious, and are often based on personal interactions with pets and other animals they have observed.\n\nPhilosophers who consider subjective experience the essence of consciousness also generally believe, as a correlate, that the existence and nature of animal consciousness can never rigorously be known. Thomas Nagel spelled out this point of view in an influential essay titled \"What Is it Like to Be a Bat?\". He said that an organism is conscious \"if and only if there is something that it is like to be that organism — something it is like \"for\" the organism\"; and he argued that no matter how much we know about an animal's brain and behavior, we can never really put ourselves into the mind of the animal and experience its world in the way it does itself. Other thinkers, such as Douglas Hofstadter, dismiss this argument as incoherent. Several psychologists and ethologists have argued for the existence of animal consciousness by describing a range of behaviors that appear to show animals holding beliefs about things they cannot directly perceive — Donald Griffin's 2001 book \"Animal Minds\" reviews a substantial portion of the evidence.\n\nOn July 7, 2012, eminent scientists from different branches of neuroscience gathered at the University of Cambridge to celebrate the Francis Crick Memorial Conference, which deals with consciousness in humans and pre-linguistic consciousness in nonhuman animals. After the conference, they signed in the presence of Stephen Hawking, the 'Cambridge Declaration on Consciousness', which summarizes the most important findings of the survey:\n\n\"We decided to reach a consensus and make a statement directed to the public that is not scientific. It's obvious to everyone in this room that animals have consciousness, but it is not obvious to the rest of the world. It is not obvious to the rest of the Western world or the Far East. It is not obvious to the society.\"\n\n\"Convergent evidence indicates that non-human animals [...], including all mammals and birds, and other creatures, [...] have the necessary neural substrates of consciousness and the capacity to exhibit intentional behaviors.\"\n\nThe idea of an artifact made conscious is an ancient theme of mythology, appearing for example in the Greek myth of Pygmalion, who carved a statue that was magically brought to life, and in medieval Jewish stories of the Golem, a magically animated homunculus built of clay. However, the possibility of actually constructing a conscious machine was probably first discussed by Ada Lovelace, in a set of notes written in 1842 about the Analytical Engine invented by Charles Babbage, a precursor (never built) to modern electronic computers. Lovelace was essentially dismissive of the idea that a machine such as the Analytical Engine could think in a humanlike way. She wrote:\n\nOne of the most influential contributions to this question was an essay written in 1950 by pioneering computer scientist Alan Turing, titled \"Computing Machinery and Intelligence\". Turing disavowed any interest in terminology, saying that even \"Can machines think?\" is too loaded with spurious connotations to be meaningful; but he proposed to replace all such questions with a specific operational test, which has become known as the Turing test. To pass the test, a computer must be able to imitate a human well enough to fool interrogators. In his essay Turing discussed a variety of possible objections, and presented a counterargument to each of them. The Turing test is commonly cited in discussions of artificial intelligence as a proposed criterion for machine consciousness; it has provoked a great deal of philosophical debate. For example, Daniel Dennett and Douglas Hofstadter argue that anything capable of passing the Turing test is necessarily conscious, while David Chalmers argues that a philosophical zombie could pass the test, yet fail to be conscious. A third group of scholars have argued that with technological growth once machines begin to display any substantial signs of human-like behavior then the dichotomy (of human consciousness compared to human-like consciousness) becomes passé and issues of machine autonomy begin to prevail even as observed in its nascent form within contemporary industry and technology. Jürgen Schmidhuber argues that consciousness is simply the result of compression. As an agent sees representation of itself recurring in the environment, the compression of this representation can be called consciousness.\n\nIn a lively exchange over what has come to be referred to as \"the Chinese room argument\", John Searle sought to refute the claim of proponents of what he calls \"strong artificial intelligence (AI)\" that a computer program can be conscious, though he does agree with advocates of \"weak AI\" that computer programs can be formatted to \"simulate\" conscious states. His own view is that consciousness has subjective, first-person causal powers by being essentially intentional due simply to the way human brains function biologically; conscious persons can perform computations, but consciousness is not inherently computational the way computer programs are. To make a Turing machine that speaks Chinese, Searle imagines a room with one monolingual English speaker (Searle himself, in fact), a book that designates a combination of Chinese symbols to be output paired with Chinese symbol input, and boxes filled with Chinese symbols. In this case, the English speaker is acting as a computer and the rulebook as a program. Searle argues that with such a machine, he would be able to process the inputs to outputs perfectly without having any understanding of Chinese, nor having any idea what the questions and answers could possibly mean. If the experiment were done in English, since Searle knows English, he would be able to take questions and give answers without any algorithms for English questions, and he would be effectively aware of what was being said and the purposes it might serve. Searle would pass the Turing test of answering the questions in both languages, but he is only conscious of what he is doing when he speaks English. Another way of putting the argument is to say that computer programs can pass the Turing test for processing the syntax of a language, but that the syntax cannot lead to semantic meaning in the way strong AI advocates hoped.\n\nIn the literature concerning artificial intelligence, Searle's essay has been second only to Turing's in the volume of debate it has generated. Searle himself was vague about what extra ingredients it would take to make a machine conscious: all he proposed was that what was needed was \"causal powers\" of the sort that the brain has and that computers lack. But other thinkers sympathetic to his basic argument have suggested that the necessary (though perhaps still not sufficient) extra conditions may include the ability to pass not just the verbal version of the Turing test, but the robotic version, which requires grounding the robot's words in the robot's sensorimotor capacity to categorize and interact with the things in the world that its words are about, Turing-indistinguishably from a real person. Turing-scale robotics is an empirical branch of research on embodied cognition and situated cognition.\n\nIn 2014, Victor Argonov has suggested a non-Turing test for machine consciousness based on machine's ability to produce philosophical judgments. He argues that a deterministic machine must be regarded as conscious if it is able to produces judgments on all problematic properties of consciousness (such as qualia or binding) having no innate (preloaded) philosophical knowledge on these issues, no philosophical discussions while learning, and no informational models of other creatures in its memory (such models may implicitly or explicitly contain knowledge about these creatures’ consciousness). However, this test can be used only to detect, but not refute the existence of consciousness. A positive result proves that machine is conscious but a negative result proves nothing. For example, absence of philosophical judgments may be\ncaused by lack of the machine’s intellect, not by absence of consciousness.\n\nFor many decades, consciousness as a research topic was avoided by the majority of mainstream scientists, because of a general feeling that a phenomenon defined in subjective terms could not properly be studied using objective experimental methods. In 1975 George Mandler published an influential psychological study which distinguished between slow, serial, and limited conscious processes and fast, parallel and extensive unconscious ones. Starting in the 1980s, an expanding community of neuroscientists and psychologists have associated themselves with a field called \"Consciousness Studies\", giving rise to a stream of experimental work published in books, journals such as \"Consciousness and Cognition\", \"Frontiers in Consciousness Research\", \"Psyche\", and the \"Journal of Consciousness Studies\", along with regular conferences organized by groups such as the Association for the Scientific Study of Consciousness.\n\nModern medical and psychological investigations into consciousness are based on psychological experiments (including, for example, the investigation of priming effects using subliminal stimuli), and on case studies of alterations in consciousness produced by trauma, illness, or drugs. Broadly viewed, scientific approaches are based on two core concepts. The first identifies the content of consciousness with the experiences that are reported by human subjects; the second makes use of the concept of consciousness that has been developed by neurologists and other medical professionals who deal with patients whose behavior is impaired. In either case, the ultimate goals are to develop techniques for assessing consciousness objectively in humans as well as other animals, and to understand the neural and psychological mechanisms that underlie it.\n\nExperimental research on consciousness presents special difficulties, due to the lack of a universally accepted operational definition. In the majority of experiments that are specifically about consciousness, the subjects are human, and the criterion used is verbal report: in other words, subjects are asked to describe their experiences, and their descriptions are treated as observations of the contents of consciousness. For example, subjects who stare continuously at a Necker cube usually report that they experience it \"flipping\" between two 3D configurations, even though the stimulus itself remains the same. The objective is to understand the relationship between the conscious awareness of stimuli (as indicated by verbal report) and the effects the stimuli have on brain activity and behavior. In several paradigms, such as the technique of response priming, the behavior of subjects is clearly influenced by stimuli for which they report no awareness, and suitable experimental manipulations can lead to increasing priming effects despite decreasing prime identification (double dissociation).\n\nVerbal report is widely considered to be the most reliable indicator of consciousness, but it raises a number of issues. For one thing, if verbal reports are treated as observations, akin to observations in other branches of science, then the possibility arises that they may contain errors—but it is difficult to make sense of the idea that subjects could be wrong about their own experiences, and even more difficult to see how such an error could be detected. Daniel Dennett has argued for an approach he calls heterophenomenology, which means treating verbal reports as stories that may or may not be true, but his ideas about how to do this have not been widely adopted. Another issue with verbal report as a criterion is that it restricts the field of study to humans who have language: this approach cannot be used to study consciousness in other species, pre-linguistic children, or people with types of brain damage that impair language. As a third issue, philosophers who dispute the validity of the Turing test may feel that it is possible, at least in principle, for verbal report to be dissociated from consciousness entirely: a philosophical zombie may give detailed verbal reports of awareness in the absence of any genuine awareness.\n\nAlthough verbal report is in practice the \"gold standard\" for ascribing consciousness, it is not the only possible criterion. In medicine, consciousness is assessed as a combination of verbal behavior, arousal, brain activity and purposeful movement. The last three of these can be used as indicators of consciousness when verbal behavior is absent. The scientific literature regarding the neural bases of arousal and purposeful movement is very extensive. Their reliability as indicators of consciousness is disputed, however, due to numerous studies showing that alert human subjects can be induced to behave purposefully in a variety of ways in spite of reporting a complete lack of awareness. Studies of the neuroscience of free will have also shown that the experiences that people report when they behave purposefully sometimes do not correspond to their actual behaviors or to the patterns of electrical activity recorded from their brains.\n\nAnother approach applies specifically to the study of self-awareness, that is, the ability to distinguish oneself from others. In the 1970s Gordon Gallup developed an operational test for self-awareness, known as the mirror test. The test examines whether animals are able to differentiate between seeing themselves in a mirror versus seeing other animals. The classic example involves placing a spot of coloring on the skin or fur near the individual's forehead and seeing if they attempt to remove it or at least touch the spot, thus indicating that they recognize that the individual they are seeing in the mirror is themselves. Humans (older than 18 months) and other great apes, bottlenose dolphins, killer whales, pigeons, European magpies and elephants have all been observed to pass this test.\n\nA major part of the scientific literature on consciousness consists of studies that examine the relationship between the experiences reported by subjects and the activity that simultaneously takes place in their brains—that is, studies of the neural correlates of consciousness. The hope is to find that activity in a particular part of the brain, or a particular pattern of global brain activity, which will be strongly predictive of conscious awareness. Several brain imaging techniques, such as EEG and fMRI, have been used for physical measures of brain activity in these studies.\n\nAnother idea that has drawn attention for several decades is that consciousness is associated with high-frequency (gamma band) oscillations in brain activity. This idea arose from proposals in the 1980s, by Christof von der Malsburg and Wolf Singer, that gamma oscillations could solve the so-called binding problem, by linking information represented in different parts of the brain into a unified experience. Rodolfo Llinás, for example, proposed that consciousness results from recurrent thalamo-cortical resonance where the specific thalamocortical systems (content) and the non-specific (centromedial thalamus) thalamocortical systems (context) interact in the gamma band frequency via synchronous oscillations.\n\nA number of studies have shown that activity in primary sensory areas of the brain is not sufficient to produce consciousness: it is possible for subjects to report a lack of awareness even when areas such as the primary visual cortex show clear electrical responses to a stimulus. Higher brain areas are seen as more promising, especially the prefrontal cortex, which is involved in a range of higher cognitive functions collectively known as executive functions. There is substantial evidence that a \"top-down\" flow of neural activity (i.e., activity propagating from the frontal cortex to sensory areas) is more predictive of conscious awareness than a \"bottom-up\" flow of activity. The prefrontal cortex is not the only candidate area, however: studies by Nikos Logothetis and his colleagues have shown, for example, that visually responsive neurons in parts of the temporal lobe reflect the visual perception in the situation when conflicting visual images are presented to different eyes (i.e., bistable percepts during binocular rivalry).\n\nModulation of neural responses may correlate with phenomenal experiences. In contrast to the raw electrical responses that do not correlate with consciousness, the modulation of these responses by other stimuli correlates surprisingly well with an important aspect of consciousness: namely with the phenomenal experience of stimulus intensity (brightness, contrast). In the research group of Danko Nikolić it has been shown that some of the changes in the subjectively perceived brightness correlated with the modulation of firing rates while others correlated with the modulation of neural synchrony. An fMRI investigation suggested that these findings were strictly limited to the primary visual areas. This indicates that, in the primary visual areas, changes in firing rates and synchrony can be considered as neural correlates of qualia—at least for some type of qualia.\n\nIn 2011, Graziano and Kastner proposed the \"attention schema\" theory of awareness. In that theory, specific cortical areas, notably in the superior temporal sulcus and the temporo-parietal junction, are used to build the construct of awareness and attribute it to other people. The same cortical machinery is also used to attribute awareness to oneself. Damage to these cortical regions can lead to deficits in consciousness such as hemispatial neglect. In the attention schema theory, the value of explaining the feature of awareness and attributing it to a person is to gain a useful predictive model of that person's attentional processing. Attention is a style of information processing in which a brain focuses its resources on a limited set of interrelated signals. Awareness, in this theory, is a useful, simplified schema that represents attentional states. To be aware of X is explained by constructing a model of one's attentional focus on X.\n\nIn the 2013, the perturbational complexity index (PCI) was proposed, a measure of the algorithmic complexity of the electrophysiological response of the cortex to transcranial magnetic stimulation. This measure was shown to be higher in individuals that are awake, in REM sleep or in a locked-in state than in those who are in deep sleep or in a vegetative state, making it potentially useful as a quantitative assessment of consciousness states.\n\nAssuming that not only humans but even some non-mammalian species are conscious, a number of evolutionary approaches to the problem of neural correlates of consciousness open up. For example, assuming that birds are conscious — a common assumption among neuroscientists and ethologists due to the extensive cognitive repertoire of birds — there are comparative neuroanatomical ways to validate some of the principal, currently competing, mammalian consciousness–brain theories. The rationale for such a comparative study is that the avian brain deviates structurally from the mammalian brain. So how similar are they? What homologues can be identified? The general conclusion from the study by Butler, et al., is that some of the major theories for the mammalian brain also appear to be valid for the avian brain. The structures assumed to be critical for consciousness in mammalian brains have homologous counterparts in avian brains. Thus the main portions of the theories of Crick and Koch, Edelman and Tononi, and Cotterill seem to be compatible with the assumption that birds are conscious. Edelman also differentiates between what he calls primary consciousness (which is a trait shared by humans and non-human animals) and higher-order consciousness as it appears in humans alone along with human language capacity. Certain aspects of the three theories, however, seem less easy to apply to the hypothesis of avian consciousness. For instance, the suggestion by Crick and Koch that layer 5 neurons of the mammalian brain have a special role, seems difficult to apply to the avian brain, since the avian homologues have a different morphology. Likewise, the theory of Eccles seems incompatible, since a structural homologue/analogue to the dendron has not been found in avian brains. The assumption of an avian consciousness also brings the reptilian brain into focus. The reason is the structural continuity between avian and reptilian brains, meaning that the phylogenetic origin of consciousness may be earlier than suggested by many leading neuroscientists.\n\nJoaquin Fuster of UCLA has advocated the position of the importance of the prefrontal cortex in humans, along with the areas of Wernicke and Broca, as being of particular importance to the development of human language capacities neuro-anatomically necessary for the emergence of higher-order consciousness in humans.\n\nOpinions are divided as to where in biological evolution consciousness emerged and about whether or not consciousness has any survival value. Some argue that consciousness is a byproduct of evolution. It has been argued that consciousness emerged (i) exclusively with the first humans, (ii) exclusively with the first mammals, (iii) independently in mammals and birds, or (iv) with the first reptiles. Other authors date the origins of consciousness to the first animals with nervous systems or early vertebrates in the Cambrian over 500 million years ago. Donald Griffin suggests in his book \"Animal Minds\" a gradual evolution of consciousness. Each of these scenarios raises the question of the possible survival value of consciousness.\n\nThomas Henry Huxley defends in an essay titled \"On the Hypothesis that Animals are Automata, and its History\" an epiphenomenalist theory of consciousness according to which consciousness is a causally inert effect of neural activity — “as the steam-whistle which accompanies the work of a locomotive engine is without influence upon its machinery”. To this William James objects in his essay \"Are We Automata?\" by stating an evolutionary argument for mind-brain interaction implying that if the preservation and development of consciousness in the biological evolution is a result of natural selection, it is plausible that consciousness has not only been influenced by neural processes, but has had a survival value itself; and it could only have had this if it had been efficacious. Karl Popper develops in the book \"The Self and Its Brain\" a similar evolutionary argument.\n\nRegarding the primary function of conscious processing, a recurring idea in recent theories is that phenomenal states somehow integrate neural activities and information-processing that would otherwise be independent. This has been called the \"integration consensus\". Another example has been proposed by Gerald Edelman called dynamic core hypothesis which puts emphasis on reentrant connections that reciprocally link areas of the brain in a massively parallel manner. Edelman also stresses the importance of the evolutionary emergence of higher-order consciousness in humans from the historically older trait of primary consciousness which humans share with non-human animals (see \"Neural correlates\" section above). These theories of integrative function present solutions to two classic problems associated with consciousness: differentiation and unity. They show how our conscious experience can discriminate between a virtually unlimited number of different possible scenes and details (differentiation) because it integrates those details from our sensory systems, while the integrative nature of consciousness in this view easily explains how our experience can seem unified as one whole despite all of these individual parts. However, it remains unspecified which kinds of information are integrated in a conscious manner and which kinds can be integrated without consciousness. Nor is it explained what specific causal role conscious integration plays, nor why the same functionality cannot be achieved without consciousness. Obviously not all kinds of information are capable of being disseminated consciously (e.g., neural activity related to vegetative functions, reflexes, unconscious motor programs, low-level perceptual analyses, etc.) and many kinds of information can be disseminated and combined with other kinds without consciousness, as in intersensory interactions such as the ventriloquism effect. Hence it remains unclear why any of it is conscious. For a review of the differences between conscious and unconscious integrations, see the article of E. Morsella.\n\nAs noted earlier, even among writers who consider consciousness to be a well-defined thing, there is widespread dispute about which animals other than humans can be said to possess it. Edelman has described this distinction as that of humans possessing higher-order consciousness while sharing the trait of primary consciousness with non-human animals (see previous paragraph). Thus, any examination of the evolution of consciousness is faced with great difficulties. Nevertheless, some writers have argued that consciousness can be viewed from the standpoint of evolutionary biology as an adaptation in the sense of a trait that increases fitness. In his article \"Evolution of consciousness\", John Eccles argued that special anatomical and physical properties of the mammalian cerebral cortex gave rise to consciousness (\"[a] psychon ... linked to [a] dendron through quantum physics\"). Bernard Baars proposed that once in place, this \"recursive\" circuitry may have provided a basis for the subsequent development of many of the functions that consciousness facilitates in higher organisms. Peter Carruthers has put forth one such potential adaptive advantage gained by conscious creatures by suggesting that consciousness allows an individual to make distinctions between appearance and reality. This ability would enable a creature to recognize the likelihood that their perceptions are deceiving them (e.g. that water in the distance may be a mirage) and behave accordingly, and it could also facilitate the manipulation of others by recognizing how things appear to them for both cooperative and devious ends.\n\nOther philosophers, however, have suggested that consciousness would not be necessary for any functional advantage in evolutionary processes. No one has given a causal explanation, they argue, of why it would not be possible for a functionally equivalent non-conscious organism (i.e., a philosophical zombie) to achieve the very same survival advantages as a conscious organism. If evolutionary processes are blind to the difference between function \"F\" being performed by conscious organism \"O\" and non-conscious organism \"O*\", it is unclear what adaptive advantage consciousness could provide. As a result, an exaptive explanation of consciousness has gained favor with some theorists that posit consciousness did not evolve as an adaptation but was an exaptation arising as a consequence of other developments such as increases in brain size or cortical rearrangement. Consciousness in this sense has been compared to the blind spot in the retina where it is not an adaption of the retina, but instead just a by-product of the way the retinal axons were wired. Several scholars including Pinker, Chomsky, Edelman, and Luria have indicated the importance of the emergence of human language as an important regulative mechanism of learning and memory in the context of the development of higher-order consciousness (see \"Neural correlates\" section above).\n\nThere are some brain states in which consciousness seems to be absent, including dreamless sleep, coma, and death. There are also a variety of circumstances that can change the relationship between the mind and the world in less drastic ways, producing what are known as altered states of consciousness. Some altered states occur naturally; others can be produced by drugs or brain damage. Altered states can be accompanied by changes in thinking, disturbances in the sense of time, feelings of loss of control, changes in emotional expression, alternations in body image and changes in meaning or significance.\n\nThe two most widely accepted altered states are sleep and dreaming. Although dream sleep and non-dream sleep appear very similar to an outside observer, each is associated with a distinct pattern of brain activity, metabolic activity, and eye movement; each is also associated with a distinct pattern of experience and cognition. During ordinary non-dream sleep, people who are awakened report only vague and sketchy thoughts, and their experiences do not cohere into a continuous narrative. During dream sleep, in contrast, people who are awakened report rich and detailed experiences in which events form a continuous progression, which may however be interrupted by bizarre or fantastic intrusions. Thought processes during the dream state frequently show a high level of irrationality. Both dream and non-dream states are associated with severe disruption of memory: it usually disappears in seconds during the non-dream state, and in minutes after awakening from a dream unless actively refreshed.\n\nResearch conducted on the effects of partial epileptic seizures on consciousness found that patients who suffer from partial epileptic seizures experience altered states of consciousness. In partial epileptic seizures, consciousness is impaired or lost while some aspects of consciousness, often automated behaviors, remain intact. Studies found that when measuring the qualitative features during partial epileptic seizures, patients exhibited an increase in arousal and became absorbed in the experience of the seizure, followed by difficulty in focusing and shifting attention.\n\nA variety of psychoactive drugs, including alcohol, have notable effects on consciousness. These range from a simple dulling of awareness produced by sedatives, to increases in the intensity of sensory qualities produced by stimulants, cannabis, empathogens–entactogens such as MDMA (\"Ecstasy\"), or most notably by the class of drugs known as psychedelics. LSD, mescaline, psilocybin, Dimethyltryptamine, and others in this group can produce major distortions of perception, including hallucinations; some users even describe their drug-induced experiences as mystical or spiritual in quality. The brain mechanisms underlying these effects are not as well understood as those induced by use of alcohol, but there is substantial evidence that alterations in the brain system that uses the chemical neurotransmitter serotonin play an essential role.\n\nThere has been some research into physiological changes in yogis and people who practise various techniques of meditation. Some research with brain waves during meditation has reported differences between those corresponding to ordinary relaxation and those corresponding to meditation. It has been disputed, however, whether there is enough evidence to count these as physiologically distinct states of consciousness.\n\nThe most extensive study of the characteristics of altered states of consciousness was made by psychologist Charles Tart in the 1960s and 1970s. Tart analyzed a state of consciousness as made up of a number of component processes, including exteroception (sensing the external world); interoception (sensing the body); input-processing (seeing meaning); emotions; memory; time sense; sense of identity; evaluation and cognitive processing; motor output; and interaction with the environment. Each of these, in his view, could be altered in multiple ways by drugs or other manipulations. The components that Tart identified have not, however, been validated by empirical studies. Research in this area has not yet reached firm conclusions, but a recent questionnaire-based study identified eleven significant factors contributing to drug-induced states of consciousness: experience of unity; spiritual experience; blissful state; insightfulness; disembodiment; impaired control and cognition; anxiety; complex imagery; elementary imagery; audio-visual synesthesia; and changed meaning of percepts.\n\nPhenomenology is a method of inquiry that attempts to examine the structure of consciousness in its own right, putting aside problems regarding the relationship of consciousness to the physical world. This approach was first proposed by the philosopher Edmund Husserl, and later elaborated by other philosophers and scientists. Husserl's original concept gave rise to two distinct lines of inquiry, in philosophy and psychology. In philosophy, phenomenology has largely been devoted to fundamental metaphysical questions, such as the nature of intentionality (\"aboutness\"). In psychology, phenomenology largely has meant attempting to investigate consciousness using the method of introspection, which means looking into one's own mind and reporting what one observes. This method fell into disrepute in the early twentieth century because of grave doubts about its reliability, but has been rehabilitated to some degree, especially when used in combination with techniques for examining brain activity.\nIntrospectively, the world of conscious experience seems to have considerable structure. Immanuel Kant asserted that the world as we perceive it is organized according to a set of fundamental \"intuitions\", which include 'object' (we perceive the world as a set of distinct things); 'shape'; 'quality' (color, warmth, etc.); 'space' (distance, direction, and location); and 'time'. Some of these constructs, such as space and time, correspond to the way the world is structured by the laws of physics; for others the correspondence is not as clear. Understanding the physical basis of qualities, such as redness or pain, has been particularly challenging. David Chalmers has called this the hard problem of consciousness. Some philosophers have argued that it is intrinsically unsolvable, because qualities (\"qualia\") are ineffable; that is, they are \"raw feels\", incapable of being analyzed into component processes. Other psychologists and neuroscientists reject these arguments. For example, research on ideasthesia shows that qualia are organised into a semantic-like network. Nevertheless, it is clear that the relationship between a physical entity such as light and a perceptual quality such as color is extraordinarily complex and indirect, as demonstrated by a variety of optical illusions such as neon color spreading.\n\nIn neuroscience, a great deal of effort has gone into investigating how the perceived world of conscious awareness is constructed inside the brain. The process is generally thought to involve two primary mechanisms: (1) hierarchical processing of sensory inputs, and (2) memory. Signals arising from sensory organs are transmitted to the brain and then processed in a series of stages, which extract multiple types of information from the raw input. In the visual system, for example, sensory signals from the eyes are transmitted to the thalamus and then to the primary visual cortex; inside the cerebral cortex they are sent to areas that extract features such as three-dimensional structure, shape, color, and motion. Memory comes into play in at least two ways. First, it allows sensory information to be evaluated in the context of previous experience. Second, and even more importantly, working memory allows information to be integrated over time so that it can generate a stable representation of the world—Gerald Edelman expressed this point vividly by titling one of his books about consciousness \"The Remembered Present\". In computational neuroscience, Bayesian approaches to brain function have been used to understand both the evaluation of sensory information in light of previous experience, and the integration of information over time. Bayesian models of the brain are probabilistic inference models, in which the brain takes advantage of prior knowledge to interpret uncertain sensory inputs in order to formulate a conscious percept; Bayesian models have successfully predicted many perceptual phenomena in vision and the nonvisual senses.\n\nDespite the large amount of information available, many important aspects of perception remain mysterious. A great deal is known about low-level signal processing in sensory systems. However, how sensory systems, action systems, and language systems interact are poorly understood. At a deeper level, there are still basic conceptual issues that remain unresolved. Many scientists have found it difficult to reconcile the fact that information is distributed across multiple brain areas with the apparent unity of consciousness: this is one aspect of the so-called binding problem. There are also some scientists who have expressed grave reservations about the idea that the brain forms representations of the outside world at all: influential members of this group include psychologist J. J. Gibson and roboticist Rodney Brooks, who both argued in favor of \"intelligence without representation\".\n\nThe medical approach to consciousness is practically oriented. It derives from a need to treat people whose brain function has been impaired as a result of disease, brain damage, toxins, or drugs. In medicine, conceptual distinctions are considered useful to the degree that they can help to guide treatments. Whereas the philosophical approach to consciousness focuses on its fundamental nature and its contents, the medical approach focuses on the amount of consciousness a person has: in medicine, consciousness is assessed as a \"level\" ranging from coma and brain death at the low end, to full alertness and purposeful responsiveness at the high end.\n\nConsciousness is of concern to patients and physicians, especially neurologists and anesthesiologists. Patients may suffer from disorders of consciousness, or may need to be anesthetized for a surgical procedure. Physicians may perform consciousness-related interventions such as instructing the patient to sleep, administering general anesthesia, or inducing medical coma. Also, bioethicists may be concerned with the ethical implications of consciousness in medical cases of patients such as the Karen Ann Quinlan case, while neuroscientists may study patients with impaired consciousness in hopes of gaining information about how the brain works.\n\nIn medicine, consciousness is examined using a set of procedures known as neuropsychological assessment. There are two commonly used methods for assessing the level of consciousness of a patient: a simple procedure that requires minimal training, and a more complex procedure that requires substantial expertise. The simple procedure begins by asking whether the patient is able to move and react to physical stimuli. If so, the next question is whether the patient can respond in a meaningful way to questions and commands. If so, the patient is asked for name, current location, and current day and time. A patient who can answer all of these questions is said to be \"alert and oriented times four\" (sometimes denoted \"A&Ox4\" on a medical chart), and is usually considered fully conscious.\n\nThe more complex procedure is known as a neurological examination, and is usually carried out by a neurologist in a hospital setting. A formal neurological examination runs through a precisely delineated series of tests, beginning with tests for basic sensorimotor reflexes, and culminating with tests for sophisticated use of language. The outcome may be summarized using the Glasgow Coma Scale, which yields a number in the range 3—15, with a score of 3 to 8 indicating coma, and 15 indicating full consciousness. The Glasgow Coma Scale has three subscales, measuring the best motor response (ranging from \"no motor response\" to \"obeys commands\"), the best eye response (ranging from \"no eye opening\" to \"eyes opening spontaneously\") and the best verbal response (ranging from \"no verbal response\" to \"fully oriented\"). There is also a simpler pediatric version of the scale, for children too young to be able to use language.\n\nIn 2013, an experimental procedure was developed to measure degrees of consciousness, the procedure involving stimulating the brain with a magnetic pulse, measuring resulting waves of electrical activity, and developing a consciousness score based on the complexity of the brain activity.\n\nMedical conditions that inhibit consciousness are considered disorders of consciousness. This category generally includes minimally conscious state and persistent vegetative state, but sometimes also includes the less severe locked-in syndrome and more severe chronic coma. Differential diagnosis of these disorders is an active area of biomedical research. Finally, brain death results in an irreversible disruption of consciousness. While other conditions may cause a moderate deterioration (e.g., dementia and delirium) or transient interruption (e.g., grand mal and petit mal seizures) of consciousness, they are not included in this category.\n\nOne of the most striking disorders of consciousness goes by the name anosognosia, a Greek-derived term meaning 'unawareness of disease'. This is a condition in which patients are disabled in some way, most commonly as a result of a stroke, but either misunderstand the nature of the problem or deny that there is anything wrong with them. The most frequently occurring form is seen in people who have experienced a stroke damaging the parietal lobe in the right hemisphere of the brain, giving rise to a syndrome known as hemispatial neglect, characterized by an inability to direct action or attention toward objects located to the left with respect to their bodies. Patients with hemispatial neglect are often paralyzed on the right side of the body, but sometimes deny being unable to move. When questioned about the obvious problem, the patient may avoid giving a direct answer, or may give an explanation that doesn't make sense. Patients with hemispatial neglect may also fail to recognize paralyzed parts of their bodies: one frequently mentioned case is of a man who repeatedly tried to throw his own paralyzed right leg out of the bed he was lying in, and when asked what he was doing, complained that somebody had put a dead leg into the bed with him. An even more striking type of anosognosia is Anton–Babinski syndrome, a rarely occurring condition in which patients become blind but claim to be able to see normally, and persist in this claim in spite of all evidence to the contrary.\n\nWilliam James is usually credited with popularizing the idea that human consciousness flows like a stream, in his \"Principles of Psychology\" of 1890. According to James, the \"stream of thought\" is governed by five characteristics: \"(1) Every thought tends to be part of a personal consciousness. (2) Within each personal consciousness thought is always changing. (3) Within each personal consciousness thought is sensibly continuous. (4) It always appears to deal with objects independent of itself. (5) It is interested in some parts of these objects to the exclusion of others\". A similar concept appears in Buddhist philosophy, expressed by the Sanskrit term \"Citta-saṃtāna\", which is usually translated as mindstream or \"mental continuum\". Buddhist teachings describe that consciousness manifests moment to moment as sense impressions and mental phenomena that are continuously changing. The teachings list six triggers that can result in the generation of different mental events. These triggers are input from the five senses (seeing, hearing, smelling, tasting or touch sensations), or a thought (relating to the past, present or the future) that happen to arise in the mind. The mental events generated as a result of these triggers are: feelings, perceptions and intentions/behaviour. The moment-by-moment manifestation of the mind-stream is said to happen in every person all the time. It even happens in a scientist who analyses various phenomena in the world, or analyses the material body including the organ brain. The manifestation of the mindstream is also described as being influenced by physical laws, biological laws, psychological laws, volitional laws, and universal laws. The purpose of the Buddhist practice of mindfulness is to understand the inherent nature of the consciousness and its characteristics.\n\nIn the west, the primary impact of the idea has been on literature rather than science: stream of consciousness as a narrative mode means writing in a way that attempts to portray the moment-to-moment thoughts and experiences of a character. This technique perhaps had its beginnings in the monologues of Shakespeare's plays, and reached its fullest development in the novels of James Joyce and Virginia Woolf, although it has also been used by many other noted writers.\n\nHere for example is a passage from Joyce's Ulysses about the thoughts of Molly Bloom:\n\nConsciousness may have a determinative role in quantum mechanics. Since consciousness is the primary aspect of an observer, and observation is sometimes viewed as a primary reason for apparent wave function collapse, consciousness may account for aspects of the measurement problem exemplified by the Schrödinger's cat paradox. This area has been an area of lively debate for decades, with recent efforts to substitute randomly caused decoherence as the source of apparent wave function collapse.\n\nMax Tegmark and John Archibald Wheeler provided a useful survey of some of the issues.\n\nTo most philosophers, the word \"consciousness\" connotes the relationship between the mind and the world. To writers on spiritual or religious topics, it frequently connotes the relationship between the mind and God, or the relationship between the mind and deeper truths that are thought to be more fundamental than the physical world. Krishna consciousness, for example, is a term used to mean an intimate linkage between the mind of a worshipper and the god Krishna. The mystical psychiatrist Richard Maurice Bucke distinguished between three types of consciousness: 'Simple Consciousness', awareness of the body, possessed by many animals; 'Self Consciousness', awareness of being aware, possessed only by humans; and 'Cosmic Consciousness', awareness of the life and order of the universe, possessed only by humans who are enlightened. Many more examples could be given, such as the various levels of spiritual consciousness presented by Prem Saran Satsangi and Stuart Hameroff. The most thorough account of the spiritual approach may be Ken Wilber's book \"The Spectrum of Consciousness\", a comparison of western and eastern ways of thinking about the mind. Wilber described consciousness as a spectrum with ordinary awareness at one end, and more profound types of awareness at higher levels.\n\n\n"}
{"id": "218798", "url": "https://en.wikipedia.org/wiki?curid=218798", "title": "Custom (law)", "text": "Custom (law)\n\nCustom in law is the established pattern of behavior that can be objectively verified within a particular social setting. A claim can be carried out in defense of \"what has always been done and accepted by law.\" Related is the idea of prescription; a right enjoyed through long custom rather than positive law.\n\nCustomary law (also, consuetudinary or unofficial law) exists where: \n\nMost customary laws deal with \"standards of community\" that have been long-established in a given locale. However the term can also apply to areas of international law where certain standards have been nearly universal in their acceptance as correct bases of action – in example, laws against piracy or slavery (see \"hostis humani generis\"). In many, though not all instances, customary laws will have supportive court rulings and case law that has evolved over time to give additional weight to their rule as law and also to demonstrate the trajectory of evolution (if any) in the interpretation of such law by relevant courts.\n\nA central issue regarding the recognition of custom is determining the appropriate methodology to know what practices and norms actually constitutes customary law. It is not immediately clear that classic Western theories of jurisprudence can be reconciled in any useful way with conceptual analyses of customary law, and thus some scholars (like John Comaroff and Simon Roberts) have characterised customary law norms in their own terms. Yet, there clearly remains some disagreement, which is seen in John Hund's critique of Comaroff and Roberts' theory, and preference for the contributions of H. L. A. Hart. Hund argues that Hart's \"The Concept of Law\" solves the conceptual problem with which scholars who have attempted to articulate how customary law principles may be identified, defined and how they operate in regulating social behaviour and resolving disputes.\n\nComaroff and Roberts' famous work, \"Rules and Processes\", attempted to detail the body of norms that constitute Tswana law in a way that was less legalistic (or rule-oriented) than had Isaac Schapera. They defined \"mekgwa le melao ya Setswana\" in terms of Casalis and Ellenberger definition: \"melao\" therefore being rules pronounced by a chief and \"mekgwa\" as norms that become customary law through traditional usage. Importantly, however, they noted that the Tswana seldom attempt to classify the vast array of existing norms into categories and they thus termed this the 'undifferentiated nature of the normative repertoire'. Moreover, they observe the co-existence of overtly incompatible norms that may breed conflict, either due to circumstances in a particular situation, or inherently due to their incongruous content. This lack of rule classification and failure to eradicate internal inconsistencies between potentially conflicting norms allows for much flexibility in dispute settlement and is also viewed as a 'strategic resource' for disputants who seek to advance their own success in a case. The latter incongruities (especially of inconsistencies of norm content) are typically solved by elevating one of the norms (tacitly) from 'the literal to the symbolic'. This allows for the accommodation of both as they now theoretically exist in different realms of reality. This is highly contextual, which further illustrates that norms cannot be viewed in isolation and are open to negotiation. Thus, although there are a small number of so-called non-negotiable norms, the vast majority are viewed and given substance contextually, which is seen as fundamental to the Tswana.\n\nComaroff and Roberts describe how outcomes of specific cases have the ability to change the normative repertoire, as the repertoire of norms is seen to be both in a state of formation and transformation at all times. These changes are justified on the grounds that they are merely giving recognition to de facto observations of transformation [219]. Furthermore, the legitimacy of a chief is a direct determinant of the legitimacy of his decisions. In the formulation of legislative pronouncements, as opposed to decisions made in dispute resolution, the chief first speaks of the proposed norm with his advisors, then council of headmen, then the public assembly debate the proposed law and may accept or reject it. A chief can proclaim the law even if the public assembly rejects it, but this is not often done; and, if the chief proclaims the legislation against the will of the public assembly, the legislation will become melao, however it is unlikely that it will be executed because its effectiveness depends on the chief's legitimacy and the norm's consistency with the practices (and changes in social relations) and will of the people under that chief.\n\nRegarding the invocation of norms in disputes, Comaroff and Roberts used the term, \"paradigm of argument\", to refer to the linguistic and conceptual frame used by a disputant, whereby 'a coherent picture of relevant events and actions in terms of one or more implicit or explicit normative referents' is created. In their explanation, the complainant (who always speaks first) thus establishes a paradigm the defendant can either accept and therefore argue within that specific paradigm or reject and therefore introduce his or her own paradigm (usually, the facts are not contested here). If the defendant means to change the paradigm, they will refer to norms as such, where actually norms are not ordinarily explicitly referenced in Tswana dispute resolution as the audience would typically already know them and just the way one presents one's case and constructs the facts will establish one's paradigm. The headman or chief adjudicating may also do same: accept the normative basis implied by the parties (or one of them), and thus not refer to norms using explicit language but rather isolate a factual issue in the dispute and then make a decision on it without expressly referring to any norms, or impose a new or different paradigm onto the parties.\n\nHund finds Comaroff and Roberts' flexibility thesis of a 'repertoire of norms' from which litigants and adjudicator choose in the process of negotiating solutions between them uncompelling. He is therefore concerned with disproving what he calls \"rule scepticism\" on their part. He notes that the concept of custom generally denotes convergent behaviour, but not all customs have the force of law. Hund therefore draws from Hart's analysis distinguishing social rules, which have internal and external aspects, from habits, which have only external aspects. Internal aspects are the reflective attitude on the part of adherents toward certain behaviours perceived to be obligatory, according to a common standard. External aspects manifest in regular, observable behaviour, but is not obligatory. In Hart's analysis, then, social rules amount to custom that has legal force.\n\nHart identifies three further differences between habits and binding social rules. First, a social rule exists where society frowns on deviation from the habit and attempts to prevent departures by criticising such behaviour. Second, when this criticism is seen socially as a good reason for adhering to the habit, and it is welcomed. And, third, when members of a group behave in a common way not only out of habit or because everyone else is doing it, but because it is seen to be a common standard that should be followed, at least by some members. Hund, however, acknowledges the difficulty of an outsider knowing the dimensions of these criteria that depend on an internal point of view.\n\nFor Hund, the first form of rule scepticism concerns the widely held opinion that, because the content of customary law derives from practice, there are actually no objective rules, since it is only behaviour that informs their construction. On this view, it is impossible to distinguish between behaviour that is rule bound and behaviour that is not—i.e., which behaviour is motivated by adherence to law (or at least done in recognition of the law) and is merely a response to other factors. Hund sees this as problematic because it makes quantifying the law almost impossible, since behaviour is obviously inconsistent. Hund argues that this is a misconception based on a failure to acknowledge the importance of the \"internal element\". In his view, by using the criteria described above, there is not this problem in deciphering what constitutes \"law\" in a particular community.\n\nAccording to Hund, the second form of rule scepticism says that, though a community may have rules, those rules are not arrived at 'deductively', i.e. they are not created through legal/moral reasoning only but are instead driven by the personal/political motives of those who create them. The scope for such influence is created by the loose and undefined nature of customary law, which, Hund argues, grants customary-lawmakers (often through traditional 'judicial processes') a wide discretion in its application. Yet, Hund contends that the fact that rules might sometimes be arrived at in the more ad hoc way, does not mean that this defines the system. If one requires a perfect system, where laws are created only deductively, then one is left with a system with no rules. For Hund, this cannot be so and an explanation for these kinds of law-making processes is found in Hart's conception of \"secondary rules\" (rules in terms of which the main body of norms are recognised). Hund therefore says that for some cultures, for instance in some sections of Tswana society, the secondary rules have developed only to the point where laws are determined with reference to politics and personal preference. This does not mean that they are not \"rules\". Hund argues that if we acknowledge a developmental pattern in societies' constructions of these secondary rules then we can understand how this society constructs its laws and how it differs from societies that have come to rely on an objective, stand-alone body of rules.\n\nThe modern codification of civil law developed from the tradition of medieval custumals, collections of local customary law that developed in a specific manorial or borough jurisdiction, and which were slowly pieced together mainly from case law and later written down by local jurists. Custumals acquired the force of law when they became the undisputed rule by which certain rights, entitlements, and obligations were regulated between members of a community. Some examples include Bracton's \"De Legibus et Consuetudinibus Angliae\" for England, the \"Coutume de Paris\" for the city of Paris, the \"Sachsenspiegel\" for northern Germany, and the many \"fueros\" of Spain.\n\nIn international law, \"customary law\" refers to the \"Law of Nations\" or the legal norms that have developed through the customary exchanges between states over time, whether based on diplomacy or aggression. Essentially, legal obligations are believed to arise between states to carry out their affairs consistently with past accepted conduct. These customs can also change based on the acceptance or rejection by states of particular acts. Some principles of customary law have achieved the force of peremptory norms, which cannot be violated or altered except by a norm of comparable strength. These norms are said to gain their strength from universal acceptance, such as the prohibitions against genocide and slavery. Customary international law can be distinguished from treaty law, which consists of explicit agreements between nations to assume obligations. However, many treaties are attempts to codify pre-existing customary law.\n\nCustomary law is a recognized source of law within jurisdictions of the civil law tradition, where it may be subordinate to both statutes and regulations. In addressing custom as a source of law within the civil law tradition, John Henry Merryman notes that, though the attention it is given in scholarly works is great, its importance is \"slight and decreasing.\" On the other hand, in many countries around the world, one or more types of customary law continue to exist side by side with official law, a condition referred to as legal pluralism (see List of national legal systems).\n\nIn the canon law of the Catholic Church, custom is a source of law. Canonical jurisprudence, however, differs from Civil law jurisprudence in requiring the express or implied consent of the legislator for a custom to obtain the force of law.\n\nIn the Common Law of England, \"Long usage\" must be established.\n\nIt is a broad principle of property law that, if something has gone on for a long time without objection, whether it be using a right of way or occupying land to which one has no title, the law will eventually recognise the fact and give the person doing it the legal right to continue.\n\nIt is known in case law as\nCustomary Rights \n\"Customary rights\". Something which has been practised since time immemorial by reference to a particular locality may acquire the legal status of a custom, which is a form of local law.The legal criteria defining a custom are precise. The most common claim in recent times, is for customary rights to moor a vessel.\n\nThe mooring must have been in continuous use for \"Time Immemorial\" which is defined by legal precedent as 12 years (or 20 years for Crown Land) for the same purpose by people using them for that purpose.\n\nTo give two examples:- A custom of mooring which might have been established in past times for over two hundred years by the fishing fleet of local inhabitants of a coastal community will not simply transfer so as to benefit present day recreational boat owners who may hail from much further afield.\n\nWhereas a group of houseboats on a mooring that has been in continuous use for the last 25 years \nwith a mixture of owner occupiers and rented houseboats, may clearly continue to be used by houseboats, where the owners live in the same town or city.\n\nBoth the purpose of the moorings and the class of persons benefited by the custom must have been clear and consistent.\n\nIn Canada, customary aboriginal law has a constitutional foundation and for this reason has increasing influence.\n\nIn the Scandinavian countries customary law continues to exist and has great influence. \n\nCustomary law is also used in some Third World countries, such as those in Africa, usually used alongside common or civil law. For example, in Ethiopia, despite the adoption of legal codes based on civil law in the 1950s according to Dolores Donovan and Getachew Assefa there are more than 60 systems of customary law currently in force, \"some of them operating quite independently of the formal state legal system.\" They offer two reasons for the relative autonomy of these customary law systems: one is that the Ethiopian government lacks sufficient resources to enforce its legal system to every corner of Ethiopia; the other is that the Ethiopian government has made a commitment to preserve these customary systems within its boundaries.\n\nIn 1995, President of Kyrgyzstan Askar Akaev announced a decree to revitalize the \"aqsaqal\" courts of village elders. The courts would have jurisdiction over property, torts and family law. The \"aqsaqal\" courts were eventually included under Article 92 of the Kyrgyz constitution. As of 2006, there were approximately 1,000 \"aqsaqal\" courts throughout Kyrgyzstan, including in the capital of Bishkek. Akaev linked the development of these courts to the rekindling of Kyrgyz national identity. In a 2005 speech, he connected the courts back to the country's nomadic past and extolled how the courts expressed the Kyrgyz ability of self-governance. Similar \"aqsaqal\" courts exist, with varying levels of legal formality, in other countries of Central Asia.\n\nThe Somali people in the Horn of Africa follow a customary law system referred to as Xeer. It survives to a significant degree everywhere in Somalia and in the Somali communities in the Ogaden. Economist Peter Leeson attributes the increase in economic activity since the fall of the Siad Barre administration to the security in life, liberty and property provided by Xeer in large parts of Somalia. The Dutch attorney Michael van Notten also draws upon his experience as a legal expert in his comprehensive study on Xeer, \"The Law of the Somalis: A Stable Foundation for Economic Development in the Horn of Africa\" (2005).\n\nIn India many customs are accepted by law. For example, Hindu marriage ceremonies are recognized by the Hindu Marriage Act.\n\nIn Indonesia, customary adat laws of the country's various indigenous ethnicities are recognized, and customary dispute resolution is recognized in Papua. Indonesian adat law are mainly divided into 19 circles, namely Aceh, Gayo, Alas, and Batak, Minangkabau, South Sumatra, the Malay regions, Bangka and Belitung, Kalimantan, Minahasa, Gorontalo, Toraja, South Sulawesi, Ternate, the Molluccas, Papua, Timor, Bali and Lombok, Central and East Java including the island of Madura, Sunda, and the Javanese monarchies, including the Yogyakarta Sultanate, Surakarta Sunanate, and the Pakualaman and Mangkunegaran princely states.\n\nCustom is used in tort law to help determine negligence. Following or disregarding a custom is not determinative of negligence, but instead is an indication of possible best practices or alternatives to a particular action.\n\n\n"}
{"id": "5987714", "url": "https://en.wikipedia.org/wiki?curid=5987714", "title": "Dave Forbes", "text": "Dave Forbes\n\nDavid Stephen Forbes (born November 16, 1948) is a Canadian retired professional ice hockey player.\n\nSigned as a free agent in 1973 by the Boston Bruins, Forbes made an impact as a defensive-minded forward as he helped guide the Bruins to the finals in 1974 during his rookie season, and to the finals in 1977. Forbes played four seasons with Boston until he was claimed by the Washington Capitals in the Waiver Draft prior to the 1977–78 season. After playing one season with the Capitals, he was released after only playing two games during the 1978–79 season and signed to play for the Cincinnati Stingers of the World Hockey Association.\n\nForbes was charged with aggravated assault in Minneapolis in 1975 after butt-ending Henry Boucha's eye socket in a game against the Minnesota North Stars. The trial received much publicity as it was highly unusual for an athlete to face criminal charges for assault during a game. The trial ended with a hung jury; the charges were not refiled.\n"}
{"id": "15331801", "url": "https://en.wikipedia.org/wiki?curid=15331801", "title": "Dead hedge", "text": "Dead hedge\n\nA dead hedge is a barrier constructed from cut branches, saplings, and foliage. The material can be from pruning, clearing, or forestry activities. Their succession is a beetle bank or hedge. \n\nDead hedges or wind-rows, as they are known in the coppice trade, are useful keeping the compartments of the coppice tidy, keeping the public from certain areas, being an excellent habitat and corridor for wildlife habitat conservation and restoration ecology, as they offer shelter for small animals, especially birds. This can be part of a beneficial \"biological pest agents\" habitat in biological pest control programs for natural landscapes and organic gardening.\n\nDead hedges usually provide an enclosure for the storage of livestock. The above biological pest control dead hedges use is also part of organic farming and sustainable agriculture.\n\nDead hedges also recycle-reuse biomass without energy use to transport to landfills, or by burning, reducing a carbon footprint impact.\n\n"}
{"id": "412990", "url": "https://en.wikipedia.org/wiki?curid=412990", "title": "Deportation", "text": "Deportation\n\nDeportation is the expulsion of a person or group of people from a place or country. The term \"expulsion\" is often used as a synonym for deportation, though expulsion is more often used in the context of international law, while deportation is more used in national (municipal) law.\n\nDefinitions of deportation apply equally to nationals and foreigners. Nonetheless, in the common usage the expulsion of foreign nationals is usually called deportation, whereas the expulsion of nationals is called extradition, banishment, exile, or penal transportation. For example, in the United States:\n\n\"Strictly speaking, transportation, extradition, and deportation, although each has the effect of removing a person from the country, are different things, and have different purposes. Transportation is by way of punishment of one convicted of an offense against the laws of the country. Extradition is the surrender to another country of one accused of an offense against its laws, there to be tried, and, if found guilty, punished. Deportation is the removal of an alien out of the country, simply because his presence is deemed inconsistent with the public welfare and without any punishment being imposed or contemplated either under the laws of the country out of which he is sent or of those of the country to which he is taken.\"\n\nExpulsion is an act by a public authority to remove a person or persons against his or her will from the territory of that state. A successful expulsion of a person by a country is called a deportation.\n\nAccording to the European Court of Human Rights, collective expulsion is any measure compelling non-nationals, as a group, to leave a country, except where such a measure is taken on the basis of a reasonable and objective examination of the particular case of each individual non-national of the group. Mass expulsion may also occur when members of an ethnic group are sent out of a state regardless of nationality. Collective expulsion, or expulsion en masse, is prohibited by several instruments of international law.\n\nDeportations widely occurred in ancient history.\n\nDeportation was practiced as a policy toward rebellious people in Achaemenid Empire. The precise legal status of the deportees is unclear; but ill-treatment is not recorded. Instances include:\n\nUnlike in the Achaemenid and Sassanian periods, records of deportation are rare during the Arsacid Parthian period. One notable example was the deportaion of the Mards in Charax, near Rhages (Ray) by Phraates I. The 10,000 Roman prisonors of war after the Battle of Carrhae appear to have been deported to Alexandria Margiana (Merv) near the eastern border in 53 BC, who are said to married to local people. It is hypothesized that some of them founded the Chinese city of Li-Jien after becoming soldiers for the Hsiung-nu, but this is doubted.\n\nHyrcanus II, the Jewish king of Judea, was settled among the Jews of Babylon in Parthia after being taken as captive by the Parthian-Jewish forces in 40 BC.\n\nRoman POWs in the Antony's Parthian War may have suffered deportation.\n\nDeportation was widely used by the Sasanians, especially during the wars with the Romans.\n\nDuring Shapur I's reign, the Romans (including Valerian) who were defeated at the Battle of Edessa were deported to Persis. Other destinations were Parthia, Khuzestan, and Asorestan. There were cities which were founded and were populated by Romans prisoners of war, including Shadh-Shapur (Dayr Mikhraq) in Meshan, Bishapur in Persis, Wuzurg-Shapur ('Uqbara; Marw-Ḥābūr), and Gundeshapur. Agricultural land were also given to the deportees. These deportations initiated the spread Christianity in the Sassanian empire. In Rēw-Ardashīr (Rishahr; Yarānshahr), Persis, there was a church for the Romans and another one for Carmanians. In the mid-3rd century, Greek-speaking deportees from north-western Syria were settled in Kashkar, Mesopotamia.\n\nAfter the Arab incursion into Persia during Shapur II's reign, he scattered the defeated Arab tribes by deporting them to other regions. Some where deported to Bahrain and Kirman, possibly to both populate these unattractive regions (due to their climate) and bringing the tribes under control.\n\nIn 395 AD, 18,000 Roman populations of Sophene, Armenia, Mesopotamia, Syria, and Cappadocia were captured and deported by the \"Huns\". the prisoners were freed by the Persians as they reached Persia, and were settled in Slōk (Wēh Ardashīr) and Kōkbā (Kōkhē). The author of the text \"Liber Calipharum\" has praised the king Yazdegerd I (399–420) for his treatment of the deportees, who also allowed some to return.\n\nMajor deportations occurred during the Anastasian War.\n\nMajor deportations occurred during the campaigns of Khosrau I from the Roman cities of Sura, Beroea, Antioch, Apamea, Callinicum, and Batnai in Osrhoene, to Wēh-Antiyōk-Khosrow (also known as Rūmagān; in Arabic: al-Rūmiyya). The city was founded near Ctesiphon especially for them, and Khosrow reportedly \"did everything in his power to make the residents want to stay\". The number of the deportees is recorded to be 292,000 in another source.\n\n of the Fourth Geneva Convention prohibits the deportation of people into or out of occupied territory under belligerent military occupation:\n\nAll countries reserve the right to deport persons without right of abode even those who are longtime residents or possess permanent residency. In general, foreigners who have committed serious crimes, entered the country illegally, overstayed or broken the conditions of their visa, or otherwise lost their legal status to remain in the country may be administratively removed or deported. In some cases, even citizens can be deported; Saudi Arabia and the UAE for example. Some western countries also have the ability to deport citizens, if they have another nationality or if they acquire citizenship through fraud.\n\nIn many cases, deportation is done by the government's executive apparatus, and as such is often subject to a simpler legal process (or none), with reduced or no right to trial, legal representation or appeal due to the subject's lack of citizenship. For example, in the 1930s, during the Great Depression, more stringent enforcement of immigration laws were ordered by the executive branch of the U.S. government, which led to the expulsion of up to 2 million Mexican nationals from the United States. In 1954, the executive branch of the U.S. government implemented Operation Wetback, a program created in response to public hysteria about immigration and immigrants from Mexico. Operation Wetback led to the deportation of nearly 1.3 million Mexicans from the United States. Between 2009 and 2016, about 3.2 million people were deported from the United States. Since 1997 U.S. mass deportations of non-citizens particularly convicted felons have risen steadily with the passing into law by the U.S. Congress of the 1996 Illegal Immigration Reform and Responsibility Act (IIRRA) which brought sweeping changes to the threshold for deportation of convicted felons that have been criticized by some as having human rights abuses. Since this time, the former U.S. Immigration and Naturalization Services (INS) has been transformed into Immigration and Customs Enforcement (ICE) and has renamed deportation as \"expedited removal\". The ICE website publishes removal statistics annually on its website. According to recent numbers ICE removed a total of 240,255 aliens in FY 2016, a two percent increase over FY 2015, but a 24 percent decrease from FY 2014.\n\nAlready in natural law of the 18th century, philosophers agreed that expulsion of a nation from the territory that it historically inhabits is not allowable. In the late 20th century, the United Nations drafted a code related to crimes against humanity; Article 18 of the \"Draft Code of Crimes Against the Peace and Security of Mankind\" declares \"large scale\" arbitrary or forcible deportation to be a crime against humanity.\n\nDeportation often requires a specific process that must be validated by a court or senior government official. It should not be confused with administrative removal, which is the process of a country denying entry to individuals at a port of entry and expelling them.\n\nDeportation can also happen within a state, when (for example) an individual or a group of people is forcibly resettled to a different part of the country. If ethnic groups are affected by this, it may also be referred to as population transfer. The rationale is often that these groups might assist the enemy in war or insurrection. For example, the American state of Georgia deported 400 female mill workers during the Civil War on the suspicion they were Northern sympathizers.\n\nDuring World War II, Joseph Stalin (see Population transfer in the Soviet Union) ordered the deportation of Volga Germans, Chechens, Crimean Tatars, Ukrainians and others to areas away from the front, including central and western Soviet Union. Some historians have estimated the number of deaths from the deportation to be as high as 1 in 3 among some populations. On February 26, 2004 the European Parliament characterized deportations of the Chechens as an act of genocide.\n\nThe Soviet Union also used deportation, as well as instituting the Russian language as the only working language and other such tactics, to achieve Russification of its occupied territories (such as the Baltic nations and Bessarabia). In this way, it removed the historical ethnic populations and repopulated the areas with Russian nationals. The deported people were sent to remote, scarcely populated areas or to GULAG labour camps. It has been estimated that, in their entirety, internal forced migrations affected some 6 million people. Of these, some 1 to 1.5 million perished.\n\nAfter World War II approximately 50,000 Hungarians were deported from South Slovakia by Czechoslovak authorities to the Czech borderlands in order to alter the ethnic composition of the region. Between 110,000 and 120,000 Japanese and Japanese Americans on the West Coast, as well as about 3,000 Italian American and about 11,500 German American families, were forcibly resettled from the coasts to internment camps in interior areas of the United States of America by President Franklin Roosevelt.\n\nIn the late 19th and early 20th century, deportation of union members and labor leaders was not uncommon in the United States during strikes or labor disputes. For an example, see the Bisbee Deportation.\n\nDeporting individuals to a colony is a special case that is neither completely internal nor external. Such deportation has occurred in history. For example, after 1717, Britain deported around 40,000 religious objectors and criminals to America before the practice ceased in 1776. The criminals were sold by jailers to shipping contractors, who then sold them to plantation owners. The criminal was forced to work for the plantation owner for the duration of their sentence. The loss of America as a colony, Australia became the destination for criminals deported to British colonies. More than 160,000 criminals were transported to Australia between 1787 and 1855.\n\nNazi policies openly deported homosexuals, Jews, Poles, and Romani from their native places of residence to Nazi concentration camps or extermination camps set up at a considerable distance from their original residences. This was the policy officially known as the \"Final Solution\". The historical term \"deportation\", occurring frequently instead of the religious term Holocaust in various locations, thus means in effect \"sent to their deaths\" — as distinct from deportations in other times and places.\n\nAn estimated 120,000 Serbs were deported from the Independent State of Croatia to German-occupied Serbia, and 300,000 fled by 1943.\n\nAlexander Berkman, Emma Goldman, C.L.R. James, Claudia Jones, Fritz Julius Kuhn, Lucky Luciano, and Anna Sage were all deported from the United States by being arrested and brought to the federal immigration control station on Ellis Island in New York Harbor and, from there, forcibly removed from the United States.\n\nIn literature, deportation appears as an overriding theme in the 1935 novel, \"Strange Passage\" by Theodore D. Irwin.\nFilms depicting or dealing with fictional cases of deportation are many and varied. Among them are \"Ellis Island\" (1936), \"Exile Express\" (1939), \"Five Came Back\" (1939), \"Deported\" (1950), and \"Gambling House\" (1951). More recently, (2002) treated the issue of U.S. deportation to the Caribbean post-1997.\n\n"}
{"id": "5920634", "url": "https://en.wikipedia.org/wiki?curid=5920634", "title": "Discrete event simulation", "text": "Discrete event simulation\n\nA discrete-event simulation (DES) models the operation of a system as a discrete sequence of events in time. Each event occurs at a particular instant in time and marks a change of state in the system. Between consecutive events, no change in the system is assumed to occur; thus the simulation can directly jump in time from one event to the next.\n\nThis contrasts with continuous simulation in which the simulation continuously tracks the system dynamics over time. Instead of being event-based, this is called an activity-based simulation; time is broken up into small time slices and the system state is updated according to the set of activities happening in the time slice. Because discrete-event simulations do not have to simulate every time slice, they can typically run much faster than the corresponding continuous simulation.\n\nA more recent method is the three-phased approach to discrete event simulation (Pidd, 1998). In this approach, the first phase is to jump to the next chronological event. The second phase is to execute all events that unconditionally occur at that time (these are called B-events). The third phase is to execute all events that conditionally occur at that time (these are called C-events). The three phase approach is a refinement of the event-based approach in which simultaneous events are ordered so as to make the most efficient use of computer resources. The three-phase approach is used by a number of commercial simulation software packages, but from the user's point of view, the specifics of the underlying simulation method are generally hidden.\n\nA common exercise in learning how to build discrete-event simulations is to model a queue, such as customers arriving at a bank to be served by a teller. In this example, the system entities are Customer-queue and Tellers. The system events are Customer-Arrival and Customer-Departure. (The event of Teller-Begins-Service can be part of the logic of the arrival and departure events.) The system states, which are changed by these events, are Number-of-Customers-in-the-Queue (an integer from 0 to n) and Teller-Status (busy or idle). The random variables that need to be characterized to model this system stochastically are Customer-Interarrival-Time and Teller-Service-Time. An agent-based framework for performance modeling of an optimistic parallel discrete event simulator is another example for a discrete event simulation.\n\nIn addition to the logic of what happens when system events occur, discrete event simulations include the following:\n\nA system state is a set of variables that captures the salient properties of the system to be studied. The state trajectory over time S(t) can be mathematically represented by a step function whose value can change whenever an event occurs.\n\nThe simulation must keep track of the current simulation time, in whatever measurement units are suitable for the system being modeled. In discrete-event simulations, as opposed to continuous simulations, time 'hops' because events are instantaneous – the clock skips to the next event start time as the simulation proceeds.\n\nThe simulation maintains at least one list of simulation events. This is sometimes called the \"pending event set\"\nbecause it lists events that are pending as a result of previously simulated event but have yet to be simulated themselves.\nAn event is described by the time at which it occurs and a type, indicating the\ncode that will be used to simulate that event. It is common for the event code to be parametrized, in which case, the event description also contains parameters to the event code.\n\nWhen events are instantaneous, activities that extend over time are modeled as sequences of events. Some simulation frameworks allow the time of an event to be specified as an interval, giving the start time and the end time of each event.\n\nSingle-threaded simulation engines based on instantaneous events have just one current event. In contrast, multi-threaded simulation engines and simulation engines supporting an interval-based event model may have multiple current events. In both cases, there are significant problems with synchronization between current events.\n\nThe pending event set is typically organized as a priority queue, sorted by event time. That is, regardless of the order in which events are added to the event set, they are removed in strictly chronological order. Various priority queue implementations have been studied in the context of discrete event simulation; alternatives studied have included splay trees, skip lists, calendar queues, and ladder queues.\nTypically, events are scheduled dynamically as the simulation proceeds. For example, in the bank example noted above, the event CUSTOMER-ARRIVAL at time t would, if the CUSTOMER_QUEUE was empty and TELLER was idle, include the creation of the subsequent event CUSTOMER-DEPARTURE to occur at time t+s, where s is a number generated from the SERVICE-TIME distribution.\n\nThe simulation needs to generate random variables of various kinds, depending on the system model. This is accomplished by one or more Pseudorandom number generators. The use of pseudo-random numbers as opposed to true random numbers is a benefit should a simulation need a rerun with exactly the same behavior.\n\nOne of the problems with the random number distributions used in discrete-event simulation is that the steady-state distributions of event times may not be known in advance. As a result, the initial set of events placed into the pending event set will not have arrival times representative of the steady-state distribution. This problem is typically solved by bootstrapping the simulation model. Only a limited effort is made to assign realistic times to the initial set of pending events. These events, however, schedule additional events, and with time, the distribution of event times approaches its steady state. This is called \"bootstrapping\" the simulation model. In gathering statistics from the running model, it is important to either disregard events that occur before the steady state is reached or to run the simulation for long enough that the bootstrapping behavior is overwhelmed by steady-state behavior. (This use of the term \"bootstrapping\" can be contrasted with its use in both statistics and computing).\n\nThe simulation typically keeps track of the system's statistics, which quantify the aspects of interest. In the bank example, it is of interest to track the mean waiting times. In a simulation model, performance metrics are not analytically derived from probability distributions, but rather as averages over replications, that is different runs of the model. Confidence intervals are usually constructed to help assess the quality of the output.\n\nBecause events are bootstrapped, theoretically a discrete-event simulation could run forever. So the simulation designer must decide when the simulation will end. Typical choices are \"at time t\" or \"after processing n number of events\" or, more generally, \"when statistical measure X reaches the value x\".\n\nThe main loop of a discrete-event simulation is something like this:\n\n\nWhile (Ending Condition is FALSE) then do the following:\n\n\nSimulation approaches are particularly well equipped to help users diagnose issues in complex environments. The Goal (Theory of Constraints) illustrates the importance of understanding bottlenecks in a system. Only process ‘improvements’ at the bottlenecks will actually improve the overall system. In many organizations bottlenecks become hidden by excess inventory, overproduction, variability in processes and variability in routing or sequencing. By accurately documenting the system inside a simulation model it is possible to gain a bird’s eye view of the entire system.\n\nA working model of a system allows management to understand performance drivers. A simulation can be built to include any number of performance indicators such as worker utilization, on-time delivery rate, scrap rate, cash cycles, and so on.\n\nAn operating theater is generally shared between several surgical disciplines. Through better understanding the nature of these procedures it may be possible to increase the patient throughput.\nExample: If a heart surgery takes on average four hours, changing an operating room schedule from eight available hours to nine will not increase patient throughput. On the other hand, if a hernia procedure takes on average twenty minutes providing an extra hour may also not yield any increased throughput if the capacity and average time spent in the recovery room is not considered.\n\nMany systems improvement ideas are built on sound principles, proven methodologies (Lean, Six Sigma, TQM, etc.) yet fail to improve the overall system. A simulation model allows the user to understand and test a performance improvement idea in the context of the overall system.\n\nSimulation modeling is commonly used to model potential investments. Through modeling investments decision-makers can make informed decisions and evaluate potential alternatives.\n\nDiscrete event simulation is used in computer network to simulate new protocols for different network traffic scenarios before deployment.\n\nSystem modeling approaches:\nComputational techniques:\nSoftware:\nDisciplines:\n\n"}
{"id": "46482228", "url": "https://en.wikipedia.org/wiki?curid=46482228", "title": "Donald Roulet", "text": "Donald Roulet\n\nDonald Eugene Roulet was a Presbyterian minister, known for involvement in Civil Rights issues within the Presbyterian Church USA. Roulet was a founding member of the Progressive Religion Coalition of Tulsa, an organization that advocates for religious tolerance and inclusion.\n\nDonald Roulet became minister of the First Presbyterian Church of Broken Arrow, Oklahoma in 1963. Through this church, Roulet established community outreach programs in the Tulsa area providing meals to senior citizens, Alcoholics Anonymous and Food Pantry Programs. Most notably, he started the Chow and Chatter Club, which provides weekly lunch to senior citizens. He served on all major committees in the Eastern Oklahoma Presbytery, before retiring in 1991. Following retirement, he served as the Executive Presbyter of the Presbytery of Southern Louisiana. Roulet obtained a Master of Divinity from McCormick Theological Seminary, as well as two Doctoral Degrees in Ministry and Theology.\n\nDonald Eugene Roulet was born in 1936 in Beverly Hills, California. He was a member of the Franco-German Roulet family, a noble family from Alsace. After graduating from Tulsa University, he married his wife Wyneth in November, 1959. They have three grown children, Scott E. Roulet, a media executive, Michelle and Steven.\n\nRoulet was an Honorary Chaplain for the Oklahoma Senate, and an Honorary Mayor of the City of Broken Arrow. He had also been honored by the Louisiana House of Representatives.\n"}
{"id": "677451", "url": "https://en.wikipedia.org/wiki?curid=677451", "title": "Effect system", "text": "Effect system\n\nIn computing, an effect system is a formal system which describes the computational effects of computer programs, such as side effects. An effect system can be used to provide a compile-time check of the possible effects of the program.\n\nThe effect system extends the notion of type to have an \"effect\" component, which comprises an effect kind and a region. The effect kind describes \"what\" is being done, and the region describes \"with what\" it is being done.\n\nAn effect system is typically an extension of a type system. The term \"type and effect system\" is sometimes used in this case. Often, a type of a value is denoted together with its effect as \"type ! effect\", where both the type component and the effect component mention certain regions (for example, a type of a mutable memory cell is parameterized by the label of the memory region in which the cell resides).\n\nSome examples of the behaviors that can be described by effect systems include:\n\nEffect systems may be used to prove the external purity of certain internally impure definitions: for example, if a function internally allocates and modifies a region of memory, but the function's type does not mention the region, then the corresponding effect may be erased from the function's effect.\n\n\n"}
{"id": "46505206", "url": "https://en.wikipedia.org/wiki?curid=46505206", "title": "Egyptian Center for Economic and Social Rights", "text": "Egyptian Center for Economic and Social Rights\n\nThe Egyptian Center for Economic and Social Rights (ECESR) is an Egyptian non-governmental legal and research organization which addresses issues of Egyptian and Arabic human rights.\n\nThe ECESR sometimes coordinates with other NGOs to address human rights issues. In a report titled \"<nowiki>'</nowiki>Above the State<nowiki>'</nowiki>\" the ECESR suggested that increased foreign investment may not lead to improved conditions for most Egyptians.\n\nECESR offices have been subjected to multiple raids by Egyptian police leading to protest from numerous other agencies.\n\n"}
{"id": "41918859", "url": "https://en.wikipedia.org/wiki?curid=41918859", "title": "Ekagrata", "text": "Ekagrata\n\nEkāgratā (Sanskrit: एकाग्रता, \"one-pointedness\") is intent pursuit of one object, close and undisturbed attention. Yoga emphasises regular practice (\"Abhyasa\") meditation and self-imposed discipline to acquire ekagrata.\n\nThe faculty called Ekāgratā may be increased by integrating the psycho-mental flux (\"sarvārthatā\" or variously-directed, discontinuous, and diffuse attention) so that one gains genuine will and a happiness different from the experience of pleasure from sense-objects. It is harder to achieve if the body is in a tiring or uncomfortable posture or if the breathing is improper.\n\nAusterity (\"tapas\") is allied to this conception of \"ekagrata\"\n\nBadarayana's Brahma Sutras (chapter 3) uses the term to mean concentration: it is held to be a quality resulting from practices discussed in the previous chapter,which are briefly mentioned in the Brihadaranyaka Upanishad and Chandogya Upanishad. \n\nAccording to the Bhagavad Gita the seeker after Truth should meditate with his mind fixed on the Lord (\"machchittāh\") and absorbed in Him (\"matparāh\"). This is \"ekagrata\". The term \"nityayuktāh\" refers to devotees who keep their mind fixed on God uninterruptedly.\n\nPatanjali highlights the importance of continuous practice of prescribed methods to gain ekagrata, the state of the meditative mind free of diverted attention etc.; and thereafter explains that:-\n\nintentness on a single point (ekagrata) of the thinking principle (\"citta\") gives rise to equilibrium of placid states (previously accumulated impressions) and aroused states (present eagerness to gain more knowledge), which are modifications (of the mind). These two states of mind remain unchanged and are brought to the state of stillness. \"Ekagrata\" and \"dharana\" do not differ from each other, or else \"dharana\" is achieving and maintaining \"ekagrata\". \"Dharana\" converges on a particular concept or object. In the state of \"ekagrata\" there is clarity and right direction: yoga begins with ekagrata and culminates in \"nirodha\", a consciousness free of movement. \"Dharana\" gives the ability to see one’s own mind, one starts looking inwards deeply. If \"ekagrata\" is lost the full power of intention to achieve goals to be achieved is lost. Intentions afflicted by doubts, fears and reactive thoughts break and diffuse the energy of intentions. The mind which is the cause of \"Sankalpa\" ('notion')-\"Vikalpa\" ('alternative') must be controlled, it must be bound. Ekagrata assists in keeping one’s own mind bound and still.\n"}
{"id": "41130", "url": "https://en.wikipedia.org/wiki?curid=41130", "title": "Extinction ratio", "text": "Extinction ratio\n\nIn telecommunications, extinction ratio (\"r\") is the ratio of two optical power levels of a digital signal generated by an optical source, e.g., a laser diode. The extinction ratio may be expressed as a fraction, in dB, or as a percentage. It may be given by\nwhere \"P\" is the optical power level generated when the light source is on, and \"P\" is the power level generated when the light source is off.\n\nThe polarization extinction ratio (PER) is the ratio of optical powers of perpendicular polarizations, usually called TE (transverse electrical) and TM (transverse magnetic). In telecommunications, the PER is used to characterize the degree of polarization in a polarization-maintaining device or fiber. For coherent transmitter and receiver, the PER is a key parameter, since X polarization and Y polarization are coded with different signals.\n\n"}
{"id": "4611484", "url": "https://en.wikipedia.org/wiki?curid=4611484", "title": "Fail-fast", "text": "Fail-fast\n\nIn systems design, a fail-fast system is one which immediately reports at its interface any condition that is likely to indicate a failure. Fail-fast systems are usually designed to stop normal operation rather than attempt to continue a possibly flawed process. Such designs often check the system's state at several points in an operation, so any failures can be detected early. The responsibility of a fail-fast module is detecting errors, then letting the next-highest level of the system handle them.\n\nFail-fast systems or modules are desirable in several circumstances:\n\n\nDevelopers also refer to fail-fast code to a code that tries to fail as soon as possible at variable or object initialization. In OOP, a fail-fast designed object initializes the internal state of the object in the constructor, launching an exception if something is wrong (vs allowing non-initialized or partially initialized objects that will fail later due to a wrong \"setter\"). The object can then be made immutable if no more changes to the internal state are expected. In functions, fail-fast code will check input parameters in the precondition. In client-server architectures, fail-fast will check the client request just upon arrival, before processing or redirecting it to other internal components, returning an error if the request fails (incorrect parameters, ...). Fail-fast designed code decreases the internal software entropy, and reduces debugging effort.\n\nFrom the field of software engineering, a Fail Fast Iterator is an iterator that attempts to raise an error if the sequence of elements processed by the iterator is changed during iteration.\n\nThe term has been widely employed as a metaphor in business, dating back to at least 2001, meaning that businesses should undertake bold experiments to determine the longterm viability of a product or strategy, rather than proceeding cautiously and investing years in a doomed approach. It became adopted as a kind of \"mantra\" within startup culture.\n\n\n"}
{"id": "22681933", "url": "https://en.wikipedia.org/wiki?curid=22681933", "title": "Fair trade coffee", "text": "Fair trade coffee\n\nFair Trade coffee is coffee that is certified as having been produced to fair trade standards.\n\nFair trade organizations create trading partnerships that are based on dialogue, transparency and respect, that seeks greater equity in international trade. These partnerships contribute to sustainable development by offering better trading conditions to coffee bean farmers.\n\nFair trade organizations are engaged actively in supporting producers and sustainable environmental farming practices. Fair trade practices prohibit child or forced labor.\n\nPrior to fair trade, prices were regulated by the International Coffee Organization according to the regulations set forth by the International Coffee Agreement of 1962. The agreement, which was negotiated at the United Nations by the Coffee Study Group, set limits on the amount of coffee traded between countries so there would be no excess supply and consequent drop in price. The ICA existed for five years, and then was renewed in 1968.\n\nThe agreement was renegotiated in 1976 due to increasing coffee prices, largely a result of a severe frost in Brazil. The new agreement allowed for the suspension of price quotas if the supply of coffee could not meet the demand, and enabling them if prices dropped too low.\n\nIn 1984, the agreement was again redrawn, this time creating a database on coffee trade, and implementing stricter import and export regulations.\n\nFair trade certification was then introduced in 1988 following a coffee crisis in which the supply of coffee was greater than the demand; since no price quotas had been reimplemented by the International Coffee Act, the market was flooded. Launched in the Netherlands, fair trade certification aimed to artificially raise coffee prices in order to ensure growers sufficient wages to turn a profit. The original name of the organization was \"Max Havelaar\", after a fictional Dutch character who opposed the exploitation of coffee farmers by Dutch colonialists in the East Indies. The organization created a label for products that met certain wage standards.\n\nQuotas remained a part of the agreement until 1989, when the organization was unable to negotiate a new agreement in time for the next year. It was decided that the 1983 agreement would be extended, but without the quotas because they had not yet been determined. A new agreement could not be negotiated until 1992.\n\nFrom 1990 to 1992, without the quotas in place, coffee prices reached an all-time low because coffee price quotas could not be decided.\n\nThe agreements of 2001 and 2007 aimed to stabilize the coffee economy by promoting coffee consumption, raising the standard of living of growers by providing economic counselling, expanding research to include niche markets and quality relating to geographic area, and conducting studies of sustainability, principles similar to fair trade.\n\nFollowing the inception of fair trade certification, the \"Transfair\" label was later launched in Germany, and within ten years three other labeling organizations commenced: The Fairtrade Foundation, TransFair USA, and Rättvisemärkt. In 1997, these four organizations jointly created Fairtrade International (formerly called FLO, or Fairtrade Labelling Organizations International), which continues to set Fairtrade standards, inspecting and certifying growers.\n\nThe fair trade labeling organizations having most of the market share and who sell through supermarkets refer to a definition developed by FINE, an association of four international fair trade networks (Fairtrade Labelling Organizations International, World Fair Trade Organization (WFTO), Network of European World shops and European Fair Trade Association (EFTA)). The standards developed by Fairtrade Labelling Organization are the most widely used.\n\nThe certification scheme is run by Fairtrade International (FLO).\n\nCoffee packers pay Fairtrade a fee for the right to use the Fairtrade logo, which gives consumers an assurance that the coffee meets Fairtrade criteria. The coffee with this certification mark must be produced by farmers and cooperatives that meet these criteria.\n\nCoffee retailers are not restricted by Fairtrade to sell Fairtrade coffee as a premium product and charge as much as they like for the coffee.\n\nImporters of Fairtrade coffee have to be registered with Fairtrade and pay a fee. Under the Fairtrade International standards they are obliged to pay a minimum price to the exporting organization, currently $1.40c/lb New York Board of Trade “C” contract, F.O.B. origin for Arabica, and $1.05 for Robusta London “EURONEXT LIFFE” contract, F.O.B origin with 30c/lb extra for organic. When the world price is above this level, they are obliged to pay 20c/lb above the world price.\n\nCertified Fairtrade coffee is normally exported by secondary or tertiary cooperatives, marketing this coffee on behalf of the cooperatives the farmers belong to with arrangements that may be complex. There is not enough demand to take all the certified coffee produced, so most has to be sold as uncertified. In 2001 only 13.6% could be sold as certified so limits were placed on new cooperatives joining the scheme. This plus an increased demand put up sales of certified to around 50% in 2003 with a figure of 37% commonly cited in recent years. Some exporting cooperatives do not manage to sell any of their output as certified, and others sell as little as 8%.\n\nThe exporting cooperatives incur costs including certification and inspection fees, additional marketing costs, costs of conforming to standards, and additional costs of cooperative operation, costs which are incurred on all coffee production, even if little or none is marketed as certified, with a higher price, so the cooperatives may make a loss on Fairtrade membership. Weber reports cooperatives not able to cover the extra costs of a marketing team for Fairtrade, with one covering only 70% of these costs after six years of Fairtrade membership.\n\nAny deficit after paying these costs means a lower price for farmers, while any surplus will normally go on “social projects” for “common goals” organized by the exporting cooperative rather than as extra payment for farmers. These may include the building of classrooms, baseball fields, or the establishment of women's groups, for instance.\n\nFLO-CERT, a for-profit business owned by Fairtrade International, handles producer certification, inspecting and certifying producer organizations in more than 50 countries in Africa, Asia, and Latin America. In the fair trade debate there are many complaints of failure to enforce these standards, with farmers, cooperatives, importers and packers.\n\nThe marketing system for Fairtrade and non-Fairtrade coffee is identical in the consuming countries, using mostly the same importing, packing, distributing and retailing firms. Some independent brands operate a virtual company, paying the normal importers, packers and distributors and advertising agencies to handle their brand rather than doing it themselves, for cost reasons.\n\nMany fair trade organizations remain that adhere to a greater or smaller degree to the original objectives of fair trade than the mainstream of Fairtrade International and its associate. These market products through alternative channels where possible, and market through specialist fair trade shops, but they have a small proportion of the total market.\n\nCriticisms of fair trade have been made as a result of independent research, and these are summarized in the fair trade debate.\n\nThere are also some criticisms of fair trade specific to coffee. Colleen Haight of the Stanford Innovation Review argues that fair trade coffee is merely a way to market the idea of ethical consumerism. Quality and transparency concerns regarding coffee are increasingly common amongst some consumers and coffee companies, as seen through the rise of the third wave coffee movement. Maintaining a balance between ethical and higher-quality coffee may be difficult with fair trade coffee due to what some coffee roasters deem as insufficient quality incentive within many fair-trade certified coffee farms. Deborah Sick’s research, involving interviews with coffee farmers in Costa Rica, finds that many farmers often produce more fair trade coffee than they can sell, so will often end up selling to independent buyers that will often pay more than fair trade buyers can. Some scholars are concerned of the artificial stimulation of coffee production, especially since worldwide demand for coffee is relatively inelastic.\n\nMany who believe fair trade coffee is insufficient utilize the direct trade model, which allows for more control over quality concerns, farmer empowerment, and sustainability issues. It also is valuable in harboring closer farmer to roaster business relationships, which can ultimately increase quality of life and profits for coffee growers and buyers alike. However, direct trade is a new concept that is only utilized by for profit businesses like Counter Culture Coffee and Intelligentsia Coffee and therefore has no third party certification.\n\n"}
{"id": "37676715", "url": "https://en.wikipedia.org/wiki?curid=37676715", "title": "Freedom of religion in South Africa", "text": "Freedom of religion in South Africa\n\nSouth Africa is a secular state, with freedom of religion enshrined in the Constitution.\n\nThe preamble to post-apartheid South Africa's Constitution of 1996 contains references to God in the form of a multilingual evocation asking for God's protection and blessing. Dutch theologian Johannes van der Ven describes this text as a \"rhetorical petition prayer\". The Constitution nevertheless enshrines the right to freedom of religion.\n\nChapter 2 of the Constitution of South Africa, the Bill of Rights, contains a number of provisions dealing with religious freedom. Section 9, the equality clause, prohibits unfair discrimination on various grounds including religion and requires national legislation to be enacted to prevent or prohibit unfair discrimination. Section 15 states that everyone has the right to freedom of conscience, religion, thought, belief and opinion. This section also allows religious observances in state and state-aided institutions, provided they follow public authority rules, they are conducted on an equitable basis and attendance is free and voluntary; and provides for the recognition of religious legal systems and marriages that are not inconsistent with the Constitution. Section 31 protects the right of persons belonging to a religious community to practise their religion together with other members of that community, and to form, join and maintain voluntary religious associations.\n\nVarious other provisions of the Constitution relate to religion and religious freedom. Sections 185 and 186 provide for a commission for the promotion and protection of the rights of cultural, religious and linguistic communities. In addition, human rights such as the right to human dignity, the right to freedom of expression and the right to freedom of association relate indirectly to the protection of religious freedom. The right to freedom of expression does not extend to hate speech based on various grounds including religion.\n\nThe constitutional right to freedom of religion is not absolute. In his keynote speech at the public endorsement ceremony of the \"South African Charter of Religious Rights and Freedoms\" in Johannesburg on 21 October 2010 Deputy Chief Justice Dikgang Moseneke stated:\n\n<poem></poem>\n\nPursuant to Section 9 of the Constitution, the Equality Act of 2000 prohibits unfair discrimination on various grounds including religion. The Equality Act does not apply to unfair discrimination in the workplace, which is covered by the Employment Equity Act.\n\nThe South African Human Rights Commission (SAHRC) is a chapter nine institution inaugurated in 1995 to support constitutional democracy. The SAHRC investigates complaints about unfair discrimination and assists members of the public with cases heard in Equality Courts.\n\nThe Commission for the Promotion and Protection of the Rights of Cultural, Religious and Linguistic Communities (CRL Rights Commission) is a chapter nine institution established in 2004 to support constitutional democracy.\n\nNational legislation and policies governing religion in schools relate to Religion Education, religious observances in schools and school dress codes:\n\nIn August 2014 the \"Organisasie vir Godsdienste-Onderrig en Demokrasie\" (\"Organisation for Religion Education and Democracy\") (OGOD) filed an application in the South Gauteng High Court to stop several public schools from describing themselves as Christian or promoting a Christian ethos in contravention of the constitution. All six schools named in the application were Afrikaans-medium public schools and their school governing bodies were members of the Federation of Governing Bodies of South African Schools (FEDSAS). The outcome of the test case applies to all public schools however. The named schools opposed the case and were supported in this by FEDSAS, AfriForum, the Freedom Front Plus political party and the African Christian Democratic Party. In June 2017 the court ruled that it is unlawful for a public school or school governing body, which function in a diverse society, to practise single faith branding aligned with one dominant religion to the exclusion of others. The schools decided not to appeal the court's ruling.\n\nThe new Constitution did not result in immediate reform of discriminatory legislation infringing on the right to religious freedom. Various legislative reforms have taken place or have been initiated since 1994 as a result of lobbying by disenfranchised groups.\n\nThe Civil Union Act, which came into effect on 30 November 2006, legalised same-sex marriage and also allowed for the legal designation of religious marriage officers without any religious restriction in accordance with the Constitution. Previously, religious marriage officers could only be legally designated as such \"for the purpose of solemnizing marriages according to Christian, Jewish or Mohammedan rites or the rites of any Indian religion\" in accordance with the Marriage Act. In accordance with section 5 of the Civil Union Act, any religious organisation may apply to the Department of Home Affairs for designation as a religious organisation and when designated as such must formally nominate suitable candidates from within their organisation to be designated by the Department of Home Affairs as religious marriage officers for the purpose of solemnising marriages according to the rites of that religious organisation.\n\nThe Witchcraft Suppression Act of 1957 based on colonial witchcraft legislation criminalises claiming a knowledge of witchcraft, conducting specified practices associated with witchcraft including the use of charms and divination, and accusing others of practising witchcraft. In 2007 the South African Law Reform Commission received submissions from the South African Pagan Rights Alliance and the Traditional Healers Organization requesting the investigation of the constitutionality of the act and on 23 March 2010 the Minister of Justice and Constitutional Development approved a South African Law Reform Commission project to review witchcraft legislation.\n\nThe Christian holidays of Christmas Day and Good Friday remained in post-apartheid South Africa's calendar of public holidays. The CRL Rights Commission held countrywide consultative public hearings in June and July 2012 to assess the need for a review of public holidays following the receipt of complaints from minority groups about unfair discrimination. The CRL Rights Commission stated that they would submit their recommendations to the Department of Home Affairs, the Department of Labour, various Portfolio Committees and the Office of the Presidency. The CRL Rights Commission published its recommendations on 17 April 2013, including the scrapping of some existing public holidays to free up days for some non-Christian religious public holidays. On 18 January 2015 the South African Law Reform Commission published a discussion document on legislation administered by the Department of Home Affairs in which it suggested \"that either these holidays be reviewed or that equal weight be given to holidays of other faiths\".\n\n\n\n\n"}
{"id": "2225961", "url": "https://en.wikipedia.org/wiki?curid=2225961", "title": "Functional block diagram", "text": "Functional block diagram\n\nA functional block diagram in systems engineering and software engineering is a block diagram. It describes the functions and interrelationships of a system. \n\nThe functional block diagram can picture:\nThe block diagram can use additional schematic symbols to show particular properties. \n\nFunctional block diagrams have been used in a wide range applications, from systems engineering to software engineering, since the late 1950s. They became a necessity in complex systems design to \"understand thoroughly from exterior design the operation of the present system and the relationship of each of the parts to the whole.\" \n\nMany specific types of functional block diagrams have emerged. For example, the functional flow block diagram is a combination of the functional block diagram and the flow chart. Many software development methodologies are built with specific functional block diagram techniques. An example from the field of industrial computing is the Function Block Diagram (FBD), a graphical language for the design of programmable logic controllers.\n\n"}
{"id": "27879368", "url": "https://en.wikipedia.org/wiki?curid=27879368", "title": "Functional divergence", "text": "Functional divergence\n\nFunctional divergence is the process by which genes, after gene duplication, shift in function from an ancestral function. Functional divergence can result in either subfunctionalization, where a paralog specializes one of several ancestral functions, or neofunctionalization, where a totally new functional capability evolves. It is thought that this process of gene duplication and functional divergence is a major originator of molecular novelty and has produced the many large protein families that exist today.\n\nFunctional divergence is just one possible outcome of gene duplication events. Other fates include nonfunctionalization where one of the paralogs acquires deleterious mutations and becomes a pseudogene and superfunctionalization (reinforcement), where both paralogs maintain original function. While gene, chromosome, or whole genome duplication events are considered the canonical sources of functional divergence of paralogs, orthologs (genes descended from speciation events) can also undergo functional divergence and horizontal gene transfer can also result in multiple copies of a gene in a genome, providing the opportunity for functional divergence.\n\nMany well known protein families are the result of this process, such as the ancient gene duplication event that led to the divergence of hemoglobin and myoglobin, the more recent duplication events that led to the various subunit expansions (alpha and beta) of vertebrate hemoglobins, or the expansion of G-protein alpha subunits \n\n"}
{"id": "14041062", "url": "https://en.wikipedia.org/wiki?curid=14041062", "title": "Function–means tree", "text": "Function–means tree\n\nIn engineering design, a function–means tree (a.k.a. function/means tree or F/M tree) is a method for functional decomposition and concept generation. At the top level, main functions are identified. Under each function, a means (or solution element) is attached. Alternative solution elements can also be attached. Each means is in turn decomposed into functions with means attached to each of them. A well-elaborated function means tree span, a design space where all concepts under consideration are represented. Requirements can be attached to functions.\n\nIn addition to product level requirements, there might be requirements on sub functions that may be a consequence of means at a higher level. The function means tree is a tool that can aid in the creative part of the design process. It can also be a tool for mapping requirements to parts in a design. This requires that there be also a mapping between means and parts in the product architecture.\n\n"}
{"id": "18152714", "url": "https://en.wikipedia.org/wiki?curid=18152714", "title": "Ipse dixit", "text": "Ipse dixit\n\nIpse dixit (Latin for \"he said it himself\") is an assertion without proof; or a dogmatic expression of opinion. \n\nThe fallacy of defending a proposition by baldly asserting that it is \"just how it is\" distorts the argument by opting out of it entirely: the claimant declares an issue to be intrinsic, and not changeable.\n\nThe Latin form of the expression comes from the Roman orator and philosopher Marcus Tullius Cicero (106–43 BC) in his theological studies \"De Natura Deorum\" (\"On the Nature of the Gods\") and is his translation of the Greek expression (with the identical meaning) αὐτὸς ἔφα (\"autòs épha\"), an argument from authority made by the disciples of Pythagoras when appealing to the pronouncements of the master rather than to reason or evidence.\n\nBefore the early 17th century, scholars applied the \"ipse dixit\" term to justify their subject-matter arguments if the arguments previously had been used by the ancient Greek philosopher Aristotle (384–322 BC).\n\nIn the late 18th century, Jeremy Bentham adapted the term \"ipse dixit\" into the word \"ipse-dixitism.\" Bentham coined the term to apply to all non-utilitarian political arguments.\n\nIn modern legal and administrative decisions, the term \"ipse dixit\" has generally been used as a criticism of arguments based solely upon the authority of an individual or organization. For example, in \"National Tire Dealers & Retreaders Association, Inc. v. Brinegar,\" 491 F.2d 31, 40 (D.C. Cir. 1974), Circuit Judge Wilkey considered that the Secretary of Transportation's \"statement of the reasons for his conclusion that the requirements are practicable is not so inherently plausible that the court can accept it on the agency's mere \"ipse dixit\"\". \n\nIn 1997, the U.S. Supreme Court recognized the problem of \"opinion evidence which is connected to existing data only by the \"ipse dixit\" of an expert\". Likewise, the Texas Supreme Court has held \"a claim will not stand or fall on the mere \"ipse dixit\" of a credentialed witness\". \n\nIn 1858, Abraham Lincoln said in his speech at Freeport, Illinois, at the second joint debate with Douglas:\n\nI pass one or two points I have because my time will very soon expire, but I must be allowed to say that Judge Douglas recurs again, as he did upon one or two other occasions, to the enormity of Lincoln,—an insignificant individual like Lincoln,— upon his \"ipse dixit\" charging a conspiracy upon a large number of members of Congress, the Supreme Court, and two Presidents, to nationalize slavery. I want to say that, in the first place, I have made no charge of any sort upon my \"ipse dixit\". I have only arrayed the evidence tending to prove it, and presented it to the understanding of others, saying what I think it proves, but giving you the means of judging whether it proves it or not. This is precisely what I have done. I have not placed it upon my \"ipse dixit\" at all.\n\n\n"}
{"id": "2502518", "url": "https://en.wikipedia.org/wiki?curid=2502518", "title": "Kan extension", "text": "Kan extension\n\nKan extensions are universal constructs in category theory, a branch of mathematics. They are closely related to adjoints, but are also related to limits and ends. They are named after Daniel M. Kan, who constructed certain (Kan) extensions using limits in 1960.\n\nAn early use of (what is now known as) a Kan extension from 1956 was in homological algebra to compute derived functors.\n\nIn \"Categories for the Working Mathematician\" Saunders Mac Lane titled a section \"All Concepts Are Kan Extensions\", and went on to write that\n\nKan extensions generalize the notion of extending a function defined on a subset to a function defined on the whole set. The definition, not surprisingly, is at a high level of abstraction. When specialised to posets, it becomes a relatively familiar type of question on constrained optimization.\n\nA Kan extension proceeds from the data of three categories \n\nand two functors\n\nand comes in two varieties: the \"left\" Kan extension and the \"right\" Kan extension of formula_3 along formula_4.\n\nIt amounts to finding the dashed arrow and the 2-cell formula_5 in the following diagram:\n\nFormally, the \"right Kan extension of formula_3 along formula_4\" consists of a functor formula_13 and a natural transformation formula_14 which is couniversal with respect to the specification, in the sense that for any functor formula_15 and natural transformation formula_16, a unique natural transformation formula_17 is defined and fits into a commutative diagram\n\nThe functor \"R\" is often written formula_22.\n\nAs with the other universal constructs in category theory, the \"left\" version of the Kan extension is dual to the \"right\" one and is obtained by replacing all categories by their opposites. The effect of this on the description above is merely to reverse the direction of the natural transformations (recall that a natural transformation formula_23 between the functors formula_24 consists of the data of an arrow formula_25 for every object formula_20 of formula_27, satisfying a \"naturality\" property. When we pass to the opposite categories, the source and target of formula_28 are swapped, causing formula_23 to act in the opposite direction).\n\nThis gives rise to the alternate description: the \"left Kan extension of formula_3 along formula_4\" consists of a functor formula_32 and a natural transformation formula_33 which are universal with respect to this specification, in the sense that for any other functor formula_15 and natural transformation formula_35, a unique natural transformation formula_36 exists and fits into a commutative diagram:\n\nThe functor \"L\" is often written formula_41.\n\nThe use of the word \"the\" (as in \"the left Kan extension\") is justified by the fact that, as with all universal constructions, if the object defined exists, then it is unique up to unique isomorphism. In this case, that means that (for left Kan extensions) if formula_42 are two left Kan extensions of formula_3 along formula_4, and formula_45 are the corresponding transformations, then there exists a unique \"isomorphism\" of functors formula_36 such that the second diagram above commutes. Likewise for right Kan extensions.\n\nSuppose that formula_47 and formula_48 are two functors. If A is small and C is cocomplete, then there exists a left Kan extension formula_49 of formula_3 along formula_4, defined at each object \"b\" of B by\n\nwhere the colimit is taken over the comma category formula_53.\n\nDually, if A is small and C is complete, then right Kan extensions along formula_4 exist, and can be computed as limits.\n\nSuppose that\n\nare two functors such that for all objects \"m\" and \"m of M and all objects \"c\" of C, the copowers formula_57 exist in A. Then the functor \"T\" has a left Kan extension \"L\" along \"K\", which is such that, for every object \"c\" of C\"',\n\nwhen the above coend exists for every object \"c\" of C.\n\nDually, right Kan extensions can be computed by the end formula\n\nThe limit of a functor formula_60 can be expressed as a Kan extension by\n\nwhere formula_62 is the unique functor from formula_63 to 𝟙 (the category with one object and one arrow, a terminal object in formula_64). The colimit of formula_4 can be expressed similarly by\n\nA functor formula_67 possesses a left adjoint if and only if the right Kan extension of formula_68 along formula_4 exists and is preserved by formula_4. In this case, a left adjoint is given by formula_71 and this Kan extension is even preserved by any functor formula_72 whatsoever, i.e. is an \"absolute\" Kan extension.\n\nDually, a right adjoint exists if and only if the left Kan extension of the identity along formula_4 exists and is preserved by formula_4.\n\n\n"}
{"id": "352635", "url": "https://en.wikipedia.org/wiki?curid=352635", "title": "Matheme", "text": "Matheme\n\nThe matheme (from \"lesson\") is a concept introduced in the work of the 20th century French psychoanalyst Jacques Lacan. The term matheme 'occurred for the first time in the lecture Lacan delivered on November 4, 1971...Between 1972 and 1973 he gave several definitions of it, passing from the use of the singular to the use of the plural and back again'.\n\n'Lacan saw his \"matheme\" as something that would ensure the integral transmission of his teachings...proof against the \"noise\" or interference inherent in any process of communication'.\n\nThey are formulae, designed as symbolic representations of his ideas and analyses. They were intended to introduce some degree of technical rigour in philosophical and psychological writing, replacing the often hard-to-understand verbal descriptions with formulae resembling those used in the hard sciences, and as an easy way to hold, remember, and rehearse some of the core ideas of both Freud and Lacan. For example: \"$<>a\" is the matheme for fantasy in the Lacanian sense, in which \"$\" refers to the subject as split into conscious and unconscious (hence the matheme is a barred S), \"a\" stands for the object-cause of desire, and \"<>\" stands for the relationship between the two.\n\nA more complex set of mathemes are Lacan's 'formulae of sexuation,' which he popularized in the March 13, 1973 session of his \"Seminar XX\". Composed of two pairs of propositions written in a unique logico-mathematical shorthand inspired by Gottlob Frege, one pair was dubbed 'masculine' and the other 'feminine.' These formulae Lacan originally constructed from Aristotelian logic over the course of an entire year of study.\n\n\"Matheme\", for Lacan, was not simply the imitation of science by philosophy, but the ideal of a perfect means for the integral transmission of knowledge. Natural language, with its constant \"metonymic slide\", fails here, where mathematics succeeds. Contemporary philosopher Alain Badiou identifies \"matheme\" with the scientific procedure.\n\nThough sometimes disparaged as a case of \"physics envy\" or accused of introducing false rigor into a discipline that is more literary theory than hard science, there is also something of a sense of humor in Lacan's formulas: of one 'sigla which I have introduced in the form of an algorithm', Lacan himself has declared that 'it is created to allow for a hundred and one different readings, a multiplicity that is admissible as long as the spoken remains caught in its algebra'.\n\nSerge Leclaire, who is one of the most respected and distinguished of all French analysts, remarked in 1975, for example, that whilst the mathemes might have a certain pedagogic utility, they were basically no more than \"graffiti\"'.\n\n"}
{"id": "97536", "url": "https://en.wikipedia.org/wiki?curid=97536", "title": "Modern synthesis (20th century)", "text": "Modern synthesis (20th century)\n\nThe modern synthesis was the early 20th-century synthesis reconciling Charles Darwin's theory of evolution and Gregor Mendel's ideas on heredity in a joint mathematical framework. Julian Huxley coined the term in his 1942 book, \"\".\n\nThe 19th century ideas of natural selection and Mendelian genetics were put together with population genetics, early in the twentieth century. The modern synthesis also addressed the relationship between the broad-scale changes of macroevolution seen by palaeontologists and the small-scale microevolution of local populations of living organisms. The synthesis was defined differently by its founders, with Ernst Mayr in 1959, G. Ledyard Stebbins in 1966 and Theodosius Dobzhansky in 1974 offering differing numbers of basic postulates, though they all included natural selection, working on heritable variation supplied by mutation. Other major figures in the synthesis included E. B. Ford, Bernhard Rensch, Ivan Schmalhausen, and George Gaylord Simpson. An early event in the modern synthesis was R. A. Fisher's 1918 paper on mathematical population genetics, but William Bateson, and separately Udny Yule, were already starting to show how Mendelian genetics could work in evolution in 1902.\n\nDifferent syntheses followed, accompanying the gradual breakup of the early 20th century synthesis, including with social behaviour in E. O. Wilson's sociobiology in 1975, evolutionary developmental biology's integration of embryology with genetics and evolution, starting in 1977, and Massimo Pigliucci's proposed extended evolutionary synthesis of 2007. In the view of the evolutionary biologist Eugene Koonin in 2009, the modern synthesis will be replaced by a 'post-modern' synthesis that will include revolutionary changes in molecular biology, the study of prokaryotes and the resulting tree of life, and genomics.\n\nCharles Darwin's 1859 book \"On the Origin of Species\" was successful in convincing most biologists that evolution had occurred, but was less successful in convincing them that natural selection was its primary mechanism. In the 19th and early 20th centuries, variations of Lamarckism (inheritance of acquired characteristics), orthogenesis (progressive evolution), saltationism (evolution by jumps) and mutationism (evolution driven by mutations) were discussed as alternatives. Alfred Russel Wallace advocated a selectionist version of evolution, and unlike Darwin completely rejected Lamarckism. In 1880, Wallace's view was labelled neo-Darwinism by Samuel Butler. \n\nFrom the 1880s onwards, there was a widespread belief among biologists that Darwinian evolution was in deep trouble. This eclipse of Darwinism (in Julian Huxley's phrase) grew out of the weaknesses in Darwin's account, written with an incorrect view of inheritance. Darwin himself believed in blending inheritance, which implied that any new variation, even if beneficial, would be weakened by 50% at each generation, as the engineer Fleeming Jenkin correctly noted in 1868. This in turn meant that small variations would not survive long enough to be selected. Blending would therefore directly oppose natural selection. In addition, Darwin and others considered Lamarckian inheritance of acquired characteristics entirely possible, and Darwin's 1868 theory of pangenesis, with contributions to the next generation (gemmules) flowing from all parts of the body, actually implied Lamarckism as well as blending.\n\nAugust Weismann's idea, set out in his 1892 book \"Das Keimplasma: eine Theorie der Vererbung\" (The Germ Plasm: a Theory of Inheritance), was that the hereditary material, which he called the germ plasm, and the rest of the body (the soma) had a one-way relationship: the germ-plasm formed the body, but the body did not influence the germ-plasm, except indirectly in its participation in a population subject to natural selection. If correct, this made Darwin's pangenesis wrong, and Lamarckian inheritance impossible. His experiment on mice, cutting off their tails and showing that their offspring had normal tails, demonstrated that inheritance was 'hard'. He argued strongly and dogmatically for Darwinism and against Lamarckism, polarising opinions among other scientists. This increased anti-Darwinian feeling, contributing to its eclipse.\n\nWhile carrying out breeding experiments to clarify the mechanism of inheritance in 1900, Hugo de Vries and Carl Correns independently rediscovered Gregor Mendel's work. News of this reached William Bateson in England, who reported on the paper during a presentation to the Royal Horticultural Society in May 1900. In Mendelian inheritance, the contributions of each parent retain their integrity rather than blending with the contribution of the other parent. In the case of a cross between two true-breeding varieties such as Mendel's round and wrinkled peas, the first-generation offspring are all alike, in this case all round. Allowing these to cross, the original characteristics reappear (segregation): about 3/4 of their offspring are round, 1/4 wrinkled. There is a discontinuity between the appearance of the offspring; de Vries coined the term allele for a variant form of an inherited characteristic. This reinforced a major division of thought, already present in the 1890s, between gradualists who followed Darwin, and saltationists such as Bateson.\n\nThe two schools were the Mendelians, such as Bateson and de Vries, who favoured mutationism, evolution driven by mutation, based on genes whose alleles segregated discretely like Mendel's peas; and the biometric school, led by Karl Pearson and Walter Weldon. The biometricians argued vigorously against mutationism, saying that empirical evidence indicated that variation was continuous in most organisms, not discrete as Mendelism seemed to predict; they wrongly believed that Mendelism inevitably implied evolution in discontinuous jumps.\n\nA traditional view is that the biometricians and the Mendelians rejected natural selection and argued for their separate theories for 20 years, the debate only resolved by the development of population genetics.\nA more recent view is that Bateson, de Vries, Thomas Hunt Morgan and Reginald Punnett had by 1918 formed a synthesis of Mendelism and mutationism. The understanding achieved by these geneticists spanned the action of natural selection on alleles (alternative forms of a gene), the Hardy-Weinberg equilibrium, the evolution of continuously-varying traits (like height), and the probability that a new mutation will become fixed. In this view, the early geneticists accepted natural selection but rejected Darwin's non-Mendelian ideas about variation and heredity, and the synthesis began soon after 1900. The traditional claim that Mendelians rejected the idea of continuous variation is false; as early as 1902, Bateson and Saunders wrote that \"If there were even so few as, say, four or five pairs of possible allelomorphs, the various homo- and hetero-zygous combinations might, on seriation, give so near an approach to a continuous curve, that the purity of the elements would be unsuspected\". Also in 1902, the statistician Udny Yule showed mathematically that given multiple factors, Mendel's theory enabled continuous variation. Yule criticised Bateson's approach as confrontational, but failed to prevent the Mendelians and the biometricians from falling out.\n\nStarting in 1906, William Castle carried out a long study of the effect of selection on coat colour in rats. The piebald or hooded pattern was recessive to the grey wild type. He crossed hooded rats with the black-backed Irish type, and then back-crossed the offspring with pure hooded rats. The dark stripe on the back was bigger. He then tried selecting different groups for bigger or smaller stripes for 5 generations, and found that it was possible to change the characteristics way beyond the initial range of variation. This effectively refuted de Vries's claim that continuous variation was caused by the environment and could not be inherited. By 1911 Castle noted that the results could be explained by Darwinian selection on heritable variation of a sufficient number of Mendelian genes.\n\nThomas Hunt Morgan began his career in genetics as a saltationist, and started out trying to demonstrate that mutations could produce new species in fruit flies. However, the experimental work at his lab with the fruit fly, \"Drosophila melanogaster\" demonstrated that rather than creating new species in a single step, mutations increased the supply of genetic variation in the population. By 1912, after years of work on the genetics of fruit flies, Morgan showed that these insects had many small Mendelian factors (discovered as mutant flies) on which Darwinian evolution could work as if variation was fully continuous. The way was open for geneticists to conclude that Mendelism supported Darwinism.\n\nThe theoretical biologist and philosopher of biology Joseph Henry Woodger led the introduction of positivism into biology with his 1929 book \"Biological Principles\". He saw a mature science as being characterised by a framework of hypotheses that could be verified by facts established by experiments. He criticised the traditional natural history style of biology, including the study of evolution, as immature science, since it relied on narrative. Woodger set out to play for biology the role of Robert Boyle's 1661 \"Sceptical Chymist\", intending to convert the subject into a formal, unified science, and ultimately, following the Vienna Circle of logical positivists like Otto Neurath and Rudolf Carnap, to reduce biology to physics and chemistry. His efforts stimulated the biologist J. B. S. Haldane to push for the axiomatisation of biology, and by influencing thinkers such as Huxley, helped to bring about the modern synthesis. The positivist climate made natural history unfashionable, and in America, research and university-level teaching on evolution declined almost to nothing by the late 1930s. The Harvard physiologist William John Crozier told his students that evolution was not even a science: \"You can't experiment with two million years!\"\n\nThe tide of opinion turned with the adoption of mathematical modelling and controlled experimentation in population genetics, combining genetics, ecology and evolution in a framework acceptable to positivism.\n\nIn 1918, R. A. Fisher wrote the paper \"The Correlation between Relatives on the Supposition of Mendelian Inheritance,\" which showed mathematically how continuous variation could result from a number of discrete genetic loci. In this and subsequent papers culminating in his 1930 book \"The Genetical Theory of Natural Selection\", Fisher showed how Mendelian genetics was consistent with the idea of evolution driven by natural selection.\n\nDuring the 1920s, a series of papers by J. B. S. Haldane applied mathematical analysis to real-world examples of natural selection, such as the evolution of industrial melanism in peppered moths. Haldane established that natural selection could work even faster than Fisher had assumed. Both workers, and others such as Dobzhansky and Wright, explicitly intended to bring biology up to the philosophical standard of the physical sciences, making it firmly based in mathematical modelling, its predictions confirmed by experiment. Natural selection, once considered hopelessly unverifiable speculation about history, was becoming predictable, measurable, and testable.\n\nThe traditional view is that developmental biology played little part in the modern synthesis, but in his 1930 book \"Embryos and Ancestors\", the evolutionary embryologist Gavin de Beer anticipated evolutionary developmental biology by showing that evolution could occur by heterochrony, such as in the retention of juvenile features in the adult. This, de Beer argued, could cause apparently sudden changes in the fossil record, since embryos fossilise poorly. As the gaps in the fossil record had been used as an argument against Darwin's gradualist evolution, de Beer's explanation supported the Darwinian position.\nHowever, despite de Beer, the modern synthesis largely ignored embryonic development to explain the form of organisms, since population genetics appeared to be an adequate explanation of how forms evolved.\n\nThe population geneticist Sewall Wright focused on combinations of genes that interacted as complexes, and the effects of inbreeding on small relatively isolated populations, which could be subject to genetic drift. In a 1932 paper, he introduced the concept of an adaptive landscape in which phenomena such as cross breeding and genetic drift in small populations could push them away from adaptive peaks, which would in turn allow natural selection to push them towards new adaptive peaks. Wright's model would appeal to field naturalists such as Theodosius Dobzhansky and Ernst Mayr who were becoming aware of the importance of geographical isolation in real world populations. The work of Fisher, Haldane and Wright helped to found the discipline of theoretical population genetics.\n\nTheodosius Dobzhansky, an emigrant from the Soviet Union to the United States, who had been a postdoctoral worker in Morgan's fruit fly lab, was one of the first to apply genetics to natural populations. He worked mostly with \"Drosophila pseudoobscura\". He says pointedly: \"Russia has a variety of climates from the Arctic to sub-tropical... Exclusively laboratory workers who neither possess nor wish to have any knowledge of living beings in nature were and are in a minority.\" Not surprisingly, there were other Russian geneticists with similar ideas, though for some time their work was known to only a few in the West. His 1937 work \"Genetics and the Origin of Species\" was a key step in bridging the gap between population geneticists and field naturalists. It presented the conclusions reached by Fisher, Haldane, and especially Wright in their highly mathematical papers in a form that was easily accessible to others. Further, Dobzhansky asserted that evolution was based on material genes, arranged in a string on physical hereditary structures, the chromosomes, and linked more or less strongly to each other according to their physical distances from each other on the chromosomes. As with Haldane and Fisher, Dobzhansky's \"evolutionary genetics\" was a genuine science, now unifying cell biology, genetics, and both micro- and macroevolution. His work emphasized that real world populations had far more genetic variability than the early population geneticists had assumed in their models, and that genetically distinct sub-populations were important. Dobzhansky argued that natural selection worked to maintain genetic diversity as well as driving change. He was influenced by his exposure in the 1920s to the work of Sergei Chetverikov, who had looked at the role of recessive genes in maintaining a reservoir of genetic variability in a population before his work was shut down by the rise of Lysenkoism in the Soviet Union. By 1937, Dobzhansky was able to argue that mutations were the main source of evolutionary changes and variability, along with chromosome rearrangements, effects of genes on their neighbours during development, and polyploidy. Next, genetic drift (he used the term in 1941), selection, migration, and geographical isolation could change gene frequencies. Thirdly, mechanisms like ecological or sexual isolation and hybrid sterility could fix the results of the earlier processes.\n\nE. B. Ford was an experimental naturalist who wanted to test natural selection in nature, virtually inventing the field of ecological genetics. His work on natural selection in wild populations of butterflies and moths was the first to show that predictions made by R. A. Fisher were correct. In 1940, he was the first to describe and define genetic polymorphism, and to predict that human blood group polymorphisms might be maintained in the population by providing some protection against disease. His 1949 book \"Mendelism and Evolution\" helped to persuade Dobzhansky to change the emphasis in the third edition of his famous textbook \"Genetics and the Origin of Species\" from drift to selection.\n\nIvan Schmalhausen developed the theory of stabilizing selection, the idea that selection can preserve a trait at some value, publishing a paper in Russian titled \"Stabilizing selection and its place among factors of evolution\" in 1941 and a monograph \"Factors of Evolution: The Theory of Stabilizing Selection\" in 1945. He developed it from J. M. Baldwin's 1902 concept that changes induced by the environment will ultimately be replaced by hereditary changes (including the Baldwin effect on behaviour), following that theory's implications to their Darwinian conclusion, and bringing him into conflict with Lysenkoism. Schmalhausen observed that stabilizing selection would remove most variations from the norm, most mutations being harmful. Dobzhansky called the work \"an important missing link in the modern view of evolution\".\n\nIn 1942, Julian Huxley's serious but popularising \"\" introduced a name for the synthesis and intentionally set out to promote a \"synthetic point of view\" on the evolutionary process. He imagined a wide synthesis of many sciences: genetics, developmental physiology, ecology, systematics, palaeontology, cytology, and mathematical analysis of biology, and assumed that evolution would proceed differently in different groups of organisms according to how their genetic material was organised and their strategies for reproduction, leading to progressive but varying evolutionary trends. His vision was of an \"evolutionary humanism\", with a system of ethics and a meaningful place for \"Man\" in the world grounded in a unified theory of evolution which would demonstrate progress leading to man at its summit. Natural selection was in his view a \"fact of nature capable of verification by observation and experiment\", while the \"period of synthesis\" of the 1920s and 1930s had formed a \"more unified science\", rivalling physics and enabling the \"rebirth of Darwinism\".\n\nHowever, the book was not the research text that it appeared to be. In the view of the philosopher of science Michael Ruse, and in Huxley's own opinion, Huxley was \"a generalist, a synthesizer of ideas, rather than a specialist\". Ruse observes that Huxley wrote as if he were adding empirical evidence to the mathematical framework established by Fisher and the population geneticists, but that this was not so. Huxley avoided mathematics, for instance not even mentioning Fisher's fundamental theorem of natural selection. Instead, Huxley used a mass of examples to demonstrate that natural selection is powerful, and that it works on Mendelian genes. The book was successful in its goal of persuading readers of the reality of evolution, effectively illustrating topics such as island biogeography, speciation, and competition. Huxley further showed that the appearance of long-term orthogenetic trends – predictable directions for evolution – in the fossil record were readily explained as allometric growth (since parts are interconnected). All the same, Huxley did not reject orthogenesis out of hand, but maintained a belief in progress all his life, with \"Homo sapiens\" as the end point, and he had since 1912 been influenced by the vitalist philosopher Henri Bergson, though in public he maintained an atheistic position on evolution. Huxley's belief in progress within evolution and evolutionary humanism was shared in various forms by Dobzhansky, Mayr, Simpson and Stebbins, all of them writing about \"the future of Mankind\". Both Huxley and Dobzhansky admired the palaeontologist priest Pierre Teilhard de Chardin, Huxley writing the introduction to Teilhard's 1955 book on orthogenesis, \"The Phenomenon of Man\". This vision required evolution to be seen as the central and guiding principle of biology.\n\nErnst Mayr's key contribution to the synthesis was \"Systematics and the Origin of Species\", published in 1942. It asserted the importance of and set out to explain population variation in evolutionary processes including speciation. He analysed in particular the effects of polytypic species, geographic variation, and isolation by geographic and other means. Mayr emphasized the importance of allopatric speciation, where geographically isolated sub-populations diverge so far that reproductive isolation occurs. He was skeptical of the reality of sympatric speciation believing that geographical isolation was a prerequisite for building up intrinsic (reproductive) isolating mechanisms. Mayr also introduced the biological species concept that defined a species as a group of interbreeding or potentially interbreeding populations that were reproductively isolated from all other populations. Before he left Germany for the United States in 1930, Mayr had been influenced by the work of the German biologist Bernhard Rensch, who in the 1920s had analyzed the geographic distribution of polytypic species, paying particular attention to how variations between populations correlated with factors such as differences in climate.\n\nGeorge Gaylord Simpson was responsible for showing that the modern synthesis was compatible with palaeontology in his 1944 book \"Tempo and Mode in Evolution\". Simpson's work was crucial because so many palaeontologists had disagreed, in some cases vigorously, with the idea that natural selection was the main mechanism of evolution. It showed that the trends of linear progression (in for example the evolution of the horse) that earlier palaeontologists had used as support for neo-Lamarckism and orthogenesis did not hold up under careful examination. Instead the fossil record was consistent with the irregular, branching, and non-directional pattern predicted by the modern synthesis.\n\nDuring the war, Mayr edited a series of bulletins of the Committee on Common Problems of Genetics, Paleontology, and Systematics, formed in 1943, reporting on discussions of a \"synthetic attack\" on the interdisciplinary problems of evolution. In 1946, the committee became the Society for the Study of Evolution, with Mayr, Dobzhansky and Sewall Wright the first of the signatories. Mayr became the editor of its journal, \"Evolution\". From Mayr and Dobzhansky's point of view, suggests the historian of science Betty Smocovitis, Darwinism was reborn, evolutionary biology was legitimised, and genetics and evolution were synthesised into a newly unified science. Everything fitted in to the new framework, except \"heretics\" like Richard Goldschmidt who annoyed Mayr and Dobzhansky by insisting on the possibility of speciation by macromutation, creating \"hopeful monsters\". The result was \"bitter controversy\".\n\nThe botanist G. Ledyard Stebbins extended the synthesis to encompass botany. He described the important effects on speciation of hybridization and polyploidy in plants in his 1950 book \"Variation and Evolution in Plants\". These permitted evolution to proceed rapidly at times, polyploidy in particular evidently being able to create new species effectively instantaneously.\n\nThe modern synthesis was defined differently by its various founders, with differing numbers of basic postulates, as shown in the table.\n\nAfter the synthesis, evolutionary biology continued to develop with major contributions from workers including W. D. Hamilton, George C. Williams, E. O. Wilson, Edward B. Lewis and others.\n\nIn 1964, W. D. Hamilton published two papers on \"The Genetical Evolution of Social Behaviour\". These defined inclusive fitness as the number of offspring equivalents an individual rears, rescues or otherwise supports through its behaviour. This was contrasted with personal reproductive fitness, the number of offspring that the individual directly begets. Hamilton, and others such as John Maynard Smith, argued that a gene's success consisted in maximising the number of copies of itself, either by begetting them or by indirectly encouraging begetting by related individuals who shared the gene, the theory of kin selection.\n\nIn 1966, George C. Williams published \"Adaptation and Natural Selection\", outlined a gene-centred view of evolution following Hamilton's concepts, disputing the idea of evolutionary progress, and attacking the then widespread theory of group selection. Williams argued that natural selection worked by changing the frequency of alleles, and could not work at the level of groups. Gene-centred evolution was popularised by Richard Dawkins in his 1976 book \"The Selfish Gene\" and developed in his more technical writings.\n\nIn 1975, E. O. Wilson published his controversial book \"\", the subtitle alluding to the modern synthesis as he attempted to bring the study of animal society into the evolutionary fold. This appeared radically new, although Wilson was following Darwin, Fisher, Dawkins and others. Critics such as Gerhard Lenski noted that he was following Huxley, Simpson and Dobzhansky's approach, which Lenski considered needlessly reductive as far as human society was concerned. By 2000, the proposed discipline of sociobiology had morphed into the relatively well-accepted discipline of evolutionary psychology.\n\nIn 1977, recombinant DNA technology enabled biologists to start to explore the genetic control of development. The growth of evolutionary developmental biology from 1978, when Edward B. Lewis discovered homeotic genes, showed that many so-called toolkit genes act to regulate development, influencing the expression of other genes. It also revealed that some of the regulatory genes are extremely ancient, so that animals as different as insects and mammals share control mechanisms; for example, the \"Pax6\" gene is involved in forming the eyes of mice and of fruit flies. Such deep homology provided strong evidence for evolution and indicated the paths that evolution had taken.\n\nIn 1982, a historical note on a series of evolutionary biology books could state without qualification that evolution is the central organizing principle of biology. Smocovitis commented on this that \"What the architects of the synthesis had worked to construct had by 1982 become a matter of fact\", adding in a footnote that \"the centrality of evolution had thus been rendered tacit knowledge, part of the received wisdom of the profession\".\n\nBy the late 20th century, however, the modern synthesis was showing its age, and fresh syntheses to remedy its defects and fill in its gaps were proposed from different directions. These have included such diverse fields as the study of society, developmental biology, epigenetics, molecular biology, microbiology, genomics, symbiogenesis, and horizontal gene transfer. The physiologist Denis Noble argues that these additions render neo-Darwinism in the sense of the early 20th century's modern synthesis \"at the least, incomplete as a theory of evolution\", and one that has been falsified by later biological research.\n\nMichael Rose and Todd Oakley note that evolutionary biology, formerly divided and \"Balkanized\", has been brought together by genomics. It has in their view discarded at least five common assumptions from the modern synthesis, namely that the genome is always a well-organised set of genes; that each gene has a single function; that species are well adapted biochemically to their ecological niches; that species are the durable units of evolution, and all levels from organism to organ, cell and molecule within the species are characteristic of it; and that the design of every organism and cell is efficient. They argue that the \"new biology\" integrates genomics, bioinformatics, and evolutionary genetics into a general-purpose toolkit for a \"Postmodern Synthesis\".\n\nIn 2007, more than half a century after the modern synthesis, Massimo Pigliucci called for an extended evolutionary synthesis to incorporate aspects of biology that had not been included or had not existed in the mid-20th century. It revisits the relative importance of different factors, challenges assumptions made in the modern synthesis, and adds new factors such as multilevel selection, transgenerational epigenetic inheritance, niche construction, and evolvability.\n\nIn 2009, Darwin's 200th anniversary, the \"Origin of Species\" 150th, and the 200th of Lamarck's \"early evolutionary synthesis\", \"Philosophie Zoologique\", the evolutionary biologist Eugene Koonin stated that while \"the edifice of the [early 20th century] Modern Synthesis has crumbled, apparently, beyond repair\", a new 21st century synthesis could be glimpsed. Three interlocking revolutions had, he argued, taken place in evolutionary biology: molecular, microbiological, and genomic. The molecular revolution included the neutral theory, that most mutations are neutral and that purifying selection happens more often than the positive form, and that all current life evolved from a single common ancestor. In microbiology, the synthesis has expanded to cover the prokaryotes, using ribosomal RNA to form a tree of life. Finally, genomics brought together the molecular and microbiological syntheses, noting that a molecular view shows that the tree of life is problematic. In particular, horizontal gene transfer between bacteria means that prokaryotes freely share genes, challenging Mayr's foundational definition of species. Further, horizontal gene transfer, gene duplication, and \"momentous events\" like endosymbiosis enable evolution to proceed in sudden jumps, ending the old gradualist-saltationist debate by showing that on this point Darwin's gradualism was wrong. The idea of progress in biology, too, is seen to be wrong, along with the modern synthesis belief in pan-adaptationism, that everything is optimally adapted: genomes plainly are not. Many of these points had already been made by other researchers such as Ulrich Kutschera and Karl J. Niklas.\n\nBiologists, alongside scholars of the history and philosophy of biology, have continued to debate the need for, and possible nature of, a replacement synthesis. For example, in 2017 Philippe Huneman and Denis M. Walsh stated in their book \"Challenging the Modern Synthesis\" that numerous theorists had pointed out that the disciplines of embryological developmental theory, morphology, and ecology had been omitted. They noted that all such arguments amounted to a continuing desire to replace the modern synthesis with one that united \"all biological fields of research related to evolution, adaptation, and diversity in a single theoretical frame.\" They observed further that there are two groups of challenges to the way the modern synthesis viewed inheritance. The first is that other modes such as epigenetic inheritance, phenotypic plasticity, the Baldwin effect, and the maternal effect allow new characteristics to arise and be passed on, and for the genes to catch up with the new adaptations later. The second is that all such mechanisms are part, not of an inheritance system, but a developmental system: the fundamental unit is not a discrete selfishly competing gene, but a collaborating system that works at all levels from genes and cells to organisms and cultures to guide evolution.\n\nLooking back at the conflicting accounts of the modern synthesis, the historian Betty Smocovitis notes in her 1996 book \"Unifying Biology: The Evolutionary Synthesis and Evolutionary Biology\" that both historians and philosophers of biology have attempted to grasp its scientific meaning, but have found it \"a moving target\"; the only thing they agreed on was that it was a historical event. In her words \"by the late 1980s the notoriety of the evolutionary synthesis was recognized . . . So notorious did 'the synthesis' become, that few serious historically minded analysts would touch the subject, let alone know where to begin to sort through the interpretive mess left behind by the numerous critics and commentators\".\n\n\n"}
{"id": "39447080", "url": "https://en.wikipedia.org/wiki?curid=39447080", "title": "Non-extensive self-consistent thermodynamical theory", "text": "Non-extensive self-consistent thermodynamical theory\n\nIn experimental physics, researchers have proposed Non-extensive self-consistent thermodynamic theory to describe phenomena observed in the Large Hadron Collider (LHC). This theory investigates a fireball for high-energy particle collisions, while using Tsallis non-extensive thermodynamics. Fireballs lead to the bootstrap idea, or self-consistency principle, just as in the Boltzmann statistics used by Rolf Hagedorn. Assuming the distribution function gets variations, due to possible symmetrical change, Abdel Nasser Tawfik applied the non-extensive concepts of high-energy particle production.\n\nThe motivation to use the non-extensive statistics from Tsallis comes from the results obtained by Bediaga et al. They showed that with the substitution of the Boltzmann factor in Hagedorn's theory by the q-exponential function, it was possible to recover good agreement between calculation and experiment, even at energies as high as those achieved at the LHC, with q>1.\n\nThe starting point of the theory is entropy for a non-extensive quantum gas of bosons and fermions, as proposed by Conroy, Miller and Plastino, which is given by formula_1 where formula_2 is the non-extended version of the Fermi–Dirac entropy and formula_3 is the non-extended version of the Bose–Einstein entropy.\n\nThat group and also Clemens and Worku, the entropy just defined leads to occupation number formulas that reduce to Bediaga's. C. Beck, shows the power-like tails present in the distributions found in high energy physics experiments.\n\nUsing the entropy defined above, the partition function results are\nSince experiments have shown that formula_5, this restriction is adopted.\n\nAnother way to write the non-extensive partition function for a fireball is\nwhere formula_7 is the density of states of the fireballs.\n\nSelf-consistency implies that both forms of partition functions must be asymptotically equivalent and that the mass spectrum and the density of states must be related to each other by\nin the limit of formula_9 sufficiently large.\n\nThe self-consistency can be asymptotically achieved by choosing\nand\nwhere formula_12 is a constant and formula_13. Here, formula_14 are arbitrary constants. For formula_15 the two expressions above approach the corresponding expressions in Hagedorn's theory.\n\nWith the mass spectrum and density of states given above, the asymptotic form of the partition function is\nwhere\nwith\n\nOne immediate consequence of the expression for the partition function is the existence of a limiting temperature formula_19. This result is equivalent to Hagedorn's result. With these results, it is expected that at sufficiently high energy, the fireball presents a constant temperature and constant entropic factor.\n\nExperimental evidence of the existence of a limiting temperature and of a limiting entropic index can be found in J. Cleymans and collaborators, and I. Sena and A. Deppman.\n"}
{"id": "214436", "url": "https://en.wikipedia.org/wiki?curid=214436", "title": "Order of precedence", "text": "Order of precedence\n\nOrder of precedence is a sequential hierarchy of nominal importance of persons. Most often it is used in the context of people by many organizations and governments, for very formal and state occasions, especially where diplomats are present. It can also be used in the context of decorations, medals and awards. Historically, the order of precedence had a more widespread use, especially in court and aristocratic life.\n\nA person's position in an order of precedence is not necessarily an indication of functional importance, but rather an indication of ceremonial or historical relevance; for instance, it may dictate where dignitaries are seated at formal dinners. The term is occasionally used to mean the order of succession—to determine who replaces the head of state in the event he or she is removed from office or incapacitated—as they are often identical, at least near the top.\n\nWhat follows are the general orders of precedence for different countries for state purposes, such as diplomatic dinners, and are made under the assumption that such functions are held in the capital. When they are held in another city or region, local officials such as governors would be much higher up the order. There may also be more specific and local orders of precedence, for particular occasions or within particular institutions. Universities and the professions often have their own rules of precedence applying locally, based (for example) on university or professional rank, each rank then being ordered within itself on the basis of seniority (i.e. date of attaining that rank). Within an institution the officials of that institution are likely to rank much higher in the order than in a general order of precedence—the chancellor or president of a university may well precede anyone except a head of state for example. The same might be true for a mayor in his or her own city.\n\n\n\n"}
{"id": "5509535", "url": "https://en.wikipedia.org/wiki?curid=5509535", "title": "Overton window", "text": "Overton window\n\nThe Overton window, also known as the window of discourse, describes the range of ideas tolerated in public discourse. The term is derived from its originator, Joseph P. Overton, a former vice president of the Mackinac Center for Public Policy, who, in his description of his window, claimed that an idea's political viability depends mainly on whether it falls within the window, rather than on politicians' individual preferences. According to Overton's description, his window includes a range of policies considered politically acceptable in the current climate of public opinion, which a politician can recommend without being considered too extreme to gain or keep public office.\n\nOverton described a spectrum from \"more free\" to \"less free\" with regard to government intervention, oriented vertically on an axis, to avoid comparison with the left-right political spectrum. As the spectrum moves or expands, an idea at a given location may become more or less politically acceptable. Political commentator Joshua Treviño postulated that the degrees of acceptance of public ideas are roughly:\n\nThe Overton window is an approach to identifying which ideas define the domain of acceptability within a democracy's possible governmental policies. Proponents of policies outside the window seek to convince or persuade the public in order to move and/or expand the window. Proponents of current policies, or similar ones, within the window seek to convince people that policies outside it should be deemed unacceptable.\n\nAfter Overton's death, others have examined the concept of adjusting the window by the deliberate promotion of ideas outside of it, or \"outer fringe\" ideas, with the intention of making less fringe ideas acceptable by comparison. The \"door-in-the-face\" technique of persuasion is similar.\n\nThe idea echoes several earlier expressions, the most recent and similarly academic being Hallin's spheres. In his 1986 book \"The Uncensored War\", communication scholar Daniel C. Hallin posits three areas of media coverage into which a topic may fall. The areas are diagrammed as concentric circles called spheres. From innermost to outermost they are the sphere of consensus, the sphere of legitimate controversy, and the sphere of deviance. Proposals and positions can be placed at varying degrees of distance from the metaphorical center, and political actors can fight over and help change these positions.\n\nHallin's theory is developed and applied primarily as a theory that explains varying levels of objectivity in media coverage, but it also accounts for the ongoing contest among media and other political actors about what counts as legitimate disagreement, potentially leading to changes in the boundaries between spheres. As one study that applies Hallin's theory explains, \"the borders between the three spheres are dynamic, depending on the political climate and on the editorial line of the various media outlets\". In this way, the idea also captures the tug-of-war over the boundaries between normal and deviant political discourse.\n\nAn idea similar to the Overton window was expressed by Anthony Trollope in 1868 in his novel \"Phineas Finn\":\n\nIn his \"West India Emancipation\" speech at Canandaigua, New York, in 1857,\nabolitionist leader Frederick Douglass described how public opinion limits the ability of those in power to act with impunity:\n\n"}
{"id": "33154613", "url": "https://en.wikipedia.org/wiki?curid=33154613", "title": "Persecution of Hazara people", "text": "Persecution of Hazara people\n\nThe persecution of Hazara people refers to the discrimination of the Hazaras, who are primarily from the central highland region of Hazarajat in Afghanistan. Significant populations of the Hazara people are also found in Quetta, Pakistan and Mashad, Iran as part of the Hazara and Afghan diasporas. The persecution of Hazara people dates back to the 16th century, with Babur from Kabulistan. It is reported that during the reign of Emir Abdur Rahman (1880–1901), thousands of Hazaras were killed, expelled and enslaved. Syed Askar Mousavi, a contemporary Hazara writer, claims that half the population of Hazarajat was displaced, shipped to neighbouring Balochistan in British India and Khorasan Province in Iran. This led to Pashtuns and other groups occupying parts of Hazarajat. The Hazara people have also been the victims of massacres committed by the Taliban and al-Qaeda. , conditions have not improved for the Hazaras in Afghanistan and thousands continue to be persecuted in neighboring Pakistan by Sunni extremist groups.\n\nHazaras are historically the most restrained ethnic minority group in the state and have witnessed slight improvements in the circumstances even with the setup of modern Afghanistan. The discrimination against this ethnic group has continued for centuries, instigated by Pashtuns and other ethnic groups. Syed Askar Mousavi, a contemporary Hazara writer, estimates that more than half of the entire population of Hazarajat was driven out of their villages, including many who were massacred. \"It is difficult to verify such an estimate, but the memory of the conquest of the Hazārajāt by ʿAbd-al-Raḥmān Khan certainly remains vivid among the Hazāras themselves, and has heavily influenced their relations with the Afghan state throughout the 20th century.\" \nThe British from neighboring British India, who were heavily involved in Afghanistan, did not document such a large figure. Others claim that Hazaras began leaving their hometown of Hazarajat due to poverty and in search of employment mostly in the 20th century. Most of these Hazaras immigrated to neighbouring Balochistan, where they were provided permanent settlement by the government of British India. Others settled in and around Mashad, in the Khorasan Province of Iran.\n\nThe Hazaras of Afghanistan faced severe political, social and economic tyranny and denial of basic civil rights. In the late 19th century, the Hazaras along with their Shia counterpart Qizilbash sided with the invading British-led Indians against the Sunni Ethnic groups of Afghanistan. In 1933, Abdul Khaliq Hazara, a Hazara student assassinated Afghan King Nadir Khan.\n\nNotably, after the Second Anglo-Afghan War, Shah Abdur conducted a campaign of repression in Hazarajat, but it was met with fierce opposition by Hazara tribal leaders. The first uprising was conducted in correlation with Shah Adbur's cousin, Mohammad Eshaq who sought to overthrow the Shah. This revolt of Hazara nationalists and anti-Shah partisans was brief, because Shah Adbur astutely used sectarian strife to divide the Hazara Shias and the Sunni partisans, thus allowing him to easily defeat his foes.\n\nThe defeat of the Hazaras in their first revolt allowed Shah Adbur to impose taxes on Hazarajat for the first time, and they severely impeded the autonomy of Hazarajat, because numerous Pashtun soldiers and government officials were garrisoned in Hazarajat in order to ensure its compliance with the Pashtun-run state. Subsequently, the Pashtuns garrisoned in Hazarajat, treated the local Hazaras inferiorly and often committed arbitrary acts of cruelty and brutality against them. This caused great unrest and a deepening hatred between the Hazaras and their Pashtun rulers, causing the Hazaras to reach their tipping point in 1892. When a local Pashtun garrison searched the home of a Hazara chieftain for arms, but the pretext was false, the garrison subsequently tied the chieftain up and made him watch while they raped his wife.\n\nThe outrage that followed allowed the Hazaras to unite once again in order to overthrow most of the local Pashtun garrisons in Hazarajat. This newfound zealous fever fermented fierce resistance against Shah Adbur and his forces. Witnessing the rising tide, Shah Adbur felt he had no choice but to wage a jihad against the Shia Hazaras, and under this casus belli Shah Adbur was able to muster around 150,000 troops. The resulting conflict was brutal and led to a great loss of life on both sides. The Hazaras fought with vigour but the attrition they faced due to lack of rations, led to their demise at the uprising's epicenter of Oruzgan. The aftermath of the uprising was a genocide at the hands of Shah Adbur, who wiped out more than half of the entire Hazara population, and caused a myriad of people to be driven out of their villages. Prior to the genocide, Hazaras made up more than half of Afghanistan's total population. Although once the largest ethnicity, they were now a minority, constituting roughly 9% of Afghanistan's total population. Accordingly, in order to stifle Hazara influence Shah Adbur fragmented Hazarajat and demarcated it so that it would encompass numerous other provinces, where the Hazara are now a minority.\n\nIn February 1993, a two-day military operation was conducted by the Islamic State of Afghanistan government and the Saudi-backed Sunni Wahhabi Ittihad-i Islami militia led by Abdul Rasul Sayyaf. At that time Ittihad-i Islami was allied with the government of Burhanuddin Rabbani. The military operation was conducted in order to seize control of the Afshar district in west Kabul where the Shia Hezb-e Wahdat militia (which was allied to Gulbuddin Hekmatyar's Sunni Hezb-i Islami and backed by Pakistan) was based and from where it was shelling civilian areas in northern Kabul. The operation also intended to capture Wahdat leader Abdul Ali Mazari. The Afshar district, situated on the slopes of Mount Afshar west of Kabul, is a densely populated district. The area is predominantly inhabited by Shia Hazara people. The Afshar military operation escalated into what became known as the Afshar massacre when the Saudi backed Wahhabi militia of Ittihad-e-Islami went on a rampage through Afshar, killing, raping, looting and burning houses. Two out of nine Islamic State sub-commanders, Anwar Dangar (later joined the Taliban) and Mullah Izzat, were also reported as leading troops that carried out abuses. The Islamic State government in collaboration with the then enemy militia of Hezb-e Wahdat as well as in cooperation with Afshar civilians established a commission to investigate the crimes that had taken place in Afshar. The commission found that around 70 people died during the street fighting and between 700 and 750 people were abducted and never returned by Abdul Rasul Sayyaf's men. These abducted victims were most likely killed or died in captivity. Dozens of women were abducted during the operation as well.\n\nFollowing the 1997 massacre of 3,000 Taliban prisoners by Abdul Malik Pahlawan in Mazar-i-Sharif thousands of Hazara men and boys were massacred by other Taliban members in the same city in August 1998. Human rights organizations reported that the dead were lying on the streets for weeks before the Taliban allowed their burial due to stench and fear of epidemics.\n\nThe pass connecting the settlements of Tashkurgan and Pule Khumri is known as Robatak Pass. A mass murder was carried out there by Taliban in May 2000 in which 31 people were reported dead. Twenty-six of the victims were Ismaili Hazara from Baghalan province. Their remains were found to the northeast of the pass, in a neighborhood known as Hazara Mazari, on the border between Baghlan and Samngan provinces. The victims were detained four months before their execution by Taliban troops between January 5 and January 14, 2000.\n\nIn January 2001 the Taliban committed a mass execution of Hazara people in Yakawlang District of Bamyan province, Afghanistan. This started on January 8 and lasted for four days; it took the lives of 170 men. Taliban apprehended about 300 people, including employees of local humanitarian organizations. They were grouped to various assemblage points where they were shot dead in public view. Around 73 women, children and elderly were taking shelter in a local mosque when Taliban fired rockets at the mosque.\n\nIn June 2010, at least nine Hazara men were killed in an ambush in Khas Urozgan District. The Taliban took responsibility for the attack.\n\nIn November 2015, Afghan militants claiming loyalty to the Islamic State beheaded seven ethnic Hazara civilians who had been abducted in the southern Afghan province of Zabul. Their throats were cut with metal wire. The victims were four men, two women, and a 9-year-old girl.\n\nOn July 23, 2016 two Islamic State suicide bombers blow themselves during the peaceful protest 'Junbish Roshnaye' in Kabul killing 160 and wounded over 200 people. The attackers were reportedly from the local affiliate of the so-called Islamic State, known as the \"Khurasan Province\" (IS-Khurasan).\n\n18 people were killed and 54 were injured in July 2016 at Kabul's landmark Sakhi Shrine by a gunman wearing an Afghan National Security Forces uniform. The attack took place on the eve of Ashura, the Shia mourning day. Responsibility for the attack was claimed by the Islamic State, or ISIS.\nThe next morning, an improvised electronic device(IED) killed at least 15 Hazara people in the Balkh province of northern Afghanistan. ISIS claimed responsibility for this attack as well. These attacks show the growing threat of the IS to the Hazara people.\n\nThere has been a significant improvement in the status and treatment of Hazaras in Afghanistan. The new Afghan constitution now recognizes them as one of the country's ethnic minorities, and they now have the full right to Afghan citizenship. In Afghanistan's recent parliamentary election, Hazaras won around 25 per cent of the seats. Hazara have also pursued higher education, enrolled in the army, and many have top government positions. For example, Mohammad Mohaqiq, a Hazara from the Hizb-i-Wahdat party, ran in the 2004 presidential election in Afghanistan, and Karim Khalili became the Vice President of Afghanistan. Since ousting the Taliban in late 2001, billions of dollars have been poured into Afghanistan for several large-scale reconstruction projects that took place from August 2012. For example, there have been more than 5000 kilometers of road pavement completed across Afghanistan, of which little was done in central Afghanistan Hazarajat. On the other hand, the Band-e Amir in the Bamyan Province became the first national park of Afghanistan. The road from Kabul to Bamyan was also built, along with new police stations, government institutions, hospitals, and schools in the Bamyan Province, Daykundi Province, and others. The first ski resort of Afghanistan was also established in the Bamyan Province.\n\nThere is still a large degree of discrimination against Hazaras, however. A new danger in the form of ISIS has become especially prominent in recent years, and they have carried out abductions, extortions and violent killings against Hazaras. The rising power of warlords, who the Hazara people perceive as a direct threat, has also been a matter of concern. There have been ethnic tensions and violent clashes with nomadic Kuchis over land access issues. Taliban fighters continue to abduct and execute Hazaras travelling in vehicles. Furthermore, anti-Hazara sentiments became stronger when the former director of the National Directorate of Security, Amrullah Saleh, accused Iran of interfering in Afghan affairs through Shias. Hazara activists still believe that the government does not serve their people's security needs sufficiently. Parts of central Afghanistan, like the unofficial Hazara capital Bamiyan, are among the country's poorest and often lack even basic necessities like water and electricity. Hazara people held a protest in March 2016 against the government's decision to move a proposed power line project out of Bamiyan, seeing it as another form of ethnic discrimination.\n\nThe history of Hazara people in Pakistan dates back to the 1840s, when Hazara tribesmen from Hazarajat began migration to colonial India because of persecution by Pashtuns and Tajiks. Many Hazaras were enlisted in the British Indian Army during the first Anglo-Afghan War (1838-1840). The mass-migration and permanent settlements started in the 1890s when Emir Abdul Rahman Khan started persecuting the Hazaras of Afghanistan. The majority of Hazara are Shi'a Muslims with a sizable Sunni minority. Pakistan is home to an estimated 20% Shia Muslim population. Sectarian violence in Pakistan started in 1980s.\n\nIn 2011 the persecution of Hazaras in Quetta has left at least 1300 dead and more than 1500 wounded. The victims include high-profile community members, laborers, women and children. One third of the victims are children. The major attacks included assassinations of Hussain Ali Yousafi, Olympia Abrar Hussain, bombing of a Hazara mosque, Ashura massacre, Quds Day bombing, Play ground massacre, Mastung massacre, January 2013 Quetta bombings, February 2013 Quetta bombing, Hazara Pilgrims carnage, Akhtarabad massacre & other terrorist attacks on Hazara People in Quetta.\n\nThe Al-Qaeda affiliated Pakistani Sunni Muslim extremist militant group Lashkar-e-Jhangvi, has claimed responsibility for most of these attacks.\n\nIn response to these killings, worldwide demonstrations were held to condemn the persecution of Hazaras in Quetta. The Hazara diaspora all over the world, namely in Australia, Western Europe, North America as well as the Hazara in Afghanistan, have protested against these killings and against the silence of international community. Haji Mohammad Mohaqiq, the political leader of the Hazara in Afghanistan, has also expressed solidarity with the Hazara community in Quetta. The persecutions have been documented by the United Nations, Amnesty International, Human Rights Watch, Asian Human Rights Commission, Human Rights Commission of Pakistan and Afghanistan Independent Human Rights Commission. EU parliamentarian Rita Borsellino has urged the international community to address the plight of Hazara people in Quetta. The members of British Parliament, Alistair Burt, Mark Lancaster, Alan Johnson, and Iain Stewart asked the government to pressure Pakistani authorities concerning the absence of justice for Hazara community in Pakistan\n\nAs a consequence of the attacks there has been a recent exodus of Hazaras trying to flee the violence. They are headed mainly to Australia & other Western Countries, where thousands of them have taken shelter and successfully relocated after obtaining refugee status. To get there, they complete an illegal and treacherous journey across Southeast Asia through air, land and sea that has already left hundreds of them dead.\n\nThe most recent attack occurred on October 10, 2017, when two unidentified attackers on a motorcycle opened fire on a van heading for a nearby vegetable market, killing the driver and four others, continuing the trend of attacks against Hazaras in Quetta. This series of bombings, attacks and assassinations have forced them to retreat to two heavily protected enclaves on either side of the city: Marriabad and Hazara Town.\n\nSo far Hundreds of Hazara individuals have been killed in Karachi, but none of the killers has never been brought to Justice. Among the dead were social workers & intellectuals.\nIn Karachi terrorists shot dead Agha Abbas, owner of famous fruit juice outlet \"Agha Juice\". Sindh police announced the arrest of Akram Lahori, chief of a banned religious group Lashkar-e-Jhangvi (lej) along with his four accomplices, for their alleged involvement in sectarian killings, including the murder of Agha Abbas.\n\nIn response, many members and leaders of Lashkar-e Jhangvi (LeJ) have been killed in military operations conducted by the army and the police.\n\nThe main character in Khaled Hosseini's novel \"The Kite Runner\" is Amir, a Pashtun boy who has a Hazara friend, Hassan, in 1970s Afghanistan. They are bullied by an older Pashtun who expresses scorn for the Hazara people and rapes Hassan.\n\nIn the book \"In The Sea There Are Crocodiles\", Eniatollah Akbari, a Hazara boy, details his journey to escape persecution in Afghanistan.\n\n\n"}
{"id": "42171408", "url": "https://en.wikipedia.org/wiki?curid=42171408", "title": "Prajñā (Hinduism)", "text": "Prajñā (Hinduism)\n\nPragña or Pragya (Sanskrit: प्रज्ञ) as प्रज्ञा, प्राज्ञ and प्राज्ञा is used to refer to the highest and purest form of wisdom, intelligence and understanding. Pragya is the state of wisdom which is higher than the knowledge obtained by reasoning and inference.\n\nThe Sanskrit word प्रज्ञ (\"Pragña\") is the combination of \"प्र (\"pra-\")\" which prefix means – before, forward, fulfiller, and used as the intensifier but rarely as a separate word and \"ज्ञ (\"jna\")\" which means - knowing or familiar with. प्रज्ञ (\"Prajña\"), meaning - wise, prudent, knowing, conversant with, is the root of प्राज्ञ (\"Prājña\") meaning – wise, learned man, intellectual, clever, intelligence dependent on individuality; प्रज्ञा (\"Prajñā\") meaning – intelligence, judgement, mental attitude, particular \"shakti\" or energy, insight, mental disposition, true or transcendental wisdom, awareness, mentality, understanding, discrimination, knowledge; and प्राज्ञा (\"Prājñā\") meaning – understanding, intelligence.\n\nIn the state of deep sleep, the Atman, limited by Prana, the vital breath, is called \"Prājña\".\n\nThere are a few Vedic Mantras which hint at Prājña, the wise and the learned intellectual. and so does Isha Upanishad which belongs to the Shukla Yajurveda.\nDayananda Saraswati, translating and commenting on the Rig Veda, draws attention to a sage of the Rig Veda who tells us –\n\nthat the radiant one, who feeds and nourishes, who ensures births, who desires association with the learned, he surely soon gains wide varied knowledge (and becomes intelligent and aware).\n\nAnd, to Vishwamitra who tells us -\n\nthat those who constantly strive to understand the ways and methods of the objective world and its origin and its being surely attain divinity (\"aishvarya\"). Sayana commenting on mantra III.27.7 observes that the most common meaning of \"māyā\" are \"prajñā\" ('intelligence') and \"kapata\" ('deceit') and that \"kratu\" of the compound-word \"Sukratu\" in mantra I.20.8 implies either \"karma\" (act) or \"prajñā\" ('knowledge').\n\nThe third chapter of the Aitareya Upanishad teaches – तत्प्रज्ञानेत्रम् प्रज्ञाने प्रतिष्ठितं प्रज्ञानेत्रो लोकः प्रज्ञानं ब्रह्म (III.i.3) that all that exist, all phenomena cosmic and psychical, are rooted in \"Prajñā\" i.e. Consciousness, and Consciousness is Brahman, in which regard Sankara in his commentary states that Brahman gets the respective names and forms as conditioned by the divergent bodies; it is the same entity that has become diversified under all the conditions and is known in every way and is thought of multifariously by all creatures as well as logicians. And, in the Kaushitaki Upanishad III.iii.4, Indra describes 'Death' as complete absorption in Prana when \"Prānā\" and \"Prajñā\" ('consciousness' or 'self'), which together live in the body and together depart, become one. The main theme of Kaushitaki Upanishad is that without \"Prajñā\" the senses do not work, which is knowledge, for by knowledge one sees clearly; \"Prajñā\" is Brahman and all things are rooted in Brahman. \"Prānā\" is \"Prajñā\", self-consciousness. It is \"Prajñā\" that takes possession of Speech, and by speech one obtains words; takes possession of the nose, and one obtains odours; takes possession of the eye, and one obtains all forms; takes possession of the ear, and one obtains all sounds; takes possession of the tongue, and one obtains all tastes of food; takes possession of the hands, and one obtains all actions; takes possession of the body, and one obtains pleasure and pain; takes possession of the organ, one obtains happiness, joy and offspring; takes possession of the feet, one obtains all movements and takes possession of mind, and one obtains all thoughts, without \"Prajñā\", no thoughts succeed.\n\nThe Vedantasara tells us that Brahman is to be thought of as being Nirguna, without attributes; Brahman is the sole reality, everything else is Anatman, non-existence and non-knowledge. Ignorance is two-fold; Brahman in relation of totality of ignorance as Ishvara has all the attributes of the creator and the ruler of the world but in relation to special ignorance is the individual soul, the defective intelligence, \"Prājña\" (प्राज्ञ) – अस्य प्राज्ञात्वमस्पष्टोपाधितयानतिप्रकाशकत्वात् ||४४||. Intelligence in its invisible form refers to Brahman – आनन्दभुक् चेतोमुखः प्राज्ञः (\"Prājña, the enjoyer of bliss, with Consciousness for its aid\" (Mandukya Upanishad 5)), the all-knowing reality, in its visible form it is the parviscient Jiva which is able to differentiate itself from Ishvara – सता सोम्य तदा सम्पन्नो भवति (\"Then (in dreamless sleep), my dear, he (Jiva) becomes one with Existence (Ishvara) \" (Chandogya Upanishad VI.viii.1)).\n\nGaudapada, in his Karika on the Mandukya Upanishad, refers to the three states of consciousness, to the one Atman perceived threefold in the same body and the threefold satisfaction; he refers to Vaisvanara – जागरितस्थानो बहिष्प्रज्ञः whose sphere of action is the waking state, to Taijasa – स्वप्नास्थानोऽन्तःप्रज्ञः whose sphere is the dream state, and to \"Prājna\" (प्राज्ञ), whose sphere in the form of cause only is deep sleep bereft of dreams, as a mass of consciousness, as the Akasha in the heart and as the blissful one. He states that 'Dream' is the wrong apprehension of reality, 'Sleep' is the state in which one does not know what reality is; when the false experience in these two states disappears Turiya is realized (Gaudapada Karika I.vii.15). And, Yajnavalkya in Brihadaranyaka Upanishad advises that the intelligent seeker of Brahman, learning about the Self alone, should practice wisdom (\"prajñā\") and not think of too many words, for that is exhausting to the organ of speech.\n\nSwami Gambhirananda explains that the state where the sleeper does not desire any enjoyable thing and does not see any dream is deep sleep, and Prājna is the doorway to the experience of the dream and waking states. \"Prājña\" is the Self as the universal person in deep sleep. Yajnavlkya tells Janaka that \"Chidaksha\", the Self of the nature of Consciousness, is consciousness behind intelligent sound and the source of Shabda Brahman whose primary form is Aum which word is to be meditated upon as \"Prajñā\" ('Knowledge'), the inmost consciousness.\n\nThe Yoga Sutras of Patanjali cover the intellectual plane from the average level of awareness to the enlarged dimension of super consciousness. According to Patanjali, Samadhi is the last aspect of the eight-fold path which leads to realisation of Yoga which unites the mortal with the immortal and \"Prajñā\" is the state of perfection, the one, total indivisible entity. The perfect \"yogi\" on attaining this Supreme state becomes a total non-entity. Patanjali states – तस्य वाचकः प्रणवः that the word which express Him is Om but mere repletion of Om is insufficient, for one should also meditate upon its meaning for gaining knowledge of the Atman and destruction of the obstacles to that knowledge on road to reaching \"Nirvichara Samadhi\" when the mind becomes pure and – ऋतम्भरा तत्र प्रज्ञा in that \"Samadhi\", knowledge is said to be filled with truth which knowledge goes beyond inference and scriptures.\n"}
{"id": "23705", "url": "https://en.wikipedia.org/wiki?curid=23705", "title": "Predestination", "text": "Predestination\n\nPredestination, in theology, is the doctrine that all events have been willed by God, usually with reference to the eventual fate of the individual soul. Explanations of predestination often seek to address the \"paradox of free will\", whereby God's omniscience seems incompatible with human free will. In this usage, predestination can be regarded as a form of religious determinism; and usually predeterminism.\n\nThere is some disagreement among scholars regarding the views on predestination of first-century AD Judaism, out of which Christianity came. Josephus wrote during the first century that the three main Jewish sects differed on this question. He argued that the Essenes and Pharisees argued that God's providence orders all human events, but the Pharisees still maintained that people are able to choose between right and wrong. He wrote that the Sadducees did not have a doctrine of providence.\nThe biblical scholar N. T. Wright argues that Josephus's portrayal of these groups is incorrect, and that the Jewish debates referenced by Josephus should be seen as having to do with God's work to liberate Israel rather than philosophical questions about predestination. Wright asserts that Essenes were content to wait for God to liberate Israel while Pharisees believed Jews needed to act in cooperation with God. John Barclay responded that Josephus's description was an over-simplification and there were likely to be complex differences between these groups which may have been similar to those described by Josephus. Francis Watson has also argued on the basis of 4 Ezra, a document dated to the first century AD, that Jewish beliefs in predestination are primarily concerned with God's choice to save some individual Jews.\n\nIn the New Testament, Romans 8–11 presents a statement on predestination. In Romans 8:28–30, Paul writes, \nBiblical scholars have interpreted this passage in several ways. Many say this only has to do with service, and is not about salvation. The Catholic biblical commentator Brendan Byrne wrote that the predestination mentioned in this passage should be interpreted as applied to the Christian community corporately rather than individuals. Another Catholic commentator, Joseph Fitzmyer, wrote that this passage teaches that God has predestined the salvation of all humans. Douglas Moo, a Protestant biblical interpreter, reads the passage as teaching that God has predestined a certain set of people to salvation. Similarly, Wright's interpretation is that in this passage Paul teaches that God will save those whom he has chosen, but Wright also emphasizes that Paul does not intend to suggest that God has eliminated human free will or responsibility. Instead, Wright asserts, Paul is saying that God's will works through that of humans to accomplish salvation.\n\nOrigen, writing in the third century, taught that God's providence extends to every individual. He believed God's predestination was based on God's foreknowledge of every individual's merits, whether in their current life or a previous life.\n\nLater in the fourth and fifth centuries, Augustine of Hippo (354–430) also taught that God orders all things while preserving human freedom. Prior to 396, Augustine believed that predestination was based on God's foreknowledge of whether individuals would believe, that God's grace was \"a reward for human assent\". Later, in response to Pelagius, Augustine said that the sin of pride consists in assuming that \"we are the ones who choose God or that God chooses us (in his foreknowledge) because of something worthy in us\", and argued that it is God's grace that causes the individual act of faith. Scholars are divided over whether Augustine's teaching implies double predestination, or the belief that God chooses some people for damnation as well as some for salvation. Catholic scholars tend to deny that he held such a view while some Protestants and secular scholars affirm that Augustine did believe in double predestination.\n\nAugustine's position raised objections. Julian of Eclanum expressed the view that Augustine was bringing Manichean thoughts into the church. For Vincent of Lérins, this was a disturbing innovation. This new tension eventually became obvious with the confrontation between Augustine and Pelagius culminating in condemnation of Pelagianism (as interpreted by Augustine) at the Council of Ephesus in 431. Pelagius denied Augustine's view of predestination in order to affirm that salvation is achieved by an act of free will.\n\nThe Council of Arles in the late fifth century condemned the position \"that some have been condemned to death, others have been predestined to life\", though this may seem to follow from Augustine's teaching. The Second Council of Orange in 529 also condemned the position that \"some have been truly predestined to evil by divine power\".\n\nIn the eighth century, John of Damascus emphasized the freedom of the human will in his doctrine of predestination, and argued that acts arising from peoples' wills are not part of God's providence at all. Damascene teaches that people's good actions are done in cooperation with God, but are not caused by him.\n\nGottschalk of Orbais, a ninth-century Saxon monk, argued that God predestines some people to hell as well as predestining some to heaven, a view known as double predestination. He was condemned by several synods, but his views remained popular. Irish theologian John Scottus Eriugena wrote a refutation of Gottschalk. Eriugena abandoned Augustine's teaching on predestination. He wrote that God's predestination should be equated with his foreknowledge of people's choices.\n\nIn the twelfth century, Thomas Aquinas taught that God predestines certain people to the beatific vision based solely on his own goodness rather than that of creatures. Aquinas also believed that people are free in their choices, fully cause their own sin, and are solely responsible for it. According to Aquinas, there are several ways in which God wills actions. He directly wills the good, indirectly wills evil consequences of good things, and only permits evil. Aquinas held that in permitting evil, God does not will it to be done or not to be done.\n\nIn the thirteenth century, William of Ockham taught that God does not cause human choices and equated predestination with divine foreknowledge. Though Ockham taught that God predestines based on people's foreseen works, he maintained that God's will was not constrained to do this.\n\nJohn Calvin rejected the idea that God permits rather than actively decrees the damnation of sinners, as well as other evil. Calvin did not believe God to be guilty of sin, but he considered it an unfathomable mystery that God seems to simultaneously will sin and to also not will sin. Though he maintained God's predestination applies to damnation as well as salvation, he taught that the damnation of the damned is caused by their sin, but that the salvation of the saved is solely caused by God. Other Protestant Reformers, including Huldrych Zwingli, also held double predestinarian views.\n\nThe Eastern Orthodox view was summarized by Bishop Theophan the Recluse in response to the question, \"What is the relationship between the Divine provision and our free will?\"\n\nCatholicism teaches the doctrine of predestination, while rejecting the classical Calvinist view known as \"double predestination\". This means that while it is held that those whom God has elected to eternal life will infallibly attain it, and are therefore said to be predestined to salvation by God, those who perish are not predestined to damnation. According to the Catholic Church, God predestines no one to go to hell, for this, a willful turning away from God (a mortal sin) is necessary, and persistence in it until the end.\" Catholicism has been generally discouraging to human attempts to guess or predict the Divine Will. The \"Catholic Encyclopedia\" entry on predestination says:\n\nPope John Paul II wrote:\nThe Catholic Catechism says, \"To God, all moments of time are present in their immediacy. When therefore he establishes his eternal plan of \"predestination\", he includes in it each person's free response to his grace.\" \n\nCatholics do not believe that any hints or evidence of the predestined status of individuals is available to humans, and predestination generally plays little or no part in Catholic teaching to the faithful, being a topic addressed in a professional theological context only.\n\nAugustine of Hippo laid the foundation for much of the later Catholic teaching on predestination. His teachings on grace and free will were largely adopted by the Second Council of Orange (529), whose decrees were directed against the Semipelagians. Augustine wrote, \nAugustine also teaches that people have free will. For example, in \"On Grace and Free Will\", (see especially chapters II–IV) Augustine states that \"He [God] has revealed to us, through His Holy Scriptures, that there is in man a free choice of will,\" and that \"God's precepts themselves would be of no use to a man unless he had free choice of will, so that by performing them he might obtain the promised rewards.\" (chap. II)\n\nThomas Aquinas' views concerning predestination are largely in agreement with Augustine and can be summarized by many of his writings in his \"Summa Theologiæ\":\n\nThis table summarizes the classical views of three different Protestant beliefs.\n\nLutherans historically hold to unconditional election unto salvation. However, some do not believe that there are certain people that are predestined to salvation, but salvation is predestined for those who seek God. Lutherans believe Christians should be assured that they are among the predestined. However, they disagree with those who make predestination the source of salvation rather than Christ's suffering, death, and resurrection. Unlike some Calvinists, Lutherans do not believe in a predestination to damnation. Instead, Lutherans teach eternal damnation is a result of the unbeliever's sins, rejection of the forgiveness of sins, and unbelief.\n\nMartin Luther's attitude towards predestination is set out in his \"On the Bondage of the Will\", published in 1525. This publication by Luther was in response to the published treatise by Desiderius Erasmus in 1524 known as \"On Free Will\". Luther based his views on Ephesians 2:8–10, which says:\n\nThe Belgic Confession of 1561 affirmed that God \"delivers and preserves\" from perdition \"all whom he, in his eternal and unchangeable council, of mere goodness hath elected in Christ Jesus our Lord, without respect to their works\" (Article XVI).\nCalvinists believe that God picked those who he will save and bring with him to Heaven before the world was created. They also believe that those people God does not save will go to Hell. John Calvin thought people who were saved could never lose their salvation and the \"elect\" (those God saved) would know they were saved because of their actions.\n\nIn this common, loose sense of the term, to affirm or to deny predestination has particular reference to the Calvinist doctrine of unconditional election. In the Calvinist interpretation of the Bible, this doctrine normally has only pastoral value related to the assurance of salvation and the absolution of salvation by grace alone. However, the philosophical implications of the doctrine of election and predestination are sometimes discussed beyond these systematic bounds. Under the topic of the doctrine of God (theology proper), the predestinating decision of God cannot be contingent upon anything outside of himself, because all other things are dependent upon him for existence and meaning. Under the topic of the doctrines of salvation (soteriology), the predestinating decision of God is made from God's knowledge of his own will (Romans 9:15), and is therefore not contingent upon human decisions (rather, free human decisions are outworkings of the decision of God, which sets the total reality within which those decisions are made in exhaustive detail: that is, nothing left to chance). Calvinists do not pretend to understand how this works; but they are insistent that the Scriptures teach both the sovereign control of God and the responsibility and freedom of human decisions.\n\nCalvinist groups use the term Hyper-Calvinism to describe Calvinistic systems that assert without qualification that God's intention to destroy some is equal to his intention to save others. Some forms of Hyper-Calvinism have racial implications, as when Dutch Calvinist theologian Franciscus Gomarus however argued that Jews, because of their refusal to worship Jesus Christ, were members of the non-elect, as also argued by John Calvin himself, based on I John 2:22–23 in The New Testament of the Bible. Some Dutch settlers in South Africa argued that black people were sons of Ham, whom Noah had cursed to be slaves, according to Genesis 9:18–19, or drew analogies between them and the Canaanites, suggesting a \"chosen people\" ideology similar to that espoused by proponents of the Jewish nation. This justified racial hierarchy on earth, as well as racial segregation of congregations, but did not exclude blacks from being part of the elect. Other Calvinists vigorously objected to these arguments (see Afrikaner Calvinism). \n\nExpressed sympathetically, the Calvinist doctrine is that God has mercy or withholds it, with particular consciousness of who are to be the recipients of mercy in Christ. Therefore, the particular persons are chosen, out of the total number of human beings, who will be rescued from enslavement to sin and the fear of death, and from punishment due to sin, to dwell forever in his presence. Those who are being saved are assured through the gifts of faith, the sacraments, and communion with God through prayer and increase of good works, that their reconciliation with him through Christ is settled by the sovereign determination of God's will. God also has particular consciousness of those who are passed over by his selection, who are without excuse for their rebellion against him, and will be judged for their sins.\n\nCalvinists typically divide on the issue of predestination into infralapsarians (sometimes called 'sublapsarians') and supralapsarians. Infralapsarians interpret the biblical election of God to highlight his love (1 John 4:8; Ephesians 1:4b–5a) and chose his elect considering the situation after the Fall, while supralapsarians interpret biblical election to highlight God's sovereignty (Romans 9:16) and that the Fall was ordained by God's decree of election. In infralapsarianism, election is God's response to the Fall, while in supralapsarianism the Fall is part of God's plan for election. In spite of the division, many Calvinist theologians would consider the debate surrounding the infra- and supralapsarian positions one in which scant Scriptural evidence can be mustered in either direction, and that, at any rate, has little effect on the overall doctrine.\n\nSome Calvinists decline to describe the eternal decree of God in terms of a sequence of events or thoughts, and many caution against the simplifications involved in describing any action of God in speculative terms. Most make distinctions between the positive manner in which God chooses some to be recipients of grace, and the manner in which grace is consciously withheld so that some are destined for everlasting punishments.\n\nDebate concerning predestination according to the common usage concerns the destiny of the damned: whether God is just if that destiny is settled prior to the existence of any actual volition of the individual, and whether the individual is in any meaningful sense responsible for his destiny if it is settled by the eternal action of God.\n\nArminians hold that God does not predetermine, but instead infallibly knows who will believe and perseveringly be saved. This view is known as conditional election, because it states that election is conditional on the one who wills to have faith in God for salvation. Although God knows from the beginning of the world who will go where, the choice is still with the individual. The Dutch Calvinist theologian Franciscus Gomarus strongly opposed the views of Jacobus Arminius with his doctrine of supralapsarian predestination.\n\nThe Church of Jesus Christ of Latter-day Saints (LDS Church) rejects the doctrine of predestination, but does believe in foreordination. Foreordination, an important doctrine of the LDS Church, teaches that during the pre-mortal existence, God selected (\"foreordained\") particular people to fulfill certain missions (\"callings\") during their mortal lives. For example, prophets were foreordained to be the Lord's servants (see Jeremiah 1:5), all who receive the priesthood were foreordained to that calling, and Jesus was foreordained to enact the atonement.\n\nThe LDS Church teaches the doctrine of moral agency, the ability to choose and act for ourselves, and decide whether to accept Christ's atonement.\n\nConditional election is the belief that God chooses for eternal salvation those whom he foresees will have faith in Christ. This belief emphasizes the importance of a person's free will. The counter-view is known as unconditional election, and is the belief that God chooses whomever he will, based solely on his purposes and apart from an individual's free will. It has long been an issue in Calvinist–Arminian debate. An alternative viewpoint is Corporate election, which distinguishes God's election and predestination for corporate entities such as the community \"in Christ,\" and individuals who can benefit from that community's election and predestination so long as they continue belonging to that community.\n\nInfralapsarianism (also called sublapsarianism) holds that predestination logically coincides with the preordination of Man's fall into sin. That is, God predestined sinful men for salvation. Therefore, according to this view, God is the ultimate cause, but not the proximate source or \"author\" of sin. Infralapsarians often emphasize a difference between God's decree (which is inviolable and inscrutable), and his revealed will (against which man is disobedient). Proponents also typically emphasize the grace and mercy of God toward all men, although teaching also that only some are predestined for salvation.\n\nIn common English parlance, the doctrine of predestination often has particular reference to the doctrines of Calvinism. The version of predestination espoused by John Calvin, after whom Calvinism is named, is sometimes referred to as \"double predestination\" because in it God predestines some people for salvation (i.e. unconditional election) and some for condemnation (i.e. Reprobation) which results by allowing the individual's own sins to condemn them. Calvin himself defines predestination as \"the eternal decree of God, by which he determined with himself whatever he wished to happen with regard to every man. Not all are created on equal terms, but some are preordained to eternal life, others to eternal damnation; and, accordingly, as each has been created for one or other of these ends, we say that he has been predestined to life or to death.\"\n\nOn the spectrum of beliefs concerning predestination, Calvinism is the strongest form among Christians. It teaches that God's predestining decision is based on the knowledge of his own will rather than foreknowledge, concerning every particular person and event; and, God continually acts with entire freedom, in order to bring about his will in completeness, but in such a way that the freedom of the creature is not violated, \"but rather, established\".\n\nCalvinists who hold the infralapsarian view of predestination usually prefer that term to \"sublapsarianism,\" perhaps with the intent of blocking the inference that they believe predestination is on the basis of foreknowledge (\"sublapsarian\" meaning, assuming the fall into sin). The different terminology has the benefit of distinguishing the Calvinist double predestination version of infralapsarianism from Lutheranism's view that predestination is a mystery, which forbids the unprofitable intrusion of prying minds since God only reveals partial knowledge to the human race.\n\nSupralapsarianism is the doctrine that God's decree of predestination for salvation and reprobation logically precedes his preordination of the human race's fall into sin. That is, God decided to save, and to damn; he then determined the means by which that would be made possible. It is a matter of controversy whether or not Calvin himself held this view, but most scholars link him with the infralapsarian position. It is known, however, that Calvin's successor in Geneva, Theodore Beza, held to the supralapsarian view.\n\nDouble predestination, or the double decree, is the doctrine that God actively reprobates, or decrees damnation of some, as well as salvation for those whom he has elected. Augustine made statements that on their own seem to teach such a doctrine, but in the context of his other writings it is not clear whether he held it. Augustine's doctrine of predestination does seem to imply a double predestinarian view. Gottschalk of Orbais taught it more explicitly in the ninth century, and Gregory of Rimini in the fourteenth. During the Protestant Reformation John Calvin also held double predestinarian views. John Calvin states: \"By predestination we mean the eternal decree of God, by which he determined with himself whatever he wished to happen with regard to every man. All are not created on equal terms, but some are preordained to eternal life, others to eternal damnation; and, accordingly, as each has been created for one or other of these ends, we say that he has been predestinated to life or to death.\"\n\nOpen theism advocates the non-traditional Arminian view of election that predestination is corporate. In corporate election, God does not choose which individuals he will save prior to creation, but rather God chooses the church as a whole. Or put differently, God chooses what type of individuals he will save. Another way the New Testament puts this is to say that God chose the church in Christ (Eph. 1:4). In other words, God chose from all eternity to save all those who would be found in Christ, by faith in God. This choosing is not primarily about salvation from eternal destruction either but is about God's chosen agency in the world. Thus individuals have full freedom in terms of whether they become members of the church or not. Corporate election is thus consistent with the open view's position on God's omniscience, which states that God's foreknowledge does not determine the outcomes of individual free will.\n\nMiddle Knowledge is a concept that was developed by Jesuit theologian Luis de Molina, and exists under a doctrine called Molinism. It attempts to deal with the topic of predestination by reconciling Gods sovereign providence with the notion of libertarian free will. The concept of Middle Knowledge holds that God has a knowledge of true pre-volitional counterfactuals for all free creatures. That is, what any individual creature with a free will (e.g. a human) would do under any given circumstance. Gods knowledge of counterfactuals is reasoned to occur logically prior to his divine creative decree (that is, prior to creation), and after his knowledge of necessary truths. Thus, Middle Knowledge holds that before the world was created, God knew what every existing creature capable of libertarian freedom (e.g. every individual human) would freely choose to do in all possible circumstances. It then holds that based on this information, God elected from a number of these possible worlds, the world most consistent with his ultimate will, which is the actual world that we live in.\n\nFor example:\n\n\nBased on this Middle Knowledge, God has the ability to actualise the world in which A is placed in a circumstance that he freely chooses to do what is consistent with Gods ultimate will. If God determined that the world most suited to his purposes is a world in which A would freely choose Y instead of Z, God can actualise a world in which Free Creature A finds himself in Circumstance B.\n\nIn this way, Middle Knowledge is thought of by its proponents to be consistent with any theological doctrines that assert God as having divine providence and man having a libertarian freedom (e.g. Calvinism, Catholicism, Lutheranism), and to offer a potential solution to the concerns that Gods providence somehow nullifies man from having true liberty in his choices.\n\n\"Qadar\" (, transliterated \"qadar\", meaning \"fate\", \"divine fore-ordainment\", \"predestination\") is the concept of divine destiny in Islam. It is one of Sunni Islam's six pillars of faith, along with belief in the Oneness of God, the Revealed Books, the Prophets of Islam, the Day of Resurrection and Angels.\n\nIn Islam, \"predestination\" is the usual English language rendering of a belief that Muslims call \"al-qada wa al-qadar\" in Arabic. The phrase means \"the divine decree and the predestination\". In Islam, God has predetermined, known, ordained, and is constantly creating every event that takes place in the world. This is entailed by his being omnipotent and omniscient. Sunni scholars hold that there is no contradiction in people's deeds (and naturally their choices) being created and predetermined by the creator, since they define free will to be the antonym of compulsion and coercion. People – in the Sunni perspective – do acknowledge that they are free, since they do not see anybody or anything forcing them to do whatever they chose to do. This, however, does not contradict that everything they do, including the choices they make, are predestined and predetermined by God. Consequently, people are already predestined to either heaven or hell at birth, as Sunnis believe; however, they will have no argument on the day of judgment since they never knew in advance what their fate would be, and they do acknowledge that they have choice; which is what moral responsibility comes with.\n\nThe concept of human will being predetermined by God's will is stated clearly in the Quran:\n\"Verily this (The Holy Quran) is no less than a Message to (all) the Worlds; (With profit) to whoever among you wills to go straight, \"but ye shall not will except as God wills;\" the Cherisher of the Worlds.\"\n\nPredestination is rejected in Shiaism.\n\nIn Rabbinic literature, there is much discussion as to the apparent contradiction between God's omniscience and free will. The representative view is that \"Everything is foreseen; yet free will is given\" (Rabbi Akiva, \"Pirkei Avoth\" 3:15). Based on this understanding, the problem is formally described as a paradox, perhaps beyond our understanding.\n\nHasdai Crescas resolved this dialectical tension by taking the position that free will doesn't exist. All of a person's actions are predetermined by the moment of their birth, and thus their judgment in the eyes of God (so to speak) is effectively preordained. In this scheme this is not a result of God's predetermining one's fate, but rather that the universe is deterministic. Crescas's views on this topic were rejected by Judaism at large. In later centuries this idea independently developed among some in the Chabad (Lubavitch) movement of Hasidic Judaism. Many individuals within Chabad take this view seriously, and hence effectively deny the existence of free will.\n\nHowever, many Chabad (Lubavitch) Jews attempt to hold both views. They affirm as infallible their rebbe's teachings that God knows and controls the fate of all, yet at the same time affirm the classical Jewish belief in free will. The inherent contradiction between the two results in their belief that such contradictions are only \"apparent\", due to man's inherent lack of ability to understand greater truths and due to the fact that Creator and Created exist in different realities. The same idea is strongly repeated by Rambam (Mishneh Torah, Laws of Repentance, Chapter 5).\n\nMany other Jews (Orthodox, Conservative, Reform and secular) affirm that since free will exists, then by definition one's fate is not preordained. It is held as a tenet of faith that whether God is omniscient or not, nothing interferes with mankind's free will. Some Jewish theologians, both during the medieval era and today, have attempted to formulate a philosophy in which free will is preserved, while also affirming that God has knowledge of what decisions people will make in the future. Whether or not these two ideas are mutually compatible, or whether there is a contradiction between the two, is still a matter of great study and interest in philosophy today.\n\nPredestination is rejected in Zoroastrian teaching. Humans bear responsibility for all situations they are in, and in the way they act toward one another. Reward, punishment, happiness, and grief all depend on how individuals live their lives.\n\n\n\n\n"}
{"id": "30865543", "url": "https://en.wikipedia.org/wiki?curid=30865543", "title": "Prenatal hormones and sexual orientation", "text": "Prenatal hormones and sexual orientation\n\nThe hormonal theory of sexuality holds that, just as exposure to certain hormones plays a role in fetal sex differentiation, such exposure also influences the sexual orientation that emerges later in the adult. Prenatal hormones may be seen as the primary determinant of adult sexual orientation, or a co-factor with genes, biological factors and/or environmental and social conditions.\n\nThe hormonal theory of sexuality and gender identity holds that, just as exposure to certain hormones plays a role in fetal sex differentiation, such exposure also influences the sexual orientation and or gender identity that emerges later in the adult. Differences in brain structure that come about from chemical messengers and genes interacting on developing brain cells are believed to be the basis of sex differences in countless behaviors, including sexual orientation. Prenatal factors that affect or interfere with the interaction of these hormones on the developing brain can influence later sex-typed behavior in children. This hypothesis is originated from countless experimental studies in non-human mammals, yet the argument that similar effects can be seen in human neurobehavioral development is a much debated topic among scholars. Recent studies, however, have provided evidence in support of prenatal androgen exposure influencing childhood sex-typed behavior.\n\nFetal hormones may be seen as either the primary influence upon adult sexual orientation or as a co-factor interacting with genes and/or environmental and social conditions. However, Garcia-Falgueras and Dick Swaab disagree that social conditions influence sexual orientation to a large degree. As seen in young children as well as in vervet and rhesus monkeys, sexually differentiated behavior in toy preference is differing in males versus females, where females prefer dolls and males prefer toy balls and cars; these preferences can be seen as early as 3–8 months in humans. It is impossible to completely rule out the social environment or the child's cognitive understanding of gender when discussing sex typed play in androgen-exposed girls. Conversely, children tend towards objects which have been labelled for their own sex, or toys that they have seen members of their sex playing with previously.\n\nAn endocrinology study by Garcia-Falgueras and Swaab postulated that \"In humans, the main mechanism responsible of sexual identity and orientation involves a direct effect of testosterone on the developing brain.\" Further, their study puts forward that intrauterine exposure to hormones is largely determinative. Sketching the argument briefly here, the authors say that sexual organs are differentiated first, and then the brain is sexually differentiated \"under the influence, mainly, of sex hormones such as testosterone, estrogen and progesterone on the developing brain cells and under the presence of different genes as well ... . The changes brought about in this stage are permanent. ... [S]exual differentiation of the brain is not caused by hormones alone, even though they are very important for gender identity and sexual orientation.\"\n\nFetal gonads develop primarily based on the presence or absence of androgen hormones, mainly testosterone, dihydrotestosterone (DHT) and androstenedione; production of testosterone and conversion into dihydrotestosterone during weeks 6 to 12 of pregnancy are key factors in the production of a male fetus's penis, scrotum and prostate. In a female, on the other hand, absence of these levels of androgens results in development of typically female genitals. Following this, sexual differentiation of the brain occurs; sex hormones exert organizational effects on the brain that will be activated in puberty. As a result of these two processes occurring separately, the degree of genital masculinization does not necessarily relate to the masculinization of the brain. Sex differences in the brain have been found in many structures, most notably the hypothalamus and the amygdala. However, few of these have been related to behavioral sex differences, and scientists are still working to establish firm links between early hormones, brain development and behavior. The study of the organizational theory of prenatal hormones can be difficult, as ethically researchers cannot alter hormones in a developing fetus; instead, scholars must rely on naturally occurring abnormalities of development to provide answers.\n\nMost extensively studied in organizational effects of hormones is congenital adrenal hyperplasia (CAH). CAH is a genetic disease that results in exposure to high levels of androgens beginning early in gestation. Girls with CAH are born with masculinized genitalia, which is corrected surgically as soon as possible. CAH provides the opportunity for natural experiments, as people with CAH can be compared to people without it. However, \"CAH is not a perfect experiment\", since, \"social responses to masculinized genitalia or factors related to the disease itself\" can confound results. Nonetheless several studies have shown that CAH has a clear but not determining influence on sexual orientation; women with CAH are less likely to be exclusively heterosexual than are other women.\nSince hormones alone do not determine sexual orientation and differentiation of the brain, the search for other factors that act upon sexual orientation have led genes such as the SRY and ZFY to be implicated.\n\nAs of 2006 results from studies in humans had found conflicting evidence regarding the effect of prenatal exposure to hormones and psychosexual outcomes; Gooren noted in 2006 that studies in subprimate mammals are invalid measures of human sexual differentiation, as sex hormones follow a more \"on-off\" role in sex-typed behavior than is found in primates.\n\nSome studies do suggest that prenatal stress significantly increases the likelihood of homosexuality or bisexuality, although varying evidence exists for which trimester is most important. Studies of endocrinology have found implications for amphetamines and thyroid-gland hormones to increase homosexuality in female offspring as well, although it has not been examined in conjunction with prenatal stress levels.\n\nSome have postulated that postnatal (e.g., social and environmental factors) development can play a role in the sexual orientation of an individual, yet solid evidence of this has yet to be discovered. Children born through artificial insemination with donor sperm and consequently raised by lesbian couples have typically been heterosexually oriented. Summed up by Bao and Swaab, \"The apparent impossibility of getting someone to change their sexual orientation ... is a major argument against the importance of the social environment in the emergence of homosexuality, as well as against the idea that homosexuality is a lifestyle choice.\"\n\nThere is evidence of a correlation between sexual orientation and traits that are determined in utero. A study by McFadden in 1998 found that auditory systems in the brain, another physical trait influenced by prenatal hormones is different in those of differing orientations; likewise the suprachiasmatic nucleus was found by Swaab and Hofman to be larger in homosexual men than in heterosexual men. The suprachiasmatic nucleus is also known to be larger in men than in women. An analysis of the hypothalamus by Swaab and Hofmann (1990;2007) found that the volume of the suprachiasmatic nucleus (SCN) in homosexual men was 1.7 times larger than a reference group of male subjects, and contained 2.1 times as many cells. During development, the volume of the SCN and the cell counts reach peak value at approximately 13 to 16 months after birth; at this age, the SCN contains the same number of cells as was found in adult male homosexuals, yet in a reference group of heterosexual males the cell numbers begin to decline to the adult value of 35% of the peak value. These results have yet to be replicated, however; there also has yet to be a meaningful interpretation of these results provided in the context of human sexual orientation. Some studies suggest gay men have also been shown to have higher levels of circulating androgens and larger penises, on average, than heterosexual men.\n\nAccording to some studies, gay men have more older brothers on average, a phenomenon known as the fraternal birth order effect. It has been suggested that the greater the number of older male siblings the higher the level of androgen fetuses are exposed to. No evidence of birth order effects have been observed in women. The theory holds that the fraternal birth order effect is a result of a maternal immune response that is produced towards a factor of male development over several male pregnancies. Bogaert's hypothesis argues that \"the target of the immune response may be malespecific molecules on the surface of male fetal brain cells (e.g., including those in the anterior hypothalamus). Antimale antibodies might bind to these molecules and thus interfere with their role in normal sexual differentiation, leading some later born males to being attracted to men as opposed to women.\" Garcia-Falgueras and Swaab state that \"The ... fraternal birth order effect ... is putatively explained by an immunological response by the mother to a product of the Y chromosome of her sons. The chance of such an immune response to male factors would increase with every pregnancy resulting in the birth of a son.\"\n\nWhile direct support has not been found for these hypotheses, evidence that favours this theory exists.<ref name=\"Blanchard/Lippa cite\"></ref> Further, while percentages of the likelihood of homosexuality have been estimated to be increased by 15–48% per older brother, these odds really account for only a few percent of the population; thus, this hypothesis cannot be universally applied to the majority of homosexual men. Not all studies have been able to reproduce the fraternal birth order effect. Some did not find any statistically significant difference in either the sibling composition or rate of older brothers of gay and straight men, including large, nationally representative studies in the US and Denmark.\n\nIn conjunction with fraternal birth order, handedness provides further evidence of prenatal effects on sexual orientation, because handedness is regarded by many as a marker of early neurodevelopment. Other correlates to handedness (e.g., cerebral laterality, prenatal hormonal profiles, spatial ability) have been linked to sexual orientation, either empirically and/or theoretically. In right-handed individuals, the number of older brothers increased the odds of homosexual orientation, but this effect was not seen in left-handed individuals. As with other purported marks indicating higher incidence of homosexuality, however, the link with handedness remains ambiguous and several studies have been unable to replicate it.\n\nA gene of the \"Rh\" system has been discussed as a possible candidate for affecting fraternal birth order, as it has been linked to both handedness and immune system functioning. Gene variants in the \"Rh\" system are implicated in a maternal response to what is known as hemolytic disease of the newborn. \"Rh\" is a factor in blood, and in cases where the mother is absent of this (\"Rh-\") while carrying an \"Rh+\" fetus, an immune response may develop with deleterious effects. The \"Rh\" gene hypothesis is a strong candidate because not only does it involve the maternal immune response, but it has been implicated in handedness as well.\n\nVariants of the androgen receptor (\"AR\") gene have also been discussed, in that non-right-handedness in men has been linked with greater CAG repeats in the \"AR\" gene, which in turn is associated with lower testosterone. A theory that high prenatal testosterone leads to neuronal and axonal loss in the corpus callosum is supported by this hypothesis.\n\nIn a 1991 study, Simon LeVay demonstrated that a tiny clump of neurons of the anterior hypothalamus—which is believed to control sexual behavior and linked to prenatal hormones—known as the interstitial nuclei of the anterior was, on average, more than twice the size in heterosexual men when contrasted to homosexual men. Due to this area also being nearly twice the size in heterosexual men than in heterosexual women, the implication is that the sexual differentiation of the hypothalamus in homosexuals is in a female direction. In 2003 scientists at Oregon State University announced that they had replicated his findings in sheep. Later studies in humans, however, have yet to confirm this finding. \n\nMost empirical or theoretical research into women's sexual orientation has, historically, been guided by the idea of lesbians as essentially masculine and heterosexual women as essentially feminine. Typically, this belief is traced to the early \"inversion theory\" of sex researchers who state that homosexuality is a result of biological abnormalities that \"invert\" sexual attraction and personality. Handedness research has provided implications; because more men than women present a preference for their left hand, the higher proportion of non-right handedness that has been discovered among lesbians when compared to heterosexual women demonstrates a possible link of prenatal masculinization and sexual orientation. Backing this up are reports that lesbians display more masculinized 2D;4D digit ratios than heterosexual women, based on data gathered from at least six different laboratories. This effect has not yet been observed between homosexual and heterosexual males. However, the validity of this measure of digit ratios remains controversial as a predictor of prenatal androgen, as many other prenatal factors may play roles in bone growth in prenatal stages of development. While many studies have found results confirming this hypothesis, others have failed to replicate \nthese findings, leaving the validity of this measure unconfirmed.\n\nDiethylstilbestrol (DES), a drug that has been in the past prescribed to prevent miscarriages, has also been studied in relation to women's sexual orientation. It has been observed to exert a masculinizing/defeminizing effect on the developing brain of the fetus. When compared to controls, higher percentages of DES-exposed women (17% vs 0%) reported that they had engaged in same-sex relations; however, the great majority of DES women stated an exclusively heterosexual orientation.\n\nGirls with congenital adrenal hyperplasia (an autosomal recessive condition which results in high androgen levels during fetal development) have more masculinized sex role identities and are more likely to have a homosexual sexual orientation as adults than controls. An alternative explanation for this effect is the fact that girls with this condition are born with masculinized external genitalia, which leads their parents to raise them in a more masculine manner, thus influencing their sexual orientation as adults. However, the degree to which the girls' genitals are masculinized does not correlate with their sexual orientation, suggesting that prenatal hormones are a stronger causal factor, not parental influence.\n\nTogether with congenital adrenal hyperplasia, DES studies have provided little support of the prenatal hormone theory of sexual orientation; they do, however, provide the framework for possible pathways to a homosexual orientation for a small number of women.\n\nIn individuals with gender dysphoria, previously known as gender identity disorder (GID), prenatal exposure to testosterone has been hypothesized to have an effect on gender identity differentiation. The 2D;4D finger ratio, or relative lengths of the 2nd \"index\" and 4th \"ring\" fingers, has become a popular measure of prenatal androgen because of accumulated evidence suggesting the 2D;4D ratios are related to prenatal exposure to testosterone. Many children with GID differentiate a homosexual orientation during adolescence, but not all of them; adults with \"early onset\", or a childhood history of cross-gender behavior, often have a homosexual orientation. Adults with \"late onset\", or those without a childhood history of said behavior, are more likely to have a non-homosexual orientation.\n\nPrenatal androgen exposure has been associated with an increased chance of patient-initiated gender reassignment to male after being initially raised as female in early childhood or infancy. Gooren found that organizational effects of prenatal androgens are more prevalent in gender role behavior than in gender identity, and that there are preliminary findings that suggest evidence of a male gender identity being more frequent in patients with fully male-typical prenatal androgenization.\n\nIndividuals with complete androgen insensitivity syndrome are almost always brought up as females, and the differentiation of gender identity/role is feminine. This example is important in demonstrating that chromosomes and gonads alone do not dictate gender identity and role.\n\nBecause organ differentiation and brain differentiation occur at different times, in rare cases transsexualism can result. Only 23% of childhood gender problems will result in transsexuality in adulthood. \nDrawing on some transsexualism cases, Garcia-Falgueras and Swaab state that \"[f]rom these examples it appears that the direct action of testosterone on the developing brain in boys and the lack of such action on the developing brain in girls are crucial factors in the development of male and female gender identity and sexual orientation ... .\" Countless studies have been run on peripheral levels of sex steroids in male and female homosexuals, a considerable number of which claimed to find \"less 'male hormone' and/or more 'female hormone' in male homosexuals and vice versa in female homosexuals\". However, these findings have been reviewed and have subsequently been dismissed by scholars as suffering from faulty design and interpretation.\n\nFactors implicated in the development of transsexuality include chromosomal abnormalities, polymorphisms of certain genes, and variations in aromatase (cytochrome P450 CYP19) and CYP17. Girls with congenital adrenal hyperplasia show an increase in probability of transsexuality later in life; however, this risk is still only 1–3% in CAH. Although historically abnormal sexual differentiation has pointed to androgens as a causal factor, there are codeterminants of gender identity and sexual orientation with overriding effects of androgens on the brain, in male transsexuals or homosexuals, or making androgen effects on the brain redundant, as in female transsexuals or homosexuals. These factors are currently unknown, and thus no clear cut answer for the cause of transsexualism and homosexuality exists.\n\nDue to relatively small population sizes, generalizability of studies on transsexuality cannot be assumed.\n\nEndocrine disrupting chemicals (EDCs) are chemicals that, at certain doses, can interfere with the endocrine system in mammals. Work on possible neurotoxic effects of endocrine disruptors, and their possible effects on sexual orientation when a fetus is exposed to them, is in its infancy: \"we mostly know about the relationship between EDC exposure and neurobehavioral function through an examination of outcomes within a limited sphere of questions.\" While studies have found that xenoestrogens and xenoandrogens can alter the brain's sexual differentiation in a number of species used as animal models, from the data in hand to date, it is \"misleading ...to expect EDCs to produce profiles of effects, such as sexually dimorphic behaviors, as literal copies of those produced by native hormones. Such agents are not hormones. They should not be expected to act precisely as hormones.\"\n\n\n\n"}
{"id": "18130567", "url": "https://en.wikipedia.org/wiki?curid=18130567", "title": "Primary consciousness", "text": "Primary consciousness\n\nPrimary consciousness is a term the American biologist Gerald Edelman coined to describe the ability, found in humans and some animals, to integrate observed events with memory to create an awareness of the present and immediate past of the world around them. This form of consciousness is also sometimes called \"sensory consciousness\". Put another way, primary consciousness is the presence of various subjective sensory contents of consciousness such as sensations, perceptions, and mental images. For example, primary consciousness includes a person's experience of the blueness of the ocean, a bird's song, and the feeling of pain. Thus, primary consciousness refers to being mentally aware of things in the world in the present without any sense of past and future; it is composed of mental images bound to a time around the measurable present.\n\nConversely, higher order consciousness can be described as being \"conscious of being conscious\"; it includes reflective thought, a concept of the past, and speculation about the future.\n\nPrimary consciousness can be subdivided into two forms, focal awareness and peripheral awareness. Focal awareness encompasses the center of attention, whereas peripheral awareness consists of things outside the center of attention, which a person or animal is only dimly aware of.\n\nOne prominent theory for the neurophysiological basis of primary consciousness was proposed by Gerald Edelman. This theory of consciousness is premised upon three major assumptions:\n\nEdelman's theory focuses on two nervous system organizations: the brainstem and limbic systems on one side and the thalamus and cerebral cortex on the other side. The brain stem and limbic system take care of essential body functioning and survival, while the thalamocortical system receives signals from sensory receptors and sends out signals to voluntary muscles such as those of the arms and legs. The theory asserts that the connection of these two systems during evolution helped animals learn adaptive behaviors. This connection allows past signals related to values set by the limbic-brain stem system and categorized signals from the outside world to be correlated, resulting in memory in conceptual areas. This memory is then linked to the organism's \"current\" perception, which results in an awareness of the present, or primary consciousness. In other words, Edelman posits that primary consciousness arises from the correlation of \"conceptual\" memory to a set of \"ongoing\" perceptual categorizations—a \"remembered present\".\n\nOther scientists have argued against Edelman's theory, instead suggesting that primary consciousness might have emerged with the basic vegetative systems of the brain. That is, the evolutionary origin might have come from sensations and primal emotions arising from sensors and receptors, both internal and surface, signaling that the well-being of the creature was immediately threatened—for example, hunger for air, thirst, hunger, pain, and extreme temperature change. This is based on neurological data showing the thalamic, hippocampal, orbitofrontal, insula, and midbrain sites are the key to consciousness of thirst.\n\nThese scientists also point out that the cortex might not be as important to primary consciousness as some neuroscientists have believed. Evidence of this lies in the fact that studies show that systematically disabling parts of the cortex in animals does not remove consciousness. Another study found that children born without a cortex are conscious. Instead of cortical mechanisms, these scientists emphasize brainstem mechanisms as essential to consciousness. Still, these scientists concede that higher order consciousness does involve the cortex and complex communication between different areas of the brain.\n\nPhysiologically, three fundamental facts stand out about primary consciousness:\n\nTo be fully comprehensive, measures of consciousness must not only define and distinguish between conscious and unconscious states, but must also provide a guide by which the conscious level, or extent of consciousness, can be determined. Measures of consciousness are each associated with particular theories.\n\nCertain defining theories are included below:\n\nWorldly discrimination theory asserts that any mental state that is manifested in behavior is conscious; thus, an organism is consciously aware of something in the world if it can discriminate it with choice behavior.\nSignal detection theory quantifies discriminability of a stimulus among a set of different stimuli.\nIntegration theories focus on finding a divide between conscious and unconscious processes. According to integration theories, conscious contents are widely available to many cognitive and/or neural processes.\n\nThese theories are then accompanied with measures of the level of consciousness, which are subdivided into behavioral measures and physiological measures.\n\nBehavioral measures of primary consciousness can be either objective or subjective. Regarding objective measures, knowledge is unconscious if it expresses itself in an indirect test. For example, the ability to pick which item might come next in a series can indicate unconscious knowledge of regularities in sequences. \"Strategic control measures\" use a person's ability to deliberately use or not use knowledge according to instructions. If they use information despite intentions not to use it, it indicates unconscious knowledge. Post-decision wagering can also be used. In this method, subjects make a first-order discrimination (i.e. a choice) and then place a wager regarding the outcome of the discrimination. Some scientists view this as a direct and objective measure of consciousness, and it can be used with children and animals. However, this method has been argued to be subjective and indirect.\n\nEvent-related cortical potentials (ERPs) have been used to assess whether a stimulus is consciously perceived or not. These EEG measures either float free of theory, gaining credibility through reliable correlation, or assume a version of integration theory in which the appearance of a particular ERP indicates global availability or locally recurrent processing.\n\nAbundant evidence indicates that consciously perceived inputs elicit widespread brain activation, as compared with inputs that do not reach consciousness.\n\nThe dynamic core hypothesis (DCH) proposes that consciousness arises from neural dynamics in the thalamocortical system, as measured by the quantity neural complexity (CN). \"CN\" is an information-theoretic measure; the \"CN\" value is high if each subset of a neural system can take on many different states, and if these states make a difference to the rest of the system.\nThe information integration theory of consciousness (IITC) shares with the DCH the idea that conscious experiences provide informative discriminations among a vast repertoire of possible experiences. In the IITC, the quantity \"phi\" is defined as the information that is integrated across the informational \"weakest link\" of a system. Importantly, \"phi\" is a measure of the capacity of a neural system to integrate information, whereas \"CN\" is a measure of the actual dynamics of the system. A third measure, causal density \"(CD)\", measures the fraction of causal interactions among elements of a system that are statistically significant.\n\nIt is important to note that subjective measures are always indirect and can be vulnerable to many biases (e.g., reluctance to report uncertain experiences). An|metacognitive]] conscious content assumes primary consciousness but not vice versa, subjective measures risk missing or rejecting the presence of sensory consciousness simply because metacognition isn't observed.\n\nFurthermore, there is the problem of post-decision wagering, which has been criticized because there is a possibility that advantageous wagering could be learned unconsciously; as a result, post-decision wagering would not in fact be considered a conscious behavior. For example, individual differences in risk aversion may lead to variations in wagering performance even with the same underlying conscious phenomenology.\n\nThus, although behavioral measures are mostly used for assessing which contents are conscious, some brain-based measures seem better suited for measuring conscious level. Objective measures also have their challenges, however. First, objective measures still require a response criterion, for example the decision of whether or not to push a button. Second, they may not even measure consciousness at all because many behavioral proxies, such as forced-choice decision accuracy, are capable of being learned unconsciously.\n\nHobson asserts that the existence of lucid dreaming means that the human brain can simultaneously occupy two states: waking and dreaming. The dreaming portion has experiences and therefore has primary consciousness, while the waking self recognizes the dreaming and can be seen as having a sort of secondary consciousness in the sense that there is an awareness of mental state. Studies have been able to show that lucid dreaming is associated with EEG power and coherence profiles that are significantly different from both non-lucid dreaming and waking. Lucid dreaming situates itself between those two states. Lucid dreaming is characterized by more 40 Hz power than non-lucid dreaming, especially in frontal regions. Since it is 40 Hz power that has been correlated with waking consciousness in previous studies, it can be suggested that enough 40 Hz power has been added to the non-lucid dreaming brain to support the increase in subjective awareness that permits lucidity but not enough to cause full awakening.\n\nDreaming is thus a virtual reality experience with a remarkably predictive simulation of external reality. Lucid dreamers may experience primary consciousness (the dream) and secondary consciousness (the waking) separately but simultaneously. Moreover, primary consciousness has recently been proposed by us to be characteristic of dreaming. It remains to be seen whether the enactment of dream behaviors uses the same brain processes as those that mediate those very behaviors in waking, and whether conscious within a dream is governed by the same processes.\n\nStudies show that it is possible to retain primary consciousness and even secondary consciousness during complex partial epileptic seizures. One study analyzed 40 patients with complex partial seizures to determine their level of consciousness during seizures. The data acquired was based on patients' subjective descriptions of their experience and descriptions from family members who witnessed the seizures. This study found there was a complete absence of consciousness in only 65% of people during the core period of the seizures. Meanwhile, 35% of seizures included some form of primary consciousness. Five seizure descriptions even reported some form of secondary consciousness, albeit short and intermittent. The level and contents of consciousness during epileptic seizures show considerable variability.\n\nIn one study, 10 adult males underwent positron emission tomography scans in three different scenarios:\n\nThe data suggest that the anterior and posterior cingulate cortex as well as the anterior wall of the third ventricle, are major elements of a circuit including thalamic, hippocampal, orbitofrontal, insula, and midbrain sites that are needed for the generation of consciousness of thirst.\nThis study shows that consciousness of some key sensations like thirst is governed by the oldest regions of the brain, which raises the question of whether it is really then possible to say when primary consciousness developed.\n\nIn some types of meditation/yoga it is possible to have the experience known as Samadhi, where there is inner alertness but no object of consciousness. This mental state corresponds with specific physiological parameters.\n"}
{"id": "19442735", "url": "https://en.wikipedia.org/wiki?curid=19442735", "title": "Psychology of reasoning", "text": "Psychology of reasoning\n\nThe psychology of reasoning is the study of how people reason, often broadly defined as the process of drawing conclusions to inform how people solve problems and make decisions. It overlaps with psychology, philosophy, linguistics, cognitive science, artificial intelligence, logic, and probability theory.\n\nPsychological experiments on how humans and other animals reason have been carried out for over 100 years. An enduring question is whether or not people have the capacity to be rational. What does it mean to be rational? Current research in this area addresses various questions about reasoning, rationality, judgments, intelligence, relationships between emotion and reasoning, and development.\n\nHow do people reason about sentences in natural language? Most experimentation on deduction has been carried out on hypothetical thought, in particular, examining how people reason about conditionals, e.g., \"If A then B\". Participants in experiments make the modus ponens inference, given the indicative conditional \"If A then B\", and given the premise \"A\", they conclude \"B\". However, given the indicative conditional and the minor premise for the modus tollens inference, \"not-B\", about half of the participants in experiments conclude \"not-A\" and the remainder concludes that nothing follows.\n\nThe ease with which people make conditional inferences is affected by content, as demonstrated in the well-known selection task developed by Peter Wason. Participants are better able to test a conditional that contains sensible content, e.g., \"if the envelope is sealed then it must have a 50 cent stamp on it\" compared to one that contains symbolic content, e.g.,\" if the letter is a vowel then the number is even\". Background knowledge can also lead to the suppression of even the simple modus ponens inference Participants given the conditional \"if Lisa has an essay to write then she studies late in the library\" and the premise \"Lisa has an essay to write \" make the modus ponens inference 'she studies late in the library', but the inference is suppressed when they are also given a second conditional \"if the library stays open then she studies late in the library\". Interpretations of the suppression effect are controversial \n\nOther investigations of propositional inference examine how people think about disjunctive alternatives, e.g., \"A or else B\", and how they reason about negation, e.g., \"It is not the case that A and B\". Many experiments have been carried out to examine how people make relational inferences, including comparisons, e.g., \"A is better than B\". Such investigations also concern spatial inferences, e.g. \"A is in front of B\" and temporal inferences, e.g. \"A occurs before B\". Other common tasks include categorical syllogisms, used to examine how people reason about quantifiers such as \"All\" or \"Some\", e.g., \"Some of the A are not B\".\n\nThere are several alternative theories of the cognitive processes that human reasoning is based on. One view is that people rely on a mental logic consisting of formal (abstract or syntactic) inference rules similar to those developed by logicians in the propositional calculus. Another view is that people rely on domain-specific or content-sensitive rules of inference. A third view is that people rely on mental models, that is, mental representations that correspond to imagined possibilities. The mental model theory is the subject of the \"mental models website\". A fourth view is that people compute probabilities.\n\nOne controversial theoretical issue is the identification of an appropriate competence model, or a standard against which to compare human reasoning. Initially classical logic was chosen as a competence model. Subsequently, some researchers opted for non-monotonic logic and Bayesian probability. Research on mental models and reasoning has led to the suggestion that people are rational in principle but err in practice. Connectionist approaches towards reasoning have also been proposed.\n\nHow does reasoning develop? Jean Piaget's theory of cognitive development describes a sequence of stages in the development of reasoning from infancy to adulthood. According to the neo-Piagetian theories of cognitive development, changes in reasoning with development come from increasing working memory capacity, increasing speed of processing, and enhanced executive functions and control. Increasing self-awareness is also an important factor.\n\nInductive reasoning makes broad generalizations from specific cases or observations. In this process of reasoning, general assertions are made based on past specific pieces of evidence. This kind of reasoning allows the conclusion to be false even if the original statement is true. For example, if one observes a college athlete, one makes predictions and assumptions about other college athletes based on that one observation. Scientists use inductive reasoning to create theories and hypotheses.\n\nIn opposition, deductive reasoning is a basic form of valid reasoning. In this reasoning process a person starts with a known claim or a general belief and from there asks what follows from these foundations or how will these premises influence other beliefs. In other words, deduction starts with a hypothesis and examines the possibilities to reach a conclusion. Deduction helps people understand why their predictions are wrong and indicates that their prior knowledge or beliefs are off track. An example of deduction can be seen in the scientific method when testing hypotheses and theories. Although the conclusion usually corresponds and therefore proves the hypothesis, there are some cases where the conclusion is logical, but the generalization is not. For example, the argument, “All young girls wear skirts. Julie is a young girl. Therefore, Julie wears skirts,” is valid logically, but is not sound because the first premise isn't true.\n\nThe syllogism is a form of deductive reasoning in which two statements reach a logical conclusion. With this reasoning, one statement could be “Every A is B” and another could be “This C is A”. Those two statements could then lead to the conclusion that “This C is B”. These types of syllogisms are used to test deductive reasoning to ensure there is a valid hypothesis. A Syllogistic Reasoning Task was created from a study performed by Morsanyi, Kinga, Handley, and Simon that examined the intuitive contributions to reasoning. They used this test to assess why “syllogistic reasoning performance is based on an interplay between a conscious and effortful evaluation of logicality and an intuitive appreciation of the believability of the conclusions”.\n\nAnother form of reasoning is called abductive reasoning. This type is based on creating and testing hypotheses using the best information available. Abductive reasoning produces the kind of daily decision-making that works best with the information present, which often is incomplete. This could involve making educated guesses from observed unexplainable phenomena. This type of reasoning can be seen in the world when doctors make decisions about diagnoses from a set of results or when jurors use the relevant evidence to make decisions about a case.\n\nJudgment and reasoning involve thinking through the options, making a judgment or conclusion and finally making a decision. Making judgments involves heuristics, or efficient strategies that usually lead you to the right answers. The most common heuristics used are attribute substitution, the availability heuristic, the representativeness heuristic and the anchoring heuristic – these all aid in quick reasoning and work in most situations. Heuristics allow for errors, a price paid to gain efficiency.\nOther errors in judgment, therefore affecting reasoning, include errors in judgment about covariation – a relationship between two variables such that the presence and magnitude of one can predict the presence and magnitude of the other. One cause of covariation is confirmation bias, or the tendency to be more responsive to evidence that confirms your beliefs. But assessing covariation can be pulled off track by neglecting base-rate information – how frequently something occurs in general. However people often ignore base rates and tend to use other information presented.\nThere are more sophisticated judgment strategies that result in fewer errors. People often reason based on availability but sometimes they look for other, more accurate, information to make judgments. This suggests there are two ways of thinking, known as the Dual-Process Model. The first, System I, is fast, automatic and uses heuristics – more of intuition. The second, System II, is slower, effortful and more likely to be correct – more reasoning.\n\n\nDecision making is often influenced by the emotion of regret and the element of risk. People are strongly motivated by regret and we can see this when they select options they tend to select the option that they will regret the least trying to minimize the amount of regret we will have. Many decisions also include a large element of risk, and in these cases people tend to ask themselves what the level of risk is. They ask themselves how much dread they would experience when thinking about a nuclear accident, and then use that dread as an indicator of risk. We ask “how does this make me feel?” rather than “how risky is this?”\n\nAntonio Damasio suggests that somatic markers, certain memories that can cause a strong bodily reaction, act as a way to guide decision making as well. For example, when you are remembering a scary movie and once again become tense and your palms might begin to sweat. Damasio argues that when making a decision we rely on our “gut feelings” to assess various options, and this makes us decide to go with a decision that is more positive and stay away from those that are negative. He also argues that the orbitofrontal cortex - located at the base of the frontal lobe, just above the eyes - is crucial in your use of somatic markers, because it is the part in the brain that allows you to interpret emotion.\n\nAnother note to make is that when emotion shapes decisions, the influence is usually based on predictions of the future. When people ask themselves how they would react, they are making inferences about the future. Researchers suggest affective forecasting, the ability to predict your own emotions, is poor because people tend to overestimate how much they will regret their errors.\n\n\n\n"}
{"id": "667941", "url": "https://en.wikipedia.org/wiki?curid=667941", "title": "Racial equality", "text": "Racial equality\n\nRacial equality occurs when institutions give equal opportunity to people of all races. In other words, institutions ignore persons' racial physical traits or skin color, and give everyone legally, morally, and politically equal opportunity. In Western society today, there is more diversity and more integration among races. Initially, attaining equality has been difficult for African, Asian, and Latino people, especially in schools. However, in the United States, racial equality, has become a law that regardless of what race an individual is, they will receive equal treatment, opportunity, education, employment, and politics.\n\nSlavery was the key to the start of the bloodiest and most traumatic war in America's history. The American Civil War was fought from 1861 to 1865. By 1860 one in three persons in the Southern States belonged to another, in a population of twelve million, four million were slaves. In September 1862 Lincoln issued his Emancipation Proclamation, which avowed the aim of freeing the slaves in the Confederacy, and made abolition one of the North's central war aims. The North took the victory. Did the end of the war represent a gain or a loss for the country? The war represents a defeat for freedom simply to be let alone, for the beneficiaries of inherited wealth or those who prefer to live on the margins of society, but a victory for those, like the immigrants from Europe and the newly emancipated blacks, who needed government to provide the necessary conditions for the pursuit of happiness.\n\nFour million slaves were freed by the result of the American Civil War. In a few years later the South's elite white was in control again. Economic power was the main reason. Deprived of control over the means of earning a living, the blacks were forced into dependence on white landowners. The blacks worked as farm laborers, or as tenants under the sharecropping system. The biggest problem was the blacks were at the mercy of their white bosses, who would tell them how to vote. Segregations of schools, healthcare and housing became entrenched in the South and the black was relegated to the status of second-class citizen.\n\nThe health of many residents differed depended on areas of living. The poor inner-cities did not or lack the necessary health care that was available in outside areas. Many of the inner-city's location was the main cause for this problem. They were isolated from other parts of society which was a large contributor to the poor health of these residents. Also, the overcrowded living conditions added to the poor health of the residents by the spread of infectious diseases.\n\nMartin Luther King Jr. is better known as a civil rights leader in the United States concerning racial equality. Martin Luther King Jr. became one of the greatest leaders due to his stance concerning various mistreated African-American men and women in the South. Moreover, he played many roles in society and won an award for the movement he conducted. Martin Luther King Jr. not only took part in the Montgomery bus boycott, became a key speaker at the March on Washington, and was one of the youngest individuals to win the Nobel Peace Prize, but he also handled his opinion in a peaceful manner. King kept his anger toward the idea of segregation of race to himself; however, he did show his passion of equality in his speeches and peaceful protest.\n\nKing displayed his very first civil rights movement by voluntarily taking a stance in the Montgomery bus boycott. The bus boycott had started by Rosa Parks refusing to give up her seat for a white male after a long and tiring day at work. Thus, after Park's arrest, King gathered the black community. in hopes for boycotting against the bus, by cutting the use of transportation. This boycott continued on for 382 days. Although, King had to overcome many attacks towards him such as arrest, and violent harassment, the result was their (African-Americans) first victory: black men and women were allowed to ride the buses in Montgomery equally as the whites.\n\nRosa Parks was born on February 4, 1913 in Montgomery, Alabama. She attended the all-black Alabama State College, and soon worked at National Association for the Advancement of Colored People (NAACP) as a secretary. Rosa Parks had become an activists by an event that triggered other events to occur. On December 1, 1955 Parks had taken the bus home from work, when all of a sudden she was being forced to give up her seat for a white male. Rosa Parks had been frustrated of the way black individuals were treated; thus, she refused and was arrested and fined $14.\n\nParks' refusal and arrest had caused a dilemma for white individuals, especially for the ones that owned the bus business. The Montgomery bus boycott had started to desegregate public transportation. Moreover, Martin Luther King Jr. had gotten involved to not only motivate the mistreated African-American population, but to share his passion of equality. This boycott lasted 382 days and ended on December 21, 1956. At the end of the bus boycott, both Rosa Parks and Martin Luther King Jr. had become national heroes. Furthermore, the Supreme Court passed a law which declared it unconstitutional to segregate on Montgomery buses.\n\nMartin Luther King Jr. was the founder of SCLC, by having summoned various numbers of black leaders in 1957. He became the President of this activist group and decided to improve communities by managing peaceful protests and boycotts regarding the social ethics of discrimination and segregation between races.\n\nFirst created on February 12, 1909 in Springfield, Illinois. This group was against violence that was directed towards African Americans. There objective was to eliminate racial inequality, and guarantee the political, educational, social and economic equality for citizens. Their office was located in New York. Moorfield Storey was named president, while, Du Bois, was the only African American Director of Publications.\n\nThere was a civil rights group called Congress of Racial Equality (CORE) that came together to fight corruption and segregation in a nonviolent manner. CORE grew profoundly after the 1950s, beginning with James Farmer who later became the leader of the group and a civil rights activist in 1941. He went back to his \"Native South\" and visited to a local movie theater, where he came upon the \"crow's nest\", an area that was reserved for blacks. He opposed the Jim Crow laws. He realized that his friends and himself supported those laws by what they did in their daily actions. He soon wrote a memo and summoned for the formation of a group of individuals that were powerful from mind and body to be able to take personal nonviolent actions to end discrimination.\n\nCORE was established in 1942 in Chicago. It was a branch of a \"Peace-Lover\" organization, which was called the Fellowship of Reconciliation (FOR). CORE used nonviolent actions procedures that involved sit-ins, which were done in lunch counters in Chicago. By 1947, CORE contributed with an interracial bus ride across the upper part of the South. They were testing state buses that the U.S Supreme Court ordered to be desegregated, which was the \"Morgan v. Virginia\" decision in 1946. This led to some success for the facilities that were testing out the orders they were given, but it didn't grab much attention especially in the national level, which was their main goal. By 1960, there was a new wave of nonviolent direct action protests that initiated through the student sit-in movement. CORE's national director James Farmer repeated the Journey of Reconciliation. Another Supreme Court ruling, \"Boynton v. Virginia\" (1960), ordered a stop to segregation in the interstate bus terminals. That came to be the Freedom Rides. The Freedom Riders traveled deep into the south and were attacked by segregationists along Alabama.\n\nCORE began in the North and was mainly concentrated in public areas. About two decades ago, the North had segregated spots where blacks were not allowed. Those places, for example, were restaurants, bowling alleys, skating rinks, and barber shops. More successful efforts were the work settings where there were some experiments with interracial workers and in housing co-operatives. CORE's main focus was to increase public recognition in the north. In the late 1940s and early 1950s, CORE moved to the border states of Missouri, Maryland, and Oklahoma.\n\nIn the first few weeks of April the two groups CORE and NAACP combined forces to make a change in racial equality. Both the groups protesters constructed a plan to shut down construction of the city's Municipal Services Building, by marching in front of Mayor James Tate's North Philadelphia row house. Furthermore, many protesters had engaged in various fights involving police and white unionists. Moreover, the two groups had caused many debates to open up regarding racial politics, discrimination, and employment.\n\nCORE's technique was always nonviolence as the method of fighting racial injustice. CORE was the first organization to use nonviolent actions in order to stop many issues that affected the black community. The student sit-ins started in February 1960. Within the year, 130 eating locations opened up in the southern communities. They were interested in how CORE approached the issue of segregation.\n\nCORE grew in the early 1940s, but continued to be composed of small groups. They persisted in being small because of the students who were part of the organization. The students would graduate and move away. Also, others were fighting for a specific cause and once the issue has been dealt with, they disappeared. CORE was only a voluntary organization; there was no paid staff.\n\nIn the South:\n\nIn the North:\n\nMany outsiders started to notice the efforts of the group. They supported them and started the Freedom Rides. CORE was more involved in the Black Power movement around the mid-1960s. Then things shifted to integration and nonviolent actions toward the organization of communities, the separation of the people, and Black Power. Also, as whites and blacks started to work together to fight over the dilemmas of segregation, white liberals weren't fond of the idea that they were working together. CORE's issues changed over time, so they worked on different actions that would come up.\n\nSit-ins, the oldest technique, have been used by CORE the most. CORE divided people into three different groups: one with all black individuals, one with all whites, and one that was interracial. These three different groups would go to a segregated eating area before the busiest hour and wait to be attended quietly. This was used to open up restaurants, and was later used for other locations.\n\nThis was used at cafeterias, ticket booths, and other places where one stands in a line in order to be served. If someone is refused, the CORE members who might be in line before him/her will also refuse to step out of line and interrupt service. CORE did this at movie theaters in Kentucky, and at a swimming pool at Palisades Amusement Park in New Jersey. This technique was also important for stopping segregation.\n\nSince 1942, two particular issues have evolved in racial equality. One is the handling of blacks to ensure equality, which was favored by the white community, and the other is the differences between southerners and non-southerners. These two issues were observed by the National Opinion Research Center (NORC). They made questions that plotted five main topics that targeted blacks at the time. The five points that affected racial equality and tracked during the years 1965–1980 were \"year, region, cohort, and education\". Many educational systems in the south and non-southern areas were in favor of segregated educational institutions among blacks. They also didn't want blacks near their neighborhood or interracial marriages to happen.\n\nThe abolishment of slavery in all states. \n\nAllowed citizenship to individuals that were born in the United States such as Native Americans and African Americans. It also stops any other state to pass their own law which will violate this amendment. It prohibits states from opposing any person's \"life, liberty or property, without law coming forward on the individual\" or to \"deny to any person within its authority the equal protection of the laws.\"\n\nAllowed African Americans to vote.\n\nGranted citizenship to individuals without discriminating or viewing race, color, or the previous act of being a slave. \n\nIn Southern States, a law that enforced a separation of blacks and whites from public facilities such as employment, housing, education, politics, military service, sports, and business. In other words, a separate but equal rank was given to the African Americans; also, it was not violating any laws that the government had made of the United States. \n\n"}
{"id": "27424120", "url": "https://en.wikipedia.org/wiki?curid=27424120", "title": "Reki-jo", "text": "Reki-jo\n\nReki-jo is a contraction of .\n\nThe Shinsengumi are a common interest of \"reki-jo\".\nOther historical figures commonly of interest to \"reki-jo\" include:\n\nModel Anne Watanabe, daughter of actor Ken Watanabe, is a notable \"reki-jo\".\n\nThe manga and anime character from the \"Genshiken\" franchise is an example of a reki-jo in popular fiction.\n\nIn the series \"Girls und Panzer\", the Hippo Team is made up of Ooarai Girls High School's reki-jo clique.\n\n\n"}
{"id": "635973", "url": "https://en.wikipedia.org/wiki?curid=635973", "title": "Ring of Gyges", "text": "Ring of Gyges\n\nThe Ring of Gyges () is a mythical magical artifact mentioned by the philosopher Plato in Book 2 of his \"Republic\" (2:359a–2:360d). It grants its owner the power to become invisible at will. Through the story of the ring, \"Republic\" considers whether an intelligent person would be moral if they did not have to fear being caught and punished for doing injustices.\n\nGyges of Lydia was a historical king, the founder of the Mermnad dynasty of Lydian kings. Various ancient works—the most well-known being \"The Histories\" of Herodotus—gave different accounts of the circumstances of his rise to power. All, however, agree in asserting that he was originally a subordinate of King Candaules of Lydia, that he killed Candaules and seized the throne, and that he had either seduced Candaules' Queen before killing him, married her afterwards, or both.\n\nIn Glaucon's recounting of the myth, an unnamed ancestor of Gyges was a shepherd in the service of the ruler of Lydia. After an earthquake, a cave was revealed in a mountainside where he was feeding his flock. Entering the cave, he discovered that it was in fact a tomb with a bronze horse containing a corpse, larger than that of a man, who wore a golden ring, which he pocketed. He discovered that the ring gave him the power to become invisible by adjusting it. He then arranged to be chosen as one of the messengers who reported to the king as to the status of the flocks. Arriving at the palace, he used his new power of invisibility to seduce the queen, and with her help he murdered the king, and became king of Lydia himself.\n\nIn \"Republic\", the tale of the ring of Gyges is described by the character of Glaucon who is the brother of Plato. Glaucon asks whether any man can be so virtuous that he could resist the temptation of being able to perform any act without being known or discovered. Glaucon suggests that morality is only a social construction, the source of which is the desire to maintain one's reputation for virtue and justice. Hence, if that sanction were removed, one's moral character would evaporate.\n\nGlaucon posits:\n\nThough his answer to Glaucon's challenge is delayed, Socrates ultimately argues that justice does not derive from this social construct: the man who abused the power of the Ring of Gyges has in fact enslaved himself to his appetites, while the man who chose not to use it remains rationally in control of himself and is therefore happy. (Republic 10:612b)\n\n\n\n"}
{"id": "3645417", "url": "https://en.wikipedia.org/wiki?curid=3645417", "title": "Society for the Study of Evolution", "text": "Society for the Study of Evolution\n\nThe Society for the Study of Evolution is a professional organization of evolutionary biologists. It was formed in the United States in 1946 to promote evolution and the integration of various fields of science concerned with evolution and to organize the publication of a scientific journal to report on new research on evolution across a variety of fields.\n\nThe Society was established at a meeting in St. Louis on March 30, 1946. Fifty-seven scientists attended the meeting, which was chaired by Alfred E. Emerson. George Gaylord Simpson was elected as the Society's first President, with E. B. Babcock, Emerson, and J. T. Patterson as his Vice-presidents and Ernst Mayr as secretary. This society grew as an extension of the US National Research Council's Committee on Common Problems of Genetics and Paleontology (later renamed the Committee on Common Problems of Genetics, Paleontology and Systematics).\n\nThe first annual meeting of the society was held in Boston, December 28–31, 1946. A grant from the American Philosophical Society led to the publication of the journal \"Evolution\".\n\nCommonly known as 'evolution meeting,' the annual conference is often held together with the Society of Systematic Biologists and the American Society of Naturalists.\n\nThe society has an official journal \"Evolution\". It was started in 1947 and is published by John Wiley & Sons. In 2017, it launched a second journal \"Evolution Letters\".\n\n\n"}
{"id": "265564", "url": "https://en.wikipedia.org/wiki?curid=265564", "title": "Solitary confinement", "text": "Solitary confinement\n\nSolitary confinement is a form of imprisonment distinguished by living in single cells with little or no contact to other inmates, strict measures to control contraband, and the use of additional security measures and equipment. It is specifically designed for disruptive inmates that are security risks to other inmates, the prison staff, or the prison itself. It is mostly employed for violations of discipline, such as murder, hostage-taking, deadly assault, and rioting. However, it is also used as a measure of protection for inmates, whose safety is threatened by other inmates. Prison authorities consider solitary confinement an administrative placement measure, not a punishment.\n\nSolitary confinement is colloquially referred to in American English as \"the hotbox\", \"the hole\", \"AdSeg\" (administrative segregation), the \"SHU\" (pronounced \"shoe\"), an acronym for \"Special Housing Unit\" or \"Security Housing Unit\"; in Australian English as \"the Slot\" or \"the Pound\"; in British English as \"the block\", \"The Segregation Unit\", or \"the cooler\". It has also been called prison \"'segregation' and 'restrictive housing.'\"\n\nSolitary confinement has received severe criticism for having detrimental psychological effects and, to some and in some cases, constituting torture. According to a 2017 review study, \"a robust scientific literature has established the negative psychological effects of solitary confinement\", leading to \"an emerging consensus among correctional as well as professional, mental health, legal, and human rights organizations to drastically limit the use of solitary confinement.\"\n\nResearch surrounding the possible psychological and physiological effects of solitary confinement dates back to the 1830s. When the new prison discipline of separate confinement was introduced at the Eastern State Penitentiary in Philadelphia in 1829, commentators attributed the high rates of mental breakdown to the system of isolating prisoners in their cells. Charles Dickens, who visited the Philadelphia Penitentiary during his travels to America, described the \"slow and daily tampering with the mysteries of the brain to be immeasurably worse than any torture of the body\". Prison records from the Denmark institute in 1870 to 1920 indicate that staff noticed inmates were exhibiting signs of mental illnesses while in isolation, revealing that the persistent problem has been around for decades.\n\nThe first comment by the Supreme Court of the United States about solitary confinement's effect on prisoner mental status was made in 1890 (In re Medley 134 U.S. 160). In it the court found that the use of solitary confinement produced reduced mental and physical capabilities. The use of solitary confinement in prisons was first introduced to regulate unruly prisoners and keep them away from the rest of the prison society (Haney, Craig; Lynch, Mona). However, solitary confinement has been linked to several developments of mental disorders, one of which being Ganser syndrome. A man developed Ganser syndrome after being held in solitary confinement for a long term sentence; however, that development is seen as rare and is unlikely in most cases.\n\nThe effects of solitary confinement on mental health are undeniable. According to the Journal of the American Academy of Psychiatry online, solitary confinement can cause an array of mental disorders, as well as provoke an already existing mental disorder in a prisoner, causing more trauma and symptoms. Solitary confinement is a form of imprisonment practiced worldwide, but no positive effects of the punishment have been proven (Jaapl). Nonetheless, penal confinement involving solitude has been described as having a beneficent effect on anthrophobes. \n\nThe practice is used when a prisoner is considered dangerous to themselves or to others, is suspected of organizing or being engaged in illegal activities outside of the prison, or, as in the case of a prisoner such as a pedophile or witness, is at a high risk of being harmed by another inmate or inmates. The latter example is a form of protective custody. Solitary confinement is also the norm in supermax prisons where prisoners who are deemed dangerous or of high risk are held. It may be hard to determine the number of people currently being held in solitary confinement because some prisons have a hard time defining it. However, it is estimated that 80,000 to 100,000 people are currently in solitary confinement.\n\nThe effects of solitary confinement on juveniles can be highly detrimental to their growth. The isolation of solitary confinement can cause anguish, provoke serious mental and physical health problems, and work against rehabilitation for juveniles. Because young people are still developing, traumatic experiences like solitary confinement may have a profound effect on their chance to rehabilitate and grow. Solitary confinement can worsen both short- and long-term psychological and physical problems or make it more likely that such problems will develop. The American Civil Liberties Union (ACLU) and Human Rights Watch created a report that incorporated the testimony of some juvenile inmates. Many interviews described how their placement in solitary confinement exacerbated the stresses of being in jail or prison. Many spoke of harming themselves with staples or razors, having hallucinations, losing touch with reality, and having thoughts of or attempting suicide – all this while having very limited access to health care.\n\nJuveniles in solitary confinement are routinely denied access to treatment, services, and programming required to meet their medical, psychological, developmental, social, and rehabilitative needs. The ACLU and the Human Rights Watch have made recommendations at both a State and Federal level regarding their lack of access to medical services etc.\n\nAs well as severe and damaging psychological effects, solitary confinement manifests physiologically as well. Solitary confinement has been reported to cause hypertension, headaches and migraines, profuse sweating, dizziness, and heart palpitations. Many inmates also experience extreme weight loss due to digestion complications and abdominal pain. Many of these symptoms are due to the intense anxiety and sensory deprivation. Inmates can also experience neck and back pain and muscle stiffness due to long periods of little to no physical activity. These symptoms often worsen with repeated visit to solitary confinement.\n\nThe UN Special Rapporteur on Torture and other UN bodies have stated that the solitary confinement (physical and social isolation of 22–24 hours per day for 1 day or more) of young people under age 18, for any duration, constitutes cruel, inhumane, or degrading treatment.\n\nIn the UK, the state has a duty to “set the highest standards of care” when it limits the liberties of children. Many believe, Frances Crook included, that incarceration and solitary confinement are the harshest forms of possible punishments and “should only be taken as a last resort.” Additionally, because children are still mentally developing, incarceration should not encourage them to commit more violent crimes.\n\nThe penal system has been cited as failing to protect juveniles in custody. In the UK, “twenty-nine children have died in penal custody in 1990. Some 41% of the children in custody were officially designated as being vulnerable.” This is attributed to the fact that isolation and physical restraint are being used as the first response to punish them for simple rule infractions. Moreover, Frances Crook argues that these punitive policies not only violate their basic rights, but also leave the children mentally unstable and left with illnesses that are often ignored. Overall, the solitary confinement of youth is considered to be counterproductive because the “restrictive environment…and intense regulation of children” aggravates them, instead of addressing the issue of rehabilitation.\n\nThe penal system in the United States developed under two separate systems known as the Auburn system and Pennsylvania system. The current system of solitary confinement was derived originally from the Pennsylvania model which was characterized by \"isolation and seclusion.\" Evidence has shown that Quakers and Calvinists supported solitary confinement as an alternative form of punishment. At the time it was meant to provide a prisoner with solitude “to reflect on his misdeeds” and restore his relationship with God. Solitary confinement was intended as an alternative to public floggings which were common at the time. In 1818, New York reformer and Friend, Thomas Eddy, lobbied for inmate labor and solitary confinement in place of other forms of punishment such as hanging. Shortly after, New York decided to include solitary confinement and inmate labor into their penal system.\n\nIn the US Federal Prison system, solitary confinement is known as the Special Housing Unit (SHU), pronounced like \"shoe\" (). California's prison system also uses the abbreviation SHU, but it stands for Security Housing Units. In other states, it is known as the Special Management Unit (SMU). Current estimates of the number of inmates held in solitary confinement are difficult to determine, though generally the minimum held at any given time has been determined to be 20,000, with estimates as high as 80,000.\n\nThe inmate held in solitary confinement for the longest time in U.S. federal prison is Thomas Silverstein, in solitary since 1983. He now resides in ADX Florence federal penitentiary in Colorado. The inmate held in solitary confinement for the longest time in the United States is Albert Woodfox, the last of the Angola Three, in solitary in Louisiana State Penitentiary from 1972 to 2016. A May 2013 report on California's Pelican Bay State Prison in \"Mother Jones\" magazine also cites one inmate there who \"recently marked his 40th year in solitary\".\n\nJuveniles are held in solitary confinement in jails and prisons across the United States, often for days, weeks, months, or even years in order to punish, protect, house, or treat some of the youth held there. There is significant controversy surrounding the use of solitary confinement in cases of juveniles.\n\nThe Troubled Teen Industry is a loosely connected series of for-profit wilderness therapy programs, boot camps, therapeutic boarding schools, and residential treatment centers. These facilities house youth after parents sign away custody of their children. These children can be sent to these facilities for any reason, without committing a crime, without a trial, and without legal representation. Solitary confinement is used widely in these programs, including wilderness programs, where children are left alone for weeks in the wilderness. Some programs place children in solitary rooms. Other times, \"code silence,\" or \"comm block,\" is used, which means that the child is not allowed to speak, and the other inmates must ignore them and pretend they do not exist. This practice was documented at Island View Residential Treatment Center.\n\nPatients in psychiatric hospitals are often put into solitary confinement, usually for 24 hours at a time, when staff members determine that they are a danger to themselves or others.\n\nThe use of SHUs within the Federal Bureau of Prisons is regulated under . When placed in the SHU, prisoners are either in \"administrative detention status\", a non-punitive status which removes prisoners from the general population when necessary to ensure the safety, security, and orderly operation of correctional facilities, or protect the public, or \"disciplinary segregation status\", a punitive status imposed only by a Discipline Hearing Officer (DHO) as a sanction for committing prohibited acts. There are more than 100 prohibited acts, all of which may result in solitary confinement, including unauthorized physical contact such as kissing, using abusive or obscene language, feigning illness, circulating a petition, insolence towards a staff member, engaging in or encouraging a group demonstration or protest, and participating in or encouraging a labor strike (also known as a prison strike), gang activity, among others.\n\nWoodbourne Correctional Facility houses the inmate in with the most time spent in New York state's solitary confinement units. Inmate Willie Bosket, now suffering mental and health problems, was confined in Woodbourne Correctional Facility. He has been in SHU for over 20 years after violent incidents directed at prison staff. Allowed no physical contact with humans, he is watched on camera at all times, takes showers in his cell (the water turns on for 10 minutes every two days) and is fed through a metal slot. He is currently serving a sentence of 82 years to life at Five Points Correctional Facility. Luis Rosado, known as 'Blue Boy', is another prisoner with a violent history facing indefinite solitary confinement in New York State's Correctional system. Pavle Stanimirovic writes about both inmates or as he distinguishes between convict and inmate in a book about his 4 years time in Solitary Confinement and long term keep lock . True Crime Author Burl Barer talks about Pavle Stanimirovic and how it was in SHU with Blue Boy, in Danamora Clinton .CF, Upstate NY a SHU 2000 Box Punch as the convict a person that has suffered a traumatic experience, his true story is a great inspiration for people that might go through the same experience entering into a sub -world of violence, was part violence and many riots, Upstate was part of gangs growing in the 1990s to 2000s is the only known comprehensive first hand account about treatment in Solitary Confinement in the NYSDOCS\n\nSolitary confinement is becoming more and more popular throughout the U.S. with some \"supermax\" prisons have nothing but solitary confinement cells. \"Some people are held in solitary confinement in special \"supermax\" prisons, such as California's Pelican Bay, Virginia's Red Onion, and the federal government's ADX in Florence, Colorado. At least 44 states and the federal system now have supermax prisons, which are generally composed solely of solitary confinement cells. Other prisoners live in SHUs, RHUs, and IMUs within ordinary prisons, and even inside local jails.\"\n\nWhen California opened its first \"adjustment center\", the goal was to return prisoners to the mainline prison population and ultimately to a society through an enrichment program of psychological and social services. However, the plan was never executed. In 1983, George Deukmejian was elected as the California governor and during his time, he formed what was then the state's newest prison – a massive, windowless “security housing unit” (SHU). SHU was intended to segregate over a thousand prisoners from the rest of the prison system through isolation. Deukmejian boasted that the Pelican Bay State Prison was a \"state-of-the-art prison that will serve as a model for the rest of the nation...\".\n\nThe prisoners are kept confined to their cells almost twenty-three hours a day and all forms of human contact through refined locking and monitoring systems are minimized. Pelican Bay SHU was one of the first visible “super-maximum security” facilities and thus it attracted lots of media attention. Those opposing the conditions of California's “supermax” resulted in the federal court criticizing certain features of the prison but left the basic regimen of segregation and isolation largely intact.\n\nOne of the policies of supermax confinement among other policies is designed to increase punishment by removing gang members from the mainline population and subject them to solitary confinement, whether it is for a set amount of time or an indefinite duration. In a recent study, it noted that the California Department of corrections has implemented ways to fix their alleged gang problem, such as using ‘confidential informants,’ segregating gang members, intercepting gang communications, setting up task forces to monitor and track gang members, locking up gang leaders in high security prisons, and ‘locking down’ entire institutions.\n\nThese facilities, supermax prisons, were originally designed to contain and control the worst criminals and those who did not adhere to the rules of prisons, AKA \"the worst of the worst\". As of 2001, the count of inmates in administrative segregation in California was 5,982 representing an 80.2% change over time, but this number is not quite correct due to deficient files provided. Increasingly, the practice of using solitary confinement long term, instead of the intended three-month period, in the supermax prisons as inmate management has become the norm. The selected inmates, who wear jumpsuits that differentiate them from the general population, will spend around 23 hours a day alone in a cell where they are offered very little and fully monitored as is procedure at Pelican Bay State Prison which is one of the largest supermax prisons in the United States. In order to be sent to Pelican Bay, the inmate has either committed murder, assault, riots, threatening staff or fellow inmates, and even gang affiliation which must be validated by the prison staff.\n\nThere are 22 SHU units of Pelican Bay which include 132 eight-cell pods that are lit by heavy Plexiglass skylights enclosed by steel cell doors. The inmates are provided with a concrete slab as a bed, a toilet, small shelf, and a concrete stool with no windows in an 80 sq. foot space. SHU inmates are allotted for an hour and a half of exercise every day where they are taken to a 26 by 20 foot area surrounded by 20 foot high cement walls. Only one prisoner from each pod can move at a time and will be placed in waist restraints for any medical/dental appointments to assist in the examination process and may also have leg restraints placed on them before they are able to leave the unit depending on the purpose of the appointment.\n\nIn San Quentin State Prison, the violence rates were still high in the 1980s despite the similar lockdowns and procedures of Pelican Bay because these prisoners use the small windows out of lockdown to either harm themselves or others. They typically will try not to harm themselves while in the psychiatric hospital ward either, but they will plan out while in lockdown until they can see their plan through. However even as they near their release dates, they are moved to “prerelease programs” out of the SHU which are successful with some prisoners, but it causes most others to become even more uncontrollable and unpredictable due to their mental states that aren’t properly cared for or screened.\n\nIn May 2012, California's prison system faced a lawsuit from the Center for Constitutional Rights and a group of California attorneys for the use of long terms of solitary confinement, some lasting for decades.\n\nIn September 2014, easing some conditions for inmates in near-solitary confinement in California prisons has died in the state legislature. The bill was among others supposed to reform Security Housing Units rules to allow the inmates to keep photographs and make a phone call after three months of good behavior was listed as inactive on Friday after a decision on Thursday evening by state Senator Loni Hancock to drop it.\n\nIn 2012, a report was conducted by the Vera Institute of Justice revealed that Maryland's use of restricted housing was twice the national average (8.5% versus an average of 4%). Legislation was introduced in in 2015.\n\nAccording to a psychiatrist, Dr. Annette Hanson's article, who works with Maryland's Department of Public Safety and Correctional Services (DPSCS), prolonged segregation does not provide deleterious effects on inmates. DPSCS also asserted that solitary confinement doesn't exist in their institutions.\n\nSince the 1980s, the New York City Department of Correction has increased the use of segregation as a discipline and management tool. In effect, segregation is a secondary sentence imposed by the correctional facility, which is usually unrelated to the conviction for which the person is incarcerated. There are high rates of use of solitary confinement in New York when compared to other U.S. states. Within the New York prison system, solitary confinement is frequently imposed for nonviolent, “trivial prisoner offenses.” Usually the common misconception is that solitary confinement is a punishment of last resort, reserved for inmates who present a threat of violence or escape. Inmates that are released from solitary confinement go through a “transitional unit” but failure in the program results in their return to solitary confinement. Overall, most of the inmates fail and return to solitary confinement. New York has the highest rate of “disciplinary segregation” in the country, making solitary confinement a regular every day action among the prison. Although prisons nationwide have decreased use of solitary confinement, the New York City Department of Correction expanded its capacity by 27 percent in 2011 and another 44 percent in 2012, according to the NYC Jails Action Coalition. Although the DOC housed 1,000 more inmates in 1990 than it does today, its jails have more solitary cells now. Due to this the city is topping the charts of municipalities with a high rate of solitary confinement. On any given day, there are about 4,500 men, women, and children in some form of isolated confinement in New York State prisons. This is not including New York City's jails, which are run under a separate system, where those in solitary confinement reach close to 1,000 or more.\n\nA new bill was introduced by Councilman Danny Dromm would require the Department of Correction to post a monthly report on its website about punitive segregation. It would also require data on the number of people in punitive segregation, the length of time in this setting, the nature of the infractions, age, mental health, if they were prescribed medication or moved to a hospital, violence against others and inmate requests. Many are supportive of this bill with the goal being to make jail facilities safer for inmates and correction officers.Individuals who are released and experience solitary confinement go back into their communities and reoffend at higher rates than general population prisoners causing them to land back into prison. Policy changes that will reduce the use and long-term impact of segregation will benefit not only the staff and prisoners in these units but also ultimately the well-being of facilities, systems, and the community. Councilman Dromm also issued a separate resolution seeking to end the practice of the time owed. For example, an inmate, because of good behavior or other reasons, might only have served 100 of his or her 180-day sentence in solitary and then was released. A few years or even decades later the person is rearrested. Under current rules he or she must complete those unserved 80 days in solitary. This resolution however is only a request since the Council does not have the authority to make the Department of Correction adhere.\n\nThe New York City Department of Corrections reported that in fiscal year 2012 more than 14.4 percent of all adolescents detained at Rikers Island between the ages of 16 and 18 were held in at least one period of solitary confinement while detained. The average length of time young people spent in solitary confinement at Rikers Island was 43 days. More than 48 percent of adolescents at this institution have diagnosed mental health problems. As violence associated with the crack epidemic became increasingly common, new measures were taken. The Red ID card system, instituted in the early 1990s, was a way of identifying inmates with histories of inciting riots, cuttings, stabbings, and other dangerous behaviors. It almost always meant the convict had spent time in a notorious ward designated for punitive confinement called \"The Bing\" (HDM 5 Block). Prisoners Pavle Stanimirović, James Rosado, Tyrone Green, Pedro Hernandez, Willie Bosket, Hector Rivera, Ángel Díaz, John Maldonado and Dominick Pollatti all spent time in \"The Bing.\"\n\nThe New York City Department of Correction ended punitive segregation for adolescents in December 2014, and ended punitive segregation for young adults, 18 to 21, in October 2016. This is partly due to the case of Kalief Browder.\n\nThe European Court of Human Rights has three labels for solitary confinement: complete sensory isolation, total social isolation and relative social isolation.\n\nEuropean Committee for the Prevention of Torture and Inhuman or Degrading Treatment or Punishment, or CPT, defines solitary confinement as \"whenever a prisoner is ordered to be held separately from other prisoners, for example, as a result of court decision, as a disciplinary sanction imposed within the prison system, as a preventative administrative measure or for the protection of the prisoner concerned\".\n\nIn Italy, a person sentenced to more than one life sentence is required to serve a period of between 6 months to 3 years in solitary confinement.\n\nSolitary confinement as a disciplinary measure for prisoners in Europe was largely reduced or eliminated during the twentieth century. In 2004, only 40 out of 75,000 inmates held in England and Wales were placed in solitary confinement cells.\n\nOfficially, the purpose of placing prisoners in secure housing units (SHUs) is to increase control over dangerous inmates. Some hope the SHU encourages prisoners to reflect on their actions. These units are characterized by extreme isolation of prisoners who \"are housed in small cells with solid steel doors…for 22 to 23 hours per day.\" Inmates are also deprived of social interaction and denied access to educational or therapeutic programs and health care while being held in SHUs.\n\nIt has been shown that the conditions of these secure housing units have severe mental and psychological effects on prisoners. Prisoners in SHUs are isolated for long periods of time. Instances of assault and torture against these prisoners in response to trivial things have also been cited. Social isolation housing, can reduce environmental stimulation, and causes a feeling of loss of control over all aspects of a prisoner's daily life. These environmental stimulations include but aren't limited to hypersensitivity to stimuli, distortions and hallucinations, increased anxiety and nervousness, diminished impulse control, severe and chronic depression, appetite loss and weight loss, heart palpitations, talking to oneself, problems sleeping, nightmares, self-mutilation, difficulties with thinking, concentration, and memory, and lower levels of brain function. The common justification by officials is that prisoners of certain natures deserve to be punished for the threat that they pose to society. This can be attributed to the fear of increasing crime rates and therefore, support the government's effort to enforce harsher forms of punishment.\n\nThe most \"notorious example of the extreme social isolation found in supermaximum custody units\" is the SHU at SouthPort NYDOCS Upstate Correctional Facility & Pelican Bay State Prison. From studying conditions at Pelican Bay, researchers argue that long-term social isolation \"carries major psychiatric risks.\" Prisoners are susceptible to developing mental illnesses because they are confined to coffin-like conditions and denied access to basic health services. Illnesses range from anxiety, clinical depression, and self-mutilation to suicidal thoughts and SHU syndrome. Yet, it is important to note that the duration of the isolation is the most important factor in determining the effects of solitary confinement.\n\nSupermax prisons, large-scale implementations of secure housing units, employ solitary confinement to isolate predatory, disorderly inmates from the rest of the prison community. Federal Bureau of Prisons create special supermax facilities to contain the most aggressive inmates in a protective effort. Kate King, professor and director of Criminal Justice at Murray State University, Benjamin Steiner, professor of Criminal Justice at the University of Cincinnati, and Stephanie Ritchie Breach, director of the Third District Youth Court, explain how while violence has always been a factor in prison life, the level of aggression is magnified in facilities where all such members of the prison system are concentrated. These scholars argue that the violent nature of supermax prisons such as Pelican Bay State Prison are perpetrated by prison culture itself. King, Steiner, and Breach question the effectiveness of these institutions and claim the violent reputation of American prisons stems from this departure from the treatment model. Supermax prisons are also scrutinized on legal and ethical bases. Scholars Jesenia Pizarro and Vanja Stenius note that the overall constitutionality of these prisons are still quite unclear. Many argue the conditions in which these inmates live do not meet the standards of the Eighth Amendment to the United States Constitution.\n\nShira E. Gordon, a University of Michigan Law Student, argues that solitary confinement leads to an increase in recidivism and violence. To substantiate this conclusion, she cites two quantitative research based studies that support this nexus and counters those who argue that solitary confinement deters recidivism. Daniel Mears and William Bales “compared recidivism rates by matching…prisoners who were incarcerated in solitary confinement with prisoners who had been in the general prison population.” They found that \"24.2 percent of the prisoners held in solitary confinement were reconvicted of a violent crime compared to 20.5 percent of prisoners held in population.\" And this behavior may be attributed to the mental illnesses prisoners may develop, as well as the dehumanizing treatment they are subject to.\n\nAccording to a March 2014 article in \"American Journal of Public Health\", “Inmates in jails and prisons attempt to harm themselves in many ways, resulting in outcomes ranging from trivial to fatal.” While some inmates are known to have psychiatric disorders prior to entering the prison, others develop mental disorders as a result of being placed in solitary confinement. A main issue within the prison system and solitary confinement is the high number of inmates who turn to self-harm. Studies have shown that the longer one stays in the prison, the more at risk he or she is to self-harm.\n\nOne study has shown that “inmates ever assigned to solitary confinement were 3.2 times as likely to commit an act of self-harm per 1000 days at some time during their incarceration as those never assigned to solitary.” The study has concluded that there is a direct correlation between inmates who self-harm and inmates that are punished into solitary confinement. Many of the inmates look to self-harm as a way to “avoid the rigors of solitary confinement.” Mental health professionals ran a series of tests that ultimately concluded that “self-harm and potentially fatal self-harm associated with solitary confinement was higher independent of mental illness status and age group.”\n\nPhysicians have concluded that for those inmates who enter the prison already diagnosed with a mental illness, the punishment of solitary confinement is extremely dangerous in that the inmates are more susceptible to exacerbating the symptoms. Professional organizations, like the National Commission on Correctional Health Care (NCCHC), the American College of Correctional Physicians, and American Psychiatric Association (APA), work to improve the mental health services, however, the systems within the prisons \"remain woefully inadequate.\" \"Psychological effects can include anxiety, depression, anger, cognitive disturbances, perceptual distortions, obsessive thoughts, paranoia, and psychosis.\" These studies suggest that a main issue with isolating prisoners who are known to have mental illnesses is that it prevents the inmates from ever possibly recovering. Instead, many \"mentally ill prisoners decompensate in isolation, requiring crisis care or psychiatric hospitalization.\" It is also noted that if a prisoner is restrained from interacting with the individuals they wish to have contact with they exhibit similar effects.\n\nSuicide is often seen as a means to escape from solitary confinement, especially amongst those who deal with deeper mental illnesses like depression. Depression is one of the most common reasons why inmates often kill themselves. Solitary confinement has been said to increase symptoms of those with mental health issues.\n\n\"Prisoner mental health is becoming increasingly important,\" and has caught the attention of the World Health Organization, which aims to reduce the \"effects of imprisonment on mental health.\" One study focused on the \"prison environment rather than on individual factors.\" The study tested two time periods, short-term and long-term, that evaluated the \"mental state changes in response to changes in the environment or prison setting.\" It ultimately concluded that solitary confinement was \"associated with negative effects on mental health.\" Segregation, though similar to solitary confinement, could not be proven to have lasting negative effects on inmates, although those who were segregated had worse mental health than those who were not segregated. The study also concluded that crowding had its own problems, as \"increased levels of social density had negative effects on the mental health of inmates.\"\n\nSome sociologists argue that prisons create a unique social environment that do not allow inmates to create strong social ties outside or inside of prison life. Men are more likely to become frustrated, and therefore more mentally unstable when keeping up with family outside of prisons. Extreme forms of solitary confinement and isolation can affect the larger society as a whole. The resocialization of newly released inmates who spent an unreasonable amount of time in solitary confinement and thus suffer from serious mental illnesses is a huge dilemma for society to face. The effects of isolation unfortunately do not stop once the inmate has been released. After release from segregated housing, psychological effects have the ability to sabotage a prisoner's potential to successfully return to the community and adjust back to ‘normal’ life. The inmates are often startled easily, and avoid crowds and public places. They seek out confined small spaces because the public areas overwhelm their sensory stimulation.\n\nIn 2002, the Commission on Safety and Abuse in America, chaired by John Joseph Gibbons and Nicholas Katzenbach found that: \"The increasing use of high-security segregation is counter-productive, often causing violence inside facilities and contributing to recidivism after release.\"\n\nSolitary confinement has been traditionally used as a behavioral reform of isolating prisoners physically, emotionally and mentally in order to control and change inmate behavior. Recently arrived inmates are more likely to violate prison rules than their inmate counterparts and thus are more likely to be put in solitary confinement. Additionally, individual attributes and environmental factors combine to increase an inmate's likelihood of being put into solitary confinement.\n\nSolitary confinement is considered to be a form of psychological torture with measurable long-term physiological effects when the period of confinement is longer than a few weeks or is continued indefinitely.\n\nThe documented psychological effects led one judge in a 2001 suit to rule that \"Solitary confinement units are virtual incubators of psychoses—seeding illness in otherwise healthy inmates and exacerbating illness in those already suffering from mental infirmities.\" In fact, as of 2016, there have been thirty-five U.S. Supreme Court cases petitioning solitary confinement.\n\nIn October 2011, UN Special Rapporteur on torture, Juan E. Méndez, told the General Assembly's third committee, which deals with social, humanitarian, and cultural affairs, that the practice could amount to torture.\n\n“Considering the severe mental pain or suffering solitary confinement may cause, it can amount to torture or cruel, inhuman or degrading treatment or punishment when used as a punishment, during pre-trial detention, indefinitely or for a prolonged period, for persons with mental disabilities or juveniles,” he warned.\n\nIn November 2014. the United Nations Committee Against Torture noted that full isolation for 22–23 hours a day in super-maximum security prisons is unacceptable. The United Nations have also banned the use of solitary confinement for longer than 15 days.\n\nMisuse of solitary confinement has been widely controversial. In immigration detention centers, reports have surfaced concerning its use against detainees in order to keep those knowledgeable about their rights away from other detainees. In the prison-industrial complex itself, reports of solitary confinement as punishment in work labor prisons have also summoned much criticism. One issue prison reform activists have fought against is the use of Security Housing Units (extreme forms of solitary confinement). They argue that they do not rehabilitate inmates but rather serve only to cause inmates psychological harm. Further reports of placing prisoners into solitary confinement based on sexual orientation, race and religion have been an ongoing but very contentious subject in the last century.\n\nOpponents of solitary confinement hold that it is a form of cruel and unusual punishment and torture because the lack of human contact, and the sensory deprivation that often go with solitary confinement, can have a severe negative impact on a prisoner's mental state that may lead to certain mental illnesses such as depression, permanent or semi-permanent changes to brain physiology, an existential crisis, and death.\n\nResearch has shown that the routine features of prison can make huge demands on limited coping resources. After prison many ex-convicts with mental illness do not receive adequate treatment for their mental health issues, because health services turn them away. This is caused by restrictive policies or lack of resources for treating the formerly incarcerated individual. In a study focusing on women and adolescent men, those who had health insurance, received mental health services, or had a job were less likely to return to jail. However, very few of the 1,000 individuals in this study received support from mental health services.\n\nTreating mentally ill patients by sentencing them into solitary confinement has captured the attention of human rights experts who conclude that “solitary confinement may amount to cruel, inhuman, or degrading treatment” that violates rights specifically targeting cruel, inhuman treatment. Health care professionals and organizations recognize the fact that solitary confinement is not ethical, yet the segregating treatment fails to come to a halt. “Experience demonstrates that prisons can operate safely and securely without putting inmates with mental illness in typical conditions of segregation.” Despite this and medical professionals’ obligations, segregation policies have not changed because mental health clinics believe that “isolation is necessary for security reasons.” In fact, many believe that it is ethical for physicians to help those in confinement but that the physicians should also be trying to stop the abuse. If they cannot do so they are expected to undertake public advocacy.\n\nThe legality of solitary confinement has been frequently challenged over the past sixty years as conceptions surrounding the practice have changed. Much of the legal discussion concerning solitary confinement has centered on whether or not it constitutes torture or cruel and unusual punishment. While international law has generally begun to discourage solitary confinement's use in penal institutions, opponents of solitary confinement have been less successful at challenging it within the United States legal system.\n\nThroughout the twentieth century, the United Nations' stance on solitary confinement has become increasingly oppositional. International law has reflected this change, and UN monitoring has led to a major reduction of solitary confinement.\n\nIn 1949, the Universal Declaration of Human Rights (UDHR) was adopted by the United Nations General Assembly. Although the Declaration is non-binding, the basic human rights outlined within it have served as the foundation of customary international law. The relevance of the Declaration to solitary confinement is found in Article 5, which states that “No one shall be subjected to torture or to cruel, inhuman or degrading treatment or punishment.\" Thus, if solitary confinement is believed to constitute torture or cruel, inhuman, or degrading treatment or punishment, then the country practicing solitary confinement is violating the provisions set by the UDHR.\n\nThe International Covenant on Civil and Political Rights (ICCPR), effective 1976, reiterates the fifth article of the UDHR; Article 7 of the ICCPR identically states, “No one shall be subjected to torture or to cruel, inhuman or degrading treatment or punishment.\" Because the ICCPR is a legally binding agreement, any nation that is signatory to the covenant would be violating international law if it practiced torture or cruel, inhuman, or degrading treatment or punishment.\n\nAt the time that the UDHR and ICCPR were adopted, solitary confinement was not yet believed to constitute torture or cruel, inhuman, or degrading treatment or punishment. Its practice, therefore, was not believed to violate international law. This changed, however, after the UN definition of torture was outlined in detail in the 1984 Convention Against Torture (CAT); Article 1.1 of the CAT states that torture is \"any act by which severe pain or suffering, whether physical or mental, is intentionally inflicted on a person\" for any reason such as obtaining information or punishment, and Article 16 of the same convention prohibits \"other acts of cruel, inhuman or degrading treatment or punishment\". Based on these provisions, many members of the UN began to believe that solitary confinement's detrimental psychological effects could, indeed, constitute cruel, inhuman, or degrading treatment or punishment, if not, torture. In the years following the CAT, UN representatives \"have publicly decried the use of solitary confinement as a violation of the CAT and ICCPR,\" as well as the UDHR.\n\nIn more recent years, UN representatives have strengthened their efforts to stop solitary confinement from being used worldwide. The urgency with which representatives have undertaken these efforts is largely due to the UN Special Rapporteurs on Torture, Manfred Nowak and Juan Méndez. Nowak and Méndez have both \"repeatedly unequivocally stated that prolonged solitary confinement is cruel, inhuman or degrading treatment, and may amount to torture\". Nowak and Méndez have been especially critical of long-term or prolonged solitary confinement, which they define as lasting fifteen days or more. Their authority and explicit characterization of solitary confinement as cruel, inhuman, or degrading treatment has led the UN to include long-term to indefinite solitary confinement in the group of practices that violate the provisions outlined in the UDHR, ICCPR, and CAT. Solitary confinement lasting for a short period of time, however, is allowed under international law when used as a last resort, though Nowak, Mendez, and many other UN representatives believe that the practice should be abolished altogether.\n\nIn the U.S., opponents of solitary confinement have argued (with varying success) that the practice violates prisoners’ Constitutional rights. Despite the long history of litigation over the practice, the Supreme Court has yet to definitively state whether or not solitary confinement is unconstitutional. The Supreme Court considered the constitutionality of long-term solitary confinement only once in the ‘‘Wilkinson v. Austin'’ case. In contrast to the Supreme Court's inaction, lower courts of the U.S. have imposed constitutional limitations on the use of solitary confinement. Despite such limitations, the federal courts have refused to find that solitary confinement is per se unconstitutional. The U.S. has also effectively “insulated itself from any official sanction for international violations by not submitting to the jurisdiction” of committees that enforce the ICCPR or CAT.\n\nSince solitary confinement has been designated as “cruel, inhuman or degrading treatment or punishment” under international law, many lawyers have argued that it is also the kind of “cruel and unusual punishments” prohibited by the Eighth Amendment. Proving this to be the case, however, has been a difficult task for attorneys at every level of the court system.\n\nIn light of the serious, long-lasting psychological effects solitary confinement can have, inmates have argued that the mental injuries they suffer qualify as “cruel and unusual punishment.” Prison officials contend that placing inmates in prolonged solitary confinement is necessary for various reasons. Some of these reasons include separating violent prisoners from the general population, separating vulnerable inmates (such as juveniles) from others, and punishing those prisoners who attempt to cause riots or try to escape. Prisoners argue, however, that the nature of these kinds of offenses does not justify the use of solitary confinement; in their eyes “there is simply no strong security need for the total social isolation that exists at some supermax prisons”.\n\nA large portion of the court cases addressing solitary confinement have approached the practice as a violation of Eighth Amendment rights. Courts have generally agreed that solitary confinement is, indeed, a violation of the Eighth Amendment for inmates with preexisting mental illness or juveniles. However, the Supreme Court concluded that “while there was a risk of serious psychological injury to inmates, that risk was not of ‘sufficiently serious magnitude’ to find a ‘per se’ violation of the Eighth Amendment for ‘‘all’’ prisoners placed in long-term solitary confinement”.\n\nShowing that solitary confinement constitutes cruel and unusual punishment has proven difficult for inmates and their attorneys. The Supreme Court requires ‘extreme deprivations’ in order to have merits for a ‘conditions-of-confinement claim’ and courts have also held that inmates are only protected against “certain kinds of extreme deprivations” by the Eighth Amendment. In ‘‘Farmer v. Brennan’’, the Supreme Court set two requirements that must be fulfilled in order to challenge solitary confinement as “cruel and unusual”. First, prisoners must show that a “substantial risk of serious harm to inmates” and second, that the prison officials were “deliberately indifferent” to such risk. To prove a prison official's “deliberate indifference,” the prisoner must “show evidence that the official was ‘actually’ aware of a prisoner's serious need and chose to ignore it”. Since the psychological impact of solitary confinement is not believed to be “objectively” cruel and unusual within the U.S. legal system, and because it is difficult to establish that prison officials are “indifferent” to prisoner health and safety, inmates and attorneys alleging these two requirements have faced limited success.\n\nThe Prison Litigation Reform Act (PLRA) further complicates inmates’ ability to claim that solitary confinement's psychological damage constitutes cruel and unusual punishment. Section 1997e(e) of the PLRA states that This demonstrates that the Eighth Amendment provides “greater protection” against physical injury than against mental pain. Therefore, unless a prisoner can demonstrate physical injury as a result of solitary confinement, he or she is unable to recover damages for any “mental or emotional injury” the confinement causes. As a result, the Eighth Amendment has not always been proven to be the most effective approach to argue against the practice of solitary confinement.\n\nLitigating against solitary confinement on the basis of the Fourteenth Amendment and due process is another less common strategy inmates have used. The Fourteenth Amendment limits the “types of prisoners” that can be placed in solitary confinement and the time the prisoners can be confined. The due process clause within the Fourteenth Amendment also regulates solitary confinement in that prisoners must be given reviews before and during their placement in solitary confinement. Court cases made on these bases do not necessarily address any “underlying problems” of solitary confinement, but they do call for increased monitoring, hearing, and reviews.\n\nInmates who are placed in solitary confinement “must be accorded meaningful periodic review to ensure that segregation [solitary confinement] is not a ‘pretext for indefinite confinement’”. As Jules Lobel, professor at the University of Pittsburgh School of Law, explains, Lobel contends that the trend in U.S. supermax prisons is to not submit these reviews at all or to provide a review with a predetermined outcome to keep the prisoner in solitary confinement. If this is indeed the case, then such inmates’ due process rights are violated.\n\nIn \"Wilkinson v. Austin\", the Supreme Court held that, in addition to the due process right to meaningful review, prisoners also have a due process right to “a statement of the reasons why they were placed or retained at the supermax” so they can better understand how to behave in the future in order to be released from solitary confinement. Lobel argues that this “implies that the officials must provide something more than a general statement that the prisoner is very dangerous”. According to Lobel this is not what usually happens at supermax facilities, so the inmates’ due process rights are violated in this way as well.\n\nIn recent circuit court cases, courts have ruled that solitary confinement of 305 days or more constitutes an “atypical and significant hardship” that implicates due process.\n\nRecognizing that the amount of proof needed to show that solitary confinement violates prisoners’ rights “is simply too high to trigger constitutional protections,” attorneys have started to approach solitary confinement from a different angle. John F. Cockrell, a recent graduate from the University of Alabama School of Law, suggests that those who challenge solitary confinement do so in context of the Americans with Disabilities Act of 1990 (ADA). Cockrell reasons that \n\nIn the past few years, several internal committees and administrative bodies involved in the United States prison and legal systems have also begun to question solitary confinement's legality. In June 2012, for example, the US Senate Judiciary Committee held its first hearing on solitary confinement. Likewise, as of 2013, the US Bureau of Prisons has announced that it will conduct its first review of how solitary confinement is used in federal prisons. Additionally, the US Department of Justice found multiple violations of the Constitution and ADA after investigating the use of solitary confinement for mentally ill inmates in two Pennsylvania prisons. The US Immigration and Customs Enforcement Agency (ICE) has also revised segregation procedures for detainees.\n\nStudies have illustrated that mentally ill inmates and juveniles are two groups more severely affected by solitary confinement than other prisoners. As such, the solitary confinement of mentally ill inmates and juveniles has been upheld as cruel and unusual in both international and US courts.\n\nThe UN has “expressly prohibit[ed] solitary confinement of juveniles and individuals with mental illness”. The Convention on the Rights of Persons with Disabilities and Convention on the Rights of the Child have played major roles in establishing the UN's position on solitary confinement of mentally ill inmates and juveniles respectively.\n\nWithin the US legal system, too, courts have held that the solitary confinement of the mentally ill is “cruel and unusual”. In fact, David Fathi, Director of the ACLU's National Prison Project, found that “every federal court that has considered claims by severely mentally ill prisoners held in solitary confinement has found this treatment unconstitutional”. These court rulings are significant in light of the fact that more than half of the prisoners currently serving jail time in the US are mentally ill according to the US Bureau of Prisons. Furthermore, approximately 30% or more of prisoners in solitary confinement are mentally ill. These rulings have the potential to dramatically change how prisons deal with mentally ill inmates, as prison officials would no longer be able to “warehouse” “difficult” prisoners if they have a preexisting mental illness. It should be noted, however, that these rulings do not guarantee that the mentally ill will not be put in solitary confinement; while they are considered a vulnerable group, these prisoners still have “limited” recourse to the Eighth Amendment.\n\nOne landmark case, \"Madrid v. Gomez\", challenged the conditions of the Security Housing Unit (SHU) in the Pelican Bay State Prison. The court ruled that the current conditions were not “per se violative of the Eighth Amendment” with respect to all inmates. However, in regard to SHU's isolation of the mentally ill and the conditions of their solitary confinement, the court found that the prison had violated the Eighth Amendment. Despite it being a landmark case, the rulings of the case have yet to set a trend among cases against other prison systems because SHU's conditions were known to be more extreme and harsh than other supermax prisons.\n\nJuveniles who are charged as adults and placed in adult prisons are usually put in protective custody, and often the conditions of protective custody are similar to those of solitary confinement. Juvenile justice experts, social scientists, and national correctional standards all agree that solitary confinement is an “ineffective therapeutic tool” that is detrimental to juveniles who are still in an “uncertain, unformed state of social identity”. Given that they are developing mentally and physically, some experts have suggested that “they are severely and permanently damaged by such conditions to a greater extent than adults”.\n\nThe use of long-term solitary confinement, along with other grievances, has triggered organized resistance from prisoners and advocacy groups in the United States. Prisoners in California and elsewhere have launched hunger strikes, citing cruel and unusual uses of solitary confinement as a major reason. Hundreds of prisoners in the United States, acting through the Center for Human Rights and Constitutional Law, have in 2012 filed a petition against solitary confinement at the United Nations. The petition alleges that solitary confinement constitutes torture and should be addressed by the international community.\n\nThe 2013 California prisoner hunger strike saw approximately 29,000 prisoners protesting conditions. This statewide hunger strike reaching 2/3 of California's prisons began with the organizing of inmates at Pelican Bay State Prison. On 11 July 2011, prisoners at Pelican Bay State Prison began a hunger strike to “protest torturous conditions in the Security Housing Unit (SHU) there”...and to advocate for procedural and policy changes like the termination of the “debriefing process” which forces prisoners “to name themselves or others as gang members as a condition of access to food or release from isolation”. Nearly 7,000 inmates throughout the California prison system stood in solidarity with these Pelican State Bay prisoners in 2011 by also refusing their food. Also in solidarity with the 2011 Pelican Bay prisoners on strike is the Bay Area coalition of grassroots organizations known as the Prisoner Hunger Strike Solidarity coalition. This coalition has aided the prisoners in their strike by providing a legal support force for their negotiations with the California Department of Corrections and Rehabilitation (CDCR) and by creating and running a media based platform to raise support and awareness for the strikers and their demands among the general public.\n\nThe CDCR's failure to meet the demands of the Pelican State Bay Prison hunger strikers in 2011 resulted in the aforementioned 2013 California prisoner hunger strike. Similar to the Pelican Bay State Prison hunger strike is the organizing of January 2011 in the supermax Ohio State Penitentiary, where prisoners Bomani Shakur, Siddique Abdullah Hasan, Jason Robb, and Namir Abdul Mateen began a hunger strike “to protest what they call their harsh mistreatment under solitary confinement”. These prisoners decided to start rejecting their meals until they could be relocated from solitary confinement to death row where their treatment as prisoners would improve. Another example took place in Fall of 2010, when prisoners throughout Georgia's prison system organized a strike in opposition to violations of the US Constitution 8th amendment protection against cruel and unusual punishment for minute infractions of rules. Inmates throughout the state, in facilities like Rogers State Prison and Hays State Prison engaged in a “self-imposed lockdown” to incite action from the Georgia Department of Corrections in meeting their demands. Similar to other prison strikes demanding systemic change in the policing and policies of prisons like the Pelican State Bay hunger strike, this self-imposed lockdown strike has reached “across multiple facilities and across racial and factional lines”.\n\nSolitary confinement has served as a site of inspiration for protest-organizing against its use in and outside of prisons and conversely, as a response tactic for prisons to react to the protest-organizing of its prisoners. In March 2014, authorities at the Northwest Detention Center in Washington relegated multiple detainees to solitary confinement units after their participation in protests for the improvement of conditions within the facility and in solidarity with activist organizing against deportation escalations outside of the facility.\n\nOrganizing against the use of solitary confinement isn't limited to the work of prisoners subject to or at risk for this treatment. Community organizing outside of prisons has also occurred to shed light on the use of solitary confinement in prisons and work towards its abolition or highly refined use. Free and accessible journals like “Turning the Tide: Journal of Anti-Racist Action, Research, & Education” and web-based projects like Solitary Watch and the Prisoner Hunger Strike Solidarity Coalition website also work to disseminate information about the use of solitary confinement in prisons and support actions to bring about the end of this practice in prisons.\n\nDr. Eisenman, an Art History professor and activist, who is involved in many “stop max” movements centered in Illinois, studies solitary confinement and explains its eventual decline. Since the 1800s solitary confinement was practiced in the penitentiary systems and its implementation and popularity at various prisons grew throughout the centuries. The practice of solitary confinement grew partly because of stigmatizing language used to refer to certain prisoners like ‘the worst of the worst,’ which became a form of “self-justifying the logic of torture”. Yet, as the use of solitary confinement progressed, public discourse around solitary confinement transitioned from a legitimate form of punishment to torture. Because many prisoners in solitary confinement suffered severe mental and physical illnesses, Eisenman describes that by the end of the nineteenth century “prisoner isolation and sensory deprivation were widely understood to be forms of torture”. Therefore, human rights groups condemned the use of solitary confinement or ‘supermax’ systems, and national and local ‘stop max’ movements have initiated in America and worldwide to stop the use of solitary confinement.\n\nScrutiny of super-maximum security prisons and the institutionalization of solitary confinement is accompanied by suggestions for alternative methods. One alternative is to administer medical treatment for disorderly inmates who display signs of mental illness. The Correction Department of New York City implemented plans to transfer mentally ill inmates to an internal facility for further help rather than solitary confinement in 2013. Dora B. Schriro, correction commissioner, said that treatment would help turn a “one size fits all” policy into a program to promote success in jail and the outside world. A second alternative is to deal with long-term inmates by promoting familial and social relationships through the encouragement of visitations which may help boost morale. Carl Kummerlowe believes that familial counseling and support may be useful for inmates nearing the end of a long-term sentence that may otherwise exhibit signs of aggression. This alternative would help inmates cope with extreme long term sentences in prisons such as those harbored in Pelican Bay. A third alternative would involve regular reevaluation and accelerated transition of isolated inmates back to prison population to help curb long-term effects of solitary confinement. These alternative methods suggest a more restorative justice approach to handling high-security offenders.\n\nMany states such as Colorado, Mississippi, and Maine have implemented plans to reduce use of supermax prisons and solitary confinement and have begun to show signs of reform. Joseph Ponte, Corrections Commissioner of Maine, cut supermax prison population by half. Colorado has announced reforms to limit the use of solitary confinement in prisons following a study that showed significant levels of confinement and isolation in prisons. Washington has also showed signs of decreased use of solitary confinement, low segregation of overall prison population, and emphasis on alternative methods.\n\nThere have been studies that have shown no difference between inmates in solitary confinement and those in normal lockup. For example, \"Effect of Solitary Confinement on Prisoners\" examines a study that compared twenty prison inmates that were put into isolation to twenty inmates from general population that were used as the controls. The subjects were tested immediately before and after being put into isolation and the results showed that although there was a slight difference in subjective feelings, there were no mental or psychomotor changes. \"Effect of Solitary Confinement on Prisoners\" argues that the negative effects of solitary have often been overemphasized and that the reason these negative findings are often reported is due to the characteristic difference between those who end up in solitary confinement and those who do not.\n\n\"Reactions and Attributes of Prisoners in Solitary Confinement,\" analyzes multiple studies conducted at different prisons throughout the United States. There was no difference found in the stress levels between the inmates inside of solitary confinement and those in general lockup according to this study. Interviews were conducted that showed that inmates had a fear of the mental effects that solitary confinement would have, but that mental harm rarely occurred. There was also no significant difference between the results of the CPI Scale between the control and the experimental group according to \"Reactions and Attributes of Prisoners in Solitary Confinement.\" This article proposes the idea that some inmates have inherent characteristics that allow them to better adapt to solitary confinement while others do not, similar to the ability to adapt to any new environment. Furthermore, it showed that the majority of inmates adapted to solitary confinement within a few days finding ways to pass time such as sleeping, thinking about the future, and exercising. This article argues that this study gives a better representation of the effects of solitary confinement as it claims the participants are average inmates in traditional solitary confinement conditions, rather than controlled experimental conditions. The conclusions drawn from this study include the argument of consistency; that in order to prove that solitary confinement is harmful to inmates, there needs to be some sort of consistent negative result and their findings do not match this.\n\nIt should be emphasized that these studies were conducted in 1963 and 1982, respectively.\n\nProponents of solitary confinement propound that solitary confinement can improve the safety of inmates and prison staff. Earlier justifications for solitary confinement in the mid 20th century included protection for a prisoner whose sexual orientation, religion, or race were far too different and seen as vulnerable to attack from fellow inmates.\n\nWhile studies have shown the effects of solitary confinement to be detrimental to all inmates, solitary confinement of women has particular consequences for women that may differ from the way it affects men. Solitary confinement rates for women in the United States are roughly comparable to those for men and about 20% of prisoners will be in solitary confinement at some point during their prison career.\n\nAccording to the Bureau of Justice Statistics’ report from 2011-2012, about 20% of female prison inmates and 17% of female jail inmates spent some time in solitary confinement during that year, numbers which are comparable to rates for men.\n\nSolitary confinement is allegedly used to prevent violence within the prison population, and is becoming more common with the prison industrial complex and the rise in incarceration rates. In most prisons, inmates that are put into solitary confinement fall into one of three categories: disciplinary segregation, voluntary administrative segregation, and involuntary administrative segregation. Disciplinary segregation is used as a punishment, while administrative segregation is a preventative measure intended to protect either the inmate being isolated or the other inmates. While segregation as a disciplinary measure or a precaution that protects other inmates is allegedly reserved for offenders who have committed violent acts while in prison, women in particular are often put into solitary for much smaller offenses, such as throwing things or talking back to guards. It is also often used against women who complain of sexual assault from prison guards or other inmates. Once they are in solitary confinement, women are often monitored more closely and disciplined more harshly than men are.\n\nAn offender who has committed a “serious disciplinary offense” may be put in solitary confinement as a punitive measure. Inmates put into disciplinary segregation are not required to be given the same privileges as those put into administrative segregation, but the duration of their stay in isolation tends to be shorter. According to a magazine written by inmates in a California prison, the practice operates under a “guilty until proven innocent” protocol, holding prisoners in solitary confinement even before it is clear that they committed the infraction.\n\nInmates who are considered to be politically threatening are sometimes put into isolation; although the United States does not officially hold political prisoners, some inmates in solitary confinement are there because of their political activism. This justification often means that minorities are more likely to end up in solitary confinement.\n\nAdministrative segregation, or “ad seg,\" is typically more common than disciplinary segregation, and serves to protect either the inmate being placed in solitary or others in the prison. An offender may be put into administrative segregation if they are thought to be dangerous to others or if their own safety is in danger, or if “the inmate has the potential to interfere with an ongoing investigation.\" Often women who vocalize the fact that they feel threatened by someone else will be put into solitary confinement, and similarly, if they are accused of acting threatening in any way, they are put into solitary without being able to defend themselves. Women who are put into administrative segregation tend to be those women who have had trouble adjusting to prison life and who are seen as “high-risk” and “high-needs” when they enter the prison. Because this type of segregation is not intended as punishment, inmates in administrative segregation are legally required to be treated in the same way as those in general confinement in the prison.\n\nWomen prisoners sometimes request to be put into solitary confinement, most often for their own protection. Specifically, some women are thought to request solitary confinement to avoid “further assaults on their identity” that might arise from their interactions and experiences in prison. Studies have found that women who have been in voluntary administrative segregation tend to have high personal or emotional needs, and some have struggled with substance abuse, although few have difficulty with “community functioning.”\n\nWomen prisoners who are deemed to be dangerous to other prisoners are sometimes put into administrative segregation; a prisoner can also be put in segregation if the officers determine that she herself is in danger and needs this protection. Like women who are voluntarily put into segregation, these women tend to have high personal and emotional needs, but many of them also have difficulties functioning in the community or associating with other people.\n\nIn general, women tend to be subjected to harsher disciplinary practices in prisons than men. In the case of solitary confinement, women are often put into segregation for committing small errors while in prison, for example spitting at a guard, while men must commit more violent infractions, such as attacking a guard, for segregation to become necessary. This could arise from the fact that women in prison are held to especially high standards of femininity, and prisons encourage them to conform to very traditional ideas of being a woman. This model of femininity requires women to be “pure, passive, heterosexual, and located in motherhood.\" When women do not comply with this standard while imprisoned, they are punished further. In fact, some prisons specifically isolate women who seem “butch” or not traditionally feminine.\n\nAnother catalyst for being put into solitary confinement that applies overwhelmingly to women is that prisoners who complain of abusive treatment by guards are often segregated as retaliation. In particular, women who speak out after guards have sexually harassed them are often put into segregation. Not only does this mean that guards who are guilty of sexually harassing inmates go unpunished, it also decreases the likelihood that women will report harassment.\n\nIn some prisons, women may be put into solitary confinement because their mental health issues prove to be too difficult for the authorities to deal with or are exhausting their resources. If the prison authorities are unable to address their inmates’ health concerns, they may put them into solitary confinement to avoid solving the problem. This means that the women in solitary confinement are often already at risk for mental health or other challenges, due to previous health concerns or sexual abuse.\n\nSolitary confinement has been shown to be detrimental to the mental and physical well-being of all inmates, but there are some ways in which being put into segregation can be more harmful for women than for men. This is often due to patriarchal structures that exist outside of the prison environment as well. They “experience segregation \"as women\"”; they are both subjected to slightly different treatment than men are and their perception of this treatment may differ as well.\n\nBeing put into solitary confinement can be very damaging to the mental health of female inmates, particularly those with a history of mental or physical illness, as has been found in a number of studies that observed and interviewed women who were being held in solitary confinement. Being held in a small space without access to objects, recreation, or human contact can lead to claustrophobia, anger, depression, hallucinations, insomnia, and obsessive ideation or fixation on dying. On a psychosomatic level, inmates in solitary confinement often experience a loss of appetite and/or weight, dizziness, or heart palpitations. Prison staff often do not respond adequately to complaints of any of these symptoms, and sometimes refuse to offer medical care or medication.\n\nSome of the anxiety that inmates, particularly female inmates, experience in solitary confinement comes from a loss or confusion of identity. Prisoners in solitary confinement are not allowed to decorate the small rooms that they are in or to bring most of their possessions that they were allowed in general confinement. This prevents the women from having any sort of entertainment, but also exacerbates feelings of a loss of individuality and of personal identity.\n\nStudies of the conditions of segregation, and interviews with the women who are subjected to them, have shown that women may also experience a collapse or confusion of identity while in prison because of their removal from their community and because of the unusual experience of space and time while in solitary confinement. Prisoners attach a lot of importance to the items that they have in their rooms; when they are placed into solitary confinement and no longer allowed to keep these identifying objects with them, they begin to lose their sense of self. Further, because prisoners kept in segregation often interact little with the outside world, and because the routines of eating and cleaning may be different from in general confinement, the women lose their ability to mark time. \"The Fire Inside\" magazine, written by offenders in California women's prisons, quotes one prisoner as saying that her recommendation for those held in solitary confinement is “to create a schedule” and figure out the time of day, because it “helps to assert control over your own life and not be totally defined by whatever ‘routine’ the prison is forcing on you.”\n\nAnother aspect of their identity that is destroyed is their ability to form relationships with others. In most societies, women are perceived as being particularly social; having relationships with other people is seen as an essential element of their role as women in particular. This is of course impossible when in solitary confinement. It has been argued that this has a harmful effect on women especially. These conclusions were drawn from interviews with women who were still in solitary confinement, women who had been in solitary but had since been transferred back to the general prison population, and women who had been in solitary but had been released from incarceration, suggesting that these effects carry over beyond their time in segregation.\n\nSome prisons do allow inmates in solitary confinement to use recreation rooms and exercise yards, but these are often monitored by cameras, creating a sense of powerlessness and humiliating and deterring the women from using these facilities. Feelings of powerlessness or hopeless are exacerbated by the fact that women are often unsure of how long they will be held in solitary confinement.\n\nAll of these factors combined can have different effects on women, making them either increasingly anxious or increasingly indifferent. While some women feel desperate and angry, others attempt to feel as little as possible in order to mitigate the effects of segregation. Because of the detrimental effect on their mental stability, inmates in solitary confinement often resort to self-harm; this behavior is more common in women than in men. This can sometimes lead to women being held in solitary confinement for longer, as punishment for their destructive actions. Similarly, it reinforces the guards’ perceptions of these women as particularly violent or dangerous to the rest of the prison community.\n\nWomen in solitary confinement are often watched over by male guards, which can result in sexual harassment ranging from discomfort caused by guards watching them during private moments to nonconsensual sexual contact. Male guards often are present while women shower or undress, stripping away the women's right to the privacy of their own bodies. Because women in solitary confinement experience so little human contact, the gaze of their guards is often the only interaction that they have with another person; this can exacerbate the feelings of loss of privacy.\n\nSimilarly, the clothing the women are required to wear is sexualized and humiliating. In some prisons, women in segregation wear a “baby doll,” a long shapeless dress, with no underclothes. Although men sometimes are required to wear the “baby doll” as well, women find that wearing it while being watched by their male guards is degrading and makes them feel powerless.\n\nBeyond this, women in segregation are sometimes subjected to sexual abuse or physical harassment by their male guards. They are often forced to undergo thorough strip searches, during which the guards are more forceful and invasive than is strictly necessary and serves mostly to demonstrate the guards’ authority over the inmates. Because so many female inmates have been victims of sexual or physical abuse, this forces them to relive the trauma of their previous abuse. This can be especially devastating for women whose mental states are already deteriorating, due to prior mental illness or to the effects of being in segregation. It can also result in pregnancy, and pregnant women in solitary confinement—whether the pregnancy was a result of a rape by a guard or not—are often denied proper medical care.\n\nWomen have also reported stories of being publicly humiliated when asking for additional sanitary pads during their menstrual periods, or being forced to hand in their used pads in order to acquire a new one, according to the women who contributed to \"The Fire Inside\" magazine. They are entirely dependent on male guards, even for such personal needs as this.\n\nWomen are more likely than men to be the primary guardian of a child or children; having a mother who is in solitary confinement, then, can be very detrimental to the children. Inmates in solitary confinement have much less frequent contact with family members, and when they do, they are usually separated by a partition. Although inmates are allowed some visits from immediate family members, a long background check is required. Children with mothers in prison are at a greater risk for depression or anxiety, substance abuse, or involvement in crime. These factors are only furthered by the more distanced relationship that becomes necessary with a mother in solitary confinement and the restrictions on visitation that accompany that.\n\nWomen who are released from solitary confinement into the general prison population are more likely than men to experience stigmatization and humiliation from the prison guards. This often leads to them isolating themselves and not interacting with other prisoners even when they are not in solitary confinement.\n\nOnce they are released from prison, too, they often have a harder time adjusting to being a part of society again, and frequently end up back in prison. Ex-offenders who were held in solitary confinement are more likely to commit violent acts against others once released than those who spent all their time in the general prison population. As one California prisoner who wrote for \"The Fire Inside\" prison magazine put it, “We go through these kind of mental, emotional, and spiritual stages. At first when you get here you’re angry and disoriented…Paranoia sets in…I slowly began to think of this cell as my safe place…What happens next year when they take the box away?” She, and other women in solitary confinement, become unequipped to deal with the outside world and the knowledge of technological advancement, social interaction skills, and mental stability that it requires.\n\nIn general, women of color, like men of color, are more likely to be put in prison than white women and men. Likewise, they are thought to be somewhat disproportionately represented in the solitary confinement population. The Bureau of Justice Statistics reports that in 2011-2012, 16% of white prison inmates, 20% of black/African American prison inmates, 16% of Hispanic or Latino prison inmates, and 20% of prison with some other racial identification were in solitary confinement at some point. The difference was slightly less pronounced in jails, with 17% of white, 17% of black/African American, 15% of Hispanic/Latino, and 21% of other inmates spending time in solitary confinement. There is no data available that specifically documents the intersection between race and gender.\n\nAlthough the number of people of color in isolation is only slightly higher than the number of white people, their experiences in solitary confinement may differ. Women in solitary confinement are treated as less than human, in ways which parallel not only the larger societal degradation of women but also that of people of color. The sexually abusive nature of their interactions with the guards, and the denial of medical care, social contact, and resources, can be seen as racialized. In particular, guards often refer to women in solitary confinement using slurs that are both misogynist and racist.\n\nWomen who are put into solitary confinement are often isolated because of actions that challenge dominant perspectives of femininity. Because women of color are often seen as possessing these non-feminine qualities already, they are more susceptible to being put into solitary confinement because of this kind of behavior. Black women are often perceived as “aggressive and recalcitrant,” Latina women are thought to be “loud and belligerent, sexually aggressive, or…unable to speak English,” and Native American women are seen as “backward, savage, and/or primitive.” Because of these preconceptions, women of color are thought to deviate strongly from the feminine ideal, which can be grounds for putting them in solitary confinement.\n\nRepresentations of crime in popular media serve to perpetuate racial stereotypes as well. Offenders of color, including women, are often portrayed as violent, hypersexual, or drug-addicted. While this is true of women of color in the general prison population as well as those held in solitary confinement, there is a particularly strong culture of fear that is built up around segregation units and the prisoners who are held there. Inmates who appear to belong to particular minority groups are often profiled by prison guards as more likely to be dangerous, violent, or involved in a gang, and therefore are moved into isolation; for example, prisoners who speak a language other than English are sometimes targeted as foreign and therefore gang-involved or dangerous.\n\n\n"}
{"id": "4042270", "url": "https://en.wikipedia.org/wiki?curid=4042270", "title": "Steering ratio", "text": "Steering ratio\n\nSteering ratio refers to the ratio between the turn of the steering wheel (in degrees) or handlebars and the turn of the wheels (in degrees).\n\nThe steering ratio is the ratio of the number of degrees of turn of the steering wheel to the number of degrees the wheel(s) turn as a result. In motorcycles, delta tricycles and bicycles, the steering ratio is always 1:1, because the steering wheel is fixed to the front wheel. A steering ratio of x:y means that a turn of the steering wheel x degree(s) causes the wheel(s) to turn y degree(s). In most passenger cars, the ratio is between 12:1 and 20:1. For example, if one complete turn of the steering wheel, 360 degrees, causes the wheels to turn 24 degrees, the ratio is then 360:24 = 15:1.\n\nA higher steering ratio means that the steering wheel is turned more to get the wheels turning, but it will be easier to turn the steering wheel. A lower steering ratio means that the steering wheel is turned less to get the wheels turning, but it will be harder to turn the steering wheel. Larger and heavier vehicles will often have a higher steering ratio, which will make the steering wheel easier to turn. If a truck had a low steering ratio, it would be very hard to turn the steering wheel. In normal and lighter cars, the wheels are easier to turn, so the steering ratio doesn't have to be as high. In race cars the ratio is typically very low, because the vehicle must respond to steering input much faster than in normal cars. The steering wheel is therefore harder to turn.\n\nVariable-ratio steering is a system that uses different ratios on the rack in a rack and pinion steering system. At the center of the rack, the space between the teeth are smaller and the space becomes larger as the pinion moves down the rack. In the middle of the rack there is a higher ratio and the ratio becomes lower as the steering wheel is turned towards lock. This makes the steering less sensitive when the steering wheel is close to its center position and makes it harder for the driver to oversteer at high speeds. As the steering wheel is turned towards lock, the wheels begin to react more to steering input\n\nA steering quickener is used to modify the steering ratio of factory-installed steering system, which in turn modifies the response time and overall handling of vehicle. When a steering quickener is employed in an automobile, the driver of the automobile can turn the steering wheel a smaller degree compared to a factory-installed steering system without a steering quickener, to turn the vehicle through same distance. On the other hand, the steering effort needed will greatly increase. If the automobile is equipped with power steering, overloading the power steering pump can also be a concern.\n\nAnother use of the term steering ratio is for the ratio between the theoretical turning radius based on ideal tire behavior and the actual turning radius based on real tire behavior. Values less than one, where the front wheel side slip is greater than the rear wheel side slip, are described as under-steering; equal to one as neutral steering; and greater than one as over-steering. Values less than zero, in which the front wheel must be turned opposite the direction of the curve due to much greater rear wheel side slip than front wheel have been described as counter-steering.\n"}
{"id": "24574448", "url": "https://en.wikipedia.org/wiki?curid=24574448", "title": "TAMPEP", "text": "TAMPEP\n\nTAMPEP (European Network for HIV/STI Prevention and Health Promotion among Migrant Sex Workers) is an international organization that supports the health and human rights of migrant sex workers in Europe. Founded in 1993, with headquarters in Amsterdam, the organization initially operated in Italy, Austria, Germany, and the Netherlands. Today, it coordinates a network of 26 organizations in 25 countries of the European Union, and receives funding from the European Commission as well as from national governmental and non-governmental organizations.\n\nThe main concern of the project is HIV/AIDS prevention; it approaches the problem from a general health and human rights approach, working for empowerment and self-determination of female and transsexual migrant sex workers, and for improvements in their working conditions and social situation. The member organizations employ street work, peer educators and informational materials to contact migrant sex workers. The organization produces regular reports about the situation of prostitutes in Europe.\n\nTAMPEP's literature emphasizes the need to cleanly distinguish between the issues of trafficking, sex work and migration. TAMPEP opposes trafficking as a human rights abuse, but supports efforts to improve working conditions of sex workers and to facilitate migration.\n\nTAMPEP has also operated in Nigeria, where it helps to rehabilitate sex workers deported from Italy.\n"}
{"id": "31212", "url": "https://en.wikipedia.org/wiki?curid=31212", "title": "Tabula rasa", "text": "Tabula rasa\n\nTabula rasa () refers to the epistemological idea that individuals are born without built-in mental content and that therefore all knowledge comes from experience or perception. Proponents of tabula rasa generally disagree with the doctrine of innatism which holds that the mind is born already in possession of certain knowledge. Generally, proponents of the \"tabula rasa\" theory also favour the \"nurture\" side of the nature versus nurture debate when it comes to aspects of one's personality, social and emotional behaviour, knowledge and sapience.\n\n\"Tabula rasa\" is a Latin phrase often translated as \"blank slate\" in English and originates from the Roman \"tabula\" used for notes, which was blanked by heating the wax and then smoothing it. This roughly equates to the English term \"blank slate\" (or, more literally, \"erased slate\") which refers to the emptiness of a slate prior to it being written on with chalk. Both may be renewed repeatedly, by melting the wax of the tablet or by erasing the chalk on the slate.\n\nIn Western philosophy, the concept of \"tabula rasa\" can be traced back to the writings of Aristotle who writes in his treatise \"Περί Ψυχῆς\" (\"De Anima\" or \"On the Soul\") of the \"unscribed tablet.\" In one of the more well-known passages of this treatise he writes that:\nHaven't we already disposed of the difficulty about interaction involving a common element, when we said that mind is in a sense potentially whatever is thinkable, though actually it is nothing until it has thought? What it thinks must be in it just as characters may be said to be on a writing-tablet on which as yet nothing stands written: this is exactly what happens with mind. \nThis idea was further developed in Ancient Greek philosophy by the Stoic school. Stoic epistemology emphasizes that the mind starts blank, but acquires knowledge as the outside world is impressed upon it. The doxographer Aetius summarizes this view as \"When a man is born, the Stoics say, he has the commanding part of his soul like a sheet of paper ready for writing upon.\" Diogenes Laërtius attributes a similar belief to the Stoic Zeno of Citium when he writes in Lives and Opinions of Eminent Philosophers that: \nPerception, again, is an impression produced on the mind, its name being appropriately borrowed from impressions on wax made by a seal; and perception they divide into, comprehensible and incomprehensible: Comprehensible, which they call the criterion of facts, and which is produced by a real object, and is, therefore, at the same time conformable to that object; Incomprehensible, which has no relation to any real object, or else, if it has any such relation, does not correspond to it, being but a vague and indistinct representation.\n\nIn the eleventh century, the theory of \"tabula rasa\" was developed more clearly by the Persian philosopher Avicenna (Ibn Sina in Arabic). He argued that the \"...human intellect at birth resembled a \"tabula rasa\", a pure potentiality that is actualized through education and comes to know,\" and that knowledge is attained through \"...empirical familiarity with objects in this world from which one abstracts universal concepts,\" which develops through a \"...syllogistic method of reasoning; observations lead to propositional statements, which when compounded lead to further abstract concepts.\" He further argued that the intellect itself \"...possesses levels of development from the static/material intellect (\"al-‘aql al-hayulani\"), that potentiality can acquire knowledge to the active intellect (\"al-‘aql al-fa‘il\"), the state of the human intellect at conjunction with the perfect source of knowledge.\"\n\nIn the twelfth century, the Andalusian-Islamic philosopher and novelist, Ibn Tufail, known as \"Abubacer\" or \"Ebn Tophail\" in the West, demonstrated the theory of \"tabula rasa\" as a thought experiment through his Arabic philosophical novel, \"Hayy ibn Yaqzan\", in which he depicted the development of the mind of a feral child \"from a tabula rasa to that of an adult, in complete isolation from society\" on a desert island, through experience alone. The Latin translation of his philosophical novel, entitled \"Philosophus Autodidactus\", published by Edward Pococke the Younger in 1671, had an influence on John Locke's formulation of \"tabula rasa\" in \"An Essay Concerning Human Understanding\".\nIn the thirteenth century, St. Thomas Aquinas brought the Aristotelian and Avicennian notions to the forefront of Christian thought. These notions sharply contrasted with the previously held Platonic notions of the human mind as an entity that preexisted somewhere in the heavens, before being sent down to join a body here on Earth (see Plato's \"Phaedo\" and \"Apology\", as well as others). St. Bonaventure (also thirteenth century) was one of the fiercest intellectual opponents of Aquinas, offering some of the strongest arguments toward the Platonic idea of the mind.\n\nThe writings of Avicenna, Ibn Tufail, and Aquinas on the \"tabula rasa\" theory stood unprogressed and untested for several centuries. For example, the late medieval English jurist Sir John Fortescue, in his work \"In Praise of the Laws of England\" (Chapter VI), takes for granted the notion of \"tabula rasa\", stressing it as the basis of the need for the education of the young in general, and of young princes specifically. \"Therefore, Prince, whilst you are young and your mind is as it were a clean slate, impress on it these things, lest in future it be impressed more pleasurably with images of lesser worth.\" (\"His igitur, Princeps, dum Adolescens es, et Anima tua velut\" Tabula rasa, \"depinge eam, ne in futurum ipsa Figuris minoris Frugi delectabilius depingatur\".)\n\nThe modern idea of the theory, however, is attributed mostly to John Locke's expression of the idea in \"Essay Concerning Human Understanding\" (he uses the term \"white paper\" in Book II, Chap. I, 2). In Locke's philosophy, \"tabula rasa\" was the theory that at birth the (human) mind is a \"blank slate\" without rules for processing data, and that data is added and rules for processing are formed solely by one's sensory experiences. The notion is central to Lockean empiricism; it serves as the starting point for Locke's subsequent explication (in Book II) of simple ideas and complex ideas. As understood by Locke, \"tabula rasa\" meant that the mind of the individual was born blank, and it also emphasized the freedom of individuals to author their own soul. Individuals are free to define the content of their character—but basic identity as a member of the human species cannot be altered. This presumption of a free, self-authored mind combined with an immutable human nature leads to the Lockean doctrine of \"natural\" rights. Locke's idea of \"tabula rasa\" is frequently compared with Thomas Hobbes's viewpoint of human nature, in which humans are endowed with inherent mental content—particularly with selfishness.\n\nThe eighteenth-century Swiss philosopher Jean-Jacques Rousseau used \"tabula rasa\" to support his argument that warfare is an advent of society and agriculture, rather than something that occurs from the human state of nature. Since \"tabula rasa\" states that humans are born with a \"blank-slate\", Rousseau uses this to suggest that humans must learn warfare.\n\n\"Tabula rasa\" also features in Sigmund Freud's psychoanalysis. Freud depicted personality traits as being formed by family dynamics (see Oedipus complex). Freud's theories imply that humans lack free will, but also that genetic influences on human personality are minimal. In Freudian psychoanalysis, one is largely determined by one's upbringing.\n\nThe \"tabula rasa\" concept became popular in social sciences during the twentieth century. Early ideas of eugenics posited that human intelligence correlated strongly with social class, but these ideas were rejected, and the idea that genes (or simply \"blood\") determined a person's character became regarded as racist. By the 1970s, scientists such as John Money had come to see gender identity as socially constructed, rather than rooted in genetics.\n\nPsychologists and neurobiologists have shown evidence that initially, the entire cerebral cortex is programmed and organized to process sensory input, control motor actions, regulate emotion, and respond reflexively (under predetermined conditions). These programmed mechanisms in the brain subsequently act to learn and refine the ability of the organism.\nFor example, psychologist Steven Pinker showed that—in contrast to written language—the brain is \"programmed\" to pick up spoken language spontaneously.\n\nThere have been claims by a minority in psychology and neurobiology, however, that the brain is \"tabula rasa\" only for certain behaviours. For instance, with respect to one's ability to acquire both general and special types of knowledge or skills, Howe argued against the existence of innate talent. There also have been neurological investigations into specific learning and memory functions, such as Karl Lashley's study on mass action and serial interaction mechanisms.\n\nImportant evidence against the \"tabula rasa\" model of the mind comes from behavioural genetics, especially twin and adoption studies (see below). These indicate strong genetic influences on personal characteristics such as IQ, alcoholism, gender identity, and other traits. Critically, multivariate studies show that the distinct faculties of the mind, such as memory and reason, fractionate along genetic boundaries. Cultural universals such as emotion and the relative resilience of psychological adaptation to accidental biological changes (for instance the David Reimer case of gender reassignment following an accident) also support basic biological mechanisms in the mind.\n\nTwin studies have resulted in important evidence against the \"tabula rasa\" model of the mind, specifically, of social behaviour.\n\nThe social pre-wiring hypothesis refers to the ontogeny of social interaction. Also informally referred to as, \"wired to be social.\" The theory questions whether there is a propensity to socially oriented action already present \"before\" birth. Research in the theory concludes that newborns are born into the world with a unique genetic wiring to be social. \n\nCircumstantial evidence supporting the social pre-wiring hypothesis can be revealed when examining newborns' behaviour. Newborns, not even hours after birth, have been found to display a preparedness for social interaction. This preparedness is expressed in ways such as their imitation of facial gestures. This observed behaviour cannot be contributed to any current form of socialization or social construction. Rather, newborns most likely inherit to some extent social behaviour and identity through genetics.\n\nPrincipal evidence of this theory is uncovered by examining twin pregnancies. The main argument is, if there are social behaviours that are inherited and developed before birth, then one should expect twin fetuses to engage in some form of social interaction before they are born. Thus, ten fetuses were analyzed over a period of time using ultrasound techniques. Using kinematic analysis, the results of the experiment were that the twin fetuses would interact with each other for longer periods and more often as the pregnancies went on. Researchers were able to conclude that the performance of movements between the co-twins were not accidental but specifically aimed.\n\nThe social pre-wiring hypothesis was proved correct, \"The central advance of this study is the demonstration that 'social actions' are already performed in the second trimester of gestation. Starting from the 14th week of gestation twin fetuses plan and execute movements specifically aimed at the co-twin. These findings force us to predate the emergence of social behaviour: when the context enables it, as in the case of twin fetuses, other-directed actions are not only possible but predominant over self-directed actions.\".\n\nIn computer science, \"tabula rasa\" refers to the development of autonomous agents with a mechanism to reason and plan toward their goal, but no \"built-in\" knowledge-base of their environment. Thus they truly are a blank slate.\n\nIn reality autonomous agents possess an initial data-set or knowledge-base, but this cannot be immutable or it would hamper autonomy and heuristic ability. Even if the data-set is empty, it usually may be argued that there is a built-in bias in the reasoning and planning mechanisms. Either intentionally or unintentionally placed there by the human designer, it thus negates the true spirit of \"tabula rasa\".\n\nA synthetic (programming) language parser (LR(1), LALR(1) or SLR(1), for example) could be considered a special case of a \"tabula rasa\", as it is designed to accept \"any\" of a possibly infinite set of source language programs, within a \"single\" programming language, and to output either a good parse of the program, or a good machine language translation of the program, either of which represents a \"success\", or, alternately, a \"failure\", and nothing else. The \"initial data-set\" is a set of tables which are generally produced mechanically by a parser table generator, usually from a BNF representation of the source language, and represents a \"table representation\" of that \"single\" programming language.\n\n\n\n"}
{"id": "7420608", "url": "https://en.wikipedia.org/wiki?curid=7420608", "title": "The Centipede's Dilemma", "text": "The Centipede's Dilemma\n\n\"The Centipede's Dilemma\" is a short poem that has lent its name to a psychological effect called the centipede effect or centipede syndrome. The centipede effect occurs when a normally automatic or unconscious activity is disrupted by consciousness of it or reflection on it. For example, a golfer thinking too closely about her swing or someone thinking too much about how he knots his tie may find his performance of the task impaired. The effect is also known as hyper-reflection or Humphrey's law after the English psychologist George Humphrey (1889–1966), who propounded it in 1923. As he wrote of the poem, \"This is a most psychological rhyme. It contains a profound truth which is illustrated daily in the lives of all of us\". The effect is the reverse of a solvitur ambulando.\n\nThe poem, a short rhyme, is usually attributed to Katherine Craster (1841–1874) in \"Pinafore Poems\", 1871. By 1881 it had begun appearing in journals such as \"The Spectator\" and \"The Living Age\". The poem later appeared in an article by British zoologist E. Ray Lankester, published in the scientific journal \"Nature\" on May 23, 1889, which discussed the work of the photographer Eadweard Muybridge in capturing the motion of animals: \"For my own part,\" wrote Lankester, \"I should greatly like to apply Mr. Muybridge's cameras, or a similar set of batteries, to the investigation of a phenomenon more puzzling even than that of 'the galloping horse'. I allude to the problem of 'the running centipede. Lankester finished the article on a fanciful note by imagining the \"disastrous results in the way of perplexity\" that could result from such an investigation, quoting the poem and mentioning that the author was unknown to him or to the friend who sent it to him. It has since been variously attributed to specific authors but without convincing evidence, and often appears under the title \"The Centipede's Dilemma\".\n\nThe version in the article is as follows:\n\nAnother version of the Centipede's Dilemma:\n\nModern versions of the poem often recast it in verse as a fable of a spider (or other protagonist) who found a clever way to avoid being eaten.\n\nAnother rhyme goes:\n\nThe psychologist George Humphrey referred to the tale in his 1923 book \"The Story of Man's Mind\": \"No man skilled at a trade needs to put his constant attention on the routine work\", he wrote. \"If he does, the job is apt to be spoiled\". He went on to recount the centipede's story, commenting, \"This is a most psychological rhyme. It contains a profound truth which is illustrated daily in the lives of all of us, for exactly the same thing happens if we pay conscious attention to any well-formed habit, such as walking\". Thus, the eponymous \"Humphrey's law\" states that once performance of a task has become automatized, conscious thought about the task, while performing it, impairs performance. Whereas habit diminishes and then eliminates the attention required for routine tasks, this automaticity is disrupted by attention to a normally unconscious competence.\n\nThe philosopher Karl Popper referred to the centipede effect in his book \"Knowledge and the Body-Mind Problem: In Defence of Interaction\": \"if we have learnt certain movements so that they have sunk below the level of conscious control, then if we try to follow them consciously we very often interfere with them so badly that we stop them\". He gives the example of the violinist Adolf Busch who was asked by fellow-violinist Bronisław Huberman how he played a certain passage of Beethoven's violin concerto. Busch told Huberman that it was quite simple—and then found that he could no longer play the passage.\n\nThe psychiatric psychoanalyst Theo L. Dorpat compares questions and interventions irrelevant to the patient's current thought process during psychotherapy in his book \"Gaslighting\" to \"the story of the centipede who became disorganized and unable to walk after he was asked, 'What's wrong with your 34th left foot?'.\"\n\nIn 1903, \"Simplicissimus\" magazine printed an adaptation of the story by the Austrian author Gustav Meyrink, \"The Curse of The Toad\" (\"Der Fluch der Kröte\"). The fable was also published in Meyrink's 1903 collection of tales, \"The Hot Soldier and Other Stories\".\n\nSpider Robinson's short story \"The Centipede's Dilemma\" concerns a psychic who uses instinctive telekinetic powers to cheat at darts, and is foiled when another character triggers hyper-reflection in him.\n\n"}
{"id": "25668921", "url": "https://en.wikipedia.org/wiki?curid=25668921", "title": "Volcano plot (statistics)", "text": "Volcano plot (statistics)\n\nIn statistics, a volcano plot is a type of scatter-plot that is used to quickly identify changes in large data sets composed of replicate data. It plots significance versus fold-change on the y and x axes, respectively. These plots are increasingly common in omic experiments such as genomics, proteomics, and metabolomics where one often has a list of many thousands of replicate data points between two conditions and one wishes to quickly identify the most meaningful changes. A volcano plot combines a measure of statistical significance from a statistical test (e.g., a p value from an ANOVA model) with the magnitude of the change, enabling quick visual identification of those data-points (genes, etc.) that display large magnitude changes that are also statistically significant.\n\nA volcano plot is constructed by plotting the negative log of the p value on the y axis (usually base 10). This results in data points with low p values (highly significant) appearing toward the top of the plot. The x axis is the log of the fold change between the two conditions. The log of the fold change is used so that changes in both directions appear equidistant from the center. Plotting points in this way results in two regions of interest in the plot: those points that are found toward the top of the plot that are far to either the left- or right-hand sides. These represent values that display large magnitude fold changes (hence being left or right of center) as well as high statistical significance (hence being toward the top).\n\nAdditional information can be added by coloring the points according to a third dimension of data (such as signal intensity), but this is not uniformly employed. Volcano plots are also used to graphically display a significance analysis of microarrays (SAM) gene selection criterion, an example of regularization.\n\nThe concept of volcano plot can be generalized to other applications, where the x axis is related to a measure of\nthe strength of a statistical signal, and y axis is related to a measure of the statistical significance of the signal.\nFor example, in a genetic association case-control study, such as Genome-wide association study,\na point in a volcano plot represents a single-nucleotide polymorphism.\nIts x value can be the odds ratio and its y value can be -log10 of the p value from a Chi-square test\nor a Chi-square test statistic.\n\n"}
