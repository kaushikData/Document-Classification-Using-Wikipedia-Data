{"id": "50761824", "url": "https://en.wikipedia.org/wiki?curid=50761824", "title": "4D vector", "text": "4D vector\n\nIn computer science, a 4D vector is a 4-component vector data type. Uses include homogeneous coordinates for 3-dimensional space in computer graphics, and \"red green blue alpha\" (RGBA) values for bitmap images with a color and alpha channel (as such they are widely used in computer graphics). They may also represent quaternions (useful for rotations) although the algebra they define is different.\n\nSome microprocessors have hardware support for 4D vectors with instructions dealing with 4 lane \"single instruction, multiple data\" (SIMD) instructions, usually with a 128-bit data path and 32-bit floating point fields.\n\nSpecific instructions (e.g., 4 element dot product) may facilitate the use of one 128-bit register to represent a 4D vector. For example, in chronological order: Hitachi SH4, PowerPC VMX128 extension, and Intel x86 SSE4.\n\nSome 4-element vector engines (e.g., the PS2 vector units) went further with the ability to broadcast components as multiply sources, and cross product support. Earlier generations of graphics processing unit (GPU) shader pipelines used \"very long instruction word\" (VLIW) instruction sets tailored for similar operations.\n\nSIMD use for 4D vectors can be conveniently wrapped in a \"vector maths library\" (commonly implemented in C or C++) \ncommonly used in video game development, along with 4×4 matrix support. These are distinct from more general linear algebra libraries in other domains focussing on matrices of arbitrary size. Such libraries sometimes support 3D vectors padded to 4D or loading 3D data into 4D registers, with arithmetic mapped efficiently to SIMD operations by per platform intrinsic function implementations. There is choice between AOS and SOA approaches given the availability of 4 element registers, versus SIMD instructions that are usually tailored toward homogenous data.\n\nShading languages for graphics processing unit (GPU) programming usually have a 4D datatypes (along with 2D, 3D) with x-y-z-w accessors including \"permutes\" or \"swizzle\" access, e.g., allowing easy swapping of RGBA or ARGB formats, accessing two 2D vectors packed into one 4D vector, etc. Modern GPUs have since moved to scalar single instruction, multiple threads (SIMT) pipelines (for more efficiency in \"general-purpose computing on graphics processing units\" (GPGPU)) but still support this programming model.\n\n"}
{"id": "12374236", "url": "https://en.wikipedia.org/wiki?curid=12374236", "title": "Absoluteness", "text": "Absoluteness\n\nIn mathematical logic, a formula is said to be absolute if it has the same truth value in each of some class of structures (also called models). Theorems about absoluteness typically establish relationships between the absoluteness of formulas and their syntactic form. \n\nThere are two weaker forms of partial absoluteness. If the truth of a formula in each substructure \"N\" of a structure \"M\" follows from its truth in \"M\", the formula is downward absolute. If the truth of a formula in a structure \"N\" implies its truth in each structure \"M\" extending \"N\", the formula is upward absolute.\n\nIssues of absoluteness are particularly important in set theory and model theory, fields where multiple structures are considered simultaneously. In model theory, several basic results and definitions are motivated by absoluteness. In set theory, the issue of which properties of sets are absolute is well studied. The Shoenfield absoluteness theorem, due to Joseph Shoenfield (1961), establishes the absoluteness of a large class of formulas between a model of set theory and its constructible universe, with important methodological consequences. The absoluteness of large cardinal axioms is also studied, with positive and negative results known.\n\nIn model theory, there are several general results and definitions related to absoluteness. A fundamental example of downward absoluteness is that universal sentences (those with only universal quantifiers) that are true in a structure are also true in every substructure of the original structure. Conversely, existential sentences are upward absolute from a structure to any structure containing it. \n\nTwo structures are defined to be elementarily equivalent if they agree about the truth value of all sentences in their shared language, that is, if all sentences in their language are absolute between the two structures. A theory is defined to be model complete if whenever \"M\" and \"N\" are models of the theory and \"M\" is a substructure of \"N\", then \"M\" is an elementary substructure of \"N\".\n\nA major part of modern set theory involves the study of different models of ZF and ZFC. It is crucial for the study of such models to know which properties of a set are absolute to different models. It is common to begin with a fixed model of set theory and only consider other transitive models containing the same ordinals as the fixed model. \n\nCertain properties are absolute to all transitive models of set theory, including the following (see Jech (2003 sec. I.12) and Kunen (1980 sec. IV.3)). \n\nOther properties, such as countability, are not absolute. \n\nSkolem's paradox is the seeming contradiction that on the one hand, the set of real numbers is uncountable (and this is provable from ZFC, or even from a small finite subsystem ZFC' of ZFC), while on the other hand there are countable transitive models of ZFC' (this is provable in ZFC), and the set of real numbers in such a model will be a countable set. The paradox can be resolved by noting that countability is not absolute to submodels of a particular model of ZFC. It is possible that a set \"X\" is countable in a model of set theory but uncountable in a submodel containing \"X\", because the submodel may contain no bijection between \"X\" and ω, while the definition of countability is the existence of such a bijection. The Löwenheim–Skolem theorem, when applied to ZFC, shows that this situation does occur.\n\nShoenfield's absoluteness theorem shows that formula_1 and formula_2 sentences in the analytical hierarchy are absolute between a model \"V\" of ZF and the constructible universe \"L\" of the model, when interpreted as statements about the natural numbers in each model. The theorem can be relativized to allow the sentence to use sets of natural numbers from \"V\" as parameters, in which case \"L\" must be replaced by the smallest submodel containing those parameters and all the ordinals. The theorem has corollaries that formula_3 sentences are upward absolute (if such a sentence holds in \"L\" then it holds in \"V\") and formula_4 sentences are downward absolute (if they hold in \"V\" then they hold in \"L\"). Because any two transitive models of set theory with the same ordinals have the same constructible universe, Shoenfield's theorem shows that two such models must agree about the truth of all formula_1 sentences. \n\nOne consequence of Shoenfield's theorem relates to the axiom of choice. Gödel proved that the constructible universe \"L\" always satisfies ZFC, including the axiom of choice, even when \"V\" is only assumed to satisfy ZF. Shoenfield's theorem shows that if there is a model of ZF in which a given formula_3 statement φ is false, then φ is also false in the constructible universe of that model. In contrapositive, this means that if ZFC proves a formula_3 sentence then that sentence is also provable in ZF. The same argument can be applied to any other principle which always holds in the constructible universe, such as the combinatorial principle ◊. Even if these principles are independent of ZF, each of their formula_3 consequences is already provable in ZF. In particular, this includes any of their consequences that can be expressed in the (first order) language of Peano arithmetic.\n\nShoenfield's theorem also shows that there are limits to the independence results that can be obtained by forcing. In particular, any sentence of Peano arithmetic is absolute to transitive models of set theory with the same ordinals. Thus it is not possible to use forcing to change the truth value of arithmetical sentences, as forcing does not change the ordinals of the model to which it is applied. Many famous open problems, such as the Riemann hypothesis and the P = NP problem, can be expressed as formula_1 sentences (or sentences of lower complexity), and thus cannot be proven independent of ZFC by forcing.\n\nThere are certain large cardinals that cannot exist in the constructible universe (\"L\") of any model of set theory. Nevertheless, the constructible universe contains all the ordinal numbers that the original model of set theory contains. This \"paradox\" can be resolved by noting that the defining properties of some large cardinals are not absolute to submodels. \n\nOne example of such a nonabsolute large cardinal axiom is for measurable cardinals; for an ordinal to be a measurable cardinal there must exist another set (the measure) satisfying certain properties. It can be shown that no such measure is constructible.\n\n\n"}
{"id": "510995", "url": "https://en.wikipedia.org/wiki?curid=510995", "title": "Actor–observer asymmetry", "text": "Actor–observer asymmetry\n\nActor–observer asymmetry (also actor–observer bias) explains the errors that one makes when forming attributions about the behavior of others . When people judge their own behavior, and they are the actor, they are more likely to attribute their actions to the particular situation than to a generalization about their personality. Yet when an observer is explaining the behavior of another person (the actor), they are more likely to attribute this behavior to the actors' overall disposition rather than to situational factors. This frequent error shows the bias that people hold in their evaluations of behavior . Because people are better acquainted with the situational (external) factors affecting their own decisions, they are more likely to see their own behavior as affected by the social situation they are in. However, because the situational effects of anothers' behavior are less accessible to the observer, observers see the actor's behavior as influenced more by the actor's overall personality. The actor-observer asymmetry is a component of the ultimate attribution error.\nSometimes the Actor–observer asymmetry is defined as the fundamental attribution error which is when people tend to focus on the internal, personal characteristic or disposition as cause of a behavior rather than the external factors or situational influences. The actor-observer asymmetry tends to happen in event where people express behavioral emotion, such a first meeting, a blind date, a shopping at a supermarket etc... (Jones & Nisbett, 1972). From a study by Jhonson and Sheldon (1993) when asking people which object they have noticed when talking with another person, their common answers were based on their own thought and the other person appearance \n\nThis term falls under \"attribution\" or \"attribution theory\". The specific hypothesis of an actor-observer asymmetry in attribution (explanations of behavior) was originally proposed by Jones and Nisbett (1971), when they claimed that \"actors tend to attribute the causes of their behavior to stimuli inherent in the situation, while observers tend to attribute behavior to stable dispositions of the actor” . Supported by initial evidence, the hypothesis was long held as firmly established, describing a robust and pervasive phenomenon of social cognition.\n\nHowever, a meta-analysis of all the published tests of the hypothesis between 1971 and 2004 yielded a contradictory finding: there was no actor-observer asymmetry of the sort had proposed. interpreted this result not so much as proof that actors and observers explained behavior exactly the same way but as evidence that the original hypothesis was fundamentally flawed in the way it framed people's explanations of behavior—namely, as attributions to either stable dispositions or to the situation. Against the background of a different theory of explanation, tested an alternative set of three actor-observer asymmetries and found consistent support for all of them. Thus, the actor-observer asymmetry does not exist in one theoretical formulation (traditional attribution theory) but does exist in the new alternative theoretical formulation. argues that this favors the alternative theoretical formulation, but current textbooks have not yet fully addressed this theoretical challenge.\n\nConsiderations of actor-observer differences can be found in other disciplines as well, such as philosophy (e.g. privileged access, incorrigibility), management studies, artificial intelligence, semiotics, anthropology, and political science.\n\nThe background of this hypothesis was in the 1960s, with social psychology's increasing interest in the cognitive mechanisms by which people make sense of their own and other people's behavior. This interest was instigated by Fritz Heider's (1958) book, \"The Psychology of Interpersonal Relations\", and the research in its wake has become known as \"attribution research\" or \"attribution theory.\"\n\nThe specific hypothesis of an \"actor–observer asymmetry\" was first proposed by social psychologists Jones and Nisbett in 1971. Jones and Nisbett hypothesized that these two roles (actors and observers) produce asymmetric explanations. Their research findings showed that “there is pervasive tendency for actors to attribute their actions to situational requirements, whereas observers tend to attribute the same actions to stable personal dispositions”. For example, a student who studies hard for an exam is likely to explain her own (the actor's) intensive studying by referring to the upcoming difficult exam (a situational factor), whereas other people (the observers) are likely to explain her studying by referring to her dispositions, such as being hardworking or ambitious.\n\nSoon after the publication of the actor-observer hypothesis, numerous research studies tested its validity, most notably the first such test by . The authors found initial evidence for the hypothesis, and so did , who also examined one possible explanation of the hypothesis: that actors explain their behaviors by reference to the situation because they attend to the situation (not to their own behaviors) whereas observers explain the actor's behavior by reference to the actor's dispositions because they attend to the actor's behavior (not to the situation). Based largely on this initial supporting evidence, the confidence in the hypothesis became uniformly high. The asymmetry was described as “robust and quite general”, \"firmly established\" and “an entrenched part of scientific psychology”. Likewise, evidence for the asymmetry was considered to be \"plentiful” and “pervasive”.\n\nOver 100 studies have been published since 1971 in which the hypothesis was put to further tests (often in the context of testing another hypothesis about causal attributions). examined this entire literature in a meta-analysis, which is a robust way of identifying consistent patterns of evidence regarding a given hypothesis across a broad set of studies. The result of this analysis was stunning: across 170 individual tests, the asymmetry practically did not exist. (The average effect sizes, computed in several accepted ways, ranged from d = -0.016 to d = 0.095; corrected for publication bias, the average effect size was 0.) Under circumscribed conditions(i.e. if the actor was portrayed as highly idiosyncratic, or in negative events), it could sometimes be found, but under other conditions, the opposite was found. The conclusion was that the widely held assumption of an actor-observer asymmetry in attribution was false.\n\nIn contrast to the article, other research has shown a strong presence of the actor-observer asymmetry even in instances with familiar people. conducted a study on pairs of university dorm roommates who liked and knew one another well. The researchers aimed for familiar pairs of participants was to discover whether or not actor-observer asymmetry existed in conditions that might atypically work against it. Previous literature suggests that actor-observer asymmetry would not be present in situations where the actors and the observers were familiar with each other, which is why Krueger and colleagues wanted to perform the study with familiar pairs. Each participant answered three questionnaires where the final scores were weighed against each other in order to understand the presence of actor-observer asymmetry. The results showed that gender did not affect the findings, so whether or not the pairs were the same or opposite sex was not a mediator for the data. The researchers found that actors were aware of the actor-observer asymmetry, but the observers were not, which is typically what happens in everyday life. Krueger and colleagues showed another side to the actor-observer asymmetry, wherein it is present even among familiar people.\n\nEven more recent evidence was published on the social acceptability of actions and the speed with which an observer's perception of an actor's moral character are determined and affected by actor-observer asymmetry. conducted two experiments in order to support the idea that an immoral action is quickly followed by a negative evaluation of the actor's moral character by the observer. On the other hand, a morally good decision by an actor is readily given a positive evaluation of that actor's moral character. This is due to the fact that actions are observed as having been made with a degree of certainty and intentionality on the part of the actor, and more distinct motives are the underlying cause of these actions, thus creating more contrasted evaluations of the actor by the observer.\n\nThe result of the meta-analysis implied that, across the board, actors and observers explain behaviors the same way. But all the tests of the classic hypothesis presupposed that people explain behavior by referring to \"dispositional\" vs. \"situational\" causes. This assumption turned out to be incorrect for the class of behavioral events that people explain most frequently in real life : intentional behaviors (e.g., buying a new car, making a mean comment). People explain unintentional behaviors in ways that the traditional disposition-situation framework can capture, but they explain intentional behaviors by using very different concepts (Buss, 1978; ). A recent empirical theory of how people explain behavior was proposed and tested by , centering on the postulate that intentional behaviors are typically explained by reasons—the mental states (typically beliefs and desires) in light of which and on the grounds of which the agent decided to act (a postulate long discussed in the philosophy of action). But people who explain intentional behavior have several choices to make, and the theory identifies the psychological antecedents and consequences of these choices:\n\nEmpirical studies have so far supported this theoretical framework.\n\nWithin this framework, the actor-observer asymmetry was then reformulated as in fact consisting of three asymmetries: that actors offer more reason explanations (relative to CHR explanations) than observers do; that actors offer more belief reasons (relative to desire reasons) than observers do; and that actors use fewer belief reason markers than observers do . tested these asymmetries across 9 studies and found consistent support for them. In the same studies they also tested the classic person/disposition vs. situation hypothesis and consistently found no support for it.\n\nThus, people do seem to explain their own actions differently from how they explain other people's actions. But these differences do not lie in a predominance of using \"dispositional\" vs. \"situational\" causes. Only when people's explanations are separated into theoretically meaningful distinctions (e.g., reasons vs. causal history of reason explanations) do the differences emerge.\n\nIn addition, an alternative theory has been proposed called the folk-conceptual theory. In contrast to the actor-observer asymmetry, it posits that people's explanations of behavior varies based on three key parameters (these parameters being: use of reason explanations vs. causal history explanations, use of belief reasons vs. desire reasons, and the use of mental state markers).\n\nThe choices of different explanations for intentional behavior (reasons, belief reasons, etc.) indicate particular psychological functions. Reasons, for example, appear to reflect (among other things) psychological closeness. People increase reason explanations (relative to CHR explanations) when they explain their own rather than another person's behavior , when they portray another person in a positive light , and when they explain behaviors of nonhuman agents for whom they have ownership and affection (e.g., a pet fish; ). Conversely, people use fewer reasons and more CHR explanations when explaining behaviors of collectives or aggregate groups . Actor-observer asymmetries can therefore be seen as part of a broader continuum of psychological distance people have to various kinds of minds (their own, others', groups', animals' etc.).\n\nCultural differences may impact how certain behaviors or actions are attributed and interpreted. Current research supports the idea that Western culture emphasizes individualism, whereas East Asian cultures emphasize collectivism.The fundamental attribution error differs in those cultures. In the Individualistic cultures people tend to favor dispositional explanations for behavior. Whereas, in the collectivist cultures where P. B. Smith and Bond (1994) implied that the fundamental attribution error is minimal or even absent, so they tend to focus on situational explanation for behavior.]] . found when viewing an underwater scene Americans focused more on fish in the foreground and the direction they were swimming within the tank than the background of the environment. This supports the idea that Americans are more like to attribute behavior to dispositional cue that are directly present in the environment or foreground. This is opposed to Japanese participants who focused on the fish, but additionally focused on the background of the environment (plants, other animals). This shows how people from East Asian cultures are more likely to attribute behavior to both dispositional and situational cues in the environment. In addition, found that when situational constraints of participants in an experiment were made more salient that only the East Asian participants had an increased perception of the situational constraints and made their judgments accordingly. This is opposed to North American participants who showed little to no change in perception of the situational constraints as they were made more salient. Additionally, it has differed in religious perspective. Protestant are most likely to focus on internal factor whether than external for behavior. Unlike the Catholic who would tend to focus on the external factor. The cause is that Protestant rely too much on correlational evidence without evidence of causality (MacKinnon, 2008). It is also cause by the fact that Protestant have stronger faith and are more aware of the soul's condition than Catholic.]]\n\nInstead of speaking of a hypothesis of an actor-observer asymmetry, some textbooks and research articles speak of an \"actor-observer bias.\" The term \"bias\" is typically used to imply that one of the explainers (either the actor or the observer) is biased or incorrect in their explanations. But which one—the actor or the observer—is supposed to be incorrect is not clear from the literature. On the one hand, Ross's (1977) hypothesis of a \"fundamental attribution error\" suggests that observers are incorrect, because they show a general tendency to overemphasize dispositional explanations and underemphasize situational ones. On the other hand, Nisbett and Wilson (1977) argued that actors don't really know the true causes of their actions (the so-called \"introspection illusion\") and often merely invent plausible explanations. themselves did not commit to calling the hypothesized actor-observer asymmetry a bias or an error. Similarly, recent theoretical positions consider asymmetries not a bias, but rather the result of multiple cognitive and motivational differences that fundamentally exist between actors and observers.\n\nThe actor-observer asymmetry is often confused with the hypothesis of a self-serving bias in attribution — the claim that people choose explanations in a strategic way so as to make themselves appear in a more positive light. The important difference between the two hypotheses is that the assumed actor-observer asymmetry is expected to hold for all events and behaviors (whether they are positive or negative) and require a specific comparison between actor explanations and observer explanations. The self-serving bias is often formulated as a complete reversal in actors' and observers' explanation tendencies as a function of positive vs. negative events. In traditional attribution terms, this means that for positive events (e.g., getting an A on an exam), actors will select explanations that refer to their own dispositions, (e.g., \"I am smart\") whereas observers will select explanations that refer to the actor's situation (e.g., \"The test was easy\"); however, for negative events (e.g., receiving an F on the exam), actors will select explanations that refer to the situation, (e.g., \"The test was impossibly hard\") whereas observers will select explanations that refer to the actor's dispositions (e.g., \"She is not smart enough\").\n\nThe actor-observer asymmetry can seem similar to the hypothesis of a positivity bias in attribution- the claim that people are biased toward favorable evaluations. This hypothesis states that people will attribute their behavior with positive consequences to internal factors and their behavior with negative consequences to external factors. The positivity bias is described in terms of the actors attributions of their own behavior. This means that people will attribute their behavior which received a positive consequence (passes their driving test and receiving their drivers license) to an internal factor (I really know the material). However, people will attribute their behavior in which they received a negative consequence (failing a driving test) to an external factor (the sun was in my eyes).\n\nObservers attribute actions of others to their future behavior. Witnessing one's actions brings the witness to attribute those same actions to that person's future behavior. This explains why first impressions are so important to us. Once an action is seen, it is hard for the observer to imagine any other differing behaviors from the actor. However, on the other hand, it is hard for actors to attribute one action they have made to their whole behavior. They view themselves as more responsive, and therefore believe themselves to be in control of all situational matters. As the actor can attribute every action in the past he/she has done, the observer can only attribute the one action that is witnessed to that actor. Therefore, will attribute dispositional, rather than situational means to the actor.\n\n\n\n\n"}
{"id": "37794527", "url": "https://en.wikipedia.org/wiki?curid=37794527", "title": "Blown bottle", "text": "Blown bottle\n\nA blown bottle is a musical instrument that produces sound when the musician blows air over the bottle opening.\n\nBlown bottles generate sound by utilizing a vibrating column of air. The bottles may be tuned by adding water or sand to the vessel.\n\nBlown bottles, like the musical jug, are sometimes used by performers of folk music. The blown bottle is assigned to note number 76 (or 77, for numbering starting with 1) in the General MIDI specification.\n\n"}
{"id": "1174295", "url": "https://en.wikipedia.org/wiki?curid=1174295", "title": "Civil Disobedience (Thoreau)", "text": "Civil Disobedience (Thoreau)\n\nResistance to Civil Government (Civil Disobedience) is an essay by American transcendentalist Henry David Thoreau that was first published in 1849. In it, Thoreau argues that individuals should not permit governments to overrule or atrophy their consciences, and that they have a duty to avoid allowing such acquiescence to enable the government to make them the agents of injustice. Thoreau was motivated in part by his disgust with slavery and the Mexican–American War (1846–1848).\n\nIn 1848, Thoreau gave lectures at the Concord Lyceum entitled \"The Rights and Duties of the Individual in relation to Government\". This formed the basis for his essay, which was first published under the title \"Resistance to Civil Government\" in a 1849 anthology by Elizabeth Peabody called \"Æsthetic Papers\". The latter title distinguished Thoreau's program from that of the \"non-resistants\" (anarcho-pacifists) who were expressing similar views. \"Resistance\" also served as part of Thoreau's metaphor comparing the government to a machine: when the machine was producing injustice, it was the duty of conscientious citizens to be \"a counter friction\" (i.e., a resistance) \"to stop the machine\".\n\nIn 1866, four years after Thoreau's death, the essay was reprinted in a collection of Thoreau's work (\"A Yankee in Canada, with Anti-Slavery and Reform Papers\") under the title \"Civil Disobedience\". Today, the essay also appears under the title \"On the Duty of Civil Disobedience\", perhaps to contrast it with William Paley's \"Of the Duty of Civil Obedience\" to which Thoreau was in part responding. For instance, the 1960 New American Library Signet Classics edition of \"Walden\" included a version with this title. \"On Civil Disobedience\" is another common title.\n\nThe word has several definitions. The one that is intended in this case is \"relating to citizens and their interrelations with one another or with the state\", and so \"civil disobedience\" means \"disobedience to the state\". Sometimes people assume that \"civil\" in this case means \"observing accepted social forms; polite\" which would make \"civil disobedience\" something like \"polite, orderly disobedience\". Although this is an acceptable dictionary definition of the word \"civil\", it is not what is intended here. This misinterpretation is one reason the essay is sometimes considered to be an argument for pacifism or for exclusively nonviolent resistance. For instance, Mahatma Gandhi used this interpretation to suggest an equivalence between Thoreau's civil disobedience and his own satyagraha.\n\nThe slavery crisis inflamed New England in the 1840s and 1850s. The environment became especially tense after the Fugitive Slave Act of 1850. A lifelong abolitionist, Thoreau delivered an impassioned speech which would later become \"Civil Disobedience\" in 1848, just months after leaving Walden Pond. The speech dealt with slavery, but at the same time excoriated American imperialism, particularly the Mexican–American War.\n\nThoreau asserts that because governments are typically more harmful than helpful, they therefore cannot be justified. Democracy is no cure for this, as majorities simply by virtue of being majorities do not also gain the virtues of wisdom and justice. The judgment of an individual's conscience is not necessarily inferior to the decisions of a political body or majority, and so \"[i]t is not desirable to cultivate a respect for the law, so much as for the right. The only obligation which I have a right to assume is to do at any time what I think right... Law never made men a whit more just; and, by means of their respect for it, even the well-disposed are daily made the agents of injustice.\" He adds, \"I cannot for an instant recognize as my government [that] which is the slave's government also.\"\n\nThe government, according to Thoreau, is not just a \"little\" corrupt or unjust in the course of doing its otherwise-important work, but in fact the government is \"primarily\" an agent of corruption and injustice. Because of this, it is \"not too soon for honest men to rebel and revolutionize\".\n\nPolitical philosophers have counseled caution about revolution because the upheaval of revolution typically causes a lot of expense and suffering. Thoreau contends that such a cost/benefit analysis is inappropriate when the government is actively facilitating an injustice as extreme as slavery. Such a fundamental immorality justifies any difficulty or expense to bring it to an end. \"This people must cease to hold slaves, and to make war on Mexico, though it cost them their existence as a people.\"\n\nThoreau tells his audience that they cannot blame this problem solely on pro-slavery Southern politicians, but must put the blame on those in, for instance, Massachusetts, \"who are more interested in commerce and agriculture than they are in humanity, and are not prepared to do justice to the slave and to Mexico, \"cost what it may\"... There are thousands who are in opinion opposed to slavery and to the war, who yet in effect do nothing to put an end to them.\" (See also: Thoreau's \"Slavery in Massachusetts\" which also advances this argument.)\n\nHe exhorts people not to just wait passively for an opportunity to \"vote\" for justice, because voting for justice is as ineffective as \"wishing\" for justice; what you need to do is to actually \"be just\". This is not to say that you have an obligation to devote your life to fighting for justice, but you \"do\" have an obligation not to commit injustice and not to give injustice your practical support.\n\nPaying taxes is one way in which otherwise well-meaning people collaborate in injustice. People who proclaim that the war in Mexico is wrong and that it is wrong to enforce slavery contradict themselves if they fund both things by paying taxes. Thoreau points out that the same people who applaud soldiers for refusing to fight an unjust war are not themselves willing to refuse to fund the government that started the war.\n\nIn a constitutional republic like the United States, people often think that the proper response to an unjust law is to try to use the political process to change the law, but to obey and respect the law until it is changed. But if the law is itself clearly unjust, and the lawmaking process is not designed to quickly obliterate such unjust laws, then Thoreau says the law deserves no respect and it should be broken. In the case of the United States, the Constitution itself enshrines the institution of slavery, and therefore falls under this condemnation. Abolitionists, in Thoreau's opinion, should completely withdraw their support of the government and stop paying taxes, even if this means courting imprisonment.\n\nBecause the government will retaliate, Thoreau says he prefers living simply because he therefore has less to lose. \"I can afford to refuse allegiance to Massachusetts... It costs me less in every sense to incur the penalty of disobedience to the State than it would to obey. I should feel as if I were worth less in that case.\"\n\nHe was briefly imprisoned for refusing to pay the poll tax, but even in jail felt freer than the people outside. He considered it an interesting experience and came out of it with a new perspective on his relationship to the government and its citizens. (He was released the next day when \"someone interfered, and paid that tax\".)\n\nThoreau said he was willing to pay the highway tax, which went to pay for something of benefit to his neighbors, but that he was opposed to taxes that went to support the government itself—even if he could not tell if his particular contribution would eventually be spent on an unjust project or a beneficial one. \"I simply wish to refuse allegiance to the State, to withdraw and stand aloof from it effectually.\"\n\nBecause government is man-made, not an element of nature or an act of God, Thoreau hoped that its makers could be reasoned with. As governments go, he felt, the U.S. government, with all its faults, was not the worst and even had some admirable qualities. But he felt we could and should insist on better. \"The progress from an absolute to a limited monarchy, from a limited monarchy to a democracy, is a progress toward a true respect for the individual... Is a democracy, such as we know it, the last improvement possible in government? Is it not possible to take a step further towards recognizing and organizing the rights of man? There will never be a really free and enlightened State until the State comes to recognize the individual as a higher and independent power, from which all its own power and authority are derived, and treats him accordingly.\"\n\nAn aphorism often erroneously attributed to Thomas Jefferson, \"That government is best which governs least...\", was actually found in Thoreau's \"Civil Disobedience.\" Thoreau was apparently paraphrasing the motto of \"The United States Magazine and Democratic Review\": \"The best government is that which governs least.\" Thoreau expanded it significantly:\n\nIndian independence leader Mohandas Gandhi (a.k.a. Mahatma Gandhi) was impressed by Thoreau's arguments. In 1907, about one year into his first \"satyagraha\" campaign in South Africa, he wrote a translated synopsis of Thoreau's argument for \"Indian Opinion\", credited Thoreau's essay with being \"the chief cause of the abolition of slavery in America\", and wrote that \"Both his example and writings are at present exactly applicable to the Indians in the Transvaal.\" He later concluded:\nAmerican civil rights leader Dr. Martin Luther King, Jr. was also influenced by this essay. In his autobiography, he wrote:\nExistentialist Martin Buber wrote, of \"Civil Disobedience\"\n\nAuthor Leo Tolstoy cited \"Civil Disobedience\" as having a strong impact on his nonviolence methodology. Others who are said to have been influenced by \"Civil Disobedience\" include: President John F. Kennedy, Supreme Court Justice William O. Douglas, and various writers such as, Marcel Proust, Ernest Hemingway, Upton Sinclair, Sinclair Lewis, and William Butler Yeats.\n\n Peabody, Elizabeth (ed). Aesthetic Papers. G.P. Putnam (New York, 1849). Available at the Internet Archive\n\n"}
{"id": "34477151", "url": "https://en.wikipedia.org/wiki?curid=34477151", "title": "Class in Aztec society", "text": "Class in Aztec society\n\nAztec society traditionally was divided into social classes. \nThe Aztec social classes grew incredibly sophisticated and complex once the Mexican people settled and began to build their empire. It's been said that the class structure was so elaborate that it impressed the Spanish almost as much as the architecture of the empire.\n\nThe Mexica people, who later became the nucleus of the Aztec empire, were for a time a nomadic tribe looking for a home. As they moved south, they came into contact with advanced peoples. Many cultures of the day looked back to the impressive culture of the Toltecs, and the Aztecs came to admire the Toltec heritage. In fact, eventually the word for artistic creations would be \"toltecayotl\", for the Toltecs, and the Aztecs themselves would claim to be descended from the great Toltec nobles.\n\nThe Mexicans were anxious to claim a Toltec heritage, so they chose a nobleman of Toltec origin as their first king, a man named Acamapichtli. He fathered a great many children by 20 wives, and his descendants became the heart of a new social class in the empire - the nobles or \"pipiltin\" (singular \"pilli\"). From then on, a king would always be chosen from among the \"pipiltin\".\n\nBasically, the ruling positions were not hereditary, but preference was given to those in the \"royal families\". Originally the \"pipiltin\" status was not hereditary, although the sons of \"pillis\" had access to better resources and education, so it was easier for them to become \"pillis\". Later the class system took on hereditary aspects.\n\nThe nobles had many other privileges. They generally received a fuller education, they were allowed to wear fancier clothes and decorate their houses. They were allowed to hold important government offices. But not all had positions of authority - some were craftsmen, or even palace servants. Those who served with distinction could move up the ranks.\n\nThe second class were the \"macehualtin\" (people), originally peasants. Eduardo Noguera\nestimates that in later stages only 20% of the population was dedicated to agriculture and food production. The other 80% of society were warriors, artisans and traders.\n\nSlaves or \"tlacotin\" also constituted an important class. Aztecs could become slaves because of debts, as a criminal punishment, or as war captives. A slave could have possessions and even own other slaves. Slavery in Aztec society was in some ways more humane than in Western cultures. While some slaves were punished criminals or prisoners of war, others sold themselves or their children into slavery due to economic hardship. Slaves could free themselves by repaying their purchase price. They could marry and own property, and their children were born free.\n\nTraveling merchants called \"pochteca\" were a small, but important class as they not only facilitated commerce, but also communicated vital information across the empire and beyond its borders. They were often employed as spies.\n\n"}
{"id": "3848172", "url": "https://en.wikipedia.org/wiki?curid=3848172", "title": "Collective identity", "text": "Collective identity\n\nCollective identity is the shared sense of belonging to a group.\n\nIn 1989, Alberto Melucci published Nomads of the Present, which introduces his model of collective identity based on studies of the social movements of the 1980s. Melucci based his ideas on the writings by Touraine and Pizzorno, specifically their ideas on social movements and collective action respectively.\n\nAlberto Melucci writes, \"collective identity is an interactive and shared definition produced by several individuals (or groups at a more complex level) and concerned with the orientation of action and the field of opportunities and constraints in which the action takes place\". Unsatisfied with the gap between theories on how collective actions form and how individuals find motivation, Melucci defines an intermediate process, in which individuals recognize that they share certain orientations in common and on that basis decide to act together. He considers collective identity as a process that is negotiated over time with three parts: cognitive definition, active relationship, and emotional investments.\n\n\nMelucci, in his writing \"The Process of Collective Identity\" argues for collective identity as a useful analytical tool to explain social movements. It addresses not only the processes within the system of the collective actor such as leadership models, ideologies, or communication methods, but also external relations with allies and competitors which all shape the collective actor. He goes on to state that it can help better understand the development of modern collective action, distinct from formal organizations, amidst the rapid development of the field of social science research. In addition, it makes collective groups as systematic collectives and not entities of ideology or defined simple value sets that could antagonize or glorify certain groups. For conflict analysis, this distinction can change the language and nature of analysis completely.\n\nSocial psychologists had interest in concepts of identity and individuality since its early days, tracing as far back as the work of George Mead. His theories focused on the relationship between individual identity and society. He theorizes a chicken-and-egg relationship between society and identity. Preexisting social structure and conditions shape a person’s identity, which in turn, interacts with others and shapes the new and emerging social structure.\n\nMore contemporarily, Polletta and Jasper defined collective identity as “an individual’s cognitive, moral, and emotional connections with a broader community, category, practice, or institution.” The collective identity of a group are often expressed through the group’s cultures and traditions. The origin of the identity can be from within the group or outside the group, but ultimately, a collective identity is only formed upon the group members’ acceptance of the identity. Though defining collective identity to be a self-central concept, they emphasize on its distinction from concepts like ideology, motivation, and personal identity.\n\nNot to be confused with social identity theory or self-categorization theory, collective identity focuses on the identity of the group as a whole, while the other theories focus on the identity of an individual(self)’s association with a group.to 2013\n\nMarxist concepts of class consciousness can be considered a root of collective identity. The identity of the class was tied to its values and interests, and includes solidarity. This idea of solidarity is shared by Durkheim, who argues that collective identity helps create bonds between individuals through shared morals and goals. Max Weber, in his book \"Economy and Society\", published posthumously in 1922, critiqued Marx's focus on production and instead suggests that class, status, and party form the three sources of collective identity.\n\nAlexander Wendt is well known for his writings on constructivist political theory, in which collective identity play a prominent role as identity is a major determining factor in the role of states in the international order. His approach focuses on group and individual identity, at the domestic and international level. This application of collective identity to explaining and describing the international system is the basis of constructivism. Constructivism has a strong focus on the social discourse that create these identities, which not only designate a country as a collective actor but possible alliances as collective groups. By grouping together countries, either by their own decision or by third parties, new alliances or blocs form through the collective identity assigned to them, even if sometimes this assignment is based on inaccurate binary groupings. Regardless of accuracy of grouping, the very act of grouping these countries together affects how the international system views them and thus treats them, which in return causes the countries to identify with each other in terms of their common position internationally. Further work on collective identity in international relations has been conducted by Richard Ned Lebow, who has argued that states view themselves and others as parts of collective power groups of states, such as rising and falling powers, and simply their sense of belonging to certain power groups or aspiring to be in others affects their interactions with other states, irrespective of the \"reality\" of their power statuses.\n\nJoseph Jordania suggested that in human evolutionary history collective identity was crucial for the physical survival of hominids and early humans. As individual hominids were too weak and slow to survive predators on their own, in the moments most critical to survival (predator attacks, combat situations, mortal danger) humans enter the altered state of consciousness where they do not feel fear and pain, do not question the behavior of other members of their group, and are ready to sacrifice their lives for evolution's more important super-ordinate goals (i.e. survival of the children or the group). Humans sometimes do not have memory of these critical moments. Absence of stressful memories is known as psychogenic amnesia. According to Jordania, human ability to follow the rhythm in big groups, to sing together in harmony, to dance for many hours and enter the ecstatic state, as well as the tradition of body painting, were all the parts of the first universal rituals. These were primarily developed as the means to synchronize each individual group-member's neural activity (through the release of neuro-chemicals), in order to reach the state of collective identity, also known as transcendence. In this state the survival needs of the group can override the instincts of individual survival.\n\n\n"}
{"id": "5254", "url": "https://en.wikipedia.org/wiki?curid=5254", "title": "Common law", "text": "Common law\n\nIn law, common law (also known as judicial precedent or judge-made law, or case law) is that body of law derived from judicial decisions of courts and similar tribunals. The defining characteristic of “common law” is that it arises as precedent. In cases where the parties disagree on what the law is, a common law court looks to past precedential decisions of relevant courts, and synthesizes the principles of those past cases as applicable to the current facts. If a similar dispute has been resolved in the past, the court is usually bound to follow the reasoning used in the prior decision (a principle known as \"stare decisis\"). If, however, the court finds that the current dispute is fundamentally distinct from all previous cases (called a \"matter of first impression\"), and legislative statutes are either silent or ambiguous on the question, judges have the authority and duty to resolve the issue (one party or the other has to win, and on disagreements of law, judges make that decision). The court states an opinion that gives reasons for the decision, and those reasons agglomerate with past decisions as precedent to bind future judges and litigants. Common law, as the body of law made by judges, stands in contrast to and on equal footing with statutes which are adopted through the legislative process, and regulations which are promulgated by the executive branch (the interactions among these different sources of law are explained later in this article). \"Stare decisis\", the principle that cases should be decided according to consistent principled rules so that similar facts will yield similar results, lies at the heart of all common law systems.\n\nToday, one-third of the world's population lives in common law jurisdictions or in systems mixed with civil law, including Antigua and Barbuda, Australia, Bahamas, Bangladesh, Barbados, Belize, Botswana, Burma, Cameroon, Canada (both the federal system and all its provinces except Quebec), Cyprus, Dominica, Fiji, Ghana, Grenada, Guyana, Hong Kong, India, Ireland, Israel, Jamaica, Kenya, Liberia, Malaysia, Marshall Islands, Micronesia, Namibia, Nauru, New Zealand, Nigeria, Pakistan, Palau, Papua New Guinea, Sierra Leone, Singapore, South Africa, Sri Lanka, Trinidad and Tobago, the United Kingdom (including its overseas territories such as Gibraltar), the United States (both the federal system and 49 of its 50 states), and Zimbabwe. Some of these countries have variants on common law systems.\n\nThe term \"common law\" has many connotations. The first three set out here are the most-common usages within the legal community. Other connotations from past centuries are sometimes seen, and are sometimes heard in everyday speech.\n\nThe first definition of \"common law\" given in \"Black's Law Dictionary\", 10th edition, 2014, is \"The body of law derived from judicial decisions, rather than from statutes or constitutions; [synonym] CASELAW, [contrast] STATUTORY LAW.\" This usage is given as the first definition in modern legal dictionaries, is characterized as the “most common” usage among legal professionals, and is the usage frequently seen in decisions of courts. In this connotation, \"common law\" distinguishes the authority that promulgated a law. For example, the law in most Anglo-American jurisdictions includes \"statutory law\" enacted by a legislature, \"regulatory law\" (in the U.S.) or “delegated legislation” (in the U.K.) promulgated by executive branch agencies pursuant to delegation of rule-making authority from the legislature, and common law or \"case law\", \"i.e.\", decisions issued by courts (or quasi-judicial tribunals within agencies). This first connotation can be further differentiated into\nPublication of decisions, and indexing, is essential to the development of common law, and thus governments and private publishers publish law reports. While all decisions in common law jurisdictions are precedent (at varying levels and scope as discussed throughout the article on precedent), some become \"leading cases\" or \"landmark decisions\" that are cited especially often.\n\n\"Black's Law Dictionary\" 10th Ed., definition 2, differentiates \"common law\" jurisdictions and legal systems from \"civil law\" or \"code\" jurisdictions. Common law systems place great weight on court decisions, which are considered \"law\" with the same force of law as statutes—for nearly a millennium, common law courts have had the authority to make law where no legislative statute exists, and statutes mean what courts interpret them to mean.\n\nBy contrast, in civil law jurisdictions (the legal tradition that prevails, or is combined with common law, in Europe and most non-Islamic, non-common law countries), courts lack authority to act if there is no statute. Civil law judges tend to give less weight to judicial precedent, which means that a civil law judge deciding a given case has more freedom to interpret the text of a statute independently (compared to a common law judge in the same circumstances), and therefore less predictably. For example, the Napoleonic code expressly forbade French judges to pronounce general principles of law. The role of providing overarching principles, which in common law jurisdictions is provided in judicial opinions, in civil law jurisdictions is filled by giving greater weight to scholarly literature, as explained below.\n\nCommon law systems trace their history to England, while civil law systems trace their history through the Napoleonic Code back to the Corpus Juris Civilis of Roman law.\n\n\"Black's Law Dictionary\" 10th Ed., definition 4, differentiates \"common law\" (or just \"law\") from \"equity\". Before 1873, England had two complementary court systems: courts of \"law\" which could only award money damages and recognized only the legal owner of property, and courts of \"equity\" (courts of chancery) that could issue injunctive relief (that is, a court order to a party to do something, give something to someone, or stop doing something) and recognized trusts of property. This split propagated to many of the colonies, including the United States. For most purposes, most jurisdictions, including the U.S. federal system and most states, have merged the two courts. Additionally, even before the separate courts were merged, most courts were permitted to apply both law and equity, though under potentially different procedural law. Nonetheless, the historical distinction between \"law\" and \"equity\" remains important today when the case involves issues such as the following:\nCourts of equity rely on common law principles of binding precedent.\n\nIn addition, there are several historical (but now archaic) uses of the term that, while no longer current, provide background context that assists in understanding the meaning of \"common law\" today.\n\nIn one usage that is now archaic, but that gives insight into the history of the common law, \"common law\" referred to the pre-Christian system of law, imported by the Saxons to England, and dating to before the Norman conquest, and before there was any consistent law to be applied. That usage is obsolete today. It is both underinclusive and overinclusive.\n\n\"Common law\" as the term is used today in common law countries contrasts with \"ius commune\". While historically the \"ius commune\" became a secure point of reference in continental European legal systems, in England it was not a point of reference at all.\n\nThe English Court of Common Pleas dealt with lawsuits in which the Monarch had no interest, i.e., between commoners.\n\n\"Black's Law Dictionary\" 10th Ed., definition 3 is \"General law common to a country as a whole, as opposed to special law that has only local application.\" From at least the 11th century and continuing for several centuries after that, there were several different circuits in the royal court system, served by itinerant judges who would travel from town to town dispensing the King's justice in \"assizes\". The term \"common law\" was used to describe the law held in common between the circuits and the different stops in each circuit. The more widely a particular law was recognized, the more weight it held, whereas purely local customs were generally subordinate to law recognized in a plurality of jurisdictions.\n\nIn a common law jurisdiction several stages of research and analysis are required to determine \"what the law is\" in a given situation. First, one must ascertain the facts. Then, one must locate any relevant statutes and cases. Then one must extract the principles, analogies and statements by various courts of what they consider important to determine how the next court is likely to rule on the facts of the present case. Later decisions, and decisions of higher courts or legislatures carry more weight than earlier cases and those of lower courts. Finally, one integrates all the lines drawn and reasons given, and determines \"what the law is\". Then, one applies that law to the facts.\n\nIn practice, common law systems are considerably more complicated than the simplified system described above. The decisions of a court are binding only in a particular jurisdiction, and even within a given jurisdiction, some courts have more power than others. For example, in most jurisdictions, decisions by appellate courts are binding on lower courts in the same jurisdiction, and on future decisions of the same appellate court, but decisions of lower courts are only non-binding persuasive authority. Interactions between common law, constitutional law, statutory law and regulatory law also give rise to considerable complexity.\n\nOliver Wendell Holmes, Jr. cautioned that \"the proper derivation of general principles in both common and constitutional law ... arise gradually, in the emergence of a consensus from a multitude of particularized prior decisions.\" Justice Cardozo noted the \"common law does not work from pre-established truths of universal and inflexible validity to conclusions derived from them deductively\", but \"[i]ts method is inductive, and it draws its generalizations from particulars\".\n\nThe common law is more malleable than statutory law. First, common law courts are not absolutely bound by precedent, but can (when extraordinarily good reason is shown) reinterpret and revise the law, without legislative intervention, to adapt to new trends in political, legal and social philosophy. Second, the common law evolves through a series of gradual steps, that gradually works out all the details, so that over a decade or more, the law can change substantially but without a sharp break, thereby reducing disruptive effects. In contrast to common law incrementalism, the legislative process is very difficult to get started, as legislatures tend to delay action until a situation is totally intolerable. For these reasons, legislative changes tend to be large, jarring and disruptive (sometimes positively, sometimes negatively, and sometimes with unintended consequences).\n\nOne example of the gradual change that typifies evolution of the common law is the gradual change in liability for negligence. The traditional common law rule through most of the 19th century was that a plaintiff could not recover for a defendant's negligent production or distribution of a harmful instrumentality unless the two were in privity of contract. Thus, only the immediate purchaser could recover for a product defect, and if a part was built up out of parts from parts manufacturers, the ultimate buyer could not recover for injury caused by a defect in the part. In an 1842 English case, \"Winterbottom v. Wright\", the postal service had contracted with Wright to maintain its coaches. Winterbottom was a driver for the post. When the coach failed and injured Winterbottom, he sued Wright. The \"Winterbottom\" court recognized that there would be \"absurd and outrageous consequences\" if an injured person could sue any person peripherally involved, and knew it had to draw a line somewhere, a limit on the causal connection between the negligent conduct and the injury. The court looked to the contractual relationships, and held that liability would only flow as far as the person in immediate contract (\"privity\") with the negligent party.\n\nA first exception to this rule arose in 1852, in the case of \"Thomas v. Winchester\", when New York's highest court held that mislabeling a poison as an innocuous herb, and then selling the mislabeled poison through a dealer who would be expected to resell it, put \"human life in imminent danger\". \"Thomas\" relied on this reason to create an exception to the \"privity\" rule. In, 1909, New York held in \"Statler v. Ray Mfg. Co.\" that a coffee urn manufacturer was liable to a person injured when the urn exploded, because the urn \"was of such a character inherently that, when applied to the purposes for which it was designed, it was liable to become a source of great danger to many people if not carefully and properly constructed\".\n\nYet the privity rule survived. In \"Cadillac Motor Car Co. v. Johnson\", (decided in 1915 by the federal appeals court for New York and several neighboring states), the court held that a car owner could not recover for injuries from a defective wheel, when the automobile owner had a contract only with the automobile dealer and not with the manufacturer, even though there was \"no question that the wheel was made of dead and ‘dozy‘ wood, quite insufficient for its purposes.\" The \"Cadillac\" court was willing to acknowledge that the case law supported exceptions for \"an article dangerous in its nature or likely to become so in the course of the ordinary usage to be contemplated by the vendor\". However, held the \"Cadillac\" court, \"one who manufactures articles dangerous only if defectively made, or installed, e.g., tables, chairs, pictures or mirrors hung on the walls, carriages, automobiles, and so on, is not liable to third parties for injuries caused by them, except in case of willful injury or fraud,\"\n\nFinally, in the famous case of \"MacPherson v. Buick Motor Co.\", in 1916, Judge Benjamin Cardozo for New York's highest court pulled a broader principle out of these predecessor cases. The facts were almost identical to \"Cadillac\" a year earlier: a wheel from a wheel manufacturer was sold to Buick, to a dealer, to MacPherson, and the wheel failed, injuring MacPherson. Judge Cardozo held:\n\nCardozo's new \"rule\" exists in no prior case, but is inferrable as a synthesis of the \"thing of danger\" principle stated in them, merely extending it to \"foreseeable danger\" even if \"the purposes for which it was designed\" were not themselves \"a source of great danger\". \"MacPherson\" takes some care to present itself as foreseeable progression, not a wild departure. Cardozo continues to adhere to the original principle of \"Winterbottom\", that \"absurd and outrageous consequences\" must be avoided, and he does so by drawing a new line in the last sentence quoted above: \"There must be knowledge of a danger, not merely possible, but probable.\" But while adhering to the underlying principle that \"some\" boundary is necessary, \"MacPherson\" overruled the prior common law by rendering the formerly dominant factor in the boundary, that is, the privity formality arising out of a contractual relationship between persons, totally irrelevant. Rather, the most important factor in the boundary would be the nature of the thing sold and the foreseeable uses that downstream purchasers would make of the thing.\n\nThe example of the evolution of the law of negligence in the preceding paragraphs illustrates two crucial principles: (a) The common law evolves, this evolution is in the hands of judges, and judges have \"made law\" for hundreds of years. (b) The reasons given for a decision are often more important in the long run than the outcome in a particular case. This is the reason that judicial opinions are usually quite long, and give rationales and policies that can be balanced with judgment in future cases, rather than the bright-line rules usually embodied in statutes.\n\nAll law systems rely on written publication of the law, so that it is accessible to all. Common law decisions are published in law reports for use by lawyers, courts and the general public.\n\nAfter the American Revolution, Massachusetts became the first state to establish an official Reporter of Decisions. As newer states needed law, they often looked first to the Massachusetts Reports for authoritative precedents as a basis for their own common law. The United States federal courts relied on private publishers until after the Civil War, and only began publishing as a government function in 1874. West Publishing in Minnesota is the largest private-sector publisher of law reports in the United States. Government publishers typically issue only decisions \"in the raw,\" while private sector publishers often add indexing, editorial analysis, and similar finding aids.\n\nIn common law legal systems, the common law is crucial to understanding almost all important areas of law. For example, in England and Wales, in English Canada, and in most states of the United States, the basic law of contracts, torts and property do not exist in statute, but only in common law (though there may be isolated modifications enacted by statute). As another example, the Supreme Court of the United States in 1877, held that a Michigan statute that established rules for solemnization of marriages did not abolish pre-existing common-law marriage, because the statute did not affirmatively require statutory solemnization and was silent as to preexisting common law.\n\nIn almost all areas of the law (even those where there is a statutory framework, such as contracts for the sale of goods, or the criminal law), legislature-enacted statutes generally give only terse statements of general principle, and the fine boundaries and definitions exist only in the interstitial common law. To find out what the precise law is that applies to a particular set of facts, one has to locate precedential decisions on the topic, and reason from those decisions by analogy.\n\nIn (common law jurisdictions (in the sense opposed to \"civil law\"), legislatures operate under the assumption that statutes will be interpreted against the backdrop of the pre-existing common law. As the United States Supreme Court explained in \"United States v Texas\", 507 U.S. 529 (1993):\n\nFor example, in most U.S. states, the criminal statutes are primarily codification of pre-existing common law. (Codification is the process of enacting a statute that collects and restates pre-existing law in a single document—when that pre-existing law is common law, the common law remains relevant to the interpretation of these statutes.) In reliance on this assumption, modern statutes often leave a number of terms and fine distinctions unstated—for example, a statute might be very brief, leaving the precise definition of terms unstated, under the assumption that these fine distinctions will be inherited from pre-existing common law. (For this reason, many modern American law schools teach the common law of crime as it stood in England in 1789, because that centuries-old English common law is a necessary foundation to interpreting modern criminal statutes.)\n\nWith the transition from English law, which had common law crimes, to the new legal system under the U.S. Constitution, which prohibited \"ex post facto\" laws at both the federal and state level, the question was raised whether there could be common law crimes in the United States. It was settled in the case of \"United States v. Hudson\", which decided that federal courts had no jurisdiction to define new common law crimes, and that there must always be a (constitutional) statute defining the offense and the penalty for it.\n\nStill, many states retain selected common law crimes. For example, in Virginia, the definition of the conduct that constitutes the crime of robbery exists only in the common law, and the robbery statute only sets the punishment. Virginia Code section 1-200 establishes the continued existence and vitality of common law principles and provides that \"The common law of England, insofar as it is not repugnant to the principles of the Bill of Rights and Constitution of this Commonwealth, shall continue in full force within the same, and be the rule of decision, except as altered by the General Assembly.\"\n\nBy contrast to statutory codification of common law, some statutes displace common law, for example to create a new cause of action that did not exist in the common law, or to legislatively overrule the common law. An example is the tort of wrongful death, which allows certain persons, usually a spouse, child or estate, to sue for damages on behalf of the deceased. There is no such tort in English common law; thus, any jurisdiction that lacks a wrongful death statute will not allow a lawsuit for the wrongful death of a loved one. Where a wrongful death statute exists, the compensation or other remedy available is limited to the remedy specified in the statute (typically, an upper limit on the amount of damages). Courts generally interpret statutes that create new causes of action narrowly—that is, limited to their precise terms—because the courts generally recognize the legislature as being supreme in deciding the reach of judge-made law unless such statute should violate some \"second order\" constitutional law provision (\"cf\". judicial activism).\n\nWhere a tort is rooted in common law, all traditionally recognized damages for that tort may be sued for, whether or not there is mention of those damages in the current statutory law. For instance, a person who sustains bodily injury through the negligence of another may sue for medical costs, pain, suffering, loss of earnings or earning capacity, mental and/or emotional distress, loss of quality of life, disfigurement and more. These damages need not be set forth in statute as they already exist in the tradition of common law. However, without a wrongful death statute, most of them are extinguished upon death.\n\nIn the United States, the power of the federal judiciary to review and invalidate unconstitutional acts of the federal executive branch is stated in the constitution, Article III sections 1 and 2: \"The judicial Power of the United States, shall be vested in one supreme Court, and in such inferior Courts as the Congress may from time to time ordain and establish. ... The judicial Power shall extend to all Cases, in Law and Equity, arising under this Constitution, the Laws of the United States, and Treaties made, or which shall be made, under their Authority...\" The first landmark decision on \"the judicial power\" was \"Marbury v. Madison\", . Later cases interpreted the \"judicial power\" of Article III to establish the power of federal courts to consider or overturn any action of Congress or of any state that conflicts with the Constitution.\n\nThe interactions between decisions of different courts is discussed further in the article on precedent.\n\nThe United States federal courts are divided into twelve regional circuits, each with a circuit court of appeals (plus a thirteenth, the Court of Appeals for the Federal Circuit, which hears appeals in patent cases and cases against the federal government, without geographic limitation). Decisions of one circuit court are binding on the district courts within the circuit and on the circuit court itself, but are only persuasive authority on sister circuits. District court decisions are not binding precedent at all, only persuasive.\n\nMost of the U.S. federal courts of appeal have adopted a rule under which, in the event of any conflict in decisions of panels (most of the courts of appeal almost always sit in panels of three), the earlier panel decision is controlling, and a panel decision may only be overruled by the court of appeals sitting \"en banc\" (that is, all active judges of the court) or by a higher court. In these courts, the older decision remains controlling when an issue comes up the third time.\n\nOther courts, for example, the Court of Customs and Patent Appeals and the Supreme Court, always sit \"en banc\", and thus the \"later\" decision controls. These courts essentially overrule all previous cases in each new case, and older cases survive only to the extent they do not conflict with newer cases. The interpretations of these courts—for example, Supreme Court interpretations of the constitution or federal statutes—are stable only so long as the older interpretation maintains the support of a majority of the court. Older decisions persist through some combination of belief that the old decision is right, and that it is not sufficiently wrong to be overruled.\n\nIn the jurisdictions of England and Wales and of Northern Ireland, since 2009, the Supreme Court of the United Kingdom has the authority to overrule and unify criminal law decisions of lower courts; it is the final court of appeal for civil law cases in all three of the UK jurisdictions but not for criminal law cases in Scotland. From 1966 to 2009, this power lay with the House of Lords, granted by the Practice Statement of 1966.\n\nCanada's federal system, described below, avoids regional variability of federal law by giving national jurisdiction to both layers of appellate courts.\n\nThe reliance on judicial opinion is a strength of common law systems, and is a significant contributor to the robust commercial systems in the United Kingdom and United States. Because there is reasonably precise guidance on almost every issue, parties (especially commercial parties) can predict whether a proposed course of action is likely to be lawful or unlawful, and have some assurance of consistency. As Justice Brandeis famously expressed it, \"in most matters it is more important that the applicable rule of law be settled than that it be settled right.\" This ability to predict gives more freedom to come close to the boundaries of the law. For example, many commercial contracts are more economically efficient, and create greater wealth, because the parties know ahead of time that the proposed arrangement, though perhaps close to the line, is almost certainly legal. Newspapers, taxpayer-funded entities with some religious affiliation, and political parties can obtain fairly clear guidance on the boundaries within which their freedom of expression rights apply.\n\nIn contrast, in jurisdictions with very weak respect for precedent, fine questions of law are redetermined anew each time they arise, making consistency and prediction more difficult, and procedures far more protracted than necessary because parties cannot rely on written statements of law as reliable guides. In jurisdictions that do not have a strong allegiance to a large body of precedent, parties have less \"a priori\" guidance (unless the written law is very clear and kept updated) and must often leave a bigger \"safety margin\" of unexploited opportunities, and final determinations are reached only after far larger expenditures on legal fees by the parties.\n\nThis is the reason for the frequent choice of the law of the State of New York in commercial contracts, even when neither entity has extensive contacts with New York—and remarkably often even when neither party has contacts with the United States. Commercial contracts almost always include a \"choice of law clause\" to reduce uncertainty. Somewhat surprisingly, contracts throughout the world (for example, contracts involving parties in Japan, France and Germany, and from most of the other states of the United States) often choose the law of New York, even where the relationship of the parties and transaction to New York is quite attenuated. Because of its history as the United States' commercial center, New York common law has a depth and predictability not (yet) available in any other jurisdictions of the United States. Similarly, American corporations are often formed under Delaware corporate law, and American contracts relating to corporate law issues (merger and acquisitions of companies, rights of shareholders, and so on.) include a Delaware choice of law clause, because of the deep body of law in Delaware on these issues. On the other hand, some other jurisdictions have sufficiently developed bodies of law so that parties have no real motivation to choose the law of a foreign jurisdiction (for example, England and Wales, and the state of California), but not yet so fully developed that parties with no relationship to the jurisdiction choose that law. Outside the United States, parties that are in different jurisdictions from each other often choose the law of England and Wales, particularly when the parties are each in former British colonies and members of the Commonwealth. The common theme in all cases is that commercial parties seek predictability and simplicity in their contractual relations, and frequently choose the law of a common law jurisdiction with a well-developed body of common law to achieve that result.\n\nLikewise, for litigation of commercial disputes arising out of unpredictable torts (as opposed to the prospective choice of law clauses in contracts discussed in the previous paragraph), certain jurisdictions attract an unusually high fraction of cases, because of the predictability afforded by the depth of decided cases. For example, London is considered the pre-eminent centre for litigation of admiralty cases.\n\nThis is not to say that common law is better in every situation. For example, civil law can be clearer than case law when the legislature has had the foresight and diligence to address the precise set of facts applicable to a particular situation. For that reason, civil law statutes tend to be somewhat more detailed than statutes written by common law legislatures—but, conversely, that tends to make the statute more difficult to read (the United States tax code is an example).\n\nThe common lawso named because it was \"common\" to all the king's courts across Englandoriginated in the practices of the courts of the English kings in the centuries following the Norman Conquest in 1066. Prior to the Norman Conquest, much of England's legal business took place in the local folk courts of its various shires and hundreds. A variety of other individual courts also existed across the land: urban boroughs and merchant fairs held their own courts, as did the universities of Oxford and Cambridge, and large landholders also held their own manorial and seigniorial courts as needed. Additionally, the Catholic Church operated its own court system that adjudicated issues of canon law.\n\nThe main sources for the history of the common law in the Middle Ages are the plea rolls and the Year Books. The plea rolls, which were the official court records for the Courts of Common Pleas and King's Bench, were written in Latin. The rolls were made up in bundles by law term: Hilary, Easter, Trinity, and Michaelmas, or winter, spring, summer, and autumn. They are currently deposited in the UK National Archives, by whose permission images of the rolls for the Courts of Common Pleas, King's Bench, and Exchequer of Pleas, from the 13th century to the 17th, can be viewed online at the Anglo-American Legal Tradition site (The O'Quinn Law Library of the University of Houston Law Center).\n\nThe doctrine of precedent developed during the 12th and 13th centuries, as the collective judicial decisions that were based in tradition, custom and precedent.\n\nThe form of reasoning used in common law is known as casuistry or case-based reasoning. The common law, as applied in civil cases (as distinct from criminal cases), was devised as a means of compensating someone for wrongful acts known as torts, including both intentional torts and torts caused by negligence, and as developing the body of law recognizing and regulating contracts. The type of procedure practiced in common law courts is known as the adversarial system; this is also a development of the common law.\n\nThe early development of case-law in the thirteenth century has been traced to Bracton's \"On the Laws and Customs of England\" and led to the yearly compilations of court cases known as Year Books, of which the first extant was published in 1268, the same year that Bracton died. The Year Books are known as the law reports of medieval England, and are a principal source for knowledge of the developing legal doctrines, concepts, and methods in the period from the 13th to the 16th centuries, when the common law developed into recognizable form.\nIn 1154, Henry II became the first Plantagenet king. Among many achievements, Henry institutionalized common law by creating a unified system of law \"common\" to the country through incorporating and elevating local custom to the national, ending local control and peculiarities, eliminating arbitrary remedies and reinstating a jury system—citizens sworn on oath to investigate reliable criminal accusations and civil claims. The jury reached its verdict through evaluating common local knowledge, not necessarily through the presentation of evidence, a distinguishing factor from today's civil and criminal court systems.\n\nHenry II developed the practice of sending judges from his own central court to hear the various disputes throughout the country. His judges would resolve disputes on an ad hoc basis according to what they interpreted the customs to be. The king's judges would then return to London and often discuss their cases and the decisions they made with the other judges. These decisions would be recorded and filed. In time, a rule, known as \"stare decisis\" (also commonly known as precedent) developed, whereby a judge would be bound to follow the decision of an earlier judge; he was required to adopt the earlier judge's interpretation of the law and apply the same principles promulgated by that earlier judge if the two cases had similar facts to one another. Once judges began to regard each other's decisions to be binding precedent, the pre-Norman system of local customs and law varying in each locality was replaced by a system that was (at least in theory, though not always in practice) common throughout the whole country, hence the name \"common law\".\n\nHenry II's creation of a powerful and unified court system, which curbed somewhat the power of canonical (church) courts, brought him (and England) into conflict with the church, most famously with Thomas Becket, the Archbishop of Canterbury. The murder of the Archbishop gave rise to a wave of popular outrage against the King. Henry was forced to repeal the disputed laws and to abandon his efforts to hold church members accountable for secular crimes (see also Constitutions of Clarendon).\n\nThe English Court of Common Pleas was established after Magna Carta to try lawsuits between commoners in which the monarch had no interest. Its judges sat in open court in the Great Hall of the king's Palace of Westminster, permanently except in the vacations between the four terms of the Legal year.\n\nJudge-made common law operated as the primary source of law for several hundred years, before Parliament acquired legislative powers to create statutory law. It is important to understand that common law is the older and more traditional source of law, and legislative power is simply a layer applied on top of the older common law foundation. Since the 12th century, courts have had parallel and co-equal authority to make law—\"legislating from the bench\" is a traditional and essential function of courts, which was carried over into the U.S. system as an essential component of the \"judicial power\" specified by Article III of the U.S. Constitution. Justice Oliver Wendell Holmes, Jr. summarized centuries of history in 1917, \"judges do and must legislate.\" There are legitimate debates on how the powers of courts and legislatures should be balanced. However, the view that courts lack law-making power is historically inaccurate and constitutionally unsupportable.\n\nIn England, judges have devised a number of rules as to how to deal with precedent decisions.\n\nThe term \"common law\" is often used as a contrast to Roman-derived \"civil law\", and the fundamental processes and forms of reasoning in the two are quite different. Nonetheless, there has been considerable cross-fertilization of ideas, while the two traditions and sets of foundational principles remain distinct.\n\nBy the time of the rediscovery of the Roman law in Europe in the 12th and 13th centuries, the common law had already developed far enough to prevent a Roman law reception as it occurred on the continent. However, the first common law scholars, most notably Glanvill and Bracton, as well as the early royal common law judges, had been well accustomed with Roman law. Often, they were clerics trained in the Roman canon law. One of the first and throughout its history one of the most significant treatises of the common law, Bracton's \"De Legibus et Consuetudinibus Angliae\" (On the Laws and Customs of England), was heavily influenced by the division of the law in Justinian's \"Institutes\". The impact of Roman law had decreased sharply after the age of Bracton, but the Roman divisions of actions into \"in rem\" (typically, actions against a \"thing\" or property for the purpose of gaining title to that property; must be filed in a court where the property is located) and \"in personam\" (typically, actions directed against a person; these can affect a person's rights and, since a person often owns things, his property too) used by Bracton had a lasting effect and laid the groundwork for a return of Roman law structural concepts in the 18th and 19th centuries. Signs of this can be found in Blackstone's \"Commentaries on the Laws of England\", and Roman law ideas regained importance with the revival of academic law schools in the 19th century. As a result, today, the main systematic divisions of the law into property, contract, and tort (and to some extent unjust enrichment) can be found in the civil law as well as in the common law.\n\nThe first attempt at a comprehensive compilation of centuries of common law was by Lord Chief Justice Edward Coke, in his treatise, \"Institutes of the Lawes of England\" in the 17th century.\n\nThe next definitive historical treatise on the common law is \"Commentaries on the Laws of England\", written by Sir William Blackstone and first published in 1765–1769.\n\nA reception statute is a statutory law adopted as a former British colony becomes independent, by which the new nation adopts (i.e. receives) pre-independence common law, to the extent not explicitly rejected by the legislative body or constitution of the new nation. Reception statutes generally consider the English common law dating prior to independence, and the precedent originating from it, as the default law, because of the importance of using an extensive and predictable body of law to govern the conduct of citizens and businesses in a new state. All U.S. states, with the partial exception of Louisiana, have either implemented reception statutes or adopted the common law by judicial opinion.\n\nOther examples of reception statutes in the United States, the states of the U.S., Canada and its provinces, and Hong Kong, are discussed in the reception statute article.\n\nYet, adoption of the common law in the newly-independent nation was not a foregone conclusion, and was controversial. Immediately after the American Revolution, there was widespread distrust and hostility to anything British, and the common law was no exception. Jeffersonians decried lawyers and their common law tradition as threats to the new republic. The Jeffersonians preferred a legislatively-enacted civil law under the control of the political process, rather than the common law developed by judges that—by design—were insulated from the political process. The Federalists believed that the common law was the birthright of Independence: after all, the natural rights to \"life, liberty, and the pursuit of happiness\" were the rights protected by common law. Even advocates for the common law approach noted that it was not an ideal fit for the newly-independent colonies: judges and lawyers alike were severely hindered by a lack of printed legal materials. Before Independence, the most comprehensive law libraries had been maintained by Tory lawyers, and those libraries vanished with the loyalist expatriation, and the ability to print books was limited. Lawyer (later president) John Adams complained that he \"suffered very much for the want of books\". To bootstrap this most basic need of a common law system—knowable, written law—in 1803, lawyers in Massachusetts donated their books to found a law library. A Jeffersonian newspaper criticized the library, as it would carry forward \"all the old authorities practiced in England for centuries back ... whereby a new system of jurisprudence [will be founded] on the high monarchical system [to] become the Common Law of this Commonwealth... [The library] may hereafter have a very unsocial purpose.\"\n\nWell into the 19th century, ancient maxims played a large role in common law adjudication. Many of these maxims had originated in Roman Law, migrated to England before the introduction of Christianity to the British Isles, and were typically stated in Latin even in English decisions. Many examples are familiar in everyday speech even today, \"One cannot be a judge in one's own cause\" (see Dr. Bonham's Case), rights are reciprocal to obligations, and the like. Judicial decisions and treatises of the 17th and 18th centuries, such at those of Lord Chief Justice Edward Coke, presented the common law as a collection of such maxims.\n\nReliance on old maxims and rigid adherence to precedent, no matter how old or ill-considered, came under critical discussion in the late 19th century, starting in the United States. Oliver Wendell Holmes, Jr. in his famous article, \"The Path of the Law\", commented, \"It is revolting to have no better reason for a rule of law than that so it was laid down in the time of Henry IV. It is still more revolting if the grounds upon which it was laid down have vanished long since, and the rule simply persists from blind imitation of the past.\" Justice Holmes noted that study of maxims might be sufficient for \"the man of the present\", but \"the man of the future is the man of statistics and the master of economics\". In an 1880 lecture at Harvard, he wrote:\n\nThe life of the law has not been logic; it has been experience. The felt necessities of the time, the prevalent moral and political theories, intuitions of public policy, avowed or unconscious, even the prejudices which judges share with their fellow men, have had a good deal more to do than the syllogism in determining the rules by which men should be governed. The law embodies the story of a nation's development through many centuries, and it cannot be dealt with as if it contained only the axioms and corollaries of a book of mathematics.\n\nIn the early 20th century, Louis Brandeis, later appointed to the United States Supreme Court, became noted for his use of policy-driving facts and economics in his briefs, and extensive appendices presenting facts that lead a judge to the advocate's conclusion. By this time, briefs relied more on facts than on Latin maxims.\n\nReliance on old maxims is now deprecated. Common law decisions today reflect both precedent and policy judgment drawn from economics, the social sciences, business, decisions of foreign courts, and the like. The degree to which these external factors \"should\" influence adjudication is the subject of active debate, but it is indisputable that judges \"do\" draw on experience and learning from everyday life, from other fields, and from other jurisdictions.\n\nAs early as the 15th century, it became the practice that litigants who felt they had been cheated by the common law system would petition the King in person. For example, they might argue that an award of damages (at common law (as opposed to equity)) was not sufficient redress for a trespasser occupying their land, and instead request that the trespasser be evicted. From this developed the system of equity, administered by the Lord Chancellor, in the courts of chancery. By their nature, equity and law were frequently in conflict and litigation would frequently continue for years as one court countermanded the other, even though it was established by the 17th century that equity should prevail.\n\nIn England, courts of law (as opposed to equity) were combined with courts of equity by the Judicature Acts of 1873 and 1875, with equity prevailing in case of conflict.\n\nIn the United States, parallel systems of law (providing money damages, with cases heard by a jury upon either party's request) and equity (fashioning a remedy to fit the situation, including injunctive relief, heard by a judge) survived well into the 20th century. The United States federal courts procedurally separated law and equity: the same judges could hear either kind of case, but a given case could only pursue causes in law or in equity, and the two kinds of cases proceeded under different procedural rules. This became problematic when a given case required both money damages and injunctive relief. In 1937, the new Federal Rules of Civil Procedure combined law and equity into one form of action, the \"civil action\". Fed.R.Civ.P. . The distinction survives to the extent that issues that were \"common law (as opposed to equity)\" as of 1791 (the date of adoption of the Seventh Amendment) are still subject to the right of either party to request a jury, and \"equity\" issues are decided by a judge.\n\nDelaware, Mississippi, and Tennessee still have separate courts of law and equity, for example, the Court of Chancery. In many states there are separate divisions for law and equity within one court.\n\nFor centuries, through the 19th century, the common law recognized only specific forms of action, and required very careful drafting of the opening pleading (called a writ) to slot into exactly one of them: Debt, Detinue, Covenant, Special Assumpsit, General Assumpsit, Trespass, Trover, Replevin, Case (or Trespass on the Case), and Ejectment. To initiate a lawsuit, a pleading had to be drafted to meet myriad technical requirements: correctly categorizing the case into the correct legal pigeonhole (pleading in the alternative was not permitted), and using specific \"magic words\" encrusted over the centuries. Under the old common law pleading standards, a suit by a \"pro se\" (\"for oneself,\" without a lawyer) party was all but impossible, and there was often considerable procedural jousting at the outset of a case over minor wording issues.\n\nOne of the major reforms of the late 19th century and early 20th century was the abolition of common law pleading requirements. A plaintiff can initiate a case by giving the defendant \"a short and plain statement\" of facts that constitute an alleged wrong. This reform moved the attention of courts from technical scrutiny of words to a more rational consideration of the facts, and opened access to justice far more broadly.\n\nThe main alternative to the common law system is the civil law system, which is used in Continental Europe, and most of the rest of the world.\n\nThe primary contrast between the two systems is the role of written decisions and precedent.\n\nIn common law jurisdictions, nearly every case that presents a \"bona fide\" disagreement on the law is resolved in a written opinion. The legal reasoning for the decision, known as \"ratio decidendi\", not only determines the court's judgment between the parties, but also stands as precedent for resolving future disputes. In contrast, civil law decisions typically do not include explanatory opinions, and thus no precedent flows from one decision to the next.\nIn common law systems, a single decided case is binding common law (connotation 1) to the same extent as statute or regulation, under the principle of \"stare decisis\". In contrast, in civil law systems, individual decisions have only advisory, not binding effect. In civil law systems, case law only acquires weight when a long series of cases use consistent reasoning, called \"jurisprudence constante\". Civil law lawyers consult case law to obtain their best prediction of how a court will rule, but comparatively, civil law judges are less bound to follow it.\n\nFor that reason, statutes in civil law systems are more comprehensive, detailed, and continuously updated, covering all matters capable of being brought before a court.\n\nCommon law systems tend to give more weight to separation of powers between the judicial branch and the executive branch. In contrast, civil law systems are typically more tolerant of allowing individual officials to exercise both powers. One example of this contrast is the difference between the two systems in allocation of responsibility between prosecutor and adjudicator.\n\nCommon law courts usually use an adversarial system, in which two sides present their cases to a neutral judge. In contrast, in civil law systems, criminal proceedings proceed under an inquisitorial system in which an examining magistrate serves two roles by developing the evidence and arguments for one side and then the other during the investigation phase.\n\nThe examining magistrate then presents the dossier detailing his or her findings to the president of the bench that will adjudicate on the case where it has been decided that a trial shall be conducted. Therefore, the president of the bench's view of the case is not neutral and may be biased while conducting the trial after the reading of the dossier. Unlike the common law proceedings, the president of the bench in the inquisitorial system is not merely an umpire and is entitled to directly interview the witnesses or express comments during the trial, as long as he or she does not express his or her view on the guilt of the accused.\n\nThe proceeding in the inquisitorial system is essentially by writing. Most of the witnesses would have given evidence in the investigation phase and such evidence will be contained in the dossier under the form of police reports. In the same way, the accused would have already put his or her case at the investigation phase but he or she will be free to change her or his evidence at trial. Whether the accused pleads guilty or not, a trial will be conducted. Unlike the adversarial system, the conviction and sentence to be served (if any) will be released by the trial jury together with the president of the trial bench, following their common deliberation.\n\nThere are many exceptions in both directions. For example, most proceedings before U.S. federal and state agencies are inquisitorial in nature, at least the initial stages (\"e.g.\", a patent examiner, a social security hearing officer, and so on), even though the law to be applied is developed through common law processes.\n\nThe role of the legal academy presents a significant \"cultural\" difference between common law (connotation 2) and civil law jurisdictions. In both systems, treatises compile decisions and state overarching principles that (in the author's opinion) explain the results of the cases. In neither system are treatises considered \"law,\" but the weight given them is nonetheless quite different.\n\nIn common law jurisdictions, lawyers and judges tend to use these treatises as only \"finding aids\" to locate the relevant cases. In common law jurisdictions, scholarly work is seldom cited as authority for what the law is. Chief Justice Roberts noted the \"great disconnect between the academy and the profession.\" When common law courts rely on scholarly work, it is almost always only for factual findings, policy justification, or the history and evolution of the law, but the court's legal conclusion is reached through analysis of relevant statutes and common law, seldom scholarly commentary.\n\nIn contrast, in civil law jurisdictions, courts give the writings of law professors significant weight, partly because civil law decisions traditionally were very brief, sometimes no more than a paragraph stating who wins and who loses. The rationale had to come from somewhere else: the academy often filled that role.\n\nThe contrast between civil law and common law legal systems has become increasingly blurred, with the growing importance of jurisprudence (similar to case law but not binding) in civil law countries, and the growing importance of statute law and codes in common law countries.\n\nExamples of common law being replaced by statute or codified rule in the United States include criminal law (since 1812, U.S. federal courts and most but not all of the States have held that criminal law must be embodied in statute if the public is to have fair notice), commercial law (the Uniform Commercial Code in the early 1960s) and procedure (the Federal Rules of Civil Procedure in the 1930s and the Federal Rules of Evidence in the 1970s). But note that in each case, the statute sets the general principles, but the interstitial common law process determines the scope and application of the statute.\n\nAn example of convergence from the other direction is shown in the 1982 decision \"Srl CILFIT and Lanificio di Gavardo SpA v Ministry of Health\" (), in which the European Court of Justice held that questions it has already answered need not be resubmitted. This showed how a historically distinctly common law principle is used by a court composed of judges (at that time) of essentially civil law jurisdiction.\n\nThe former Soviet Bloc and other Socialist countries used a Socialist law system.\n\nMuch of the Muslim world uses Sharia (also called Islamic law).\n\nThe common law constitutes the basis of the legal systems of:\n\nand many other generally English-speaking countries or Commonwealth countries (except the UK's Scotland, which is bijuridicial, and Malta). Essentially, every country that was colonised at some time by England, Great Britain, or the United Kingdom uses common law except those that were formerly colonised by other nations, such as Quebec (which follows the law of France in part), South Africa and Sri Lanka (which follow Roman Dutch law), where the prior civil law system was retained to respect the civil rights of the local colonists. Guyana and Saint Lucia have mixed Common Law and Civil Law systems.\n\nThe remainder of this section discusses jurisdiction-specific variants, arranged chronologically.\n\nScotland is often said to use the civil law system, but it has a unique system that combines elements of an uncodified civil law dating back to the Corpus Juris Civilis with an element of its own common law long predating the Treaty of Union with England in 1707 (see Legal institutions of Scotland in the High Middle Ages), founded on the customary laws of the tribes residing there. Historically, Scottish common law differed in that the use of \"precedent\" was subject to the courts' seeking to discover the principle that justifies a law rather than searching for an example as a \"precedent\", and principles of natural justice and fairness have always played a role in Scots Law. From the 19th century, the Scottish approach to precedent developed into a \"stare decisis\" akin to that already established in England thereby reflecting a narrower, more modern approach to the application of case law in subsequent instances. This is not to say that the substantive rules of the common laws of both countries are the same although in many matters (particularly those of UK-wide interest) they are similar.\n\nScotland shares the Supreme Court, with England, Wales and Northern Ireland for civil cases; the court's decisions are binding on the jurisdiction from which a case arises but only influential on similar cases arising in Scotland. This has had the effect of converging the law in certain areas. For instance, the modern UK law of negligence is based on \"Donoghue v Stevenson\", a case originating in Paisley, Scotland.\n\nScotland maintains a separate criminal law system from the rest of the UK, with the High Court of Justiciary being the final court for criminal appeals. The highest court of appeal in civil cases brought in Scotland is now the Supreme Court of the United Kingdom (before October 2009, final appellate jurisdiction lay with the House of Lords).\n\nThe centuries-old authority of the common law courts in England to develop law case by case and to apply statute law—\"legislating from the bench\"— is a traditional function of courts, which was carried over into the U.S. system as an essential component of the \"judicial power\" specified by Article III of the U.S. constitution. Justice Oliver Wendell Holmes, Jr. summarized centuries of history in 1917, \"judges do and must legislate” (in the federal courts, only interstitially, in state courts, to the full limits of common law adjudicatory authority).\n\nThe state of New York, which also has a civil law history from its Dutch colonial days, began a codification of its law in the 19th century. The only part of this codification process that was considered complete is known as the Field Code applying to civil procedure. The original colony of New Netherland was settled by the Dutch and the law was also Dutch. When the English captured pre-existing colonies they continued to allow the local settlers to keep their civil law. However, the Dutch settlers revolted against the English and the colony was recaptured by the Dutch. When the English finally regained control of New Netherland they forced, as a punishment unique in the history of the British Empire, the English imposed common law upon all the colonists, including the Dutch. This was problematic, as the patroon system of land holding, based on the feudal system and civil law, continued to operate in the colony until it was abolished in the mid-19th century. The influence of Roman-Dutch law continued in the colony well into the late 19th century. The codification of a law of general obligations shows how remnants of the civil law tradition in New York continued on from the Dutch days.\n\nUnder Louisiana's codified system, the Louisiana Civil Code, private law—that is, substantive law between private sector parties—is based on principles of law from continental Europe, with some common law influences. These principles derive ultimately from Roman law, transmitted through French law and Spanish law, as the state's current territory intersects the area of North America colonized by Spain and by France. Contrary to popular belief, the Louisiana code does not directly derive from the Napoleonic Code, as the latter was enacted in 1804, one year after the Louisiana Purchase. However, the two codes are similar in many respects due to common roots.\n\nLouisiana's criminal law largely rests on English common law. Louisiana's administrative law is generally similar to the administrative law of the U.S. federal government and other U.S. states. Louisiana's procedural law is generally in line with that of other U.S. states, which in turn is generally based on the U.S. Federal Rules of Civil Procedure.\n\nHistorically notable among the Louisiana code's differences from common law is the role of property rights among women, particularly in inheritance gained by widows.\n\nThe U.S. state of California has a system based on common law, but it has codified the law in the manner of the civil law jurisdictions. The reason for the enactment of the California Codes in the 19th century was to replace a pre-existing system based on Spanish civil law with a system based on common law, similar to that in most other states. California and a number of other Western states, however, have retained the concept of community property derived from civil law. The California courts have treated portions of the codes as an extension of the common-law tradition, subject to judicial development in the same manner as judge-made common law. (Most notably, in the case \"Li v. Yellow Cab Co.\", 13 Cal.3d 804 (1975), the California Supreme Court adopted the principle of comparative negligence in the face of a California Civil Code provision codifying the traditional common-law doctrine of contributory negligence.)\n\nThe United States federal government (as opposed to the states) has a variant on a common law system. United States federal courts only act as interpreters of statutes and the constitution by elaborating and precisely defining broad statutory language (connotation 1(b) above), but, unlike state courts, do not act as an independent source of common law.\n\nBefore 1938, the federal courts, like almost all other common law courts, decided the law on any issue where the relevant legislature (either the U.S. Congress or state legislature, depending on the issue), had not acted, by looking to courts in the same system, that is, other federal courts, even on issues of state law, and even where there was no express grant of authority from Congress or the Constitution.\n\nIn 1938, the U.S. Supreme Court in \"Erie Railroad Co. v. Tompkins\" 304 U.S. 64, 78 (1938), overruled earlier precedent, and held \"There is no federal general common law,\" thus confining the federal courts to act only as interpreters of law originating elsewhere. \"E.g.\", \"Texas Industries v. Radcliff\", (without an express grant of statutory authority, federal courts cannot create rules of intuitive justice, for example, a right to contribution from co-conspirators). Post-1938, federal courts deciding issues that arise under state law are required to defer to state court interpretations of state statutes, or reason what a state's highest court would rule if presented with the issue, or to certify the question to the state's highest court for resolution.\n\nLater courts have limited \"Erie\" slightly, to create a few situations where United States federal courts are permitted to create federal common law rules without express statutory authority, for example, where a federal rule of decision is necessary to protect uniquely federal interests, such as foreign affairs, or financial instruments issued by the federal government. \"See, e.g.\", \"Clearfield Trust Co. v. United States\", (giving federal courts the authority to fashion common law rules with respect to issues of federal power, in this case negotiable instruments backed by the federal government); \"see also\" \"International News Service v. Associated Press\", 248 U.S. 215 (1918) (creating a cause of action for misappropriation of \"hot news\" that lacks any statutory grounding); \"but see National Basketball Association v. Motorola, Inc.\", 105 F.3d 841, 843–44, 853 (2d Cir. 1997) (noting continued vitality of \"INS\" \"hot news\" tort under New York state law, but leaving open the question of whether it survives under federal law). Except on Constitutional issues, Congress is free to legislatively overrule federal courts' common law.\n\nMost executive branch agencies in the United States federal government have some adjudicatory authority. To greater or lesser extent, agencies honor their own precedent to ensure consistent results. Agency decision making is governed by the Administrative Procedure Act of 1946.\n\nFor example, the National Labor Relations Board issues relatively few regulations, but instead promulgates most of its substantive rules through common law (connotation 1).\n\nThe law of India, Pakistan, and Bangladesh are largely based on English common law because of the long period of British colonial influence during the period of the British Raj.\n\nAncient India represented a distinct tradition of law, and had an historically independent school of legal theory and practice. The \"Arthashastra\", dating from 400 BCE and the \"Manusmriti\", from 100 CE, were influential treatises in India, texts that were considered authoritative legal guidance. Manu's central philosophy was tolerance and pluralism, and was cited across Southeast Asia. Early in this period, which finally culminated in the creation of the Gupta Empire, relations with ancient Greece and Rome were not infrequent. The appearance of similar fundamental institutions of international law in various parts of the world show that they are inherent in international society, irrespective of culture and tradition. Inter-State relations in the pre-Islamic period resulted in clear-cut rules of warfare of a high humanitarian standard, in rules of neutrality, of treaty law, of customary law embodied in religious charters, in exchange of embassies of a temporary or semi-permanent character.\n\nWhen India became part of the British Empire, there was a break in tradition, and Hindu and Islamic law were supplanted by the common law. After the failed rebellion against the British in 1857, the British Parliament took over control of India from the British East India Company, and British India came under the direct rule of the Crown. The British Parliament passed the Government of India Act of 1858 to this effect, which set up the structure of British government in India. It established in Britain the office of the Secretary of State for India through whom the Parliament would exercise its rule, along with a Council of India to aid him. It also established the office of the Governor-General of India along with an Executive Council in India, which consisted of high officials of the British Government. As a result, the present judicial system of the country derives largely from the British system and has little correlation to the institutions of the pre-British era.\n\nPost-partition, India retained its common law system. Much of contemporary Indian law shows substantial European and American influence. Legislation first introduced by the British is still in effect in modified form today. During the drafting of the Indian Constitution, laws from Ireland, the United States, Britain, and France were all synthesized to produce a refined set of Indian laws. Indian laws also adhere to the United Nations guidelines on human rights law and environmental law. Certain international trade laws, such as those on intellectual property, are also enforced in India.\n\nThe exception to this rule is in the state of Goa, annexed in stages in the 1960s through 1980s. In Goa, a Portuguese uniform civil code is in place, in which all religions have a common law regarding marriages, divorces and adoption.\n\nPost-partition, Pakistan retained its common law system.\n\nPost-partition, Bangladesh retained its common law system.\n\nCanada has separate federal and provincial legal systems. The division of jurisdiction between the federal and provincial Parliaments is specified in the Canadian constitution.\n\nEach province and territory is considered a separate jurisdiction with respect to common law matters. As such, only the provincial legislature may enact legislation to amend private law. Each has its own procedural law, statutorily created provincial courts and superior trial courts with inherent jurisdiction culminating in the Court of Appeal of the province. This is the highest court in provincial jurisdiction, only subject to the Supreme Court of Canada in terms of appeal of their decisions. All but one of the provinces of Canada use a common law system (the exception being Quebec, which uses a French-heritage civil law system for issues arising within provincial jurisdiction, such as property ownership and contracts).\n\nCanadian Federal Courts operate under a separate system throughout Canada and deal with narrower subject matter than superior courts in provincial jurisdiction. They hear cases reserved for federal jurisdiction by the Canadian constitution, such as immigration, intellectual property, judicial review of federal government decisions, and admiralty. The Federal Court of Appeal is the appellate level court in federal jurisdiction and hears cases in multiple cities, and unlike the United States, the Canadian Federal Court of Appeal is not divided into appellate circuits.\n\nCriminal law is uniform throughout Canada. It is based on the constitution and federal statutory Criminal Code, as interpreted by the Supreme Court of Canada. The administration of justice and enforcement of the criminal code are the responsibilities of the provinces.\n\nCanadian federal statutes must use the terminology of both the common law and civil law for those matters; this is referred to as legislative bijuralism.\n\nNicaragua's legal system is also a mixture of the English Common Law and Civil Law. This situation was brought through the influence of British administration of the Eastern half of the Mosquito Coast from the mid-17th century until about 1894, the William Walker period from about 1855 through 1857, USA interventions/occupations during the period from 1909 to 1933, the influence of USA institutions during the Somoza family administrations (1933 through 1979) and the considerable importation between 1979 and the present of USA culture and institutions.\n\nIsrael has a common law legal system. Its basic principles are inherited from the law of the British Mandate of Palestine and thus resemble those of British and American law, namely: the role of courts in creating the body of law and the authority of the supreme court in reviewing and if necessary overturning legislative and executive decisions, as well as employing the adversarial system. One of the primary reasons that the Israeli constitution remains unwritten is the fear by whatever party holds power that creating a written constitution, combined with the common-law elements, would severely limit the powers of the Knesset (which, following the doctrine of parliamentary sovereignty, holds near-unlimited power).\n\nRoman Dutch Common law is a bijuridical or mixed system of law similar to the common law system in Scotland and Louisiana. Roman Dutch common law jurisdictions include South Africa, Botswana, Lesotho, Namibia, Swaziland, Sri-Lanka and Zimbabwe. Many of these jurisdictions recognise customary law, and in some, such as South Africa the Constitution requires that the common law be developed in accordance with the Bill of Rights. Roman Dutch common law is a development of Roman Dutch law by courts in the Roman Dutch common law jurisdictions. During the Napoleonic wars the Kingdom of the Netherlands adopted the French \"code civil\" in 1809, however the Dutch colonies in the Cape of Good Hope and Sri Lanka, at the time called Ceylon, were seized by the British to prevent them being used as bases by the French Navy. The system was developed by the courts and spread with the expansion of British colonies in Southern Africa. Roman Dutch common law relies on legal principles set out in Roman law sources such as Justinian's Institutes and Digest, and also on the writing of Dutch jurists of the 17th century such as Grotius and Voet. In practice, the majority of decisions rely on recent precedent.\n\nGhana follows the English common-law tradition which was inherited from the British during her colonisation. Consequently, the laws of Ghana are, for the most part, a modified version of imported law that is continuously adapting to changing socio-economic and political realities of the country. The Bond of 184 4 was the first most important event in the history of Ghana (then Gold Coast) that marked the critical period when the people ceded their independence to the British and gave the British judicial authority. Later, the Supreme Court Ordinance of 1876 “formally” introduced British law, be it the common law or statutory law, in the Gold Coast. Section 14 of the Ordinance formalised the application of the common-law tradition in the country.\n\nGhana, after independence, did not do away with the common law system inherited from the British, and today it has been enshrined in the 1992 Constitution of the country. Chapter four of Ghana's Constitution, entitled “The Laws of Ghana”, has in Article 11(1) the list of laws applicable in the state. This comprises (a) the Constitution; (b) enactments made by or under the authority of the Parliament established by the Constitution; (c) any Orders, Rules and Regulations made by any person or authority under a power conferred by the Constitution; (d) the existing law; and (e) the common law. Thus, the modern-day Constitution of Ghana, like those before it, embraced the English common law by entrenching it in its provisions. The doctrine of judicial precedence which is based on the principle of \"stare decisis\" as applied in England and other pure common law countries also applies in Ghana.\n\nEdward Coke, a 17th-century Lord Chief Justice of the English Court of Common Pleas and a Member of Parliament, wrote several legal texts that collected and integrated centuries of case law. Lawyers in both England and America learned the law from his \"Institutes\" and \"Reports\" until the end of the 18th century. His works are still cited by common law courts around the world.\n\nThe next definitive historical treatise on the common law is \"Commentaries on the Laws of England\", written by Sir William Blackstone and first published in 1765–1769. Since 1979, a facsimile edition of that first edition has been available in four paper-bound volumes. Today it has been superseded in the English part of the United Kingdom by Halsbury's Laws of England that covers both common and statutory English law.\n\nWhile he was still on the Massachusetts Supreme Judicial Court, and before being named to the U.S. Supreme Court, Justice Oliver Wendell Holmes, Jr. published a short volume called \"The Common Law\", which remains a classic in the field. Unlike Blackstone and the Restatements, Holmes' book only briefly discusses what the law \"is\"; rather, Holmes describes the common law \"process\". Law professor John Chipman Gray's \"The Nature and Sources of the Law\", an examination and survey of the common law, is also still commonly read in U.S. law schools.\n\nIn the United States, Restatements of various subject matter areas (Contracts, Torts, Judgments, and so on.), edited by the American Law Institute, collect the common law for the area. The ALI Restatements are often cited by American courts and lawyers for propositions of uncodified common law, and are considered highly persuasive authority, just below binding precedential decisions. The Corpus Juris Secundum is an encyclopedia whose main content is a compendium of the common law and its variations throughout the various state jurisdictions.\n\nScots \"common law\" covers matters including murder and theft, and has sources in custom, in legal writings and previous court decisions. The legal writings used are called \"Institutional Texts\" and come mostly from the 17th, 18th and 19th centuries. Examples include Craig, \"Jus Feudale\" (1655) and Stair, \"The Institutions of the Law of Scotland\" (1681).\n\n\n\n\n\n\n\n\n\n"}
{"id": "15319199", "url": "https://en.wikipedia.org/wiki?curid=15319199", "title": "Conscious automatism", "text": "Conscious automatism\n\nConscious automatism (C.A.) is a position on the philosophic question that asks whether determinism, as distinguished from “free will”, can be considered the sole operant principle in human decision making.\n\nConscious automatism holds that we human beings, like the other animals we generally consider our inferiors, are conscious but respond as automata to our prior conditioning (within our physiological powers and limitations) in all of our apparently “willed” decisions. According to this view, the “freedom” we exercise in decision making, a uniqueness that convention leads us to believe distinguishes us from the other mammals, is illusory, for our motives are all, without exception, caused, in the manner we concede that all other changes are causally initiated in the world around us.\n\nThus in epistemology C.A. is the logical conclusion of a strictly determinist explanation of human conduct and denies that our decision making is free in any sense from causal determinants. Conscious automatism, in refusing the compromise long in vogue among philosophers between freedom and determinism, has as its most disturbing corollary the abandonment of ethicists’ traditional reliance upon the notion of moral responsibility as the foundation of most moral systems and criminal justice institutions. It is, therefore, one of the most iconoclastic principles adduced in the history of moral philosophy as well, having profound practical societal consequences if widely accepted.\n\nThe term was recently given significant new substance in the book \"Grandest Illusion: The Seductive Myth of Free Will\", by Norman Haughness, which states forcefully the case for acknowledging the power of exceptionless determinism in human behavior. In Grandest Illusion the arguments claiming that the human will is free in any or all cases from total dependence on causal antecedents are analyzed and criticized in an overtly partisan effort to reveal the flaws in their coherence and logical validity. This in contrast to most recent literature in the field, well-exemplified by \"The Oxford Handbook of Free Will\", edited by Robert Kane, whose contributors without exception take positions supporting voluntarism or maintaining agnostic reservations.\n\nHaughness contends that freedom of willing is no more than a faith, which he calls “voluntarism“. He claims that, despite having little empirical basis except in unexamined intuition, free will has been accommodated and, indeed, vigorously defended by philosophers in large part because its abandonment is emotively an extremely repellent notion, suggesting loss of personal autonomy to nearly all who contemplate it. Equally intolerable to many is the fear that, without it, moral responsibility would lose its customarily revered place in society and moral chaos would thereupon necessarily ensue. This problem he addresses only briefly, urging that it is only by changing prior conditioning that conduct can be made conducive to decriminalizing society rather than, as at present, by reliance on ethical norms that are simply not present or are defective in most offenders.\n\nThe term “conscious automata” was employed as long ago as 1874, by Thomas H. Huxley in a famous address he delivered in Belfast titled \"On the Hypothesis that Animals are Automata, and Its History\". But Huxley’s version of conscious automatism was a compromise. He acknowledged the validity of David Hume’s attack on the popular but illusory notion of a causal nexus, extending it to a firm denial that laws of nature state what “must” occur (admitting only that they state what “will” occur, a distinction that has remained unclear to many). Huxley saw this as an opening to deny that there exist any sort of “iron laws” that necessitate human conduct. He believed in such abstractions as “spirit” and insisted that we possess enough “freedom” to “do our duty” and “do as we like,” obvious exceptions to a thoroughgoing determinist view of human motivation. Thus, at bottom he supported only a conscious semi-automatism similar to the ambiguous views of most contemporary philosophers.\n\n"}
{"id": "4655806", "url": "https://en.wikipedia.org/wiki?curid=4655806", "title": "Contingency management", "text": "Contingency management\n\nContingency management (CM) is most-widely used in the field of substance abuse, often implemented as part of clinical behavior analysis. CM refers to the application of the three-term contingency (or operant conditioning), which uses stimulus control and positive reinforcement to change behavior. Patients' behaviors are rewarded (or, less often, punished); generally, adherence to or failure to adhere to program rules and regulations or their treatment plan. CM derives from the science of applied behavior analysis (ABA), and by most evaluations, its procedures produces one of the largest effect sizes out of all mental health and educational interventions.\n\nOne form of contingency management is the token economy system. Token systems can be used in an individual or group format. Token systems have been shown to be successful with a diverse array of populations including those suffering from addiction, those with special needs, and delinquents. However, recent research questions the use of token systems with very young children. The exception to the last would be the treatment of stuttering. The goal of such systems is to gradually thin out and to help the person begin to access the natural community of reinforcement (the reinforcement typically received in the world for performing the behavior).\n\nWalker (1990) presents an overview of token systems and combining such procedures with other interventions in the classroom. He relates the comprehensiveness of token systems to the child's level of difficulty.\n\nAnother form of contingency management is voucher programs. In voucher-based contingency management patients earn vouchers exchangeable for retail items contingent upon objectively verified abstinence from recent drug use or compliance with other behavior-change targets. This particular form of contingency management was introduced in the early 1990s as a treatment for cocaine dependence. The approach is the most reliably effective method for producing cocaine abstinence in controlled clinical trials.\n\nMedication take-home privileges is another form of contingency management frequently used in methadone maintenance treatment. Patients are permitted to \"earn\" take-home doses of their methadone in exchange for increasing, decreasing, or ceasing certain behaviors. For example, a patient may be given one take-home dose per week after submitting negative drug screens (generally via urine testing) for three months. (It is worth noting that take home-doses (or \"bottles\") are seen as desirable rewards because they allow patients to come to the clinic less often to obtain their medication).\n\nBased in applied behavior analysis (ABA), contingency management includes techniques such as choice, shaping, time-out, making contracts between the therapist and patient, and token economy.\n\nContingent vouchers are also used to cease smoking addictions. One study claims that addicts with substance use disorders can receive help with their addiction through the use of voucher-based treatment for smoking. In addition, nicotine replacement (NRT) can help with addiction combined with the vouchers.\n\nLevel systems are often employed as a form of contingency management system. Level systems are designed such that once one level is achieved, then the person earns all the privileges for that level and the levels lower than it.\n\nA meta-analysis of contingency management in drug programs showed that it has a large effect. These contingencies are delivered based on abstinence and attendance goals and can take the form of vouchers, the opportunity to win prizes, or privileges. They have been used with single problem addictions as well as dual diagnoses and homeless. Overall contingency management has been found to be an effective and cost efficient addition to drug treatment.\n\nIn contrast to these findings in a recent study, the researchers found out that Nicotine replacement treatment only improved the effects of contingent vouchers on short-term smoking abstinence. However, in the long term the effects of contingent vouchers had no impact on tobacco resistance.\n\nMany organizations exists for board certified behavior analysts using contingency management around the world.\n\n"}
{"id": "23226143", "url": "https://en.wikipedia.org/wiki?curid=23226143", "title": "Cotton made in Africa", "text": "Cotton made in Africa\n\nCotton made in Africa is a project initiative launched and managed by the Aid by Trade Foundation (AbTF), headquartered in Hamburg. AbTF was founded in 2005 by Dr. Michael Otto, the Hamburg business entrepreneur and Chairman of Otto Group. Cotton marketed under the badge is produced according to strict criteria for environmental, economic and social sustainability.\n\n'Helping people to help themselves' is a core CmiA principle. The smallholder farmers receive on-site training in improved cultivation methods which allow them to increase their crop yields, generate higher income and thus raise their standard of living through their own efforts. CmiA plans to finance training over the long term through financial contributions from participating cotton trading companies, as well as through levying CmiA licence fees. Strictly speaking, CmiA is not organic cotton but places a strong emphasis on reducing the use of pesticides. However, pesticides listed under the Stockholm Convention are banned, as non-degradable or partially degradable organic toxins, so-called POPs.\n\nCmiA Project countries include the West African states of Benin and Burkina Faso as well as Zambia - and since April 2008, also Mozambique. These four countries are amongst the poorest on the planet. The Project reaches around 130,000 smallholder farmers in these regions and their efforts produce some 85,000 tonnes of raw CmiA cotton from a cultivation area of some 160.000 hectares.\n\nIn on-site training the African smallholder farmers learn about efficient methods of cultivation and how best to conserve precious resources. These skills help them increase their crops’ yield and quality through their own efforts. This qualification approach is aimed at helping the smallholder farmers find their own way out of the poverty trap in the long term, through targeting a significant improvement in the farmers’ income. And the results of initial studies show that the Project is having a beneficial effect: in Zambia, for instance, the crop yields of some groups of farmers have more than doubled, while in Benin the quality of the cotton has been substantially improved after only two planting seasons.\n\nIn its detailed implementation of the Project, the Foundation works closely with its partners and specialists on site in the Project areas. Besides the German Federal Ministry for Economic Cooperation and Development (BMZ), CmiA is also supported by the Bill & Melinda Gates Foundation, while the DEG, GTZ as well as the cotton traders Dunavant, ICA Talon and Faso Coton also participate in the Project. Further stakeholders supporting CmiA in an advisory capacity are Accenture, Avery Dennison, German Agro Action, German Nature and Biodiversity Conservation Union (NABU), McCann Erickson and the World Wide Fund For Nature. With the signature of a partnership agreement in December 2008 between the DEG and the Bill & Melinda Gates Foundation for the support of the cotton sector in sub-saharan Africa, CmiA gained a further valuable partner and sponsor to help finance the roll-out of the Project to other West African countries.\n\nIn-field cotton production, transport, ginning and storage of the raw cotton are all evaluated within the framework of an independent verification process based on a filter and traffic-light system. The structure and content of the CmiA verification system was prepared by the Dutch University of Wageningen and subsequently further developed by the consultancy PriceWaterhouseCoopers, in close co-operation with central Aid by Trade Foundation stakeholders. The core of the verification system contains a filter based on a series of exclusion criteria, as well as a group of sustainability indicators. The exclusion criteria include the most abusive forms of child labour, slavery, forced labour and infringement of freedom of association (union membership). The sustainability indicators include soil and water protection practices such as crop rotation and soil refertilisation as well as the responsible use of pesticides.\n\nAs a pragmatic, market-orientated approach, the economic feasibility of Cotton made in Africa is not dependent on charity but on activating market forces. This means that expenses such as premium payments to the farmers, which ultimately add to the cost of the raw product, do not arise. CmiA-produced raw cotton is traded at market prices; in this regard the AbTF does not act as a cotton trader but rather as Project developer and holds the marketing rights to CmiA. As distribution partners, the members of the Demand Alliance pay a licence fee which is then reinvested in the Project countries.\n\nCmiA targets the mass market for cotton goods, and the Demand Alliance of international textile companies is a decisive factor in the Project initiative’s success. These companies take up CmiA cotton for the production of their own goods and through this demand create a pull effect which runs right along the textile chain to reach the smallholder farmers in Africa. Demand Alliance members include Anson's, Celio, Otto Group, Peek & Cloppenburg, PUMA, QVC, Tchibo, Tom Tailor, s.Oliver and 1888 Mills, LLC.\n\nCotton made in Africa is used in the fashion and home textiles segments and all articles using CmiA are distinguished by a red label. CmiA is an ingredient brand: this means that it is not a product brand, but rather a brand for African cotton which is used as a raw material in branded products. CmiA thus defines itself as a Quality Seal and appears besides an already existing brand. It is also applied by branded product suppliers as an ‘extra quality mark’ to distinguish and differentiate their respective product.\n\nA 2008 survey of German consumers, commissioned by Accenture and carried out by market research institute Forsa, confirms the validity of the business model and development approach of initiatives such as Fairtrade or CmiA and organic products. Results show that 85 percent of German consumers are willing to pay more for clothing that can be proven to have been produced under environmentally sustainable and ethical working conditions. According to the survey, the significance of the topic of sustainability in consumer behaviour is also growing: a quarter of consumers surveyed stated they were willing to pay over 20 percent more for clothing produced under sustainable conditions, although one in three respondees stated they planned to reduce their clothing expenditure. A clear consequence of these developments is that companies which ignore the trend towards sustainability are very likely to lose customers. 77 percent of Germans stated that they would buy less or even no products from their preferred supplier, if it could not prove that these had been produced under sustainable conditions.\n\n"}
{"id": "26064582", "url": "https://en.wikipedia.org/wiki?curid=26064582", "title": "DYNAMO (programming language)", "text": "DYNAMO (programming language)\n\nDYNAMO (DYNAmic MOdels) is an historically important simulation language and accompanying graphical notation developed within the system dynamics analytical framework. It was originally for industrial dynamics but was soon extended to other applications, including population and resource studies\nand urban planning.\n\nDYNAMO was initially developed under the direction of Jay Wright Forrester in the late 1950s, by Dr. Phyllis Fox,\nAlexander L. Pugh III, Grace Duren,\nand others\nat the M.I.T. Computation Center.\n\nDYNAMO was used for the system dynamics simulations of global resource-depletion reported in the Club of Rome's Limits to Growth, but has since fallen into disuse.\n\nIn 1958, Forrester unwittingly instigated DYNAMO's development when he asked an MIT staff programmer to compute needed solutions to some equations, for a Harvard Business Review paper he was writing about industrial dynamics.\nThe programmer, Richard Bennett, chose to implement a system (SIMPLE - \"Simulation of Industrial Management Problems with Lots of Equations\") that took coded equations as symbolic input and computed solutions. SIMPLE became the proof-of-concept for DYNAMO: rather than have a specialist programmer \"hard-code\" a special-purpose solver in a general purpose programming language, users could specify a system's equations in a special simulation language and get simulation output from one program execution.\n\nDYNAMO was designed to emphasize the following:\n\n\nAmong the ways in which DYNAMO was above the standard of the time, it featured units checking of numerical types and relatively clear error messages.\n\nThe earliest versions were written in assembly language for the IBM 704, then for the IBM 709 and IBM 7090. DYNAMO II was written in AED-0, an extended version of Algol 60.\nDynamo II/F, in 1971, generated portable FORTRAN code\nand both Dynamo II/F and Dynamo III improved the system's portability by being written in FORTRAN.\n\nOriginally designed for batch processing on mainframe computers, it was made available on minicomputers in the late 1970s,\nand became available as \"micro-Dynamo\" on personal computers in the early 1980s.\nThe language went through several revisions from DYNAMO II up to DYNAMO IV in 1983,\n\nApart from its (indirectly felt) public impact in environmental issues raised by the controversy over \"Limits to Growth\", DYNAMO was influential in the history of discrete-event simulation even though it was essentially a package for continuous simulation specified through difference equations. It has been said by some to have opened opportunities for computer modelling even for users of relatively low mathematical sophistication. On the other hand, it has also been criticized as weak precisely where mathematical sophistication should be required and for relying only on Euler integration.\n\n\n"}
{"id": "3149897", "url": "https://en.wikipedia.org/wiki?curid=3149897", "title": "Deviation analysis", "text": "Deviation analysis\n\nDeviation analysis may mean;\n\n"}
{"id": "18483349", "url": "https://en.wikipedia.org/wiki?curid=18483349", "title": "Diligence", "text": "Diligence\n\nDiligence is one of the seven heavenly virtues. Diligent behavior is indicative of a work ethic; a belief that work is good in itself. Diligence is carefulness and persistent effort or work. \n\nBernard et al. suggest diligence in a student is defined as an effort he or she puts towards balanced and holistic development in mental, physical, social and spiritual dimensions. They find diligence in students is correlated with academic performance. This is especially found in younger students. The support of parents and educators encourages students to be diligent. Other factors which encourage diligence in students include motivation, discipline, concentration, responsibility and devotedness.\n\nThe last words of the Buddha were \"Strive on with diligence.\" Diligence is an integral part of all Buddhist teaching, and is considered the fourth of the pāramitā. In Mahayana tradition diligence is the third pāramitā and the first which is said to lead to liberation. The practice of diligence will bring an increase of qualities.\n\nDiligence, in Christianity, is the effort to do one's part, while keeping faith and reliance in God. In other words, diligence and faith are two sides of a mystery. One doesn’t know how, despite one's effort, it all works out. But diligence when combined with faith assures spiritual success. Diligence as one of seven virtues describes thoroughness, completeness and persistence of an action, particularly in matters of faith.\n\nAccording to Brian Hatcher, the precepts of Hinduism require a human being to discover and live a \"dharmic\" life. To live a \"dharmic\" life, one must live with right intention with diligence, and with concern for well being of others. The Hindus celebrate Diwali, a festival of lights, where Goddess Lakshmi (also called Goddess Sri) is worshipped; the goddess symbolizes thorough preparation, being organized, diligent and honest. These characteristics are considered by Hindus as essential for success and Shubh Labh (ethical profit).\n\nDue diligence is the necessary amount of diligence required in a professional activity to avoid being negligent. This commonly arises in major acquisitions where the legal principle of caveat emptor (\"let the buyer beware\") requires the purchaser to make a diligent survey of the property or service being sold. \n\n"}
{"id": "1983769", "url": "https://en.wikipedia.org/wiki?curid=1983769", "title": "F-coalgebra", "text": "F-coalgebra\n\nIn mathematics, specifically in category theory, an formula_1-coalgebra is a structure defined according to a functor formula_1. For both algebra and coalgebra, a functor is a convenient and general way of organizing a signature. This has applications in computer science: examples of coalgebras include lazy, infinite data structures, such as streams, and also transition systems.\n\nformula_1-coalgebras are dual to formula_1-algebras. Just as the class of all algebras for a given signature and equational theory form a variety, so does the class of all formula_1-coalgebras satisfying a given equational theory form a covariety, where the signature is given by formula_1.\n\nLet \n\nbe an endofunctor on a category formula_8.\nAn formula_1-coalgebra is an object formula_10 of formula_8 together with a morphism \n\nof formula_8, usually written as formula_14.\n\nAn formula_1-coalgebra homomorphism from formula_14 to another formula_1-coalgebra\nformula_18 is a morphism \n\nin formula_8 such that \n\nThus the formula_1-coalgebras for a given functor \"F\" constitute a category.\n\nThe set of conatural numbers formula_23 consisting of the nonnegative integers and also infinity when equipped with the function formula_24 given by formula_25, formula_26 for formula_27 and formula_28 is a coalgebra of the endofunctor formula_29 that sends a set to its disjoint union with the singleton set formula_30. In fact, formula_31 is the terminal coalgebra of this endofunctor.\n\nMore generally, fix some set formula_10, and consider the functor formula_33 that sends formula_34 to formula_35. Then an formula_1-coalgebra formula_37 is a finite or infinite stream over the alphabet where formula_34 is the set of states and formula_39 is the state-transition function. Applying the state-transition function to a state may yield two possible results: either an element of formula_10 together with the next state of the stream, or the element of the singleton set formula_41 as a separate \"final state\" indicating that there are no more values in the stream.\n\nIn many practical applications, the state-transition function of such a coalgebraic object may be of the form formula_42, which readily factorizes into a collection of \"selectors\", \"observers\", \"methods\" formula_43. Special cases of practical interest include observers yielding attribute values, and mutator methods of the form formula_44 taking additional parameters and yielding states. This decomposition is dual to the decomposition of initial formula_1-algebras into sums of 'constructors'.\n\nLet \"P\" be the power set construction on the category of sets, considered as a covariant functor. The \"P\"-coalgebras are in bijective correspondence with sets with a binary relation. \nNow fix another set, \"A\". Then coalgebras for the endofunctor \"P\"(\"A\"×(-)) are in bijective correspondence with labelled transition systems, and homomorphisms between coalgebras correspond to functional bisimulations between labelled transition systems.\n\nIn computer science, coalgebra has emerged as a convenient and suitably general way of specifying the behaviour of systems and data structures that are potentially infinite, for example classes in object-oriented programming, streams and transition systems. While algebraic specification deals with functional behaviour, typically using inductive datatypes generated by constructors, coalgebraic specification is concerned with behaviour modelled by coinductive process types that are observable by selectors, much in the spirit of automata theory. An important role is played here by final coalgebras, which are complete sets of possibly infinite behaviours, such as streams. The natural logic to express properties of such systems is coalgebraic modal logic.\n\n\n\n"}
{"id": "14174684", "url": "https://en.wikipedia.org/wiki?curid=14174684", "title": "Family honor", "text": "Family honor\n\nFamily honor (or honour) is an abstract concept involving the perceived quality of worthiness and respectability that affects the social standing and the self-evaluation of a group of related people, both corporately and individually. The family is viewed as the main source of honor and the community highly values the relationship between honor and the family. The conduct of family members reflects upon family honor and the way the family perceives itself, and is perceived by others. Family honor can be dependent upon many factors and areas that are affected by family honor include multiple aspects of lifestyle such as social status, religion, clothing, eating, education, job or career, ownership such as real estate, and marriage.\n\nPeople who live in cultures of honor, perceive family as the central institution in their society and a person's social identity depends largely on their family. Therefore, it is important for these individuals to fulfill expectations of family and society in order to be accepted by their family and experience feelings of belonging to this central institution that they are tied to through birth or marriage. In some cultures, maintaining family honor is perceived as more important than either individual freedom, or individual achievement.\n\nThe ideology and practice of family honor varies from country to country. Individuals of certain cultures are often unaware or discerning in their understanding of differing cultural traditions. Many fail to grasp the concept of honor as the basis for traditions such as defending one's honor or their family's. Some cultures value family honor more than others. Many times a family's honor may overpower the actions or beliefs of the individual. However, a theme that is common within many traditions is the respecting of elders. Children of the family are to respect their elders who have earned what some call a \"badge of 'honor'\" representative of their age. Once an individual has lived throughout life for several years, they have earned this badge of honor and should be shown respect teaching their young the cultural traditions that have deemed them honorable.\nAn individual is considered as honorable based on his/her behaviors and characteristics he or she displays that the society deems to be worthy of honor. In addition, honor also entails the aspect of how high of a position an individual holds in relation to the group and how much he or she is respected by others.\n\nOne of the ideals of family honor is social class. Social class can be defined as a group of people categorized into a hierarchy based on the amount of money they have accumulated, how much education they have received, and the amount of power they hold within society, amongst other variables. People who play similar roles within society tend to have similar outlooks. Social standing affects the way in which families form. It determines how and who a person mates with, how they raise their children, and how people relate to one another.\n\nHistorically, honor is a quality ascribed to an individual in two ways: either by obtaining it through his or her birth into an honorable family or being assigned as honorable by powerful people who hold higher status in the society. An individual's parental lineage, is the traditional source for his or her honor. Because honor is passed through paternal lineage in most patrilineal cultures, these societies historically considered having sons as a source of pride and honor. For example, in the Moroccan culture, it is still a preference among women to have sons instead of daughters. Morocco is a typical patrilineal society in which the son has a more important function for the family such as the son supports his parents once they have aged compared to the daughter who will marry into a different group becoming a loss to the family. In such societies men also hold more sexual rights compared to women besides the supportive role men obtain from caring for their aging parents. Females in these societies are perceived as threats to family honor.\n\nWithin cultures, honor is an important and highly esteemed theme. It can be maintained through living up to one's word and promises, providing for the family, and keeping a certain social status. Honor can be affected by both men and women through ways in which a man heightens his family's honorable status, and a woman can shame her family through disapproved actions. Ensuing constant pressure to uphold her family's honor, a woman can suffer psychological and social damage.\n\nThe different effects honor instills upon men and women can be seen in the ancient world, where women and men played contrasting roles in society. Men displayed their honorable roles in public while women were restricted to the limitations of their households. While in public, women were required to avoid conversations with estranged men while only visiting places frequented by women. In the present Islamic culture, men hold a higher social status, but they also carry more responsibility in caring and providing for their family. If a man is single or childless his place in society does not waver or become lower. A woman should have a family whom she stays faithful to and respectful towards at all times. A man's actions will not greatly affect or hurt his family's standing like a woman's actions would. Women are perceived as vulnerable individuals who must be kept safe at all times. This aspect of a woman's characterization comes from her fertility and role within her family.\n\nSocieties in which \"family honor\" is considered highly important generally place a correspondingly high degree of restriction of the freedom of women. In these cultures, a family may defend its honor, or may seek reparation or revenge if the family honor is perceived to have been abused or treated with disrespect. In Ancient Rome, sexual activity of married women outside of their marriage was seen as dishonor to the family and it was legal for men to kill their wives or married daughters that shamed the family through adultery. Reasoning for the designation of women to private and/or nonmale areas comes from the ancient tradition of a woman's place in the world. Women are not seen as independent individuals, but rather extensions of their male counterparts' identity and honor.\n\nBecause the approval of honor is dependent upon the recognition of others, during ancient times individuals worked hard for the approval of their peers within their societal cultures. This meant that individuals were more likely to behave like their honorable counterparts. Groups reinforced what it meant to be honorable through various expected behaviors and goals placed amongst individual members. This discouraged members from any negative activity that may have adversely affected a group or family's honor. In the event that the leader of the group promoted actions that did not appear to be honorable on a larger societal scale, the leader then offered some explanation defending their actions which lead to the preservation of what they defined as honor and their traditions forever.\n\nIn Ancient Rome, chastity and loyalty of members of a family was an important factor contributing to family honor in addition to social standing and accomplishments of that family. For example, if a married woman committed adultery, her father had the legal right to kill her whereas her husband was required to divorce her. If the husband chose not to divorce his wife, he would jeopardize his honor and be labeled as a pimp.\n\nIn some cultures with strong principles of family honor, offspring are not free to choose a partner for themselves but may instead be expected to enter into an arranged marriage or if the offspring resists, into a forced marriage or child marriage.\n\nThe use of violence may be collective in its character, where many relatives act together. Males and females in this type of honor culture may act as either persecutors and the oppressed, for instance a son in a family may be forced to enter into an arranged marriage by his older relatives while controlling his sisters.\n\nThe aspects of family honor mentioned above differ throughout varying cultures and countries. Family honor in the Bedouin and other Middle Eastern cultures consists of interdependent forms of ird and sharaf. Ird is the honor of a woman she is born with which involves her chastity and continence whereas sharaf is the honor code for men which depends on ird of women in the family. Due to its connection to ird, sharaf includes protecting ird of the family members. The adherence to these gender-specific honor codes is important to keep the respectability and sexual honors of the family, particularly men, known as namus. For example, the sexual relationships of a girl are seen in these societies to make her impure and of lesser value, which affects her eligibility for marriage. Public knowledge and gossip about sexual impurity or adultery are proposed to be the main reasons that loss of family honor can bring shame to the family. Preservation of family honor is not only important for respectability of family members in society but also affects the fate of all family members. To protect family honor and dignity, families may resort in killing the woman who is involved in the dishonorable act. In an associated context, to protect the purity and chastity of young girls, families may decide to practice female genital mutilation, a practice that removes or damages female genital organs to assure that sex will not be pleasurable. A mutilated woman is changed so that she has no desire to engage in sexual activity that may undermine the family's honor.\n\nAn example of this can be seen in Sierra Leone, Africa where young girls are mutilated every year. The number of girls mutilated in Africa per year has risen to 3 million. Rugiatu Turay, founder of the Amazonian Initiative Movement, protects young girls from being circumcised by other women in secret societies like Sande and other female practitioners who still engage in the ceremonial tradition today. Girls as young as the age of five assist in the mutilation of other young girls in the country. At the age of 12, Turay was snatched by female family members, held down and had her clitoris cut off with a knife. She was beaten, forced to walk, and had hot pepper water poured in her eyes. As she was mutilated, the women sang, danced, and clap ceremoniously. According to these women, Turay had become a woman. However, females are generally mutilated under the age of 15. Girls who are trained to assist in this ceremony are trained as young as five years old. Turay has convinced 400 practitioners to stop the practice of female mutilation, but 97 million females have been mutilated within the country and the numbers remain constant, even increasing. The practice has been enforced by politicians within the country and locals refer to the practice as a ceremony that initiates womanhood, prepares females for marriage, and restricts their sexual conduct.\n\nFamily honor is a highly valued concept known as namus in Turkey and it is linked to female modesty, chastity, and family reputation among other families, as well as loyalty.\n\nAn ideology of preserving family honor is deeply rooted is society and is not affected by high levels of education. Many women in Turkey are well educated but still are expected to be modest and sexually pure in order to preserve the honor of their families. If a family's honor is breached, it brings shame to the entire family. In such cases, traditionally the family would decide the fate of the female that brought shame. This might involve forcing the young woman into a shotgun wedding, while in extreme cases a young male in the family was given the duty to cleanse the family name through an honor killing. With recent changes to criminal law that removed reduced sentences for honor killings, females that brought shame to the family are sometimes forced to commit honor suicides by their families, especially in the predominantly Kurdish South-East regions, a region that greatly values traditions. Families who do not want their sons to face possible incrimination have encouraged their daughters to commit suicide. The number of female suicides over the years has increased greatly. Stories have surfaced revealing girls who are given tools with which to kill themselves such as rope to hang themselves, poisons to drink, or a gun to shoot themselves. Some murders have also been disguised as suicides in order to protect family members. Female family members are not the only ones that may be punished to preserve family honor. It is proposed that the death of a male homosexual physics student, Ahmet Yildiz, was an honor killing.\n\nMembers of the Republican People Party have stated that in the six months preceding Hatice Firat's death a woman had been killed every day because of domestic violence.\n\nSimilar to the South African and Turkish culture, family is a central value for Asian societies. Asian families are usually multi-generational, patriarchal and self-sufficient structures strongly bound to traditions. For instance, in India touching feet of relatives and elderly is a ritual to express respect and submission. However, family honor entails different components depending on the continental region. For example, family honor is strongly linked to female chastity in Afghanistan, Pakistan, and India in a similar fashion to Middle Eastern and Mediterranean societies. Whereas men threaten family honor by extreme actions such as murder and addiction, females may dishonor family by leaving the house too often or having unnecessary conversations with men. Sikh women need to be modest and reserved to be considered honorable; even rape is seen as a major insult to family honor. Cultures near the Middle East also consider involuntary sexual assaults dishonorable and shameful.\n\nContrastingly in other Asian cultures, especially for families in South Asia and the Far East, family honor depends on other factors such as education. Academic success of a student is seen as a source of pride and honor for the Asian family. Therefore, both the Asian student and the parents work hard to avoid academic failure which brings shame to the family. In the past, honor in East Asia was also linked to success in the battlefield. In Japan, for example, ritualized suicide practices such as harakiri were committed by Japanese samurai for centuries in the event of a defeat in battle. Instead of being captured or living with the shame of defeat, harakiri was committed in order to preserve the honor of their families.\n\nIn Europe, similar to traditional practices in South Africa, honor relates to different concepts depending on the geographic area; whereas honor is strongly linked to family reputation in the Mediterranean countries, in Northern Europe it has a more individualized meaning that is focused on personal accomplishments and qualities. Similar to gender-specific family honor codes in the Middle East, Mediterranean nations also traditionally exhibit such codes; women are seen as honorable by their chastity whereas men are seen as honorable by their productivity, toughness, and by protecting the honor of the women. In Italy, infidelity of women was seen dishonorable, thus crimes of passion were classified as second-degree murders until the 1970s. Although Western and Northern European nations traditionally have a more individualistic approach to honor, there have been an increase in honor killings or crimes of passion within their borders by immigrant populations residing in these countries. The European culture also served as a basis for American traditions of honor as well.\n\nIn mainly Muslim Kosovo, the impact on family honor of admitting one has been raped, has discouraged some women from applying for compensation as victims of atrocities committed during the 1998-99 war with Serbia.\n\nIn Denmark, the migration authority published that 24% of immigrants of non-Western heritage and their offspring of ages 18-29 were limited in their choice of partner by their relatives. The report showed a higher incidence for women than men and in areas with high concentrations of migrants, 59% were limited in choice of partner. Of migrant women who lived in high-concentration areas, fewer of those in education or employment were limited. Of migrant women who live in areas with a low share of migrants, 22% were limited in partner choice. It was also shown that migrant youth are more limited if their social circles only comprises other migrants when it came to choosing a partner.\n\nIn 2018, an investigation into court cases involving domestic violence against children showed that 47% of the cases involved parents who were both born abroad. According to a researcher at Norwegian Police University College the over-representation was due to cultural (honor culture) and legal differences in Norway and foreign countries.\n\nThe Swedish National Police Board and the Swedish Prosecution Authority define honor related crime as crimes against a relative who, according to the perpetrator and his family's point of view has disohonoured the family honor. These crimes are intended to prevent the family honor being damaged or to restore damaged or lost family honor.\n\nThe most serious honor related crime is often organised and deliberate. Incidents include torture, forced suicides, forced marriages, rapes, kidnapping, assault, mortal threats, extortion and protecting a criminal.\n\nIn a 2009 study by the Swedish Agency for Youth and Civil Society (MUCF), about 70 000 individuals of ages 16-25 stated they could not freely choose whom to marry. The MUCF report is limited to people aged 16-25 and for instance excludes adult women who wish to divorce but are threatened with violence due to family honor. Women in such situations face a greater threat as they are persecuted by both their own extended family and that of the husband. Some women's shelters report that nearly all women who seek refuge with them are fleeing honor based violence. In 2012, the county administrative board of Östergötland got a mandate to coordinate efforts against honor culture-based violence and persecution.\n\nAccording to an investigation of 3000 cases by newspaper Göteborgsposten, the most common scenario are girls being supervised and banned from being outside the home after school hours, who are forced to wear an Islamic veil and girls risking a forced marriage. About 80% of the child victims have been physically abused, most frequently with bare hands but also being beaten with belts or cables. In several cases the children have been burned with kitchen utensils or metal objects.\n\nIn a 2018 interview, researcher Astrid Schlytter stated that polls had shown that a third of all girls with two foreign-born parents faced restrictions in school, are forbidden to have a boyfriend and must be a virgin when they marry and they are not allowed to choose whom they marry. Using patterns of behaviour observed in Denmark, Norway and the UK Schlytter estimated that there were 240 000youth suffer under an honour culture (Swedish: \"hedersförtryck\").\n\nIn the UK, honor crimes include forced marriage and female genital mutilation and honour based crimes disproportionally affect women from ethnic minorities. The number of honor crimes reported to police increased from 3335 in 2014 to 5595 in 2015, an increase of 68%, before a slight drop to 5105 in 2016. Figures published by the Crown Prosecution Service showed that 256 crimes were referred to the CPS by police in 2016-17, about 5% of the cases reported. Of the 256 referrals, 215 lead to prosecutions which resulted in 122 convictions.\n\nThe Old South took honor particularly seriously. Southerners in the Old South held themselves to their own sets of social codes. An affront to a Southerner's honor, if serious enough, was resolved by a duel. Dueling was originally a European custom, later adopted by the United States. Dueling was not technically legal in the United States, but it was difficult to enforce the laws written against it, especially in the Old South. Usually only men engaged in duels; their opponents were men they perceived to be equals. Public opinion for dueling varied: some thought it was a barbaric and backwards custom, while others believed it was a perfectly legitimate way of dealing with affronts to honor.\n\nLooking at the Hispanic community, similar to many of the countries mentioned above, elders are seen as wise and are to be shown respect from other family members. Family members turn to elders for help regularly, and when a family member falls ill wisdom on what should be done to care for the ill family member is searched for within the elders of the family.\n\nMen are the dominant figures within their households and embody a decisive, authoritative role. Contrary to popular belief, women hold as much weight within their homes as their husbands. They are the matriarchs of the family, and the family's health and stability relies on the mother. Although they need to be protected, women are cherished within their families as important figures. \nHispanic families strongly display their emotions towards one another. Family members show that they care and love one another through taking care of each other. They search for reinforcement and support within their own homes more often than they would in today's society. The Hispanic culture has what is called Curanderismo. This is a system in which families consult the help of a religious figure called a curandero who gives medical, psychological, and social advice. Families make offerings unto the curandero such as money, candle lighting, creating metal or wooden offerings (shaped in the form of the body part in need of healing), etc. \nMany families believe that all personal or familial issues should be kept within the home. The Hispanic culture values modesty for all individuals including males and children in addition to females who historically, are expected to behave in a modest fashion. Family members that suffer from mental illnesses are reluctant to inform their family members of this information in fear that their family members will criticize them.\n\nIn the aspect of childbirth, men are required to wait until after the mother has had birth and dressed in a decent manner to visit his wife and newborn child. Mothers typically accompany the new mother during birth. Much like the American culture, Hispanic women take time to rest after childbirth, but traditionally they returned to heavier labor jobs as opposed to jobs normally held by women within society.\n\nIn one country in particular Brazil, the community attempts to divide the upper-class families who are considered honorable from the lower-class families who are seen as a threat to society in Rio de Janeiro. The country defends family honor through the creation of different policies and laws, but this has caused great opposition. Politics has played a major in role in determining the status and meaning of what is considered to be honorable within Brazils’ society.\n\nIn the late 1800s Viveiros de Castro noted an increase in violations of female honor within Brazil at the turn of the century. Women were expanding their roles throughout society which many believed opened doors for women to be taken advantage of and seduced. Viveiros de Castro believed that women's working in factories was a threat to society and morality. Men believed that the new change in opinion amongst women contributed to this new susceptibility. Many men believed that women believed they were freer than they actually were, and because of this the actions of women led them to lose honor because of their lack of dependency on the male gender. The new century had changed the image of how women were historically perceived and portrayed. Certain individuals, a judge by the name of Nelson Hungria (quoted in Sueann Caulfield's book) specifically, labeled a woman's reserved role as the source of her honor which was lost once she branched out into society losing this reserved quality attributed to women. Because women chose to leave the traditional role of being the homemaker they lost the characterization of being innocent and some assumed they were engaging sexual activities.\n\nMichael Herzfeld, an anthropologist, argued that the idea of women losing their chastity derived from those who wished to explain a woman's new role within society. The idea of women expanding their roles outside of the home in society went against the ideas and morals that were upheld centuries before. In order to defend this morality, many highlighted the customs of the past as something that should have been continuously practiced and enforced even in a new modern era.\n\nMany women were subjected to sexual trials in which they were criticized for being dishonorable. Women during this time were similar to their ancestors. They engaged in practices such as sex before marriage, consenting to unions, and taking on the head role within their homes. However, these acts were perceived in an extremely contrasting manner during this period (after World War I). Because of this, many were uncertain of how they should approach the act of preserving sexual honor.\n\nTurning to a different aspect of society that intertwined itself with idea of honor, politics played a major role in defining honor within Brazil. The country attempted to define honor while displaying this view of honor along with the country's traditions to others around the world. In September 1920, King Albert and Queen Elisabeth made a trip to Brazil. This trip sparked major controversy from different parties in the country. Many believed the trip was an attempt to \"Europeanize\" the country. Some viewed the trip as a positive way to show off Brazil the country and its civilization. Others viewed the trip as a negative opportunity in which the culture would attempt to conform to European standards. In doing so, attempts by the upper class would be made to hide Brazil's struggle of poverty which was a main part of its society and culture at the time. With this trip the importance of honor intensified. Before the King and Queen arrived, preparing for the couple included exposing and exercising honor in a manner many believed would promote the division of social classes and international affairs. Those who were responsible for posing as advocates for their country concealed their social class under what was perceived as honorable and behaved as though they themselves were a part of an \"honorable\" class. One of the aspects they displayed were gender ideologies that played a crucial role in differentiating social classes from one another. Natives desired to portray the country the best way possible. In doing so, they defended their families’ traditions and morals and sexual honor.\n\nTowards the end of the 1930s, the definition of honor within Brazilian society has transformed completely. In result, in 1940, a penal code derived definitions of the term honor. Sexual crimes became a breaking of not family honor but \"social customs\". With the Vargas regime (Dictator Getúlio Vargas who ruled from 1937–1945), came a new form or definition of honor. Many attribute the change in the meaning of honor and a devaluing of its meaning to Vargas’ rule. Vargas attributed the aspect of authority to the meaning of honor. Vargas closely tied traditional Brazilian family honor with the aspect of the nation's honor. Through his regime, Vargas intended to create a hierarchy of social, authoritative classes. However, debates over class, and gender in relation to honor and the nation of Brazil continued to take place. Women continued to transform their traditional roles and these changes could not be neglected.\n\n"}
{"id": "16482552", "url": "https://en.wikipedia.org/wiki?curid=16482552", "title": "Flag-waving", "text": "Flag-waving\n\nFlag-waving is a fallacious argument or propaganda technique used to justify an action based on the undue connection to nationalism or patriotism or benefit for an idea, group or country. It is a variant of argumentum ad populum. This fallacy appeals to emotion instead to logic of the audience aiming to manipulate them to win an argument. All ad populum fallacies are based on the presumption that the recipients already have certain beliefs, biases, and prejudices about the issue. If flag-waving is based on connecting to some symbol of patriotism or nationalism it is a form of appeal to stirring symbols which can be based on undue connection not only to nationalism but also to some religious or cultural symbols. I.e. a politician appearing on TV with children, farmer, teacher, together with the “common” man, etc.\n\nThe act of flag-waving is trivial display of support or loyalty to the nation or to the political party.\n"}
{"id": "1488195", "url": "https://en.wikipedia.org/wiki?curid=1488195", "title": "Fundamental theorems of welfare economics", "text": "Fundamental theorems of welfare economics\n\nThere are two fundamental theorems of welfare economics. The First Theorem states that a market will tend toward a competitive equilibrium that is weakly Pareto optimal when the market maintains the following three attributes: \n\n1. Complete markets as no transaction costs and because of this each actor also has perfect information.\n\n2. Price-taking behavior as no monopolists and easy entry and exit from a market.\n\nFurthermore, the First Theorem states that the equilibrium will be fully Pareto optimal with the additional condition of:\n\n3. Local nonsatiation of preferences as for any original bundle of goods there is another bundle of goods arbitrarily close to the original bundle, but that is preferred.\n\nThe Second Theorem states that out of all possible Pareto optimal outcomes one can achieve any particular one by enacting a lump-sum wealth redistribution and then letting the market take over.\n\nThe First Theorem is often taken to be an analytical confirmation of Adam Smith's \"invisible hand\" hypothesis, namely that \"competitive markets tend toward an efficient allocation of resources\". The theorem supports a case for non-intervention in ideal conditions: let the markets do the work and the outcome will be Pareto efficient. However, Pareto efficiency is not necessarily the same thing as desirability; it merely indicates that no one can be made better off without someone being made worse off. There can be many possible Pareto efficient allocations of resources and not all of them may be equally desirable by society.\n\nThis appears to make the case that intervention has a legitimate place in policy – redistributions can allow us to select from all efficient outcomes for one that has other desired features, such as distributional equity. The shortcoming is that for the theorem to hold, the transfers have to be lump-sum and the government needs to have perfect information on individual consumers' tastes as well as the production possibilities of firms. An additional mathematical condition is that preferences and production technologies have to be convex.\n\nThe first fundamental theorem was first demonstrated graphically by economist Abba Lerner and mathematically by economists Harold Hotelling, Oskar Lange, Maurice Allais, Lionel McKenzie, Kenneth Arrow and Gérard Debreu. The theorem holds under general conditions.\n\nThe formal statement of the theorem is as follows: \"If preferences are locally nonsatiated, and if formula_1 is a price equilibrium with transfers, then the allocation formula_2is Pareto optimal.\" An equilibrium in this sense either relates to an exchange economy only or presupposes that firms are allocatively and productively efficient, which can be shown to follow from perfectly competitive factor and production markets.\n\nGiven a set formula_3 of types of goods we work in the real vector space over formula_3, formula_5 and use boldface for vector valued variables. For instance, if formula_6 then formula_5 would be a three dimensional vector space and the vector formula_8 would represent the bundle of goods containing one unit of butter, 2 units of cookies and 3 units of milk.\n\nSuppose that consumer \"i\" has wealth formula_9 such that formula_10 where formula_11 is the aggregate endowment of goods (i.e. the sum of all consumer and producer endowments) and formula_12 is the production of firm \"j\".\n\nPreference maximization (from the definition of price equilibrium with transfers) implies (using formula_13 to denote the preference relation for consumer \"i\"):\n\nIn other words, if a bundle of goods is strictly preferred to formula_16 it must be unaffordable at price formula_17. Local nonsatiation additionally implies:\n\nTo see why, imagine that formula_18 but formula_21. Then by local nonsatiation we could find formula_22 arbitrarily close to formula_23 (and so still affordable) but which is strictly preferred to formula_16. But formula_16 is the result of preference maximization, so this is a contradiction.\n\nAn allocation is a pair formula_26 where formula_27 and formula_28, i.e. formula_29 is the 'matrix' (allowing potentially infinite rows/columns) whose \"i\"th column is the bundle of goods allocated to consumer \"i\" and formula_30 is the 'matrix' whose \"j\"th column is the production of firm \"j\". We restrict our attention to feasible allocations which are those allocations in which no consumer sells or producer consumes goods which they lack, i.e.,for every good and every consumer that consumers initial endowment plus their net demand must be positive similarly for producers.\n\nNow consider an allocation formula_26 that Pareto dominates formula_32. This means that formula_18 for all \"i\" and formula_14 for some \"i\". By the above, we know formula_35 for all \"i\" and formula_36 for some \"i\". Summing, we find:\n\nBecause formula_38 is profit maximizing, we know formula_39, so formula_40. But goods must be conserved so formula_41. Hence, formula_26 is not feasible. Since all Pareto-dominating allocations are not feasible, formula_2 must itself be Pareto optimal.\n\nNote that while the fact that formula_38 is profit maximizing is simply assumed in the statement of the theorem the result is only useful/interesting to the extent such a profit maximizing allocation of production is possible. Fortunately, for any restriction of the production allocation formula_38 and price to a closed subset on which the marginal price is bounded away from 0, e.g., any reasonable choice of continuous functions to parameterize possible productions, such a maximum exists. This follows from the fact that the minimal marginal price and finite wealth limits the maximum feasible production (0 limits the minimum) and Tychonoff's theorem ensures the product of these compacts spaces is compact ensuring us a maximum of whatever continuous function we desire exists.\n\nThe Second Theorem formally states that, under the assumptions that every production set formula_46 is convex and every preference relation formula_47 is convex and locally nonsatiated, any desired Pareto-efficient allocation can be supported as a price \"quasi\"-equilibrium with transfers. Further assumptions are needed to prove this statement for price equilibria with transfers.\n\nThe proof proceeds in two steps: first, we prove that any Pareto-efficient allocation can be supported as a price quasi-equilibrium with transfers; then, we give conditions under which a price quasi-equilibrium is also a price equilibrium.\n\nLet us define a price quasi-equilibrium with transfers as an allocation formula_48, a price vector \"p\", and a vector of wealth levels \"w\" (achieved by lump-sum transfers) with formula_49 (where formula_50 is the aggregate endowment of goods and formula_51 is the production of firm \"j\") such that:\n\nThe only difference between this definition and the standard definition of a price equilibrium with transfers is in statement (\"ii\"). The inequality is weak here (formula_56) making it a price quasi-equilibrium. Later we will strengthen this to make a price equilibrium.\nDefine formula_62 to be the set of all consumption bundles strictly preferred to formula_58 by consumer \"i\", and let \"V\" be the sum of all formula_62. formula_62 is convex due to the convexity of the preference relation formula_47. \"V\" is convex because every formula_62 is convex. Similarly formula_68, the union of all production sets formula_69 plus the aggregate endowment, is convex because every formula_69 is convex. We also know that the intersection of \"V\" and formula_68 must be empty, because if it were not it would imply there existed a bundle that is strictly preferred to formula_48 by everyone and is also affordable. This is ruled out by the Pareto-optimality of formula_48.\n\nThese two convex, non-intersecting sets allow us to apply the separating hyperplane theorem. This theorem states that there exists a price vector formula_74 and a number \"r\" such that formula_75 for every formula_76 and formula_77 for every formula_78. In other words, there exists a price vector that defines a hyperplane that perfectly separates the two convex sets.\n\nNext we argue that if formula_79 for all \"i\" then formula_80. This is due to local nonsatiation: there must be a bundle formula_81 arbitrarily close to formula_57 that is strictly preferred to formula_58 and hence part of formula_62, so formula_85. Taking the limit as formula_86 does not change the weak inequality, so formula_80 as well. In other words, formula_57 is in the closure of \"V\".\n\nUsing this relation we see that for formula_58 itself formula_90. We also know that formula_91, so formula_92 as well. Combining these we find that formula_93. We can use this equation to show that formula_94 fits the definition of a price quasi-equilibrium with transfers.\n\nBecause formula_93 and formula_96 we know that for any firm j:\n\nwhich implies formula_52. Similarly we know:\n\nwhich implies formula_102. These two statements, along with the feasibility of the allocation at the Pareto optimum, satisfy the three conditions for a price quasi-equilibrium with transfers supported by wealth levels formula_103 for all \"i\".\n\nWe now turn to conditions under which a price quasi-equilibrium is also a price equilibrium, in other words, conditions under which the statement \"if formula_55 then formula_56\" imples \"if formula_55 then formula_107\". For this to be true we need now to assume that the consumption set formula_108 is convex and the preference relation formula_47 is continuous. Then, if there exists a consumption vector formula_81 such that formula_111 and formula_112, a price quasi-equilibrium is a price equilibrium.\n\nTo see why, assume to the contrary formula_55 and formula_114, and formula_57 exists. Then by the convexity of formula_108 we have a bundle formula_117 with formula_118. By the continuity of formula_47 for formula_120 close to 1 we have formula_121. This is a contradiction, because this bundle is preferred to formula_58 and costs less than formula_9.\n\nHence, for price quasi-equilibria to be price equilibria it is sufficient that the consumption set be convex, the preference relation to be continuous, and for there always to exist a \"cheaper\" consumption bundle formula_81. One way to ensure the existence of such a bundle is to require wealth levels formula_9 to be strictly positive for all consumers \"i\".\n\nBecause of welfare economics' close ties to social choice theory, Arrow's impossibility theorem is sometimes listed as a third fundamental theorem.\n\nThe ideal conditions of the theorems, however are an abstraction. The Greenwald-Stiglitz theorem, for example, states that in the presence of either imperfect information, or incomplete markets, markets are not Pareto efficient. Thus, in real world economies, the degree of these variations from ideal conditions must factor into policy choices. Further, even if these ideal conditions hold, the First Welfare Theorem fails in an overlapping generations model.\n\n"}
{"id": "42431493", "url": "https://en.wikipedia.org/wiki?curid=42431493", "title": "Human rights and development", "text": "Human rights and development\n\nHuman rights and development aims converge in many instances and are beneficial only to the government and not the people although there can be conflict between their different approaches. Today, a human rights-based approach is viewed by many as essential to achieving development goals. Historically, the \"minority clauses\" guaranteeing civil and political rights and religious and cultural toleration to minorities were significant acts emerging from the peace process of World War I relating to a peoples rights to self-determination. Overseen by the League of Nations Council the process allowed petitions from individuals and was monitored under the jurisdiction of the Permanent Court of International Justice. The 'clauses' are an important early signpost in both the human rights and development histories.\n\nThe initial impetus of the current human rights legal regime and movement was in reaction to the Nazi atrocities of World War II. Human Rights are importantly referred to in the United Nations Charter in both the Preamble and under Article 1 though only sparingly. The preamble of the UN Charter reaffirms \"faith in fundamental human rights, in the dignity and worth of the human person, in the equal rights of men and women\". Article 2(4) however prohibits the use of force and has ever since be used to block humanitarian actions though Chapter VII provides for Security Council enforcement measures.\n\nThe Charter established the Economic and Social council which set up the UN Human Rights Commission now the United Nations Human Rights Council. Chapter VI of the Charter entitled International Economic and Social Cooperation provides Article 55 (c) the \"universal respect for, and observance of human rights and fundamental freedoms for all without distinction as to race, sex, language or religion\". Article 56 requires States to take joint and separate actions in cooperation with the UN to achieve their mutual aims. Human rights are inherent in the progress of economic social and cultural goals and therefore to Human Development as such.\n\nThe Universal Declaration of Human Rights 1948 is not binding law and reflects an unwillingness of Allied powers to codify an International Bill of Rights where fears that colonial interests would be negatively affected were still influential. Human rights are viewed as universal, indivisible, interdependent and interrelated. René Cassin one of the architects of the declaration conceived the rights as divided into 4 pillars supporting the roof a temple, \"dignity, liberty, equality, and brotherhood\". Articles 1 & 2 comprising the first pillar relates to human 'dignity' shared by all individuals regardless of religion, creed, ethnicity, religion, or sex. Articles 100-19 the second pillar invokes first-generation rights civil 'liberties' fought for during the Enlightenment. Articles 20-26 the third pillar are second-generation rights, relating to political, social and economic equity, championed during the Industrial Revolution. Articles 27-28 the fourth pillar are third-generation rights associated with community and national solidarity advocated from the late 19th. These pillars support the roof of the temple Articles 29-30 representing the conditions in society under which the rights of individuals can be realized\n\nCertain civil and political rights converging with development aims include Article 2 which entitles everyone to rights with distinction as to race, colour, sex, or language; Article 3 the rights to life, liberty and security of person; Article 8 the right to effective remedy and Article 9 the right to an independent tribunal; Article 19 entails freedom of expression and Article 20 freedom of peaceful assembly; Article 21 is the right to participate in government and Article 26 provides rights to education.\n\nArticle 28 importantly signifies ' Everyone is entitled to a social and international order in which the rights and freedoms set forth in this declaration can be fully realized. The right calls for enforcement mechanisms and echoes Chapter VII of the UN Charter permitting security council intervention for human rights violations on a scale that threatens world peace. The UN Charter allows for a limit to state sovereignty were Human Rights are threatened. Two critiques of the declaration are that it did not make political rights dependent on multi-party democracy and there is a lack of protection for ethnic minorities, protecting individual rights do not necessarily protect group rights.\n\nThe nexus between grave human rights violations and international security is significant as atrocities within a sovereign state are of concern to international law, when they upset neighbouring states in a manner disturbing to world peace. Article 55 of the Charter states \"promotion of the respect for human rights helps create conditions of stability\" and \"recognition of ... equal and inalienable rights of all members of the human family is the foundation ... of peace in the world\". Taken together the United Nations Charter and Universal Declaration of Human Rights provide a legal mechanism which may challenge the sovereign rights of States to oppress people within their own jurisdiction\n\nThe Vienna Declaration and Programme of Action (VDPA) reaffirms the right to development under part 1, paragraph 10 and was adopted by consensus at the World Conference on Human Rights1993. The United Nations Office of the High Commissioner for Human Rights was created by the declaration and endorsed by the United Nations General Assembly (UNGA) under resolution 48/121.\n\nThe Rio Declaration on Environment and Development sought solutions to poverty, the growing gap between industrialized and developing countries and environmental problems. All elements were accorded equal weight and the declaration defined the rights and obligations of nations in 27 principles and recognizes \"the polluter pays\" as its guiding tenet.\n\nThe Action 2 Plan of Action and work plan stems from the UN Secretary General report Strengthening of the United Nations; An Agenda for Further Change. Integrating human rights into humanitarian, development and peace keeping work throughout the UN system. The plan introduces the UN Common Learning Package and a Human Rights-Based Approach (HRBA) which builds on the experience of all agencies.\n\nThe emphasis of the HRBA is based on common understanding and requires that 1) all programmes of development co-operation, policies and technical assistance should further the realisation of human rights as laid down in the Universal Declaration of Human Rights and other international human rights instruments; 2) human rights standards contained in, and principles derived from, the Universal Declaration of Human Rights and other international human rights instruments guide all development cooperation and programming in all sectors and in all phases of the programming process and 3) development cooperation contributes to the development of the capacities of 'duty-bearers' to meet their obligations and/or of 'rights-holders' to claim their rights.\n\nThe major human rights principles guiding the programme are regarded as universality and inalienability; indivisibility; interdependence and interrelatedness; non-discrimination and equality; participation and inclusion; accountability and the rule of law.\n\nThe Declaration on the Right to Development was proclaimed by the UNGA under resolution 41/128 in 1986. with only the United States voting against the resolution and eight absentions. The United Nations recognizes no hierarchy of rights, and all human rights are equal and interdependent, the right to development then is not an umbrella right that encompasses or trumps other rights nor is it a right with the status of a mere political aspiration.\n\nThe Right to development is regarded as an inalienable human right which all peoples are entitled to participate in, contribute to, and enjoy economic, social, cultural and political development. The right includes 1) people-centred development, identifying \"the human person\" as the central subject, participant and beneficiary of development; 2) a human rights-based approach specifically requiring that development is to be carried out in a manner \"in which all human rights and fundamental freedoms can be fully realized\"; 3) participation, calling for the \"active, free and meaningful participation\" of people in development; 4) equity, underlining the need for \"the fair distribution of the benefits\" of development; 5) non-discrimination, permitting \"no distinction as to race, sex, language or religion\"; and 6) self-determination, the declaration integrates self-determination, including full sovereignty over natural resources, as a constituent element of the right to development.\n\nThe right is a third generation right viewed as a group right such that it is owed to communities as opposed to an individual right applying to individuals \"It is a people, not an individual, that is entitled to the right to self-determination and to national and global development\" One obstacle to the right is in the difficult process of defining 'people' for the purposes of self- determination. Additionally, most developing states voice concerns about the negative impacts of aspects of international trade, unequal access to technology and crushing debt burden and hope to create binding obligations to facilitate development as a way of improving governance and the rule of law. The right to development embodies three additional attributes which clarify its meaning and specify how it may reduce poverty 1) The first is a holistic approach which integrates human rights into the process 2) an enabling environment offers fairer terms in the economic relations for developing countries and 3) the concept of social justice and equity involves the participation of the people of countries involved and a fair distribution of developmental benefits with special attention given to marginalised and vulnerable members of the population.\n\nThe right was first recognised in 1981 under Article 22 of the African Charter on Human and Peoples' Rights and subsequently in the Arab Charter on Human Rights. It is now recognised in numerous international instruments, with the Rio Declaration asserting under principle 1 \"Human beings are at the centre of concerns for sustainable development, they are entitled to a healthy and productive life in harmony with nature\". Other instruments include the Vienna Declaration and Programme of Action the United Nations Millennium Declaration, the 2002 Monterrey Consensus, the 2005 World Summit and the 2007 Declaration on the Rights of Indigenous Peoples.\n\nArticle 3 provides that \"States have the primary responsibility for the creation of national and international conditions favourable to the realization of the right to development\" and this encompasses three main levels 1) States acting collectively in global and regional partnerships; 2) States acting individually as they adopt and implement policies that affect persons not strictly within their jurisdiction and 3) States acting individually as they formulate national development policies and programmes affecting persons within their jurisdiction.\n\nArticle 6 importantly provides \"States should undertake, at the national level, all necessary measures for the realization of the right to development, echoing Article 2.1 of the International Covenant on Economic, Social and Cultural Rights (ICESCR) which states that \"each State Party to the present Covenant undertakes to take steps, individually and through international assistance and co-operation, especially economic and technical, to the maximum of its available resources. Furthermore, the Maastricht Guidelines on violations of economic, social and cultural rights provides that a state is in violation of the Covenant if it fails to allocate the maximum of its available resources to realizing human rights.\n\nThe Intergovermental Working Group on the Right to Development was established in 1998 and meets once a year reporting to the Human Rights Council (HRC) and the General Assembly. Its mandate is to globally (a) monitor and review progress made in the promotion and implementation of the right to development as elaborated in the Declaration, providing recommendations and analyzing obstacles to its full enjoyment; (b) to review reports and other information submitted by States, United Nations agencies, relevant international and non-governmental organizations, on the relationship between their activities and the right to development; and (c) to present a report to the HRC including advice to the Office of the United Nations High Commissioner for Human Rights (OHCHR)\n\nThe mandate of the High Commissioner (HC) and the OHCHR as stated in resolution 48/141 4 (c) seeks \"to promote and protect the realization of the right to development and to enhance support from relevant bodies of the UN system for this purpose.\" The right to development is highlighted in the General Assembly and the HRC which both request the UN Secretary-General and the HC to report annually on progress in the implementation of the right to development including activities aimed at strengthening the global partnership for development between Member States, development agencies and international development, financial and trade institutions.\n\nThe U.N. Commission on Human Rights adopted by consensus a resolution on the Right to Development 1998/24 .\" Effects on the full enjoyment of human rights of the economic adjustment policies arising from foreign debt and, in particular, on the implementation of the Declaration on the Right to Development\". The Commission recommended a follow up mechanism consisting of an open ended working group (OEWG) and an Independent Expert, Arjun Kumar Sengupta and Indian economist who was selected to the post . The purpose of the working group was to monitor and review the progress of the Independent Expert and report back to the Commission. The Independent Expert presented to the working group at each of its sessions a study on the current state of progress in the implementation of the right to development.\n\nPoverty Reduction Strategy Papers (PRSP) were first introduced in 1999 as a condition of eligibility for debt relief among Heavily Indebted Poor Countries (HIPC). The rationale of the process was to promote national and local 'ownership' of macroeconomic policies ensuring that they were sufficiently adapted to relieving poverty in the poorest countries. The process represents an embrace of the values of participation and transparency in the formulation of macroeconomic policy, and thus has the potential to shape the content of these policies in order to meet the needs of the poor.\n\n(PRSP's) are prepared by member countries in a participatory process with domestic stakeholders and development partners like the World Bank or International Monetary Fund. These are updated every three years with progress reports describing the country's macroeconomic, structural and social policies and programs over a three-year or longer period to promote growth and reduce poverty. Interim PRSPs (I-PRSPs) summarize the current knowledge and analysis of a country's poverty situation, describe the existing poverty reduction strategy, and lay out the process for producing a fully developed PRSP in a participatory fashion.\n\nCountry documents, along with the accompanying IMF/World Bank Joint Staff Assessments (JSAs), are available on their websites by agreement with the member country as a service to users of the IMF and World Bank websites. The introduction of PRSPs was a recognition by the IMF and the World Bank of the importance of country ownership of reform programs as well as the need for a greater focus on poverty reduction. PRSPs aim to provide the crucial link between national public actions, donor support, and the development outcomes needed to meet the United Nations' Millennium Development Goals (MDGs), which are centered on halving poverty between 1990 and 2015. PRSPs guide policies associated concessional lending as well as debt relief under the Heavily Indebted Poor Countries (HIPC) Initiative.\n\nFive core principles underlie the approach. Poverty reduction strategies should be 1) country-driven, promoting national ownership of strategies through broad-based participation of civil society; 2) result-oriented and focused on outcomes that will benefit the poor; 3) comprehensive in recognizing the multidimensional nature of poverty; 4) partnership-oriented, involving coordinated participation of development partners (government, domestic stakeholders, and external donors); and 5) based on a long-term perspective for poverty reduction.\n\nIn 2001 The UN High Commissioner for Human Rights commissioned the 2001 guidelines for the integration of human rights into poverty reduction Strategies which were further developed in the 2005 guidelines The Commissioner in a concept note also states that the human rights framework is \"a useful tool strengthening the accountability and equity dimensions of the Poverty Reductions Strategies. In 2008 specific strategies were introduced in regards to Poverty Reduction and Health that affirmed the place of Human Rights in the achievement of the Millennium goals.\n\nIn September 2000, world leaders made commitments in the Millennium Declaration UN resolution 55/2 on topics that included peace, security, human rights, the environment and development targets which were later configured into the eight Millennium Development Goals (MDGs). These goals are sets of development targets that center on halving poverty and improving the welfare of the world's poorest by 2015. The IMF contributes to the goals through advice, technical assistance, lending to countries and mobilizing donor support.\n\nThe Millennium Declaration considers six fundamental values necessary for international relations 1) freedom to raise children in dignity, freedom from hunger and from the fear of violence, oppression and injustice, including democratic and participatory governance based on the will of the people. 2) equality, no individual or nation must be denied the opportunity to benefit from development. 3) solidarity, global inequities must be managed to distribute costs and burdens fairly in accordance with the principles of equity and social justice, while those who benefit least deserve help from those who benefit most. 4) tolerance, differences within and between societies should not be feared or repressed, but cherished as a precious asset of humanity, while cultures of peace and dialogue among all civilizations should be promoted. 5) Respect for nature. Prudence must be shown in the management of all living species and natural resources, through sustainable development and unsustainable patterns of production and consumption must be changed in the interest of the future welfare of our descendants and 6) shared responsibility, responsibility for managing worldwide economic and social development, as well as threats to international peace and security, must be shared among the nations of the world and should be exercised multilaterally.\n\nHuman rights have played a limited role in influencing MDG planning, though there are strong similarities between them and the content of the MDGs which resemble many economic and social rights. MDGs provide benchmarks for economic and social rights, while human rights strategies offer enhanced legitimacy, equity and sustainability to the MDG policies. The Millennium Declaration substantially refers to human rights and leaders have committed themselves to respecting recognized human rights and fundamental freedoms, including the right to development. Economic, social and cultural rights, the rights of women, migrant, minorities, and participation are all emphasized in the declaration yet the pursuit of the MDGs has been in isolation from it. MDG targets are not sufficiently focused on inequalities within a country and human rights instruments require a minimum core level of economic, social and cultural rights to be immediately realized for all and for all discrimination in the exercise of rights to be eliminated. Inequalities within countries lead to violent conflict and countries focus on the relatively well-off among the poor in order to reach a particular MDG target.\n\nThe MDGs are accompanied by 18 targets measured by 60 indicators though the relationship between the goals, targets and indicators is not always clear. A range of activities are promoted as a means of achieving the MDGs such as tailoring the MDGs to the regional, national and local context and undertaking national needs assessments and monitoring progress through yearly MDG reports.\n\nNon-State actors also carry human rights responsibilities with at least a minimum duty of not interfering with human rights such as the OECD Guidelines for Multinational Enterprises provides a complaint system for violations by companies. A specific critique of MDGs is that they place emphasis on the mobilization of financial resources and technical solutions, but less on transforming power relations that are partially responsible for levels of poverty. The World Bank has observed that in many situations the real barriers to progress on the MDGs are social and political. The realization of human rights therefore may be a precondition to fulfilling development goals\n\nThe present global institutional order is foreseeably associated with avoidable severe poverty and its impositions may constitute an ongoing human rights violation. There are many measures of poverty and it is now regarded that poverty is more than the measure of a low income. Amartya Sen argues that individual physical characteristics, environmental and social conditions as well as behavioural expectations all play a role. The UN Committee on Economic, Social and Cultural Rights defines poverty as \"human conditions characterised by chronic deprivation of resources capabilities, choices, security and power necessary for the enjoyment of an adequate standard of living\"\n\nJeffrey Sachs place poverty in an historical trajectory with the ending of slavery, colonialism, segregation and apartheid but do not link these human rights movements to current causes of poverty elimination. Policy economists discuss minimum standards, transparency, and participation unrelated to the human rights framework where poverty is seen to increases social wastage distorting economic and service delivery outcomes. Joseph Stiglitz in \"Making Globalization Work\" refers to a gap between economic and political globalization and that a growth oriented economic analysis disregarding the impact of income on the realization of rights such as health or education and focusing instead on making choices in a world of limited resources. There is debate whether attention to civil and political rights makes way for economic development or whether economic growth is more likely to create institutional and political development. The G-20 2005 Statement on Global Development Issues does not mention human rights or human development and good governance is referred to only in relation to economic policy. In the 2009 the Global Plan for Recovery and Reform also fails to mention human rights or human development. The ingrained philosophy is a world economy based on market principles and effective regulation.\n\nA strand of economics embraces human rights language such as the International Development Ethics Association who apply a normative approach to development theories. The Mérida Declaration provides \"the absolute respect for the dignity of the human person regardless of gender, ethnic group social class, religion age or nationality. The UN Development Programme UNDP which is promoted by the Human Development and Capability Association (HDCA) is open to a human rights perspective as stated in the Human Development Report of 2001 \"human development and human rights are mutually reinforcing helping to secure the well-being and dignity of all people\". The Economic and Social Council put out a statement in May 2001 specifically addressing poverty as a human right concern and Special Rapporteur Mohammed Habib Cherif reported to the Sub Commission on the Promotion and Protection of Human Rights at its 58th session now the Advisory Committee on Human Rights and extreme Poverty. Human rights under these development perspectives revolve around the concept of freedom with expanding choice. The World Conference on Human Rights the Vienna Declaration confirmed that extreme poverty and social exclusion constitute a violation of human dignity and urgent steps are necessary to achieve better knowledge of extreme poverty and its causes.\n\nThe first MDG is to Eradicate Extreme Poverty and Hunger. Economic growth is regarded as the principal mechanism to achieve this goal while a human rights approach requires a focus on poor growth and a consideration of groups seeking development paths other than the conventional free market, export-driven model. The targets here are 1) To halve, between by 2015, the proportion of people whose income is less than $1 a day comparable to the \"Right to adequate standard of living\"; 2) to achieve full employment and decent work for all is comparable to the \"Right to work\" and 3) to halve by 2015 the proportion of people who suffer from hunger, comparable to the \"Right to food\", and correspondingly rights to life and health.\n\nSouth-eastern Asia is the first developing region to reach the hunger reduction target ahead of 2015. Undernourished people in the total population of the region decreased from 29.6% in 1990-1992 to 10.9% in 2010-2012. However, globally the slowing of growth brings continual job losses. Unemployment has increased by 28 million since 2007, and an estimated 39 million people have dropped out of the labour market, leaving 67 million people without jobs as a result of the global financial crisis. Though the number of workers living with their families on less than $1.25 a day has declined dramatically over the past decade by 294 million, new estimates show that 60.9% of workers in the developing world still live on less than $4 a day.\n\nIn Yemen the World Food Programme (WFP) Food For Girls Education Programme has been tackling hunger and enrolment challenges, where more than 60% of primary school children not in schools are girls. Families who send their girls to school are eligible to receive an annual ration of wheat and vegetable oil. Since 2010 the programme has reached almost 200,000 girls. Whilst in India the UNDP is supporting the Mahatma Gandhi National Rural Employment Program, promoting laws passed in 2005 which guarantee the right to a minimum of 100 days of paid work a year for landless labourers and marginal farmers. The scheme now provides 50 days work a year to around 50 million households where almost half of the beneficiaries are women.\n\nThe Zero Hunger Challenge another UN initiative with numerous NGO partners has as it aims 1) 100% access to adequate food all year round; 2) zero stunted children less than 2 years old; 3) where all food systems are sustainable; 4) a 100% increase in smallholder productivity and income; and 5) a zero loss or waste of food.\n\nVarun Gauri argues that economic and social rights, such as the right to health care or education, may be understood not as legal instruments for individuals, but as duties for governments and international agencies such that everyone bears some responsibility for their fulfillment. Economists accept that the realization of high standards of health and education are conducive to economic growth. The human rights approach regards transparency and empowerment as ends in themselves, while an economic approach sees them as instrumental to a welfare outcome.\n\nThe second MDG is to Achieve Universal Primary Education. The target is to ensure that by 2015, children everywhere will be able to complete a full course of primary schooling comparable to the \"Right to education\", the goal however ignores the requirement of \"free primary education\" as conceived by the human right. \nEven after 4 years of primary schooling, as many as 250 million children cannot read and write undermining the basis for all future learning. Going to school is not enough and improving actual learning is critical. Early school leaving is a major factor, 137 million children entered first grade in 2011, with 34 million likely to leave before reaching the last grade, an early leaving rate of 25%, the same as in 2000. Poverty, gender and residential location are key factors keeping children out of school. Children from the poorest households are three times more likely to be out of school than children from the richest households. Globally 123 million youth aged 15 to 24 lack basic reading and writing skills whilst 61% of them are young women.\n\nPositive developments have occurred in Afghanistan and Bangladesh where the Let Us Learn initiative has overcome barriers to education. UNICEF enrolled 3,917 five-year-olds in school programmes, including 153 disabled children from the most disadvantaged region of rural Bangladesh, 60% of which were girls. In Afghanistan 9,339 children and youth participated in community based learning programmes with 84% being girls. UNICEF and partners responded to 286 humanitarian crises in 79 countries in 2012 and helped some 3.56 million children and adolescents gain access to formal and non formal basic education.\n\nThe Secretary-General's Global Education First initiative (GEFI) has a commitment with companies and private foundations making pledges of over $1.5 billion ensuring that all children have a quality, relevant and transformative education, whilst the Global Partnership for Education (GPE) helped more than 19 million children go to school since 2003. Leading donors promised an initial $1.5 billion over three years, with the fund aiming to secure another 25 million children in school as of 2014.\n\nThe third MDG is to promote gender equality and empower women. Eliminating gender inequality is supported by international human rights instruments, such as the Convention on the Elimination of All Forms of Discrimination against Women. The goal sets women's empowerment as the objective but the related target is narrowly concerned with education. Eliminating gender disparity in primary and secondary education by 2015 is narrowly conceived but comparable to Women's Right to equality. Of note the share of women employed outside of agriculture rose to 40% in 2013 but only by 20% in Southern Asia, Western Asia and Northern Africa while the global share of women in parliament continues to rise and reached 20% in 2012.\n\nGender gaps in access to education have narrowed but inequalities remain in all levels of education, girls face barriers to schooling, particularly in Northern Africa, sub-Saharan Africa and Western Asia. Access to secondary and university education remains unequal with disparities at universities the most extreme. In Southern Asia, 77 girls per 100 boys are enrolled in tertiary education while in sub-Saharan Africa the gender gap in enrolment has widened from 66 girls per 100 boys in 2000 to 61 girls per 100 boys in 2011. Poverty is the main cause of unequal access to education with women and girls in many parts of the world forced to spend many hours fetching water and girls often do not attend school because of a lack of adequate sanitation facilities. Child marriage and violence against girls are also significant barriers to education. Women still enter the labour market on an unequal basis to men, even after accounting for educational background and skills. Women are often relegated to vulnerable forms of employment, with little or no financial security or social benefits.\n\nRegarding women's rights and land empowerment, Kerry Rittich notes that programmes which promote the formal real property rights of women, in place of customary laws or other informal mechanisms, have the potential to both improve and retard women's access to land. The programmes promoting property rights tend to go together with measures to formalize, commodify, and individualize landholdings, and that these three processes often intensify the dispossession of women who may have had access to land under informal arrangements or customary law. The promotion of property rights from an economic perspective may well undermine the social rights of women in developing countries. Legal conceptions of property, treat property not as a mere resource but as a set of relations between individuals and groups. This approach may highlight otherwise unforeseen distributive consequences for women, moving from an informal property regime to a formalized and individualized one.\n\nMason and Carlsson note that, unless gender inequality in land holding is taken into account when implementing land tenure reforms, improved land tenure security may diminish women's land holdings. A variety of factors can lead to this result, including discriminatory inheritance laws, the application of an androcentric definition of 'the head of household', and inequalities in women's capacity to participate in the market for land. Costa Rica and Colombia land reforms were undertaken in a way that improved women's ownership of land. Women who own the land they work have greater incentives to raise their labour productivity, and women who earn more income are more likely than men to invest in the household and in their children's education and nutrition stressing the importance of applying a human rights lens such that norms of non-discrimination and equal property rights are required when implementing economic reforms.\n\nThe fourth MDG is to reduce child mortality. A human rights approach emphasizes the State's obligations regarding the availability of functioning health systems and making sure that all groups can effectively access them by addressing obstacles like discrimination. The target here is the reduction of two-thirds of the mortality rate of children under five by 2015 comparable to the \"Right to life\". Around 17,000 fewer children are dying each day, yet 6.6 million children under five died in 2012, mostly from preventable diseases. In sub-Saharan Africa, one in ten children dies before the age five.\n\nSub-Saharan Africa and Southern Asia accounted for 5.3 million 81% of the 6.6 million deaths The main killers are pneumonia, prenatal and intrapartum complications, diarrhoea and malaria. The first month, particularly the first 24 hours, are the most dangerous in a child's life. Newborns now account for almost half 44% of under-five deaths and undernutrition contributes to 45% of all under-five deaths. Over the past two decades in Bangladesh UNICEF has supported local efforts training community health-care workers leading to a decline in maternal and child mortality. Infant mortality declined from 100 deaths per 1,000 live births in 1990 to 33 deaths per 1,000 live births in 2012. In the same period under five mortality dropped by 72% from 144 deaths per 1,000 births in 1990 to 41 deaths per 1000 births in 2012.\n\nThe development goal is related to \"Child Labour\". Rights advocates regard child labour as a violation to numerous rights of a child such that it must be eradicated to ensure children's human rights are ends themselves while development economics views child labour as an inter-generational loss of potential income. Children suffer diminished human capital where reductions in health and education affect their future productivity. The International Labour Organization's (ILO's) estimates that current levels of child labour will result in an income foregone of $5 trillion between 2000 and 2020. Currently 23% of the world's children aged between 5 and 17 are engaged in some form of work. Betcherman demonstrates the important insights that economic analysis can provide in understanding how best to reduce child labour. Factors contributing to child labour can be seen in terms of incentives that encourage child work, constraints that compel children to work, and decisions that may not be made in the best interests of the children. Other factors must also be considered, direct (books, transport) and indirect (poor quality, loss of household labour) costs of education leading parents to regard education as not providing sufficient immediate returns to the household or child.\n\nElizabeth Gibbons, Friedrich Huebler, and Edilberto Loaiza consider how, at the level of statistical analysis, the application of the human rights principle of non-discrimination can affect our understanding of child labour. Existing methods of calculating the extent of child labour under report the degree of work done by girls, because the measures exclude household chores. By failing to consider 'female work' within the definition of child labour, the impact of child work on the educational and health attainment of girls is made invisible. Gibbons, Huebler, and Loaiza also investigate some factors affecting school attendance; labour and household poverty are generally constraints on attendance but a mother's educational attainment correlates positively with school attendance, revealing the inter-generational payoff from investments in girls' education. Household wealth and the level of education of the primary caretaker also have a significant effect on educational attainment\n\nIn India the Right of Children to Free and Compulsory Education Act has led to the inclusion of a justiciable right to education in relation to children between the ages of 6 and 14 and provides an impetus to government to address critical problems in the provision of education. The idea of education as a 'fundamental right' focuses local political action and agitation among oppressed communities, who rely on the new constitutional provision as a way of pressing demands on local and regional government.\n\nThe fifth MDG is to improve maternal health. The target is to reduce by three quarters the maternal mortality ratio and to achieve universal access to reproductive health by 2015 comparable to \"right to life and health\". Complications during pregnancy or childbirth are one of the leading causes of death for adolescent girls, 140 million women worldwide married or in civil union would like to delay or avoid pregnancy, but have no access to family planning. 47 million babies were delivered without skilled care in 2011.\n\nMaternal mortality is lower in countries where levels of contraceptive use and skilled attendance at birth are high. sub-Saharan Africa has the world's highest maternal mortality ratio with a contraceptive use of 25% and low levels of skilled attendance at birth. Education for girls is vital to reducing maternal mortality. The risk of maternal death is 2.7 times higher among women with no education, and 2 times higher among women with one to six years of education than for women with twelve plus years of education.\n\nSupported by UNFPA, Bangladesh is training midwives according to international midwifery standards. Hundreds of nurses have upgraded their knowledge with practical and theoretical training. In India more than two-thirds of maternal deaths occur in impoverished states due to the inability to get medical care in time. UNICEF and its partners are working to avoid these preventable maternal deaths through innovative schemes such as a conditional cash transfer programme for women who deliver in health facilities. In Sierra Leone a year after the launch of the Free Health Care 2010 initiative there was a 150% improvement in maternal complications managed in health facilities and a 61% reduction in the maternal mortality rate.\n\nLaunched at the UN MDG Summit in 2010, Every Woman Every Child mobilizes global action to save the lives of women and children and to improve their health and lives. Partners in this area include The GAVI Matching Fund for Immunization, a private-public initiative in which the UK Department for International Development and the Bill & Melinda Gates Foundation match contributions from the private sector to deliver critical vaccines to the lowest income countries. Furthermore, UN Women is implementing a joint programme in Central African Republic, Chad, Guinea, Haiti, Mali, Niger and Togo highlighting links between violence against women and maternal health, promoting funding and training midwives and health workers.\n\nThis sixth MDG is to combat HIV/AIDS, malaria and other diseases. The goal has three targets 1) to halt and reverse HIV/AIDS, 2) to achieve universal treatment for HIV/AIDs 3) to halt and reverse Malaria and other Diseases unquestionably reflecting the \"Right to health\". To date 2.3 million people are newly infected by HIV each year, with 1.6 million in sub-Saharan Africa. Tuberculosis (TB) mortality rate decreased 41% between 1991 and 2011, yet TB killed 1.4 million people in 2011, including 430,000 among people who were HIV-positive. Multidrug-resistant TB is a major global challenge and the rate of people accessing treatment is slow.\n\nIn 2008, reports appeared that malaria parasites in Cambodia and Thailand were resisting artemisinin, the most effective single drug to treat malaria. The countries launched a joint monitoring, prevention and treatment project in seven provinces along their shared border, with support from WHO. In Thailand more than 300 volunteer village malaria health workers were trained to provide free services to test for malaria and directly observe the treatment of patients. Use of a smart phone to capture data on patients and to monitor treatment has accelerated progress. An electronic malaria information system (e-MIS) uploaded on the health workers' mobile devices shows malaria volunteers where to find patients, the status of their treatment, the situation and trends. In Ethiopia a programme, supported by UNICEF and its partners, is preventing transmission of the virus from HIV-positive mothers to their children, a critical measure in ensuring an AIDS-free generation.\n\nThe Getting to Zero initiative has ten Southeast Asian nations committed to making Zero New HIV Infections, Zero Discrimination and Zero HIV- Related Deaths a reality.\n\nThe seventh MDG is to ensure environmental sustainability. A human rights approach to sustainable development emphasizes improving accountability systems, access to information on environmental issues, and the obligations of developed States to assist more vulnerable States, especially those affected by climate change.\n\nThere are four targets in this goal 1) To integrate principles of sustainable development into country policies and reverse the loss of environmental resources comparable to a \"Right to environmental health\"; 2) to reduce biodiversity loss by achieving a significant reduction in the rate of loss; 3) to halve by 2015, the proportion of the population without sustainable access to safe drinking water and basic sanitation comparable to the \"Right to water and sanitation\" and 4) to achieve, by 2020, a significant improvement in the lives of at least 100 million slum dwellers, comparable to the \"Right to adequate housing\".\n\nOf note a staggering 2.5 billion people still do not have access to toilets or latrines. Open defecation is a practice that poses serious health and environmental risks and stopping it is a key factor in the progress of sanitation goals. In 2013, UN Member States adopted the Sanitation for All resolution calling for increased efforts to improve access to proper sanitation. The number of slum dwellers however continues to grow, due to the fast pace of urbanization. The number of urban residents living in slum conditions was estimated at 863 million in 2012, compared to 650 million in 1990 and 760 million in 2000.\n\nSpecies are moving towards extinction at an ever-faster pace, and reduced biodiversity has serious consequences for the ecosystem services upon which all people depend. The largest loss of forests occurs in South America, around 3.6 million hectares per year from 2005 to 2010. Deforestation threatens global sustainability and the progress towards hunger and poverty reduction as forests provide food, water, wood, fuel and other services used by millions of the world's poorest. Brazil's northeast the most densely populated semi-arid region in the world has limited rainfall and cyclic drought forcing many of the 22 million residents to resort in illegal charcoal production, stripping the region of forests. A project by the International Fund for Agricultural Development (IFAD) to promote agro-ecology is showing farmers how to make a living from the land while conserving the environment.\n\nNearly one-third of marine fish stocks have been overexploited and the world's fisheries can no longer produce maximum sustainable yields due to continuing expansion of the fishing industry in many countries. The Montreal Protocol has led to a 98% reduction in the consumption of ozone-depleting substances since 1986 yet carbon dioxide emissions have increased by more than 46% since 1990.\n\nAfricas first transboundary biosphere reserves in Benin, Burkina Faso, Côte d'Ivoire, Mali, Niger and Senegal are set up with funding from the Global Environment Facility, working with the UN Environment Programme (UNEP) and UNESCO in 2002. The reserves prevent desertification, testing sustainable economies and integrating local communities.\n\nThe development goal is strongly related to rights to \"Food, Water & Sanitation\". Defined as 'freedom from hunger', the right to food may be seen as a right to 'nutrition'. Nutrition is achieved not through food alone but with clean water, health-care, hygiene, and other inputs. In India despite constitutional protections of certain economic and social rights, including the right to food, and relatively stable democratic institutions, the underprivileged are excluded from actively participating in democratic politics, with the result that their aspirations and priorities are not reflected in public policy. The elitism of public policy further disempowers the poor by perpetuating their deprivations.\n\nThe state bearing primary responsibility for the right to food, there is also responsibilities on local communities and families to ensure basic nutrition is equally available to all members. Dre`ze accepts that this complicates the question of how the right to food can be enforced, additionally the right to food cannot be realized in isolation from other social and economic rights, such as the right to health.\n\nThe Rio +20 Conference took place in 2012 produced the Future We Want outcome document and created the UN High-level Political Forum on sustainable development which issued the Global Sustainable Development Report in 2013 its special theme the convergence of climate, land, energy, water and development issues. \"The unabated rise in the scale of materials consumption has increased global environmental, social and economic pressures. There is increasing evidence that we are jeopardizing several of the Earth's basic life support systems. Countries and people trapped in persistent poverty have probably suffered most from these impacts. And future generations will most likely face much greater challenges to meet their own needs\".\n\nThe eighth MDG is to . There are five targets 1) to develop predictable, non-discriminatory trading and financial system rules; 2) to address the needs of least developed countries, landlocked countries and small island developing states; 3) to deal comprehensively with developing countries' debt; 4) to provide access to affordable, essential drugs in developing countries in cooperation with pharmaceutical companies and 5) to make available benefits of new technologies. All targets are comparable to the \"Right to development\".\n\nOf note a total of 83% of least developed country exports enter developed countries duty-free. In the developing world, 31% of the population use the Internet, compared with 77% of the developed world. In 2012 ODA of $126 billion was 4% less than in 2011, which was 2% less than in 2010. This is the first time since 1996-1997 that ODA fell in two consecutive years, while essential medicines are available in only 57% of public sector facilities and 65% of private facilities in selected developing countries. There are over six billion mobile phone subscriptions worldwide and for every person who uses the Internet from a computer, two do so from a mobile device. In South Africa, over 25,000 students have improved their math skills through interactive exercises and quizzes on mobile phones through cooperation between government, Nokia and individual schools and teachers.\n\nThe MDG Gap Task Force was created by the UN Secretary-General in 2007 to improve monitoring of the global commitments contained in MDG 8 tracking existing commitments and identifying gaps and obstacles to fulfilment in development assistance, trade, debt sustainability, access to essential medicines and new technologies. The Task Force integrates more than 30 UN and other international agencies while The Integrated Implementation Framework records and monitors financial and policy commitments made by UN Member States and other international stakeholders.\n\nCriticism of the Millennium goals are that they should be transformative not technocratic. A key element in empowering people is that the response should be framed within a broader view of poverty that addresses root causes like power inequalities. Creating an inventory of public goods and services for distribution and seeking to fill deficits through foreign aid follows the history of development. A rights-based approach seeks to identify systemic obstacles that keep people from accessing opportunity. Genuine participation and access to information are the cornerstone of empowerment and instrumental gains occur when local knowledge and local preferences are used. Civil and political rights like the rights to vote, to freedom of expression and to freedom of association are crucial if excluded groups are to ensure that Governments focus on the MDGs with a human rights basis.\n\nHuman rights in relations to develop goals possess a number of different characteristics. Rights are universal, the birthright of all humans, and are focused on the inherent dignity and equal worth of all. Human rights cannot be waived or taken away and they impose obligations of action and omission. Rights are internationally guaranteed and legally protect individuals and groups. Rights have corresponding obligations on the duty-bearer traditionally the state, who must 1) respect human rights by refraining from interfering with them; 2) protect human rights by ensuring that private actors do not interfere with people's ability to exercise them (e.g. ensure that private schools enrol children from ethnic minorities); 3) fulfil human rights by adopting all necessary measures (e.g. create health programmes to provide medicines or pass laws to recognize indigenous ancestral lands and 4) guarantee human rights without discrimination of any kind including disability, health status, age, sexual orientation, civil, political and social status.\n\nInternational human rights law predate the MDGs, and States have existing legal obligations to realize human rights such that development goals targets and indicators need to be aligned with a human rights approach. The process of alignment should involve 1) adapting each target to the relevant economic, social or cultural right; 2) mainstreaming gender; 3) ensuring the excluded are included; and 4) ensuring indicators are rights sensitive. There must be minimum standards for the process agreed on by all participants that includes the design, implementation and monitoring of development strategies; which are inclusive of women and marginalized groups. Elite capture and reinforcement of existing social hierarchies and power relations must be prevented and information must be transparent and accessible, finally there must be accountability mechanisms to ensure the participatory process is kept to these standards such that overall there is a prioritization of human rights in policy and resource allocation.\n\nThe Development CoOperation Forum is an initiative of the United Nations Economic and Social Council (ECOSCO) and now held biannually. The objectives of the upcoming forum include 1) Assess how a global partnership for development beyond 2015 could work in practice. 2) examine implications of a post-2015 development agenda for development cooperation; 3) identify ways to enhance national and global accountability and effective monitoring of development cooperation and 4) advance policy dialogue and concrete actions by Southern development cooperation partners on commons issues and challenges.\n\nThe International Labour Organization (ILO) since its formation in 1919 has lent strong support to workers rights and its work compliments human rights as stipulated under Article 23 of the UDHR., Article 22 of the International Covenant on Civil and Political Rights and Article 11 of the European Convention. The organization has developed its own conventions and committees for advise on labour laws and mediates between trade unions and employers guarding labour principles outlined in the UN Global Compact.\n\nThe ILO Conventions include Freedom of Association and Protection of the Right to Organise Convention 1948 and the Right to Organise and Collective Bargaining Convention, 1949. In 1998 the organization issued a declaration of four core labour rights 1) freedom of association and the effective right of collective bargaining 2) the prohibition of forced compulsory labour 3) the effective abolition of child labour 4) the elimination of discrimination in respect of employment or occupation. Collective bargaining may be viewed as an individual right to combine with other individual workers in a position to achieve wage justice, safe working conditions, fair disciplinary treatment and comradery. It is also a practice that counterbalances and overcomes inequalities in market forces.\n\nThe Fair Labor Association (FLA) developed a Workplace Code of Conduct \nbased on ILO standards and addresses 1) forced labour; 2) child labour; 3) harassment or abuse; 4) nondiscrimination; 5) health and safety; 6) freedom of association and collective bargaining; 7) wages and benefits 8) hours of work and 9 overtime compensation.\n\nAround half of the wealthiest 100 entities in the world today are corporations not countries. with many organisations committing gross human rights violations from which they earn vast profits. Wars are inflamed through arms sales and corporations deal in conflict commodities like diamonds.\n\nImportantly the legal personality of corporations was established in the \"Barcelona Traction\" case. (1970) In 2004 the UN Commission on Human Rights asked the OHCHR to compile a report on the responsibilities of transnational corporations (TNCs) and following up on the report a Special Representative was appointed to look at the issues and to comment on the relationship of TNC's and other business enterprises. The Ruggie Reports from between 2005 -2011 present a conceptual and policy framework to help guide relevant actors comprising three core principles \"protect, respect and remedy\". It is the State duty to \"protect\" against human rights abuses by third parties, including business; whilst there is a corporate responsibility to \"respect\" human rights; and furthermore there is need for effective access to \"remedies.\" In 2011 The United Nations Guiding Principles on Business and Human Rights were annexed to the last report.\n\nStates have the primary role in preventing and addressing corporate related human rights abuses under resolution 8/7 governments can support and strengthen market pressures on companies to respect rights whilst adequate reporting enables stakeholders to examine rights related performance. To fulfil the duty to protect states must regulate and adjudicate the acts of business enterprises. International Human rights treaties do not themselves create direct obligations for corporations but treaty bodies refer more directly to the role of states in specifically guarding against human rights violations by corporations. The more recent Convention on the Rights of Persons with Disabilities clearly provides that state parties have an obligation to take all appropriate measures to eliminate discrimination on the basis of disability by any person organization or private enterprise. An unresolved legal issue in this regard is as to the extent of a State's jurisdiction, does a states obligation extend extra-territorially or internationally?\n\nBusiness enterprises should respect human rights, avoiding infringing on the human rights of others and they should address adverse human rights impacts when they are involved. The responsibility of business enterprises to respect human rights refers to those rights as expressed in the International Bill of Human Rights and the principles concerning fundamental rights set out in the International Labour Organization Declaration on Fundamental Principles and Rights at Work. As part of their duty to protect against business related human rights abuse States must take appropriate steps to ensure that those affected have access to effective remedy through judicial, administrative, legislative or other appropriate means.\n\nSince the 1990s soft law instruments have been relied upon to guide corporate behaviour such as the OECD Guidelines for Multinational Enterprises, the UN Global Compact and the UN draft norms on transnational corporation and other business enterprises. The OECD Guidelines cover a wide range of issues including labour and environmental standards, human rights, corruption, consumer protection, technology amongst others. The guidelines are completely voluntary and were revised in 2000 and updated in 2011. In 2000 a complaint procedure was introduced allowing NGO's and others to submit complaints to alleged breaches where previously only trade unions could submit complaints. The 2011 update introduced a specific chapter on human rights and aligns the guidelines with the UN Special Rapporteur framework of \"protect respect and remedy\".\n\nIn 2000 the UN established the Global Compact which call on business leaders \"embrace and enact' a set of 10 principles relating to human rights, labour rights, environmental protections and corruption. The compact did not include a mechanism for dispute resolution. In response to this criticism integrity measures were introduced in 2005 which created a complaints procedure for systematic abuse of the compacts overall aims and principles.\n\nIn 2003 a UN subcommission on the promotion and protection of Human Rights adopted a set of international norms applying to TNC's and other business they are based on international instruments, non binding declarations and guidelines adopted by multilateral organizations. The norms include 1) general obligations; 2) rights to equal opportunity and non-discriminatory treatment; 3) rights to security of persons; 4) rights of workers 5) respect for national sovereignty and human rights; 6) obligations with regard to consumer protection; 7) obligations with regard to environmental protection 8) general provisions of implementation and 9) definitions. The norms however do not have legal status and are unlikely to be developed further and the subcomission is now replaced by the Human Rights Council Advisory Committee.\n\nThere has also emerged over the past decades a proliferation of company specific and multi-stakeholder codes of conduct such as the Sullivan principles and as such hundreds of companies have now publicly committed to upholding basic human rights. Codes of conduct are regarded as part of the soft law regime and are not legally binding but the general normative effect may lead to legal effect as standards may be incorporated into employment and agency contracts.\n\nThe Human Rights Commission tasked with drawing up the UDHR was divided on whether the bill should be legally enforceable either as an annex to the UN Charter or as a multilateral convention. As a Declaration of principles it has no powers of implementation but results in new developments of customary international law. As a non legal document the declaration yet defines the nature and meaning of a pledge to respect human rights provided under Article 55 of the UN Charter. Since its initial singing with 48 members and 8 abstention it has grown to include 192 member states. As such Human rights have an inherent dignity and are inalienable, they \"should be protected by the rule of law\" to prevent the need of individuals being compelled to revolt against tyranny\n\nDuring the 1970s, General Pinochet's crimes in Argentina contributed greatly to the general assembly passing the United Nations Convention against Torture1975 while the Helsinki Accords 1975 also gave strength to the Human Rights movement. Today the binding UN covenants of the ICCPR and the ICESCR are now in force. In 1977 the Security Council imposed mandatory trade sanctions on South Africa after having previously declared apartheid as \"a grave threat to the peace\" justifying the interference into the States internal affairs. The ban on trade was not policed and circumnavigated by multinational corporations. During this period Andrei Sakharov drew attention to the plight of political prisoners whilst critiquing the UN system for its partisan politics. Václav Havel appealed to the Helsinki promise of political cooperation to be taken at face value. These developments coincided with a shift in US foreign policy to include human rights in its agenda while the twin covenants making human rights abuse a legitimate subject of international concern.\n\nThe Commission and Human Rights Council have not substantially acted on human rights violations and states represented on the commission have not wished to create enforcement procedures which might be used on themselves or their allies, such that tragedies like Pol Pot's Genocide and the execution of Ken Saro-Wiwa persist. The Human Rights Committee a body of independent experts monitor the implementation of the ICCPR. All parties must submit an initial report and are subject to four yearly reporting. Concerns and recommendations are addressed in \"concluding observations\" addressed to the State Party. Article 41 provides for interstate complaints while the Optional Protocol 1 gives the committee competence to examine individual complaints of alleged violation by State Parties to the Protocol\n\nEnforcement in relation to TNC's has often been through tort litigation where human rights standards have been incorporated into domestic legislation. though International law itself is yet unable to impose human rights obligations on corporations. The Alien Tort Statute or Alien Tort Claims Act (ATCA) of 1789 draws directly on international norms to hold corporations liable for conduct that violates human rights. The ATCA allows a plaintiff not resident in the USA to sue a defendant over which a US court has jurisdiction for a violation of the law of nations even where the event is outside US territory. In \"Filartiga v Pane-Irala\" a Paraguayan policeman was sued for torture and murder of the plaintiffs relative though in \"Sosa v Alvarez Machain\" it was held That the ATCA did not extend to arbitrary arrest or detention in violation of the UDHR and the ICCPR.\n\nIn \"Doe v Unocal\" a civil claim was brought under the ATCA alleging abuses on the part of an oil consortium and its security representatives which resulted in forced labour, murder, rape and torture of villages. The Court held that a reasonable person could conclude on the evidence that Uncol had aided and abetted the abuses committed by the Myanmar Military and court drew on the jurisprudence of the International Criminal Tribunal for the former Yugoslavia (ICTY) for its decision.\n\nThe International Criminal Court (ICC) may hold individuals accountable for human rights abuses under the provision of its founding statute. it does not however have jurisdiction of corporations though individuals within corporations can be held to account. The Court has jurisdiction to try cases of genocide, crimes against humanity and war crimes where states with the domestic criminal jurisdiction are unwilling to carry out investigations. Where multinational corporations commit crimes on a scale that reach the level of the courts jurisdiction individuals responsible can then be held liable.\n\n\n\n"}
{"id": "41358691", "url": "https://en.wikipedia.org/wiki?curid=41358691", "title": "Hydrodynamic quantum analogs", "text": "Hydrodynamic quantum analogs\n\nThe hydrodynamic quantum analogs refer to experimentally observed phenomena involving bouncing fluid droplets over a vibrating fluid bath that behave analogously to several quantum mechanical systems. A droplet can be made to bounce indefinitely in a stationary position on a vibrating fluid surface. This is possible due to a pervading air layer that prevents the drop from coalescing into the bath. For certain combinations of bath surface acceleration, droplet size, and vibration frequency, a bouncing droplet will cease to stay in a stationary position, but instead “walk” in a rectilinear motion on top of the fluid bath. Walking droplet systems have been found to mimic several quantum mechanical phenomena including particle diffraction, quantum tunneling, quantized orbits, the Zeeman Effect, and the quantum corral.\n\nBesides being an interesting means to visualise phenomena that are typical of the quantum mechanical world, floating droplets on a vibrating bath have interesting analogies with the pilot wave theory, also known as the De Broglie–Bohm theory, or the causal interpretation, one of the many interpretations of quantum mechanics in its early stages of conception and development. The theory was initially proposed by Louis de Broglie in 1927, \nand later developed by David Bohm. It suggests that all particles in motion are actually borne on a wave-like motion, similar to how an object moves on a tide. In this theory, it is the evolution of the carrier wave that is given by the Schrödinger equation. It is a deterministic theory and is entirely nonlocal. It is an example of a hidden variable theory, and all non-relativistic quantum mechanics can be accounted for in this theory. The theory was abandoned by de Broglie in 1932, and it gave way to the Copenhagen interpretation. The Copenhagen interpretation does not use the concept of the carrier wave or that a particle moves in definite paths until a measurement is made. \n\nFloating droplets on a vibrating bath were first described in writing by Jearl Walker in a 1978 article in \"Scientific American\". Recently in 2005, Yves Couder and his lab were the first to systematically study the dynamics of bouncing droplets and discovered most of the quantum mechanical analogs. John Bush and his lab expanded upon Couder’s work and studied the system in greater detail.\n\nA fluid droplet can float or bounce over a vibrating fluid bath because of the presence of an air layer between the droplet and the bath surface. The behavior of the droplet depends on the acceleration of the bath surface. Below a critical acceleration, the droplet will take successively smaller bounces before the intervening air layer eventually drains from underneath, causing the droplet to coalesce. Above the bouncing threshold, the intervening air layer replenishes during each bounce so the droplet never touches the bath surface. Near the bath surface, the droplet experiences equilibrium between inertial forces, gravity, and a reaction force due to the interaction with the air layer above the bath surface. This reaction force serves to launch the droplet back above the air like a trampoline. Molacek and Bush proposed two different models for the reaction force. The first models the reaction force as a linear spring, leading to the following equation of motion:\n\nThis model was found to more accurately conform to the experimental data.\n\nFor a small range of frequencies and drop sizes, a fluid droplet on a vibrating bath can be made to “walk” on the surface if the surface acceleration is sufficiently high (but still below the Faraday instability). That is, the droplet does not simply bounce in a stationary position but instead wanders in a straight line or in a chaotic trajectory. When a droplet interacts with the surface it creates a transient wave that propagates from the point of impact. These waves usually decay and stabilizing forces keep the droplet from drifting. However, when the surface acceleration is high, the transient waves created upon impact do not decay as quickly, deforming the surface such that the stabilizing forces are not enough to keep the droplet stationary. Thus, the droplet begins to “walk.” A detailed account of the forces involved in the dynamics of walking droplets is found in [ref].\n\nA walking droplet on a vibrating fluid bath was found to behave analogously to several different quantum mechanical systems, namely particle diffraction, quantum tunneling, quantized orbits, the Zeeman effect, and the quantum corral.\n\nIt has been known since the early 19th century that when light is shone through one or two small slits, a diffraction pattern is shown on a screen far from the slits. Light behaves as a wave and interferes with itself through the slits, creating a pattern of alternating high and low intensity. Single electrons also exhibit wave-like behavior as a result of wave-particle duality. When electrons are fired through small slits, the probability of the electron striking the screen at a specific point shows an interference pattern as well.\n\nIn 2006, Couder and Fort demonstrated that walking droplets passing through one or two slits exhibit similar interference behavior. They used a square shaped vibrating fluid bath with a constant depth (aside from the walls). The “walls” were regions of much lower depth, where the droplets would be stopped or reflected away. When the droplets were placed in the same initial location, they would pass through the slits and be scattered, seemingly randomly. However, by plotting a histogram of the droplets based on scattering angle, the researchers found that the scattering angle was not random, but droplets had preferred directions that followed the same pattern as light or electrons. In this way, the droplet may mimic the behavior of a quantum particle as it passes through the slit.\n\nQuantum tunneling is the quantum mechanical phenomenon where a quantum particle passes through a potential barrier. In classical mechanics, a classical particle could not pass through a potential barrier if the particle does not have enough energy, so the tunneling effect is confined to the quantum realm. For example, a rolling ball would not reach the top of a steep hill without adequate energy. However, a quantum particle, acting as a wave, can undergo both reflection and transmission at a potential barrier. This can be shown as a solution to the time dependent Schrödinger Equation. There is a finite, but usually small, probability to find the electron at a location past the barrier. This probability decreases exponentially with increasing barrier width.\n\nThe macroscopic analogy using fluid droplets was first demonstrated in 2009. Researchers set up a square vibrating bath surrounded by walls on its perimeter. These “walls” were regions of lower depth, where a walking droplet may be reflected away. When the walking droplets were allowed to move around in the domain, they usually were reflected away from the barriers. However, surprisingly, sometimes the walking droplet would bounce past the barrier, similar to a quantum particle undergoing tunneling. In fact, the crossing probability was also found to decrease exponentially with increasing width of the barrier, exactly analogous to a quantum tunneling particle.\n\nWhen two atomic particles interact and form a bound state, such the hydrogen atom, the energy spectrum is discrete. That is, the energy levels of the bound state are not continuous and only exist in discrete quantities, forming “quantized orbits.” In the case of a hydrogen atom, the quantized orbits are characterized by atomic orbitals, whose shapes are functions of discrete quantum numbers.\n\nOn the macroscopic level, two walking fluid droplets can interact on a vibrating surface. It was found that the droplets would orbit each other in a stable configuration with a fixed distance apart. The stable distances came in discrete values. The stable orbiting droplets analogously represent a bound state in the quantum mechanical system. The discrete values of the distance between droplets are analogous to discrete energy levels as well.\n\nWhen an external magnetic field is applied to a hydrogen atom, for example, the energy levels are shifted to values slightly above or below the original level. The direction of shift depends on the sign of the z-component of the total angular momentum. This phenomenon is known as the Zeeman Effect.\n\nIn the context of walking droplets, an analogous Zeeman Effect can be demonstrated by observing orbiting droplets in a vibrating fluid bath. The bath is also brought to rotate at a constant angular velocity. In the rotating bath, the equilibrium distance between droplets shifts slightly farther or closer. The direction of shift depends on whether the orbiting drops rotate in the same direction as the bath or in opposite directions. The analogy to the quantum effect is clear. The bath rotation is analogous to an externally applied magnetic field, and the distance between droplets is analogous to energy levels. The distance shifts under an applied bath rotation, just as the energy levels shift under an applied magnetic field.\n\nResearchers have found that a walking droplet placed in a circular bath does not wander randomly, but rather there are specific locations the droplet is more likely to be found. Specifically, the probability of finding the walking droplet as a function of the distance from the center is non-uniform and there are several peaks of higher probability. This probability distribution mimics that of an electron confined to a quantum corral.\n\n\n"}
{"id": "2929560", "url": "https://en.wikipedia.org/wiki?curid=2929560", "title": "Hyle", "text": "Hyle\n\nIn philosophy, hyle (; from ) refers to matter or stuff. It can also be the material cause underlying a change in Aristotelian philosophy. The Greeks originally had no word for matter in general, as opposed to raw material suitable for some specific purpose or other, so Aristotle adapted the word for \"wood\" to this purpose. The idea that everything physical is made of the same basic substance holds up well under modern science, although it may be thought of more in terms of energy or matter/energy.\n\nThe Aristotelian concept of \"hyle\" is the principle that correlates with \"eidos\" (form) and this can be demonstrated in the way the philosopher described \"hyle,\" saying it is that which receives form or definiteness, that which is formed. Aristotle explained that \"By \"hyle\" I mean that which in itself is neither a particular thing nor of a certain quantity nor assigned to any other of the categories by which being is determined.\" This means that hyle is brought into existence not due to its being its agent or its own actuality but only when form attaches to it. It is maintained that the Aristotelian concept should not be understood as a \"stuff\" since there is, for example, \"hyle\" that is intellectual as well as sensible \"hyle\" found in the body. \n\nFor Aristotle, hyle is composed of four elements - fire, water, air, and earth - but these were not considered pure substances since matter and form exist in a combination of hot, moist, dry, and cold so that everything is united to form the elements.\n\nThe matter of hyle is closely related to that of substance, in so far as both endure a change in form, or transformation. Aristotle defined primary substance as that which can neither be predicated nor attributed to something else, and he explained the transformation between the four terrestrial elements in terms of an abstract primary matter that underlies each element due to the four combinations of two properties: hot or cold and wet or dry. He stipulated that transformations between opposing elements, where both properties differ, must be analyzed as two discrete steps wherein one of the two properties changes to its contrary while the other remains unchanged (see essence and hylomorphism).\n\nModern substance theory differs, for example Kant's \"Ding an sich\", or \"thing in itself\", is generally described as whatever is its own cause, or alternatively as a thing whose only property is that it is that thing (or, in other words, that it has only that property). However, this notion is subject to the criticism, as by Nietzsche, that there is no way to \"directly\" prove the existence of any thing which has no properties, since such a thing could not possibly interact with other things and thus would be unobservable and indeterminate.\n\nOn the other hand, we may need to postulate a substance that endures through change in order to explain the nature of change—without an enduring factor that persists through change, there is no change but only a succession of unrelated events. The existence of change is hard to deny, and if we have to postulate something \"unobserved\" in order to explain what \"is\" observed, that is a valid \"indirect\" demonstration (by abductive reasoning). Moreover, something like a prime substance is posited by physics in the form of matter/energy.\n\n"}
{"id": "1710974", "url": "https://en.wikipedia.org/wiki?curid=1710974", "title": "Institutional dichotomy", "text": "Institutional dichotomy\n\nInstitutional dichotomy, according to John Wolfenden (responsible for the Wolfenden Report), in his essay \"The Gap — The Bridge\", states that the dichotomization of intellectual disciplines by educational institutions, specifically collegiate institutions, is to blame for the communication gap between specialists in different fields.\n\nForced to pursue contrasting disciplines in college, students diverge from the broad educational background established in high school and pursue narrower studies. As a result, these students lose contact with the shared basis of their education as they venture into separate abstract studies. In effect, the communication gap of collegiate students widens as they become saturated with a curriculum of abstractions that relate to a single area of study.\n\nFor instance, a college freshman chooses mathematics as his field of study while another chooses English. As they study, the two students become grossly out of touch as they adapt to new languages which will soon serve as a code in their future careers. The mathematics student becomes consumed by symbols and numbers while the English student immerses himself in a sea of classical literary styles and grammatical mechanics. Consequently, the students soon become ill-equipped to communicate with each other. The mathematics student now becomes \"illiterate\" by standards of the English major and the English major becomes \"innumerate\" by standards of the mathematics major. \n\nBecause knowledge is increasing, some fragmentation of disciplines is inevitable. The problem with fragmentation is that students are forced to live in ignorance of studies outside of their fields.\n\n\"The Two Cultures and the Scientific Revolution\" by C. P. Snow, 1959\n"}
{"id": "6582852", "url": "https://en.wikipedia.org/wiki?curid=6582852", "title": "Internet vigilantism", "text": "Internet vigilantism\n\nInternet vigilantism is the act of carrying out vigilante activities through the Internet (the communication network or its service providers) or carried out using applications (World Wide Web, e-mail) that depend on the Internet. The term encompasses vigilantism against alleged scams, crimes, and non-Internet related behavior. It was termed netilantism or digilantism in the wake of the Boston Marathon bombing.\n\nSome have suggested that the Internet's lack of central control prompted the tendency towards vigilante reactions against certain behaviors in the same way that they have prompted those behaviors to occur in the first place. Some observers note that the emergence of Internet vigilantism is an offshoot of the inability of governments to effectively police the Internet.\n\nVigilante activities on the Web are often based on denunciations that take a punitive turn. There are many methods and ways to vigilante on the web, but they can be defined into four main dimensions.\n\nMainly based on indignation, this dimension is punctual, people most of the time do not even realize they have been reported. These actions are often of low intensity, such as taking pictures, and the objective is a call to reinforce security or civility.\n\nPeople most of the time do not even realize that they have been reported, so the consequences for them a generally weak. The Instagram account \"Passenger Shaming\" is an example of that kind of vigilante.\n\nInvestigation is the next step, it is about seeking to identify a person or a group of people. It most often rely on collective work and with more important means. Also, this field of vigilantism refers to action whose intentionality is more assertive. The investigation can be useful to help police institutions, but the risk, with a public denonciation is to make a witch hunt and limit the presumption of innocence.\n\nIdentification and investigation with a clear objective of punishing the guilty party. It is a lot more organised than investigation. The method is very controversial because the targeting of the individual is very important \n\nUnlike the first three forms of online self-righteousness, these are practices that are framed by devices specifically designed for whistle-blowing and, on the other hand, more explicitly rooted in justifications. They also refer themselves to the general interest. Wikileaks is an example of that kind of organized vigilante.\n\nThe following are methods of Internet vigilantism that have been used or proposed for use:\n\nScam baiting is the practice of feigning interest in a scam in order to manipulate the scammer behind it. The purpose of scam baiting might be to waste the scammers' time, embarrass him or her, cause them to reveal information which can be passed on to legal authorities in the hope that they will be prosecuted, get them to spend money, or simply to amuse the baiter.\n\nScam baiting emerged in response to e-mail based frauds such as the common Nigerian 419 scam. Many websites publish transcripts of correspondences between baiters and scammers, and also publish their \"trophies\" online, which include videos and images scam baiters have obtained from scammers.\n\nThe social networking tools of the World Wide Web have been used as a tool to easily and widely publicize instances of perceived anti-social behavior.\n\nDavid Furlow, chairman of the Media, Privacy and Defamation Committee of the American Bar Association, has identified the potential privacy concerns raised by websites facilitating the distribution of information that is not part of the public record (documents filed with a government agency), and has said that such websites \"just [give] a forum to people whose statements may not reflect truth.\"\n\nAfter some controversial incidents of public shaming, the popular link-sharing and discussion website Reddit introduced a strict rule against the publication of non-public personally-identifying information via the site (colloquially known on Reddit and elsewhere as \"doxing\"). Those who break the rule are subject to a site-wide ban, and their posts and even entire communities may be removed for breaking the rule.\n\nPublic shaming as a form of Internet vigilantism is also prevalent in China. One of the recent cases involved a woman who cheated on her husband, who posted his wife's romantic alliance online. Online groups began targeting her lover on the street, harassing him relentlessly until he finally quit his university and stayed at home.\n\nIn 2015, online shaming was the subject of a book titled So You've Been Publicly Shamed by Jon Ronson.\n\nA DDoS attack can be used to take down malicious websites, such as those being used for phishing or drive-by downloads. Thousands of people generate traffic to a website, flooding it such that it goes over quota or simply can't serve that many requests in a timely manner.\n\nProject Chanology was a protest movement against the practices of the Church of Scientology by members of Anonymous, a leaderless Internet-based group that defines itself as ubiquitous. The project was started in response to the Church of Scientology's attempts to remove material from a highly publicized interview with Scientologist Tom Cruise from the Internet in January 2008.\n\nProject Chanology began its campaign by organizing and delivering a series of denial-of-service attacks against Scientology websites. The group was successful in taking down local and global Scientology websites intermittently from January 18, 2008 until at least January 25, 2008. Anonymous had early success rendering major Scientology websites inaccessible and leaking documents allegedly stolen from Scientology computers. This resulted in a large amount of coverage on social bookmarking websites.\n\nIn September 2010, Girish Kumar, the founder of Aiplex Software, admitted to using distributed denial of service attacks against known and suspected copyright violators including some large-profile P2P sites resulted in the company's servers as well as those of the MPAA and RIAA suffering a DDoS attack themselves. The attack was launched by Anonymous, coordinated through IRC; the participants have willingly given control over their LOIC to the IRC, forming a voluntary botnet in order to overpower their targets.\n\nAs a result, Aiplex went offline for a full 24 hours while the MPAA's website was unreachable for 22 hours. The RIAA, the Gallant Macmillan and ACS Law firm, as well as AFACT and the Ministry of Sound has been targeted as well.\n\nOn 16 October 2010, Anonymous launched an attack against the UK Intellectual Property Office website. The attack commenced at 17:00 GMT, causing the site to go down swiftly. It was brought back online on October 22. The rationale for the attack was that the site was \"Perpetuating the system that is allowing the exploitative usage of copyright and intellectual property.\"\n\nIn December 2002, convicted spammer Alan Ralsky was interviewed by the Detroit News. In the interview, Ralsky defended his position by arguing that spamming was a \"perfectly legal business.\" He also claimed that he would never quit spamming and expressed interest at some of the newest spamming technologies such as \"stealth spamming\".\n\nShortly afterwards, this article was posted on Slashdot, a popular technology news site. In response to Ralsky's remarks, the members of Slashdot posted his personal information and urged people to use this information to subscribe Ralsky to a number of free mailing subscriptions for the purpose of sending junk mail to his home. As a result, Ralsky's home received bags of mail daily.\n\nIn response to MegaUpload's seizure by the US Department of Justice and FBI, the hacker group Anonymous announced on Twitter, \"We Anonymous are launching our largest attack ever on government and music industry sites. Lulz. The FBI didn't think they would get away with this did they? They should have expected us.\" Later that week, as many as 10 sites had been taken offline in response to the Megaupload shutdown including the FBI, Universal Music, RIAA (Recording Industry Association of America) and Hadopi - the French government agency responsible for \"protecting creative works on the Internet\" and \"the attacks were carried out by spreading links via Twitter and other parts of the Internet which carried out distributed denial-of-service attacks\".\n\nAmerican judge Shannen Rossmiller, serving in Montana, has a controversial role as a vigilante online terrorist-hunter, posing as militant anti-American Muslim radicals online, hoping to attract the eye of those with similar mindsets.\n\nGoogle bombing is a process where website owners manipulate Internet search ranking algorithms to link searches from one term to another. A group of activists chose to manipulate Google by adding hyperlinks to George W. Bush and Michael Moore with the anchor text \"miserable failure\", so that a person searching for the term \"miserable failure\" was more likely to find political figures.\n\nThe campaign for the neologism \"santorum\" started with a contest held in May 2003 by Dan Savage, a columnist and LGBT rights activist. Savage asked his readers to create a definition for the word \"santorum\" in response to then-U.S. Senator Rick Santorum's views on homosexuality, and comments about same sex marriage. In his comments, Santorum had stated that \"In every society, the definition of marriage has not ever to my knowledge included homosexuality. That's not to pick on homosexuality. It's not, you know, man on child, man on dog, or whatever the case may be.\" Savage announced the winning entry, which defined \"santorum\" as \"the frothy mixture of lube and fecal matter that is sometimes the byproduct of anal sex\". He created a web site, spreadingsantorum.com (and santorum.com), to promote the definition, which became a top Internet search result displacing the Senator's official website on many search engines, including Google, Yahoo! Search, and Bing. Savage offered in May 2010 to remove the site if Santorum donated $5 million to Freedom to Marry, an advocacy group for same-sex marriage.\n\nIn September 2014 the hacker group 'Lizard Squad' carried out multiple DDoS attacks against a variety of online games, including Destiny, Call of Duty: Ghosts, FIFA, Madden, and The Sims 4. The game servers were brought offline multiple times, which caused a large commotion in the gaming community and on Twitter.\n\nPerverted Justice is a well-known example of an anti-pedophile organization that engages online volunteers in its activities to expose and convict adults who, using email or web sites, solicit minors in order to commit child sexual abuse. As part of its initiatives, this organization posts the personal information of offenders online, including their pictures, homes, and places of business or work. It carries out its activities offline, after its members reportedly harass offenders who have been previously arrested at their workplaces and even at home. It also often collaborates with television crews such as those from Dateline. Some freely hosted blogs claim to expose real or potential child sex offenders. The television series \"To Catch a Predator,\" aired 12 episodes featuring this form of sting operation to lure predators into sexual liaisons. Producers used the Internet, particularly chat rooms, to entrap would-be offenders into fake assignations with minors. Once the pedophile arrives at the scene, he was publicly shamed and harangued by a television personality before getting arrested by a local law enforcement. The humiliation also entailed being booked and questioned, which were recorded for network viewing.\n\nAnother initiative, Predator Hunter, headed by Wendell Kreuth, aims to track down and expose the pornography-related activities of alleged 'sexual predators'. In 2002, Kreuth disclosed details of his activities in an interview with Minnesota Public Radio.\n\nThe Australian group MAKO has used the Internet to warn families about sex offenders in their areas, and to coordinate warnings about them.\n\nMembers of the subculture \"Anonymous\" have also been credited for seeking out pedophiles and collaborating with law enforcement. They describe themselves as a collection of individuals united by ideas. They left a mark with the arrest of Canadian pedophile Chris Forcand. In early November 2011, Anonymous launched Operation Darknet, which targeted websites that distribute and traffic child pornography. Anonymous reportedly leaked the personal details of more than 1,100 pedophiles to Pastebin, and invited FBI and Interpol to investigate the information for leads.\n\nMembers of the Usenet group Alt.Hackers.Malicious have also been known to target and expose child predators, taking credit for dozens of arrests and convictions. They are most well known for breaking into the NAMBLA servers on three separate occasions, downloading and disseminating the organization's membership information as well as emails which directly led to several arrests and convictions of child sexual abuse.\n\nIn June, Anonymous members claimed to have located and identified two predators in Edmonton, Alberta, Canada. After passing on the information and \"evidence\" including a video purportedly showing one of the alleged pedophiles attempting to lure youths, Edmonton police announced they would not be able to lay charges due to a lack of real evidence. They also stated that Anonymous' interference and public attacks on their integrity in the media were interfering with their investigation of legitimate cases, and not providing them with any help. An e-mailed statement to media from Alberta Law Enforcement Response Teams’ Integrated Child Exploitation (ICE) Unit in Edmonton said, \"The video postings this week have not only hampered our investigations, but have also distracted our ICE team and investigators from other work,\" adding \"The time we have spent dealing with these videos has been at the expense of other important child sexual exploitation investigations.\" ICE followed up by saying they are committed to working with any tipster who can help them stop child exploitation, including Anonymous.\n\nOrganizations similar to vigilante action against pedophiles also target ID theft. Posing as ID thieves, they gather stolen personal information such as \"dumps\" (the raw encoded information contained on a payment or identification card's magnetic stripe, microchip or transponder), bank account numbers and login information, social security numbers, etc. They then pass this information on to the associated banks, to credit monitoring companies, or to law enforcement.\n\nOther groups specialize in the removal of phishing websites, fake banks, and fraudulent online storefronts, a practice known as \"site-killing\". Artists Against 419 is a web site specializing in the removal of fake bank websites. Such groups often use tactics like DDoS attacks on the offending website, with the aim of drawing attention to the site by its hosting service or rapid consumption of the site's monthly bandwidth allowance. The Artists Against 419 always argued their tools were not a denial-of-service attack. At any rate they abandoned such tactics in 2007.\n\nSome companies engage in Internet vigilantism for profit. One such example is MediaDefender, a company which used methods such as entrapment, P2P poisoning, and DDoS attacks.\n\nAround the time of the 2008 Summer Olympics torch relay, which was marred by unrest in Tibet, Chinese hackers claim to have hacked the websites of CNN (accused of selective reporting on the 2008 Lhasa riots) and Carrefour (a French shopping chain, allegedly supporting Tibetan independence), while websites and forums gave tutorials on how to launch a DDoS attack specifically on the CNN website.\n\nSome people form themselves into vigilante groups aiming (overtly) to expose injustice, whitewash and cover-ups in high-profile criminal cases against innocent victims, often children. Recent cases include the death of JonBenét Ramsey in the US and the disappearance of the British girl Madeleine McCann in Portugal.\n\nAn example cited on the tech news site securityfocus.com by Kevin Poulsen illustrates how two coders implemented and distributed a program that disguised itself as activation key generators and cracks for illegal software circulating on peer-to-peer file sharing sites. The duo researched software that was popular on these file sharing sites and tagged their code with their names. As soon as the software was executed, it displayed a large message: “Bad Pirate! So, you think you can steal from software companies do you? That's called theft, don't worry your secret is safe with me. Go thou [sic] and sin no more.\" The software then called back to a central server and logged the file name under which it was executed, amount of time the message was displayed on the downloader’s computer screen and their IP address. The information gathered was then re-posted onto a public website showing the downloader’s IP address and country of origin. The program also had a unique ID embedded into each downloaded copy of it for tracking purposes to keep track of how it traversed the different networks.\nMany sites have taken measures to prevent vigilantism. One form is the reporting and deletion of any sensitive information regarding an individual or group that can lead to their identity being known. Admins, moderators, users, and bots all take action to find and detect doxing.\n\nIn 2002 in the United States, Representative Howard Berman proposed the \"Peer to Peer Piracy Prevention Act\", which would have protected copyright holders from liability for taking measures to prevent the distribution, reproduction or display of their copyrighted works on peer-to-peer computer networks. Berman stated that the legislation would have given copyright holders \"both carrots and sticks\" and said that \"copyright owners should be free to use reasonable, limited self-help measures to thwart P2P piracy if they can do so without causing harm.\" Smith College assistant professor James D. Miller acknowledged the threats to the privacy of legitimate Internet users that such actions would pose, but drew comparisons with other successful crime-fighting measures that can invade privacy, such as metal detectors at airports.\n\n\n\n"}
{"id": "6126919", "url": "https://en.wikipedia.org/wiki?curid=6126919", "title": "Ivan Tyrrell", "text": "Ivan Tyrrell\n\nIvan Tyrrell (; born 18 October 1943) is a British educator, writer, and artist. He lives with his wife Véronique in the Cotswolds, England.\n\nTyrrell left Wallington County Grammar School to study art as an apprentice at F.G. Marshal in 1959. In 1962 he began a fine arts course at Croydon Art College and was taught painting by Bridget Riley, Barry Fantoni and John Hoyland among others. He left college disillusioned with the art world and worked in London advertising studios before setting up a graphic design company in 1971 on the South Coast in Sussex.\n\nTwo silk-screen posters produced with fellow artist Frederick Carver featured in \"Les Sixties\", a Paris exhibition of psychedelic art that then transferred to the Brighton Festival and… “the spectral, hallucinatory scenarios of J.G. Ballard, especially in his novel \"The Crystal World\" – bodied forth in Tyrrell’s apocalyptic poster design.\"\n\nIn 1965 Tyrrell, whilst still a student, had met the writer, Idries Shah, who had begun introducing timeless ideas from the Sufi tradition into the Western world. In 1969 he was invited to attend regular gatherings of writers, poets, actors, businessmen, diplomats, academics, craftsmen and others at Shah’s home in Kent.\n\nHe joined The Institute for Cultural Research in 1970. In 1977 Tyrrell art directed thirty-six illustrators for the first edition of \"World Tales\" by Idries Shah and contributed some illustrations himself.\n\nIn 1987 he closed his graphic design service due to the recession and began learning about psychotherapy. He was shocked to discover how bad training was: most psychotherapists had little basic knowledge of psychology and worked mainly from simplistic and cult-like therapy movements.\n\nIn 1993, encouraged by the psychiatrist and writer Robin Skynner, author Doris Lessing, psychologist Joe Griffin and Idries Shah, he launched a journal, \"The Therapist\", in an attempt to inject some scientific rigour and common sense into the field. Medical journalist Denise Winn was appointed Editor in 1997 and Ivan Tyrrell became General Editor. In 2000 its name was changed to \"Human Givens\", to reflect the growing interest in the Human Givens approach to psychotherapy, behaviour and education that he was developing with Griffin. Human Givens is now the official journal of the Human Givens Institute. The journal gave him the opportunity of publishing interviews with people whose ideas interested him such as: Richard Bentall, Doris Lessing, Robin Skynner, Margaret Heffernan, John Cacioppo and many others.\n\nTyrrell began teaching courses in psychology and psychotherapy in 1996 and is now director with Joe Griffin of Human Givens College. The Griffin/Tyrrell collaboration contributed to psychotherapy and consciousness studies and publications. Their human givens approach is now endorsed by peer-reviewed papers.\n\n\n\n"}
{"id": "1074997", "url": "https://en.wikipedia.org/wiki?curid=1074997", "title": "Lamb shift", "text": "Lamb shift\n\nIn physics, the Lamb shift, named after Willis Lamb, is a difference in energy between two energy levels 2\"S\" and 2\"P\" (in term symbol notation) of the hydrogen atom which was not predicted by the Dirac equation, according to which these states should have the same energy.\n\nInteraction between vacuum energy fluctuations and the hydrogen electron in these different orbitals is the cause of the Lamb shift, as was shown subsequent to its discovery. The Lamb shift has since played a significant role through vacuum energy fluctuations in theoretical prediction of Hawking radiation from black holes.\n\nThis effect was first measured in 1947 in the Lamb–Retherford experiment on the hydrogen microwave spectrum and this measurement provided the stimulus for renormalization theory to handle the divergences. It was the harbinger of modern quantum electrodynamics developed by Julian Schwinger, Richard Feynman, Ernst Stueckelberg, Sin-Itiro Tomonaga and Freeman Dyson. Lamb won the Nobel Prize in Physics in 1955 for his discoveries related to the Lamb shift.\n\nOn Lamb's 65th birthday, Freeman Dyson addressed him as follows: \"Those years, when the Lamb shift was the central theme of physics, were golden years for all the physicists of my generation. You were the first to see that this tiny shift, so elusive and hard to measure, would clarify our thinking about particles and fields.\"\n\nThis heuristic derivation of the electrodynamic level shift following Welton is from \"Quantum Optics\".\n\nThe fluctuation in the electric and magnetic fields associated with the QED vacuum perturbs the electric potential due to the atomic nucleus. This perturbation causes a fluctuation in the position of the electron, which explains the energy shift. The difference of potential energy is given by\n\nSince the fluctuations are isotropic,\n\nSo one can obtain\n\nThe classical equation of motion for the electron displacement (\"δr\") induced by a single mode of the field of wave vector and frequency \"ν\" is\n\nand this is valid only when the frequency \"ν\" is greater than \"ν\" in the Bohr orbit, formula_6. The electron is unable to respond to the fluctuating field if the fluctuations are smaller than the natural orbital frequency in the atom.\n\nFor the field oscillating at \"ν\",\n\ntherefore\n\nwhere formula_9 is some large normalization volume (the volume of the hypothetical \"box\" containing the hydrogen atom). By the summation over all formula_10\n\nThis result diverges when no limits about the integral (at both large and small frequencies). As mentioned above, this method is expected to be valid only when formula_6, or equivalently formula_13. It is also valid only for wavelengths longer than the Compton wavelength, or equivalently formula_14. Therefore, one can choose the upper and lower limit of the integral and these limits make the result converge.\n\nFor the atomic orbital and the Coulomb potential,\n\nsince it is known that\n\nFor \"p\" orbitals, the nonrelativistic wave function vanishes at the origin, so there is no energy shift. But for \"s\" orbitals there is some finite value at the origin,\n\nwhere the Bohr radius is\n\nTherefore,\n\nFinally, the difference of the potential energy becomes:\n\nwhere formula_22 is the fine-structure constant. This shift is about 1 GHz, very similar with the observed energy shift.\n\nIn 1947 Willis Lamb and Robert Retherford carried out an experiment using microwave techniques to stimulate radio-frequency transitions between\n\"S\" and \"P\" levels of hydrogen. By using lower frequencies than for optical transitions the Doppler broadening could be neglected (Doppler broadening is proportional to the frequency). The energy difference Lamb and Retherford found was a rise of about 1000 MHz of the \"S\" level above the \"P\" level.\n\nThis particular difference is a one-loop effect of quantum electrodynamics, and can be interpreted as the influence of virtual photons that have been emitted and re-absorbed by the atom. In quantum electrodynamics the electromagnetic field is quantized and, like the harmonic oscillator in quantum mechanics, its lowest state is not zero. Thus, there exist small zero-point oscillations that cause the electron to execute rapid oscillatory motions. The electron is \"smeared out\" and each radius value is changed from \"r\" to \"r\" + \"δr\" (a small but finite perturbation).\n\nThe Coulomb potential is therefore perturbed by a small amount and the degeneracy of the two energy levels is removed. The new potential can be approximated (using atomic units) as follows:\n\nThe Lamb shift itself is given by\n\nwith \"k\"(\"n\", 0) around 13 varying slightly with \"n\", and\n\nwith \"k\"(\"n\",) a small number (< 0.05).\n\nFor a derivation of Δ\"E\" see for example:\n\nIn 1947, Hans Bethe was the first to explain the Lamb shift in the hydrogen spectrum, and he thus laid the foundation for the modern development of quantum electrodynamics. Bethe was able to derive the Lamb shift by implementing the idea of mass renormalization, which allowed him to calculate the observed energy shift as the difference between the shift of a bound electron and the shift of a free electron.\n\nThe Lamb shift currently provides a measurement of the fine-structure constant α to better than one part in a million, allowing a precision test of quantum electrodynamics.\n\nA different perspective relates Zitterbewegung to the Lamb shift.\n\n\n"}
{"id": "49102340", "url": "https://en.wikipedia.org/wiki?curid=49102340", "title": "Language and spatial cognition", "text": "Language and spatial cognition\n\nThe question whether the use of language influences spatial cognition is closely related to theories of linguistic relativity—also known as the Sapir-Whorf hypothesis—which states that the structure of a language affects cognitive processes of the speaker. Debates about this topic are mainly focused on the extent to which language influences spatial cognition or if it does at all. Research also concerns differences between perspectives on spatial relations across cultures, what these imply, and the exploration of potentially partaking cognitive mechanisms.\n\nResearch shows that frames of reference for spatial cognition differ across cultures and that language could play a crucial role in structuring these different frames.\nThree types of perspectives on space can be distinguished:\nLanguages like English or Dutch do not exclusively make use of relative descriptions but these appear to be most frequent compared to intrinsic or absolute descriptions. An absolute frame of reference is usually restricted to large scale geographical descriptions in these languages. Speakers of the Australian languages Arrernte, Guugu Yimithirr, and Kuuk Thaayore only use absolute descriptions.\nThe relative and intrinsic perspectives seem to be connected as there is no known language which applies only one of these frames of reference exclusively.\n\n(1.) It has been argued that people universally use an egocentric representation to solve non-linguistic spatial tasks which would align with the relative frame of reference.\n(2.) Other researchers have proposed that people apply multiple frames of reference during their daily lives and that languages reflect these cognitive structures.\nIn the light of the current body of literature the second view seems to be the more plausible one.\n\nThe dominant frames of reference have found to be reflected in the common types of gesticulation in the respective language. Speakers of absolute languages would typically represent an object moving north with a hand movement towards the north. Whereas speakers of relative languages typically depict a movement of an object to the right with a hand movement to the right, independent of the direction they are facing during speech. Speakers of intrinsic languages would, for example, typically represent human movement from the perspective of the mover with a sagittal hand gesture away from the speaker.\n\nA study by Boroditsky and Gaby compared speakers of an absolute language—Pormpuraawans—with English speakers. The task on which they compared them consisted of the spatial arrangement of cards which showed a temporal progression. The result was that the speakers of the relative language (Americans) exclusively chose to represent time spatially as progressing from left (earlier time) to right (later time). Whereas the Pormpuraawans took the direction they faced into account and preferred to depict time as progressing from east (earlier time) to west (later time) the most.\n\nConfounding variables could potentially explain a significant proportion of the measured difference in performance between the linguistic frames of reference. \nThese can be categorized into three types of confounding factors:\n\nGentner, Özyürek, Gürcanli, and Goldin-Meadow found that deaf children, who lacked a conventional language, did not use gestures to convey spatial relations (see home sign). Building on that, they showed that deaf children performed significantly worse on a task of spatial cognition compared to hearing children. They concluded that the acquisition of (spatial) language is an important factor in shaping spatial cognition.\n\nSeveral mechanisms accounting for or contributing to the possible effect of language on cognition have been suggested: \n"}
{"id": "53504025", "url": "https://en.wikipedia.org/wiki?curid=53504025", "title": "Legal syllogism", "text": "Legal syllogism\n\nLegal syllogism is a legal concept concerning the law and its application. It is based upon deductive reasoning applied for the sake of law, hence it is also called legal deduction or deductive legal reasoning.\n\nIn legal syllogism there are two premises, minor and major, and one conclusion.\n\nThe place of the major premise is taken by a legal norm (or rule). This norm (rule) may be derived from canonical text (text of statutes, constitutions, regulations, international treaties and agreements, ordinances, bylaws etc) or from a judicial precedent. In the latter case, it can be called \"ratio decidendi\" or ruling. In the main, it can be considered as a general expression which, in generic terms, states what one ought to do or ought not to do in a certain type of circumstances. \n\nThe facts of the case at hand (also called pending, instant, \"sub judice\", at bar or under argument) serve as the minor premise. These facts may be understood as all elements of the factual setting of the case at hand, i.e. the details of the events, things and persons which occurred in a case to which the rule/norm that constitutes the major premise is to be applied deductively.\n\nThe conclusion is formed by the legal consequence for the case at hand.\n\nIf the norm that forms the major premise is valid (binding in a given legal system) and the facts of the case at hand are proven or posited as true, the conclusion of legal syllogism which flows from subsuming these facts under this norm (rule) is supposed to be correct as well.\n\nIn that sense, legal syllogism can be deemed to be equally infallible as 'ordinary' ('logical') syllogism. Such a claim is, however, ill-founded and, in fact, subsumption of a concrete case under a general rule proves to be a value-laden and goal-oriented process. Neither is it 'logical', nor 'mechanical'. \n\n"}
{"id": "969736", "url": "https://en.wikipedia.org/wiki?curid=969736", "title": "Livestock branding", "text": "Livestock branding\n\nLivestock branding is a technique for marking livestock so as to identify the owner. Originally, livestock branding only referred to hot branding large stock with a branding iron, though the term now includes alternative techniques. Other forms of livestock identification include freeze branding, inner lip or ear tattoos, earmarking, ear tagging, and radio-frequency identification (RFID), tagging with a microchip implant. The semi-permanent paint markings used to identify sheep are called a paint or colour brand. In the American West, branding evolved into a complex marking system still in use today.\n\nThe act of marking livestock with fire-heated marks to identify ownership has origins in ancient times, with use dating back to the ancient Egyptians around 2,700BC. Among the ancient Romans, the symbols used for brands were sometimes chosen as part of a magic spell aimed at protecting animals from harm.\n\nIn English lexicon, the word \"brand\", common to most Germanic languages (from which root also comes \"burn\", cf. German \"Brand\" \"burning, fire\"), originally meant anything hot or burning, such as a \"firebrand\", a burning stick. By the European Middle Ages, it commonly identified the process of burning a mark into stock animals with thick hides, such as cattle, so as to identify ownership under \"animus revertendi\". The practice became particularly widespread in nations with large cattle grazing regions, such as Spain.\n\nThese European customs were imported to the Americas and were further refined by the \"vaquero\" tradition in what today is the southwestern United States and northern Mexico. In the American West, a \"branding iron\" consisted of an iron rod with a simple symbol or mark, which cowboys heated in a fire. After the branding iron turned red hot, the cowboy pressed the branding iron against the hide of the cow. The unique brand meant that cattle owned by multiple ranches could then graze freely together on the open range. Cowboys could then separate the cattle at \"roundup\" time for driving to market. Cattle rustlers using running irons were ingenious in changing brands. The most famous brand change involved the making of the X I T brand into the Star-Cross brand, a star with a cross inside. Brands became so numerous that it became necessary to record them in books that the ranchers could carry in their pockets. Laws were passed requiring the registration of brands, and the inspection of cattle driven through various territories. Penalties were imposed on those who failed to obtain a bill of sale with a list of brands on the animals purchased.\n\nFrom the Americas, many cattle branding traditions and techniques spread to Australia, where a distinct set of traditions and techniques developed. Livestock branding has been practiced in Australia since 1866, but after 1897, owners had to register their brands. These fire and paint brands could not then be duplicated legally. \nFree-range or open-range grazing is less common today than in the past. However, branding still has its uses. The main purpose is in proving ownership of lost or stolen animals. Many western US states have strict laws regarding brands, including brand registration, and require brand inspections. In many cases, a brand on an animal is considered \"prima facie\" proof of ownership. (See Brand Book)\n\nIn the hides and leather industry, brands are treated as a defect, and can diminish the value of hides. This industry has a number of traditional terms relating to the type of brand on a hide. \"Colorado branded\" (slang \"Collie\") refers to placement of a brand on the side of an animal, although this does not necessarily indicate the animal is from Colorado. \"Butt branded\" refers to a hide which has had a brand placed on the portion of the skin covering the rump area of the animal. A \"cleanskin\" animal is one without a brand while the skin without a brand is \"native\".\n\nOutside of the livestock industry, hot branding was used in 2003 by tortoise researchers to provide a permanent means of unique identification of individual Galapagos tortoises being studied. In this case, the brand was applied to the rear of the tortoises' shells. This technique has since been superseded by implanted PIT microchips (combined with ID numbers painted on the shell).\n\nThe traditional cowboy or stockman captured and secured an animal for branding by roping it, laying it over on the ground, tying its legs together, and applying a branding iron that had been heated in a fire. Modern ranch practice has moved toward use of chutes where animals can be run into a confined area and safely secured while the brand is applied. Two types of restraint are the cattle crush or squeeze chute (for larger cattle), which may close on either side of a standing animal, or a branding cradle, where calves are caught in a cradle which is rotated so that the animal is lying on its side. \nBronco branding is an old method of catching cleanskin (unbranded) cattle on Top End cattle stations for branding in Australia. A heavy horse, usually with some draught horse bloodlines and typically fitted with a harness horse collar, is used to rope the selected calf. The calf is then pulled up to several sloping topped panels and a post constructed for the purpose in the centre of the yard. The unmounted stockmen then apply leg ropes and pull it to the ground to be branded, earmarked and castrated (if a bull) there. With the advent of portable cradles, this method of branding has been mostly phased out on stations. However, there are now quite a few bronco branding competitions at rodeos and campdrafting days, etc.\n\nSome ranches still heat branding irons in a wood or coal fire; others use an electric branding iron or electric sources to heat a traditional iron. Gas-fired branding iron heaters are quite popular in Australia, as iron temperatures can be regulated and there is not the heat of a nearby fire. Regardless of heating method, the iron is only applied for the amount of time needed to remove all hair and create a permanent mark. Branding irons are applied for a longer time to cattle than to horses, due to the differing thicknesses of their skins. If a brand is applied too long, it can damage the skin too deeply, thus requiring treatment for potential infection and longer-term healing. Branding wet stock may result in the smudging of the brand. Brand identification may be difficult on long-haired animals, and may necessitate clipping of the area to view the brand.\n\nHorses may also be branded on their hooves, but this is not a permanent mark, so needs to be redone about every six months. In the military, some brands indicated the horses' army and squadron numbers. These identification numbers were used on British army horses so dead horses on the battlefield could be identified. The hooves of the dead horses were then removed and returned to the Horse Guards with a request for replacements. This method was used to prevent fraudulent requests for horses. Merino rams and bulls are sometimes firebranded on their horns for permanent individual identification.\n\nTemporary branding is achieved by heat branding lightly, so that the hair is burned, but the skin is not damaged. Because this persists only until the animal sheds its hair, it is not considered a properly applied brand.\n\nSome types of identification are numbering systems, neck chains, nose printing, electronic identification, and tattooing. The numbering system is a way to identify animals in a herd. It does this by putting together a letter and number to represent the year born and the birth order. The neck chains are a common way of identification with dairy cattle. The chain is labeled with a tag that has a number on it that goes along with the identification numbers. Nose printing is a common way of identification in the sale ring and at exhibiting show with some livestock. This method is like finger printing: it uses ink and cannot be modified. Electronic identification is where an electronic ear tag, microchip, or collar is placed on an animal by implanting the chip. This is done in case a tag is lost.\n\nThere are several methods of temporary branding for goats. Ear tagging, ear tattooing, and microchipping are three of these. These types of branding are usually used on goats under eight weeks of age because regular branding would harm them. Techniques similar to these are also used on sheep.\n\nTemporary branding in ewes can be done with paint, crayons, spray markers, chalk, and much more. These can last for up to several months at a time. The sheep's identification number is painted or sprayed onto their sides or back. However, regular spray paint should never be used, as it contains chemicals that acts as painful skin irritants. Only paint that is made specifically for sheep should be put onto them.\n\nIn contrast to traditional hot-iron branding, freeze branding uses a branding iron that has been chilled with a coolant such as dry ice or liquid nitrogen. Rather than burning a scar into the animal, a freeze brand damages the pigment-producing hair cells, causing the animal's hair to grow white where the brand has been applied. Freeze brands cause less damage to the animals' hides than hot iron brands, and can be more visible. Horses are frequently freeze-branded. At this time, hogs cannot be successfully freeze branded, as their hair pigment cells are better protected. Also, freeze branding is slower, more expensive, less predictable (more care is required in application to assure desired results), and in some places does not constitute a legal brand on cattle. When an animal grows a long hair coat, the freeze brand is still visible, but its details are not always clear. Thus, it is sometimes necessary to shave or closely trim the hair so that a sharper image of a freeze brand can be viewed.\n\nTo apply a freeze brand, all hair is shaved at the branding site. This is because hair is an excellent insulator, and must be removed so the extreme cold of the freeze branding iron can be applied directly to the skin. The iron, made of metal such as brass or copper that removes heat rapidly from the skin, is submerged into the coolant. Immediately before the iron is applied, the animal's skin is rubbed, squirted, or sprayed with a generous amount of 99% alcohol, then the freeze branding iron is removed from the coolant and held onto the skin with firm pressure for several seconds. The exact amount of time will vary according to the species of the animal, the thickness of its skin, the type of metal the branding iron is made of, the type of coolant being used, and the color of its hair coat. Because a freeze-branded hair follicle regrows as white hair, a light-haired animal will have a freeze brand kept on the skin longer than does a dark-haired animal, so as to eliminate the hair follicle altogether and allow bare skin to show the brand.\n\nBesides livestock, freeze branding can also be used on wild, hairless animals such as dolphins for purposes of tracking individuals. The brand appears as a white mark on their bare skin and can last for decades.\n\nImmediately after the freeze branding iron is removed from the skin, an indented outline of the brand will be visible. Within seconds, however, the outline will disappear and within several minutes after that, the brand outline will reappear as swollen, puffy skin. Once the swelling subsides, for a short time, the brand will be difficult or impossible to see, but in a few days, the branded skin will begin to flake, and within three to four weeks, the brand will begin to take on its permanent appearance.\n\nIn Australia, all Arabian, Part Bred Arabians, Australian Stock Horses, Quarter Horses, Thoroughbreds, and the nine pony breeds registered in the Australian Pony Stud Book must be branded with an owner brand on the near (left) shoulder and an individual foaling drop number (in relation to the other foals) over the foaling year number on the off shoulder. In Queensland, these three brands may be placed on the near shoulder in the above order. Stock Horse and Quarter Horse classification brands are placed on the hindquarters by the classifiers.\n\nThoroughbreds and Standardbreds in Australia and New Zealand are freeze branded. Standardbred brands are in the form of the Alpha Angle Branding System (AABS), which the United States also uses.\n\nIn the United States, branding of horses is not generally mandated by the government; however, there are a few exceptions: captured Mustangs made available for adoption by the BLM are freeze branded on the neck, usually with the AABS or with numbers, for identification. Horses that test positive for equine infectious anemia, that are quarantined for life rather than euthanized, will be freeze branded for permanent identification. Race horses of any breed are usually required by state racing commissions to have a lip tattoo, to be identified at the track. Some breed associations have, at times, offered freeze branding as either a requirement for registration or simply as an optional benefit to members, and individual horse owners may choose branding as a means by which to permanently identify their animals. As of 2011, the issue of whether to mandate horses be implanted with RFID microchips under the National Animal Identification System generated considerable controversy in the United States.\n\nMost brands in the United States include capital letters or numerals, often combined with other symbols such as a slash, circle, half circle, cross, or bar. Brands of this type have a specialized language for \"calling\" the brand. Some owners prefer to use simple pictures; these brands are called using a short description of the picture (e.g., \"rising sun\"). Reading a brand aloud is referred to as “calling the brand“. Brands are called from left to right, top to bottom, and when one character encloses another, from outside to inside. Reading of complex brands and picture brands depends at times upon the owner's interpretation, may vary depending upon location, and it may require an expert to identify some of the more complex marks.\n\nTerms used are:\n\n\nCombinations of symbols can be made with each symbol distinct, or:\n\n\n"}
{"id": "221419", "url": "https://en.wikipedia.org/wiki?curid=221419", "title": "Marginalism", "text": "Marginalism\n\nMarginalism is a theory of economics that attempts to explain the discrepancy in the value of goods and services by reference to their secondary, or marginal, utility. The reason why the price of diamonds is higher than that of water, for example, owes to the greater additional satisfaction of the diamonds over the water. Thus, while the water has greater total utility, the diamond has greater marginal utility.\n\nAlthough the central concept of marginalism is that of marginal utility, marginalists, following the lead of Alfred Marshall, drew upon the idea of marginal physical productivity in explanation of cost. The neoclassical tradition that emerged from British marginalism abandoned the concept of utility and gave marginal rates of substitution a more fundamental role in analysis. Marginalism is an integral part of mainstream economic theory.\n\nFor issues of marginality, constraints are conceptualized as a \"border\" or \"margin\". The location of the margin for any individual corresponds to his or her \"endowment\", broadly conceived to include opportunities. This endowment is determined by many things including physical laws (which constrain how forms of energy and matter may be transformed), accidents of nature (which determine the presence of natural resources), and the outcomes of past decisions made both by others and by the individual.\n\nA value that holds true given particular constraints is a \"marginal\" value. A change that would be affected as or by a specific loosening or tightening of those constraints is a \"marginal\" change.\n\nNeoclassical economics usually assumes that marginal changes are infinitesimals or limits. (Though this assumption makes the analysis less robust, it increases tractability.) One is therefore often told that \"marginal\" is synonymous with \"very small\", though in more general analysis this may not be operationally true (and would not in any case be literally true). Frequently, economic analysis concerns the marginal values associated with a change of one unit of a resource, because decisions are often made in terms of units; marginalism seeks to explain unit prices in terms of such marginal values.\n\nThe marginal use of a good or service is the specific use to which an agent would put a given increase, or the specific use of the good or service that would be abandoned in response to a given decrease.\n\nMarginalism assumes, for any given agent, economic rationality and an ordering of possible states-of-the-world, such that, for any given set of constraints, there is an attainable state which is best in the eyes of that agent. Descriptive marginalism asserts that choice amongst the specific means by which various anticipated specific states-of-the-world (outcomes) might be affected is governed only by the distinctions amongst those specific outcomes; prescriptive marginalism asserts that such choice \"ought\" to be so governed.\n\nOn such assumptions, each increase would be put to the specific, feasible, previously unrealized use of greatest priority, and each decrease would result in abandonment of the use of lowest priority amongst the uses to which the good or service had been put.\n\nThe marginal utility of a good or service is the utility of its marginal use. Under the assumption of economic rationality, it is the utility of its least urgent possible use \"from\" the best feasible combination of actions in which its use is included.\n\nIn 20th century mainstream economics, the term \"utility\" has come to be formally defined as a \"quantification\" capturing preferences by assigning greater quantities to states, goods, services, or applications that are of higher priority. But marginalism and the concept of marginal utility predate the establishment of this convention within economics. The more general conception of utility is that of \"use\" or \"usefulness\", and this conception is at the heart of marginalism; the term \"marginal utility\" arose from translation of the German \"Grenznutzen\", which literally means \"border use\", referring directly to the marginal use, and the more general formulations of marginal utility do not treat quantification as an \"essential\" feature. On the other hand, none of the early marginalists insisted that utility were \"not\" quantified, some indeed treated quantification as an essential feature, and those who did not still used an assumption of quantification for expository purposes. In this context, it is not surprising to find many presentations that fail to recognize a more general approach.\n\nUnder the special case in which usefulness can be quantified, the change in utility of moving from state formula_1 to state formula_2 is\nMoreover, if formula_1 and formula_2 are distinguishable by values of just one variable formula_6 which is itself quantified, then it becomes possible to speak of the ratio of the marginal utility of the change in formula_6 to the size of that change:\n(where “c.p.” indicates that the \"only\" independent variable to change is formula_6).\n\nMainstream neoclassical economics will typically assume that\nis well defined, and use “marginal utility” to refer to a partial derivative\n\nThe \"law\" of diminishing marginal utility (also known as a \"Gossen's First Law\") is that, \"ceteris paribus\", as additional amounts of a good or service are added to available resources, their marginal utilities are decreasing. This \"law\" is sometimes treated as a tautology, sometimes as something proven by introspection, or sometimes as a mere instrumental assumption, adopted only for its perceived predictive efficacy. Actually, it is not quite any of these things, though it may have aspects of each. The \"law\" does not hold under all circumstances, so it is neither a tautology nor otherwise proveable; but it has a basis in prior observation.\n\nAn individual will typically be able to partially order the potential uses of a good or service. If there is scarcity, then a rational agent will satisfy wants of highest possible priority, so that no want is avoidably sacrificed to satisfy a want of \"lower\" priority. In the absence of complementarity across the uses, this will imply that the priority of use of any additional amount will be lower than the priority of the established uses, as in this famous example:\n\nHowever, if there \"is\" a complementarity across uses, then an amount added can bring things past a desired tipping point, or an amount subtracted cause them to fall short. In such cases, the marginal utility of a good or service might actually be \"increasing\".\n\nWithout the presumption that utility is quantified, the \"diminishing\" of utility should not be taken to be itself an arithmetic subtraction. It is the movement from use of higher to lower priority, and may be no more than a purely ordinal change.\n\nWhen quantification of utility is assumed, diminishing marginal utility corresponds to a utility function whose \"slope\" is continually or continuously decreasing. In the latter case, if the function is also smooth, then the “law” may be expressed\nNeoclassical economics usually supplements or supplants discussion of marginal utility with indifference curves, which were originally derived as the level curves of utility functions, or can be produced without presumption of quantification, but are often simply treated as axiomatic. In the absence of complementarity of goods or services, diminishing marginal utility implies convexity of indifference curves (though such convexity would also follow from quasiconcavity of the utility function).\n\nThe \"rate of substitution\" is the \"least favorable\" rate at which an agent is willing to exchange units of one good or service for units of another. The marginal rate of substitution (\"MRS\") is the rate of substitution at the margin – in other words, given some constraint(s).\n\nWhen goods and services are discrete, the least favorable rate at which an agent would trade A for B will usually be different from that at which she would trade B for A:\nBut, when the goods and services are continuously divisible, in the limiting case\nand the marginal rate of substitution is the slope of the indifference curve (multiplied by formula_15).\n\nIf, for example, Lisa will not trade a goat for anything less than two sheep, then her\nAnd if she will not trade a sheep for anything less than two goats, then her\nBut if she would trade one gram of banana for one ounce of ice cream \"and vice versa\", then\n\nWhen indifference curves (which are essentially graphs of instantaneous rates of substitution) and the convexity of those curves are not taken as given, the \"law\" of diminishing marginal utility is invoked to explain diminishing marginal rates of substitution – a willingness to accept fewer units of good or service formula_19 in substitution for formula_20 as one's holdings of formula_19 grow relative to those of formula_20. If an individual has a stock or flow of a good or service whose marginal utility is less than would be that of some other good or service for which he or she could trade, then it is in his or her interest to effect that trade. Of course, as one thing is traded-away and another is acquired, the respective marginal gains or losses from further trades are now changed. On the assumption that the marginal utility of one is diminishing, and the other is not increasing, all else being equal, an individual will demand an increasing ratio of that which is acquired to that which is sacrificed. (One important way in which all else might not be equal is when the use of the one good or service complements that of the other. In such cases, exchange ratios might be constant.) If any trader can better his or her own marginal position by offering an exchange more favorable to other traders with desired goods or services, then he or she will do so.\n\nAt the highest level of generality, a marginal cost is a marginal opportunity cost. In most contexts, however, \"marginal cost\" will refer to marginal \"pecuniary\" cost – that is to say marginal cost measured by forgone money.\n\nA thorough-going marginalism sees marginal cost as increasing under the \"law\" of diminishing marginal utility, because applying resources to one application reduces their availability to other applications. Neoclassical economics tends to disregard this argument, but to see marginal costs as increasing in consequence of diminishing returns.\n\nMarginalism and neoclassical economics typically explain price formation broadly through the interaction of curves or schedules of supply and demand. In any case buyers are modelled as pursuing typically lower quantities, and sellers offering typically higher quantities, as price is increased, with each being willing to trade until the marginal value of what they would trade-away exceeds that of the thing for which they would trade.\n\nDemand curves are explained by marginalism in terms of marginal rates of substitution.\n\nAt any given price, a prospective buyer has some marginal rate of substitution of money for the good or service in question. Given the \"law\" of diminishing marginal utility, or otherwise given convex indifference curves, the rates are such that the willingness to forgo money for the good or service decreases as the buyer would have ever more of the good or service and ever less money. Hence, any given buyer has a demand schedule that generally decreases in response to price (at least until quantity demanded reaches zero). The aggregate quantity demanded by all buyers is, at any given price, just the sum of the quantities demanded by individual buyers, so it too decreases as price increases.\n\nBoth neoclassical economics and thorough-going marginalism could be said to explain supply curves in terms of marginal cost; however, there are marked differences in conceptions of that cost.\n\nMarginalists in the tradition of Marshall and neoclassical economists tend to represent the supply curve for any producer as a curve of marginal pecuniary costs objectively determined by physical processes, with an upward slope determined by diminishing returns.\n\nA more thorough-going marginalism represents the supply curve as a \"complementary demand curve\" – where the demand is \"for\" money and the purchase is made \"with\" a good or service. The shape of that curve is then determined by marginal rates of substitution of money for that good or service.\n\nBy confining themselves to limiting cases in which sellers or buyers are both \"price takers\" – so that demand functions ignore supply functions or \"vice versa\" – Marshallian marginalists and neoclassical economists produced tractable models of \"pure\" or \"perfect\" competition and of various forms of \"imperfect\" competition, which models are usually captured by relatively simple graphs. Other marginalists have sought to present what they thought of as more realistic explanations, but this work has been relatively uninfluential on the mainstream of economic thought.\n\nThe \"law\" of diminishing marginal utility is said to explain the \"paradox of water and diamonds\", most commonly associated with Adam Smith (though recognized by earlier thinkers). Human beings cannot even survive without water, whereas diamonds, in Smith's day, were ornamentation or engraving bits. Yet water had a very small price, and diamonds a very large price. Marginalists explained that it is the \"marginal\" usefulness of any given quantity that matters, rather than the usefulness of a \"class\" or of a \"totality\". For most people, water was sufficiently abundant that the loss or gain of a gallon would withdraw or add only some very minor use if any, whereas diamonds were in much more restricted supply, so that the loss or gain was much greater.\n\nThat is not to say that the price of any good or service is simply a function of the marginal utility that it has for any one individual nor for some ostensibly typical individual. Rather, individuals are willing to trade based upon the respective marginal utilities of the goods that they have or desire (with these marginal utilities being distinct for each potential trader), and prices thus develop constrained by these marginal utilities.\n\nPerhaps the essence of a notion of diminishing marginal utility can be found in Aristotle's \"Politics\", wherein he writes \n\nA great variety of economists concluded that there was \"some\" sort of inter-relationship between utility and rarity that effected economic decisions, and in turn informed the determination of prices.\n\nEighteenth-century Italian mercantilists, such as Antonio Genovesi, Giammaria Ortes, Pietro Verri, Cesare Beccaria, and Giovanni Rinaldo, held that value was explained in terms of the general utility and of scarcity, though they did not typically work-out a theory of how these interacted. In \"Della Moneta\" (1751), Abbé Ferdinando Galiani, a pupil of Genovesi, attempted to explain value as a ratio of two ratios, \"utility\" and \"scarcity\", with the latter component ratio being the ratio of quantity to use.\n\nAnne Robert Jacques Turgot, in \"Réflexions sur la formation et la distribution de richesse\" (1769), held that value derived from the general utility of the class to which a good belonged, from comparison of present and future wants, and from anticipated difficulties in procurement.\n\nLike the Italian mercantilists, Étienne Bonnot de Condillac saw value as determined by utility associated with the class to which the good belongs, and by estimated scarcity. In \"De commerce et le gouvernement\" (1776), Condillac emphasized that value is not based upon cost but that costs were paid because of value.\n\nThis last point was famously restated by the Nineteenth Century proto-marginalist, Richard Whately, who in \"Introductory Lectures on Political Economy\" (1832) wrote (Whately's student Nassau William Senior is noted below as an early marginalist.)\n\nFrédéric Bastiat in chapters V and XI of his \"Economic Harmonies\" (1850) also develops a theory of value as ratio between services that increment utility, rather than between total utility.\n\nThe first unambiguous published statement of any sort of theory of marginal utility was by Daniel Bernoulli, in \"Specimen theoriae novae de mensura sortis\". This paper appeared in 1738, but a draft had been written in 1731 or in 1732. In 1728, Gabriel Cramer produced fundamentally the same theory in a private letter. Each had sought to resolve the St. Petersburg paradox, and had concluded that the marginal desirability of money decreased as it was accumulated, more specifically such that the desirability of a sum were the natural logarithm (Bernoulli) or square root (Cramer) thereof. However, the more general implications of this hypothesis were not explicated, and the work fell into obscurity.\n\nIn \"A Lecture on the Notion of Value as Distinguished Not Only from Utility, but also from Value in Exchange\", delivered in 1833 and included in \"Lectures on Population, Value, Poor Laws and Rent\" (1837), William Forster Lloyd explicitly offered a general marginal utility theory, but did not offer its derivation nor elaborate its implications. The importance of his statement seems to have been lost on everyone (including Lloyd) until the early 20th century, by which time others had independently developed and popularized the same insight.\n\nIn \"An Outline of the Science of Political Economy\" (1836), Nassau William Senior asserted that marginal utilities were the ultimate determinant of demand, yet apparently did not pursue implications, though some interpret his work as indeed doing just that.\n\nIn \"De la mesure de l'utilité des travaux publics\" (1844), Jules Dupuit applied a conception of marginal utility to the problem of determining bridge tolls.\n\nIn 1854, Hermann Heinrich Gossen published \"Die Entwicklung der Gesetze des menschlichen Verkehrs und der daraus fließenden Regeln für menschliches Handeln\", which presented a marginal utility theory and to a very large extent worked-out its implications for the behavior of a market economy. However, Gossen's work was not well received in the Germany of his time, most copies were destroyed unsold, and he was virtually forgotten until rediscovered after the so-called Marginal Revolution.\n\nMarginalism as a formal theory can be attributed to the work of three economists, Jevons in England, Menger in Austria, and Walras in Switzerland. William Stanley Jevons first proposed the theory in articles in 1863 and 1871. Similarly, Carl Menger presented the theory in 1871. Menger explained why individuals use marginal utility to decide amongst trade-offs, but while his illustrative examples present utility as quantified, his essential assumptions do not.\nLéon Walras introduced the theory in \"Éléments d'économie politique pure\", the first part of which was published in 1874. (American John Bates Clark is also associated with the origins of Marginalism, but did little to advance the theory.\n\nAlthough the Marginal Revolution flowed from the work of Jevons, Menger, and Walras, their work might have failed to enter the mainstream were it not for a second generation of economists. In England, the second generation were exemplified by Philip Wicksteed, by William Smart, and by Alfred Marshall; in Austria by Eugen Böhm von Bawerk and by Friedrich von Wieser; in Switzerland by Vilfredo Pareto; and in America by Herbert Joseph Davenport and by Frank A. Fetter.\n\nThere were significant, distinguishing features amongst the approaches of Jevons, Menger, and Walras, but the second generation did not maintain distinctions along national or linguistic lines. The work of von Wieser was heavily influenced by that of Walras. Wicksteed was heavily influenced by Menger. Fetter referred to himself and Davenport as part of \"the American Psychological School\", named in imitation of the Austrian \"Psychological School\". (And Clark's work from this period onward similarly shows heavy influence by Menger.) William Smart began as a conveyor of Austrian School theory to English-language readers, though he fell increasingly under the influence of Marshall.\n\nBöhm-Bawerk was perhaps the most able expositor of Menger's conception. He was further noted for producing a theory of interest and of profit in equilibrium based upon the interaction of diminishing marginal utility with diminishing marginal productivity of time and with time preference. (This theory was adopted in full and then further developed by Knut Wicksell and, with modifications including formal disregard for time-preference, by Wicksell's American rival Irving Fisher.)\n\nMarshall was the second-generation marginalist whose work on marginal utility came most to inform the mainstream of neoclassical economics, especially by way of his \"Principles of Economics\", the first volume of which was published in 1890. Marshall constructed the demand curve with the aid of assumptions that utility was quantified, and that the marginal utility of money was constant (or nearly so). Like Jevons, Marshall did not see an explanation for supply in the theory of marginal utility, so he paired a marginal explanation of demand with a more classical explanation of supply, wherein costs were taken to be objectively determined. (Marshall later actively mischaracterized the criticism that these costs were themselves ultimately determined by marginal utilities.)\n\nThe doctrines of marginalism and the Marginal Revolution are often interpreted as a response to the rise of the worker's movement, Marxian economics and the earlier (Ricardian) socialist theories of the exploitation of labour. The first volume of \"Das Kapital\" was not published until July 1867, when marginalism was already developing, but before the advent of Marxian economics, proto-marginalist ideas such as those of Gossen had largely fallen on deaf ears. It was only in the 1880s, when Marxism had come to the fore as the main economic theory of the workers' movement, that Gossen found (posthumous) recognition.\n\nAside from the rise of Marxism, E. Screpanti and S. Zamagni point to a different 'external' reason for marginalism's success, which is its successful response to the Long Depression and the resurgence of class conflict in all developed capitalist economies after the 1848-1870 period of social peace. Marginalism, Screpanti and Zamagni argue, offered a theory of the free market as perfect, as performing optimal allocation of resources, while it allowed economists to blame any adverse effects of laissez-faire economics on the interference of workers' coalitions in the proper functioning of the market.\n\nScholars have suggested that the success of the generation who followed the preceptors of the Revolution was their ability to formulate straightforward responses to Marxist economic theory. The most famous of these was that of Böhm-Bawerk, “Zum Abschluss des Marxschen Systems” (1896), but the first was Wicksteed's “The Marxian Theory of Value. \"Das Kapital\": a criticism” (1884, followed by “The Jevonian criticism of Marx: a rejoinder” in 1885). The most famous early Marxist responses were Rudolf Hilferding's \"Böhm-Bawerks Marx-Kritik\" (1904) and \"The Economic Theory of the Leisure Class\" (1914) by Nikolai Bukharin.\n\nIn his 1881 work \"Mathematical Psychics\", Francis Ysidro Edgeworth presented the indifference curve, deriving its properties from marginalist theory which assumed utility to be a differentiable function of quantified goods and services. But it came to be seen that indifference curves could be considered as somehow \"given\", without bothering with notions of utility.\n\nIn 1915, Eugen Slutsky derived a theory of consumer choice solely from properties of indifference curves. Because of the World War, the Bolshevik Revolution, and his own subsequent loss of interest, Slutsky's work drew almost no notice, but similar work in 1934 by John Hicks and R. G. D. Allen derived much the same results and found a significant audience. (Allen subsequently drew attention to Slutsky's earlier accomplishment.)\n\nAlthough some of the third generation of Austrian School economists had by 1911 rejected the quantification of utility while continuing to think in terms of marginal utility, most economists presumed that utility must be a sort of quantity. Indifference curve analysis seemed to represent a way of dispensing with presumptions of quantification, albeït that a seemingly arbitrary assumption (admitted by Hicks to be a \"rabbit out of a hat\") about decreasing marginal rates of substitution would then have to be introduced to have convexity of indifference curves.\n\nFor those who accepted that superseded marginal utility analysis had been superseded by indifference curve analysis, the former became at best somewhat analogous to the Bohr model of the atom—perhaps pedagogically useful, but “old fashioned” and ultimately incorrect.\n\nWhen Cramer and Bernoulli introduced the notion of diminishing marginal utility, it had been to address a paradox of gambling, rather than the paradox of value. The marginalists of the revolution, however, had been formally concerned with problems in which there was neither risk nor uncertainty. So too with the indifference curve analysis of Slutsky, Hicks, and Allen.\n\nThe expected utility hypothesis of Bernoulli \"et alii\" was revived by various 20th century thinkers, including Frank Ramsey (1926), John von Neumann and Oskar Morgenstern (1944), and Leonard Savage (1954). Although this hypothesis remains controversial, it brings not merely utility but a quantified conception thereof back into the mainstream of economic thought, and would dispatch the Ockhamistic argument. (It should perhaps be noted that, in expected utility analysis, the “law” of diminishing marginal utility corresponds to what is called “risk aversion”.)\n\nKarl Marx died before marginalism became the interpretation of economic value accepted by mainstream economics. His theory was based on the labor theory of value, which distinguishes between exchange value and use value. In his \"Capital\" he rejected the explanation of long-term market values by supply and demand:\n\nIn his early response to marginalism, Nikolai Bukharin argued that \"the subjective evaluation from which price is to be derived really starts from this price\", concluding:\n\nSimilarly a later Marxist critic, Ernest Mandel, argued that marginalism was \"divorced from reality\", ignored the role of production, and that:\n\nMaurice Dobb argued that prices derived through marginalism depend on the distribution of income. The ability of consumers to express their preferences is dependent on their spending power. As the theory asserts that prices arise in the act of exchange, Dobb argues that it cannot explain how the distribution of income affects prices and consequently cannot explain prices.\n\nDobb also criticized the \"motives\" behind marginal utility theory. Jevons wrote, for example, \"so far as is consistent with the inequality of wealth in every community, all commodities are distributed by exchange so as to produce the maximum social benefit.\" (See Fundamental theorems of welfare economics.) Dobb contended that this statement indicated that marginalism is intended to insulate market economics from criticism by making prices the natural result of the given income distribution.\n\nSome economists strongly influenced by the Marxian tradition such as Oskar Lange, Włodzimierz Brus, and Michał Kalecki have attempted to integrate the insights of classical political economy, marginalism, and neoclassical economics. They believed that Marx lacked a sophisticated theory of prices, and neoclassical economics lacked a theory of the social frameworks of economic activity. Some other Marxists have also argued that on one level there is no conflict between marginalism and Marxism: one could employ a marginalist theory of supply and demand within the context of a “big picture” understanding of the Marxist notion that capitalists exploit surplus labor.\n\n\n"}
{"id": "56656177", "url": "https://en.wikipedia.org/wiki?curid=56656177", "title": "María Clara doctrine", "text": "María Clara doctrine\n\nThe María Clara doctrine, also known as the Woman's Honor doctrine, is a legal doctrine applied by Philippine courts regarding cases that concerns abuse against women.\n\nThe doctrine was named after María Clara from José Rizal's novel \"Noli Me Tángere\". Clara is characterized as reserved and shy and was later considered an \"ideal\" role model for women in Philippine culture. \n\nThe doctrine became a part of the Supreme Court of the Philippines' jurisprudence sometime in 1960 following the \"People v. Taño\" case. The high court through Justice Alejo Labrador has asserted a \"well known fact\" that women, especially Filipinos \"would not admit that they have been abused unless that abuse had actually happened.\" The court said that women's natural instict is to protect their honor.The case involved three armed robbers who the court found liable for taking turns in raping a woman.\n\nAbout 58 years later since the doctrine entered the high court's jurisprudence, the Third Division of the Supreme Court reverse a ruling on January 17, 2018 by a Davao court on two people convicted of rape. The 2018 decision was released in late-February. The case involves an alleged rape that happened in 2009 and the two accused were sentenced of \"reclusión perpetua\", or forty years of imprisonment, in 2012. The decision was affirmed by the Court of Appeals in 2016.\nThe court described the doctrine as causing a \"travesty of justice\" by putting the accused at an \"unfair disadvantage\", criticizing the doctrine for assuming that no Filipina woman of \"decent repute\" would falsely claim that she was abused. It urged for the acceptance of the \"realities of a woman’s dynamic role\" in Philippine society today so one can \"evaluate the testimony of a private complainant of rape without gender bias or cultural misconception\". It also stated that the discrepancies in the alleged victim's testimonies had cast doubt on whether the rape incident did or did not happen.\n\nThis has led to concerns and speculations that the high court has abandoned the doctrine. The Gabriela Women's Party condemned the decision which it viewed made the Maria Clara doctrine invalid saying the ruling reversal will empower rapists and disagreed with the court's assessment of the societal status of women.\n\nOn February 21, 2018, Supreme Court's spokesperson, Theodore Te has clarified that it was not the case since the high court can abandon a doctrine only during a full session.\n"}
{"id": "8564494", "url": "https://en.wikipedia.org/wiki?curid=8564494", "title": "Mater semper certa est", "text": "Mater semper certa est\n\nSince 1978, when the first child was conceived by the technique of \"in-vitro\" fertilization, the principle of no longer applies, since a child may have a \"genetic\" and a \"natural\" (\"birth\") mother who are different individuals. Since then some countries have converted the old natural law to an equivalent codified law - in 1997 Germany introduced paragraph 1571 (\"motherhood\") of the BGB (civil code) reading (\"the mother of a child is the woman who gave birth to it\"). \n\nThe Roman law principle however does not stop at the mother, in fact it continues with (\"The father is always uncertain\"). This was regulated by the law of (\"the father is he to whom marriage points\"). Essentially paternity fraud had originally been a marriage fraud in the civil code due to this principle. Today some married fathers use the modern tools of DNA testing to ensure a certainty on their fatherhood.\n"}
{"id": "21056", "url": "https://en.wikipedia.org/wiki?curid=21056", "title": "Moral equivalence", "text": "Moral equivalence\n\nMoral equivalence is a term used in political debate, usually to deny that a moral comparison can be made of two sides in a conflict, or in the actions or tactics of two sides.\n\nThe term had some currency in polemic debates about the Cold War, and currently the Arab–Israeli conflict. \"Moral equivalence\" began to be used as a polemic \"term-of-retort\" to \"moral relativism\", which had been gaining use as an indictment against political foreign policy that appeared to use only a situation-based application of widely held ethical standards.\n\nInternational conflicts are sometimes viewed similarly, and interested parties periodically urge both sides to conduct a ceasefire and negotiate their differences. However these negotiations may prove difficult in that both parties in a conflict believe that they are morally superior to the other, and are unwilling to negotiate on basis of moral equivalence.\n\nIn the Cold War context, the term was and is most commonly used by anti-Communists as an accusation of formal fallacy for leftist criticisms of United States foreign policy and military conduct.\n\nMany such people believed in the idea that the United States was intrinsically benevolent, that the extension of its power, influence and hegemony was an extension of benevolence and would bring freedom to those people subject to that hegemony. Therefore, those who opposed the United States were by definition evil, trying to deny its benevolence to people. The USSR and its allies, in contrast, practiced a totalitarian ideology. A territory under US hegemony thus would be freed from possibly being in the camp of the totalitarian power and would help to weaken it. Thus, all means were justified in keeping territories away from Soviet influence in this way. This extended to countries not under Soviet influence but instead said to be sympathetic at all in any way with it. Therefore, Chile under Salvador Allende was not under Soviet domination, but removing him would help weaken the USSR by removing a government ruled with the help of a Communist Party. The big picture, they would say, justified the tortures carried out by the Augusto Pinochet dictatorship as it served to weaken the totalitarian Communist camp and in time bring about the freedom of those under its domination.\n\nSome of those who criticized US foreign policy at the time contended that US power in the Cold War was used only to pursue an economically-driven agenda. They claim that the underlying economic motivation eroded any claims of moral superiority, leaving the hostile acts in (Korea, Hungary, Cuban Missile Crisis, Vietnam, Afghanistan, Nicaragua) to stand on their own. In contrast, those who justified US interventions in the Cold War period always cast these as being motivated by the need to contain totalitarianism and thus fulfilled a higher moral imperative.\n\nAn early popularizer of the expression was Jeane Kirkpatrick, who was United States ambassador to the United Nations in the Reagan administration. Kirkpatrick published an article called \"The Myth of Moral Equivalence\" in 1986, in which sharply criticized those who she alleged were claiming that there was \"no moral difference\" between the Soviet Union and democratic states. In fact, very few critics of United States policies in the Cold War era argued that there was a moral equivalence between the two sides. Communists, for instance, argued that the Soviet Union was morally superior to its adversaries. Kirkpatrick herself was one of the most outspoken voices calling for the US to support authoritarian military regimes in Central America that were responsible for major human rights violations. When four US churchwomen were raped and murdered by government soldiers in El Salvador, Kirkpatrick downplayed the gravity of the crime, remarking that 'the nuns were not just nuns, they were political activists'. According to Congressman Robert Torricelli, Reagan administration officials, including Kirkpatrick, deliberately suppressed information about government abuses in El Salvador: \"While the Reagan Administration was certifying human rights progress in El Salvador they knew the terrible truth that the Salvadoran military was engaged in a widespread campaign of terror and torture.\"\n\nLeftist critics usually argued that the United States itself created a \"moral equivalence\" when some of its actions, such as President Ronald Reagan's support for the \"Contra\" insurgency against the Sandinista government in Nicaragua, put it on the same level of immorality as the Soviet Union.\n\nMoral equivalence has featured in debates over NATO expansion, the overthrow of rogue states, the invasion of Iraq, and the War on Terror. Concepts of moral hierarchy have been applied to foreign policy challenges such as Islamic fundamentalists, anti-Israel powers, Russia, China, drug traffickers, and Serbian nationalists, among others.\n\n"}
{"id": "13231523", "url": "https://en.wikipedia.org/wiki?curid=13231523", "title": "Nishkam Karma", "text": "Nishkam Karma\n\nNishkam Karma (sanskrit IAST : \"niṣkāmakarma\"), self-less or desireless action, is an action performed without any expectation of fruits or results, and the central tenet of Karma Yoga path to Liberation. Its modern advocates press upon achieving success following the principles of Yoga, and stepping beyond personal goals and agendas while pursuing any action over greater good, which has become well known since it is the central message of the Bhagavad Gita.\n\nIn Indian philosophy, action or Karma has been divided into three categories, according to their intrinsic qualities or gunas. Here Nishkam Karma belongs to the first category, the \"Sattva\" (pure) or actions which add to calmness; the Sakam Karma (Self-centred action) comes in the second \"rājasika\" (aggression) and Vikarma (bad-action) comes under the third, \"tāmasika\" which correlates to darkness or inertia.\n\nThe opposite of \"Sakam Karma\" (Attached Involvement) or actions done with results in mind, Nishkam Karma has been variously explained as 'Duty for duty's sake' and as 'Detached Involvement', which is neither negative attitude or indifference; and has today found many advocates in the modern business area where the emphasis has shifted to ethical business practices adhering to intrinsic human values and reducing stress at the workplace.\n\nAnother aspect that differentiates it from Sakam or selfish action, is that while the former is guided by inspiration, the latter is all about motivation, and that makes the central difference in its results, for example Sakam Karma might lead to excessive work pressure and workaholism as it aims at success, and hence creates more chances of physical and psychological burn outs. On the other hand Nishkam Karma, means more balanced approach to work, and as work has been turned into a pursuit of personal excellence, which results in greater personal satisfaction, which one would have otherwise sought in job satisfaction coming from external rewards. One important fallout of the entire shift is that where one is essentially an ethical practice inside-out leading to the adage, ‘Work is worship’ show itself literally at workplace, leading to greater work commitment, the other since it is so much result oriented can lead to unethical business and professional ethics, as seen so often at modern work place \n\nSince the central tenet of practicing Nishkam Karma is Mindfulness in the present moment. Over time, this practice leads to not only equanimity of mind as it allows the practitioner to stay detached from results, and hence from ups and downs of business that are inevitable in any business arena, while maintaining constant work commitment since work as now been turned into a personal act of worship. Further in the long run it leads to cleansing of the heart but also spiritual growth and holistic development.\n\nNishkam Karma, gets an important place in the \"Bhagavad Gita\", the central text of Mahabharata, where Krishna advocates 'Nishkam Karma Yoga' (the Yoga of Selfless Action) as the ideal path to realize the Truth. Allocated work done without expectations, motives, or thinking about its outcomes tends to purify one's mind and gradually makes an individual fit to see the value of reason and the benefits of renouncing the work itself. These concepts are vividly described in the following verses:\n\n\n"}
{"id": "543119", "url": "https://en.wikipedia.org/wiki?curid=543119", "title": "Normal probability plot", "text": "Normal probability plot\n\nThe normal probability plot is a graphical technique to identify substantive departures from normality. This includes identifying outliers, skewness, kurtosis, a need for transformations, and mixtures. Normal probability plots are made of raw data, residuals from model fits, and estimated parameters. \n\nIn a normal probability plot (also called a \"normal plot\"), the sorted data are plotted vs. values selected to make the resulting image look close to a straight line if the data are approximately normally distributed. Deviations from a straight line suggest departures from normality. The plotting can be manually performed by using a special graph paper, called \"normal probability paper\". With modern computers normal plots are commonly made with software. \n\nThe normal probability plot is a special case of the Q–Q probability plot for a normal distribution. The theoretical quantiles are generally chosen to approximate either the mean or the median of the corresponding order statistics. \n\nThe normal probability plot is formed by plotting the sorted data vs. an approximation to the means or medians of the corresponding order statistics; see rankit. Some users plot the data on the vertical axis; others plot the data on the horizontal axis. \n\nDifferent sources use slightly different approximations for rankits. The formula used by the \"qqnorm\" function in the basic \"stats\" package in R (programming language) is as follows: \n\nfor , \nwhere \n\nand is the standard normal quantile function. \n\nIf the data are consistent with a sample from a normal distribution, the points should lie close to a straight line. As a reference, a straight line can be fit to the points. The further the points vary from this line, the greater the indication of departure from normality. If the sample has mean 0, standard deviation 1 then a line through 0 with slope 1 could be used. \n\nWith more points, random deviations from a line will be less pronounced. Normal plots are often used with as few as 7 points, e.g., with plotting the effects in a saturated model from a 2-level fractional factorial experiment. With fewer points, it becomes harder to distinguish between random variability and a substantive deviation from normality.\n\nProbability plots for distributions other than the normal are computed in exactly the same way. The normal quantile function is simply replaced by the quantile function of the desired distribution. In this way, a probability plot can easily be generated for any distribution for which one has the quantile function.\n\nWith a location-scale family of distributions, the location and scale parameters of the distribution can be estimated from the intercept and the slope of the line. For other distributions the parameters must first be estimated before a probability plot can be made.\n\nThis is a sample of size 50 from a normal distribution, plotted as both a histogram, and a normal probability plot.\n\nThis is a sample of size 50 from a right-skewed distribution, plotted as both a histogram, and a normal probability plot.\n\nThis is a sample of size 50 from a uniform distribution, plotted as both a histogram, and a normal probability plot.\n\n\n"}
{"id": "25369256", "url": "https://en.wikipedia.org/wiki?curid=25369256", "title": "Peres metric", "text": "Peres metric\n\nIn mathematical physics, the Peres metric is defined by the proper time\n\nfor any arbitrary function \"f\". If \"f\" is a harmonic function with respect to \"x\" and \"y\", then the corresponding Peres metric satisfies the Einstein field equations in vacuum. Such a metric is often studied in the context of gravitational waves. The metric is named for Israeli physicist Asher Peres, who first defined the metric in 1959.\n\n"}
{"id": "49895", "url": "https://en.wikipedia.org/wiki?curid=49895", "title": "Piety", "text": "Piety\n\nIn spiritual terminology, piety is a virtue that may include religious devotion, spirituality, or a mixture of both. A common element in most conceptions of piety is humility.\n\nThe word piety comes from the Latin word \"pietas\", the noun form of the adjective \"pius\" (which means \"devout\" or \"dutiful\"). \n\n\"Pietas\" in traditional Latin usage expressed a complex, highly valued Roman virtue; a man with \"pietas\" respected his responsibilities to gods, country, parents, and kin. In its strictest sense it was the sort of love a son ought to have for his father. Aeneas's consistent epithet in Virgil and other Latin authors is \"pius\", a term that connotes reverence toward the gods and familial dutifulness. At the fall of Troy, Aeneas carries to safety his father, the lame Anchises, and the Lares and Penates, the statues of the household gods.\n\nIn addressing whether children have an obligation to provide support for their parents, Aquinas quotes, Cicero, \"...\"piety gives both duty and homage\": \"duty\" referring to service, and \"homage\" to reverence or honor.\" Filial piety is central to Confucian ethics.\n\nIn Catholicism, Eastern Orthodoxy, Lutheranism, and Anglicanism, piety is one of the seven gifts of the Holy Spirit. \"It engenders in the soul a filial respect for God, a generous love toward him, and an affectionate obedience that wants to do what he commands because it loves the one who commands.\" \n\nPiety belongs to the virtue of Religion, which the concordant judgment of theologians put among the moral virtues, as a part of the cardinal virtue Justice, since by it one tenders to God what is due to him.\n\nPope Francis described piety as recognizing “our belonging to God, our deep bond with him, a relationship that gives meaning to our whole life and keeps us resolute, in communion with him, even during the most difficult and troubled moments” in life.\n\n"}
{"id": "44450846", "url": "https://en.wikipedia.org/wiki?curid=44450846", "title": "Prison violence", "text": "Prison violence\n\nPrison violence is a daily occurrence due to the diverse inmates with varied criminal backgrounds in penitentiaries. The three different types of attacks are inmate on inmate, inmate on guard, and self-inflicted. These attacks can either be impulsive and spontaneous or well-planned out and premeditated. Factors such as gang rivalries, overcrowding, minor disputes, and prison design contribute to the violent attacks that transpire. Prisons are trying to avoid, or at least better deal with these situations by being proactive. They are taking steps like placing violent convicts and gang leaders into solitary confinement, balancing the cells by critically examining each inmate to see where they are likely to reside peacefully, reducing blind spots, and training as well as educating the officers.\n\nPrison violence is inflicted onto either another inmate, a prison guard, or themselves. In 1999, it was reported that one in five inmates, or twenty percent of inmates, at fourteen state prisons had been physically assaulted by another inmate. Prison violence can consist of inmates fighting with their fists, homemade weapons, or being raped. The attacks that are implemented onto anyone but the self are either instrumental or expressive.\n\n\n\n\nPrison violence is capable of occurring anywhere throughout a prison. Any inmate is capable of acting rash and snapping at any given moment, that an outbreak can occur anywhere and at any time. Oftentimes, an inmate will look for a place that offers a sufficient amount of time to commit their act proficiently. If they are outside of their cell, they have the chance to smuggle out a homemade weapon by placing it up their rectum. Although these acts can occur anywhere, a very common place inmates search for is a blind spot.\n\nPrisons are covered with guards standing watch, CCTV, or a combination of the two. Neither of these can possibly cover every inch of a prison’s ground, which is why “…blind spots…allow inmates to conceal illicit activity from security staff”. Therefore, inmates purposefully look for these blind spots to commit violent acts undetected by prison guards. The inmate’s goal is to know that they are going to be able to complete the act of violence to the degree that they desire without guards noticing and intervening. Inmates look for places that give them more time to complete their attacks.\n\nThe perpetrators of violent attacks are convicted criminals, some of whom in prison for committing crimes that left multiple people brutally beaten and left for dead, so violence is in many of these individual’s nature. These people, “…settle disputes and seek power in the way they are accustomed- through violence”. This natural fire in their bellies is undoubtedly a huge factor that goes into why prison violence occurs, but the physical design of the prison can serve as another factor. A prison can either have indirect or direct supervision. Both types of supervision have their strengths, but also detrimental weaknesses.\n\nIndirect supervision is when a correctional officer is placed in an enclosed booth and must constantly watch over the inmates through a bird’s eye view. The physical interactions that officers have with the inmates is minimal, for most of the communication comes through an intercom system. Inmates are placed in their own cells and officers have physical barriers to ensure their own safety. When havoc is wreaked, a call for a response team is placed over the intercom. This type of supervision is strong, but has some drawbacks, such as the creation of blind spots. These are created through indirect supervision because the guards standing watch can have objects blocking tiny spots or they may just not be looking in the right direction at the right time. Indirect supervision is an impersonal and more distant form of supervision that helps with officer safety, but leaves blind spots for “…inmates to conceal illicit activity from security staff”.\n\nDirect supervision is a more personal type of design because officers are assigned a cell block to patrol. Through this layout, the guards actually speak to cellmates one-on-one. The minor altercations that take place throughout the day is directly handled by the patrol officer, but this single officer cannot prevent a violent attack from happening. As soon as their back is turned or their attention is focused on someone else, the perpetrator can still commit their violence. In this form of supervision officers are left more vulnerable, but it also leads to, “…decreased tension and stress of staff and inmates…”. Direct supervision is more of a hands-on form of management, where “…major incidents are not as numerous and minor incidents result in higher numbers…”.\n\nOvercrowding is a huge problem many prisons face because handling so many short-fused inmates at once can lead to many altercations. The combination of “…overcrowding, inadequate supervision, and inmate access to weapons- can create opportunities for…offenses”. Trying to assert authority and strict rules on these violent offenders is extremely difficult due to the fact that these people do not respond well to restrictions and being told what to do. Having to focus on so many dangerous people at once is just not possible because there will always be someone not being watched over at any given moment; this is most likely when inmates choose to strike. Overcrowding is a very common issue in American prisons that leads to prison violence because the prisons will be understaffed.\n\nPrison violence and prison suicide in England and Wales have been increasing year on year while staffing levels have been falling. Reduction in the number of staff is blamed for this and the Ministry of Justice has admitted that staff cuts are a factor.<ref name=\"Guardian27/10/2016\">Prison violence epidemic partly due to staff cuts, MoJ admits \"The Guardian\"</ref> It was felt urgent action was needed. The government has provided money for increased staff but staffing levels are set to remain below 2010 levels.\n\nMark Day, of the Prison Reform Trust spoke of a “hidden emergency unfolding in our prison system” and said increasing prison violence should not become the new normal the lives of people living and working in prisons depended on that. Frances Crook, of the Howard League for Penal Reform, said: \nMost inmates look to get into an altercation armed with some sort of homemade weapon. The weapons they use to attack their victims are made to be very destructive and can easily be both hidden and accessed. They use objects such as shanks, clubs, daggers, razors, and saps to serve as weapons. A shank is a homemade knife, and is used to stab the person they are planning on fighting with, typically created by sharpening a common object. Clubs are considered “…objects such as pitchers, hot pots, and broom handles…”. They are put into use by throwing or hitting their target with these objects. A sap is typically a padlock enclosed in a sock, but really any hard object can be placed inside. Their prey is hit, typically over the head, with this weapon. Razor blades are very commonly used to commit prison violence. When an inmate knows there is a possibly of facing an attack, they will often place razors inside their mouths (in their cheeks) so that they can spit the razor out of their mouth and slash up the other person’s face. Since this tactic has been caught onto, many times a person will first punch whomever they are fighting in the face so that if a razor is in there, their whole mouth will get cut up. An inmate can choose the shank, club, dagger, razor, or sap as their weapon of choice to either do harm or protect themselves. When it comes to creating these weapons, prisoners really do serve as craftsmen and make weapon-making into an art of the sort.\n\nThe prison store, supplies provided by prisons, and objects visitors bring are typically where the weapon creation process begins. They get a hold of items, “…such as disposable razors and toothbrushes”. Then, these materials get manipulated and transformed into a weapon of destruction. They may sharpen it or harden it using other items. In other instances, “Items that appear innocuous have been converted into weapons”. Inmates also use everyday items in their natural form in dangerous ways that is clearly not used as they were originally intended. Often, when an inmate uses this form to create their weapons, it is used on officers because the items do not look questionable so it is easy to catch the corrections officer off guard. Some will, “…fashion the metal post of a bunk bed or the edge of a cell door into a spear…that could be flung from inside a cell and penetrate a man’s neck or liver”, which is called the bone crusher. Some inmates will go to great lengths to create weapons and many different ways to create these weapons has been discovered.\n\nOfficers call prison gangs STGs, or security threat groups. These groups are highly dangerous and take part in a huge majority of attacks that occur in prisons. Originally, “The early formation of STGs was based on racial/ethnic ideologies and protection from other groups. Later they developed the intent to commit acts of violence and form crime syndicates”. These gangs’ sole purpose is to have control and dominance, which is gained through violent attacks. Often, these attacks are committed onto rivals and people issued in the Bad News List. The Bad News List can be presumed as a factor for prison violence. This list is circulated among a gang and once a name is found on this list, it is inevitable that they will be attacked. A person is typically place on the Bad News List if they, “…stole from an affiliate on the outside, or because you failed to repay a drug debt, or because you’re suspected of ratting someone out”. The people on the list will be attacked on sight, but once their debts are paid, they are immediately removed from the Bad News List. Most, if not all, gang prison violence is instrumental and is very intricately planned out. Gang members will often send out or receive encoded, in depth letters on violent attacks that are ordered to take place, other times, “…gang members used the drainage pipes of their in-cell toilets to communicate clandestinely across cellblocks…”. It has become clear that, “Extensive communication systems coordinated between inmates, criminal activity, and street gangs are common”, and a vast majority of the prison violence that occurs begins with these communication systems. Security threat groups are at the heart of many of the altercations that take place within prison walls and they remorselessly commit these vicious acts simply because they are ordered to do so.\n\nInmates often feel animosity and a sense of hatred towards prison guards due to the treatment they receive and the power the guards have over them. In 1999, more than 2,400 correctional officers required medical attention after being assaulted by an inmate, and according to a 2002-2003 study, most guards were assaulted through the use of clubs. Along with these clubs, inmates tend to use weapons of opportunity when attacking an officer. A weapon of opportunity is any typical, everyday object that is not considered a weapon until used in a destructive way. The reason for this hostility, and ultimately inmate attacks on guards can be placed onto the way the incarcerated are treated.\n\nInmates are often humiliated and have extreme force placed upon them. There are no excuses that can be made in an officer’s offense to defend these actions, unless their life was put into jeopardy. Implementing these uncalled for actions reasonably cause animosity between the inmates and guards. There are cases where if an inmate disobeys an order, “…groups of officers…approach his cell, dressed in protective gear and armed with shield, Tasers, and other weapons. If the inmate refuses to comply, the officers will flood his cell with chemical agents…they have reportedly thrown stinger grenades, which spray rubber pellets into a concentrated area…and violently subdue him”. Correctional and Detention personnel use force as a last resort, in the above scenario; entry into an inmate's cell would need to be necessary before force could be justified. For example, if an inmate has a court hearing and has barricaded himself in his cell, refusing to come out or comply with the officials orders force might be used. Another instance would be if the inmate needed to be transferred to another facility and refuses to comply with the directives to move.\n\nPreventing all prison violence is an impossible task because it is impossible to be prepared for any and every situation. Nevertheless, prisons are taking measures to avoid, or at least limit, this violence. They are doing things such as balancing the cells, reducing blind spots, and training officers. When prisons receive new inmates, they search the background of the individual; they look into things like any possible gang affiliation and any history of racism or anger issues. After piecing this information together, the officers will place them in a cell block that they feel is most appropriate and that will cause the least arousal between the new inmate and the ones already housed there. Reducing the blind spots is a difficult task to complete because it is impossible to watch every inch of the prison at once, but by watching over as much as possible at a time does reduce the chances of violence occurring. Training officers is the third measure being taken. If officers treat the inmates properly and not be rash and assert violence on them so quickly, the inmates may feel more respected and not look to retaliate. Also with the training, officers are learning how to deal with minor altercations more effectively, as in without force and violence unless necessary. Also, the correction officers are learning about the psychology of the inmates. These officers are becoming aware of the psychological differences and hardships the incarcerated tend to face and how to properly deal with them. If all of these precautionary measures are taken, then prison violence rates can definitely lower, although completely vanishing is something not likely.\n\nA supermax is a separate facility within a prison where inmates are placed, “…for violent/predatory behavior within other institutions. They may be identified as gang leaders, or considered high risk for escape. Inmates incarcerated in the supermax facility do not have the freedoms allowed inmates in general population because of their security status/institutional disciplinary record”. These inmates are placed in a cell for twenty three hours a day and have limitation than the typical convict possess. This prevention measure works because it takes the biggest threats and influences, such as gang members, out of the picture. An issue that arises with this is that, “…some prisoners subjected to isolation become so damaged that they pose a renewed threat to staff and inmates when they return to the general prison population”. This means that the already dangerous and threatening inmates can return to the regular prison population with a new, stronger desire to retaliate and cause prison violence. The supermax facility serves as a good method to eradicate the influence of the most dangerous of inmates, but risks the return of a vengeful inmate.\n"}
{"id": "55131254", "url": "https://en.wikipedia.org/wiki?curid=55131254", "title": "Quantum groupoid", "text": "Quantum groupoid\n\nIn mathematics, a quantum groupoid is any of a number of notions in noncommutative geometry analogous to the notion of groupoid. In usual geometry, the information of a groupoid can be contained in its monoidal category of representations (by a version of Tannaka–Krein duality), in its groupoid algebra or in the commutative Hopf algebroid of functions on the groupoid. Thus formalisms trying to capture quantum groupoids include certain classes of (autonomous) monoidal categories, Hopf algebroids etc.\n\n"}
{"id": "56846504", "url": "https://en.wikipedia.org/wiki?curid=56846504", "title": "Rug plot", "text": "Rug plot\n\nA rug plot is a plot of data for a single qualitative variable, displayed as marks along an axis. It is used to visualise the distribution of the data. As such it is analogous to a histogram with zero-width bins, or a one-dimensional scatter plot.\n\nRug plots are often used in combination with two-dimensional scatter plots by placing a rug plot of the x values of the data along the x-axis, and similarly for the y values. This is the origin of the term \"rug plot\", as these rug plots with perpendicular markers look like tassels along the edges of the rectangular \"rug\" of the scatter plot.\n\n"}
{"id": "159554", "url": "https://en.wikipedia.org/wiki?curid=159554", "title": "Sex change", "text": "Sex change\n\nSex change is a process by which a person or animal changes sex – that is, by which female sexual characteristics are substituted for male ones, or vice versa. Sex change may occur naturally, as in the case of the sequential hermaphroditism observed in some species. Most commonly, however, the term is used for sex reassignment therapy, including sex reassignment surgery, carried out on humans. It is also sometimes used for the medical procedures applied to intersex people. The term may also be applied to the broader process of changing gender role (\"living as a woman\" instead of living as a man, or vice versa), including but not necessarily limited to medical procedures.\n\nSome species exhibit sequential hermaphroditism. In these species, such as many species of coral reef fishes, sex change is a normal anatomical process. Clownfish, wrasses, moray eels, gobies and other fish species are known to change sex, including reproductive functions. A school of clownfish is always built into a hierarchy with a female fish at the top. When she dies, the most dominant male changes sex and takes her place. In the wrasses (the family Labridae), sex change is from female to male, with the largest female of the harem changing into a male and taking over the harem upon the disappearance of the previous dominant male.\n\nNatural sex change, in both directions, has also been reported in mushroom corals. This is posited to take place in response to environmental or energetic constraints, and to improve the organism's evolutionary fitness; similar phenomena are observed in some dioecious plants.\n\nChickens can sometimes undergo natural sex changes. Normally, female chickens have just one functional ovary, on their left side. Although two sex organs are present during the embryonic stages of all birds, once a chicken's female hormones come into effect, it typically develops only the left ovary. The right gonad, which has yet to be defined as an ovary, testes, or both (called an ovotestis), typically remains dormant. Certain medical conditions can cause a chicken's left ovary to regress. In the absence of a functional left ovary, the dormant right sex organ may begin to grow, if the activated right gonad is an ovotestis or testes, it will begin secreting androgens. The hen does not completely change into a rooster, however. This transition is limited to making the bird phenotypically male. The condition could also be caused by mycotoxins that can develop when animal feed is stored, and these have the same effect as synthetic hormones. In about 10 per cent of cases, if eggs fertilised with male chromosomes are cooled by a few degrees for three days after laying, the relative activity of the sex hormones will favour development of female characteristics. The sex chromosomes work by coding for enzymes that affect the bird’s development in the egg and during its life. This cooling will produce a chicken with a fully functioning and reproductively fertile female body-type; even though the chicken is genetically male.\n\nSeveral medical conditions can result in an apparent sex change in humans, where the appearance at birth is somewhat, mostly, or completely of one sex, but changes over the course of a lifetime to being somewhat, mostly or completely of the other sex. The overwhelming majority of natural sex changes are from a female appearance at birth to a male appearance after puberty, due to either 5-alpha-reductase deficiency (5alpha-RD-2) or 17-beta-hydroxysteroid dehydrogenase deficiency (17beta-HSD-3). A relative handful of male to female changes have been reported, and the etiologies of these are not well understood.\n\nGenetic females (with two X chromosomes) with congenital adrenal hyperplasia lack an enzyme needed by the adrenal gland to make the hormones cortisol and aldosterone. Without these hormones, the body produces more androgens. This causes male sex characteristics to appear early (or inappropriately).\n\nGenetic males (with one X and one Y chromosome) with androgen insensitivity syndrome (AIS) are resistant to androgens. As a result, the person has some or all of the physical characteristics of a female, despite having the genetic makeup of a male. The degree of sexual ambiguity varies widely in persons with incomplete AIS. Incomplete AIS can include other disorders such as Reifenstein syndrome which is associated with breast development in men.\n\nHumans are most commonly said to have \"a sex change\" when they undergo sex reassignment therapy, that is, a set of medical procedures undergone by transsexual people to alter their sexual characteristics from male to female or from female to male. The term may also refer specifically to sex reassignment surgery, which usually refers to genital surgery only. The term is also sometimes used for the medical procedures intersex people undergo, or, more often, are subjected to as children.\n\nThe term \"sex change\" is sometimes also used for the whole process of changing gender role (\"living as a woman\" instead of living as a man, or vice versa), not limited to medical procedures. (This process is often much more important to transgender people than the medical procedures themselves, although medically induced changes and surgeries may be needed to make a change of gender role possible, both socially and legally; they can also have a very significant impact on the person's well-being.)\n\nMany people regard the term \"sex reassignment surgery\" as preferable to \"sex change\". Sex in humans is usually determined by four factors:\n\nNot all of these factors can be changed:\n\nGender reassignment is usually preceded by a period of feminization or masculinization. This is accomplished through hormone replacement therapy, where, for those transitioning to female, estrogens and antiandrogens and sometimes progestogens are prescribed. For those transitioning to male, androgens are prescribed. The most common minimum waiting period before gender reassignment surgery is two years, as specified by the Standards of Care for the Health of Transsexual, Transgender, and Gender Nonconforming People. Hormone replacement therapy is normally started after sufficient counselling, and/or after a period of living 'full-time' (in the target gender) typically for a minimum of six months. This waiting period may vary depending on local regulations, and is sometimes nonexistent. Many trans people become medical tourists, as gender reassignment surgery is typically less expensive, less regulated, and sometimes performed by much more experienced surgeons in countries such as Thailand.\n"}
{"id": "25272420", "url": "https://en.wikipedia.org/wiki?curid=25272420", "title": "Stalking", "text": "Stalking\n\nStalking is unwanted or repeated surveillance by an individual or group towards another person. Stalking behaviors are interrelated to harassment and intimidation and may include following the victim in person or monitoring them. The term \"stalking\" is used with some differing definitions in psychiatry and psychology, as well as in some legal jurisdictions as a term for a criminal offense.\n\nAccording to a 2002 report by the U.S. National Center for Victims of Crime, \"virtually any unwanted contact between two people that directly or indirectly communicates a threat or places the victim in fear can be considered stalking\", although in practice the legal standard is usually somewhat stricter.\n\nThe difficulties associated with defining this term exactly (or defining it at all) are well documented.\n\nHaving been used since at least the 16th century to refer to a prowler or a poacher (\"Oxford English Dictionary\"), the term \"stalker\" was initially used by media in the 20th century to describe people who pester and harass others, initially with specific reference to the harassment of celebrities by strangers who were described as being \"obsessed\". This use of the word appears to have been coined by the tabloid press in the United States. With time, the meaning of stalking changed and incorporated individuals being harassed by their former partners. Pathé and Mullen describe stalking as \"a constellation of behaviours in which an individual inflicts upon another repeated unwanted intrusions and communications\". Stalking can be defined as the willful and repeated following, watching and/or harassing of another person. Unlike other crimes, which usually involve one act, stalking is a \"series\" of actions that occur over a period of time.\n\nAlthough stalking is illegal in most areas of the world, some of the actions that contribute to stalking may be legal, such as gathering information, calling someone on the phone, texting, sending gifts, emailing, or instant messaging. They become illegal when they breach the legal definition of harassment (e.g., an action such as sending a text is not usually illegal, but is illegal when frequently repeated to an unwilling recipient). In fact, United Kingdom law states the incident only has to happen twice when the harasser should be aware their behavior is unacceptable (e.g., two phone calls to a stranger, two gifts, following the victim then phoning them, etc).\n\nCultural norms and meaning effect the way stalking is defined. Scholars note that the majority of men and women admit engaging in various stalking-like behaviors following a breakup, but stop such behaviors over time, suggesting that \"engagement in low levels of unwanted pursuit behaviors for a relatively short amount of time, particularly in the context of a relationship break-up, may be normative for heterosexual dating relationships occurring within U.S. culture.\"\n\nThe Violence Against Women Act of 2005, amending a United States statute, 108 Stat. 1902 et seq, defined stalking as \"engaging in a course of conduct directed at a specific person that would cause a reasonable person to—\n\nPeople characterized as stalkers may be accused of having a mistaken belief that another person loves them (erotomania), or that they need rescuing. Stalking can consist of an accumulation of a series of actions which, by themselves, can be legal, such as calling on the phone, sending gifts, or sending emails.\n\nStalkers may use overt and covert intimidation, threats and violence to frighten their victims. They may engage in vandalism and property damage or make physical attacks that are meant to frighten. Less common are sexual assaults.\n\nIntimate partner stalkers are the most dangerous type. In the UK, for example, most stalkers are former partners and evidence indicates that mental illness-facilitated stalking propagated in the media accounts for only a minority of cases of alleged stalking. A UK Home Office research study on the use of the Protection from Harassment Act stated: \"The study found that the Protection from Harassment Act is being used to deal with a variety of behaviour such as domestic and inter-neighbour disputes. It is rarely used for stalking as portrayed by the media since only a small minority of cases in the survey involved such behaviour.\"\n\nDisruptions in daily life necessary to escape the stalker, including changes in employment, residence and phone numbers, take a toll on the victim's well-being and may lead to a sense of isolation.\n\nAccording to Lamber Royakkers:\n\n\"Stalking is a form of mental assault, in which the perpetrator repeatedly, unwantedly, and disruptively breaks into the life-world of the victim, with whom they have no relationship (or no longer have). Moreover, the separated acts that make up the intrusion cannot by themselves cause the mental abuse, but do taken together (cumulative effect).\"\n\nStalking has also been described as a form of close relationship between the parties, albeit a disjunctive one where the two participants have opposing goals rather than cooperative goals. One participant, often a woman, likely wishes to end the relationship entirely, but may find herself unable to easily do so. The other participant, often but not always a man, wishes to escalate the relationship. It has been described as a close relationship because the duration, frequency, and intensity of contact may rival that of a more traditional conjunctive dating relationship.\n\nBased on work with stalking victims for eight years in Australia, Mullen and Pathé identified different types of stalking victims dependent on their previous relationship to the stalker. These are:\n\nAccording to one study, women often target other women, whereas men primarily stalk women. A January 2009 report from the United States Department of Justice reports that \"Males were as likely to report being stalked by a male as a female offender. 43% of male stalking victims stated that the offender was female, while 41% of male victims stated that the offender was another male. Female victims of stalking were significantly more likely to be stalked by a male (67%) rather than a female (24%) offender.\" This report provides considerable data by gender and race about both stalking and harassment, obtained via the 2006 Supplemental Victimization Survey (SVS), by the U.S. Census Bureau for the U.S. Department of Justice. In an article by Jennifer Langhinrichsen-Rohling she discusses how gender plays a role in the difference between stalkers and victims. She says, \"gender is associated with the types of emotional reactions that are experienced by recipients of stalking related events, including the degree of fear experienced by the victim.\" In addition, she hypothesizes that gender may also effect how police handle a case of stalking, how the victim copes with the situation, and how the stalker might view their behavior. She discusses how victims might view certain forms of stalking as normal because of gender socialization influences on the acceptability of certain behaviors. She emphasizes that in the United Kingdom, Australia, and the United States, strangers are considered more dangerous when it comes to stalking than a former partner. Media also plays an important role due to portrayals of male stalking behavior as acceptable, influencing men into thinking it is normal. Since gender roles are socially constructed, sometimes men don't report stalking. She also mentions coercive control theory, \"future research will be needed to determine if this theory can predict how changes in social structures and gender-specific norms will result in variations in rates of stalking for men versus women over time in the United States and across the world.\"\n\nPsychologists often group individuals who stalk into two categories: psychotic and nonpsychotic. Some stalkers may have pre-existing psychotic disorders such as delusional disorder, schizoaffective disorder, or schizophrenia. However, most stalkers are nonpsychotic and may exhibit disorders or neuroses such as major depression, adjustment disorder, or substance dependence, as well as a variety of personality disorders (such as antisocial, borderline, or narcissistic). The nonpsychotic stalkers' pursuit of victims is primarily angry, vindictive, focused, often including projection of blame, obsession, dependency, minimization, denial, and jealousy. Conversely, only 10% of stalkers had an erotomanic delusional disorder.\n\nIn \"A Study of Stalkers\" Mullen \"et al\". (2000) identified five types of stalkers:\nIn addition to Mullen et al., Joseph A. Davis, Ph.D., an American researcher, crime analyst, and university psychology professor at San Diego State University investigated, as a member of the Stalking Case Assessment Team (SCAT), special unit within the San Diego District Attorney's Office, hundreds of cases involving what he called and typed \"terrestrial\" and \"cyberstalking\" between 1995 and 2002. This research culminated in one of the most comprehensive books written to date on the subject. It is considered the \"gold standard\" as a reference to stalking crimes, victim protection, safety planning, security and threat assessment published by CRC Press, Inc., in August, 2001.\n\nThe 2002 National Victim Association Academy defines an additional form of stalking: The vengeance/terrorist stalker. Both the vengeance stalker and terrorist stalker (the latter sometimes called the political stalker) do not, in contrast with some of the aforementioned types of stalkers, seek a personal relationship with their victims but rather force them to emit a certain response. While the vengeance stalker's motive is \"to get even\" with the other person whom he/she perceives has done some wrong to them (e.g., an employee who believes is fired without justification from their job by their superior), the political stalker intends to accomplish a political agenda, also using threats and intimidation to force his/her target to refrain and/or become involved in some particular activity, regardless of the victim's consent. For example, most prosecutions in this stalking category have been against anti-abortionists who stalk doctors in an attempt to discourage the performance of abortions.\n\nStalkers may fit categories with paranoia disorders. Intimacy-seeking stalkers often have delusional disorders involving erotomanic delusions. With rejected stalkers, the continual clinging to a relationship of an inadequate or dependent person couples with the entitlement of the narcissistic personality, and the persistent jealousy of the paranoid personality. In contrast, resentful stalkers demonstrate an almost \"pure culture of persecution\", with delusional disorders of the paranoid type, paranoid personalities, and paranoid schizophrenia.\n\nOne of the uncertainties in understanding the origins of stalking is that the concept is now widely understood in terms of specific behaviors which are found to be offensive and/or illegal. As discussed above, these specific (apparently stalking) behaviors may have multiple motivations.\n\nIn addition, the personality characteristics that are often discussed as antecedent to stalking may also produce behavior that is not stalking as conventionally defined. Some research suggests there is a spectrum of what might be called \"obsessed following behavior.\" People who complain obsessively and for years, about a perceived wrong or wrong-doer, when no one else can perceive the injury—and people who cannot or will not \"let go\" of a person or a place or an idea—comprise a wider group of persons that may be problematic in ways that seem similar to stalking. Some of these people get extruded from their organizations—they may get hospitalized or fired or let go if their behavior is defined in terms of illegal stalking, but many others do good or even excellent work in their organizations and appear to have just one focus of tenacious obsession.\n\nCyberstalking is the use of computers or other electronic technology to facilitate stalking. In Davis (2001), Lucks identified a separate category of stalkers who instead of a terrestrial means, prefer to perpetrate crimes against their targeted victims through electronic and online means. Amongst college students, Ménard and Pincus found that men who had a high score of sexual abuse as children and narcissistic vulnerability were more likely to become stalkers. Out of the women who participated in their study, 9% were cyberstalkers meanwhile only 4% were overt stalkers. In addition, the male participants revealed the opposite, 16% were overt stalkers while 11% were cyberstalkers. Alcohol and physical abuse both played a role in predicting women's cyberstalking and in men, \"preoccupied attachment significantly predicted cyber stalking\".\n\nAccording to a U.S. Department of Justice special report a significant number of people reporting stalking incidents claim that they had been stalked by more than one person, with 18.2% reporting that they were stalked by two people, 13.1% reporting that they had been stalked by three or more. The report did not break down these cases into numbers of victims who claimed to have been stalked by several people individually, and by people acting in concert. A question asked of respondents reporting three or more stalkers by polling personnel about whether the stalking was related to co-workers, members of a gang, fraternities, sororities, etc., did not have its responses indicated in the survey results as released by the DOJ. The data for this report was obtained via the 2006 Supplemental Victimization Survey (SVS), conducted by the U.S. Census Bureau for the Department of Justice.\n\nAccording to a United Kingdom study by Sheridan and Boon, in 5% of the cases they studied there was more than one stalker, and 40% of the victims said that friends or family of their stalker had also been involved. In 15% of cases, the victim was unaware of any reason for the harassment.\n\nOver a quarter of all stalking and harassment victims do not know their stalkers in any capacity. About a tenth responding to the SVS did not know the identities of their stalkers. 11% of victims said they had been stalked for five years or more.\n\nIn 1999, Pathe, Mullen and Purcell wrote that popular interest in stalking was promoting false claims. In 2004, Sheridan and Blaauw said that they estimated that 11.5% of claims in a sample of 357 reported claims of stalking were false.\n\nAccording to Sheridan and Blaauw, 70% of false stalking reports were made by people suffering from delusions, stating that \"after eight uncertain cases were excluded, the false reporting rate was judged to be 11.5%, with the majority of false victims suffering delusions (70%).\" Another study estimated the proportion of false reports that were due to delusions as 64%.\n\nNews reports have described how groups of Internet users have cooperated to exchange detailed conspiracy theories involving coordinated activities by large numbers of people called \"gang stalking\". The activities involved are described as involving electronic harassment, the use of \"psychotronic weapons\", and other alleged mind control techniques. These have been reported by external observers as being examples of belief systems, as opposed to reports of objective phenomena. Some psychiatrists and psychologists say \"Web sites that amplify reports of mind control and group stalking\" are \"an extreme community that may encourage delusional thinking\" and represent \"a dark side of social networking. They may reinforce the troubled thinking of the mentally ill and impede treatment.\"\n\nA study from Australia and the United Kingdom by Lorraine Sheridan and David James compared 128 self-defined victims of 'gang-stalking' with a randomly selected group of 128 self-declared victims of stalking by an individual. All 128 'victims' of gang-stalking were judged to be delusional, compared with only 3.9% of victims of individual-stalking. There were highly significant differences between the two samples on depressive symptoms, post-traumatic symptomatology and adverse impact on social and occupational function, with the self-declared victims of gang-stalking more severely affected. The authors concluded that \"group-stalking appears to be delusional in basis, but complainants suffer marked psychological and practical sequelae. This is important in the assessment of risk in stalking cases, early referral to psychiatric services and allocation of police resources.\"\n\nAccording to a study conducted by Purcell, Pathé and Mullen (2002), 23% of the Australian population reported having been stalked.\n\nStieger, Burger and Schild conducted a survey in Austria, revealing a lifetime prevalence of 11% (women: 17%, men: 3%).\nFurther results include: 86% of stalking victims were female, 81% of the stalkers were male. Women were mainly stalked by men (88%) while men were almost equally stalked by men and women (60% male stalkers). 19% of the stalking victims reported that they were still being stalked at the time of study participation (point prevalence rate: 2%). To 70% of the victims, the stalker was known, being a prior intimate partner in 40%, a friend or acquaintance in 23% and a colleague at work in 13% of cases. As a consequence, 72% of the victims reported having changed their lifestyle. 52% of former and ongoing stalking victims reported suffering from a currently impaired (pathological) psychological well-being. There was no significant difference between the incidence of stalking in rural and urban areas.\n\nIn 1998 Budd and Mattinson found a lifetime prevalence of 12% in England and Wales (16% female, 7% males).\nIn 2010/11 43% of stalking victims were found to be male and 57% female.\n\nAccording to a paper by staff from the Fixated Threat Assessment Centre, a unit established to deal with people with fixations on public figures, 86% of a sample group of 100 people assessed by them appeared to them to suffer from psychotic illness; 57% of the sample group were subsequently admitted to hospital, and 26% treated in the community.\n\nA similar retrospective study published in 2009 in \"Psychological Medicine\" based on a sample of threats to the Royal Family kept by the Metropolitan Police Service over a period of 15 years, suggested that 83.6% of the writers of these letters suffered from serious mental illness.\n\nDressing, Kuehner and Gass conducted a representative survey in Mannheim, a middle-sized German city, and reported a lifetime prevalence of having been stalked of almost 12%.\n\nTjaden and Thoennes reported a lifetime prevalence (being stalked) of 8% in females and 2% in males (depending on how strict the definition) in the National Violence Against Women Survey.\n\nEvery Australian state enacted laws prohibiting stalking during the 1990s, with Queensland being the first state to do so in 1994. The laws vary slightly from state to state, with Queensland's laws having the broadest scope, and South Australian laws the most restrictive. Punishments vary from a maximum of 10 years imprisonment in some states, to a fine for the lowest severity of stalking in others. Australian anti-stalking laws have some notable features. Unlike many US jurisdictions they do not require the victim to have felt fear or distress as a result of the behaviour, only that a reasonable person would have felt this way. In some states, the anti-stalking laws operate extra-territorially, meaning that an individual can be charged with stalking if either they or the victim are in the relevant state. Most Australian states provide the option of a restraining order in cases of stalking, breach of which is punishable as a criminal offence. There has been relatively little research into Australian court outcomes in stalking cases, although Freckelton (2001) found that in the state of Victoria, most stalkers received fines or community based dispositions.\n\nSection 264 of the Criminal Code, titled \"criminal harassment\", addresses acts which are termed \"stalking\" in many other jurisdictions. The provisions of the section came into force in August 1993 with the intent of further strengthening laws protecting women. It is a hybrid offence, which may be punishable upon summary conviction or as an indictable offence, the latter of which may carry a prison term of up to ten years. Section 264 has withstood Charter challenges.\n\nThe Chief, Policing Services Program, for Statistics Canada has stated:\n\n\"... of the 10,756 incidents of criminal harassment reported to police in 2006, 1,429 of these involved more than one accused.\"\"\n\nArticle 222-33-2 of the French Penal Code (added in 2002) penalizes \"Moral harassment,\" which is: \"Harassing another person by repeated conduct which is designed to or leads to a deterioration of his conditions of work liable to harm his rights and his dignity, to damage his physical or mental health or compromise his career prospects,\" with a year's imprisonment and a fine of EUR15,000.\nThe German Criminal Code (§ 238 StGB) penalizes \"Nachstellung\", defined as threatening or seeking proximity or remote contact with another person and thus heavily influencing their lives, with up to three years of imprisonment. The definition is not strict and allows \"similar behaviour\" to also be classified as stalking.\nIn 2013, Indian Parliament made amendments to the Indian Penal Code, introducing stalking as a criminal offence. Stalking has been defined as a man following or contacting a woman, despite clear indication of disinterest by the woman, or monitoring her use of the Internet or electronic communication. A man committing the offence of stalking would be liable for imprisonment up to three years for the first offence, and shall also be liable to fine and for any subsequent conviction would be liable for imprisonment up to five years and with fine.\n\nFollowing a series of high-profile incidents that came to public attention in the past years, a law was proposed in June 2008, and became effective in February 2009 (D.L. 23.02.2009 n. 11), making a criminal offence under the newly introduced art. 612 bis of the penal code, punishable with imprisonment ranging from six months up to five years, any \"continuative harassing, threatening or persecuting behaviour which: (1) causes a state of anxiety and fear in the victim(s), or; (2) ingenerates within the victim(s) a motivated fear for his/her own safety or for the safety of relatives, , or others tied to the victim him/herself by an affective relationship, or; (3), forces the victim(s) to change his/her living habits\". If the perpetrator of the offense is a subject tied to the victim by kinship or that is or has been in the past involved in a relationship with the victim (i.e. current or former/divorced/split husband/wife or fiancée), and/or if the victim is a pregnant woman or a minor or a person with disabilities, the sanction can be elevated up to six years of incarceration.\n\nIn 2000, Japan enacted a national law to combat this behaviour, after the murder of Shiori Ino. Acts of stalking can be viewed as \"interfering [with] the tranquility of others' lives\" and are prohibited under petty offence laws.\n\nIn the Wetboek van Strafrecht there is an Article 285b that considers stalking as a crime, actually an Antragsdelikt:\nArticle 285b:\n\nArticle 208 of the 2014 Criminal Code states:-\n\nArticle 208: Harassment\n\n1. The act of someone who repeatedly follows, without right or a legitimate interest, a person or his or her home, workplace or other place frequented, thus causing a state of fear.\n\n2. Making phone calls or communication by means of transmission, which by frequent or continuous use, causes fear to a person. This shall be punished with imprisonment from one to three months or a fine if the case is not a more serious offense.\n\n3. Criminal action is initiated by prior complaint of the victim.\n\nAlready before the enactment of the Protection from Harassment Act 1997, the Malicious Communications Act 1988 and the Telecommunications Act 1984 (now the Communications Act 2003) criminalised indecent, offensive or threatening phone calls and the sending of an indecent, offensive or threatening letter, electronic communication or other article to another person. Before 1997 no specific offence existed in England and Wales but in Scotland incidents could be dealt with under pre-existing law with life imprisonment available for the worst offences \n\nEngland and Wales\n\nIn England and Wales, \"harassment\" was criminalised by the enactment of the Protection from Harassment Act 1997, which came into force on 16 June 1997. It makes it a criminal offence, punishable by up to six months' imprisonment, to make a course of conduct which amounts to harassment of another on two or more occasions. The court can also issue a restraining order, which carries a maximum punishment of five years' imprisonment if breached. In England and Wales, liability may arise in the event that the victim suffers either mental or physical harm as a result of being harassed (or slang term stalked) (see \"R. v. Constanza\").\n\nIn 2012, the Prime Minister, David Cameron, stated that the government intended to make another attempt to create a law aimed specifically at stalking behaviour.\n\nIn May 2012, the Protection of Freedoms Act 2012 created the offence of stalking for the first time in England/Wales by inserting these offences into the Protection from Harassment Act 1997. The act of stalking under this section is exemplified by contacting, or attempting to contact, a person by any means, publishing any statement or other material relating or purporting to relate to a person, monitoring the use by a person of the internet, email or any other form of electronic communication, loitering in any place (whether public or private), interfering with any property in the possession of a person or watching or spying on a person.\n\nThe Protection Of Freedoms Act 2012 also added Section 4(a) into the Protection From Harassment Act 1997 which covered 'Stalking involving fear of violence or serious alarm or distress'. This created the offence of where a person's conduct amounts to stalking and either causes another to fear (on at least two occasions) that violence will be used against them or conduct that causes another person serious alarm or distress which has a substantial effect on their usual day to day activities.\n\nScotland\n\nIn Scotland, behaviour commonly described as stalking was already prosecuted as the Common Law offence of breach of the peace (not to be confused with the minor English offence of the same description) before the introduction of the statutory offence against s.39 of the Criminal Justice and Licensing (Scotland) Act 2010; either course can still be taken depending on the circumstances of each case. The statutory offence incurs a penalty of 12 months imprisonment or a fine upon summary conviction or a maximum of five years' imprisonment and/or a fine upon conviction on indictment; penalties for conviction for Breach of the Peace are limited only by the sentencing powers of the court thus a case remitted to the High Court can carry a sentence of imprisonment for life.\n\nProvision is made under the Protection from Harassment Act against stalking to deal with the civil offence (i.e. the interference with the victim's personal rights), falling under the law of delict. Victims of stalking may sue for interdict against an alleged stalker, or a non-harassment order, breach of which is an offence.\n\nCalifornia was the first state to criminalize stalking in the United States in 1990 as a result of numerous high-profile stalking cases in California, including the 1982 attempted murder of actress Theresa Saldana, the 1988 massacre by Richard Farley, the 1989 murder of actress Rebecca Schaeffer, and five Orange County stalking murders, also in 1989. The first anti-stalking law in the United States, California Penal Code Section 646.9, was developed and proposed by Municipal Court Judge John Watson of Orange County. Watson with U.S. Congressman Ed Royce introduced the law in 1990. Also in 1990, the Los Angeles Police Department (LAPD) began the United States' first Threat Management Unit, founded by LAPD Captain Robert Martin.\n\nWithin three years thereafter, every state in the United States followed suit to create the crime of stalking, under different names such as \"criminal harassment\" or \"criminal menace\". The Driver's Privacy Protection Act (DPPA) was enacted in 1994 in response to numerous cases of a driver's information being abused for criminal activity, with prominent examples including the Saldana and Schaeffer stalking cases. The DPPA prohibits states from disclosing a driver's personal information without permission by State Department of Motor Vehicles (DMV). As of 2011, stalking is an offense under section 120a of the Uniform Code of Military Justice (UCMJ). The law took effect on 1 October 2007.\n\nStalking is a controversial crime because a conviction does not require any physical harm. The anti-stalking statute of Illinois is particularly controversial. It is particularly restrictive, by the standards of this type of legislation.\n\nThe Council of Europe Convention on preventing and combating violence against women and domestic violence defines and criminalizes stalking, as well as other forms of violence against women. The Convention came into force on 1 August 2014.\n\nStalking has been a key plot element in a number of movies. Robert De Niro has notably played a stalker in at least four films.\n\n\n\n\n\n"}
{"id": "49481270", "url": "https://en.wikipedia.org/wiki?curid=49481270", "title": "System U", "text": "System U\n\nIn mathematical logic, System U and System U are pure type systems, i.e. special forms of a typed lambda calculus with an arbitrary number of sorts, axioms and rules (or dependencies between the sorts). They were both proved inconsistent by Jean-Yves Girard in 1972. This result led to the realization that Martin-Löf's original 1971 type theory was inconsistent as it allowed the same \"Type in Type\" behaviour that Girard's paradox exploits.\n\nSystem U is defined as a pure type system with\n\nSystem U is defined the same with the exception of the formula_4 rule.\n\nThe sorts formula_5 and formula_6 are conventionally called “Type” and “Kind”, respectively; the sort formula_7 doesn't have a specific name. The two axioms describe the containment of types in kinds (formula_8) and kinds in formula_7 (formula_10). Intuitively, the sorts describe a hierarchy in the \"nature\" of the terms.\n\nThe rules govern the dependencies between the sorts: formula_21 says that values may depend on values (functions), formula_22 allows values to depend on types (polymorphism), formula_23 allows types to depend on types (type operators), and so on.\n\nThe definitions of System U and U allow the assignment of polymorphic kinds to \"generic constructors\" in analogy to polymorphic types of terms in classical polymorphic lambda calculi, such as System F. An example of such a generic constructor might be (where \"k\" denotes a kind variable)\n\nThis mechanism is sufficient to construct a term with the type formula_25, which implies that every type is inhabited. By the Curry–Howard correspondence, this is equivalent to all logical propositions being provable, which makes the system inconsistent.\n\nGirard's paradox is the type-theoretic analogue of Russell's paradox in set theory.\n\n"}
{"id": "29182754", "url": "https://en.wikipedia.org/wiki?curid=29182754", "title": "Theories of famines", "text": "Theories of famines\n\nThe conventional explanation until 1951 for the cause of famines was the decline of food availability (abbreviated as FAD for food availability decline). The assumption was that the central cause of all famines was a decline in food availability. However this does not explain why only a certain section of the population such as the agricultural laborer was affected by famines while others were insulated from them.\n\nIt has been suggested that the causal mechanism for precipitating starvation includes many variables other than just decline of food availability such as the inability of an agricultural laborer to exchange his primary entitlement, i.e. labor for rice, when his employment became erratic or was completely eliminated. According to the proposed theory, famines are due to an inability of a person to exchange his entitlements rather than to food unavailability. This theory is called the failure of exchange entitlements or FEE in short.\n\nAmartya Sen advances the theory that lack of democracy and famines are interrelated; he cites the example of the Bengal famine of 1943, stating that it only occurred because of the lack of democracy in India under British rule. He further argues that the situation was aggravated by the British government's suspension of trade in rice and grains among various Indian provinces.\n\nOlivier Rubin's review of the evidence disagrees with Sen; after examining the cases of post-Independence India, Niger, and Malawi, he finds that \"democracy is no panacea against famine.\" Rubin's analysis questions whether democracy and a free press were sufficient to truly avert famine in 1967 and 1972 (the Maharashtra famine involved some 130,000 deaths), and notes that some dynamics of electoral democracy complicate rather than bring about famine relief efforts. Rubin does not address colonial period famines.\n\nOn the other hand, Andrew Banik's study \"Starvation and India's democracy\" affirms Sen's thesis, but indicates that while democracy has been able to prevent famines in India, it has not been sufficient to avoid severe under-nutrition and starvation deaths, which Banik calls a 'silent emergency' in the country.\n\nAccording to a FEWSNET report, \"Famines are not natural phenomena, they are catastrophic political failures.\"\n\n\n"}
{"id": "48917358", "url": "https://en.wikipedia.org/wiki?curid=48917358", "title": "Theory of narrative thought", "text": "Theory of narrative thought\n\nThe Theory of Narrative Thought is a theory of thought designed to bridge the gap between the neurological functioning of the brain and the flow of everyday conscious experience. Proposed by Lee Roy Beach, the theory is expanded by Beach, Byron Bissell, and James Wise (2016).\n\n The theory of narrative thought (TNT) is a refinement of image theory which was developed as an alternative to rational choice theory. The essence of image theory is that decisions are shaped by long-term attempts to manage the future rather than short-term results. The image theory model of the decision process, called the compatibility test, held up in both laboratory and field tests (Beach, L. R., & Connolly, T. (2005). The Psychology of Decision Making: People in Organizations. Thousand Oaks, CA: Sage) and has been retained, but renamed, as the discrepancy test in TNT.\n\nThe theory of narrative thought (TNT) describes the brain as being composed of subsystems that act together to give rise to consciousness. Some of these subsystems, such as perception and memory, contribute content to consciousness. One subsystem in the left hemisphere codes the content in language while a corresponding subsystem in the right hemisphere links it with emotions. Working together as a single system, called the “interpreter,” they organize the content of consciousness. This order is the origin of narrative but at this point it is rudimentary, a proto-narrative. The proto-narrative is simple but up-to-date; it reflects what is happening at the moment. For infants, proto-narratives are pretty much the whole story, but as memories are formed, past proto-narratives become linked with present proto-narratives and, as caregivers lend a hand, more elaborate narratives take shape. As a store of elaborated narratives develops, proto-narratives continue to update them with current information from the perceptual system. This keeps the narratives aware of what is going on in the internal and external environments. Over time, two kinds of narratives develop.\n\nChronicle narratives are about what happened in the past, what is happening now, and what is expected to happen in the future. They are the ongoing story of one’s conscious experience. Procedural narratives are about how to do things. They are about the actions one can take to better inform one’s chronicle narratives. They also are about the actions one can take to shape the future by acting directly upon the internal or external environment to produce desired results. Procedural narratives are subordinate to chronicle narratives. When used alone, the word “narrative” refers to chronicle narratives. [Note that chronicle and procedural narratives are parallel to, but not identical to, Daniel Kahneman’s (2011) System 1 and System 2.]\n\nNarratives are more than just updated memories about what has happened recently. They are the stuff of ongoing conscious experience, of moment-to-moment thinking, of the richness of mental life, and they are the foundations for informed guesses about the future. They are a mixture of memories and of visual, auditory, and other imagery as well as the accompanying emotions. Their elements are symbols that stand for real or imagined events and actors (including oneself), where the actors are animate beings or inanimate forces. The events and actors are linked by causality. Causality implies temporality and, for animate actors, purpose. That is, a narrative consists of a temporal arrangement of events that are purposefully caused by animate beings (including oneself) or are the result of inanimate forces. The narrative’s storyline is its meaning, which is created by a coherent arrangement of the events and actors.\n\nCausality is the structural backbone of all narratives, both chronicle and procedural. This is because it is the source of narrative temporality. This temporal aspect of causality works retrospectively, from effect to cause, which allows one to account for what is happening now as a result of what has happened in the past. And it works prospectively, from cause to effect, which allows one to set expectations for what will happen in the future as a result of what is happening now and what came before. A good narrative is plausible if its actors’ actions contribute to the story line and are not uncharacteristic, i.e., are reasonably consistent across narratives. A good narrative is coherent if the actions of the actors and the effects of those actions conform to one’s causal rules. In short, a good narrative makes sense in that there are no loose ends.\n\nNoncontingent rules are about what to expect to happen as a result of actions by other people or outside forces over which one has no control. Contingent rules are about what one expects to happen as a result of one’s own actions. These rules form the causal linkages among narratives’ elements and are the bases of expected and action projections respectively.\n\nCausal rules tell one what caused something to happen or how to make something happen. Another kind of rule, normative rules, tell one why something should happen. Normative rules are about what qualifies as desirable and what does not. That is, normative rules are standards for what is ethical, right, proper, principled, reasonable, appropriate, preferred, and so on, all of which are one’s values and preferences.\n\nThe current narrative is the narrative one is focused upon at the moment. It is the narrative that makes sense of what has happened leading up to the present, what is happening right now, and what will happen next. The latter, results from extrapolating the past and present segments of current narrative to make educated guesses about the future. A guess about how the future might unfold if one does not make an effort to change it is called an expected projection and a guess about how the future might unfold as a result of one’s efforts to change it is called an action projection. Both projections are narratives. Both are extrapolations of the current narrative. Both are constructed using one’s store of causal rules. Both are subject to the scrutiny of normative rules. Both are imaginary.\n\nWhen the future is projected, based upon the current narrative, the emotions associated with the relevant normative rules provide the criteria for evaluating the desirability of that future. Each feature of the projected future elicits an emotion that reflects how well it meets the relevant standard(s) set by one’s normative rule(s). A positive emotion is elicited if it meets the standard(s) and a negative emotion is elicited if it doesn’t. The strength of the elicited emotion is a function of the degree to which the feature exceeds or falls short of the standard(s). When evaluating the desirability of the projected future, the focus is on the features that fall short of one’s standards—called violations. If the violations are too abundant, too large, or too important, the associated negative emotions mount to a point at which one must conclude that the projected future will be undesirable. When this happens, survival, or simply unacceptable discomfort, dictates that something must be done to change the future so that when it arrives it will be more desirable than if things are simply allowed to happen as they will. The action agenda for changing the future is called a plan and execution of that plan is called implementation. The anticipated result of implementing the plan is the action projection. An acceptable plan is one that offers a sufficiently desirable future, a future that is compatible with one’s values and preferences.\n\nA plan is a narrative about how one intends to go from the present to a more desirable future—how one intends to influence the course of ongoing events in a desirable direction. Like other narratives, plans must be plausible and coherent. Plausibility means that all the relevant elements, including oneself, are included and that their proposed actions are reasonable. Coherence means that the sequence of tactics creates a feasible causal chain from the present to the desired future. Plausibility is revealed by the ease with which one can imagine oneself and other actors engaging in a successful implementation of the plan, even if it will require hard work. Plausibility also requires that this activity seems natural and lifelike, and that success doesn’t rely on unlikely events or unrealistic amounts effort and resources. Coherence is revealed by the completeness of the causal chain of tactics, even though one knows one probably won’t end up doing things exactly as planned. A plan that lacks plausibility and/or coherence inspires little confidence (which is an emotion associated with a normative standard), which prompts its revision or replacement by another plan.\n\nBriefly stated: (1) There are two kinds of narratives: chronicle narratives, which are stories about ongoing events, including the expected future, and procedural narratives, which are stories about how to do things; (2) both kinds of narrative are structured by time and causality and both are “good narratives” if they are plausible and coherent; (3) the undesirability of the expected future is assessed by its failure to meet standards set by one’s values and preferences; (4) action is prompted when the projected future is determined to be so undesirable as to be unacceptable.\n\nBoth Beach (2010) and Beach, Bissell, and Wise (2016) open with a historical description of the ebbing fortunes of “executive mind,” as a scientific concept but how, over the past 50 years, it has come back, albeit on firmer ground, as “the brain.” But while “the brain” may be the new name for “mind,” the fact that the old name continues to be used in both scientific and everyday discourse suggests that the new name doesn’t quite do the job. That is, rather than merely reflecting sloppy usage, the word “mind” reflects something more than merely neural activity in the brain.\n\nOther than the computer analogy and the information processing metaphor, cognitive science has produce no encompassing theory. But it seems to be widely assumed that when such a theory appears, it will necessarily be in terms of brain function to which conscious experience is subsidiary and derivative. TNT challenges this assumption by recognizing that brain functioning and conscious experience are two qualitatively different things. Although subjective experience derives from brain activity, it is not reducible to it. Therefore, the theory recognizes the importance of the brain and how it works, but it also recognizes the importance of conscious experience and how it works. Putting the two together as equally legitimate and complementary provides the “something more” than neural activity in the brain that is implied by the word “mind.”\nMuch has been written about the characteristics of mind, mostly by philosophers. The commonalities across those discussions reveals three primary characteristics that a theory of mind should address and that are, in fact, addressed by TNT: Thinking that is both reflective and reflexive—that is able to consider both itself and things other than itself. Knowing that allows distinctions between truth and falsity, error and ignorance, and belief and opinion. Purpose that results in actions aimed at foreseen objectives. In addition, TNT addresses the most common questions raised in these philosophical discussions: How does the mind operate? What are its “intrinsic excellences or defects?” How is it related to matter, to bodily organs, to material conditions, and to other minds? Is it possessed in common with animals? Does it exist separate from corporeality? Insofar as the theory adequately deals with these characteristics and answers these questions, it qualifies as a modern theory of mind.\n\n"}
{"id": "22278748", "url": "https://en.wikipedia.org/wiki?curid=22278748", "title": "Touchstone (metaphor)", "text": "Touchstone (metaphor)\n\nAs a metaphor, a touchstone refers to any physical or intellectual measure by which the validity or merit of a concept can be tested. It is similar in use to an acid test, litmus test in politics, or, from a negative perspective, a shibboleth where the criterion is considered by some to be out-of-date.\nThe word was introduced into literary criticism by Matthew Arnold in \"the Study of Poetry\" (1880) to denote short but distinctive passages, selected from the writings of the greatest poets, which he used to determine the relative value of passages or poems which are compared to them. Arnold proposed this method of evaluation as a corrective for what he called the \"fallacious\" estimates of poems according to their \"historic\" importance in the development of literature, or else according to their \"personal\" appeal to an individual critic.\n\nA touchstone is a small tablet of dark stone such as fieldstone, slate, or lydite, used for assaying precious metal alloys. It has a finely grained surface on which soft metals leave a visible trace.\n\nAn example in literature is the character of Touchstone in Shakespeare's \"As You Like It\", described as \"a wise fool who acts as a kind of guide or point of reference throughout the play, putting everyone, including himself, to the comic test\".\n\nA touchstone can be a short passage from recognized masters' works used in assaying the relative merit of poetry and literature. This sense was coined by Matthew Arnold in his essay \"The Study of Poetry\", where he gives Hamlet's dying words to Horatio as an example of a touchstone.\n\nIn Germany, various interest groups sometimes send questionnaires to the campaigning political parties before federal parliament elections. These questionnaires, consisting of political survey questions the interest groups are interested in, are often called \"electoral touchstones\" (\"German:\" ). Those answers of a political party which might support or threaten the political goals of an interest group are finally published by the group in order to influence the voting behavior of potential voters being in favor of the political views of the interest group.\n"}
{"id": "2383576", "url": "https://en.wikipedia.org/wiki?curid=2383576", "title": "Wim Delvoye", "text": "Wim Delvoye\n\nWim Delvoye (born 1965 in Wervik, West Flanders) is a Belgian neo-conceptual artist known for his inventive and often shocking projects. Much of his work is focused on the body. He repeatedly links the attractive with the repulsive, creating work that holds within it inherent contradictions – one does not know whether to stare, be seduced, or to look away. As the critic Robert Enright wrote in the art magazine \"Border Crossings\", \"Delvoye is involved in a way of making art that reorients our understanding of how beauty can be created\". Wim Delvoye has an eclectic oeuvre, exposing his interest in a range of themes, from bodily function, and scatology to the function of art in the current market economy, and numerous subjects in between. He lives and works in Brighton, UK.\n\nDelvoye was raised in Wervik, a small town in West Flanders, Belgium. He did not have a religious upbringing but has been influenced by the Roman Catholic architecture that surrounded him. In a conversation with Michaël Amy of the \"New York Times\", Delvoye stated, \"I have vivid memories of crowds marching behind a single statue as well as of people kneeling in front of painted and carved altarpieces… Although I was barely aware of the ideas lurking behind these types of images, I soon understood that paintings and sculptures were of great importance\".\n\nGrowing up, Delvoye attended exhibitions with his parents, and his love of drawing eventually led him to art school, the Royal Academy of Fine Arts (Ghent). Delvoye has said that the pessimistic expectations for Belgian art students freed him, essentially making him realize that he “had nothing to lose”. Shortly thereafter, Delvoye began painting over wallpaper and carpets, coloring in the existing patterns and defying the tendency towards free expression vibrant in the art world at the time.\n\nDelvoye considers himself an originator of concepts—he is attracted initially to the theory behind pieces, instead of the act of painting itself. After 1990, specialists directed by Delvoye have executed most of his work. In 1992, Delvoye received international recognition with the presentation of his “Mosaic” at Documenta IX, a symmetrical display of glazed tiles featuring photographs of his own excrement. The organizer of Documenta IX, Jan Hoet claimed, “The strength of Wim Delvoye lies in his ability to engineer conflict by combining the fine arts and folk art, and playing seriousness against irony.” Three of his most well known projects are “Cloaca”, “Art Farm”, and a series of Gothic works.\n\nDelvoye is perhaps best known for his digestive machine, \"Cloaca\", which he unveiled at the Museum voor Hedendaagse Kunst, Antwerp, after eight years of consultation with experts in fields ranging from plumbing to gastroenterology. As a comment on the Belgians’ love of fine dining, \"Cloaca\" is a large installation that turns food into feces, allowing Delvoye to explore the digestive process. In his large mechanism, food begins at a long, transparent bowl (mouth), travels through a number of machine-like assembly stations, and ends in hard matter which is separated from liquid through a cylinder. Delvoye collects and sells the realistically smelling output, suspended in small jars of resin at his Ghent studio. When asked about his inspiration, Delvoye stated that everything in modern life is pointless. The most useless object he could create was a machine that serves no purpose at all, besides the reduction of food to waste. \"Cloaca\" has appeared in many incarnations including: \"Cloaca Original\", \"Cloaca - New & Improved\", \"Cloaca Turbo\", \"Cloaca Quattro\", \"Cloaca N° 5\", and \"Personal Cloaca\". Delvoye also sold specially printed toilet paper as a souvenir of the exhibit. In 2016, 5 rolls from the 2007 Mudam Luxembourg exhibit were offered for re-sale for US$300 through an online vendor.\n\nPreviously, Delvoye claimed that he would never sell a \"Cloaca\" machine to a museum as he could never trust that the curator would maintain the installation properly. However, after two years of discussion with David Walsh, Delvoye agreed to construct a custom \"Cloaca\" built specifically for the Museum of Old and New Art in Hobart, Tasmania. The new installation is suspended from the museum ceiling in a room custom-built for it.\n\nThough Delvoye started tattooing pig skins taken from slaughterhouses in the United States in 1992, he began to tattoo live pigs in 1997. Delvoye was interested in the idea that “the pig would literally grow in value,\" both in a physical and economic sense. He ultimately moved the operation to an Art Farm in China in 2004. The pigs have been inked with a diverse array of designs, including the trivial, such as skulls and crosses, to Louis Vuitton designs, to designs dictated by the pig's anatomy\". In an interview with \"ArtAsiaPacific's\" Paul Laster, Delvoye described the process of tattooing a live pig, \"we sedate it, shave it and apply Vaseline to its skin\".\n\nDelvoye is additionally well known for his “gothic” style work. In 2001, Delvoye, with the help of a radiologist, had several of his friends paint themselves with small amounts of barium, and perform explicit sexual acts in medical X-ray clinics. He then used the X-ray scans to fill gothic window frames instead of classic stained glass. Delvoye suggests that radiography reduces the body to a machine. When he was not an active participant, Delvoye observed from a computer screen in another room, allowing the subjects enough distance to perform normally, although Delvoye has described the whole operation as \"very medical, very antiseptic\". Delvoye also creates oversized laser-cut steel sculptures of objects typically found in construction (like a cement truck), customized in seventeenth-century Flemish Baroque style. These structures juxtapose \"medieval craftsmanship with Gothic filigree\". Delvoye brings together the heavy, brute force of contemporary machinery and the delicate craftsmanship associated with Gothic architecture.\n\nIn a 2013 show in New York City, Delvoye showed intricate laser-cut works combining architectural and figurative references with shapes such as a Möbius band or a Rorschach inkblot.\n\n\n"}
{"id": "860924", "url": "https://en.wikipedia.org/wiki?curid=860924", "title": "Wind farm", "text": "Wind farm\n\nA wind farm or wind park is a group of wind turbines in the same location used to produce electricity. A large wind farm may consist of several hundred individual wind turbines and cover an extended area of hundreds of square miles, but the land between the turbines may be used for agricultural or other purposes. A wind farm can also be located offshore.\n\nMany of the largest operational onshore wind farms are located in China, India, and the United States. For example, the largest wind farm in the world, Gansu Wind Farm in China has a capacity of over 6,000 MW as of 2012, with a goal of 20,000 MW by 2020. As of September 2018, the 659 MW Walney Wind Farm in the UK is the largest offshore wind farm in the world.\n\nIndividual wind turbine designs continue to increase in power, resulting in fewer turbines being needed for the same total output. See list of most powerful wind turbines.\n\nThe location is critical to the success of a wind farm. Conditions contributing to a successful wind farm location include: wind conditions, access to electric transmission, physical access, and local electric prices.\n\nThe faster the average windspeed the more electricity the wind turbine will generate, so faster winds are economically better for wind farm developers. The balancing factor is that strong gusts and high turbulence require stronger more expensive turbines, otherwise they risk damage. The ideal wind conditions would be strong steady winds with low turbulence coming from a single direction.\n\nUsually sites are screened on the basis of a wind atlas, and validated with wind measurements. Meteorological wind data alone is usually not sufficient for accurate siting of a large wind power project. Collection of site specific data for wind speed and direction is crucial to determining site potential in order to finance the project. Local winds are often monitored for a year or more, and detailed wind maps are constructed before wind generators are installed.\nThe wind blows faster at higher altitudes because of the reduced influence of drag. The increase in velocity with altitude is most dramatic near the surface and is affected by topography, surface roughness, and upwind obstacles such as trees or buildings.\n\nHow closely to space the turbines together is a major factor in wind farm design. The closer the turbines are together the more the upwind turbines block wind from their neighbors. However spacing turbines far apart increases the costs of roads and cables, and raises the amount of land needed to install a specific capacity of turbines. As a result of these factors, turbine spacing varies by site. Generally speaking manufacturers require 3.5 times the rotor diameter of the turbine between turbines as a minimum. Closer spacing is possible depending on the turbine model, the conditions at the site, and how the site will be operated.\n\nThe world's first wind farm was 0.6 MW, consisting of 20 wind turbines rated at 30 kilowatts each, installed on the shoulder of Crotched Mountain in southern New Hampshire in December 1980.\n\nOnshore turbine installations in hilly or mountainous regions tend to be on ridges generally three kilometres or more inland from the nearest shoreline. This is done to exploit the topographic acceleration as the wind accelerates over a ridge. The additional wind speeds gained in this way can increase energy produced because more wind goes through the turbines. The exact position of each turbine matters, because a difference of 30m could potentially double output. This careful placement is referred to as 'micro-siting'.\n\nEurope is the leader in offshore wind energy, with the first offshore wind farm (Vindeby) being installed in Denmark in 1991. As of 2010, there are 39 offshore wind farms in waters off Belgium, Denmark, Finland, Germany, Ireland, the Netherlands, Norway, Sweden and the United Kingdom, with a combined operating capacity of 2,396 MW. More than 100 GW (or 100,000 MW) of offshore projects are proposed or under development in Europe. The European Wind Energy Association has set a target of 40 GW installed by 2020 and 150 GW by 2030.\n\n, The Walney Wind Farm in the United Kingdom is the largest offshore wind farm in the world at 659 MW, followed by the London Array (630 MW) also in the UK.\n\nOffshore wind turbines are less obtrusive than turbines on land, as their apparent size and noise is mitigated by distance. Because water has less surface roughness than land (especially deeper water), the average wind speed is usually considerably higher over open water. Capacity factors (utilisation rates) are considerably higher than for onshore locations.\n\nThe province of Ontario in Canada is pursuing several proposed locations in the Great Lakes, including the suspended Trillium Power Wind 1 approximately 20 km from shore and over 400 MW in size. Other Canadian projects include one on the Pacific west coast.\n\nIn 2010, there were no offshore wind farms in the United States, but projects were under development in wind-rich areas of the East Coast, Great Lakes, and Pacific coast; and in late 2016 the Block Island Wind Farm was commissioned.\n\nInstallation and service / maintenance of off-shore wind farms are a specific challenge for technology and economic operation of a wind farm. , there are 20 jackup vessels for lifting components, but few can lift sizes above 5MW. Service vessels have to be operated nearly 24/7 (availability higher than 80% of time) to get sufficient amortisation from the wind turbines. Therefore, special fast service vehicles for installation (like Wind Turbine Shuttle) as well as for maintenance (including heave compensation and heave compensated working platforms to allow the service staff to enter the wind turbine also at difficult weather conditions) are required. So-called inertial and optical based Ship Stabilization and Motion Control systems (iSSMC) are used for that.\n\nThere exist also some wind farms which were mainly built for testing wind turbines. In such wind farms, there is usually from each type to be tested only a single wind turbine. Such farms have usually at least one meteorological tower. An example of an experimental wind farm is Østerild Wind Turbine Test Field.\n\nFor some time, airborne wind farms have been discussed. An airborne wind farm is a group of airborne wind energy systems near to each other, connected to the grid in the same point.\n\nIn just five years, China leapfrogged the rest of the world in wind energy production, going from 2,599 MW of capacity in 2006 to 62,733 MW at the end of 2011. However, the rapid growth outpaced China's infrastructure and new construction slowed significantly in 2012.\n\nAt the end of 2009, wind power in China accounted for 25.1 gigawatts (GW) of electricity generating capacity, and China has identified wind power as a key growth component of the country's economy. With its large land mass and long coastline, China has exceptional wind resources. Researchers from Harvard and Tsinghua University have found that China could meet all of their electricity demands from wind power by 2030.\n\nBy the end of 2008, at least 15 Chinese companies were commercially producing wind turbines and several dozen more were producing components. Turbine sizes of 1.5 MW to 3 MW became common. Leading wind power companies in China were Goldwind, Dongfang Electric, and Sinovel along with most major foreign wind turbine manufacturers. China also increased production of small-scale wind turbines to about 80,000 turbines (80 MW) in 2008. Through all these developments, the Chinese wind industry appeared unaffected by the global financial crisis, according to industry observers.\n\nAccording to the Global Wind Energy Council, the development of wind energy in China, in terms of scale and rhythm, is absolutely unparalleled in the world. The National People's Congress permanent committee passed a law that requires the Chinese energy companies to purchase all the electricity produced by the renewable energy sector.\n\nThe European Union has a total installed wind capacity of 93,957 MW. Germany has the third-largest capacity in the world (after China and the United States) with an installed capacity was 29,060 MW at the end of 2011, and Spain has 21,674 MW. Italy and France each had between 6,000 and 7,000 MW. By January 2014, the UK installed capacity was 10,495 MW. But energy production can be different from capacity – in 2010, Spain had the highest European wind power production with 43 TWh compared to Germany's 35 TWh.\n\nEurope's largest windfarm is the 'London Array', an off-shore wind farm in the Thames Estuary in the United Kingdom, with a current capacity of 630 MW (the world's largest off-shore wind farm). Other large wind farms in Europe include Fântânele-Cogealac Wind Farm near Constanța, Romania with 600 MW capacity, and Whitelee Wind Farm near Glasgow, Scotland which has a total capacity of 539 MW.\n\nAn important limiting factor of wind power is variable power generated by wind farms. In most locations the wind blows only part of the time, which means that there has to be back-up capacity of conventional generating capacity to cover periods that the wind is not blowing. To address this issue it has been proposed to create a \"supergrid\" to connect national grids together across western Europe, ranging from Denmark across the southern North Sea to England and the Celtic Sea to Ireland, and further south to France and Spain especially in Higueruela which was for some time the biggest wind farm in the world. The idea is that by the time a low pressure area has moved away from Denmark to the Baltic Sea the next low appears off the coast of Ireland. Therefore, while it is true that the wind is not blowing everywhere all of the time, it will always be blowing somewhere.\n\nIndia has the fifth largest installed wind power capacity in the world. As of 31 March 2014, the installed capacity of wind power was 21136.3 MW mainly spread across Tamil Nadu state (7253 MW). Wind power accounts nearly 8.5% of India's total installed power generation capacity, and it generates 1.6% of the country's power.\n\nThe 117 MW Tafila Wind Farm in Jordan was inaugurated in December 2015, and is the first large scale wind farm project in the region.\n\nMorocco has undertaken a vast wind energy program, to support the development of renewable energy and energy efficiency in the country. The Moroccan Integrated Wind Energy Project, spanning over a period of 10 years with a total investment estimated at $3.25 billion, will enable the country to bring the installed capacity, from wind energy, from 280 MW in 2010 to 2000 MW in 2020.\n\nPakistan has wind corridors in Jhimpir, Gharo and Keti Bundar in Sindh province and is currently developing wind power plants in Jhimpir and Mirpur Sakro (District Thatta). The government of Pakistan decided to develop wind power energy sources due to problems supplying energy to the southern coastal regions of Sindh and Balochistan.\nThe Zorlu Energy Putin Power Plant is the first wind power plant in Pakistan. The wind farm is being developed in Jhimpir, by Zorlu Energy Pakistan the local subsidiary of a Turkish company. The total cost of project is $136 million.[3] Completed in 2012, it has a total capacity of around 56MW.\nFauji Fertilizer Company Energy Limited, has build a 49.5 MW wind Energy Farm at Jhimpir. Contract of supply of mechanical design was awarded to Nordex and Descon Engineering Limited. Nordex a German wind turbine manufacturer. In the end of 2011 49.6 MW will be completed.Pakistani Govt. also has issued LOI of 100 MW Wind power plant to FFCEL. Pakistani Govt. has plans to achieve electric power up to 2500 MW by the end of 2015 from wind energy to bring down energy shortage.\n\nCurrently four wind farms are operational (Fauji Fertilizer 49.5 MW (subsidiary of Fauji Foundation), Three Gorges 49.5 MW, Zorlu Energy Pakistan 56 MW, Sapphire Wind Power Co Ltd 52.6 MW) and six are under construction phase ( Master Wind Energy Ltd 52.6 MW, Sachal Energy Development Ltd 49.5 MW, Yunus Energy Ltd 49.5 MW, Gul Energy 49.5 MW, Metro Energy 49.5 MW, Tapal Energy ) and expected to achieve COD in 2017.\n\nIn Gharo wind corridor, two wind farms (Foundation Energy 1 & II each 49.5 MW) are operational while two wind farms Tenaga Generasi Ltd 49.5 MW and HydroChina Dawood Power Pvt Ltd 49.5 are under construction and expected to achieve COD in 2017.\n\nAccording to a USAID report, Pakistan has the potential of producing 150,000 megawatts of wind energy, of which only the Sindh corridor can produce 40,000 megawatts.\n\nThe Philippines has the first windfarm in Southeast Asia. Located Northern part of the countries' biggest island Luzon, alongside the seashore of Bangui, Ilocos Norte.\n\nThe wind farm uses 20 units of 70-metre (230 ft) high Vestas V82 1.65 MW wind turbines, arranged on a single row stretching along a nine-kilometer shoreline off Bangui Bay, facing the West Philippine Sea.\n\nPhase I of the NorthWind power project in Bangui Bay consists of 15 wind turbines, each capable of producing electricity up to a maximum capacity of 1.65 MW, for a total of 24.75 MW. The 15 on-shore turbines are spaced 326 metres (1,070 ft) apart, each 70 metres (230 ft) high, with 41 metres (135 ft) long blades, with a rotor diameter of 82 metres (269 ft) and a wind swept area of 5,281 square metres (56,840 sq ft). Phase II, was completed on August 2008, and added 5 more wind turbines with the same capacity, and brought the total capacity to 33 MW. All 20 turbines describes a graceful arc reflecting the shoreline of Bangui Bay, facing the West Philippine Sea.\n\nAdjacent municipalities of Burgos and Pagudpud followed with 50 and 27 wind turbines with a capacity of 3 MW each for a Total of 150 MW and 81 MW respectively.\n\nTwo other wind farms were built outside of Ilocos Norte, the Pililla Wind Farm in Rizal and the Mindoro Wind Farm near Puerto Galera in Oriental Mindoro.\n\nSri Lanka has received funding from the Asian Development Bank amounting to $300 million to invest in renewable energies. From this funding as well as $80 million from the Sri Lankan Government and $60 million from France’s Agence Française de Développement, Sri Lanka is building two 100MW wind farms from 2017 due to be completed by late 2020 in Northern Sri Lanka.\n\n \nAs of September 2015 a number of sizable wind farms have been constructed in South Africa mostly in the Western Cape region. These include the 100 MW Sere Wind Farm and the 138 MW Gouda Wind Facility.\n\nMost future wind farms in South Africa are earmarked for locations along the Eastern Cape coastline. Eskom has constructed one small scale prototype windfarm at Klipheuwel in the Western Cape and another demonstrator site is near Darling with phase 1 completed. The first commercial wind farm, Coega Wind Farm in Port Elisabeth, was developed by the Belgian company Electrawinds.\n\nU.S. wind power installed capacity in 2012 exceeded 51,630 MW and supplies 3% of the nation's electricity.\n\nNew installations place the U.S. on a trajectory to generate 20% of the nation’s electricity by 2030 from wind energy. Growth in 2008 channeled some $17 billion into the economy, positioning wind power as one of the leading sources of new power generation in the country, along with natural gas. Wind projects completed in 2008 accounted for about 42% of the entire new power-producing capacity added in the U.S. during the year.\n\nAt the end of 2008, about 85,000 people were employed in the U.S. wind industry, and GE Energy was the largest domestic wind turbine manufacturer. Wind projects boosted local tax bases and revitalized the economy of rural communities by providing a steady income stream to farmers with wind turbines on their land. Wind power in the U.S. provides enough electricity to power the equivalent of nearly 9 million homes, avoiding the emissions of 57 million tons of carbon each year and reducing expected carbon emissions from the electricity sector by 2.5%.\n\nTexas, with 10,929 MW of capacity, has the most installed wind power capacity of any U.S. state, followed by California with 4,570 MW and Iowa with 4,536 MW. The Alta Wind Energy Center (1,020 MW) in California is the nation's largest wind farm in terms of capacity. Altamont Pass Wind Farm is the largest wind farm in the U.S. in terms of the number of individual turbines.\n\nPublic perception is that renewable energies such as wind, solar, biomass and geothermal are having a significant positive impact on global warming. All of these sources combined only supplied 1.3% of global energy in 2013 as 8 billion tonnes of coal was burned annually.\n\nOne of the biggest factors inhibiting wind farm construction is human opposition. A study has shown \"turbine placement close to residents may heighten their uncertainty and concern of the wind turbines and overshadow any positive inclinations towards the development.\"\n\nWind farm development is affected by the emphasis being primarily placed on the domain of landscape assessment and environmental impact when seeking farm sites. The viability and efficiency of the wind farm are barely touched upon, instead falling to the developer. For example, Sturge et al. of the University of Sheffield wrote that in many countries where wind energy is becoming popular, engineering aspects, specifically energy yield are not being taken into consideration, either by the public or in the process of planning consent for wind farm development. As energy is the main purpose of wind farms, a lack of attention given to the subject could be detrimental to the general acceptance of wind farms.\n\nCompared to the environmental impact of traditional energy sources, the environmental impact of wind power is relatively minor. Wind power consumes no fuel, and emits no air pollution, unlike fossil fuel power sources. The energy consumed to manufacture and transport the materials used to build a wind power plant is equal to the new energy produced by the plant within a few months. While a wind farm may cover a large area of land, many land uses such as agriculture are compatible, with only small areas of turbine foundations and infrastructure made unavailable for use.\n\nThere are reports of bird and bat mortality at wind turbines as there are around other artificial structures. The scale of the ecological impact may or may not be significant, depending on specific circumstances. The estimated number of bird deaths caused by wind turbines in the United States is between 140,000 and 328,000, whereas deaths caused by domestic cats in the United States are estimated to be between 1.3 and 4.0 billion birds each year and over 100 million birds are killed in the United States each year by impact with windows.\nPrevention and mitigation of wildlife fatalities, and protection of peat bogs, affect the siting and operation of wind turbines.\n\nThere have been multiple scientific, peer-reviewed studies into wind farm noise, which have concluded that infrasound from wind farms is not a hazard to human health and there is no verifiable evidence for 'Wind Turbine Syndrome' causing Vibroacoustic disease, although some suggest further research might still be useful.\n\nA 2007 report by the U.S. National Research Council noted that noise produced by wind turbines is generally not a major concern for humans beyond a half-mile or so. Low-frequency vibration and its effects on humans are not well understood and sensitivity to such vibration resulting from wind-turbine noise is highly variable among humans. There are opposing views on this subject, and more research needs to be done on the effects of low-frequency noise on humans.\n\nIn a 2009 report about \"Rural Wind Farms\", a Standing Committee of the Parliament of New South Wales, Australia, recommended a minimum setback of two kilometres between wind turbines and neighbouring houses (which can be waived by the affected neighbour) as a precautionary approach.\n\nA 2014 paper suggests that the 'Wind Turbine Syndrome' is mainly caused by the nocebo effect and other psychological mechanisms. Australian science magazine Cosmos states that although the symptoms are real for those who suffer from the condition, doctors need to first eliminate known causes (such as pre-existing cancers or thyroid disease) before reaching definitive conclusions with the caveat that new technologies often bring new, previously unknown health risks.\n\nUtility-scale wind farms must have access to transmission lines to transport energy. The wind farm developer may be obliged to install extra equipment or control systems in the wind farm to meet the technical standards set by the operator of a transmission line. The company or person that develops the wind farm can then sell the power on the grid through the transmission lines and ultimately chooses whether to hold on to the rights or sell the farm or parts of it to big business like GE, for example.\n\nWind farms can interfere with ground radar systems used for military, weather and air traffic control. The large, rapidly moving blades of the turbines can return signals to the radar that can be mistaken as an aircraft or weather pattern.\nActual aircraft and weather patterns around wind farms can be accurately detected, as there is no fundamental physical constraint preventing that. But aging radar infrastructure is significantly challenged with the task. The US military is using wind turbines on some bases, including Barstow near the radar test facility.\n\nThe level of interference is a function of the signal processors used within the radar, the speed of the aircraft and the relative orientation of wind turbines/aircraft with respect to the radar. An aircraft flying above the wind farm's turning blades could become impossible to detect because the blade tips can be moving at nearly aircraft velocity. Studies are currently being performed to determine the level of this interference and will be used in future site planning. Issues include masking (shadowing), clutter (noise), and signal alteration. Radar issues have stalled as much as 10,000 MW of projects in USA.\n\nSome very long range radars are not affected by wind farms.\n\nPermanent problem solving include a \"non-initiation window\" to hide the turbines while still tracking aircraft over the wind farm, and a similar method mitigates the false returns.\nEngland's Newcastle Airport is using a short-term mitigation; to \"blank\" the turbines on the radar map with a software patch. Wind turbine blades using stealth technology are being developed to mitigate radar reflection problems for aviation. As well as stealth windfarms, the future development of infill radar systems could filter out the turbine interference.\n\nA mobile radar system, the Lockheed Martin TPS-77, can distinguish between aircraft and wind turbines, and more than 170 TPS-77 radars are in use around the world. \n\nThere are also reports of negative effects on radio and television reception in wind farm communities. Potential solutions include predictive interference modelling as a component of site selection.\n\nWind turbines can often cause terrestrial television interference when the direct path between television transmitter and receiver is blocked by terrain. Interference effects become significant when the reflected signal from the turbine blades approaches the strength of the direct unreflected signal. Reflected signals from the turbine blades can cause loss of picture, pixellation and disrupted sound. There is a common misunderstanding that digital TV signals will not be affected by turbines — in practice they are.\n\nA 2010 study found that in the immediate vicinity of wind farms, the climate is cooler during the day and slightly warmer during the night than the surrounding areas due to the turbulence generated by the blades.\n\nIn another study an analysis carried out on corn and soybean crops in the central areas of the United States noted that the microclimate generated by wind turbines improves crops as it prevents the late spring and early autumn frosts, and also reduces the action of pathogenic fungi that grow on the leaves. Even at the height of summer heat, the lowering of 2.5–3 degrees above the crops due to turbulence caused by the blades, can make a difference for the cultivation of corn.\n\n\n"}
{"id": "34599315", "url": "https://en.wikipedia.org/wiki?curid=34599315", "title": "Yi Cheol-seung", "text": "Yi Cheol-seung\n\nLee Chul-seung (or Yi Cheol-seung, Lee Chul-sung or Lee Chul Sung) (Hangul:, Hanja:李哲承; May 15, 1922 – February 27, 2016) was a South Korean 7-term National Assemblyman (lawmaker, conservative) and a founding father of the Republic of Korea after the Korean War (1950-1953). A political heavyweight, Lee was an independence and democracy fighter and leader; anti-communism; anti-military rule; anti-Japanese rule; an advocate of bipartisanship particularly when it came to national security; and an advocate of non-governmental organizations. After Korea was liberated from Japanese colonial rule in 1945, Lee \"led a student union that opposed a trusteeship, under which Korea would be governed by foreign powers after World War II, and entered politics in 1954 after winning a parliamentary seat.\" Lee and his two political rivals former President Kim Young-sam and former President Kim Dae-jung were famous for their political competition and the establishment and development of democracy in South Korea. He was given an honorable burial for his life contributions at the Seoul National Cemetery on March 2, 2016 where former South Korean presidents are also buried.\n\n\n1946 \n\n1954\n1958~1961\n1961\n1966\n1969\n1971~1973\n1973\n1975\n1976\n1978\n1984~\n1985\n1987\n\nOn May 16, 1961, Park Chung-hee, Kim Jong-pil, and Lee Nak-sun successfully staged a military coup d'etat. Immediately after, Park Chung-hee sent aides to try and win over key opposition lawmakers including Lee who rejected Park's request for help. Lee was forced to leave politics and went to the United States where he was vocally opposed to the military coup in Korea and studied Political Science at the University of Pennsylvania.\n\n1990\n1993\n1994~\n1995~\n1996~\n1998\n2005\n2007\n2011~2016\n\nLee died on February 27, 2016 at 03:45 KST, at Samsung Hospital in Seoul at the age of 94. A funeral was held for him on March 2, 2016 that began with a five-day wake and a police-escorted procession that led to the National Assembly and ended with a gun salute at the Seoul National Cemetery where he is buried along with former South Korean presidents.\n\n\n\n"}
