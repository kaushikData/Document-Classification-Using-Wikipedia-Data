{"id": "241267", "url": "https://en.wikipedia.org/wiki?curid=241267", "title": "12-hour clock", "text": "12-hour clock\n\nThe 12-hour clock is a time convention in which the 24 hours of the day are divided into two periods: a.m. (from Latin \"ante meridiem\", translates to, before midday) and p.m. (from Latin \"post meridiem\" translates to, past midday). Each period consists of 12 hours numbered: \"12\" (acting as zero), \"1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\" and \"11\". The 24 hour/day cycle starts at 12 midnight (may be indicated as 12 a.m.), runs through 12 noon (may be indicated as 12 p.m.), and continues to the midnight at the end of the day. The 12-hour clock has been developed from the middle of the second millennium BC to the 16th century AD.\n\nThe 12-hour time convention is common in several English-speaking nations and former British colonies, as well as a few other countries.\n\nThe natural day-and-night division of a calendar day forms the fundamental basis as to why each day is split into two cycles.\nOriginally there were two cycles; one cycle which could be tracked by the position of the Sun (day) followed by one cycle which could be tracked by the Moon and stars (night).\nThis would eventually evolve into the two 12-hour periods that started at midnight (a.m.) and noon (p.m.) which are used today. Noon itself is rarely abbreviated today, but if it is, it is denoted M.\n\nThe 12-hour clock can be traced back as far as Mesopotamia and Ancient Egypt.\nBoth an Egyptian sundial for daytime use\nand an Egyptian water clock for night-time use were found in the tomb of Pharaoh Amenhotep I.\nDating to c. 1500 BC, these clocks divided their respective times of use into 12 hours each.\n\nThe Romans also used a 12-hour clock: daylight was divided into 12 equal hours (thus hours having varying length throughout the year) and the night was divided into four watches.\n\nThe first mechanical clocks in the 14th century, if they had dials at all, showed all 24 hours, used the 24-hour analog dial, influenced by astronomers' familiarity with the astrolabe and sundial, and their desire to model the Earth's apparent motion around the Sun.\nIn Northern Europe these dials generally used the 12-hour numbering scheme in Roman numerals, but showed both \"a.m.\" and \"p.m.\" periods in sequence. This is known as the double-XII system, and can be seen on many surviving clock faces, such as those at Wells and Exeter.\n\nElsewhere in Europe, particularly in Italy, numbering was more likely to be based on the 24-hour system (I to XXIV), reflecting the Italian style of counting the hours. The 12-hour clock was used throughout the British empire.\n\nDuring the 15th and 16th centuries, the 12-hour analog dial and time system gradually became established as standard throughout Northern Europe for general public use. The 24-hour analog dial was reserved for more specialized applications, such as astronomical clocks and chronometers.\n\nMost analog clocks and watches today use the 12-hour dial, on which the shorter hour hand rotates once every 12 hours and twice in one day. Some analog clock dials have an inner ring of numbers along with the standard 1-to-12 numbered ring. The number 12 is paired either with a 00 or a 24, while the numbers 1 through 11 are paired with the numbers 13 through 23, respectively. This modification allows the clock to be read also in the 24-hour notation. This kind of 12-hour clock can be found in countries where the 24-hour clock is preferred.\n\nIn several countries the 12-hour clock is the dominant written and spoken system of time, predominantly in nations that were part of the former British Empire, for example, the United Kingdom, Republic of Ireland, the United States, Australia, New Zealand, India, Pakistan, Bangladesh, Malaysia and others follow this convention as well such as Egypt, Mexico and the former American colony of the Philippines. In most countries, however, the 24-hour clock is the standard system used, especially in writing. Some nations in Europe and Latin America use a combination of the two, preferring the 12-hour system in colloquial speech but using the 24-hour system in written form and in formal contexts.\n\nThe 12-hour clock in speech often uses phrases such as \" ... in the morning, ... in the afternoon, ... in the evening,\" and \"...at night\". In the United Kingdom, these descriptive phrases are still used. \"Rider's British Merlin\" almanac for 1795 and a similar almanac for 1773 published in London used them.. Other than English-speaking countries, the terms \"a.m.\" and \"p.m.\" are seldom used and often unknown.\n\nIn most countries, computers by default show the time in 24-hour notation. Most operating systems, including Microsoft Windows and Unix-like systems such as Linux and macOS, activate the 12-hour notation by default for a limited number of language and region settings. This behavior can be changed by the user, such as with the Windows operating system \"Region and Language\" settings.\n\nThe Latin abbreviations \"a.m.\" and \"p.m.\" (often written \"am\" and \"pm\", \"AM\" and \"PM\", or \"A.M.\" and \"P.M.\") are used in English and Spanish. The equivalents in Greek are and , respectively, and in Sinhala () for (, - fore, pre) and () for (, - after, post). However, noon is rarely abbreviated in any of these languages, noon normally being written in full. In Portuguese, there are two official options and many other used, for example, using 21:45 pm: 21h45 or 21h45min (official ones) or 21:45 or 9:45 p.m. In Irish, \"a.m.\" and \"i.n.\" are used, standing for \"ar maidin\" (\"in the morning\") and \"iarnóin\" (\"afternoon\") respectively.\n\nMost other languages lack formal abbreviations for \"before noon\" and \"after noon\", and their users use the 12-hour clock only orally and informally. However, in many languages, such as Russian and Hebrew, informal designations are used, such as \"9 in the morning\" or \"3 in the night\".\n\nWhen abbreviations and phrases are omitted, one may rely on sentence context and societal norms to reduce ambiguity. For example, if one commutes to work at \"9:00\", 9:00 a.m. may be implied, but if a social dance is scheduled to begin at \"9:00\", it may begin at 9:00 p.m.\n\nThe terms \"a.m.\" and \"p.m.\" are abbreviations of the Latin \"ante meridiem\" (before midday) and \"post meridiem\" (after midday). Depending on the style guide referenced, the abbreviations \"a.m.\" and \"p.m.\" are variously written in small capitals (\" and \"), uppercase letters without a period (\"AM\" and \"PM\"), uppercase letters with periods, or lowercase letters (\"am\" and \"pm\" or, more commonly, \"a.m.\" and \"p.m.\").\n\nSome stylebooks suggest the use of a space between the number and the a.m. or p.m. abbreviation. Style guides recommend not using a.m. and p.m. without a time preceding it, although doing so can be advantageous when describing an event that always happens before or after noon.\n\nThe hour/minute separator varies between countries: some use a colon, others use a period (full stop), and still others use the letter h. In many instances using the 24-hour clock, there is no separator between hours and minutes (0800, read as written, i.e. \"oh-eight-hundred\").\n\nIn Unicode, there exist symbols for:\n\nThey are meant to be used only with Chinese-Japanese-Korean character sets, as they take up exactly the same space as one Chinese character.\n\nIt is common to round the time to the nearest five minutes and express the time as so many minutes past an hour, for example, \"five past five\" or \"five to five\".15 minutes is often expressed as \"a quarter\" such as \"a quarter past five\" and 30 minutes as \"half past five\" or merely \"half five\"). The time would be spoken as 8:45, and \"\"(a) quarter to\" \"nine\"\". Moreover, in situations where the relevant hour is obvious or has been recently mentioned, speakers can use terms \"quarter to\" and \"half past\" to avoid elaborate sentences in particularly informal conversations. These forms are often commonly used in television and radio broadcasts that cover multiple time zones at one-hour intervals.\n\nInstead of meaning 5:30, the \"half five\" expression is sometimes used to mean 4:30, or \"half-way to five\", especially for regions such as the American Midwest and other areas that have been particularly influenced by German culture. This meaning follows the pattern choices of many Germanic and Slavic languages, including Dutch, Danish, Finnish, Russian and Swedish, as well as Hungarian.\n\nMinutes may be expressed as an exact number of minutes past the hour specifying the time of day (e.g., 6:32 p.m. is \"six thirty-two\"). Additionally, when expressing the time using the \"past (after)\" or \"to (before)\" formula, it is conventional to choose the number of minutes below 30 (e.g., 6.32 pm is conventionally \"twenty-eight minutes to seven\" rather than \"thirty-two minutes past six\").\n\nIn spoken English, full hours are often represented by the numbered hour followed by \"o'clock\" (10:00 as \"ten o'clock\", 2:00 as \"two o'clock\"). This may be followed by the \"a.m.\" or \"p.m.\" designator, though phrases such as \"in the morning, in the afternoon, in the evening,\" or \"at night\" more commonly follow analog-style terms such as \"o'clock, half past three,\" and \"quarter to four. O'clock\" itself may be omitted, telling a time as \"four a.m.\" or \"four p.m.\" Minutes \":01\" to \":09\" are usually pronounced as \"oh one\" to \"oh nine\" (\"nought\" or \"zero\" can also be used instead of \"oh\"). Minutes \":10\" to \":59\" are pronounced as their usual number-words. For instance, 6:02 a.m. can be pronounced \"six oh two a.m.\" whereas 6:32 a.m. could be told as \"six thirty-two a.m.\"\n\nIt is not always clear what times \"12:00 a.m.\" and \"12:00 p.m.\" denote. From the Latin words \"meridies\" (midday), \"ante\" (before) and \"post\" (after), the term \"ante meridiem\" (a.m.) means before midday and \"post meridiem\" (p.m.) means after midday. Since \"noon\" (midday - \"meridies\" (m.)) is neither before nor after itself, the terms a.m. and p.m. do not apply. Although \"12 m.\" was suggested as a way to indicate noon, this is seldom done and also does not resolve the question of how to indicate midnight.\n\n\"The American Heritage Dictionary of the English Language\" states \"By convention, \"12 AM\" denotes midnight and \"12 PM\" denotes noon. Because of the potential for confusion, it is advisable to use \"12 noon\" and \"12 midnight\".\"\n\nE. G. Richards in his book \"Mapping Time\" provided a diagram in which 12 a.m. means noon and 12 p.m. means midnight. The style manual of the United States Government Printing Office used 12 a.m. for noon and 12 p.m. for midnight until its 2008 edition, when it reversed these designations, later maintained in its 2016 revision.\n\nMany U.S. style guides, and NIST's \"Frequently asked questions (FAQ)\" web page, recommend that it is clearest if one refers to \"noon\" or \"12:00 noon\" and \"midnight\" or \"12:00 midnight\" (rather than to \"12:00 p.m.\" and \"12:00 a.m.\"). The NIST website states that \"12 a.m. and 12 p.m. are ambiguous and should not be used.\"\n\n\"The Associated Press Stylebook\" specifies that midnight \"is part of the day that is ending, not the one that is beginning.\" Thus, according to AP style, \"midnight Friday\" occurs one minute after 11:59 p.m. Friday, not one minute before 12:01 a.m. Friday.\n\n\"The Canadian Press Stylebook\" says, \"write \"noon\" or \"midnight\", not \"12 noon\" or \"12 midnight\".\" Phrases such as \"12 a.m.\" and \"12 p.m.\" are not mentioned at all. Britain's National Physical Laboratory \"FAQ-Time\" web page states \"In cases where the context cannot be relied upon to place a particular event, the pair of days straddling midnight can be quoted\"; also \"the terms 12 a.m. and 12 p.m. should be avoided.\"\n\nLikewise, some U.S. style guides recommend either clarifying \"midnight\" with other context clues, such as specifying the two dates between which it falls, or not referring to midnight at all. For an example of the latter method, \"midnight\" is replaced with \"11:59 p.m.\" for the end of a day or \"12:01 a.m.\" for the start of a day. That has become common in the United States in legal contracts and for airplane, bus, or train schedules, though some schedules use other conventions. Occasionally, when trains run at regular intervals, the pattern may be broken at midnight by displacing the midnight departure one or more minutes, such as to 11:59 p.m. or 12:01 a.m.\n\n\n"}
{"id": "1057043", "url": "https://en.wikipedia.org/wiki?curid=1057043", "title": "Abnormality (behavior)", "text": "Abnormality (behavior)\n\nAbnormality (or dysfunctional behavior) is a behavioral characteristic assigned to those with conditions regarded as rare or dysfunctional. Behavior is considered abnormal when it is atypical or out of the ordinary, consists of undesirable behavior, and results in impairment in the individual's functioning. Abnormality is that which is considered deviant from specific societal, cultural and ethical expectations. These expectations are broadly dependent on age, gender, traditional and societal categorizations. The definition of abnormal behavior is an often debated issue in abnormal psychology because of these subjective variables. \n\n\"Abnormal\" behavior should not be confused with \"unusual\" behavior. Behavior that is out of the ordinary is not necessarily indicative of a mental or psychological disorder. Abnormal behavior, on the other hand, while not a mental disorder in itself, is often indicative of mental and psychological disorders. A psychological disorder is defined as an \"ongoing dysfunctional pattern of thought, emotion, and behavior that causes significant distress, and is considered deviant in that person's culture or society\". Important to note is that abnormal behavior, as it relates to psychological disorders, would be \"ongoing\" and a cause of \"significant distress\". A mental disorder describes a patient who has a medical condition whereby the medical practitioner makes a judgement that the patient is exhibiting abnormal behavior based on the DSM-5 criteria. Thus, simply because a behavior is unusual does not make it abnormal; it is only considered abnormal if it meets these criteria.\n\nThere are five main criteria of abnormality. They are: \n\nAbnormal behaviors are \"actions that are unexpected and often evaluated negatively because they differ from typical or usual behavior\". \n\nThe following Criteria are subjective:\n\n\n\nThe standard criteria in psychology and psychiatry is that of mental illness or mental disorder. Determination of abnormality is based upon medical diagnosis.\n\nOther Criteria\n\n\nA common approach to defining abnormality is a Multi-Criteria approach, where all definitions of abnormality are used to determine whether an individual's behavior is abnormal. For example, psychologists would be prepared to define an individual's behavior as \"abnormal\" if the following criteria are met. \n\n\n\n\nA good example of an abnormal behavior assessed by a multi-criteria approach is depression: it is commonly seen as a deviation from ideal mental stability, it often stops the individual from 'functioning' a normal life, and, though it is a relatively common mental disorder, it is still statistically infrequent. Most people do not experience significant major depressive disorder in their lifetime. Thus, depression and its associated behaviors would be considered abnormal. \n\nThough not mentioned by many psychologists a lot of abnormal people can all agree that they were bullied into social ostracism when they were in school or by their families, they would tell you how people were consistently angry with them. For example: \n\nKid A: Loves things that are the social norms, loves the expected interests that Kid A was told to love by parents and loved ones, has a group of friends that loves everything Kid A loves and respects. \n\nKid B: Sees Kid A and his group of friends and wants to fit in with Kid A’s friends, he does everything he can to fit in to the social norms and expected interests Kid A loves, Kid A sees Kid B takes an interest in Kid A, Kid A gets ferociously offended and yells at Kid B to NEVER do those things again. Kid B then, feels alone,sad and empty and eventually finds something NOT liked by everyone and then LOVES it. \n\n"}
{"id": "48302927", "url": "https://en.wikipedia.org/wiki?curid=48302927", "title": "Access to public information in Serbia", "text": "Access to public information in Serbia\n\nAccess to public information and freedom of information (FOI) refer to the right of access to information held by public bodies also known as \"right to know\". Access to public information is considered of fundamental importance for the effective functioning of democratic systems, as it enhances governments' and public officials' accountability, boosting people participation and allowing their informed participation into public life. The fundamental premise of the right of access to public information is that the information held by governmental institutions is in principle public and may be concealed only on the basis of legitimate reasons which should be detailed in the law.\n\nIn Serbia, access to public information is guaranteed in the Constitution and protected by the Law on free Access to Information of Public Importance adopted in 2003 and amended in 2007 and 2009. \nThe scope of the right entails that everyone in Serbia has the right to access to information of public importance and to be informed whether public authorities hold specific information, whether such information is already accessible, and to obtain a copy of the requested information.\nThe Commissioner for Information of Public Importance and Protection of personal data is the authority entitled by law to monitor the respect of obligations entailed by this Law.\n\nSerbia is considered among the countries with the best regulatory framework regarding access to information of public relevance: the Global Right to Information Rating, compiled by NGOs AccessInfo and Centre for Law and Democracy, ranks the country in the second position in its global ranking assessing the quality of legislative frameworks regulating FOI across the world.\n\nThe right of access to public information is defined in Article 51 of the Constitution of Serbia, which establishes the right of everybody to be informed about issues of public importance and the deriving obligation of state bodies and public organizations to guarantee the access to such information.\n\nThe right to access to information of public relevance is translated into national law by the Law on Free Access to Information of Public Importance adopted in 2003 and amended in 2007 and 2009.\n\nThe scope of the law is valued positively especially inasmuch as it extends the right to access to information to all natural person, notwithstanding their citizenship, temporary or permanent residence in the country.\n\nMoreover, the right to access information applies to the executive, legislative and judicial bodies, State-owned enterprises, as well as other public authorities and private bodies that perform a public function or that receive significant public funding are also obliged to disclose information of public relevance (Art. 3).\n\nRequests should be lodged in written form, with no need for the applicant to specify the reason for the request.\nThe public authority shall reply without delay and within 15 days at the latest. If the requested information entails consequences for the protection of a person's life or freedom, public health and the environment, the time span at the disposal of authorities is reduced to 48 hours. In cases in which the document contains information that the public has no legitimate interest to know, the applicant has the right to access to other parts of the documents.\n\nLimitations to the right to access to information are defined in Article 9 of the Law, establishing that legitimate limitation may derive if the requested information exposes to risk the life, health, safety or another vital interest of a person; if it obstacles the work of the judiciary; if it threatens national defense, national and public safety, international relations or the government's ability to manage the national economic processes. Finally, classified information are excluded from the right.\n\nThe authority in charge of monitoring the respect of the Law is the Commissioner for Information of Public Importance. The Commissioner is an independent, second-level appeal instance: if a public authority does not respond to the request within the deadline, the applicant may lodge a complaint with the Commissioner, except in cases prescribed by this Law (Art.16).\n\nThe Commissioner is entitled by Law to issue decisions on disputed cases, and his/her decisions should be enforced by the Government of the Republic of Serbia if necessary (Art 28). The Commissioner is appointed by the National Assembly of the Republic of Serbia on proposal of the Committee of the National Assembly responsible for information. The position of the Commissioner for Information has been held since 2004 by Rodoljub Šabić, who was appointed for an initial 7-years term and then re-elected in 2011.\n\nAside from examining individual complaints related to violations of the right to free access to information, the Commissioner also addresses citizens’ requests asking how to exercise their right to information, provides to state authorities opinions about the implementation of the law, trainings for law implementation and takes part in activities related to the EU accession process.\n\nIt has been noted that a significant limitation of the right set forth in the Constitution is due to the restrictions applied to the admissibility of complaints against first instance decisions: a complaint is not admissible if “lodged against decisions of the National Assembly, the President of the Republic, the Government of the Republic of Serbia, the Supreme Court of Serbia, the Constitutional Court and the Republic Public Prosecutor” (Art. 22).\n\nSince the adoption of the Law on Access to Information in 2004, a significant increase in the number of requests has been registered by the entitled Commissioner, pointing to the positive fact that the right is increasing being used by citizens and media professionals in Serbia. At the same time, the increasing number of complaints filed to the Commissioner demonstrates the reluctancy by authorities to timely and fully comply with the obligation established by the Law on access to information.\n\nIn its annual report for 2015, the Commissioner for Information notes some limitation to the effective implementation of the law. These have to do, according to the Commissioner, particularly with insufficient accountability for violations of the Law and inefficient mechanisms of enforcement of the Commissioner’s decisions.\n\nConsidering the implementation of the Law on Access to Information in Serbia and its impact on the exercise of journalism, Freedom House has noted in 2016 that “Despite the existence of the 2004 Law on Free Access to Information of Public Importance, authorities frequently obstruct journalists’ efforts to obtain public information”.\n\nConcern over implementation, alignment with European standards, endowment of resources to the Commissioner for Information and enforcement of his decisions is highlighted also by the European Union in its annual report.\n\nA landmark case by the European Court of Human Rights related to the right to access to information in Serbia. \nIn 2006, the Belgrade-based NGO Youth Initiative for Human Rights (YIHR) filed a request to the Serbian Security Intelligence Agency demanding information concerning the use of electronic surveillance measures by that agency in 2005. \nThe Agency denied access to the requested information twice, first on grounds of secrecy and then, after a binding decision by the Commissioner for Information stating that the information should be made public, by declaring that it did not hold the requested information.\n\nYIHR appealed to the European Court of Human Rights under Article 6 and Article 10 of the Convention.\nIn June 2013, the verdict of the ECtHR defined “unpersuasive” the argument used by the Agency according to which it did not hold the information requested and found that the restrictions imposed by the Serbian intelligence agency were not justified by domestic law and hence constituted a violation of article 10 of the European Convention on Human Rights.\n\n\n"}
{"id": "43592732", "url": "https://en.wikipedia.org/wiki?curid=43592732", "title": "Aikyam", "text": "Aikyam\n\nAikyam (Sanskrit: ऐक्यम्) means – oneness, unity, harmony, unanimity, identity or sameness or identical. All thoughts of the Upanishads move around two fundamental ideas – Brahman and the Atman; as a rule these terms are used synonymously, there is no difference between these two. The main theme of Vedantic teaching is identity of the individual and the Total (\"jiva isvara aikyam\"), that the self (\"Atman\") and awareness (\" Chaitanya \") are identical (\"aikyam\"). \"Aikyam\" means oneness or identity.\n\nThe Vedas are part of oral tradition, therefore they are called \" Śruti \" (that which is heard), Upanishads, known as the Vedanta, are the destroyer of bondage. The oneness of the Individual Self and the Universal Self (\"jīvātma paramātma aikyam\") is \"Śrutisara\", the ultimate purport of the Vedas. In the compound word – \"Brahman atman aikyam\", unity of the Brahman and the Atman, is described the fundamental dogma of the Vedanta system.\n\nThe Vedic Rishis tell us – सत्त्वानुरूपा सर्वस्य श्रद्धा भवति – that undoubtedly the faith of all men conforms to their mental constitution, they speak about the two Unmanifests – the one which transforms itself and causes other transformations, and the other one that supports the former it had projected with the intention of commencing creation, although there is no real difference between these two. Rishi Dirghatamas (Rig Veda I.163.4) prays to Agni thus:-\n\nThis unique awareness of Sameness which is actually the awareness of Oneness is the knowledge of Reality, the true knowledge of existence, gaining which knowledge the true seeker ceases to see difference in this vast world of \"variety\" which difference is seen only as so many names echoing and re-echoing persistently in one’s mind. Rishi Venobhargavah (Rig Veda IX.85.9) also speaks about the same knowledge of Oneness when he prays:-\nand tells us about the stars and celestial luminaries dotting the sky shining because of the light of the self-effulgent Brahman shining brightly revealing everything and providing strength and stability (अधिद्यामस्थात्),who is pure and the source of amrita (पीयूषं) desired by the learned people (नृचक्षसः), who is the giver of happiness and who is the deliverer being the only source of immortality.201-203\n\nVedantasara explains that the subject (\"visheya\") is the identity of the individual self and Brahman, which is of the nature of Pure Intelligence (wherein all ideas of separation and variety are effaced) and is to be realized – सर्वे वेदा यत् पदमामनन्ति – That goal which all the Vedas declare (Katha Upanishad I.ii.15), and that the connection (\"sambandha\") is the relation between that identity which is to be realized and the evidence of the Upanishads that establishes it, as between a thing to be known and that which tells of it.p.16 \nsankara states that the notion of a multitude of souls is valid only at the level of the empirical world. While the \"Atman\" stays within the limits of the body, emotions and intellect, there cannot be any dissolution, any absolute unity (\"sarvarthā- aikyam\") with Brahman; the soul is only the reflection of the higher \"ātman\". There is only one reality. That about which the cognition does not change is \"sat\" – real and that about which cognition keeps changing or is negated is \"asat\" – unreal; the Atman or Brahman alone being unchangeable and un-negatable is the only \"sat\" or Reality.\n\nAccording to Madhavacharya, \"aikyam\" cannot be real at all; if it were, the absolutism would have vanished. The Absolute is the only reality, \"aikyam\" cannot be another reality. And, Nagarjuna explains – if there were to be identity of cause and effect, then there would be oneness of producer and the produce; if there were to be difference between cause and effect, then the cause would be equal to a non-cause. \n"}
{"id": "14002867", "url": "https://en.wikipedia.org/wiki?curid=14002867", "title": "Annie Arniel", "text": "Annie Arniel\n\nAnnie Arniel (May 1873 – February 9, 1924) was a suffragist and women's rights advocate. Born in Harrington, Delaware, United States, as Anna L. Melvin, she married George Arniel of Canada and was widowed in 1910. Annie played a key role in helping to win the women's vote in the United States.\n\nArniel was a factory worker, living in downtown Wilmington, Delaware, when she was recruited by Mabel Vernon and Alice Paul for membership in the National Woman's Party (NWP). As a member of the Silent Sentinels she was among the first six suffragists arrested and jailed on June 27, 1917, at the White House. She served eight jail terms for suffrage protesting: three days in June 1917; 60 days in the Occoquan prison in Virginia, from August to September 1917, for picketing; 15 days for a meeting in Lafayette Square; and five sentences of five days each in January and February 1919 for the NWP's watchfire demonstrations.\n\n\n"}
{"id": "6024273", "url": "https://en.wikipedia.org/wiki?curid=6024273", "title": "Arsenault-Cameron v Prince Edward Island", "text": "Arsenault-Cameron v Prince Edward Island\n\nArsenault-Cameron v Prince Edward Island, [2000] 1 S.C.R. 3, 2000 SCC 1, is a landmark Supreme Court of Canada decision on minority language rights. The Court found that the numbers of Francophone children in Summerside, Prince Edward Island warranted French-language education in Summerside, under section 23 of the \"Canadian Charter of Rights and Freedoms\", and the province was constitutionally obligated to create a French language school.\n\nA number of Francophone families living in Summerside made a request to the French Language Board to build a French-language school in the community rather than bus the children to the closest French school 57 minutes away. The Board made a proposal to the Minister which was rejected.\n\nThe family applied for a declaration against the province to build a school in Summerside. At trial the declaration was granted but was overturned on appeal.\n\nIn the decision of \"Arsenault-Cameron v. Prince Edward Island\", [1999] 3 S.C.R. 851, prior to the language rights hearing, the counsel for the government sought to have Bastarache recuse himself for reasonable apprehension of bias due to his history of championing the French language. In an application to Bastarache, he held that he was not biased to hear the case, and so did not recuse himself.\n\nMajor and Bastarache, writing for a unanimous court, applied a purposive interpretation to section 23 of the \"Charter\". He found that the purpose of the right is to redress past injustices and provide \"an official language minority with equal access to high quality education in its own language in circumstances where community development will be enhanced.\"\n"}
{"id": "5848023", "url": "https://en.wikipedia.org/wiki?curid=5848023", "title": "Austin Hobart Clark", "text": "Austin Hobart Clark\n\nAustin Hobart Clark (December 17, 1880 – October 28, 1954) was an American zoologist. He was born in Wellesley, Massachusetts and died in Washington, D.C. His research covered a wide range of topics including oceanography, marine biology, ornithology, and entomology.\n\nThe son of Theodore Minot Clark and Jeannette French Clark, Clark obtained his Bachelor of Arts at Harvard University in 1903. He had five children with his first wife Mary Wendell Upham, whom he married on March 6, 1906. Mary died in December 1931 and Clark was remarried in 1933 to Leila Gay Forbes.\n\nIn 1901, Clark organized a scientific expedition to Isla Margarita in Venezuela. From 1903 to 1905, he conducted research in the Antilles. From 1906 to 1907, he led a scientific team aboard the 1882 USS \"Albatross\". In 1908, he took a post at the National Museum of Natural History, which he held until his retirement in 1950.\n\nClark had important and various roles in a number of learned societies: to name a few, he was president of the Entomological Society of Washington, vice president of the American Geophysical Union, and directed the press service of the American Association for the Advancement of Science.\n\nClark was author to more than 600 publications written in English, French, Italian, German, and Russian. Some of the most well-known include \"Animals of Land and Sea\" (1925), \"Nature Narratives\" (two volumes, 1929 and 1931), \"The New Evolution\" (1930), and \"Animals Alive\" (1948).\n\nSeveral animal species and genera were first scientifically described by Clark, including the Lesser Antillean macaw (1905), the Martinique parrot (1905), the Dominican green-and-yellow macaw (1908), the mulga parrot (1910), the crustacean genus \"Laomenes\" (1919) or the starfish species \"Copidaster lymani\" (1948).\n\nClark is best known for his evolutionary theory called zoogenesis, which he introduced in his book \"The New Evolution: Zoogenesis\" (1930). His theory challenged the single tree view of evolution, according to Clark the major types of life forms on earth evolved separately and independently from all the others. Clark wrote that \"the seemingly simultaneous appearance of all the phyla or major groups of animals simply means that life at its very first beginnings developed at once and simultaneously from the primitive single cell in every possible direction, giving rise to some original form or forms in every phylum.\" He termed this process, \"eogenesis\".\n\nClark was quote-mined by creationists but he rejected any supernatural view of origins.\n\n\n"}
{"id": "10000937", "url": "https://en.wikipedia.org/wiki?curid=10000937", "title": "Category (Kant)", "text": "Category (Kant)\n\nIn Kant's philosophy, a category ( in the original or \"Kategorie\" in modern German) is a pure concept of the understanding (\"Verstand\"). A Kantian category is a characteristic of the appearance of any object in general, before it has been experienced. Kant wrote that \"They are concepts of an object in general….\" Kant also wrote that, \"…pure cоncepts [Categories] of the undеrstanding which apply to objects of intuition in general….\" Such a category is not a classificatory division, as the word is commonly used. It is, instead, the condition of the possibility of objects in general, that is, objects as such, any and all objects, not specific objects in particular.\n\nThe word comes from the Greek κατηγορία, \"katēgoria\", meaning \"that which can be said, predicated, or publicly declared and asserted, about something.\" A category is an attribute, property, quality, or characteristic that can be predicated of a thing. \"…I remark concerning the categories…that their logical employment consists in their use as predicates of objects.\" Kant called them \"ontological predicates.\"\n\nA category is that which can be said of everything in general, that is, of anything that is an object. John Stuart Mill wrote: \"The Categories, or Predicaments — the former a Greek word, the latter its literal translation in the Latin language — were believed to be an enumeration of all things capable of being named, an enumeration by the \"summa genera\" (highest kind), i.e., the most extensive classes into which things could be distributed, which, therefore, were so many highest Predicates, one or other of which was supposed capable of being affirmed with truth of every nameable thing whatsoever.\"\n\nAristotle had claimed that the following ten predicates or categories could be asserted of anything in general: substance, quantity, quality, relation, action, affection (passivity), place, time (date), position, and state. These are supposed to be the qualities or attributes that can be affirmed of each and every thing in experience. Any particular object that exists in thought must have been able to have the Categories attributed to it as possible predicates because the Categories are the properties, qualities, or characteristics of any possible object in general. The Categories of Aristotle and Kant are the general properties that belong to all things without expressing the peculiar nature of any particular thing. Kant appreciated Aristotle's effort, but said that his table was imperfect because \" … as he had no guiding principle, he merely picked them up as they occurred to him...\"\n\nThe Categories do not provide knowledge of individual, particular objects. Any object, however, must have Categories as its characteristics if it is to be an object of experience. It is presupposed or assumed that anything that is a specific object must possess Categories as its properties because Categories are predicates of an object in general. An object in general does not have all of the Categories as predicates at one time. For example, a general object cannot have the qualitative Categories of reality and negation at the same time. Similarly, an object in general cannot have both unity and plurality as quantitative predicates at once. The Categories of Modality exclude each other. Therefore, a general object cannot simultaneously have the Categories of possibility/impossibility and existence/non–existence as qualities.\n\nSince the Categories are a list of that which can be said of every object, they are related only to human language. In making a verbal statement about an object, a speaker makes a judgment. A general object, that is, every object, has attributes that are contained in Kant's list of Categories. In a judgment, or verbal statement, the Categories are the predicates that can be asserted of every object and all objects.\n\nKant believed that the ability of the human understanding (German: \"Verstand\", Greek: \"dianoia\" \"διάνοια\", Latin: \"ratio\") to think about and know an object is the same as the making of a spoken or written judgment about an object. According to him, \"Our ability to judge is equivalent to our ability to think.\"\nA judgment is the thought that a thing is known to have a certain quality or attribute. For example, the sentence \"The rose is red\" is a judgment. Kant created a table of the forms of such judgments as they relate to all objects in general.\n\nThis table of judgments was used by Kant as a model for the table of categories. Taken together, these twelvefold tables constitute the formal structure for Kant's architectonic conception of his philosophical system.\n\nCategories are entirely different from the appearances of objects. According to Kant, in order to relate to specific phenomena, categories must be \"applied\" through time. The way that this is done is called a schema.\n\nArthur Schopenhauer, in his criticism of the Kantian philosophy, found many errors in Kant's use of the Categories of Quality, Quantity, Relation, and Modality. Schopenhauer also noted that in accordance with Kant's claim, non-human animals would not be able to know objects. Animals would only know impressions on their sense organs, which Kant mistakenly calls perception.\n\n\n"}
{"id": "5625552", "url": "https://en.wikipedia.org/wiki?curid=5625552", "title": "Chinese Library Classification", "text": "Chinese Library Classification\n\nThe Chinese Library Classification (CLC; ), also known as Classification for Chinese Libraries (CCL), is effectively the national library classification scheme in China. It is used in almost all primary and secondary schools, universities, academic institutions, as well as public libraries. It is also used by publishers to classify all books published in China.\n\nThe Book Classification of Chinese Libraries (BCCL) was first published in 1975, under the auspices of China's Administrative Bureau of Cultural Affairs. Its fourth edition (1999) was renamed CLC. In September 2010, the fifth edition was published by National Library of China Publishing House.\nCLC has twenty-two top-level categories, and inherits a Marxist orientation from its earlier editions. (For instance, category A is Marxism, Leninism, Maoism & Deng Xiaoping Theory.) It contains a total of 43600 categories, many of which are recent additions, meeting the needs of a rapidly changing nation.\n\nThe 22 top categories and selected sub-categories of CLC (5th Edition) are as follows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe other library classifications in China are:\n\n\nThe other library classifications for Chinese materials outside mainland China are:\n\n\n"}
{"id": "47971127", "url": "https://en.wikipedia.org/wiki?curid=47971127", "title": "Chinese sun and moon mirrors", "text": "Chinese sun and moon mirrors\n\nThe yángsuì 陽燧 or sun-mirror was an ancient Chinese burning-mirror that concentrates sunlight to ignite tinder and the fāngzhū 方諸 or moon-mirror was a device that collects nighttime dew by condensation. These two bronze implements are literary metaphors for yin and yang, associating the \"\"yang\"-mirror\" \"yangsui\" with the sun (a.k.a. \"tàiyáng\" 太陽 \"great \"yang\"), fire, dry, and round, and the \"yin\"-mirror\" \"fangshu\" with the moon (\"tàiyīn\" 太陰 \"great \"yin\"\"), water, wet, and square.\n\nThere are numerous Chinese names for the fire-producing \"yángsuì\" 陽燧 \"sun-mirror\" and water-producing \"fāngzhū\" 方諸 \"moon-mirror\".\n\nYángsuì < Old Chinese *\"laŋsə-lu[t]-s\" can be written 陽遂 or 陽燧, compounding \"yáng\" 陽 (of \"yīnyáng\") \"sunshine; shining; sunny side\" with \"suì\" 遂 \"advance; accomplish; achieve\" or \"suì\" 燧 (clarified with the fire radical 火) \"light a fire\". Compare the mirrorless \"sui\" terms Suiren 燧人 (with \"person\") \"a mythical sage who invented friction firelighting\", \"suìshí\" 燧石 (with \"stone\") \"flint\", \"mùsuì\" 木燧 (with \"wood\"), meaning either \"hearth-board\" or \"fire-drill\", and \"fēngsuì\" 烽燧 (with \"beacon\") \"beacon-fire\". \"Yángsuìzú\" 陽燧足 \"sun-mirror feet\" is an old Chinese name for \"brittle star\". \"Suì\" 燧 also had early graphic variants 鐆 and 䥙, written with the metal radical 金 specifying the bronze mirror.\n\nThe \"Hanyu Da Cidian\" unabridged Chinese dictionary (1993, 11: 1974) gives three meanings for \"yángsuì\" 陽遂 (written without the \"fire radical\"): 亦作\"阳燧\" 古代利用日光取火的凹面铜镜 [\"Also written 阳燧, a concave bronze mirror anciently used to start a fire from sunlight.\"]; 清畅通达貌 [\"appearance of clear, unobstructed flowing\"], which was first recorded in a poem (洞箫赋) by Wang Bao (c. 84 – c. 53 BCE); and 古代车上的一种采光装置 [\"an ancient type of chariot window that admits light\"], which was first recorded in the \"Book of Jin\" history covering 265 to 420 CE.\n\nThree uncommon variant names for the concave fire-starting mirror are fúsuì < *\"[b]asә-lu[t]-s 夫遂 (with 夫 \"that\") used in the \"Zhouli\" (below), jīnsuì < *\"k(r)[ә]msә-lu[t]-s 金燧 (with 金 \"metal\") used in the \"Liji\" (below), and yángfú < *\"laŋ[b](r)o\" 陽符 used in \"Taiping Yulan\" (below) (1993, 2: 1457).\n\nEnglish translations of the Chinese sun-mirror in classic texts (cited below) include:\n\nThe name fāngzhū < *\"C-paŋta\" 方諸 combines \"fāng\" 方 \"square; side; region\" and \"zhū\" 諸 \"all; various\". The \"Hanyu Da Cidian\" (1993, 6: 1570) gives two \"fāngzhū\" meanings: 古代在月下承露取水的器具 [\"an ancient device used to collect dew in the moonlight in order to obtain water\", with the oldest usage example from the \"Huainanzi\" (below); 传说中仙人住所 \"a mythical place where \"xian\" 'transcendents; immortals' reside\"], which was first recorded in (c. 499) Shangqing School Daoist collection \"Zhen'gao\" 真誥 \"Declarations of the Perfected\", which says Fangzhu was named from being square, 1,300 \"li\" on each side, and 9,000 \"zhang\" high. Gustave Schlegel (1875: 612) says the \"yangsui\" mirror is perfectly round and the \"fangzhu\" is (\"le Carré total\") \"perfectly square\", which is consistent with \"yanyang\" theory since roundness pertained to \"yang\" and heavenly fiery things, while squareness pertained to \"yin\" and earthly watery things. Umehara (1956: 142) described square mirrors believed to be from the Qin dynasty. \"Qīngtóng\" 青童 \"Azure Lad\", which is a homophone of \"qīngtóng\" 青銅 (lit. \"azure copper\") \"bronze\", is one of the main deities in Shangqing Daoism, and lord of the mythic paradise Fangzhu \"Square Speculum Isle\" in the eastern sea near Mount Penglai (Smith 2008: 803).\n\nThe (983) \"Taiping Yulan\" encyclopedia lists some \"yinyang\" synonyms of \"yangsui\" and \"fangzhu\", \"The \"yangsui\" or yángfú < *\"laŋ[b](r)o 陽符 (with \"fú\" 符 \"tally; talisman; magic figure\") obtains fire from the sun. The yīnfú < *\"q(r)um[b](r)o 陰符 (cf. \"Yinfujing\" \"Hidden Tally Scripture\") or yīnsuì < *\"q(r)umsə-lu[t]-s\" 陰燧 obtains water from the moon. They are copper amalgam mirrors, also named 'water and fire mirrors'.\"\n\n\"Chénglùpán\" 承露盤 \"plate for receiving dew\" is a near-synonym for \"fangzhu\" (Needham and Wang 1962: 89). The \"huabiao\", which is a type of Chinese architectural column traditionally erected in front of palaces and tombs, is topped by a mythical \"hou\" 犼 \"a wolf-headed Chinese dragon\" sitting on a round \"chenglupan\" \"dew-collecting plate\" cap.\n\nThere are comparatively fewer English translations of the Chinese moon-mirror, which lacks a direct translation equivalent and is more frequently romanized, include:\n\nMetaphorically using \"fangzhu\" and \"yangsui\" mirrors to represent \"yin\" and \"yang\" reflects a more commonly used Chinese philosophical metaphor of a mirror to denote the \"xin\" 心 \"heart-mind\". For instance, the \"Zhuangzi\" famously says having a mirror-like \"xin\" represents the ideal state of unity with the Dao.\nDo not be a corpse for fame, Do not be a storehouse of schemes; Do not be responsible for affairs, Do not be a proprietor of knowledge. Thoroughly embody unendingness and wander in nonbeginning. Thoroughly experience what you receive from heaven but do not reveal what you attain. Just be empty, that's all. The mind of the ultimate man functions like a mirror. It neither sends off nor welcomes; it responds but does not retain. Therefore, he can triumph over things without injury. (7, tr. Mair 1994: 70-71) \n\nThe stillness of the sage is not because stillness is said to be good and therefore he is still. It is because the myriad things are unable to disturb his mind that he is still. When water is still, it clearly reflects whiskers and brows. It is so accurate that the great craftsman takes his standard from it. If still water has such clarity, how much more so pure spirit! The stillness of the mind of the sage is the mirror of heaven and earth, the looking glass of the myriad things. (13, tr. Mair 1994: 119-120) \n\nMany scholars of Chinese philosophy have analyzed the mirror metaphor for the \"xin\" \"heart-mind\". Harold Oshima (1983: 75) explains that for a modern Westerner who regards a mirror as a commonplace looking-glass, this metaphor \"appears quite pedestrian and unexciting\" until one realizes that the ancient Chinese imagined mirrors \"to possess broad and mysterious powers.\" For instance, a mirror can reveal and control demons. The \"Baopuzi\" (above) says a Daoist practitioner entering the mountains would suspend a mirror on his back, which was believed to prevent the approach of demons—compare the European belief that a mirror is apotropaic toward vampires who are supposedly unable to produce a reflection. Oshima says the \"yangsui\" burning-mirror that miraculously produces fire best illustrates the \"great sense of mystery surrounding mirrors\". \"Certainly this mirror symbolized a powerful connection with the greater powers of the heavens and, as such, would have served admirably as a model for the [\"xin\"].\"\nFor the early Chinese, mirrors were not simply passive \"reflectors\" of information, they offered accurate and appropriate \"responses\" to whatever came before them. When placed before the sun—the ultimate \"yang\" 陽 phenomenon in the world—they respond with fire: the pure essence of \"yang\". When placed before the moon—the ultimate \"yin\" 陰 phenomenon in the world—they respond with water: the pure essence of \"yin\". Thus mirrors offer the paradigm for \"proper responsiveness\": they reflect the true essence of the ultimate \"yin\" and \"yang\"—the alpha and omega of phenomena in early Chinese cosmology.\" (Carr and Ivanhoe 2000: 56) \nErin Cline says the early Chinese attributed mirrors to have a mysterious power and great religious significance. The ceremonial bronze \"fusui\" 夫遂 and \"yangsui\" 陽燧 mirrors were seen as active, responsive objects because they could be used to produce fire and water (two of the Five Phases). \nWhen placed outside, concave mirrors focused sunlight to produce fire, while bronze mirrors gathered condensation in the light of the moon. But it was not simply the fact that mirrors had the power to \"gather\" or \"produce\" that made them objects of religious significance in ancient China; it was what they produced. Water and fire were thought to be the pure essences of \"yin\" and \"yang\", respectively, and the fact that mirrors appeared to \"draw\" these substances from the sun and moon reinforced the cosmological power that was already associated with them. (2008: 338)\n\nThe Chinese classics contain early information about \"yangsui\" fire-mirrors and \"fangshu\" water-mirrors. The first two sources below are \"ritual texts\" of uncertain dates, and the others are presented chronologically.\n\nThe (c. 2nd century BCE) \"Zhouli\" \"Zhou Rites\" is a compilation of Eastern Zhou (771-256 BCE) texts about government bureaucracy and administration. It describes two kinds of ritual officials making the purifying \"new fire\". The \"Siguan\" 司爟 \"Directors of Fire Ceremonies\" used a \"zuānsuì\" 鑽燧 \"fire-drill\", for which a variety of different woods were chosen at five periods during the year (Biot 1881 2: 194). The \"Sixuanshi\" 司烜氏 \"Directors of Sun Fire\" ceremonially used a \"yangsui\" \"burning-mirror\" to start the \"new fire\".\nThey have the duty of receiving, with the [\"fusui\" 夫遂] mirror, brilliant fire from the sun; and of receiving with the (ordinary) mirror [\"jian\" 鑒] brilliant water from the moon. They carry out these operations in order to prepare brilliant rice, brilliant torches for sacrifices, and brilliant water. (tr. Needham and Wang 1962: 87, cf. Biot 1881 2: 381) \nThe \"Zhouli\" commentary of Zheng Xuan (127–200) glosses \"fusui\" as \"yangsui\". The sub-commentary of Jia Gongyan 賈公彦 says the \"fusui\" is called \"yangsui\" because it starts a fire by means of the \"jīng\" 精 \"spirit; essence\" of the \"taiyang\" \"great \"yang\"; sun\".\n\nAnother ritual text similar to the \"Zhouli\", the (c. 2nd-1st century BCE) \"Liji\" \"Record of Rites\" is a compilation of Eastern Zhou textual materials. \"The Pattern of the Family\" section lists idealized duties of family members. Sons and daughters-in-law are supposed to wear a utility belt that includes metal and wood (two of the Five Phases) \"suì\" fire-starters: \"jīnsuì\" 金燧 \"burning-mirror\" and a \"mùsuì\" 木燧 \"fire-drill\", which implies that fire-mirrors were quite commonly used among the ancient Chinese (Forke 1911: 497).\nFrom the left and right of the girdle [a son] should hang their articles for use—on the left side, the duster and handkerchief, the knife and whetstone, the small spike, and the metal speculum for getting fire from the sun [金燧]; on the right, the archer's thimble for the thumb and the armlet, the tube for writing instruments, the knife-case [or \"needle-case\" for a daughter-in-law], the larger spike, and the borer for getting fire from wood [木燧]. (tr. Legge 1885 27: 449, 450) \nZheng Xuan's \"Liji\" commentary glosses \"musui\" as \"zuānhuǒ\" 鑽火 \"produce fire by friction\". Kong Yingda (574 – 648) quotes Huang Kan 皇侃, \"When it is daylight, use the \"jinsui\" to start a fire from the sun, when it is dark, use the \"musui\" to start a fire with a drill\". The commentary of Sun Xidan 孙希旦 (1736-1784) says \"jinsui\" or \"yangsui\" 陽遂 \"\"yang\" burning-mirrors\" should ideally be cast on the Summer Solstice and \"yinjian\" 陰鑒 \"\"yin\" mirrors\" on the Winter Solstice.\n\nThe \"Chunqiu Fanlu\" (14), attributed to Dong Zhongshu (179–104 BC), says \"císhí\" 磁石 \"lodestone\" attracts iron and \"jǐngjīn\" 頸金 \"neck metal; burning-mirror\" attracts fire; Joseph Needham and Wang Ling (1962: 88) suggest the name \"neck metal\" derives from either the mirror being hung round the neck, or because necks are concave things.\n\nLiu An's (c. 139 BCE) \"Huainanzi\" \"Masters of Huainan\", which is a compendium of writings from various schools of Chinese philosophy, was the first text to record \"fangzhu\" dew-collectors.\n\nTwo \"Huainanzi\" chapters metaphorically use \"sun and moon mirrors\" to exemplify \"yang\" and \"yin\" categories and elucidate the Chinese notion of \"ganying\" \"cosmic resonance\" through which categorically identical things mutually resonate and influence each other. The \"yángsuì\" 陽燧 \"burning-mirror\" is \"yang\", round, and sun-like; the \"fāngzhū\" 方諸 \"square receptacle\" is \"yin\", square, and moon-like. The first context describes \"yangsui\" and \"fangzhu\" mirrors \"jiàn\" 見 \"seeing\" the sun and moon. \nThe Way of Heaven is called the Round; the Way of Earth is called the Square. The square governs the obscure; the circular governs the bright. The bright emits \"qi\", and for this reason fire is the external brilliance of the sun. The obscure sucks in \"qi\", and for this reason water is the internal luminosity of the moon. Emitted \"qi\" endows; retained \"qi\" transforms. Thus yang endows and yin transforms. The unbalanced \"qi\" of Heaven and Earth, becoming perturbed, causes wind; the harmonious \"qi\" of Heaven and Earth, becoming calm, causes rain. When yin and yang rub against each other, their interaction [感] produces thunder. Aroused, they produce thunderclaps; disordered they produce mist. When the yang \"qi\" prevails, it scatters to make rain and dew; when the yin \"qi\" prevails, it freezes to make frost and snow. Hairy and feather creatures make up the class of flying and walking things and are subject to yang. Creatures with scales and shells make up the class of creeping and hiding things and are subject to yin. The sun is the ruler of yang. Therefore, in spring and summer animals shed their fur; at the summer solstice, stags' antlers drop off. The moon is the fundament of yin. Therefore when the moon wanes, the brains of fish shrink; when the moon dies, wasps and crabs shrivel up. Fire flies upward; water flows downward. Thus, the flight of birds is aloft; the movement of fishes is downward. Things within the same class mutually move one another; root and twig mutually respond to each other [相應]. Therefore, when the burning mirror sees the sun, it ignites tinder and produces fire [故陽燧見日則燃而為火]. When the square receptacle sees the moon, it moistens and produces water [方諸見月則津而為水]. When the tiger roars, the valley winds rush; when the dragon arises, the bright clouds accumulate. When \"qilins\" wrangle, the sun or moon is eclipsed; when the leviathan dies, comets appear. When silkworms secrete fragmented silk, the \"shang\" string [of a stringed instrument] snaps. When meteors fall, the Bohai surges upward. (3.2, tr. Major et al. 2010: 115-116) \nThe second mentions some of the same \"yinyang\" and \"ganying\" folk-beliefs. \nThat things in their [various] categories are mutually responsive [相應] is [something] dark, mysterious, deep, and subtle. Knowledge is not capable of assessing it; argument is not capable of explaining it. Thus, when the east wind arrives, wine turns clear and overflows [its vessels]; when silkworms secrete fragmented silk, the \"shang\" string [of a stringed instrument] snaps. Something has stimulated [感] them. When a picture is traced out with the ashes of reeds, the moon's halo has a [corresponding] gap. When the leviathan dies, comets appear. Something has moved them. Thus, when a sage occupies the throne, he embraces the Way and does not speak, and his nurturance reaches to the myriad people. But when ruler and ministers [harbor] distrust in their hearts, back-to-back arcs appear in the sky. The mutual responses [相應] of spirit \"qi\" are subtle indeed! Thus, mountain clouds are like grassy hummocks; river clouds are like fish scales; dryland clouds are like smoky fire; cataract clouds are like billowing water. All resemble their forms and evoke responses [感] according to their class. The burning mirror takes fire from the sun; the square receptacle takes dew from the moon [夫陽燧取火於日方諸取露於月]. Of [all the things] between Heaven and Earth, even a skilled astrologer cannot master all their techniques. [Even] a hand [that can hold] minutely tiny and indistinct things cannot grasp a beam of light. However, from what is within the palm of one's hand, one can trace [correlative] categories to beyond the extreme end point [of the cosmos]. [Thus] that one can set up [these implements] and produce water and fire is [a function of] the mutually [responsive] movement of yin and yang of the same \"qi\". (6.2, tr. Major et al. 2010:216-217) \nThe \"Huainanzi\" commentary of Gao You (fl. 210 CE) says,\nThe burning mirror is of metal. One takes a metal cup untarnished with verdigris and polishes it strongly, then it is heated by being made to face the sun at noon time; in this position cause it to play upon mugwort tinder and this will take fire. The [\"fangzhu\"] is the Yin mirror [\"yinsui\" 陰燧]; it is like a large clam(-shell) [\"dage\" 大蛤]. It is also polished and held under the moonlight at full moon; water collects upon it, which can be received in drops upon the bronze plate. So the statements of our ancient teacher are really true. (tr. Needham and Wang 1962: 88) \nAccording to Needham and Wang (1962: 90), this comparison between a \"fangzhu\" mirror that drew water from the moon and a bivalve shell reflects an ancient Chinese confusion between beliefs about moon-mirrors and beliefs that certain marine animals waxed and waned in correspondence with the moon. For example, the (c. 3rd century BCE) \"Guanzi\" says,\nThe virtue of a ruler is what all the people obey, just as the moon is the root and fount of all Yin things. So at full moon, shellfish [\"bangge\" 蚌蛤] are fleshy, and all that is Yin abounds. When the moon has waned, the shellfish are empty and Yin things weak. When the moon appears in the heavens all Yin things are influenced right down to the depths of the sea. So the sage lets virtue flow forth from himself, and the four outer wildernesses rejoice in his benevolent love. (tr. Needham and Wang 1962: 31) \nThe authors compare Aristotle's (c. 350 BCE) \"Parts of Animals\" recording that some kinds of sea urchins were fat and good to eat at the full moon, which was one of the oldest biological observations about the lunar periodicity of the reproductive system of echinoderms, especially sea urchins.\n\nA third \"Huainanzi\" chapter accurately describes the importance of finding a \"sui\" burning-mirror's focal point. \nThe Way of employing people is like drawing fire from a mirror [以燧取火]; if you're too far away [from the tinder], you won't get anything; if you're too close, it won't work. The right [distance] lies between far away and close. Observing the dawn, he [calculates] the shift [of the sun] at dusk; measuring the crooked, he tells [how far] something departs from the straight and level. When a sage matches things up, it is as if he holds up a mirror to their form; from the crooked [reflection], he can get to the nature [of things]. (17.227-228, tr. Major et al. 2010: 707-708) \nThe \"Huainanzi\" frequently uses the term \"suìhuǒ\" 燧火 \"kindle a fire\", for instance, in the second month of summer, the Emperor \"drinks water gathered from the eight winds and cooks with fire [kindled from] cudrania branches (5.5, tr. Major et al. 2010; 188).\n\nWang Chong's (c. 80 CE) \"Lunheng\" mentions the \"fangzhu\" 方諸 in two chapters (46, 47), and the \"yangsui\" in five, written 陽遂 (8, 32) and 陽燧 (47, 74, 80).\n\nThe German sinologist Alfred Forke's (1907, 1911) English translation of the \"Lunheng\" consistently renders \"fangzhu\" as \"moon-mirror\" and \"yangsui\" as \"burning-glass\", because two chapters describe \"liquefying five stones\" (\"wǔshí\" 五石) on a bingwu day (43rd in the 60-day sexagenary cycle) in the fifth lunar month. Forke (1911: 496) circularly reasons that, \"If this be true, the material must have been a sort of glass, for otherwise it could not possess the qualities of a burning glass. Just flint glass of which optical instruments are now made consists of five stony and earthy substances—silica, lead oxide, potash, lime, and clay. The Taoists in their alchemistical researches may have discovered such a mixture.\" The French sinologist Berthold Laufer (1915: 182-183, 187) refutes Forke's \"downright literary concoction\" of \"yangsui\" as \"burning-glass\" because Wang Chong's \"wushi\" 五石 \"five stones\" reference was a literary allusion to the Nüwa legend's \"wuseshi\" 五色石 \"five-colored stone; multicolored stone\", and because the Zhou Chinese did not have a word for \"glass\", which was unknown to them. Forke overlooked the (c. 320) Daoist text \"Baopuzi\" (below, Ware 1966: 294) that also describes smelting the \"five minerals\" (identified as realgar, cinnabar, orpiment, alum, and laminar malachite) on the \"bingwu\" day of a fifth month to make magic daggers that will protect travelers from water demons.\n\nBoth \"Lunheng\" contexts about casting a \"yangsui\" \"burning-mirror\" on a \"bingwu\" day use the phrase \"xiāoliàn wǔshí\" 消鍊五石 \"smelting five minerals\". The first contrasts burning-mirrors and crooked sword-blades.\nThe laws of Heaven can be applied in a right and in a wrong way. The right way is in harmony with Heaven, the wrong one owes its results to human astuteness, but cannot in its effects be distinguished from the right one. This will be shown by the following. Among the \"Tribute of Yu\" are mentioned jade and white corals. These were the produce of earth and genuine precious stones and pearls. But the Taoists melt five kinds of stones, and make five-coloured gems out of them. Their lustre, if compared with real gems, does not differ. Pearls in fishes and shells are as genuine as the jade-stones in the Tribute of Yu. Yet the Marquis of Sui made pearls from chemicals, which were as brilliant as genuine ones. This is the climax of Taoist learning and a triumph of their skill. By means of a burning-glass [陽燧] one catches fire from heaven. Of five stones liquefied on the [Bingwu] day of the 5th moon an instrument is cast, which, when polished bright, held up against the sun, brings down fire too, in precisely the same manner as, when fire is caught in the proper way. Now, one goes even so far as to furbish the crooked blades of swords, till they shine, when, held up against the sun, they attract fire also. Crooked blades are not burning-glasses; that they can catch fire is the effect of rubbing. Now, provided the bad-natured men are of the same kind as good-natured ones, then they can be influenced, and induced to do good. Should they be of a different kind, they can also be coerced in the same manner as the Taoists cast gems, Sui Hou made pearls, and people furbish the crooked blades of swords. Enlightened with learning and familiarized with virtue, they too begin by and by to practise benevolence and equity. (8, tr. Forke 1907: 377-378) \nNeedham and Wang interpret this \"Lunheng\" passage as an account of making glass burning-lenses. Despite Forke's translation of \"suíhòu\" 隨侯, with \"suí\" 隨 \"follow; comply with; the ancient state Sui\" and \"hóu\" 侯 \"marquis\", as the legendary \"Sui Hou; Marquis of Sui\" who received a fabulous pearl from a snake; they translate \"following proper timing\", citing the Chinese alchemical term \"huǒhòu\" 火候 \"fire-times; times when heating should begin and end\", and reading \"hóu\" 侯 \"marquis\" as a miscopy of \"hòu\" 候 \"time; wait; situation\".\nBut by following proper timing (i.e. when to begin heating and how long to go on) pearls can be made from chemicals [\"yao\" 藥], just as brilliant as genuine ones. This is the climax of Taoist learning and a triumph of their skill. Now by means of the burning-mirror [\"yangsui\"] one catches fire from heaven. Yet of five mineral substances liquefied and transmuted on a [\"bingwu\"] day in the fifth month, an instrument [\"qi\" 器] is cast, which, when brightly polished and held up against the sun, brings down fire too, in precisely the same manner as when fire is caught in the proper way. (tr. Needham and Wang 1962: 112) \nWang Chong gives three contrasts between \"genuine\" and \"imitation\" things: the opaque glass \"jade\" made by Daoist alchemists with the real thing; the artificially made \"pearls\" with true pearls; and the \"instrument\" made by liquefying five different minerals, which can concentrate the sun's rays like the traditional bronze burning-mirror. Furthermore, Needham and Wang question why the \"Lunheng\" specifies five different minerals, \nBronze would require only two ores, perhaps even only one, with possible addition of a flux. Glass needs silica, limestone, an alkaline carbonate, and perhaps litharge or the barium mineral, together with colouring matter. Of course, the text does not clearly tell us that lenses were being made; the instruments might have been simply glass mirrors imitating the bronze ones. (1962: 113) \nBased on archeological finds of glass objects substituting for jade and bronze ones in tombs dating back to the Warring States period, Needham and Wang (1962: 113) conclude that the Chinese were making glass lenses in the 1st century CE, and probably as far back as the 3rd century BCE.\n\nThe second context explains \"ganying\" \"cosmic resonance\" with examples of \"bingwu\" burning-mirrors, moon-mirrors, and \"tulong\" 土龍 \"clay dragons\" believed analogously to cause rainfall like Chinese \"long\" dragons. It describes a dispute between Han astronomer Liu Xin, who used a clay dragon in a rain sacrifice, but could not explain the reason why it worked, when the scholar Huan Tan argued that only a genuine lodestone can attract needles.\nThe objection that the dragon was not genuine, is all right, but it is wrong not to insist on relationship. When an east wind blows, wine flows over, and [when a whale dies, a comet appears.] The principle of Heaven is spontaneity, and does not resemble human activity, being essentially like that affinity between clouds and dragons. The sun is fire, and the moon is water. Fire and water are always affected by genuine fluids. Now, physicists cast burning-glasses [陽燧] wherewith to catch the flying fire from the sun, and they produce moon-mirrors [方諸] to draw the water from the moon. That is not spontaneity, yet Heaven agrees to it. A clay dragon is not genuine either, but why should it not be apt to affect Heaven? With a burning-glass one draws fire from Heaven. In the fifth month, on a [bingwu] day at noon, they melt five stones, and cast an instrument with which they obtain fire. Now, without further ceremony, they also take the crooked hooks on swords and blades, rub them, hold them up towards the sun, and likewise affect Heaven. If a clay dragon cannot be compared with a burning-glass, it can at least be placed on a level with those crooked hooks on swords and blades. (47, tr. Forke 1911: 350-351) \nA third \"Lunheng\" chapter, which mentions casting burning-mirrors on the fifth month but not the \"bingwu\" day, criticizes the Han philosopher Dong Zhongshu's belief that clay dragons could cause rain.\n[E]ven Heaven may be induced to respond, by tricks. In order to stir up the heavenly fluid, the spirit should be used, but people will employ burning glasses [陽燧], to attract the fire from the sky. By melting five stones and moulding an instrument in the fifth month, in the height of summer, one may obtain fire. But now people merely take knives and swords or crooked blades of common copper, and, by rubbing them and holding them up against the sun, they likewise get fire. As by burning glasses, knives, swords, and blades one may obtain fire from the sun, so even ordinary men, being neither Worthies nor Sages, can influence the fluid of Heaven, as Tung Chung Shu was convinced that by a clay dragon he could attract the clouds and rain, and he had still some reason for this belief. If even those who in this manner conform to the working of Heaven, cannot be termed Worthies, how much less have those a claim to this name who barely win people’s hearts? (80, tr. Forke 1911: 132) \n\nThe other \"Lunheng\" reference to moon-mirrors mentions moon mythology about the moon rabbit and three-legged toad.\nWhen we hold up a moon-mirror [方諸] towards the moon, water comes down. The moon approaching the Hyades or leaving the constellation of the ‘House’ from the north, it nearly always inevitably rains. The animals in the moon are the hare and the toad. Their counterparts on earth are snails and corn-weevils. When the moon is eclipsed in the sky, snails and corn-weevils decrease on earth, which proves that they are of the same kind. When it rains without ceasing, one attacks all that belongs to the Yin. To obtain a result one ought to hunt and kill hares and toads, and smash snails and corn-weevils. (46, tr. Forke 1911: 341) \n\nTwo chapters mention \"yangsui\" mirrors to express skepticism about the Chinese myth that the archer Houyi shot down nine of the Ten Suns (children of Di Jun and Xihe) that were burning up earth.\nWe see that with a sun-glass fire [陽遂] is drawn from heaven, the sun being a big fire. Since on earth fire is one fluid, and the earth has not ten fires, how can heaven possess ten suns? Perhaps the so called ten suns are some other things, whose light and shape resembles that of the sun. They are staying in the ‘Hot Water Abyss’, and always climb up Fu-sang. Yü and Yi saw them, and described them as ten suns. (32, tr. Forke 1911: 272-273) \nThese legendary references are to Fusang, Yu, and Yi. \nThe sun is fire: in the sky it is the sun, and on earth it is fire. How shall we prove it? A burning glass [陽遂] being held up towards the sun, fire comes down from heaven. Consequently fire is the solar fluid. The sun is connected with the cycle of ten, but fire is not. How is it that there are ten suns and twelve constellations? The suns are combined with these constellations, therefore [\"jia\"] is joined to [\"zi\"]. But what are the so called ten suns? Are there ten real suns, or is there only one with ten different names? (74, tr. Forke 1911: 412) \n\"Jia\" 甲 and \"zi\" 子 are the first signs of the heavenly stems and earthly branches in the Chinese calendar.\n\nThree \"Inner Chapters\" of the (c. 320 CE) \"Baopuzi\", written by the Jin Dynasty scholar Ge Hong, provide information about \"yangsui\" 陽燧 \"burning-mirrors\" and \"fangzhu\" 方諸 \"dew-mirrors\".\n\nIn Chapter 3 \"Rejoinder to Popular Conceptions\", Ge Hong mentions the commonly used sun and moon mirrors to answer an interlocutor who criticizes Daoist alchemical recipes for immortality as \"specious … unreliable fabrications of wondermongers\".\nAccording to your argument, they would appear inefficacious, but even the most minor of them is not without effect. I have frequently seen people obtain water from the moon at night by means of a speculum, and fire from the sun in the morning by used of a burning-mirror [餘數見人以方諸求水於夕月陽燧引火於朝日]. I have seen people conceal themselves to the point of complete disappearance, or change their appearance so that they no longer seem human. I have seen them knot a kerchief, throw it to the ground, and produce a hopping hare. I have seen them sew together a red belt and thereby produce a wriggling snake. I have seen people make melons and fruit ripen in an instant, or dragons and fish come and go in a basin. All of these things occurred just as it was said they would. (tr. Ware 1966: 62-3) \n\nChapter 4 \"Gold and Cinnabar\" refers to the \"yinyang\" mirrors in two contexts. The first describes an alchemical elixir method that uses a burning-mirror to create a mercury alloy dew-mirror.\nThere is also a [\"Minshan danfa\" 岷山丹法], found in a cave by [Zhang Kaita 張蓋蹋] as he was giving careful thought to such matters on Mount Min. This method forges yellow copper alloy to make a speculum for gathering water from the moon [其法鼓冶黃銅以作方諸]. It is then covered with mercury and its interior heated with solar essence (gathered by a burning-mirror) [以承取月中水以水銀覆之]. The taking of this substance over a long period will produce immortality. This same text also teaches us to place this elixir in a copper mirror coated with realgar, cover it with mercury, and expose it to the sun for twenty days, after which it is uncovered and treated. When taken in the form of pills the size of grams, washed down with the first water drawn from the well at dawn, for a hundred days, it makes the blind see, and by itself cures those who are ill. It will also turn white hair black and regrow teeth. (tr. Ware 1966: 83-84) \nThe second \"fangzhu\" context describes using plates and bowls made from an elixir of immortality in order to collect the \"yè\" 液 \"liquid; fluid; juice\" (tr. \"exudate\") of the sun and moon, which also provides immortality.\n\nChapter 16 \"The Yellow and the White\" uses the abbreviations \"zhu\" 諸 and \"sui\" 燧 along with \"fangzhu\" and \"yangsui\" to compare natural and artificial transformations. \nWhat is it that the arts of transformation cannot do? May I remind my readers that the human body, which is normally visible, can be made to disappear? Ghosts and gods are normally invisible, but there are ways and means to make them visible. Those capable of operating these methods and prescriptions will be found to abound wherever you go. Water and fire are present in the sky, but they may be brought down with specula and burning-mirrors [水火在天而取之以諸燧]; lead is naturally white, but it can be reddened and mistaken for cinnabar. Cinnabar is naturally red, but it can be whitened to look like lead. Clouds, rain, frost, and snow are all breaths belonging to heaven and earth, but those produced by art differ in no way from the natural phenomena. Flying things and those that creep and crawl have been created in specific shapes, but it would be impossible ever to finish listing the thousands upon thousands of sudden metamorphoses which they can undergo. Man himself is the most highly honored member of creation and the most highly endowed, yet there are just as many instances of men and women changing into cranes, stones, tigers, monkeys, sand, or lizards. The cases of high mountains becoming deep abysses and of profound valleys changing into peaks are metamorphoses on an immense scale. It is clear, therefore, that transformation is something spontaneous in nature. Why should we doubt the possibility of making gold and silver from something different? Compare, if you will, the fire obtained with a burning-mirror and the water which condenses at night on the surface of a metal speculum [譬諸陽燧所得之火方諸所得之水]. Do they differ from ordinary water and fire? (tr. Ware 1966: 262-263) \n\nThe \"Baopuzi\" also mentions \"míngjìng\" 明鏡 \"bright mirror\" magic, such as meditating on paired \"sun\" and \"moon\" mirrors to see spiritual beings, using mirror reflections to protect against shapeshifting demons (de Groot 1910: 1000-1005 discusses Chinese demon-conquering mirrors), and practicing Daoist multilocation. \nAt other times a bright mirror nine inches or more in diameter [明鏡徑九寸已上] is used for looking at oneself with something on the mind. After seven days and nights a god or genie will appear, either male, female, old, or young, and a single declaration on its part discloses automatically what is occurring at that moment a thousand miles away. Sometimes two mirrors are used and designated sun and moon respectively. Or four are used and designated as the four circumferences, by which is meant the front, rear, left, and right, to which each points when one looks into them. When four mirrors are used, a large number of gods are seen to appear; sometimes pell-mell, other times riding dragons or tigers and wearing hats and clothes of many colors, different from those seen in ordinary life. There are books and illustrations to document all this. (15, tr. Ware 1966: 255-256) \n\nThe spirits in old objects are capable of assuming human shape for the purpose of confusing human vision and constantly putting human beings to a test. It is only when reflected in a mirror that they are unable to alter their true forms. Therefore, in the old days, all processors entering the mountains suspended on their backs a mirror measuring nine inches or more in diameter [明鏡徑九寸已上], so that aged demons would not dare approach them. If any did come to test them, they were to turn and look at them in the mirror. If they were genii or good mountain gods, they would look like human beings when viewed in the mirror. If they were birds, animals, or evil demons, their true forms would appear in the mirror. If such a demon comes toward you, you must walk backward, turning your mirror toward it, in order to drive it away. Then observe it. If it is an aged demon it is sure to have no heels. If it has heels, it is a mountain god. (17, tr. Ware 1966: 281) \n\nThe preservation of Mystery-Unity [玄一] consists in imagining yourself as being divided into three persons. Once these three have become visible, you can continue to increase the number to several dozen, all like yourself, who may be concealed or revealed, and all of whom are automatically in possession of secret oral directions. This may be termed a process for multiplying the body. Through this method [Zuo Cu], [Ji Liao], and my uncle [Ge Xuan] could be in several dozen places at one time. When guests were present they could be one host speaking the guests in the house, another host greeting guests beside the stream, and still another host making cases with his fishing line, but the guests were unable to distinguish which was he true one. My teacher used to say that to preserve Unity was to practice jointly Bright Mirror [守一兼修明鏡], and that on becoming successful in the mirror procedure a man would be able to multiply his body to several dozen all with the same dress and facial expression. (18, tr. Ware 1966: 306) \n\nLi Shizhen's (1578) \"Bencao Gangmu\" classic pharmacopeia mentions both burning-mirrors and dew-mirrors.\n\n\"Yangsui\" \"burning-mirror\" occurs with \"huǒzhū\" 火珠 (lit. \"fire pearl/bead\") \"burning-lens\" in the entry for \"àihuǒ\" 艾火 \"igniting mugwort for moxibustion\".\nThe fire used in cauterizing with mugwort ought to be fire really obtained from the sun by means of a sun-mirror [艾火] or fire-pearl (lens?) [火珠] exposed to the sun. Next in efficacy is fire obtained by boring into [\"huái\" 槐 \"locust tree\"] wood, and only in cases of emergency, or when it is difficult to procure such fire, it may be taken from a lamp of pure hempseed oil, or from a wax taper. (火1, tr. Groot 1910 6:947) \nLi Shizhen explains (tr. Forke 1911: 497), \"[The \"yangsui\"] is a fire mirror made of cast copper. Its face is concave. Rubbing it warm and holding it towards the sun, one obtains fire by bringing some artemisia near it. This is what the [\"ZhouIi\"] says about the comptroller of light receiving the brilliant light from the sun by his fire speculum.\"\n\nThe \"huozhu\" \"fire pearl\" burning-lens was introduced into China during the Tang dynasty (Schafer 1963: 237). The (945) \"Old Book of Tang\" records that in 630, envoys from Chams presented Emperor Taizong of Tang (r. 626-649) with a crystalline \"huǒzhū\" 火珠 (lit. \"fire pearl/bead\") \"fire orb; burning glass\", the size of a hen's egg, that would concentrate the sun's rays and ignite a piece of punk. The envoys said they obtained this tribute gift in the country of the \"Luóchà\" 羅剎 \"rakshasa creatures in Hindu mythology\", probably imported into India from the Hellenistic Near East (Schafer 1963: 237). Needham and Wang (1962: 115) say \"Luocha\" \"the country of the Rakshas\", is not Sri Lanka, but rather Pahang, Malaysia. The (1060) \"New Book of Tang\" account says the year was 631 and the fire-orb came from Bali. The American sinologist Edward H. Schafer (1963: 237, 239) notes that the Chinese \"huozhu\" name reflects the Sanskrit \"agnimaṇi\" \"fire jewel\" name for burning-glasses, and later Tang dynasty sources use hybrid names like \"yangsuizhu\" \"Solar-Kindling Pearl\", showing that the crystal fire-orb was regarded as the legitimate successor of the ancient bronze burning-bowl.\n\n\"Fangzhu\" occurs in the \"Bencao Gangmu\" entry for \"míngshuǐ\" 明水 \"bright water\" used in rituals (水1 天水類, tr. Forke 1911: 497-498), which is explained as \"fangzhu shui\" 方諸水 \"dew-mirror water\". [Chen Cangqi 陳藏器] says that it is a \"dabang\" 大蚌 \"big oyster[-shell]\" that, \"when rubbed and held up towards the moon, draws some drops of water from it, resembling dew in the morning\". [Other authors say] \"fang\" 方 means \"shi\" 石 \"stone\", or \"a mixture of five stones\", and \"zhu\" 諸 means \"zhū\" 珠 \"pearl; bead\". [Li Shizhen] \"rejects all these explanations contending that the [\"fangzhu\"] was a mirror like the burning speculum, and similarly manufactured. This view is supported by the above quoted passage of the [\"Zhouli\"], which expressly speaks of a mirror employed to obtain water from the moon. This very pure water was perhaps used at sacrifices.\"\n\nBronze mirrors have special significance within the history of metallurgy in China. In the archaeology of China, copper and bronze mirrors first appeared in the (pre-16th century BCE) \"early metalwork\" period before the Shang dynasty. Developments of metal plaques and mirrors appear to have been faster in the Northwestern Region where there was more frequent use of metals in the social life. In particular, the (c. 2050-1915 BCE) Qijia culture, mainly in Gansu and eastern Qinghai, has provided rich finds of copper mirrors (Bai 2013: 157, 164). Archeological evidence shows that \"yangsui\" burning-mirrors were \"clearly one of the earliest uses to which mirrors were put, and the art of producing them was doubtless well known in the [Zhou dynasty]\" (Todd and Rupert 1935: 14). Chemical analyses of Chinese Bronze Age mirrors reveal that early technicians produced sophisticated speculum metal, a white, silvery smooth, high-tin bronze alloy that provides extremely reflective surfaces, used for mirrors and reflecting telescopes (Needham and Lu 1974: 198). Among Chinese ritual bronzes, the most common mirror was \"jiàn\" 鑒 \"mirror\", which anciently referred to either a circular mirror, often with intricate ornamentation on the back, or a tall, broad dish for water.\n\nThe \"Kaogongji\" \"Record Examining Crafts\" section of the \"Zhouli\" (above) lists six official standards for \"tóngxī\" 銅錫 copper-tin (Cu-Sn) bronze alloys to produce different implements; from the least tin (1 part per 5 parts copper) for \"bells and sacrificial urns\" to the most (1 part tin per 1 part copper) for \"metallic mirrors\", namely, the \"jiànsuì\" 鑒燧 \"mirror-igniter\" alloy (Hirth 1907: 217-218). However, these ratios are based on Chinese numerology instead of practical metallurgy. \nBeyond about 32% the alloy becomes excessively brittle, and increasing tin content brings no further advantages of any kind; this the Han metallurgists evidently knew. Indeed they knew much more, for they almost always added up to 9% of lead, a constituent which greatly improved the casting properties. Han specular metal is truly white, reflects without tinning or silvering, resists scratching and corrosion well, and was admirably adapted for the purposes of its makers. (Needham and Wang 1962: 89) \nBesides the \"Kaogongji\" half-copper and half-tin formula, other Chinese texts describe the \"yangsui\" and \"fangzhu\" speculum alloy as \"jīnxī\" 金錫 \"gold and tin\" or \"qīngtóngxī\" 青銅錫 \"bronze and tin\" (Forke 1911: 497).\n\nUnless a mirror surface is truly smooth, image quality falls off rapidly with distance. Chinese bronze mirrors included both smooth plane mirrors and precisely curved mirrors of bright finish and high reflectivity. Needham and Wang (1962: 91) say, \"That high-tin bronze (specular metal) was used from [Zhou] times onward is certain, and that it was sometimes coated with a layer of tin by heating above 2300°C. is highly probable; this would give at least 80% reflectivity.\" Later the tin was deposited by means of a mercury amalgam, as recorded in the \"Baopuzi\" (4, above).\n\nFu Ju Xiansheng 負局先生 \"Master Box-on-his-Back\" was the Daoist patron saint of mirror-polishers. The (c. 4th century CE) \"Liexian Zhuan\" (tr. Giles 1948: 50-51) says Fu Chu \"always carried on his back a box of implements for polishing mirrors, and used to frequent the market-towns of Wu in order to exhibit his skill in this work. He charged one cash for polishing a mirror. Having inquired of his host if there were any sick persons in the place, he would produce a drug made up into purple pills and administer these. Those who took them invariably recovered.\"\n\nThe casting of Chinese sun-mirrors and moon-mirrors ideally followed the principles of Chinese astrology, \"yinyang\", and \"wuxing\". The \"Lunheng\" (above) says \"yangsui\" and \"fangzhu\" mirrors should be smelted from five minerals when a \"bingwu\" (43rd of 60-day cycle) day occurs in the 5th lunar month. The (4th century) \"Soushenji\" explains, \"The fire mirror must be cast in the 5th month on a [\"bingwu\"] day at noon, the moon mirror in the eleventh month on a [\"renzi\"] day at midnight.\" These times, the middle of summer and of winter are in harmony with the theory of the Five Elements (Forke 1911: 497). Many early bronze mirrors have inscriptions mentioning the \"bingwu\" day, which was considered auspicious for casting operations since the cyclical \"bing\" was associated with the west and metal, while \"wu\" was associated with the south and fire; correspondingly, the moon-mirrors were cast on \"renzi\" days in the twelfth month, and these cyclical signs are associated with the complementary elements of water and wood (Needham and Wang 1962: 113).\n\nThe Chinese use of burning-mirrors has parallels in other civilizations, especially to produce ritual \"pure fire\", used as the source for lighting other fires.\n\nBurning-mirrors were known to the Greeks and Romans. Archimedes supposedly set fire to the Roman fleet with burning-mirrors in 212 BCE, when Syracuse was besieged by Marcus Claudius Marcellus (Simms 1977). Plutarch's (c. 1st century CE) \"Parallel Lives\" account of Numa Pompilius (r. 715-673 BCE) records the Vestal Virgins using burning-mirrors to light the sacred fire of Vesta.\nIf it (the fire) happens by any accident to be put out, … it is not to be lighted again from another fire, but new fire is to be gained by drawing a pure and unpolluted flame from the sunbeams. They kindle it generally with concave vessels of brass, formed by hollowing out an isosceles rectangular triangle, whose lines from the circumference meet in one single point. This being placed against the sun, causes its rays to converge in the centre, which, by reflection, acquiring the force and activity of fire, rarefy the air, and immediately kindle such light and dry matter as they think fit to apply. (tr. Langhorne 1821 1: 195) \n\nThe striking contemporaneity of the first burning-mirror references in Chinese and European literature, probably indicates the spread in both directions of a technique originally Mesopotamian or Egyptian (Needham and Wang 1962: 88).\n\nIn ancient India, the physician Vagbhata's \"Ashtānga hridayasamhitā\" mentions using burning-mirrors twice, to grind certain drugs on it, and to cauterize a rat bite wound (Laufer 1915: 220).\n\nAbu'l-Fazl ibn Mubarak's history of the Mughal emperor Akbar (r. 1556-1605) records a pair of sacred sun and moon stones: Hindi \"sūryakānta\" \"a crystal burning lens used to light the sacred fire\" and \"chandrakānta\" (Sanskrit \"candrakānta\" \"beloved by the moon\") \"a moonstone that drips water when exposed to moonlight\".\nAt noon of the day, when the sun enters the nineteenth degree of Aries, the whole world being then surrounded by its light, they expose to the rays of the sun a round piece of a white and shining stone, called in Hindi \"sūryakānta\". A piece of cotton is then held near it, which catches fire from the heat of the stone. This celestial fire is committed to the care of proper persons. …There is also a shining white stone, called \"chandrakānt\", which, upon being exposed to the beams of the moon, drips water. (Laufer 1915: 221-222). \nOwing to the similarities of Chinese \"yangsui\" and \"fangzhu\" mirrors with Indian \"sūryakānta\" and \"candrakānta\" stones, Tang (1935) proposes a trans-cultural diffusion from China to the Mughal Empire.\n\n\n\n"}
{"id": "1506652", "url": "https://en.wikipedia.org/wiki?curid=1506652", "title": "Choropleth map", "text": "Choropleth map\n\nA choropleth map (from Greek χῶρος (\"area/region\") + πλῆθος (\"multitude\")) is a thematic map in which areas are shaded or patterned in proportion to the measurement of the statistical variable being displayed on the map, such as population density or per-capita income. \n\nChoropleth maps provide an easy way to visualize how a measurement varies across a geographic area or show the level of variability within a region. A heat map is similar but does not use geographic boundaries.\n\nThe earliest known choropleth map was created in 1826 by Baron Pierre Charles Dupin. They were first called \"cartes teintées\" (\"coloured map\" in French). The term \"choroplethe map\" was introduced in 1938 by the geographer John Kirtland Wright in \"Problems in Population Mapping\".\n\nChoropleth maps are based on statistical data aggregated over previously defined regions (e.g., counties), in contrast to area-class and isarithmic maps, in which region boundaries are defined by data patterns. Thus, where defined regions are important to a discussion, as in an election map divided by electoral regions, choropleths are preferred.\n\nWhere real-world patterns may not conform to the regions discussed, issues such as the ecological fallacy and the modifiable areal unit problem (MAUP) can lead to major misinterpretations, and other techniques are preferable. Similarly, the size and specificity of the displayed regions depend on the variable being represented. While the use of smaller and more specific regions can decrease the risk of ecological fallacy and MAUP, it can cause the map to appear to be more complicated. Although representing specific data in large regions can be misleading, it can make the map clearer and easier to interpret and remember. The choice of regions will ultimately depend on the map's intended audience and purpose.\n\nThe dasymetric technique can be thought of as a compromise approach in many situations. Broadly speaking, choropleths represent two types of data: spatially extensive or spatially intensive. \n\nAnother common error in choropleths is the use of raw data values to represent magnitude rather than normalized values to produce a map of densities. This is problematic because the eye naturally integrates over areas of the same color, giving undue prominence to larger polygons of moderate magnitude and minimizing the significance of smaller polygons with high magnitudes. The problem with using data in total counts arises when the polygons are not all the same size (in area or total population), as in the figure at right. Because a single color, representing a single value, is spread over the entire area of the district, large areas will be more dominant in the visual hierarchy than they should be, and are commonly misinterpreted as having larger values than smaller districts with the same color. To solve this issue, one can \"normalize\" the variable by dividing it by the total area, thus deriving \"density\", which is a field. Another solution is to represent total amounts using a proportional symbol map.\n\n\nWhen mapping quantitative data, a specific color progression should be used to depict the data properly. There are several different types of color progressions used by cartographers. The following are described in detail in Robinson et al. (1995)\n\nSingle-hue progressions fade from a dark shade of the chosen color to a very light or white shade of relatively the same hue. This is a common method used to map magnitude. The darkest hue represents the greatest number in the data set and the lightest shade representing the least number.\n\nTwo variables may be shown through the use of two overprinted single color scales. The hues typically used are from red to white for the first data set and blue to white for the second, they are then overprinted to produce varying hues. These type of maps show the magnitude of the values in relation to each other.\n\nBi-polar progressions are normally used with two opposite hues to show a change in value from negative to positive or on either side of some either central tendency, such as the mean of the variable being mapped or other significant value like room temperature. For example, a typical progression when mapping temperatures is from dark blue (for cold) to dark red (for hot) with white in the middle. When one extreme can be considered better than the other (as in this map of life expectancy) then it is common to denote the poor alternative with shades of red, and the good alternative with green.\n\nComplementary hue progressions are a type of bi-polar progression. This can be done with any of the complementary colors and will fade from each of the darker end point hues into a gray shade representing the middle. An example would be using blue and yellow as the two end points.\n\nBlended hue progressions use related hues to blend together the two end point hues. This type of color progression is typically used to show elevation changes. For example, from yellow through orange to brown.\n\nPartial spectral hue progressions are used to map mixtures of two distinct sets of data. This type of hue progression will blend two adjacent opponent hues and show the magnitude of the mixing data classes. \n\nFull spectral progression contains hues from blue through red. This is common on relief maps and modern weather maps. This type of progression is not recommended under other circumstances because certain color connotations can confuse the map user.\n\nValue progression maps are monochromatic. Although any color may be used, the archetype is from black to white with intervening shades of gray that represent magnitude. According to Robinson \"et al.\" (1995). this is the best way to portray a magnitude message to the map audience. It is clearly understood by the user and easy to produce in print.\n\nWhen using any of these methods, there are two important principles: first is that darker colors are perceived as being higher in magnitude; second is that, while there are millions of color variations, the human eye is limited as to how many colors it can easily distinguish. Generally, five to seven color categories are recommended. The map user should be able to easily identify the implied magnitude of the hue and to match it with the legend.\n\nAdditional considerations include color blindness and various reproduction techniques. For example, the red–green bi-polar progression described in the section above is likely to cause problems for dichromats. A related issue is that color scales which rely primarily on hue with insufficient variation in saturation or intensity may be compromised if reproduced in black and white. Conversely, if a map is legible in black and white, then a prospective user's perception of color is irrelevant.\n\nColor can greatly enhance the communication between the cartographer and their audience, but poor color choice can result in a map that is neither effective nor appealing to the map user. Sometimes simpler is better.\n\n\n"}
{"id": "13353993", "url": "https://en.wikipedia.org/wiki?curid=13353993", "title": "Cognitive miser", "text": "Cognitive miser\n\nIn psychology, the human mind is considered to be a cognitive miser due to the tendency of people to think and solve problems in simpler and less effortful ways rather than in more sophisticated and more effortful ways, regardless of intelligence. Just as a miser seeks to avoid spending money, the human mind often seeks to avoid spending computational effort. The cognitive miser theory is an umbrella theory of cognition that brings together previous research on heuristics and attributional biases to explain how and why people are cognitive misers.\n\nThe term \"cognitive miser\" was first introduced by Susan Fiske and Shelley Taylor in 1984. It is an important concept in social cognition theory and has been influential in other social sciences including but not exclusive to economics and political science.\n\nBefore Fiske and Taylor's cognitive miser theory, the predominant model of social cognition was the naïve scientist. First proposed in 1958 by Fritz Heider in \"The Psychology of Interpersonal Relations,\" this theory holds that humans think and act with dispassionate rationality whilst engaging in detailed and nuanced thought processes for both complex and routine actions. In this way, humans were thought to think like scientists, albeit naïve ones, measuring and analyzing the world around them. Applying this framework to human thought processes, naïve scientists seek the consistency and stability that comes from a coherent view of the world and need for environmental control.\n\nIn order to meet these needs, naïve scientists make attributions. Thus, attribution theory emerged from the study of the ways in which individuals assess causal relationships and mechanisms. Through the study of causal attributions, led by Harold Kelley and Bernard Weiner amongst others, social psychologists began to observe that subjects regularly demonstrate several attributional biases including but not limited to the fundamental attribution error.\n\nThe study of attributions had two effects: it created further interest in testing the naive scientist and opened up a new wave of social psychology research that questioned its explanatory power. This second effect helped to lay the foundation for Fiske and Taylor's cognitive miser.\n\nMuch of the cognitive miser theory is built upon work done on heuristics in judgment and decision-making, most notably Amos Tversky and Daniel Kahneman results published in a series of influential articles. Heuristics can be defined as the \"judgmental shortcuts that generally get us where we need to go—and quickly—but at the cost of occasionally sending us off course.\" In their work, Kahneman and Tversky demonstrated that people rely upon different types of heuristics or mental short cuts in order to save time and mental energy. However, in relying upon heuristics instead of detailed analysis, like the information processing employed by Heider's naïve scientist, biased information processing is more likely to occur. Some of these heuristics include the representativeness heuristic (the inclination to assign specific attributes to an individual the more he/she matches the prototype of that group), availability heuristic (the inclination to judge the likelihood of something occurring because of the ease of thinking of examples of that event occurring) and anchoring heuristic (the inclination to overweight the importance and influence of an initial piece of information). The frequency with which Kahneman and Tversky and other attribution researchers found the individuals employed mental shortcuts to make decisions and assessments laid important groundwork for the overarching idea that individuals and their minds act efficiently instead of analytically.\n\nThe wave of research on attributional biases done by Kahneman, Tversky and others effectively ended the dominance of Heider's naïve scientist within social psychology. Fiske and Taylor, building upon the prevalence of heuristics in human cognition, offered their theory of the cognitive miser. It is, in many ways, a unifying theory which suggests that humans engage in economically prudent thought processes, instead of acting like scientists who rationally weigh costs and benefits, test hypothesis, and update expectations based upon the results of the experiments that are our everyday actions. In other words, humans are more inclined to act as cognitive misers using mental short cuts to make assessments and decisions, about issues and ideas about which they know very little as well as issues of great salience. Fiske and Taylor argue that acting as cognitive misers is rational due to the sheer volume and intensity of information and stimuli humans intake However, other psychologists also argue that the cognitively miserly tendency of humans is a primary reason why \"humans are often less than rational\".\n\nThe implications of this theory raise important questions about both cognition and human behavior. In addition to streamlining cognition in complicated, analytical tasks, cognitive misers are also at work when dealing with unfamiliar issues as well as issues of great importance. Voting behavior in democracies are an arena in which the cognitive miser is at work. Acting as a cognitive miser should lead those with expertise in an area to more efficient information processing and streamlined decision making. However, as Lau and Redlawsk note, acting as cognitive miser who employs heuristics can have very different results for high-information and low-information voters. They write, \"...cognitive heuristics are at times employed by almost all voters, and that they are particularly likely to be used when the choice situation facing voters is complex... heuristic use generally increases the probability of a correct vote by political experts but decreases the probability of a correct vote by novices.\" In democracies, where no vote is weighted more or less because of the expertise behind its casting, low-information voters, acting as cognitive misers, can have broad and potentially deleterious choices for a society.\n\nLater models suggest that the cognitive miser and the naïve scientist create two poles of social cognition that are too monolithic. Instead, Fiske, Taylor, and Arie W. Kruglanski and other social psychologists offer an alternative explanation of social cognition: the motivated tactician. According to this theory, people employ either shortcuts or thoughtful analysis based upon the context and salience of a particular issue. In other words, this theory suggests that humans are, in fact, \"both\" naive scientists and cognitive misers.\n\n\n"}
{"id": "22963407", "url": "https://en.wikipedia.org/wiki?curid=22963407", "title": "Community indicators", "text": "Community indicators\n\nCommunity indicators are \"measurements that provide information about past and current trends and assist planners and community leaders in making decisions that affect future outcomes\". They provide insight into the overall direction of a community: whether it is improving, declining, or staying the same, or is some mix of all three.\n\nIn essence, indicators are measurements that reflect the interplay between social, environmental, and economic factors affecting a region’s or community’s well-being. Community indicators projects typically are conducted by nonprofit organizations within a community, although in some cases they are initiated by the public sector.\n\nCommunity indicators are a localized response to the perceived invalidity of the traditional predominantly economic indicators, such as GDP, that are used for measuring human progress. This invalidity takes two forms. First, economic indicators account for all money transactions as beneficial for quality of life, whereas some of these can be seen as decidedly negative (e.g., money spent on environmental cleanup of pollution that could have been prevented). Secondly, strictly economic indicators do not count the value of non-monetary activity, such as homemaker and volunteer work and non-cash public assistance, which are decidedly positive for the quality of life of many families (Journal article by David Swain, Danielle Hollar; International Journal of Public Administration, Vol. 26, 2003).\n\nA communities level approach to this apparent invalidity is based on the evidence of a social group whose members reside in a specific locality, share government, and often have a common culture and history. Community indicators are not a new concept; they have been in use since 1910, when the Russell Sage Foundation initiated the development of local surveys for measuring industrial, educational, recreational, and other factors. The processes used by the Sage Foundation are similar to those that reemerged during the 1990s. But the difference today is the use of indicators to consider the full spectrum of a community’s well-being, not just isolated factors. Nowadays, indicators are used by many constituencies within a community. After a decade of renewed attention to community indicators, they now represent a valuable mechanism to improve monitoring and evaluation in planning.\n\nRussell Sage Foundation employed “over two thousand local surveys taken on education, recreation, public health, crime, and general social conditions” to assess social conditions. The first survey was conducted in Pittsburgh, Pennsylvania. (In the late 1990s, Pittsburgh again embraced indicators, with its Sustainable Pittsburgh Goals and Indicators Project.) Many of the surveys used\nby the Sage Foundation were conducted by nonprofit organizations, such as chambers of commerce and citizen committees. These surveys yielded social trends indicators and were popular until the Great Depression and World War II, when economic measures such as the gross domestic product or gross national product indicators took greater precedence\n\nCommunity information systems (CIS) bring together a wide range of community indicators — social, economic and environmental data and information around objectives:\n\n\n"}
{"id": "6235952", "url": "https://en.wikipedia.org/wiki?curid=6235952", "title": "Compartmentalization (psychology)", "text": "Compartmentalization (psychology)\n\nCompartmentalization is a subconscious psychological defense mechanism used to avoid cognitive dissonance, or the mental discomfort and anxiety caused by a person's having conflicting values, cognitions, emotions, beliefs, etc. within themselves. \n\nCompartmentalization allows these conflicting ideas to co-exist by inhibiting direct or explicit acknowledgement and interaction between separate compartmentalized self-states. \n\nPsychoanalysis considers that whereas isolation separates thoughts from feeling, compartmentalization separates different (incompatible) cognitions from each other. As a secondary, intellectual defense, it may be linked to rationalization. It is also related to the phenomenon of neurotic typing, whereby everything must be classified into mutually exclusive and watertight categories.\n\nOtto Kernberg has used the term \"bridging interventions\" for the therapist's attempts to straddle and contain contradictory and compartmentalized components of the patient's mind.\n\nCompartmentalization may lead to hidden vulnerabilities in those who use it as a major defense mechanism.\n\nThose suffering from borderline personality disorder will often divide people into all good versus all bad, to avoid the conflicts removing the compartments would inevitably bring, using denial or indifference to protect against any indications of contradictory evidence.\n\nUsing indifference towards a better viewpoint is a normal and common example of this. It can be caused by someone having used multiple compartment ideals and having been uncomfortable with modifying them, at risk of being found incorrect. This often causes double-standards, and bias.\n\nConflicting social identities may be dealt with by compartmentalizing them and dealing with each only in a context-dependent way.\n\nIn his novel, \"The Human Factor\", Graham Greene has one of his corrupt officials use the rectangular boxes of Ben Nicholson's art as a guide to avoiding moral responsibility for bureaucratic decision-making—a way to compartmentalize oneself within one's own separately colored box.\n\nDoris Lessing considered that the essential theme of \"The Golden Notebook\" was \"that we must not divide things off, must not compartmentalise. 'Bound. Free. Good. Bad. Yes. No. Capitalism. Socialism. Sex. Love...'\".\n\n"}
{"id": "38191512", "url": "https://en.wikipedia.org/wiki?curid=38191512", "title": "Concept-driven strategy", "text": "Concept-driven strategy\n\nA concept-driven strategy is a process for formulating strategy that draws on the explanation of how humans inquire provided by linguistic pragmatic philosophy. This argues that thinking starts by selecting (explicitly or implicitly) a set of concepts (frames, patterns, lens, principles, etc.) gained from our past experiences. These are used to reflect on whatever happens, or is done, in the future.\n\nConcept-driven strategy therefore starts from agreeing and enacting a set of strategic concepts (organizing principles) that \"works best\" for an organisation. For example, a hospital might set its strategy as intending to be Caring, World Class, Local, Evidence Based, and Team Based. A University might set its strategy as intending to be Ranked, Problem Solving, Online, Equis, and Offering Pathways. A commercial corporation might set its strategy as intending to be Innovative, Global, Have Visible Supply Chains, Agile and Market Share Dominant. These strategic concepts make up its \"Statement of Intent\" (or Purpose).\n\nMuch of the strategic management literature mutates Peter Drucker's call for corporations to start the strategic management process by producing a statement of purpose, mission and objectives. This has been mutated into a call to start with a vision, mission and objectives statement. There is an alternative approach which focuses on the Statement of Purpose or Intent. Drucker's example for this statement for a commercial corporation was to state that the corporation's purpose was to create customers. That is, it was going to use the concept of 'customer creation' to coordinate and organise the cognition or mindset of those that worked for the organisation. This was why the corporation existed. Having one concept is now thought to be insufficient. George Armitage Miller's modified The Magical Number Seven, Plus or Minus Two and dialectic suggests a handful of concepts under tension would be preferable.\n\nThe Statement of Purpose, Statement of Intent or concept-driven approach to strategy formulation therefore focuses on setting and enacting a set strategic concepts. If a participatory approach is being used these concepts will be acquired through a process of collaboration with stakeholders. Once agreed the strategic concepts can be used to coordinate activities and act as a set of decision making criteria. The set of concepts that make up the Statement of Intent is then used to make sense of an unpredictable future across an organisation in a co-ordinated manner.\n\nLinguistic pragmatism argues that our prior conceptions interpret our perception (sensory inputs). These conceptions are represented by concepts like running, smiling, justice, reasoning and agility. They are patterns of activity, experienced in our past and remembered. They can be named by those with language and so shared.\n\nBagginni explains pragmatic concepts using the classic example of whether the earth is flat or round.\n\nAnother example would be that we can think of the war in Iraqi differently by reflecting off the concepts of oil security, Imperialism, aggressive capitalism, liberation or democracy. \nThe concept-driven approach to strategy formulation involves setting and using a set of linguistic pragmatic concepts.\n\nThe steps to formulating a participatory concept-driven strategy are:\n\n\nConcept-driven strategy is the name given to a number of similar strategic thinking approaches.\n\nGenerally, the term 'concept-driven' is used to encourage a focus on the 'concepts' being used. See Concept learning or Management Concepts.\n\nSome organisations produce a 'statement of intent' with little thought as to the concepts it contains. However, if it is a short list of concepts, high level objectives, principles, priorities or frames, then concept-driven strategy offers a philosophical basis for these statements.\n\nSome organisations produce a 'strategic principles' statement which again is similar to a statement of intent and the same applies about the concepts approach offering a philosophical basis. The term 'strategic priorities' or 'strategic values' are often used in the same way as strategic principles.\n\nThe literature about 'corporate purpose' is also similar to that of strategic intent. Sometimes, purpose refers to present actions and intent to future ones. If purpose is expressed as a set of concepts, then the concepts approach again provides some philosophical basis.\n\nThere is a connection between 'systems thinking' and concept-driven strategy. The Churchman/Ackoff stream of systems thinking was interested in a developing generic system of concepts for thinking about problems. Rather than a generic set of concepts, the concept-driven approach uses whatever concepts stakeholders think work best for the future of their organisation.\n\nThere is a military planning approach called 'concept-led'. The military-like leadership seems to have moved the concepts from being drivers to be leaders. There seems to be very little difference otherwise.\n\nIn turbulent environments, concepts are thought 'more flexible than objectives' (goals, targets) as they provide why certain actions are preferable. The purpose and intent literature likes to distinguish itself from the objectives literature by saying purpose and intent provide the reasons for (why change), the driver for change. Objectives are where you end up. In complex dynamic situations, there may be many acceptable end points, many of which cannot be anticipated by planners. Arguably the only objective is to survive. How is explained in the statement of intent.\n\nPerhaps strangely, there is a connection between 'metaphor', metaphoric criticism, or conceptual metaphor and concept-driven strategy. Pragmatic concepts are not images but most concepts relate to metaphors. For example, to say an organisation is like a machine, with cogs, or like an adaptive organism, is to use the concepts of machine and organism to reflect on organisations. Much of what has been written about the usefulness of metaphors in planning applies to concepts.\n\nThe term 'strategic frames' is not common given the extensive literature on frame analysis but frames and pragmatic concepts seem to be very similar. Amos Tversky defines a frame as a conception of outcomes.\n\nThe system of strategic concepts listed in a statement of intent, purpose, principles, frames or conceptual metaphor are organizing principle(s).\n\nAlso, as Karl Weick explains sensemaking as the process of conceptualising problems, concept-driven strategy might be thought of as a pragmatic means of sensemaking a strategy.\n\n\n"}
{"id": "28916015", "url": "https://en.wikipedia.org/wiki?curid=28916015", "title": "Cordelia Fine", "text": "Cordelia Fine\n\nCordelia Fine is a Canadian-born British philosopher, psychologist and writer.\nShe is a Full Professor of History and Philosophy of Science at The University of Melbourne, Australia.\nFine has written three popular science books on the topics of social cognition, neuroscience, and the popular myths of sex differences.\nHer latest book \"Testosterone Rex\" won the Royal Society Science Book Prize, 2017.\nShe has authored several academic book chapters and numerous academic publications.\nFine is also noted for coining the term 'neurosexism'.\n\nAs a science communicator, Fine has given many public and keynote lectures across the education, business, academic and public sectors.\nFine has also written for the New York Times, Scientific American, New Scientist, They Psychologist, The Guardian, and The Monthly, among others, and has reviewed books for the Financial Times and the Wall Street Journal.\n\nIn April 2018 Cordelia Fine was awarded the Edinburgh Medal. This medal is awarded to \"men and women of science and technology whose professional achievements are judged to have made a significant contribution to the understanding and well-being of humanity.\"\n\nCordelia Fine was awarded a bachelor's degree in Experimental Psychology with first-class honours from Oxford University, a Master of Philosophy \nin Criminology from Cambridge University, and a PhD in Psychology from University College London.\n\nSince completing her PhD, Cordelia Fine has undertaken research at the School of Philosophy & Bioethics at Monash University, at the Centre for Applied Philosophy & Public Ethics at the Australian National University, and at the Centre for Agency, Values & Ethics (CAVE) at Macquarie University.\nFrom 2012 to 2016 she was an ARC Future Fellow at the Melbourne School of Psychological Sciences.\nShe was also an Associate Professor in the Melbourne Business School, at the University of Melbourne until 2016. She is currently a Professor in the School of Historical and Philosophical Studies at the University of Melbourne, Australia\n\nFine's first book, \"A Mind of Its Own\", synthesizes a large amount of cognitive research to show that the mind often gives a distorted picture of reality. \n\nHer second book, \"Delusions of Gender\", argues that conclusions that science has shown that men's and women's brains are intrinsically different in ways that explain the gender status quo are premature and often based on flawed methods and unexamined assumptions. She also challenges the common assumption that a gender-egalitarian society means that differences in social outcomes and interests must be due to biology. \"With still such different contexts and circumstances for men and women, it's simply not possible to compare the choices they make and draw confident conclusions about the sexes' different inner natures.\" Fine's approach to gender has been criticised by those who think it behaviourist, and for not accounting for what psychiatry terms gender identity disorders. However, as Fine pointed out in \"The Psychologist\", the book is concerned with scientific evidence presented as support for the idea that males and females are, on average, 'hardwired' to 'systemise' versus 'empathise', rather than the question of the extent to which core gender identity is 'hardwired'; and that she does not subscribe to a behaviourist or social determinist view of development, but rather \"one in which the developmental path is constructed, step by step, out of the continuous and dynamic interaction between brain, genes and environment.\" \n\nBen Barres, a Professor of Neurobiology at Stanford University, wrote in a review of the book for \"PLOS Biology\" that Fine's \"analysis of this data should be required reading for every neurobiology student, if not every human being.\" The neuroscientists Margaret McCarthy and Gregory Ball, have said that Fine presents a one-sided picture of the study of sex differences, and that \"Delusions of Gender\" threatened to \"severely hamper\" progress in this field. However, neuroscientists Geert de Vries and Nancy Forger of the Neuroscience Institute at Georgia State University cite the work of Fine and colleagues in noting that \"unsubstantiated claims about the nature and function of neural sex differences continue to be made and such claims may do serious harm\". Together with Barnard College sociomedical scientist Rebecca Jordan-Young, Fine has rejected the claim, based on quotations of her criticisms of popular misrepresentations of science, that she is \"anti-sex differences\". Fine and Jordan-Young, with other co-authors, have published recommendations and guidelines for improving the quality of scientific investigations of sex/gender differences in research.\n\nFine's third book, \"Testosterone Rex,\" critiques an account of sex differences and their evolutionary, neural and hormonal basis that is prominent in the popular literature, and also often influential in some areas of scientific research. In 2017 it won the prestigious Royal Society Science Books Prize. \n\n\"Testosterone Rex (book)\n\n\"Delusions of Gender (book)\n\n\n\"A Mind of Its Own (book)\n\n\n\n\n"}
{"id": "1690329", "url": "https://en.wikipedia.org/wiki?curid=1690329", "title": "Cromwell's rule", "text": "Cromwell's rule\n\nCromwell's rule, named by statistician Dennis Lindley, states that the use of prior probabilities of 0 (\"the event will definitely not occur\") or 1 (\"the event will definitely occur\") should be avoided, except when applied to statements that are logically true or false, such as 2+2 equaling 4 or 5.\n\nThe reference is to Oliver Cromwell, who wrote to the General Assembly of the Church of Scotland on 5 August 1650, including a phrase that has become well known and frequently quoted:\nAs Lindley puts it, assigning a probability should \"leave a little probability for the moon being made of green cheese; it can be as small as 1 in a million, but have it there since otherwise an army of astronauts returning with samples of the said cheese will leave you unmoved.\" Similarly, in assessing the likelihood that tossing a coin will result in either a head or a tail facing upwards, there is a possibility, albeit remote, that the coin will land on its edge and remain in that position.\n\nIf the prior probability assigned to a hypothesis is 0 or 1, then, by Bayes' theorem, the posterior probability (probability of the hypothesis, given the evidence) is forced to be 0 or 1 as well; no evidence, no matter how strong, could have any influence.\n\nA strengthened version of Cromwell's rule, applying also to statements of arithmetic and logic, alters the first rule of probability, or the convexity rule, 0 ≤ Pr(\"A\") ≤ 1, to 0 < Pr(\"A\") < 1.\n\nAn example of Bayesian divergence of opinion is based on Appendix A of Sharon Bertsch McGrayne's 2011 book. Tim and Susan disagree as to whether a stranger who has two fair coins and one unfair coin (one with heads on both sides) has tossed one of the two fair coins or the unfair one; the stranger has tossed one of his coins three times and it has come up heads each time. \n\nTim assumes that the stranger picked the coin randomly – i.e., assumes a prior probability distribution in which each coin had a 1/3 chance of being the one picked. Applying Bayesian inference, Tim then calculates an 80% probability that the result of three consecutive heads was achieved by using the unfair coin, because each of the fair coins had a 1/8 chance of giving three straight heads, while the unfair coin had an 8/8 chance; out of 24 equally likely possibilities for what could happen, 8 out of the 10 that agree with the observations came from the unfair coin. If more flips are conducted, each further head increases the probability that the coin is the unfair one. If no tail ever appears, this probability converges to 1. But if a tail ever occurs, the probability that the coin is unfair immediately goes to 0 and stays at 0 permanently.\n\nSusan assumes the stranger chose a fair coin (so the prior probability that the tossed coin is the unfair coin is 0). Consequently, Susan calculates the probability that three (or any number of consecutive heads) were tossed with the unfair coin must be 0; if still more heads are thrown, Susan does not change her probability. Tim and Susan's probabilities do not converge as more and more heads are thrown.\n\nAn example of Bayesian convergence of opinion is in Nate Silver's 2012 book \"The Signal and the Noise: Why so many predictions fail — but some don't\". After stating, \"Absolutely nothing useful is realized when one person who holds that there is a 0 (zero) percent probability of something argues against another person who holds that the probability is 100 percent\", Silver describes a simulation where three investors start out with initial guesses of 10%, 50% and 90% that the stock market is in a bull market; by the end of the simulation (shown in a graph), \"all of the investors conclude they are in a bull market with almost (although not exactly of course) 100 percent certainty.\"\n\n"}
{"id": "12824540", "url": "https://en.wikipedia.org/wiki?curid=12824540", "title": "Dakṣiṇācāra", "text": "Dakṣiṇācāra\n\nThe term Dakshinachara (Right-Hand Path) is a technical term used to refer to Tantric sects that do not engage in heterodox practices. In contrast, \"Vamachara\" (Left-Hand Path) is used to describe particular tantric practices that are considered heterodox according to usual Hindu social norms.\n\nN. N. Bhattacharyya explains the Sanskrit technical term \"\" as follows:\nThe means of spiritual attainment which varies from person to person according to competence... \"Ācāras\" are generally of seven kinds – Veda, Vaiṣṇava, Śaiva, Dakṣiṇa, Vāma, Siddhāṇta, and Kaula, falling into two broad categories – Dakṣiṇa and Vāma. Interpretations vary regarding the nature and grouping of the \"ācāras\".\n\"\" mans \"right\". For this reason, the term Dakṣiṇāra is often translated \"Right-hand practice\".\n\nThe \"Brahma Yamala\", a Tantric text, says there are three currents of tradition (dakshina, vama, and madhyama) characterized respectively by the predominance of each of the three gunas (sattva, rajas, and tamas). According to this text, dakshina is characterized by sattva, and is pure; Madhyama, characterized by rajas, is mixed; and Vama, characterized by tamas, is impure. The Tantras of each class follow a particular line of spiritual practices. Dakshinachara consists of traditional Hindu practices such as asceticism and meditation.\n\n\n"}
{"id": "2733733", "url": "https://en.wikipedia.org/wiki?curid=2733733", "title": "Delayed gratification", "text": "Delayed gratification\n\nDelayed gratification, or deferred gratification, describes the process that the subject undergoes when the subject resists the temptation of an immediate reward in preference for a later reward. Generally, delayed gratification is associated with resisting a smaller but more immediate reward in order to receive a larger or more enduring reward later. A growing body of literature has linked the ability to delay gratification to a host of other positive outcomes, including academic success, physical health, psychological health, and social competence.\n\nA person's ability to delay gratification relates to other similar skills such as patience, impulse control, self-control and willpower, all of which are involved in self-regulation. Broadly, self-regulation encompasses a person's capacity to adapt the self as necessary to meet demands of the environment. Delaying gratification is the reverse of delay discounting, which is \"the preference for smaller immediate rewards over larger but delayed rewards\" and refers to the \"fact that the subjective value of reward decreases with increasing delay to its receipt\". It is theorized that the ability to delay rewards is under the control of the cognitive-affective personality system (CAPS).\n\nSeveral factors can affect a person's ability to delay gratification. Cognitive strategies, such as the use of distracting or \"cool\" thoughts, can increase delay ability, as can neurological factors, such as strength of connections in the frontal-striatal pathway. Behavioral researchers have focused on the contingencies that govern choices to delay reinforcement, and have studied how to manipulate those contingencies in order to lengthen delay. Age plays a role too; children under five years old demonstrate a marked lack of delayed gratification ability and most commonly seek immediate gratification. A very small difference between males and females suggest that females may be better at delaying rewards. The ability to wait or seek immediate reinforcement is related to avoidance-related behaviors such as procrastination, and to other clinical diagnoses such as anxiety, attention deficit hyperactivity disorder and depression.\n\nSigmund Freud, the founder of psychoanalytic theory, discussed the ego's role in balancing the immediate pleasure-driven desires of the id with the morality-driven choices of the superego. Funder and Block expanded psychoanalytic research on the topic, and found that impulsivity, or a lack of ego-control, has a stronger effect on one's ability to delay rewards if a reward is more desirable. Finally, environmental and social factors play a role; for example, delay is affected by the self-imposed or external nature of a reward contingency, by the degree of task engagement required during the delay, by early mother-child relationship characteristics, by a person's previous experiences with unreliable promises of rewards (e.g., in poverty), and by contemporary sociocultural expectations and paradigms. Research on animals comprises another body of literature describing delayed gratification characteristics that are not as easily tested in human samples, such as ecological factors affecting the skill.\n\nOne well-supported theory of self-regulation, called the Cognitive-affective personality system (CAPS), suggests that delaying gratification results from an ability to use \"cool\" regulatory strategies (i.e., calm, controlled and cognitive strategies) over \"hot regulatory strategies (i.e., emotional, impulsive, automatic reactions), when faced with provocation. In \"hot\" processing, a person thinks intently about the object causing temptation, and especially about its most appealing elements, and is subsequently less able to resist the immediate reward. The use of cool strategies can translate to more control over behavior. Effective \"cool\" strategies involve distraction and restructuring the perception of the tempting stimulus to make it seem less appealing. For example, in one study of pre-adolescent boys with behavioral problems, the boys showed a reduction in verbal and physical aggression when they used \"cool\" strategies, such as looking away or distracting themselves. The most effective type of distraction seems to be imagining another desirable reward, which takes attention away from the immediate temptations.\n\nThe seminal research on delayed gratification – the now-famous \"marshmallow experiment\" – was conducted by Walter Mischel in the 1960s and 1970s at Stanford University. Mischel and his colleagues were interested in strategies that preschool children used to resist temptation. They presented four-year-olds with a marshmallow and told the children that they had two options: (1) ring a bell at any point to summon the experimenter and eat the marshmallow, or (2) wait until the experimenter returned (about 15 minutes later), and earn two marshmallows. The message was: \"small reward now, bigger reward later.\" Some children broke down and ate the marshmallow, whereas others were able to delay gratification and earn the coveted two marshmallows. In follow-up experiments, Mischel found that children were able to wait longer if they used certain \"cool\" distraction techniques (covering their eyes, hiding under the desk, singing songs, or imagining pretzels instead of the marshmallow in front of them), or if they changed the way they thought about the marshmallow (focusing on its similarity to a cotton ball, rather than on its gooey, delectable taste).\n\nThe children who waited longer, when re-evaluated as teenagers and adults, demonstrated a striking array of advantages over their peers. As teenagers, they had higher SAT scores, social competence, self-assuredness and self-worth, and were rated by their parents as more mature, better able to cope with stress, more likely to plan ahead, and more likely to use reason. They were less likely to have conduct disorders or high levels of impulsivity, aggressiveness and hyperactivity. As adults, the high delayers were less likely to have drug problems or other addictive behaviors, get divorced, or be overweight. Each minute that a preschooler was able to delay gratification translated to a .2% reduction in Body Mass Index 30 years later.\n\nEach of these positive outcomes requires some ability to forgo short-term reward in favor of a higher payoff in the future. The ability to delay gratification also appears to be a buffer against rejection sensitivity (the tendency to be anxious when anticipating interpersonal rejection). In a 20-year follow-up of the marshmallow experiment, individuals with vulnerability to high rejection sensitivity who had shown strong delay of gratification abilities as preschoolers had higher self-esteem and self-worth and more adaptive coping skills, in comparison to the individuals who had high rejection sensitivity but low delay of gratification as four-year-olds. These compelling longitudinal findings converge with other studies showing a similar pattern: The ability to resist temptation early in life translates to persistent benefits across settings.\n\nForty years after the first marshmallow test studies, neuroimaging data has shed light on the neural correlates of delayed gratification. A team led by B. J. Casey, of Cornell University, recruited 59 of the original participants – who are now in their mid-40s – and gave them a delayed gratification task. Instead of resisting marshmallows, these adults were instructed to suppress responses to images of happy faces, but not to neutral or fearful faces. Those who had been high delayers as pre-schoolers were more successful at controlling their impulses in response to the emotional faces (i.e., not pressing the button in response to happy faces), suggesting that the high delayers continued to show better ability to dampen or resist impulses. Casey and colleagues also scanned the brains of 26 participants using functional magnetic resonance imaging (fMRI) as they completed the task. The researchers hypothesized that high delayers would be more likely to use \"cool\" regulation strategies to control their responses, which would manifest as activation of the right prefrontal cortex, whereas low delayers would use \"hot\" strategies, which would activate the ventral striatum, an area also linked to addiction. Indeed, results showed this differential brain activity. This mirrors other fMRI research of delayed gratification conducted by Noah Shamosh and Jeremy Gray, of Yale University, demonstrating that individuals who chose larger delayed rewards over smaller immediate rewards (in hypothetical situations) showed greater brain activation in the anterior prefrontal cortex.\n\nThe way that a person frames a situation heavily influences a decision's outcome. Research on \"hot\" and \"cool\" strategies suggests that when children cognitively represent what they are waiting for as a real reward by focusing on the reward's arousing, \"hot\" qualities (taste, smell, sound,feel, etc.) their self-control and delay of gratification decreases, while directing attention to a symbol of the reward by focusing on its abstract, \"cool\" qualities (shape, color, number, etc.), can enhance self-control and increase the delay. Optimal self-control and the longest delay to gratification can be achieved by directing attention to a competing item, especially the arousing, \"hot\" qualities of a competing item. For example, delays are increased when thinking about the taste and smell of popcorn while waiting to eat candy. This illustrates an individual's ability to manipulate his/her cognitive representation of external stimuli for goal-directed purposes.\n\nDelaying gratification is the same as controlling the impulse for immediate gratification, which requires cognitive control. The ventral striatum, located in the midbrain, is the part of the limbic system that is the reward center as well as a pleasure center. The limbic system will always react to the potential for instant pleasure. To override this instinct, the prefrontal cortex, which is also associated with reasoning and rational thought, must be active. The prefrontal cortex is also the part of the brain that determines the focus of a person's attention, which enables a better framing that facilitates delayed gratification. During adolescence and early adulthood, the prefrontal cortex develops and matures to become more complicated and connected with the rest of the brain. Older children and adults find the deferment-of-gratification tasks easier than do young children for this reason. However, the relative ability to defer gratification remains stable throughout development. Children who can better control impulses grow up to be adults who also have better control. Practicing deferred gratification is quite beneficial to cognitive abilities throughout life.\n\nBehaviorists focus on the acquisition and teaching of delayed gratification, and have developed therapeutic techniques for increasing ability to delay. Behavior analysts capitalize on the effective principles of reinforcement when shaping behavior by making rewards contingent on the person's current behavior, which promotes learning a delay of gratification. It is important to note that for a behavior modification regimen to succeed, the reward must have some value to the participant. Without a reward that is meaningful, providing delayed or immediate gratification serves little purpose, as the reward is not a strong reinforcer of the desired behavior.\n\nBehavior theorists see delaying gratification as an adaptive skill. It has been shown that learning to delay gratification promotes positive social behavior, such as sharing and positive peer interactions. For example, students who learn to delay gratification are better able to complete their assigned activities. To put it simply, if someone undertakes an activity with the promise of a delayed reward after, the task's completion becomes more likely.\n\nBehavioral researchers have found that a choice for instant versus delayed gratification is influenced by several factors including whether the reward is negative or positive reinforcement. A past study by Solnick et al., focused on an experiment where the main concentrations were time added to both conditions and the preference of the participants with experiencing a loud noise for variable amounts of time: 15, 30, 60, and 90 seconds. The buttons to turn off the noise were manipulated by one button turning off the noise for a short amount of time and the other turning the noise off for an extended time. The participants were found to be more willing to turn off the noise immediately for 90 seconds rather than turning it off for the 120 seconds after a 60-second delay was issued. Findings illustrate that participants chose not to delay their gratification for the relief of noise but rather instantly silence it for a shorter amount of time.\n\nIn a 2011 study, researchers tested to see if people would willingly choose between instant and delayed gratification by offering them a set amount of (hypothetical) money that they could receive presently, or telling them they could wait a month for more money. Results suggested that willingness to delay gratification depended on the amount of money being offered, but also showed wide individual variation in the threshold of later reward that was motivating enough to forgo the immediate reward. The subjective value of a reward can also stem from the way one describes the potential reward. As prospect theory states, people are heavily loss-averse. People tend to value a commodity more when it is considered to be something that can be lost or given up than when it is evaluated as a potential gain.\n\nThe duration of time until an eventual reward also affects participants' choice of immediate or delayed gratification. A 2001 study demonstrated that if a reward will not be granted for an extensive amount of time, such as 180–300 months (15–25 years), the monetary amount of the reward is inconsequential; instead, the bulk of the participants choose the immediate reward, even if their delayed reward would be quite large. Delayed gratification has its limits, and a delay can only be so long before it is judged to be not worth the effort it takes to wait.\n\nIn a Year 3 elementary classroom in South Wales a teacher was having difficulty keeping three girls on task during designated private study times. The teacher reached for aid from behavior analysts, and a delayed gratification behavior modification plan was put into place. The study gave limits on the numbers of questions the children could ask, and if they did not exceed the limit, they were given tokens for rewards. The token economy for rewards is an example of delayed gratification, by way of cool processing. Instead of having the girls focus on attention-seeking behaviors that distracted the teacher and the students, the teacher had them focus on how many questions they had, and if they needed to ask for help from the teacher. They also focused on gaining tokens rather than focusing on the final reward, which increased their delays. By giving the children this goal and the promise of positive reinforcement for good behavior, the girls dropped their rate of question-asking and attention-seeking.\n\nCompared to neurotypical children, those with ADHD generally demonstrate greater impulsivity by being influenced by reward immediacy and quality more than by the frequency of reward and effort to obtain it. However, researchers have empirically shown that these impulsive behavior patterns can be changed through the implementation of a simple self-control training procedure in which reinforcer immediacy competes with the frequency, quantity or saliency of the reward, and the delay is gradually increased. One study demonstrated that any verbal activity while waiting for reinforcement increases delay to gratification in participants with ADHD. In another study, three children diagnosed with ADHD and demonstrating impulsivity were trained to prefer reward rate and saliency more than immediacy through manipulation of the quality of the reinforcers and by systematically increasing the delay with a changing-criterion design. Post-assessment of the children illustrated that self-control can transfer to untrained dimensions of reinforcement; such as an increase in quality over immediacy preference due to direct training resulting in an increase in quantity over immediacy preference.\n\nAt birth, infants are unable to wait for their wants and needs to be met and exhibit a defining lack of impulse control. With age, developing children are able to retain impulsivity but also gain control over their immediate desires and are increasingly able to prolong gratification. Developmental psychologists study the progression of impulse control and delay of gratification over the lifespan, including deficiencies in development that are closely related to attention deficits and behavior problems.\n\nChildren under five years old display the least effective strategies for delaying gratification, such as looking at the reward and thinking about its arousing features. By 5 years old, most children are able to demonstrate better self-control by recognizing the counter-productivity of focusing on the reward. Five-year-olds often choose instead to actively distract themselves or even use self-instructions to remind themselves of the contingency that waiting produces a reward of a greater value. Between 8 and 13 years old, children develop the cognitive ability to differentiate and employ abstract versus arousing thoughts in order to distract their minds from the reward and thereby increase the delay. Once delaying strategies are developed, the capacity to resist temptation is relatively stable throughout adulthood. Preschoolers' performance on delayed gratification tasks correlates with their adolescent performance on tasks designed to measure similar constructs and processing, which parallels the corresponding development of willpower and the fronto-striatal circuit (neural pathways that connect the frontal lobe to other brain regions). Declines in self-regulation and impulse control in old age predict corresponding declines in reward-delaying strategies, specifically reduced temporal discounting due to a decrease in cooling strategies.\n\nThroughout 33 studies on gender differences, a small significant effect (r = .06) has been found indicating that a base-rate of 10% more females are able to delay rewards than males, which is the typical percentage of difference found between the sexes on measures such as personality or social behavior. This effect may be related to the slight gender differences found in delay discounting (i.e., minimizing the value of a delayed reward) and higher levels of impulsivity and inattention in boys. Further studies are needed to analyze if this minute difference begins at a certain age (e.g., puberty) or if it has a stable magnitude throughout the lifespan. Some researchers suggest this gender difference may correspond with a mother's tendency to sacrifice her wants and needs in order to meet those of her child more frequently than a father does.\n\nSelf-control has been called the \"master virtue\" by clinical and social psychologists, suggesting that the ability to delay gratification plays a critical role in a person's overall psychological adjustment. People with better ability to delay gratification report higher wellbeing, self-esteem and openness to experience, as well as more productive ways of responding to anger and other provocations. Early delay ability has been shown to protect against the development of a variety of emotional vulnerabilities later in life, such as aggression and features of borderline personality disorder. Meanwhile, many maladaptive coping skills that characterize mental illness entail a difficulty delaying gratification. The tendency to choose short-term rewards at the expense of longer-term benefits permeates many forms of psychopathology.\n\nA growing body of research suggests that self-control is akin to a muscle that can be strengthened through practice. In other words, self-control abilities are malleable, a fact that can be a source of hope for those who struggle with this skill. In psychotherapy, treatment for impulse-control issues often involves teaching individuals to realize the downsides of acting on immediate urges and in turn to practice delaying gratification. In anxiety disorders, this process occurs through exposure to a feared situation – which is very uncomfortable at first, but eventually becomes tolerable and even trains a person's mind and body that these situations are less threatening than originally feared. Exposure therapy is only effective if an individual can delay gratification and resist the urge to escape the situation early on. To shed insight on the tradeoff between short- and long-term gains, therapists might also help individuals construct a pro-con list of a certain behavior, with sections for short-term and long-term outcomes. For maladaptive coping behaviors such as self-injury, substance use or avoidance, there are generally no long-term pros. Meanwhile, abstinence from acting on a harmful urge (i.e., delayed gratification) generally results in long-term benefits. This realization can be a powerful impetus for change.\n\nExternalizing disorders (i.e., acting-out disorders) show a clearer link to delayed gratification, since they more directly involve deficits in impulse control. For example, attention deficit hyperactivity disorder (ADHD) and aggressive behavior are associated with difficulty delaying gratification in children and adolescents, as are substance abuse, gambling, and other addictive behaviors in adolescents and adults. In a 2010 study, teenagers and young adults with stronger abilities to delay gratification were less likely to drink alcohol, or to smoke cigarettes or cannabis. A 2011 study found that the contrast in delayed gratification between children with and without ADHD was no longer significant after statistically controlling for IQ (in other words, ADHD was not associated with delayed gratification above and beyond the influence of IQ). This may stem from the high correlation between intelligence and delayed gratification, and suggests that the tie between delayed gratification and ADHD could benefit from more investigation.\n\nDifficulty delaying gratification also plays a role in internalizing disorders like anxiety and depression. A hallmark behavior in anxiety is avoidance of feared or anxiety-provoking situations. By seeking the immediate relief that comes with avoidance, a person is succumbing to the pull of instant gratification over the larger reward from overcoming the fear and anxiety that caused the avoidance. Procrastination, which is often a reflection of anxiety, is a clear example: a person avoids a dreaded task by engaging in a more enjoyable immediate activity instead. Obsessive–compulsive disorder (OCD) is a more jarring case of this anxiety-related struggle to delay gratification; someone with OCD is unable to resist compulsions that temporarily mitigate the torture of obsessive thoughts, even though these compulsions do not banish the obsessions in the long run. One experiment, however, did not find any significant differences between samples with OCD and healthy controls in delayed gratification, while finding substantially improved delayed gratification among those with obsessive–compulsive personality disorder. Depression is also associated with lower capacity to delay gratification, though the direction of cause and effect is not clear. A depressed person who has difficulty pushing him or herself to engage in previously enjoyed activities is (deliberately or not) prioritizing short-term comfort and is demonstrating an impaired ability to delay gratification. There is evidence that individuals who engage in deliberate self-harm (i.e., cut themselves) are less able to tolerate emotional distress but are more able to tolerate physical pain. Thus it is argued that they injure themselves because they cannot delay gratification and need a way to end emotional pain quickly.\n\nSigmund Freud viewed the struggle to delay gratification as a person's efforts to overcome the instinctive, libidinal drive of the id. According to classic psychoanalytic theory, a person's psyche is composed of the id, ego and superego. The id is driven by the pleasure principle: it wants physical pleasure, and it wants it now. The ego, operating under the reality principle, serves to moderate the id's desire for instant gratification against the superego, which is guided by a person's internalized sense of morality. According to psychoanalytic theory, a person with difficulty delaying gratification is plagued by intrapsychic conflict – the ego cannot adequately regulate the battle between the id and the superego – and experiences psychological distress, often in the form of anxiety or \"neurosis\".\n\nOther psychoanalytic researchers describe a more nuanced, and less universally positive, view of delayed gratification. David C. Funder and Jack Block theorized that a person's tendency to delay, or not delay, gratification is just one element of a broader construct called ego control, defined as a person's ability to modulate or control impulses. Ego control \"ranges from ego undercontrol at one end to ego overcontrol at the other\", according to Funder. These tendencies are thought to be relatively stable in each individual, such that someone who tends toward undercontrol will \"grab whatever rewards are immediately available even at the cost of long-term gain\" and someone who tends toward overcontrol will \"delay or even forgo pleasures even when they can be had without cost\". By this view, delay of gratification may be adaptive in certain settings, but inappropriate or even costly in other settings.\n\nFunder and Block draw a distinction between the ego-control model, in which delayed gratification is seen as a general tendency to contain motivational impulses (whether or not it is adaptive in a specific instance), and the ego-resiliency model (supported by Mischel's research), in which delayed gratification is seen as a skill that arises only when it is adaptive. To tease apart these models, Funder and Block explored the association between ego control, ego resiliency, IQ and delayed gratification in adolescents. The adolescents had the choice between being paid $4 at each of six study sessions or delaying their payment until the last session, in which case they would also earn an addition $4 of \"interest\". The results supported both models of delayed gratification. The teens' tendency to delay gratification was indeed associated with IQ and with ego resiliency (e.g., higher delayers were rated as more responsible, consistent, likable, sympathetic, generous; less hostile, moody, self-indulgent, rebellious), but was also independently associated with ego control (e.g., higher delayers were rated as \"tends toward over-control of needs and impulses\" and \"favors conservative values in a number of areas\"). The researchers noted that individual differences in ego control (i.e., overall impulsivity) may play a larger role in delayed gratification when the incentives are larger and more motivating.\n\nWriting in 1998, Funder described delayed gratification as a \"mixed bag\". He concluded: \"Participants who exhibited the most delay were not just 'better' at self-control, but in a sense they seemed unable to avoid it. [...] Delayers are in general smart and well-adjusted, but they also tend to be somewhat overcontrolled and unnecessarily inhibited.\"\n\nFactors affecting one's ability to delay gratification depend on whether the delay contingency is self-imposed (delay can be terminated at the will of the person waiting) or externally imposed by another person, institution or circumstance. When the contingency is self-imposed, the physical presence of the reward seems to aid in delaying gratification. On the other hand, when the delay is externally imposed, children are not able to wait as long when the reward is present, suggesting greater frustration under these circumstances.\n\nEngaging in work or an assigned task can generate an effective distraction from a reward and enable a person to wait for a longer delay, as long as the reward is not being flaunted. Having the reward present during work (and easily accessible) creates a negative frustration—akin to teasing—rather than providing motivation. For example, a child who can see other children playing outside while finishing his/her homework will be less motivated to wait for his/her turn for recess. Another factor work and task engagement adds to the delay of gratification is that if the work is interesting and has some reinforcing quality inherent to it, then attention to the reward will reduce work productivity since it becomes a distraction to the work rather than a motivation to finish it.\n\nThe more positive emotions and behavior that a 12- to 24-month-old toddler displays when coping with separation from a parent, the better s/he is 3.5 years later at using cooling strategies in order to delay gratification. This suggests that the emotional skills and processes required for coping with social and interpersonal frustrations are similar to those utilized for coping with the aggravation of goal-directed delay of gratification. Maternal attachment also influences the development of a child's ability to delay gratification. An interaction has been found between a mother's level of control and how close a child stays to the mother while exploring the environment. Children who have controlling mothers and explore their environment at a far distance from her are able to employ more cooling strategies and delay rewards longer. Similarly, children who stay close to a non-controlling mothers also use more cool strategies and demonstrate longer delays. This suggests that some children of controlling mothers have better learned how to distract themselves from or effectively avoid intrusive stimuli, although additional effects on their emotional competency are speculated but unknown. A greater capacity to delay gratification by using effective attentional strategies is also seen in preschoolers whose mothers had been responsive and supportive during particularly stressful times of self-regulation when the child was a toddler, indicating that maternal responsiveness during highly demanding times is crucial for the development of self-regulation, self-control and emotional competency.\n\nResearchers have investigated whether the reliability of the reward affects one's ability to delay gratification. Reliability of the reward refers to how well the reward received matches what the person was expecting or promised in terms of quality and quantity. For example, researchers told children that they would receive better art supplies if they waited. After the children successfully waited for the reward, better supplies could not be \"found\" and so they had to use the crayons and stickers that were in poor shape. Comparing these children to ones who received their promised rewards reliably revealed different results on subsequent Marshmallow tests measuring delayed gratification. Children who had learned that the researcher's promise was unreliable quickly succumbed to eating the marshmallow, waiting only an average of three minutes. Conversely, children who had learned that the researcher was reliable were able to wait an average of 12 minutes, with many of them waiting the full 15 minutes for the researcher to return in order to double the reward to two marshmallows.\n\nEvolutionary theory can argue against the selection of the deferred gratification trait since there are both costs and risks associated with delaying gratification behavior. One such cost is the basic opportunity cost associated with time spent waiting. While waiting, individuals lose time that could be used to find other food. Seeking high calorie food conveys a clear evolutionary advantage. There are also two risks associated with being patient. First, there is a risk that another animal might get to the food first, also known as an interruption risk. Second, there is the risk that the chance to get the reward will be cut short, perhaps by a predator, also known as a termination risk. These costs and risks create situations in which the fitness of the individual is threatened. There are several examples that show how reward delay occurs in the real world. For example, animals that eat fruit have the option of eating unripe fruit right away, or waiting, delaying gratification, until it becomes ripe. The interruption risk plays a part here, because if the individual forgoes the unripe fruit, there is a chance that another individual may come along and get to it first. Also, in extractive foraging, such as with nuts and shellfish, the outer shell creates a delay. However, animals that can store food and defer eating are more likely to survive during harsh conditions, and thus delaying gratification may also incur an evolutionary advantage.\n\nIt is likely that there is a strong genetic component to deferred gratification, though no direct link has been established. Since many complex genetic interactions are necessary for neurons to perform the simplest tasks, it is hard to isolate one gene to study this behavior. For this same reason, multiple genes are likely responsible for deferred gratification. Further research is necessary to discover the genetic corollaries to delayed gratification.\n\nDelayed gratification or deferred gratification is an animal behavior that can be linked to delay discounting, ecological factors, individual fitness, and neurobiological mechanisms. Research for this behavior has been conducted with animals such as capuchin monkeys, tamarins, marmosets, rats, and pigeons.\n\nWhen animals are faced with a choice to either wait for a reward, or receive a reward right away, the discounting of the reward is hyperbolic. As the length of time of waiting for a reward increases, the reward is discounted at a gradual rate. Empirical data have suggested that exponential discounting, rewards discounting at a constant rate per unit of waiting time, only occurs when there are random interruptions in foraging. Discounting can also be related to the risk sensitivity of animals. Rather than relating risk to delay, risk sensitivity acts as a function of delay discounting. In a study conducted by Haden and Platt, macaque monkeys were given the choice of a medium reward that they knew they would receive, versus a more risky choice. The riskier choice would reward the monkey with a large reward fifty percent of the time, and a small reward the other fifty percent. The ultimate payoff was the same, but the monkeys preferred the riskier choice. They speculated that the monkeys did not see their action as risky, but rather as a large, delayed reward. They reasoned that the monkeys viewed the large reward as certain: if they did not get the large reward the first time around, they would eventually get it, but at a longer delay.\nTo test for this theory, they gave the same test while varying the time between the opportunities to choose a reward. They found that as the interval increased, the number of times that the monkeys chose the more risky reward decreased. While this occurred in macaque monkeys, the varying interval time did not affect pigeons' choices in another study. This suggests that research looking into varying risk sensitivity of different species is needed. When provided a choice between a small, short delay reward, and a large, long delay reward, there is an impulsive preference for the former. Additionally, as the delay time for the small/short and large/long reward increases, there is a shift in preference toward the larger, delayed reward. This evidence only supports hyperbolic discounting, not exponential.\n\nAlthough predicting reward preference seems simple when using empirical models, there are a number of ecological factors that seem to affect the delayed gratification behavior of animals. In real world situations, \"discounting makes sense because of the inherent uncertainty of future payoffs\".\n\nOne study looked at how reward discounting is context specific. By differing the time and space between small and large rewards, they were able to test how these factors affected the decision making in tamarins and marmosets. They showed that tamarins will travel longer distances for larger food rewards, but will not wait as long as marmosets. Conversely, marmosets will wait longer, but will not travel as far. They then concluded that this discounting behavior directly correlates to the normal feeding behavior of species. The tamarins feed over large distances, looking for insects. Capturing and eating insects requires a quick and impulsive decision and action. The marmosets, on the other hand, eat tree sap, which takes more time to secrete, but does not require that the marmosets to cover large distances.\n\nThe physiological similarities between humans and other animals, especially primates, have led to more comparative research between the two groups. Future research with animal models then can expand our own understanding of how people make decisions about instant versus delayed gratification in the real world.\n\n"}
{"id": "57025458", "url": "https://en.wikipedia.org/wiki?curid=57025458", "title": "Extensive category", "text": "Extensive category\n\nIn mathematics, an extensive category is a category \"C\" with finite coproducts that are disjoint and well-behaved with respect to pullbacks. Equivalently, \"C\" is extensive if the coproduct functor from the product of the slice categories \"C\"/\"X\" × \"C\"/\"Y\" to the slice category \"C\"/(\"X\" + \"Y\") is an equivalence of categories for all objects \"X\" and \"Y\" of \"C\".\n\nThe categories Set and Top of sets and topological spaces, respectively, are extensive categories. More generally, the category of presheaves on any small category is extensive.\n\nThe category CRing of affine schemes is extensive.\n"}
{"id": "43417032", "url": "https://en.wikipedia.org/wiki?curid=43417032", "title": "Extraterritorial operation", "text": "Extraterritorial operation\n\nAn extraterritorial operation in international law is a law enforcement or military operation conducted outside the territory or jurisdiction of the state of the forces in operation, generally within the territory of another sovereign state. Under international law, these activities are generally highly restricted, and it is considered a violation of a state's sovereignty if any other state engages in law enforcement or military operations within another state without gaining that state's consent:\nThe policing of transnational and international crimes is a challenge to state-based law enforcement agencies, as jurisdiction restricts the direct intervention a state's agencies can legally take in another state's jurisdiction, with even basic law enforcement activities such as arrest and detention \"tantamount to abduction\" when carried out extraterritorially. These explicit limits on extraterritorial law enforcement operations has therefore instead encouraged co-operation between law enforcement agencies of sovereign states, forming supranational agencies such as Interpol to encourage co-operation, and placing additional obligations on the state such as \"aut dedere aut judicare\" (\"extradite or prosecute\") to compel prosecution of certain types of transnational crime, including hijacking of civilian aircraft, taking of civilian hostages, and other acts of terrorism, as well as crimes against diplomats and other \"internationally protected persons\".\n\nWhile extraterritorial law enforcement activity is highly restricted and subject to the approval of the 'host' state, traditional interstate military operations assume some degree of extraterritorial operation. As Stigall points out, innate in 'just' war (\"jus ad bellum\") is the expectation that one state may be conducting military activity against, and within the borders, of another state; the laws of armed conflict \"[presuppose] extraterritoriality\". Therefore, \"[i]f the circumstances exist for the \nlawful use of force under \"jus ad bellum\", then so long as a state abides by the rules articulated in \"jus in bello\" [the law of war], that state’s extraterritorial actions are considered lawful.\"\n\nProblems with the legitimacy of extraterritorial operations arise, according to Stigall, when one state is conducting military activity against non-state actors in a state \"that is not party to the conflict\". Although some commentators suggest that the use of force is permitted in some of these cases, with Deeks' commentary on the 'Unwilling or Unable Test' mentioning sources that recommend that \"neutrality law permits a belligerent to use force on a neutral state’s territory if the neutral state is unable or unwilling to prevent violations of its neutrality by another belligerent\", Stigall reminds \"that such view is not universal, and textual authority for such cross-border attacks is limited\".\n\nFor the European Union, key tenets of its human rights law jurisdiction are laid down in Article 1 of the European Convention on Human Rights (ECHR), with the convention employed to complement and reinforce the more specific scope of humanitarian law. The application of this to extraterritorial operations has been noted by Ryngaert as mixed, with \"Al-Skeini and others v United Kingdom\" in 2011 attempting \"to square \"Bankovic \"[\"v. Belgium\"'s \"sufficient control\" model of jurisdiction] with the personal model of jurisdiction\", and \"Al-Jedda v United Kingdom\" \"tried to reconcile the ‘ultimate control and authority’ standard... with the ‘effective operational control’ standard endorsed by the UN’s International Law Commission.\" Ryngaert declares each of the two results to be \"an awkward hybrid theory\".\n\n"}
{"id": "6515803", "url": "https://en.wikipedia.org/wiki?curid=6515803", "title": "Free will in theology", "text": "Free will in theology\n\nFree will in theology is an important part of the debate on free will in general. Religions vary greatly in their response to the standard argument against free will and thus might appeal to any number of responses to the paradox of free will, the claim that omniscience and free will are incompatible.\n\nThe theological doctrine of divine foreknowledge is often alleged to be in conflict with free will, particularly in Calvinistic circles: if God knows exactly what will happen (right down to every choice a person makes), it would seem that the \"freedom\" of these choices is called into question.\n\nThis problem is related to the Aristotelian problem of the sea battle: tomorrow either there will or will not be a sea battle. According to the Law of excluded middle, there seems to be two options. If there will be sea battle, then it seems that it was true even yesterday that there would be one. Thus it is \"necessary\" that the sea battle will occur. If there will not be one, then, by similar reasoning, it is necessary that it will not occur. That means that the future, whatever it is, is completely fixed by past truths: true propositions about the future (a deterministic conclusion is reached: things could not have been any other way).\n\nHowever, some philosophers follow William of Ockham in holding that necessity and possibility are defined with respect to a given point in time and a given matrix of empirical circumstances, and so something that is merely possible from the perspective of one observer may be necessary from the perspective of an omniscient. Some philosophers follow Philo in holding that free will is a feature of a human's soul, and thus that non-human animals lack free will.\n\nJewish philosophy stresses that free will is a product of the intrinsic human soul, using the word \"neshama\" (from the Hebrew root \"n.sh.m.\" or .נ.ש.מ meaning \"breath\"), but the ability to make a free choice is through \"Yechida\" (from Hebrew word \"yachid\", יחיד, singular), the part of the soul that is united with God, the only being that is not hindered by or dependent on cause and effect (thus, freedom of will does not belong to the realm of the physical reality, and inability of natural philosophy to account for it is expected).\n\nIn Islam, the theological issue is not usually how to reconcile free will with God's foreknowledge but with God's \"jabr\" or divine commanding power. al-Ash'ari developed an \"acquisition\" or \"dual-agency\" form of compatibilism, in which human free will and divine \"jabr\" were both asserted, and which became a cornerstone of the dominant Ash'ari position. In Shia Islam, Ash'aris understanding of a higher balance toward predestination is challenged by most theologists. Free will, according to Islamic doctrine is the main factor for man's accountability in his/her actions throughout life. All actions committed by man's free will are said to be counted on the Day of Judgement because they are his/her own and not God's.\n\nThe philosopher Søren Kierkegaard claimed that divine omnipotence cannot be separated from divine goodness. As a truly omnipotent and good being, God could create beings with true freedom over God. Furthermore, God would voluntarily do so because \"the greatest good... which can be done for a being, greater than anything else that one can do for it, is to be truly free.\" Alvin Plantinga's \"free will defense\" is a contemporary expansion of this theme, adding how God, free will, and evil are consistent.\n\nThe biblical ground for free will lies in the fall into sin by Adam and Eve that occurred in their \"willfully chosen\" disobedience to God.\n\n\"Freedom” and \"free will\" can be treated as one because the two terms are commonly used as synonyms. However, there are widespread disagreements in definitions of the two terms. Because of these disagreements, Mortimer Adler found that a delineation of three kinds of freedom is necessary for clarity on the subject, as follows:\n\n(1) Circumstantial freedom is \"freedom from coercion or restraint\" that prevents acting as one wills.\n\n\n(2) Natural freedom (a.k.a. volitional freedom) is freedom to determine one’s own \"decisions or plans.\" Natural freedom is inherent in all people, in all circumstances, and \"\"without regard\" to any state of mind or character which they may or may not acquire in the course of their lives.\"\n\n\n(3) Acquired freedom is freedom \"to live as [one] ought to live,\" a freedom that requires a transformation whereby a person acquires a righteous, holy, healthy, etc. \"state of mind or character.\"\n\n\nMark R. Talbot, a \"classical Christian theist,\" views this acquired \"compatibilist freedom\" as the freedom that \"Scripture portrays as worth having.\"\n\nOpen theism denies that classical theism’s compatibilist \"freedom to choose to be righteous without the possibility of choosing otherwise.\" qualifies as true freedom. For open theism, true libertarian freedom is incompatibilist freedom. Regardless of factors, a person has the freedom to choose opposite alternatives. In open theist William Hasker’s words, regarding any action it is always \"\"within the agent’s power to perform the action and also in the agent’s power to refrain from the action\".\" Although open theism generally contradicts classical theism’s \"freedom to choose to be righteous without the possibility of choosing otherwise,\" Hasker allows that Jesus possessed and humans in heaven will possess such a freedom. Regarding Jesus, Hasker views Jesus as “a free agent,” but he also thinks that \"it was not really possible\" that Jesus would \"abort the mission.\" Regarding heaven, Hasker foresees that as the result of our choice we will be \"unable to sin\" because all sinful impulses will be gone.\n\nTheologians of the Roman Catholic Church universally embrace the idea of free will, but generally do not view free will as existing apart from or in contradiction to grace. According to the Roman Catholic Church \"To God, all moments of time are present in their immediacy. When therefore he establishes his eternal plan of \"predestination\", he includes in it each person's free response to his grace.\" The Council of Trent declared that \"the free will of man, moved and excited by God, can by its consent co-operate with God, Who excites and invites its action; and that it can thereby dispose and prepare itself to obtain the grace of justification. The will can resist grace if it chooses. It is not like a lifeless thing, which remains purely passive. Weakened and diminished by Adam's fall, free will is yet not destroyed in the race (Sess. VI, cap. i and v).\"\n\nSt. Augustine and St. Thomas Aquinas wrote extensively on free will, with Augustine focusing on the importance of free will in his responses to the Manichaeans, and also on the limitations of a concept of unlimited free will as denial of grace, in his refutations of Pelagius.\n\nThe Catechism of the Roman Catholic Church asserts that \"Freedom is the power, rooted in reason and will\". It goes on to say that \"God created man a rational being, conferring on him the dignity of a person who can initiate and control his own actions. God willed that man should be 'left in the hand of his own counsel,' so that he might of his own accord seek his Creator and freely attain his full and blessed perfection by cleaving to him.\"\" The section concludes with the role that grace plays, \"By the working of grace the Holy Spirit educates us in spiritual freedom in order to make us free collaborators in his work in the Church and in the world.\"\n\nLatin Christianity's views on free will and grace are often contrasted with predestination in Reformed Protestant Christianity, especially after the Counter-Reformation, but in understanding differing conceptions of free will it is just as important to understand the differing conceptions of the nature of God, focusing on the idea that God can be all-powerful and all-knowing even while people continue to exercise free will, because God transcends time.\n\nThe papal encyclical on human freedom, \"Libertas Praestantissimum\" by Pope Leo XIII (1888), seems to leave the question unresolved as to the relation between free will and determinism: whether the correct notion is the compatibilist one or the libertarian one. The quotations supporting compatibilism include the one from St. Thomas (footnote 4) near the end of paragraph 6, regarding the cause of evil (\"Whereas, when he sins, he acts in opposition to reason, is moved by another, and is the victim of foreign misapprehensions\"), and a similar passus suggesting a natural, cause-and-effect function of human will (\"harmony with his natural inclinations\", \"Creator of will\", \"by whom all things are moved in conformity with their nature\") near the end of paragraph 8 (when considering the problem of how grace can have effects on free will). On the other hand, metaphysical libertarianism – at least as a sort of possibility of reversing the direction of one's acting – is suggested by the reference to the well-known philosophical term \"metaphysical freedom\" at the beginning of paragraph 3 and, to an extent, a contrasting comparison of animals, which always act \"of necessity\", with human liberty, by means of which one can \"either act or not act, do this or do that\".\n\nCritique that seems more or less to support popular incompatibilistic views can be found in some papal documents especially in the 20th century, no \"explicit\" condemnation, however, of causal determinism in its most generic form can be found there. More often these documents focus on condemnation of physicalism/materialism and the stressing of significance of belief in soul, as a non-physical indivisible substance equipped with intellect and will, which decides human proceeding in a (perhaps imprecise) way.\n\nThe concept of free will is also of vital importance in the Oriental (or non-Chalcedonian) Churches, those in communion with the Coptic Orthodox Church of Alexandria. As in Judaism, free will is regarded as axiomatic. Everyone is regarded as having a free choice as to in what measure he or she will follow his or her conscience or arrogance, these two having been appointed for each individual. The more one follows one's conscience, the more it brings one good results, and the more one follows one's arrogance, the more it brings one bad results. Following only one's arrogance is sometimes likened to the dangers of falling into a pit while walking in pitch darkness, without the light of conscience to illuminate the path. Very similar doctrines have also found written expression in the Dead Sea Scrolls \"Manual of Discipline\", and in some religious texts possessed by the Beta Israel Jews of Ethiopia.\n\nThe Eastern (or Chalcedonian) Orthodox Church espouses a belief different from the Lutheran, Calvinist, and Arminian Protestant views. The difference is in the interpretation of original sin, alternatively known as \"ancestral sin,\" where the Orthodox do not believe in total depravity. The Orthodox reject the Pelagian view that the original sin did not damage human nature; they accept that the human nature is depraved, but despite man's fallenness the divine image he bears has not been destroyed.\n\nThe Orthodox Church holds to the teaching of synergy (συνεργός, meaning working together), which says that man has the freedom to, and must if he wants to be saved, choose to accept and work with the grace of God. St. John Cassian, a 4th-century Church Father and pupil of St. John Chrysostom, articulated this view and all the Eastern Fathers embraced it. He taught that \"Divine grace is necessary to enable a sinner to return unto God and live, yet man must first, of himself, desire and attempt to choose and obey God\", and that \"Divine grace is indispensable for salvation, but it does not necessarily need to precede a free human choice, because, despite the weakness of human volition, the will can take the initiative toward God.\".\n\nSome Orthodox Christians use the parable of a drowning man to plainly illustrate the teaching of synergy: God from the ship throws a rope to a drowning man, pulls him up, saving him, and the man, if he wants to be saved, must hold on tightly to the rope; explaining both that salvation is a gift from God and man cannot save himself, and that man must co-work (syn-ergo) with God in the process of salvation.\n\nFyodor Dostoevsky, the Russian Orthodox Christian novelist, suggested many arguments for and against free will. Famous arguments are found in \"The Grand Inquisitor\" chapter in \"The Brothers Karamazov\", and in his work \"Notes from Underground\". He also developed an argument that suicide, if irrational, is actually a validation of free will (see Kirilov in the Demons) novel. As for the argument presented in \"The Brothers Karamazov\"'s section \"The Rebellion\" that the suffering of innocents was not worth the price of free will, Dostoevsky appears to propose the idea of apocatastasis (or universal reconciliation) as one possible rational solution.\n\nIllustrating as it does that the human part in salvation (represented by holding on to the rope) must be preceded and accompanied by grace (represented by the casting and drawing of the rope), the image of the drowning man holding on to the rope cast and drawn by his rescuer corresponds closely to Roman Catholic teaching, which holds that God, who \"destined us in love to be his sons\" and \"to be conformed to the image of his Son\", includes in his eternal plan of \"predestination\" each person's free response to his grace.\n\nThe Roman Catholic Church holds to the teaching that \"by free will, (the human person) is capable of directing himself toward his true good … man is endowed with freedom, an outstanding manifestation of the divine image'.\" Man has free will either to accept or reject the grace of God, so that for salvation \"there is a kind of interplay, or synergy, between human freedom and divine grace\". \"Justification establishes cooperation between God's grace and man's freedom. On man's part it is expressed by the assent of faith to the Word of God, which invites him to conversion, and in the cooperation of charity with the prompting of the Holy Spirit who precedes and preserves his assent: 'When God touches man's heart through the illumination of the Holy Spirit, man himself is not inactive while receiving that inspiration, since he could reject it; and yet, without God's grace, he cannot by his own free will move himself toward justice in God's sight' (Council of Trent).\"\n\nGod has freely chosen to associate man with the work of his grace. the fatherly action of God is first on his own initiative, and then follows man's free acting through his collaboration. For Roman Catholics, therefore, human cooperation with grace is essential. When God establishes his eternal plan of 'predestination', he includes in it each person's free response to his grace, whether it is positive or negative: \"In this city, in fact, both Herod and Pontius Pilate, with the Gentiles and the peoples of Israel, gathered together against your holy servant Jesus, whom you anointed, to do whatever your hand and your plan had predestined to take place\" ().\n\nThe initiative comes from God, but it demands a free response from man: \"God has freely chosen to associate man with the work of his grace. the fatherly action of God is first on his own initiative, and then follows man's free acting through his collaboration\". \"Since the initiative belongs to God in the order of grace, no one can merit the initial grace of forgiveness and justification, at the beginning of conversion. Moved by the Holy Spirit and by charity, we can then merit for ourselves and for others the graces needed for our sanctification, for the increase of grace and charity, and for the attainment of eternal life.\"\n\nOrthodox theologian Vladimir Lossky has stated that the teaching of John Cassian, who in the East is considered a witness to Tradition, but who \"was unable to make himself correctly understood\", \"was interpreted, on the rational plane, as a semi-pelagianism, and was condemned in the West\".\nWhere the Roman Catholic Church defends the concept of faith and free will these are questioned in the East by the conclusions of the Second Council of Orange. This council is not accepted by the Eastern churches and the Roman Catholic Church's use of describing their position and St Cassian as Semi-Pelagian is also rejected.\n\nAlthough the Roman Catholic Church explicitly teaches that \"original sin does not have the character of a personal fault in any of Adam's descendants\", some Eastern Orthodox nevertheless claim that Roman Catholicism professes the teaching, which they attribute to Saint Augustine, that everyone bears not only the consequence, but also the guilt of Adam's sin.\n\nVarious Roman Catholic theologians identify Cassian as a teacher of the semipelagian heresy which was condemned by the Council of Orange. While the Orthodox do not apply the term semipelagian to their theology, they criticize the Roman Catholics for rejecting Cassian whom they accept as fully orthodox, and for holding that human consent to God's justifying action is itself an effect of grace, a position shared by Eastern Orthodox theologian Georges Florovsky, who says that the Eastern Orthodox Church \"always understood that God initiates, accompanies, and completes everything in the process of salvation\", rejecting instead the Calvinist idea of irresistible grace.\n\nRecently, some Roman Catholic theologians have argued that Cassian's writings should not be considered semipelagian. And scholars of other denominations too have concluded that Cassian's thought \"is not Semi-Pelagian\", and that he instead taught that \"salvation is, from beginning to end, the effect of God's grace\" and held that \"God's grace, not human free will, is responsible for 'everything which pertains to salvation' - even faith.\"\n\nThe Orthodox Church holds to the teaching of synergy (συνεργός, meaning working together), which says that man has the freedom to, and must if he wants to be saved, choose to accept and work with the grace of God. Once baptised the experience of his salvation and relationship with God is called theosis. Mankind has free will to accept or reject the grace of God. Rejection of the gifts of God is called blasphemy of the Holy Spirit (gifts of grace, faith, life). The first who defined this teaching was John Cassian, 4th-century Church Father, and a pupil of John Chrysostom, and all Eastern Fathers accept it. He taught that \"Divine grace is necessary to enable a sinner to return unto God and live, yet man must first, of himself, desire and attempt to choose and obey God\", and that \"Divine grace is indispensable for salvation, but it does not necessarily need to precede a free human choice, because, despite the weakness of human volition, the will can take the initiative toward God.\".\n\nSome Orthodox use an example of a drowning man to illustrate the teaching of synergy: God from the ship throws a rope to a drowning man, the man may take the rope if he wants to be saved, but he may decide not to take the rope and perish by his own will. Explaining both that salvation is a gift from God and man cannot save himself. That man must co-work (syn-ergo) with God in the process of salvation.\n\nChristians who were influenced by the teachings of Jacobus Arminius (such as Methodists) believe that while God is all-knowing and always knows what choices each person will make, and he still gives them the ability to choose or not choose everything, regardless of whether there are any internal or external factors contributing to that choice. \n\nLike John Calvin, Arminius affirmed total depravity, but Arminius believed that only prevenient grace allowed people to choose salvation:\n\nConcerning grace and free will, this is what I teach according to the Scriptures and orthodox consent: Free will is unable to begin or to perfect any true and spiritual good, without grace... This grace [\"prœvenit\"] goes before, accompanies, and follows; it excites, assists, operates that we will, and co operates lest we will in vain.\nPrevenient grace is divine grace which precedes human decision. It exists prior to and without reference to anything humans may have done. As humans are corrupted by the effects of sin, prevenient grace allows persons to engage their God-given free will to choose the salvation offered by God in Jesus Christ or to reject that salvific offer.\n\nThomas Jay Oord offers perhaps the most cogent free will theology presupposing prevenient grace. What he calls \"essential kenosis\" says God acts preveniently to give freedom/agency to all creatures. This gift comes from God's eternal essence, and is therefore necessary. God remains free in choosing how to love, but the fact that God loves and therefore gives freedom/agency to others is a necessary part of what it means to be divine.\n\nThis view is backed in the Bible with verses such as Luke 13:34, NKJV\n\nO Jerusalem, Jerusalem, the one who kills the prophets and stones those who are sent to her! How often I wanted to gather your children together, as a hen gathers her brood under her wings, but you were not willing!” \nHere we see Jesus lamenting that He is unable to save Jerusalem as they are not willing. We see that whilst Jesus wants to save Jerusalem He respects their choice to continue on in sin despite His will that they be saved.\n\n Lutherans believe that although humans have free will concerning civil righteousness, they cannot work spiritual righteousness without the Holy Spirit, since righteousness in the heart cannot be wrought in the absence of the Holy Spirit. In other words, humanity is free to choose and act in every regard except for the choice of salvation.\n\nLutherans also teach that sinners, while capable of doing works that are outwardly \"good,\" are not capable of doing works that satisfy God's justice. Every human thought and deed is infected with sin and sinful motives. For Luther himself, in his \"Bondage of the Will\", people are by nature endowed with free-will/free choice in regard to “goods and possessions” with which a person “has the right of using, acting, and omitting according to his Free-will.” However, in “God-ward” things pertaining to “salvation or damnation” people are in bondage “either to the will of God, or to the will of Satan.”\n\nAs found in Paul Althaus’ study of Luther’s theology, sin’s infection of every human thought and deed began with Adam’s fall into sin, the Original Sin. Adam’s fall was a “terrible example” of what “free will” will do unless God constantly motivates it to virtuous behavior. Humanity inherits Adam’s sin. Thus, in our “natural condition,” we have an inborn desire to sin because that is the person we are by birth. As Luther noted, “Adam sinned willingly and freely and from him a will to sin has been born into us so that we cannot sin innocently but only voluntarily.”\n\nThe controversial term \"liberum arbitrium\" was translated “free-will” by Henry Cole and “free will” remains in general use. However, the Rupp/Watson study of Luther and Erasmus chose “free choice” as the translation and provided a rationale. Luther used “free choice” (or “free-will”) to denote the fact that humans act “spontaneously” and with “a desirous willingness.” He also allowed “Free-will” as that “power” by which humans “can be caught by the Spirit” of God. However, he deplored the use of the term “Free-will” because it is too “grand, copious, and full.” Therefore, Luther held that the inborn faculty of “willingness” should be “called by some other term.”\n\nAlthough our wills are a function of and are in bondage to our inherited sinful desires, Luther insisted that we sin “voluntarily.” Voluntarily means that we sin of our own free will. We will to do what we desire. As long as we desire sin, our wills are only free for sin. This is Luther’s “bondage of the will” to sin. The sinner’s “will is bound, but it is and remains \"his\" will. He repeatedly and voluntarily acts according to it.” So it is, to be set free from sin and for righteousness requires a “rebirth through faith.” A rebirth of faith gives “true freedom from sin,” which is, wrote Luther, \"a liberty [freedom] to do good.”\n\nTo use a biblical word important to Luther, to be set free \"from\" sin and \"for\" righteousness requires a metanoia. Luther used Jesus’ image of the good and bad trees to depict the necessity of changing the person to change what a person wills and does. In Jesus’ image, “a good tree cannot bear bad fruit, and a bad tree cannot bear good fruit” (Matthew 7:18). Like the bad tree that can only produce bad fruit, before a rebirth through faith, people are in bondage to the sinful desires of their hearts. They can only will to do sin, albeit “spontaneously and with a desirous willingness.” Given his view of the human condition, Luther concluded that, without a rebirth, the “free choice” that all humans possess is “not free at all” because it cannot of itself free itself from its inherent bondage to sin.\n\nThus, Luther distinguished between different kinds of freedom: (a) by nature, a freedom to act as we will and (b) by rebirth through faith, a freedom to act righteously.\n\nOrthodox Lutheran theology holds that God made the world, including humanity, perfect, holy and sinless. However, Adam and Eve chose to disobey God, trusting in their own strength, knowledge, and wisdom. Consequently, people are saddled with original sin, born sinful and unable to avoid committing sinful acts. For Lutherans, original sin is the \"chief sin, a root and fountainhead of all actual sins.\"\n\nAccording to Lutherans, God preserves his creation, in doing so cooperates with everything that happens, and guides the universe. While God cooperates with both good and evil deeds, with evil deeds he does so only inasmuch as they are deeds, but not with the evil in them. God concurs with an act's effect, but he does not cooperate in the corruption of an act or the evil of its effect. Lutherans believe everything exists for the sake of the Christian Church, and that God guides everything for its welfare and growth.\n\nLutherans believe that the elect are predestined to salvation. Lutherans believe Christians should be assured that they are among the predestined. Lutherans believe that all who trust in Jesus alone can be certain of their salvation, for it is in Christ's work and his promises in which their certainty lies. According to Lutheranism, the central final hope of the Christian is \"the resurrection of the body and the life everlasting\" as confessed in the Apostles' Creed rather than predestination. Conversion or regeneration in the strict sense of the term is the work of divine grace and power by which man, born of the flesh, and void of all power to think, to will, or to do any good thing, and dead in sin is, through the gospel and holy baptism, taken from a state of sin and spiritual death under God's wrath into a state of spiritual life of faith and grace, rendered able to will and to do what is spiritually good and, especially, led to accept the benefits of the redemption which is in Christ Jesus.\n\nLutherans disagree with those that make predestination the source of salvation rather than Christ's suffering, death, and resurrection. Lutherans reject the Calvinist doctrine of the perseverance of the saints. Like both Calvinist camps, Lutherans view the work of salvation as monergistic in that \"the natural [that is, corrupted and divinely unrenewed] powers of man cannot do anything or help towards salvation\" (Formula of Concord: Solid Declaration, art. ii, par. 71), and Lutherans go further along the same lines as the Free Grace advocates to say that the recipient of saving grace need not cooperate with it. Hence, Lutherans believe that a true Christian (that is, a genuine recipient of saving grace) can lose his or her salvation, \"[b]ut the cause is not as though God were unwilling to grant grace for perseverance to those in whom He has begun the good work... [but that these persons] wilfully turn away...\" (Formula of Concord: Solid Declaration, art. xi, par. 42). Unlike Calvinists, Lutherans do not believe in a predestination to damnation. Instead, Lutherans teach eternal damnation is a result of the unbeliever's sins, rejection of the forgiveness of sins, and unbelief.\n\nThe Anabaptist movement was characterized by the fundamental belief in the free will of man. Many earlier movements such as Waldensians and others likewise held this viewpoint. Denominations today representing this view include Old Order Mennonites, Amish, and Conservative Mennonites.\n\nJohn Calvin ascribed “free will” to all people in the sense that they act “voluntarily, and not by compulsion.” He elaborated his position by allowing \"that man has choice and that it is self-determined” and that his actions stem from “his own voluntary choosing.”\n\nThe free will that Calvin ascribed to all people is what Mortimer Adler calls the “natural freedom” of the will. This freedom to will what one desires is inherent in all people.\n\nCalvin held this kind of inherent/natural free will in disesteem because unless people acquire the freedom to live as they ought by being transformed, they will desire and voluntarily choose to sin. “Man is said to have free will,” wrote Calvin, “because he acts voluntarily, and not by compulsion. This is perfectly true: but why should so small a matter have been dignified with so proud a title?” The glitch in this inherent/natural freedom of the will is that although all people have the “faculty of willing,” by nature they are unavoidably (and yet voluntarily without compulsion) under “the bondage of sin.”\n\nThe kind of free will that Calvin esteems is what Adler calls “acquired freedom” of the will, the freedom/ability “to live as [one] ought.” To possess acquired free will requires a change by which a person acquires a desire to live a life marked by virtuous qualities. As Calvin describes the change required for acquired freedom, the will “must be wholly transformed and renovated.”\n\nCalvin depicts this transformation as “a new heart and a new spirit (Ezek. 18:31).” It sets one free from “bondage to sin” and enables “piety towards God, and love towards men, general holiness and purity of life.”\n\nCalvinist Protestants embrace the idea of predestination, namely, that God chose who would be saved and who would be not saved prior to the creation. They quote Ephesians 1:4 \"For he chose us in him before the creation of the world to be holy and blameless in his sight\" and also 2:8 \"For it is by grace you are saved, through faith, and this not of yourselves, it is the gift of God.\" One of the strongest defenders of this theological point of view was the American Puritan preacher and theologian Jonathan Edwards.\n\nEdwards believed that indeterminism was incompatible with individual dependence on God and hence with his sovereignty. He reasoned that if individuals' responses to God's grace are contra-causally free, then their salvation depends partly on them and therefore God's sovereignty is not \"absolute and universal.\" Edwards' book \"Freedom of the Will\" defends theological determinism. In this book, Edwards attempts to show that libertarianism is incoherent. For example, he argues that by 'self-determination' the libertarian must mean either that one's actions including one's acts of willing are preceded by an act of free will or that one's acts of will lack sufficient causes. The first leads to an infinite regress while the second implies that acts of will happen accidentally and hence can't make someone \"better or worse, any more than a tree is better than other trees because it oftener happens to be lit upon by a swan or nightingale; or a rock more vicious than other rocks, because rattlesnakes have happened oftener to crawl over it.\"\n\nIt should not be thought that this view completely denies freedom of choice, however. It claims that man is free to act on his strongest moral impulse and volition, which is externally determined, but is not free to act contrary to them, or to alter them. Proponents, such as John L. Girardeau, have indicated their belief that moral neutrality is impossible; that even if it were possible, and one were equally inclined to contrary options, one could make no choice at all; that if one is inclined, however slightly, toward one option, then that person will necessarily choose that one over any others.\n\nSome non-Calvinist Christians attempt a reconciliation of the dual concepts of predestination and free will by pointing to the situation of God as Christ. In taking the form of a man, a necessary element of this process was that Jesus Christ lived the existence of a mortal. When Jesus was born he was not born with the omniscient power of God the Creator, but with the mind of a human child - yet he was still God in essence. The precedent this creates is that God is able to will the abandonment of His knowledge, or ignore knowledge, while remaining fully God. Thus it is not inconceivable that although omniscience demands that God knows what the future holds for individuals, it is within his power to deny this knowledge in order to preserve individual free will. Other theologians argue that the Calvinist-Edwardsean view suggests that if all human volitions are predetermined by God, then all actions dictated by fallen will of man necessarily satisfy His sovereign decree. Hence, it is impossible to act outside of God's perfect will, a conclusion some non-Calvinists claim poses a serious problem for ethics and moral theology.\n\nAn early proposal toward such a reconciliation states that God is, in fact, not aware of future events, but rather, being eternal, He is outside time, and sees the past, present, and future as one whole creation. Consequently, it is not as though God would know \"in advance\" that Jeffrey Dahmer would become guilty of homicide years prior to the event as an example, but that He was aware of it from all eternity, viewing all time as a single present. This was the view offered by Boethius in Book V of \"The Consolation of Philosophy\".\n\nCalvinist theologian Loraine Boettner argued that the doctrine of divine foreknowledge does not escape the alleged problems of divine foreordination. He wrote that \"what God foreknows must, in the very nature of the case, be as fixed and certain as what is foreordained; and if one is inconsistent with the free agency of man, the other is also. Foreordination renders the events certain, while foreknowledge presupposes that they are certain.\" Some Christian theologians, feeling the bite of this argument, have opted to limit the doctrine of foreknowledge if not do away with it altogether, thus forming a new school of thought, similar to Socinianism and process theology, called open theism.\n\nThis table summarizes three classical Protestant beliefs about free will.\n\nMormons or Latter-day Saints, believe that God has given all humans the gift of moral agency. Moral agency includes free will and agency. Proper exercise of unfettered choice leads to the ultimate goal of returning to God's presence. Having the choice to do right or wrong was important, because God wants a society of a certain type—those that comply with eternal laws. Before this Earth was created, this dispute over agency rose to the level that there was a \"war in heaven.\" Lucifer (who favored no agency) and his followers were cast out of heaven for rebelling against God's will. Many Mormon leaders have also taught that the battle in Heaven over agency is now being carried out on earth, where dictators, influenced by Satan, fight against freedom (or free agency) in governments contrary to the will of God.\n\nMormons also believe in a limited form of foreordination — not in deterministic, unalterable decrees, but rather in callings from God for individuals to perform specific missions in mortality. Those who are foreordained can reject the foreordination, either outright or by transgressing the laws of God and becoming unworthy to fulfill the call.\n\nThe New Church, or Swedenborgianism, teaches that every person has complete freedom to choose heaven or hell. Emanuel Swedenborg, upon whose writings the New Church is founded, argued that if God is love itself, people must have free will. If God is love itself, then He desires no harm to come to anyone: and so it is impossible that he would predestine anyone to hell. On the other hand, if God is love itself, then He must love things outside of Himself; and if people do not have the freedom to choose evil, they are simply extensions of God, and He cannot love them as something outside of Himself. In addition, Swedenborg argues that if a person does not have free will to choose goodness and faith, then all of the commandments in the Bible to love God and the neighbor are worthless, since no one can choose to do them - and it is impossible that a God who is love itself and wisdom itself would give impossible commandments.\n\nAs Hinduism is primarily a conglomerate of different religious traditions, there is no one accepted view on the concept of free will. Within the predominant schools of Hindu philosophy there are two main opinions. The Advaita (monistic) schools generally believe in a fate-based approach, and the Dvaita (dualistic) schools are proponents for the theory of free will. The different schools' understandings are based upon their conceptions of the nature of the supreme Being (see Brahman, Paramatma and Ishvara) and how the individual soul (atma or jiva) dictates, or is dictated by karma within the illusory existence of maya.\n\nIn both Dvaita and Advaita schools, and also in the many other traditions within Hinduism, there is a strong belief in destiny and that both the past and future are known, or viewable, by certain saints or mystics as well as by the supreme being (Ishvara) in traditions where Ishvara is worshipped as an \"all-knowing being\". In the Bhagavad Gita, the Avatar, Krishna says to Arjuna: \nHowever, this belief in destiny is not necessarily believed to rule out the existence of free will, as in some cases both free will and destiny are believed to exist simultaneously.\n\nThe Bhagavad Gita also states:\n\nThe six orthodox (astika) schools of thought in Hindu philosophy give differing opinions: In the Samkhya, for instance, matter is without any freedom, and soul lacks any ability to control the unfolding of matter. The only real freedom (\"kaivalya\") consists in realizing the ultimate separateness of matter and self. For the Yoga school, only Ishvara is truly free, and its freedom is also distinct from all feelings, thoughts, actions, or wills, and is thus not at all a freedom of will. The metaphysics of the Nyaya and Vaisheshika schools strongly suggest a belief in determinism, but do not seem to make explicit claims about determinism or free will.\n\nA quotation from Swami Vivekananda, a Vedantist, offers a good example of the worry about free will in the Hindu tradition.\nTherefore, we see at once that there cannot be any such thing as free-will; the very words are a contradiction, because will is what we know, and everything that we know is within our universe, and everything within our universe is moulded by conditions of time, space and causality. ... To acquire freedom we have to get beyond the limitations of this universe; it cannot be found here.\n\nHowever, Vivekananda's above quote can't be taken as a literal refutation of all free will, as Vivekanda's teacher, Ramakrishna Paramahansa used to teach that man is like a goat tied to a stake - the karmic debts and human nature bind him and the amount of free will he has is analogous to the amount of freedom the rope allows; as one progresses spiritually, the rope becomes longer.\n\nOn the other hand, Mimamsa, Vedanta, and the more theistic versions of Hinduism such as Shaivism and Vaishnavism have often emphasized the importance of free will. For example, in the Bhagavad Gita the living beings (jivas) are described as being of a \"higher nature\" who have the freedom to exploit the inferior material nature (prakrti):\nBesides these, O mighty-armed Arjuna, there is another, superior energy of Mine, which comprises the living entities who are exploiting the resources of this material, inferior nature. \n\nThe doctrine of Karma in Hinduism requires both that we pay for our actions in the past, and that our actions in the present be free enough to allow us to deserve the future reward or punishment that we will receive for our present actions. The Advaitin philosopher Chandrashekhara Bharati Swaminah puts it this way:\nFate is past karma, free-will is present karma. Both are really one, that is, karma, though they may differ in the matter of time. There can be no conflict when they are really one.\n\nFate, as I told you, is the resultant of the past exercise of your free-will. By exercising your free-will in the past, you brought on the resultant fate. By exercising your free-will in the present, I want you to wipe out your past record if it hurts you, or to add to it if you find it enjoyable. In any case, whether for acquiring more happiness or for reducing misery, you have to exercise your free-will in the present.\n\nDisputes about free will in Islam began with the Mu'tazili vs Hanbali disputes, with the Mu'tazili arguing that humans had \"qadar\", the capacity to do right or wrong, and thus deserved the reward or punishment they received, whereas Hanbali insisted on God's \"jabr\", or total power and initiative in managing all events. Schools that developed around earlier thinkers such as Abu Hanifa and al-Ash'ari searched for ways to explain how both human \"qadar\" and divine \"jabr\" could be asserted at the same time. Ash'ari develops a \"dual agency\" or \"acquisition\" account of free will in which every human action has two distinct agents. God creates the possibility of a human action with his divine \"jabr\", but then the human follows through and \"acquires\" the act, making it theirs and taking responsibility for it using their human \"qadar\".\n\nThe belief in free will (Hebrew: \"bechirah chofshit\" בחירה חפשית, \"bechirah\" בחירה) is axiomatic in Jewish thought, and is closely linked with the concept of reward and punishment, based on the Torah itself: \"I [God] have set before you life and death, blessing and curse: therefore choose life\" ( Deuteronomy 30:19).\n\nFree will is therefore discussed at length in Jewish philosophy, firstly as regards God's purpose in creation, and secondly as regards the closely related, resultant, paradox. The topic is also often discussed in connection with Negative theology, Divine simplicity and Divine Providence, as well as Jewish principles of faith in general.\n\nThe traditional teaching regarding the purpose of creation, particularly as influenced by Jewish mysticism, is that \"This world is like a corridor to the World to Come\". \"Man was created for the sole purpose of rejoicing in God, and deriving pleasure from the splendor of His Presence… The place where this joy may truly be derived is the World to Come, which was expressly created to provide for it; but the path to the object of our desires is this world...\" Free will is thus required by God's justice, “otherwise, Man would not be given or denied good for actions over which he had no control”.\n\nIt is further understood that in order for Man to have true free choice, he must not only have inner free will, but also an environment in which a choice between obedience and disobedience exists. God thus created the world such that both good and evil can operate freely, this is the meaning of the rabbinic maxim, \"All is in the hands of Heaven except the fear of Heaven\".\n\nAccording to Maimonides,\nIn rabbinic literature, there is much discussion as to the apparent contradiction between God's omniscience and free will. The representative view is that \"Everything is foreseen; yet free will is given\". Based on this understanding, the problem is formally described as a paradox, beyond our understanding.\nThe paradox is explained, but not resolved, by observing that God exists outside of time, and therefore, his knowledge of the future is exactly the same as his knowledge of the past and present. Just as his knowledge of the past does not interfere with man's free will, neither does his knowledge of the future. This distinction, between foreknowledge and predestination, is in fact discussed by Abraham ibn Daud.\n\nOne analogy here is that of time travel. The time traveller, having returned from the future, knows in advance what x will do, but while he knows what x will do, that knowledge does not cause x to do so: x had free will, even while the time traveller had foreknowledge. One objection raised against this analogy – and ibn Daud’s distinction – is that if x truly has free will, he may choose to act otherwise when the event in question comes to pass, and therefore the time traveller (or God) merely has knowledge of a \"possible\" event: even having seen the event, there is no way to know with certainty what x will do; see the view of Gersonides below. Further, the presence of the time traveller, may have had some chaotic effect on x's circumstances and choice, absent when the event comes to pass in the present.)\n\nAlthough the above discussion of the paradox represents the majority Rabbinic view, there are several major thinkers who resolve the issue by explicitly \"excluding\" human action from divine foreknowledge.\n\nBoth and Judah ha-Levi hold that \"the decisions of man precede God's knowledge\". Gersonides holds that God knows, beforehand, the choices open to each individual, but does not know which choice the individual, in his freedom, will make. Isaiah Horowitz takes the view that God cannot know which moral choices people will make, but that, nevertheless, this does not impair his perfection.\n\nIn line with this thinking, the teaching from \"Pirkei Avoth\" above, is then to be read as: \"Everything is \"observed\" (while - and no matter where - it happens), \"and\" (since the actor is unaware of being observed) free will is given \".\n\nThe existence of free will, and the paradox above (as addressed by either approach), is closely linked to the concept of \"Tzimtzum\". \"Tzimtzum\" entails the idea that God \"constricted\" his infinite essence, to allow for the existence of a \"conceptual space\" in which a finite, independent world could exist. This \"constriction\" made free will possible, and hence the potential to earn the World to Come.\n\nFurther, according to the first approach, it is understood that the Free-will Omniscience paradox provides a temporal parallel to the paradox inherent within \"Tzimtzum\". In granting free will, God has somehow \"constricted\" his foreknowledge, to allow for Man's independent action; He thus has foreknowledge and yet free will exists. In the case of \"Tzimtzum\", God has \"constricted\" his essence to allow for Man's independent existence; He is thus immanent and yet transcendent.\n\n\n\n\n"}
{"id": "11774223", "url": "https://en.wikipedia.org/wiki?curid=11774223", "title": "Function (engineering)", "text": "Function (engineering)\n\nIn engineering, a function is interpreted as a specific process, action or task that a system is able to perform.\n\nIn the lifecycle of engineering projects, there are usually distinguished subsequently: \"Requirements\" and \"Functional specification\" documents. The \"Requirements\" usually specifies the most important attributes of the requested system. In the \"Design specification\" documents, physical or software processes and systems are frequently the requested functions\n\nFor advertising and marketing of technical products, the number of functions they can perform is often counted and used for promotion. For example a calculator capable of the basic mathematical operations of addition, subtraction, multiplication, and division, would be called a \"four-function\" model; when other operations are added, for example for scientific, financial, or statistical calculations, advertisers speak of \"57 scientific functions\", etc. A wristwatch with stopwatch and timer facilities would similarly claim a specified number of functions. To maximise the claim, trivial operations which do not significantly enhance the functionality of a product may be counted.\n\n"}
{"id": "19809492", "url": "https://en.wikipedia.org/wiki?curid=19809492", "title": "Goodwin model (economics)", "text": "Goodwin model (economics)\n\nThe Goodwin model, sometimes called Goodwin’s class struggle model, is a model of endogenous economic fluctuations first proposed by the American economist Richard M. Goodwin in 1967. It combines aspects of the Harrod–Domar growth model with the Phillips curve to generate endogenous cycles in economic activity (output, unemployment, wages) unlike most modern macroeconomic models in which movements in economic aggregates are driven by exogenously assumed shocks. Since Goodwin’s publication in 1967 the model has been extended and applied in various ways.\n\nOutput is given by the aggregate production function\n\nwhere:\n\nAll of these variables are functions of time, though the time subscripts have been suppressed for convenience. \n\nUnlike in the Harrod–Domar model, full capital utilization is assumed. Hence\n\nat all times. The employment rate is given by\n\nwhere \"n\" is total labor force which grows at the rate \"β\". Additionally, labor productivity \"a\", is assumed to also increase at the rate \"α\". Note that in this case the rate of growth of the employment rate is given by\n\nThe growth rate of the absolute level of employment in turn is given by\n\nWages are assumed to change according to a linearized Phillips curve relationship given by\n\nIn other words, if the labor market is 'tight' (employment is already high) there is upward pressure on wages and vice versa in a 'lax' labor market. This is the aspect of the model that can loosely be associated with the \"class struggle\" portion of its name, however, this kind of Phillips curve can be found in many Macroeconomic models.\n\nThe workers' share in output is \"u\", which by definition is\n\nHence the growth rate of the workers' share is\n\nLabor's share in output increases with wages but declines with productivity growth as less workers are needed to produce the same amount of output.\n\nFinally we have the capital accumulation equation and the resulting growth rate for output (since k and q grow at the same rate by assumption of full utilization of capital and constant returns to scale). It is assumed that workers consume their wages and capital owners save a portion s of their profits (note that the model generalizes to the case where capitalists save more than workers) and that capital depreciates at the rate delta. The growth rate of output and capital is then given by\n\nThis in turn implies that\n\nThe two differential equations\n\nare the key equations of the model and in fact are the Lotka–Volterra equations (which are used in biology to model predator-prey interaction).\n\nWhile the model can be solved explicitly it is instructive to analyze the trajectory of the economy in terms of a phase diagram. Setting the two equations above equal to zero we get the values of \"u\" and \"v\" at which growth of \"v\" and growth \"u\", respectively, are zero.\n\nThese two lines (along with parameter restrictions which ensure that neither u nor v can go higher than 1) divide the positive orthant into four regions. The figure below indicates with arrows the movement of the economy in each region. For example the north-western region (high employment, low labor's share in output) the economy is moving north-east (employment is rising, worker's share is increasing). Once it crosses the u* line it will begin moving south-west.\n\nThe figure below illustrates the movement of potential output (output at full employment), actual output and wages over time.\n\nAs can be seen the Goodwin model can generate endogenous fluctuations in economic activity without relying on extraneous assumptions of outside shocks, whether on the demand or supply side.\n\nThe model has been applied and extended by many economists since its first presentation in 1967.\n\n\n"}
{"id": "409919", "url": "https://en.wikipedia.org/wiki?curid=409919", "title": "Historical race concepts", "text": "Historical race concepts\n\nThe concept of race as a rough division of anatomically modern humans (\"Homo sapiens\") has a long and complicated history. The word \"race\" itself is modern and was used in the sense of \"nation, ethnic group\" during the 16th to 19th century, and only acquired its modern meaning in the field of physical anthropology from the mid 19th century. The politicization of the field under the concept of racism in the 20th century led to a decline in racial studies during the 1930s to 1980s, culminating in a poststructuralist deconstruction of race as a social construct.\n\nThe word \"race\", interpreted to mean an identifiable group of people who share a common descent, was introduced into English in about 1580, from the Old French ' (1512), from Italian '. An earlier but etymologically distinct word for a similar concept was the Latin word \"\" meaning a group sharing qualities related to birth, descent, origin, race, stock, or family; this Latin word is cognate with the Greek words \"genos\", () meaning \"race or kind\", and \"gonos\", which has meanings related to \"birth, offspring, stock ...\".\n\nIn many ancient civilizations, individuals with widely varying physical appearances became full members of a society by growing up within that society or by adopting that society's cultural norms. (Snowden 1983; Lewis 1990).\n\nClassical civilizations from Rome to China tended to invest the most importance in familial or tribal affiliation than an individual's physical appearance (Dikötter 1992; Goldenberg 2003). Societies still tended to equate physical characteristics, such as hair and eye colour, with psychological and moral qualities, usually assigning the highest qualities to their own people and lower qualities to the \"Other\", either lower classes or outsiders to their society. For example, an historian of the 3rd century Han Dynasty in the territory of present-day China describes barbarians of blond hair and green eyes as resembling \"the monkeys from which they are descended\". (Gossett, pp. 4).\n\nDominant in ancient Greek and Roman conceptions of human diversity was the thesis that physical differences between different populations could be attributed to environmental factors. Though ancient peoples likely had no knowledge of evolutionary theory or genetic variability, their concepts of race could be described as malleable. Chief among environmental causes for physical difference in the ancient period were climate and geography. Though thinkers in ancient civilizations recognized differences in physical characteristics between different populations, the general consensus was that all non-Greeks were barbarians. This barbarian status, however, was not thought to be fixed; rather, one could shed the 'barbarian' status simply by adopting Greek culture. (Graves 2001)\n\nHippocrates of Cos believed, as many thinkers throughout early history did, that factors such as geography and climate played a significant role in the physical appearance of different peoples. He writes, \"the forms and dispositions of mankind correspond with the nature of the country\". He attributed physical and temperamental differences among different peoples to environmental factors such as climate, water sources, elevation and terrain. He noted that temperate climates created peoples who were \"sluggish\" and \"not apt for labor\", while extreme climates led to peoples who were \"sharp\", \"industrious\" and \"vigilant\". He also noted that peoples of \"mountainous, rugged, elevated, and well-watered\" countries displayed \"enterprising\" and \"warlike\" characteristics, while peoples of \"level, windy, and well-watered\" countries were \"unmanly\" and \"gentle\".\n\nThe Roman emperor Julian factored in the constitutions, laws, capacities, and character of peoples:\n\nEuropean medieval models of race generally mixed Classical ideas with the notion that humanity as a whole was descended from Shem, Ham and Japheth, the three sons of Noah, producing distinct Semitic (Asiatic), Hamitic (African), and Japhetic (Indo-European) peoples. This theory dates back to the Babylonian \"Talmud\", which states, \"the descendants of Ham are cursed by being black, and [it] depicts Ham as a sinful man and his progeny as degenerates.\"\n\nIn the 9th century, Al-Jahiz, an Afro-Arab Islamic philosopher, attempted to explain the origins of different human skin colors, particularly black skin, which he believed to be the result of the environment. He cited a stony region of black basalt in the northern Najd as evidence for his theory.\n\nIn the 14th century, the Islamic sociologist Ibn Khaldun, dispelled the Babylonian \"Talmud\"'s account of peoples and their characteristics as a myth. He wrote that black skin was due to the hot climate of sub-Saharan Africa and not due to the descendants of Ham being cursed.\n\nIndependently of Ibn Kaldun's work, the question of whether skin colour is heritable or a product of the environment is raised in 17th to 18th century European anthropology. \nGeorgius Hornius (1666) inherits the rabbinical view of heritability, while François Bernier (1684) argues for at least partial influence of the environment. \nIbn Khaldun's work was later translated into French, especially for use in Algeria, but in the process, the work was \"transformed from local knowledge to colonial categories of knowledge\". William Desborough Cooley'1s \"The Negro Land of the Arabs Examined and Explained\" (1841) has excerpts of translations of Khaldun's work that were not affected by French colonial ideas. For example, Cooley quotes Khaldun's describing the great African civilization of Ghana (in Cooley's translation):\n\nIbn Khaldun suggests a link between the rise of the Almoravids and the decline of Ghana. But, historians have found virtually no evidence for an Almoravid conquest of Ghana.\n\nScientists who were interested in natural history, including biological and geological scientists, were known as \"naturalists\". They would collect, examine, describe, and arrange data from their explorations into categories according to certain criteria. People who were particularly skilled at organizing specific sets of data in a logically and comprehensive fashion were known as classifiers and systematists. This process was a new trend in science that served to help answer fundamental questions by collecting and organizing materials for systematic study, also known as taxonomy.\n\nAs the study of natural history grew, so did society's effort to classify human groups. Some zoologists and scientists wondered what made humans different from animals in the primate family. Furthermore, they contemplated whether homo sapiens should be classified as one species with multiple varieties or separate species. In the 16th and 17th century, scientists attempted to classify \"Homo sapiens\" based on a geographic arrangement of human populations based on skin color, others simply on geographic location, shape, stature, food habits, and other distinguishing characteristics. Occasionally the term \"race\" was used but most of the early taxonomist used classificatory terms such as \"peoples\", \"nations\", \"types\", \"varieties\", and \"species\".\n\nItalian philosopher Giordano Bruno (1548–1600) and Jean Bodin (1530–1596), French philosopher, attempted a rudimentary geographic arrangement of known human populations based on skin color. Bodin's color classifications were purely descriptive, including neutral terms such as \"duskish colour, like roasted quinze\", \"black\", \"chestnut\", and \"farish white\".\n\nGerman and English scientists, Bernhard Varen (1622–1650) and John Ray (1627–1705) classified human populations into categories according to stature, shape, food habits, and skin color, along with any other distinguishing characteristics.\nRay was also the first person to produce a biological definition of species.\n\nFrançois Bernier (1625–1688) is believed to have developed the first comprehensive classification of humans into distinct races which was published in a French journal article in 1684, \"Nouvelle division de la terre par les différentes espèces ou races l'habitant\", New division of Earth by the different species or races which inhabit it. (Gossett, 1997:32–33). Bernier advocated using the \"four quarters\" of the globe as the basis for providing labels for human differences. The four subgroups that Bernier used were Europeans, Far Easterners, Negroes (blacks), and Lapps.\n\nAs noted earlier, scientists attempted to classify \"Homo sapiens\" based on a geographic arrangement of human populations. Some based their hypothetical divisions of race on the most obvious physical differences, like skin color, while others used geographic location, shape, stature, food habits, and other distinguishing characteristics to delineate between races. However, cultural notions of racial and gender superiority tainted early scientific discovery. In the 18th century, scientists began to include behavioral or psychological traits in their reported observations—which traits often had derogatory or demeaning implications—and researchers often assumed that those traits were related to their race, and therefore, innate and unchangeable. Other areas of interest were to determine the exact number of races, categorize and name them, and examine the primary and secondary causes of variation between groups.\n\nThe Great Chain of Being, a medieval idea that there was a hierarchical structure of life from the most fundamental elements to the most perfect, began to encroach upon the idea of race. As taxonomy grew, scientists began to assume that the human species could be divided into distinct subgroups. One's \"race\" necessarily implied that one group had certain character qualities and physical dispositions that differentiated it from other human populations. Society assigned different values to those differentiations, as well as other, more trivial traits (a man with a strong chin was assumed to possess a stronger character than men with weaker chins). This essentially created a gap between races by deeming one race superior or inferior to another race, thus creating a hierarchy of races. In this way, science was used as justification for unfair treatment of different human populations.\n\nThe systematization of race concepts during the Enlightenment period brought with it the conflict between monogenism (a single origin for all human races) and polygenism (the hypothesis that races had separate origins). This debate was originally cast in creationist terms as a question of one versus many creations of humanity, but continued after evolution was widely accepted, at which point the question was given in terms of whether humans had split from their ancestral species one or many times.\n\nJohann Friedrich Blumenbach (1752–1840) divided the human species into five races in 1779, later founded on crania research (description of human skulls), and called them (1793/1795):\n\nBlumenbach's classification of the Mongolian race included all East Asians and some Central Asians as well as the Inuit (Eskimos) of the American arctic, excluding peoples of Southeast Asian islands and Pacific Islanders, which were categorized in a separate Malayan race. Blumenbach's American race comprised most peoples of the Americas (excepting the polar region) and of the Caribbean.\n\nBlumenbach argued that physical characteristics like skin color, cranial profile, etc., were depended on geography and nutrition and custom.\nBlumenbach's work included his description of sixty human crania (skulls) published originally in fascicules as \"Decas craniorum\" (Göttingen, 1790–1828). This was a founding work for other scientists in the field of craniometry.\n\nFurther anatomical study led him to the conclusion that 'individual Africans differ as much, or even more, from other individual Africans as Europeans differ from Europeans'. Furthermore, he concluded that Africans were not inferior to the rest of mankind 'concerning healthy faculties of understanding, excellent natural talents and mental capacities'.\n\"Finally, I am of opinion that after all these numerous instances I have brought together of negroes of capacity, it would not be difficult to mention entire well-known provinces of Europe, from out of which you would not easily expect to obtain off-hand such good authors, poets, philosophers, and correspondents of the Paris Academy; and on the other hand, there is no so-called savage nation known under the sun which has so much distinguished itself by such examples of perfectibility and original capacity for scientific culture, and thereby attached itself so closely to the most civilized nations of the earth, as the Negro.\"\nThese five groups saw some continuity in the various classification schemes of the 19th century, in some cases augmented, e.g. by the Australoid race and the Capoid race in some cases the Mongolian (East Asian) and American collapsed into a single group.\n\nAmong the 19th century naturalists who defined the field were Georges Cuvier, James Cowles Pritchard, Louis Agassiz, Charles Pickering (\"Races of Man and Their Geographical Distribution\", 1848). Cuvier enumerated three races, Pritchard seven, Agassiz twelve, and Pickering eleven.\n\nThe 19th century saw attempts to change race from a taxonomic to a biological concept. For example, using anthropometrics, invented by Francis Galton and Alphonse Bertillon, they measured the shapes and sizes of skulls and related the results to group differences in intelligence or other attributes (Lieberman 2001).\n\nThese scientists made three claims about race: first, that races are objective, naturally occurring divisions of humanity; second, that there is a strong relationship between biological races and other human phenomena (such as forms of activity and interpersonal relations and culture, and by extension the relative material success of cultures), thus biologizing the notion of \"race\", as Foucault demonstrated in his historical analysis; third, that race is therefore a valid scientific category that can be used to explain and predict individual and group behavior. Races were distinguished by skin color, facial type, cranial profile and size, texture and color of hair. Moreover, races were almost universally considered to reflect group differences in moral character and intelligence.\n\nStefan Kuhl wrote that the eugenics movement rejected the racial and national hypotheses of Arthur Gobineau and his writing \"An Essay on the Inequality of the Human Races\". According to Kuhl, the eugenicists believed that nations were political and cultural constructs, not race constructs, because nations were the result of race mixtures. Vacher de Lapouge's \"anthroposociology\", asserted as self-evident the biological inferiority of particular groups (Kevles 1985). In many parts of the world, the idea of race became a way of rigidly dividing groups by culture as well as by physical appearances (Hannaford 1996). Campaigns of oppression and genocide were often motivated by supposed racial differences (Horowitz 2001).\n\nDuring the late 19th century and early 20th century, the tension between some who believed in hierarchy and innate superiority, and others who believed in human equality, was at a paramount. The former continued to exacerbate the belief that certain races were innately inferior by examining their shortcomings, namely by examining and testing intelligence between groups. Some scientists claimed that there was a biological determinant of race by evaluating one's genes and DNA. Different methods of eugenics, the study and practice of human selective breeding often with a race as a primary concentration, was still widely accepted in Britain, Germany, and the United States. On the other hand, many scientists understood race as a social construct. They believed that the phenotypical expression of an individual were determined by one's genes that are inherited through reproduction but there were certain social constructs, such as culture, environment, and language that were primary in shaping behavioral characteristics. Some advocated that race 'should centre not on what race explains about society, but rather on the questions of who, why and with what effect social significance is attached to racial attributes that are constructed in particular political and socio-economic contexts', and thus, addressing the \"folk\" or \"mythological representations\" of race.\n\nAfter Louis Agassiz (1807–1873) traveled to the United States, he became a prolific writer in what has been later termed the genre of scientific racism. Agassiz was specifically a believer and advocate in polygenism, that races came from separate origins (specifically separate creations), were endowed with unequal attributes, and could be classified into specific climatic zones, in the same way he felt other animals and plants could be classified.\n\nThese included Western American Temperate (the indigenous peoples west of the Rockies); Eastern American Temperate (east of the Rockies); Tropical Asiatic (south of the Himalayas); Temperate Asiatic (east of the Urals and north of the Himalayas); South American Temperate (South America); New Holland (Australia); Arctic (Alaska and Arctic Canada); Cape of Good Hope (South Africa); and American Tropical (Central America and the West Indies).\n\nAgassiz denied that species originated in single pairs, whether at a single location or at many. He argued instead multiple individuals in each species were created at the same time and then distributed throughout the continents where God meant for them to dwell. His lectures on polygenism were popular among the slaveholders in the South, for many this opinion legitimized the belief in a lower standard of the Negro.\n\nHis stance in this case was considered to be quite radical in its time, because it went against the more orthodox and standard reading of the Bible in his time which implied all human stock descended from a single couple (Adam and Eve), and in his defense Agassiz often used what now sounds like a very \"modern\" argument about the need for independence between science and religion; though Agassiz, unlike many polygeneticists, maintained his religious beliefs and was not anti-Biblical in general.\n\nIn the context of ethnology and anthropology of the mid-19th century, Agassiz's polygenetic views became explicitly seen as opposing Darwin's views on race, which sought to show the common origin of all human races and the superficiality of racial differences. Darwin's second book on evolution, The Descent of Man, features extensive argumentation addressing the single origin of the races, at times explicitly opposing Agassiz's theories.\n\nArthur de Gobineau (1816–1882) was a successful diplomat for the French Second Empire. Initially he was posted to Persia, before working in Brazil and other countries. He came to believe that race created culture, arguing that distinctions between the three \"black\", \"white\", and \"yellow\" races were natural barriers, and that \"race-mixing\" breaks those barriers and leads to chaos. He classified the Middle East, Central Asia, the Indian subcontinent, North Africa, and southern France as racially mixed.\n\nGobineau believed the white race was superior to the others. He thought it corresponded to the ancient Indo-European culture, also known as \"Aryan\". Gobineau originally wrote that white race miscegenation was inevitable. He attributed much of the economic turmoils in France to pollution of races. Later on in his life, he altered his opinion to believe that the white race could be saved.\n\nTo Gobineau, the development of empires was ultimately destructive to the \"superior races\" that created them, since they led to the mixing of distinct races. This he saw as a degenerative process.\n\nAccording to his definitions, the people of Spain, most of France, most of Germany, southern and western Iran as well as Switzerland, Austria, northern Italy, and a large part of Britain, consisted of a degenerative race arising from miscegenation. Also according to him, the whole of north India consisted of a yellow race.\n\nThomas Huxley (1825 –1895) wrote one paper, \"On the Geographical Distribution of the Chief Modifications of Mankind\" (1870), in which he proposed a distinction within the human species ('races'), and their distribution across the earth. He also acknowledged that certain geographical areas with more complex ethnic compositions, including much of the Horn of Africa and the India subcontinent, did not fit into his racial paradigm. As such, he noted that: \"I have purposely omitted such people as the Abyssinians and the Hindoos, who there is every reason to believe result from the intermixture of distinct stocks.\" By the late nineteenth century, Huxley's Xanthochroi group had been redefined as the Nordic race, whereas his Melanochroi became the Mediterranean race. His Melanochroi thus eventually also comprised various other dark Caucasoid populations, including the Hamites (e.g. Berbers, Somalis, northern Sudanese, ancient Egyptians) and Moors.\n\nHuxley's paper was rejected by the Royal Society, and this became one of the many theories to be advanced and dropped by the early exponents of evolution.\n\nDespite rejection by Huxley and the science community, the paper is sometimes cited in support of racialism. Along with Darwin, Huxley was a monogenist, the belief that all humans are part of the same species, with morphological variations emerging out of an initial uniformity. (Stepan, p. 44). This view contrasts polygenism, the theory that each race is actually a separate species with separate sites of origin.\n\nDespite Huxley's monogenism and his abolitionism on ethical grounds, Huxley assumed a hierarchy of innate abilities, a stance evinced in papers such as \"Emancipation Black and White\" and his most famous paper, \"Evolution and Ethics\".\n\nIn the former, he writes that the \"highest places in the hierarchy of civilization will assuredly not be within the reach of our dusky cousins, though it is by no means necessary that they should be restricted to the lowest\". (Stepan, p. 79–80).\nThough Charles Darwin's evolutionary theory was set forth in 1859 upon publication of \"On the Origin of Species\", this work was largely absent of explicit reference to Darwin’s theory applied to man. This application by Darwin would not become explicit until 1871 with the publication of his second great book on evolution, \"The Descent of Man, and Selection in Relation to Sex\".\n\nDarwin's publication of this book occurred within the heated debates between advocates of monogeny, who held that all races came from a common ancestor, and advocates of polygeny, who held that the races were separately created. Darwin, who had come from a family with strong abolitionist ties, had experienced and was disturbed by cultures of slavery during his voyage on the Beagle years earlier. Noted Darwin biographers Adrian Desmond and James Moore argue that Darwin's writings on evolution were not only influenced by his abolitionist tendencies, but also his belief that non-white races were equal in regard to their intellectual capacity as white races, a belief which had been strongly disputed by scientists such as Morton, Agassiz and Broca, all noted polygenists.\n\nBy the late 1860s, however, Darwin's theory of evolution had been thought to be compatible with the polygenist thesis (Stepan 1982). Darwin thus used \"Descent of Man\" to disprove the polygenist thesis and end the debate between polygeny and monogeny once and for all. Darwin also used it to disprove other hypotheses about racial difference that had persisted since the time of ancient Greece, for example, that differences in skin color and body constitution occurred because of differences of geography and climate.\n\nDarwin concluded, for example, that the biological similarities between the different races were \"too great\" for the polygenist thesis to be plausible. He also used the idea of races to argue for the continuity between humans and animals, noting that it would be highly implausible that man should, by mere accident acquire characteristics shared by many apes.\n\nDarwin sought to demonstrate that the physical characteristics that were being used to define race for centuries (i.e. skin color and facial features) were superficial and had no utility for survival. Because, according to Darwin, any characteristic that did not have survival value could not have been naturally selected, he devised another hypothesis for the development and persistence of these characteristics. The mechanism Darwin developed is known as sexual selection.\n\nThough the idea of sexual selection had appeared in earlier works by Darwin, it was not until the late 1860s when it received full consideration (Stepan 1982). Furthermore, it was not until 1914 that sexual selection received serious consideration as a racial theory by naturalist thinkers.\n\nDarwin defined sexual selection as the \"struggle between individuals of one sex, generally the males, for the possession of the other sex\". Sexual selection consisted of two types for Darwin: 1.) The physical struggle for a mate, and 2.) The preference for some color or another, typically by females of a given species. Darwin asserted that the differing human races (insofar as race was conceived phenotypically) had arbitrary standards of ideal beauty, and that these standards reflected important physical characteristics sought in mates.\n\nBroadly speaking, Darwin's attitudes of what race was and how it developed in the human species are attributable to two assertions, 1.) That all human beings, regardless of race share a single, common ancestor and 2.) Phenotypic racial differences are superficially selected, and have no survival value. Given these two beliefs, some believe Darwin to have established monogenism as the dominant paradigm for racial ancestry, and to have defeated the scientific racism practiced by Morton, Knott, Agassiz et. Al, as well as notions that there existed a natural racial hierarchy that reflected inborn differences and measures of value between the different human races.\nNevertheless, he stated: \"The various races, when carefully compared and measured, differ much from each other – as in the texture of hair, the relative proportions of all parts of the body, the capacity of the lungs, the form and capacity of the skull, and even the convolutions of the brain. But it would be an endless task to specify the numerous points of difference. The races differ also in constitution, in acclimatization and in liability to certain diseases. Their mental characteristics are likewise very distinct; chiefly as it would appear in their emotion, but partly in their intellectual faculties.\" (\"The Descent of Man\", chapter VII).\n\nIn \"The Descent of Man\", Darwin noted the great difficulty naturalists had in trying to decide how many \"races\" there actually were:\nMan has been studied more carefully than any other animal, and yet there is the greatest possible diversity amongst capable judges whether he should be classed as a single species or race, or as two (Virey), as three (Jacquinot), as four (Kant), five (Blumenbach), six (Buffon), seven (Hunter), eight (Agassiz), eleven (Pickering), fifteen (Bory St. Vincent), sixteen (Desmoulins), twenty-two (Morton), sixty (Crawfurd), or as sixty-three, according to Burke. This diversity of judgment does not prove that the races ought not to be ranked as species, but it shews that they graduate into each other, and that it is hardly possible to discover clear distinctive characters between them.\n\nSeveral social and political developments that occurred at the end of the 19th century and into the 20th century led to the transformation in the discourse of race. Three movements that historians have considered are: the coming of mass democracy, the age of imperialist expansion, and the impact of Nazism. More than any other, the violence of Nazi rule, the Holocaust, and World War II transformed the whole discussion of race. Nazism made an argument for racial superiority based on a biological basis. This led to the idea that people could be divided into discrete groups and based on the divisions, there would be severe, tortuous, and often fatal consequence. The exposition of racial theory beginning in the Third Reich, up to the Final Solution, created a popular moral revolution against racism. In 1950, and as a response to the genocide of Nazism, UNESCO was formed and released a statement saying that there was no biological determinant or basis for race.\n\nConsequently, studies of human variation focused more on actual patterns of variation and evolutionary patterns among populations and less about classification. Some scientists point to three discoveries. Firstly, African populations exhibit greater genetic diversity and less linkage disequilibrium because of their long history. Secondly, genetic similarity is directly correlated with geographic proximity. Lastly, some loci reflect selection in response to environmental gradients. Therefore, some argue, human racial groups do not appear to be distinct ethnic groups.\n\nFranz Boas (1858–1942) was a German American anthropologist and has been called the \"Father of American Anthropology\". Boas made significant contributions within anthropology, more specifically, physical anthropology, linguistics, archaeology, and cultural anthropology. His work put an emphasis on cultural and environmental effects on people to explain their development into adulthood and evaluated them in concert with human biology and evolution. This encouraged academics to break away from static taxonomical classifications of race. It is said that before Boas, anthropology was the study of race, and after Boas, anthropology was the study of culture.\n\nSir Julian Sorell Huxley (1887–1975) was an English evolutionary biologist, humanist and internationalist. After returning to England from a tour of the United States in 1924, Huxley wrote a series of articles for the \"Spectator\" which he expressed his belief in the drastic differences between \"negros\" and \"whites\". He believed that the color of \"blood\" – percentage of 'white' and 'black' blood – that a person had would determine a person's mental capacity, moral probity, and social behavior. \"Blood\" also determined how individuals should be treated by society. He was a proponent of racial inequality and segregation.\n\nBy 1930, Huxley's ideas on race and inherited intellectual capacity of human groups became more liberal. By the mid-1930s, Huxley was considered one of the leading antiracist and committed much of his time and efforts into publicizing the fight against Nazism.\n\nAlfred Cort Haddon (1855–1940) was a British anthropologist and ethnologist.\n\nIn 1935, Huxley and A. C. Haddon wrote, \"We Europeans\", which greatly popularized the struggle against racial science and attacked the Nazis' abuse of science to promote their racial theories. Although they argued that 'any biological arrangement of the types of European man is still largely a subjective process', they proposed that humankind could be divided up into \"major\" and \"minor subspecies\". They believed that races were a classification based on hereditary traits but should not by nature be used to condemn or deem inferior to another group. Like most of their peers, they continued to maintain a distinction between the social meaning of race and the scientific study of race. From a scientific stand point, they were willing to accept that concepts of superiority and inferiority did not exist, but from a social stand point, they continued to believe that racial differences were significant. For example, they argued that genetic differences between groups were functionally important for certain jobs or tasks.\n\nCarleton Stevens Coon (1904–1981) was an American physical anthropologist, Professor of Anthropology at the University of Pennsylvania, lecturer and professor at Harvard, and president of the American Association of Physical Anthropologists.\n\nIn 1939, Coon published \"The Races of Europe\", in which he concluded:\n\n\nIn 1962, Coon also published \"The Origin of Races\", wherein he offered a definitive statement of the polygenist view. He also argued that human fossils could be assigned a date, a race, and an evolutionary grade. Coon divided humanity into five races and believed that each race had ascended the ladder of human evolution at different rates.\n\nMontague Francis Ashley Montagu (1905–1999) was a British-American anthropologist. In 1942, he made a strong effort to have the word \"race\" replaced with \"ethnic group\" by publishing his book, \"Man's Most Dangerous Myth: The Fallacy of Race\". He was also selected to draft the initial 1950 UNESCO Statement on Race.\n\nMontagu would later publish \"An Introduction to Physical Anthropology\", a comprehensive treatise on human diversity. In doing so, he sought to provide a firmer scientific framework through which to discuss biological variation among populations.\n\nThe United Nations Educational, Scientific and Cultural Organization (UNESCO) was established November 16, 1945, in the wake of the genocide of Nazism. The UNESCO 1945 constitution declared that, \"The great and terrible war which now has ended was made possible by the denial of the democratic principles of the dignity, equality and mutual respect of men, and by the propagation, in their place, through ignorance and prejudice, of the doctrine of the inequality of men and races.\" Between 1950 and 1978 the UNESCO issued five statements on the issue of race.\n\nThe first of the UNESCO statements on race was \"The Race Question\" and was issued on July 18, 1950. The statement included both a rejection of a scientific basis for theories of racial hierarchies and a moral condemnation of racism. Its first statement suggested in particular to \"drop the term 'race' altogether and speak of 'ethnic groups, which proved to be controversial. The 1950 statement was most concerned with dispelling the notion of race as species. It did not reject the idea of a biological basis to racial categories. Instead it defined the concept of race in terms as a population defined by certain anatomical and physiological characteristics as being divergent from other populations; it gives the examples of the Caucasian, Mongoloid and Negroid races. The statements maintain that there are no \"pure races\" and that biological variability was as great within any race as between races. It argued that there is no scientific basis for believing that there are any innate differences in intellectual, psychological or emotional potential among races.\n\nThe statement was drafted by Ashley Montagu and endorsed by some of the leading researchers of the time, in the fields of psychology, biology, cultural anthropology and ethnology. The statement was endorsed by Ernest Beaglehole, Juan Comas, L. A. Costa Pinto, Franklin Frazier, sociologist specialised in race relations studies, Morris Ginsberg, founding chairperson of the British Sociological Association, Humayun Kabir, writer, philosopher and Education Minister of India twice, Claude Lévi-Strauss, one of the founders of ethnology and leading theorist of structural anthropology, and Ashley Montagu, anthropologist and author of \"The Elephant Man: A Study in Human Dignity\", who was the rapporteur.\n\nAs a result of a lack of representation of physical anthropologists in the drafting committee the 1950 publication was criticized by biologists and physical anthropologists for confusing the biological and social senses of race and for going beyond the scientific facts, although there was a general agreement about the statements conclusions.\n\nUNESCO assembled a new committee with better representation of the physical sciences and drafted a new statement released in 1951. The 1951 statement, published as \"The Race Concept\", focused on race as a biological heuristic that could serve as the basis for evolutionary studies of human populations. It considered the existing races to be the result of such evolutionary processes throughout human history. It also maintained that \"equality of opportunity and equality in law in no way depend, as ethical principles, upon the assertion that human beings are in fact equal in endowment.\"\n\nAs the 1950 and 1951 statements generated considerable attention, in 1964 a new commission was formed to draft a third statement titled \"Proposals on the Biological Aspects of Race\". According to Michael Banton (2008), this statement broke more clearly with the notion of race-as-species than the previous two statements, declaring that almost any genetically differentiated population could be defined as a race. The statement stated that \"Different classifications of mankind into major stocks, and of those into more restricted categories (races, which are groups of populations, or single populations) have been proposed on the basis of hereditary physical traits. Nearly all classifications recognise at least three major stocks\" and \"There is no national, religious, geographic, linguistic or cultural group which constitutes a race ipso facto; the concept of race is purely biological.\" It concluded with \"The biological data given above stand in open contradiction to the tenets of racism. Racist theories can in no way pretend to have any scientific foundation.\"\n\nThe 1950, '51 and '64 statements focused on the dispelling the scientific foundations for racism but did not consider other factors contributing to racism. For this reason, in 1967 a new committee was assembled, including representatives of the social sciences (sociologists, lawyers, ethnographers and geneticists), to draft a statement \"covering the social, ethical and philosophical aspects of the problem\". This statement was the first to provide a definition of racism: \"antisocial beliefs and acts which are based upon the fallacy that discriminatory intergroup relations are justifiable on biological grounds\". The statement continued to denounce the many negative social affects of racism.\n\nIn 1978 the general assembly of the UNESCO considered the four previous statements and published a collective \"Declaration on Race and Racial Prejudice\". This declaration included Apartheid as one of the examples of racism, an inclusion which caused South Africa to step out of the assembly. It declared that a number of public policies and laws needed to be implemented. It stated that:\n\nThe 20th-century criticism of racial anthropology were significantly based on the school of Franz Boas, professor of anthropology at Columbia University from 1899, who beginning in 1920 strongly favoured the influence of social environment over heritability. As a reaction to the rise of Nazi Germany and its prominent espousing of racist ideologies in the 1930s, there was an outpouring of popular works by scientists criticizing the use of race to justify the politics of \"superiority\" and \"inferiority\". An influential work in this regard was the publication of \"We Europeans: A Survey of \"Racial\" Problems\" by Julian Huxley and A. C. Haddon in 1935, which sought to show that population genetics allowed for only a highly limited definition of race at best. Another popular work during this period, \"The Races of Mankind\" by Ruth Benedict and Gene Weltfish, argued that though there were some extreme racial differences, they were primarily superficial, and in any case did not justify political action.\n\nClaude Lévi-Strauss' \"Race and History\" (UNESCO, 1952) was another critique of the biological \"race\" notion, arguing in favor of cultural relativism through a metaphor of cultures as different trains crossing each other in various directions and speed, thus each one seeming to progress to himself while others supposedly kept immobile. This, in his view, clearly showed that \"race\" was no longer a useful indicator of cultural superiority.\n\nIn his 1984 article in the \"Essence\" magazine, \"On Being 'White' ... and Other Lies\", James Baldwin reads the history of racialization in America as both figuratively and literally violent, remarking that \"race\" only exists as a social construction within a network of force relations: \"America became white — the people who, as they claim, 'settled' the country became white — because of the necessity of denying the Black presence, and justifying the Black subjugation. No community can be based on such a principle — or, in other words, no community can be established on so genocidal a lie. White men from Norway, for example, where they were Norwegians — became white: by slaughtering the cattle, poisoning the well, torching the houses, massacring Native Americans, raping Black women... Because they are white, they cannot allow themselves to be tormented by the suspicion that all men are brothers.\"\n\nApart from its function as a vernacular term, the term \"race\" – as Nancy Stepan notes in her 1982 book, \"The Idea of Race in Science, Great Britain 1800–1960\" – varied widely in its usage, even in science, from the 18th century through the 20th; the term referred \"at one time or another\" to \"cultural, religious, national, linguistic, ethnic and geographical groups of human beings\" — everything from \"Celts\" to \"Spanish Americans\" to \"Hottentots\" to \"Europeans\" (p. xvii).\n\nIn the 1979 preface to \"Blackness: Text and Pretext\", Henry Louis Gates, Jr., describes the elusive element of \"blackness\" in Afro-American literature as lacking an \"essence\", defined instead \"by a network of relations that form a particular aesthetic unity\" (p. 162). Continuing his poststructuralist-inflected negation of blackness as an essence, in his 1985 introduction to a special issue of the journal \"Critical Inquiry\", Gates goes even further, calling race itself a \"dangerous trope\" (p. 5). He argues that \"race has become a trope of the ultimate, irreducible difference between cultures, linguistic groups, or adherents of specific belief systems which — more often than not — also have fundamentally opposed economic interests\" (p. 5).\n\nLinda Gottfredson, on the other hand, has argued that denying (or trying to conceal) real biological differences between groups on average IQ instead cause people to seek something to blame for the differing average group achievements, causing resentment and hostility. She argues that \"virtually all the victim groups of genocide in the Twentieth Century had relatively \"high\" average levels of achievement.\"\n\n\n\n\n"}
{"id": "51429", "url": "https://en.wikipedia.org/wiki?curid=51429", "title": "Hyperreal number", "text": "Hyperreal number\n\nThe system of hyperreal numbers is a way of treating infinite and infinitesimal quantities. The hyperreals, or nonstandard reals, *R, are an extension of the real numbers R that contains numbers greater than anything of the form\n\nSuch numbers are infinite, and their reciprocals are infinitesimals. The term \"hyper-real\" was introduced by Edwin Hewitt in 1948.\n\nThe hyperreal numbers satisfy the transfer principle, a rigorous version of Leibniz's heuristic Law of Continuity. The transfer principle states that true first order statements about R are also valid in *R. For example, the commutative law of addition, \"x\" + \"y\" = \"y\" + \"x\", holds for the hyperreals just as it does for the reals; since R is a real closed field, so is *R. Since formula_2 for all integers \"n\", one also has formula_3 for all hyperintegers \"H\". The transfer principle for ultrapowers is a consequence of Łoś' theorem of 1955.\n\nConcerns about the soundness of arguments involving infinitesimals date back to ancient Greek mathematics, with Archimedes replacing such proofs with ones using other techniques such as the method of exhaustion. In the 1960s, Abraham Robinson proved that the hyperreals were logically consistent if and only if the reals were. This put to rest the fear that any proof involving infinitesimals might be unsound, provided that they were manipulated according to the logical rules that Robinson delineated.\n\nThe application of hyperreal numbers and in particular the transfer principle to problems of analysis is called non-standard analysis. One immediate application is the definition of the basic concepts of analysis such as derivative and integral in a direct fashion, without passing via logical complications of multiple quantifiers. Thus, the derivative of \"f(x)\" becomes formula_4 for an infinitesimal formula_5, where \"st(·)\" denotes the standard part function, which \"rounds off\" each finite hyperreal to the nearest real. Similarly, the integral is defined as the standard part of a suitable infinite sum.\n\nThe idea of the hyperreal system is to extend the real numbers R to form a system *R that includes infinitesimal and infinite numbers, but without changing any of the elementary axioms of algebra. Any statement of the form \"for any number x...\" that is true for the reals is also true for the hyperreals. For example, the axiom that states \"for any number \"x\", \"x\" + 0 = \"x\"\" still applies. The same is true for quantification over several numbers, e.g., \"for any numbers \"x\" and \"y\", \"xy\" = \"yx\".\" This ability to carry over statements from the reals to the hyperreals is called the transfer principle. However, statements of the form \"for any \"set\" of numbers S ...\" may not carry over. The only properties that differ between the reals and the hyperreals are those that rely on quantification over sets, or other higher-level structures such as functions and relations, which are typically constructed out of sets. Each real set, function, and relation has its natural hyperreal extension, satisfying the same first-order properties. The kinds of logical sentences that obey this restriction on quantification are referred to as statements in first-order logic.\n\nThe transfer principle, however, doesn't mean that R and *R have identical behavior. For instance, in *R there exists an element \"ω\" such that\n\nbut there is no such number in R. (In other words, *R is not Archimedean.) This is possible because the nonexistence of \"ω\" cannot be expressed as a first order statement.\n\nInformal notations for non-real quantities have historically appeared in calculus in two contexts: as infinitesimals like \"dx\" and as the symbol ∞, used, for example, in limits of integration of improper integrals.\n\nAs an example of the transfer principle, the statement that for any nonzero number \"x\", \"2x\" ≠ \"x\", is true for the real numbers, and it is in the form required by the transfer principle, so it is also true for the hyperreal numbers. This shows that it is not possible to use a generic symbol such as ∞ for all the infinite quantities in the hyperreal system; infinite quantities differ in magnitude from other infinite quantities, and infinitesimals from other infinitesimals.\n\nSimilarly, the casual use of 1/0 = ∞ is invalid, since the transfer principle applies to the statement that division by zero is undefined. The rigorous counterpart of such a calculation would be that if ε is a non-zero infinitesimal, then 1/ε is infinite.\n\nFor any finite hyperreal number \"x\", its standard part, st \"x\", is defined as the unique real number that differs from it only infinitesimally. The derivative of a function \"y\"(\"x\") is defined not as \"dy/dx\" but as the standard part of \"dy/dx\".\n\nFor example, to find the derivative \"f′\"(\"x\") of the function \"f\"(\"x\") = \"x\", let \"dx\" be a non-zero infinitesimal. Then,\n\nThe use of the standard part in the definition of the derivative is a rigorous alternative to the traditional practice of neglecting the square of an infinitesimal quantity. Dual numbers are a number system based this idea. After the third line of the differentiation above, the typical method from Newton through the 19th century would have been simply to discard the \"dx\" term. In the hyperreal system,\n\"dx\" ≠ 0, since \"dx\" is nonzero, and the transfer principle can be applied to the statement that the square of any nonzero number is nonzero. However, the quantity \"dx\" is infinitesimally small compared to \"dx\"; that is, the hyperreal system contains a hierarchy of infinitesimal quantities.\n\nOne way of defining a definite integral in the hyperreal system is as the standard part of an infinite sum on a hyperfinite lattice defined as \"a\", \"a + dx\", \"a + 2dx\", ... \"a + ndx\", where \"dx\" is infinitesimal, n is an infinite hypernatural, and the lower and upper bounds of integration are \"a\" and \"b\" = \"a\" + \"n\" \"dx.\"\n\nThe hyperreals *R form an ordered field containing the reals R as a subfield. Unlike the reals, the hyperreals do not form a standard metric space, but by virtue of their order they carry an order topology.\n\nThe use of the definite article \"the\" in the phrase \"the hyperreal numbers\" is somewhat misleading in that there is not a unique ordered field that is referred to in most treatments.\nHowever, a 2003 paper by Vladimir Kanovei and Saharon Shelah shows that there is a definable, countably saturated (meaning ω-saturated, but not, of course, countable) elementary extension of the reals, which therefore has a good claim to the title of \"the\" hyperreal numbers. Furthermore, the field obtained by the ultrapower construction from the space of all real sequences, is unique up to isomorphism if one assumes the continuum hypothesis.\n\nThe condition of being a hyperreal field is a stronger one than that of being a real closed field strictly containing R. It is also stronger than that of being a superreal field in the sense of Dales and Woodin.\n\nThe hyperreals can be developed either axiomatically or by more constructively oriented methods. The essence of the axiomatic approach is to assert (1) the existence of at least one infinitesimal number, and (2) the validity of the transfer principle. In the following subsection we give a detailed outline of a more constructive approach. This method allows one to construct the hyperreals if given a set-theoretic object called an ultrafilter, but the ultrafilter itself cannot be explicitly constructed.\n\nWhen Newton and (more explicitly) Leibniz introduced differentials, they used infinitesimals and these were still regarded as useful by later mathematicians such as Euler and Cauchy. Nonetheless these concepts were from the beginning seen as suspect, notably by George Berkeley. Berkeley's criticism centered on a perceived shift in hypothesis in the definition of the derivative in terms of infinitesimals (or fluxions), where \"dx\" is assumed to be nonzero at the beginning of the calculation, and to vanish at its conclusion (see Ghosts of departed quantities for details). When in the 1800s calculus was put on a firm footing through the development of the (ε, δ)-definition of limit by Bolzano, Cauchy, Weierstrass, and others, infinitesimals were largely abandoned, though research in non-Archimedean fields continued (Ehrlich 2006).\n\nHowever, in the 1960s Abraham Robinson showed how infinitely large and infinitesimal numbers can be rigorously defined and used to develop the field of non-standard analysis. Robinson developed his theory nonconstructively, using model theory; however it is possible to proceed using only algebra and topology, and proving the transfer principle as a consequence of the definitions. In other words hyperreal numbers \"per se\", aside from their use in nonstandard analysis, have no necessary relationship to model theory or first order logic, although they were discovered by the application of model theoretic techniques from logic. Hyper-real fields were in fact originally introduced by Hewitt (1948) by purely algebraic techniques, using an ultrapower construction.\n\nWe are going to construct a hyperreal field via sequences of reals. In fact we can add and multiply sequences componentwise; for example:\n\nand analogously for multiplication.\nThis turns the set of such sequences into a commutative ring, which is in fact a real algebra A. We have a natural embedding of R in A by identifying the real number \"r\" with the sequence (\"r\", \"r\", \"r\", …) and this identification preserves the corresponding algebraic operations of the reals. The intuitive motivation is, for example, to represent an infinitesimal number using a sequence that approaches zero. The inverse of such a sequence would represent an infinite number. As we will see below, the difficulties arise because of the need to define rules for comparing such sequences in a manner that, although inevitably somewhat arbitrary, must be self-consistent and well defined. For example, we may have two sequences that differ in their first \"n\" members, but are equal after that; such sequences should clearly be considered as representing the same hyperreal number. Similarly, most sequences oscillate randomly forever, and we must find some way of taking such a sequence and interpreting it as, say, formula_8, where formula_9 is a certain infinitesimal number.\n\nComparing sequences is thus a delicate matter. We could, for example, try to define a relation between sequences in a componentwise fashion:\n\nbut here we run into trouble, since some entries of the first sequence may be bigger than the corresponding entries of the second sequence, and some others may be smaller. It follows that the relation defined in this way is only a partial order. To get around this, we have to specify which positions matter. Since there are infinitely many indices, we don't want finite sets of indices to matter. A consistent choice of index sets that matter is given by any free ultrafilter \"U\" on the natural numbers; these can be characterized as ultrafilters that do not contain any finite sets. (The good news is that Zorn's lemma guarantees the existence of many such \"U\"; the bad news is that they cannot be explicitly constructed.) We think of \"U\" as singling out those sets of indices that \"matter\": We write (\"a\", \"a\", \"a\", ...) ≤ (\"b\", \"b\", \"b\", ...) if and only if the set of natural numbers { \"n\" : \"a\" ≤ \"b\" } is in \"U\".\n\nThis is a total preorder and it turns into a total order if we agree not to distinguish between two sequences \"a\" and \"b\" if \"a\"≤\"b\" and \"b\"≤\"a\". With this identification, the ordered field *R of hyperreals is constructed. From an algebraic point of view, \"U\" allows us to define a corresponding maximal ideal I in the commutative ring A (namely, the set of the sequences that vanish in some element of \"U\"), and then to define *R as A/I; as the quotient of a commutative ring by a maximal ideal, *R is a field. This is also notated A/\"U\", directly in terms of the free ultrafilter \"U\"; the two are equivalent. The maximality of I follows from the possibility of, given a sequence \"a\", constructing a sequence \"b\" inverting the non-null elements of \"a\" and not altering its null entries. If the set on which \"a\" vanishes is not in \"U\", the product \"ab\" is identified with the number 1, and any ideal containing 1 must be \"A\". In the resulting field, these \"a\" and \"b\" are inverses.\n\nThe field A/\"U\" is an ultrapower of R.\nSince this field contains R it has cardinality at least that of the continuum. Since A has cardinality\n\nit is also no larger than formula_12, and hence has the same cardinality as R.\n\nOne question we might ask is whether, if we had chosen a different free ultrafilter \"V\", the quotient field A/\"U\" would be isomorphic as an ordered field to A/\"V\". This question turns out to be equivalent to the continuum hypothesis; in ZFC with the continuum hypothesis we can prove this field is unique up to order isomorphism, and in ZFC with the negation of continuum hypothesis we can prove that there are non-order-isomorphic pairs of fields that are both countably indexed ultrapowers of the reals.\n\nFor more information about this method of construction, see ultraproduct.\n\nThe following is an intuitive way of understanding the hyperreal numbers. The approach taken here is very close to the one in the book by Goldblatt. Recall that the sequences converging to zero are sometimes called infinitely small. These are almost the infinitesimals in a sense; the true infinitesimals include certain classes of sequences that contain a sequence converging to zero.\n\nLet us see where these classes come from. Consider first the sequences of real numbers. They form a ring, that is, one can multiply, add and subtract them, but not always divide by a non-zero element. The real numbers are considered as the constant sequences, the sequence is zero if it is identically zero, that is, \"a\" = 0 for all \"n\".\n\nIn our ring of sequences one can get \"ab\" = 0 with neither \"a\" = 0 nor \"b\" = 0. Thus, if for two sequences formula_13 one has \"ab\" = 0, at least one of them should be declared zero. Surprisingly enough, there is a consistent way to do it. As a result, the equivalence classes of sequences that differ by some sequence declared zero will form a field, which is called a hyperreal field. It will contain the infinitesimals in addition to the ordinary real numbers, as well as infinitely large numbers (the reciprocals of infinitesimals, including those represented by sequences diverging to infinity). Also every hyperreal that is not infinitely large will be infinitely close to an ordinary real, in other words, it will be the sum of an ordinary real and an infinitesimal.\n\nThis construction is parallel to the construction of the reals from the rationals given by Cantor. He started with the ring of the Cauchy sequences of rationals and declared all the sequences that converge to zero to be zero. The result is the reals. To continue the construction of hyperreals, let us consider the zero sets of our sequences, that is, the formula_14, that is, formula_15 is the set of indexes formula_16 for which formula_17. It is clear that if formula_18, then the union of formula_15 and formula_20 is \"N\" (the set of all natural numbers), so:\nNow the idea is to single out a bunch \"U\" of subsets \"X\" of \"N\" and to declare that formula_27 if and only if formula_15 belongs to \"U\". From the above conditions one can see that:\n\nAny family of sets that satisfies (2–4) is called a filter (an example: the complements to the finite sets, it is called the Fréchet filter and it is used in the usual limit theory). If (1) also holds, U is called an ultrafilter (because you can add no more sets to it without breaking it). The only explicitly known example of an ultrafilter is the family of sets containing a given element (in our case, say, the number 10). Such ultrafilters are called trivial, and if we use it in our construction, we come back to the ordinary real numbers. Any ultrafilter containing a finite set is trivial. It is known that any filter can be extended to an ultrafilter, but the proof uses the axiom of choice. The existence of a nontrivial ultrafilter (the ultrafilter lemma) can be added as an extra axiom, as it is weaker than the axiom of choice.\n\nNow if we take a nontrivial ultrafilter (which is an extension of the Fréchet filter) and do our construction, we get the hyperreal numbers as a result.\n\nIf formula_29 is a real function of a real variable formula_30 then formula_29 naturally extends to a hyperreal function of a hyperreal variable by composition:\nwhere formula_33 means \"the equivalence class of the sequence formula_34 relative to our ultrafilter\", two sequences being in the same class if and only if the zero set of their difference belongs to our ultrafilter.\n\nAll the arithmetical expressions and formulas make sense for hyperreals and hold true if they are true for the ordinary reals. It turns out that any finite (that is, such that formula_35 for some ordinary real formula_21) hyperreal formula_30 will be of the form formula_38 where formula_39 is an ordinary (called standard) real and formula_40 is an infinitesimal. It can be proven by bisection method used in proving the Bolzano-Weierstrass theorem, the property (1) of ultrafilters turns out to be crucial.\nNow one can see that formula_29 is continuous means that formula_42 is infinitely small whenever formula_43 is, and formula_29 is differentiable means that\nis infinitely small whenever formula_43 is. Remarkably, if one allows formula_21 to be hyperreal, the derivative will be automatically continuous (because, formula_29 being differentiable at formula_30,\nis infinitely small when formula_43 is, therefore formula_52 is also infinitely small when formula_43 is).\n\nThe finite elements F of *R form a local ring, and in fact a valuation ring, with the unique maximal ideal S being the infinitesimals; the quotient F/S is isomorphic to the reals. Hence we have a homomorphic mapping, st(\"x\"), from F to R whose kernel consists of the infinitesimals and which sends every element \"x\" of F to a unique real number whose difference from x is in S; which is to say, is infinitesimal. Put another way, every \"finite\" nonstandard real number is \"very close\" to a unique real number, in the sense that if \"x\" is a finite nonstandard real, then there exists one and only one real number st(\"x\") such that \"x\" – st(\"x\") is infinitesimal. This number st(\"x\") is called the standard part of \"x\", conceptually the same as \"x\" \"to the nearest real number\". This operation is an order-preserving homomorphism and hence is well-behaved both algebraically and order theoretically. It is order-preserving though not isotonic; i.e. formula_54 implies formula_55, but formula_56 does not imply formula_57.\n\nThe map st is continuous with respect to the order topology on the finite hyperreals; in fact it is locally constant.\n\nSuppose \"X\" is a Tychonoff space, also called a T space, and C(\"X\") is the algebra of continuous real-valued functions on \"X\". Suppose M is a maximal ideal in C(\"X\"). Then the factor algebra A = C(\"X\")/M is a totally ordered field F containing the reals. If F strictly contains R then M is called a hyperreal ideal (terminology due to Hewitt (1948)) and F a hyperreal field. Note that no assumption is being made that the cardinality of F is greater than R; it can in fact have the same cardinality.\n\nAn important special case is where the topology on \"X\" is the discrete topology; in this case \"X\" can be identified with a cardinal number κ and C(\"X\") with the real algebra formula_62 of functions from κ to R. The hyperreal fields we obtain in this case are called ultrapowers of R and are identical to the ultrapowers constructed via free ultrafilters in model theory.\n\n\n\n"}
{"id": "5620900", "url": "https://en.wikipedia.org/wiki?curid=5620900", "title": "Ideal speech situation", "text": "Ideal speech situation\n\nAn ideal speech situation was a term introduced in the early philosophy of Jürgen Habermas. It argues that an ideal speech situation is found when communication between individuals is governed by basic, implied rules. In an ideal speech situation, participants would be able to evaluate each other’s assertions solely on the basis of reason and evidence in an atmosphere completely free of any nonrational “coercive” influences, including both physical and psychological coercion. Furthermore, all participants would be motivated solely by the desire to obtain a rational consensus.\nMembers of the public sphere must adhere to certain rules for an \"ideal speech situation\" to occur. They are:\n\n1. Every subject with the competence to speak and act is allowed to take part in a discourse.\n\n2a. Everyone is allowed to question any assertion whatever.\n\n2b. Everyone is allowed to introduce any assertion whatever into the discourse.\n\n2c. Everyone is allowed to express their attitudes, desires and needs without any hesitation.\n\n3. No speaker may be prevented, by internal or external coercion, from exercising his rights as laid down in (1) and (2)\nThe concept of the ideal speech situation came under attack in the 1970s by theorists who persistently relativized the concept, arguing that any \"particular\" conception of an ideal speech situation could not be proven completely correct, so that any (still-unknown) gaps would allow associated oppressions to arise or persist.\n\nHabermas responded to this in 1983 with \"Moral Consciousness and Communicative Action\" (English trans. 1990). In this work he no longer spoke of a known ideal speech situation but instead of a new moral system (\"Discourse ethics\") that could be derived from the \"presuppositions of argumentation\". These in turn could \"initially\" be postulated by philosophical analysis in the same way that Immanuel Kant tried to justify his own moral system through transcendental arguments. However, in contradistinction to Kant, Habermas recognizes that the presuppositions of argumentation can be tested in practice by a device he terms \"performative contradiction\". If critics object to the presuppositions of argumentation, their argument \"might\" be turned on them to demonstrate that their argument has already granted the existence of whatever specific presupposition of argument they object to. However, if such a performative contradiction cannot be found, then the presuppositions of argumentation must be revised to take account of the criticism and the moral system derived from these presuppositions altered accordingly. In other words, \"performative contradiction\" is not a trump card to dismiss all objections but a fair test of those objections. The dialectical nature of Habermas's argument often goes unrecognized.\n\nThe ideal speech situation, in its assumption of literal rather than figurative language function (language \"below\" rather than \"above\" the context-forming horizon of the lifeworld), is taken as the model for formal pragmatic analysis of speech-acts.\n\n\n\n"}
{"id": "26152150", "url": "https://en.wikipedia.org/wiki?curid=26152150", "title": "Immediacy (philosophy)", "text": "Immediacy (philosophy)\n\nImmediacy is a philosophical concept related to time and temporal perspectives, both visual, cognitive. Considerations of immediacy reflect on how we experience the world and what reality is. It possesses characteristics of both of the homophonic heterographs 'immanent' and 'imminent', and what entails to both within ontology.\n"}
{"id": "2183067", "url": "https://en.wikipedia.org/wiki?curid=2183067", "title": "José Offerman", "text": "José Offerman\n\nJosé Antonio Offerman Dono (born November 8, 1968) is a Dominican retired professional baseball player who played professional baseball for nearly 20 years. He played for 15 seasons in the Major League Baseball and has played 4 seasons of independent and Mexican League baseball since leaving MLB.\n\nHe most recently managed the Licey Tigers of the Dominican Winter League, leading them to the 2008–2009 and 2013–2014 Dominican Winter League Championship. During a baseball game on January 16, 2010, Offerman attacked an umpire during an argument and, as a result, was banned from the Winter League for three years. He managed the Rojos del Águila de Veracruz of the Mexican League in 2014.\n\nAfter attending Colegio Biblico Cristiano High School in San Pedro de Macorís, Offerman signed with the Los Angeles Dodgers as an amateur free agent in 1986. In , he completed his first season of professional play being named as Best Prospect in the Pioneer League. Progressing rapidly through the minor leagues, he made his major league debut against the Montreal Expos on August 19, becoming the 55th player in major league history to hit a home run in his first major league at-bat.\n\nBy , Offerman became the Dodgers' starting shortstop. On opening day 1993, he was the first batter to ever face the Florida Marlins, striking out against Charlie Hough. He made his first appearance in the All-Star Game in 1995 but was traded to the Kansas City Royals after the season, mostly because of his very poor defense. After a year as a utility player, he won the starting second baseman job in 1997. Offerman had his best offensive seasons in Kansas City, culminating in , when he hit .315 with a league-leading 13 triples and the fifth most stolen bases, 45. After that season, he signed with the Boston Red Sox as a free agent, making the All-Star Game for the second time in 1999.\n\nKnown more for his hitting skills than his fielding, Offerman's offense began to decline in . He was sent to the Seattle Mariners during the season, but was released afterwards. In , he joined the Montreal Expos in spring training but was cut before the regular season began. He spent the entire year with the Bridgeport Bluefish of the independent Atlantic League. In , he won a spot on the Minnesota Twins roster and led the league in pinch-hits with 12 in 29 attempts. He started with the Philadelphia Phillies but was released after a slow start. Later, he signed with the New York Mets and was called back up to the majors in June.\n\nMost recently, Offerman played in the 2008 Caribbean World Series for the Licey Tigers – Dominican Republic 2 team – where he assisted the team in winning its 10th Caribbean World Series title. During the series he signed a contract with the 2008 Veracruz Red Eagles of the Mexican Summer League.\n\nIn December, 2008, Offerman was named player-manager of Licey Tigers of the Dominican Winter League. With Offerman as manager, Licey swept the Dominican Winter League Baseball Championships, winning five straight against the Gigantes del Cibao. As champions, Licey was then invited to participate in the 2009 Caribbean World Series with Offerman as manager (the series was ultimately won by Venezuela). (The Caribbean World Series is affiliated with the Winter League programs of Major League Baseball, featuring MLB players and prospects from the Dominican Winter League, Mexican Pacific League, Puerto Rican Professional Baseball League and Venezuelan Professional Baseball League.)\n\nOn January 7, 2014, Offerman was again named manager of the Licey Tigers of the Dominican Winter League, replacing Mike Guerrero. With Offerman at the helm, Licey won the Dominican Winter League Baseball Championships, winning five games to three over the Leones del Escogido. As champions again, Licey has been invited to the 2014 Caribbean World Series with Offerman as manager. At present, his team has qualified for the semifinals of the tournament.\n\nHe has not played or managed professional baseball in the United States since 2007. \nOn August 14, , Offerman was thrown out of a Ducks game against the Bridgeport Bluefish for charging Bluefish pitcher Matt Beech with a bat after he was hit by a pitch. Beech sustained broken finger in the resulting melee. Bluefish catcher John Nathans was also hit in the back of the head during the bench-clearing melee, receiving a severe concussion that effectively ended his playing career. Beech and Nathans were taken to Bridgeport Hospital where they were treated and released. After being removed from the game, Offerman was arrested by the Bridgeport Police.\n\nOn August 15, 2007, he was suspended indefinitely. The independent Atlantic League announced on August 17, 2007 that Offerman would remain suspended at least until the legal case was resolved.\n\nOn September 24, 2007, Offerman pleaded not guilty to two second degree assault charges.\n\nHis case was pending in Bridgeport Superior Court GA#2 in Bridgeport, Connecticut. He was represented by Attorney Frank J. Riccio II. On October 30, 2007, Offerman was given two years special probation called \"Accelerated Rehabilitation ('AR').\" The Court determined that his actions on August 14, 2007 were of an aberrant nature. The Court also found that Offerman is not likely to offend again in the future.\n\nNathans filed a $4.8 million civil suit against Offerman in February 2009, claiming that he still has post-concussion syndrome and that the injury allegedly caused by Offerman ended his baseball career.\nOn July 29, 2014, Nathans won his suit, and Offerman was ordered to pay $940,000.\n\nOn 16 January 2010, Offerman once again engaged in an on-field assault when he struck an umpire while managing a Dominican Republic winter league game. Offerman, manager of the Licey Tigers, came onto the field during the third inning while losing a 6-0 game to the Cibao Giants, to protest ejection of his catcher for arguing balls and strikes and ended up arguing with first-base umpire D.J. Reyburn. He swung with a right hook at Reyburn, who then fell to the ground. Offerman was detained by stadium security, eventually being transported to the local police station to await the end of the game and Reyburn's decision whether to ask for charges to be pressed against him or not.\n\nA day after the incident, the American crew that umpired the game resigned their positions with the Dominican Baseball League and left the country, reportedly due to threats and concerns about their own safety. Because of this incident Offerman received a lifetime ban from the Dominican Republic Winter League, a suspension that was eventually lifted in February 2013. Coincidentally, at the time he was suspended, Offerman was replacing Dave Jauss as Licey manager after Jauss was suspended himself for two years for bumping an umpire during a playoff game.\n\nHe is the father of WWE ring announcer and former reality television star JoJo Offerman.\n\n\n"}
{"id": "31601131", "url": "https://en.wikipedia.org/wiki?curid=31601131", "title": "Kindness Day UK", "text": "Kindness Day UK\n\nKindness Day UK is celebrated on World Kindness Day, every 13 November. Kindness Day UK is a celebration of kindness, which aims to increase the value of kindness in society as well as increase the amount of kind acts that take place, making kindness a greater part in our daily life. Kindness Day UK is affiliated with the World Kindness Movement (WKM) which is a coalition of like minded organisations containing 18 member nations. It was set up in 2010 by Louise Burfitt-Dons who founded the Cool To Be Kind anti-bullying campaign in 2001 and UK Kindness Movement in 2005 and David Jamilly who founded The Good Deeds Organisation in 2005 and went on to found Kindness UK in 2011. It is now celebrated by a range of charities, associations, businesses, schools, organisations, institutions and individuals across the UK.\n\nKindness Day UK and World Kindness Day are on 13 November every year and celebrated and promoted by the UK members of the World Kindness Movement. On this date the Kindness Day UK campaign's mission is to make everyone in the UK carry out an act of kindness and take a small ‘pause for kindness’ to value its importance. As an overall mission, the Kindness Day UK campaign aims to make kindness to people, animals and the environment a bigger part of day-to-day life in the UK.\n\nThe date decreed for World Kindness Day is 13 November. This was the opening day of the first World Kindness Movement conference held at Tokyo in 1998, and the 35th anniversary of the Small Kindness Movement of Japan\n\nKindness Day has received a great amount of support from celebrities, enterprise, politicians and religious leaders. Supporters include Dame Barbara Stocking DBE, Chief Executive of Oxfam, The Rt HON Sir John Major KG CH, Russell Brand, Holly Willoughby and Sir Stuart Rose, Chairman of Marks and Spencer, The Rt Hon David Blunkett, Gary Lineker, Sir Alex Ferguson, Vanessa Feltz, Camilla Dallerup, Peter Snow, Jo Brand, Billy Murray, Patsy Kensit, Alan Titchmarsh, Brian Blessed, Jilly Cooper, Noel Edmonds, Charles Kennedy MP, Arlene Phillips, Ruby Wax and Monica Cafferky.\n\n\n"}
{"id": "253283", "url": "https://en.wikipedia.org/wiki?curid=253283", "title": "Linguistic imperialism", "text": "Linguistic imperialism\n\nLinguistic imperialism, or language imperialism, a phenomenon that occasionally occurs, defined as \"the transfer of a dominant language to other people\". This language \"transfer\" comes about because of imperialism. The transfer is considered to be a demonstration of power—traditionally, military power but also, in the modern world, economic power—and aspects of the dominant culture are usually transferred along with the language.\n\nIn the modern world, linguistic imperialism may also be considered in the context of international development, affecting the standard by which organizations like the International Monetary Fund (IMF) and the World Bank evaluate the trustworthiness and value of providing structural adjustment loans.\n\nSince the early 1990s, linguistic imperialism has attracted attention among scholars of applied linguistics. In particular, Robert Phillipson's 1992 book, \"Linguistic Imperialism\", has led to considerable debate about its merits and shortcomings. Phillipson found denunciations of linguistic imperialism that dated back to Nazi critiques of the British Council (European aristocracy was at the time agreeing on the use of English), and to Soviet analyses of English as the language of world capitalism and world domination. In this vein, criticism of English as a world language is rooted in anti-globalism.\n\nPhillipson defines English linguistic imperialism as \"the dominance of English... asserted and maintained by the establishment and continuous reconstitution of structural and cultural inequalities between English and other languages.\"\n\nPhillipson's theory supports the historic spread of English as an international language and that language's continued dominance, particularly in postcolonial settings such as India, Pakistan, Uganda, Zimbabwe, etc., but also increasingly in \"neo-colonial\" settings such as continental Europe. His theory draws mainly on Johan Galtung's imperialism theory, Antonio Gramsci's social theory, and in particular on his notion of cultural hegemony.\n\nA central theme of Phillipson's theory is the complex hegemonic processes which, he asserts, continue to sustain the pre-eminence of English in the world today. His book analyzes the British Council's use of rhetoric to promote English, and discusses key tenets of English applied linguistics and English-language-teaching methodology. These tenets hold that:\n\n\nAccording to Phillipson, those who promote English—organizations such as the British Council, the International Monetary Fund and the World Bank, and individuals such as operators of English-language schools—use three types of argument:\n\nOther arguments for English are\n\nAnother theme in Phillipson's work is \"linguicism\"—the species of prejudice that leads to endangered languages becoming extinct or losing their local eminence due to the rise and competing prominence of English.\n\nIn 1976, Black school children in Soweto protested at being taught in Afrikaans, which had been pushed by the Apartheid authorities concerned at the growing refusal of the Black population to speak it. They reasoned that by only having access to Afrikaner resources the South African government could control them more closely than having access to a global language i.e. English. 176 children died for the right to be taught in English. The Uprising became a turning point in the overthrow of Apartheid years later.\n\nAt various times, especially in colonial settings or where a dominant culture has sought to unify a region under its control, a similar phenomenon has arisen. In the Roman Empire, Latin—originally the language of a limited region in central Italy—was imposed first on the rest of Italy and later on large parts of Europe, largely displacing previous languages spoken there, while in Roman Africa Latin was merely dominant until it and the native languages were displaced by Arabization.\n\nAnatolia was similarly diverse linguistically when it was ruled by small native states. Under the Persian and Hellenistic empires, the language of the conqueror served as the \"lingua franca\". The indigenous Anatolian languages disappeared.\n\nIn the Far East, Africa and South America, regional languages have been or are being coercively replaced or marginalized by the language of a dominant culture—Tibetan and regional Chinese varieties by Mandarin Chinese, Ainu and Ryukyuan by Japanese, Quechua by Spanish, Malayo-Polynesian languages by Malay, Philippine languages by Filipino/Tagalog and so on. Arabization has eliminated many indigenous languages in North Africa, and restricted Coptic to sacred use.\n\nThe English language during the Middle Ages was an object of linguistic imperialism by the French language, particularly following the Norman conquest. For hundreds of years, French or Anglo-Norman was the language of administration (\"See Law French\") and therefore a language of superior status in England. Latin remained the language of the church and of learning. Although many words introduced by the Normans are today indistinguishable by most English-speakers from native Germanic words, later-learned loanwords derived from Latin or French often have a more cultured sound to a native English-speaker.\n\nFollowing the establishment of the Holy Roman Empire over much of present-day Germany and Central Europe, the German language and its dialects became the preferred language of many Central-European nobility. With varying success, German spread across much of Central and Eastern Europe as a language of trade and status. This ended with World War II (\"See also Germanization.\").\n\nFrench too has expanded. Languages such as Occitan, Breton, Basque, Catalan and Corsican are to a great extent marginalised in France. This process, known as Francization, often causes resistance amongst the subject peoples, leading to demands for independence. Examples of this can still be found in Brittany and Flanders (Belgium).\n\nSpanish and to a lesser extent Portuguese colonization, made these languages prevalent in South America and in parts of Africa, Asia (the Philippines), Macau and in former times in Formosa. In Iberia, Castilian Spanish, as spoken in the kingdom of Castile was imposed on other regions of Spain, initially by Germanic Habsburg Spain and later more fervently by the French Bourbon Spain; it was labeled \"the companion of the Empire\" by Antonio de Nebrija (1492) in the introduction to his \"Gramática de la lengua castellana\". Russian linguistic imperialism can be detected in Belarus both in the former dispute over the name of the country (Belarus vs Belorussia) and in the common spelling of the name of their president. English transcription has overtaken the Russian form Alexander Lukashenko instead of Belarusian form Alyaksandr Lukashenka.\n\nMany scholars have participated in lively discussions of Phillipson's claims. Alan Davies, for instance, envisions the spectre of Phillipson haunting the Department of Applied Linguistics in Edinburgh:\n\nFor Davies, two cultures inhabit linguistic imperialism: one, a culture of guilt (\"colonies should never have happened\"); the other, that of romantic despair (\"we shouldn't be doing what we are doing\"). Rajagopalan goes a step farther and maintains that Phillipson's book has led to a guilt complex among English language learning and teaching (ELT) professionals.\n\nDavies also argues that Phillipson's claims are not falsifiable: what \"if the dominated... wanted to adopt English and continue to want to keep it? RP's unfalsifiable answer must be that they don't, they can't, they've been persuaded against their better interests.\" It has thus been argued that Phillipson's theory is patronizing in the sense that it does not regard developing countries as being capable of independent decision-making (to adopt or not to adopt ELT). In the context of Nigeria, Bisong holds that people in the \"periphery\" use English pragmatically—they send their children to English-language schools precisely because they want them to grow up multilingual. Regarding Phillipson, Bisong maintains that \"to interpret such actions as emanating from people who are victims of Centre linguistic imperialism is to bend sociolinguistic evidence to suit a preconceived thesis\". If English should be abolished because it is foreign, Bisong argues, then Nigeria itself would also have to be dissolved, because it was conceived as a colonial structure.\n\nFurthermore, the assumption that the English language itself is imperialistic has come under attack. Henry Widdowson has argued that \"there is a fundamental contradiction in the idea that the language of itself exerts hegemonic control: namely that if this were the case, you would never be able to challenge such control\". Additionally, the idea that the promotion of English necessarily implies a demotion of local languages has been challenged. Holborrow points out that \"not all Englishes in the centre dominate, nor are all speakers in the periphery equally discriminated against\". Irish English, for instance, could be regarded as a non-dominant centre variety of English.\n\nThus it could be argued that, while those who follow Phillipson see choices about language as externally imposed, the other camp sees them as decisions made by individuals.\n\nThose who support the arguments favoring the existence of linguistic imperialism claim that arguments against it are often advanced by monolingual native-speakers of English who may see the current status of English as a fact worthy of celebration.\n\nIn contrast, it has been argued that those who see the increasing spread of English in the world as a worrying development (that marginalizes the status of local and regional languages as well as potentially undermining or eroding cultural values) are likely to be far more receptive to Phillipson's views. Alastair Pennycook, Suresh Canagarajah, Adrian Holliday and Julian Edge broadly fall into this group and are often described as critical applied linguists.\n\nHowever, Henry Widdowson’s remarks on critical discourse analysis may also be applied to the critical applied linguists:\n\nAs a response to English linguistic imperialism, de-anglicisation became a matter of national pride in some places and especially in regions that were once under colonial rule, where vestiges of colonial domination are a sensitive subject. Following centuries of English rule in Ireland, an argument for de-anglicisation was delivered before the Irish National Literary Society in Dublin, 25 November 1892; \"When we speak of 'The Necessity for De-Anglicising the Irish Nation', we mean it, not as a protest against imitating what is best in the English people, for that would be absurd, but rather to show the folly of neglecting what is Irish, and hastening to adopt, pell-mell, and indiscriminately, everything that is English, simply because it is English.\" Despite its status as an official language, the Irish language has been reduced to a minority language in Ireland as a result of centuries of English rule, as is the case in North America where their indigenous languages have been replaced by that of the colonists, and continued to decline even after independence.\n\nAccording to Ghil'ad Zuckermann, \"Native tongue title and language rights should be promoted. The government ought to define Aboriginal and Torres Strait Islander vernaculars as official languages of Australia. We must change the linguistic landscape of Whyalla and elsewhere. Signs should be in both English and the local indigenous language. We ought to acknowledge intellectual property of indigenous knowledge including language, music and dance.\"\n\nSome who reject the concept of linguistic imperialism argue that the global spread of English is better understood in the framework of appropriation—that English is used around the world \"for local purposes\". In addition to the example of Nigeria, above, the following examples have been given:\n\n\nSuch an \"internationalization\" of English might also create new possibilities for English native-speakers. McCabe elaborates:\n\n"}
{"id": "17997117", "url": "https://en.wikipedia.org/wiki?curid=17997117", "title": "List of global sustainability statistics", "text": "List of global sustainability statistics\n\nGlobal sustainability statistics are benchmarks for measuring the status of sustainability parameters. The following agencies provide baseline data for sustainability governance. They are just one form of data used for sustainability accounting and are valuable for assessing trends and measuring progress. \n\nThis list provides sources of statistics at the \"global\" level of governance only.\n\n\n"}
{"id": "1639470", "url": "https://en.wikipedia.org/wiki?curid=1639470", "title": "Loose coupling", "text": "Loose coupling\n\nIn computing and systems design a loosely coupled system is one in which each of its components has, or makes use of, little or no knowledge of the definitions of other separate components. Subareas include the coupling of classes, interfaces, data, and services. Loose coupling is the opposite of tight coupling.\n\nComponents in a loosely coupled system can be replaced with alternative implementations that provide the same services. Components in a loosely coupled system are less constrained to the same platform, language, operating system, or build environment.\n\nIf systems are decoupled in time, it is difficult to also provide transactional integrity; additional coordination protocols are required. Data replication across different systems provides loose coupling (in availability), but creates issues in maintaining consistency (data synchronization).\n\nLoose coupling in broader distributed system design is achieved by the use of transactions, queues provided by message-oriented middleware, and interoperability standards.\n\nFour types of autonomy, which promote loose coupling, are: \"reference autonomy\", \"time autonomy\", \"format autonomy\", and \"platform autonomy\".\n\nLoose coupling is an architectural principle and design goal in service-oriented architectures; eleven forms of loose coupling and their tight coupling counterparts are listed in: \nEnterprise Service Bus (ESB) middleware was invented to achieve loose coupling in multiple dimensions; however, overengineered and mispositioned ESBs can also have the contrary effect and create undesired tight coupling and a central architectural hotspot.\n\nEvent-driven architecture also aims at promoting loose coupling.\n\nLoose coupling of interfaces can be enhanced by publishing data in a standard format (such as XML or JSON).\n\nLoose coupling between program components can be enhanced by using standard data types in parameters. Passing customized data types or objects requires both components to have knowledge of the custom data definition.\n\nLoose coupling of services can be enhanced by reducing the information passed into a service to the key data. For example, a service that sends a letter is most reusable when just the customer identifier is passed and the customer address is obtained within the service. This decouples services because services do not need to be called in a specific order (e.g. GetCustomerAddress, SendLetter).\n\nLoose coupling of application integration in business process automation contexts can be increased by following a presentation layer integration model in which automation applications interact with underlying automated applications through the presentation layer or graphical user interface.\n\nCoupling refers to the degree of direct knowledge that one component has of another. Loose coupling in computing is interpreted as encapsulation vs. non-encapsulation.\n\nAn example of tight coupling occurs when a dependent class contains a pointer directly to a concrete class which provides the required behavior. The dependency cannot be substituted, or its \"signature\" changed, without requiring a change to the dependent class. Loose coupling occurs when the dependent class contains a pointer only to an interface, which can then be implemented by one or many concrete classes. The dependent class's dependency is to a \"contract\" specified by the interface; a defined list of methods and/or properties that implementing classes must provide. Any class that implements the interface can thus satisfy the dependency of a dependent class without having to change the class. This allows for extensibility in software design; a new class implementing an interface can be written to replace a current dependency in some or all situations, without requiring a change to the dependent class; the new and old classes can be interchanged freely. Strong coupling does not allow this.\n\nThis is a UML diagram illustrating an example of \"loose\" coupling between a dependent class and a set of concrete classes, which provide the required behavior:\n\nFor comparison, this diagram illustrates the alternative design with \"strong\" coupling between the dependent class and a provider:\n\nComputer programming languages having notions of either functions as the core module (see Functional programming) or functions as objects provide excellent examples of loosely coupled programming. Functional languages have patterns of Continuations, Closure, or generators. See Clojure and Lisp as examples of function programming languages. Object-oriented languages like Smalltalk and Ruby have code blocks, whereas Eiffel has agents. The basic idea is to objectify (encapsulate as an object) a function independent of any other enclosing concept (e.g. decoupling an object function from any direct knowledge of the enclosing object). See First-class function for further insight into functions as objects, which qualifies as one form of first-class function.\n\nSo, for example, in an object-oriented language, when a function of an object is referenced as an object (freeing it from having any knowledge of its enclosing host object) the new function object can be passed, stored, and called at a later time. Recipient objects (to whom these functional objects are given) can safely execute (call) the contained function at their own convenience without any direct knowledge of the enclosing host object. In this way, a program can execute chains or groups of functional objects, while safely decoupled from having any direct reference to the enclosing host object.\n\nPhone numbers are an excellent analog and can easily illustrate the degree of this decoupling.\n\nFor example: Some entity provides another with a phone number to call to get a particular job done. When the number is called, the calling entity is effectively saying, \"Please do this job for me.\" The decoupling or loose coupling is immediately apparent. The entity receiving the number to call may have no knowledge of where the number came from (e.g. a reference to the supplier of the number). On the other side, the caller is decoupled from specific knowledge of who they are calling, where they are, and knowing how the receiver of the call operates internally.\n\nCarrying the example a step further, the caller might say to the receiver of the call, \"Please do this job for me. Call me back at this number when you are finished.\" The 'number' being offered to the receiver is referred to as a \"Call-back\". Again, the loose coupling or decoupled nature of this functional object is apparent. The receiver of the call-back is unaware of what or who is being called. It only knows that it can make the call and decides for itself when to call. In reality, the call-back may not even be to the one who provided the call-back in the first place. This level of indirection is what makes function objects an excellent technology for achieving loosely coupled programs.\n\nThe degree of the loose coupling can be measured by noting the number of changes in data elements that could occur in the sending or receiving systems and determining if the computers would still continue communicating correctly. These changes include items such as:\n\n"}
{"id": "6415906", "url": "https://en.wikipedia.org/wiki?curid=6415906", "title": "Overbelief", "text": "Overbelief\n\nOverbelief (also written as \"over-belief\") is a philosophical term for a belief adopted that requires more evidence than one presently has. Generally, acts of overbelief are justified on emotional need or faith, and a need to make sense of spiritual experience, rather than on empirical evidence. This idea originates from the works of William James in The Varieties of Religious Experience and refers to the conceptual framework that individuals have. For James, a typical example of an overbelief would be R. W. Trine's contention that \"The great central fact of the universe is that spirit of infinite life and power that is back of all, that manifests itself in and through all.\" James acknowledges that his own over-beliefs are so minimal that to some religious believers they may seem like \"under-beliefs\".\n\n"}
{"id": "2498236", "url": "https://en.wikipedia.org/wiki?curid=2498236", "title": "People's Democracy (Ireland)", "text": "People's Democracy (Ireland)\n\nPeople's Democracy (PD) was a political organisation that, while supporting the campaign for civil rights for Northern Ireland's Catholic minority, stated that such rights could only be achieved through the establishment of a socialist republic for all of Ireland. It demanded more radical reforms of the government of Northern Ireland than the Northern Ireland Civil Rights Association it came from.\n\nIt was founded on 9 October 1968 at a meeting held in the Queen's University Belfast debating hall. A catalyst for its foundation had been the attack on a Northern Ireland Civil Rights Association (NICRA) march in Derry on 5 October by the Royal Ulster Constabulary (RUC).\n\nThe group consisted mainly of students who were involved with the Northern Ireland Civil Rights Association or left wing groups such as the Labour Clubs and Young Socialist Alliance.\n\nAt the meeting the group decided on five aims:\n\nIt was initially led by a committee of ten members which consisted of Queen's University students Malcolm Miles, Fergus Woods, Anne McBurnley, Ian Godall, Bernadette Devlin, Joe Martin, Eddie McCamely, Michael O'Kane and Patricia Drinan, as well as Kevin Boyle, a law lecturer at QUB. Other prominent members included Cyril Toman, Eamon McCann and Michael Farrell.\n\nThe name of the group was selected by accident, according to Bernadette Devlin.\nAfter marches in Belfast, in imitation of Martin Luther King, Jr.'s Selma to Montgomery marches, about 40 People's Democracy members held a four-day march between Belfast and Derry starting on 1 January 1969. The march was repeatedly attacked by loyalists along its route, including an incident at Burntollet bridge on 4 January where the marchers were attacked by about 200 unionists, including off-duty special constables, armed with iron bars, bottles and stones, while the RUC stood by and watched.\n\nPD became increasingly radicalised as a result of these events. They also attacked the censorship laws in the Republic — earning a rebuke from Ruairi Quinn and Basil Miller, then leaders of Students for Democratic Action, a revolutionary socialist student organisation, for letting British imperialism off the hook. In later years, members of the PD either quit politics altogether or became independent left-wing activists (such as Devlin and Farrell).\n\nIn 1971, PD became a founder of the Socialist Labour Alliance.\n\nIn the mid-1970s, the experience of the Ulster Workers' Council strike led to PD predicting a loyalist takeover in Northern Ireland, but it later came round to the view that this perspective was incorrect, giving loyalism a degree of autonomy from imperialism which it did not possess. The minority which clung to the old perspective left to form the Left Revolutionary Group, becoming the Red Republican Party in 1976, which was moribund by 1978.\n\nDuring the 1970s, PD evolved towards Trotskyist positions and, by merging with the Dublin-based Movement for a Socialist Republic, was recognised by the reunified Fourth International as its Irish section.\n\nPD was especially active around the issues of internment and prisoners' rights. Following the formation of the National H-Block/Armagh Committee in 1979 to build support for the Republican prisoners then on the \"blanket protest\" in support of political status and the subsequent death of Bobby Sands and nine of his comrades during the H-Block hunger strikes, a number of members of the organisation, led by Vincent Doherty - then a member of the Political Committee and a former party general election candidate - argued that PD should join Sinn Féin, which had moved openly to the left in the late 1970s and early 1980s.\n\nIn 1981, two members of People's Democracy were elected to Belfast City Council. John McAnulty and Fergus O'Hare were elected in a joint campaign with the IRSP. Fergus O'Hare won the council seat of Gerry Fitt, a sitting Westminster MP. O'Hare had been a founding member of the National H-Block/Armagh Committee and had previously been chairperson of the Political Hostages Release Committee which spearheaded the campaign against internment in the early 1970s. He subsequently went on to found the first Irish-language secondary school in Northern Ireland Meánscoil Feirste.\n\nWhen Sinn Féin ended its boycott of elections and gained mass support among the republican community, PD entered a political crisis. From 1982 on, a number of activists left them and joined Sinn Féin. At a PD national conference in 1986, a group including Anne Speed proposed the dissolution of the group and that the members all join SF as individuals. This position was defeated by 19 votes to five. A few weeks later the minority of five resigned from PD followed by their supporters and joined Sinn Féin. The remaining rump who continued to oppose this view maintained PD as a small propaganda group.\n\nIn the early 1990s the remaining members of PD initiated the Irish Committee for a Marxist Programme as an attempt to regroup socialists and left wing republicans. This project ended in 1996, when PD dissolved and reconstituted itself as Socialist Democracy, adopting the program put forward by the ICMP.\n\n\n"}
{"id": "34872017", "url": "https://en.wikipedia.org/wiki?curid=34872017", "title": "Personality changes", "text": "Personality changes\n\nSome debates have pervaded the field of psychology since its genesis. Perhaps one of the most salient ones deals with the nature of personality. Personality psychology studies one's distinctive style of cognition, behavior, and affect. However, this concept elicits discord among psychologists as some have insisted that it does not exist, while others struggle with issues of measurement.\n\nPersonality, one's characteristic way of feeling, behaving and thinking, is often conceptualized as a person's standing on each Big Five personality trait (extraversion, neuroticism, openness to experience, agreeableness and conscientiousness). A person's personality profile is thus gauged from their standing on five broad concepts which predict, among other life outcomes, behavior and the quality of interpersonal relationships. Initially, it was believed that one's Big Five profile was static and dichotomous in that one was either at one extreme of each trait or another \nFor example, people are typically categorized as introverted or extraverted. Personality was therefore assessed in terms of generalities or averages. In noticing the strong inconsistencies in how people behaved across situations, some psychologists dismissed personality as nonexistent.\n\nThis school of thought attributes human behavior to environmental factors, relegating individual differences to situational artifacts and contesting the existence of individual predispositions. It was led by situationists like Walter Mischel (1968). Their contention held that personality was a fictitious concept. For them, the discrepancies observed across one's behaviors were evidence that interindividual differences did not exist \nSome aspects of the situationist perspective even suggest that all human beings are the same and that the differences we observe are simply illusory biproducts of the environment. \nHowever, personologists soon integrated these inconsistencies into their conceptualization of personality. They modified the old, more monolithic construct by measuring how people differ across situations. Their new methods of personality assessment describe fluctuations in personality characteristics as consistent and predictable for each person based on the environment he is in and his predispositions. Some work suggests that people can espouse different levels of a personality dimension as the social situations and time of day change\nTherefore, someone is not conscientious all the time, but can be conscientious at work and a lot less so when she is home. This work also suggests that intrapersonal variations on a trait can be even larger than interpersonal variations. Extraversion varies more within a person than across individuals, for example. This work was based on individual self-ratings during the day across a long period of time. This allowed for researchers to assess moment-to-moment and day to day variations on personality attributes.\nPersonologists now tend to agree that people's personalities are variegated and are not to be conceptualized through bipolar characterizations (e.g. extraversion vs introversion). Rather people oscillate between the two extremes of a trait. The pattern of this oscillation then constitutes personality.\n\nIn addition, social roles (e.g. employee) have been identified as a potential sources of personality change. Researchers have found strong correspondences between the demands of a social role and one's personality profile. \nIf the role requires that the person enacting it be conscientious, her standing on this trait is more likely to be high. Conversely, once he leaves that role and or takes on another which entails less conscientiousness, he will manifest a lower level standing on that trait. Longitudinal research demonstrates that people's personality trajectories can often be explained by the social roles they espoused and relinquished throughout their life stages. Thus social roles are often studied as fundamental predictors of personality. \nThe goals associated with them elicit the appropriation of certain personality profiles by the people enacting them. For example, employees judged effective by their peers and superiors are often described as conscientious as well. \nPersonality also changes through life stages. This may be due to physiological changes associated with development but also experiences that impact behavior. Adolescence and young adulthood have been found to be prime periods of personality changes, especially in the domains of extraversion and agreeableness. It has long been believed that personality development is shaped by life experiences that intensify the propensities that led individuals to those experiences in the first place, which is known as the corresponsive principle.\n\nSubsequent research endeavors have integrated these findings in their methods of investigation. Researchers distinguish between mean level and rank order changes in trait standing during old age. \nTheir study of personality trajectories is thus contingent on time and on age considerations. Mottus, Johnson and Geary (2012) found that instability engendered by aging does not necessarily affect one's standing within an age cohort. Hence, fluctuations and stability coexist so that one changes relative to one's former self but not relative to one's peers. Similarly, other psychologists found that Neuroticism, Extraversion (only in men), and Openness decreased with age after 70, but Conscientiousness and Agreeableness increased with age (the latter only in men). Moreover, they suggest that there is a decline on each trait after the age of 81.\n\nPersonality inconsistency has become such a prevalent consideration for personologists that some even conceptualize it as a predisposition in itself. Fleisher and Woehr (2008) suggest that that consistency across the Big Five is a construct that is fairly stable and contributes to the predictive validity of personality measures. Hence inconsistency is quantifiable much like a trait and constitutes an index of and enhances the fit of psychological models.\n\nTo accommodate the inconsistency demonstrated on personality tests, researchers developed the Frame Of Reference principle (FOR). According to this theory, people tend to think of their personality in terms of a specific social context when they are asked to rate them. Whichever environment is cognitively salient at the time of the personality measurement will influence the respondent's ratings on a trait measure.\nIf, for example, the person is thinking in terms of their student identity, then the personality ratings he reports will most likely reflect the profile he espouses in the context of student life. Accounting for the FOR principle aims at increasing the validity of personality measures. This demonstrates that the predictive validity of personality measures which specify a social context is a lot higher than those measures which take a more generic approach.\nThis point is substantiated by yet another body of work suggesting that FOR instructions moderated the link between extraversion and openness scores on manager ratings of employee performance \nThis research thus recognizes the importance of intrapersonal fluctuations contingent on personality is context specific and is not necessarily generalizable across social domains and time.\n\nThere are two very specific types of change that researchers tend to focus on: rank-order change and mean-level change. A \"rank-order change\" refers to a change in an individual's personality trait relative to other individuals; such changes do not occur very often.\nA \"mean-level change\" refers to an absolute change in the individual's level of a certain trait over time. Longitudinal research shows that mean-level change does occur. However, some traits tend to change while some traits tend to stay stable.\n\nThere is an increase in consistency of a trait as age increases. However, personality does not stop changing at a specific age. Biological and social transitions in life may also be a factor for change. Biological transitions are stages like puberty or first childbirth. Social transitions might be changes in social roles like becoming a parent or working at a first job. These life transitions do not necessarily cause change, but they may be reasons for change. One theory says that whether or not these life transitions cause personality change is based on whether the transition was expected based on age or was unforeseen. The events that are expected will cause personality change because those events have common scripts. However, events that are unexpected will give prominence to the traits that already exist for the individual. Historical context also affects personality change. Major life events can lead to changes in personality that can persist for more than a decade. A longitudinal study followed women over 30 years and found that they showed increases in individualism. This may have been due to the changes that were occurring in the country at the time.\n\nNegative life events, long-term difficulties, and deteriorated life quality, all predict small but persistent increases in neuroticism, while positive life events, and improved life quality, predict small but persistent decreases in neuroticism. There appears to be no point during the lifespan that neuroticism is immutable, which is known as the plasticity principle.\n\nThere are multiple ways for an individual's personality to change. Individuals will change their behavior based on the ideas in their environment that emit rewards and punishments. Some of these ideas might be implicit, like social roles. The individual changes his or her personality to fit into a social role if it is favorable. Other ideas might be more explicit like a parent trying to change a child's behavior.\nAn individual may decide to actively try to change his or her own behavior/ personality after thinking about his or her own actions. Therapy involves the same type of introspection. The individual along with the therapist identifies the behaviors that are inappropriate, and then self-monitors in order to change them. Eventually the individual internalizes the behavior they want to attain, and that trait will generalize to other areas of the individual's life.\nPersonality change also occurs when individuals observe the actions of others. Individuals may mimic the behaviors of others and then internalize those behaviors. Once the individual internalizes those behaviors they are said to be a part of that person's personality.\nIndividuals also receive feedback from other individuals or groups about their own personality. This is a driving force of change because the individual has social motivations to change his or her personality. It has also been shown that major positive and negative life events can predict changes in personality.\n\nThe Big Five personality traits are often used to measure change in personality. There is a mean-level change in the Big Five traits from age 10 to 65.\nThe trends seen in adulthood are different from trends seen in childhood and adolescence. Some research suggests that during adolescence rank-order change does occur and therefore personality is highly unstable. Gender differences are also shown before adulthood. Conscientiousness drops from late childhood to adolescence, but then picks back up from adolescence into adulthood. Agreeableness also drops from late childhood to adolescence, but then picks back up from adolescence into adulthood. Neuroticism shows a different trend for males and females in childhood and adolescence. For females, Neuroticism increases from childhood to adolescence. Then Neuroticism levels from adolescence into adulthood and continues the adult trend of decreasing. Males however, tend to gradually decrease in Neuroticism from childhood to adolescence into adulthood. Extraversion drops from childhood to adolescence and then does not significantly change. Openness to experience also shows a different trend for different genders. Females tend to decrease in Openness to experience from childhood to early adulthood and then gradually increases all throughout adulthood. Males tend to decrease in Openness to experience from childhood to adolescence, then it tends to increase through adulthood. In adulthood, Neuroticism tends to decrease, while Conscientiousness and Agreeableness tend to increase. Extraversion and Openness to experience do not seem to change much during adulthood. These trends seen in adulthood are different from trends seen in childhood and adolescence. Cross-cultural research shows that German, British, Czech, and Turkish people show similar trends of these personality traits.\n\nThe Big Five personality traits can also be broken down into facets. Different facets of each personality trait are often correlated with different behavioral outcomes. Breaking down the personality traits into facets is difficult and not yet at a consensus. However, it is important to look at change in facets over a lifetime separate from just the change in traits because different facets of the same trait show different trends. Neuroticism can be broken into the two facets of anxiety and depression. Anxiety has the same trend as Neuroticism for both males and females. For females, anxiety increases from childhood to adolescence, at emerging adulthood it levels out, and then starts to decrease into and throughout middle age. Anxiety in males tends to decrease from late childhood through adulthood. Depression (not clinical depression, but rather susceptibility to negative affect) shows two peaks in females. Females tend to have higher levels of this kind of depression in adolescence and then again in early adulthood. Depression does, however, have a negative trend through adulthood. For males, depression tends to show an increase from childhood to early adulthood and then shows a slight decrease through middle age.\n\n"}
{"id": "2172175", "url": "https://en.wikipedia.org/wiki?curid=2172175", "title": "Planogram", "text": "Planogram\n\nPlanograms, also known as plano-grams, plan-o-grams, schematics and POGs, are visual representations of a store's products or services on display. They are considered a tool for visual merchandising. According to the \"Oxford English Dictionary\", a plangoram \"is a diagram or model that indicates the placement of retail products on shelves in order to maximize sales.\" The effectiveness of the planogram can be measured by the sales volume generated from the specific area being diagramed.\n\nPlanograms are predominantly used in retail businesses. A planogram defines the location and quantity of products to be placed on display. The rules and theories for creating planograms are set under the terms of merchandising. For example, given limited shelf space, a vendor may prefer to provide a wide assortment of products, or may limit the assortment but increase the facings of each product to avoid stock-outs. Manufacturers often send planograms to stores ahead of new product shipments. This is useful when a vendor wants retail displays in multiple store locations to have the same look and feel. Often, a consumer goods manufacturer releases a planogram with each new product to show how the product can relate to existing products.\n\nFast-moving consumer goods organizations and supermarkets mostly use text and box-based planograms to optimize shelf space, inventory turns and profit margins. Apparel brands and retailers are more focused on presentation and use pictorial planograms that illustrate the look and brand identity for each product.\n\nVisual product placement is supported by different theories including; horizontal, vertical, and block placement. Horizontal product placement increases the concentration of a certain article. Research studies suggest that a product's relation to customer eye levels directly correlates to its sales. This depends on the customer's distance from the unit. Vertical product placement puts products on more than one shelf level to achieve – of placement space. Similar products are placed in blocks.\n\nCommercial placement is determined by both market share placement and margin placement. Market share research companies like ACNielsen collect sales data for various products and calculate market share of products in various market segments. Margin placement is determined by the profit margin of a specific item. Higher margin places a product closer to the front of the store, where it is most likely to attract attention.\n\n\nThe planogram concept originated with KMart. Planograms are created with the help of planogramming software by a Planogram Specialist, Space Planning Specialist or Space Planning Manager. The retail industry utilizes software to ensure proper stocking. Retailers turn to planogram software to reflect each store’s particular customer profile and localized demand, while maintaining centralized control and supply chain efficiency. \n\nFor example, some software packages focused upon fast-moving consumer goods and hard goods sectors made enhancements to transfer parts of shelving elements to single store measurements, which, according to the producers, should increase efficiency.\n\nRetailers automate the creation of store-specific planograms through use of corporate-level business rules and constraints describing best practices. Such planogramming solutions allow these companies to respond with location and language-specific messaging, pricing, and product placements based on business rules derived from location, campaign and fixture attributes to create localized assortments.\n\nRecent advances in store virtualization and collaboration allow manufacturers, retailers and category management experts from across the globe to work in the same virtual store in real time. \n"}
{"id": "278439", "url": "https://en.wikipedia.org/wiki?curid=278439", "title": "Power vacuum", "text": "Power vacuum\n\nIn political science and political history, the term power vacuum, also known as a power void, is an analogy between a physical vacuum, to the political condition \"when someone has lost control of something and no one has replaced them.\" The situation can occur when a government has no identifiable central power or authority. The physical analogy suggests that in a power vacuum, other forces will tend to \"rush in\" to fill the vacuum as soon as it is created, perhaps in the form of an armed militia or insurgents, military coup, warlord or dictator. The term is also often used in organized crime when a crime family becomes vulnerable to competition.\n\nHereditary or statutory order of succession or effective succession planning are orderly ways to resolve questions of succession to positions of power. When such methods are unavailable, such as in failed dictatorships or civil wars, a power vacuum arises, which prompts a power struggle entailing political competition, violence, or (usually) both. A power vacuum can also occur after a constitutional crisis in which large portions of the government resign or are removed, creating unclear succession.\n\nHistoric examples include the death of Alexander the Great, the 11th century power vacuum in the middle east which allowed the Seljuks to take over, the defeat of France in the Franco-Prussian War, the death of Vladimir Lenin, and the decrease in power of Great Britain and France in the Middle East after the Suez Crisis.\n\nDuring the course of the Ming treasure voyages (1405-1433), the Chinese Ming empire was the dominant political and military force within the Indian Ocean. However, in 1433, the Chinese government withdrew their treasure fleet and thus left a large void within the Indian Ocean.\n\nWhen in 2003 the United States led a coalition to oust Saddam Hussein in the Iraq War, the absence of an all-out Iraqi opposition force at war with government forces meant that once the Ba'ath Party was removed, no local figures were on hand to immediately assume the now-vacant administerial posts. For this reason, Paul Bremer was appointed by the United States government as the interim head of state to oversee the transition.\n\nIn other western-led interventions such as in Kosovo (1999) and Libya (2011) where the initial claim of justification in each case was a humanitarian matter, there had been active opposition fighting on the ground to oust the relevant governments (in the case of Kosovo, this meant removal of state forces from the desired territory rather than ousting the government itself). Subsequently, successor entities were immediately effective in Libya and Kosovo.\n\n"}
{"id": "56413729", "url": "https://en.wikipedia.org/wiki?curid=56413729", "title": "Recycling rates by country", "text": "Recycling rates by country\n\nThe following table gives the percentages of material that is recycled, incinerated, incinerated to produce energy and landfilled.\n"}
{"id": "7963663", "url": "https://en.wikipedia.org/wiki?curid=7963663", "title": "Red Power movement", "text": "Red Power movement\n\nThe Red Power movement was a social movement led by Native American youth to demand self-determination for Native Americans in the United States. Organizations that were part of Red Power Movement included American Indian Movement (AIM) and National Indian Youth Council (NIYC). This movement sought the rights for Native Americans to make policies and programs for themselves while maintaining and controlling their own land and resources. The Red Power movement took a confrontational and civil disobedience approach to inciting change in United States to Native American affairs compared to using negotiations and settlements, which national Native American groups such as National Congress of American Indians had before. Red Power centered around mass action, militant action, and unified action.\n\nThe phrase \"Red Power\", attributed to the author Vine Deloria, Jr, commonly expressed a growing sense of pan-Indian identity in the late 1960s among American Indians in the United States.\n\nEvents that were part of the movement include the Occupation of Alcatraz, the Trail of Broken Treaties, the Occupation of Wounded Knee, along with intermittent protests and occupations throughout the era. The lasting impression of the Red Power movement was the resurrection of American Indian pride, action, and awareness. Many bills and laws were also enacted in favor of American Indians in response to the Red Power movement, one of the most important being the reversal of tribe recognition termination.\n\nFrom 1953 to 1964, the United States government terminated recognition of more than 100 tribes and bands as sovereign dependent nations with the House Concurrent Resolution 108. This resolution stated that the tribes would be under US law and treated as American citizens instead of having the status as wards of the US. The affected tribes were no longer protected by the government and stripped of their right to govern their own people.\n\nThe Relocation Act of 1956 resulted in as many as 750,000 American Indians migrating to cities during the period from 1950-1980. This Act was implemented to encourage and provide support for American Indians to find jobs in cities and improve their lives from the poverty-ridden reservations. The government offered vocational training, housing, and financial support for those who chose to relocate. These promised amenities were often not provided or inadequately provided, resulting in American Indians distanced from their cultural lands and economically worse off than before.\n\nThe Relocation and Termination era described above fueled the resistance of American Indians. The oldest recognized National American Indian group was National Congress of American Indians (NCAI), established in 1944. NCAI set a precedent by successfully being the first multi-tribal political organization run entirely by Indians. NCAI fought against voting discrimination, against the termination of government to government relationship between the US and native tribes, and against US interference in tribal counsels. They aimed to close gaps between Indians who lived on reservations and those who had relocated to cities, elderly and Indian Youth, and different tribes from one another. NCAI was the main political organization that preceded the Red Power Movement.\n\nAt the forefront of the Red Power Movement was American Indian Movement(AIM), which was founded in 1968 in Minneapolis, Minnesota. Its members belonged to and represented mainly urban Indian communities, and its leaders were young and militant. Like the Black Panthers and Brown Berets, AIM was initially organized to work for Indian civil rights in cities. Its members monitored law enforcement practices, and worked to highlight and prevent police harassment and brutality. AIM soon played a major role in building a network of urban Indian centers, churches and philanthropic organizations. It helped establish the \"powwow circuit,\" which publicized news of protest activities across the country. Skillful in attracting attention from the news media, AIM inspired local chapters and writing about American Indian political issues.\n\nThe National Indian Youth Council(NIYC) was founded in 1961 by young American Indians who were college students or recent college graduates. They were one of the first militant Indian rights organizations following the conservative ways of the NCAI. NIYC were strong opponents of the Bureau of Indian Affairs and got involved in many of the events in the Red Power Movement. Like AIM, the council believed in and fought for the recognition of tribes federally and reinstating tribal governance.\n\nWomen of All Red Nations (WARN) emerged in 1974 from the main founders, Lorelei DeCora Means, Madonna Thunderhawk, Phyllis Young, Janet McCloud, and others. WARN acted as a branch from AIM that focused on American Indian women's and family rights. Main issues that WARN fought against were the forced sterilization of Native women and the lack of adequate health services on the reservations. WARN took action by becoming involved in Indian custody battles, protesting mining companies who were poisoning food and water sources, and collecting data on Indian women who had been sterilized without consent.\n\nThe International Indian Treaty Council (IITC) was founded in 1974 in Standing Rock, South Dakota. More than 98 Indigenous tribes were represented by over 5000 people at this first gathering. IITC grew into a voice for Indians internationally—covering North, Central, and South America, the Caribbean, and the Pacific. IITC focuses on the pursuit of sovereignty and self-determination for indigenous peoples through activism, training, and unified gatherings. As the first indigenous organization to be granted Consultive Status by the United Nations Economic and Social Council (ECOSOC) in 1977, IITC was able to represent the concerns and fight for the acknowledgement of indigenous rights to the UN.\n\nFrom 1969 to the Longest Walk of 1978, the Red Power Movement highlighted issues through social protest. Its goals were for the federal government to honor treaty obligations and provide financial \"resources, education, housing and healthcare to alleviate poverty.\" The RPM wanted to gain Indian participation in social institutions; it was instrumental in supporting the founding of Indian colleges, as well as the creation of Indian studies programs at existing institutions, and the establishment of museums and cultural centers to celebrate Indian contributions.\n\nThe 1960s marked the beginning of a \"Native American Renaissance\" in literature. New books such as Vine Deloria, Jr.'s \"Custer Died for Your Sins\" (1969) and the classic \"Black Elk Speaks\" (1961), reprinted from the 1930s, reached millions of readers inside and outside Indian communities. A wide variety of Indian writers, historians, and essayists gained publication following these successes and new authors were widely read. N. Scott Momaday won the Pulitzer Prize for one of his novels and Leslie Silko received acclaim. Fiction and nonfiction works about Indian life and lore have continued to attract a large audience. Authors such as Louise Erdrich and Michael Dorris have earned continued recognition. Since the late twentieth century, novels by Sherman Alexie have been adapted for film as well.\n\nThe Occupation of Alcatraz began on November 20, 1969 when more than 80 young, mostly college aged American Indians, who identified themselves as Indians of All Tribes (IAT) boarded boats to approach and occupy Alcatraz Island overnight. The young American Indians settled with the legal backing of a Sioux Treaty that named any federal \"out of use\" land available for Indians. The US federal government had closed the Alcatraz federal prison and the island was no longer in use as of 1962. This treaty was used to send the message that treaties are still relevant and should be honored. \n\nThe occupation had been planned ahead of time by Adam Nordwall, a successful Indian businessman, and Richard Oakes, a San Francisco State student. The two agreed to and told sympathetic media outlets about their plan to take over Alcatraz at a dinner party hosted by \"San Francisco Chronicle\" reporter Tim Findley. They threatened that if there were any leaks of the story early, the plan to occupy Alcatraz would be called off. Their first attempt, on November 9, 1969—the date the media had been told—resulted in circling the island in a boat with media coverage from all over the Bay Area. Although they did not begin the occupation that night, Oakes jumped off of the circling boat as others followed and swam to Alcatraz. After making it to Alcatraz, the young Indians were removed by Coast Guard that night but would be back in much larger numbers on November 20.During the occupation, IAT released a statement called the Alcatraz Proclamation which explained that the Indians had the right to Alcatraz Island due to the right to discovery. The Proclamation continued onto describing the deserted prison island as comparable to the conditions of the Indian Reservations. IAT was also joined by National Indian Youth Council (NIYC) during the Alcatraz movement and the growing group of young, educated, and passionate American Indians made their presence known in the media. Richard Oakes became the public figure for the occupation and participated in the press conferences for releases of documents such as the Alcatraz Proclamation and goals for the island which included building cultural centers, educational facilities, and recreational spaces for Indians to be together as Indians.\n\nThe Occupation of Alcatraz ended after a series of disorienting events on the island. The January 1970 death of Richard Oakes' 13-year-old stepdaughter due to falling from a building brought Richard and his wife Anne back to the mainland. Some of the student occupiers went back to school when the Oakes' left. A problem of drug and alcohol abuse also became prominent on the island, which affected the occupations reputation. The remaining leaders were John Trudell, LaNada Means, and Stella Leach, who could not end up agreeing on a way to further develop the occupation. Electricity and water being cut off to the island by May, and a suspicious fire that burned three buildings were further factors that led to the dismantling of the occupation. Protestors continued to depart from the island during the downward spiral. On June 11, 1971 a large amount of police officers used force to remove the remaining few protestors.\n\nAlthough the protesters ultimately failed to achieve their specific goals, they helped catalyze the Indian community. With the occupation of Alcatraz, a participant said, \"we got back our worth, our pride, our dignity, our humanity.\"\n\nWith young, college aged students at the center of many Red Power movement protests, the pursuit of higher education, particularly for American Indians became a main initiative. In 1970, while the Alcatraz occupation was still occurring, a group of Indian youth took over US military surplus land near Davis, California. These youth had applied for the land but were denied access after UC Davis was granted access, regardless of UC Davis' legally incomplete application. In retaliation, the youth hopped the fences onto the property leading to the establishment and occupation of D-Q University. D-Q University became the first tribal university that was established in California, and the first that was not affiliated with a single reservation. A deed was granted to the student occupation in April 1971. Since then, D-Q University became part of the Tribal Colleges and Universities and received accreditation in 1977. The curriculum of D-Q University included cultural and traditional focused education in order to educate Indians about Indians. The university struggled to keep enrollment rates up and secure funding, which resulted in the ultimate loss of accreditation in 2005. However, the occupation that created D-Q University highlighted the importance of higher education for American Indians to the Red Power Movement.\n\nIn August 1972, the Red Power movement continued under the direction of American Indian Movement(AIM) with the trail of broken treaties. The trail of broken treaties, a play on the \"Trail of Tears,\" was the migration of seven caravans from areas across the west coast to the Bureau of Indian Affairs (BIA) in Washington D.C. The BIA had become widely associated with corruption and not acting in the best interest of the American Indians. The protestors started arriving in D.C. on November 1 with the intent of bringing a list of twenty demands to the BIA. Upon arrival, the activists and GSA security had a misunderstanding about the activists being housed in the BIA building. This resulted in the activists overpowering the security and taking over the building. The American Indians then barricaded the doors, with furniture from the BIA they had broken apart, and the occupation began on November 2, 1972. This occupation of the BIA had started the week before the presidential election, making a D.C. occupation the center of media attention. Threats of police force were used daily against the Indians if they did not come out. Supporters from outside of the occupation would come to the BIA to create a human barricade keeping the police from entering the occupied building. On November 6, a judge had given an order for the occupiers to vacate the building before 6 pm that day or they would be forcibly evicted. As the Indians braced for eviction, some exited the building to create a perimeter around it with clubs, spears and other weaponry to resist. Others inside the building were rumored to have guns and explosives awaiting the invasion of GSA officials. The spokesman of the occupation, Russel Means, spoke on the front stairs of the BIA explaining that the occupation would end when their demands had been met, and no time sooner. The deadline for the Indians to leave was pushed back yet again to November 8. Before this date, Indian lawyers had discovered evidence that would essentially abolish the BIA with exposure of corruption and misuse of the program. On November 8, the protestors left the BIA building with paintings, artifacts, and $2 million worth of damage.\n\nThe Wounded Knee Incident started on February 27, 1973 and lasted 71 days. More than 200 Indians in support of the Oglala Sioux people of Pine Ridge Reservation took over the town of Wounded Knee, South Dakota. The Oglala Sioux Civil Rights Organization (OSCRO), a group of mostly full-Indian women that lived on Pine Ridge Reservation had been unsuccessful in a trial to impeach Dick Wilson, who was the chairman of the Oglala Sioux Tribal Council. Critics of Wilson claimed he was too close to white people, too cozy with the government, and was disrespecting his Oglala Sioux culture. Enraged that Wilson had not been impeached, OSCRO continued to gather and brainstorm a response. They decided to ask AIM for help in reacting to what they felt was an injustice. With AIM in the picture, occupying Wounded Knee was their final decision.\n\nWounded Knee was chosen as a tribute to the Wounded Knee Massacre of 1890, where hundreds of Lakota Indians were killed by the 7th US Cavalry Regiment in reported efforts to disarm the Indians. As a historical remembrance of the massacre, the town had visitor trade posts dedicated to the grave sites of the Indians that many Indians thought were disrespectful and used for commercial purposes. The owners of the trade posts would sell native Indian crafts for more than they had bought them and had a history of racism towards the local Indians. The occupiers attacked the trade posts first to accumulate the ammunitions and weaponry that were held there. The occupation formed to deliver a message that American Indians would not sit around peacefully as treaties were broken, unfair trials were given, and their land was ceded. Federal agents gathered around Wounded Knee while the occupiers would host events for the media to cover in order to promote their message. Throughout the occupation of Wounded Knee, the protestors and federal agents would often have shootouts at night. The Indians would be shooting from inside Wounded Knee and the federal agents from the outside perimeter they had formed. From these shootouts, two Indians were killed and one federal agent was permanently paralyzed. The death of the second Indian, who was from the Pine Ridge Reservation and an Oglala Sioux, Buddy Lamont, led many Indians to seek an end to the violent occupation. On May 8, 1973 the American Indians surrendered to the surrounding federal agents after 10 weeks. Russell Means, one of the more recognized leaders of the AIM, negotiated with U.S. forces to release the hostages on the premises that the U.S. Senate Foreign Relations Committee hold hearings on the Indian treaties that were broken by the U.S. government as well as investigations of the Bureau of Indian Affairs and its members' attention to the living conditions at Pine Ridge.\n\nThis event is not only significant because it was one of the first violent acts initiated first by the Natives, but it also led to generations of Indians getting involved in civil rights and tribal affairs. The Nixon administration had earlier declared that it had wanted to end the \"revolutionary Indian element\", but because so many Natives took notice and began to make changes in the local governments controlling their reservations, the administration failed to end their protests and stopped trying to interfere.\n\nRussell Means and Dennis Banks, the two AIM leaders mostly in charge of Wounded Knee II, were arrested immediately after the hostages were released. However, on September 16, 1973, the charges were dropped and they were dismissed on the account that the U.S. government had unlawfully influenced witnesses and tampered with evidence. The violence of these types of protests then continued through the rest of the 1970s.\n\nThe following is a list of occupations by Red Power activists:\n\nThe Red Power movement had accomplished many of its goals by the time direct social activism declined in the late 1970s. \"By the early 1980s, over 100 Indian studies programs had been created in the United States. Tribal museums opened.\" Among the most prominent of the cultural centers is the National Museum of the American Indian (NMAI), which was sponsored by Hawaii's senator Daniel Inouye and authorized by the US Congress in 1989. The NMAI opened on the Mall in Washington, DC in 2004. It also has a branch at the former US Customs House, on the Bowling Green in Lower Manhattan.\n\nMany laws were passed in response to the Red Power movement, one of the most notable being the Indian Self-Determination and Education Assistance Act of 1975, which reversed the termination of federal tribe recognition. This act restored the recognition and government to government status to tribes, giving them control to govern their own tribes and reservations with funding provided by the government if they followed certain guidelines. Since the termination of Indian tribe recognition was a major catalyst to start the movement, regaining recognition was considered a huge success for RPM.\n\nThe following laws were passed during the movement:\n\n\n"}
{"id": "56460428", "url": "https://en.wikipedia.org/wiki?curid=56460428", "title": "Reduce (parallel pattern)", "text": "Reduce (parallel pattern)\n\nReduce is a collective communication primitive used in the context of a parallel programming model to combine multiple vectors into one, using an associative binary operator formula_1. Every vector is present at a distinct processor in the beginning. The goal of the primitive is to apply the operator in the order given by the processor-indices to the vectors until only one is left. The reduction of sets of elements is an integral part of programming models such as Map Reduce, where a function is applied (mapped) to all elements before they are reduced. Other parallel algorithms use reduce as a primary operation to solve more complex problems. The Message Passing Interface implements it in the operations codice_1 and codice_2, with the difference that the result is available at one (root) processing unit or all of them. Closely related to reduce is the broadcast operation, which distributes data to all processors. Many reduce algorithms can be used for broadcasting by reverting them and omitting the operator.\n\nFormally, reduce takes an associative (but not necessarily commutative) operator formula_1, which can be evaluated in constant time and an input set formula_3of formula_4 vectors with formula_5 elements each. The total size of a vector is defined as formula_6. The result formula_7 of the operation is the combination of the elements formula_8 and has to be stored at a specified root processor at the end of the execution. For example, the result of a reduction on the set formula_9, where all vectors have size one is formula_10. If the result formula_7 has to be available at every processor after the computation has finished, it is often called Allreduce. An optimal sequential linear-time algorithm for reduction can apply the operator successively from front to back, always replacing two vectors with the result of the operation applied to all its elements, thus creating an instance that has one vector less. It needs formula_12 steps until only formula_7 is left. Sequential algorithms can not perform better than linear time, but parallel algorithms leave some space left to optimize.\n\nRegarding parallel algorithms, there are two main models of parallel computation, the parallel random access machine as an extension of the RAM with shared memory between processing units and the bulk synchronous parallel computer which takes communication and synchronization into account. Both models have different implications for the time-complexity, therefore two algorithms will be shown.\n\nThis algorithm represents a widely spread method to handle inputs where formula_4 is a power of two. The reverse procedure is often used for broadcasting elements.\nThe binary operator for vectors is defined such that formula_25. The algorithm further assumes that in the beginning formula_26 for all formula_21 and formula_4 is a power of two and uses the processing units formula_29. In every iteration, half of the processing units become inactive and do not contribute to further computations. The figure shows a visualization of the algorithm using addition as the operator. Vertical lines represent the processing units where the computation of the elements on that line take place. The eight input elements are located on the bottom and every animation step corresponds to one parallel step in the execution of the algorithm. An active processor formula_19 evaluates the given operator on the element formula_31 it is currently holding and formula_32 where formula_33 is the minimal index fulfilling formula_34, so that formula_35 is becoming an inactive processor in the current step. formula_31 and formula_32 are not necessarily elements of the input set formula_38 as the fields are overwritten and reused for previously evaluated expressions. To coordinate the roles of the processing units in each step without causing additional communication between them, the fact that the processing units are indexed with numbers from formula_39 to formula_40 is used. Each processor looks at its formula_20-th least significant bit and decides whether to get inactive or compute the operator on its own element and the element with the index where the formula_20-th bit is not set. The underlying communication pattern of the algorithm is a binomial tree, hence the name of the algorithm.\n\nOnly formula_43 holds the result in the end, therefore it is the root processor. For an Allreduce-operation the result has to be distributed, which can be done by appending a broadcast from formula_43. Furthermore, the number formula_4 of processors is restricted to be a power of two. This can be lifted by padding the number of processors to the next power of two. There are also algorithms that are more tailored for this use-case.\n\nThe main loop is executed formula_46 times, the time needed for the part done in parallel is in formula_47 as a processing unit either combines two vectors or becomes inactive. Thus the parallel time formula_48 for the PRAM is formula_49. The strategy for handling read and write conflicts can be chosen as restrictive as an exclusive read and exclusive write (EREW). The efficiency formula_50 of the algorithm is formula_51 and therefore the efficiency is formula_52. The efficiency suffers because of the fact that half of the active processing units become inactive after each step, so formula_53 units are active in step formula_21.\n\nIn contrast to the PRAM-algorithm, in the distributed memory model memory is not shared between processing units and data has to be exchanged explicitly between units, resulting in communication overhead that is accounted for. The following algorithm takes this into consideration.\nThe only difference between the distributed algorithm and the PRAM version is the inclusion of explicit communication primitives, the operating principle stays the same.\n\nA simple analysis for the algorithm uses the BSP-model and incorporates the time formula_68 needed to initiate communication and formula_69 the time needed to send a byte. Then the resulting runtime is formula_70, as formula_5 elements of a vector are send in each iteration and have size formula_6 in total.\n\nFor distributed memory models, it can make sense to use pipelined communication. This is especially the case when formula_68 is small in comparison to formula_69. Usually, linear pipelines split data or a task into smaller pieces and process them in stages. In contrast to the binomial tree algorithms, the pipelined algorithm uses the fact that the vectors are not inseparable, but the operator can be evaluated for single elements:\n\nIt is important to note that the send and receive operations have to be executed concurrently for the algorithm to work. The result vector is stored at formula_86 at the end. The associated animation shows an execution of the algorithm on vectors of size four with five processing units. Two steps of the animation visualize one parallel execution step. The number of steps in the parallel execution are formula_87, it takes formula_40 steps until the last processing unit receives its first element and additional formula_89 until all elements are received. Therefore, the runtime in the BSP-model is formula_90, assuming that formula_6 is the total byte-size of a vector.\n\nAlthough formula_5 has a fixed value, it is possible to logically group elements of a vector together and reduce formula_5. For example, a problem instance with vectors of size four can be handled by splitting the vectors into the first two and last two elements, which are always transmitted and computed together. In this case, double the volume is send each step, but the number of steps has roughly halved. It means that the parameter formula_5 is halfed, while the total byte-size formula_6 stays the same. The runtime formula_96 for this approach depends on the value of formula_5, which can be optimized if formula_68 and formula_69 are known. It is optimal for formula_100, assuming that this results in a smaller formula_5 that divides the original one.\n\nThe binomial tree and the pipeline both have their advantages and disadvantages, depending on the values of formula_68 and formula_69 for the parallel communication. While the binomial tree algorithm is better suited for small vectors, the pipelined algorithm profits from a distribution of the elements to fewer processing units with more elements contained in one vector. Both approaches can be combined into one algorithm which uses a tree as its underlying communication pattern and splits the computation of the operator into pieces at the same time. Instead of the binomial tree, a Fibonacci tree is used which has the property that the height of the trees rooted at its two children differ by one. It helps to balance the load on all processing units as each unit can only evaluate one operator in one iteration on one of its elements, but it has two child-processors it receives values from.\n\nThe animation shows the execution of such an algorithm in a full-duplex communication model. Communication links are represented by black lines between the vectors of elements and build a Fibonacci tree of size seven in this example. If an element is send to another processing unit the link is colored with the color of the corresponding element. An element that is received by a processor is added to the already existing element of same color (at the same index in the vector).\n\nThe algorithm itself propagates the partial sums from bottom to top until all elements are contained in the sum at the root processor on top. In the first step of the execution, the processing units which are leafs in the underlying tree send their first elements to their parent. This is similar to the send operations of the binomial tree algorithm with the key difference that the leaf units each have two more elements which have to be send and therefore do not become inactive, but can continue to send elements, which is analogous to the pipelined approach and improves efficiency. Processing units that are not leafs start to send their elements in order of the indices in the vector once they have received an element from a child. In the example they send green, blue and red elements in this order. If two processors compete to send their elements to the same processor, then the element of the right child is received first. Because of the structure of the Fibonacci tree all processors send or receive elements while the \"pipeline\" is filled. The pipeline is filled from the point where each unit has received an element and until the leaf units have no more elements to send.\n\nEach iteration of the algorithm takes at most time formula_104. The height of the tree factors into the time it needs to fill the pipeline and for Fibonacci trees it is known to be about formula_105 where formula_106 is the golden ratio. Once the pipeline is filled, all processors are active in each step. Because inner nodes have two children, they have to receive formula_107 elements. Therefore, the runtime of the algorithm is formula_108. It is minimal if the number of elements in a vector is chosen such that formula_109.\n\nReduction is one of the main collective operations implemented in the Message Passing Interface, where performance of the used algorithm is important and evaluated constantly for different use cases.\n\nMapReduce relies heavily on efficient reduction algorithms to process big data sets, even on huge clusters.\n\nSome parallel sorting algorithms use reductions to be able to handle very big data sets.\n\n"}
{"id": "236098", "url": "https://en.wikipedia.org/wiki?curid=236098", "title": "Subsequence", "text": "Subsequence\n\nIn mathematics, a subsequence is a sequence that can be derived from another sequence by deleting some or no elements without changing the order of the remaining elements. For example, the sequence formula_1 is a subsequence of formula_2 obtained after removal of elements formula_3, formula_4, and formula_5. The relation of one sequence being the subsequence of another is a preorder.\n\nThe subsequence should not be confused with substring formula_6 which can be derived from the above string formula_2 by deleting substring formula_8. The substring is a refinement of the subsequence. \n\nThe list of all subsequences for the word \"apple\" would be \"a, ap, al, ae, app, apl, ape, ale, appl, appe, aple, apple, p, pp, pl, pe, ppl, ppe, ple, pple, l, le, e\". \n\nGiven two sequences \"X\" and \"Y\", a sequence \"Z\" is said to be a \"common subsequence\" of \"X\" and \"Y\", if \"Z\" is a subsequence of both \"X\" and \"Y\". For example, if\n\nthen a common subsequence of \"X\" and \"Y\" could be\n\nThis would \"not\" be the \"longest common subsequence\", since \"Z\" only has length 3, and the common subsequence formula_12 has length 4. The longest common subsequence of \"X\" and \"Y\" is formula_13.\n\nSubsequences have applications to computer science, especially in the discipline of bioinformatics, where computers are used to compare, analyze, and store DNA, RNA, and protein sequences.\n\nTake two sequences of DNA containing 37 elements, say:\n\nThe longest common subsequence of sequences 1 and 2 is:\n\nThis can be illustrated by highlighting the 27 elements of the longest common subsequence into the initial sequences:\n\nAnother way to show this is to \"align\" the two sequences, \"i.e.\", to position elements of the longest common subsequence in a same column (indicated by the vertical bar) and to introduce a special character (here, a dash) in one sequence when two elements in the same column differ:\n\nSubsequences are used to determine how similar the two strands of DNA are, using the DNA bases: adenine, guanine, cytosine and thymine.\n\n\n"}
{"id": "46513756", "url": "https://en.wikipedia.org/wiki?curid=46513756", "title": "The unexamined life is not worth living", "text": "The unexamined life is not worth living\n\n\"The unexamined life is not worth living\" () is a famous dictum apparently uttered by Socrates at his trial for impiety and corrupting youth, for which he was subsequently sentenced to death, as described in Plato's \"Apology\" (38a5–6).\n\nThis statement relates to Socrates' understanding and attitude towards death and his commitment to fulfill his goal of investigating and understanding the statement of the Pythia. Socrates understood the Pythia's response to Chaerephon's question as a communication from the god Apollo and this became Socrates's prime directive, his \"raison d'etre\". For Socrates, to be separated from elenchus by exile (preventing him from investigating the statement) was therefore a fate worse than death. Since Socrates was religious and trusted his religious experiences, such as his guiding daimonic voice, he accordingly preferred to continue to seek the truth to the answer to his question, in the after-life, than live a life not identifying the answer on earth.\n\nThe words were supposedly spoken by Socrates at his trial after he chose death rather than exile. They represent (in modern terms) the noble choice, that is, the choice of death in the face of an alternative.\n\nSocrates believed that philosophy – \"the love of wisdom\" – was the most important pursuit above all else. For some, he exemplifies more than anyone else in history the pursuit of wisdom through questioning and logical argument, by examining and by thinking. His 'examination' of life in this way spilled out into the lives of others, such that they began their own 'examination' of life, but he knew they would all die one day, as saying that a life without philosophy – an 'unexamined' life – was not worth living.\n\n"}
{"id": "833690", "url": "https://en.wikipedia.org/wiki?curid=833690", "title": "Tolerance interval", "text": "Tolerance interval\n\nA tolerance interval is a statistical interval within which, with some confidence level, a specified proportion of a sampled population falls. \"More specifically, a 100×p%/100×(1−α) tolerance interval provides limits within which at least a certain proportion (p) of the population falls with a given level of confidence (1−α).\" \"A (p, 1−α) tolerance interval (TI) based on a sample is constructed so that it would include at least a proportion p of the sampled population with confidence 1−α; such a TI is usually referred to as p-content − (1−α) coverage TI.\" \"A (p, 1−α) upper tolerance limit (TL) is simply an 1−α upper confidence limit for the 100 p percentile of the population.\"\n\nA tolerance interval can be seen as a statistical version of a probability interval. \"In the parameters-known case, a 95% tolerance interval and a 95% prediction interval are the same.\" If we knew a population's exact parameters, we would be able to compute a range within which a certain proportion of the population falls. For example, if we know a population is normally distributed with mean formula_1 and standard deviation formula_2, then the interval formula_3 includes 95% of the population (1.96 is the z-score for 95% coverage of a normally distributed population).\n\nHowever, if we have only a sample from the population, we know only the sample mean formula_4 and sample standard deviation formula_5, which are only estimates of the true parameters. In that case, formula_6 will not necessarily include 95% of the population, due to variance in these estimates. A tolerance interval bounds this variance by introducing a confidence level formula_7, which is the confidence with which this interval actually includes the specified proportion of the population. For a normally distributed population, a z-score can be transformed into a \"\"k\" factor\" or tolerance factor for a given formula_7 via lookup tables or several approximation formulas. \"As the degrees of freedom approach infinity, the prediction and tolerance intervals become equal.\"\n\nThe tolerance interval is less widely known than the confidence interval and prediction interval, a situation some educators have lamented, as it can lead to misuse of the other intervals where a tolerance interval is more appropriate.\n\nThe tolerance interval differs from a confidence interval in that the confidence interval bounds a single-valued population parameter (the mean or the variance, for example) with some confidence, while the tolerance interval bounds the range of data values that includes a specific proportion of the population. Whereas a confidence interval's size is entirely due to sampling error, and will approach a zero-width interval at the true population parameter as sample size increases, a tolerance interval's size is due partly to sampling error and partly to actual variance in the population, and will approach the population's probability interval as sample size increases.\n\nThe tolerance interval is related to a prediction interval in that both put bounds on variation in future samples. The prediction interval only bounds a single future sample, however, whereas a tolerance interval bounds the entire population (equivalently, an arbitrary sequence of future samples). In other words, a prediction interval covers a specified proportion of a population \"on average\", whereas a tolerance interval covers it \"with a certain confidence level\", making the tolerance interval more appropriate if a single interval is intended to bound multiple future samples.\n\n gives the following example: So consider once again a proverbial EPA mileage test scenario, in which several nominally identical autos of a particular model are tested to produce mileage figures formula_9. If such data are processed to produce a 95% confidence interval for the mean mileage of the model, it is, for example, possible to use it to project the mean or total gasoline consumption for the manufactured fleet of such autos over their first 5,000 miles of use. Such an interval, would however, not be of much help to a person renting one of these cars and wondering whether the (full) 10-gallon tank of gas will suffice to carry him the 350 miles to his destination. For that job, a prediction interval would be much more useful. (Consider the differing implications of being \"95% sure\" that formula_10 as opposed to being \"95% sure\" that formula_11.) But neither a confidence interval for formula_1 nor a prediction interval for a single additional mileage is exactly what is needed by a design engineer charged with determining how large a gas tank the model really needs to guarantee that 99% of the autos produced will have a 400-mile cruising range. What the engineer really needs is a tolerance interval for a fraction formula_13 of mileages of such autos.\n\nAnother example is given by: The air lead levels were collected from formula_14 different areas within the facility. It was noted that the log-transformed lead levels fitted a normal distribution well (that is, the data are from a lognormal distribution. Let formula_1 and formula_16, respectively, denote the population mean and variance for the log-transformed data. If formula_17 denotes the corresponding random variable, we thus have formula_18. We note that exp(mu) is the median air lead level. A confidence interval for mu can be constructed the usual way, based on the \"t\"-distribution; this in turn will provide a confidence interval for the median air lead level. If formula_19 and S denote the sample mean and standard deviation of the log-transformed data for a sample of size n, a 95% confidence interval for mu is given by formula_20, where formula_21 denotes the 1-alpha quantile of a \"t\"-distribution with m degrees of freedom. It may also be of interest to derive a 95% upper confidence bound for the median air lead level. Such a bound for mu is given by formula_22. Consequently, a 95% upper confidence bound for the median air lead is given by formula_23. Now suppose we want to predict the air lead level at a particular area within the laboratory. A 95% upper prediction limit for the log-transformed lead level is given by formula_24. A two-sided prediction interval can be similarly computed. The meaning and interpretation of these intervals are well known. For example, if the confidence interval formula_25 is computed repeatedly from independent samples, 95% of the intervals so computed will include the true value of formula_1, in the long run. In other words, the interval is meant to provide information concerning the parameter formula_1 only. A prediction interval has a similar interpretation, and is meant to provide information concerning a single lead level only. Now suppose we want to use the sample to conclude whether or not at least 95% of the population lead levels are below a threshold. The confidence interval and prediction interval cannot answer this question, since the confidence interval is only for the median lead level, and the prediction interval is only for a single lead level. What is required is a tolerance interval; more specifically, an upper tolerance limit. The upper tolerance limit is to be computed subject to the condition that at least 95% of the population lead levels is below the limit, with a certain confidence level, say 99%.\n\nOne-sided normal tolerance intervals have an exact solution in terms of the sample mean and sample variance based on the noncentral \"t\"-distribution. \nTwo-sided normal tolerance intervals can be obtained based on the noncentral chi-squared distribution.\n\n\n"}
{"id": "46476782", "url": "https://en.wikipedia.org/wiki?curid=46476782", "title": "Transgender people and military service", "text": "Transgender people and military service\n\nPeople of diverse sexual orientation and gender identity, including lesbian, gay, bisexual, and transgender (LGBT), serve in the armed forces of every country. However, not all armed forces have policies explicitly permitting LGBT personnel. Generally speaking, Western European militaries show a greater tendency toward inclusion of LGBT individuals. As of 30 October 2017, 20 countries allowed transgender military personnel to serve openly: Australia, Austria, Belgium, Bolivia, Canada, the Czech Republic, Denmark, Estonia, Finland, France, Germany, Ireland, Israel, Netherlands, New Zealand, Norway, Spain, Sweden, United Kingdom, and the United States. Cuba and Thailand reportedly allowed transgender service in a limited capacity. In 1974, the Netherlands was the first country to allow transgender military personnel.\n\nThere are arguments against the inclusion of transgender people in military service. One argument is based on the view that being transgender is a mental illness, and as such transgender individuals are unfit for service. This argument follows a high incidence of depression and suicide manifest in transgender individuals. This is especially pertinent in individuals who have had sex-reassignment surgery and are unsatisfied with the results; in such cases severe depression is prevalent. Hormone therapy can affect mood and a sense of well-being, a factor that counts against inclusion of transgender people and its effect on service capability. Besides the well-being argument of hormone treatment, complications may arise due to hormone treatments. Possible complications arising from estrogen and testosterone therapies include an increased risk of thromboembolic disease, myocardial infarction, breast cancer, fertility problems, stroke, abnormal liver function, renal disease, endometrial cancer, and osteoporosis. Any of these could cause significant issues to effective military service, especially when deployed in remote areas or in field training settings.\n\nA further argument is that in order to have an effective, smooth-running military, there must be cohesion within the unit. It is argued that transgender individuals would have a negative impact on unit cohesion. \"The bonds of trust among individual service members\" are vital. There is a fear that if transgender personnel be allowed to serve openly, morale will be detrimentally affected. But this argument neglects to deal with the question of what kinds of structural accommodations might be needed to maintain morale and unit cohesion in such situations. Military service forces members into very intimate living quarters. Requiring members to live in situations that make them feel disconcerted and uncomfortable may result in their performance being undermined. The logistics of accommodating a group of individuals with such varying degrees of gender representation would be staggering. The costs alone of allowing transgender people to serve counts heavily against inclusion. Not only logistically and structurally, but also in medical costs. It is estimated that a male-to-female transition can cost between US$7,000 and $24,000; female-to-male transition can exceed US$50,000. Which, depending on policy, the military may have to fund.\n\nBy excluding a demographic from equal service, militaries are overtly intensifying the stigma of that group's civic inferiority. This is supported by the notion that all citizens are obligated to serve their nations if the need arises. Allowing transgender military personnel to serve openly without fear of exclusion would be a huge step toward equality. It has been recognized by some academics that the inclusion of all LGBT personnel in the military is more than a mere human rights issue, it is argued that for militaries to survive in the twenty-first century diversity is critical.\n\nWith advancements in the current understanding of human experience, sexual identity is now better understood. Where being transgender was once considered a paraphilic disorder, the current Diagnostic and Statistical Manual of Mental Disorders places being transgender in a separate chapter, terming the condition gender dysphoria. It is argued that militaries that exclude transgender people on grounds of mental illness, whose policies pathologize gender dysphoria, are at odds with the current medical understanding. This argument requires that transgender personnel be treated by the same level of medical care as all other personnel, in accordance with established medical practice.\n\nExperts argue that there is absolutely no empirical evidence that supports the argument that transgender people are unfit for service. Often cited are factors such as a supposed predisposition of transgender individuals to problems such as depression, anxiety, and suicidal thoughts; this is countered by the prevalence of these same issues in the LGB community, yet in many countries their service is not excluded. By creating a more accepting environment, distress that transgender personnel feel might be mitigated if they may serve openly with full support.\n\nWhilst militaries often cite the high medical cost of transgender people, they fail to reconcile this argument with current standards with other service members. For example, militaries often allow hormone treatments for an array of reasons and conditions, besides gender dysphoria; a common hormone treatment being contraceptive. Furthermore, the often cited risks of cross hormone treatment are rare, and not likely to cause any significant issues to the military. Whilst the cost of gender reassignment surgery is high, it is suggested that fewer than 2% of transgender members per year will choose to undergo gender reassignment surgery.\n\nPerhaps one of the most supporting arguments is based on the experiences of the 18 countries that currently allow transgender service. Research on the impacts of allowing LGBT to serve openly in the Israeli Defense Forces, British Armed Forces, and Canadian Armed Forces found no necessary negative impacts on performance, unit cohesion or morality. The idea of unit cohesion can also be demonstrated by a social study conducted less than one year prior to the repeal of the ban preventing transgender personnel from serving openly in the United States military. Morten G. Ender, David E. Rohall, and Michael D. Matthews presented the American military academy, Reserve Officers Training Corps, and civilian undergraduates with a survey to assess the general attitude on the prospect of the transgender community serving in the U.S. Armed Forces. After statistical analysis, 50.8% of individuals disagreed with the ban. In regards to productivity, 72.6% of subjects say that transgender inclusion would have no impact on their ability to do their job. Finally, on the subject of visibility, 21.8% of those interviewed said they would want transgender individuals to tell them their gender preferences, 56.1% said no preference. Overall, based on this study one year prior to the ban, the majority of the people that participated in the survey showed overwhelming support towards the inclusion of the transgender community in the United States military. \n\nIn October 2017, ruling that a renewed ban within the US military should not go into force, US District Judge Colleen Kollar-Kotelly stated that the evidence presented up to that time showed that \"all of the reasons proffered ... for excluding transgender individuals from the military in this case were not merely unsupported, but were actually contradicted by the studies, conclusions and judgment of the military itself\".\n\nEighteen years after the Australian Defence Force lifted their ban on gay and lesbian service, the ADF reversed policy that excluded transgender people from military service. The policy of inclusion was reportedly still in effect in 2017.\n\nIt is believed that the Australian Defence Force was the last agency whose policy specifically allowed for firing employees for transitioning gender. The ADF policy supports diversity in the military identifying LGBTI as a main priority, whose key objective is to position the ADF as an employer of choice, who as an organisation respects and supports the inclusion of gender diverse persons.\n\nIn 2013 Australian law formally codified protections against discrimination based on gender identity by including federal protections for LGBTI in the Sex Discrimination Act 1984. There are approximately 15 transgender service member who are openly living as their identified gender, with the support of ADF ranking officials who have been vocally committed to creating an inclusive and diverse military environment.\n\nIn a One Plus One interview with ABC News ADF's highest ranking transgender service member Lieutenant Colonel Cate McGregor speechwriter to the Chief of Army, Lieutenant General David Morrison AO, stated that the Chief of Army took the view that the \"army could not survive if it became a demographic ghetto\" and described an underbelly within the military whose culture was to exclude those who are different. In the wake of the Jedi Council sex scandal Chief of Army released a strongly worded statement urging all service members to show moral courage, to stand against any person degrading another individual. He further stated that he will \"be ruthless in ridding the army of people who cannot live up to its values\".\n\nWhilst there might still be a long road to full acceptance of the transgender community in Australia, transgender service members and their families are supported by DEFGLIS whose aim is to support LGBTI personnel and families, strengthen defence capability through inclusion, and educate the workforce about diversity.\n\nAs of 2014, Austria allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2014, Belgium allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nThe Armed Forces of Bolivia announced in 2013 that LGBT citizens would be allowed to serve beginning in 2015. As of 2014, Bolivia allowed transgender people to serve openly in the military. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2014, Canada allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2014, the Czech Republic allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2014, Denmark allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2014, Estonia allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2014, Finland allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2014, France allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nIn France, the military is sometimes initially more accepting of transgender service members than civilian authorities are, at least in some localities and jurisdictions, but they are also influenced by rulings of civilian courts which have strict requirements about changing identity documents. One service member was whipsawed by initially positive reception in the military, later overruled after a civilian court decision.\n\nIn 2009, a transgender Adjutant in the French Air Force who had already served 18 years as a man, returned to her unit in Nancy as a woman after a sick leave. Her superiors took stock of the situation, and provided the necessary uniforms and military papers with her new name. Delphine Ravisé-Giard was reintegrated into the military smoothly and without incident. On the other hand, she had difficulties in civilian life, such as when presenting her driver's license, passport, or other papers. The military then issued a request to the Nancy to have her gender and name altered on her birth certificate, but their decision was negative based on the fact that she had not yet undergone sex reassignment surgery so her situation was reversible. A 1992 decision by the \"Cour de cassation\" (Court of Appeals) requires those wishing to change their legal documents to show proof of being diagnosed with \"transsexual syndrome\" which is listed as a long-term psychiatric disorder in France, and to have undergone surgical intervention, but the Adjutant declared that she had no \"long-term psychiatric disorder\", and any question about any surgical interventions she had or didn't have was her private affair. Her lawyer insinuated that the real reason for the denial had to do with her ability to still have a child, and that the court's objective was sterilization before they would accord a legal name and gender change. The Commissioner for Human Rights of the European Council said that a transgender person \"seeking to have their gender identity legally recognized should not be forced to submit to sterilization or to any other medical treatment.\"\n\nHowever, in December, following the District Court decision, Hervé Morin, the Minister of Defense, ordered her to turn in her military papers, which she did. Meanwhile, she discovered that the name on her pay stub reverted to her old name, that the military supplement that women service members receive for feminine undergarments had been removed, and that the military was even going to dock her pay for the supplement she received while serving two years as a woman.\n\nAs of 2014, Germany allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2017, Iran requires all male citizens over age 18 to serve in the military, but transgender women, who are classified as having mental disorders. New military identity cards listed the subsection of the law dictating this exemption. This practice of identifying transgender individuals put them at risk of physical abuse and discrimination.\n\nCommenting in July 2017 on the Trump administration's decision to roll back service in the U.S. military by openly transgender personnel, Taoiseach Leo Varadkar said, \"On the transgender ban, it is not something I agree with.\" He further indicated that Ireland had never formally banned transgender military service and that he would not consider introducing such a ban.\n\nAs of 2014, Israel allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2014, the Netherlands allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nThe New Zealand Defence Force has been lauded as a world leader in diversity and for support of the LGBTQI community, and has been ranked as number one for integration of lesbian, gay, bisexual, and transgender personnel into the nation's military.\n\nWith the addition of the Human Rights Act to the New Zealand Bill of Rights Act in 1994, discrimination based on sexual orientation was criminalised. Although there is no specific reference to transgender people in the New Zealand statute, it has been held by the Solicitor General that protections for transgender people did in fact come under the New Zealand Bill of Rights Act 1990 under the sex discrimination provision. Whilst the Human Rights Commission and many activists still assert the need for an express provision in the New Zealand Bill of Rights Act to properly protect transgender people from discrimination, the NZDF as an equal opportunity employer does not discriminate on the basis of gender identity. The policy of inclusion was reportedly still in effect in 2017.\n\nIn support of maintaining diversity and inclusiveness the Chief of Defence Force approved the establishment of a support group for the military's LGBTI personnel. In 2012 an organisation called the NZDF Overwatch was launched within the defence force. Overwatch provides peer support and networking within the defence force to the GLBTI community, both in uniform and out. The organisation also offers education and guidance to command and commanders.\nThe NZDF and Overwatch was recognised for their inclusiveness and approach to equal employment opportunity being named the Supreme award winner of the ANZ and Equal Employment Opportunities Trust, Diversity Awards NZ 2013.\n\nAs of 2014, Norway allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2014, Spain allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nAs of 2014, Sweden allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nIn Thailand, identity documents may not be changed. All males must show up for the military conscription event on draft day, and kathoeys are not exempt from this requirement. It is possible for kathoeys to get an exemption certificate that will allow them to avoid service, but they must still attend, in order to present the document and be dismissed. As a result, on draft day, lines of people awaiting processing may include transgender women in makeup and feminine attire, waiting along with the male draftees. Contrary to the wide impression of acceptance of transgender women in Thailand, many complain about being treated as second-class citizens, and of the stress of being undressed or publicly humiliated.\n\nAs of 2014, the United Kingdom allowed transgender people to serve openly in its military forces. The policy of inclusion was reportedly still in effect in 2017.\n\nThe United States' military policy previously allowed for exclusion of transgender people from service on medical grounds. While gay, lesbian, and bisexual service members were allowed to serve openly since 2011, transgender service members risked discharge if they did not pass as their assigned sex. This required that service members conceal their gender identities throughout service.\n\nIt was estimated that in 2008–2009 there were approximately 15,500 transgender individuals either serving on active duty or in the National Guard or Army Reserve forces within the U.S. Military. A 2016 study, however, based on previous research estimated that only between 1,320 and 6,630 transgender individuals served on active duty and between 830 and 4,160 in reserve duty, with midrange figures of 2,450 in active duty and 1,510 in reserves.\n\nA key controversy and concern for transgender service members is the use of military medical services to transition from one gender to another.\n\nOn 22 August 2013, the day after her sentencing at an Army court-martial, U.S. soldier Chelsea Manning issued a public statement declaring herself to be a transgender woman. In 2014, while incarcerated in the United States Disciplinary Barracks, Manning filed a lawsuit against Secretary of Defense Hagel for failing to provide appropriate medical treatment necessary for her gender transformation. In a military first, hormone therapy to assist with Manning's gender conformity was approved in early 2015 and added to her treatment plan along with other provisions such as cosmetics and female undergarments.\n\nAir Force Secretary Deborah Lee James openly supported a change to the military's transgender policy, stating in 2014 that it was likely to be reviewed in the next year or so. In February 2015, Secretary of Defense Ashton Carter stated he was open minded about including transgender people in the military and that nothing but individual lack of merit should preclude such people from service. Carter's statement was later endorsed by President Obama.\n\nOn 19 August 2015, Carter stated in a memo that the Defense Department had begun the process of dismantling the ban and that transgender people would be able to openly serve in the U.S. military by 27 May 2016. Department of Defense regulations that ban transgender persons from US military service were repealed on 30 June 2016. Beginning on that date, otherwise qualified United States service members could not any longer be discharged, denied reenlistment, involuntarily separated, or denied continuation of service because of being transgender.\n\nOn 26 July 2017, US President Donald Trump announced that transgender people would no longer be allowed to serve in the US military. The following day, General Joseph Dunford, Chairman of the Joint Chiefs of Staff, stated that openly transgender people will continue to be allowed to serve until Trump provides direction to James Mattis, the Secretary of Defense.\n\nThe Palm Center released, on 1 August 2017, a letter signed by 56 retired generals and admirals opposing the proposed ban on transgender military service members. The letter stated that if implemented, the ban \"would cause significant disruptions, deprive the military of mission-critical talent and compromise the integrity of transgender troops who would be forced to live a lie, as well as non-transgender peers who would be forced to choose between reporting their comrades or disobeying policy\".\n\nOn 9 August 2017, five transgender United States military personnel sued Trump and top Pentagon officials over the proposed banning of transgender people from serving in the military. The suit asks the court to prevent the ban from going into effect. Two major LGBT-rights organizations filed a petition in the United States District Court in Washington on behalf of the five transgender service members.\n\nTrump signed a presidential memorandum, dated 25 August 2017, directing the Secretary of Defense and Secretary of Homeland Security to submit an implementation plan by 21 February 2018, to reinstate the ban and halt the use of military funds for \"sex reassignment surgical procedures for military personnel\". On 30 October 2017, US District Judge Colleen Kollar-Kotelly barred the administration from excluding transgender people from military service in \"Jane Doe v. Trump\", but did not address whether federal funds should be used to pay for sex reassignment surgery for service members. The ruling also stated that that as far as could be seen, \"all of the reasons proffered by the president for excluding transgender individuals from the military in this case were not merely unsupported, but were actually contradicted by the studies, conclusions and judgment of the military itself\".\n\nIn November 2017, the Defense Health Agency for the first time approved payment for sex reassignment surgery for an active-duty US military service member. The patient, an infantry soldier who is a transwoman, had already begun a course of treatment for gender reassignment. The procedure, which the treating doctor deemed medically necessary, was performed on 14 November at a private hospital, since US military hospitals lack the requisite surgical expertise. On 11 December, Kollar-Kotelly ruled that the government must accept transgender recruits into the military by 1 January 2018. After the ruling, the Department of Justice appealed to the United States Court of Appeals for the District of Columbia Circuit to issue a stay on the district court's ruling. The Pentagon confirmed on 26 February 2018 that the first transgender recruit had signed a contract to join the military.\n\nOn March 23, 2018, President Trump banned transgender and transsexual people with current or previous gender dysphoria from serving in the U.S. military. However, the Pentagon said they would comply with the court decision until it is reversed. The policy was stayed in \"Karnoski vs. Trump\" (Western District of Washington) on 13 April 2018, when the court ruled that the 2018 memorandum essentially repeated the same issues as its predecessor order from 2017, that transgender service members (and transgender individuals as a class) were a protected class entitled to strict scrutiny of adverse laws (or at worst, a quasi-suspect class), and ordered that matter continue to a full trial hearing on the legality of the proposed policy.\n\n\n"}
{"id": "2406648", "url": "https://en.wikipedia.org/wiki?curid=2406648", "title": "Violence Against Women Act", "text": "Violence Against Women Act\n\nThe Violence Against Women Act of 1994 (VAWA) is a United States federal law (Title IV, sec. 40001-40703 of the Violent Crime Control and Law Enforcement Act, ) signed as by President Bill Clinton on September 13, 1994 (codified in part at 42 U.S.C. sections 13701 through 14040). The Act provided $1.6 billion toward investigation and prosecution of violent crimes against women, imposed automatic and mandatory restitution on those convicted, and allowed civil redress in cases prosecutors chose to leave un-prosecuted. The Act also established the Office on Violence Against Women within the Department of Justice.\n\nVAWA was drafted by the office of Senator Joe Biden (D-DE) and co-written by Democrat Louise Slaughter, the Representative from New York, with support from a broad coalition of advocacy groups. The Act passed through Congress with bipartisan support in 1994, clearing the United States House of Representatives by a vote of 235–195 and the Senate by a vote of 61–38, although the following year House Republicans attempted to cut the Act's funding. In the 2000 Supreme Court case \"United States v. Morrison\", a sharply divided Court struck down the VAWA provision allowing women the right to sue their attackers in federal court. By a 5–4 majority, the Court overturned the provision as exceeding the federal government's powers under the Commerce Clause.\n\nVAWA was reauthorized by bipartisan majorities in Congress in 2000 (H.R. 1248, Roll Call 415-3), and again in December 2005, and signed by President George W. Bush. The Act's 2012 renewal was opposed by conservative Republicans, who objected to extending the Act's protections to same-sex couples and to provisions allowing battered illegal immigrants to claim temporary visas. Ultimately, VAWA was again reauthorized in 2013, after a long legislative battle throughout 2012–2013.\n\nThe World Conference on Human Rights, held in Vienna, Austria, in 1993, and the Declaration on the Elimination of Violence Against Women in the same year, concluded that civil society and governments have acknowledged that domestic violence is a public health policy and human rights concern. In the United States, according to the National Intimate Partner Sexual Violence Survey of 2010 1 in 6 women suffered some kind of sexual violence induced by their intimate partner during the course of their lives.\n\nThe Violence Against Women Act was developed and passed as a result of extensive grassroots efforts in the late 1980s and early 1990s, with advocates and professionals from the battered women's movement, sexual assault advocates, victim services field, law enforcement agencies, prosecutors' offices, the courts, and the private bar urging Congress to adopt significant legislation to address domestic and sexual violence [citation needed]. One of the greatest successes of VAWA is its emphasis on a coordinated community response to domestic violence, sex dating violence, sexual assault, and stalking; courts, law enforcement, prosecutors, victim services, and the private bar currently work together in a coordinated effort that did not exist before at the state and local levels [citation needed]. VAWA also supports the work of community-based organizations that are engaged in work to end domestic violence, dating violence, sexual assault, and stalking; particularly those groups that provide culturally and linguistically specific services. Additionally, VAWA provides specific support for work with tribes and tribal organizations to end domestic violence, dating violence, sexual assault, and stalking against Native American women.\n\nMany grant programs authorized in VAWA have been funded by the U.S. Congress. The following grant programs, which are administered primarily through the Office on Violence Against Women in the U.S. Department of Justice have received appropriations from Congress:\n\n\nThe American Civil Liberties Union (ACLU) had originally expressed concerns about the Act, saying that the increased penalties were rash, that the increased pretrial detention was \"repugnant\" to the U.S. Constitution, that the mandatory HIV testing of those only charged but not convicted was an infringement of a citizen’s right to privacy, and that the edict for automatic payment of full restitution was non-judicious (see their paper: \"Analysis of Major Civil Liberties Abuses in the Crime Bill Conference Report as Passed by the House and the Senate\", dated September 29, 1994). The ACLU has, however, supported reauthorization of VAWA on the condition that the \"unconstitutional DNA provision\" be removed.\n\nThe ACLU, in its July 27, 2005 'Letter to the Senate Judiciary Committee Regarding the Violence Against Women Act of 2005, S. 1197' stated that \"VAWA is one of the most effective pieces of legislation enacted to end domestic violence, dating violence, sexual assault, and stalking. It has dramatically improved the law enforcement response to violence against women and has provided critical services necessary to support women in their struggle to overcome abusive situations\".\n\nSome activists oppose the bill. Janice Shaw Course, a senior fellow at Concerned Women for America's Beverly LaHaye Institute called the Act a \"boondoggle\" which \"ends up creating a climate of suspicion where all men are feared or viewed as violent and all women are viewed as victims\". She described the Act as creating a \"climate of false accusations, rush to judgment and hidden agendas\" and criticized it for failing to address the factors identified by the Centers for Disease Control and Prevention as leading to violent, abusive behavior. Conservative activist Phyllis Schlafly denounced VAWA as a tool to \"fill feminist coffers\" and argued that the Act promoted \"divorce, breakup of marriage and hatred of men\".\n\nIn 2000, the Supreme Court of the United States held part of VAWA unconstitutional in \"United States v. Morrison\" on federalism grounds. In that decision, only the civil rights remedy of VAWA was struck down. The provisions providing program funding were unaffected.\n\nIn 2005, the reauthorization of VAWA (as HR3402) defined what population benefited under the term of \"Underserved Populations\" described as \" Populations underserved because of geographic location, underserved racial and ethnic populations, populations underserved because of special needs (such as language barriers, disabilities, alienage status, or age) and any other population determined to be underserved by the Attorney General or by the Secretary of Health and Human Services as appropriate\". The reauthorization also \"Amends the Omnibus Crime Control and Safe Streets Act of 1968\" to \"prohibit officials from requiring sex offense victims to submit to a polygraph examination as a condition for proceeding with an investigation or prosecution of a sex offense.\"\n\nIn 2011, the law expired. In 2012 the law was up for reauthorization in Congress. Different versions of the legislation have been passed along party lines in the Senate and House, with the Republican-sponsored House version favoring the reduction of services to undocumented immigrants and LGBT individuals. Another area of contention is the provision of the law giving Native American tribal authorities jurisdiction over sex crimes involving non-Native Americans on tribal lands. This provision is considered to have constitutional implications, as non-tribes people are under the jurisdiction of the United States federal government and are granted the protections of the U.S. Constitution, protections that tribal courts do not often have. The two bills were pending reconciliation, and a final bill did not reach the President's desk before the end of the year, temporarily ending the coverage of the Act after 18 years, as the 112th Congress adjourned.\n\nThe Act's 2012 renewal was opposed by conservative Republicans, who objected to extending the Act's protections to same-sex couples and to provisions allowing battered undocumented individuals to claim temporary visas, also known as U visas. The U visa is restricted to 10,000 applicants annually whereas the number of applicants far exceeds these 10,000 for each fiscal year. In order to be considered for the U visa, one of the requirements for immigrant women is that they need to cooperate in the detention of the abuser. Studies show that 30 to 50% of immigrant women are suffering from physical violence and 62% experience physical or psychological abuse in contrast to only 21% of citizens in the United States.\n\nIn April 2012, the Senate voted to reauthorize the Violence Against Women Act, and the House subsequently passed its own measure (omitting provisions of the Senate bill that would protect gays, Native Americans living in reservations, and immigrants who are victims of domestic violence). Reconciliation of the two bills was stymied by procedural measures, leaving the re-authorization in question. The Senate's 2012 re-authorization of VAWA was not brought up for a vote in the House.\n\nIn 2013, the question of jurisdiction over offenses in Indian country continued to be at issue over the question of whether defendants who are not tribal members would be treated fairly by tribal courts or afforded constitutional guarantees.\n\nOn February 12, 2013, the Senate passed an extension of the Violence Against Women Act by a vote of 78–22. The measure went to the House of Representatives where jurisdiction of tribal courts and inclusion of same-sex couples were expected to be at issue. Possible solutions advanced were permitting either removal or appeal to federal courts by non-tribal defendants. The Senate had tacked on the Trafficking Victims Protection Act which is another bone of contention due to a clause which requires provision of reproductive health services to victims of sex trafficking.\n\nOn February 28, 2013, in a 286–138 vote, the House passed the Senate's all-inclusive version of the bill. House Republicans had previously hoped to pass their own version of the measure—one that substantially weakened the bill's protections for certain categories. The stripped down version, which allowed only limited protection for LGBT and Native Americans, was rejected 257 to 166. The renewed act expanded federal protections to gay, lesbian, and transgender individuals, Native Americans and immigrants.\n\nOn March 7, 2013, President Barack Obama signed the Violence Against Women Reauthorization Act of 2013.\n\nThe U.S. Conference of Catholic Bishops opposed portions of the act that addressed the categories \"sexual orientation\" and \"gender identity\", calling the sections unnecessary to achieve equal protection of all persons.\n\n138 House Republicans voted against the version of the act that became law. However, several, including Steve King (R-Iowa), Bill Johnson (R-Ohio), Tim Walberg (R-Michigan), Vicky Hartzler (R-Missouri), Keith Rothfus (R-Pennsylvania), and Tim Murphy (R-Pennsylvania), claimed to have voted in favor of the act. Some have called this claim disingenuous because the group only voted in favor of a GOP proposed alternative version of the bill that did not contain provisions intended to protect gays, lesbians and transgender individuals, Native Americans and undocumented immigrants.\n\nOn September 12, 2013, at an event marking the 19th anniversary of the bill, Vice President Joe Biden criticized the Republicans who slowed the passage of the reauthorization of the act as being \"this sort of Neanderthal crowd\".\n\nThe Violence Against Women laws provide programs and services, including:\n\nWhen a woman—the Wisconsin Coalition Against Domestic Violence generally refers to petitioners as female as most are women—is the beneficiary of an order of protection, per VAWA it is generally enforceable nationwide under the terms of full faith and credit. Although the order may be granted only in a specific state, full faith and credit requires that it be enforced in other states as though the order was granted in their states.\n\nVAWA allows for the possibility that certain individuals who might not otherwise be eligible for immigration benefits may petition for US permanent residency on the grounds of a close relationship with a US citizen or permanent resident who has been abusing them. The following persons are eligible to benefit from the immigration provisions of VAWA:\n\nAlthough the title of the Act and the titles of its sections refer to victims of domestic violence as women, the operative text is gender-neutral, providing coverage for male victims as well. Individual organizations have not been successful in using VAWA to provide equal coverage for men. The law has twice been amended in attempts to address this situation. The 2005 reauthorization added a non-exclusivity provision clarifying that the title should not be construed to prohibit male victims from receiving services under the Act. The 2013 reauthorization added a non-discrimination provision that prohibits organizations receiving funding under the Act from discriminating on the basis of sex, although the law allows an exception for \"sex segregation or sex-specific programming\" when it is deemed to be \"necessary to the essential operations of a program.\" Jan Brown, the Founder and Executive Director of the Domestic Abuse Helpline for Men and Women contends that the Act may not be sufficient to ensure equal access to services.\n\nOfficial federal government groups that have developed, being established by President Barack Obama, in relation to the Violence Against Women Act include the White House Council on Women and Girls and the White House Task Force to Protect Students from Sexual Assault. The ultimate aims of both groups are to help improve and/or protect the well-being and safety of women and girls in the United States.\n\n\n"}
{"id": "3779776", "url": "https://en.wikipedia.org/wiki?curid=3779776", "title": "Wisdom of repugnance", "text": "Wisdom of repugnance\n\nThe wisdom of repugnance, or the yuck factor, also known informally as \"appeal to disgust\",\nis the belief that an intuitive (or \"deep-seated\") negative response to some thing, idea, or practice should be interpreted as evidence for the intrinsically harmful or evil character of that thing. Furthermore, it refers to the notion that wisdom may manifest itself in feelings of disgust towards anything which lacks goodness or wisdom, though the feelings or the reasoning of such 'wisdom' may not be immediately explicable through reason.\n\nThe term \"wisdom of repugnance\" was coined in 1997 by Leon Kass, chairman (2001–2005) of the President's Council on Bioethics, in an article in \"The New Republic\", which was later expanded into a further (2001) article in the same magazine, and also incorporated into his 2002 book \"Life, Liberty, and the Defense of Dignity\". Kass stated that disgust was not an argument \"per se\", but went on to say that \"in crucial cases... repugnance is the emotional expression of deep wisdom, beyond reason's power fully to articulate.\"\n\nThe term remains largely confined to discussions of bioethics, and is somewhat related to the term \"yuck factor\". However, unlike the latter, it is used almost exclusively by those who accept its underlying premise; i.e., that repugnance does, in fact, indicate wisdom. It is thus often viewed as loaded language, and is primarily used by certain bioconservatives to justify their position.\n\nThe term has since migrated to other controversies, such as same-sex marriage, pornography, marijuana legalization, alternative sexualities and, in some cases, legalization of early abortion. In all cases, it expresses the view that one's \"gut reaction\" might justify objecting to some practice even in the absence of a persuasive rational case against that practice.\n\nThe wisdom of repugnance has been criticized, both as an example of a fallacious appeal to emotion and for an underlying premise which seems to reject rationalism. Although mainstream science concedes that a sense of disgust most likely evolved as a useful defense mechanism (e.g. in that it tends to prevent or prohibit potentially harmful behaviour such as inbreeding, cannibalism, and coprophagia), social psychologists question whether the instinct can serve any moral or logical value when removed from the context in which it was originally acquired.\n\nMartha Nussbaum explicitly opposes the concept of a disgust-based morality. Nussbaum notes that disgust has been used throughout history as a justification for persecution. For example, at various times racism, antisemitism, sexism, and homophobia have all been driven by popular repulsion.\n\nStephen Jay Gould has remarked that \"our prejudices often overwhelm our limited information. [They] are so venerable, so reflexive, so much a part of our second nature, that we never stop to recognize their status as social decisions with radical alternatives—and we view them instead as given and obvious truths.\"\n\nBritish bioethicist John Harris replied to Kass's view by arguing that, \"there is no necessary connection between phenomena, attitudes, or actions that make us uneasy, or even those that disgust us, and those phenomena, attitudes, and actions that there are good reasons for judging unethical. Nor does it follow that those things we are confident are unethical must be prohibited by legislation or regulation.\"\n\nThe word \"squick\" was created within BDSM subculture in reaction to this sort of reasoning, and denotes a \"gut reaction\" of disgust without the implication of any sort of actual moral judgment.\n\n\n"}
{"id": "17666338", "url": "https://en.wikipedia.org/wiki?curid=17666338", "title": "Workplace privacy", "text": "Workplace privacy\n\nEmployees typically must relinquish some of their privacy while at the workplace, but how much they must do so can be a contentious issue. The debate rages on as to whether it is moral, ethical and legal for employers to monitor the actions of their employees. Employers believe that monitoring is necessary both to discourage illicit activity and to limit liability. Although, with this problem of monitoring employees, many are experiencing a negative effect on emotional and physical stress including fatigue, lowered employee morale and lack of motivation within the workplace. Employers might choose to monitor employee activities using surveillance cameras, or may wish to record employees activities while using company owned computers or telephones. Courts are finding that disputes between workplace privacy and freedom are being complicated with the advancement of technology as traditional rules that govern areas of privacy law are debatable and becoming less important.\n\nThe EU Directive 95/46/EC on the protection of individuals with regards to the processing of personal data and on the free movement of such data limits and regulates the collection of personal information on individuals, including workers. Firms that monitor employees' use of e-mail, internet, or phones as part of their business practice with out notifying employees or obtaining employee consent can be, in most cases, sued under Article 8 the European Convention on Human Rights. Although EU law is clear that e-mail interception is illegal, the law is not totally clear as to whether companies may prohibit employees from sending private e-mails.\n\nThe Omnibus Crime Control and Safe Streets Act of 1968 provides some privacy protections for employees. \"See Omnibus Crime Control and Safe Streets Act of 1968 § Employee Privacy\". The Electronic Communications Privacy Act extends protections to include email messages, cell phones and other electronic communications. \"See Electronic Communications Privacy Act § Employee Privacy\".\n\nA 2005 survey of more than 500 U.S. companies found that over half of employers had disciplined employees and about one in four had terminated (fired) an employee for \"inappropriate\" use of the internet, such as sending an inappropriate email message to a client or supervisor, neglecting work while chatting with friends, or viewing pornography during work hours.\n\nThe tools that are used for electronic surveillance are often caching proxy servers that are also used for web monitoring.\n\nIn \"R v Cole\", the Supreme Court of Canada ruled that \n\nAccording to the Coase Theorem, an employer and an employee never agree to a contractual arrangement that would reduce the total surplus generated by the two parties together. Hence, when we observe workplace surveillance, then the costs (say, the worker’s disutility caused by the loss of privacy) must be smaller than the benefit (say, the additional profit due to a reduction of shirking), because otherwise the parties would abolish surveillance (the worker would be willing to accept a smaller wage in exchange for more privacy, which would increase the employer’s profit more than surveillance could do). However, the Coase Theorem holds only if there are no transaction costs. Schmitz (2005) has shown that in the presence of asymmetric information (leading to a moral hazard problem), the total surplus generated by an employer and an employee can be increased if workplace surveillance is prohibited by law. \n\n\n"}
