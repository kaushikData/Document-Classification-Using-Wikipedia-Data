{"id": "3272347", "url": "https://en.wikipedia.org/wiki?curid=3272347", "title": "Activity diagram", "text": "Activity diagram\n\nActivity diagrams are graphical representations of workflows of stepwise activities and actions with support for choice, iteration and concurrency. In the Unified Modeling Language, activity diagrams are intended to model both computational and organizational processes (i.e., workflows), as well as the data flows intersecting with the related activities. Although activity diagrams primarily show the overall flow of control, they can also include elements showing the flow of data between activities through one or more data stores.\n\nActivity diagrams are constructed from a limited number of shapes, connected with arrows. The most important shape types:\nArrows run from the start towards the end and represent the order in which activities happen.\n\nActivity diagrams can be regarded as a form of a structured flowchart combined with a traditional data flow diagram. Typical flowchart techniques lack constructs for expressing concurrency. However, the join and split symbols in activity diagrams only resolve this for simple cases; the meaning of the model is not clear when they are arbitrarily combined with decisions or loops.\n\nWhile in UML 1.x, activity diagrams were a specialized form of state diagrams, in UML 2.x, the activity diagrams were reformalized to be based on Petri net-like semantics, increasing the scope of situations that can be modeled using activity diagrams. These changes cause many UML 1.x activity diagrams to be interpreted differently in UML 2.x.\n\nUML activity diagrams in version 2.x can be used in various domains, e.g. in design of embedded systems. It is possible to verify such a specification using model checking technique.\n\n\n"}
{"id": "1686342", "url": "https://en.wikipedia.org/wiki?curid=1686342", "title": "Adaptive behavior", "text": "Adaptive behavior\n\nAdaptive behavior refers to behavior that enables a person (usually used in the context of children) to get along in his or her environment with greatest success and least conflict with others. This is a term used in the areas of psychology and special education. Adaptive behavior relates to every day skills or tasks that the average person is able to complete, similar to the term life skills.\n\nNonconstructive or disruptive social or personal behaviors can sometimes be used to achieve a constructive outcome. For example, a constant repetitive action could be re-focused on something that creates or builds something. In other words, the behavior can be adapted to something else.\n\nIn contrast, maladaptive behavior is a type of behavior that is often used to reduce one's anxiety, but the result is dysfunctional and non-productive. For example, avoiding situations because you have unrealistic fears may initially reduce your anxiety, but it is non-productive in alleviating the actual problem in the long term. Maladaptive behavior is frequently used as an indicator of abnormality or mental dysfunction, since its assessment is relatively free from subjectivity. However, many behaviors considered moral can be maladaptive, such as dissent or abstinence.\n\nAdaptive behavior reflects an individual’s social and practical competence to meet the demands of everyday living. Behavior patterns change throughout a person's development, across life settings and social constructs, changes in personal values, and the expectations of others. It is important to assess adaptive behavior in order to determine how well an individual functions in daily life: vocationally, socially and educationally.\n\n\nLimitations in self-care skills and social relationships, as well as behavioral excesses are common characteristics of individuals with mental disabilities. Individuals with mental disabilities who require extensive supports are often taught basic self care skills such as dressing, eating, and hygiene. Direct instruction and environmental supports, such as added prompts and simplified routines are necessary to ensure that deficits in these adaptive areas do not come to seriously limit one's quality of life.\n\nMost children with milder forms of mental disabilities learn how to take care of their basic needs, but they often require training in self-management skills to achieve the levels of performance necessary for eventual independent living. Making and sustaining friendships and personal relationships present significant challenges for many persons with mental disabilities. Limited cognitive processing skills, poor language development, and unusual or inappropriate behaviors can seriously impede interacting with others. Teaching students with mental disabilities appropriate social and interpersonal skills is one of the most important functions of special education. Students with mental disabilities more often exhibit behavior problems than children without disabilities. Some of the behaviors observed by students with mental disabilities are difficulties accepting criticism, limited self-control, and inappropriate behaviors. The greater the severity of the mental disabilities, generally the higher the incidence of behavioral problems.\n\nIn education, adaptive behavior is defined as that which (1) meets the needs of the community of stakeholders (parents, teachers, peers, and later employers) and (2) meets the needs of the learner, \"now\" and \"in the future\". Specifically, these behaviors include such things as effective speech, self-help, using money, cooking, and reading, for example.\n\nTraining in adaptive behavior is a key component of any educational program, but is critically important for children with special needs. The US Department of Education has allocated billions of dollars ($12.3 billion in 2008) for Special Education programs aimed at improving educational and early intervention outcomes for children with disabilities. \nIn 2001, the United States National Research Council published a comprehensive review of interventions for children and adults diagnosed with autism. The review indicates that interventions based on applied behavior analysis have been effective with these groups.\n\nAdaptive behavior includes socially responsible and independent performance of daily activities. However, the specific activities and skills needed may differ from setting to setting. When a student is going to school, school and academic skills are adaptive. However, some of those same skills might be useless or maladaptive in a job settings, so the transition between school and job needs careful attention.\n\nAdaptive behavior includes the age-appropriate behaviors necessary for people to live independently and to function safely and appropriately in daily life. Adaptive behaviors include life skills such as grooming, dressing, safety, food handling, working, money management, cleaning, making friends, social skills, and the personal responsibility expected of their age and social group. Specific skills include:\n\n\nAdaptive behaviors are considered to change due to the persons culture and surroundings. Professors have to delve into the students technical and comprehension skills to measure how adaptive their behavior is. \n\n\nEvery human being must learn a set of skills that is beneficial for the environments and communities they live in. Adaptive skills are stepping stones toward accessing and benefiting from local or remote communities. This means that, in urban environments, to go to the movies, a child will have to learn to navigate through the town or take the bus, read the movie schedule, and pay for the movie. Adaptive skills allow for safer exploration because they provide the learner with an increased awareness of his/her surroundings and of changes in context, that require new adaptive responses to meet the demands and dangers of that new context. Adaptive skills may generate more opportunities to engage in meaningful social interactions and acceptance. Adaptive skills are socially acceptable and desirable at any age and regardless of gender (with the exception of gender specific biological differences such as menstrual care skills, etc.)\n\nAdaptive skills encompass a range of daily situations and they usually start with a task analysis. The task analysis will reveal all the steps necessary to perform the task in the natural environment. The use of behavior analytic procedures has been documented, with children, adolescents and adults, under the guidance of behavior analysts and supervised behavioral technicians. The list of applications has a broad scope and it is in continuous expansion as more research is carried out in applied behavior analysis (see \"Journal of Applied Behavior Analysis\", \"The Analysis of Verbal Behavior\").\n\nAccording to practopoietic theory, creation of adaptive behavior involves special, \"poietic\" interactions among different levels of system organization. These interactions are described on the basis of cybernetic theory in particular, good regulator theorem. In practopoietic systems, lower levels of organization determine the properties of higher levels of organization, but not the other way around. This ensures that lower levels of organization (e.g., genes) always possess cybernetically more general knowledge than the higher levels of organization—knowledge at a higher level being a special case of the knowledge at the lower level. At the highest level of organization lies the overt behavior. Cognitive operations lay in the middle parts of that hierarchy, above genes and below behavior. For behavior to be adaptive, at least three adaptive traverses are needed.\n\n\n"}
{"id": "51231091", "url": "https://en.wikipedia.org/wiki?curid=51231091", "title": "Alternatives assessment", "text": "Alternatives assessment\n\nAlternatives assessment or alternatives analysis is a problem-solving approach used in environmental design, technology, and policy. It aims to minimize environmental harm by comparing multiple potential solutions in the context of a specific problem, design goal, or policy objective. It is intended to inform decision-making in situations with many possible courses of action, a wide range of variables to consider, and significant degrees of uncertainty. Alternatives assessment was originally developed as a robust way to guide precautionary action and avoid paralysis by analysis; authors such as O'Brien have presented alternatives assessment as an approach that is complementary to risk assessment, the dominant decision-making approach in environmental policy. Likewise, Ashford has described the similar concept of \"technology options analysis\" as a way to generate innovative solutions to the problems of industrial pollution more effectively than through risk-based regulation.\n\nAlternatives assessment is practiced in a variety of settings, including but not limited to green chemistry, sustainable design, supply-chain chemicals management, and chemicals policy. One prominent application area for alternatives assessment is the substitution of hazardous chemicals with safer alternatives, also known as chemical alternatives assessment.\n\nGenerally, alternatives assessment involves considering a number of possible options to achieve a specific objective, and applying a principled comparative analysis. The objective is usually to improve the environmental performance or safety of a specific product, material, process, or other activity. Potential alternatives considered in the analysis may include different chemical substances, materials, technologies, methods of use, or even extensive redesign to enable new ways of achieving the objective while avoiding the problem. Understanding the consequences of each available option is central to the process and goals of alternatives assessment, because this helps avoid decisions that substitute one problem with another (unknown) problem. The comparative analysis can involve any number of criteria for evaluating options, and these are typically focused on environmental health and sustainability.\n\nThere is no single protocol that dictates how options should be identified, evaluated, and compared in an alternatives assessment. Rather, a number of different alternatives assessment \"frameworks\" exist, which serve to structure decision-making and to enable systematic consideration of the key factors. Jacobs and colleagues identify six major components of alternatives assessment: evaluation of hazard, exposure, life cycle impacts, technical feasibility, and economic feasibility; and an overall decision-making strategy.\n\nOne major framework, the Lowell Center for Sustainable Production Alternatives Assessment Framework, conceives of alternatives assessment very broadly, as a reflexive problem-solving process that recognizes the social and technical complexity of environmental problems. It emphasizes aspects such as stakeholder participation, transparency of the process, and open discussion of values in decision-making. Most other frameworks are more narrow and primarily focused on technical aspects.\n\nChemical alternatives assessment (or \"substitution of hazardous chemicals\") is the use of alternatives assessment for finding safer and environmentally preferable design options to reduce or eliminate the use of hazardous chemical substances. Safer alternatives to hazardous chemicals may simply be other chemical substances, or may involve deeper changes in material or product design. Chemical alternatives assessment aims to provide the basis for well-informed decision-making by thoroughly characterizing chemicals and materials (and other design options) across a wide range of environmental and health impact categories. The rationale for this is to avoid shifting environmental health burdens from one category of impacts to another (e.g., substituting a carcinogenic chemical with a neurotoxic one), \nand to minimize the unintended consequences of decisions made under conditions of uncertainty and ignorance—in other words, to prevent \"regrettable substitutions\", where an alternative appeared better based on limited knowledge, but turned out to be worse or equally bad.\n\nAn array of methodologies and tools for chemical alternatives assessment have been developed worldwide and have been deployed in a variety of industry sectors. Chemical alternatives assessment frameworks include chemical hazard assessment methods that consider a wide range of hazard endpoints, such as those defined in the\nGlobally Harmonized System or the GreenScreen for Safer Chemicals.\n\n\nScientists from a variety of government agencies, academic institutions, non-profit organizations, and firms have contributed to developing the practice of alternatives assessment.\n\nScientific research in the US federal government has contributed to alternatives assessment frameworks and practices. In 2014 the US National Research Council released a chemical alternatives assessment framework developed by an expert working group. Prior to this, the US Environmental Protection Agency ran a program called \"Design for the Environment\" (now called Safer Choice), which developed chemical alternatives assessment methodology and created partnerships to undertake numerous alternatives assessments for chemicals of concern in products.\n\nAlternatives assessment has featured in some state-level chemicals policies and regulatory activities. The Massachusetts Toxics Use Reduction Institute has provided public technical assistance for \"toxics use reduction planning\", which includes alternatives assessment. More recently, the California Department of Toxic Substances Control is implementing new regulations that require firms to undertake alternatives assessments for selected priority chemicals in products. The Interstate Chemicals Clearinghouse, an association of state governments, has also produced its own guide to alternatives assessment.\n\nSome US-based companies have begun to use chemical alternatives assessment to address chemical safety issues in supply chains. For example, firms that participate in the Business-NGO Working Group for Safer Chemicals and Sustainable Materials have produced their own guidance for chemical alternatives assessment.\n\nThe Sweden-based non-governmental organization ChemSec has been active in developing resources and tools for the substitution of hazardous chemicals. The Substitution support portal (SUBSPORT) is an EU-based collaboratively-developed resource for chemical substitution. It includes alternatives assessment case studies.\n"}
{"id": "54975167", "url": "https://en.wikipedia.org/wiki?curid=54975167", "title": "Analgesic adjuvant", "text": "Analgesic adjuvant\n\nAn analgesic adjuvant is a medication that is typically used for indications other than pain control but provides control of pain in some painful diseases. Anti-emetics and medication to relieve constipation are two examples of non-adjuvant medication indications because these are used to treat side effects and adverse effects. Examples include:\n\n\nThe exact mechanism of carbamazepine, gabapentin, and pregabalin is similarly unclear, but these anticonvulsants are used to treat neuropathic pain with differing degrees of success.\n\n"}
{"id": "44119867", "url": "https://en.wikipedia.org/wiki?curid=44119867", "title": "Ars Electronica", "text": "Ars Electronica\n\nArs Electronica Linz GmbH is an Austrian cultural, educational and scientific institute active in the field of new media art, founded in Linz in 1979. It is based at the Ars Electronica Center, which houses the Museum of the Future, in the city of Linz. Ars Electronica’s activities focus on the interlinkages between art, technology and society. It runs an annual festival, and manages a multidisciplinary media arts R&D facility known as the Futurelab. It also confers the Prix Ars Electronica awards.\n\nArs Electronica began with its first festival in September 1979. Its founders were Hannes Leopoldseder, Hubert Bognermayr, Herbert W. Franke, and Ulrich Rützel. The festival was held biennially at first, and annually since 1986. The Prix Ars Electronica was inaugurated in 1987 and has been awarded every year since then. Ars Electronica Linz GmbH was incorporated as a limited company in 1995. The Ars Electronica Center, together with the Futurelab, opened in 1996, and was remodelled in 2009.\n\nFunding is provided by the City of Linz, the Province of Upper Austria and the Republic of Austria, in addition to private partners. In 2014 the organization is headed by artistic director Gerfried Stocker and financial director Diethard Schwarzmair.\n\nThe annual Ars Electronica festival is a gathering of artists, scientists and technologists, intended as \"a setting for experimentation, evaluation and reinvention\". The festival has always exerted a public presence in Linz, mounting large-scale open-air projects and holding lectures, discussions and workshops in a wide range of public venues.\n\nEach year the festival is devoted to a specific theme. The festival in 2014, from 4–8 September, had as its theme \"C... What it Takes to Change\", i.e. ways in which social change and innovation can be promoted. It attracted 579 participants and about 85,000 visitors.\n\nA form of concept art, Device Art has been described as \"...a rebellion of form, taking everyday objects and inverting them to tell you something different\". Among the examples exhibited at the 2014 festival were:\n\nA display called \"Smart atoms: spaxels version\" was developed by Ars Electronica Futurelab and shown at the 2014 festival. The \"space pixels\" – automatically controlled drones fitted with LEDs - fly in formation to create apparent three-dimensional objects against the night sky.\n\nThe Prix Ars Electronica is an annual award made in several categories, \"honoring creativity and innovativeness in the use of digital media\". Award winners are selected by a five-person international expert jury, who may themselves propose candidates. The prize may be awarded to individuals or to teams or organizations, and may be awarded for a specific work of art or for another form of innovation. Grover (2008) has described the top-ranking award, the Golden Nica, as \"the Oscar of digital art\".\n\nThe Prix was first awarded in 1987, and there have been several changes in the categories since then. In 2014 there were 2,703 entries from 77 countries. All entries remain on display in an online archive, the Prix Ars Electronica Showcase, containing over 55,000 items.\n\nAwards of the \"Golden Nica\" (worth 10,000 euros), \"Awards of Distinction\", and \"Honorary Mentions\" are made in the following categories:\nNote: \n\nThere is also a grant scheme to honor and support ideas of exceptional promise. It is known as \"[the next idea] voestalpine Art and Technology Grant\".\n\n\nThe Center, also known as the \"Museum of the Future\", is housed in a modern complex of buildings by the Danube. It acts as Ars Electronica’s permanent base and showcase. The majority of the space is used for public exhibitions and events, with an emphasis on interactivity and participation. Major themes are life sciences, environmental issues, and preparation for impending technological developments with likely impacts on society.\n\nThere is also provision for conferences, workshops, and R&D. The Center was enhanced and expanded in 2009, coincident with Linz’s term as European Capital of Culture. It is the most-visited museum in Linz.\n\nThe Futurelab, housed at the Ars Electronica Center, is a center of expertise for multidisciplinary research and development of new cyberarts technologies. It is staffed by about 25 permanent team members, and offers residencies to established and emerging artists and researchers.\n\nThe Futurelab has produced infrastructure and content for the Center and Festival. More recently it has engaged in joint ventures with universities and the private sector.\n\nThe winner of [the next idea] voestalpine Art and Technology Grant is entitled to a term as Artist/Scientist-in-Residence at the Futurelab.\n\nTrent Nathaniel Grover has included an Appendix about Ars Electronica in his book \"Dream of the Techno-Shaman\" (2008). He describes the institute’s activities as “a unique platform for exploring, discussing, tracking, and analyzing the interrelation between art, technology, and society”. Such work, he argues, affirms the place of the human being at the center of techno-cultural processes, as “beneficiaries, victims, and, above all, creators and appliers of new technology”. Noting that the rapid pace of technological innovation has profound implications for culture and society, he presents the role of Ars Electronica as working to integrate developments in technology with art and society to the benefit of all, and contrasts this perspective with the Modernist call for \"art for art’s sake\".\n\nGrover concludes by hoping that Ars Electronica \"will be able to maintain its ongoing quest for innovation and expansion so that we can all benefit from and further involve ourselves in the integration of art, technology, and society\".\n\nGrover (2008) has described the published work of Ars Electronica as \"a compelling snapshot of codependent technological and artistic development with expansive and lasting social and cultural impact.\"\n\n\n\n"}
{"id": "191145", "url": "https://en.wikipedia.org/wiki?curid=191145", "title": "Autonomy", "text": "Autonomy\n\nIn development or moral, political, and bioethical philosophy, autonomy is the capacity to make an informed, un-coerced decision. Autonomous organizations or institutions are independent or self-governing. Autonomy can also be defined from human resource perspective and it means a level of discretion granted to an employee in his or her work. In such cases, autonomy is known to bring some sense of job satisfaction among the employees. Autonomy is a term that is also widely used and in the field of medicine. As a matter of fact, personal autonomy is greatly recognized and valued in health care.\n\nIn the sociology of knowledge, a branch of sociology, a controversy over the boundaries of autonomy stopped at the concept of relative autonomy, until a typology of autonomy was created and developed within science and technology studies. According to it, the contemporary form of science's existing autonomy is the reflexive autonomy: actors and structures within the scientific field are able to translate or to reflect diverse themes presented by social and political fields, as well as influence them regarding the thematic choices on research projects.\n\nInstitutional autonomy is having the capacities as a legislator to be able to implant and pursue official goals. The institutions are responsible for finding the right amount of resources or modify their current plans, programs, courses, responsibilities, and services to be able to have the means fit the end. But in order to do so, they must counter the obstacles that can occur, such as social pressure and socioeconomic difficulties. From a legislator's point of view, to increase institutional autonomy, conditions of self-management and institutional self-governance must be put in place. An increase in leadership and a redistribution of the responsibilities of decision-making would be beneficial to the research of resources. \nInstitutional autonomy was often seen as a synonym for self-determination, and the government feared that it would lead institutions to an irredentist or secessionist state. But autonomy should be seen as the solution to the struggles of self-determination. Self-determination is a movement toward independence, whereas autonomy is a way to accommodate the separatist in a country. Institutional autonomy has been the answer to conflicts regarding minorities and ethnic groups in a society. Allowing more autonomy to groups and institutions helps create diplomatic relationships with them and the government.\n\nIn governmental parlence, autonomy refers to self-governance. An example of an autonomous jurisdiction was the former United States governance of the Philippine Islands. The \"Philippine Autonomy Act of 1916\" provided the framework for the creation of an autonomous government under which the Filipino people had broader domestic autonomy than previously, although it reserved certain privileges to the United States to protect its sovereign rights and interests. Another example was the status of Kosovo as the Socialist Autonomous Province of Kosovo under the former Yugoslav government of Marshal Tito.\n\nAutonomy is a key concept that has a broad impact on different fields of philosophy. In metaphysical philosophy, the concept of autonomy is referenced in discussions about free will, fatalism, determinism, and agency. In \"How to Make Good Decisions and Be Right All the Time\", philosopher Iain King developed an 'Autonomy Principle', which he defines as \"Let people choose for themselves, unless we know their interests better than they can.\" King argues it is not enough to know someone else's interests better than the person; autonomy should only be infringed if a person is \"unable\" to know their own interests on a particular matter. In moral philosophy, autonomy refers to subjecting oneself to objective moral law.\n\nImmanuel Kant (1724–1804) defined autonomy by three themes regarding contemporary ethics. Firstly, autonomy as the right for one to make their own decisions excluding any interference from others. Secondly, autonomy as the capacity to make such decisions through one's own independence of mind and after personal reflection. Thirdly, as an ideal way of living life autonomously. In summary, autonomy is the moral right one possesses, or the capacity we have in order to think and make decisions for oneself providing some degree of control or power over the events that unfold within one's everyday life.\n\nThe context in which Kant addresses autonomy is in regards to moral theory, asking both foundational and abstract questions. He believed that in order for there to be morality, there must be autonomy. He breaks down autonomy into two distinct components. “Auto” can be defined as the negative form of independence, or to be free in a negative sense. This is the aspect where decisions are made on your own. Whereas, “nomos” is the positive sense, a freedom or lawfulness, where you are choosing a law to follow. Kantian autonomy also provides a sense of rational autonomy, simply meaning one rationally possesses the motivation to govern their own life. Rational autonomy entails making your own decisions but it cannot be done solely in isolation. Cooperative rational interactions are required to both develop and exercise our ability to live in a world with others.\n\nKant argued that morality presupposes this autonomy () in moral agents, since moral requirements are expressed in categorical imperatives. An imperative is categorical if it issues a valid command independent of personal desires or interests that would provide a reason for obeying the command. It is hypothetical if the validity of its command, if the reason why one can be expected to obey it, is the fact that one desires or is interested in something further that obedience to the command would entail. \"Don't speed on the freeway if you don't want to be stopped by the police\" is a hypothetical imperative. \"It is wrong to break the law, so don't speed on the freeway\" is a categorical imperative. The hypothetical command not to speed on the freeway is not valid for you if you do not care whether you are stopped by the police. The categorical command is valid for you either way. Autonomous moral agents can be expected to obey the command of a categorical imperative even if they lack a personal desire or interest in doing so. It remains an open question whether they will, however.\n\nThe Kantian concept of autonomy is often misconstrued, leaving out the important point about the autonomous agent's self-subjection to the moral law. It is thought that autonomy is fully explained as the ability to obey a categorical command independently of a personal desire or interest in doing so—or worse, that autonomy is \"obeying\" a categorical command independently of a natural desire or interest; and that heteronomy, its opposite, is acting instead on personal motives of the kind referenced in hypothetical imperatives.\n\nIn his \"Groundwork of the Metaphysic of Morals\", Kant applied the concept of autonomy also to define the concept of personhood and human dignity. Autonomy, along with rationality, are seen by Kant as the two criteria for a meaningful life. Kant would consider a life lived without these not worth living; it would be a life of value equal to that of a plant or insect. According to Kant autonomy is part of the reason that we hold others morally accountable for their actions. Human actions are morally praise- or blame-worthy in virtue of our autonomy. Non- autonomous beings such as plants or animals are not blameworthy due to their actions being non-autonomous. Kant's position on crime and punishment is influenced by his views on autonomy. Brainwashing or drugging criminals into being law-abiding citizens would be immoral as it would not be respecting their autonomy. Rehabilitation must be sought in a way that respects their autonomy and dignity as human beings.\n\nFriedrich Nietzsche wrote about autonomy and the moral fight. Autonomy in this sense is referred to as the free self and entails several aspects of the self, including self-respect and even self-love. This can be interpreted as influenced by Kant (self-respect) and Aristotle (self-love). For Nietzsche, valuing ethical autonomy can dissolve the conflict between love (self-love) and law (self-respect) which can then translate into reality through experiences of being self-responsible. Because Nietzsche defines having a sense of freedom with being responsible for one's own life, freedom and self-responsibility can be very much linked to autonomy.\n\nThe Swiss philosopher Jean Piaget (1896-1980) believed that autonomy comes from within and results from a “free decision”. It is of intrinsic value and the morality of autonomy is not only accepted but obligatory. When an attempt at social interchange occurs, it is reciprocal, ideal and natural for there to be autonomy regardless of why the collaboration with others has taken place. For Piaget, the term autonomous can be used to explain the idea that rules are self-chosen. By choosing which rules to follow or not, we are in turn determining our own behaviour.\n\nPiaget studied the cognitive development of children by analyzing them during their games and through interviews, establishing (among other principles) that the children moral maturation process occurs in two phases, the first of heteronomy and the second of autonomy:\nRules are objective and unchanging. They must be literal because the authority are ordering it and do not fit exceptions or discussions. The base of the rule is the superior authority (parents, adults, the State), that it should not give reason for the rules imposed or fulfilled them in any case. Duties provided are conceived as given from oneself. Any moral motivation and sentiments are possible through what one believes to be right. \nRules are the product of an agreement and, therefore, are modifiable. They can be subject to interpretation and fit exceptions and objections. The base of the rule is its own acceptance, and its meaning has to be explained. Sanctions must be proportionate to the absence, assuming that sometimes offenses can go unpunished, so that collective punishment is unacceptable if it is not the guilty. The circumstances may not punish a guilty. Duties provided are conceived as given from the outside. One follows rules mechanically as it is simply a rule, or as a way to avoid a form of punishment.\n\nThe American psychologist Lawrence Kohlberg (1927-1987) continues the studies of Piaget. His studies collected information from different latitudes to eliminate the cultural variability, and focused on the moral reasoning, and not so much in the behavior or its consequences. Through interviews with adolescent and teenage boys, who were to try and solve “moral dilemmas,” Kohlberg went on to further develop the stages of moral development. The answers they provided could be one of two things. Either they choose to obey a given law, authority figure or rule of some sort or they chose to take actions that would serve a human need but in turn break this given rule or command.\n\nThe most popular moral dilemma asked involved the wife of a man approaching death due to a special type of cancer. Because the drug was too expensive to obtain on his own, and because the pharmacist who discovered and sold the drug had no compassion for him and only wanted profits, he stole it. Kohlberg asks these adolescent and teenage boys (10-, 13- and 16-year-olds) if they think that is what the husband should have done or not. Therefore, depending on their decisions, they provided answers to Kohlberg about deeper rationales and thoughts and determined what they value as important. This value then determined the “structure” of their moral reasoning.\n\nKohlberg established three stages of morality, each of which is subdivided into two levels. They are read in progressive sense, that is, higher levels indicate greater autonomy.\n\nAutonomy in childhood and adolescence is when one strives to gain a sense of oneself as a separate, self-governing individual. Between ages 1–3, during the second stage of Erikson's and Freud's stages of development, the psychosocial crisis that occurs is autonomy versus shame and doubt. The significant event that occurs during this stage is that children must learn to be autonomous, and failure to do so may lead to the child doubting their own abilities and feel ashamed. When a child becomes autonomous it allows them to explore and acquire new skills. Autonomy has two vital aspects wherein there is an emotional component where one relies more on themselves rather than their parents and a behavioural component where one makes decisions independently by using their judgement. The styles of child rearing affect the development of a child's autonomy. Authoritative child rearing is the most successful approach, where the parents engage in autonomy granting appropriate to their age and abilities. Autonomy in adolescence is closely related to their quest for identity. In adolescence parents and peers act as agents of influence. Peer influence in early adolescence may help the process of an adolescent to gradually become more autonomous by being less susceptible to parental or peer influence as they get older. In adolescence the most important developmental task is to develop a healthy sense of autonomy.\n\nIn Christianity, autonomy is manifested as a partial self-governance on various levels of church administration. During the history of Christianity, there were two basic types of autonomy. Some important parishes and monasteries have been given special autonomous rights and privileges, and the best known example of monastic autonomy is the famous Eastern Orthodox monastic community on Mount Athos in Greece. On the other hand, administrative autonomy of entire ecclesiastical provinces has throughout history included various degrees of internal self-governance.\n\nIn ecclesiology of Eastern Orthodox Churches, there is a clear distinction between autonomy and autocephaly, since autocephalous churches have full self-governance and independence, while every autonomous church is subjected to some autocephalous church, having a certain degree of internal self-governance. Since every autonomous church had its own historical path to ecclesiastical autonomy, there are significant differences between various autonomous churches in respect of their particular degrees of self-governance. For example, churches that are autonomous can have their highest-ranking bishops, such as an archbishop or metropolitan, appointed or confirmed by the patriarch of the mother church from which it was granted its autonomy, but generally they remain self-governing in many other respects.\n\nIn the history of Western Christianity the question of ecclesiastical autonomy was also one of the most important questions, especially during the first centuries of Christianity, since various archbishops and metropolitans in Western Europe have often opposed centralizing tendencies of the Church of Rome. For example, the Roman Catholic Church is governed by its canon law which applies to all Roman Catholic churches which are thus not considered autonomous. Various denominations of Protestant churches usually have more decentralized power, and churches may be autonomous, thus having their own rules or laws of government, at the national, local, or even individual level.\n\nSartre brings the notion of the Cartesian god being totally free and autonomous. He states that existence precedes essence with god being the creator of the essences, eternal truths and divine will. This pure freedom of god relates to human freedom and autonomy; where a human is not subjected to pre-existing ideas and values.\n\nAccording to the first amendment, In the United States of America, the federal government is restricted in building a national church. This is due to the first amendment's recognizing people's freedom's to worship their faith according to their own belief's. For example, the American government has removed the church from their \"sphere of authority\" due to the churches historical impact on politics and their authority on the public. This was the beginning of the disestablishment process. The Protestant churches in the United States had a large impact on American culture, in the nineteenth century, where they organized the establishment of schools, hospitals, orphanages, colleges, magazines etc. This has brought up the famous, however, misinterpreted term of the separation of church and state. These churches lost the legislative and financial support from the state.\n\nThe first disestablishment began with the introduction of the bill of rights. In the twentieth century, due to the great depression of the 1930s and the completion of the second world war, the American churches were revived. Specifically the Protestant churches. This was the beginning of the second disestablishment were churches had become popular again but held no legislative power. One of the main reasons why the churches gained attendance and popularity was due to the baby boom. Where soldiers came back from the second world war and started their families. The large influx of newborns gave the churches a new wave of followers. However, these followers did not hold the same beliefs as their parents and brought upon the political, and religious revolutions of the 1960s.\n\nDuring the 1960s, the collapse of religious and cultural middle brought upon the third disestablishment. Religion became important to the individual and less likely the community. The changes brought from these revolutions significantly increased the personal autonomy of individuals due to the lack of structural restraints giving their added freedom of choice. This concept is known as \"new voluntarism\" where individuals have free choice on how to be religious and the free choice whether to be religious or not.\n\nIn a medical context, respect for a patient's personal autonomy is considered one of many fundamental ethical principles in medicine. Autonomy can be defined as the ability of the person to make his or her own decisions. This faith in autonomy is the central premise of the concept of informed consent and shared decision making. This idea, while considered essential to today's practice of medicine, was developed in the last 50 years. According to Tom Beauchamp and James Childress (in \"Principles of Biomedical Ethics\"), the Nuremberg trials detailed accounts of horrifyingly exploitative medical \"experiments\" which violated the subjects' physical integrity and personal autonomy. These incidences prompted calls for safeguards in medical research, such as the Nuremberg Code which stressed the importance of voluntary participation in medical research. It is believed that the Nuremberg Code served as the premise for many current documents regarding research ethics.\n\nRespect for autonomy became incorporated in health care and patients could be allowed to make personal decisions about the health care services that they receive. Notably, autonomy has several aspects as well as challenges that affect health care operations. The manner in which a patient is handled may undermine or support autonomy of a patient and for this reason, the way a patient is communicated to becomes very crucial. A good relationship between a patient and a health care practitioner needs to be well defined to ensure that autonomy of a patient is respected. Just like in any other life situation, a patient would not like to be under the control of another person. The move to emphasize respect for patient's autonomy rose from the vulnerabilities that were pointed out in regards to autonomy.\n\nHowever, autonomy does not only apply in a research context. Users of the health care system have the right to be treated with respect for their autonomy, instead of being dominated by the physician. This is referred to as paternalism. While paternalism is meant to be overall good for the patient, this can very easily interfere with autonomy. Through the therapeutic relationship, a thoughtful dialogue between the client and the physician may lead to better outcomes for the client, as he or she is more of a participant in decision-making.\n\nAutonomy varies and some patients find it overwhelming especially the minors when faced with emergency situations. It is important to note that not every patient is capable of making an autonomous decision. those who are unable to make the decisions prompt a challenge to medical practitioners since it becomes difficult to determine the ability of a patient to make a decision. to some extent, it has been said that emphasis of autonomy in health care has undermined the practice of health care practitioners to improve the health of their patient as necessary. The scenario has led to tension in the relationship between a patient and a health care practitioner. This is because as much as a physician want to prevent a patient from suffering, he or she still has to respect autonomy. Beneficence allows physicians to act responsibly in their practice, which may involve overlooking autonomy. The gap between a patient and a physician has led to problems because in other cases, the patients have complained of not being adequately informed.\n\nThe seven elements of informed consent (as defined by Beauchamp and Childress) include threshold elements (competence and voluntariness), information elements (disclosure, recommendation, and understanding) and consent elements (decision and authorization). Some philosophers such as Harry Frankfurt consider Beauchamp and Childress criteria insufficient. They claim that an action can only be considered autonomous if it involves the exercise of the capacity to form higher-order values about desires when acting intentionally. What this means is that patients may understand their situation and choices but would not be autonomous unless the patient is able to form value judgements about their reasons for choosing treatment options they would not be acting autonomously.\n\nThere are many different definitions of autonomy, many of which place the individual in a social context. See also: relational autonomy, which suggests that a person is defined through their relationships with others, and \"supported autonomy\" which suggests that in specific circumstances it may be necessary to temporarily compromise the autonomy of the person in the short term in order to preserve their autonomy in the long-term. Other definitions of the autonomy imagine the person as a contained and self-sufficient being whose rights should not be compromised under any circumstance.\n\nIn certain unique circumstances, government may have the right to temporarily override the right to bodily integrity in order to preserve the life and well-being of the person. Such action can be described using the principle of \"supported autonomy\", a concept that was developed to describe unique situations in mental health (examples include the forced feeding of a person dying from the eating disorder anorexia nervosa, or the temporary treatment of a person living with a psychotic disorder with antipsychotic medication). While controversial, the principle of supported autonomy aligns with the role of government to protect the life and liberty of its citizens. Terrence F. Ackerman has highlighted problems with these situations, he claims that by undertaking this course of action physician or governments run the risk of misinterpreting a conflict of values as a constraining effect of illness on a patient's autonomy.\n\nSince the 1960s, there have been attempts to increase patient autonomy including the requirement that physician's take bioethics courses during their time in medical school. Despite large-scale commitment to promoting patient autonomy, public mistrust of medicine in developed countries has remained. Onora O'Neill has ascribed this lack of trust to medical institutions and professionals introducing measures that benefit themselves, not the patient. O’Neill claims that this focus on autonomy promotion has been at the expense of issues like distribution of healthcare resources and public health.\n\nOne proposal to increase patient autonomy is through the use of support staff. The use of support staff including medical assistants, physician assistants, nurse practitioners, nurses, and other staff that can promote patient interests and better patient care. Nurses especially can learn about patient beliefs and values in order to increase informed consent and possibly persuade the patient through logic and reason to entertain a certain treatment plan. This would promote both autonomy and beneficence, while keeping the physician's integrity intact. Furthermore, Humphreys asserts that nurses should have professional autonomy within their scope of practice (35-37). Humphreys argues that if nurses exercise their professional autonomy more, then there will be an increase patient autonomy (35-37).\n\nAfter the Second World War there was a push for international human rights that came in many waves. Autonomy as a basic human right started the building block in the beginning of these layers alongside with liberty. The Universal declarations of Human rights of 1948 has made mention of autonomy or the legal protected right to individual self-determination in article 22.\n\nDocuments such as the United Nations Declaration on the Rights of Indigenous Peoples reconfirm international law in the aspect of human rights because those laws were already there, but it is also responsible for making sure that the laws highlighted when it comes to autonomy, cultural and integrity and land rights are made within an indigenous context by taking special attention to their historical and contemporary events\n\nThe United Nations Declaration on the Rights of Indigenous Peoples article 3 also through international law provides Human rights for Indigenous individuals through its third article by giving them a right to self-determination meaning they have all the liberties to chose their political status, and are capable to go and improve their economics social, and cultural statuses in society by developing it. Another example of this is article 4 of the same document which gives them autonomous rights when it comes to their internal or local affairs and how they can fund themselves in order to be able to self govern themselves.\n\nMinorities in countries are also protected as well by international law; the 27th article of the United Nations International covenant on Civil and Political rights or the ICCPR does so by allowing these individuals to be able to enjoy their own culture or use their language. Minorities in that manner are people from ethnic religious or linguistic groups according to the document.\n\nThe European Court of Human rights, is an international court that has been created on behalf of the European Conventions of Human rights. However, when it comes to autonomy they did not explicitly state it when it comes to the rights that individuals have. The current article 8 has remedied to that when the case of \"Pretty v the United Nations which was a case in 2002 involving assisted suicide\" where autonomy was used as a legal right in law. It was where Autonomy was distinguished and its reach into law was marked as well making it the foundations for legal precedent in making case law originating from the European Court of Human rights\n\nThe Yogyakarta Principles, a document with no binding effect in international human rights law, contend that \"self-determination\" used as meaning of autonomy on one's own matters including informed consent or sexual and reproductive rights, is integral for one's self-defined or gender identity and refused any medical procedures as a requirement for legal recognition of the gender identity of transgender. If eventually accepted by the international community in a treaty, this would make these ideas human rights in the law. The Convention on the Rights of Persons with Disabilities also defines autonomy as principles of rights of a person with disability including \"the freedom to make one's own choices, and independence of persons\".\n\nA study conducted by David C. Giles and John Maltby conveyed that after age effecting factors were removed a high emotional autonomy was a significant predictor of celebrity interest, as well as high attachment to peers with a low attachment to parents. Patterns of intense personal interest in celebrities was found to be conjunction with low levels of closeness and security. Furthermore, the results suggested that adults with a secondary group of pseudo-friends during development from parental attachment, usually focus solely on one particular celebrity, which could be due to difficulties in making this transition.\n\n\n\n"}
{"id": "36021876", "url": "https://en.wikipedia.org/wiki?curid=36021876", "title": "Baldin Collection", "text": "Baldin Collection\n\nThe Baldin Collection is a group of 364 masterpieces removed from Germany to the Soviet Union by Russian Army officer Victor Baldin at the end of World War II. The ensemble consists of 362 drawings and 2 paintings by Dürer, van Gogh, Manet, Rembrandt, Rubens, Titian and other famous artists. Historically part of the collection at the Kunsthalle Bremen, the Baldin group came from a much larger cache of artworks stored by the Germans in a Brandenburg castle to protect it from air raids. In 1945 the castle was occupied by the Red Army and the storage vaults were looted, mainly by Russian soldiers but also by the local German population. The works Baldin took were then hidden at a Soviet Research Institute for many years. In 1991 the collection was moved to the Hermitage Museum in Saint Petersburg where its existence was revealed to the world in 1992. It remains there today.\n\nSince then the Baldin Collection has been regarded as looted art and is the subject of fierce debate among experts, between Germany and Russia, and among politicians inside Russia itself. While Victor Baldin did steal the works, he is also credited with having saved them from destruction. For decades he appealed to senior officials, including Soviet leaders Leonid Brezhnev and Mikhail Gorbachev, to get them returned to Germany. In 1989 Baldin even traveled to Bremen, West Germany, to reveal the existence of the secret collection to the Kunsthalle. In the 1990s the government of Boris Yeltsin finally agreed to return the works, but subsequent Russian governments have blocked such plans. Today the Collection has been called \"of singular importance to the entire issue of trophy art\" by the Russians and a \"cause célèbre of German-Russian Restitution Politics\" by those who support its return.\n\nAt the outbreak of World War II in 1939, the Bremen Art Museum (German: \"Kunsthalle Bremen\") was closed and its priceless paintings, drawings, prints, and sculpture were stored in the basement. Bremen, an important manufacturing center, became an early target for Allied strategic bombing. On the night of 5 September 1942, a fire bomb destroyed the central staircase and six gallery rooms of the museum. It also burned a version of Emanuel Leutze's famous painting \"Washington Crossing the Delaware\", which because of its size could not be moved. After this damage, the Kunsthalle collections were moved to more secure storage in various bank vaults underneath Bremen. In 1943, as bombing intensified, Bremen's mayor decreed that the museum's collections be moved to safety outside the city. The collection was divided up between four castles in Germany. A set of 50 paintings, 1715 drawings and 3000 prints were moved to Schloss Karnzow, the hunting lodge of Count von Königsmarck, near the small town of Kyritz north of Berlin in the Province of Brandenburg.\n\nAfter Germany's defeat, Brandenburg and specifically the area around Karnzow Castle was occupied by the Red Army. On 29 May 1945 soldiers and officers of the 38th Field Engineers' Brigade billeted at the Castle began looting it. Victor Baldin, an Army captain and combat engineer, found opened boxes in the cellar, saw documents trampled on the floor, and observed soldiers lighting their way by using burning papers. Baldin, an art restorer before the war, recognized these as drawings by the great masters. Baldin intervened and sealed the cellar. Scrutinizing the treasures lying about, he found works by Corot, Delacroix, Degas, Dürer, Van Dyke, Van Gogh, Goya, Manet, Raphael, Rembrandt, Rodin, Rubens, Toulouse-Lautrec, and Titian.\n\nBaldin became determined to save what he could. He later said \"I started in on the beautiful things, then I saw it was all beautiful.\" He took drawings away from soldiers by force, by deception and in exchange for personal items. In one case, it took him three days to obtain a drawing of Christ's head by Albrecht Dürer from another officer. Baldin managed to coax the officer into exchanging it for his chrome boots. Of the thousands of works stored in the cellar, Baldin managed to save just 362 drawings and 2 paintings. Among them was the only known pen and ink study by van Gogh of his famous painting, \"Starry Night\" As the Soviet Army withdrew, the cellars were left open and what little remained of the collection was lost to local looters and the weather.\n\nBaldin's actions and motives are still debated today. He did indeed cut the drawings from their mounts, put them into a suitcase, carry them to Russia and hide them in his apartment. However, while at the castle Baldin also wrote down descriptions of every work he saw, copied the German signatures and labels, and later carefully documented their provenance. He also begged for an official military transport so the collection could be handled more securely, but none were available, and his request was denied. As a result, it is generally agreed that Baldin's efforts rescued priceless masterpieces from outright destruction. In addition, because of his specialized art knowledge, what would become known as the \"Baldin Collection\" became the most important part of the Kunsthalle collection remaining from Schloss Karnzow.\n\nIn contrast to Baldin's efforts, works looted by Baldin's comrades from Karnzow have been found as far afield as Azerbaijan and in varying states of decay. In the late 1990s eight disputed drawings, including the world-famous \"Frauenbad\" (\"Women's Bathhouse\") by Albrecht Dürer, were seized by United States Customs in an incident of black market trading. Today over 1,500 items from the Kunsthalle collection that were stored at Karnzow remain missing.\n\nAfter their return home, some of the officers who had participated in the looting at Karnzow donated their pieces to museums around the Soviet Union. In 1948 Baldin deposited his at the A. V. Shchusev State Scientific Research Museum of Architecture in Moscow, where the masterpieces became a Soviet state secret. Baldin worked as an art restorer at the museum and eventually became its general director in 1963, a post he held for 25 years.\n\nBaldin then tried for decades to give the stolen art back to Germany. He took the courageous steps of writing to Soviet leader Leonid Brezhnev in 1973, to the chief ideologist of the Communist Party Yegor Ligachev in 1987, and many other Soviet political and cultural officials including Mikhail Suslov, Mikhail Gorbachev, and Raisa Gorbachev – all to no avail. In 1989, during the period of increased transparency in the Soviet Union known as perestroika, Baldin took another unprecedented step. He traveled to Bremen, West Germany, and met with the director of the Kunsthalle, Dr Siegfried Salzmann. The director was shocked to learn that important parts of the long lost collection had survived. With hands shaking, he read the list of the missing masterpieces that Baldin had prepared years before. Baldin had put pencil marks next to those works he had personally rescued. He has since been called the \"hero of the story.\"\n\nIn 1991, Baldin wrote to Russian President Boris Yeltsin and finally received his first reply, in which the president agreed it would be politically correct to return the works to Germany. However, that same year nationalist elements in the Russian government hurriedly transferred the collection to the State Hermitage Museum in St. Petersburg in a cover-up attempt. As of 2012 it is still unclear if one of the most famous works in the collection, \"Cypresses in Starry Night\" (1889) by Van Gogh, is at the Hermitage or remains in Moscow.\n\nIn legal proceedings and political debates during the following years it appeared that collection might return to its rightful owner. In 2000, a group of 101 pieces from another part of Baldin's brigade, including Albrecht Duerers' 1494 watercolor \"View of a Rock Castle by a River\", were returned to the Kunsthalle by Russia. This was followed by the simultaneous return of two artifacts of the Amber Room, bought and financed by a Bremen businessman to speed up the process. Anatoly Vilkov, from the Russian ministry of culture, stated that \"Russia has no right to keep the Baldin collection. We did not receive this right through a gift, since by law the collection did not belong to the donor Baldin.\"\n\nThe potential return of the collection to Germany began to face increasing opposition from Russian nationalist leaders, including Communist legislator and former Culture Minister of the USSR Nikolai Gubenko. Gubenko had been one of those involved in the 1991 transfer of the art to the Hermitage to hide it. The State Duma, which included Gubenko as a member, passed a non-binding resolution on 12 March 2003 asking President Vladimir Putin to prevent the Culture Ministry from returning the Baldin Collection.\n\nRussian Culture Minister Mikhail Shvydkoy opposed these moves to keep the collection in Russia; he regarded it as illegal loot based on a 1998 law that protected only those artworks from World War II taken by official Soviet trophy brigades and not private citizens. In 2003 he confirmed an order by the Russian General Prosecutor confirming a resolution of the Hanse Supreme court, which had decided the entire 364 remaining items were the official property of the Bremen Kunsthalle. Shvydkoy and the German Minister of Culture Christina Weiss even signed an agreement that 20 pieces of the Baldin ensemble could remain in Russia. Shvydkoy later received an official reprimand and was threatened by deputy prosecutor Vladimir Kolsenikov with criminal charges if he attempted to return the rest of the collection to Germany. In 2005 Aleksandr Sergeyevich Sokolov, Russia's new Culture Minister, then contradicted previous promises and stated that he opposed the return of the Baldin collection to Germany. As of 2010, it appeared that the collection would not be returning to Germany any time soon.\n\nAccording to a 2005 interview with Baldin's widow Julia Siwakowa, it was always his wish that the looted art be returned to the Kunsthalle. Baldin's last will stated: \"The collection belongs to humankind, not only Germany, and as the collection was located at the Kunsthalle Bremen, it must be returned to this place.\" The history of Victor Baldin, the stolen paintings and their odyssey is featured in the 2007 book \"Victor Baldin – The Man with the Suitcase/Victor Baldin – Der Mann mit dem Koffer\".\n\n"}
{"id": "58583499", "url": "https://en.wikipedia.org/wiki?curid=58583499", "title": "Benjamin Heidersberger", "text": "Benjamin Heidersberger\n\nBenjamin Heidersberger (born in 1957 in Braunschweig, Germany) is a German media artist, journalist, entrepreneur and culture manager. He lives and works in Berlin and Wolfsburg.\n\nHeidersberger studied physics, biology, and computer science at the Technical University of Braunschweig in 1978. From 1978 to 1984, he was part of the interdisciplinary artist group \"Head Resonance\" in Wolfsburg. Along with vocalist and percussionist Peter Elsner, they conducted research on how ideas become reality in architecture, music, performance and installation. \n\nIn 1984, he moved to Hamburg to work for a PC-dealer. From 1988 onward, he was an editor of the Computer-Magazine, \"MACup,\" about hardware and software, and later about art, technology, and society. \n\nIn 1989, he co-founded the \"Ponton-Lab\" as an artist group and realised interactive media and TV-projects on Documenta- 8 and Documenta- IX, in Japan 1993 as well as on Ars Electronica 1986, 89, 90 and 96 under the brand \"Van Gogh TV\". \n\nIn 1992, the international project Piazza virtuale was realised, transmitting during the 100 days of Documenta daily 90 minutes of live-TV from 12 studios across Europe. The same year he curated the exhibition \"Creative Software – On Men and Milestones\" at Ars Electronica.\n\nIn 1993 and 1994, Heidersberger taught Design of Electronic Media at Merz-Academy in Stuttgart. Ponton-Lab was formed into a full-service internet agency with up to 20 employees and realised the websites for the Lower Saxony State Government and for the Federal Press Office and later the Ministry of Foreign Affairs. 1998 he launched Kulturserver, an online community for art and culture consisting of online-services for 20.000 artists similar to social media. The project was invited to present at the international conference “Cultura y Desarrollo” in Havana.\n\nIn 2002, he founded the Heidersberger Institute in Wolfsburg Castle to archive and publish the work of his father, photographer Heinrich Heidersberger. The Institute collaborates with contemporary artists to contextualise that work. In the same year he was curator for netart on the 4th Werkleitz Binnale.\n\nBeginning in 2011 Heidersberger gave lectures at the Department of Media Studies and Musicology in Humboldt-University. In 2012, he curated and produced the concert of the Japanese composer Shinji Kanki, for the Alvar Aalto Festival in Wolfsburg. He realized the algorithmic piano composition Pentatonic Permutations in a series of concerts and sound installations, among others at Ars Electronica 2016.\n\nIn 2017, he began curating the production-arts festival \"Drehmoment\" for the \"KulturRegion Stuttgart\".\n\n\n"}
{"id": "32779693", "url": "https://en.wikipedia.org/wiki?curid=32779693", "title": "Betsy Graves Reyneau", "text": "Betsy Graves Reyneau\n\nBetsy Graves Reyneau (1888–1964) was an American painter, best known for a series of portraits of prominent African Americans once owned by the Harmon Foundation. Mary McLeod Bethune, George Washington Carver, Joe Louis, and Thurgood Marshall were among her sitters.\n\nReyneau was raised in Detroit, and although discouraged by her father from becoming an artist on the grounds that it was inappropriate for a woman, she broke ties with the family to pursue that career, and as a young woman attended the School of the Museum of Fine Arts, Boston. She later lived in France for a time before returning to the United States and becoming active in civil rights causes. She was later selected by the Circuit Court of Detroit, unbeknownst to her family, to paint a portrait of her grandfather, Michigan Supreme Court Justice Benjamin F. Graves. Reyneau was also a suffragette; she became, in 1917, one of the first woman to be arrested and imprisoned for protesting Woodrow Wilson's stance on women's voting rights.\n\nMany of Reyneau's portraits are currently in the collection of the National Portrait Gallery of the Smithsonian Institution. She was inducted into the Michigan Women's Hall of Fame.\n\n"}
{"id": "1558498", "url": "https://en.wikipedia.org/wiki?curid=1558498", "title": "Cabin fever", "text": "Cabin fever\n\nCabin fever is an idiomatic term for a claustrophobic reaction that takes place when a person or group ends up in an isolated or solitary location, or stuck indoors in confined quarters for an extended period of time. Cabin fever describes the extreme irritability and restlessness a person may feel in these limiting situations. Cabin fever is also associated with boredom from being indoors for a lengthy amount of time.\n\nA person may experience cabin fever in a situation such as being isolated within a vacation cottage out in the country, or away from a civilization.\n\nWhen experiencing cabin fever, a person may tend to sleep, to have a distrust of anyone they are with, or to have an urge to go outside even in bad weather. The phrase is also used humorously to indicate simple boredom from being home alone for an extended period of time.\n\nCabin fever is not directly fatal to an individual suffering from the peculiar disorder. However, related symptoms can lead the sufferer to make irrational decisions that could potentially cause them to lose their life. Some examples would be suicide from the seclusion or paranoia, or leaving the safety of a cabin during a terrible snow storm that one may be stuck in.\n\nOne therapy for cabin fever is as simple as getting out and interacting with nature directly. Research has demonstrated that even brief interactions with nature can promote improved cognitive functioning, support a positive mood, and overall well-being. Escaping the confinement of the indoors and changing one’s scenery and surroundings can easily help an individual experiencing cabin fever overcome their mania. Going outside to experience the openness of the world will stimulate the brain and body enough to eliminate feelings of intense claustrophobia, paranoia, and restlessness associated with cabin fever.\n\nThere is little evidence of those suffering from cabin fever seeing therapists or counselors for treatment, most sufferers simply discuss their symptoms with family or friends as a way of changing the feelings of loneliness and boredom. However, there are cases of “cabin fever” that are diagnosed as mid-winter depression or Seasonal Affective Disorder (SAD). \n\nThe concept of Cabin fever was used as a theme in Charlie Chaplin's 1925 film \"The Gold Rush\", the 1980 horror film \"The Shining\", \"The Simpsons\" episode \"Mountain of Madness\", and the 2010 video game \"Alan Wake\". A song called \"Cabin Fever\" features in the 1996 musical comedy \"Muppet Treasure Island\", afflicting sailors on a ship trapped in the doldrums. Cabin Fever was the name of Wiz Khalifa's 2011 mixtape which was released February 17th. There is a quest in the popular MMORPG \"RuneScape\" of the same name.\n\nCabin fever is one of the possible afflictions the player character can suffer from in the video game set in the post-apocalyptic Canadian wasteland, \"The Long Dark\"; the condition prevents one from sleeping indoors, thus forcing them to brave the elements in order to rest.\n\nIn \"Blade Runner 2049\", fictional female character Joi, who is a virtual girlfriend of main character K, at the beginning of the movie is stating that she is suffering from \"cabin fever\".\n\n\"Cabin Fever\" is a 2002 American horror film directed by Eli Roth and starring Rider Strong, Jordan Ladd, James DeBello, and Giuseppe Andrews.\nThe story follows a group of college graduates who rent a cabin in the woods and begin to fall victim to a flesh-eating virus. The inspiration for the film's story came from a real life experience during a trip to Iceland when Roth developed a skin infection. The film spawned a sequel \"\" (2009), a prequel \"\" (2014), and a 2016 remake of the original, also called \"Cabin Fever\".\n\n"}
{"id": "21697672", "url": "https://en.wikipedia.org/wiki?curid=21697672", "title": "Cavalieri's principle", "text": "Cavalieri's principle\n\nIn geometry, Cavalieri's principle, a modern implementation of the method of indivisibles, named after Bonaventura Cavalieri, is as follows:\n\n\nToday Cavalieri's principle is seen as an early step towards integral calculus, and while it is used in some forms, such as its generalization in Fubini's theorem, results using Cavalieri's principle can often be shown more directly via integration. In the other direction, Cavalieri's principle grew out of the ancient Greek method of exhaustion, which used limits but did not use infinitesimals.\n\nCavalieri's principle was originally called the method of indivisibles, the name it was known by in Renaissance Europe. Cavalieri developed a complete theory of indivisibles, elaborated in his \"Geometria indivisibilibus continuorum nova quadam ratione promota\" (\"Geometry, advanced in a new way by the indivisibles of the continua\", 1635) and his \"Exercitationes geometricae sex\" (\"Six geometrical exercises\", 1647).\n\nIn the 3rd century BC, Archimedes, using a method resembling Cavalieri's principle, was able to find the volume of a sphere given the volumes of a cone and cylinder in his work \"The Method of Mechanical Theorems\". In the 5th century AD, Zu Chongzhi and his son Zu Gengzhi established a similar method to find a sphere's volume. The transition from Cavalieri's indivisibles to Evangelista Torricelli's and John Wallis's infinitesimals was a major advance in the history of the calculus. The indivisibles were entities of codimension 1, so that a plane figure was thought as made out of an infinity of 1-dimensional lines. Meanwhile, infinitesimals were entities of the same dimension as the figure they make up; thus, a plane figure would be made out of \"parallelograms\" of infinitesimal width. Applying the formula for the sum of an arithmetic progression, Wallis computed the area of a triangle by partitioning it into infinitesimal parallelograms of width 1/∞.\n\nIf one knows that the volume of a cone is formula_1, then one can use Cavalieri's principle to derive the fact that the volume of a sphere is formula_2, where formula_3 is the radius.\n\nThat is done as follows: Consider a sphere of radius formula_3 and a cylinder of radius formula_3 and height formula_3. Within the cylinder is the cone whose apex is at the center of one base of the cylinder and whose base is the other base of the cylinder. By the Pythagorean theorem, the plane located formula_7 units above the \"equator\" intersects the sphere in a circle of area formula_8. The area of the plane's intersection with the part of the cylinder that is \"outside\" of the cone is also formula_8. As we can see, the area of every intersection of the circle with the horizontal plane located at any height formula_7 equals the area of the intersection of the plane with the part of the cylinder that is \"outside\" of the cone; thus, applying Cavalieri's principle, we could say that the volume of the half sphere equals the volume of the part of the cylinder that is \"outside\" the cone. The aforementioned volume of the cone is formula_11 of the volume of the cylinder, thus the volume \"outside\" of the cone is formula_12 the volume of the cylinder. Therefore the volume of the upper half of the sphere is formula_12 of the volume of the cylinder. The volume of the cylinder is\n\nTherefore the volume of the upper half-sphere is formula_15 and that of the whole sphere is formula_16.\n\nThe fact that the volume of any pyramid, regardless of the shape of the base, whether circular as in the case of a cone, or square as in the case of the Egyptian pyramids, or any other shape, is (1/3) × base × height, can be established by Cavalieri's principle if one knows only that it is true in one case. One may initially establish it in a single case by partitioning the interior of a triangular prism into three pyramidal components of equal volumes. One may show the equality of those three volumes by means of Cavalieri's principle.\n\nIn fact, Cavalieri's principle or similar infinitesimal argument is \"necessary\" to compute the volume of cones and even pyramids, which is essentially the content of Hilbert's third problem – polyhedral pyramids and cones cannot be cut and rearranged into a standard shape, and instead must be compared by infinite (infinitesimal) means. The ancient Greeks used various precursor techniques such as Archimedes's mechanical arguments or method of exhaustion to compute these volumes.\n\nIn what is called the napkin ring problem, one shows by Cavalieri's principle that when a hole is drilled straight through the centre of a sphere where the remaining band has height \"h\", the volume of the remaining material surprisingly does not depend on the size of the sphere. The cross-section of the remaining ring is a plane annulus, whose area is the difference between the areas of two circles. By the Pythagorean theorem, the area of one of the two circles is \"π\" times \"r\" − \"y\", where \"r\" is the sphere's radius and \"y\" is the distance from the plane of the equator to the cutting plane, and that of the other is \"π\" times \"r\" − (\"h\"/2). When these are subtracted, the \"r\" cancels; hence the lack of dependence of the bottom-line answer upon \"r\".\n\nN. Reed has shown how to find the area bounded by a cycloid by using Cavalieri's principle. A circle of radius \"r\" can roll in a clockwise direction upon a line below it, or in a counterclockwise direction upon a line above it. A point on the circle thereby traces out two cycloids. When the circle has rolled any particular distance, the angle through which it would have turned clockwise and that through which it would have turned counterclockwise are the same. The two points tracing the cycloids are therefore at equal heights. The line through them is therefore horizontal (i.e. parallel to the two lines on which the circle rolls). Consequently each horizontal cross-section of the circle has the same length as the corresponding horizontal cross-section of the region bounded by the two arcs of cyloids. By Cavalieri's principle, the circle therefore has the same area as that region.\n\nConsider the rectangle bounding a single cycloid arch. From the definition of a cycloid, it has width and height , so its area is four times the area of the circle. Calculate the area within this rectangle that lies above the cycloid arch by bisecting the rectangle at the midpoint where the arch meets the rectangle, rotate one piece by 180° and overlay the other half of the rectangle with it. The new rectangle, of area twice that of the circle, consists of the \"lens\" region between two cycloids, whose area was calculated above to be the same as that of the circle, and the two regions that formed the region above the cycloid arch in the original rectangle. Thus, the area bounded by a rectangle above a single complete arch of the cycloid has area equal to the area of the circle, and so, the area bounded by the arch is three times the area of the circle.\n\n\n"}
{"id": "165119", "url": "https://en.wikipedia.org/wiki?curid=165119", "title": "Cowardice", "text": "Cowardice\n\nCowardice is a trait wherein fear and excessive self-concern override doing or saying what is right, good, and of help to others or oneself in a time of need—it is the opposite of courage. As a label, \"cowardice\" indicates a failure of character in the face of a challenge. One who succumbs to cowardice is known as a coward.\n\nMany military codes of justice proscribe cowardice in combat as a crime punishable by death (note the phrase \"shot at dawn\").\n\nAs the opposite of an action or trait that many existing and formerly extant cultures demand, cowardice rates as a character flaw that many societies and their representatives stigmatize and/or punish.\n\nAccording to the \"Online Etymology Dictionary\", the word \"coward\" came into English from the Old French word \"coart\" (modern French \"couard\"), which is a combination of the word for \"tail\" (Modern French \"queue\", Latin \"cauda\") and an agent noun suffix. It would therefore have meant \"one with a tail\", which may conjur an image of an animal displaying its tail in flight of fear (\"turning tail\"), or a dog's habit of putting its tail between its legs when it is afraid. Like many other English words of French origin, this word was introduced in the English language by the French-speaking Normans, after the Norman conquest of England in 1066.\n\nThe English surname Coward (as in Noël Coward), however, has the same origin and meaning as the word \"cowherd\".\n\nActs of cowardice have long been punishable by military law, which defines a wide range of cowardly offenses, including desertion in face of the enemy and surrendering to the enemy against orders. The punishment for such acts is typically severe, ranging from corporal punishment to the death sentence. Cowardly conduct is specifically mentioned within the United States Uniform Code of Military Justice, in Article 99.\n\nGenerally, cowardice was punishable by execution during World War I, and those who were caught were often court-martialed and, in many cases, executed by firing squad. British men executed for cowardice were often not commemorated on war memorials, and their families often did not receive benefits and had to endure social stigma. However, many decades later, those soldiers all received posthumous pardons in the Armed Forces Act 2006 and have been commemorated with the Shot at Dawn Memorial. Unlike British, French, German, and Soviet/Russian forces, the United States forces tried soldiers for cowardice but never followed through with execution while German commanders were less inclined to use execution as a form of punishment.\n\nConsiderable controversy was generated by military historian S.L.A. Marshall, who claimed that 75% of U.S. combat troops in World War II never fired at the enemy for the purpose of killing, even while under direct threat. Author Dave Grossman attempted to explain these findings in his book \"\". Marshall's findings were later challenged as mistaken or even fabricated, and were not replicated in a more rigorous study of Canadian troops in World War II.\n\n\n"}
{"id": "2710800", "url": "https://en.wikipedia.org/wiki?curid=2710800", "title": "Curvature invariant (general relativity)", "text": "Curvature invariant (general relativity)\n\nIn general relativity, curvature invariants are a set of scalars formed from the Riemann, Weyl and Ricci tensors - which represent curvature, hence the name, - and possibly operations on them such as contraction, covariant differentiation and dualisation.\n\nCertain invariants formed from these curvature tensors play an important role in classifying spacetimes. Invariants are actually less powerful for distinguishing locally non-isometric Lorentzian manifolds than they are for distinguishing Riemannian manifolds. This means that they are more limited in their applications than for manifolds endowed with a positive definite metric tensor.\n\nThe principal invariants of the Riemann and Weyl tensors are certain quadratic polynomial invariants (i.e., sums of squares of components).\n\nThe principal invariants of the Riemann tensor of a four-dimensional Lorentzian manifold are\n"}
{"id": "21766677", "url": "https://en.wikipedia.org/wiki?curid=21766677", "title": "East Pole–West Pole divide", "text": "East Pole–West Pole divide\n\nThe East Pole–West Pole divide in the fields of cognitive psychology and cognitive neuroscience is an intellectual schism between researchers subscribing to the nativist and empiricist schools of thought. The term arose from the fact that much of the theory and research supporting nativism, modularity of mind, and computational theory of mind originated at several universities located on the East Coast, including Harvard University, the University of Michigan, Massachusetts Institute of Technology, and Tufts University. Conversely, much of the research and theory supporting empiricism, emergentism, and embodied cognition originated at several universities located on the West Coast, including the University of California, Berkeley, the Salk Institute, and, most notably, the University of California, San Diego. In reality, the divide is not so clear, with many universities and scholars on both coasts (as well as the Midwest and around the world) supporting each position, as well as more moderate positions in between the two extremes. The phrase was coined by Jerry Fodor at an MIT conference on cognition, at which he referred to another researcher as a \"West Coast theorist,\" apparently unaware that the researcher worked at Yale University.\n\nVery few researchers adhere strictly to the extreme positions highlighted by the East Pole–West Pole debate. That is, there are very few empiricists who believe in the Lockean ideal of the \"tabula rasa\" (namely, that children are born with no innate knowledge or constraints), and there are very few nativists who agree with Fodor's assertion that all concepts that are learned over the course of life are present in the mind prior to birth. Nevertheless, most scholars within the fields of cognitive science and developmental psychology affiliate themselves with one of the two positions through the means of their research.\n\nThe two books best known for espousing the empiricist and nativist positions within the context of cognitive psychology are \"Rethinking Innateness\" by Jeffrey Elman et al. and \"The Modularity of Mind\" by Jerry Fodor, respectively. Incidentally, the authors are affiliated with the two institutions on which the East Pole–West Pole metaphor is based, UCSD and MIT, affirming the relevance and pervasiveness of this moniker for the intellectual divide.\n\nNativists\nEmpiricists\n\n\n"}
{"id": "295571", "url": "https://en.wikipedia.org/wiki?curid=295571", "title": "Eight Consciousnesses", "text": "Eight Consciousnesses\n\nThe Eight Consciousnesses (Skt. \"aṣṭa vijñānakāyāḥ\") is a classification developed in the tradition of the Yogācāra school of Mahayana Buddhism. They enumerate the five sense consciousnesses, supplemented by the mental consciousness (\"manovijñāna\"), the defiled mental consciousness (\"kliṣṭamanovijñāna\"), and finally the fundamental store-house consciousness (\"ālāyavijñāna\"), which is the basis of the other seven. This eighth consciousness is said to store the impressions (\"vāsanāḥ\") of previous experiences, which form the seeds (\"bīja\") of future karma in this life and in the next after rebirth.\n\nAll surviving schools of Buddhist thought accept – \"in common\" – the existence of the first six primary consciousnesses (Sanskrit: ', ). The internally coherent school associated with Maitreya, Asaṅga, and Vasubandhu, however, uniquely – or \"uncommonly\" – also posits the existence of two additional primary consciousnesses, \"kliṣṭamanovijñāna\" and ', in order to explain the workings of \"karma\". The first six of these primary consciousnesses comprise the five sensory faculties together with mental consciousness, which is counted as the sixth. According to Gareth Sparham, The ' doctrine arose on the Indian subcontinent about one thousand years before Tsong kha pa. It gained its place in a distinctly system over a period of some three hundred years stretching from 100 to 400 , culminating in the ', a short text by Asaṅga (circa 350), setting out a systematic presentation of the ' doctrine developed over the previous centuries. It is the doctrine found in this text in particular that Tsong kha pa, in his \"Ocean of Eloquence\", treats as having been revealed in toto by the Buddha and transmitted to suffering humanity through the founding saints (Tib. \"shing rta srol byed\"): Maitreya<nowiki>[-nātha]</nowiki>, Asaṅga, and Vasubandhu.While some noteworthy modern scholars of the Gelug tradition (which was founded by Tsongkhapa's reforms to Atisha's Kadam school) assert that the ' is posited only in the Yogācāra philosophical tenet system, all non-Gelug schools of Tibetan buddhism maintain that the ' is accepted by the various Madhyamaka schools, as well. The eightfold network of primary consciousnesses – ' in Sanskrit (from compounding ', \"eight\", with ', the plural of \"vijñāna\" \"consciousnesses\"), or  –  is roughly sketched out in the following table.\n\nThe first five sense-consciousnesses along with the sixth consciousness are identified in the Suttapiṭaka, especially the Salayatanavagga subsection of the Saṃyuttanikāya:\nAlso, the early Buddhist texts speak of anusayā (Sanskrit: anuśayāḥ), the “underlying tendencies” or “latent dispositions” which keep beings caught in the circle of samsara. These potential tendencies are generally seen as unconscious processes which \"lie beneath\" our everyday consciousness, and according to Waldron \"they represent the potential, the tendency, for cognitive and emotional afflictions (Pali: \"kilesā\", Sanskrit: \"kleśāḥ\") to arise\".\n\nThe Sautrāntika school of Buddhism, which relied closely on the sutras, developed a theory of seeds (\"bīja\", 種子) in the mindstream (\"cittasaṃtāna\", 心相續, lit. \"mind-character-continuity\") to explain how karma and the latent dispositions continued throughout life and rebirth. This theory later developed into the alayavijñana view.\n\nThe Theravāda theory of the bhavaṅga may also be a forerunner of the ālāyavijñana theory. Vasubandhu cites the bhavaṅgavijñāna of the Sinhalese school (\"Tāmraparṇīyanikāya\") as a forerunner of the ālāyavijñāna. The Theravadin theory is also mentioned by Xuánzàng.\n\nThe texts of the Yogācāra school gives a detailed explanation of the workings of the mind and the way it constructs the reality we experience. It is \"meant to be an explanation of experience, rather than a system of ontology\". The theory of the ālāyavijñana and the other consciousnesses developed out of a need to work out various issues in Buddhist Abhidharma thought. According to Lambert Schmithausen, the first mention of the concept occurs in the Yogācārabhumiśāstra, which posits a basal consciousness that contains seeds for future cognitive processes. It is also described in the Saṃdhinirmocanasūtra and in the Mahāyānasaṃgraha of Asaṅga.\n\nVasubandhu is considered to be the systematizer of Yogācāra thought. Vasubandhu used the concept of the six consciousnesses, on which he elaborated in the \"Triṃśikaikākārikā\" (Treatise in Thirty Stanzas).\n\nAccording to the traditional interpretation, Vasubandhu states that there are eight consciousnesses (\"vijñānāni\", singular: \"vijñāna\"):\nAccording to Kalupahana, this classification of eight consciousnesses is based on a misunderstanding of Vasubandhu's Triṃśikaikākārikā by later adherents.\n\nThe ālayavijñāna (Japanese: 阿頼耶識 arayashiki), or the \"All-encompassing foundation consciousness\", forms the \"base-consciousness\" (\"mūlavijñāna\") or \"causal consciousness\". According to the traditional interpretation, the other seven consciousnesses are \"evolving\" or \"transforming\" consciousnesses originating in this base-consciousness. \nThe store-house consciousness accumulates all potential energy as seeds (\"bīja\") for the mental (\"nāma\") and physical (\"rūpa\") manifestation of one's existence (nāmarūpa). It is the storehouse-consciousness which induces rebirth, causing the origination of a new existence.\n\nThe ālayavijñāna is also described in the Saṃdhinirmocanasūtra as the \"mind which has all the seeds\" (\"sarvabījakam cittam\") which enters the womb and develops based on two forms of appropriation or attachment (\"upādāna\"); to the material sense faculties, and to predispositions (\"vāsanāḥ\") towards conceptual proliferations (\"prapañca\"). The Saṃdhinirmocanasūtra also defines it in varying ways:\n\n\"This consciousness is also called the appropriating consciousness (\"adana-vijñana\") because the body is grasped and appropriated by it.\"\n\n\"It is also called the \"alaya-vijñana\" because it dwells in and attaches to this body in a common destiny (\"ekayogakṣema-arthena\").\"\n\n\"It is also called mind (\"citta\") because it is heaped up and accumulated by [the six cognitive objects, i.e.:] visual forms, sounds, smells, flavors, tangibles and dharmas.\"\n\nIn a seemingly innovative move, the Saṃdhinirmocanasūtra states that the alayavijñana is always active subliminally and occurs simultaneously with, \"supported by and depending upon\" the six sense consciousnesses.\n\nAccording to Asanga's Mahāyānasaṃgraha, the alayavijñana is taught by other Buddhist schools by different names. He states that the alaya is what the Mahasamghikas call the “root-consciousness” (\"mulavijñana\"), what the Mahīśāsakas call “the aggregate which lasts as long as samsara” (\"asaṃsārikaskandha\") and what the Sthaviras call the bhavaṅga.\n\nThe store-house consciousness receives impressions from all functions of the other consciousnesses, and retains them as potential energy, \"bīja\" or \"seeds\", for their further manifestations and activities. Since it serves as the container for all experiential impressions it is also called the \"seed consciousness\" (種子識) or container consciousness.\n\nAccording to Yogācāra teachings, the seeds stored in the store consciousness of sentient beings are not pure.\n\nThe store consciousness, while being originally immaculate in itself, contains a \"mysterious mixture of purity and defilement, good and evil\". Because of this mixture the transformation of consciousness from defilement to purity can take place and awakening is possible.\n\nThrough the process of purification the dharma practitioner can become an Arhat, when the four defilements of the mental functions of the manas-consciousness are purified. \n\nAccording to the Laṅkāvatārasūtra and the schools of Chan and Zen Buddhism, the ālāyavijñāna is identical with the \"tathāgatagarbha\", and is fundamentally pure.\n\nThe equation of ālāyavijñāna and tathāgatagarbha was contested. It was seen as \"something akin to the Hindu notions of \"ātman\" (permanent, invariant self) and \"\" (primordial substrative nature from which all mental, emotional and physical things evolve).\" According to Lusthaus, the critique led by the end of the eighth century to the rise of the logico-epistemic tradition of Yogācāra and a hybrid school combining \"Tathāgatagarbha\" thought with basic Yogācāra doctrines:\n\nThe traditional interpretation of the eight consciousnesses may be discarded on the ground of a reinterpretation of Vasubandhu's works. According to Kalupahana, instead of positing such an consciousnesses, the Triṃśikaikākārikā describes the \"transformations\" of this consciousness:\nThese transformations are threefold:\nThe first transformation results in the \"ālāya\":\nThe ālāyavijñāna therefore is not an eighth consciousness, but the resultant of the transformation of consciousness:\nThe second transformation is \"manana\", self-consciousness or \"Self-view, self-confusion, self-esteem and self-love\". According to the Lankavatara and later interpreters it is the seventh consciousness. It is \"thinking\" about the various perceptions occurring in the stream of consciousness\". The alaya is defiled by this self-interest;\nThe third transformation is \"viṣayavijñapti\", the \"\"concept\" of the object\". In this transformation the \"concept\" of objects is created. By creating these concepts human beings become \"susceptible to grasping after the object\":\nA similar perspective is give by Walpola Rahula. According to Walpola Rahula, all the elements of the Yogācāra storehouse-consciousness are already found in the Pāli Canon. He writes that the three layers of the mind (\"citta\", \"manas\", and \"vijñāna\") as presented by Asaṅga are also mentioned in the Pāli Canon:\n\nAccording to Thomas McEvilley, although Vasubandhu had postulated numerous ālāya-vijñāna-s, a separate one for each individual person in the parakalpita, this multiplicity was later eliminated in the Fa Hsiang and Huayan metaphysics. These schools inculcated instead the doctrine of a single universal and eternal ālaya-vijñāna. This exalted enstatement of the ālāyavijñāna is described in the Fa Hsiang as \"primordial unity\".\n\nThomas McEvilley further argues that the presentation of the three natures by Vasubandhu is consistent with the Neo-platonist views of Plotinus and his universal 'One', 'Mind', and 'Soul'.\n\nA core teaching of Chan/Zen Buddhism describes the transformation of the Eight Consciousnesses into the Four Wisdoms. In this teaching, Buddhist practice is to turn the light of awareness around, from misconceptions regarding the nature of reality as being external, to kenshō, \"directly see one's own nature\".. Thus the Eighth Consciousness is transformed into the Great Perfect Mirror Wisdom, the Seventh Consciousness into the Equality (Universal Nature) Wisdom, the Sixth Consciousness into the Profound Observing Wisdom, and First to Fifth Consciousnesses into the All Performing (Perfection of Action) Wisdom.\n\nThe Interpenetration (通達) and Essence-Function (體用) of Wonhyo (元曉) is described in the Treatise on Awakening Mahāyāna Faith (大乘起信論, \"Mahāyānaśraddhotpādaśāstra,\" AMF in the excerpt below):\n\n\n"}
{"id": "25881839", "url": "https://en.wikipedia.org/wiki?curid=25881839", "title": "Entropic gravity", "text": "Entropic gravity\n\nEntropic gravity, also known as emergent gravity, is a theory in modern physics that describes gravity as an \"entropic force\"—a force with macro-scale homogeneity but which is subject to quantum-level disorder—and not a fundamental interaction. The theory, based on string theory, black hole physics, and quantum information theory, describes gravity as an \"emergent\" phenomenon that springs from the quantum entanglement of small bits of spacetime information. As such, entropic gravity is said to abide by the second law of thermodynamics under which the entropy of a physical system tends to increase over time.\n\nAt its simplest, the theory holds that when gravity becomes vanishingly weak—levels seen only at interstellar distances—it diverges from its classically understood nature and its strength begins to decay \"linearly with distance\" from a mass.\n\nEntropic gravity provides the underlying framework to explain Modified Newtonian Dynamics, or MOND, which holds that at a gravitational acceleration threshold of approximately m/s², gravitational strength begins to vary \"inversely\" (linearly) with distance from a mass rather than the normal inverse-square law of the distance. This is an exceedingly low threshold, measuring only 12 trillionths gravity’s strength at earth’s surface; an object dropped from a height of one meter would fall for 36 hours were earth’s gravity this weak. It is also 3,000 times less than exists at the point where crossed our solar system’s heliopause and entered interstellar space.\n\nThe theory claims to be consistent with both the macro-level observations of Newtonian gravity as well as Einstein's theory of general relativity and its gravitational distortion of spacetime. Importantly, the theory also explains (without invoking the existence of dark matter and its accompanying math featuring new free parameters that are tweaked to obtain the desired outcome) why galactic rotation curves differ from the profile expected with visible matter.\n\nThe theory of entropic gravity posits that what has been interpreted as unobserved dark matter is the product of quantum effects that can be regarded as a form of \"positive dark energy\" that lifts the vacuum energy of space from its ground state value. A central tenet of the theory is that the positive dark energy leads to a thermal-volume law contribution to entropy that overtakes the area law of anti-de Sitter space precisely at\nthe cosmological horizon.\n\nThe theory has been controversial within the physics community but has sparked research and experiments to test its validity.\n\nThe thermodynamic description of gravity has a history that goes back at least to research on black hole thermodynamics by Bekenstein and Hawking in the mid-1970s. These studies suggest a deep connection between gravity and thermodynamics, which describes the behavior of heat. In 1995, Jacobson demonstrated that the Einstein field equations describing relativistic gravitation can be derived by combining general thermodynamic considerations with the equivalence principle. Subsequently, other physicists, most notably Thanu Padmanabhan, began to explore links between gravity and entropy.\n\nIn 2009, Erik Verlinde proposed a conceptual model that describes gravity as an entropic force. He argues (similar to Jacobson's result) that gravity is a consequence of the \"information associated with the positions of material bodies\". This model combines the thermodynamic approach to gravity with Gerard 't Hooft's holographic principle. It implies that gravity is not a fundamental interaction, but an emergent phenomenon which arises from the statistical behavior of microscopic degrees of freedom encoded on a holographic screen. The paper drew a variety of responses from the scientific community. Andrew Strominger, a string theorist at Harvard said \"Some people have said it can't be right, others that it's right and we already knew it — that it’s right and profound, right and trivial.\"\n\nIn July 2011, Verlinde presented the further development of his ideas in a contribution to the Strings 2011 conference, including an explanation for the origin of dark matter.\n\nVerlinde's article also attracted a large amount of media exposure, and led to immediate follow-up work in cosmology, the dark energy hypothesis, cosmological acceleration, cosmological inflation, and loop quantum gravity. Also, a specific microscopic model has been proposed that indeed leads to entropic gravity emerging at large scales. Entropic gravity can emerge from quantum entanglement of local Rindler horizons.\n\nThe law of gravitation is derived from classical statistical mechanics applied to the holographic principle, that states that the description of a volume of space can be thought of as formula_1 bits of binary information, encoded on a boundary to that region, a closed surface of area formula_2. The information is evenly distributed on the surface with each bit requiring an area equal to formula_3, the so-called \"Planck area\", from which formula_1 can thus be computed:\n\nwhere formula_6 is the Planck length. The Planck length is defined as:\n\nwhere formula_8 is the universal gravitational constant, formula_9 is the speed of light, and formula_10 is the reduced Planck constant. When substituted in the equation for formula_1 we find:\n\nThe statistical equipartition theorem defines the temperature formula_13 of a system with formula_1 degrees of freedom in terms of its energy formula_15 such that:\n\nwhere formula_17 is the Boltzmann constant. This is the equivalent energy for a mass formula_18 according to:\n\nThe effective temperature experienced due to a uniform acceleration in a vacuum field according to the Unruh effect is:\n\nwhere formula_21 is that acceleration, which for a mass formula_22 would be attributed to a force formula_23 according to Newton's second law of motion:\n\nTaking the holographic screen to be a sphere of radius formula_25, the surface area would be given by:\n\nFrom algebraic substitution of these into the above relations, one derives from first principles Newton's law of universal gravitation:\n\nEntropic gravity, as proposed by Verlinde in his original article, reproduces the Einstein field equations and, in a Newtonian approximation, a 1/r potential for gravitational forces. Since its results do not differ from Newtonian gravity except in regions of extremely small gravitational fields, testing the theory with earth-based laboratory experiments doesn’t appear feasible. Spacecraft-based experiments performed at Lagrangian points within our solar system would be expensive and challenging.\n\nEven so, entropic gravity in its current form has been severely challenged on formal grounds. Matt Visser has shown that the attempt to model conservative forces in the general Newtonian case (i.e. for arbitrary potentials and an unlimited number of discrete masses) leads to unphysical requirements for the required entropy and involves an unnatural number of temperature baths of differing temperatures. Visser concludes:\nFor the derivation of Einstein's equations from an entropic gravity perspective, Tower Wang shows that the inclusion of energy-momentum conservation and cosmological homogeneity and isotropy requirements severely restrict a wide class of potential modifications of entropic gravity, some of which have been used to generalize entropic gravity beyond the singular case of an entropic model of Einstein's equations. Wang asserts that:\nCosmological observations using available technology can be used to test the theory. On the basis of lensing by the galaxy cluster Abell 1689, Nieuwenhuizen concludes that EG is strongly ruled out unless additional (dark) matter like eV neutrinos is added. A team from Leiden Observatory statistically observing the lensing effect of gravitational fields at large distances from the centers of more than 33,000 galaxies, found that those gravitational fields were consistent with Verlinde's theory. Using conventional gravitational theory, the fields implied by these observations (as well as from measured galaxy rotation curves) could only be ascribed to a particular distribution of dark matter.\n\nIn June 2017, a study by Princeton University researcher Kris Pardo asserted that Verlinde's theory is inconsistent with the observed rotation velocities of dwarf galaxies.\n\nSabine Hossenfelder argues that \"one should interpret these studies with caution\" because \"approximations must be made to arrive at [the tested] equation[s]\" and it's not yet clear that the approximations are themselves correct.\n\nAnother criticism of entropic gravity is that entropic processes should, as critics argue, break quantum coherence. Experiments with ultra-cold neutrons in the gravitational field of Earth are claimed to show that neutrons lie on discrete levels exactly as predicted by the Schrödinger equation considering the gravitation to be a conservative potential field without any decoherent factors. Archil Kobakhidze argues that this result disproves entropic gravity. Luboš Motl gives explanations of this position in his blog, while Chaichian et al. suggest a potential loophole in the argument in weak gravitational fields such as those affecting Earth-bound experiments.\n\n\n"}
{"id": "13607524", "url": "https://en.wikipedia.org/wiki?curid=13607524", "title": "Every Race Has a Flag but the Coon", "text": "Every Race Has a Flag but the Coon\n\n\"Every Race Has a Flag but the Coon\" was a song written by Will A. Heelan, and J. Fred Helf that was popular in the United States and the United Kingdom. The song followed the previous success of \"All Coons Look Alike to Me\", written in 1896 by Ernest Hogan. H. L. Mencken cites it as being one of the three coon songs which \"firmly established the term \"coon\" in the American vocabulary\".\n\nThe song was a musical hit of the day by A. M. Rothschild and Company in 1901. New York's Siegel Cooper Company referred to it as one of his greatest hits in April a year later. The next month it was sung during \"Music on the Piers\" in New York, being the first song played at the Metropolitan Avenue pier. In his book \"The Movies That Changed Us: Reflections on the Screen\", Nick Clooney refers to the song as part of the \"hit parade\" of popular music one could use to measure the temper of the times when \"The Birth of a Nation\" premiered in 1915. The tune is repeatedly referred to in the literature as having the ability to incite violence merely by whistling it in the direction of an African American. It was also Marie Dressler's contribution to the 'coon' genre. Lottie Gilson, Williams and Walker, Frances Curran, Hodges and Launchmere, Libby and Bennett, Zoa Matthews, Johnnie Carroll, Clarice Vance, Gerie Gilson, Joe Bonnell, The Eldridges and \"100 other artists\" sang the song with \"overwhelming success\" according to its sheet music.\n\nThe song motivated the creation of the Pan-African flag in 1920 by the members of the Universal Negro Improvement Association and African Communities League. \nIn a 1927 report of a 1921 speech appearing in the \"Negro World\" weekly newspaper, Marcus Garvey was quoted as saying,\nThe lyrics to \"Every Race Has a Flag but the Coon\" include the musical meme \"four eleven forty four\".\n\n"}
{"id": "1397910", "url": "https://en.wikipedia.org/wiki?curid=1397910", "title": "Existential phenomenology", "text": "Existential phenomenology\n\nExistential phenomenology is Martin Heidegger's brand of phenomenology.\n\nIn contrast with his former mentor Edmund Husserl, Heidegger (in his \"Being and Time\") put ontology before epistemology and thought that phenomenology would have to be based on an observation and analysis of \"Dasein\" (\"being-there\"), human being, investigating the fundamental ontology of the \"Lebenswelt\" (lifeworld, Husserl's term) underlying all so-called regional ontologies of the special sciences. In Heidegger's philosophy, people are thrown into the world in a given situation, but they are also a project towards the future, possibility, freedom, wait, hope, anguish. In contrast with the philosopher Kierkegaard, Heidegger wanted to explore the problem of \"Dasein\" existentially (\"existenzial\"), rather than existentielly (\"existenziell\") because Heidegger argued Kierkegaard had already described the latter with \"penetrating fashion\".\n\nBesides Heidegger, other existential phenomenologists were Hannah Arendt, Karl Jaspers, Emmanuel Levinas, Gabriel Marcel, Jean-Paul Sartre, Simone de Beauvoir, Frantz Fanon, Maurice Merleau-Ponty, and Samuel Todes.\n\nExistential phenomenology extends also to other disciplines. For example, Leo Steinberg's essay \"The Philosophical Brothel\" describes Picasso's \"Les Demoiselles d'Avignon\" in a perspective that is existential-phenomenological. It has also impacted architectural theory, especially in the phenomenological and Heideggerian approaches to space, place, dwelling, technology, etc.\n\n"}
{"id": "1377832", "url": "https://en.wikipedia.org/wiki?curid=1377832", "title": "Guideline", "text": "Guideline\n\nA guideline is a statement by which to determine a course of action. A guideline aims to streamline particular processes according to a set routine or sound practice. By definition, following a guideline is never mandatory. Guidelines are not binding and are not enforced.\n\nGuidelines may be issued by and used by any organization (governmental or private) to make the actions of its employees or divisions more predictable, and presumably of higher quality.\n\nExamples of guidelines are:\n"}
{"id": "24307466", "url": "https://en.wikipedia.org/wiki?curid=24307466", "title": "Harmonic progression (mathematics)", "text": "Harmonic progression (mathematics)\n\nIn mathematics, a harmonic progression (or harmonic sequence) is a progression formed by taking the reciprocals of an arithmetic progression. It is a sequence of the form\n\nwhere −a/\"d\" is not a natural number and \"k\" is a natural number.\n\nEquivalently, a sequence is a harmonic progression when each term is the harmonic mean of the neighboring terms.\n\nIt is not possible for a harmonic progression (other than the trivial case where \"a\" = 1 and \"k\" = 0) to sum to an integer. The reason is that, necessarily, at least one denominator of the progression will be divisible by a prime number that does not divide any other denominator.\n\n\nIf collinear points A, B, C, and D are such that D is the harmonic conjugate of C with respect to A and B, then the distances from any one of these points to the three remaining points form harmonic progression. Specifically, each of the sequences\nAC, AB, AD; BC, BA, BD; CA, CD, CB; and DA, DC, DB are harmonic progressions, where each of the distances is signed according to a fixed orientation of the line.\n\nIn a triangle, if the altitudes are in arithmetic progression, then the sides are in harmonic progression\n\n\n"}
{"id": "13665", "url": "https://en.wikipedia.org/wiki?curid=13665", "title": "Hausdorff maximal principle", "text": "Hausdorff maximal principle\n\nIn mathematics, the Hausdorff maximal principle is an alternate and earlier formulation of Zorn's lemma proved by Felix Hausdorff in 1914 (Moore 1982:168). It states that in any partially ordered set, every totally ordered subset is contained in a maximal totally ordered subset.\n\nThe Hausdorff maximal principle is one of many statements equivalent to the axiom of choice over ZF (Zermelo–Fraenkel set theory without the axiom of choice). The principle is also called the Hausdorff maximality theorem or the Kuratowski lemma (Kelley 1955:33).\n\nThe Hausdorff maximal principle states that, in any partially ordered set, every totally ordered subset is contained in a maximal totally ordered subset. Here a maximal totally ordered subset is one that, if enlarged in any way, does not remain totally ordered. The maximal set produced by the principle is not unique, in general; there may be many maximal totally ordered subsets containing a given totally ordered subset.\n\nAn equivalent form of the principle is that in every partially ordered set there exists a maximal totally ordered subset.\n\nTo prove that it follows from the original form, let \"A\" be a poset. Then formula_1 is a totally ordered subset of \"A\", hence there exists a maximal totally ordered subset containing formula_1, in particular \"A\" contains a maximal totally ordered subset.\n\nFor the converse direction, let \"A\" be a partially ordered set and \"T\" a totally ordered subset of \"A\". Then\nis partially ordered by set inclusion formula_4, therefore it contains a maximal totally ordered subset \"P\". Then the set formula_5 satisfies the desired properties.\n\nThe proof that the Hausdorff maximal principle is equivalent to Zorn's lemma is very similar to this proof.\n\nEXAMPLE 1. If \"A\" is any collection of sets, the relation \"is a proper subset of\" is a strict partial order on \"A\". Suppose that \"A\" is the collection of all circular regions (interiors of circles) in the plane. One maximal totally ordered sub-collection of \"A\" consists of all circular regions with centers at the origin. Another maximal totally ordered sub-collection consists of all circular regions bounded by circles tangent from the right to the y-axis at the origin.\n\nEXAMPLE 2. If (x, y) and (x, y) are two points of the plane ℝ, define (x, y) < (x, y)\n\nif y = y and x < x. This is a partial ordering of ℝ under which two points are comparable only if they lie on the same horizontal line. The maximal totally ordered sets are horizontal lines in ℝ.\n\n\n"}
{"id": "103944", "url": "https://en.wikipedia.org/wiki?curid=103944", "title": "Index of conservation articles", "text": "Index of conservation articles\n\nThis is an index of conservation topics. It is an alphabetical index of articles relating to conservation biology and conservation of the natural environment.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "12246701", "url": "https://en.wikipedia.org/wiki?curid=12246701", "title": "Jan Coucke and Pieter Goethals", "text": "Jan Coucke and Pieter Goethals\n\nJan Coucke (c. 1812 – 16 November 1860) and Pieter Goethals (c. 1826 – 16 November 1860) were two Flemings who were sentenced to death for murder in 1860 at a time Belgium was legally only French-speaking, though the majority of the citizens spoke Dutch, and only the official language was acknowledged by the Courts of Justice. They became an example as well as an exponent of how the French-speaking bourgeoisie (from Wallonia but also from Flanders) treated their Flemish fellow-citizens, of whom the language – if not its speakers – was considered inferior by the elite.\nLater on, the real perpetrators confessed to the murder, which in 1873 led to a debate in parliament that ended in the \"Coremans Act\", one of the first laws to recognize Dutch as an official language in Belgium, allowing the Flemish to use their own language at Flemish courts, though not yet in Brussels.\n\nOn 23 March 1860, widow Dubois was the victim of an assault and robbery by night in Couillet near Charleroi. She was discovered in agony only the next day, and died of her injuries a few days later. To the village policeman, she had only been able to utter that her attackers spoke \"Flemish\". Consequently, the attention was drawn on two Flemings who had been making a living in the region, Jan Coucke, a forty-nine-year-old potato salesman born in Sint-Denijs near Kortrijk, and Pieter Goethals, a railroad worker originating from Lotenhulle and thirty-four years of age.\n\nTheir trial in French at the Assize Court of Hainaut in Mons started on 20 August 1860. Although both lived in Couillet, Wallonia, and spoke French for their work, they were assisted by a Dutch translator, Pierre Van Horenbeek.\n\nProsecutor Charles-Victor de Bavay obtained their death sentence five days later. They were beheaded on the Grand Market Place of Charleroi a few weeks later.\n\nIn 1861, a year after the execution, 14 members of the infamous Black Gang were to appear before the same assize court. The leader of the gang, Leopold Rabet, confessed that French-speaking gang members had killed the widow Dubois. Jean-Baptiste Boucher and Auguste Leclercq confessed to having committed the murder and were sentenced to death. They also confessed that although Coucke and Goethals did not kill the widow, they were their accomplices.\n\nOn 18 July 2005 at the Belgian federal parliament, Filip De Man directed a series of questions at the vice-prime minister and minister of Justice (Laurette Onkelinx), regarding the case Coucke and Goethals. His introduction stated that since 1861 there had been several attempts to officially restore the honour of Coucke and Goethals. In 2000, Johan Vande Lanotte, and Geert Goedertier had still written (in \"België voor beginners. Wegwijs in het Belgisch labyrint\", p. 27, die Keure, Brugge) that Coucke and Goethals were not the murderers of the widow, but were informed on the murder. In 1948, a study by the Flemish journalist Herman Bossier had concluded that there had not been a miscarriage of justice, as according to the journalist, the declaration by Rabet included errors and two other members of the Black Gang, after their trial, had talked about the Flemish as accomplices; the interpreter would not have been a \"gendarme\" from Luxembourg, but a sworn translator of Dutch origin (\"Nederlandse afkomst\"). On five occasions Goethals would have confessed and as chief railroad worker he had to know the French language, while Coucke sold vegetables to French-speaking customers and, having had money problems before the murder, thereafter had means of which he could not demonstrate the origin.\n\nThe Member of Parliament then asked whether the \"dossier\" of the trial case could be looked into by MPs or by civilians, and whether it corroborated the journalist's statements about Rabet, the interpreter, Goethals' confessions, and Coucke's financial situation. He also wished to know whether the nine death penalties of 17 January 1862 by the same court of which seven had been reduced, were connected to the Black Gang and thus to Boucher, Leclerq, and Rabet. Would the Minister of Justice in this case be willing to ask the advice of the Attorney General at the Appeal Court of Mons, and to ask for the revision of the verdict of 1869, or to provide reasons for not asking the latter.\n\nThe Minister replied one year later, on 24 July 2006. The confession of guilt by third parties can be considered as a \"new fact\" having taken place after the conviction, offering the possibility to review the case. The criticism and advises that several authors may have brought forward, do not form a ground for a revision. According to the Minister, of the mentioned elements, only the statement by Rabet form such a ground in as far it is of a nature that proves the innocence of the convicts and it has been made in circumstances giving credibility to that statement or confession. The mentioned information however, does not offer the possibility to assess the reality, the circumstances, and the reach of the declarations by Rabet. The \"dossier\" on the case can be viewed if the Attorney General at the Appeal Court of Mons gives his permission, even in case it is in the National Archives as it is over a hundred years old.\n\n\n"}
{"id": "54449420", "url": "https://en.wikipedia.org/wiki?curid=54449420", "title": "Jonathan McIntosh", "text": "Jonathan McIntosh\n\nJonathan McIntosh is an American producer, writer, artist, and cultural critic. He is the creator of the Pop Culture Detective Agency video series examining intersections of politics, masculinity, and entertainment. He was also a producer and co-writer on the \"Tropes vs. Women in Video Games\" YouTube video series.\n\nMcIntosh produced video mashups early in his film career. A proponent of remix culture, he spoke on the topic and how media produced in this fashion can be uniquely powerful tools for commenting on political and social issues.\n\nAmerican academic and political activist Lawrence Lessig cites McIntosh's work as among his favorites in the book Remix: Making Art and Commerce Thrive in the Hybrid Economy for its ability to deliver \"a message more powerfully than any original alone could.\" \n\nIn 2012, McIntosh spoke before the United States Copyright Office to advocate for exemptions to the Digital Millennium Copyright Act—a law designed to criminalize the unauthorized production and dissemination of technology, devices, or services regarding copyrighted works—that was adversely affecting video artists like himself. His 2009 video, \"Buffy versus Edward: Twilight Remixed\"—a high-profile mashup video and Webby Award nominee for remixing—was used as an example in the copyright discussion. The final rulemaking stated an exemption for: \"Motion pictures (including television shows and videos), as defined in 17 U.S.C. 101, where circumvention is undertaken solely in order to make use of short portions of the motion pictures for the purpose of criticism or comment in limited instances.\" It specifically points out \"Buffy versus Edward: Twilight Remixed\" in the rulemaking: Based on the video evidence presented, the Register is able to conclude that diminished quality likely would impair the criticism and comment contained in noncommercial videos. For example, the Register is able to perceive that Buffy vs Edward and other noncommercial videos would suffer significantly because of blurring and the loss of detail in characters’ expression and sense of depth.\n\nFrom 2013-2015, McIntosh worked on the Tropes vs. Women in Video Games YouTube video series as a producer and co-writer. The web series was a highly successful Kickstarter created by Anita Sarkeesian that examined gender tropes in video games.\n\nIn 2016 McIntosh launched the Pop Culture Detective Agency, a Patreon-funded web series examining the intersections of politics, masculinity, and entertainment. The long-form video essays examine a variety of topics within these themes. One episode explored the concept of toxic masculinity through an American pop culture lens. Other episodes are devoted to examining specific pieces of pop culture, such as television programs Steven Universe and The Big Bang Theory, and films including Fantastic Beasts and Where to Find Them and Star Wars. Some of the videos produced in the series propose new cultural tropes in which to understand the topics discussed, such as \"Born Sexy Yesterday\", which seeks to explain how fictional characters exhibit men’s fear of experienced women.\n\nIn 2014, McIntosh wrote the opinion piece, \"Playing with privilege: the invisible benefits of gaming while male\", which addressed the Gamergate controversy that had been receiving increasing media attention and public discourse. In the piece, he sought to address the underlying problems that contributed toward sexism in video gaming by examining the inherent privileges that male-identified gamers benefit from. Taking inspiration from the famous \"Daily Effects of White Privilege\" list by Peggy McIntosh, among others, McIntosh listed 25 Daily Effects of Male Game Privilege. These included such privileges as \"I will never be asked or expected to speak for all other gamers who share my gender.\"\n\n"}
{"id": "1701800", "url": "https://en.wikipedia.org/wiki?curid=1701800", "title": "Law of the case", "text": "Law of the case\n\nThe law of the case is a legal term of art that is applicable mainly in common law, or Anglo-American, jurisdictions that recognize the related doctrine of \"stare decisis.\" The phrase refers to instances where \"rulings made by a trial court and not challenged on appeal become the law of the case.\" \"Unless the trial court's rulings were clearly in error or there has been an important change in circumstances, the court's prior rulings must stand.\" Usually the situation occurs when either a case is on appeal for the second time—\"e.g.\" if the reviewing court remanded the matter to the trial court and the party appeals again or if the case was appealed in a higher appellate court—for example, from an appellate court to the highest court. \n\nAs generally used, \"law of the case\" states that, if an appellate court has passed on a legal question and remanded the case to the court below for further proceedings, the legal question thus determined by the appellate court will not be differently determined on a subsequent appeal in the same case where the facts remain the same.\n\nThe doctrine provides that an appellate court’s determination on a legal issue is binding on both the trial court on remand and on the appellate court on a subsequent appeal given the same case and substantially the same facts.\n\nThe \"law of the case\" doctrine, however, is one of policy only and will be disregarded when compelling circumstances call for a redetermination of a point of law on prior appeal. This is particularly true where an intervening or a contemporaneous change in law has occurred where former decisions have been overruled or new precedent has been established by controlling authority.\n\nThe \"law of the case\" doctrine precludes reconsideration of a previously decided issue unless one of three \"exceptional circumstances\" exists: (1) when substantially different evidence is raised at a subsequent trial, (2) when a subsequent contrary view of the law is decided by the controlling authority, or (3) when a decision is clearly erroneous and would result in a manifest injustice.\n\n"}
{"id": "40851390", "url": "https://en.wikipedia.org/wiki?curid=40851390", "title": "Legal opportunity structure", "text": "Legal opportunity structure\n\nLegal opportunity structure or legal opportunity is a concept found in the study of law and social movements. It was first used in order to distinguish it from political opportunity structure or political opportunity, on the basis that law and the courts deserved to be studied in their own right rather than being lumped together with political institutions. Legal opportunities are made up of: access to the courts, which may be affected in particular by the law on standing or \"locus standi\", and costs rules; 'legal stock' or the set of available precedents on which to hang a case; and judicial receptiveness. Some of these are more obviously structural than others - hence the term legal opportunity is sometimes preferred over legal opportunity structure.\n\nLegal opportunity has been used as an independent variable to help to explain strategy choice by social movement organisations (SMOs) - e.g. why SMOS adopt litigation rather than protest or political lobbying as a strategy. Other variables or explanatory frameworks it is commonly found alongside include framing, resource mobilization and grievance. It can also be employed as a dependent variable.\nLegal opportunity theory has been applied to a wide range of policy areas which have seen legal mobilization by social movements, including the environmental, animal rights, women's, LGBT, labor, civil rights, human rights, and disability movements.\n"}
{"id": "12916916", "url": "https://en.wikipedia.org/wiki?curid=12916916", "title": "Moral rationalism", "text": "Moral rationalism\n\nMoral rationalism, also called ethical rationalism, is a view in meta-ethics (specifically the epistemology of ethics) according to which moral principles are knowable \"a priori\", by reason alone. Some prominent figures in the history of philosophy who have defended moral rationalism are Plato and Immanuel Kant. Perhaps the most prominent figure in the history of philosophy who has rejected moral rationalism is David Hume. Recent philosophers who have defended moral rationalism include Richard Hare, Christine Korsgaard, Alan Gewirth, and Michael Smith.\n\nMoral rationalism is similar to the rationalist version of ethical intuitionism; however, they are distinct views. Moral rationalism is neutral on whether basic moral beliefs are known via inference or not. A moral rationalist who believes that some moral beliefs are justified non-inferentially is a rationalist ethical intuitionist. So, rationalist ethical intuitionism implies moral rationalism, but the reverse does not hold.\n\nThere are two main forms of moral rationalism, associated with two major forms of reasoning. If moral reasoning is based on theoretical reason, and is hence analogous to discovering empirical or scientific truths about the world, a purely emotionless being could arrive at the truths of reason. Such a being wouldn't necessarily be motivated to act morally. Beings who are motivated to act morally can also arrive at moral truths, but needn't rely upon their emotions to do so.\n\nMany moral rationalists believe that moral reasoning is based on practical reason, which involves choices about what to do or intend to do, including how to achieve one's goals and what goals one should have in the first place. In this view, moral reasoning always involves emotional states and hence be intrinsically motivating. Immanuel Kant expressed this view when he said that immoral actions do not involve a contradiction in belief, but a contradiction in the will, that is, in one's commitment to a principle which one intends to motivate actions. Christine Korsgaard's elaboration of Kantian reasoning tries to show that if ethics is actually based on practical reasoning, this shows that it can be objective and universal, without having to appeal to questionable metaphysical assumptions.\n\nMoral sense theorists (or sentimentalists), such as David Hume, are the key opponents of moral rationalism. In Book 3 of \"A Treatise of Human Nature\" and in \"An Enquiry Concerning the Principles of Morals\" (EPM), Hume argues (among other things) that reason and emotions (or the \"passions\" as he often calls them) are quite distinct faculties and that the foundations of morality lie in sentiment, not reason. Hume takes it as a fact about human psychology and morality that moral judgments have an essentially emotional, sentimental, or otherwise non-rational or cognitive character to them. According to Hume, \"...morality is determined by sentiment. It defines virtue to be whatever mental action or quality gives to a spectator the pleasing sentiment of approbation; and vice the contrary\" (EPM, Appendix 1, ¶10).\n\n"}
{"id": "48243754", "url": "https://en.wikipedia.org/wiki?curid=48243754", "title": "Negative consequentialism", "text": "Negative consequentialism\n\nNegative consequentialism is a version of the ethical theory consequentialism, which is \"one of the major theories of normative ethics.\" Like other versions of consequentialism, negative consequentialism holds that moral right and wrong depend only on the value of outcomes. That is, for negative and other versions of consequentialism, questions such as \"what should I do?\" and \"what kind of person should I be?\" are answered only based on consequences. Negative consequentialism differs from other versions of consequentialism by giving greater weight in moral deliberations to what is bad (e.g. suffering or injustice) than what is good (e.g. happiness or justice).\n\nA specific type of consequentialism is utilitarianism, which says that the consequences that matter are those that affect well-being. Consequentialism is broader than utilitarianism in that consequentialism can say that the value of outcomes depend on other things than well-being; for example, justice, fairness, and equality. Negative utilitarianism is thus a form of negative consequentialism. Much more has been written explicitly about negative utilitarianism than directly about negative consequentialism, although since negative utilitarianism is a form of negative consequentialism, everything that has been written about negative utilitarianism is by definition about a specific (utilitarian) version of negative consequentialism. Similarly to how there are many variations of consequentialism and negative utilitarianism, there are many versions of negative consequentialism, for example negative prioritarianism and negative consequentialist egalitarianism.\n\nG. E. Moore's ethics can be said to be a negative consequentialism (more precisely, a consequentialism with a negative utilitarian component), because he has been labeled a consequentialist, and he said that \"consciousness of intense pain is, by itself, a great evil\" whereas \"the mere consciousness of pleasure, however intense, does not, \"by itself\", appear to be a \"great\" good, even if it has some slight intrinsic value. In short, pain (if we understand by this expression, the consciousness of pain) appears to be a far worse evil than pleasure is a good.\" Moore wrote in the first half of the 20th century before any of the terms 'consequentialism,' 'negative utilitarianism' or 'negative consequentialism' were coined, and he did not use the term 'negative consequentialism' himself. Similarly to Moore, Ingemar Hedenius defended a consequentialism that could be called negative (or could be said to have a negative utilitarian component) because he assigned more importance to suffering than to happiness. Hedenius saw the worst in life, such as infernalistic suffering, as so evil that calculations of happiness versus suffering becomes unnecessary; he did not see that such evil could be counterbalanced by any good, such as happiness.\n\nPhilosophy professor Clark Wolf defends \"negative consequentialism as a component of a larger theory of justice.\" Walter Sinnott-Armstrong interprets Bernard Gert's moral system as a \"sophisticated form of negative objective universal public rule consequentialism.\" Jamie Mayerfeld argues for a strong duty to relieve suffering, which is consequentialist in form. He says that \"suffering is more bad than happiness is good,\" and that \"the lifelong bliss of many people, no matter how many, cannot justify our allowing the lifelong torture of one.\"\n\n"}
{"id": "470886", "url": "https://en.wikipedia.org/wiki?curid=470886", "title": "Object permanence", "text": "Object permanence\n\nObject permanence is the understanding that objects continue to exist even when they cannot be perceived (seen, heard, touched, smelled or sensed in any way). This is a fundamental concept studied in the field of developmental psychology, the subfield of psychology that addresses the development of young children's social and mental capacities. There is not yet scientific consensus on when the understanding of object permanence emerges in human development.\n\nJean Piaget, the Swiss psychologist who first studied object permanence in infants, argued that it is one of an infant's most important accomplishments, as, without this concept, objects would have no separate, permanent existence. In Piaget's theory of cognitive development, infants develop this understanding by the end of the \"sensorimotor stage,\" which lasts from birth to about two years of age. Piaget thought that an infant's perception and understanding of the world depended on their motor development, which was required for the infant to link visual, tactile and motor representations of objects. According to this view, it is through touching and handling objects that infants develop object permanence.\n\nDevelopmental psychologist Jean Piaget conducted experiments that collected behavioral tests on infants. Piaget studied object permanence by observing infants' reactions when a favorite object or toy was presented and then was covered with a blanket or removed from sight. Object permanence is considered to be one of the earliest methods for evaluating working memory. An infant that has started to develop object permanence might reach for the toy or try to grab the blanket off the toy. Infants that have not yet developed this might appear confused. Piaget interpreted these behavioral signs as evidence of a belief that the object had ceased to exist. Reactions of most infants that had already started developing object permanence were of frustration because they knew it existed, but didn't know where it was. However, the reaction of infants that had not yet started developing object permanence was more oblivious. If an infant searched for the object, it was assumed that they believed it continued to exist.\n\nPiaget concluded that some infants are too young to understand object permanence, which explains why they do not cry when their parents are gone (\"out of sight, out of mind\"). A lack of object permanence can lead to A-not-B errors, where children reach for a thing at a place where it should not be. Older infants are less likely to make the A-not-B error because they are able to understand the concept of object permanence more than younger infants. However, researchers have found that A-not-B errors do not always show up consistently. They concluded that this type of error might be due to a failure in memory or the fact that infants usually tend to repeat a previous motor behavior.\n\nIn Piaget's formulation, there are six stages of object permanence. These are:\n\n\nIn more recent years, the original Piagetian object permanence account has been challenged by a series of infant studies suggesting that much younger infants do have a clear sense that objects exist even when out of sight. Bower showed object permanence in 3-month-olds. This goes against Piaget's coordination of secondary circular reactions stage because infants aren't supposed to understand that a completely hidden object still exists until they are eight to twelve months old. The two studies below demonstrate this idea.\n\nThe first study showed infants a toy car that moved down an inclined track, disappeared behind a screen, and then reemerged at the other end, still on the track. The researchers created a \"possible event\" where a toy mouse was placed behind the tracks but was hidden by the screen as the car rolled by. Then, researchers created an \"impossible event.\" In this situation, the toy mouse was placed on the tracks but was secretly removed after the screen was lowered so that the car seemed to go through the mouse. Also in the 1991 study the researchers used an experiment involving two differently sized carrots (one tall and one short) in order to test the infants response when the carrots would be moved behind a short wall. The wall was specifically designed to make the short carrot disappear, as well as tested the infants for habituation patterns on the disappearance of the tall carrot behind the wall (impossible event). Infants as young as 3½ months displayed greater stimulation toward the impossible event and much more habituation at the possible event. This indicated that they may have been surprised by the impossible event, which suggested they remembered not only that the toy mouse still existed (object permanence) but also its location. The same was true of the tall carrot in the second experiment. This research suggests that infants understand more about objects earlier than Piaget proposed.\n\nThere are primarily four challenges to Piaget's framework:\n\n\nOne criticism of Piaget's theory is that culture and education exert stronger influences on a child's development than Piaget maintained. These factors depend on how much practice their culture provides in developmental processes, such as conversational skills.\n\nExperiments in non-human primates suggest that monkeys can track the displacement of invisible targets, that invisible displacement is represented in the prefrontal cortex, and that development of the frontal cortex is linked to the acquisition of object permanence. Various evidence from human infants is consistent with this. For example, formation of synapses in the frontal cortex peaks during human infancy, and recent experiments using near infrared spectroscopy to gather neuroimaging data from infants suggests that activity in the frontal cortex is associated with successful completion of object permanence tasks.\n\nHowever, many other types of animals have been shown to have the ability for object permanence. These include dogs, cats, and a few species of birds such as the carrion crow, Eurasian jays and food-storing magpies. Dogs are able to reach a level of object permanence that allows them to find food after it has been hidden beneath one of two cups and rotated 90°. Similarly, cats are able to understand object permanence but not to the same extent that dogs can. Cats fail to understand that if they see something go into an apparatus in one direction that it will still be there if the cat tries to enter from another direction. However, while cats did not seem to be quite as good at this ‘invisible displacement test’ as dogs are, it’s hard to say whether their poorer performance is a true reflection of their abilities or just due to the way in which they’ve been tested. A longitudinal study found that carrion crows' ability developed gradually, albeit with slight changes in the order of mastery compared to human infants. There was only one task, task 15, that the crows were not able to master. The crows showed perseverative searches at a previously rewarded location (the so-called ‘A-not-B error’). They mastered visible rotational displacements consistently, but failed at more complex invisible rotational displacements. Another study tested the comparison of how long it took food-storing magpies to develop the object permanence necessary for them to be able to live independently. The research suggests that these magpies followed a very similar pattern as human infants while they were developing.\n\nOne of the areas of focus on object permanence has been how physical disabilities (blindness, cerebral palsy and deafness) and intellectual disabilities (Down syndrome, etc.) affect the development of object permanence. In a study that was performed in 1975-76, the results showed that the only area where children with intellectual disabilities performed more weakly than children without disabilities was along the lines of social interaction. Other tasks, such as imitation and causality tasks, were performed more weakly by the children without disabilities. However, object permanence was still acquired similarly because it was not related to social interaction.\n\nSome psychologists believe that 'while object permanence alone may not predict communicative achievement, object permanence along with several other sensorimotor milestones, plays a critical role in, and interacts with, the communicative development of children with severe disabilities'. This was observed in 2006, in a study recognizing where the full mastery of object permanence is one of the milestones that ties into a child's ability to engage in mental representation. Along with the relationship with language acquisition, object permanence is also related to the achievement of self-recognition. This same study also focused specifically on the effects that Down syndrome has on object permanence. They found that the reason why the children that participated were so successful in acquiring object permanence, was due to their social strength in imitation. Along with imitation being a potential factor in the success, another factor that could impact children with Down syndrome could also be the willingness of the child to cooperate.\n\nOther, more recent studies suggest that the idea of object permanence may not be an innate function of young children. While, in reference to Piaget's theory, it has been established that young children develop object permanence as they age, the question arises: does this occur because of a particular perception that already existed within the minds of these young children? Is object permanence really an inbred response to the neural pathways developing in young minds? Studies suggest that a multitude of variables may be responsible for the development of object permanence rather than a natural talent of infants. Evidence suggests that infants use a variety of cues while studying an object and their perception of the object's permanence can be tested without physically hiding the object. Rather, the object is occluded, slightly obstructed, from the infants view and they are left only other visual cues, such as examining the object from different trajectories. It was also found that the longer an infant focuses on an object may be due to detected discontinuities in their visual field, or the flow of events, with which the infant has become familiar.\n\n"}
{"id": "128027", "url": "https://en.wikipedia.org/wiki?curid=128027", "title": "Operant conditioning", "text": "Operant conditioning\n\nOperant conditioning (also called instrumental conditioning) is a learning process through which the strength of a behavior is modified by reinforcement or punishment. It is also a procedure that is used to bring about such learning.\n\nAlthough operant and classical conditioning both involve behaviors controlled by environmental stimuli, they differ in nature. In operant conditioning, stimuli present when a behavior is rewarded or punished come to control that behavior. For example, a child may learn to open a box to get the candy inside, or learn to avoid touching a hot stove; in operant terms, the box and the stove are \"discriminative stimuli\". Operant behavior is said to be \"voluntary\": for example, the child may face a choice between opening the box and petting a puppy.\n\nIn contrast, classical conditioning involves involuntary behavior based on the pairing of stimuli with biologically significant events. For example, sight of candy may cause a child to salivate, or the sound of a door slam may signal an angry parent, causing a child to tremble. Salivation and trembling are not operants; they are not reinforced by their consequences, and they are not voluntarily \"chosen\".\n\nThe study of animal learning in the 20th century was dominated by the analysis of these two sorts of learning, and they are still at the core of behavior analysis.\n\nOperant conditioning, sometimes called \"instrumental learning\", was first extensively studied by Edward L. Thorndike (1874–1949), who observed the behavior of cats trying to escape from home-made puzzle boxes. A cat could escape from the box by a simple response such as pulling a cord or pushing a pole, but when first constrained, the cats took a long time to get out. With repeated trials ineffective responses occurred less frequently and successful responses occurred more frequently, so the cats escaped more and more quickly. Thorndike generalized this finding in his law of effect, which states that behaviors followed by satisfying consequences tend to be repeated and those that produce unpleasant consequences are less likely to be repeated. In short, some consequences \"strengthen\" behavior and some consequences \"weaken\" behavior. By plotting escape time against trial number Thorndike produced the first known animal learning curves through this procedure.\n\nHumans appear to learn many simple behaviors through the sort of process studied by Thorndike, now called operant conditioning. That is, responses are retained when they lead to a successful outcome and discarded when they do not, or when they produce aversive effects. This usually happens without being planned by any \"teacher\", but operant conditioning has been used by parents in teaching their children for thousands of years.\n\nB.F. Skinner (1904–1990) is referred to as the father of operant conditioning, and his work is frequently cited in connection with this topic. His 1938 book \"The Behavior of Organisms: An Experimental Analysis\", initiated his lifelong study of operant conditioning and its application to human and animal behavior. Following the ideas of Ernst Mach, Skinner rejected Thorndike's reference to unobservable mental states such as satisfaction, building his analysis on observable behavior and its equally observable consequences.\n\nSkinner believed that classical conditioning was too simplistic to be used to describe something as complex as human behavior. Operant conditioning, in his opinion, better described human behavior as it examined causes and effects of intentional behavior.\n\nTo implement his empirical approach, Skinner invented the operant conditioning chamber, or \"Skinner Box\", in which subjects such as pigeons and rats were isolated and could be exposed to carefully controlled stimuli. Unlike Thorndike's puzzle box, this arrangement allowed the subject to make one or two simple, repeatable responses, and the rate of such responses became Skinner's primary behavioral measure. Another invention, the cumulative recorder, produced a graphical record from which these response rates could be estimated. These records were the primary data that Skinner and his colleagues used to explore the effects on response rate of various reinforcement schedules. A reinforcement schedule may be defined as \"any procedure that delivers reinforcement to an organism according to some well-defined rule\". The effects of schedules became, in turn, the basic findings from which Skinner developed his account of operant conditioning. He also drew on many less formal observations of human and animal behavior.\n\nMany of Skinner's writings are devoted to the application of operant conditioning to human behavior. In 1948 he published \"Walden Two\", a fictional account of a peaceful, happy, productive community organized around his conditioning principles. In 1957, Skinner published \"Verbal Behavior\", which extended the principles of operant conditioning to language, a form of human behavior that had previously been analyzed quite differently by linguists and others. Skinner defined new functional relationships such as \"mands\" and \"tacts\" to capture some essentials of language, but he introduced no new principles, treating verbal behavior like any other behavior controlled by its consequences, which included the reactions of the speaker's audience.\n\nOperant behavior is said to be \"emitted\"; that is, initially it is not elicited by any particular stimulus. Thus one may ask why it happens in the first place. The answer to this question is like Darwin's answer to the question of the origin of a \"new\" bodily structure, namely, variation and selection. Similarly, the behavior of an individual varies from moment to moment, in such aspects as the specific motions involved, the amount of force applied, or the timing of the response. Variations that lead to reinforcement are strengthened, and if reinforcement is consistent, the behavior tends to remain stable. However, behavioral variability can itself be altered through the manipulation of certain variables.\n\nReinforcement and punishment are the core tools through which operant behavior is modified. These terms are defined by their effect on behavior. Either may be positive or negative. \nAnother procedure is called \"extinction\".\nThere are a total of five consequences. \n\nIt is important to note that actors (e.g. a rat) are not spoken of as being reinforced, punished, or extinguished; it is the \"actions\" that are reinforced, punished, or extinguished. Reinforcement, punishment, and extinction are not terms whose use is restricted to the laboratory. Naturally-occurring consequences can also reinforce, punish, or extinguish behavior and are not always planned or delivered on purpose.\n\nSchedules of reinforcement are rules that control the delivery of reinforcement. The rules specify either the time that reinforcement is to be made available, or the number of responses to be made, or both. Many rules are possible, but the following are the most basic and commonly used\n\n\nThe effectiveness of reinforcement and punishment can be changed. \n\nShaping is a conditioning method much used in animal training and in teaching nonverbal humans. It depends on operant variability and reinforcement, as described above. The trainer starts by identifying the desired final (or \"target\") behavior. Next, the trainer chooses a behavior that the animal or person already emits with some probability. The form of this behavior is then gradually changed across successive trials by reinforcing behaviors that approximate the target behavior more and more closely. When the target behavior is finally emitted, it may be strengthened and maintained by the use of a schedule of reinforcement.\n\nNoncontingent reinforcement is the delivery of reinforcing stimuli regardless of the organism's behavior. Noncontingent reinforcement may be used in an attempt to reduce an undesired target behavior by reinforcing multiple alternative responses while extinguishing the target response. As no measured behavior is identified as being strengthened, there is controversy surrounding the use of the term noncontingent \"reinforcement\".\n\nThough initially operant behavior is emitted without an identified reference to a particular stimulus, during operant conditioning operants come under the control of stimuli that are present when behavior is reinforced. Such stimuli are called \"discriminative stimuli.\" A so-called \"three-term contingency\" is the result. That is, discriminative stimuli set the occasion for responses that produce reward or punishment. Example: a rat may be trained to press a lever only when a light comes on; a dog rushes to the kitchen when it hears the rattle of his/her food bag; a child reaches for candy when s/he sees it on a table.\n\nMost behavior is under stimulus control. Several aspects of this may be distinguished: \n\nMost behavior cannot easily be described in terms of individual responses reinforced one by one. The scope of operant analysis is expanded through the idea of behavioral chains, which are sequences of responses bound together by the three-term contingencies defined above. Chaining is based on the fact, experimentally demonstrated, that a discriminative stimulus not only sets the occasion for subsequent behavior, but it can also reinforce a behavior that precedes it. That is, a discriminative stimulus is also a \"conditioned reinforcer\". For example, the light that sets the occasion for lever pressing may be used to reinforce \"turning around\" in the presence of a noise. This results in the sequence \"noise – turn-around – light – press lever – food\". Much longer chains can be built by adding more stimuli and responses.\n\nIn escape learning, a behavior terminates an (aversive) stimulus. For example, shielding one's eyes from sunlight terminates the (aversive) stimulation of bright light in one's eyes. (This is an example of negative reinforcement, defined above.) Behavior that is maintained by preventing a stimulus is called \"avoidance,\" as, for example, putting on sun glasses before going outdoors. Avoidance behavior raises the so-called \"avoidance paradox\", for, it may be asked, how can the non-occurrence of a stimulus serve as a reinforcer? This question is addressed by several theories of avoidance (see below).\n\nTwo kinds of experimental settings are commonly used: discriminated and free-operant avoidance learning.\n\nA discriminated avoidance experiment involves a series of trials in which a neutral stimulus such as a light is followed by an aversive stimulus such as a shock. After the neutral stimulus appears an operant response such as a lever press prevents or terminate the aversive stimulus. In early trials, the subject does not make the response until the aversive stimulus has come on, so these early trials are called \"escape\" trials. As learning progresses, the subject begins to respond during the neutral stimulus and thus prevents the aversive stimulus from occurring. Such trials are called \"avoidance trials.\" This experiment is said to involve classical conditioning because a neutral CS is paired with the aversive US; this idea underlies the two-factor theory of avoidance learning described below.\n\nIn free-operant avoidance a subject periodically receives an aversive stimulus (often an electric shock) unless an operant response is made; the response delays the onset of the shock. In this situation, unlike discriminated avoidance, no prior stimulus signals the shock. Two crucial time intervals determine the rate of avoidance learning. This first is the S-S (shock-shock) interval. This is time between successive shocks in the absence of a response. The second interval is the R-S (response-shock) interval. This specifies the time by which an operant response delays the onset of the next shock. Note that each time the subject performs the operant response, the R-S interval without shock begins anew.\n\nThis theory was originally proposed in order to explain discriminated avoidance learning, in which an organism learns to avoid an aversive stimulus by escaping from a signal for that stimulus. Two processes are involved: classical conditioning of the signal followed by operant conditioning of the escape response:\n\na) \"Classical conditioning of fear.\" Initially the organism experiences the pairing of a CS (conditioned stimulus) with an aversive US (unconditioned stimulus). The theory assumes that this pairing creates an association between the CS and the US through classical conditioning and, because of the aversive nature of the US, the CS comes to elicit a conditioned emotional reaction (CER) – \"fear.\" b) \"Reinforcement of the operant response by fear-reduction.\" As a result of the first process, the CS now signals fear; this unpleasant emotional reaction serves to motivate operant responses, and responses that terminate the CS are reinforced by fear termination. Note that the theory does not say that the organism \"avoids\" the US in the sense of anticipating it, but rather that the organism \"escapes\" an aversive internal state that is caused by the CS.\nSeveral experimental findings seem to run counter to two-factor theory. For example, avoidance behavior often extinguishes very slowly even when the initial CS-US pairing never occurs again, so the fear response might be expected to extinguish (see Classical conditioning). Further, animals that have learned to avoid often show little evidence of fear, suggesting that escape from fear is not necessary to maintain avoidance behavior.\n\nSome theorists suggest that avoidance behavior may simply be a special case of operant behavior maintained by its consequences. In this view the idea of \"consequences\" is expanded to include sensitivity to a pattern of events. Thus, in avoidance, the consequence of a response is a reduction in the rate of aversive stimulation. Indeed, experimental evidence suggests that a \"missed shock\" is detected as a stimulus, and can act as a reinforcer. Cognitive theories of avoidance take this idea a step farther. For example, a rat comes to \"expect\" shock if it fails to press a lever and to \"expect no shock\" if it presses it, and avoidance behavior is strengthened if these expectancies are confirmed.\n\nOperant hoarding refers to the observation that rats reinforced in a certain way may allow food pellets to accumulate in a food tray instead of retrieving those pellets. In this procedure, retrieval of the pellets always instituted a one-minute period of extinction during which no additional food pellets were available but those that had been accumulated earlier could be consumed. This finding appears to contradict the usual finding that rats behave impulsively in situations in which there is a choice between a smaller food object right away and a larger food object after some delay. See schedules of reinforcement.\n\nThe first scientific studies identifying neurons that responded in ways that suggested they encode for conditioned stimuli came from work by Mahlon deLong and by R.T. Richardson. They showed that nucleus basalis neurons, which release acetylcholine broadly throughout the cerebral cortex, are activated shortly after a conditioned stimulus, or after a primary reward if no conditioned stimulus exists. These neurons are equally active for positive and negative reinforcers, and have been shown to be related to neuroplasticity in many cortical regions. Evidence also exists that dopamine is activated at similar times. There is considerable evidence that dopamine participates in both reinforcement and aversive learning. Dopamine pathways project much more densely onto frontal cortex regions. Cholinergic projections, in contrast, are dense even in the posterior cortical regions like the primary visual cortex. A study of patients with Parkinson's disease, a condition attributed to the insufficient action of dopamine, further illustrates the role of dopamine in positive reinforcement. It showed that while off their medication, patients learned more readily with aversive consequences than with positive reinforcement. Patients who were on their medication showed the opposite to be the case, positive reinforcement proving to be the more effective form of learning when dopamine activity is high.\n\nA neurochemical process involving dopamine has been suggested to underlie reinforcement. When an organism experiences a reinforcing stimulus, dopamine pathways in the brain are activated. This network of pathways \"releases a short pulse of dopamine onto many dendrites, thus broadcasting a global reinforcement signal to postsynaptic neurons.\" This allows recently activated synapses to increase their sensitivity to efferent (conducting outward) signals, thus increasing the probability of occurrence for the recent responses that preceded the reinforcement. These responses are, statistically, the most likely to have been the behavior responsible for successfully achieving reinforcement. But when the application of reinforcement is either less immediate or less contingent (less consistent), the ability of dopamine to act upon the appropriate synapses is reduced.\n\nA number of observations seem to show that operant behavior can be established without reinforcement in the sense defined above. Most cited is the phenomenon of autoshaping (sometimes called \"sign tracking\"), in which a stimulus is repeatedly followed by reinforcement, and in consequence the animal begins to respond to the stimulus. For example, a response key is lighted and then food is presented. When this is repeated a few times a pigeon subject begins to peck the key even though food comes whether the bird pecks or not. Similarly, rats begin to handle small objects, such as a lever, when food is presented nearby. Strikingly, pigeons and rats persist in this behavior even when pecking the key or pressing the lever leads to less food (omission training). Another apparent operant behavior that appears without reinforcement is contrafreeloading.\n\nThese observations and others appear to contradict the law of effect, and they have prompted some researchers to propose new conceptualizations of operant reinforcement (e.g.) A more general view is that autoshaping is an instance of classical conditioning; the autoshaping procedure has, in fact, become one of the most common ways to measure classical conditioning. In this view, many behaviors can be influenced by both classical contingencies (stimulus-response) and operant contingencies (response-reinforcement), and the experimenter's task is to work out how these interact.\n\nThe example of someone having a positive experience with a drug is easy to see how drug dependence and the law of effect works. The tolerance for a drug goes down as one continues to use it after having a positive experience with a certain amount the first time. It will take more and more to get that same feeling. This is when the controlled substance in an experiment would have to be modified and the experiment would really begin. The law of work for psychologist B. F. Skinner almost half a century later on the principles of operant conditioning, \"a learning process by which the effect, or consequence, of a response influences the future rate of production of that response.\n\nReinforcement and punishment are ubiquitous in human social interactions, and a great many applications of operant principles have been suggested and implemented. Following are a few examples.\n\nApplied behavior analysis is the discipline initiated by B. F. Skinner that applies the principles of conditioning to the modification of socially significant human behavior. It uses the basic concepts of conditioning theory, including conditioned stimulus (S), discriminative stimulus (S), response (R), and reinforcing stimulus (S or S for reinforcers, sometimes S for aversive stimuli). A conditioned stimulus controls behaviors developed through respondent (classical) conditioning, such as emotional reactions. The other three terms combine to form Skinner's \"three-term contingency\": a discriminative stimulus sets the occasion for responses that lead to reinforcement. Researchers have found the following protocol to be effective when they use the tools of operant conditioning to modify human behavior:\n\nPractitioners of applied behavior analysis (ABA) bring these procedures, and many variations and developments of them, to bear on a variety of socially significant behaviors and issues. In many cases, practitioners use operant techniques to develop constructive, socially acceptable behaviors to replace aberrant behaviors. The techniques of ABA have been effectively applied in to such things as early intensive behavioral interventions for children with an autism spectrum disorder (ASD) research on the principles influencing criminal behavior, HIV prevention, conservation of natural resources, education, gerontology, health and exercise, industrial safety, language acquisition, littering, medical procedures, parenting, psychotherapy, seatbelt use, severe mental disorders, sports, substance abuse, phobias, pediatric feeding disorders, and zoo management and care of animals. Some of these applications are among those described below.\n\nPositive and negative reinforcement play central roles in the development and maintenance of addiction and drug dependence. An addictive drug is intrinsically rewarding; that is, it functions as a primary positive reinforcer of drug use. The brain's reward system assigns it incentive salience (i.e., it is \"wanted\" or \"desired\"), so as an addiction develops, deprivation of the drug leads to craving. In addition, stimuli associated with drug use – e.g., the sight of a syringe, and the location of use – become associated with the intense reinforcement induced by the drug. These previously neutral stimuli acquire several properties: their appearance can induce craving, and they can become conditioned positive reinforcers of continued use. Thus, if an addicted individual encounters one of these drug cues, a craving for the associated drug may reappear. For example, anti-drug agencies previously used posters with images of drug paraphernalia as an attempt to show the dangers of drug use. However, such posters are no longer used because of the effects of incentive salience in causing relapse upon sight of the stimuli illustrated in the posters.\n\nIn drug dependent individuals, negative reinforcement occurs when a drug is self-administered in order to alleviate or \"escape\" the symptoms of physical dependence (e.g., tremors and sweating) and/or psychological dependence (e.g., anhedonia, restlessness, irritability, and anxiety) that arise during the state of drug withdrawal.\n\nAnimal trainers and pet owners were applying the principles and practices of operant conditioning long before these ideas were named and studied, and animal training still provides one of the clearest and most convincing examples of operant control. Of the concepts and procedures described in this article, a few of the most salient are the following: \n(a) availability of primary reinforcement (e.g. a bag of dog yummies); \n(b) the use of secondary reinforcement, (e.g. sounding a clicker immediately after a desired response, then giving yummy); \n(c) contingency, assuring that reinforcement (e.g. the clicker) follows the desired behavior and not something else; \n(d) shaping, as in gradually getting a dog to jump higher and higher; \n(e) intermittent reinforcement, as in gradually reducing the frequency of reinforcement to induce persistent behavior without satiation; \n(f) chaining, where a complex behavior is gradually constructed from smaller units.\n\nExample of animal training from Seaworld related on Operant conditioning \nAnimal training has effects on positive reinforcement and negative reinforcement. Schedules of reinforcements may play a big role on the animal training case.\n\nProviding positive reinforcement for appropriate child behaviors is a major focus of parent management training. Typically, parents learn to reward appropriate behavior through social rewards (such as praise, smiles, and hugs) as well as concrete rewards (such as stickers or points towards a larger reward as part of an incentive system created collaboratively with the child). In addition, parents learn to select simple behaviors as an initial focus and reward each of the small steps that their child achieves towards reaching a larger goal (this concept is called \"successive approximations\").\n\nBoth psychologists and economists have become interested in applying operant concepts and findings to the behavior of humans in the marketplace. An example \nis the analysis of consumer demand, as indexed by the amount of a commodity that is purchased. In economics, the degree to which price influences consumption is called \"the price elasticity of demand.\" Certain commodities are more elastic than others; for example, a change in price of certain foods may have a large effect on the amount bought, while gasoline and other essentials may be less affected by price changes. In terms of operant analysis, such effects may be interpreted in terms of motivations of consumers and the relative value of the commodities as reinforcers.\n\nAs stated earlier in this article, a variable ratio schedule yields reinforcement after the emission of an unpredictable number of responses. This schedule typically generates rapid, persistent responding. Slot machines pay off on a variable ratio schedule, and they produce just this sort of persistent lever-pulling behavior in gamblers. The variable ratio payoff from slot machines and other forms of gambling has often been cited as a factor underlying gambling addiction.\n\nNudge theory (or nudge) is a concept in behavioural science, political theory and economics which argues that indirect suggestions to try to achieve non-forced compliance can influence the motives, incentives and decision making of groups and individuals, at least as effectively – if not more effectively – than direct instruction, legislation, or enforcement.\n\nThe concept of praise as a means of behavioral reinforcement is rooted in B.F. Skinner's model of operant conditioning. Through this lens, praise has been viewed as a means of positive reinforcement, wherein an observed behavior is made more likely to occur by contingently praising said behavior. Hundreds of studies have demonstrated the effectiveness of praise in promoting positive behaviors, notably in the study of teacher and parent use of praise on child in promoting improved behavior and academic performance, but also in the study of work performance. Praise has also been demonstrated to reinforce positive behaviors in non-praised adjacent individuals (such as a classmate of the praise recipient) through vicarious reinforcement. Praise may be more or less effective in changing behavior depending on its form, content and delivery. In order for praise to effect positive behavior change, it must be contingent on the positive behavior (i.e., only administered after the targeted behavior is enacted), must specify the particulars of the behavior that is to be reinforced, and must be delivered sincerely and credibly.\n\nAcknowledging the effect of praise as a positive reinforcement strategy, numerous behavioral and cognitive behavioral interventions have incorporated the use of praise in their protocols. The strategic use of praise is recognized as an evidence-based practice in both classroom management and parenting training interventions, though praise is often subsumed in intervention research into a larger category of positive reinforcement, which includes strategies such as strategic attention and behavioral rewards.\n\nSeveral studies have been done on the effect cognitive-behavioral therapy and operant-behavioral therapy have on different medical conditions. When patients developed cognitive and behavioral techniques that changed their behaviors, attitudes, and emotions; their pain severity decreased. The results of these studies showed an influence of cognitions on pain perception and impact presented explained the general efficacy of Cognitive-Behavioral therapy (CBT) and Operant-Behavioral therapy (OBT).\n\nBraiker identified the following ways that manipulators control their victims:\n\nTraumatic bonding occurs as the result of ongoing cycles of abuse in which the intermittent reinforcement of reward and punishment creates powerful emotional bonds that are resistant to change.\n\nThe other source indicated that \n\n'The necessary conditions for traumatic bonding are that one person must dominate the other and that the level of abuse chronically spikes and then subsides. The relationship is characterized by periods of permissive, compassionate, and even affectionate behavior from the dominant person, punctuated by intermittent episodes of intense abuse. To maintain the upper hand, the victimizer manipulates the behavior of the victim and limits the victim's options so as to perpetuate the power imbalance. Any threat to the balance of dominance and submission may be met with an escalating cycle of punishment ranging from seething intimidation to intensely violent outbursts. The victimizer also isolates the victim from other sources of support, which reduces the likelihood of detection and intervention, impairs the victim's ability to receive countervailing self-referent feedback, and strengthens the sense of unilateral dependency...The traumatic effects of these abusive relationships may include the impairment of the victim's capacity for accurate self-appraisal, leading to a sense of personal inadequacy and a subordinate sense of dependence upon the dominating person. Victims also may encounter a variety of unpleasant social and legal consequences of their emotional and behavioral affiliation with someone who perpetrated aggressive acts, even if they themselves were the recipients of the aggression. '.\n\nHuman beings have an innate resistance to killing and are reluctant to act in a direct, aggressive way towards members of their own species, even to save life.  This resistance to killing has caused infantry to be remarkably inefficient throughout the history of military warfare.\n\nThis phenomenon was not understood until S.L.A. Marshall (Brigadier General and military historian) undertook interview studies of WWII infantry immediately following combat engagement. Marshall's well-known and controversial book, Men Against Fire, revealed that only 15% of soldiers fired their rifles with the purpose of killing in combat. Following acceptance of Marshall's research by the US Army in 1946, the Human Resources Research Office of the US Army began implementing new training protocols which resemble operant conditioning methods.  Subsequent applications of such methods increased the percentage of soldiers able to kill to around 50% in Korea and over 90% in Vietnam. Revolutions in training included replacing traditional pop-up firing ranges with three-dimensional, man-shaped, pop-up targets which collapsed when hit.  This provided immediate feedback and acted as positive reinforcement for a soldier's behavior. Other improvements to military training methods have included the timed firing course; more realistic training; high repetitions; praise from superiors; marksmanship rewards; and group recognition. Negative reinforcement includes peer accountability or the requirement to retake courses.  Modern military training conditions mid-brain response to combat pressure by closely simulating actual combat, using mainly Pavlovian Classical Conditioning and Skinnerian operant Conditioning (both forms of Behaviorism).Modern marksmanship training is such an excellent example of behaviorism that it has been used for years in the introductory psychology course taught to all cadets at the US Military Academy at West Point as a classic example of operant conditioning. In the 1980s, during a visit to West Point, B.F. Skinner identified modern military marksmanship training as a near-perfect application of operant conditioning.Lt. Col. Dave Grossman states about operant conditioning and US Military training that:It is entirely possible that no one intentionally sat down to use operant conditioning or behavior modification techniques to train soldiers in this area…But from the standpoint of a psychologist who is also a historian and a career soldier, it has become increasingly obvious to me that this is exactly what has been achieved.In his book, On Killing: The Psychological Cost of Learning to Kill in War and Society, Grossman overviews the main factors influencing individual acts of aggression as:\n\n\nPsychological distancing includes physical distance, dehumanizing the enemy (including through propaganda), and the impersonal use of technology such as night vision, drones, and airstrikes.  Modern conditioning techniques have had parallel effects on law enforcement firing rates.\n\nThe majority of video games are designed around a compulsion loop, adding a type of positive reinforcement through a variable rate schedule to keep the player playing. This can lead to the pathology of video game addiction.\nAs part of a trend in the monetization of video games during the 2010s, some games offered loot boxes as rewards or as items purchasable by real world funds. Boxes contains a random selection of in-game items. The practice has been tied to the same methods that slot machines and other gambling devices dole out rewards, as it follows a variable rate schedule. While the general perception that loot boxes are a form of gambling, the practice is only classified as such in a few countries. However, methods to use those items as virtual currency for online gambling or trading for real world money has created a skin gambling market that is under legal evaluation.\n\nAshforth discussed potentially destructive sides of leadership and identified what he referred to as petty tyrants: leaders who exercise a tyrannical style of management, resulting in a climate of fear in the workplace. Partial or intermittent negative reinforcement can create an effective climate of fear and doubt. When employees get the sense that bullies are tolerated, a climate of fear may be the result.\n\nIndividual differences in sensitivity to reward, punishment, and motivation have been studied under the premises of reinforcement sensitivity theory and have also been applied to workplace performance.\n\nOne of the many reasons proposed for the dramatic costs associated with healthcare is the practice of defensive medicine. Prabhu reviews the article by Cole and discusses how the responses of two groups of neurosurgeons are classic operant behavior. One group practice in a state with restrictions on medical lawsuits and the other group with no restrictions. The group of neurosurgeons were queried anonymously on their practice patterns. The physicians changed their practice in response to a negative feedback (fear from lawsuit) in the group that practiced in a state with no restrictions on medical lawsuits.\n\n"}
{"id": "302645", "url": "https://en.wikipedia.org/wiki?curid=302645", "title": "Originalism", "text": "Originalism\n\nIn the context of United States law, originalism is a concept regarding the interpretation of the Constitution that asserts that all statements in the constitution must be interpreted based on the original understanding of the authors or the people at the time it was ratified. This concept views the Constitution as stable from the time of enactment, and that the meaning of its contents can be changed only by the steps set out in Article Five. This notion stands in contrast to the concept of the living constitution, which asserts that the Constitution is intended to be interpreted based on the context of the current times, even if such interpretation is different from the original interpretations of the document.\n\nThe term originated in the 1980s. Originalism is an umbrella term for interpretative methods that hold to the \"fixation thesis\", the notion that an utterance's semantic content is fixed at the time it is uttered. Originalists seek one of two alternative sources of meaning:\n\nSuch theories share the view that there is an identifiable original intent or original meaning, contemporaneous with the ratification of a constitution or statute, which should govern its subsequent interpretation. The divisions between the theories relate to what exactly that identifiable original intent or original meaning is: the intentions of the authors or the ratifiers, the original meaning of the text, a combination of the two, or the original meaning of the text but not its expected application.\n\nBret Boyce described the origins of the term \"originalist\" as follows: The term \"originalism\" has been most commonly used since the middle 1980s and was apparently coined by Paul Brest in \"The Misconceived Quest for the Original Understanding\". It is often asserted that \"originalism\" is synonymous with \"strict constructionism\".\nBoth theories are associated with textualist and formalist schools of thought, however there are pronounced differences between them. Scalia differentiated the two by pointing out that, unlike an originalist, a strict constructionist would not acknowledge that \"he uses a cane\" means \"he walks with a cane\" (because, strictly speaking, this is not what \"he uses a cane\" means). Scalia averred that he was \"not a strict constructionist, and no-one ought to be\"; he goes further, calling strict constructionism \"a degraded form of textualism that brings the whole philosophy into disrepute\".\n\nOriginalism is a theory of \"interpretation\", not \"construction\". However, this distinction between \"interpretation\" and \"construction\" is controversial and is rejected by many nonoriginalists as artificial. As Scalia said, \"the Constitution, or any text, should be interpreted [n]either strictly [n]or sloppily; it should be interpreted reasonably\"; once originalism has told a Judge what the provision of the Constitution means, they are bound by that meaning—however the business of Judging is not simply to know what the text means (interpretation), but to take the law's necessarily general provisions and apply them to the specifics of a given case or controversy (construction). In many cases, the meaning might be so specific that no discretion is permissible, but in many cases, it is still before the Judge to say what a reasonable interpretation might be. A judge could, therefore, be both an originalist \"and\" a strict constructionist—but he is not one by virtue of being the other.\n\nOriginalism is actually a family of related views. As a movement, originalism can be traced to Robert Bork's \"Neutral Principles and Some First Amendment Problems\", published in the \"Indiana Law Journal\" in January 1971. However, it was not until the 1980s, when conservative jurists began to take seats on the Supreme Court, that the debate really began in earnest. \"Old originalism\" focused primarily on \"intent\", mostly by default. But that line was largely abandoned in the early 1990s; as \"new originalism\" emerged; most adherents subscribed to \"original meaning\" originalism, though there are some intentionalists within new originalism.\n\nThe \"original form of originalism\" is sometimes called intentionalism, or \"original intent\" originalism, and looked for the subjective intent of a law's enactors. One problem with this approach is identifying the relevant \"lawmaker\" whose intent is sought. For instance, the authors of the U.S. Constitution could be the particular Founding Fathers that drafted it, such as those on the Committee of Detail. Or, since the Constitution purports to originate from the People, one could look to the various state ratifying conventions. The intentionalist methodology involves studying the writings of its authors, or the records of the Philadelphia Convention, or debates in the state legislatures, for clues as to their intent.\n\nThere are two kinds of \"intent analysis\", reflecting two meanings of the word \"intent\". The first, a rule of common law construction during the Founding Era, is \"functional\" intent. The second is \"motivational\" intent. To understand the difference, one can use the metaphor of an architect who designs a Gothic church with flying buttresses. The functional intent of flying buttresses is to prevent the weight of the roof from spreading the walls and causing a collapse of the building, which can be inferred from examining the design as a whole. The motivational intent might be to create work for his brother-in-law who is a flying buttress subcontractor. Using original intent analysis of the first kind, we can discern that the language of Article III of the U.S. Constitution was to delegate to Congress the power to allocate original and appellate jurisdictions, and not to remove some jurisdiction, involving a constitutional question, from all courts. That would suggest that the decision was wrong in \"Ex Parte McCardle\".\n\nHowever, a number of problems are inherent in intentionalism, and \"a fortiori\" when that theory is applied to the Constitution. For example, most of the Founders did not leave detailed discussions of what their intent was in 1787, and while a few did, there is no reason to think that they should be dispositive of what the rest thought. Moreover, the discussions of the drafters may have been recorded; however they were not available to the ratifiers in each state. The theory of original intent was challenged in a string of law review articles in the 1980s. Specifically, original intent was seen as lacking good answers to three important questions: whether a diverse group such as the framers even \"had\" a single intent; if they \"did\", whether it could be determined from two centuries' distance; and whether the framers themselves would have supported original intent.\n\nIn response to this, a different strain of originalism, articulated by (among others) Antonin Scalia, Robert Bork, and Randy Barnett, came to the fore. This is dubbed original \"meaning\".\n\nJustice Oliver Wendell Holmes argued that interpreting what was meant by someone who wrote a law was not trying to \"get into his mind\" because the issue was \"not what this man meant, but what those words would mean in the mouth of a normal speaker of English, using them in the circumstances in which they were used.\" This is the essential precept of modern originalism.\n\nThe most robust and widely cited form of originalism, \"original meaning\", emphasizes how the text would have been understood by a reasonable person in the historical period during which the constitution was proposed, ratified, and first implemented. For example, economist Thomas Sowell notes that phrases like \"due process\" and \"freedom of the press\" had a long established meaning in English law, even before they were put into the Constitution of the United States.\" Applying this form involves studying dictionaries and other writings of the time (for example, Blackstone's \"Commentaries on the Laws of England\"; see \"Matters rendered moot by originalism\", \"infra\") to establish what particular terms meant. See \"Methodology\", infra).\n\nJustice Scalia, one of the most forceful modern advocates for originalism, defined himself as belonging to the latter category:\nThough there may be no evidence that the Founding Fathers intended the Constitution to be like a statute, this fact does not matter under Scalia's approach. Adherence to original meaning is explicitly divorced from the intent of the Founders; rather, the reasons for adhering to original meaning derive from other justifications, such as the argument that the understanding of the ratifiers (the people of the several States at the time of the adoption of the Constitution) should be controlling, as well as consequentialist arguments about original meaning's positive effect on rule of law.\n\nPerhaps the clearest example illustrating the importance of the difference between original intent and original meaning is the Twenty-seventh Amendment. The Twenty-seventh Amendment was proposed as part of the Bill of Rights in 1791, but failed to be ratified by the required number of states for two centuries, eventually being ratified in 1992. An original intent inquiry might ask what the framers understood the amendment to mean when it was written, though some would argue that it was the intent of the latter-day ratifiers that is important. An original-meaning inquiry would ask what the plain, public meaning of the text was in 1992 when it was eventually ratified.\n\n\"Semantic-originalism\" is Ronald Dworkin's term for the theory that the original meaning of many statutes implies that those statutes prohibit certain acts widely considered not to be prohibited by the statutes at the time of their passages. This type of originalism contrasts with \"expectations originalism\", which adheres to how the statutes functioned at the times of their passages, without any expectation that they would function in any other particular ways.\n\nJustice Antonin Scalia and other originalists often claim that the death penalty is not \"cruel and unusual punishment\" because at the time of the Eighth Amendment's passage, it was a punishment believed to be neither cruel nor unusual. Dworkin and the semantic-originalists assert, however, that if advances in moral philosophy (presuming that such advances are possible) reveal that the death penalty is in fact \"cruel and unusual\", then the original meaning of the Eighth Amendment implies that the death penalty is unconstitutional. All the same, Justice Scalia purported to follow semantic originalism, although he conceded that Dworkin does not believe Scalia was true to that calling.\n\nFramework Originalism is an approach developed by Jack Balkin, a professor of law at Yale Law School. Framework Originalism, or Living Originalism, is a blend of primarily two constitutional interpretive methods: originalism and Living Constitution. Balkin holds that there is no inherent contradiction between these two, aforementioned, interpretive approaches—when properly understood. Framework Originalists view the Constitution as an \"initial framework for governance that sets politics in motion.\" This \"framework\" must be built-out or filled-out over time, successive generations, by the various legislative and judicial branches. This process is achieved, primarily, through building political institutions, passing legislation, and creating precedents (both judicial and non-judicial). In effect, the process of building out the Constitution on top of the framework of the original meaning is living constitutionalism, the change of and progress of law over time to address particular (current) issues. The authority of the judiciary and of the political branches to engage in constitutional construction comes from their \"joint responsiveness to public opinion\" over long stretches of time, while operating within the basic framework of the original meaning. Balkin claims that through mechanisms of social influence, both judges and the political branches inevitably come to reflect and respond to changing social mores, norms, customs and (public) opinions.\n\nAccording to Framework originalism, interpreters should adhere to the original meaning of the Constitution, but are not necessarily required to follow the original expected application (although they may use it to create doctrines and decide cases). For example, states should extend the equal protection of the laws to all peoples, in cases where it would not originally or normally be applied to. Contemporary interpreters are not bound by how people in 1868 would have applied these words and meanings to issues such as racial segregation or (sexual) discrimination, largely due to the fact the fourteenth amendment is concerned with such issues (as well as the fact that the fourteenth amendment was not proposed or ratified by the founders). When the Constitution uses or applies principles or standards, like \"equal protection\" or \"unreasonable searches and seizures,\" further construction is usually required, by either the judiciary, the executive or legislative branch. Therefore, Balkin claims, (pure, unadulterated) originalism is not sufficient to decide a wide range of cases or controversies. Judges, he posits, will have to \"engage in considerable constitutional construction as well as the elaboration and application of previous constructions.\" For example, originalism (in and of itself), is not sufficient enough to constrain judicial behavior. Constraint itself does not just come from doctrine or canons, it also comes from institutional, political, and cultural sources. These constraints include: multi-member or panel courts (where the balance of power lies with moderate judges); the screening of judges through the federal judicial appointment process; social and cultural influences on the judiciary (which keep judges attuned and attentive to popular opinions and the political will of the people); and prevailing professional legal culture and professional conceptions of the role of the judiciary (which produce social norms or mores). These constraints ensure that judges act as impartial arbiters of the law and to try to behave in a principled manner, as it applies to decision making.\n\nIn \"The Original Meaning of the Recess Appointments Clause\", Michael B. Rappaport described the methodology associated with the \"original meaning\" form of originalism as follows:\n\n\nOriginalism, in all its various forms, is predicated on a specific view of what the Constitution \"is\", a view articulated by Chief Justice John Marshall in \"Marbury v. Madison\":\nOriginalism assumes that \"Marbury\" is correct: the Constitution is the \"operating charter\" granted to government by the people, as per the preamble to the United States Constitution, and its written nature introduces a certain discipline into its interpretation. Originalism further assumes that the need for such a written charter was derived from the perception, on the part of the Framers, of the abuses of power under the (unwritten) British Constitution, under which the Constitution was essentially whatever Parliament decided it should be. In writing out a Constitution which explicitly granted the government certain authorities, and withheld from it others, and in which power was balanced between multiple agencies (the Presidency, two chambers of Congress and the Supreme Court at the national level, and State governments of the United States with similar branches), the intention of the Framers was to restrain government, originalists argue, and the value of such a document is nullified if that document's meaning is not fixed. As one author stated, \"If the constitution can mean anything, then the constitution is reduced to meaninglessness.\"\n\nDissenting in \"Romer v. Evans\", Scalia wrote:\nThis statement summarizes the role for the court envisioned by originalists, that is, that the Court parses what the general law and constitution says of a particular case or controversy, and when questions arise as to the meaning of a given constitutional provision, that provision should be given the meaning it was understood to mean when ratified. Reviewing Steven D Smith's book \"Law's Quandary\", Scalia applied this formulation to some controversial topics routinely brought before the Court:\nIn \"Marbury\", Chief Justice John Marshall established that the Supreme Court could invalidate laws which violated the Constitution (that is, judicial review), which helped establish the Supreme Court as having its own distinct sphere of influence within the federal government. However, this power was itself balanced with the requirement that the Court could only invalidate legislation if it was \"unconstitutional\". Originalists argue that the modern court no longer follows this requirement. They argue that—since \"U.S. v. Darby\", in which Justice Stone (writing for a unanimous Court) ruled that the Tenth Amendment had no legal meaning—the Court has increasingly taken to making rulings in which the Court has determined not what the Constitution \"says\", but rather, the Court has sought to determine what is \"morally correct\" at \"this\" point in the nation's history, in terms of \"the evolving standards of decency\" (and considering \"the context of international jurisprudence\"), and then justified that determination through a \"creative reading\" of the text. This latter approach is frequently termed \"the Living constitution\"; Scalia inveighed that \"the worst thing about the living constitution is that it will destroy the constitution\".\n\nOriginalists are sharply critical of the use of \"the evolving standards of decency\" (a term which first appeared in \"Trop v. Dulles\") and of reference to the opinions of courts in foreign countries (excepting treaties to which the United States is a signatory, per Article II, Section 2, Clause 2 of the United States Constitution) in Constitutional interpretation.\n\nIn an originalist interpretation, if the meaning of the Constitution is static, then any ex post facto information (such as the opinions of the American people, American judges, or the judiciaries of any foreign country) is inherently valueless for interpretation of the meaning of the Constitution, and should not form any part of constitutional jurisprudence. The Constitution is thus fixed and has procedures defining how it can be changed.\n\nThe exception to the use of foreign law is the English common law, which originalists regard as setting the philosophical stage for the US Constitution and the American common and civil law. Hence, an originalist might cite Blackstone's \"Commentaries\" to establish the meaning of the term \"due process\" as it would have been understood at the time of ratification.\n\nArguments for and against Originalism should be read in conjunction with alternative views and rebuttals, presented in footnotes.\n\n\n\n\n\n\n"}
{"id": "43662522", "url": "https://en.wikipedia.org/wiki?curid=43662522", "title": "Partial groupoid", "text": "Partial groupoid\n\nIn abstract algebra, a partial groupoid (also called halfgroupoid, pargoid, or partial magma) is a set endowed with a partial binary operation.\n\nA partial groupoid is a partial algebra.\n\nA partial groupoid formula_1 is called a partial semigroup if the following associative law holds:\n\nLet formula_2 such that formula_3 and formula_4, then \n"}
{"id": "305024", "url": "https://en.wikipedia.org/wiki?curid=305024", "title": "Pratītyasamutpāda", "text": "Pratītyasamutpāda\n\nPratītyasamutpāda (; \"paṭiccasamuppāda\"), commonly translated as dependent origination, or dependent arising, is a key principle in Buddhist teachings, which states that all \"dharmas\" (\"phenomena\") arise in dependence upon other \"dharmas\": \"if this exists, that exists; if this ceases to exist, that also ceases to exist\".\n\nThe principle is expressed in the links of dependent origination (Pali: \"dvādasanidānāni,\" Sanskrit: \"dvādaśanidānāni\") in Buddhism, a linear list of twelve elements from the Buddhist teachings which arise depending on the preceding link. Traditionally the list is interpreted as describing the conditional arising of rebirth in \"saṃsāra\", and the resultant \"duḥkha\" (suffering, pain, unsatisfactoriness). An alternate Theravada interpretation regards the list as describing the arising of mental formations and the resultant notion of \"I\" and \"mine,\" which are the source of suffering. Traditionally, the reversal of the causal chain is explained as leading to the annihilation of mental formations and rebirth. \n\nScholars have noted inconsistencies in the list, and regard it to be a later synthesis of several older lists. The first four links may be a mockery of the Vedic-Brahmanic cosmogeny, as described in the \"Hymn of Creation\" of Veda X, 129 and the Brihadaranyaka Upanishad. These were integrated with a branched list which describe the conditioning of mental processes, akin to the five skandhas. Eventually, this branched list developed into the standard twelvefold chain as a linear list. While this list may be interpreted as describing the processes which give rise to rebirth, in essence it describes the arising of \"dukkha\" as a psychological process, without the involvement of an atman.\n\n\"Pratityasamutpada\" (Sanskrit: प्रतीत्यसमुत्पाद) consists of two terms:\n\nThe term has been translated into English variously as \"dependent origination\", \"dependent arising\", \"interdependent co-arising\", \"conditioned arising\", and \"conditioned genesis\".\n\nThe term may also refer to the twelve nidānas, Pali: \"dvādasanidānāni,\" Sanskrit: \"dvādaśanidānāni,\" from \"dvāvaśa\" (\"twelve\") + \"nidānāni\" (plural of \"nidāna\", \"cause, motivation, link\"). Generally speaking, in the Mahayana tradition, \"pratityasamutpada\" (Sanskrit) is used to refer to the general principle of interdependent causation, whereas in the Theravada tradition, \"paticcasamuppāda\" (Pali) is used to refer to the twelve nidānas.\n\nThe \"Pratityasamutpada\" teachings asserts neither direct Newtonian-like causality nor a single causality. Rather, it asserts an indirect conditioned causality and a plural causality. The \"causal link\" propositions in Buddhism is very different from the idea of causality that developed in Europe. Instead, the concept of causality in Buddhism is referring to conditions created by a plurality of causes that necessarily co-originate phenomena within and across lifetimes, such as karma in one life creating conditions that lead to rebirth in one of realms of existence for another lifetime. The \"Pratītyasamutpāda\" principle asserts that the dependent origination is necessary and sufficient condition in both directions. This is expressed in Majjhima Nikaya as \"When this is, that is; This arising, that arises; When this is not, that is not; This ceasing, that ceases.\"\n\nAccording to Peter Harvey, \"Pratityasamutpada\" is an ontological principle; that is, a theory to explain the nature and relations of being, becoming, existence and ultimate reality. Buddhism asserts that there is nothing independent, except the state of nirvana. All physical and mental states depend on and arise from other pre-existing states, and in turn from them arise other dependent states while they cease. The 'dependent arisings' have a causal conditioning, and thus \"Pratityasamutpada\" is the Buddhist belief that causality is the basis of ontology, not a creator God nor the ontological Vedic concept called universal Self (Brahman) nor any other 'transcendent creative principle'.\n\nThe Pratītyasamutpāda ontological principle in Buddhism is applied not only to explain the nature and existence of matter and empirically observed phenomenon, but also to the nature and existence of life. In abstract form, according to Peter Harvey, \"the doctrine states: 'That being, this comes to be; from the arising of that, this arises; that being absent, this is not; from the cessation of that, this ceases'.\" There is no 'first cause' from which all beings arose.\n\nAgainst Harvey's ontological interpretation, Eviatar Shulman argues that \nShulman grants that there are some ontological implications that may be gleaned from dependent origination, but that at its core it is concerned with \"identifying the different processes of mental conditioning and describing their relations\".\n\nNoa Ronkin states that while Buddha suspends all views regarding certain metaphysical questions, he is not an anti-metaphysician: nothing in the texts suggests that metaphysical questions are completely meaningless, instead Buddha taught that sentient experience is dependently originated and that whatever is dependently originated is conditioned, impermanent, subject to change, and lacking independent selfhood.\n\nAccording to Stephen Laumakis, pratītyasamutpāda is also an epistemological principle; that is, a theory about how we gain correct and incorrect knowledge about being, becoming, existence and reality. The 'dependent origination' doctrine, states Peter Harvey, \"highlights the Buddhist notion that all apparently substantial entities within the world are in fact wrongly perceived. We live under the illusion that terms such as 'I', self, mountain, tree, etc. denote permanent and stable things. The doctrine teaches this is not so.\" There is nothing permanent (anicca), nothing substantial, no unique individual self in the nature of becoming and existence (anatta), because everything is a result of \"dependent origination\". There are no independent objects and independent subjects, according to the Pratītyasamutpāda doctrine, there is fundamental emptiness in all phenomena and experiences.\n\nThe twelve nidānas (Pali: \"dvādasanidānāni,\" Sanskrit: \"dvādaśanidānāni\") is a linear list of twelve elements from the Buddhist teachings which are \"pratītyasamutpāda\", arising depending on the previous link. According to Shulman, \"the 12 links \"are paticcasamuppada\"\"; in the suttas, dependent origination refers to nothing else but the process of mental conditioning as described by the twelve \"nidanas\".\n\nTraditionally the standard-list is interpreted as describing the conditional arising of rebirth in \"saṃsāra\", and the resultant \"duḥkha\" (suffering, pain, unsatisfactoriness). An alternate interpretation regards the list as describing the causal arising of mental formations and the resultant \"duḥkha\". Traditionally, the reversal of the causal chain is explained as leading to the annihilation of mental formations and rebirth. Scholars have noted inconsistencies in the list, and regard it to be a later synthesis of several older lists.\n\nThere are various Nidana lists throughout the Early Buddhist Texts and collections such as the Pali Nikayas, the most common of which is a list of Twelve Nidānas which appears in both Pali texts and Mahayana sutras such as the Salistamba Sutra. The 'dependent origination' doctrine is presented in Vinaya Pitaka 1.1–2, in abbreviated form in Samyutta Nikaya 2.1, 2.19 and 2.76.\n\nDīgha Nikāya Sutta 1, the Brahmajala Sutta, verse 3.71 describes six Nidānas:\nDīgha Nikāya, Sutta 14 describes ten links, and in Sutta 15 nine links are described, but without the six sensebases:\nDescriptions of the full sequence of twelve links can be found elsewhere in the Pali canon, for instance in section 12 of the Samyutta Nikaya:\n\"Nidanas\" are co-dependent events or phenomena, which act as links on a chain, conditioning and depending on each other. When certain conditions are present, they give rise to subsequent conditions, which in turn give rise to other conditions. Phenomena are sustained only so long as their sustaining factors remain. This causal relationship is expressed in its most general form as follows: \nThis natural law of \"this/that causality\" is independent of being discovered, just like the laws of physics. In particular, the Buddha applied this law of causality to determine the cause of \"dukkha\". Understanding the relationships between the phenomena that sustain dukkha is said to lead to nibbana, complete freedom from samsara \n\nTraditionally, the reversal of the causal chain is explained as leading to the annihilation of mental formations and rebirth: \"From the remainderless fading and cessation of \"ignorance\" comes the cessation of \"(volitional) fabrications\"\" et cetera.\n\nThe Upanisa Sutta in the Samyutta Nikaya describes the reversed order, in which the causes for enlightenment are given. This application of the principle of dependent arising is referred to in Theravada exegetical literature as \"transcendental dependent arising\". The chain in this case is:\n\nWithin the Theravada Buddhist tradition, the twelve nidanas are considered to be the most significant application of the principle of dependent origination. \n\nThe nikayas themselves do not give a systematic explanation of the nidana series. As an expository device, the commentarial tradition presented the factors as a linear sequence spanning over three lives, thus shifting the theme from a single conception (and birth) to a sequence of \"incarnations\" (roughly speaking). The twelve nidanas were interpreted by Buddhaghosa (c. fifth century CE) of the Sri Lankan Mahavihara tradition as encompassing three successive lives, as outlined in his influential Visuddhimagga. According to Buddhaghosa, the first two nidanas, namely ignorance (nescience) and motivation, relate to the previous life and forecast the destiny of the person. The third to the tenth nidanas relate to the present life, beginning with the descent of \"vijnana\" (consciousness, perception) into the womb. The last two nidanas (birth and death) represent the future lives conditioned by the present causes. Because of Buddhaghosa's vast influence in the development of Theravada scholasticism, this model has been very influential in the Theravada school.\n\nYet, the twelve nidanas have also been interpreted within the Theravada tradition as explaining the arising of psychological or phenomenological processes in the present moment. There is scriptural support for this as an explanation in the Abhidharmakosa of Vasubandhu, insofar as Vasubandu states that on occasion \"the twelve parts are realized in one and the same moment\". Prayudh Payutto notes that in Buddhaghosa's Sammohavinodani, a commentary to the Vibhanga of the Abhidhamma Pitaka, the principle of Dependent Origination is explained as occurring entirely within the space of one mind moment. According to Prayudh Payutto there is material in the Vibhanga which discusses both models, the three lifetimes model and the phenomenological mind moment model. This thesis is also defended by Bhikkhu Buddhadasa's \"Paticcasamuppada: Practical Dependent Origination.\" In this interpretation, Birth and Death refer not to physical birth and death, but to the birth and death of our self-concept, the \"emergence of the ego\". According to Buddhadhasa,\nAccording to Akira Hirakawa and Paul Groner, the three-lives model, with its \"embryological\" interpretation which links dependent origination with rebirth was also promoted by the Sarvastivadin school (a north Indian branch of the Sthavira nikāya) as evidenced by the Abhidharmakosa of Vasubandhu (fl. 4th to 5th century CE).\n\nThe Abhidharmakosa also outlines three other models of the twelve nidanas, that were used by the Sarvastivada schools together with the three lifetimes model:\n\nAsanga (4th century CE) groups the twelve nidanas into four groups: 1-3 cause of dharmas; 4-7 dharmas; 8-10 cause of suffering; 11-12 suffering.\n\nThe \"bhavachakra\" (Sanskrit; Pāli: \"bhavachakra\"; Tibetan: \"srid pa'i 'khor lo\") is a symbolic representation of saṃsāra (or cyclic existence). It is found on the outside walls of Tibetan Buddhist temples and monasteries in the Indo-Tibetan region, to help ordinary people understand Buddhist teachings. The Three Fires sit at the very center of the schemata in the Bhavacakra and drive the whole edifice. In Himalayan iconographic representations of the Bhavacakra such as within Tibetan Buddhism, the Three Fires are known as the Three Poisons which are often represented as the Gankyil. The Gankyil is also often represented as the hub of the Dharmacakra.\n\nTsongkhapa, following Asanga, explains how the twelve nidanas can be applied to one life of a single person, two lives of a single person, and three lives of a single person. \n\nDiscussing the three lifetimes model, Alex Wayman states that the Theravada/Sarvāstivāda interpretation is different from the Vajrayana view, because the Vajrayana view places a \"bardo\" or an intermediate state between death and rebirth, which is denied by the Theravadins and Sarvastivadins. This denial necessitated placing the first two nidanas of the \"dependent origination\" chain into the past life. The Tibetan Buddhism tradition allocates the twelve nidanas differently between various lives.\n\nAccording to Frauwallner, the twelvefold chain is a combination of two lists. Originally, the Buddha explained the appearance of \"dukkha\" from \"tanha\", \"thirst,\" craving. This is explained and described in the second part, from \"tanha\" on fowards. Later on, under influence of concurring systems, the Buddha incorporated \"avijja\", \"ignorance,\" as a cause of suffering into his system. This is described in the first part, which describes the entry of \"vijnana\" into the womb, where the embryo develops. Frauwallner notes that \"the purely mechanical mixing of both the two parts of the causal chainis remarkable and enigmatical.\" Noting that \"contradictory thoughts stand directly near one another in the oldest Buddhistic ideas\" many times, Frauwallner explains this as a \"deficiency in systematization, the inability to mix different views and principles into a great unity.\"\n\nAccording to Schumann, the twelvefold chain is a later composition by monks, consisting of three shorter lists. These lists may have encompassed \"nidana\" 1-4, 5-8, and 8-12. The progress of this composition can be traced in various steps in the canon.\n\nLambert Schmitthausen argues that the twelve-fold list is a synthesis from three previous lists, arguing that the three lifetimes-interpretation is an unintended consequence of this synthesis.\n\nRoderick S. Bucknell analysed four versions of the twelve nidanas, to explain the existence of various versions of the \"pratitya-samutpada\" sequence. The twevefold version is the \"standard version,\" in which \"vijnana\" refers to sensual consciousness. According to Bucknell, the \"standard version\" of the twelve nidanas developed out of an ancestor version, which in turn was derived from two different versions, in which \"vijnana\" is differently explained. \n\nIn the socalled \"branched version\", which is not strictly linear, but connects a couple of branches, \"vijnana\" is derived from the coming together of the sense organs and the sense objects, a description which can also be found in other sutras. The three of them constitute \"phassa\" (\"contact\"). From there on, the list is linear. In the Sutta-nipata version, which is altogether linear, \"vijnana\" is derived from \"avijja\" (\"ignorance\") and \"Saṅkhāra\" (\"activities\" (RSB); also translated as \"volitional formations\"). \n\nThe \"Mahanidana-sutta\" describes a \"looped version,\" which is also further linear, in which \"vijnana\" and \"nama-rupa\" condition each other. According to Bucknell, this \"looped version\" is derived from the \"branched version.\" According to Bucknell, \"some accounts of the looped version state explicitly that the chain of causation goes no further back than the loop. The Mahanidana further explains \"vijnana\" as \"consciousness that descends into the mother's womb at the moment of conception.\" Waldron notes that \"vijnana\" here has two aspects, namely \"samsaric \"vijnana\"\" and \"cognitive consciousness.\" \"Samsaric \"vijnana\"\" is \"consciousness per se, the basic sentience necessary for all animate life,\" which descends into the womb at the time of conception. Cognitive consciousness is related to the senses and the sense objects. It is \"samsaric \"vijnana\"\" which forms, in Buddhist thought, the connection between two lifes. While these two aspects were largely undifferentiated in early Buddhist thought, these two aspects and their relation was explicated in later Buddhist thought, giving rise to the concept of \"alaya-vijñana\".\n\nWhile the \"branched version\" refers directly to the six sense objects, the \"looped version\" and the standard version instead name it \"nama-rupa\", which eventually was misinterpreted as \"name-and-form\" in the traditional sense. This created \"new causal series,\" which made it possible to interpret the beginning of the chain as referring to rebirth, just like the end of the chain. In line with this reinterpretation, \"vijnana\" \"became the consciousness that descends into the mother's womb at conception, while \"nama-rupa\" became the mind-body complex that [...] experiences contact (\"phassa\") and so on.\" \n\nBucknell further notes that the \"branched version,\" in which \"nama-rupa\" refers to the six classes of sense-objects, corresponds with Buddhadasas psychological interpretation of the twelve nidanas. The \"looped version,\" in which \"vijanana\" corresponds with \"rebirth consciousness,\" corresponds with defenders of the traditional interpretation, such as Nyanatiloka. According to Bucknell, the linear list, with its distortions and changed meaning for \"nama-rupa\" and \"vinaya\", may have developed when the list came to be recited in reverse order.\n\nAlex Wayman has argued that the idea of \"dependent origination\" may precede the birth of the Buddha, noting that the first four causal links starting with Avidya in the Twelve Nidānas are found in the cosmic development theory of the \"Brihadaranyaka Upanishad\" and other older Vedic texts. Jeffrey Hopkins notes that terms synonymous to \"Pratītyasamutpāda\" are \"Apekṣhasamutpāda\" and \"Prāpyasamutpāda\". According to Kalupahana, the concept of causality and causal efficacy where \"cause produces an effect because a property or \"svadha\" (energy) is inherent in something\", appears extensively in the Indian thought in the Vedic literature of the 2nd millennium BCE, such as the 10th mandala of the \"Rigveda\" and the Brahmanas layer of the Vedas. \n \nA similar resemblance has been noted by Jurewicz, who argues that the first four \"nidanas\" resemble the \"Hymn of Creation\" of RigVeda X, 129, in which \"avijja\" (ignorance) leads to \"kamma\" (\"desire\"), which is the seed of \"vijnana\" (\"consciousness\"). This consciousness is a \"singular consciousness,\" (Jurewicz) \"non-dual consciousness,\" (Gombrich) \"reflexive, cognizing itself\" (Gombrich). When the created world, \"name and form\", evolves, pure consciousness manifests itself in the world. It mistakenly identifies itself with \"name and form\", losing sight of its real identity. The Buddha mimicked this creation story, making clear how the entanglement with the world \"drive a human being into deeper and deeper ignorance about himself.\" According to Jurewicz, the Buddha may have picked the term \"nama-rupa\", because \"the division of consciousness into name and form has only the negative value of an act which hinders cognition.\" \n\nAccording to Gombrich, the Buddhist tradition soon lost sight of this connection with the Vedic worldview. It was aware that at this point there is the appearance of an individual person, which the Buddha referred to as the five skandhas, denying a self (\"atman\") separate from these skandhas. The Buddhist tradition equated \"rupa\" with the first \"skandha\", and \"nama\" with the other four. Yet, as Gombrich notes, \"samkhara\", \"vijnana\", and \"vedana\" also appear as separate links in the twelvefold list, so this eqaution can't be correct for this \"nidana\". According to Jurewizc, all twelve nidanas show similarities with the Vedic cosmogeny. They may have been invoked for educated listeners, to make the point that suffering arises in dependence on psychological processes without an atman, thereby rejecting the Vedic outlook.\n\nAccording to Gombrich, following Frauwallner, the twelve-fold list is a combination of two previous lists, the second list beginning with \"tanha\", \"thirst,\" the cause of suffering as described in the second Noble Truth\". The first list consists of the first four \"nidanas\", which parody the Vedic-Brahmanic cosmogony, as described by Jurewicz. According to Gombrich, the two lists were combined, resulting in contradictions in it's negative version. Gombrich further notes that\n\nAccording to Mathieu Boisvert, nidana 3-10 correlate with the five skandhas. Boisvert notes that \"sanna\", \"perception,\" is not part of the twelvefold chain, but does play a role in the prevention of the arising of the \"samkharas\". Likewise, Waldron notes that the \"anusaya\", \"underlying tendencies, are the link between the cognitive provcesses of \"phassa\" (\"contact\") and \"vedana\" (feeling), and the afflictive responses of \"tanha\" (\"craving\") and \"upadana\" (\"grasping\").\nAccording to Schumann, the Nidanas are a later synthesis of Buddhist teachings, meant to make them more comprehensible. Comparison with the five skhandhas shows that the chain contains logical inconsistencies, which can be explained when the chain is considered to be a later elaboration. This way it is explainable that nama-rupa en consciousness in the 9-fold are the beginning or start, while in the 12-fold chain they are preceded by ignorance and formations. Those can only exist when nama-rupa en consciousness are present.\nSchumann also proposes that the 12-fold is extended over three existences, and illustrate the succession of rebirths. While Buddhaghosa and Vasubandhu maintain a 2-8-2 schema, Schumann maintains a 3-6-3 scheme, putting the five skandhas aside the twelve nidanas.\n\nThe second and third truths in the Four Noble Truths are related to the principle of dependent origination, with dependent arising elaborating the arising of suffering. The second truth applies dependent origination in a direct order, while the third truth applies it in inverse order.\n\nAltogether the various lists combine as follows:\n\nAccording to Eisel Mazard, the twelve Nidanas are a description of \"a sequence of stages prior to birth,\" as an \"orthodox defense against any doctrine of a 'supernal self' or soul of any kind [...] excluding an un-mentioned life-force (jīva) that followers could presumed to be additional to the birth of the body, the arising of consciousness, and the other aspects mentioned in the 12-links formula.\" According to Mazard, \"many later sources have digressed from the basic theme and subject-matter of the original text, knowingly or unknowingly.\"\n\nThe notion of karma is integrated into the list of twelve nidanas, and has been extensively commented on by ancient Buddhist scholars such as Nagarjuna. Karma consists of any intentional action, whether of body or speech or in mind, which can be either advantageous (merit) or disadvantageous (demerit). Both good and bad karma sustain the cycle of samsara (rebirth) and associated dukkha, and both prevent the attainment of nirvana.\n\nAccording to Nagarjuna, the second causal link (\"sankhara\", motivations) and the tenth causal link (\"bhava\", gestation) are two karmas through which sentient beings trigger seven sufferings identified in the Twelve Nidanas, and from this arises the revolving rebirth cycles.\n\nTo be liberated from samsara and dukkha, asserts Buddhism, the 'dependent origination' doctrine implies that the karmic activity must cease. One aspect of this 'causal link breaking' is to destroy the \"deeply seated propensities, festering predilections\" (asavas) which are karmic causal flow because these lead to rebirth.\n\nIn the Madhyamaka philosophy, to say that an object is \"empty\" is synonymous with saying that it is dependently originated. Nāgārjuna equates emptiness with dependent origination in Mūlamadhyamakakārikā 24.18-19; \nIn his analysis, svabhāva is somewhat redefined from the Sarvastivada-Vaibhāṣika interpretation to mean: \"inherent existence\" or \"self-characterization.\" Nagarjuna notably rejected the idea of \"dharmas\" containing svabhāva, meaning 'a self-sustaining, permanent, or unchanging identity.' If a \"dharma\" was inherently what-it-was from its own side, what need would there be for causes and conditions to bring that object into being? If any object was characterized by 'being-itself,' then it has no need to dependently rely on anything else. Further, such an identity or self-characterization would prevent the process of dependent origination. Inherence would prevent any kind of origination at all, for things would simply always have been, and things would always continue to be. Madhyamaka suggests that uncharacterized mere experiences—with no specific qualities—are designated by conceptual labels, and this brings them into being (See Prasaṅgika Merely Designated Causality). According to Nagarjuna, even the principle of causality itself is dependently originated, and hence it is empty. \n\nMadhyamaka is interpreted in different ways by different traditions. In the Tibetan Gelug school, all dharmas are said to lack any \"inherent\" existence, according to the Tibetan scholar Tsongkhapa in his Ocean of Reasoning.\n\nIn the Dzogchen tradition of Tibetan Buddhism, the concept of dependent origination is considered to be complementary to the concept of emptiness. Specifically, this tradition emphasizes the indivisibility of appearance and emptiness—also known as the relative and absolute aspects of reality:\n\nIn Mipham Rinpoche's \"Beacon of Certainty\", this relationship is explained using the metaphor of the reflection of the moon in water. According to this metaphor:\n\nOne of the founders of Tibetan Buddhism, Padmasambhava, emphasized his respect for this relationship as follows:\n\nThe Huayan school taught the doctrine of the mutual containment and interpenetration of all phenomena, as expressed in Indra's net. One thing contains all other existing things, and all existing things contain that one thing. This philosophy is based in the tradition of the great Madhyamaka scholar Nagarjuna and, more specifically, on the Avatamsaka Sutra. Regarded by D.T. Suzuki as the crowning achievement of Buddhist philosophy, the \"Avatamsaka Sutra\" elaborates in great detail on the principal of dependent origination. This sutra describes a cosmos of infinite realms upon realms, mutually containing one another.\n\nThich Nhat Hanh states, \"\"Pratitya samutpada\" is sometimes called the teaching of cause and effect, but that can be misleading, because we usually think of cause and effect as separate entities, with cause always preceding effect, and one cause leading to one effect. According to the teaching of Interdependent Co-Arising, cause and effect co-arise (\"samutpada\") and everything is a result of multiple causes and conditions... In the sutras, this image is given: \"Three cut reeds can stand only by leaning on one another. If you take one away, the other two will fall.\" In Buddhist texts, one cause is never enough to bring about an effect. A cause must, at the same time, be an effect, and every effect must also be the cause of something else. This is the basis, states Hanh, for the idea that there is no first and only cause, something that does not itself need a cause.\n\nSogyal Rinpoche states all things, when seen and understood in their true relation, are not independent but interdependent with all other things. A tree, for example, cannot be isolated from anything else. It has no independent existence, states Rinpoche.\n\nJay L. Garfield states that Mulamadhyamikakarika uses the causal relation to understand the nature of reality, and of our relation to it. This attempt is similar to the use of causation by Hume, Kant, and Schopenhauer as they present their arguments. Nagarjuna uses causation to present his arguments on how one individualizes objects, orders one's experience of the world, and understands agency in the world.\n\nThe concept of \"pratītyasamutpāda\" has also been compared to Western metaphysics, the study of reality. Schilbrack states that the doctrine of interdependent origination seems to fit the definition of a metaphysical teaching, by questioning whether there is anything at all. Hoffman disagrees, and asserts that pratītyasamutpāda should not be considered a metaphysical doctrine in the strictest sense, since it does not confirm nor deny specific entities or realities.\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "494995", "url": "https://en.wikipedia.org/wiki?curid=494995", "title": "Pullback (differential geometry)", "text": "Pullback (differential geometry)\n\nSuppose that \"φ\":\"M\"→ \"N\" is a smooth map between smooth manifolds \"M\" and \"N\"; then there is an associated linear map from the space of 1-forms on \"N\" (the linear space of sections of the cotangent bundle) to the space of 1-forms on \"M\". This linear map is known as the pullback (by \"φ\"), and is frequently denoted by \"φ\". More generally, any covariant tensor field – in particular any differential form – on \"N\" may be pulled back to \"M\" using \"φ\".\n\nWhen the map \"φ\" is a diffeomorphism, then the pullback, together with the pushforward, can be used to transform any tensor field from \"N\" to \"M\" or vice versa. In particular, if \"φ\" is a diffeomorphism between open subsets of R and R, viewed as a change of coordinates (perhaps between different charts on a manifold \"M\"), then the pullback and pushforward describe the transformation properties of covariant and contravariant tensors used in more traditional (coordinate dependent) approaches to the subject.\n\nThe idea behind the pullback is essentially the notion of precomposition of one function with another. However, by combining this idea in several different contexts, quite elaborate pullback operations can be constructed. This article begins with the simplest operations, then uses them to construct more sophisticated ones. Roughly speaking, the pullback mechanism (using precomposition) turns several constructions in differential geometry into contravariant functors.\n\nLet φ:\"M\"→ \"N\" be a smooth map between (smooth) manifolds \"M\" and \"N\", and suppose \"f\":\"N\"→R is a smooth function on \"N\". Then the pullback of \"f\" by φ is the smooth function φ\"f\" on \"M\" defined by\n\nMore generally, if \"f\":\"N\"→\"A\" is a smooth map from \"N\" to any other manifold \"A\", then φ\"f\"(\"x\")=\"f\"(φ(\"x\")) is a smooth map from \"M\" to \"A\".\n\nIf \"E\" is a vector bundle (or indeed any fiber bundle) over \"N\" and \"φ\":\"M\"→\"N\" is a smooth map, then the pullback bundle \"φ\"\"E\" is a vector bundle (or fiber bundle) over \"M\" whose fiber over \"x\" in \"M\" is given by (\"φ\"\"E\") = \"E\".\n\nIn this situation, precomposition defines a pullback operation on sections of \"E\": if \"s\" is a section of \"E\" over \"N\", then the pullback section formula_1 is a section of \"φ\"\"E\" over \"M\".\n\nLet Φ:\"V\"→ \"W\" be a linear map between vector spaces \"V\" and \"W\" (i.e., Φ is an element of \"L\"(\"V\",\"W\"), also denoted Hom(\"V\",\"W\")), and let\n\nbe a multilinear form on \"W\" (also known as a tensor — not to be confused with a tensor field — of rank (0,\"s\"), where \"s\" is the number of factors of \"W\" in the product). Then the pullback Φ\"F\" of \"F\" by Φ is a multilinear form on \"V\" defined by precomposing \"F\" with Φ. More precisely, given vectors \"v\",\"v\"...,\"v\" in \"V\", Φ\"F\" is defined by the formula\n\nwhich is a multilinear form on \"V\". Hence Φ is a (linear) operator from multilinear forms on \"W\" to multilinear forms on \"V\". As a special case, note that if \"F\" is a linear form (or (0,1) -tensor) on \"W\", so that \"F\" is an element of \"W\", the dual space of \"W\", then Φ\"F\" is an element of \"V\", and so pullback by Φ defines a linear map between dual spaces which acts in the opposite direction to the linear map Φ itself:\n\nFrom a tensorial point of view, it is natural to try to extend the notion of pullback to tensors of arbitrary rank, i.e., to multilinear maps on \"W\"\ntaking values in a tensor product formula_5 of \"r\" copies of \"W\". However, elements of such a tensor product do not pull back naturally: instead there is a pushforward operation from formula_6 to formula_5 given by\n\nNevertheless, it follows from this that if Φ is invertible, pullback can be defined using pushforward by the inverse function Φ. Combining these two constructions yields a pushforward operation, along an invertible linear map, for tensors of any rank (\"r\",\"s\").\n\nLet \"φ\" : \"M\" → \"N\" be a smooth map between smooth manifolds. Then the differential of \"φ\", written \"φ\", \"dφ\", or \"Dφ\", is a vector bundle morphism (over \"M\") from the tangent bundle \"TM\" of \"M\" to the pullback bundle \"φ\"\"TN\". The transpose of \"φ\" is therefore a bundle map from \"φ\"\"T\"\"N\" to \"T\"\"M\", the cotangent bundle of \"M\".\n\nNow suppose that \"α\" is a section of \"T\"\"N\" (a 1-form on \"N\"), and precompose \"α\" with \"φ\" to obtain a pullback section of \"φ\"\"T\"\"N\". Applying the above bundle map (pointwise) to this section yields the pullback of \"α\" by \"φ\", which is the 1-form \"φ\"\"α\" on \"M\" defined by\nfor \"x\" in \"M\" and \"X\" in \"T\"\"M\".\n\nThe construction of the previous section generalizes immediately to tensor bundles of rank (0,\"s\") for any natural number \"s\": a (0,\"s\") tensor field on a manifold \"N\" is a section of the tensor bundle on \"N\" whose fiber at \"y\" in \"N\" is the space of multilinear \"s\"-forms\nBy taking Φ equal to the (pointwise) differential of a smooth map \"φ\" from \"M\" to \"N\", the pullback of multilinear forms can be combined with the pullback of sections to yield a pullback (0,\"s\") tensor field on \"M\". More precisely if \"S\" is a (0,\"s\")-tensor field on \"N\", then the pullback of \"S\" by \"φ\" is the (0,\"s\")-tensor field \"φ\"\"S\" on \"M\" defined by\nfor \"x\" in \"M\" and \"X\" in \"T\"\"M\".\n\nA particular important case of the pullback of covariant tensor fields is the pullback of differential forms. If \"α\" is a differential \"k\"-form, i.e., a section of the exterior bundle Λ\"T\"*\"N\" of (fiberwise) alternating \"k\"-forms on \"TN\", then the pullback of \"α\" is the differential \"k\"-form on \"M\" defined by the same formula as in the previous section:\nfor \"x\" in \"M\" and \"X\" in \"T\"\"M\".\n\nThe pullback of differential forms has two properties which make it extremely useful.\n\n1. It is compatible with the wedge product in the sense that for differential forms \"α\" and \"β\" on \"N\", \n2. It is compatible with the exterior derivative \"d\": if \"α\" is a differential form on \"N\" then\n\nWhen the map \"φ\" between manifolds is a diffeomorphism, that is, it has a smooth inverse, then pullback can be defined for the vector fields as well as for 1-forms, and thus, by extension, for an arbitrary mixed tensor field on the manifold. The linear map\ncan be inverted to give\n\nA general mixed tensor field will then transform using Φ and Φ according to the tensor product decomposition of the tensor bundle into copies of \"TN\" and \"TN\". When \"M\" = \"N\", then the pullback and the pushforward describe the transformation properties of a tensor on the manifold \"M\". In traditional terms, the pullback describes the transformation properties of the covariant indices of a tensor; by contrast, the transformation of the contravariant indices is given by a pushforward.\n\nThe construction of the previous section has a representation-theoretic interpretation when \"φ\" is a diffeomorphism from a manifold \"M\" to itself. In this case the derivative \"dφ\" is a section of GL(\"TM\",\"φ\"\"TM\"). This induces a pullback action on sections of any bundle associated to the frame bundle GL(\"M\") of \"M\" by a representation of the general linear group GL(\"m\") (\"m\" = dim \"M\").\n\nSee Lie derivative. By applying the preceding ideas to the local 1-parameter group of diffeomorphisms defined by a vector field on \"M\", and differentiating with respect to the parameter, a notion of Lie derivative on any associated bundle is obtained.\n\nIf formula_17 is a connection (or covariant derivative) on a vector bundle formula_18 over formula_19 and formula_20 is a smooth map from formula_21 to formula_19, then there is a pullback connection formula_23 on formula_20formula_18 over formula_21, determined uniquely by the condition that\n\n\n"}
{"id": "9591787", "url": "https://en.wikipedia.org/wiki?curid=9591787", "title": "Punishment (psychology)", "text": "Punishment (psychology)\n\nIn operant conditioning, punishment is any change in a human or animal's surroundings that occurs after a given behavior or response which reduces the likelihood of that behavior occurring again in the future. As with reinforcement, it is the \"behavior\", not the animal, that is punished. Whether a change is or is not punishing is determined by its effect on the rate that the behavior occurs, not by any \"hostile\" or aversive features of the change. For example, a painful stimulus which would act as a punisher for most people may actually reinforce some behaviors of masochistic individuals.\n\nThere are two types of punishment in operant conditioning:\n\n\nPunishment is not a mirror effect of reinforcement. In experiments with laboratory animals and studies with children, punishment decreases the likelihood of a previously reinforced response only temporarily, and it can produce other \"emotional\" behavior (wing-flapping in pigeons, for example) and physiological changes (increased heart rate, for example) that have no clear equivalents in reinforcement.\n\nPunishment is considered by some behavioral psychologists to be a \"primary process\" – a completely independent phenomenon of learning, distinct from reinforcement. Others see it as a category of negative reinforcement, creating a situation in which any punishment-avoiding behavior (even standing still) is reinforced.\n\nPositive punishment occurs when a response produces a stimulus and that response decreases in probability in the future \nin similar circumstances.\n\nNegative punishment occurs when a response produces the removal of a stimulus and that response decreases in probability in the future in similar circumstances.\n\nSimply put, reinforcers serve to increase behaviors whereas punishers serve to decrease behaviors; thus, positive reinforcers are stimuli that the subject will work to attain, and negative reinforcers are stimuli that the subject will work to be rid of or to end. The table below illustrates the adding and subtracting of stimuli (pleasant or aversive) in relation to reinforcement vs. punishment.\n\n\"Aversive stimulus\", \"punisher\", and \"punishing stimulus\" are somewhat synonymous. \"Punishment\" may be used for (a) an aversive stimulus or (b) the occurrence of any punishing change or (c) the part of an experiment in which a particular response is punished. However, some things considered aversive (such as spanking) can become reinforcing. In addition, some things that are aversive may not be punishing if accompanying changes are reinforcing. A classic example would be mis-behavior that is 'punished' by a teacher but actually increases over time due to the reinforcing effects of attention on the student.\n\nPain, loud noises, foul tastes, bright lights, and exclusion are all things that would pass the \"caveman test\" as an aversive stimulus, and are therefore primary punishers. The sound of someone booing, the wrong-answer buzzer on a game show, and a ticket on your car windshield are all things you have learned to think about as negative, and are considered secondary punishers.\n\nContrary to suggestions by Skinner and others that punishment typically has weak or impermanent effects, a large body of research has shown that it can have a powerful and lasting effect in suppressing the punished behavior. However, it may also have powerful and lasting side effects. For example, an aversive stimulus used to punish a particular behavior may also elicit a strong emotional response that may suppress unpunished behavior and become associated with situational stimuli through classical conditioning. Such side effects suggest caution and restraint in the use of punishment to modify behavior. (Further reading: )\n\nOne variable affecting punishment is contingency, which is defined as the dependency of events. A behavior may be dependent on a stimulus or dependent on a response. The purpose of punishment is to reduce a behavior, and the degree to which punishment is effective in reducing a targeted behavior is dependent on the relationship between the behavior and a punishment. For example, if a rat receives an aversive stimulus, such as a shock each time it presses a lever, then it is clear that contingency occurs between lever pressing and shock. In this case, the punisher (shock) is contingent upon the appearance of the behavior (lever pressing). Punishment is most effective when contingency is present between a behavior and a punisher. A second variable affecting punishment is contiguity, which is the closeness of events in time and/or space. Contiguity is important to reducing behavior because the longer the time interval between an unwanted behavior and a punishing effect, the less effective the punishment will be. One major problem with a time delay between a behavior and a punishment is that other behaviors may present during that time delay. The subject may then associate the punishment given with the unintended behaviors, and thus suppressing those behaviors instead of the targeted behavior. Therefore, immediate punishment is more effective in reducing a targeted behavior than a delayed punishment would be.\n\nPunishment is sometimes used for treatment programs in applied behavior analysis in the most extreme cases, to reduce dangerous behaviors such as head banging or biting exhibited most commonly by children or people with special needs or disabilities. Punishment is considered one of the ethical challenges to autism treatment and is one of the major reasons for discussion of professionalizing behavior analysis. Professionalizing behavior analysis through licensure would create a board to ensure that consumers or families had a place to air disputes. (see Professional practice of behavior analysis)\n\nControversy regarding ABA persists in the autism community. A 2017 study found that 46% of people with autism spectrum undergoing ABA met the criteria for post-traumatic stress disorder (PTSD), and the risk of developing it as a result of ABA is more than 86% higher in people with autism spectrum than in non-obese people. type of therapy. According to the researchers, the risk of PTSD was increased when ABA was used regardless of the age of the patient (adults and children were examined).\n\nBraiker identified the following ways that manipulators control their victims:\n\nTraumatic bonding occurs as the result of ongoing cycles of abuse in which the intermittent reinforcement of reward and punishment creates powerful emotional bonds that are resistant to change.\n\n"}
{"id": "10386571", "url": "https://en.wikipedia.org/wiki?curid=10386571", "title": "Rebound effect (conservation)", "text": "Rebound effect (conservation)\n\nIn conservation and energy economics, the rebound effect (or take-back effect) is the reduction in expected gains from new technologies that increase the efficiency of resource use, because of behavioral or other systemic responses. These responses usually tend to offset the beneficial effects of the new technology or other measures taken.\n\nWhile the literature on the rebound effect generally focuses on the effect of technological improvements on energy consumption, the theory can also be applied to the use of any natural resource or other input, such as labor. The rebound effect is generally expressed as a ratio of the lost benefit compared to the expected environmental benefit when holding consumption constant.\n\nFor instance, if a 5% improvement in vehicle fuel efficiency results in only a 2% drop in fuel use, there is a 60% rebound effect (since = 60%). The 'missing' 3% might have been consumed by driving faster or further than before.\n\nThe existence of the rebound effect is uncontroversial. However, debate continues as to the magnitude and impact of the effect in real world situations.\nDepending on the magnitude of the rebound effect, there are five different rebound effect (RE) types:\n\nIn order to avoid the rebound effect, environmental economists have suggested that any cost savings from efficiency gains be taxed in order to keep the cost of use the same.\n\nThe rebound effect was first described by William Stanley Jevons in his 1865 book \"The Coal Question\", where he observed that the invention in Britain of a more efficient steam engine meant that the use of coal became economically viable for many new uses. This ultimately led to increased coal demand and much increased coal consumption, even as the amount of coal required for any particular use fell. According to Jevons, \"It is a confusion of ideas to suppose that the economical use of fuel is equivalent to diminished consumption. The very contrary is the truth.\"\n\nHowever, most contemporary authors credit Daniel Khazzoom for the re-emergence of the rebound effect in the research literature. Although Khazzoom did not use the term, he raised the idea that there is a less than one-to-one correlation between gains in energy efficiency and reductions in energy use, because of a change in the 'price content' of energy in the provision of the final consumer product. His study was based on energy efficiency gains in home appliances, but the principle applies throughout the economy. A commonly studied example is that of a more fuel-efficient car. As each kilometre of travel becomes cheaper, there will be an increase in driving speed and/or kilometres driven, as long as the price elasticity of demand for car travel is not zero. Other examples might include the growth in garden lighting after the introduction of energy-saving Light Emitting Diodes or the increasing size of houses driven partly by higher fuel efficiency in home heating technologies. If the rebound effect is larger than 100%, all gains from the increased fuel efficiency would be wiped out by increases in demand (the Jevons paradox).\n\nKhazzoom's thesis was criticized heavily by Michael Grubb and Amory Lovins who dismissed any disconnection between energy efficiency improvements in an individual market, and an economy-wide reduction in energy consumption. Developing Khazzoom's idea further, and prompting heated debate in the Energy Policy journal at that time, Len Brookes wrote of the fallacies in the energy-efficiency solution to greenhouse gas emissions. His analysis showed that any economically justified improvements in energy efficiency would in fact stimulate economic growth and increase total energy use. For improvements in energy efficiency to contribute to a reduction in economy-wide energy consumption, the improvement must come at a greater economic cost. Commenting in regard to energy efficiency advocates, he concludes that, \"the present high profile of the topic seems to owe more to the current tide of green fervor than to sober consideration of the facts, and the validity and cost of solutions.\"\n\nIn 1992, economist Harry Saunders coined the term \"Khazzoom-Brookes postulate\" to describe the idea that energy efficiency gains paradoxically result in increases in energy use (the modern day equivalent of the Jevons paradox). He modeled energy efficiency gains using a variety of neo-classical growth models, and showed that the postulate is true over a wide range of assumptions. In the conclusion of his paper, Saunders stated that:\nThis work provided a theoretical grounding for empirical studies and played an important role in framing the problem of the rebound effect. It also reinforced an emerging ideological divide between energy economists on the extent of the yet to be named effect. The two tightly held positions are:\n\nEven though many studies have been undertaken in this area, neither position has yet claimed a consensus view in the academic literature. Recent studies have demonstrated that direct rebound effects are significant (about 30% for energy), but that there is not enough information about indirect effects to know whether or how often back-fire occurs. Economists tend to the first position, but most governments, businesses, and environmental groups adhere to the second. Governments and environmental groups often advocate further research into fuel efficiency and radical increases in the efficient use of energy as the primary means for reducing energy use and reducing greenhouse gas emissions (to alleviate the impacts of climate change). However, if the first position more accurately reflects economic reality, current efforts to invent fuel-efficient technologies may not much reduce energy use, and may in fact paradoxically increase oil and coal consumption, and greenhouse gas emissions, over the long run.\n\nThe full rebound effect can be distinguished into three different economic reactions to technological changes: \nIn the example of improved vehicle fuel efficiency, the direct effect would be the increased fuel use from more driving as driving becomes cheaper. The indirect effect would incorporate the increased consumption of other goods enabled by household cost savings from increased fuel efficiency. Since consumption of other goods increases, the embodied fuel used in the production of those goods would increase as well. Finally, the economy-wide effect would include the long-term effect of the increase in vehicle fuel efficiency on production and consumption possibilities throughout the economy, including any effects on economic growth rates.\n\nFor cost reducing resource efficiency, distinguishing between direct and indirect effects is shown in Figure 1 below. The horizontal axis shows units of consumption of the targets good (which could be for example clothes washing, and measured in terms of kilograms of clean clothes) with consumption of all other goods and services on the vertical axis. An economical technology change that enables each unit of washing to be produced with less electricity results in a reduction of the price per unit of washing. This shifts the household budget line rightwards. The result is a substitution effect because of the decreased relative price, but also an income effect due to the increased real income. The substitution effect increases consumption of washing from Q1 to QS, and the income effect from QS to Q2. The total increase in consumption of washing from Q1 to Q2 and the resulting increase in electricity consumption is the direct effect. The indirect effect comprises the increase in other consumption, from O1 to O2. The scale of each of these effects depends on the elasticity of demand for each of the goods, and the embodied resource or externality associated with each good. Indirect effects are difficult to measure empirically. In the manufacturing sector, it has been estimated that there is about a 24% rebound effect due to increases in fuel efficiency. A parallel effect will happen for cost saving efficient technologies for producers, where output and substitution effects will occur.\n\nThe rebound effect can increase the difficulty of projecting the reduction in greenhouse emissions from an improvement in energy efficiency. Estimation of the scale of direct effects on residential electricity, heating and motor fuel consumption has been common motivation for research of rebound effects. Evaluation and econometric methods are the two approaches generally employed in estimating the size of this effect. Evaluation methods rely on quasi-experimental studies and measure the before and after changes to energy consumption from the implementation of energy efficient technology, while econometric methods utilize elasticity estimates to forecast the likely effects from changes in the effective price of energy services.\n\nResearch has found that in developed countries, the direct rebound effect is usually small to moderate, ranging from roughly 5% to 40% in residential space heating and cooling. Some of the direct rebound effect can be attributed to consumers who were previously unable to use a service. However, the rebound effect may be more significant in the context of the undeveloped markets in developing economies.\n\nFor conservation measures, indirect effects closely approximate the total economy-wide effect. Conservation measures constitute a change in consumption patterns away from particular targeted goods towards other goods. Figure 2 shows that a change in preference of a household results in a new consumption pattern that has less of the target good (QT to QT`), and more of all other goods (QO to QO`). The resource consumption or externalities embodied in this other consumption is the indirect effect.\n\nAlthough a persuasive view has prevailed that indirect effects with respect to energy and greenhouse emissions should be very small due to energy directly comprising only a small component of household expenditure, this view is gradually being eroded. Many recent studies based on life-cycle analysis show the energy consumed indirectly by households is often higher than consumed directly through electricity, gas, and motor fuel, and is a growing proportion. This is evident in the results of recent studies that indicate indirect effects from household conservation can range from 10% to 200% depending on the scenario, with higher indirect rebounds from diet changes aiming to reduce food miles.\n\nEven if the direct and indirect rebound effects add up to less than 100%, technological improvements that increase efficiency may still result in economy-wide effects that results in increased resource use for the economy as a whole. In particular, this would happen if increased resource efficiency enables an expansion of production in the economy, and an increase in the rate of economic growth. For example, for the case of energy use, more efficient technology is equivalent to a lower price for energy resources. It is well known that changes in energy costs have a large impact on economic growth rates. In the 1970s, sharp increases in petroleum prices led to stagflation (recession and inflation) in the developed countries, whereas in the 1990s lower petroleum prices contributed to higher economic growth. An improvement in energy efficiency has the same effect as lower fuel prices, and leads to faster economic growth. Economists generally believe that especially for the case of energy use, more efficient technologies will lead to increased use, because of this growth effect.\n\nTo model the scale of this effect, economists use computational general equilibrium (CGE) models. While CGE methodology is by no means perfect, results indicate that economy-wide rebound effects are likely to be very high, with estimates above 100% being rather common. One simple CGE model has been made available online for use by economists.\n\nResearch has shown that the direct rebound effects for energy services is lower at high income levels, due to less price sensitivity. Studies have found that own-price elasticity of gas consumption by UK households was two times greater for households in the lowest income decile when compared to the highest decile. Studies have also observed higher rebounds in low-income houses for improvements in heating technology. Evaluation methods have also been used to assess the scale of rebound effects from efficient heating installations in lower income homes in the United Kingdom. This research found that direct effects are close to 100% in many cases. High income households in developed countries are likely to set the temperature at the optimum comfort level, regardless of the cost – therefore any cost reduction does not result in increased heating, for it was already optimal. But low-income households are more price sensitive, and have made thermal sacrifices due to the cost of heating. In this case, a high direct rebound is likely. This analogy can be extended to most household energy consumption.\n\nThe size of the rebound effect is likely to be higher in developing countries according to macro-level assessments and case studies. One case study was undertaken in rural India to evaluate the impact of an alternative energy scheme. Households were given solar powered lighting in an attempt to reduce the use of kerosene for lighting to zero except for seasons with insufficient sunshine. The scheme was also designed to encourage a future willingness to pay for efficient lighting. The results were surprising, with high direct rebounds between 50 and 80%, and total direct and indirect rebound above 100%. Because the new lighting source was essentially zero cost, operating hours for lighting went up from an average of 2 to 6 per day, with new lighting consisting of a combination of both the no-cost solar lamps and also kerosene lamps. Also, more cooking was undertaken which enabled an increased trade of food with neighboring villages.\n\nThe individual opportunity of cost is an often overlooked cause of the rebound effect. Just as improved workplace tools result in an increased expectation of productivity, so does the increased availability of time result in an increase in demand for a service. Research articles often examine increasingly convenient and more rapid modes of transportation to determine the rebound effect in energy demand. Because time cost forms a major part of the total cost of commuter transport, rapid modes will reduce real costs, but will also encourage longer commuting distances which will in turn increase energy consumption. While important, it is almost impossible to estimate empirically the scale of such effects due to the subjective nature of the value of time. Time saved can either be used towards additional work or leisure which may have differing degrees of rebound effect. Labor time saved at work due to the increased labour productivity is likely to be spent on further labor time at higher productive rates. For leisure time saving, this may simply encourage people to diversify their leisure interests to fill their generally fixed period of leisure time.\n\nIn order to ensure that efficiency enhancing technological improvements actually reduce fuel use, the ecological economists Mathis Wackernagel and William Rees have suggested that any cost savings from efficiency gains be \"taxed away or otherwise removed from further economic circulation. Preferably they should be captured for reinvestment in natural capital rehabilitation.\" This can be achieved through, for example, the imposition of a green tax, a cap and trade program, higher fuel taxes or the proposed \"restore\" approach where part of the savings is directed back to the resource. Policies can also directly address projected yearly consumption of energy rather than device efficiency, especially for systems where the use can be accurately projected, such as street lighting.\n\n\n"}
{"id": "102065", "url": "https://en.wikipedia.org/wiki?curid=102065", "title": "Shibboleth", "text": "Shibboleth\n\nA shibboleth () is any custom or tradition, particularly a speech pattern, that distinguishes one group of people (an ingroup) from others (outgroups). Shibboleths have been used throughout history in many societies as passwords, simple ways of self-identification, signaling loyalty and affinity, maintaining traditional segregation or keeping out perceived threats.\n\nThe term originates from the Hebrew word \"shibbólet\" (), which literally means the part of a plant containing grains, such as an ear of corn or a stalk of grain or, in different contexts, \"stream, torrent\". The modern use derives from an account in the Hebrew Bible, in which pronunciation of this word was used to distinguish Ephraimites, whose dialect used a differently sounding first consonant. The difference concerns the Hebrew letter \"shin\", which is now pronounced as (as in \"shoe\").\n\nRecorded in the Book of Judges, chapter 12, after the inhabitants of Gilead inflicted a military defeat upon the invading tribe of Ephraim (around 1370–1070 BCE), the surviving Ephraimites tried to cross the River Jordan back into their home territory and the Gileadites secured the river's fords to stop them. To identify and kill these Ephraimites, the Gileadites told each suspected survivor to say the word \"shibboleth\". The Ephraimite dialect resulted in a pronunciation that, to Gileadites, sounded like \"sibboleth\". In the King James Bible the anecdote appears thus (with the word already in its current English spelling):\nAnd the Gileadites took the passages of Jordan before the Ephraimites: and it was so, that when those Ephraimites which were escaped said, Let me go over; that the men of Gilead said unto him, Art thou an Ephraimite? If he said, Nay;Then said they unto him, Say now Shibboleth: and he said Sibboleth: for he could not frame to pronounce it right. Then they took him, and slew him at the passages of Jordan: and there fell at that time of the Ephraimites forty and two thousand.\n\nIn numerous cases of conflict between groups speaking different languages or dialects, one side used shibboleths in a way similar to the above-mentioned Biblical use, i.e., to discover hiding members of the opposing group. Modern researchers use the term \"shibboleth\" for all such uses, whether or not the people involved were using it themselves.\n\nIn modern American English, a shibboleth also has a wider meaning, referring to any \"in-group\" word or phrase that can distinguish members of a group from outsiders – even when not used by a hostile other group. It is also sometimes used in a broader sense to mean jargon, the proper use of which identifies speakers as members of a particular group or subculture.\n\nThe term shibboleth can also be extended, as in the discipline of semiotics, to describe non-linguistic elements of culture such as diet, fashion and cultural values.\n\nCultural touchstones and shared experience can also be shibboleths of a sort. For example, people about the same age who are from the same nation tend to have the same memories of popular songs, television shows, and events from their formative years. One-hit wonders prove particularly distinctive. Much the same is true of alumni of a particular school, veterans of military service, and other groups. Discussing such memories is a common way of bonding. In-jokes can be a similar type of shared-experience shibboleth.\n\nBy analogy with the biblical account, in information technology a shibboleth is a community-wide password that enables a member of that community to access an online resource without revealing her individual identity. The origin server can vouch for the identity of the individual user without giving the target server any further identifying information. Hence the individual user does not know the password that is actually employed – it is generated internally by the origin server – and so cannot betray it to outsiders.\n\nYet another more pejorative usage involves underlining the fact that the original meaning of a symbol has in effect been lost and that the symbol now serves merely to identify allegiance, being described as \"nothing more than a shibboleth\".\n\nNobel Prize-laureate economist Paul Samuelson applied the term \"shibboleth\" in works including \"Foundations of Economic Analysis\" to an idea for which \"the means becomes the end, and the letter of the law takes precedence over the spirit.\" Samuelson admitted that \"shibboleth\" is an imperfect term for this phenomenon, and sometimes used \"fetish\" as a synonym, though he complained that the latter \"has too pejorative a ring.\"\n\nShibboleths have been used by different subcultures throughout the world at different times. Regional differences, level of expertise, and computer coding techniques are several forms that shibboleths have taken.\n\nThe legend goes that before the Guldensporenslag (Battle of the Golden Spurs) in May 1302, the Flemish slaughtered every Frenchman they could find in the city of Bruges, an act known as the \"Brugse Metten\". They identified Frenchmen based on their inability to pronounce the Flemish phrase ' (shield and friend), or possibly ' (friend of the Guilds). However, many Medieval Flemish dialects did not contain the cluster \"sch-\" either (even today's Kortrijk dialect has \"sk-\"), and Medieval French rolled the r just as Flemish did.\n\n\"Bûter, brea, en griene tsiis; wa't dat net sizze kin, is gjin oprjochte Fries\" () means \"Butter, rye bread and green cheese, whoever cannot say that is not a genuine Frisian\" was used by the Frisian Pier Gerlofs Donia during a Frisian rebellion (1515–1523). Ships whose crew could not pronounce this properly were usually plundered and soldiers who could not were beheaded by Donia himself.\n\nThe Dutch used the name of the seaside town of Scheveningen as a shibboleth to tell Germans from the Dutch (\"Sch\" in Dutch is analyzed as the letter \"s\" and the digraph \"ch\", producing the consonant cluster , while in German it is analyzed as the trigraph \"sch,\" pronounced ).\n\nIn Sardinia 28 April is celebrated as \"sa dii de s'aciappa\" (the day of pursuit and capture) or Sa die de sa Sardigna (Sardinia's Day). On that date in 1794 people in Cagliari chased suspected officers of the ruling Piedmontese king and asked them to say \"nara cixidi\" (Sardinian for ‘chickpea’), which the Piedmontese could not pronounce. Some 514 officers were thus identified and sent back to the mainland.\n\nIn October 1937 the Spanish word for parsley, \"perejil\", was used as a shibboleth to identify Haitian immigrants living along the border in the Dominican Republic. The president of the Dominican Republic, Rafael Trujillo, ordered the execution of these people. It is alleged that between 20,000 and 30,000 individuals were murdered within a few days in the Parsley Massacre, although more recent scholarship and the lack of evidence such as mass graves puts the actual total as low as 1,000.\n\nDuring the Black July riots of Sri Lanka in 1983 many Tamils were massacred by Sinhalese youths. In many cases these massacres took the form of boarding buses and getting the passengers to pronounce words that had hard BAs at the start of the word (like \"Baldiya\" – bucket) and executing the people who found it difficult.\n\nDuring World War II, some United States soldiers in the Pacific theater used the word \"\" as a shibboleth to challenge unidentified persons, on the premise that Japanese people often pronounce the letter L as R or confuse Rs with Ls; the word is also an American colloquialism that even a foreign person fairly well-versed in American English would probably mispronounce or be unfamiliar with. In Oliver Gramling's \"Free Men are Fighting: The Story of World War II\" (1942) the author notes that, in the war, Japanese spies would often approach checkpoints posing as American or Filipino military personnel. A shibboleth such as \"lollapalooza\" would be used by the sentry, who, if the first two syllables come back as \"rorra,\" would \"open fire without waiting to hear the remainder\".\n\nDuring the Allied breakout from the Normandy beachheads in 1944, hand-to-hand fighting occurred throughout the hedgerows and thick undergrowth of the Norman countryside. British and American troops were told to use the word \"Thunderer\" as a countersign through the thick foliage. Given the number of syllables and the leading \"th\" sound, it was believed that the word would invariably be mispronounced by native German speakers.\n\nDuring The Troubles in Northern Ireland, use of the name Derry or Londonderry for the province's second-largest city was often taken as an indication of the speaker's political stance, and as such frequently implied more than simply naming the location. The pronunciation of the letter H is a related shibboleth, with Catholics and Protestants often pronouncing the letter differently.\nIn Australia and New Zealand, the words \"fish and chips\" are often used to highlight the difference in each country's short-i vowel sound [ɪ] and asking someone to say the phrase can identify which country they are from. Australian English has a higher forward sound [i], close to the y in happy and city, while New Zealand English has a lower backward sound [ɘ], a slightly higher version of the a in about and comma. Thus, New Zealanders hear Australians say \"feesh and cheeps,\" while Australians hear New Zealanders say \"fush and chups.\"\n\nA \"furtive shibboleth\" is a type of a shibboleth which identifies individuals as being part of a group not based on their ability to pronounce one or more words, but on their ability to recognize a seemingly-innocuous phrase as a secret message. For example, members of Alcoholics Anonymous sometimes refer to themselves as \"a friend of Bill W.\", which is a reference to AA's founder, William Griffith Wilson. To the unindoctrinated, this would seem like a casual – if off-topic – remark, but other AA members would understand its meaning.\n\nSimilarly, during World War II, a homosexual US sailor might call himself a \"friend of Dorothy\", a tongue-in-cheek acknowledgment of a stereotypical affinity for Judy Garland in \"The Wizard of Oz\". This code was so effective that even after the higher command learned that the phrase was a way for gay sailors to identify each other, they failed to recognize its origins, and purportedly invested a great deal of time and effort into hunting down this \"Dorothy,\" whom they assumed to be an actual woman who was somehow assisting and organizing homosexual servicemen.\n\nColombian conceptual artist Doris Salcedo created a work titled \"Shibboleth\" at Tate Modern, London, in 2007–2008. The piece consisted of a 548-foot-long crack that bisected the floor of the Tate's lobby space.\n\nSalcedo said of the work:\nIn an episode of \"The West Wing\" titled \"Shibboleth\", President Bartlet discusses the meaning of the word at length. His advisors believe it is a catch phrase or cliche, after which Bartlet reminds them of its earlier biblical significance. He later becomes certain that a group of Chinese religious asylum seekers are indeed Christian when their representative uses the word to refer to his faith during a meeting.\n"}
{"id": "2504255", "url": "https://en.wikipedia.org/wiki?curid=2504255", "title": "Social dominance orientation", "text": "Social dominance orientation\n\nSocial dominance orientation (SDO) is a personality trait which predicts social and political attitudes, and is a widely used social psychological scale. SDO is conceptualized as a measure of individual differences in levels of group-based discrimination; that is, it is a measure of an individual's preference for hierarchy within any social system and the domination over lower-status groups. It is a predisposition toward anti-egalitarianism within and between groups. The concept of SDO as a measurable individual difference is a product of social dominance theory.\n\nIndividuals who score high in SDO desire to maintain and, in many cases, increase the differences between social statuses of different groups, as well as individual group members. Typically, they are dominant, driven, tough, and seekers of power. People high in SDO also prefer hierarchical group orientations. Often, people who score high in SDO adhere strongly to belief in a \"dog-eat-dog\" world. It has also been found that men are generally higher than women in SDO measures. Studies have found that SDO has a strong positive relationship with authoritarian and racist beliefs.\n\nSDO was first proposed by Jim Sidanius and Felicia Pratto as part of their social dominance theory (SDT). SDO is the key measurable component of SDT that is specific to it.\n\nSDT begins with the empirical observation that surplus-producing social systems have a threefold group-based hierarchy structure: age-based, gender-based and \"arbitrary set-based\", which can include race, class, sexual orientation, caste, ethnicity, religious affiliation, etc. Age-based hierarchies invariably give more power to adults and middle-age people than children and younger adults, and gender-based hierarchies invariably grant more power to one gender over others, but arbitrary-set hierarchies—though quite resilient—are truly arbitrary.\n\nSDT is based on three primary assumptions:\n\nSDO is the individual attitudinal aspect of SDT. It is influenced by group status, socialization, and temperament. In turn, it influences support for HE and HA \"legitimating myths\", defined as \"values, attitudes, beliefs, causal attributions and ideologies\" that in turn justify social institutions and practices that either enhance or attenuate group hierarchy.\n\nWhile the correlation of gender with SDO scores has been empirically measured and confirmed, the impact of temperament and socialization is less clear. Duckitt has suggested a model of attitude development for SDO, suggesting that unaffectionate socialisation in childhood causes a tough-minded attitude. According to Duckitt's model, people high in tough-minded personality are predisposed to view the world as a competitive place in which resource competition is zero-sum. A desire to compete, which fits with social dominance orientation, influences in-group and outside-group attitudes. People high in SDO also believe that hierarchies are present in all aspects of society and are more likely to agree with statements such as \"It's probably a good thing that certain groups are at the top and other groups are at the bottom\". In turn, SDO predicts stereotyping, discrimination and prejudice.\n\nSDO has been measured by a series of scales that have been refined over time, all of which contain a balance of pro- and contra-trait statements or phrases. A 7-point Likert scale is used for each item; participants rate their agreement or disagreement with the statements from 1 (strongly disagree) to 7 (strongly agree). Most of the research was conducted with the SDO-5 (a 14-point scale) and SDO-6. The SDO-7 scale is the most recent scale measuring social dominance orientation, which embeds two sub-dimensions: dominance (SDO-D) and anti-egalitarianism (SDO-E).\n\n\n\n\nKeying is reversed on questions 9 through 16, to control for acquiescence bias.\n\nRubin and Hewstone (2004) argue that social dominance research has changed its focus dramatically over the years, and these changes have been reflected in different versions of the social dominance orientation construct. Social dominance orientation was originally defined as \"the degree to which individuals desire social dominance and superiority for themselves and their primordial groups over other groups\" (p. 209). It then quickly changed to not only \"(a) a…desire for and value given to in-group dominance over out-groups\" but also \"(b) the desire for nonegalitarian, hierarchical relationships between groups within the social system\" (p. 1007). The most recent measure of social dominance orientation (see SDO-6 above) focuses on the \"general desire for unequal relations among social groups, regardless of whether this means ingroup domination or ingroup subordination\" (p. 312). Given these changes, Rubin and Hewstone believe that evidence for social dominance theory should be considered \"as supporting three separate SDO hypotheses, rather than one single theory\" (p. 22).\n\nRobert Altemeyer said that people with a high SDO want more power (agreeing with items such as \"\"Winning is more important than how you play the game\") and are more Machiavellian (manipulative and amoral, agreeing with items such as \"There really is no such thing as\" 'right and wrong' and \"It all boils down to what you can get away with\"\").\n\nThese observations are at odds with conceptualisations of SDO as a group-based phenomenon, suggesting that the SDO reflects interpersonal dominance, not only group-based dominance. This is supported by Sidanius and Pratto's own evidence that high-SDO individuals tend to gravitate toward hierarchy-enhancing jobs and institutions, such as law enforcement, that are themselves hierarchically structured vis-a-vis individuals within them.\n\nSDO correlates weakly with right-wing authoritarianism (RWA) (r ≈ .18). Both predict attitudes, such as sexist, racist, and heterosexist attitudes. The two contribute to different forms of prejudice; SDO correlates to higher prejudice against subordinate and disadvantaged groups, RWA correlates to higher prejudice against threatening groups, while both are associated with increases in prejudice for \"dissident\" groups. SDO and RWA contribute to prejudice in an additive rather than interactive way (the interaction of SDO and RWA accounted, in one study, for an average of less than .001% variance in addition to their linear combination), that is the association between SDO and prejudice is similar regardless of a person's level of RWA, and vice versa. Crawford et al. (2013) found that RWA and SDO differentially predicted interpretations of media reports about socially threatening (for example, gays and lesbians) and disadvantaged groups (for example, African Americans), respectively. Subjects with high SDO, but not RWA, scores reacted positively to articles and authors that opposed affirmative action, and negatively to pro-affirmative-action article content. Moreover, RWA, but not SDO, predicted subjects' evaluations of same-sex relationships, such that high-RWA individuals favored anti-same-sex relationships article content and low-RWA individuals favorably rated pro-same-sex relationships content.\n\nStudies on the relationship of SDO with the higher order Big Five personality traits have associated high SDO with lower openness to experience and lower agreeableness. Meta-analytic aggregation of these studies indicates that the association with low Agreeableness is more robust than the link to Openness to experience. Individuals low in Agreeableness are more inclined to report being motivated by self-interest and self-indulgence\".\" They also tend to be more self-centred and are more 'tough-minded' compared to those who are high on Agreeableness, leading them to perceive the world to be a highly-competitive place, where the way to success is through power and dominance – all of which predict SDO.\n\nLow Openness, by contrast, aligns more strongly with RWA; thinking in clear and straightforward moral codes that dictate how society as a system should function. Being low in Openness prompts the individual to value security, stability and control: fundamental elements of RWA.\n\nIn case of SDO all five facets of Agreeableness significantly correlate (negatively), even after controlling for RWA. 'Tough-mindedness' (opposite of tender-mindedness' facet) is the strongest predictor of SDO. After the effect of SDO is controlled for only one facet of agreeableness is predictive of RWA. Facets also distinguish SDO from RWA, with 'Dominators' (individuals high on SDO), but not 'authoritarians' (individuals who score high on RWA), having been found to be lower in dutifulness, morality, sympathy and co-operation. RWA is also associated with religiosity, conservativism, righteousness, and, to some extent, a conscientious moral code, which distinguishes RWA from SDO.\n\nSDO is inversely related to empathy. Facets of Agreeableness that are linked to altruism, sympathy and compassion are the\nstrongest predictors of SDO. SDO has been suggested to have a link with callous affect (which is to be found on the psychopathy sub-scale), the 'polar opposite' of empathy.\n\nThe relationship between SDO and \"(lack of)\" empathy has been found to be reciprocal – with equivocal findings. Some studies show that empathy significantly impacts SDO, whereas other research suggest the opposite effect is more robust; that SDO predicts empathy. The latter showcases how powerful of a predictor SDO may be, not only affecting individual's certain behaviours, but potentially influencing upstream the\nproneness to those behaviours. It also suggests, that those scoring high on SDO proactively avoid scenarios that could prompt\nthem to be more empathetic or tender-minded. This avoidance decreases concern for other's welfare.\n\nEmpathy indirectly affects generalized prejudice through its negative relationship with SDO. It also\nhas a direct effect on generalized prejudice, as lack of empathy makes one unable to put oneself in the other person's shoes, which predicts prejudice and antidemocratic views.\n\nFelicia Pratto and her colleagues have found evidence that a high social dominance orientation is strongly correlated with conservative political views, and opposition to programs and policies that aim to promote equality (such as affirmative action, laws advocating equal rights for homosexuals, women in combat, etc.).\n\nThere has been some debate within the psychology community on what the relation is between SDO and racism/sexism. One explanation suggests that opposition to programs that promote equality need not be based on racism or sexism but on a \"principled conservatism\", that is, a \"concern for equity, color-blindness, and genuine conservative values\".\n\nSome principled-conservatism theorists have suggested that racism and conservatism are independent, and only very weakly correlated among the highly educated, who truly understand the concepts of conservative values and attitudes. In an effort to examine the relationship between education, SDO, and racism, Sidanius and his colleagues asked approximately 4,600 Euro-Americans to complete a survey in which they were asked about their political and social attitudes, and their social dominance orientation was assessed. \"These findings contradict much of the case for the principled conservatism hypothesis, which maintains that political values that are largely devoid of racism, especially among highly educated people.\" Contrary to what these theorists would predict, correlations among SDO, political conservatism, and racism were strongest among the most educated, and weakest among the least educated. Sidanius and his colleagues hypothesized this was because the most educated conservatives tend to be more invested in the hierarchical structure of society and in maintaining the inequality of the status quo in society in order to safeguard their status.\n\nSDO is typically measured as an individual personality construct. However, cultural forms of SDO have been discovered on the macro level of society. Discrimination, prejudice and stereotyping can occur at various levels of institutions in society, such as transnational corporations, government agencies, schools and criminal justice systems. The basis of this theory of societal level SDO is rooted in evolutionary psychology, which states that humans have an evolved predisposition to express social dominance that is heightened under certain social conditions (such as group status) and is also mediated by factors such as individual personality and temperament. Democratic societies are lower in SDO measures The more that a society encourages citizens to cooperate with others and feel concern for the welfare of others, the lower the SDO in that culture. High levels of national income and empowerment of women are also associated with low national SDO, whereas more traditional societies with lower income, male domination and more closed institutional systems are associated with a higher SDO. Individuals who are socialized within these traditional societies are more likely to internalize gender hierarchies and are less likely to challenge them.\n\nThe biology of SDO is unknown.\n\nPlenty of evidence suggests that men tend to score higher on SDO than women, and this is true across different countries,\ncultures, age-groups, classes, religions and educational levels. Researchers argue for an\n'invariance' in the difference between men and women's SDO; suggesting that even if all other factors were to be controlled for, the difference between men and women's SDO would still remain – this however in some cases is disproved.\n\nFrom an evolutionary and biological perspective SDO facilitates men to be successful in their reproductive strategy through\nachieving social power and control over other males and becoming desired mating partners for the opposite sex.\n\nMales are observed to be more socially hierarchical, as indicated by speaking time, and yielding to interruptions.\n\nNoting that males tend to have higher SDO scores than females, Sidanius and Pratto speculate that SDO may be influenced by hormones that differ between the sexes, namely androgens, primarily testosterone. Male levels of testosterone are much higher than that of females.\n\nTaking a socio-cultural perspective, it is argued that the gap between women and men in SDO is dependent upon societal norms prescribing different expectations for gender roles of men and women. Men are expected to be dominant and assertive, whereas women are supposed to be submissive and tender.\n\nDifferences between male and female attributional cognitive complexity is suggested contribute to the gender gap in SDO. Women have been found to be more attributionally complex compared to men; they use more contextual information and evaluate social information more precisely. It is proposed that lower social status prompts higher cognitive complexity in order to compensate for the lack of control in that social situation by processing it more attentively and evaluating it more in depth. The difference in cognitive complexity between high and low status individuals could contribute to the differences between male and female SDO.\n\n"}
{"id": "247315", "url": "https://en.wikipedia.org/wiki?curid=247315", "title": "Status quo", "text": "Status quo\n\nIt is the nominal form of the prepositional Latin phrase \"\" – literally \"in the state in which\", which itself is a shortening of the original phrase ', meaning \"in the state in which things were before the war\". To maintain the status quo is to keep the things the way they presently are. The related phrase ', literally \"the state in which before\", means \"the state of affairs that existed previously\".\n\nSocial movements are an example of times when the status quo might be challenged. In these instances \"status quo\" refers to the current state of affairs around a particular issue, or perhaps the current culture or social climate of an entire society or nation. The status quo is generally perceived negatively by supporters of the social movement, and people who want to maintain the status quo can be seen as being resistant to progress.\n\nPoliticians sometimes refer to a status quo. Often there is a policy of deliberate ambiguity, referring to the status quo rather than formalizing the status. Clark Kerr is reported to have said: \"The status quo is the only solution that cannot be vetoed\".\n\nKarl Marx viewed organized religion as a means for the bourgeoisie to keep the proletariat content with an unequal status quo, and education is seen by others as a means of maintaining the status quo of society.\n\n"}
{"id": "28673779", "url": "https://en.wikipedia.org/wiki?curid=28673779", "title": "The Big Mo", "text": "The Big Mo\n\nThe Big Mo (\"Big Momentum\") is behavioral momentum that operates on a large scale. The concept originally applied to sporting events in the 1960s in the United States, as momentum appeared to have an effect on a team's performance. Successful teams were said to have \"The Big Mo\" on their side. This has since extended situations in which momentum is a driving factor, such as during political campaigns, social upheavals, economic cycles, and financial bubbles.\n\nThe term was used by George H. W. Bush during his quest for the Republican nomination to run for President in 1980. After he won the Iowa caucuses, and was facing further contests, Bush Senior said, \"Now they will be after me, howling and yowling at my heels. What we will have is momentum. We will look forward to Big Mo being on our side, as they say in athletics.\" Eventually, Bush lost to Ronald Reagan who went on to become the 40th President of the United States.\n\nResearch conducted in 2005, by Christopher Hull at Georgetown University, US, suggested that from 1980 to 2000, \"Big Mo\" (large scale momentum) had amplified key events in US presidential races.\nIn 2007, three researchers from the London Business School, Elroy Dimson, Paul Marsh and Mike Staunton, observed in their paper \"108 Years of Momentum Profits\" that \"momentum appears to have an inordinate and unexplained impact on the behaviour of investment markets that contradicts the efficient market theory\". One of the researchers, Dr Paul Marsh said, \"We remain puzzled (by these findings) and we are not the only ones; most academics are vaguely embarrassed by this.\"\n\nIn the lead-up to the British election in May 2010, James Forsyth, the political editor of \"The Spectator\" magazine, wrote, \"The Big Mo is with the Tories. In a campaign, momentum matters. It is, for good or ill, the prism through which the media report things.\"\n\nIn 2010, an analysis conducted by Mark Roeder, a former executive at the Swiss-based UBS Bank, suggested that Big Mo \"played a pivotal role\" in the 2008–09 global financial crisis. Roeder suggested that,\nIn January 2011, a report in \"The Economist\" magazine, titled \"The Big Mo\", said,\nThe mechanism by which momentum influences human behaviour on a large scale is not known, but a number of theories exist. In 1982, a research team led by John Nevin, Professor Emeritus of Psychology at the University of New Hampshire, US, together with Charlotte Mandel and Jean Atak, wrote a paper called \"The Analysis of Behavioural Momentum\", in which they explored why certain behaviours can become persistent over time. The team proposed that people's tendency to continue to behave in a certain way, and resist change, is dependent on the type of reinforcement they receive. The team developed a method for calculating the impact of behavioural momentum, based on the Newtonian formula: Δ\"V\" = \"f\" / \"m\", in which Δ\"V\" is the change in velocity or, in behavioural terms, response rate; Velocity (\"V\") refers to the response rate; mass (\"m\") refers to the response strength, and force (\"f\") refers to the change in the contingencies for the behaviour (i.e., environment change). The work of Nevin, Mandel and Atak has been influential in the development of social and health-care policies, such as drug rehabilitation programs, where behavioural persistence (momentum) and relapse are critical issues. \n\nMore controversial theories about behavioural momentum derive from quantum physics and quantum field theory. In her book \"The Field\", author Lyn McTaggart cites experiments that show that in certain group environments that, \"each member of the group becomes less highly-tuned to their own separate information and more receptive to that of other group members. In effect, they pick up someone else's information from the 'field' as if it were their own\". She says this phenomenon is akin to what sports teams experience when they \"enter the zone\" and are influenced by momentum.\n\nThe \"Big Mo\" was also the nickname for the battleship \"USS Missouri\". This was the ship where Japan signed their surrender to the United States.\n\n"}
{"id": "46788547", "url": "https://en.wikipedia.org/wiki?curid=46788547", "title": "The Son Also Rises (book)", "text": "The Son Also Rises (book)\n\nThe Son Also Rises is a 2014 non-fiction book on the study of social mobility by the economist Gregory Clark. It is based on historical estimates of social mobility in various countries made by Clark in collaboration with other researchers, though Clark takes pains to point out from the start the controversial conclusions he draws are his alone.\n\nThe book's title, like Clark's previous book's title, is a pun on the title of an Ernest Hemingway novel - in this case, \"The Sun Also Rises\".\n\nThe book follows relatively successful and unsuccessful extended families through the centuries in England, the United States, Sweden, India, China, Taiwan, Japan, Korea, and Chile. Clark uses an innovative technique of following families by seeing whether or not rare surnames kept turning up in university enrollment records, registers of physicians, lists of members of parliament, and other similar contemporary historical registers. Clark finds that the persistence of high or low social status is greater than would be expected from the generally accepted correlations of income between parents and children, conflicting with virtually all measures of social mobility previously developed by other researchers, which Clark claims are flawed. According to Clark, social mobility proceeds at a similar rate in all of the societies and in all the periods of history studiedwith the exceptions of social groups with higher endogamy (tendency to marry within the same group), who experience higher social persistence and therefore even lower social mobility.\n\nThe book attempts to explain the difference between Clark's estimates of social mobility rates and estimates by other researchers by noting that the effects measured by other researchers are based on only a few generations, and argues that Clarke's posited hidden variable of inherited \"underlying social competence\" is swamped by chance variations in status from generation to generation - variations which Clarke says are smoothed out in his longer-term study. This can be analogised to looking at a graph to understand the trend in the market price of a stocka graph of a stock price over a one-day period may show large \"zigzag\" price swings and no apparent order, whereas a longer-term stock price graph, particularly if smoothed, may reveal a long-term trend for the price of the stock to increase or decrease.\n\nFrom his finding that ethnically homogeneous societies, such as Japan and Korea, had similar rates of social mobility to ethnically diverse societies, such as the United States, Clark infers that racism may not be a significant factor affecting social mobility. From his finding that families who had many children were able to pass down their high social status just as well as families who had few children, Clark infers that simple inheritance of wealth cannot explain the persistence of high social status. From the referenced studies on the lack of correlation between the intelligence and adult family income of adopted children and their adoptive parents, Clark infers that family environment cannot explain the transmittal of social status from one generation to the next.\n\nClark controversially hypothesises that the main reason for the unexpectedly high persistence of social status in families (or, put another way, the unexpectedly low degree of social mobility he finds) is that high-status people are more likely to have genes that are beneficial to them achieving high status, and are therefore more likely to pass such genes on to their children.\n\nThe book also advocates a generous welfare state, on the grounds that people of lower social status are unlikely to be able to advance very far in life, contrary to the widespread American Dream ideology of \"anyone can make it in America if they work hard enough\", and so people's advantages in life come about mostly through accident of birth, not effort.\n\nKourtellos, Marr and Tan note that Clark's main conclusion that social mobility has always been low is supported by several other papers by other researchers.\n\nClark wrote a February 21, 2014 \"New York Times\" article: \"Your Ancestors, Your Fate\". He also wrote an article for \"The Guardian\", published a year later.\n\n"}
{"id": "1329938", "url": "https://en.wikipedia.org/wiki?curid=1329938", "title": "Toast (honor)", "text": "Toast (honor)\n\nA toast is a ritual in which a drink is taken as an expression of honor or goodwill. The term may be applied to the person or thing so honored, the drink taken, or the verbal expression accompanying the drink. Thus, a person could be \"the toast of the evening\", for whom someone \"proposes a toast\" to congratulate and for whom a third person \"toasts\" in agreement. The ritual forms the basis of the literary and performance genre, of which Mark Twain's \"To the Babies\" is a well-known example.\n\nThe toast as described here is rooted in Western culture, but certain cultures outside that sphere have their own traditions in which consuming a drink is connected with ideas of celebration and honor. While the physical and verbal ritual of the toast may be elaborate and formal, merely raising one's glass towards someone or something and then drinking is essentially a toast as well, the message being one of goodwill towards the person or thing indicated.\n\nAccording to various apocryphal stories, the custom of touching glasses evolved from concerns about poisoning. By one account, clinking glasses together would cause each drink to spill over into the others' (though there is no real evidence for such an origin). According to other stories, the word \"toast\" became associated with the custom in the 17th century, based on a custom of flavoring drinks with spiced toast. The word originally referred to the lady in whose honor the drink was proposed, her name being seen as figuratively flavoring the drink. The \"International Handbook on Alcohol and Culture\" says toasting \"is probably a secular vestige of ancient sacrificial libations in which a sacred liquid was offered to the gods: blood or wine in exchange for a wish, a prayer summarized in the words 'long life!' or 'to your health!\n\nToasts are generally offered at times of celebration or commemoration, including certain holidays, such as New Year's Eve. Other occasions include retirement celebrations, housewarming parties, births, etc. The protocol for toasting at weddings is comparatively elaborate and fixed. At a wedding reception, the father of the bride, in his role as host, regularly offers the first toast, thanking the guests for attending, offering tasteful remembrances of the bride's childhood, and wishing the newlyweds a happy life together. The best man usually proposes a toast in the form of best wishes and congratulations to the newlyweds. A best man's toast takes the form of a short speech (3–5 minutes) that combines a mixture of humor and sincerity. The humor often comes in the shape of the best man telling jokes at the groom's expense whilst the sincerity incorporates the praise and complimentary comments that a best man should make about the bride and groom, amongst others. The actual \"toast\" is then delivered at the end of the speech and is a short phrase wishing the newlyweds a happy, healthy, loving life together. The maid of honor may follow suit, appropriately tailoring her comments to the bride. The groom may offer the final toast, thanking the bride's parents for hosting the wedding, the wedding party for their participation, and finally dedicating the toast to the bridesmaids.\n\nTypical traditional wedding toasts include the following:\nToasts are also offered on patriotic occasions, as in the case of Stephen Decatur's famous \"Our country! In our intercourse with foreign nations may we always be in the right; but our country, right or wrong.\" Equally traditional are satiric verses:\n\nToasts may be solemn, sentimental, humorous, bawdy, or insulting. The practice of announcing one's intention to make a toast and signalling for quiet by rapping on the wineglass, while common, is regarded by some authorities as rude. Except in very small and informal gatherings, a toast is offered standing. At a gathering, none should offer a toast to the guest of honor until the host has had the opportunity to do so. In English-speaking countries, guests may signal their approval of the toast by saying \"hear hear\". The person honored should neither stand nor drink, but after the toast should rise to thank the one who has offered the toast and take a drink, perhaps but not necessarily offering a toast in turn. As toasts may occur in long series, experienced attendees often make sure to leave enough wine in the glass to allow participation in numerous toasts.\n\nPutting one's glass down before the toast is complete, or simply holding one's glass without drinking is widely regarded as impolite, suggesting that one does not share the benevolent sentiments expressed in the toast, nor the unity and fellowship implicit in toasting itself. Even the non-drinker is counseled not to refuse to allow wine to be poured for a toast. Inverting the glass is especially discouraged.\n\nToasting traditionally involves alcoholic beverages. Champagne (or at least some variety of sparkling wine) is regarded as especially festive and is widely associated with New Year's Eve and other celebrations. Many people nowadays substitute sparkling fruit juice (often packaged in champagne-style bottles), and many authorities consider it perfectly acceptable to participate in a toast while drinking water. Toasting with an empty glass may be viewed by some as acceptable behavior for the non-drinker, though feigning to drink from such a glass would likely be seen as ridiculous. The person giving the toast should never do so with an empty glass, even if the glass contains nothing more than water.\n\nTeetotalers may view the drinking of toasts to be abominable and incompatible with their stand, as witnessed by this narrative from \"The Teetotaler\" (1840):\nAt the anniversary of Cheshunt College, Sir Culling Eardley Smith was in the chair. This gentleman, after dinner, said \"he had subscribed to the Teetotal Pledge, which of course was incompatible with the drinking of toasts;\" when the Rev. J. Blackburn, (minister of Claremont Chapel, Pentonville,) said \"he was not a teetotaler,—\"he was not in bondage,\"—and on that subject he had very recently been preaching.\" What could the Rev. Gentleman mean by this, but that he had recently been preaching against Teetotalism? Let the Rev. Gentleman look at drinking customs and their enormous evils, and ask himself if he has done his duty; or whether he expects to be pronounced \"a good an faithful servant\", if he continues even from the pulpit to encourage the great damning evil of this nation. Mr. Donaldson said that he was happy to add, that one of the most popular ministers of the day, the Rev. J. Sherman, gave Mr. B. a pretty severe and well-merited reply, by saying, \"His brother Blackburn had said, he (Mr. B.) was not in bondage; he must be allowed to say, that he rejoiced that he (Mr. S.) had been enabled to break through the old and stupid custom of washing down sentiments by draughts of intoxicating liquors. \"He had thus become a free man.\"\n\nMr. Donaldson concluded with some very severe animadversions upon the infamous conduct of Mr. Blackburn.\nIt is a superstition in the United States Navy that a toast is never to be made with water, since the person so honored will be doomed to a watery grave. During a United States Air Force Dining In, all toasts are traditionally made with wine except for the final toast of the night made in honor of POWs/MIAs; because these honorees did not have the luxury of wine while in captivity, the toast is made with water. Some versions of the protocol prescribe a toast in water for all deceased comrades.\n\nIt is or was the custom on the (British) Royal Navy to drink toasts sitting, because in old-type wooden warships below decks there was not enough headroom to stand upright.\n\nProsit is a Latin word from which the German short form \"prost\" is derived. It is a toast, that is an acclamation made before drinking an alcoholic beverage when drinkers chink glasses. The expression dates back to the beginning of the 18th century when it was used among university students and eventually made its way into every day language. In a ceremonious context and in connection with a short speech, the English word toast may also be used.\n\nThe word is, as mentioned above, of Latin origin and it comes from the verb \"prodesse\" (= \"to benefit sth/sb\", \"to be beneficial\"). Consequently, \"prosit\" is the conjugated form (3rd person Singular, Present Subjunctive, Active) and therefore an optative: \"To you/ to your health\". Like the colloquial \"prost\", \"prosit\" was originally used by university students.\n\nIn German, synonyms like \"Wohl bekomm's!\", \"Zum Wohl!\", and many versions from other languages may also be used instead of \"prosit\". The acclamation itself is also referred to as a \"prosit\". The verb form is \"zuprosten\", where the prefix \"zu\" means that the speech act is targeted at one or several people.\n\nIn the Swabian dialect, the word has the further meaning of a belch, called a \"Prositle\". The acclamation is followed by the clinking of glasses, often linked to other rules like making eye contact. This ritual is commonly attributed to a medieval custom, whereby one could avoid being poisoned by one's drinking companions, as a few drops of each beverage got mixed when clinking glasses. There is every likelihood that this did not work. It was much more effective for one table to share one or more drinking vessels, a procedure which was common for a long time.\n\nIn Danish, Swedish, and Norwegian, prosit is a blessing used in response to a sneeze, in the same way the English expression \"bless you\" is used.\n\nIn Germany, toasting, not necessarily by words but usually just by touching each other's drinking vessels, is usually a very closely observed part of culture. In private company, no one should drink a sip of alcohol before having toasted all the other people at the table. In doing this, it is very important to look directly into the other drinker's eyes. Not practising this is considered rude and often, humorously, believed to attract all kinds of bad luck (e.g. \"seven years of bad luck\" and the like).\n\nIn the British Royal Navy, the officers' noon mess typically began with the loyal toast, followed by a toast distinctive for the day of the week:\n\nThe sequence was also prescribed in at least one publication for the United States Navy.\n\nA toast might be spontaneous and free-form, a carefully planned original speech, or a recitation of traditional sentiments such as this Irish example:\nAn informal variation of the last 2 lines is:\n\nIn various cultures worldwide, toasting is common and to not do so may be a breach of etiquette. The general theme of a toast is \"good luck\" or \"good health\". At formal meals in certain countries of the Commonwealth of Nations, the first toast to be proposed is traditionally the Loyal Toast (\"The Queen\"). This may be adapted in other countries to give a loyal toast to the appropriate Head of State.\n\nSelected examples of toasts worldwide:\n\n"}
{"id": "449938", "url": "https://en.wikipedia.org/wiki?curid=449938", "title": "Triskelion", "text": "Triskelion\n\nA triskelion or triskele is a motif consisting of a triple spiral exhibiting rotational symmetry.\nThe spiral design can be based on interlocking Archimedean spirals, or represent three bent human legs.\n\nBoth terms are from Greek (\"triskelion\") or (\"triskeles\"), \"three-legged\", from prefix \"τρι-\" (\"tri-\"), \"three times\" + \"σκέλος\" (\"skelos\"), \"leg\".\n\nA triskelion is a traditional symbol of Sicily, where it is called \"trinacria\"; the Isle of Man, where it is known in Manx as \"Tree Cassyn Vannin\", and Brittany where it is known as \"Triskèle\". Ingushetia also has a (stylised) triskelion in its flag.\n\nThe triskelion symbol appears in many early cultures, the first in Malta (4400–3600 BCE) and in the astronomical calendar at the famous megalithic tomb of Newgrange in Ireland built around 3200 BCE, Mycenaean vessels, on coinage in Lycia, and on staters of Pamphylia (at Aspendos, 370–333 BCE) and Pisidia. It appears as a heraldic emblem on warriors' shields depicted on Greek pottery.\n\nThe triskelion is an ancient symbol of Sicily, with the head of the Gorgon, with snakes as hair, from which radiate three legs bent at the knee. The symbol dates back to when Sicily was part of Magna Graecia, the colonial extension of Greece beyond the Aegean. Pliny the Elder attributes the origin of the triskelion of Sicily to the triangular form of the island, the ancient \"Trinacria\" (from the Greek \"tri-\" (three) and ἄκρα \"akra\" (end, peak, citadel), which consists of three large capes equidistant from each other, pointing in their respective directions, the names of which were Pelorus, Pachynus, and Lilybæum.\n\nThe Celtic symbol of three conjoined spirals may have had triple significance similar to the imagery that lies behind the triskelion. The triple spiral motif is a Neolithic symbol in Western Europe. Though popularly considered a \"Celtic\" symbol, it is in fact a pre-Celtic symbol. It is carved into the rock of a stone lozenge near the main entrance of the prehistoric Newgrange monument in County Meath, Ireland. Newgrange, which was built around 3200 BCE, predates the Celtic arrival in Ireland, but has long since been incorporated into Celtic culture. The symbol is also found carved in rock in Castro Culture settlement in modern-day Galicia and Northern Portugal. In Ireland before the 5th century, in Celtic Christianity the triskele took on new meaning, as a symbol of the Trinity (Father, Son, and Holy Spirit), and therefore also a symbol of eternity. Its popularity continues today as a decorative symbol of faith for Christians of Celtic descent around the world.\n\nTraditional Asian versions of the triskelion include the Japanese Mitsudomoe, the Tibetan Buddhist Gankyil, and the Korean Sam Taegeuk.\nA triskelion is featured on the seal of the United States Department of Transportation.\n\nA triskelion shape is the basis for the roundel of the Irish Air Corps, and the logo for the Trisquel Linux distribution.\n\nA triskelion shape was used in the design of RCA's \"Spider\" 45 rpm adapter, a popular plastic adapter for vinyl records, which allows larger center-holed 45 rpm records (commonly used on 7\" singles and EPs) to spin on players designed for smaller center-holed 33-1/3 rpm records (the standard for 10\" and 12\" LPs). The design was practical, the three curved arms providing equal spring and thus keeping the hole centred. The iconic design of the Spider has led to its adoption as a popular symbol for record and music enthusiasts.\n\nOne of the most commonly used symbols of the BDSM community is a derivation of a triskelion shape within a circle.\n\nThe South African neo-Nazi White supremacist White nationalist organization and political party Afrikaner Weerstandsbeweging uses a Triskele composed of three sevens as its symbol in place of the Nazi Swastika.\n\nThe Flag of the Isle of Man bears 3 legs based on the Triskele.\n\nThe crest of the Breton football club En Avant de Guingamp combines the Flag of Brittany, the team colours and the triple spiral triskelion.\n\n\"The Gamesters of Triskelion\" is a second-season episode of the American science fiction television series \"Star Trek\".\n\nIn the Marvel Universe, the intelligence agency S.H.I.E.L.D. uses the Triskelion as its headquarters .\n\nThe Triskele is also used as a prominent symbol in MTV's \"Teen Wolf (2011 TV Series)\" which draws heavily from Celtic mythology. A Triskele was used by some younger betas to keep from shifting & maintain calm. This happens by the beta repeating \"Alpha, Beta, Omega\" or \"The Sun, The Moon, The Truth\" over and over again until the beta is calm.\n\nIn Merlin (2008 TV series) it was used as symbol of druids.\n\nThe triskele, usually consisting of spirals, but also the \"horned triskelion\", is used by some polytheistic reconstructionist and neopagan groups. As a Celtic symbol, it is used primarily by groups with a Celtic cultural orientation and, less frequently, can also be found in use by various eclectic or syncretic traditions such as Neopaganism. The spiral triskele is one of the primary symbols of Celtic Reconstructionist Paganism. Celtic Reconstructionists use the symbol to represent a variety of triplicities in their cosmology and theology; it is also a favored symbol due to its association with the god Manannán mac Lir.\n\nThe endocytic protein, clathrin, is triskelion-shaped.\nThe Ediacaran fossil Tribrachidium is also triskelion shaped.\n"}
{"id": "21347678", "url": "https://en.wikipedia.org/wiki?curid=21347678", "title": "Unit of measurement", "text": "Unit of measurement\n\nA unit of measurement is a definite magnitude of a quantity, defined and adopted by convention or by law, that is used as a standard for measurement of the same kind of quantity. Any other quantity of that kind can be expressed as a multiple of the unit of measurement.\n\nFor example, a length is a physical quantity. The metre is a unit of length that represents a definite predetermined length. When we say 10 metres (or 10 m), we actually mean 10 times the definite predetermined length called \"metre\".\nMeasurement is a process of determining how large or small a physical quantity is as compared to a basic reference quantity of the same kind.\n\nThe definition, agreement, and practical use of units of measurement have played a crucial role in human endeavour from early ages up to the present. A multitude of systems of units used to be very common. Now there is a global standard, the International System of Units (SI), the modern form of the metric system.\n\nIn trade, weights and measures is often a subject of governmental regulation, to ensure fairness and transparency. The International Bureau of Weights and Measures (BIPM) is tasked with ensuring worldwide uniformity of measurements and their traceability to the International System of Units (SI).\n\nMetrology is the science of developing nationally and internationally accepted units of measurement.\n\nIn physics and metrology, units are standards for measurement of physical quantities that need clear definitions to be useful. Reproducibility of experimental results is central to the scientific method. A standard system of units facilitates this. Scientific systems of units are a refinement of the concept of weights and measures historically developed for commercial purposes.\n\nScience, medicine, and engineering often use larger and smaller units of measurement than those used in everyday life. The judicious selection of the units of measurement can aid researchers in problem solving (see, for example, dimensional analysis).\n\nIn the social sciences, there are no standard units of measurement and the theory and practice of measurement is studied in psychometrics and the theory of conjoint measurement.\n\nA unit of measurement is a standardised quantity of a physical property, used as a factor to express occurring quantities of that property. Units of measurement were among the earliest tools invented by humans. Primitive societies needed rudimentary measures for many tasks: constructing dwellings of an appropriate size and shape, fashioning clothing, or bartering food or raw materials.\n\nThe earliest known uniform systems of measurement seem to have all been created sometime in the 4th and 3rd millennia BC among the ancient peoples of Mesopotamia, Egypt and the Indus Valley, and perhaps also Elam in Persia as well.\n\nWeights and measures are mentioned in the Bible (Leviticus 19:35–36). It is a commandment to be honest and have fair measures.\n\nIn the \"Magna Carta\" of 1215 (The Great Charter) with the seal of King John, put before him by the Barons of England, King John agreed in Clause 35 \"There shall be one measure of wine throughout our whole realm, and one measure of ale and one measure of corn—namely, the London quart;—and one width of dyed and russet and hauberk cloths—namely, two ells below the selvage...\"\n\nAs of the 21st Century, multiple unit systems are used all over the world such as the United States Customary System, the British Customary System, and the International System. However, the United States is the only industrialized country that has not yet completely converted to the Metric System. The systematic effort to develop a universally acceptable system of units dates back to 1790 when the French National Assembly charged the French Academy of Sciences to come up such a unit system. This system was the precursor to the metric system which was quickly developed in France but did not take on universal acceptance until 1875 when The Metric Convention Treaty was signed by 17 nations. After this treaty was signed, a General Conference of Weights and Measures (CGPM) was established. The CGPM produced the current SI system which was adopted in 1954 at the 10th conference of weights and measures. Currently, the United States is a dual-system society which uses both the SI system and the US Customary system.\n\nHistorically many of the systems of measurement which had been in use were to some extent based on the dimensions of the human body. As a result, units of measure could vary not only from location to location, but from person to person.\n\nMetric systems of units have evolved since the adoption of the original metric system in France in 1791. The current international standard metric system is the International System of Units (abbreviated to SI). An important feature of modern systems is standardization. Each unit has a universally recognized size.\nBoth the imperial units and US customary units derive from earlier English units. Imperial units were mostly used in the British Commonwealth and the former British Empire. US customary units are still the main system of measurement used in the United States despite Congress having legally authorised metric measure on 28 July 1866. Some steps towards US metrication have been made, particularly the redefinition of basic US and imperial units to derive exactly from SI units. Since the international yard and pound agreement of 1959 the US and imperial inch is now defined as exactly , and the US and imperial avoirdupois pound is now defined as exactly .\n\nWhile the above systems of units are based on arbitrary unit values, formalised as standards, some unit values occur naturally in science. Systems of units based on these are called natural units. Similar to natural units, atomic units (au) are a convenient system of units of measurement used in atomic physics.\n\nAlso a great number of unusual and non-standard units may be encountered. These may include the solar mass (), the megaton (the energy released by detonating one million tons of trinitrotoluene, TNT) and the electronvolt.\n\nTo reduce the incidence of retail fraud, many national statutes have standard definitions of weights and measures that may be used (hence \"statute measure\"), and these are verified by legal officers.\n\nIn informal settings, a quantity may be described as multiples of that of a familiar entity, which can be easier to contextualise than a value in a formal unit system. For instance, a publication may describe an area in a foreign country as a number of multiples of the area of a region local to the readership. The propensity for certain concepts to be used frequently can give rise to loosely defined \"systems\" of units.\n\nDifferent systems of units are based on different choices of a set of base units.\nThe most widely used system of units is the International System of Units, or SI. There are seven SI base units. All other SI units can be derived from these base units.\n\nFor most quantities a unit is necessary to communicate values of that physical quantity. For example, conveying to someone a particular length without using some sort of unit is impossible, because a length cannot be described without a reference used to make sense of the value given.\n\nBut not all quantities require a unit of their own. Using physical laws, units of quantities can be expressed as combinations of units of other quantities. Thus only a small set of units is required. These units are taken as the \"base units\". Other units are \"derived units\". Derived units are a matter of convenience, as they can be expressed in terms of basic units. Which units are considered base units is a matter of choice.\n\nThe base units of SI are actually not the smallest set possible. Smaller sets have been defined. For example, there are unit sets in which the electric and magnetic field have the same unit. This is based on physical laws that show that electric and magnetic field are actually different manifestations of the same phenomenon.\n\nAny value of a physical quantity is expressed as a comparison to a unit of that quantity. For example, the value of a physical quantity \"Z\" is expressed as the product of a unit [Z] and a numerical factor:\n\nThe multiplication sign is usually left out, just as it is left out between variables in scientific notation of formulas. The conventions used to express quantities is referred to as quantity calculus. In formulas the unit [Z] can be treated as if it were a specific magnitude of a kind of physical dimension: see dimensional analysis for more on this treatment.\n\nUnits can only be added or subtracted if they are the same type; however units can always be multiplied or divided, as George Gamow used to explain. Let formula_4 be \"2 candlesticks\" and formula_5 \"3 cabdrivers\", then\n\nA distinction should be made between units and standards. A unit is fixed by its definition, and is independent of physical conditions such as temperature. By contrast, a standard is a physical realization of a unit, and realizes that unit only under certain physical conditions. For example, the metre is a unit, while a metal bar is a standard. One metre is the same length regardless of temperature, but a metal bar will be exactly one metre long only at a certain temperature.\n\nThere are certain rules that have to be used when dealing with units:\n\n\nConversion of units involves comparison of different standard physical values, either of a single physical quantity or of a physical quantity and a combination of other physical quantities.\n\nStarting with:\n\njust replace the original unit formula_9 with its meaning in terms of the desired unit formula_10, e.g. if formula_11, then:\n\nNow formula_13 and formula_14 are both numerical values, so just calculate their product.\n\nOr, which is just mathematically the same thing, multiply \"Z\" by unity, the product is still \"Z\":\n\nFor example, you have an expression for a physical value \"Z\" involving the unit \"feet per second\" (formula_9) and you want it in terms of the unit \"miles per hour\" (formula_10):\n\nOr as an example using the metric system, you have a value of fuel economy in the unit \"litres per 100 kilometres\" and you want it in terms of the unit \"microlitres per metre\":\n\nOne example of the importance of agreed units is the failure of the NASA Mars Climate Orbiter, which was accidentally destroyed on a mission to Mars in September 1999 instead of entering orbit due to miscommunications about the value of forces: different computer programs used different units of measurement (newton versus pound force). Considerable amounts of effort, time, and money were wasted.\n\nOn 15 April 1999, Korean Air cargo flight 6316 from Shanghai to Seoul was lost due to the crew confusing tower instructions (in metres) and altimeter readings (in feet). Three crew and five people on the ground were killed. Thirty-seven were injured.\n\nIn 1983, a Boeing 767 (which thanks to its pilot's gliding skills landed safely and became known as the Gimli Glider) ran out of fuel in mid-flight because of two mistakes in figuring the fuel supply of Air Canada's first aircraft to use metric measurements. This accident was the result of both confusion due to the simultaneous use of metric and Imperial measures and confusion of mass and volume measures.\n\n\n\n\n\n\n"}
{"id": "14337857", "url": "https://en.wikipedia.org/wiki?curid=14337857", "title": "Urgent computing", "text": "Urgent computing\n\nUrgent computing is prioritized and immediate access on supercomputers and grids for emergency computations such as severe weather prediction during matters of immediate concern. \n\nApplications that provide decision makers with information during critical emergencies cannot waste time waiting in job queues and need access to computational resources as soon as possible.\n"}
{"id": "273381", "url": "https://en.wikipedia.org/wiki?curid=273381", "title": "Violent crime", "text": "Violent crime\n\nA violent crime or crime of violence is a crime in which an offender or perpetrator uses or threatens to use force upon a victim. This entails both crimes in which the violent act is the objective, such as murder or rape, as well as crimes in which violence is the means to an end. Violent crimes may, or may not, be committed with weapons. Depending on the jurisdiction, violent crimes may vary from homicide to harassment. Typically, violent criminals includes aircraft hijackers, bank robbers, muggers, burglars, terrorists, carjackers, rapists, kidnappers, torturers, active shooters, murderers, gangsters, drug cartels, and others.\n\nThe comparison of violent crime statistics between countries is usually problematic, due to the way different countries classify crime. Valid comparisons require that similar offences between jurisdictions be compared. Often this is not possible, because crime statistics aggregate equivalent offences in such different ways that make it difficult or impossible to obtain a valid comparison. Depending on the jurisdiction, violent crimes may include: homicide, murder, assault, manslaughter, sexual assault, rape, robbery, negligence, endangerment, kidnapping (abduction), extortion, and harassment. Different countries also have different systems of recording and reporting crimes.\n\nThe first annual national survey of crime victimization in Australia, the Crime Victimisation Survey, was conducted in 2008-09. Personal crimes included in the survey are: \n\nIn 2009, the Australian Standard Offence Classification (ASOC), which had no single category for violent crime, was replaced by the Australian and New Zealand Standard Offence Classification (ANZSOC). The ANZSOC also has no single category for violent crime, but the first 6 of its divisions involve offenses committed against a person: \n\nCanada conducts an annual measure of crime incidences called the Uniform Crime Reporting Survey (UCR). UCR \"Violent \"Criminal Code\"\" violations include: homicide, attempted murder, sexual assault, assault, robbery, criminal harassment, uttering threats, and other violent violations. Canada also collects information on crime victimization every five years via its General Social Survey on Victimisation (GSS). Among the eight GSS crimes tracked are three violent crimes: sexual assault, robbery, and physical assault.\n\nNew Zealand's crime statistics has a category for violence that includes homicides, kidnapping, abduction, robbery, assaults, intimidation, threats, and group assembly, while all sexual offences are shown in a separate category from violence.\n\nAustria, Czech Republic, Finland, Germany, England, Latvia, Netherlands, Portugal, Greece and Sweden count minor violence like slapping another person as assault. An example is the case of Ilias Kasidiaris in 2012. Kasidaris, then spokesperson for Greece's far-right Golden Dawn party, slapped a left-wing female opponent in the face during a live televised debate. He was subsequently wanted by Greek prosecutors for assault and faced an arrest warrant.\n\nFrance does not count minor violence like slapping somebody as assault.\n\nThe United Kingdom includes all violence against the person, sexual offences, as violent crime. Today violent crimes are considered the most heinous whereas historically, according to Simon Dedo, crimes against property were equally important. Rates of violent crime in the UK are recorded by the British Crime Survey. For the 2010/2011 report on crime in England and Wales, the statistics show that violent crime continues a general downward trend observed over the last few decades as shown in the graph. \"The 2010/11 BCS showed overall violence was down 47 per cent on the level seen at its peak in 1995; representing nearly two million fewer violent offences per year.\" In 2010/11, 31 people per 1000 interviewed reported being a victim of violent crime in the 12 preceding months. Regarding murder, \"increasing levels of homicide (at around 2% to 3% per year) [have been observed] from the 1960s through to the end of the twentieth century\". Recently the murder rate has declined, \"a fall of 19 per cent in homicides since 2001/02\", as measured by The Homicide Index.\n\nThere are two main crime databases maintained by the United States Department of Justice (DOJ): the Bureau of Justice Statistics' National Crime Victimization Survey (NCVS) and the Federal Bureau of Investigation's Uniform Crime Report (UCR). Non-fatal violence is reported in the NCVS, which measures rape and sexual assault, robbery, and aggravated and simple assault reported by households surveyed by the U.S. Census Bureau. The UCR tracks similar non-fatal violence, plus murder and non-negligent manslaughter recorded by law enforcement.\n\nThere are significant methodological and definitional differences between the NCVS and UCR:\nSince they use different methodologies and measure overlapping, but not identical, crimes, the data are complementary and not necessarily congruent.\n\nIn October 2013, the Bureau of Justice Statistics (BJS) reported that violent crime (rape or sexual assault, robbery, aggravated and simple assault) rates for U.S. residents aged 12 and older increased in 2012 for the second consecutive year. The overall rate rose from 22.6 victimizations per 1,000 persons in 2011 to 26.1 in 2012. Most of the increase was in simple assaults. From 1993 to 2012, overall violent victimization declined by two-thirds, from a rate of 79.8 per 1,000 to 26.1 per 1,000.\n\nIn 2011, the UCR violent crime rate had dropped to 386.3 cases per 100,000 persons, compared to 729.6 per 100,000 in 1990.\n\nU.S. homicide data is also available in the National Vital Statistics System (NVSS).\n\n\n"}
{"id": "44201934", "url": "https://en.wikipedia.org/wiki?curid=44201934", "title": "West Africa Network for Peacebuilding", "text": "West Africa Network for Peacebuilding\n\nThe West Africa Network for Peacebuilding The West Africa Network for Peacebuilding (WANEP) is a leading Regional Peacebuilding organisation founded in 1998 in response to civil wars that plagued West Africa in the 1990s. Over the years, WANEP has succeeded in establishing strong national networks in every Member State of ECOWAS with over 550 member organisations across West Africa. WANEP places special focus on collaborative approaches to conflict prevention, and peacebuilding, working with diverse actors from civil society, governments, intergovernmental bodies, women groups and other partners in a bid to establish a platform for dialogue, experience sharing and learning, thereby complementing efforts at ensuring sustainable peace and development in West Africa and beyond.\n\nWANEP was founded by two distinguished Africans; Samuel Gbaydee Doe and Emmanuel Habuka Bombande. Sam Gbadyee Doe is a peacebuilding and development professional from Liberia. He began his academic career from the University of Liberia where he studied Economics with the intention of being a banker and later proceeded to the Eastern Mennonite University for his MA in conflict transformation and Bradford University in the U.K. for a PhD. It was at EMU that the dream for the establishment of WANEP began when his paths crossed with John Paul Lederach and Emmanuel Bombande.\n\nMr. Emmanuel Habuka Bombande is a Ghanaian National Peacebuilding Practitioner with proven expertise in conflict transformation, peacebuilding, and development. After his social science degree from the Kwame Nkrumah University of Science and Technology-Kumasi Ghana, Mr. Bombande proceeded to the Eastern Mennonite University, USA for a master's degree in Conflict Transformation. It was there he met Sam Doe leading to the birth of WANEP.\n\nThe story of WANEP cannot be completely told without mentioning the invaluable contributions of Professor John Paul Lederach especially during the formation and nurturing stages of the institution which he described as …”Beginning of a new era of peace, healing, reconciliation and hope in West Africa.” He was instrumental to bringing together and mentoring the two co-founders of WANEP.\n\nBased on Sam Doe's background in working with trauma during the Second Liberian Civil War, and in establishing youth dialogue organizations and Bombande’s efforts with Hizkias Assefa at the Nairobi Peace Initiative in resolving the Kokomba-Nanumba conflict in northern Ghana, WANEP focused on both lessening existing conflicts and preventing future outbreaks. By directing efforts toward grassroots efforts the organization helped local leaders and citizens resolve conflicts without outside intervention.\n\nSamuel Gbaydee Doe served as the executive director of WANEP from its formation in 1998 until 2004. In 2004, then director of programs, Emmanuel Bombande was appointed executive director. In 2015,Dr. Chukwuemeka Eze, formerly the Program Director\ntook over from Bombande as the Executive Director while Levinia Addae-Mensah is the Deputy Executive Director/Program Director.\n\nWANEP has a niche in training CSOs, government and other practitioners in peacebuilding and conflict prevention. This niche has worked well in supporting peace and averting conflict in many situations. WANEP implements programs to equip the youth, business owners, women, traditional leaders and state agencies with requisite skills in conflict prevention and supports them to find local solutions or interventions to their unique conflict situations.WANEP emphasizes ownership and bottom-up approach to peacebuilding practice which enables the National Networks to carry out interventions that reflect the peculiarities of human security issues in their various countries. The national networks represent the WANEP brand and work in member states while the Regional Secretariat engages at the strategic level with ECOWAS, AU, UN and other intergovernmental, governmental and non-governmental organizations.\n\nWANEP's key area of focus includes but not limited to the following;\n\nUnder the WIPNET program, WANEP facilitated the Liberian Women Mass action for Peace initiated by Liberian Women in 2003. The women peace activism’s intervention in Liberia under the WIPNET program, led to the eventual ceasefire in the Liberian war. The outcome of the Liberian peace process and the role of WIPNET have been acknowledged all over the world and led to the Nobel Peace Prize awarded to Her Excellency Ellen Johnson and Lemay Gbowe (WANEP Liberia former Coordinator for the WIPNET program). The mass action for peace is credited with urging Charles Taylor’s government and the Liberians for Reconciliation and Democracy (LURD) into a ceasefire and leading to the end of the conflict. WANEP also facilitated the creation of ‘Peace Hut’ in Liberia to facilitate the reconciliation process and provide environment for victims to meet and reconcile with offenders. This concept was replicated in Cote d'Ivoire.\n\nPresident Ellen Johnson Sirleaf has cited WIPNET as being one of the key factors supporting women’s prominent role in peace building in Liberia.\nIn 2015, WANEP signed an MOU with the African Union Commission to provide support to the Commission’s Peace and Security Department in the implementation of the AU Peace and Security Architecture (APSA) including the gender mainstreaming of the architecture.\n\nThe work of WANEP in establishing an early warning system has been instrumental in helping to resolve multiple conflicts in early stages. In 2014 this effort was officially recognized by Cote d’Ivoire’s permanent representative to the United Nations Youssoufou Bamba in his official remarks at the Informal interactive Dialogue on the Responsibility to Protect: \"Fulfilling our collective responsibility: International assistance and the responsibility to protect,\", September 8, 2014.\n\nWANEP experience in peacebuilding has been sought for replication in East and Central Africa. The unique structure of WANEP contributed to WANEP’s choice as the Civil Society implementing partner for the operationalization of ECOWAS Early Warning Mechanism (ECOWARN).\n\nA cet égard, permettez-moi de relever le travail remarquable que fait la section ivoirienne de la West Africa Network for Peacebuilding, la WANEP-CI, qui a mis en place une système indépendant d'alerte précoce, notamment par la diffusion de rapports mensuels de la collection d'informations, relatives à la sécurité humaine, et qui vise bien entendu, à soutenir les actions de prévention des conflits, et de promotion de la paix en Côte d'ivoire.\n\nIn September 2013 WANEP was also recognized for their work with ECOWAS to promote peace education in selected secondary schools across the region. [These studies] will impart new ways of thinking and new way of viewing conflict thereby leading to building new structures and cultural practices in the society that deepens peaceful coexistence.\n\nECOWAS/WANEP relationship was the first example of civil society and intergovernmental partnership not only in West Africa but Africa generally. The partnership has been highlighted as the best practice of building alliances with CSOs in conflict prevention and is a referral point \n<www.wanep.org/resource page>\n\nThe organization works with several regional partners including the Economic Community of West African States, the African Union’s Economic, Social, and Cultural Council ECOSOCC, and the United Nations Economic and Social Council(ECOSOC). WANEP is also a member of the Peace and Security cluster of ECOSOCC representing West Africa, and is the West Africa Regional Representative of the Global Partnership for the Prevention of Armed Conflict (GPPAC)and the Focal Point for Africa CSOs on the AU-EU Joint Strategy (JAES).\n\nIn 2002, WANEP entered into a historic partnership with the Economic Community of West African States (ECOWAS) in the implementation of a regional early warning and response system referred to as ECOWARN. In 2004, WANEP and ECOWAS signed a Memorandum of Understanding (MOU) which has consistently been renewed. this inter-governmental structure acts as a regional early warning and response system. WANEP and ECOWAS partnership enables typically non-governmental organizations a path to Track 1 diplomacy efforts early on in conflicts.\n\nInspired by its desire to contribute and commit to the sustenance of peace during elections, WANEP in collaboration with United States Agency for International Development (USAID) is implementing a five-year project (2015 to 2019) tagged, “Mitigating Election Violence in West Africa through National Early Warning Systems (NEWS)” in target countries of West Africa namely, Burkina Faso, Cote d’Ivoire, Niger, Ghana and Sierra Leone. Through this project, WANEP set up and operationalized an Election Situation Room (ESR) during elections in those countries. WANEP also partnered with other key stakeholders to run ESR in countries such as Benin, The Gambia and Nigeria.\n\nWANEP is working in partnership with the Kofi Annan International Peacekeeping Training Centre (KAIPTC) in Accra, Ghana to run the West Africa Peacebuilding Institute (WAPI)\n\nWANEP Publications and Reports (www.wanep.org/resource page)\n"}
{"id": "25644349", "url": "https://en.wikipedia.org/wiki?curid=25644349", "title": "William Harris (civil rights leader)", "text": "William Harris (civil rights leader)\n\nWilliam Harris (1867–1931) was an early Western Australian leader for Aboriginal civil rights.\n\n1867 - Born in Western Australia, he received a rudimentary education as a private pupil at the Swan Native and Half-Caste Mission, before educating himself to a considerable extent.\n\n1904 – While working at the ports and on stations in the Ashburton and Gascoyne districts of Western Australia, Harris witnessed the brutish and cruel practices used to oppress, disenfranchise and subjugate the local Aboriginal people. After \"The Times\" (London) and the Australia press published an account of the ill-treatment of Aboriginal people in the Nor’-West of the State, Harris entered public debate about the issue with a letter to the press accusing the Colonial Secretary, Walter Kingsmill of willful hypocrisy and misrepresentation. Kingsmill had vehemently denied there was any evidence of the ill-treatment of Aboriginal people. Harris also criticized the Chief Protector of Aborigines for Western Australia, Henry Charles Prinsep for turning Aboriginal people off their land.\n\nAt the time the State Registrar-General, Malcolm A.C. Fraser had Harris in mind for a temporary position with the State Government to compile the vocabulary and descriptions of Aboriginal customs from different portions of the State together for posterity. Within weeks of the publication of Harris’s letter Malcolm Fraser appointed journalist Mrs Daisy Bates to the position.\n\n1906 – While prospecting in the Eastern Goldfields of Western Australia, Harris observed extensive starvation and disease among the local Aboriginal population. Harris was so concerned by what he witnessed that he traveled to Perth and on February 8, 1906, Harris and the Goldfields MP, Patrick Lynch M.L.A. met with the State Premier, Mr C.H. Rason. Harris explained that the Aboriginal people living on the eastern goldfields were in desperate need of food and medicine and handed Premier Rason a letter signed by the local Justices of the Peace lending their support. Harris also had a meeting with the Chief Protector of Aborigines, Mr Prinsep in an effort to persuade the Aborigines Department to supply rations, clothes and medicine to those starving and diseased.\n\n1921 - When Mrs Daisy Bates began making national headlines with sensational stories accusing the Aboriginal people of cannibalism, William Harris was one of very few who contested her allegations. In her rejoinder to a published letter by Harris disputing her views, she wrote, ‘the only good half-caste is a dead one. William Harris reproached her comment as “a stigma on a small class of people whose position in the community was an unenviable one”.\n\n1926 – Alarmed at the persecution inflicted upon Aboriginal people by the West Australian Aborigines Department and its officials, he voiced the intention to form the Native Union of Western Australia. Harris was particularly concerned about conditions at Mogumber (Moore River Native Settlement) after the Chief Protector of Aborigines A. O. Neville changed the settlements purpose from an Aboriginal farming community to an internment camp.\n\n1928 – In March 1928 William Harris headed the first Aboriginal deputation to meet with a West Australian Premier Philip Collier. Wilfred Morrison, Edward Jacobs, Arthur Kickett, William Bodney, William Harris, his brother Edward and his nephew Norman Harris met with the Premier for an hour and half. They asked the Premier to repeal the Aborigines Act 1905 and give Aboriginal people the same rights at the white community. Describing the conditions at Mogumber as intolerable, they implored him to close it down. Because Aboriginal people were prohibited from entering central Perth, throughout the meeting they referred to Perth as ‘white city’. William Harris also told Premier Collier that Mrs Daisy Bates and Chief Protector Neville were the worst enemies of the Aboriginal people.\n\n1930 - William Harris moved to the town of Geraldton where he died on 13 July 1931 and is buried in the Aboriginal cemetery at Utacarra, Geraldton.\n\nThe Aborigines Act 1905, continued to govern the lives of all Aboriginal people in Western Australia until it was repealed by the Native Welfare Act 1963. Mogumber (Moore River Native Settlement) continued as a segregation facility until 1974.\n"}
