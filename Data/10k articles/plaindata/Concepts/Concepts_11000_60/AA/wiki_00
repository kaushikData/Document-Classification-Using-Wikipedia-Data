{"id": "2784", "url": "https://en.wikipedia.org/wiki?curid=2784", "title": "Ahimsa", "text": "Ahimsa\n\nAhimsa (Sanskrit: अहिंसा IAST: ', Pāli: ') means 'not to injure' and 'compassion' and refers to a key virtue in Indian religions. The word is derived from the Sanskrit root \"hiṃs\" – to strike; \"hiṃsā\" is injury or harm, \"a-hiṃsā\" is the opposite of this, i.e. cause no injury, do no harm. Ahimsa is also referred to as nonviolence, and it applies to all living beings—including all animals—in ancient Indian religions.\n\nAhimsa is one of the cardinal virtues and an important tenet of Jainism, Hinduism, and Buddhism. Ahimsa is a multidimensional concept, inspired by the premise that all living beings have the spark of the divine spiritual energy; therefore, to hurt another being is to hurt oneself. Ahimsa has also been related to the notion that any violence has karmic consequences. While ancient scholars of Hinduism pioneered and over time perfected the principles of Ahimsa, the concept reached an extraordinary status in the ethical philosophy of Jainism. Most popularly, Mahatma Gandhi strongly believed in the principle of \"ahimsa\".\n\nAhimsa's precept of 'cause no injury' includes one's deeds, words, and thoughts. Classical literature of Hinduism such as Mahabharata and Ramayana, as well as modern scholars debate principles of Ahimsa when one is faced with war and situations requiring self-defence. The historic literature from India and modern discussions have contributed to theories of Just War, and theories of appropriate self-defence.\n\nThe word \"Ahimsa\"—sometimes spelled as \"Ahinsa\"—is derived from the Sanskrit root \"hiṃs\" – to strike; \"hiṃsā\" is injury or harm, \"a-hiṃsā\" is the opposite of this, i.e. \"non harming\" or \"nonviolence\".\n\nNonviolence or \"Ahimsa\" is one of the cardinal virtues and an important tenet of Jainism, Hinduism, and Buddhism. It is a multidimensional concept, inspired by the premise that all living beings have the spark of the divine spiritual energy; therefore, to hurt another being is to hurt oneself. It has also been related to the notion that any violence has karmic consequences. While ancient scholars of Hinduism pioneered and over time perfected the principles of \"Ahimsa\", the concept reached an extraordinary status in the ethical philosophy of Jainism.\n\nParsvanatha, the twenty-third \"tirthankara\" of Jainism, revived, advocated for and preached the concept of nonviolence in around eighth-century BC. Mahavira, the twenty-fourth and the last \"tirthankara\" further strengthened the idea in sixth-century BC; which was believed to be founded by the first tirthankara Rushabhdev over a million years ago.\n\nAhimsa as an ethical concept evolved in Vedic texts. The oldest scripts indirectly mention Ahimsa, but do not emphasise it. Over time, the Hindu scripts revise ritual practices and the concept of Ahimsa is increasingly refined and emphasised, ultimately Ahimsa becomes the highest virtue by the late Vedic era (about 500 BC). For example, hymn 10.22.25 in the Rig Veda uses the words Satya (truthfulness) and Ahimsa in a prayer to deity Indra; later, the Yajur Veda dated to be between 1000 BC and 600 BC, states, \"may all beings look at me with a friendly eye, may I do likewise, and may we look at each other with the eyes of a friend\".\n\nThe term \"Ahimsa\" appears in the text Taittiriya Shakha of the Yajurveda (TS 5.2.8.7), where it refers to non-injury to the sacrificer himself. It occurs several times in the \"Shatapatha Brahmana\" in the sense of \"non-injury\". The Ahimsa doctrine is a late Vedic era development in Brahmanical culture. The earliest reference to the idea of non-violence to animals (\"pashu-Ahimsa\"), apparently in a moral sense, is in the Kapisthala Katha Samhita of the Yajurveda (KapS 31.11), which may have been written in about the 8th century BCE.\n\nBowker states the word appears but is uncommon in the principal Upanishads. Kaneda gives examples of the word \"Ahimsa\" in these Upanishads. Other scholars suggest \"Ahimsa\" as an ethical concept that started evolving in the Vedas, becoming an increasingly central concept in Upanishads.\n\nThe Chāndogya Upaniṣad, dated to the 8th or 7th century BCE, one of the oldest Upanishads, has the earliest evidence for the Vedic era use of the word \"Ahimsa\" in the sense familiar in Hinduism (a code of conduct). It bars violence against \"all creatures\" (\"sarvabhuta\") and the practitioner of Ahimsa is said to escape from the cycle of rebirths (CU 8.15.1). Some scholars state that this 8th or 7th-century BCE mention may have been an influence of Jainism on Vedic Hinduism. Others scholar state that this relationship is speculative, and though Jainism is an ancient tradition the oldest traceable texts of Jainism tradition are from many centuries after the Vedic era ended.\n\nChāndogya Upaniṣad also names Ahimsa, along with Satyavacanam (truthfulness), Arjavam (sincerity), Danam (charity), Tapo (penance/meditation), as one of five essential virtues (CU 3.17.4).\n\nThe Sandilya Upanishad lists ten forbearances: \"Ahimsa\", \"Satya\", \"Asteya\", \"Brahmacharya\", \"Daya\", \"Arjava\", \"Kshama\", \"Dhriti\", \"Mitahara\" and \"Saucha\". According to Kaneda, the term Ahimsa is an important spiritual doctrine shared by Hinduism, Buddhism and Jainism. It literally means 'non-injury' and 'non-killing'. It implies the total avoidance of harming of any kind of living creatures not only by deeds, but also by words and in thoughts.\n\nThe Mahabharata, one of the epics of Hinduism, has multiple mentions of the phrase \"Ahimsa Paramo Dharma\" (अहिंसा परमॊ धर्मः), which literally means: non-violence is the highest moral virtue. For example, Mahaprasthanika Parva has the verse:\n<poem>\nअहिंसा परमॊ धर्मस तथाहिंसा परॊ दमः।\nअहिंसा परमं दानम अहिंसा परमस तपः।\nअहिंसा परमॊ यज्ञस तथाहिस्मा परं बलम।\nअहिंसा परमं मित्रम अहिंसा परमं सुखम।\nअहिंसा परमं सत्यम अहिंसा परमं शरुतम॥\n</poem>\nThe above passage from Mahabharata emphasises the cardinal importance of Ahimsa in Hinduism, and literally means:\n<poem>\nAhimsa is the highest virtue, Ahimsa is the highest self-control, \nAhimsa is the greatest gift, Ahimsa is the best suffering, \nAhimsa is the highest sacrifice, Ahimsa is the finest strength, \nAhimsa is the greatest friend, Ahimsa is the greatest happiness, \nAhimsa is the highest truth, and Ahimsa is the greatest teaching.\n</poem>\nSome other examples where the phrase \"Ahimsa Paramo Dharma\" are discussed include Adi Parva, Vana Parva and Anushasana Parva. The Bhagavad Gita, among other things, discusses the doubts and questions about appropriate response when one faces systematic violence or war. These verses develop the concepts of lawful violence in self-defence and the theories of just war. However, there is no consensus on this interpretation. Gandhi, for example, considers this debate about non-violence and lawful violence as a mere metaphor for the internal war within each human being, when he or she faces moral questions.\n\nThe classical texts of Hinduism devote numerous chapters discussing what people who practice the virtue of Ahimsa, can and must do when they are faced with war, violent threat or need to sentence someone convicted of a crime. These discussions have led to theories of just war, theories of reasonable self-defence and theories of proportionate punishment. Arthashastra discusses, among other things, why and what constitutes proportionate response and punishment.\n\nThe precepts of Ahimsa under Hinduism require that war must be avoided, with sincere and truthful dialogue. Force must be the last resort. If war becomes necessary, its cause must be just, its purpose virtuous, its objective to restrain the wicked, its aim peace, its method lawful. War can only be started and stopped by a legitimate authority. Weapons used must be proportionate to the opponent and the aim of war, not indiscriminate tools of destruction. All strategies and weapons used in the war must be to defeat the opponent, not designed to cause misery to the opponent; for example, use of arrows is allowed, but use of arrows smeared with painful poison is not allowed. Warriors must use judgment in the battlefield. Cruelty to the opponent during war is forbidden. Wounded, unarmed opponent warriors must not be attacked or killed, they must be brought to your realm and given medical treatment. Children, women and civilians must not be injured. While the war is in progress, sincere dialogue for peace must continue.\n\nIn matters of self-defence, different interpretations of ancient Hindu texts have been offered. For example, Tähtinen suggests self-defence is appropriate, criminals are not protected by the rule of Ahimsa, and Hindu scriptures support the use of violence against an armed attacker. Ahimsa is not meant to imply pacifism.\n\nAlternate theories of self-defence, inspired by Ahimsa, build principles similar to theories of just war. Aikido, pioneered in Japan, illustrates one such principles of self-defence. Morihei Ueshiba, the founder of Aikido, described his inspiration as Ahimsa. According to this interpretation of Ahimsa in self-defence, one must not assume that the world is free of aggression. One must presume that some people will, out of ignorance, error or fear, attack other persons or intrude into their space, physically or verbally. The aim of self-defence, suggested Ueshiba, must be to neutralise the aggression of the attacker, and avoid the conflict. The best defence is one where the victim is protected, as well as the attacker is respected and not injured if possible. Under Ahimsa and Aikido, there are no enemies, and appropriate self-defence focuses on neutralising the immaturity, assumptions and aggressive strivings of the attacker.\n\nTähtinen concludes that Hindus have no misgivings about death penalty; their position is that evil-doers who deserve death should be killed, and that a king in particular is obliged to punish criminals and should not hesitate to kill them, even if they happen to be his own brothers and sons.\n\nOther scholars conclude that the scriptures of Hinduism suggest sentences for any crime must be fair, proportional and not cruel.\n\nThere is no consensus on pacifism among modern Hindu scholars. The conflict between pacifistic interpretations of Ahimsa and the theories of just war prescribed by the Gita has been resolved by some scholars such as Mohandas Karamchand Gandhi, as being an allegory, wherein the battlefield is the soul and Arjuna, the war is within each human being, where human's higher impulses struggle against his own evil impulses.\n\nThe Hindu precept of 'cause no injury' applies to animals and all life forms. This precept isn't found in the oldest verses of Vedas, but increasingly becomes one of the central ideas between 500 BC and 400 AD. In the oldest texts, numerous ritual sacrifices of animals, including cows and horses, are highlighted and hardly any mention is made of Ahimsa to non-human life.\n\nHindu texts dated to 1st millennium BC, initially mention meat as food, then evolve to suggestions that only meat obtained through ritual sacrifice can be eaten, thereafter evolving to the stance that one should eat no meat because it hurts animals, with verses describing the noble life as one that lives on flowers, roots and fruits alone.\n\nLater texts of Hinduism declare Ahimsa one of the primary virtues, declare any killing or harming any life as against \"dharma\" (moral life). Finally, the discussion in Upanishads and Hindu Epics shifts to whether a human being can ever live his or her life without harming animal and plant life in some way; which and when plants or animal meat may be eaten, whether violence against animals causes human beings to become less compassionate, and if and how one may exert least harm to non-human life consistent with ahimsa precept, given the constraints of life and human needs. The Mahabharata permits hunting by warriors, but opposes it in the case of hermits who must be strictly non-violent. Sushruta Samhita, a Hindu text written in the 3rd or 4th century, in Chapter XLVI suggests proper diet as a means of treating certain illnesses, and recommends various fishes and meats for different ailments and for pregnant women, and the Charaka Samhita describes meat as superior to all other kinds of food for convalescents.\n\nAcross the texts of Hinduism, there is a profusion of ideas about the virtue of Ahimsa when applied to non-human life, but without a universal consensus. Alsdorf claims the debate and disagreements between supporters of vegetarian lifestyle and meat eaters was significant. Even suggested exceptions – ritual slaughter and hunting – were challenged by advocates of Ahimsa. In the Mahabharata both sides present various arguments to substantiate their viewpoints. Moreover, a hunter defends his profession in a long discourse.\n\nMany of the arguments proposed in favor of non-violence to animals refer to the bliss one feels, the rewards it entails before or after death, the danger and harm it prevents, as well as to the karmic consequences of violence.\n\nThe ancient Hindu texts discuss Ahimsa and non-animal life. They discourage wanton destruction of nature including of wild and cultivated plants. Hermits (sannyasins) were urged to live on a fruitarian diet so as to avoid the destruction of plants. Scholars claim the principles of ecological non-violence is innate in the Hindu tradition, and its conceptual fountain has been Ahimsa as their cardinal virtue.\n\nThe classical literature of Hinduism exists in many Indian languages. For example, the \"Tirukkural,\" written between 200 BC and 400 AD, and sometimes called the Tamil Veda, is one of the most cherished classics on Hinduism written in a South Indian language. The Kural dedicates Chapters 26, 32 and 33 of Book I to the virtue of Ahimsa, namely, vegetarianism, non-harming, and non-killing, respectively. The Kural says that Ahimsa applies to all life forms.\n\nIn the 19th and 20th centuries, prominent figures of Indian spirituality such as Shrimad Rajchandraji and Swami Vivekananda emphasised the importance of Ahimsa.\n\nMohandas Karamchand Gandhi promoted the principle of Ahimsa, very successful by applying it to all spheres of life, particularly to politics (Swaraj). His non-violent resistance movement satyagraha had an immense impact on India, impressed public opinion in Western countries, and influenced the leaders of various civil and political rights movements such as the American civil rights movement's Martin Luther King, Jr. and James Bevel. In Gandhi's thought, Ahimsa precludes not only the act of inflicting a physical injury, but also mental states like evil thoughts and hatred, unkind behavior such as harsh words, dishonesty and lying, all of which he saw as manifestations of violence incompatible with Ahimsa. Gandhi believed Ahimsa to be a creative energy force, encompassing all interactions leading one's self to find satya, \"Divine Truth\". Sri Aurobindo criticised the Gandhian concept of Ahimsa as unrealistic and not universally applicable; he adopted a pragmatic non-pacifist position, saying that the justification of violence depends on the specific circumstances of the given situation. \n\nGandhi stated that he viewed \"Ahimsa is in Hinduism, it is in Christianity as well as in Islam.\" He added, \"Nonviolence is common to all religions, but it has found the highest expression and application in Hinduism (I do not regard Jainism or Buddhism as separate from Hinduism).\" When questioned whether violence and non-violence is both taught in Quran, he stated, \"I have heard it from many Muslim friends that the Koran teaches the use of non-violence. (... The) argument about non-violence in the Holy Koran is an interpolation, not necessary for my thesis.\"\n\nA historical and philosophical study of Ahimsa was instrumental in the shaping of Albert Schweitzer's principle of \"reverence for life\". Schweitzer praised Indian philosophical and religious traditions for ethics of Ahimsa as, \"the laying down of the commandment not to kill and not to damage is one of the greatest events in the spiritual history of humankind\", but suggested that \"not-killing and not-harming\" is not always practically possible as in self-defence, nor ethical as in chronic starving during a famine case.\n\nAhimsa is imperative for practitioners of Patañjali's eight limb Raja yoga system. It is included in the first limb and is the first of five Yamas (self restraints) which, together with the second limb, make up the code of ethical conduct in Yoga philosophy. Ahimsa is also one of the ten \"Yamas\" in Hatha Yoga according to verse 1.1.17 of its classic manual \"Hatha Yoga Pradipika\".\nThe significance of Ahimsa as the very first restraint in the very first limb of Yoga (Yamas), is that it defines the necessary foundation for progress through Yoga. It is a precursor to Asana, implying that success in Yogasana can be had only if the self is purified in thought, word and deed through the self-restraint of Ahimsa.\n\nIn Jainism, the understanding and implementation of \"Ahimsā\" is more radical, scrupulous, and comprehensive than in any other religion. Killing any living being out of passions is considered \"hiṃsā\" (to injure) and abstaining from such an act is \"ahimsā\" (noninjury). The vow of ahimsā is considered the foremost among the 'five vows of Jainism'. Other vows like truth (satya) are meant for safeguarding the vow of ahimsā. In the practice of Ahimsa, the requirements are less strict for the lay persons (sravakas) who have undertaken \"anuvrata\" (Smaller Vows) than for the Jain monastics who are bound by the Mahavrata \"Great Vows\". The statement \"\" is often found inscribed on the walls of the Jain temples. Like in Hinduism, the aim is to prevent the accumulation of harmful karma. When Mahavira revived and reorganised the Jain faith in the 6th or 5th century BCE, Ahimsa was already an established, strictly observed rule. Rishabhanatha (Ādinātha), the first Jain Tirthankara, whom modern Western historians consider to be a historical figure, followed by Parshvanatha (Pārśvanātha) the twenty-third Tirthankara lived in about the 8th century BCE. He founded the community to which Mahavira's parents belonged. Ahimsa was already part of the \"Fourfold Restraint\" (\"Caujjama\"), the vows taken by Parshva's followers. In the times of Mahavira and in the following centuries, Jains were at odds with both Buddhists and followers of the Vedic religion or Hindus, whom they accused of negligence and inconsistency in the implementation of Ahimsa. According to the Jain tradition either lacto vegetarianism or veganism is mandatory.\n\nThe Jain concept of Ahimsa is characterised by several aspects. It does not make any exception for ritual sacrificers and professional warrior-hunters. Killing of animals for food is absolutely ruled out. Jains also make considerable efforts not to injure plants in everyday life as far as possible. Though they admit that plants must be destroyed for the sake of food, they accept such violence only inasmuch as it is indispensable for human survival, and there are special instructions for preventing unnecessary violence against plants. Jains go out of their way so as not to hurt even small insects and other minuscule animals. For example, Jains often do not go out at night, when they are more likely to step upon an insect. In their view, injury caused by carelessness is like injury caused by deliberate action. Eating honey is strictly outlawed, as it would amount to violence against the bees. Some Jains abstain from farming because it inevitably entails unintentional killing or injuring of many small animals, such as worms and insects, but agriculture is not forbidden in general and there are Jain farmers.\n\nTheoretically, all life forms are said to deserve full protection from all kinds of injury, but Jains recognise a hierarchy of life. Mobile beings are given higher protection than immobile ones. For the mobile beings, they distinguish between one-sensed, two-sensed, three-sensed, four-sensed and five-sensed ones; a one-sensed animal has touch as its only sensory modality. The more senses a being has, the more they care about non-injuring it. Among the five-sensed beings, the precept of non-injury and non-violence to the rational ones (humans) is strongest in Jain Ahimsa.\n\nIn Jain theology, it does not matter how correct or defensible the violence may be, one must not kill any being, and \"non-violence is one's highest religious duty\".\n\nMahatma Gandhi, who was greatly influenced by Jainism, said:\nIn Buddhist texts \"Ahimsa\" (or its Pāli cognate ) is part of the Five Precepts (), the first of which has been to abstain from killing. This precept of Ahimsa is applicable to both the Buddhist layperson and the monk community.\n\nThe Ahimsa precept is not a commandment and transgressions did not invite religious sanctions for laypersons, but their power has been in the Buddhist belief in karmic consequences and their impact in afterlife during rebirth. Killing, in Buddhist belief, could lead to rebirth in the hellish realm, and for a longer time in more severe conditions if the murder victim was a monk. Saving animals from slaughter for meat is believed to be a way to acquire merit for better rebirth. These moral precepts have been voluntarily self-enforced in lay Buddhist culture through the associated belief in karma and rebirth. The Buddhist texts not only recommended Ahimsa, but suggest avoiding trading goods that contribute to or are a result of violence:\n\nUnlike lay Buddhists, transgressions by monks do invite sanctions. Full expulsion of a monk from \"sangha\" follows instances of killing, just like any other serious offense against the monastic \"nikaya\" code of conduct.\n\nViolent ways of punishing criminals and prisoners of war was not explicitly condemned in Buddhism, but peaceful ways of conflict resolution and punishment with the least amount of injury were encouraged. The early texts condemn the mental states that lead to violent behavior.\n\nNonviolence is an overriding theme within the Pali Canon. While the early texts condemn killing in the strongest terms, and portray the ideal queen/king as a pacifist, such a queen/king is nonetheless flanked by an army. It seems that the Buddha's teaching on nonviolence was not interpreted or put into practice in an uncompromisingly pacifist or anti-military-service way by early Buddhists. The early texts assume war to be a fact of life, and well-skilled warriors are viewed as necessary for defensive warfare. In Pali texts, injunctions to abstain from violence and involvement with military affairs are directed at members of the sangha; later Mahayana texts, which often generalise monastic norms to laity, require this of lay people as well.\n\nThe early texts do not contain just-war ideology as such. Some argue that a sutta in the \"Gamani Samyuttam\" rules out all military service. In this passage, a soldier asks the Buddha if it is true that, as she/he has been told, soldiers slain in battle are reborn in a heavenly realm. The Buddha reluctantly replies that if she/he is killed in battle while her/his mind is seized with the intention to kill, she/he will undergo an unpleasant rebirth. In the early texts, a person's mental state at the time of death is generally viewed as having a great impact on the next birth.\n\nSome Buddhists point to other early texts as justifying defensive war. One example is the \"Kosala Samyutta\", in which King Pasenadi, a righteous king favored by the Buddha, learns of an impending attack on his kingdom. He arms himself in defence, and leads his army into battle to protect his kingdom from attack. He lost this battle but won the war. King Pasenadi eventually defeated King Ajatasattu and captured him alive. He thought that, although this King of Magadha has transgressed against his kingdom, he had not transgressed against him personally, and Ajatasattu was still his nephew. He released Ajatasattu and did not harm him. Upon his return, the Buddha said (among other things) that Pasenadi \"is a friend of virtue, acquainted with virtue, intimate with virtue\", while the opposite is said of the aggressor, King Ajatasattu.\n\nAccording to Theravada commentaries, there are five requisite factors that must all be fulfilled for an act to be both an act of killing and to be karmically negative. These are: (1) the presence of a living being, human or animal; (2) the knowledge that the being is a living being; (3) the intent to kill; (4) the act of killing by some means; and (5) the resulting death. Some Buddhists have argued on this basis that the act of killing is complicated, and its ethicization is predicated upon intent. Some have argued that in defensive postures, for example, the primary intention of a soldier is not to kill, but to defend against aggression, and the act of killing in that situation would have minimal negative karmic repercussions.\n\nAccording to Dr. Babasaheb Ambedkar, there is circumstantial evidence encouraging Ahimsa, from the Buddha's doctrine, \"Love all, so that you may not wish to kill any.\" Gautama Buddha distinguished between a principle and a rule. He did not make Ahimsa a matter of rule, but suggested it as a matter of principle. This gives Buddhists freedom to act.\n\nThe emperors of Sui dynasty, Tang dynasty and early Song dynasty banned killing in Lunar calendar 1st, 5th, and 9th month. Empress Wu Tse-Tien banned killing for more than half a year in 692. Some also banned fishing for some time each year.\n\nThere were bans after death of emperors, Buddhist and Taoist prayers, and natural disasters such as after a drought in 1926 summer Shanghai and an 8 days ban from August 12, 1959, after the August 7 flood (), the last big flood before the 88 Taiwan Flood.\n\nPeople avoid killing during some festivals, like the Taoist Ghost Festival, the Nine Emperor Gods Festival, the Vegetarian Festival and many others.\n\n\n"}
{"id": "31098217", "url": "https://en.wikipedia.org/wiki?curid=31098217", "title": "Akiko Ichikawa", "text": "Akiko Ichikawa\n\nHer article on the photography of Dorothea Lange, Ansel Adams, and Toyo Miyatake at Manzanar for Hyperallergic went viral in fall 2016, following comments by a spokesperson of a Trump-supporting PAC on Fox News.\n\nIchikawa's family emigrated to the US, via San Francisco, when she was three. She grew up with two siblings in the suburbs of Boston and Nashville, and attended Brown University graduating with honors. She moved to New York City four days later entering Hunter College's MFA program 18 months later. She currently lives and works in New York City.\n\nHer concept-based artwork exists in the forms of performance art, installation art and net.art. Her performance works include a series of site-specific gifting performances called \"Limited, Limited Edition\" which she has presented at Socrates Sculpture Park, in Long Island City, Queens; in Jamaica, Queens; at the Incheon Women Artists' Biennale in Incheon, South Korea; at On Stellar Rays gallery in the Lower East Side; in three locations in Newark, New Jersey for Aljira Center for Contemporary Art, in a school yard in East Harlem; on 14th Street as a part of the Art in Odd Places performance festival, and on H Street NE in Washington D.C. For \"Bad Kanji\" (2015), she painted temporary kanji tattoos on viewers at the Spring/Break Art Show, held in the historic office spaces above New York City's James A. Farley Post Office. The work was reviewed favorably.\n\nShe also works as an art historian and has enacted two of Fluxus-member Alison Knowles's event scores, namely \"#5 Wounded Furniture\" and \"#3 Nivea Cream Piece.\" The latter was live-blogged on Hyperallergic and well-received, with Kyle Chayka writing that it was \"definitely among [his] favorites.\" In 2015, Ichikawa wrote about the Japanese American incarceration through the photography of Dorothea Lange, Ansel Adams, and Toyo Miyatake for Hyperallergic went viral, shared over 8,000 times on Facebook. In 2018, she reminded New York art world readers about the \"Golden Venture\" incident, which marked the start of contemporary punitive immigration policies at the presidential level, under President Bill Clinton.\n\nIn the Aughts she created a net.art piece that simulated a series of imagined art installations. Ichikawa has also created a series of Facebook groups around food organized by color, touching upon issues of cultural identity, food sourcing, gentrification, environmental concerns, and greenwashing while sharing nutrition and cost-cutting tips: \"I ♥ Yellow Food,\" \"I ♥ Orange Food,\" \"I ♥ Red Food,\" \"I ♥ Green Food\", and \"I ♥ Blue Food\". While not supportive of Facebook's history of massive online-privacy violations, its carrying the 2016 Republican National Convention, and its other roles in the empowerment of Donald J. Trump's presidential candidacy (along with other mainstream media), the artist nevertheless viewed the social media site as an effective, user-friendly way to include as many participants as possible. She has lately turned to Instagram, owned by Facebook.\n\nIchikawa's art before 2005 was primarily focusseinstallation art, built around the placement and assembly of basic construction materials in gallery spaces. She presented one such installation for her solo exhibition at Momenta Art and another at Andrew Kreps gallery in a group exhibition curated by Dean Daderko (now a curator at the Contemporary Arts Museum Houston). The series evolved into a Net.art piece, \"Where Do We Come From? What Are We? Where Are We Going?\" that is permanently stored on Rhizome.org.\n\nShe has written on contemporary art for \"Flash Art\" on the work of Ken Lum, Laurel Nakadate, Dan Peterson, Yasue Maetake, and, for \"NY Arts\" magazine, the work of Jane and Louise Wilson and for \"Zing Magazine\", the work of Siah Armajani.\n\nIn 2015, she wrote about the photography of Dorothea Lange, Ansel Adams, and Toyo Miyatake and the Japanese American incarceration for Hyperallergic. The article received its biggest spike in interest (about 5,000 more Facebook shares, totaling 8,000) after the spokesman of a Trump-supporting PAC cited the Japanese American incarceration as precedent for a Muslim registry on Fox News in early November 2016. In 2018, she covered the folded paper work of the \"Golden Venture\" migrants held in York, Pennsylvania that was shown at the Museum of Chinese in America, in New York City.\n\nShe has also written about the closing of Tekserve, the performance of a group of young area Native American musicians, and, with Danielle Wu, performance art by young artists of Asian descent in a New York City-based performance art festival. In 2018, she wrote about the paper-folding work of the Golden Venture migrants for Art in America online and served as the social media writer for #callresponse during its New York City exhibition run at EFA Project Space.\n\n\nHer younger sister, Yoko Ichikawa, is an Oakland, California-based part-time graphic designer. Her younger brother, Kenshin Ichikawa, founded and designed Rocksmith streetwear, which has done collaborative lines with the Wu Tang Clan, Malcolm X's daughters, and a music video with Future, among other things. Rocksmith has also been worn by all of the major American hip-hop stars. Yoko is a graduate of Wesleyan University, where she majored in West African dance, Kenshin a graduate of Columbia University. The latter is married to UC Berkeley Food Institute policy director Nina Fallenbaum.\n\n"}
{"id": "25821227", "url": "https://en.wikipedia.org/wiki?curid=25821227", "title": "Candle problem", "text": "Candle problem\n\nThe candle problem or candle task, also known as Duncker's candle problem, is a cognitive performance test, measuring the influence of functional fixedness on a participant's problem solving capabilities. The test was created by Gestalt psychologist Karl Duncker and published posthumously in 1945. Duncker originally presented this test in his thesis on problem-solving tasks at Clark University.\n\nThe test presents the participant with the following task: how to fix and light a candle on a wall (a cork board) in a way so the candle wax won't drip onto the table below. To do so, one may only use the following along with the candle:\n\n\nThe solution is to empty the box of thumbtacks, use the thumbtacks to nail the box to the wall, put the candle into the box, and light the candle with the match. The concept of functional fixedness predicts that the participant will only see the box as a device to hold the thumbtacks and not immediately perceive it as a separate and functional component available to be used in solving the task.\n\nMany of the people who attempted the test explored other creative, but less efficient, methods to achieve the goal. For example, some tried to tack the candle to the wall without using the thumbtack box, and others attempted to melt some of the candle’s wax and use it as an adhesive to stick the candle to the wall. Neither method works. However, if the task is presented with the tacks piled \"next\" to the box (rather than inside it), virtually all of the participants were shown to achieve the optimal solution, which is self defined.\n\nThe test has been given to numerous people, including M.B.A. students at the Kellogg School of Management in a study investigating whether living abroad and creativity are linked.\n\nGlucksberg (1962) used a 2 × 2 design manipulating whether the tacks and matches were inside or outside of their boxes and whether subjects were offered cash prizes for completing the task quickly. Subjects who were offered no prize, termed \"low-drive\", were told \"We are doing pilot work on various problems in order to decide which will be the best ones to use in an experiment we plan to do later. We would like to obtain norms on the time needed to solve.\" The remaining subjects, termed \"high-drive\", were told \"Depending on how quickly you solve the problem you can win $5.00 or $20.00. The top 25% of the \"S\"s [subjects] in your group will win $5.00 each; the best will receive $20.00. Time to solve will be the criterion used.\" (As a note, adjusting for inflation since 1962, the study's publish year, the amounts in dollars would be approximately $ and $, respectively.) The empty-boxes condition was found to be easier than the filled-boxes condition: more subjects solved the problem, and those who did solve the problem solved it faster. Within the filled-boxes condition, high-drive subjects performed \"worse\" than low-drive subjects. Glucksberg interpreted this result in terms of \"neobehavioristic drive theory\": \"high drive prolongs extinction of the dominant habit and thus retards the correct habit from gaining ascendancy\". An explanation in terms of the overjustification effect is made difficult by the lack of a main effect for drive and by a nonsignificant trend in the opposite direction within the empty-boxes condition.\n\nAnother way to explain the higher levels of failure during the high-drive condition is that the process of turning the task into a competition for limited resources can create mild levels of stress in the subject, which can lead to a sympathetic nervous system response known as fight-or-flight. This stress response effectively shuts down the creative thinking and problem solving areas of the brain in the prefrontal cortex.\n\nE. Tory Higgins and W. M. Chaires found that having subjects repeat the names of common pairs of objects in this test, but in a different and unaccustomed linguistic structure, such as \"box \"and\" tacks\" instead of \"box \"of\" tacks\", facilitated performance on the candle problem. This phrasing helps one to distinguish the two entities as different and more accessible.\nIn a written version of the task given to people at Stanford University, Michael C. Frank and language acquisition researcher Michael Ramscar reported that simply underlining certain relevant materials (\"\"on the table there is a candle, a box of tacks, and a book of matches\"...\") increases the number of candle-problem solvers from 25% to 50%.\n"}
{"id": "1409006", "url": "https://en.wikipedia.org/wiki?curid=1409006", "title": "Common knowledge (logic)", "text": "Common knowledge (logic)\n\nCommon knowledge is a special kind of knowledge for a group of agents. There is \"common knowledge\" of \"p\" in a group of agents \"G\" when all the agents in \"G\" know \"p\", they all know that they know \"p\", they all know that they all know that they know \"p\", and so on \"ad infinitum\".\n\nThe concept was first introduced in the philosophical literature by David Kellogg Lewis in his study \"Convention\" (1969). The sociologist Morris Friedell defined common knowledge in a 1969 paper. It was first given a mathematical formulation in a set-theoretical framework by Robert Aumann (1976). Computer scientists grew an interest in the subject of epistemic logic in general – and of common knowledge in particular – starting in the 1980s. There are numerous puzzles based upon the concept which have been extensively investigated by mathematicians such as John Conway.\n\nThe philosopher Stephen Schiffer, in his book \"Meaning\", independently developed a notion he called \"mutual knowledge\" which functions quite similarly to Lewis's \"common knowledge\".\n\nThe idea of common knowledge is often introduced by some variant of the following puzzle:\n\nOn an island, there are \"k\" people who have blue eyes, and the rest of the people have green eyes. At the start of the puzzle, no one on the island ever knows their own eye color. By rule, if a person on the island ever discovers they have blue eyes, that person must leave the island at dawn; anyone not making such a discovery always sleeps until after dawn. On the island, each person knows every other person's eye color, there are no reflective surfaces, and there is no communication of eye color.\n\nAt some point, an outsider comes to the island, calls together all the people on the island, and makes the following public announcement: \"At least one of you has blue eyes\". The outsider, furthermore, is known by all to be truthful, and all know that all know this, and so on: it is common knowledge that he is truthful, and thus it becomes common knowledge that there is at least one islander who has blue eyes. The problem: assuming all persons on the island are completely logical and that this too is common knowledge, what is the eventual outcome?\n\nThe answer is that, on the \"k\"th dawn after the announcement, all the blue-eyed people will leave the island.\n\nThe solution can be seen with an inductive argument. If \"k\" = 1 (that is, there is exactly one blue-eyed person), the person will recognize that they alone have blue eyes (by seeing only green eyes in the others) and leave at the first dawn. If \"k\" = 2, no one will leave at the first dawn. The two blue-eyed people, seeing only one person with blue eyes, \"and\" that no one left on the 1st dawn (and thus that \"k\" > 1), will leave on the second dawn. Inductively, it can be reasoned that no one will leave at the first \"k\" − 1 dawns if and only if there are at least \"k\" blue-eyed people. Those with blue eyes, seeing \"k\" − 1 blue-eyed people among the others and knowing there must be at least \"k\", will reason that they must have blue eyes and leave.\n\nWhat's most interesting about this scenario is that, for \"k\" > 1, the outsider is only telling the island citizens what they already know: that there are blue-eyed people among them. However, before this fact is announced, the fact is not \"common knowledge\".\n\nFor \"k\" = 2, it is merely \"first-order\" knowledge. Each blue-eyed person knows that there is someone with blue eyes, but each blue eyed person does \"not\" know that the other blue-eyed person has this same knowledge.\n\nFor \"k\" = 3, it is \"second order\" knowledge. Each blue-eyed person knows that a second blue-eyed person knows that a third person has blue eyes, but no one knows that there is a \"third\" blue-eyed person with that knowledge, until the outsider makes his statement.\n\nIn general: For \"k\" > 1, it is \"(\"k\" − 1)th order\" knowledge. Each blue-eyed person knows that a second blue-eyed person knows that a third blue-eyed person knows that... (repeat for a total of \"k\" − 1 levels) a \"k\"th person has blue eyes, but no one knows that there is a \"\"k\"th\" blue-eyed person with that knowledge, until the outsider makes his statement. The notion of \"common knowledge\" therefore has a palpable effect. Knowing that everyone knows does make a difference. When the outsider's public announcement (a fact already known to all) becomes common knowledge, the blue-eyed people on this island eventually deduce their status, and leave.\n\nCommon knowledge can be given a logical definition in multi-modal logic systems in which the modal operators are interpreted epistemically. At the propositional level, such systems are extensions of propositional logic. The extension consists of the introduction of a group \"G\" of \"agents\", and of \"n\" modal operators \"K\" (with \"i\" = 1, ..., \"n\") with the intended meaning that \"agent \"i\" knows.\" Thus \"K formula_1\" (where formula_1 is a formula of the calculus) is read \"agent \"i\" knows formula_1.\" We can define an operator \"E\" with the intended meaning of \"everyone in group \"G\" knows\" by defining it with the axiom\n\nBy abbreviating the expression formula_5 with formula_6 and defining formula_7, we could then define common knowledge with the axiom\n\nThere is however a complication. The languages of epistemic logic are usually \"finitary\", whereas the axiom above defines common knowledge as an infinite conjunction of formulas, hence not a well-formed formula of the language. To overcome this difficulty, a \"fixed-point\" definition of common knowledge can be given. Intuitively, common knowledge is thought of as the fixed point of the \"equation\" formula_9. In this way, it is possible to find a formula formula_10 implying formula_11 from which, in the limit, we can infer common knowledge of formula_1.\n\nThis \"syntactic\" characterization is given semantic content through so-called \"Kripke structures\". A Kripke structure is given by (i) a set of states (or possible worlds) \"S\", (ii) \"n\" \"accessibility relations\" formula_13, defined on formula_14, intuitively representing what states agent \"i\" considers possible from any given state, and (iii) a valuation function formula_15 assigning a truth value, in each state, to each primitive proposition in the language. The semantics for the knowledge operator is given by stipulating that formula_16 is true at state \"s\" iff formula_1 is true at \"all\" states \"t\" such that formula_18. The semantics for the common knowledge operator, then, is given by taking, for each group of agents \"G\", the reflexive and transitive closure of the formula_19, for all agents \"i\" in \"G\", call such a relation formula_20, and stipulating that formula_21 is true at state \"s\" iff formula_1 is true at \"all\" states \"t\" such that formula_23.\n\nAlternatively (yet equivalently) common knowledge can be formalized using set theory (this was the path taken by the Nobel laureate Robert Aumann in his seminal 1976 paper). We will start with a set of states \"S\". We can then define an event \"E\" as a subset of the set of states \"S\". For each agent \"i\", define a partition on \"S\", \"P\". This partition represents the state of knowledge of an agent in a state. In state \"s\", agent \"i\" knows that one of the states in \"P\"(\"s\") obtains, but not which one. (Here \"P\"(\"s\") denotes the unique element of \"P\" containing \"s\". Note that this model excludes cases in which agents know things that are not true.)\n\nWe can now define a knowledge function \"K\" in the following way:\n\nThat is, \"K\"(\"e\") is the set of states where the agent will know that event \"e\" obtains. It is a subset of \"e\".\n\nSimilar to the modal logic formulation above, we can define an operator for the idea that \"everyone knows \"e\"\".\n\nAs with the modal operator, we will iterate the \"E\" function, formula_26 and formula_27. Using this we can then define a common knowledge function,\n\nThe equivalence with the syntactic approach sketched above can easily be seen: consider an Aumann structure as the one just defined. We can define a correspondent Kripke structure by taking (i) the same space \"S\", (ii) accessibility relations formula_19 that define the equivalence classes corresponding to the partitions formula_30, and (iii) a valuation function such that it yields value \"true\" to the primitive proposition \"p\" in all and only the states \"s\" such that formula_31, where formula_32 is the event of the Aumann structure corresponding to the primitive proposition \"p\". It is not difficult to see that the common knowledge accessibility function formula_20 defined in the previous section corresponds to the finest common coarsening of the partitions formula_30 for all formula_35, which is the finitary characterization of common knowledge also given by Aumann in the 1976 article.\n\nCommon knowledge was used by David Lewis in his pioneering game-theoretical account of convention. In this sense, common knowledge is a concept still central for linguists and philosophers of language (see Clark 1996) maintaining a Lewisian, conventionalist account of language.\n\nRobert Aumann introduced a set theoretical formulation of common knowledge (theoretically equivalent to the one given above) and proved the so-called agreement theorem through which: if two agents have common prior probability over a certain event, and the posterior probabilities are common knowledge, then such posterior probabilities are equal. A result based on the agreement theorem and proven by Milgrom shows that, given certain conditions on market efficiency and information, speculative trade is impossible.\n\nThe concept of common knowledge is central in game theory. For several years it has been thought that the assumption of common knowledge of rationality for the players in the game was fundamental. It turns out (Aumann and Brandenburger 1995) that, in 2-player games, common knowledge of rationality is not needed as an epistemic condition for Nash equilibrium strategies.\n\nComputer scientists use languages incorporating epistemic logics (and common knowledge) to reason about distributed systems. Such systems can be based on logics more complicated than simple propositional epistemic logic, see Wooldridge \"Reasoning about Artificial Agents\", 2000 (in which he uses a first-order logic incorporating epistemic and temporal operators) or van der Hoek et al. \"Alternating Time Epistemic Logic\".\n\nIn his 2007 book, \"The Stuff of Thought: Language as a Window into Human Nature,\" Steven Pinker uses the notion of common knowledge to analyze the kind of indirect speech involved in innuendoes.\n\n\n\n\n"}
{"id": "18858579", "url": "https://en.wikipedia.org/wiki?curid=18858579", "title": "Coordinate-free", "text": "Coordinate-free\n\nA coordinate-free, or component-free, treatment of a scientific theory or mathematical topic develops its concepts on any form of manifold without reference to any particular coordinate system. \n\nCoordinate-free treatments generally allow for simpler systems of equations and inherently constrain certain types of inconsistency, allowing greater mathematical elegance at the cost of some abstraction from the detailed formulae needed to evaluate these equations within a particular system of coordinates. \n\nCoordinate-free treatments were the only available approach to geometry (and are now known as synthetic geometry) before the development of analytic geometry by Descartes. After several centuries of generally coordinate-based exposition, the modern tendency is generally to introduce students to coordinate-free treatments early on, and then to derive the coordinate-based treatments from the coordinate-free treatment, rather than \"vice versa\".\n\nFields that are now often introduced with coordinate-free treatments include vector calculus, tensors, differential geometry, and computer graphics.\n\nIn physics, the existence of coordinate-free treatments of physical theories is a corollary of the principle of general covariance.\n\n"}
{"id": "1022286", "url": "https://en.wikipedia.org/wiki?curid=1022286", "title": "Derivative algebra (abstract algebra)", "text": "Derivative algebra (abstract algebra)\n\nIn abstract algebra, a derivative algebra is an algebraic structure of the signature \nwhere \n\nis a Boolean algebra and is a unary operator, the derivative operator, satisfying the identities: \n\nx is called the derivative of x. Derivative algebras provide an algebraic abstraction of the derived set operator in topology. They also play the same role for the modal logic \"wK4\" = \"K\" + \"p\"∧?\"p\" → ??\"p\" that Boolean algebras play for ordinary propositional logic. \n\n"}
{"id": "221519", "url": "https://en.wikipedia.org/wiki?curid=221519", "title": "Differential form", "text": "Differential form\n\nIn the mathematical fields of differential geometry and tensor calculus, differential forms are an approach to multivariable calculus that is independent of coordinates. Differential forms provide a unified approach to define integrands over curves, surfaces, volumes, and higher-dimensional manifolds. The modern notion of differential forms was pioneered by Élie Cartan. It has many applications, especially in geometry, topology and physics.\n\nFor instance, the expression from one-variable calculus is an example of a -form, and can be integrated over an interval in the domain of :\nSimilarly, the expression is a -form that has a surface integral over an oriented surface :\nThe symbol denotes the exterior product, sometimes called the \"wedge product\", of two differential forms. Likewise, a -form represents a volume element that can be integrated over a region of space. In general, a -form is an object that may be integrated over -dimensional sets, and is homogeneous of degree in the coordinate differentials.\n\nThe algebra of differential forms is organized in a way that naturally reflects the orientation of the domain of integration. There is an operation on differential forms known as the exterior derivative that, when acting on a -form, produces a -form. This operation extends the differential of a function, and is directly related to the divergence and the curl of a vector field in a manner that makes the fundamental theorem of calculus, the divergence theorem, Green's theorem, and Stokes' theorem special cases of the same general result, known in this context also as the generalized Stokes' theorem. In a deeper way, this theorem relates the topology of the domain of integration to the structure of the differential forms themselves; the precise connection is known as de Rham's theorem.\n\nThe general setting for the study of differential forms is on a differentiable manifold. Differential -forms are naturally dual to vector fields on a manifold, and the pairing between vector fields and -forms is extended to arbitrary differential forms by the interior product. The algebra of differential forms along with the exterior derivative defined on it is preserved by the pullback under smooth functions between two manifolds. This feature allows geometrically invariant information to be moved from one space to another via the pullback, provided that the information is expressed in terms of differential forms. As an example, the change of variables formula for integration becomes a simple statement that an integral is preserved under pullback.\n\nDifferential forms are part of the field of differential geometry, influenced by linear algebra. Although the notion of a differential is quite old, the initial attempt at an algebraic organization of differential forms is usually credited to Élie Cartan with reference to his 1899 paper. Some aspects of the exterior algebra of differential forms appears in Hermann Grassmann's 1844 work, \"Die Lineale Ausdehnungslehre, ein neuer Zweig der Mathematik\" [The Theory of Linear Extension, a New Branch of Mathematics]\n\nDifferential forms provide an approach to multivariable calculus that is independent of coordinates.\n\nA differential -form can be integrated over a manifold of dimension . A differential one-form can be thought of as measuring an infinitesimal (oriented) length, or one-dimensional density. A differential two-form can be thought of as measuring an infinitesimal (oriented) area, or two-dimensional density. And so on.\n\nIntegration of differential forms is well-defined only on oriented manifolds. An example of a one dimensional manifold is an interval , and intervals can be given an orientation: they are positively oriented if , and negatively oriented otherwise. If then the integral of the differential one-form over the interval (with its natural positive orientation) is\nwhich is the negative of the integral of the same differential form over the same interval, when equipped with the opposite orientation. That is:\nThis gives a geometrical context to the conventions for one-dimensional integrals, that the sign changes when the orientation of the interval is reversed. A standard explanation of this in one-variable integration theory is that, when the limits of integration are in the opposite order (), the increment is negative. The integrals are negatives of one another because the oriented lengths \"dx\" have opposite directions.\n\nMore generally, an -form is an oriented density that can be integrated over an -dimensional oriented manifold. (For example, a -form can be integrated over an oriented curve, a -form can be integrated over an oriented surface, etc.) If is an oriented -dimensional manifold, and is the same manifold with opposed orientation and is an -form, then one has:\nThese conventions correspond to interpreting the integrand as a differential form, integrated over a chain. In measure theory, by contrast, one interprets the integrand as a function with respect to a measure and integrates over a subset , without any notion of orientation; one writes formula_6 to indicate integration over a subset . This is a minor distinction in one dimension, but becomes subtler on higher-dimensional manifolds; see below for details.\n\nMaking the notion of an oriented density precise, and thus of a differential form, involves the exterior algebra. The basic -forms are the differentials of the coordinates: , ..., . Each of these represents a covector that measures a small displacement in the corresponding coordinate direction. A general -form is a linear combination of these differentials\nwhere the formula_8 are functions of the coordinates. A differential -form is integrated along an oriented curve as a line integral.\n\nThe basic two-forms are expressions , where . This represents an infinitesimal oriented square parallel to the –-plane. A general two-form is a linear combination of these, and it is integrated just like a surface integral.\n\nA fundamental operation defined on differential forms is the exterior product (the symbol is the wedge ). This is similar to the cross product from vector calculus, in that it is an alternating product. For instance,\nbecause the square whose first side is and second side is is to be regarded as having the opposite orientation as the square whose first side is and whose second side is . The exterior product allows higher dimensional differential forms to be built out of lower-dimensional ones, in much the same way that the cross product in vector calculus allows one to compute the area vector of a parallelogram from vectors pointing up the two sides.\n\nIn addition to the exterior product, there is also the exterior derivative operator . Like the differential of a function, the exterior derivative gives a way of quantifying a differential form's sensitivity to change. In , if is a -form, then is a -form defined by\n\nwith extension to general -forms occurring linearly.\n\nThis more general approach allows for a more natural coordinate-free approach to integration on manifolds. It also allows for a natural generalization of the fundamental theorem of calculus (see ).\n\nLet be an open set in . A differential -form (\"zero-form\") is defined to be a smooth function on . If is any vector in , then has a directional derivative , which is another function on whose value at a point is the rate of change (at ) of in the direction:\n\nIn particular, if is the th coordinate vector then is the partial derivative of with respect to the th coordinate function, i.e., , where , , ..., are the coordinate functions on . By their very definition, partial derivatives depend upon the choice of coordinates: if new coordinates , , ..., are introduced, then\n\nThe first idea leading to differential forms is the observation that is a linear function of :\n\nfor any vectors , and any real number . This linear map from to is denoted and called the derivative of at . Thus . The object can be viewed as a function on , whose value at is not a real number, but the linear map . This is just the usual Fréchet derivative – an example of a differential -form.\n\nSince any vector is a linear combination of its components, is uniquely determined by for each and each , which are just the partial derivatives of on . Thus provides a way of encoding the partial derivatives of . It can be decoded by noticing that the coordinates , , ..., are themselves functions on , and so define differential -forms , , ..., . Let . Since , the Kronecker delta function, it follows that\n\nThe meaning of this expression is given by evaluating both sides at an arbitrary point : on the right hand side, the sum is defined \"pointwise\", so that\nApplying both sides to , the result on each side is the th partial derivative of at . Since and were arbitrary, this proves the formula .\n\nMore generally, for any smooth functions and on , we define the differential -form pointwise by\n\nfor each . Any differential -form arises this way, and by using it follows that any differential -form on may be expressed in coordinates as\n\nfor some smooth functions on .\n\nThe second idea leading to differential forms arises from the following question: given a differential -form on , when does there exist a function on such that ? The above expansion reduces this question to the search for a function whose partial derivatives are equal to given functions . For , such a function does not always exist: any smooth function satisfies\n\nso it will be impossible to find such an unless\n\nfor all and .\n\nThe skew-symmetry of the left hand side in and suggests introducing an antisymmetric product on differential -forms, the exterior product, so that these equations can be combined into a single condition\n\nwhere is defined so that:\n\nThis is an example of a differential -form. This -form is called the exterior derivative of . It is given by\n\nTo summarize: is a necessary condition for the existence of a function with .\n\nDifferential -forms, -forms, and -forms are special cases of differential forms. For each , there is a space of differential -forms, which can be expressed in terms of the coordinates as\n\nfor a collection of functions . Antisymmetry, which was already present for -forms, makes it possible to restrict the sum to those sets of indices for which .\n\nDifferential forms can be multiplied together using the exterior product, and for any differential -form , there is a differential -form called the exterior derivative of .\n\nDifferential forms, the exterior product and the exterior derivative are independent of a choice of coordinates. Consequently, they may be defined on any smooth manifold . One way to do this is cover with coordinate charts and define a differential -form on to be a family of differential -forms on each chart which agree on the overlaps. However, there are more intrinsic definitions which make the independence of coordinates manifest.\n\nLet be a smooth manifold. A smooth differential form of degree is a smooth section of the th exterior power of the cotangent bundle of . The set of all differential -forms on a manifold is a vector space, often denoted .\n\nThe definition of a differential form may be restated as follows. At any point , a -form defines an element\nwhere is the tangent space to at and is its dual space. This space is naturally isomorphic to the fiber at of the dual bundle of the th exterior power of the tangent bundle of . That is, is also a linear functional\n\nBy the universal property of exterior powers, this is equivalently an alternating multilinear map\nConsequently, a differential -form may be evaluated against any -tuple of tangent vectors to the same point of . For example, a differential -form assigns to each point a linear functional on . In the presence of an inner product on (induced by a Riemannian metric on ), may be represented as the inner product with a tangent vector . Differential -forms are sometimes called covariant vector fields, covector fields, or \"dual vector fields\", particularly within physics.\n\nThe exterior algebra may be embedded in the tensor algebra by means of the alternation map. The alternation map is defined as a mapping \nFor a tensor at a point ,\nwhere is the symmetric group on elements. The alternation map is constant on the cosets of the ideal in the tensor algebra generated by the symmetric 2-forms, and therefore descends to an embedding\n\nThis map exhibits as a totally antisymmetric covariant tensor field of rank . The differential forms on are in one-to-one correspondence with such tensor fields.\n\nAs well as the addition and multiplication by scalar operations which arise from the vector space structure, there are several other standard operations defined on differential forms. The most important operations are the exterior product of two differential forms, the exterior derivative of a single differential form, the interior product of a differential form and a vector field, the Lie derivative of a differential form with respect to a vector field and the covariant derivative of a differential form with respect to a vector field on a manifold with a defined connection.\n\nThe exterior product of a -form and an -form is a ()-form denoted . At each point of the manifold , the forms and are elements of an exterior power of the tangent space at . When the exterior algebra is viewed as a quotient of the tensor algebra, the exterior product corresponds to the tensor product (modulo the equivalence relation defining the exterior algebra).\n\nThe antisymmetry inherent in the exterior algebra means that when is viewed as a multilinear functional, it is alternating. However, when the exterior algebra embedded a subspace of the tensor algebra by means of the alternation map, the tensor product is not alternating. There is an explicit formula which describes the exterior product in this situation. The exterior product is\nThis description is useful for explicit computations. For example, if , then is the -form whose value at a point is the alternating bilinear form defined by\nfor .\n\nThe exterior product is bilinear: If , , and are any differential forms, and if is any smooth function, then\n\nIt is \"skew commutative\" (also known as \"graded commutative\"), meaning that it satisfies a variant of anticommutativity that depends on the degrees of the forms: if is a -form and is an -form, then\n\nOn a Riemannian manifold, or more generally a pseudo-Riemannian manifold, the metric defines a fibre-wise isomorphism of the tangent and cotangent spaces. This makes it possible to convert vector fields to covector fields and vice versa. It also enables the definition of additional operations such as the Hodge star operator formula_34 and the codifferential formula_35, which has degree and is adjoint to the exterior differential .\n\nOn a pseudo-Riemannian manifold, -forms can be identified with vector fields; vector fields have additional distinct algebraic structures, which are listed here for context and to avoid confusion.\n\nFirstly, each (co)tangent space generates a Clifford algebra, where the product of a (co)vector with itself is given by the value of a quadratic form – in this case, the natural one induced by the metric. This algebra is \"distinct\" from the exterior algebra of differential forms, which can be viewed as a Clifford algebra where the quadratic form vanishes (since the exterior product of any vector with itself is zero). Clifford algebras are thus non-anti-commutative (\"quantum\") deformations of the exterior algebra. They are studied in geometric algebra.\n\nAnother alternative is to consider vector fields as derivations. The (noncommutative) algebra of differential operators they generate is the Weyl algebra and is a noncommutative (\"quantum\") deformation of the \"symmetric\" algebra in the vector fields.\n\nOne important property of the exterior derivative is that . This means that the exterior derivative defines a cochain complex:\n\nThis complex is called the de Rham complex, and its cohomology is by definition the de Rham cohomology of . By the Poincaré lemma, the de Rham complex is locally exact except at . The kernel at is the space of locally constant functions on . Therefore, the complex is a resolution of the constant sheaf formula_37, which in turn implies a form of de Rham's theorem: de Rham cohomology computes the sheaf cohomology of formula_37.\n\nSuppose that is smooth. The differential of is a smooth map between the tangent bundles of and . This map is also denoted and called the pushforward. For any point and any , there is a well-defined pushforward vector in . However, the same is not true of a vector field. If is not injective, say because has two or more preimages, then the vector field may determine two or more distinct vectors in . If is not surjective, then will be a point at which does not determine any tangent vector at all. Since a vector field on determines, by definition, a unique tangent vector at every point of , the pushforward of a vector field does not always exist.\n\nBy contrast, it is always possible to pull back a differential form. A differential form on may be viewed as a linear functional on each tangent space. Precomposing this functional with the differential defines a linear functional on each tangent space of and therefore a differential form on . The existence of pullbacks is one of the key features of the theory of differential forms. It leads to the existence of pullback maps in other situations, such as pullback homomorphisms in de Rham cohomology.\n\nFormally, let be smooth, and let be a smooth -form on . Then there is a differential form on , called the pullback of , which captures the behavior of as seen relative to . To define the pullback, fix a point of and tangent vectors , ..., to at . The pullback of is defined by the formula\n\nThere are several more abstract ways to view this definition. If is a -form on , then it may be viewed as a section of the cotangent bundle of . Using to denote a dual map, the dual to the differential of is . The pullback of may be defined to be the composite\nThis is a section of the cotangent bundle of and hence a differential -form on . In full generality, let formula_41 denote the th exterior power of the dual map to the differential. Then the pullback of a -form is the composite\n\nAnother abstract way to view the pullback comes from viewing a -form as a linear functional on tangent spaces. From this point of view, is a morphism of vector bundles\nwhere is the trivial rank one bundle on . The composite map\ndefines a linear functional on each tangent space of , and therefore it factors through the trivial bundle . The vector bundle morphism formula_45 defined in this way is .\n\nPullback respects all of the basic operations on forms. If and are forms and is a real number, then\n\nThe pullback of a form can also be written in coordinates. Assume that , ..., are coordinates on , that , ..., are coordinates on , and that these coordinate systems are related by the formulas for all . Locally on , can be written as\n\nwhere, for each choice of , ..., , is a real-valued function of , ..., . Using the linearity of pullback and its compatibility with exterior product, the pullback of has the formula\n\nEach exterior derivative can be expanded in terms of , ..., . The resulting -form can be written using Jacobian matrices:\n\nHere, formula_50 denotes the determinant of the matrix whose entries are formula_51, formula_52.\n\nA differential -form can be integrated over an oriented -dimensional manifold. When the -form is defined on an -dimensional manifold with , then the -form can be integrated over oriented -dimensional submanifolds. If , this is just evaluation of a function at points. Other values of correspond to line integrals, surface integrals, volume integrals, and so on. There are several equivalent ways to formally define the integral of a differential form, all of which depend on reducing to the case of Euclidean space.\n\nLet be an open subset of . Give its standard orientation and the restriction of that orientation. Every smooth -form on has the form\nfor some smooth function . Such a function has an integral in the usual Riemann or Lebesgue sense. This allows us to define the integral of to be the integral of :\nFixing an orientation is necessary for this to be well-defined. The skew-symmetry of differential forms means that the integral of, say, must be the negative of the integral of . Riemann and Lebesgue integrals cannot see this dependence on the ordering of the coordinates, so they leave the sign of the integral undetermined. The orientation resolves this ambiguity.\n\nLet be an -manifold and an -form on . First, assume that there is a parametrization of by an open subset of Euclidean space. That is, assume that there exists a diffeomorphism\nwhere . Give the orientation induced by . Then defines the integral of over to be the integral of over . In coordinates, this has the following expression. Fix a chart on with coordinates . Then\nSuppose that is defined by\nThen the integral may be written in coordinates as\nwhere\nis the determinant of the Jacobian. The Jacobian exists because is differentiable.\n\nIn general, an -manifold cannot be parametrized by an open subset of . But such a parametrization is always possible locally, so it is possible to define integrals over arbitrary manifolds by defining them as sums of integrals over collections of local parametrizations. Moreover, it is also possible to define parametrizations of -dimensional subsets for , and this makes it possible to define integrals of -forms. To make this precise, it is convenient to fix a standard domain in , usually a cube or a simplex. A -chain is a formal sum of smooth embeddings . That is, it is a collection of smooth embeddings, each of which is assigned an integer multiplicity. Each smooth embedding determines a -dimensional submanifold of . If the chain is\nthen the integral of a -form over is defined to be the sum of the integrals over the terms of :\n\nThis approach to defining integration does not assign a direct meaning to integration over the whole manifold . However, it is still possible to assign such a meaning indirectly because every smooth manifold may be smoothly triangulated in an essentially unique way, and the integral over may be defined to be the integral over the chain determined by a triangulation.\n\nThere is another approach, expounded in , which does directly assign a meaning to integration over , but this approach requires fixing an orientation of . The integral of an -form on an -dimensional manifold is defined by working in charts. Suppose first that is supported on a single positively oriented chart. On this chart, it may be pulled back to an -form on an open subset of . Here, the form has a well-defined Riemann or Lebesgue integral as before. The change of variables formula and the assumption that the chart is positively oriented together ensure that the integral of is independent of the chosen chart. In the general case, use a partition of unity to write as a sum of -forms, each of which is supported in a single positively oriented chart, and define the integral of to be the sum of the integrals of each term in the partition of unity.\n\nIt is also possible to integrate -forms on oriented -dimensional submanifolds using this more intrinsic approach. The form is pulled back to the submanifold, where the integral is defined using charts as before. For example, given a path , integrating a -form on the path is simply pulling back the form to a form on , and this integral is the integral of the function on the interval.\n\nFubini's theorem states that the integral over a set that is a product may be computed as an iterated integral over the two factors in the product. This suggests that the integral of a differential form over a product ought to be computable as an iterated integral as well. The geometric flexibility of differential forms ensures that this is possible not just for products, but in more general situations as well. Under some hypotheses, it is possible to integrate along the fibers of a smooth map, and the analog of Fubini's theorem is the case where this map is the projection from a product to one of its factors.\n\nBecause integrating a differential form over a submanifold requires fixing an orientation, a prerequisite to integration along fibers is the existence of a well-defined orientation on those fibers. Let and be two orientable manifolds of pure dimensions and , respectively. Suppose that is a surjective submersion. This implies that each fiber is -dimensional and that, around each point of , there is a chart on which looks like the projection from a product onto one of its factors. Fix and set . Suppose that\nand that does not vanish. Following , there is a unique\nwhich may be thought of as the fibral part of with respect to . More precisely, define to be the inclusion. Then is defined by the property that,\nwhere\nis any -covector for which\nThe form may also be notated .\n\nMoreover, for fixed , varies smoothly with respect to . That is, suppose that\nis a smooth section of the projection map; we say that is a smooth differential -form on along . Then there is a smooth differential -form on such that, at each ,\nThis form is denoted . The same construction works if is an -form in a neighborhood of the fiber, and the same notation is used. A consequence is that each fiber is orientable. In particular, a choice of orientation forms on and defines an orientation of every fiber of .\n\nThe analog of Fubini's theorem is as follows. As before, and are two orientable manifolds of pure dimensions and , and is a surjective submersion. Fix orientations of and , and give each fiber of the induced orientation. Let be an -form on , and let be an -form on that is almost everywhere positive with respect to the orientation of . Then, for almost every , the form is a well-defined integrable form on . Moreover, there is an integrable -form on defined by\nDenote this form by\nThen proves the generalized Fubini formula\n\nIt is also possible to integrate forms of other degrees along the fibers of a submersion. Assume the same hypotheses as before, and let be a compactly supported -form on . Then there is a -form on which is the result of integrating along the fibers of . The form is defined by specifying, at each , how pairs against each -vector at , and the value of that pairing is an integral over that depends only on , , and the orientations of and . More precisely, at each , there is an isomorphism\ndefined by the interior product\nIf , then a -vector at determines an -covector at by pullback:\nEach of these covectors has an exterior product against , so there is an -form on along defined by\nThis form depends on the orientation of but not the choice of . Then the -form is uniquely defined by the property\nand is smooth . This form also denoted and called the integral of along the fibers of \"f\". Integration along fibers is important for the construction of Gysin maps in de Rham cohomology.\n\nIntegration along fibers satisfies the projection formula . If is any -form on , then\n\nThe fundamental relationship between the exterior derivative and integration is given by the Stokes' theorem: If is an ()-form with compact support on and denotes the boundary of with its induced orientation, then\n\nA key consequence of this is that \"the integral of a closed form over homologous chains is equal\": If is a closed -form and and are -chains that are homologous (such that is the boundary of a ()-chain ), then formula_79, since the difference is the integral formula_80.\n\nFor example, if is the derivative of a potential function on the plane or , then the integral of over a path from to does not depend on the choice of path (the integral is ), since different paths with given endpoints are homotopic, hence homologous (a weaker condition). This case is called the gradient theorem, and generalizes the fundamental theorem of calculus. This path independence is very useful in contour integration.\n\nThis theorem also underlies the duality between de Rham cohomology and the homology of chains.\n\nOn a \"general\" differentiable manifold (without additional structure), differential forms \"cannot\" be integrated over subsets of the manifold; this distinction is key to the distinction between differential forms, which are integrated over chains or oriented submanifolds, and measures, which are integrated over subsets. The simplest example is attempting to integrate the -form over the interval . Assuming the usual distance (and thus measure) on the real line, this integral is either or , depending on \"orientation:\" formula_81, while formula_82. By contrast, the integral of the \"measure\" on the interval is unambiguously (formally, the integral of the constant function with respect to this measure is ). Similarly, under a change of coordinates a differential -form changes by the Jacobian determinant , while a measure changes by the \"absolute value\" of the Jacobian determinant, , which further reflects the issue of orientation. For example, under the map on the line, the differential form pulls back to ; orientation has reversed; while the Lebesgue measure, which here we denote , pulls back to ; it does not change.\n\nIn the presence of the additional data of an \"orientation\", it is possible to integrate -forms (top-dimensional forms) over the entire manifold or over compact subsets; integration over the entire manifold corresponds to integrating the form over the fundamental class of the manifold, . Formally, in the presence of an orientation, one may identify -forms with densities on a manifold; densities in turn define a measure, and thus can be integrated .\n\nOn an orientable but not oriented manifold, there are two choices of orientation; either choice allows one to integrate -forms over compact subsets, with the two choices differing by a sign. On non-orientable manifold, -forms and densities cannot be identified —notably, any top-dimensional form must vanish somewhere (there are no volume forms on non-orientable manifolds), but there are nowhere-vanishing densities— thus while one can integrate densities over compact subsets, one cannot integrate -forms. One can instead identify densities with top-dimensional pseudoforms.\n\nEven in the presence of an orientation, there is in general no meaningful way to integrate -forms over subsets for because there is no consistent way to use the ambient orientation to orient -dimensional subsets. Geometrically, a -dimensional subset can be turned around in place, yielding the same subset with the reserve orientation; for example, the horizontal axis in a plane can be rotated by a half-circle. Compare the Gram determinant of a set of vectors in an -dimensional space, which, unlike the determinant of vectors, is always positive, corresponding to a squared number. An orientation of a -submanifold is therefore extra data not derivable from the ambient manifold.\n\nOn a Riemannian manifold, one may define a -dimensional Hausdorff measure for any (integer or real), which may be integrated over -dimensional subsets of the manifold. A function times this Hausdorff measure can then be integrated over -dimensional subsets, providing a measure-theoretic analog to integration of -forms. The -dimensional Hausdorff measure yields a density, as above.\n\nThe differential form analog of a distribution or generalized function is called a current. The space of -currents on is the dual space to an appropriate space of differential -forms. Currents play the role of generalized domains of integration, similar to but even more flexible than chains.\n\nDifferential forms arise in some important physical contexts. For example, in Maxwell's theory of electromagnetism, the Faraday 2-form, or electromagnetic field strength, is\n\nwhere the are formed from the electromagnetic fields formula_84 and formula_85; e.g., , , or equivalent definitions.\n\nThis form is a special case of the curvature form on the principal bundle on which both electromagnetism and general gauge theories may be described. The connection form for the principal bundle is the vector potential, typically denoted by , when represented in some gauge. One then has\n\nThe current -form is\n\nwhere are the four components of the current density. (Here it is a matter of convention to write instead of , i.e. to use capital letters, and to write instead of . However, the vector rsp. tensor components and the above-mentioned forms have different physical dimensions. Moreover, by decision of an international commission of the International Union of Pure and Applied Physics, the magnetic polarization vector is called formula_88 since several decades, and by some publishers , i.e. the same name is used for different quantities.)\n\nUsing the above-mentioned definitions, Maxwell's equations can be written very compactly in geometrized units as\n\nwhere formula_90 denotes the Hodge star operator. Similar considerations describe the geometry of gauge theories in general.\n\nThe -form formula_91, which is dual to the Faraday form, is also called Maxwell 2-form.\n\nElectromagnetism is an example of a gauge theory. Here the Lie group is , the one-dimensional unitary group, which is in particular abelian. There are gauge theories, such as Yang–Mills theory, in which the Lie group is not abelian. In that case, one gets relations which are similar to those described here. The analog of the field in such theories is the curvature form of the connection, which is represented in a gauge by a Lie algebra-valued one-form . The Yang–Mills field is then defined by\n\nIn the abelian case, such as electromagnetism, , but this does not hold in general. Likewise the field equations are modified by additional terms involving exterior products of and , owing to the structure equations of the gauge group.\n\nNumerous minimality results for complex analytic manifolds are based on the Wirtinger inequality for 2-forms. A succinct proof may be found in Herbert Federer's classic text \"Geometric Measure Theory\". The Wirtinger inequality is also a key ingredient in Gromov's inequality for complex projective space in systolic geometry.\n\n\n\n"}
{"id": "6881256", "url": "https://en.wikipedia.org/wiki?curid=6881256", "title": "Digital Arts and Culture", "text": "Digital Arts and Culture\n\nDigital Arts and Culture was a conference series that was established by Espen Aarseth in 1998, and was one of the first academic events to gather researchers, practitioners and artists working within the field of digital arts, cultures, aesthetics and design. The DAC conference started out as an annual conference, and was held every second year, until 2009.\n\n\n"}
{"id": "25273305", "url": "https://en.wikipedia.org/wiki?curid=25273305", "title": "Eternal statement", "text": "Eternal statement\n\nAn eternal statement is a statement whose token instances all have the same truth value. For instance, every inscription or utterance of the sentence \"On July 15, 2009 it rains in Boston\" has the same truth value, no matter when or where it is asserted. This type of statement is distinguished from others in that its context will not influence its truth value. Essentially, an eternal statement is a true statement, regardless of how it used. \n\n"}
{"id": "5585610", "url": "https://en.wikipedia.org/wiki?curid=5585610", "title": "Food critic", "text": "Food critic\n\nThe terms food critic, food writer, and restaurant critic can all be used to describe a writer who analyzes food or restaurants and then publishes the results of their findings. While these terms are not strictly synonymous they are often used interchangeably, at least in some circumstances. Those who share their opinions via food columns in newspapers and magazines are known as food columnists. They are often experts in the field.\n\n\"Food writer\" is often used as a broad term that encompasses someone who writes about food and about restaurants. For example, Ruth Reichl is often described as a food writer/editor, who in the course of her career served as the \"restaurant critic\" for \"The New York Times\" and for the \"Los Angeles Times\". R.W. \"Johnny\" Apple was also described as a food writer, but never served as a designated restaurant critic. Nonetheless, he wrote frequently about restaurants as he traveled in search of good eats. Calvin Trillin writes a great deal about food (among other things) and has been known to write occasionally about specific restaurants, e.g., Arthur Bryant's and Diedee's. But restaurants figure less prominently in his writing than in Apple's. Finally, Richard Olney was also a noted food writer, but rarely if ever wrote about restaurants.\n\nFood critics and \"restaurant critic\" are synonyms, in practice, although there is still a distinction to be made. Both suggest a critical, evaluative stance that often involves some kind of rating system. The distinction, if any involves the range of possible investigation. \"Food critic\" has a more contemporary vibe, suggesting that restaurants, bakeries, food festivals, street vendors, and taco trucks are all fair game. Jonathan Gold of \"L.A. Weekly\" and the \"Los Angeles Times\", who holds the distinction of being the first food critic to win the Pulitzer Prize, exemplifies this trend. \"Restaurant critic\" is the more traditional title and can connote a more restricted sphere of operations — traditional restaurants, with perhaps those serving French cuisine being the examples. The change in practice, if not in terminology, is often attributed to Reichl's arrival at the \"New York Times\", replacing Bryan Miller. In a series of well-documented incidents, Miller complained that Reichl was \"giving SoHo noodle shops 2 and 3 stars\" and destroying the rating system that had been built up by Craig Claiborne, Mimi Sheraton, and Miller.\n\nFor most of the past century, the most highly visible food critics have been those who have written for daily newspapers throughout the world and a few who have been restaurant reviewers for influential magazines, such as \"Gourmet\" in the United States. The ephemeral nature of radio and television has meant that very few food critics have used this medium effectively (as opposed to chefs who have used all media to great effect). An example is the BBC's \"The Food Programme\". Hugh Fearnley-Whittingstall has also used both broadcast media and print to concentrate on food production rather than presentation, starting a new column in \"The Guardian\" in September 2006.\n\nRestaurant critics range in their approach to writing from the acerbic (such as A. A. Gill from London), to the witty/humorous (such as Morgan Murphy, \"America's Funniest Food Critic,\" or Terry Durack from \"The Independent on Sunday\") to the \"been there done that\" approach of Ruth Reichl of \"Gourmet\" and formerly of \"The New York Times\". Other notable critics include Patricia Wells of the \"International Herald Tribune\", who writes knowledgeable and perceptive articles about food and restaurants and who occasionally uses the sword rather than her usual suave style. Another was R. W. Apple, Jr., from \"The New York Times\", who wrote long, thoughtful articles about his travels throughout the world in search of great food. Brad A. Johnson in Los Angeles is the only American restaurant critic to win both the coveted James Beard Award and the Le Cordon Bleu World Food Media Award for restaurant criticism.\n\nThen there are myriad regional food critics, ranging from Nancy Leson in Seattle, to Pat Nourse in Sydney, Cooper Adams in Albany, and Stephen Downes and John Lethlean in Melbourne, who pen weekly and monthly reviews of the best of their respective cities.\n\nGiles Coren was very known to his show, \"Million Dollar Critic\" who assesses the restaurants in Canada & United States where he focuses on quality of services, food taste & the ambiance of each and every restaurant that he visited. Aside from his hosting project, he is also a food columnist for The London Times, GQ, Tatler & The Independent UK to tell about his reviews of restaurants around the world, especially in United Kingdom.\n\nThe internet has slowly become more important in forming opinions about restaurants. Food criticism on the Internet has allowed creation of shows with specific audiences.\n\n\n"}
{"id": "11039478", "url": "https://en.wikipedia.org/wiki?curid=11039478", "title": "Henry Farnham Perkins", "text": "Henry Farnham Perkins\n\nHenry Farnham Perkins (1877–1956) was an American zoologist and eugenicist.\n\nHe was born at 205 South Prospect Street in Burlington, Chittenden County, Vermont in the house where he spent his entire life in the affluent \"Burlington Hill\" neighborhood next to the University of Vermont on May 10, 1877. He was born into a family with Midwestern roots that trace back to \"Mayflower\" passengers, Love Brewster, a founder of the town of Bridgewater, Massachusetts; Elder William Brewster, the Pilgrim colonist leader and spiritual elder of the Plymouth Colony; and William Bradford, Governor of the Plymouth Colony and the second signer and primary architect of the Mayflower Compact in Provincetown Harbor. He was also a descendant of Martha Wadsworth Brewster, a notable 18th-century American poet and writer.\n\nHe was the only son and the second child of George Henry Perkins and the grandson of Frederick Perkins and Harriet Olmstead. Henry's father was a noted American educator, naturalist and Professor of Geology and kindred sciences at the University of Vermont. His father served as Dean of Arts and Sciences, vice president and was appointed interim president of the University of Vermont during World War I. He was also the state geologist of Vermont from 1898 to 1933. He graduated Phi Beta Kappa from Yale University, class of 1867; received the degree of Doctor of Philosophy from Yale in 1869.\n\nHis mother was Mary Judd Farnham, an 1863 graduate of Knox College, and a daughter of Eli Farnham and Jerusha Brewster Loomis. She attended the debates between Abraham Lincoln and Stephen A. Douglas at Knox College on October 7, 1858. It was said of her that she was a woman of superior mental endowments. She was the president of the Vermont Chapter of the Woman's Christian Temperance Union, and was active in her church and philanthropic work. Her first cousin was Dr. George Trumbull Ladd an American philosopher, educator and psychologist.\n\nMary's parents had emigrated to Illinois in 1836 and were the among the founders and pioneers of Galesburg, Illinois. They built a temporary cabin in Log City near current Lake Storey, just north of Galesburg, the settlers having decided that no log cabins were to be built inside the town limits. They were also instrumental in the founding of Knox College. Eli Farnham served as secretary of the Board of Trustees for nearly forty years and also the first school teacher in Galesburg.\n\nHe graduated Phi Beta Kappa from the University of Vermont, Burlington in 1898, received his M.Sc in 1899 and was awarded his PhD in Zoology at Johns Hopkins University in 1902. The title of his doctoral thesis was \"The Development of Gonionema Murbachii\", which was on the development and life cycle of Gonionema murbachii (a type of jellyfish). After receiving his doctorate, he joined the faculty of UVM where he remained until his retirement.\n\nHe married on June 11, 1903 at Baltimore, Baltimore County, Maryland, Mary Edmunds, born at Baltimore, Maryland on October 18, 1874 the daughter of James Richard Edmunds and Anna Smith Keyser. She was the sister of Dr. Charles Keyser Edmunds, one of his fellow graduate students at Johns Hopkins. He was president of Canton Christian College in Canton, Kwangtung Province, China and the fifth president of Pomona College in Claremont, California. Another brother was James Richard Edmunds, Jr., a graduate of the University of Pennsylvania, and a notable Architect in Baltimore, Maryland.\n\nShe was a descendant of John Howland, (c. 1599–1673) who was one of the Pilgrims who travelled from England to North America on the Mayflower, signed the Mayflower Compact, and helped found Plymouth Colony. She was also the great great granddaughter of Thomas Hurst Hughes, the founder and owner of the Congress Hall Hotel in Cape May, New Jersey, and a Republican member of the United States House of Representatives from New Jersey.\n\nHenry and Mary were the parents of two children, Anna Keyser Perkins-Middlebrook, who married as her second husband, Stanwood Wollaston and Harriet Perkins.\n\nIn 1903, he was appointed associate professor of Zoology at University of Vermont, Burlington. He taught biology, entomology, anatomy and physiology, and embryology during the first half of his career. In 1911 was promoted to full professor and served as chairman of the Zoology Department. His sporadic research projects involved field studies in the rapidly fading naturalist tradition: studies of birds, game fish, and marine invertebrates. He retired in 1945 and remained active in the UVM Alumni Association until his death in 1956.\n\nHis interest in eugenics began shortly after the end of World War I. It was after World War I that he learned of a study by the U.S. Army which was used as part of the draft process. The results from the Army study showed that men from Vermont had an inordinately high rate of \"defects\" (such as diabetes, epilepsy, \"deformities\" and \"mental deficiency\"). Perkins saw this as a problem that needed to be fixed. He went about trying to \"fix\" this through investigation and social reform. This reform, as denounced by historian Nancy Gallagher in her research titled \"Breeding better Vermonters\", also targeted French Canadians and American natives in Vermont state, considered \"insane invasion\" to eliminate.\n\nAround the same time, he revamped his Zoology curriculum and began teaching courses specifically on Heredity and Evolution. His heredity class provided the first known venue for eugenics education at UVM and the inspiration for a \"Eugenics Survey\"—a field station to study Vermonters.\n\nHe died on November 24, 1956 in Burlington, Vermont. He is buried in Greenmount Cemetery, Burlington, Vermont.\n\n\n\n"}
{"id": "19515158", "url": "https://en.wikipedia.org/wiki?curid=19515158", "title": "Higher-dimensional algebra", "text": "Higher-dimensional algebra\n\nIn mathematics, especially (higher) category theory, higher-dimensional algebra is the study of categorified structures. It has applications in nonabelian algebraic topology, and generalizes abstract algebra.\n\nA first step towards defining higher dimensional algebras is the concept of 2-category of higher category theory, followed by the more 'geometric' concept of double category.\n\nA higher level concept is thus defined as a category of categories, or super-category, which generalises to higher dimensions the notion of category – regarded as any structure which is an interpretation of Lawvere's axioms of the \"elementary theory of abstract categories\" (ETAC). Ll.\n\n, Thus, a supercategory and also a super-category, can be regarded as natural extensions of the concepts of meta-category, multicategory, and multi-graph, \"k\"-partite graph, or colored graph (see a color figure, and also its definition in graph theory).\n\nSupercategories were first introduced in 1970, and were subsequently developed for applications in theoretical physics (especially quantum field theory and topological quantum field theory) and mathematical biology or mathematical biophysics.\n\nOther pathways in HDA involve: bicategories, homomorphisms of bicategories, variable categories (\"aka\", indexed, or parametrized categories), topoi, effective descent, and enriched and internal categories.\n\nIn higher-dimensional algebra (HDA), a double groupoid is a generalisation of a one-dimensional groupoid to two dimensions, and the latter groupoid can be considered as a special case of a category with all invertible arrows, or morphisms.\n\nDouble groupoids are often used to capture information about geometrical objects such as higher-dimensional manifolds (or \"n\"-dimensional manifolds). In general, an \"n\"-dimensional manifold is a space that locally looks like an \"n\"-dimensional Euclidean space, but whose global structure may be non-Euclidean.\n\nDouble groupoids were first introduced by Ronald Brown in 1976, in ref. and were further developed towards applications in nonabelian algebraic topology. A related, 'dual' concept is that of a double algebroid, and the more general concept of R-algebroid.\n\nMany of the higher dimensional algebraic structures are noncommutative and, therefore, their study is a very significant part of nonabelian category theory, and also of Nonabelian Algebraic Topology (NAAT) which generalises to higher dimensions ideas coming from the fundamental group. Such algebraic structures in dimensions greater than 1 develop the nonabelian character of the fundamental group, and they are in a precise sense \"‘more nonabelian than the groups' \". These noncommutative, or more specifically, nonabelian structures reflect more accurately the geometrical complications of higher dimensions than the known homology and homotopy groups commonly encountered in classical algebraic topology.\nAn important part of nonabelian algebraic topology is concerned with the properties and applications of homotopy groupoids and filtered spaces. Noncommutative double groupoids and double algebroids are only the first examples of such higher dimensional structures that are nonabelian. The new methods of Nonabelian Algebraic Topology (NAAT) \"``can be applied to determine homotopy invariants of spaces, and homotopy classification of maps, in cases which include some classical results, and allow results not available by classical methods\"\". Cubical omega-groupoids, higher homotopy groupoids, crossed modules, crossed complexes and Galois groupoids are key concepts in developing applications related to homotopy of filtered spaces, higher dimensional space structures, the construction of the fundamental groupoid of a topos E in the general theory of topoi, and also in their physical applications in nonabelian quantum theories, and recent developments in quantum gravity, as well as categorical and topological dynamics. Further examples of such applications include the generalisations of noncommutative geometry formalizations of the noncommutative standard models \"via\" fundamental double groupoids and spacetime structures even more general than topoi or the lower-dimensional noncommutative spacetimes encountered in several topological quantum field theories and noncommutative geometry theories of quantum gravity.\n\nA fundamental result in NAAT is the generalised, higher homotopy van Kampen theorem proven by R. Brown which states that ``\"the homotopy type of a topological space can be computed by a suitable colimit or homotopy colimit over homotopy types of its pieces'. A related example is that of van Kampen theorems for categories of covering morphisms in lextensive categories. Other reports of generalisations of the van Kampen theorem include statements for 2-categories and a topos of topoi .\nImportant results in HDA are also the extensions of the Galois theory in categories and variable categories, or indexed/`parametrized' categories. The Joyal–Tierney representation theorem for topoi is also a generalisation of the Galois theory.\nThus, indexing by bicategories in the sense of Benabou one also includes here the Joyal–Tierney theory.\n\nIn quantum field theory, there exist quantum categories. and quantum double groupoids./ One can consider quantum double groupoids to be fundamental groupoids defined via a 2-functor, which allows one to think about the physically interesting case of quantum fundamental groupoids (QFGs) in terms of the bicategory Span(Groupoids), and then constructing 2-Hilbert spaces and 2-linear maps for manifolds and cobordisms. At the next step, one obtains cobordisms with corners via natural transformations of such 2-functors. A claim was then made that, with the gauge group SU(2), \"the extended TQFT, or ETQFT, gives a theory equivalent to the Ponzano–Regge model of quantum gravity\"; similarly, the Turaev–Viro model would be then obtained with representations of SU(2). Therefore, one can describe the state space of a gauge theory – or many kinds of quantum field theories (QFTs) and local quantum physics, in terms of the transformation groupoids given by symmetries, as for example in the case of a gauge theory, by the gauge transformations acting on states that are, in this case, connections. In the case of symmetries related to quantum groups, one would obtain structures that are representation categories of quantum groupoids, instead of the 2-vector spaces that are representation categories of groupoids.\n\n\n"}
{"id": "37797", "url": "https://en.wikipedia.org/wiki?curid=37797", "title": "Hilbert's paradox of the Grand Hotel", "text": "Hilbert's paradox of the Grand Hotel\n\nHilbert's paradox of the Grand Hotel (colloquial: Infinite Hotel Paradox or Hilbert's Hotel) is a thought experiment which illustrates a counterintuitive property of infinite sets. It is demonstrated that a fully occupied hotel with infinitely many rooms may still accommodate additional guests, even infinitely many of them, and this process may be repeated infinitely often. The idea was introduced by David Hilbert in a 1924 lecture \"Über das Unendliche\", reprinted in , and was popularized through George Gamow's 1947 book \"One Two Three... Infinity\".\n\nConsider a hypothetical hotel with a countably infinite number of rooms, all of which are occupied. One might be tempted to think that the hotel would not be able to accommodate any newly arriving guests, as would be the case with a finite number of rooms, where the pigeonhole principle would apply.\n\nSuppose a new guest arrives and wishes to be accommodated in the hotel. We can (simultaneously) move the guest currently in room 1 to room 2, the guest currently in room 2 to room 3, and so on, moving every guest from his current room \"n\" to room \"n\"+1. After this, room 1 is empty and the new guest can be moved into that room. By repeating this procedure, it is possible to make room for any finite number of new guests.\n\nIt is also possible to accommodate a \"countably infinite\" number of new guests: just move the person occupying room 1 to room 2, the guest occupying room 2 to room 4, and, in general, the guest occupying room \"n\" to room 2\"n\" (2 times \"n\"), and all the odd-numbered rooms (which are countably infinite) will be free for the new guests.\n\nIt is possible to accommodate countably infinitely many coachloads of countably infinite passengers each, by several different methods. Most methods depend on the seats in the coaches being already numbered (or use the axiom of countable choice). In general any pairing function can be used to solve this problem. For each of these methods, consider a passenger's seat number on a coach to be formula_1, and their coach number to be formula_2, and the numbers formula_1 and formula_2 are then fed into the two arguments of the pairing function.\n\nEmpty the odd numbered rooms by sending the guest in room formula_5 to room formula_6, then put the first coach's load in rooms formula_7, the second coach's load in rooms formula_8; for coach number formula_2 we use the rooms formula_10 where formula_11 is the formula_2th odd prime number. This solution leaves certain rooms empty (which may or may not be useful to the hotel); specifically, all odd numbers that are not prime powers, such as 15 or 847, will no longer be occupied. (So, strictly speaking, this shows that the number of arrivals is \"less than or equal to\" the number of vacancies created. It is easier to show, by an independent means, that the number of arrivals is also \"greater than or equal to\" the number of vacancies, and thus that they are \"equal\", than to modify the algorithm to an exact fit.) (The algorithm works equally well if one interchanges formula_1 and formula_2, but whichever choice is made, it must be applied uniformly throughout.)\n\nYou can put each person of a certain seat formula_15 and coach formula_2 into room formula_17 (presuming \"c\"=0 for the people already in the hotel, 1 for the first coach, etc. ...). Because every number has a unique prime factorization, it's easy to see all people will have a room, while no two people will end up in the same room. For example, the person in room 2592 (formula_18) was sitting in on the 4th coach, on the 5th seat. Like the prime powers method, this solution leaves certain rooms empty.\n\nThis method can also easily be expanded for infinite nights, infinite entrances, etc. ... ( formula_19 )\n\nFor each passenger, compare the lengths of formula_1 and formula_2 as written in any positional numeral system, such as decimal. (Treat each hotel resident as being in coach #0.) If either number is shorter, add leading zeroes to it until both values have the same number of digits. Interleave the digits to produce a room number: its digits will be [first digit of coach number]-[first digit of seat number]-[second digit of coach number]-[second digit of seat number]-etc. The hotel (coach #0) guest in room number 1729 moves to room 01070209 (i.e., room 1,070,209.) The passenger on seat 1234 of coach 789 goes to room 01728394 (or just 1728394).\n\nUnlike the prime powers solution, this one fills the hotel completely, and we can reconstruct a guest's original coach and seat by reversing the interleaving process. First add a leading zero if the room has an odd number of digits. Then de-interleave the number into two numbers: the seat number consists of the odd-numbered digits and the coach number is the even-numbered ones. Of course, the original encoding is arbitrary, and the roles of the two numbers can be reversed (seat-odd and coach-even), so long as it is applied consistently.\n\nThose already in the hotel will be moved to room formula_22, or the formula_1th triangular number. Those in a coach will be in room formula_24, or the formula_25 triangular number plus formula_1. In this way all the rooms will be filled by one, and only one, guest.\n\nThis pairing function can be demonstrated visually by structuring the hotel as a one-room-deep, infinitely tall pyramid. The pyramid's topmost row is a single room: room 1; its second row is rooms 2 and 3; and so on. The column formed by the set of rightmost rooms will correspond to the triangular numbers. Once they are filled (by the hotel's redistributed occupants), the remaining empty rooms form the shape of a pyramid exactly identical to the original shape. Thus, the process can be repeated for each infinite set. Doing this one at a time for each coach would require an infinite number of steps, but by using the prior formulas, a guest can determine what his room \"will be\" once his coach has been reached in the process, and can simply go there immediately.\n\nLet formula_27. formula_28 is countable since formula_29 is countable, hence we may enumerate its elements formula_30. Now if formula_31, assign the formula_32th guest of the formula_33th coach to the formula_1th room (consider the guests already in the hotel as guests of the formula_35th coach). Thus we have a function assigning each person to a room; furthermore, this assignment does not skip over any rooms.\n\nSuppose the hotel is next to an ocean, and an infinite number of car ferries arrive, each bearing an infinite number of coaches, each with an infinite number of passengers. This is a situation involving three \"levels\" of infinity, and it can be solved by extensions of any of the previous solutions.\n\nThe prime factorization method can be applied by adding a new prime number for every additional layer of infinity ( formula_36, with formula_37 the ferry).\n\nThe prime power solution can be applied with further exponentiation of prime numbers, resulting in very large room numbers even given small inputs. For example, the passenger in the second seat of the third bus on the second ferry (address 2-3-2) would raise the 2nd odd prime (5) to 49, which is the result of the 3rd odd prime (7) being raised to the power of his seat number (2). This room number would have over thirty decimal digits.\n\nThe interleaving method can be used with three interleaved \"strands\" instead of two. The passenger with the address 2-3-2 would go to room 232, while the one with the address 4935-198-82217 would go to room #008,402,912,391,587 (the leading zeroes can be removed).\n\nAnticipating the possibility of any number of layers of infinite guests, the hotel may wish to assign rooms such that no guest will need to move, no matter how many guests arrive afterward. One solution is to convert each arrival's address into a binary number in which ones are used as separators at the start of each layer, while a number within a given layer (such as a guests' coach number) is represented with that many zeroes. Thus, a guest with the prior address 2-5-1-3-1 (five infinite layers) would go to room 10010000010100010 (decimal 295458).\n\nAs an added step in this process, one zero can be removed from each section of the number; in this example, the guest's new room is 101000011001 (decimal 2585). This ensures that every room could be filled by a hypothetical guest. If no infinite sets of guests arrive, then only rooms that are a power of two will be occupied.\n\nAlthough a room can be found for any finite number of nested infinities of people, the same is not always true for an infinite number of layers, even if a finite number of elements exists at each layer.\n\nThe set of real numbers, and the set of guests in this example, is uncountably infinite. Because no one-to-one pairing can be made between countable and uncountable sets, rooms at the hotel cannot be made for all of these guests, although any countably infinite subset of them can still be accommodated.\n\nIf this variant is modified in certain ways, then the set of people is countable again. For example, suppose there \"were\" a largest ship, directly containing a finite (or countably infinite) number of both ships and people, and each of these ships in turn contained both ships and people, and so forth. This time, any given person is a finite number of levels \"down\" from the top, and thus can be identified with a unique finite address. The set of people is countable again, even if the total number of layers is infinite, because we do not have to consider an \"infinitieth layer\" in either direction.\n\nHilbert's paradox is a veridical paradox: it leads to a counter-intuitive result that is provably true. The statements \"there is a guest to every room\" and \"no more guests can be accommodated\" are not equivalent when there are infinitely many rooms.\n\nInitially, this state of affairs might seem to be counter-intuitive. The properties of \"infinite collections of things\" are quite different from those of \"finite collections of things\". The paradox of Hilbert's Grand Hotel can be understood by using Cantor's theory of transfinite numbers. Thus, while in an ordinary (finite) hotel with more than one room, the number of odd-numbered rooms is obviously smaller than the total number of rooms. However, in Hilbert's aptly named Grand Hotel, the quantity of odd-numbered rooms is not smaller than the total \"number\" of rooms. In mathematical terms, the cardinality of the subset containing the odd-numbered rooms is the same as the cardinality of the set of all rooms. Indeed, infinite sets are characterized as sets that have proper subsets of the same cardinality. For countable sets (sets with the same cardinality as the natural numbers) this cardinality is formula_38.\n\nRephrased, for any countably infinite set, there exists a bijective function which maps the countably infinite set to the set of natural numbers, even if the countably infinite set contains the natural numbers. For example, the set of rational numbers—those numbers which can be written as a quotient of integers—contains the natural numbers as a subset, but is no bigger than the set of natural numbers since the rationals are countable: there is a bijection from the naturals to the rationals.\n\n\n\n"}
{"id": "12943121", "url": "https://en.wikipedia.org/wiki?curid=12943121", "title": "Hindu units of time", "text": "Hindu units of time\n\nHindu texts describe units of Kala measurements, from \"microseconds\" to \"Trillions\" of years. According to these texts, time is cyclic, which repeats itself forever.\n\nVarious fragments of time are used in Hindu Scriptures like Vedas, Bhagavata Purana, Vishnu Puran, Mahabharata, Suryasidhanta etc. A summary of the Hindu metrics of time (\" vyavahāra\") follows.\n\n\n\nThe Lifespan of the pitras is 100 years of pitras (3,000 Solar years).\n\nThe life span of any Hindu deva spans nearly (or more than) 4.5 million years. Statistically, we can also look it as:\n\nThe Time measurement section of the Book I Chapter III explains the above as follows:\n\n(2 \"Kalpas\" constitute a day and night of Brahma, 8.64 billion human years)\n\nOne day of Brahma is divided into 1000 parts called \"charaṇas\".\n\nThe four yugas which come one after the other are as follows (along with their durations): \n\nThe cycle repeats itself, so altogether there are 1,000 cycles of Mahā-Yuga in one day of Brahma.\n\nCurrently, 50 years of Brahma have elapsed. The last Kalpa at the end of the 50th year is called Padma Kalpa. We are currently in the first 'day' of the 51st year. This Brahma's day, Kalpa is named as Shveta-Varaha Kalpa. Within this Day, six Manvantaras have already elapsed and this is the seventh Manvantara, named as – Vaivasvatha Manvantara (or Sraddhadeva Manvantara). Within the Vaivasvatha Manvantara, 27 Mahayugas (4 Yugas together is a Mahayuga), and the Krita, Treta and Dwapara Yugas of the 28th Mahayuga have elapsed. This Kaliyuga is in the 28th Mahayuga. This Kaliyuga began in the year 3102 BCE in the proleptic Julian Calendar. Since 50 years of Brahma have already elapsed, this is the second Parardha, also called as Dvithiya Parardha.\n432000 × 10 × 1000 × 2 = 8.64 billion years (2 Kalpa (day and night))\n8.64 × 10 × 30 × 12 = 3.1104 Trillion Years (1 year of Brahma)3.1104 × 10 × 50 = 155.52 trillion years (50 years of Brahma)\n(6 × 71 × 4320000) + 7 × 1.728 × 10^6 = 1852416000 years elapsed in first six Manvataras, and Sandhi Kalas in the current Kalpa\n27 × 4320000 = 116640000 years elapsed in first 27 Mahayugas of the current Manvantara\n1.728 × 10^6 + 1.296 × 10^6 + 864000 = 3888000 years elapsed in current Mahayuga\n3102 + 2017 = 5119 years elapsed in current Kaliyuga.\nSo the total time elapsed since current Brahma is\n155520000000000 + 1852416000 + 116640000 + 3888000 + 5119 = 155,521,972,949,120 years\n\n(one hundred fifty-five trillion, five hundred twenty-one billion, nine hundred seventy-two million, nine hundred forty-nine thousand, one hundred twenty years) as of 2018 AD\n\nTotal age of Brahma is 100 (Brahma Years) which is equal to 311,040,000,000,000 Human years\nThe current Kali Yuga began at midnight 17 February / 18 February in 3102 BCE in the proleptic Julian calendar. As per the information above about Yuga periods, only 5,120 years are passed out of 432,000 years of current Kali Yuga, and hence another 426,880 years are left to complete this 28th Kali Yuga of Vaivaswatha Manvantara.\n\n\n"}
{"id": "4170137", "url": "https://en.wikipedia.org/wiki?curid=4170137", "title": "Hyde Park Barracks, Sydney", "text": "Hyde Park Barracks, Sydney\n\nThe Hyde Park Barracks Museum is a brick building and compound designed by convict architect Francis Greenway between 1818 and 1819; originally built at the head of Macquarie Street (1819) to house convict men and boys.\n\nThe site is managed by the Historic Houses Trust of New South Wales as a museum open to the public for a modest fee. The site is listed on New South Wales State Heritage Register and the Commonwealth Heritage List, and is inscribed on the UNESCO World Heritage List as one of 11 pre-eminent Australian Convict Sites as amongst \"the best surviving examples of large-scale convict transportation and the colonial expansion of European powers through the presence and labour of convicts.\"\n\nConstructed by convict labour by order of Governor Lachlan Macquarie, the Barracks is one of the most familiar works of the accomplished colonial England-born, Australian architect Francis Howard Greenway. As the principal male convict barracks in New South Wales it provided lodgings for convicts working in government employment around Sydney until its closure in mid-1848.\n\nIt has had many occupants since then. It was an Immigration Depot for single female immigrants seeking work as domestic servants and awaiting family reunion from 1848 to 1886 and also a female asylum from 1862 to 1886. From 1887 to 1979 law courts and government offices were based at the Barracks. Construction began in 1817.\n\nIn 1991, Hyde Park Barracks underwent conservation and adaptation work by award-winning architects Tonkin Zulaikha Greer and conservation architects Clive Lucas Stapleton and Partners. The completed project won the Australian Institute of Architects national Lachlan Macquarie Award in 1992. Now, the newly installed Hyde Park Barracks is a museum operated by the Historic Houses Trust of New South Wales. Tourists who visit the building discover the daily lives of convicts and other occupants through exhibitions on Sydney's male convict labour force, Australia's convict system, an innovative soundscape, excavated artefacts, exposed layers of building fabric and the complex's rooms and spaces.\n\nIn June 2015, Mark Speakman the Minister for the Environment of New South Wales announced Unlocking Heritage, a two-year program aimed at giving children the opportunity to experience Sydney's living museums. This program will allow students to wear convict clothing and sleep in the Barrack's hammocks. A million dollars has been allocated for this program. Museum director Mark Goggin thinks that children will learn more about history if they can experience it hands-on, '\"Particularly for the kids to wear the convict shirts, eat the gruel, sleep over with their mates in hammocks and imagining what life was like 200 years ago.\"' The program is starting out with children and hoping to expand to adult participation.\n\nIn July 2010, at the 34th session of the UNESCO World Heritage Committee, the Hyde Park Barracks and ten other Australian sites with a significant association with convict transportation were inscribed as a group on the World Heritage List as the Australian Convict Sites. The listing explains that the 11 sites present \"the best surviving examples of large-scale convict transportation and the colonial expansion of European powers through the presence and labour of convicts\". Of the 11 sites the Old Great North Road, Old Government House at Parramatta and Cockatoo Island are also within the Sydney region.\n\nAccording to the Living Museum website, the fees for admission as of 2015 are $10 for adult admission, $5 for children or commissions, $20 for families (two adults and two children) and free to members. Group and school tours are available by phoning the museum. Hours of operation are 10am – 5pm daily. Closed on Christmas and Good Friday. The Hyde Barracks are one fourth of the Sydney Living History Museum series. The other three are the Susannah Place Museum, the Museum of Sydney and the Justice & Police Museum. A pass can be purchased at any of the locations that will enable visitors to visit all four locations at a discounted price. Adults $18, Children and Concessions $9. The pass is valid for three months.\n\n\n"}
{"id": "25152980", "url": "https://en.wikipedia.org/wiki?curid=25152980", "title": "Illusionism (philosophy)", "text": "Illusionism (philosophy)\n\nIllusionism is a metaphysical theory first propounded by professor Saul Smilansky of the University of Haifa. It holds that people have illusory beliefs about free will. Furthermore, it holds that it is both of key importance and morally right that people not be disabused of these beliefs, because the illusion has benefits both to individuals and to society. Belief in hard incompatibilism, argues Smilansky, removes an individual's basis for a sense of self-worth in his or her own achievements. It is \"extremely damaging to our view of ourselves, to our sense of achievement, worth, and self-respect\".\n\nNeither compatibilism nor hard determinism are the whole story, according to Smilansky, and there exists an \"ultimate perspective\" in which \"some\" parts of compatibilism are valid and \"some\" parts of hard determinism are valid. However, Smilansky asserts, the nature of what he terms the \"fundamental dualism\" between hard determinism and compatibilism is a morally undesirable one, in that both beliefs, in their absolute forms, have adverse consequences. The distinctions between choice and luck made by compatibilism are important, but wholly undermined by hard determinism. But, conversely, hard determinism undermines the morally important notions of justice and respect, leaving them nothing more than \"shallow\" notions.\n\nSmilansky's thesis is considered a radical one, and other philosophers disagree with it. Professor Derk Pereboom of Cornell University, for example, disagrees that hard incompatibilism necessarily does away with self-worth, because to a large extent that sense of self-worth isn't related to will at all, let alone to free will. Aspects of worthiness such as natural beauty, native physical ability, and intelligence are not voluntary. Professor James Lenman of the University of Glasgow (at the time) takes a similar line, arguing that Smilansky's expression of the problems is overstated. The problems that he presents are less fundamentally metaphysical than simply practical in nature.\n\n"}
{"id": "25680702", "url": "https://en.wikipedia.org/wiki?curid=25680702", "title": "Inequality of bargaining power", "text": "Inequality of bargaining power\n\nIn law, economics and the social sciences, inequality of bargaining power is where one party to a \"bargain\", contract or agreement, has more and better alternatives than the other party. This results in one party having greater \"power\" than the other to choose not to take the deal and makes it more likely that this party will gain more favourable terms. Inequality of bargaining power is where some believe that freedom of contract ceases to be real freedom, or that some have more freedom than others, and that it represents a place at which markets fail.\n\nWhere bargaining power is persistently unequal, the concept of inequality of bargaining power serves as a justification for the implication of mandatory terms into contracts by law, or the non-enforcement of a contract by the courts.\n\nThe concept of inequality of bargaining power was long recognised, particularly with regard to workers. In the \"Wealth of Nations\" Adam Smith wrote,\n\nBeatrice Webb and Sidney Webb in their treatise \"Industrial Democracy\" significantly expanded on the critique of 19th century labour conditions and advocated a comprehensive system of labour law contained a chapter called, \"The Higgling of the Market\". They argued that the labour market was dominated by employers, and therefore had the same effect as monopsony. Workers generally are more under pressure to sell their labour than an employer is under to buy it. An employer can hold out longer, because typically he will have greater financial reserves. This means that much labour is supplied merely out of necessity, than free choice (shifting the supply curve to the right) and it is a false kind of competitive environment. The Webbs also pointed out that discrimination can decrease job opportunities for women or minorities, and that the legal institutions underpinning the market were skewed in favour of employers. Most importantly, they believed that a large pool of unemployed people was a constant downward drag on the ability of workers to bargain for better conditions.\n\nThe Webbs felt that these factors all added up to systemic inequality of bargaining power between workers and employers. The first ever use of the phrase \"inequality of bargaining power\", however, appears to have been by the British philosopher, John Beattie Crozier in \"The Wheel of Wealth\".\n\n\n\"The real measure of market power is not whether a supplier presents his terms on a take-it-or-leave basis but whether the consumer, if he decides to ‘leave it’ has available to him a workably competitive range of alternative sources of supply. Whether this is or is not so simply cannot be derived intuitively from the fact that a particular supplier is offering non-negotiable standard-form terms. It is a matter for independent inquiry. If the market is workably competitive, any supplier offering uncompetitive standard form terms will have to reformulate his total package of price and non-price terms to prevent consumers (at least consumers at the margin, which are the decisive consideration in such a market) from switching their business to other competitors...\n\nNon-economists often overlook the importance of marginal analysis in this context. For example, if only 10 per cent of the buyers of insurance policies or dry-cleaning services studied all terms scrupulously before contracting an were influence in their choice of policy by their evaluation of the so-called fine print clauses, and if no supplier of insurance or dry-cleaning services was able to ‘term discriminate’ between these consumers and other consumers in the market, there would be strong competitive pressures on each supplier to adjust the terms of his contracts so as to avoid losing this potential business...\n\nWhen one asks why, many consumers probably rely in part on the constraints imposed by other consumers at the margin (ie, they let the market shop for them).\"\n\"The point is obvious but worth making because it affects the conditions under which relief should be given: whereas advice as to value will normally save the contract with the ‘poor and ignorant person’, the master of the ship drifting onto the rocks would still have been open to exploitation even if he had had the entire House of Lords on board to advise him.\"\n\n\n\"In so far as the reduction of costs of production and distribution thus achieved is reflected in reduced prices, society as a whole ultimately benefits from the use of standard contracts… The use of contracts has, however, another aspect which has become increasingly important. Standard contracts are typically used by enterprises with strong bargaining power. The weaker party, in need of the goods or services, is frequently not in a position to shop around for better terms, either because the author of the standard contract has a monopoly (natural or artificial) or because all competitors use the same clauses. His contractual intention is but a subjection more or less voluntary to terms dictated by the stronger party, terms whose consequences are often understood only in a vague way, if at all.\"\n\n\n\"The legislature has also recognized the fact, which the experience of legislators in many states has corroborated, that the proprietors of these establishments and their operatives do not stand upon an equality, and that their interests are, to a certain extent, conflicting. The former naturally desire to obtain as much labor as possible from their employees, while the latter are often induced by the fear of discharge to conform to regulations which their judgment, fairly exercised, would pronounce to be detrimental to their health or strength. In other words, the proprietors lay down the rules, and the laborers are practically constrained to obey them. In such cases self-interest is often an unsafe guide, and the legislature may properly interpose its authority.\"\n\n\"The inequality of bargaining power between employees who do not possess full freedom of association or actual liberty of contract and employers who are organized in the corporate or other forms of ownership association substantially burdens and affects the flow of commerce, and tends to aggravate recurrent business depressions, by depressing wage rates and the purchasing power of wage earners in industry and by preventing the stabilization of competitive wage rates and working conditions within and between industries.\"\n\n\"It is easy now to see that Parliament in 1906 might have felt that the only way of giving labour an equality of bargaining power with capital was to give it special immunities which the common law did not permit. Even now, when the scales have been redressed, it is easy to see that Parliament might think that a strike, whether reprehensible or not, ought not to be made a ground for litigation and that industrial peace should be sought by other means.\"\n\n\n\n\n\n"}
{"id": "1763403", "url": "https://en.wikipedia.org/wiki?curid=1763403", "title": "Interactive cinema", "text": "Interactive cinema\n\nInteractive cinema tries to give the audience an active role in the showing of movies. The movie \"Kinoautomat\" by Czechoslovakian director Raduz Cincera presented in the Czech Pavilion at Expo 67 in Montreal is considered to be the first cinema-like interactive movie. The availability of computers for the display of interactive video has made it easier to create interactive movies.\n\nAnother newer definition of interactive cinema is a video game which is a hybrid between participation and viewing, giving the player - or viewer, as it were - a strong amount of control in the characters' decisions. A prominent pioneer of such a technique is the successful Hideo Kojima, whose gameplay often takes a priority to the storyline and long cutscenes. His game \"Policenauts\", a point and click adventure game which has shootout sequences (that make use of the lightgun peripheral on the Sega Saturn version of the game), has a subtitle which reads \"Interactive cinema\" on the cover art of all versions of said game, which is an early example of a prominent game developer labelling their game as such. In 1999, Sega's Shenmue video game series was highly praised for its implementation of interactive cinematic elements. Designed by Yu Suzuki, he stated that his goal \"was to create a game that was intricate and lifelike by merging the cinematic qualities of movies and the interactivity of computer games\". A recent incarnation of an idea similar to this one is \"Fahrenheit\", (censored version released in US and Canada as \"Indigo Prophecy\") a game dubbed as \"interactive cinema\" by its France-based developer, Quantic Dream.\n\n1992 saw the release of North America's first interactive motion picture, I'm Your Man. Certain Loews Theatres locations were retrofitted with controllers to allow audiences to vote on decisions made by the main character. Although initially touted as the first step toward virtual reality cinema, the experiment was a failure and the equipment was removed from theaters by 1994.\n\n\n"}
{"id": "12734024", "url": "https://en.wikipedia.org/wiki?curid=12734024", "title": "Internal affairs doctrine", "text": "Internal affairs doctrine\n\nThe internal affairs doctrine is a choice of law rule in corporations law. Simply stated, it provides that the \"internal affairs\" of a corporation (e.g. conflicts between shareholders and management figures such as the board of directors and corporate officers) will be governed by the corporate statutes and case law of the state in which the corporation is incorporated, sometimes referred to as the lex incorporationis.\n\nThe internal affairs doctrine ensures that such issues as voting rights of shareholders, distributions of dividends and corporate property, and the fiduciary obligations of management are all determined in accordance with the law of the state in which the company is incorporated. On the other hand, the \"external affairs\" of a corporation, such as labor and employment issues and tax liability, are typically governed by the law of the state in which the corporation is doing business. Some issues and activities, such as contracts, mergers and acquisitions, and sales of securities to third parties, may be governed both by the laws of the state of incorporation and by the laws of the state in which the transaction takes place, and in some cases, by federal law as well (for example, United States securities law and antitrust law).\n\nIn the United States, each state has the power to set its own corporate law. Because of this, and the fact that the internal affairs doctrine has been used by courts to allow application of the \"lex incorporationis\", this has created a competitive market for incorporations among the states. Several states have taken advantage of this situation by becoming corporate havens, particularly Delaware and Nevada. Likewise, many jurisdictions apply the internal affairs doctrine internationally, which has permitted offshore financial centres to flourish.\n\n\n"}
{"id": "15387", "url": "https://en.wikipedia.org/wiki?curid=15387", "title": "Irreducible complexity", "text": "Irreducible complexity\n\nIrreducible complexity (IC) is the idea that certain biological systems cannot evolve by successive small modifications to pre-existing functional systems through natural selection. Irreducible complexity is central to the creationist concept of intelligent design, but it is rejected by the scientific community, which regards intelligent design as pseudoscience. Irreducible complexity is one of two main arguments used by intelligent design proponents, the other being specified complexity.\n\nThe theological argument from design was presented in creation science with assertions that evolution could not explain complex molecular mechanisms, and in 1993 Michael Behe, a professor of biochemistry at Lehigh University, presented these arguments in a revised version of \"Of Pandas and People\". In his 1996 book \"Darwin's Black Box\" he called this \"irreducible complexity\" and said it made evolution through natural selection of random mutations impossible. This was based on the mistaken assumption that evolution relies on improvement of existing functions, ignoring how complex adaptations originate from changes in function, and disregarding published research. Evolutionary biologists have published rebuttals showing how systems discussed by Behe can evolve, and examples documented through comparative genomics show that complex molecular systems are formed by the addition of components as revealed by different temporal origins of their proteins.\n\nIn the 2005 \"Kitzmiller v. Dover Area School District\" trial, Behe gave testimony on the subject of irreducible complexity. The court found that \"Professor Behe's claim for irreducible complexity has been refuted in peer-reviewed research papers and has been rejected by the scientific community at large.\"\n\nMichael Behe defined irreducible complexity in natural selection in his book \"Darwin's Black Box\":\n... a single system which is composed of several well-matched, interacting parts that contribute to the basic function, and where the removal of any one of the parts causes the system to effectively cease functioning.\n\nA second definition given by Behe (his \"evolutionary definition\") is as follows:\nAn irreducibly complex evolutionary pathway is one that contains one or more unselected steps (that is, one or more necessary-but-unselected mutations). The degree of irreducible complexity is the number of unselected steps in the pathway.\n\nIntelligent design advocate William A. Dembski gives this definition:\nA system performing a given basic function is irreducibly complex if it includes a set of well-matched, mutually interacting, nonarbitrarily individuated parts such that each part in the set is indispensable to maintaining the system's basic, and therefore original, function. The set of these indispensable parts is known as the irreducible core of the system.\n\nThe argument from irreducible complexity is a descendant of the teleological argument for God (the argument from design or from complexity). This states that because certain things in nature appear very complicated, they must have been designed. William Paley famously argued, in his 1802 watchmaker analogy, that complexity in nature implies a God for the same reason that the existence of a watch implies the existence of a watchmaker. This argument has a long history, and one can trace it back at least as far as Cicero's \"De Natura Deorum\" ii.34, written in 45 BC.\n\nGalen (1st and 2nd centuries AD) wrote about the large number of parts of the body and their relationships, which observation was cited as evidence for creation. The idea that the interdependence between parts would have implications for the origins of living things was raised by writers starting with Pierre Gassendi in the mid-17th century and by John Wilkins (1614-1672), who wrote (citing Galen), \"Now to imagine, that all these things, according to their several kinds, could be brought into this regular frame and order, to which such an infinite number of Intentions are required, without the contrivance of some wise Agent, must needs be irrational in the highest degree.\" In the late 17th-century, Thomas Burnet referred to \"a multitude of pieces aptly joyn'd\" to argue against the eternity of life. In the early 18th century, Nicolas Malebranche wrote \"An organized body contains an infinity of parts that mutually depend upon one another in relation to particular ends, all of which must be actually formed in order to work as a whole\", arguing in favor of preformation, rather than epigenesis, of the individual; and a similar argument about the origins of the individual was made by other 18th-century students of natural history. In his 1790 book, \"The Critique of Judgment\", Kant is said by Guyer to argue that \"we cannot conceive how a whole that comes into being only gradually from its parts can nevertheless be the cause of the properties of those parts\".\n\nChapter XV of Paley's \"Natural Theology\" discusses at length what he called \"relations\" of parts of living things as an indication of their design.\n\nGeorges Cuvier applied his principle of the \"correlation of parts\" to describe an animal from fragmentary remains. For Cuvier, this related to another principle of his, the \"conditions of existence\", which excluded the possibility of transmutation of species.\n\nWhile he did not originate the term, Charles Darwin identified the argument as a possible way to falsify a prediction of the theory of evolution at the outset. In \"The Origin of Species\" (1859), he wrote, \"If it could be demonstrated that any complex organ existed, which could not possibly have been formed by numerous, successive, slight modifications, my theory would absolutely break down. But I can find out no such case.\" Darwin's theory of evolution challenges the teleological argument by postulating an alternative explanation to that of an intelligent designer—namely, evolution by natural selection. By showing how simple unintelligent forces can ratchet up designs of extraordinary complexity without invoking outside design, Darwin showed that an intelligent designer was not the necessary conclusion to draw from complexity in nature. The argument from irreducible complexity attempts to demonstrate that certain biological features cannot be purely the product of Darwinian evolution.\n\nIn the late 19th century, in a dispute between supporters of the adequacy of natural selection and those who held for inheritance of acquired characteristics, one of the arguments made repeatedly by Herbert Spencer, and followed by others, depended on what Spencer referred to as \"co-adaptation\" of \"co-operative\" parts, as in: \"We come now to Professor Weismann's endeavour to disprove my second thesis — that it is impossible to explain by natural selection alone the co-adaptation of co-operative parts. It is thirty years since this was set forth in \"The Principles of Biology.\" In §166, I instanced the enormous horns of the extinct Irish elk, and contended that in this and in kindred cases, where for the efficient use of some one enlarged part many other parts have to be simultaneously enlarged, it is out of the question to suppose that they can have all spontaneously varied in the required proportions.\" Darwin responded to Spencer's objections in chapter XXV of \"The Variation of Animals and Plants under Domestication\" (1868). The history of this concept in the dispute has been characterized: \"An older and more religious tradition of idealist thinkers were committed to the explanation of complex adaptive contrivances by intelligent design. ... Another line of thinkers, unified by the recurrent publications of Herbert Spencer, also saw co-adaptation as a composed, irreducible whole, but sought to explain it by the inheritance of acquired characteristics.\"\n\nSt. George Jackson Mivart raised the objection to natural selection that \"Complex and simultaneous co-ordinations … until so far developed as to effect the requisite junctions, are useless\" which \"amounts to the concept of \"irreducible complexity\" as defined by … Michael Behe\".\n\nHermann Muller, in the early 20th century, discussed a concept similar to irreducible complexity. However, far from seeing this as a problem for evolution, he described the \"interlocking\" of biological features as a consequence to be expected of evolution, which would lead to irreversibility of some evolutionary changes. He wrote, \"Being thus finally woven, as it were, into the most intimate fabric of the organism, the once novel character can no longer be withdrawn with impunity, and may have become vitally necessary.\"\n\nIn 1974 the young Earth creationist Henry M. Morris introduced a similar concept in his book \"Scientific Creationism\", in which he wrote; \"This issue can actually be attacked quantitatively, using simple principles of mathematical probability. The problem is simply whether a complex system, in which many components function unitedly together, and in which each component is uniquely necessary to the efficient functioning of the whole, could ever arise by random processes.\"\n\nIn 1975 Thomas H. Frazzetta published a book-length study of a concept similar to irreducible complexity, explained by gradual, step-wise, non-teleological evolution. Frazzetta wrote: \"A complex adaptation is one constructed of \"several\" components that must blend together operationally to make the adaptation \"work\". It is analogous to a machine whose performance depends upon careful cooperation among its parts. In the case of the machine, no single part can greatly be altered without changing the performance of the entire machine.\" The machine that he chose as an analog is the Peaucellier–Lipkin linkage, and one biological system given extended description was the jaw apparatus of a python. The conclusion of this investigation, rather than that evolution of a complex adaptation was impossible, \"awed by the adaptations of living things, to be stunned by their complexity and suitability\", was \"to accept the inescapable but not humiliating fact that much of mankind can be seen in a tree or a lizard.\"\n\nIn 1981, Ariel Roth, in defense of the creation-science position in the trial \"McLean v. Arkansas\", said of \"complex integrated structures\": \"This system would not be functional until all the parts were there ... How did these parts survive during evolution ...?\"\n\nIn 1985 Cairns-Smith wrote of \"interlocking\": \"How can a complex collaboration between components evolve in small steps?\" and used the analogy of the scaffolding called centering - used to build an arch then removed afterwards: \"Surely there was 'scaffolding'. Before the multitudinous components of present biochemistry could come to lean together \"they had to lean on something else.\"\" However, neither Muller or Cairns-Smith claimed their ideas as evidence of something supernatural.\n\nAn essay in support of creationism published in 1994 referred to bacterial flagella as showing \"multiple, integrated components\", where \"nothing about them works unless every one of their complexly fashioned and integrated components are in place\". The author asked the reader to \"imagine the effects of natural selection on those organisms that fortuitously evolved the flagella ... without the concommitant control mechanisms\".\n\nAn early concept of irreducibly complex systems comes from Ludwig von Bertalanffy (1901-1972), an Austrian biologist. He believed that complex systems must be examined as complete, irreducible systems in order to fully understand how they work. He extended his work on biological complexity into a general theory of systems in a book titled \"General Systems Theory\".\n\nAfter James Watson and Francis Crick published the structure of DNA in the early 1950s, General Systems Theory lost many of its adherents in the physical and biological sciences.\nHowever, Systems theory remained popular in the social sciences long after its demise in the physical and biological sciences.\n\nMichael Behe developed his ideas on the concept around 1992, in the early days of the 'wedge movement', and first presented his ideas about \"irreducible complexity\" in June 1993 when the \"Johnson-Behe cadre of scholars\" met at Pajaro Dunes in California. He set out his ideas in the second edition of \"Of Pandas and People\" published in 1993, extensively revising Chapter 6 \"Biochemical Similarities\" with new sections on the complex mechanism of blood clotting and on the origin of proteins.\n\nHe first used the term \"irreducible complexity\" in his 1996 book \"Darwin's Black Box\", to refer to certain complex biochemical cellular systems. He posits that evolutionary mechanisms cannot explain the development of such \"irreducibly complex\" systems. Notably, Behe credits philosopher William Paley for the original concept (alone among the predecessors) and suggests that his application of the concept to biological systems is entirely original.\n\nIntelligent design advocates argue that irreducibly complex systems must have been deliberately engineered by some form of intelligence.\n\nIn 2001, Michael Behe wrote: \"[T]here is an asymmetry between my current definition of irreducible complexity and the task facing natural selection. I hope to repair this defect in future work.\" Behe specifically explained that the \"current definition puts the focus on removing a part from an already functioning system\", but the \"difficult task facing Darwinian evolution, however, would not be to remove parts from sophisticated pre-existing systems; it would be to bring together components to make a new system in the first place\". In the 2005 \"Kitzmiller v. Dover Area School District\" trial, Behe testified under oath that he \"did not judge [the asymmetry] serious enough to [have revised the book] yet.\"\n\nBehe additionally testified that the presence of irreducible complexity in organisms would not rule out the involvement of evolutionary mechanisms in the development of organic life. He further testified that he knew of no earlier \"peer reviewed articles in scientific journals discussing the intelligent design of the blood clotting cascade,\" but that there were \"probably a large number of peer reviewed articles in science journals that demonstrate that the blood clotting system is indeed a purposeful arrangement of parts of great complexity and sophistication.\" (The judge ruled that \"intelligent design is not science and is essentially religious in nature\".)\n\nAccording to the theory of evolution, genetic variations occur without specific design or intent. The environment \"selects\" the variants that have the highest fitness, which are then passed on to the next generation of organisms. Change occurs by the gradual operation of natural forces over time, perhaps slowly, perhaps more quickly (see punctuated equilibrium). This process is able to adapt complex structures from simpler beginnings, or convert complex structures from one function to another (see spandrel). Most intelligent design advocates accept that evolution occurs through mutation and natural selection at the \"micro level\", such as changing the relative frequency of various beak lengths in finches, but assert that it cannot account for irreducible complexity, because none of the parts of an irreducible system would be functional or advantageous until the entire system is in place.\n\nBehe uses the mousetrap as an illustrative example of this concept. A mousetrap consists of five interacting pieces: the base, the catch, the spring, the hammer, and the hold-down bar. All of these must be in place for the mousetrap to work, as the removal of any one piece destroys the function of the mousetrap. Likewise, he asserts that biological systems require multiple parts working together in order to function. Intelligent design advocates claim that natural selection could not create from scratch those systems for which science is currently unable to find a viable evolutionary pathway of successive, slight modifications, because the selectable function is only present when all parts are assembled.\n\nIn his 2008 book \"Only A Theory\", biologist Kenneth R. Miller challenges Behe's claim that the mousetrap is irreducibly complex. Miller observes that various subsets of the five components can be devised to form cooperative units, ones that have different functions from the mousetrap and so, in biological terms, could form functional spandrels before being adapted to the new function of catching mice. In an example taken from his high school experience, Miller recalls that one of his classmates...struck upon the brilliant idea of using an old, broken mousetrap as a spitball catapult, and it worked brilliantly... It had worked perfectly as something other than a mousetrap... my rowdy friend had pulled a couple of parts --probably the hold-down bar and catch-- off the trap to make it easier to conceal and more effective as a catapult... [leaving] the base, the spring, and the hammer. Not much of a mousetrap, but a helluva spitball launcher... I realized why [Behe's] mousetrap analogy had bothered me. It was wrong. The mousetrap is not irreducibly complex after all.\n\nOther systems identified by Miller that include mousetrap components include the following:\n\nThe point of the reduction is that - in biology - most or all of the components were already at hand, by the time it became necessary to build a mousetrap. As such, it required far fewer steps to develop a mousetrap than to design all the components from scratch.\n\nThus, the development of the mousetrap, said to consist of five different parts which had no function on their own, has been reduced to one step: the assembly from parts that are already present, performing other functions.\n\nThe Intelligent Design argument focuses on the functionality to catch mice. It skips over the case that many, if not all, parts are already available in their own right, at the time that the need for a mousetrap arises.\n\nSupporters of intelligent design argue that anything less than the complete form of such a system or organ would not work at all, or would in fact be a \"detriment\" to the organism, and would therefore never survive the process of natural selection. Although they accept that some complex systems and organs \"can\" be explained by evolution, they claim that organs and biological features which are \"irreducibly complex\" cannot be explained by current models, and that an intelligent designer must have created life or guided its evolution. Accordingly, the debate on irreducible complexity concerns two questions: whether irreducible complexity can be found in nature, and what significance it would have if it did exist in nature.\n\nBehe's original examples of irreducibly complex mechanisms included the bacterial flagellum of \"E. coli\", the blood clotting cascade, cilia, and the adaptive immune system.\n\nBehe argues that organs and biological features which are irreducibly complex cannot be wholly explained by current models of evolution. In explicating his definition of \"irreducible complexity\" he notes that:\nAn irreducibly complex system cannot be produced directly (that is, by continuously improving the initial function, which continues to work by the same mechanism) by slight, successive modifications of a precursor system, because any precursor to an irreducibly complex system that is missing a part is by definition nonfunctional.\n\nIrreducible complexity is not an argument that evolution does not occur, but rather an argument that it is \"incomplete\". In the last chapter of \"Darwin's Black Box\", Behe goes on to explain his view that irreducible complexity is evidence for intelligent design. Mainstream critics, however, argue that irreducible complexity, as defined by Behe, can be generated by known evolutionary mechanisms. Behe's claim that no scientific literature adequately modeled the origins of biochemical systems through evolutionary mechanisms has been challenged by TalkOrigins. The judge in the \"Dover\" trial wrote \"By defining irreducible complexity in the way that he has, Professor Behe attempts to exclude the phenomenon of exaptation by definitional fiat, ignoring as he does so abundant evidence which refutes his argument. Notably, the NAS has rejected Professor Behe's claim for irreducible complexity...\"\n\nBehe and others have suggested a number of biological features that they believe may be irreducibly complex.\n\nThe process of blood clotting or coagulation cascade in vertebrates is a complex biological pathway which is given as an example of apparent irreducible complexity.\n\nThe irreducible complexity argument assumes that the necessary parts of a system have always been necessary, and therefore could not have been added sequentially. However, in evolution, something which is at first merely advantageous can later become necessary. Natural selection can lead to complex biochemical systems being built up from simpler systems, or to existing functional systems being recombined as a new system with a different function. For example, one of the clotting factors that Behe listed as a part of the clotting cascade (Factor XII, also called Hageman factor) was later found to be absent in whales, demonstrating that it is not essential for a clotting system. Many purportedly irreducible structures can be found in other organisms as much simpler systems that utilize fewer parts. These systems, in turn, may have had even simpler precursors that are now extinct. Behe has responded to critics of his clotting cascade arguments by suggesting that homology is evidence for evolution, but not for natural selection.\n\nThe \"improbability argument\" also misrepresents natural selection. It is correct to say that a set of simultaneous mutations that form a complex protein structure is so unlikely as to be unfeasible, but that is not what Darwin advocated. His explanation is based on small accumulated changes that take place without a final goal. Each step must be advantageous in its own right, although biologists may not yet understand the reason behind all of them—for example, jawless fish accomplish blood clotting with just six proteins instead of the full ten.\n\nThe eye is an example of a supposedly irreducibly complex structure, due to its many elaborate and interlocking parts, seemingly all dependent upon one another. It is frequently cited by intelligent design and creationism advocates as an example of irreducible complexity. Behe used the \"development of the eye problem\" as evidence for intelligent design in \"Darwin's Black Box\". Although Behe acknowledged that the evolution of the larger anatomical features of the eye have been well-explained, he pointed out that the complexity of the minute biochemical reactions required at a molecular level for light sensitivity still defies explanation. Creationist Jonathan Sarfati has described the eye as evolutionary biologists' \"greatest challenge as an example of superb 'irreducible complexity' in God's creation\", specifically pointing to the supposed \"vast complexity\" required for transparency.\n\nIn an often misquoted passage from \"On the Origin of Species\", Charles Darwin appears to acknowledge the eye's development as a difficulty for his theory. However, the quote in context shows that Darwin actually had a very good understanding of the evolution of the eye (see fallacy of quoting out of context). He notes that \"to suppose that the eye ... could have been formed by natural selection, seems, I freely confess, absurd in the highest possible degree\". Yet this observation was merely a rhetorical device for Darwin. He goes on to explain that if gradual evolution of the eye could be shown to be possible, \"the difficulty of believing that a perfect and complex eye could be formed by natural selection ... can hardly be considered real\". He then proceeded to roughly map out a likely course for evolution using examples of gradually more complex eyes of various species.\n\nSince Darwin's day, the eye's ancestry has become much better understood. Although learning about the construction of ancient eyes through fossil evidence is problematic due to the soft tissues leaving no imprint or remains, genetic and comparative anatomical evidence has increasingly supported the idea of a common ancestry for all eyes.\n\nCurrent evidence does suggest possible evolutionary lineages for the origins of the anatomical features of the eye. One likely chain of development is that the eyes originated as simple patches of photoreceptor cells that could detect the presence or absence of light, but not its direction. When, via random mutation across the population, the photosensitive cells happened to have developed on a small depression, it endowed the organism with a better sense of the light's source. This small change gave the organism an advantage over those without the mutation. This genetic trait would then be \"selected for\" as those with the trait would have an increased chance of survival, and therefore progeny, over those without the trait. Individuals with deeper depressions would be able to discern changes in light over a wider field than those individuals with shallower depressions. As ever deeper depressions were advantageous to the organism, gradually, this depression would become a pit into which light would strike certain cells depending on its angle. The organism slowly gained increasingly precise visual information. And again, this gradual process continued as individuals having a slightly shrunken aperture of the eye had an advantage over those without the mutation as an aperture increases how collimated the light is at any one specific group of photoreceptors. As this trait developed, the eye became effectively a pinhole camera which allowed the organism to dimly make out shapes—the nautilus is a modern example of an animal with such an eye. Finally, via this same selection process, a protective layer of transparent cells over the aperture was differentiated into a crude lens, and the interior of the eye was filled with humours to assist in focusing images. In this way, eyes are recognized by modern biologists as actually a relatively unambiguous and simple structure to evolve, and many of the major developments of the eye's evolution are believed to have taken place over only a few million years, during the Cambrian explosion. Behe asserts that this is only an explanation of the gross anatomical steps, however, and not an explanation of the changes in discrete biochemical systems that would have needed to take place.\n\nBehe maintains that the complexity of light sensitivity at the molecular level and the minute biochemical reactions required for those first \"simple patches of photoreceptor[s]\" still defies explanation, and that the proposed series of infinitesimal steps to get from patches of photoreceptors to a fully functional eye would actually be considered great, complex leaps in evolution if viewed on the molecular scale. Other intelligent design proponents claim that the evolution of the entire visual system would be difficult rather than the eye alone.\n\nThe flagella of certain bacteria constitute a molecular motor requiring the interaction of about 40 different protein parts. Behe presents this as a prime example of an irreducibly complex structure defined as \"a single system composed of several well-matched, interacting parts that contribute to the basic function, wherein the removal of any one of the parts causes the system to effectively cease functioning\", and argues that since \"an irreducibly complex system that is missing a part is by definition nonfunctional\", it could not have evolved gradually through natural selection.\n\nReducible complexity. In contrast to Behe's claims, many proteins can be deleted or mutated and the flagellum still works, even though sometimes at reduced efficiency. In fact, the composition of flagella is surprisingly diverse across bacteria with many proteins only found in some species but not others. Hence the flagellar apparatus is clearly very flexible in evolutionary terms and perfectly able to lose or gain protein components. Further studies have shown that, contrary to claims of \"irreducible complexity\", flagella and related protein transport mechanisms show evidence of evolution through Darwinian processes, providing case studies in how complex systems can evolve from simpler components. Multiple processes were involved in the evolution of the flagellum, including horizontal gene transfer.\n\nEvolution from Type Three Secretion Systems. Scientists regard this argument as having been disproved in the light of research dating back to 1996 as well as more recent findings. They point out that the basal body of the flagella has been found to be similar to the Type III secretion system (TTSS), a needle-like structure that pathogenic germs such as \"Salmonella\" and \"Yersinia pestis\" use to inject toxins into living eucaryote cells. The needle's base has ten elements in common with the flagellum, but it is missing forty of the proteins that make a flagellum work. The TTSS system negates Behe's claim that taking away any one of the flagellum's parts would prevent the system from functioning. On this basis, Kenneth Miller notes that, \"The parts of this supposedly irreducibly complex system actually have functions of their own.\" Studies have also shown that similar parts of the flagellum in different bacterial species can have different functions despite showing evidence of common descent, and that certain parts of the flagellum can be removed without completely eliminating its functionality.\n\nDembski has argued that phylogenetically, the TTSS is found in a narrow range of bacteria which makes it seem to him to be a late innovation, whereas flagella are widespread throughout many bacterial groups, and he argues that it was an early innovation. Against Dembski's argument, different flagella use completely different mechanisms, and publications show a plausible path in which bacterial flagella could have evolved from a secretion system.\n\nThe cilium construction of axoneme microtubules movement by the sliding of dynein protein was cited by Behe as an example of irreducible complexity. He further said that the advances in knowledge in the subsequent 10 years had shown that the complexity of intraflagellar transport for two hundred components cilium and many other cellular structures is substantially greater than was known earlier.\n\nThe bombardier beetle is able to defend itself by directing a spray of hot fluid at an attacker. The mechanism involves a system for mixing hydroquinones and hydrogen peroxide, which react violently to attain a temperature near boiling point, and in some species a nozzle which allows the spray to be directed accurately in any direction.\n\nThe unique combination of features of the bombardier beetle's defense mechanism—strongly exothermic reactions, boiling-hot fluids, and explosive release—have been claimed by creationists]] and proponents of intelligent design to be examples of irreducible complexity. Biologists such as the taxonomist Mark Isaak note however that step-by-step evolution of the mechanism could readily have occurred. In particular, quinones are precursors to sclerotin, used to harden the skeleton of many insects, while peroxide is a common by-product of metabolism.\n\nLike intelligent design, the concept it seeks to support, irreducible complexity has failed to gain any notable acceptance within the scientific community. One science writer called it a \"full-blown intellectual surrender strategy\".\n\nResearchers have proposed potentially viable evolutionary pathways for allegedly irreducibly complex systems such as blood clotting, the immune system and the flagellum - the three examples Behe proposed. John H. McDonald even showed his example of a mousetrap to be reducible. If irreducible complexity is an insurmountable obstacle to evolution, it should not be possible to conceive of such pathways.\n\nNiall Shanks and Karl H. Joplin, both of East Tennessee State University, have shown that systems satisfying Behe's characterization of irreducible biochemical complexity can arise naturally and spontaneously as the result of self-organizing chemical processes. They also assert that what evolved biochemical and molecular systems actually exhibit is \"redundant complexity\"—a kind of complexity that is the product of an evolved biochemical process. They claim that Behe overestimated the significance of irreducible complexity because of his simple, linear view of biochemical reactions, resulting in his taking snapshots of selective features of biological systems, structures, and processes, while ignoring the redundant complexity of the context in which those features are naturally embedded. They also criticized his over-reliance of overly simplistic metaphors, such as his mousetrap.\n\nA computer model of the co-evolution of proteins binding to DNA in the peer-reviewed journal \"Nucleic Acids Research\" consisted of several parts (DNA binders and DNA binding sites) which contribute to the basic function; removal of either one leads immediately to the death of the organism. This model fits the definition of irreducible complexity exactly, yet it evolves. (The program can be run from Ev program.)\n\nIn addition, research published in the peer-reviewed journal \"Nature\" has shown that computer simulations of evolution demonstrate that it is possible for complex features to evolve naturally.\n\nOne can compare a mousetrap with a cat in this context. Both normally function so as to control the mouse population. The cat has many parts that can be removed leaving it still functional; for example, its tail can be bobbed, or it can lose an ear in a fight. Comparing the cat and the mousetrap, then, one sees that the mousetrap (which is not alive) offers better evidence, in terms of irreducible complexity, for intelligent design than the cat. Even looking at the mousetrap analogy, several critics have described ways in which the parts of the mousetrap could have independent uses or could develop in stages, demonstrating that it is not irreducibly complex.\n\nMoreover, even cases where removing a certain component in an organic system will cause the system to fail do not demonstrate that the system could not have been formed in a step-by-step, evolutionary process. By analogy, stone arches are irreducibly complex—if you remove any stone the arch will collapse—yet humans build them easily enough, one stone at a time, by building over centering that is removed afterward. Similarly, naturally occurring arches of stone form by the weathering away of bits of stone from a large concretion that has formed previously.\n\nEvolution can act to simplify as well as to complicate. This raises the possibility that seemingly irreducibly complex biological features may have been achieved with a period of increasing complexity, followed by a period of simplification.\n\nA team led by Joseph Thornton, assistant professor of biology at the University of Oregon's Center for Ecology and Evolutionary Biology, using techniques for resurrecting ancient genes, reconstructed the evolution of an apparently irreducibly complex molecular system. The April 7, 2006 issue of \"Science\" published this research.\n\nIrreducible complexity may not actually exist in nature, and the examples given by Behe and others may not in fact represent irreducible complexity, but can be explained in terms of simpler precursors. The theory of facilitated variation challenges irreducible complexity. Marc W. Kirschner, a professor and chair of Department of Systems Biology at Harvard Medical School, and John C. Gerhart, a professor in Molecular and Cell Biology, University of California, Berkeley, presented this theory in 2005. They describe how certain mutation and changes can cause apparent irreducible complexity. Thus, seemingly irreducibly complex structures are merely \"very complex\", or they are simply misunderstood or misrepresented.\n\nThe precursors of complex systems, when they are not useful in themselves, may be useful to perform other, unrelated functions. Evolutionary biologists argue that evolution often works in this kind of blind, haphazard manner in which the function of an early form is not necessarily the same as the function of the later form. The term used for this process is exaptation. The mammalian middle ear (derived from a jawbone) and the panda's thumb (derived from a wrist bone spur) provide classic examples. A 2006 article in \"Nature\" demonstrates intermediate states leading toward the development of the ear in a Devonian fish (about 360 million years ago). Furthermore, recent research shows that viruses play a heretofore unexpected role in evolution by mixing and matching genes from various hosts.\n\nArguments for irreducibility often assume that things started out the same way they ended up—as we see them now. However, that may not necessarily be the case. In the \"Dover\" trial an expert witness for the plaintiffs, Ken Miller, demonstrated this possibility using Behe's mousetrap analogy. By removing several parts, Miller made the object unusable as a mousetrap, but he pointed out that it was now a perfectly functional, if unstylish, tie clip.\n\nIrreducible complexity can be seen as equivalent to an \"uncrossable valley\" in a fitness landscape. A number of mathematical models of evolution have explored the circumstances under which such valleys can, nevertheless, be crossed.\n\nSome critics, such as Jerry Coyne (professor of evolutionary biology at the University of Chicago) and Eugenie Scott (a physical anthropologist and former executive director of the National Center for Science Education) have argued that the concept of irreducible complexity and, more generally, intelligent design is not falsifiable and, therefore, not scientific.\n\nBehe argues that the theory that irreducibly complex systems could not have evolved can be falsified by an experiment where such systems are evolved. For example, he posits taking bacteria with no flagellum and imposing a selective pressure for mobility. If, after a few thousand generations, the bacteria evolved the bacterial flagellum, then Behe believes that this would refute his theory.\n\nOther critics take a different approach, pointing to experimental evidence that they believe falsifies the argument for Intelligent Design from irreducible complexity. For example, Kenneth Miller cites the lab work of Barry G. Hall on E. coli, which he asserts is evidence that \"Behe is wrong\".\n\nOther evidence that irreducible complexity is not a problem for evolution comes from the field of computer science, which routinely uses computer analogues of the processes of evolution in order to automatically design complex solutions to problems. The results of such genetic algorithms are frequently irreducibly complex since the process, like evolution, both removes non-essential components over time as well as adding new components. The removal of unused components with no essential function, like the natural process where rock underneath a natural arch is removed, can produce irreducibly complex structures without requiring the intervention of a designer. Researchers applying these algorithms automatically produce human-competitive designs—but no human designer is required.\n\nIntelligent design proponents attribute to an intelligent designer those biological structures they believe are irreducibly complex and therefore they say a natural explanation is insufficient to account for them. However, critics view irreducible complexity as a special case of the \"complexity indicates design\" claim, and thus see it as an argument from ignorance and as a God-of-the-gaps argument.\n\nEugenie Scott, along with Glenn Branch and other critics, has argued that many points raised by intelligent-design proponents are arguments from ignorance. Behe has been accused by critics of using an \"argument by lack of imagination\".\n\nIrreducible complexity is at its core an argument against evolution. If truly irreducible systems are found, the argument goes, then intelligent design must be the correct explanation for their existence. However, this conclusion is based on the assumption that current evolutionary theory and intelligent design are the only two valid models to explain life, a false dilemma.\n\nWhile testifying during the 2005 \"Kitzmiller v. Dover Area School District\" trial, Behe conceded that there are no peer-reviewed papers supporting his claims that complex molecular systems, like the bacterial flagellum, the blood-clotting cascade, and the immune system, were intelligently designed nor are there any peer-reviewed articles supporting his argument that certain complex molecular structures are \"irreducibly complex.\"\n\nIn the final ruling of \"Kitzmiller v. Dover Area School District\", Judge Jones specifically singled out Behe and irreducible complexity:\n\n\n\n"}
{"id": "22780689", "url": "https://en.wikipedia.org/wiki?curid=22780689", "title": "Jamaicans for Justice", "text": "Jamaicans for Justice\n\nJamaicans for Justice (JFJ) is a non-profit, non-partisan human rights organization in Jamaica. JFJ was founded in 1999 in Kingston, Jamaica. The group was co-founded by Jamaican human rights activist Dr. Carolyn Gomes who in 2008 was awarded the United Nations Prize in the Field of Human Rights. The organization is most widely known for providing legal support to hundreds of victims of state abuse in Jamaica and litigation of human rights issues before Jamaican and international tribunals. \n\nJamaican for Justice (JFJ) arose out of the Gas Riots of 16 April 1999. On 19 August 1999 four months after the riots, JFJ came into being. On 15 October, it was officially a legal entity. The founders of JFJ saw strong need for a human rights action group to address the frustrations of the Jamaican people and the systemic abuse by the security forces. These frustrations included many instances of alleged corruption in the public sphere, apparent miscarriages of Justice in the judicial system and imbalances in the socio-economic system. Since its formation, JFJ has also developed working relationships with Amnesty International, USAID Jamaica, The Carter Center, Article 21, Street Law, CEJIL and the Inter-American Commission on Human Rights.\n\nJFJ has represented hundreds of low-income victims of state abuse, leading a number of campaigns in high-profile cases.\n\n\nThe protection of the rights of children in the care of the Jamaican state has been an issue of concern for JFJ since 2001 but came to the fore in 2003 when citizens began to bring problems concerning children to the attention of the organisation. Since that time, JFJ has actively monitored the situation of wards of the state in children’s homes, places of safety, lock-up, remand and correctional facilities to gather data, provide reports and lobby vigorously for the protection of Jamaica’s most vulnerable citizens.\n\nJFJ was co-founded and led for over a decade by prominent activist Dr. Carolyn Gomes, who was awarded the 2008 United Nations Prize in the Field of Human Rights.In 2016, criminologist and civil society organizer Horace Levy was appointed as Executive Director. Levy retired in December, 2017 and was succeeded by present Executive Director, Rodjé Malcolm. \n\n"}
{"id": "37866466", "url": "https://en.wikipedia.org/wiki?curid=37866466", "title": "Juror misconduct", "text": "Juror misconduct\n\nJuror misconduct is when the law of the court is violated by a member of the jury while a court case is in progression or after it has reached a verdict.\n\nMisconduct can take several forms:\n\n\"An inclination of temperament or outlook; especially: a personal and sometimes unreasoned judgement\"\n\nAn example mentioned in Eltis's article \"Courts, Litigants and the Digital Age. Law, Ethics and Practice\" is a juror in Manchester who tweeted openly throughout a rape trial. She was found to be tweeting to her friends and asking them to poll whether they thought that the man being tried was guilty or not; whether he committed the rape or not. Another example was the case of Wardlaw v. State where a member of the jury, against the direct instructions by the judge to not use the Internet, looked up the definition of the illness that the individual on trial was stated to be suffering. This jury member also looked up symptoms and whether lying was an effect of suffering with this mental illness. The juror did learn that lying was in fact a \"symptom\"; however, she chose to gather this information during the discussion to find a verdict.\n\nWhether it is on a phone or using a computer, the Internet has become society’s source for everything. Regarding the place of social media within trials, the Internet has frequently been used by jury members to gain access to additional information about a certain mental illness, or a broader definition or they are outsourcing trial information. The legal system and both the Charter of Rights and Freedoms and both the 5th amendment and 6th amendment in the United States are built around the fact that everyone is required to have a fair trial free from bias. There have been multiple instances where certain cases required retrials because of bias on the part of one or more of the jury members. The Internet, while it is the primary source to find additional information and details about another individual, does not necessarily mean that the information it provides is necessarily correct or accurate. According to Bell’s article, \"Juror Misconduct and the Internet\", the use of the Internet within trials is not a new occurrence. It has been found in many cases, jurors who have searched for words unfamiliar to them, done extensive research, “engaged in at-home experiments, visited accident scenes, and otherwise obtained specialized knowledge.\n\nThese sources seem to revolve around cases which include members of the jury searching for additional information about a certain term or illness that is significant in the case at hand. Usually the main outlets are encyclopedic definitions or Wikipedia. The use of the Internet has also given jurors the ability to easily and readily access information that they may want to find out about. As stated in Bell's article, many jurors do not have the time during breaks to go out to a library and locate hard copy sources of information needed, thus making the Internet the primary source because all it requires is the simple push of a button.\n\nThis type of information includes access to different sources of information such as (1) “information about parties and witnesses” referring to information about a defendant’s past, background information on a specific employer or business, both publicized information and private information such as driving records, and tickets. All this information is easily accessible over the Internet and all this information was shared among jury members in specific cases. The main outlets usually include Twitter, Facebook, and online encyclopedias and dictionaries. This would overthrow the entire trial thus causing an automatic mistrial. 2 “Scientific and Technical Information”. This source of information refers to using the Internet to perform their own form of investigation on the side without actually having to go to the physical scene of the crime. This form of personal investigation may use Google Earth to acquire specific locations and specific fine points about a crime scene such as neighbourhoods, distances between certain homes and areas, etc.\n\nSince the Internet is frequently used to taint certain verdicts, many judges have put bans and limitations on jury members and their use of the Internet. When certain individuals are called to be on jury duty, they are told they are not allowed to communicate with other people who are not involved with the case, and they are told they are not allowed to use the Internet to research anything or to send out or receive any information that would compromise the integrity and fairness of the case at hand. This is definitely a challenge as the Internet is ever present in our society today. Another major problem, aside from the fact that a large majority of people have access to the Internet, is that the information individuals find may not be the entire truth, or may not be 100% accurate. When outside information is brought into a trial, it causes difficulties in ensuring no bias and a fair trial. Having outside information that is also inaccurate adds more bias and more unfairness to a trial.\n\nThis method is rare as it normally only occurs during cases with a heavy media influence and because it involves the constant watch of the actions of jury members individually to ensure they do not use the Internet or ruin the verdict and trial in any manner. This method can become problematic because jury members are only watched during the time when they are ready to deliberate amongst each other to reach a decision.\n\nThis method is slightly more effective because not only will it minimize the amount of jurors to stand during trial, therefore eliminating potential bias and use of outside sources, but it would be useful because it “would also systematically exclude younger jurors and those who otherwise have basic experience using computers and the Internet…”. According to Bell’s article, the main reason behind why outside research is often conducted is because of the desire to satisfy one's curiosity.\n\nIf a jury member is discovered to have brought in outside information, and juror misconduct is clearly present, then the jury member in question may actually be fined by the judge. This seems to be a deterrent to try and prevent future juror misconduct mishaps. It has been found to not be a successful deterrent because it solely shrinks the pool of individuals who wish to participate. A plausible way to prevent this misconduct from taking place is ensuring that the jury members, before the trial, understand completely “what constitutes research, their curiosity, and their perceived “moral duty” to render verdicts based on complete information”. Another successful deterrent is to show how using outside influence is negative, how the life of the individual on trial is in the hands of these chosen jury members (Bell, 94) and to take away their sources of internet, such as phones, before the actual trial commences.\n\nMistrials are the common response in cases where juror misconduct has occurred. Mistrials can be costly and thus will be avoided if possible. When mistrials are seen as a solution, they are compared to wasted assets “when it could have easily been avoided”. If the possibility presents itself, according to Eltis’s article, simply dismissing the misconduct as unacceptable would be less destructive than a mistrial. Dismissing this misconduct will be destructive since it would not cause the trial to be fair. Overall, it is felt that a mistrial is quite a harsh decision, especially since Internet use by a juror is considered “impossible to control”.\n\nUnder the common law, jurors could be charged with contempt of court if they were found to have carried out independent research into the case they were trying. Proving that a juror was guilty of a contempt required proof that she had acted contrary to a judicial order (e.g. to refrain from carrying out research online). This created uncertainty and possible inconsistency, as judicial directions to jurors could vary. The Law Commission of England & Wales felt it would be better to create a separate criminal offence, as this would make the law clearer for jurors. The Law Commission also felt that the creation of a new offence would give jurors suspected of misconduct greater due process protections, as contempt was tried according to summary court procedure, whereas the proposed offence would be an indictable offence, and therefore subject to the due process protections of a full jury trial.\n\nThe Criminal Justice and Courts Act 2015 brought these proposals into law. As Crosby explains:The Act makes it an offence for jurors to ‘research the case during the trial period’, to ‘disclose [improper] information to another member of the jury during the trial period’, and to engage in ‘conduct from which it may reasonably be concluded that the [juror] intends to try the issue otherwise than on the basis of the evidence presented in the proceedings on the issue’. Those found guilty of one of the new offences will be liable to imprisonment for up to two years, and will be disqualified from further service for a decade. What distinguishes these new offences from the existing option of using contempt proceedings is the fact jurors would now be proceeded against on indictment: that they would be tried by their peers for alleged misconduct. This represents a significant change in juror management techniques, as it is probable that criminal trial jurors accused of misconduct have never been tried in this way.Former jurors found guilty of one of the new offences will be disqualified from jury service for ten years, even if they have been fined rather than imprisoned. Such disqualifications had previously required: a sentence of imprisonment; a community order; a community rehabilitation order; a community punishment order; a community punishment and rehabilitation order; a drug treatment and testing order; or a drug abstinence order. The 2015 Act introduces for the first time the principle that a fine may also be sufficient for temporary juror disqualification.\n\n"}
{"id": "1434556", "url": "https://en.wikipedia.org/wiki?curid=1434556", "title": "Kama", "text": "Kama\n\nKama (Sanskrit, Pali; Devanagari: काम) means \"desire, wish, longing\" in Hindu and Buddhist literature. Kama often connotes sexual desire and longing in contemporary literature, but the concept more broadly refers to any desire, wish, passion, longing, pleasure of the senses, the aesthetic enjoyment of life, affection, or love, with or without sexual connotations.\n\nKama is one of the four goals of human life in Hindu traditions. It is considered an essential and healthy goal of human life when pursued without sacrificing the other three goals: Dharma (virtuous, proper, moral life), Artha (material prosperity, income security, means of life) and Moksha (liberation, release, self-actualization). Together, these four aims of life are called Puruṣārtha.\n\nKama means \"desire, wish or longing\". In contemporary literature, kama refers usually to sexual desire. However, the term also refers to any sensory enjoyment, emotional attraction and aesthetic pleasure such as from arts, dance, music, painting, sculpture and nature.\n\nThe concept kama is found in some of the earliest known verses in the Vedas. For example, Book 10 of the Rig Veda describes the creation of the universe from nothing by the great heat. There in hymn 129, it states:\nThe Brhadaranyaka Upanishad, one of the oldest Upanishads of Hinduism, uses the term kama, also in a broader sense, to refer to any desire:\nAncient Indian literature such as the Epics, which followed the Upanishads, develop and explain the concept of kama together with Artha and Dharma. The Mahabharata, for example, provides one of the expansive definitions of kama. The Epic claims kama to be any agreeable and desirable experience (pleasure) generated by the interaction of one or more of the five senses with anything congenial to that sense and while the mind is concurrently in harmony with the other goals of human life (dharma, artha and moksha).\n\nKama often implies the short form of the word kamana (desire, appetition or appetite). Kama, however, is more than kamana. Kama is an experience that includes the discovery of an object, learning about the object, emotional connection, the process of enjoyment and the resulting feeling of well-being before, during, and after the experience.\n\nVatsyayana, the author of the Kamasutra, describes kama as happiness that is a \"manasa vyapara\" (phenomenon of the mind). Just like the Mahabharata, Vatsyayana's \"Kamasutra\" defines kama as pleasure an individual experiences from the world, with one or more senses: ̨hearing, seeing, tasting, smelling, and feeling—in harmony with one's mind and soul. Experiencing harmonious music is kama, as is being inspired by natural beauty, the aesthetic appreciation of a work of art, and admiring with joy something created by another human being. \"Kama Sutra\", in its discourse on kama, describes many forms of art, dance, and music, along with sex, as the means to pleasure and enjoyment.\n\nJohn Lochtefeld explains kama as desire, noting that it often refers to sexual desire in contemporary literature, but in ancient Indian literature kāma includes any kind of attraction and pleasure such as those deriving from the arts.\n\nKarl Potter describes kama as an attitude and capacity. A little girl who hugs her teddy bear with a smile is experiencing kama, as are two lovers in embrace. During these experiences, the person connects and identifies the beloved as part of oneself and feels more complete, fulfilled, and whole by experiencing that connection and nearness. This, in the Indian perspective, is kāma.\n\nHindery notes the inconsistent and diverse expositions of kama in various ancient texts of India. Some texts, such as the Epic Ramayana, paint kama through the desire of Rama for Sita — a desire that transcends the physical and marital into a love that is spiritual, and something that gives Rama his meaning of life, his reason to live. Sita and Rama both frequently express their unwillingness and inability to live without the other. This romantic and spiritual view of kama in the Ramayana by Valmiki is quite different, claim Hindery and others, than the normative and dry description of kama in the law codes of smriti by Manu for example.\n\nGavin Flood explains kama as \"love\" without violating dharma (moral responsibility), artha (material prosperity) and one's journey towards moksha (spiritual liberation).\n\nIn Hinduism, kama is regarded as one of the four proper and necessary goals of human life (purusharthas), the others being Dharma (virtuous, proper, moral life), Artha (material prosperity, income security, means of life) and Moksha (liberation, release, self-actualization).\n\nAncient Indian literature emphasizes that dharma precedes and is essential. If dharma is ignored, artha and kama lead to social chaos.\n\nVatsyayana in \"Kama Sutra\" recognizes relative value of three goals as follows: artha precedes kama, while dharma precedes both kama and artha. Vatsyayana, in Chapter 2 of \"Kama Sutra\", presents a series of philosophical objections argued against kama and then offers his answers to refute those objections. For example, one objection to kama (pleasure, enjoyment), acknowledges Vatsyayana, is this concern that kāma is an obstacle to moral and ethical life, to religious pursuits, to hard work, and to productive pursuit of prosperity and wealth. The pursuit of pleasure, claim objectors, encourages individuals to commit unrighteous deeds, bring distress, carelessness, levity and suffering later in life. These objections were then answered by Vatsyayana, with the declaration that kama is as necessary to human beings as food, and kama is holistic with dharma and artha.\n\nJust like good food is necessary for the well being of the body, good pleasure is necessary for the healthy existence of a human being, suggests Vatsyayana. A life devoid of pleasure and enjoyment—sexual, artistic, of nature—is hollow and empty. Just like no one should stop farming crops even though everyone knows herds of deer exist and will try to eat the crop as it grows up, in the same way claims Vatsyayana, one should not stop one's pursuit of kama because dangers exist. Kama should be followed with thought, care, caution and enthusiasm, just like farming or any other life pursuit.\n\nVatsyayana's book the \"Kama Sutra\", in parts of the world, is presumed or depicted as a synonym for creative sexual positions; in reality, only 20% of \"Kama Sutra\" is about sexual positions. The majority of the book, notes Jacob Levy, is about the philosophy and theory of love, what triggers desire, what sustains it, how and when it is good or bad. \"Kama Sutra\" presents kama as an essential and joyful aspect of human existence.\n\nVatsyayana claims kama is never in conflict with dharma or artha, rather all three coexist and kama results from the other two.\n\nIn Hindu philosophy, pleasure in general, and sexual pleasure in particular, is neither shameful nor dirty. It is necessary for human life, essential for well being of every individual, and wholesome when pursued with due consideration of dharma and artha. Unlike the precepts of some religions, kama is celebrated in Hinduism, as a value in its own right. Together with artha and dharma, it is an aspect of a holistic life. All three \"purusharthas\"—Dharma, Artha and Kama—are equally and simultaneously important.\n\nSome ancient Indian literature observe that the relative precedence of artha, kama and dharma are naturally different for different people and different age groups. In a baby or child, education and kāma (artistic desires) take precedence; in youth kāma and artha take precedence; while in old age dharma takes precedence.\n\nKama is personified as deity Kamadeva and his consort Rati. Deity Kama is comparable to the Greek deity Eros—they both trigger human sexual attraction and sensual desire. Kama rides a parrot, and the deity is armed with bow and arrows to pierce hearts. The bow is made of sugarcane stalk, the bowstring is a line of bees, and the arrows are tipped with five flowers representing five emotions-driven love states. The five flowers on Kama arrows are lotus flower (infatuation), ashoka flower (intoxication with thoughts about the other person), mango flower (exhaustion and emptiness in absence of the other), jasmine flower (pining for the other) and blue lotus flower (paralysis with confusion and feelings). Kama is also known as \"Ananga\" (literally \"one without body\") because desire strikes formlessly, through feelings in unseen ways. The other names for deity Kama include Madan (he who intoxicates with love), Manmatha (he who agitates the mind), Pradyumna (he who conquers all) and Kushumesu (he whose arrows are flowers).\n\nIn Buddhism's Pali Canon, the Gautama Buddha renounced (Pali: \"nekkhamma\") sensuality (\"kama\") in route to his Awakening. Some Buddhist lay practitioners recite daily the Five Precepts, a commitment to abstain from \"sexual misconduct\" (\"kāmesu micchacara\" กาเมสุ มิจฺฉาจารา). Typical of Pali Canon discourses, the Dhammika Sutta (Sn 2.14) includes a more explicit correlate to this precept when the Buddha enjoins a follower to \"observe celibacy or at least do not have sex with another's wife.\"\n\nIn the Theosophy of Blavatsky, Kama is the fourth principle of the septenary, associated with emotions and desires, attachment to existence, volition, and lust.\n\nKamaloka is a \"semi\"-material plane, subjective and invisible to humans, where disembodied \"personalities\", the astral forms, called Kama-rupa remain until they fade out from it by the complete exhaustion of the effects of the mental impulses that created these eidolons of human and animal passions and desires. It is associated with Hades of ancient Greeks and the Amenti of the Egyptians, the land of Silent Shadows; a division of the first group of the \"Trailokya\".\n\n\n\n"}
{"id": "18259273", "url": "https://en.wikipedia.org/wiki?curid=18259273", "title": "Last injurious exposure rule", "text": "Last injurious exposure rule\n\nIn law, the last injurious exposure rule is the principle that when an occupational disease was caused by a succession of jobs, or could have been caused by any one of a succession of jobs, the most recent employer with the risk exposure is liable.\n"}
{"id": "563405", "url": "https://en.wikipedia.org/wiki?curid=563405", "title": "League system", "text": "League system\n\nA league system is a hierarchy of leagues in a sport. They are often called pyramids, due to their tendency to split into an increasing number of regional divisions further down the system. League systems of some sort are used in many sports in many countries.\n\nIn association football, rugby union and rugby league, league systems are usually connected by the process of promotion and relegation, in which teams from a lower division who finish at the top of the standings in their league are promoted (advanced to the next level of the system) while teams who finish lowest in their division are relegated (move down to a lower division). This process can be automatic each year, or can require playoffs.\n\nIn North America, league systems in the most popular sports do not use promotion or relegation. Most professional sports are divided into major and minor leagues. Baseball and association football (known as soccer in North America) have well-defined pyramid shapes to their minor league hierarchies, each managed by a governing body (Minor League Baseball, an organization under the authority of the Commissioner of Baseball, governs baseball leagues; the United States Soccer Federation designates the American soccer pyramid.) Ice hockey's professional minor league system is linear, with one league at most of the four levels of the game; the ice hockey league system in North America is governed by collective bargaining agreements and affiliation deals between the NHL, AHL and ECHL.\n\nGridiron football does not operate on a league system. Different professional leagues play by very different sets of rules in different seasons (the NFL plays 11-a-side on a 100-yard field in autumn and early winter, the CFL uses 12-a-side on a 110-yard field in summer and early fall, while arena football and the minor indoor leagues each play 8-a-side on a 50-yard field in the spring and early summer). There have been attempts at forming true minor leagues for the professional game (most recently with 2017's The Spring League); none so far have been able to balance the major leagues' requests with the ability to maintain financial solvency.\n\n"}
{"id": "33456209", "url": "https://en.wikipedia.org/wiki?curid=33456209", "title": "Learned industriousness", "text": "Learned industriousness\n\nLearned industriousness is a behaviorally rooted theory developed by Robert Eisenberger to explain the differences in general work effort among people of equivalent ability. According to Eisenberger, individuals who are reinforced for exerting high effort on a task are also secondarily reinforced by the sensation of high effort. Individuals with a history of reinforcement for effort are predicted to generalize this effort to new behaviors.\n\nAn individual is considered industrious if he or she demonstrates perseverance and determination in performing a task. This term has also been used interchangeably with work ethic, which is generally regarded as the attitude that hard work and effort is virtuous. Learned industriousness theory asserts that industriousness is developed over time through a history of reinforcement.\n\nLearned helplessness is a term to explain a specific pattern of behavior that occurs in both animals and humans. When an animal or human is consistently exposed to an aversive condition (pain, unpleasant noise, etc.) and is unable to escape this condition, that animal or human will become helpless and stop attempting escape. The animal or human may develop motivational deficits, as demonstrated in learned helplessness experiments. In contrast, learned industriousness theory attempts to explain why some individuals are more motivated than others. In an attempt to merge these two phenomena, Eisenberger, Park, & Frank invoked learned industriousness in children by providing task-contingent verbal approval for a small group of behaviors, contrasting this with a group of children conditioned to exhibit learned helplessness, and a control group. On a subsequent approval-contingent task, children conditioned task-contingent verbal approval outperformed controls. However, the learned-helplessness group performed no differently from controls.\n\nEffort is the subjective experience of fatigue felt by the body when it is in motion or meets resistance. This fatigue can refer to both physical and mental fatigue depending on the task at hand. Until the theory of learned industriousness, effort was generally considered an aversive sensation. Hull summed up this concept with the Law of Least Effort, which asserts that individuals will choose a solution that minimizes effort for any given problem. Learned industriousness theory is considered an addendum to the Law of Least Effort.\n\nIndividuals with high levels of industriousness have a history of applying great effort towards tasks. It has been demonstrated in many studies that different uses of goals result in more effort and task persistence. Thus, specific goal-setting strategies are antecedents to effort and subsequently increase the likelihood of an individual 'learning' industriousness. Below is an overview of the findings.\n\nA goal is defined as the \"object or aim of an action\". As motivational tools, goals have been shown to improve performance in a wide variety of settings. For example, one study looked at the effects of high goals versus low goals on performance. To investigate this effect, students were given goals for a brainstorming activity; those with higher goals were able to brainstorm more ideas than those with lower goals. Therefore, the investigator concluded that goal setting not only increases performance, but more ambitious goals evoke better performance than lower-set goals.\n\nIn addition to improving performance, setting goals also increases task effort and persistence. In one study, participants were assigned to three groups: short-term goals, long-term goals, and a control group with no goals. The participants were then asked to attempt a complicated mirror maze as many times as they would like. Both groups with goals persisted on the maze task significantly longer than the control group, providing evidence that goals promote higher effort and persistence.\n\nAnother facet of goals that has been studied in relation to task persistence is whether the goal is a cooperative or competitive goal structure. A cooperative goal structure is one in which an individual must work alongside a group to reach a common goal, whereas a competitive goal structure is one in which an individual competes with others to reach a goal. The investigators tested whether participants' social values (cooperativeness, competitiveness, and individualism) moderate the relationship between goal structure and task persistence. In accordance with their hypotheses, individuals who were classified as \"cooperators\" persisted longer on the cooperative goal-structured task than the competitive goal-structured task. Similarly, individuals who were classified as \"individualists\" persisted longer on a competitive goal-structured task than a cooperative one. Therefore, the investigators conclude that the effect of \"cooperative versus competitive goal structures on task persistence are influenced by individuals' social values and history of rewarded effort\".\n\nThere are certain aspects of tasks that induce greater effort and persistence: a performer's interest in the task and the level of difficulty of the task. These factors are relevant in creating an environment where an individual is likely to exert more effort and, in turn, become more industrious. Therefore, task interest and task difficulty may both act as moderators in the relationship between effort and industriousness.\n\nTask interest, or an individual's engagement in an activity, is claimed to be an antecedent to the exertion of effort on a task. In a study by Fisher & Noble, the hypothesis that task interest is important for self-regulation during performance and task effort was empirically tested. The findings suggest that task interest positively predicted effort with a significant correlation. While a significant correlation cannot prove causation, there is evidence that higher effort is linked to higher intrinsic motivation. Other studies have supported this finding as well.\n\nTask difficulty is also suggested to precede high effort. The reasoning behind this claim is that high difficulty tasks evoke high effort exertion if the individual is motivated to succeed on the task. The study conducted by Fisher and Noble also supports this hypothesis, as a significant positive relationship between task difficulty and effort was found.\n\nAccording to Daniels & Daniels, reinforcement is any stimulus, event, or situation that fulfills the following two requirements:\n\nA stimulus, event, or situation is considered a reinforcer if it follows a targeted behavior and causes the increased occurrence of that behavior. Many confuse the terms \"reward\" and \"reinforcer\" because they often mean the same thing; a reward is given as a consequence of a desired behavior and often motivates an individual to perform that behavior again in order to receive another reward. However, individuals can receive rewards and not increase the behavior in question (e.g., receiving a prize for completing a marathon may not motivate an individual to run more marathons). In that case, the reward is not a reinforcer because it does not increase the frequency of the behavior. Positive reinforcement is any stimulus that is presented after a behavior and increases the frequency of that behavior. Negative reinforcement is the removal of an aversive stimulus after a behavior that increases the frequency of that behavior. Both positive and negative reinforcement are effective in the development of industriousness.\n\nLearned industriousness theory asserts that reinforcing an individual for achieving a performance standard increases the likelihood of that individual's performing those behaviors again. If the individual exerted high levels of effort during the completion of the task, the effort takes on its own reinforcing value. This is because the individual enjoys the sensation of working hard because it is associated with reinforcement. Therefore, this individual is more likely to generalize this high level of effort to other tasks because it is less aversive and is associated with positive results. On the other hand, the theory also claims that if an individual has a history of being reinforced for completing tasks with very low levels of effort, that individual will eventually generalize this low level of effort to other tasks. This facet of the theory is termed \"learned laziness.\" Evidence for these claims is provided below.\n\nEisenberger's theory claims an essentially dichotomous relationship between effort and reinforcement: the exertion of low effort on a simple tasked paired with high levels of reinforcement will result in low levels of effort on future tasks; on the other hand, the exertion of high effort on a difficult task paired with low levels of reinforcement (intermittent reinforcement) will result in high levels of effort on future tasks. A study conducted by Drucker et al. showed support for this claim. In this study, participants were randomly assigned to computer tasks that ranged in level of difficulty and then given either high or low levels of reinforcement for performance on the task. Participants then were given an anagram task on which their persistence time was measured. In accordance with Eisenberger's theory, individuals who were highly reinforced for performance on the low-difficulty computer task spent less time persisting on the subsequent anagram task, demonstrating that the low level of effort generalized to another activity. Additionally, individuals who were given low levels of reinforcement for performance on the moderately high-difficulty computer task spent more time persisting on the anagram task. This demonstrated that the effort exerted on the first task, paired with low levels of reinforcement, generalized to the following task. However, participants who were given the highest-difficulty computer tasks did not generalize this effort. According to the researchers, this version of the task was so difficult that the participants could not succeed and thus demonstrated a pattern of behaviors similar to learned helplessness.\n\nIn addition to being an antecedent to industriousness, effort is the foremost consequence of learned industriousness theory. As predicted by the theory, multiple experimental studies have demonstrated increased effort when paired with reinforcement.\n\nPierce, Cameron, Banko, and So conducted two studies in directly testing Eisenberger's theory. Mimicking Drucker's methodology, the authors placed participants in a task that was of either constant or progressively higher difficulty and then either rewarded for completing the task or not rewarded (a 2x2 experiment). Afterwards the participants were presented with a difficult free-choice task. Participants who were in the progressive difficulty-reward condition spent more time on the free-choice task, especially compared to the constant difficulty-reward condition (who spent the least amount of time). A year later, Cameron, Pierce, and So repeated the experiment, this time with an easy/difficult task condition split instead of a constant/progressive difficulty condition split. Not only did participants in the difficult-reward condition put forth more effort in the free-choice phase, the authors found that participants who were rewarded for completing the difficult task performed better on the free choice task than those who were not rewarded. Additionally, participants who were rewarded for completing the easy task performed worse on the free choice task than those who were not rewarded.\n\nAnother similar study found that the secondary effort reinforcement, both positive and negative, is equally transferable to tasks other than the one originally used in the conditioning.\n\nThere have been many studies looking at the links between creativity and rewards. Many argue that if students are rewarded for a task such as creativity, they will be less interested, perform worse, and enjoy the task less once the reward is removed. Eisenberger applied his learned industriousness theory to studies of creativity to show that extrinsic rewards do not always negatively affect intrinsic motivation or creativity.\n\nUsing a similar training, Eisenberger and Selbst performed a series of experiments looking at whether creativity and divergent thought could be conditioned in the same manner as effort. Participants performed a task where they pulled letters out of a long word to create different words and were either given a performance standard (high difficulty condition) or no performance standard (low difficulty condition). After completing five rounds of words, the participants were instructed to make as many unique drawings from a circle as they could. The pictures were judged for uniqueness and general creativity.\n\nThe authors found similar results to previous learned industriousness studies: participants in the high difficulty-low reward condition showed more creativity in the circle drawing task than those without a reward while participants in the low difficulty-low reward showed even less creativity. Although most creativity research up until that point suggested that any reward for creative thoughts reduced generalized creativity, this study showed that increases or decreases in generalized creativity depend on whether or not high or low divergent thought is rewarded.\n\nCurrently the area of study that learned industriousness has been cited in the applied world is smoking and drug cessation research. An example of such research is Quinn et al.'s correlational study which examined the levels of persistence of smokers vs. non-smokers using the Anagram Persistence Task (APT) and the Mirror-Tracing Persistence Task (MTPT). As predicted, non-smokers had higher levels of persistence than smokers. The authors suggested that people who have been reinforced with high effort throughout their lives would be more persistent in their use of strategies for coping with stress than smokers and that people reinforced with low effort would be more likely to use low effort strategies when coping with stress (such as smoking). In addition, people with low persistence are less likely to produce the high effort behaviors required to quit smoking. Adding support to Brandon et al.'s hypotheses is a study by Brown, Lejuez, Kahler, & Strong. The authors found that smokers who have never been able to quit for more than a day had lower levels of persistence than those who were able to quit for at least 3 months at a time.\n\nAnother study by Brandon, Herzog, Juliano, Irvin, Lazev, & Simmons continued the work of the previous two by using a longitudinal perspective. After testing for persistence using the APT and the MTPT, the participants went through eleven days of smoking cessation therapy that included cognitive-behavioral therapy, training on coping strategies, and nicotine replacement therapy. Participants were then contacted on a monthly basis for 6 months and then at 9 and 12 months for updates on their smoking habits. In addition to supporting previous findings that smokers perform worse on persistence tasks, participants who scored higher on the persistence tasks were less likely to relapse during the 12-month period of the study. Although the study was again limited because of its correlational design, the authors suggest that their results fit within the theoretical framework of learned industriousness.\n\nAn additional study by Steinberg et al. looking at adolescents and smoking found much of the same results as Brandon et al. Non-smoking adolescents scored higher on a self-reported persistence measure than smokers and smokers who planned on quitting scored higher than those who did not plan on quitting.\n\nThere are several areas in which the literature on learned industriousness can be expanded. Due to the unclear results of Eisenberger's study of a Learned Industriousness-Learned Helplessness Continuum, further research should be done to provide evidence for or against its existence. This research could be useful for personnel selection purposes and understanding performance in the workplace. Also, the most current smoking-related learned industriousness research has been correlational; experimental studies could not only be powerful evidence for the theory but also generate important practical contributions for smoking cessation therapy.\n\n\n"}
{"id": "58077499", "url": "https://en.wikipedia.org/wiki?curid=58077499", "title": "Louis Vialleton", "text": "Louis Vialleton\n\nLouis Marius Vialleton (December 22, 1859 - December 18, 1929) was a French zoologist and writer, best known for his advocation of non-Darwinian evolution.\n\nVialleton was born in Vienne. He was the first professor of histology in the faculty of medicine at the University of Montpellier. Vialleton rejected any form of continuous evolution and favoured saltationism.\n\nVialleton attempted to refute gradual transformism from a morphological perspective in his work \"Morphologie générale Membres et ceintures des vertébrés tétrapodes: Critique morphotogique du transformisme\" (1924). Zoologist Étienne Rabaud responded with a critical article.\n\nHe contributed the chapter \"Morphologie et transformisme\" to the book \"Le Transformisme\" (1927). Vialleton's views were often misrepresented by creationists as anti-evolutionary. His writings were influential to creationists such as Douglas Dewar. However, he did not reject evolution. He was also incorrectly described as a critic of evolution by A. Morley Davies.\n\nVialleton was a vitalist.\n\n\n"}
{"id": "1193738", "url": "https://en.wikipedia.org/wiki?curid=1193738", "title": "Lucy Burns", "text": "Lucy Burns\n\nLucy Burns (July 28, 1879 – December 22, 1966) was an American suffragist and women's rights advocate. She was a passionate activist in the United States and in the United Kingdom. Burns was a close friend of Alice Paul, and together they ultimately formed the National Woman's Party.\n\nBurns was born in New York to an Irish Catholic family. She was described by fellow National Woman's Party member Inez Haynes Irwin as \"blue-eyed and fresh-complexioned; dimpled; and her head is burdened, even as Alice Paul's, with an enormous weight of hair.\" She was extremely beautiful, and lewd men always treated her disrespectfully. She was a gifted student and first attended Packer Collegiate Institute, or what was originally known as the Brooklyn Female Academy, for second preparatory school in 1890. Packer Collegiate Institute prided itself on \"teaching girls to be ladies\", and they emphasized religious education while advocating more liberal ideals such as educating \"the mind to habits of thinking with clearness and force.\" Burns also met one of her lifelong role models, Laura Wylie, while attending Packer Collegiate Institute. Wylie was one of the first women to go to Yale University Graduate School. Burns also attended Columbia University, Vassar College, and Yale University before becoming an English teacher.\n\nBurns taught at Erasmus High School in Brooklyn for two years. While Burns enjoyed the educational field, she generally found the experience to be frustrating and wanted to continue her own studies. In 1906, at age twenty-seven, she moved to Germany to resume her studies in language. In Germany, Burns studied at the Universities of Bonn and Berlin from 1906 to 1909. Burns later moved to the United Kingdom, where she enrolled at Oxford University to study English. Burns was fortunate enough to have a very extensive educational background because her father, Edwards Burns, supported her and financed her international education.\n\nBurns's first major experiences with activism were with the Pankhursts in the United Kingdom from 1909 to 1912. While attending graduate school in Germany, Lucy Burns traveled briefly to England where she met Emmeline Pankhurst and her daughters Christabel and Sylvia. She was so inspired by their activism and charisma that she dropped her graduate studies to stay with them and work in the Women's Social and Political Union, an organization dedicated to fighting for women's rights in the United Kingdom. Burns was employed by the Women's Social and Political Union as a salaried organizer from 1910 to 1912. While working with the Pankhursts in the United Kingdom, Lucy Burns became increasingly passionate about activism and participated in numerous campaigns with the WSPU. One of her first major contributions was organizing a parade in Edinburgh as part of the campaign in Scotland in 1909. While Burns is not a widely known speaker from the woman's rights movement, she did make a variety of speeches in marketplaces and on street corners while in Europe. Her activism resulted in numerous court appearances and reports of \"disorderly conduct\" in the newspapers. In August 1909, she hid on the roof of the St Andrew's Hall in Glasgow She planned to break through the roof and disrupt a political speech by the Earl of Crewe in front of an all-male audience. \n\nWhile working with the WSPU, Lucy Burns met Alice Paul at a London police station. Both women had been arrested for demonstrating, and Alice Paul introduced herself when she noticed that Lucy Burns was wearing an American flag pin on her lapel. The women discussed their suffrage experiences in the United Kingdom and the American women's movement. Burns and Paul bonded over their frustration with the inactivity and ineffective leadership of the American suffrage movement by Anna Howard Shaw. Their similar passions and fearlessness in the face of opposition made them quickly become good friends. Both women were passionate about activism, and the feminist struggle for equality in the UK inspired Burns and Paul to continue the fight in the United States in 1912.\n\nSuffrage historian Eleanor Clift compares the partnership of Paul and Burns to that of Susan B. Anthony and Elizabeth Cady Stanton. She notes that they \"were opposites in appearance and temperament... [w]hereas Paul appeared fragile, Burns was tall and curvaceous, the picture of vigorous health...unlike Paul, who was uncompromising and hard to get along with, Burns was pliable and willing to negotiate. Paul was the militant; Burns, the diplomat.\" Despite their stark differences, Paul and Burns worked together so effectively that followers would often describe them as having \"one mind and spirit.\".\n\nUpon returning to the United States, Paul and Burns joined the National American Women Suffrage Association (NAWSA) as leaders of its Congressional Committee. Both women felt it was critical to hold the political party in power responsible for a federal suffrage amendment. By holding an entire party accountable, Paul and Burns believed that congressmen would be forced to take action or risk losing their seats. This militant tactic was presented by Paul and Burns at the 1912 NAWSA convention in Philadelphia to Anna Howard Shaw and other NAWSA leaders. NAWSA leaders rejected their proposal because they felt any action against the Democratic Party, which had just won the presidential election, was premature at that point. Not willing to back down without a fight, Burns and Paul enlisted the help of Jane Addams, a well-respected and more unorthodox NAWSA leader, to petition their cause to her fellow NAWSA leaders. While the women were forced to tone down their proposal, NAWSA leaders did authorize a suffrage parade during Woodrow Wilson's inauguration. NAWSA's one stipulation was that Paul and Burns' Congressional Committee would receive no further funding from NAWSA. While Burns and Paul readily agreed to this stipulation, this event marked the beginning of their divide with NAWSA.\n\nBecause of the arguments over tactics and funding, Burns and Paul felt it would be best if they added to NAWSA's Congressional Committee and formed a group still associated with NAWSA, but one with its own governing body. This new committee was called the Congressional Union of the National American Women Suffrage Association. Burns was elected unanimously as an executive member of the Congressional Union of the National American Women Suffrage Association. In April 1913, NAWSA decided they wanted to distance themselves from the more radical group and no longer allowed their name to be used in the title, so the Congressional Union of the National American Women Suffrage Association was renamed just the Congressional Union. Despite this, Burns and Paul still wanted the Congressional Union to be associated with NAWSA, so they applied for it to be considered a NAWSA auxiliary. The Congressional Union was granted auxiliary membership, but the relationship remained tenuous.\n\nAdding to the growing tensions between the Congressional Union and NAWSA, Burns made a radical proposal once again at the 1913 NAWSA convention in Washington, D.C. Because Democrats controlled the White House and both houses of Congress at the time, Burns wanted to give them an ultimatum—support our bill for suffrage or we will make sure you don't get reelected. Burns stated \"Inaction establishes just as clear a record as does a policy of open hostility.\" She was no longer going to stand for the apathy from the Democratic Party. Burns was particularly infuriated with President Wilson because he had told them he would support the Committee on Suffrage, but then never mentioned his promise in his address to Congress. When a delegation of women from NAWSA tried to meet with him to address this incident and register their protest, Wilson claimed to be ill. A few days later, Wilson reneged his vow to support suffrage and said he would not impose his private views on Congress.\n\nNAWSA felt they could no longer tolerate the radical tactics employed and advocated by the Congressional Union, and they wanted to officially sever their ties. Paul and Burns did not want to start a completely separate organization that could potentially rival NAWSA and hinder progress in the movement, so they tried on numerous occasions to initiate negotiations with NAWSA leaders. Despite their efforts, the Congressional Union officially split from NAWSA on February 12, 1914.\n\nMany predicted that this split would do irreparable harm to women's campaign for suffrage; the cynics did not discourage Paul and Burns, and they began planning their campaign against the Democrats in the summer of 1914. In addition to confronting the Democratic Party, Burns and Paul had to address displeased members within their own organization; some women were complaining that the Congressional Union was elitist, authoritarian, and undemocratic. Paul believed centralized authority was critical to accomplishing their goals and operating effectively, so they did not make any drastic changes; to appease their members they solicited suggestions and stated \"We would be most grateful for any constructive plan which you can lay before us.\"\n\nWhile trying to address both internal and external attacks, the Congressional Union worked to keep the Anthony amendment afloat in 1914. The Anthony amendment, or Mondell Resolution, was a federal amendment for woman's suffrage and what would ultimately become the nineteenth amendment. Since their split from NAWSA, Ruth Hanna McCormick had become the chairwoman of NAWSA's Congressional Committee. Without consulting the NAWSA Board, she had endorsed the alternative Shafroth-Palmer amendment on their behalf. This posed a huge threat to the work of Burns and Paul because the Shafroth amendment, if passed, would make suffrage a states' rights only issue. While Burns, Paul, and other women from both the Congressional Union and NAWSA met to address this issue, NAWSA ultimately remained in support of the Shafroth amendment, and the Congressional Union continued its campaign for federal suffrage.\n\nBurns was the first woman to speak before the Congressional delegates in 1914, when the Anthony amendment finally made it out of committee and into the House. While her speech was primarily intended to set the stage for Alice Paul, she also outlined the accomplishments of the Congressional Union. The fact that she was the first to speak at such a critical time for federal suffrage shows not only her courage in the face of opposition, but how well respected she was by her fellow leaders and suffragists. The speeches of Burns and Paul were incredibly important at that time in the movement because they showed politicians that women would unite as a voting bloc.\n\nFollowing this, the Congressional Union sent two organizers to each of the nine states where women had the right to vote. Burns went to San Francisco, California with suffragist Rose Winslow. Organizing women in these states was not an easy task, and raising adequate funds was found to be particularly troublesome; Burns is quoted as saying \"If the women here, however, would only give me the money they are willing to spend on luncheons and dinners I will get along admirably.\" Burns spread the message about suffrage in theaters, on the streets, by going door-to-door, and by circulating cartoons and pamphlets. By election time in 1914 the Democratic Party had become an extremely vocal critic of the Congressional Union, and ultimately the Congressional Union claimed responsibility for five Democratic losses.\n\nIn 1915 the Congressional Union decided to put its efforts into organizing in every state that did not already have a branch. The goal of this plan was to continue what their 1914 state-by-state campaign had started and make suffrage a national issue with demand in every state. In 1915 Burns also became the editor of the Congressional Union's newspaper \"The Suffragist\". During this time period, NAWSA was experiencing a lot of internal strife. After their convention in 1915, Anna Howard Shaw stepped down as president, and many believed this would be a time for potential reconciliation between the Congressional Union and NAWSA.\n\nBurns and Paul met with NAWSA officials and other women from the Congressional Union at the Willard Hotel in Washington, D.C. on December 17, 1915. NAWSA wanted the Congressional Union to become an affiliate but they had numerous demands—the Congressional Union was to end its anti-Democratic Party campaign and never wage any political campaigns in the future. These demands were viewed as completely unreasonable, and the meeting ended without any reconciliation or possibility of future attempts.\n\nAfter all of the turmoil of the past few years, Alice Paul announced a radical new plan for 1916—she wanted to organize a woman's political party. Burns adamantly supported this plan and on June 5, 6 and 7, 1916 at the Blackstone Theater in Chicago, delegates and female voters met to organize the National Woman's Party (NWP). Burns and Paul were committed to direct action in fighting for women's rights and particularly their right to vote. They were opposed by more conservative suffragists who advocated less militant tactics. NAWSA leaders thought the tactics of the National Woman's Party were futile and would alienate Democrats that were sympathetic to suffrage. Membership in the NWP was limited to only enfranchised women, and their sole goal was promoting a federal amendment for woman's suffrage.\n\nBurns played a large role in the National Woman's Party. She worked in virtually every aspect of the organization at one time or another. Specifically, she was a chief organizer, lobby head, newspaper editor, suffrage educator, teacher, orator, architect of the banner campaign, rallying force, and symbol of the NWP. In Burns 'suffrage schools', she taught women how to conduct automobile campaigns, lobby, and work with the press. She was savvy with working with the media and supplied two hundred news correspondents with frequent news bulletins.\n\nThe National Woman's Party led dozens of women to picket the White House in Washington, D.C. as Silent Sentinels beginning in January 1917. A bi-partisan organization, it directed its attacks at the office of the President of the United States, in this case, Woodrow Wilson. Burns also opposed World War I, seeing it as a war led by powerful men that resulted in young men being drafted and giving their lives with little free will. Throughout her career with the National Woman's Party, Burns was known to have a bitter sense of injustice and become angry because of the actions of the President or apathetic Americans.\n\nBurns was arrested while picketing the White House and was sent to Occoquan Workhouse. In jail, Burns joined Alice Paul and many other women in hunger strikes to demonstrate their commitment to their cause, asserting that they were political prisoners. Burns was prepared for the hunger strikes since she had previously participated in them in Europe with the WSPU. Being imprisoned did not stop Burns' activism. From within the workhouse she organized protests with other prisoners.\n\nBurns also helped organize and circulate one of the first documents that defined the status of political prisoners. This document described the rights of political prisoners and listed their demands for an attorney, family visits, reading and writing materials, and food from outside the prison. It was circulated through holes in the walls until every suffrage prisoner had signed it. Once prison officials realized what Burns was doing, they had her transferred to a district jail and put in solitary confinement.\n\nAfter Burns was released, she was quickly rearrested for continuing protests, picketing, and marching at the White House. Upon her third arrest in 1917, the judge aimed to make an example of Burns, and she was given the maximum sentence. Once again a prisoner at Occoquan Workhouse, Lucy Burns endured what is remembered as the \"Night of Terror.\" The women were treated brutally and were refused medical attention. To unite the women, Burns tried to call roll and refused to stop despite numerous threats by the guards. When they realized Lucy Burns's spirit was not going to be easily broken, they handcuffed her hands above her head to her cell door and left her that way for the entire night. Burns was so loved and respected by her fellow suffragists that the women in the cell across from her held their hands above their head and stood in the same position. Despite her courage and extraordinary leadership skills, the burden of working so diligently did bother Burns at times; she once told Alice Paul, \"I am so nervous I cannot eat or sleep. I am such a coward I ought to be a village seamstress, instead of a Woman's Party organizer.\"\n\nAfter enduring the torture of the \"Night of Terror,\" the women refused to eat for three days. The guards tried to tempt the women with fried chicken, but this was only viewed as an insult; Burns told the other women \"I think this riotous feast which has just passed our doors is the last effort of the institution to dislodge all of us who can be dislodged. They think there is nothing in our souls above fried chicken.\"\n\nRealizing something urgent needed to be done or he would potentially have dead prisoners on his hands, the warden moved Burns to another jail and told the remaining women that the strike was over. He also ordered Burns to be force fed. Historian Eleanor Clift recounts that the force feeding of Lucy Burns required \"five people to hold her down, and when she refused to open her mouth, they shoved the feeding tube up her nostril.\" This treatment was extremely painful and dangerous, causing Burns to have severe nosebleeds. Of the well-known suffragists of the era, Burns spent the most time in jail.\n\nBurns and other suffragists had been told by the chairman of the House Committee on Suffrage that the House would not pass a suffrage amendment before 1920. To their surprise, it was announced in late 1917 that the House would make a decision on January 10, 1918. The amendment passed in the House by a vote of 274 to 136, and the women of the NWP, including Burns, began working on the 11 additional votes they would need for the amendment to pass in the Senate. Unfortunately on June 27, 1918, the Senate narrowly failed to pass the amendment.\n\nBurns and Paul were enraged, but after coming so close there was no chance that they were going to give up now. They resumed their protests at the White House on August 6, 1918. Once again the women were jailed, exposed to horrendous conditions, and released shortly thereafter. Their focus then was moved to helping pro-suffrage candidates get elected in November. For the first time, the NWP did not give allegiance to one party over another; they supported anyone who was willing to support suffrage, and this cost the Democrats their majority in Congress.\n\nAs tensions grew between the suffragists and President Wilson, he realized something had to be done quickly to end the highly publicized protests and clashes between the police and suffragists. He requested that Congress convene for a special session in May 1919. On May 21 the House of Representatives passed the Susan B. Anthony amendment 304 to 89, and on June 4, the Senate passed it 66 to 30. Surprisingly, the suffragists were very subdued at the announcement of this victory. The suffragists battle was not yet over; they still had to make sure a majority of the states ratified the amendment. Finally in August 1920, Tennessee became the thirty-sixth state to ratify the Anthony amendment, and Burns' quest for federal suffrage was finally over.\n\nAt this point Burns was completely exhausted and quoted as saying \"I don't want to do anything more. I think we have done all this for women, and we have sacrificed everything we possessed for them, and now let them fight for it now. I am not going to fight anymore.\" All of her time spent in jail and experiences as a suffragist had left her bitter towards married women and others who didn't take action during the suffrage movement. After the women of the United States gained the right to vote, Burns retired from political life and devoted herself to the Catholic Church and her orphaned niece. She died on December 22, 1966 in Brooklyn, New York.\n\nIn 2004, HBO Films broadcast \"Iron Jawed Angels\", chronicling the voting rights movement of Lucy Burns, Alice Paul, and other suffragists. Burns was portrayed by Australian actress Frances O'Connor.\n\nThe Lucy Burns Institute, a nonprofit educational organization located in Madison, Wisconsin, is named after Burns.\n\nA suffragist museum called the Lucy Burns Museum is being constructed at the former site of the Occoquan Workhouse, where the \"Night of Terror\" took place.\n\n\n\n"}
{"id": "7951430", "url": "https://en.wikipedia.org/wiki?curid=7951430", "title": "Malay units of measurement", "text": "Malay units of measurement\n\nUnits of measurement used in Malaysia and neighbouring countries include the \"kati\", a unit of mass, and the \"gantang\", a unit of volume.\n\nIn measuring amount by mass, the common unit is \"kati\", which is about 1 lb (604.79 g). A higher unit is \"pikul\" or \"picul\", which is 100 \"kati\" or .\n\nIn measuring amount by volume, the common unit is \"gantang\" (gallon), which is equivalent to or 8 pints. \nTo make it clear,\nGantang equals a Gallon. A Gallon has sub measurements of 4 Quarts, or 8 Pints, or 16 Cups. A Gantang has sub measurements of 4 Churpak, or 8 Leng, or 16 Chentong. \nChurpak equals a Quart.\nLeng equals a Pint.\nChentong equals a Cup.<ref>\n\n\"Chentong\" is also normally used only in certain areas, and so eight \"leng\" makes up a \"gantang\".\n\nWhen used to measure unhusked rice, a \"gantang\" weights about .\n\n"}
{"id": "2565663", "url": "https://en.wikipedia.org/wiki?curid=2565663", "title": "Masking (personality)", "text": "Masking (personality)\n\nMasking is a process in which an individual changes or \"masks\" their natural personality to conform to social pressures, abuse, and/or harassment. Some examples of masking are a single overly dominant temperament, or humor, two incongruent temperaments, or displaying three of the four main temperaments within the same individual. Masking can be strongly influenced by environmental factors such as authoritarian parents, rejection, and emotional, physical, or sexual abuse. An individual may not even know he or she is wearing a mask because it is a behavior that can take many forms.\n\nMasking should not be confused with masking behavior which is to mentally block feelings of suffering as a survival mechanism.\n\nThe term masking was first used to describe the act of concealing disgust by \nEkman (1972) and Friesen (1969). It was also thought of as a learned behavior. Developmental studies have shown that this ability has begun as early as preschool and improves with age. In recent developmental studies, masking has evolved and is now defined as concealing one's emotion by portraying another emotion. It is mostly used to conceal a negative emotion (usually sadness, frustration, and anger) with a positive emotion.\n\nContextual factors including relationships with one's conversation partner, status differences, location, and social setting are all reasons as to why an individual would express, suppress, or mask an emotion. Masking is a facade to behave in certain ways that would help one hide their emotions and represses emotions that are not approved by those around them. Because a person wants to receive acceptance from the public, masking helps disguise characteristics like anger, jealousy or rage - emotions that would not be considered socially acceptable.\n\n\nMasking negative emotions differ for each gender. Females tend to have an easier time hiding their negative emotions towards something they dislike than males do. One of the disputable reasons as to why females are able to mask their negative emotions better is society's pressure that a girl must act nice.\n\nMasking also differs between cultures. Some studies state that certain cultures tend to moderate their expressions of emotion while others show a greater amount of positive emotions and expressions.\n\nEach person masks their emotions differently. During one's childhood, an individual learns to behave a certain way when they receive approval from those around them and thus develops a mask. The individual is \"not conscious of the role they've adopted and is projecting outwards to people they meet\". In some cases where the individual is highly conscious, they may not know that they are wearing a mask. Wearing a mask takes away energy from our consciousness and, in the long run, wears out our energy. A person's mask is noticeable when he or she is sick or weak as the individual will no longer have the power to keep the mask on.\n\nLittle is known about the effects of masking one's negative emotions. In the workplace, masking leads to feelings of dissonance, insincerity, job dissatisfaction, emotional and physical exhaustion, and self-reported health problems. Some have also reported experiencing somatic symptoms and deleterious physiological and cognitive effects as a consequence.\n\nEmotions that are usually concealed:\n\nEmotions that are expressed in place of the concealed emotions:\n\n\n"}
{"id": "428535", "url": "https://en.wikipedia.org/wiki?curid=428535", "title": "Maure", "text": "Maure\n\nA Maure, since the 11th century, is the symbol of a Moor's head. The term has Phoenician and Greek origins; see Moors.\n\nThis symbol is used for political purposes.\n\nThe Maure is the African Unification Front's flag and emblem.\n\nThe main charge in the coat of arms in Corsica is \"\", Corsican for \"The Moor\", originally a female Moor blindfolded and wearing a necklace made of beads. An early version is attested in the 14th-century Gelre Armorial, where an unblindfolded Moor's head represents Corsica as a state of the Crown of Aragon. In 1736, it was used by both sides during the struggle for independence.\n\nIn 1760, General Pasquale Paoli ordered the necklace to be removed from the head and the blindfold raised. His reason, reported by his biographers, was \" () Later the blindfold was changed to a headband.\n\nThe current flag of Corsica is the \" (\"\"), is male rather than female, and has a regular knot at the back of the head.\n\nThe flag of Sardinia is informally known as \"the Four Moors\" (, , ) and comprises four Moor heads.\n\n\n"}
{"id": "4111503", "url": "https://en.wikipedia.org/wiki?curid=4111503", "title": "Mining simulator", "text": "Mining simulator\n\nA mining simulator is a system used to replicate elements of mining operations, for training or efficiency analysis. Mining simulation application can range from pure statistical analysis, to scale models, all the way to replica cabins of mining machinery mounted on pneumatic actuators surrounded by screens displaying three-dimensional imagery. These simulators rely on physics engines and geodata to accurately simulate the dynamics of the environment.\n\n"}
{"id": "17702675", "url": "https://en.wikipedia.org/wiki?curid=17702675", "title": "Multi-vari chart", "text": "Multi-vari chart\n\nIn quality control, multi-vari charts are a visual way of presenting variability through a series of charts. The content and format of the charts has evolved over time.\n\nMulti-vari charts were first described by Leonard Seder in 1950, though they were developed independently by multiple sources. They were inspired by the stock market candlestick charts or open-high-low-close charts.\n\nAs originally conceived, the multi-vari chart resembles a Shewhart individuals control chart with the following differences:\n\nThe three panels are interpreted as follows:\n\nMore recently, the term \"multi-vari chart\" has been used to describe a visual way to display analysis of variance data (typically be expressed in tabular format). It consists of a series of panels which portray minimum, mean, and maximum responses for each treatment combination of interest rather than for periods of time.\n\nBecause it is a two-dimensional representation of multiple dimensions (one for each factor in the ANOVA), the multi-vari chart is only useful for comparing the variability among at most four factors.\n\nThe chart consists of the following:\n"}
{"id": "8043894", "url": "https://en.wikipedia.org/wiki?curid=8043894", "title": "Myanmar units of measurement", "text": "Myanmar units of measurement\n\nThe traditional Burmese units of measurement are still in everyday use in Myanmar (also known as Burma). According to the CIA Factbook, Myanmar is one of three countries that have not adopted the International System of Units (SI) metric system as their official system of weights and measures. However, in June 2011, the Burmese government's Ministry of Commerce began discussing proposals to reform the measurement system in Burma and adopt the metric system used by most of its trading partners, and in October 2013, Dr. Pwint San, Deputy Minister for Commerce, announced that the country was preparing to adopt the metric system.\n\nMost of the nation uses Burmese units only, although Burmese government web pages in English use imperial and metric units inconsistently. For instance, the Ministry of Construction uses miles to describe the length of roads and square feet for the size of houses, but square kilometres for the total land area of new town developments in Yangon City. The Ministry of Agriculture uses acres for land areas. The Ministry of Foreign Affairs uses kilometres (with mile equivalents in parentheses) to describe the dimensions of the country.\n\nIn October 2013, the Ministry of Commerce announced that Myanmar was preparing to adopt the International System of Units (SI System) as the country's official system of measurement.\n\n"}
{"id": "12619632", "url": "https://en.wikipedia.org/wiki?curid=12619632", "title": "Oncorhynchus masou formosanus", "text": "Oncorhynchus masou formosanus\n\nOncorhynchus masou formosanus, the Formosan landlocked salmon or Taiwanese salmon, is a freshwater salmonid fish endemic to Taiwan.\n\nThe Formosan landlocked salmon is a subspecies of the more widespread West-Pacific cherry salmon (or masu salmon). This Taiwanese subspecies is critically endangered, being at high risk for extinction, and is protected in its native habitat. The Formosan land-locked salmon is one of the rarest fish in the world. Once a staple of the Taiwanese aborigine diet, there are now barely more than 400 of this type of salmon left. Overfishing has led to its decline. Conservationists are trying to save this subspecies which is threatened nowadays mainly by pollution.\n\nFormosan landlocked salmon are about a foot in length and inhabit cold, slow-flowing streams with gently sloping beds at elevations above , such as the Chichiawan Stream and the Kaoshan Stream (formerly named Hsuehshan Stream/Wuling Stream) in the upper reaches of the Tachia River.\n\nThe taxonomic rank of the endemic Taiwanese salmon is in dispute. Some authors consider it not distinct from the nominate cherry salmon (\"O. masou masou\"), others as a regional subspecies \"O. masou formosanus\", and still others list is as a full species \"O. formosanus\".\n\nAt this time, these salmon represent the southernmost natural distribution of members of the family Salmonidae in Asia.\n"}
{"id": "1176256", "url": "https://en.wikipedia.org/wiki?curid=1176256", "title": "Peacemakers", "text": "Peacemakers\n\nPeacemakers was an American pacifist organization. The name of the group was taken from a section of the Bible, the Beatitudes or Sermon on the Mount: “Blessed are the peacemakers, for they will be called children of God.”\n\nThe group was founded following a conference on “More Disciplined and Revolutionary Pacifist Activity” in Chicago in July 1948 to advocate nonviolent resistance in the service of peace, particularly draft resistance and tax resistance. The group’s members vowed:\n\n(1) to refuse to serve in the armed forces in either peace or war; (2) to refuse to make or transport weapons of war; (3) to refuse to be conscripted or to register; (4) to consider to refuse to pay taxes for war purposes — a position already adopted by some; (5) to spread the idea of peacemaking and to develop non-violent methods of opposing war through various forms of non-cooperation and to advocate unilateral disarmament and economic democracy.\n\nThe group was organized largely by Ernest and Marion Bromley and Juanita and Wally Nelson. Among the organization’s other founders were A.J. Muste, Dwight Macdonald, Ralph T. Templin, Roy Kepler, Cecil Hinshaw, Milton Mayer, Bayard Rustin, George Houser, and Horace Champney. Many members came from the Committee for Nonviolent Revolution, which had been formed two years before. Some other participants of note included Benny Bargen, Dorothy Day, Ralph DiGia, Fyke Farmer, Walter Gormly, Ammon Hennacy, Bradford Lyttle, Maurice McCrackin, Mary Stone McDowell, Karl Meyer, James Otsuka, Jim Peck, Eroseanna Robinson, Igal Roodenko, Max Sandin, George Willoughby, Lillian Willoughby, and Edmund Wilson.\n\nThe “Tax Refusal Committee” of Peacemakers is credited for founding the modern American war tax resistance movement. Peacemakers published the first guide to war tax resistance in 1963. There had been examples of organized war tax resistance in America for centuries, largely in congregations of the historic peace churches, but Peacemakers was the first non-sectarian organized war tax resistance group.\n\nPeacemakers differed from other pacifist and nonviolent resistance organizations in its emphasis on small-scale, local, \"cell\"-based organization and intentional communities. It had no national office, paid staff, or membership list. Some member groups organized funds to aid war resisters and people in the civil rights movement who had suffered reprisals.\n\n\n"}
{"id": "1068768", "url": "https://en.wikipedia.org/wiki?curid=1068768", "title": "Phytoremediation", "text": "Phytoremediation\n\nPhytoremediation /ˌfaɪtəʊrɪˌmiːdɪˈeɪʃən/ () refers to the technologies that use living plants to clean up soil, air, and water contaminated with hazardous contaminants. It is defined as \"the use of green plants and the associated microorganisms, along with proper soil amendments and agronomic techniques to either contain, remove or render toxic environmental contaminants harmless\".\n\nPhytoremediation is a cost-effective plant-based approach of remediation that takes advantage of the ability of plants to concentrate elements and compounds from the environment and to metabolize various molecules in their tissues. It refers to the natural ability of certain plants called hyperaccumulators to bioaccumulate, degrade, or render harmless contaminants in soils, water, or air. Toxic heavy metals and organic pollutants are the major targets for phytoremediation. Knowledge of the physiological and molecular mechanisms of phytoremediation began to emerge in recent years together with biological and engineering strategies designed to optimize and improve phytoremediation. In addition, several field trials confirmed the feasibility of using plants for environmental cleanup.\n\nPhytoremediation may be applied wherever the soil or static water environment has become polluted or is suffering ongoing chronic pollution. Examples where phytoremediation has been used successfully include the restoration of abandoned metal mine workings, and sites where polychlorinated biphenyls have been dumped during manufacture and mitigation of ongoing coal mine discharges reducing the impact of contaminants in soils, water, or air. Contaminants such as metals, pesticides, solvents, explosives, and crude oil and its derivatives, have been mitigated in phytoremediation projects worldwide. Many plants such as mustard plants, alpine pennycress, hemp, and pigweed have proven to be successful at hyperaccumulating contaminants at toxic waste sites.\n\nNot all plants are able to accumulate heavy metals or organics pollutants due to differences the physiology of the plant. Even cultivars within the same species have varying abilities to accumulate pollutants.\n\nOver the past 20 years, this technology has become increasingly popular and has been employed at sites with soils contaminated with lead, uranium, and arsenic. While it has the advantage that environmental concerns may be treated in situ, one major disadvantage of phytoremediation is that it requires a long-term commitment, as the process is dependent on a plant's ability to grow and thrive in an environment that is not ideal for normal plant growth.\n\n\nPhytoremediation of efficiency of metal by \"Ficus microcarpa\" was evaluated through a real scale experiment. The root biomass production of the species varied significantly from 3.68 to 5.43 g because of the spatial heterogeneity of different metals. According to the study it could take 4-93 years to purify excess Cd on the experimental site. Mercury was unable to be premeditated by \"F. microcarpa\". The species of plant was moved to unpolluted soil. When transplanted Cd and CU were transferred to the rhizosphere soil. Pb and Hg were not released.\n\nThe Alaska Department of Environmental Conservation (ADEC) has been monitoring fuel oil spills at the Kaltag School in Kaltag, Alaska, since 1991. The community has been working with ADEC to use a phytoremediation plan drafted by scientists at the University of Alaska Fairbanks. The ADEC continues to keep the public informed of the progress on their website.\n\nA range of processes mediated by plants or algae are useful in treating environmental problems:\n\nPhytoextraction (or \"phytoaccumulation\" or \"phytosequestration\") uses plants or algae to remove contaminants from soil or water into harvestable plant biomass. The roots take up substances from the soil or water and concentrate it above ground in the plant biomass Organisms that can uptake extremely high amounts of contaminants from the soil are called hyperaccumulators. Phytoextraction can also be performed by plants (e.g.Populus and Salix) that take up lower levels of pollutants, but due to their high growth rate and biomass production, may remove a considerable amount of contaminants from the soil. Phytoextraction has been growing rapidly in popularity worldwide for the last twenty years or so. Typically, phytoextraction is used for heavy metals or other inorganics. At the time of disposal, contaminants are typically concentrated in the much smaller volume of the plant matter than in the initially contaminated soil or sediment. After harvest, a lower level of the contaminant will remain in the soil, so the growth/harvest cycle must usually be repeated through several crops to achieve a significant cleanup. After the process, the cleaned soil can support other vegetation. Mining of these extracted metals through phytomining, is also being experimented with as a way of recovering the material. Hyperaccumulators are plants that can naturally take up the contaminants in soil unassisted. In many cases these are metallophyte plants that can tolerate and incorporate high levels of toxic metals. Induced or assisted phytoextraction is a process where a conditioning fluid containing a chelator or another agent is added to soil to increase metal solubility or mobilization so that the plants can absorb them more easily. While this leads to increased metal uptake by plants, it can also lead to large amounts of available metals in the soil beyond what the plants are able to translocate, causing potential leaching into the subsoil or groundwater.\n\nExamples of plants that are known to accumulate the following contaminants:\n\nPhytostabilization reduces the mobility of substances in the environment, for example, by limiting the leaching of substances from the soil. It focuses on the long term stabilization and containment of the pollutant. The plant immobilizes the pollutants by binding them to soil particles making them less available for plant or human uptake. Unlike phytoextraction, phytostabilization focuses mainly on sequestering pollutants in soil near the roots but not in plant tissues. Pollutants become less bioavailable, resulting in reduced exposure. The plants can also excrete a substance that produces a chemical reaction, converting the heavy metal pollutant into a less toxic form. Stabilization results in reduced erosion, runoff, leaching, in addition to reducing the bioavailability of the contaminant. An example application of phytostabilization is using a vegetative cap to stabilize and contain mine tailings.\n\nPhytodegradation (also called phytotransformation) uses plants or microorganisms to degrade organic pollutants in the soil or within the body of the plant. The organic compounds are broken down by enzymes that the plant roots secrete and these molecules are then taken up by the plant and released through transpiration. This process works best with organic contaminants like herbicides, trichloroethylene, and methyl \"tert\"-butyl ether.\n\nPhytotransformation results in the chemical modification of environmental substances as a direct result of plant metabolism, often resulting in their inactivation, degradation (phytodegradation), or immobilization (phytostabilization). In the case of organic pollutants, such as pesticides, explosives, solvents, industrial chemicals, and other xenobiotic substances, certain plants, such as Cannas, render these substances non-toxic by their metabolism. In other cases, microorganisms living in association with plant roots may metabolize these substances in soil or water. These complex and recalcitrant compounds cannot be broken down to basic molecules (water, carbon-dioxide, etc.) by plant molecules, and, hence, the term \"phytotransformation\" represents a change in chemical structure without complete breakdown of the compound.\nThe term \"Green Liver\" is used to describe phytotransformation, as plants behave analogously to the human liver when dealing with these xenobiotic compounds (foreign compound/pollutant). After uptake of the xenobiotics, plant enzymes increase the polarity of the xenobiotics by adding functional groups such as hydroxyl groups (-OH).\n\nThis is known as Phase I metabolism, similar to the way that the human liver increases the polarity of drugs and foreign compounds (drug metabolism). Whereas in the human liver enzymes such as cytochrome P450s are responsible for the initial reactions, in plants enzymes such as peroxidases, phenoloxidases, esterases and nitroreductases carry out the same role.\n\nIn the second stage of phytotransformation, known as Phase II metabolism, plant biomolecules such as glucose and amino acids are added to the polarized xenobiotic to further increase the polarity (known as conjugation). This is again similar to the processes occurring in the human liver where glucuronidation (addition of glucose molecules by the UGT class of enzymes, e.g. UGT1A1) and glutathione addition reactions occur on reactive centres of the xenobiotic.\n\nPhase I and II reactions serve to increase the polarity and reduce the toxicity of the compounds, although many exceptions to the rule are seen. The increased polarity also allows for easy transport of the xenobiotic along aqueous channels.\n\nIn the final stage of phytotransformation (Phase III metabolism), a sequestration of the xenobiotic occurs within the plant. The xenobiotics polymerize in a lignin-like manner and develop a complex structure that is sequestered in the plant. This ensures that the xenobiotic is safely stored, and does not affect the functioning of the plant. However, preliminary studies have shown that these plants can be toxic to small animals (such as snails), and, hence, plants involved in phytotransformation may need to be maintained in a closed enclosure.\n\nHence, the plants reduce toxicity (with exceptions) and sequester the xenobiotics in phytotransformation. Trinitrotoluene phytotransformation has been extensively researched and a transformation pathway has been proposed.\n\nPhytostimulation (or rhizodegradation) is the enhancement of soil microbial activity for the degradation of organic contaminants, typically by organisms that associate with roots. This process occurs within the rhizosphere, which is the layer of soil that surrounds the roots. Plants release carbohydrates and acids that stimulate microorganism activity which results in the biodegradation of the organic contaminants. This means that the microorganisms are able to digest and break down the toxic substances into harmless form. Phytostimulation has been shown to be effective in degrading petroleum hydrocarbons, PCBs, and PAHs. Phytostimulation can also involve aquatic plants supporting active populations of microbial degraders, as in the stimulation of atrazine degradation by hornwort.\n\nPhytovolatilization is the removal of substances from soil or water with release into the air, sometimes as a result of phytotransformation to more volatile and/or less polluting substances. In this process, contaminants are taken up by the plant and through transpiration, evaporate into the atmosphere. This is the most studied form of phytovolatilization, where volatilization occurs at the stem and leaves of the plant, however indirect phytovolatilization occurs when contaminants are volatilized from the root zone. Selenium (Se) and Mercury (Hg) are often removed from soil through phytovolatilization. Poplar trees are one of the most successful plants for removing VOCs through this process due to its high transpiration rate.\n\nRhizofiltration is a process that filters water through a mass of roots to remove toxic substances or excess nutrients. The pollutants remain absorbed in or adsorbed to the roots. This process is often used to clean up contaminated groundwater through planting directly in the contaminated site or through removing the contaminated water and providing it to these plants in an off-site location. In either case though, typically plants are first grown in a greenhouse under precise conditions.\n\nBiological hydraulic containment occurs when some plants, like poplars, draw water upwards through the soil into the roots and out through the plant, which decreases the movement of soluble contaminants downwards, deeper into the site and into the groundwater.\n\nPhytodesalination uses halophytes (plants adapted to saline soil) to extract salt from the soil to improve its fertility\n\nBreeding programs and genetic engineering are powerful methods for enhancing natural phytoremediation capabilities, or for introducing new capabilities into plants. Genes for phytoremediation may originate from a micro-organism or may be transferred from one plant to another variety better adapted to the environmental conditions at the cleanup site. For example, genes encoding a nitroreductase from a bacterium were inserted into tobacco and showed faster removal of TNT and enhanced resistance to the toxic effects of TNT.\nResearchers have also discovered a mechanism in plants that allows them to grow even when the pollution concentration in the soil is lethal for non-treated plants. Some natural, biodegradable compounds, such as exogenous polyamines, allow the plants to tolerate concentrations of pollutants 500 times higher than untreated plants, and to absorb more pollutants.\n\nA plant is said to be a hyperaccumulator if it can concentrate the pollutants in a minimum percentage which varies according to the pollutant involved (for example: more than 1000 mg/kg of dry weight for nickel, copper, cobalt, chromium or lead; or more than 10,000 mg/kg for zinc or manganese). This capacity for accumulation is due to hypertolerance, or \"phytotolerance\": the result of adaptative evolution from the plants to hostile environments through many generations. A number of interactions may be affected by metal hyperaccumulation, including protection, interferences with neighbour plants of different species, mutualism (including mycorrhizae, pollen and seed dispersal), commensalism, and biofilm.\n\n\nAs plants are able to translocate and accumulate particular types of contaminants, plants can be used as biosensors of subsurface contamination, thereby allowing investigators to quickly delineate contaminant plumes. Chlorinated solvents, such as trichloroethylene, have been observed in tree trunks at concentrations related to groundwater concentrations. To ease field implementation of phytoscreening, standard methods have been developed to extract a section of the tree trunk for later laboratory analysis, often by using an increment borer. Phytoscreening may lead to more optimized site investigations and reduce contaminated site cleanup costs.\n\n\n\n"}
{"id": "5322649", "url": "https://en.wikipedia.org/wiki?curid=5322649", "title": "Plank of Carneades", "text": "Plank of Carneades\n\nIn ethics, the plank of Carneades is a thought experiment first proposed by Carneades of Cyrene; it explores the concept of self-defense in relation to murder.\n\nIn the thought experiment, there are two shipwrecked sailors, A and B. They both see a plank that can only support one of them and both of them swim towards it. Sailor A gets to the plank first. Sailor B, who is going to drown, pushes A off and away from the plank and, thus, proximately, causes A to drown. Sailor B gets on the plank and is later saved by a rescue team. The thought experiment poses the question of whether Sailor B can be tried for murder because if B had to kill A in order to live, then it would arguably be in self-defense.\n\nThe Case of the Speluncean Explorers by legal philosopher Lon Fuller is a similar exploration of morality and legality \"in extremis\".\n\n\n"}
{"id": "460710", "url": "https://en.wikipedia.org/wiki?curid=460710", "title": "Pseudo-photograph", "text": "Pseudo-photograph\n\nA pseudo-photograph is \"an image, whether made by computer-graphics or otherwise howsoever, which appears to be a photograph\".\n\nAlthough the term pseudo-photograph can be applied regardless of what it depicts, in law its meaning is especially relevant regarding child pornography.\n\nIn the UK, the Criminal Justice and Public Order Act 1994 amended the Protection of Children Act 1978 so as to define the concept of an \"indecent pseudo-photograph of a child\".\n\n\n"}
{"id": "32137290", "url": "https://en.wikipedia.org/wiki?curid=32137290", "title": "Shouwang Church", "text": "Shouwang Church\n\nThe Shouwang Church (守望教会) is a Protestant house church in Beijing, China, and almost the biggest of about 3,000 of such congregations in the city. The word \"shouwang\" means \"to keep watch\" in Mandarin.\n\nThe church was founded in 1993 by Jin Tianming, a chemical engineering graduate of Tsinghua University of Korean ethnicity. Since then, the number of its members has increased from 10 to 1,000 as of June 2011.\n\nThe services are conducted at members' homes or in rented conference rooms; its other activities include 40 biblical reading groups, choir practice and catechism. Shouwang members typically belong to the middle and upper classes, and include professors, doctors, lawyers, students and Party members.\n\nLike other house churches, the Shouwang Church is subject to harassment by the Chinese authorities, who disapprove of religious groups that are not subject to state control. The church was forced to change headquarters more than 20 times, and was prevented from buying or renting a church building.\n\nPersecution intensified in the context of the general 2011 crackdown on dissidents, following an announcement by church leaders that they would begin holding Sunday service meetings in public, if they were not allowed to acquire premises. As of June 2011, several dozen Shouwang followers are detained every week and forced to sign a disavowal of their spiritual guide before being released, and six church leaders have been placed under house arrest without court documentation. According to the German weekly \"Die Zeit\", Beijing police use around 4,500 officers to provide surveillance of Zhongguancun Square and of the homes of about 500 church members, to prevent the church from congregating.\n"}
{"id": "665434", "url": "https://en.wikipedia.org/wiki?curid=665434", "title": "Shrunken head", "text": "Shrunken head\n\nA shrunken head is a severed and specially prepared human head that is used for trophy, ritual, or trade purposes.\n\nHeadhunting has occurred in many regions of the world, but the practice of headshrinking has only been documented in the northwestern region of the Amazon rainforest. The only tribes known to have shrunken human heads are of the Jivaroan tribes. These include the Shuar, Achuar, Huambisa and Aguaruna tribes, found in Ecuador and Peru. The Shuar call a shrunken head a \"tsantsa\", also transliterated \"tzantza\". Many tribe leaders would show off their heads to scare enemies.\n\nThe process of creating a shrunken head begins with removing the skull from the neck. An incision is made on the back of the ear and all the skin and flesh is removed from the cranium. Red seeds are placed underneath the nostrils and the lips are sewn shut. The mouth is held together with three palm pins. Fat from the flesh of the head is removed. Then a wooden ball is placed under the flesh in order to keep the form. The flesh is then boiled in water that has been saturated with a number of herbs containing tannins. The head is then dried with hot rocks and sand, while molding it to retain its human features. The skin is then rubbed down with charcoal ash. Decorative beads may be added to the head.\n\nIn the head shrinking tradition, it is believed that coating the skin in ash keeps the \"muisak\", or avenging soul, from seeping out.\n\nShrunken heads are known for their mandibular prognathism, facial distortion and shrinkage of the lateral sides of the forehead; these are artifacts of the shrinking process.\n\nAmong the Shuar and Achuar, the reduction of the heads was followed by a series of feasts centered on important rituals.\n\nThe practice of preparing shrunken heads originally had religious significance; shrinking the head of an enemy was believed to harness the spirit of that enemy and compel him to serve the shrinker. It was said to prevent the soul from avenging his death.\n\nShuar believed in the existence of three fundamental spirits:\n\nTo block a Muisak from using its powers, they severed their enemies' heads and shrank them. The process also served as a way of warning their enemies. Despite these precautions, the owner of the trophy did not keep it for long. Many heads were later used in religious ceremonies and feasts that celebrated the victories of the tribe. Accounts vary as to whether the heads would be discarded or stored.\n\nWhen Westerners created an economic demand for shrunken heads there was a sharp increase in the rate of killings in an effort to supply tourists and collectors of ethnographic items. The terms headhunting and headhunting parties come from this practice.\n\nGuns were usually what the Shuar acquired in exchange for their shrunken heads, the rate being one gun per head. But weapons were not the only items exchanged. Around 1910, shrunken heads were being sold by a curio shop in Lima for one Peruvian gold pound, equal in value to a British gold sovereign. In 1919, the price in Panama's curio shop for shrunken heads had risen to £5. By the 1930s, when heads were freely exchanged, a person could buy a shrunken head for about twenty-five U.S. dollars. A stop was put to this when the Peruvian and Ecuadorian governments worked together to outlaw the traffic in heads.\n\nAlso encouraged by this trade, people in Colombia and Panama unconnected to the Jívaros began to make counterfeit \"tsantsas\". They used corpses from morgues, or the heads of monkeys or sloths. Some even used goatskin. Kate Duncan wrote in 2001 that \"It has been estimated that about 80 percent of the tsantsas in private and museum hands are fraudulent,\" including almost all that are female or which include an entire torso rather than just a head.\n\nThor Heyerdahl recounts in \"Kon-Tiki\" (1947) the various problems of getting into the Jívaro (Shuar) area in Ecuador to get balsa wood for his expedition raft. Local people would not guide his team into the jungle for fear of being killed and having their heads shrunk. In 1951 and 1952 sales of such items in London were being advertised in \"The Times\", one example being priced at $250, a hundredfold appreciation since the early twentieth century.\n\nIn 1999, the National Museum of the American Indian repatriated the authentic shrunken heads in its collection to Ecuador. Most other countries have also banned the trade. Currently, replica shrunken heads are manufactured as curios for the tourist trade. These are made from leather and animal hides formed to resemble the originals.\n\n\n"}
{"id": "5117137", "url": "https://en.wikipedia.org/wiki?curid=5117137", "title": "Social Choice and Individual Values", "text": "Social Choice and Individual Values\n\nKenneth Arrow's monograph Social Choice and Individual Values (1951, 2nd ed., 1963) and a theorem within it created modern social choice theory, a rigorous melding of social ethics and voting theory with an economic flavor. Somewhat formally, the \"social choice\" in the title refers to Arrow's representation of how \"social values\" from the \"set of individual orderings\" would be implemented under the \"constitution\". Less formally, each social choice corresponds to the feasible set of laws passed by a \"vote\" (the set of orderings) under the constitution even if not every individual voted in favor of all the laws.\n\nThe work culminated in what Arrow called the \"General Possibility Theorem,\" better known thereafter as Arrow's (impossibility) theorem. The theorem states that, absent restrictions on either individual preferences or neutrality of the constitution to feasible alternatives, there exists no social choice rule that satisfies a set of plausible requirements. The result generalizes the voting paradox, which shows that majority voting may fail to yield a stable outcome.\n\nThe Introduction contrasts voting and markets with dictatorship and social convention (such as those in a religious code). Both exemplify social decisions. Voting and markets facilitate \"social\" choice in a sense, whereas dictatorship and convention limit it. The former amalgamate possibly differing tastes to make a social choice. The concern is with formal aspects of generalizing such choices. In this respect it is comparable to analysis of the voting paradox from use of majority rule as a value.\nArrow asks whether other methods of taste aggregation (whether by voting or markets), using other values, remedy the problem or are satisfactory in other ways. Here logical consistency is one check on acceptability of all the values. To answer the questions, Arrow proposes removing the distinction between voting and markets in favor of a more general category of collective social choice.\n\nThe analysis uses ordinal rankings of individual choice to represent behavioral patterns. Cardinal measures of individual utility and, \"a fortiori\", interpersonal comparisons of utility are avoided on grounds that such measures are unnecessary to represent behavior and depend on mutually incompatible value judgments (p. 9).\n\nFollowing Abram Bergson, whose formulation of a social welfare function launched ordinalist welfare economics, Arrow avoids locating a social good as independent of individual values. Rather, social values inhere in actions from social-decision rules (hypostatized as \"constitutional conditions\") using individual values as input. Then 'social values' means \"nothing more than social choices\" (p. 106).\n\nTopics implicated along the way include game theory, the compensation principle in welfare economics, extended sympathy, Leibniz's principle of the identity of indiscernibles, logrolling, and similarity of social judgments through single-peaked preferences, Kant’s categorical imperative, or the decision process.\n\nThe book defines a few terms and logical symbols used thereafter and their applied empirical interpretation (pp. 11–19, 23). Key among these is the \"vote\" ('set of orderings') of the society (more generally \"collectivity\") composed of individuals (“voters” here) in the following form: \n\nThe ordering of each voter ranks social states, including the \"distribution\" of commodities (possibly based on equity, by whatever metric, or any other consideration), not merely direct consumption by that voter. So, the ordering is an \"individual value,\" not merely, as in earlier analysis, a purely private \"taste.\" Arrow notes that the distinction is not sharp. Resource allocation is specified in the production of each social state in the ordering.\n\nThe comprehensive nature of \"commodities\", the \"set\" of \"social states\", and the \"set\" of \"orderings\" was noted by early reviewers.\n\nThe two properties that define any ordering of the set of \"objects\" in question (all \"social states\" here) are:\n\n \nThe earlier definition of an ordering implies that any given ordering entails one of three responses on the \"ballot\" as between any pair of social states (\"x\", \"y\"): \"better than\", \"as good as\", or \"worse than\" (in preference ranking). (Here \"as good as\" is an \"equally-ranked,\" not a \"don't know,\" relation.) \n\nAn ordering of a voter is denoted by R. That ordering of voter \"i\" is denoted with a subscript as formula_1.\n\nIf voter \"i\" changes orderings, primes distinguish the first and second, say formula_1 compared to formula_1' . The same notation can apply for two different hypothetical orderings of the same voter.\n\nThe interest of the book is in amalgamating sets of orderings. This is accomplished through a 'constitution'. \n\nA social ordering of a constitution is denoted R. (Context or a subscript distinguishes a voter ordering \"R\" from the same symbol for a social ordering.)\n\nFor any two social states \"x\" and \"y\" of a given social ordering \"R\":\n\nx P y is \"social preference\" of \"x\" over \"y\" (\"x\" is selected over \"y\" by the rule).\n\nx I y is \"social indifference\" between \"x\" and \"y\" (both are ranked the same by the rule).\n\nx R y is either \"social preference\" of \"x\" over \"y\" or \"social indifference\" between \"x\" and \"y\" (\"x\" is ranked least as good as \"y\" by the rule).\n\nA social ordering applies to each ordering in the set of orderings (hence the \"social\" part and the associated amalgamation). This is so regardless of (dis)similarity between the social ordering and any or all the orderings in the set. But Arrow places the constitution in the context of ordinalist welfare economics, which attempts to aggregate different tastes in a coherent, plausible way.\nArrow (pp. 15, 26–28) shows how to go from the social ordering \"R\" for a given set of orderings to a particular 'social choice' by specifying:\n\n\nThe social ordering \"R\" then selects the top-ranked social state(s) from the subset as the \"social choice\" set. \nLess informally, the social choice function is the function mapping each environment \"S\" of available social states (at least two) for any \"given\" set of orderings (and corresponding social ordering \"R\") to the social choice set, the set of social states each element of which is top-ranked (by \"R\") for that environment and that set of orderings.\n\nThe social choice function is denoted C(S). Consider an environment that has just two social states, \"x\" and \"y\": \"C(S)\" = \"C([x, y])\". Suppose \"x\" is the only top-ranked social state. Then C([\"x\", \"y\"]) = {\"x\"}, the \"social choice\" set. If \"x\" and \"y\" are instead tied, \"C([x, y])\" = {\"x\", \"y\"}. Formally (p. 15), \"C(S)\" is the set of all \"x\" in \"S\" such that, for all \"y\" in \"S\", \"x R y\" (\"\"x\" is at least as good as \"y\"\").\n\nThe next section invokes the following. Let \"R\" and \"R' \" stand for social orderings of the constitution corresponding to any 2 sets of orderings. If \"R\" and \"R' \" for the same environment \"S\" map to the same social choice(s), the relation of the identical social choices for \"R\" and \"R' \"is represented as: C(\"S\") = C'(\"S\").\n\nA constitution might seem to be a promising alternative to dictatorship and vote-immune social convention or external control. Arrow describes the \"connectedness\" of a social ordering as requiring only that \"some\" social choice be made from any environment of available social states. Since some social state will prevail, this is hard to deny (especially with no place on the ballot for abstention). The \"transitivity\" of a social ordering has an advantage over requiring unanimity (or much less) to change between social states if there is a maladapted \"status quo\" (that is, one subject to \"democratic paralysis\"). Absent deadlock, transitivity crowds out any reference to the \"status quo\" as a privileged default blocking the path to a social choice (p. 120).\n\nArrow proposes the following \"apparently reasonable\" conditions to constrain the social ordering(s) of the constitution (pp. 25, 96-97).\n\n\nEach voter is permitted by the constitution to rank the set of social states in any order, though with only one ordering per voter for a given set of orderings.\n\nArrow describes this condition as an extension of ordinalism with its emphasis on prospectively observable behavior (for the subset in question). He ascribes practical advantage to the condition from \"every known electoral system\" satisfying it (p. 110).\n\nThe conditions, particularly the second and third, may seem minimal, but jointly they are harsh, as may be represented in either of two ways.\n\n\nAn alternate statement of the theorem adds the following condition to the above:\n\n\nArrow (1951, p. 26) describes social welfare here as at least not negatively related to individual preferences. \n\nUnder imposition, for every set of orderings in the domain, the social ranking for at least one \"x\" and \"y\" is only \"x R y\". The vote makes no difference to the outcome. \nThe proof is in two parts (Arrow, 1963, pp. 97–100). The first part considers the hypothetical case of some one voter's ordering that \"prevails\" ('is decisive') as to the social choice for \"some\" pair of social states no matter what that voter's preference for the pair, despite all other voters opposing. It is shown that, for a constitution satisfying Unrestricted Domain, Pareto and Independence, that voter's ordering would prevail for \"every\" pair of social states, no matter what the orderings of others. So, the voter would be a Dictator. Thus, Nondictatorship requires postulating that no one would so prevail for even one pair of social states.\n\nThe second part considers more generally a set of voters that would prevail for some pair of social states, despite all other voters (if any) preferring otherwise. Pareto and Unrestricted Domain for a constitution imply that such a set would at least include the entire set of voters. By Nondictatorship, the set must have at least 2 voters. Among all such sets, postulate a set such that no other set is smaller. Such a set can be constructed with Unrestricted Domain and an adaptation of the voting paradox to imply a still smaller set. This contradicts the postulate and so proves the theorem.\n\nThe book proposes some apparently reasonable conditions for a \"voting\" rule, in particular, a 'constitution', to make consistent, feasible social choices in a welfarist context. But then any constitution that allows dictatorship requires it, and any constitution that requires nondictatorship contradicts one of the other conditions. Hence, the \"paradox of social choice\".\n\nThe set of \"conditions\" across \"different\" possible votes refined welfare economics and differentiated Arrow's constitution from the \"pre-Arrow social welfare function\". In so doing, it also ruled out any one consistent social ordering to which an agent or official might appeal in trying to implement social welfare through the votes of other\"s\" under the constitution. The result generalizes and deepens the voting paradox to any voting rule satisfying the conditions, however complex or comprehensive.\n\nThe 1963 edition includes an additional chapter with a simpler proof of Arrow's Theorem and corrects an earlier point noted by Blau. It also elaborates on advantages of the conditions and cites studies of Riker and Dahl that as an empirical matter intransitivity of the voting mechanism may produce unsatisfactory inaction or majority opposition. These support Arrow's characterization of a constitution across possible votes (that is, collective rationality) as \"an important attribute of a genuinely democratic system capable of full adaptation to varying environments\" (p. 120).\n\nThe theorem might seem to have unravelled a skein of behavior-based social-ethical theory from Adam Smith and Bentham on. But Arrow himself expresses hope at the end of his Nobel prize lecture that, though the philosophical and distributive implications of the paradox of social choice were \"still not clear,\" others would \"take this paradox as a challenge rather than as a discouraging barrier.\"\n\nThe large subsequent literature has included reformulation to extend, weaken, or replace the conditions and derive implications. In this respect Arrow's framework has been an instrument for generalizing voting theory and critically evaluating and broadening economic policy and social choice theory.\n\n\n\n"}
{"id": "325726", "url": "https://en.wikipedia.org/wiki?curid=325726", "title": "Social network analysis", "text": "Social network analysis\n\nSocial network analysis (SNA) is the process of investigating social structures through the use of networks and graph theory. It characterizes networked structures in terms of \"nodes\" (individual actors, people, or things within the network) and the \"ties\", \"edges\", or \"links\" (relationships or interactions) that connect them. Examples of social structures commonly visualized through social network analysis include social media networks, memes spread, information circulation, friendship and acquaintance networks, collaboration graphs, kinship, disease transmission, and sexual relationships. These networks are often visualized through \"sociograms\" in which nodes are represented as points and ties are represented as lines.\n\nSocial network analysis has emerged as a key technique in modern sociology. It has also gained a significant following in anthropology, biology, demography, communication studies, economics, geography, history, information science, organizational studies, political science, social psychology, development studies, sociolinguistics, and computer science and is now commonly available as a consumer tool (see the list of SNA software).\n\nSocial network analysis has its theoretical roots in the work of early sociologists such as Georg Simmel and Émile Durkheim, who wrote about the importance of studying patterns of relationships that connect social actors. Social scientists have used the concept of \"social networks\" since early in the 20th century to connote complex sets of relationships between members of social systems at all scales, from interpersonal to international. In the 1930s Jacob Moreno and Helen Jennings introduced basic analytical methods. In 1954, John Arundel Barnes started using the term systematically to denote patterns of ties, encompassing concepts traditionally used by the public and those used by social scientists: bounded groups (e.g., tribes, families) and social categories (e.g., gender, ethnicity). Scholars such as Ronald Burt, Kathleen Carley, Mark Granovetter, David Krackhardt, Edward Laumann, Anatol Rapoport, Barry Wellman, Douglas R. White, and Harrison White expanded the use of systematic social network analysis. Even in the study of literature, network analysis has been applied by Anheier, Gerhards and Romo, Wouter De Nooy, and Burgert Senekal. Indeed, social network analysis has found applications in various academic disciplines, as well as practical applications such as countering money laundering and terrorism.\n\nHomophily: The extent to which actors form ties with similar versus dissimilar others. Similarity can be defined by gender, race, age, occupation, educational achievement, status, values or any other salient characteristic. Homophily is also referred to as assortativity.\n\nMultiplexity: The number of content-forms contained in a tie. For example, two people who are friends and also work together would have a multiplexity of 2. Multiplexity has been associated with relationship strength.\n\nMutuality/Reciprocity: The extent to which two actors reciprocate each other's friendship or other interaction.\n\nNetwork Closure: A measure of the completeness of relational triads. An individual's assumption of network closure (i.e. that their friends are also friends) is called transitivity. Transitivity is an outcome of the individual or situational trait of Need for Cognitive Closure.\n\nPropinquity: The tendency for actors to have more ties with geographically close others.\n\nBridge: An individual whose weak ties fill a structural hole, providing the only link between two individuals or clusters. It also includes the shortest route when a longer one is unfeasible due to a high risk of message distortion or delivery failure.\n\nCentrality: Centrality refers to a group of metrics that aim to quantify the \"importance\" or \"influence\" (in a variety of senses) of a particular node (or group) within a network. Examples of common methods of measuring \"centrality\" include betweenness centrality, closeness centrality, eigenvector centrality, alpha centrality, and degree centrality.\n\nDensity: The proportion of direct ties in a network relative to the total number possible.\n\nDistance: The minimum number of ties required to connect two particular actors, as popularized by Stanley Milgram's small world experiment and the idea of 'six degrees of separation'.\n\nStructural holes: The absence of ties between two parts of a network. Finding and exploiting a structural hole can give an entrepreneur a competitive advantage. This concept was developed by sociologist Ronald Burt, and is sometimes referred to as an alternate conception of social capital.\n\nTie Strength: Defined by the linear combination of time, emotional intensity, intimacy and reciprocity (i.e. mutuality). Strong ties are associated with homophily, propinquity and transitivity, while weak ties are associated with bridges.\n\nGroups are identified as 'cliques' if every individual is directly tied to every other individual, 'social circles' if there is less stringency of direct contact, which is imprecise, or as structurally cohesive blocks if precision is wanted.\n\nClustering coefficient: A measure of the likelihood that two associates of a node are associates. A higher clustering coefficient indicates a greater 'cliquishness'.\n\nCohesion: The degree to which actors are connected directly to each other by cohesive bonds. Structural cohesion refers to the minimum number of members who, if removed from a group, would disconnect the group.\n\nVisual representation of social networks is important to understand the network data and convey the result of the analysis. Numerous methods of visualization for data produced by social network analysis have been presented. Many of the analytic software have modules for network visualization. Exploration of the data is done through displaying nodes and ties in various layouts, and attributing colors, size and other advanced properties to nodes. Visual representations of networks may be a powerful method for conveying complex information, but care should be taken in interpreting node and graph properties from visual displays alone, as they may misrepresent structural properties better captured through quantitative analyses.\n\nSigned graphs can be used to illustrate good and bad relationships between humans. A positive edge between two nodes denotes a positive relationship (friendship, alliance, dating) and a negative edge between two nodes denotes a negative relationship (hatred, anger). Signed social network graphs can be used to predict the future evolution of the graph. In signed social networks, there is the concept of \"balanced\" and \"unbalanced\" cycles. A balanced cycle is defined as a cycle where the product of all the signs are positive. According to balance theory, balanced graphs represent a group of people who are unlikely to change their opinions of the other people in the group. Unbalanced graphs represent a group of people who are very likely to change their opinions of the people in their group. For example, a group of 3 people (A, B, and C) where A and B have a positive relationship, B and C have a positive relationship, but C and A have a negative relationship is an unbalanced cycle. This group is very likely to morph into a balanced cycle, such as one where B only has a good relationship with A, and both A and B have a negative relationship with C. By using the concept of balanced and unbalanced cycles, the evolution of signed social network graphs can be predicted.\n\nEspecially when using social network analysis as a tool for facilitating change, different approaches of participatory network mapping have proven useful. Here participants / interviewers provide network data by actually mapping out the network (with pen and paper or digitally) during the data collection session. An example of a pen-and-paper network mapping approach, which also includes the collection of some actor attributes (perceived influence and goals of actors) is the * Net-map toolbox. One benefit of this approach is that it allows researchers to collect qualitative data and ask clarifying questions while the network data is collected.\n\nSocial networking potential (SNP) is a numeric coefficient, derived through algorithms to represent both the size of an individual's social network and their ability to influence that network. A close synonym is the Alpha User, a person with a high SNP.\n\nSNP coefficients have two primary functions:\n\nBy calculating the SNP of respondents and by targeting High SNP respondents, the strength and relevance of quantitative marketing research used to drive viral marketing strategies is enhanced.\n\nVariables used to calculate an individual's SNP include but are not limited to: participation in Social Networking activities, group memberships, leadership roles, recognition, publication/editing/contributing to non-electronic media, publication/editing/contributing to electronic media (websites, blogs), and frequency of past distribution of information within their network. The acronym \"SNP\" and some of the first algorithms developed to quantify an individual's social networking potential were described in the white paper \"Advertising Research is Changing\" (Gerstley, 2003) See Viral Marketing.\n\nThe first book to discuss the commercial use of Alpha Users among mobile telecoms audiences was 3G Marketing by Ahonen, Kasper and Melkko in 2004. The first book to discuss Alpha Users more generally in the context of social marketing intelligence was Communities Dominate Brands by Ahonen & Moore in 2005. In 2012, Nicola Greco (UCL) presents at TEDx the Social Networking Potential as a parallelism to the potential energy that users generate and companies should use, stating that \"SNP is the new asset that every company should aim to have\".\n\nSocial network analysis is used extensively in a wide range of applications and disciplines. Some common network analysis applications include data aggregation and mining, network propagation modeling, network modeling and sampling, user attribute and behavior analysis, community-maintained resource support, location-based interaction analysis, social sharing and filtering, recommender systems development, and link prediction and entity resolution. In the private sector, businesses use social network analysis to support activities such as customer interaction and analysis, information system development analysis, marketing, and business intelligence needs (see social media analytics). Some public sector uses include development of leader engagement strategies, analysis of individual and group engagement and media use, and community-based problem solving.\n\nSocial network analysis is also used in intelligence, counter-intelligence and law enforcement activities. This technique allows the analysts to map a clandestine or covert organization such as a espionage ring, an organized crime family or a street gang. The National Security Agency (NSA) uses its clandestine mass electronic surveillance programs to generate the data needed to perform this type of analysis on terrorist cells and other networks deemed relevant to national security. The NSA looks up to three nodes deep during this network analysis. After the initial mapping of the social network is complete, analysis is performed to determine the structure of the network and determine, for example, the leaders within the network. This allows military or law enforcement assets to launch capture-or-kill decapitation attacks on the high-value targets in leadership positions to disrupt the functioning of the network.\nThe NSA has been performing social network analysis on call detail records (CDRs), also known as metadata, since shortly after the September 11 attacks.\n\nLarge textual corpora can be turned into networks and then analysed with the method of social network analysis. In these networks, the nodes are Social Actors, and the links are Actions. The extraction of these networks can be automated, by using parsers. The resulting networks, which can contain thousands of nodes, are then analysed by using tools from network theory to identify the key actors, the key communities or parties, and general properties such as robustness or structural stability of the overall network, or centrality of certain nodes. This automates the approach introduced by Quantitative Narrative Analysis, whereby subject-verb-object triplets are identified with pairs of actors linked by an action, or pairs formed by actor-object.\nSocial network analysis has also been applied to understanding online behavior by individuals, organizations, and between websites. Hyperlink analysis can be used to analyze the connections between websites or webpages to examine how information flows as individuals navigate the web. The connections between organizations has been analyzed via hyperlink analysis to examine which organizations within an issue community.\n\nSocial network analysis has been applied to social media as a tool to understand behavior between individuals or organizations through their linkages on social media websites such as Twitter and Facebook.\n\nOne of the most current methods of the application of SNA is to the study of computer-supported collaborative learning (CSCL). When applied to CSCL, SNA is used to help understand how learners collaborate in terms of amount, frequency, and length, as well as the quality, topic, and strategies of communication. Additionally, SNA can focus on specific aspects of the network connection, or the entire network as a whole. It uses graphical representations, written representations, and data representations to help examine the connections within a CSCL network. When applying SNA to a CSCL environment the interactions of the participants are treated as a social network. The focus of the analysis is on the \"connections\" made among the participants – how they interact and communicate – as opposed to how each participant behaved on his or her own.\n\nThere are several key terms associated with social network analysis research in computer-supported collaborative learning such as: density, centrality, indegree, outdegree, and sociogram.\n\n\nIn-degree and out-degree variables are related to centrality.\n\n\nResearchers employ social network analysis in the study of computer-supported collaborative learning in part due to the unique capabilities it offers. This particular method allows the study of interaction patterns within a networked learning community and can help illustrate the extent of the participants' interactions with the other members of the group. The graphics created using SNA tools provide visualizations of the connections among participants and the strategies used to communicate within the group. Some authors also suggest that SNA provides a method of easily analyzing changes in participatory patterns of members over time.\n\nA number of research studies have applied SNA to CSCL across a variety of contexts. The findings include the correlation between a network's density and the teacher's presence, a greater regard for the recommendations of \"central\" participants, infrequency of cross-gender interaction in a network, and the relatively small role played by an instructor in an asynchronous learning network.\n\nAlthough many studies have demonstrated the value of social network analysis within the computer-supported collaborative learning field, researchers have suggested that SNA by itself is not enough for achieving a full understanding of CSCL. The complexity of the interaction processes and the myriad sources of data make it difficult for SNA to provide an in-depth analysis of CSCL. Researchers indicate that SNA needs to be complemented with other methods of analysis to form a more accurate picture of collaborative learning experiences.\n\nA number of research studies have combined other types of analysis with SNA in the study of CSCL. This can be referred to as a multi-method approach or data triangulation, which will lead to an increase of evaluation reliability in CSCL studies.\n\n\n\n\n\n"}
{"id": "1715392", "url": "https://en.wikipedia.org/wiki?curid=1715392", "title": "State actor", "text": "State actor\n\nIn United States law, a state actor is a person who is acting on behalf of a governmental body, and is therefore subject to regulation under the United States Bill of Rights, including the First, Fifth and Fourteenth Amendments, which prohibit the federal and state governments from violating certain rights and freedoms.\n\nThough the term would seem to include only persons who are directly employed by the state, the United States Supreme Court has interpreted these amendments and laws passed pursuant to them to cover many persons who have only an indirect relationship with the government. Controversies have arisen, for example, over whether private companies that run towns (the \"company-town\") and prisons (traditionally a state function) can be held liable as state actors when they violate fundamental civil rights. This question remains unresolved, but the Supreme Court has held private citizens to be liable as state actors when they conspire with government officials to deprive people of their rights.\n\nConversely, in \"National Collegiate Athletic Association v. Smith\", the Supreme Court has found that the National Collegiate Athletic Association is not a state actor for the purposes of 28 U.S.C. 1983 because it was national, rather than acting on behalf of one state actor. For the purposes of a Bivens\naction, however, it might still be a state actor.\n\nThe 1989 case of \"DeShaney v. Winnebago County\" was decided on the basis of the \"state action doctrine\". Social workers separated a young son Joshua from his abusive father Randy, but concluded there was not enough evidence for a permanent separation, and later reunited son with father; later, the father beat his son into a persistent vegetative state. The Supreme Court ruled that despite involvement by state social workers, the state of Wisconsin was not a \"state actor\" and was therefore not responsible. Accordingly, the Fourteenth Amendment protections did not apply, according to constitutional scholar John E. Finn.\n\nUnlike state actors, private actors are generally not required to afford individuals the constitutional rights mentioned above. In nearly all U.S. states, private shopping center owners can eject protesters from their land for trespassing, and private associations can eject members or deny admission to applicants, with no warning and for no reason. But in a handful of states, notably California, state constitutional protections and certain common law rights have been extended to limit private actors. California allows the peaceful exercise of free speech in private shopping centers (see \"Pruneyard Shopping Center v. Robins\" (1980)) and requires certain types of private actors to afford current or potential members a rudimentary version of procedural due process called fair procedure.\n\nThere are a number of situations where the United States Supreme Court has recognized the conduct of individuals or private organizations to be \"state action,\" and therefore subject to provisions of the Constitution such as Equal Protection, Due Process, or the First Amendment. The Supreme Court has held the following:\n\n\nAccording to constitutional law scholar Gillian E. Metzger:\n\nThe underlying presumption is that cases where private actors wield public power are rare and occur mainly when the government tries to hide behind private surrogates whom it controls. Current doctrine pays little attention to whether the government is, in fact, delegating power to private entities to act on its behalf. To the extent private delegations are considered, it is under the rubric of private delegation doctrine, which assesses whether the Constitution's separation of powers and due process requirements prohibit the government from delegating certain types of powers to private hands. But constitutional law makes no attempt to link the constitutionality of a private delegation to the risk that it will place government power outside of constitutional controls.\n\n"}
{"id": "361558", "url": "https://en.wikipedia.org/wiki?curid=361558", "title": "Strangling", "text": "Strangling\n\nStrangling is compression of the neck that may lead to unconsciousness or death by causing an increasingly hypoxic state in the brain. Fatal strangling typically occurs in cases of violence, accidents, and is one of two main ways that hanging causes death (alongside breaking the victim's neck).\n\nStrangling does not have to be fatal; limited or interrupted strangling is practised in erotic asphyxia, in the choking game, and is an important technique in many combat sports and self-defence systems. \nStrangling can be divided into three general types according to the mechanism used:\n\nStrangling involves one or several mechanisms that interfere with the normal flow of oxygen into the brain:\nDepending on the particular method of strangulation, one or several of these typically occur in combination; vascular obstruction is usually the main mechanism. Complete obstruction of blood flow to the brain is associated with irreversible neurological damage and death, but during strangulation there is still unimpeded blood flow in the vertebral arteries. Estimates have been made that significant occlusion of the carotid arteries and jugular veins occurs with a pressure of around , while the trachea demands six times more at approximately .\n\nAs in all cases of strangulation, the rapidity of death can be affected by the susceptibility to carotid sinus stimulation. Carotid sinus reflex death is sometimes considered a mechanism of death in cases of strangulation, but it remains highly disputed. The reported time from application to unconsciousness varies from 7–14 seconds if effectively applied to one minute in other cases, with death occurring minutes after unconsciousness.\n\nManual strangulation (also known as \"throttling\") is strangling with the hands, fingers, or other extremities and sometimes also with blunt objects, such as batons. Depending on how the strangling is performed, it may compress the airway, interfere with the flow of blood in the neck, or work as a combination of the two. Consequently, manual strangulation may damage the larynx, and fracture the hyoid or other bones in the neck. In cases of airway compression, manual strangling leads to the frightening sensation of air hunger and may induce violent struggling.\n\nMore technical variants of manual strangulation are referred to as chokeholds, and are extensively practised and used in various martial arts, combat sports, self-defense systems, and in military hand-to-hand combat application. In some martial arts like judo and jujutsu, strangles or chokes that constrict blood flow are regarded as a safe way to render the opponent unconscious as opposed to other attacks, e.g., strikes to the head.\nDuring the 18th century, a sentence of \"Death by Throttling\" would be passed upon the verdict of a Court Martial for the crime of desertion from the British Army.\n\nLigature strangulation (also known as \"garroting\") is strangling with some form of cord such as rope, wire, or shoe laces, either partially or fully circumferencing the neck. Even though the mechanism of strangulation is similar, it is usually distinguished from hanging by the strangling force being something other than the person's own bodyweight. Incomplete occlusion of the carotid arteries is expected and, in cases of homicide, the victim may struggle for a period of time, with unconsciousness typically occurring in 10 to 15 seconds. Cases of ligature strangulation generally involve homicides of women, children, and the elderly, but accidents and suicides occur as well.\n\nCompared to hanging, the ligature mark will most likely be located lower on the neck of the victim.\n\nDuring the Spanish Inquisition, victims who admitted their alleged sins and recanted were killed via ligature strangulation (i.e. the garrote) before their bodies were burnt during the \"auto-da-fé\". Throughout much of the 20th and 21st centuries, the American Mafia used ligature strangulation as a means of murdering their victims. Confessed American serial killer Altemio Sanchez used ligature strangulation in the rapes and/or murders of his victims, as did Gary Ridgway, the Green River Killer.\n\n\n"}
{"id": "22828874", "url": "https://en.wikipedia.org/wiki?curid=22828874", "title": "Struggle session", "text": "Struggle session\n\nA struggle session was a form of public humiliation and torture that was used by the Communist Party of China in the Mao era, particularly during the Cultural Revolution, to shape public opinion and humiliate, persecute, or execute political rivals and those deemed class enemies.\n\nIn general, the victim of a struggle session was forced to admit various crimes before a crowd of people who would verbally and physically abuse the victim until he or she confessed. Struggle sessions were often held at the workplace of the accused, but they were sometimes conducted in sports stadiums where large crowds would gather if the target was well-known.\n\nAccording to Lin Yutang, the expression comes from \"批判\" () and \"鬥爭\" (), so the whole expression conveys the message of \"inciting the spirit of judgment and fighting\". Instead of saying the full phrase \"批判鬥爭\" (), it was shortened to \"批鬥\" ().\n\nStruggle sessions developed from similar ideas of criticism and self-criticism in the Soviet Union from the 1920s. The term refers to class struggle; the session is held to \"benefit\" the target, by eliminating all traces of counterrevolutionary, reactionary thinking. Chinese communists resisted this at first, because struggle sessions conflicted with the Chinese concept of saving face, but struggle sessions became commonplace at Communist Party meetings during the 1930s due to public popularity.\n\nMargaret Chu, writing retrospectively for the Cardinal Mindszenty Foundation's \"Mindszenty Report\", in November 1998, said: \n\nAnne F. Thurston, in \"Enemies of the People\", gave a description of an infamous struggle session for the professor You Xiaoli:\n\nLately, the term \"struggle session\" has come to be applied to any scene where victims are publicly badgered to confess imaginary crimes under the pretext of self-criticism and rehabilitation.\n\nStruggle sessions were disowned in China after 1978, when the reformers led by Deng Xiaoping took power. Deng Xiaoping prohibited struggle sessions and other kinds of Mao-era violent political campaigns.\n\nIn September 2013, Xi Jinping has taken his \"criticism and self-criticism\" campaign on the road, attending a series of meetings where Hebei provincial cadres were made to admit shortcomings and offer ideas for correcting their behaviour. Xi has instructed regional officials to \"promote self-criticism and criticism\" to implement his \"mass line\" campaign, which he said is necessary to eliminate formality, bureaucracy, hedonism and extravagance among rank-and-file cadres.\n\n"}
{"id": "11906995", "url": "https://en.wikipedia.org/wiki?curid=11906995", "title": "Thought of Thomas Aquinas", "text": "Thought of Thomas Aquinas\n\nThis article contains a selection of thoughts of Thomas Aquinas on various topics. It is not intended as a complete account of Aquinas's thought. Within Aquinas' thought is included the philosophical school of Thomism.\n\nAquinas defines distributive justice as follows:\n\n[I]n distributive justice something is given to a private individual, in so far as what belongs to the whole is due to the part, and in a quantity that is proportionate to the importance of the position of that part in respect of the whole. Consequently in distributive justice a person receives all the more of the common goods, according as he holds a more prominent position in the community. This prominence in an aristocratic community is gauged according to virtue, in an oligarchy according to wealth, in a democracy according to liberty, and in various ways according to various forms of community. Hence in distributive justice the mean is observed, not according to equality between thing and thing, but according to proportion between things and persons: in such a way that even as one person surpasses another, so that which is given to one person surpasses that which is allotted to another.\nAquinas asserts that Christians have a duty to distribute with provision to the poorest of society. (See: Gilson, Etienne, \"The Christian Philosophy of St. Thomas Aquinas\", University of Notre Dame Press, 1994)\n\nThe following is a summary of Summa Contra Gentiles, Book 3, Chapter 146, which was written by Aquinas prior to writing the Summa Theologica. St. Thomas was a vocal supporter of the death penalty. This was based on the theory (found in natural moral law), that the state has not only the right, but the duty to protect its citizens from enemies, both from within, and without.\n\nFor those who have been appropriately appointed, there is no sin in administering punishment. For those who refuse to obey God's laws, it is correct for society to rebuke them with civil and criminal sanctions. No one sins working for justice and within the law. Actions that are necessary to preserve the good of society are not inherently evil. The common good of the whole society is greater and better than the good of any particular person. \"The life of certain pestiferous men is an impediment to the common good which is the concord of human society. Therefore, certain men must be removed by death from the society of men.\" This is likened to the physician who must amputate a diseased limb, or a cancer, for the good of the whole person. He based this on I Corinthians 5, 6: \"You know that a little leaven corrupts the whole lump of dough?\" and I Corinthians 5, 13: \"Put away the evil one from among yourselves\"; Romans 13,4: \"[it is said of earthly power that] he bears not the sword in vain: for he is God's minister, an avenger to execute wrath upon him that does evil\"; I Peter 2, 13-14: \"Be subjected therefore to every human creature for God's sake: whether to be on the king as excelling, or to governors as sent by him for the punishment of evildoers and for the praise of good.\" He believed these passages superseded the text of Exodus 20,13: \"Thou shall not kill.\" This is mentioned again in Matthew 5,21. Also, it is argued that Matthew 13, 30: \"Suffer both the weeds and the wheat to grow until the harvest.\" The harvest was interpreted as meaning the end of the world. This is explained by Matthew 13,38-40.\n\nAquinas acknowledged these passages could also be interpreted as meaning there should be no use of the death penalty if there was a chance of injuring the innocent. The prohibition \"Thou shall not kill\", was superseded by Exodus 22,18: \"Wrongdoers you shall not suffer to live.\" The argument that evildoers should be allowed to live in the hope that they might be redeemed was rejected by Aquinas as frivolous. If they would not repent in the face of death, it was unreasonable to assume they would ever repent. \"How many people are we to allow to be murdered while waiting for the repentance of the wrongdoer?\", he asked, rhetorically. Using the death penalty for revenge, or retribution is a violation of natural moral law.\n\nMany believe the correct interpretation of the commandment to be \"Thou shalt not murder.\" This interpretation allows for Aquinas' belief that the death penalty is an acceptable practice as delivered by those in authority over such things, such as government, which is divinely appointed as to God's will.\n\nUnder Pope John Paul II, the Catholic Church came, according to one of two interpretations of \"Evangelium Vitae\", to advocate incarceration in lieu of the death penalty.\n\nAquinas advocated the death penalty for obstinate heretics, writing\nWith regard to heretics two points must be observed: one, on their own side; the other, on the side of the Church. On their own side there is the sin, whereby they deserve not only to be separated from the Church by excommunication, but also to be severed from the world by death. For it is a much graver matter to corrupt the faith which quickens the soul, than to forge money, which supports temporal life. Wherefore if forgers of money and other evil-doers are forthwith condemned to death by the secular authority, much more reason is there for heretics, as soon as they are convicted of heresy, to be not only excommunicated but even put to death.On the part of the Church, however, there is mercy which looks to the conversion of the wanderer, wherefore she condemns not at once, but \"after the first and second admonition,\" as the Apostle directs: after that, if he is yet stubborn, the Church no longer hoping for his conversion, looks to the salvation of others, by excommunicating him and separating him from the Church, and furthermore delivers him to the secular tribunal to be exterminated thereby from the world by death. For Jerome commenting on Galatians 5:9, \"A little leaven,\" says: \"Cut off the decayed flesh, expel the mangy sheep from the fold, lest the whole house, the whole paste, the whole body, the whole flock, burn, perish, rot, die. Arius was but one spark in Alexandria, but as that spark was not at once put out, the whole earth was laid waste by its flame.\" (ST II:II 11:3 \"corpus\")\n\nThis position of Aquinas was congruous with the political and religious teaching of the day. The penalty of death for obdurate heretics had been the standard for generations prior to the time of Aquinas. It had been formalized in Canon Law during the Lateran Councils of 1179 and 1215. It was also the standard part of most criminal and civil laws prior to the time of Aquinas. Cathars were executed in Oxford in 1166. Another was burned at the stake in London in 1210. Of course, these, and many others pre-dated Aquinas. Since it was the Church's responsibility to attend to the eternal salvation of souls, heresy could not be tolerated. Heretics were given two chances to recant their views. This is a position which, by modern standards would be considered exceptionally harsh, and has changed and softened since the 13th century. The Church was inexorably intermixed with the secular political structure. This was before the modern concept of separation of church and state had developed. It was also a product of Scholasticism which did not seek to find an equivocal position, but rather to reach a decisive univocal conclusion on matters of religion and philosophy.\n\nAs can be seen by reading the article of Michael Novak, Aquinas' view in this matter is one of the more difficult parts of dealing with Thomism Needless to say, the attitudes of Aquinas were prevalent in his time. This view must be taken in context with the attitude shown by Aquinas in eschewing the forced baptism of the children of heretics, which was recommended by, among others, John Duns Scotus. The heretics Aquinas was referring to were those baptized Catholics who held positions of authority within the Church, and nonetheless persisted in teaching heretical views. It remains one of those passages which must be taken in context of the total message of Thomism. The growth of various heretical positions, leading to the Reformation, made execution of heretics impractical and counterproductive. Excommunication remained the penalty for such Church leaders who taught heresy. Aquinas' view is steeped in the traditions of Roman Law. A review of the legal history prior to the time of Aquinas reveals the nature of recommending execution of heretics. The issue came to a head with the Manichean (Cathari) heresy. Justinian's code confirmed that Manicheanism was a capital crime. It was concluded that other heretics were to be deemed no better. The opinion prevailed in legal circles that human law and divine command demanded the death of the obdurate heretic. It was routinely enforced by both Church and State. In severe cases of religious pestilence, there was a need for a holy war. These prevailing feelings were legislated by the Church in the Lateran Councils of 1179 and 1215.\n\nThe impenitent heretic when convicted by the ecclesiastical court for execution. Often, there was a plea for the life of the heretic, so as to avoid the appearance of \"irregularity\" and blood guilt. Frederick II, (1194–1250) incorporated the execution of heretics into his civil and criminal code of the Holy Roman Empire.\n\n\nFirstly, economics in the Middle Ages worked very differently from how they operate in the modern age. The Fifth Lateran Council defined usury as \"from its use, a thing which produces nothing is applied to the acquiring of gain and profit without any work, any expense or any risk\", and that the modern idea of what the usury is cannot be applied to Thomasian thought.\n\nSt. Thomas asserted that usury was a violation of natural moral law. All things are created for their natural end (Aristotle). Money is not an end but a means of buying goods and services. Putting money out for the generation of more money is an evil unto itself. The formal value of money is the face value. Yet usury allows this face value to fluctuate, and hence the value of money can be diminished, thereby robbing the person who has purchased the money for use. Money stands alone as a non-vendible substance which is degraded from its natural end by selling.\n\nAnother argument used by Aquinas was that of the Roman distinction between consumable goods and non-consumable goods. Food and clothes are consumable in that once they are used, they are gone. A piece of land is non-consumable since it can produce crops for years, yet never lose its value. Money as defined by Aquinas is a consumable. To put it out for profit betrays its purpose in natural law. This is the view that prevailed for the next three centuries following St. Thomas' death.\n\nYet it was the one Realistic Scholastic interpretation of natural law that was completely disconnected from the economic reality of the day. The time of Aquinas was one where land feudalism was ceding prominence to money capitalism. Over the next several centuries it became clear that capitalism would provide a greater amount of goods and services than any other system.\n\nEven in the time of Aquinas (and before), kings and popes engaged in usury. Some of the effects of Protestantism were a clarification of the views and acceptance of the practice of usury. Profit from lending became an acceptable goal. The Council of Trent (1545–1563) adopted Aquinas' view of usury, calling it a sin of equal gravity to that of homicide. This included putting money out for any return, no matter how minimal. It can be argued that this rigid stance may have encouraged the Protestant movement in larger money and trading centers.\n\nOur views concerning capitalism, unfair labor practice, living wage, price gouging, monopolies, fair trade practices, and predatory pricing, inter alia, are remnants of the inculcation of Aquinas' interpretation of natural moral law. (See Colish p. 333–334).\n\nThe issue was never as clear as the stance Aquinas took would indicate. From Pope Gregory IX (written about 1241, when Aquinas was 16 years old): \"He who loans a sum of money to one sailing or going to market, since he has assumed upon himself a risk, is not to be considered a usurer who will receive something beyond his lot. He also who gives ten solidi (a monetary unit), so that at another time just as many measures of grain, wine and oil may be paid back to him, and although these are worth more at the present time, it is probably doubtful whether at the time of payment, they will be worth more or less, for this reason, should not be considered a usurer. By reason of this doubt he is also excused, who sells clothing, grain, wine, oil, or other wares so that as a set time he receives for them more than they are worth at that time, if however, he had not intended so to sell them at the time of the contract.\" (See Denzinger, p. 178). In other words, if the lender of the money \"assumed the risk\" (\"assumpsit\" in Latin), along with the borrower, it was not usury.\n\nA century earlier, in the Second Lateran Council, (Second Council of the Lateran), under the aegis of Pope Innocent II (1139) called the practice of loaning money \"detestable and shameful... insatiable rapacity of money lenders, forbidden both by divine and human laws throughout the Old and New Testament, we condemn, and separate from the ecclesiastical consolation...\" (Denzinger p. 148–149).\n\nThe Council of Vienne (1311–1312) under Pope Clement V declared: \"If anyone shall fall into that error, so that he obstinately presumes to declare that it is not a sin to exercise usury, we decree that he must be punished as a heretic.\" (Denzinger p. 189). The distinction between usury and putting money out while \"assuming the risk\" was not mentioned. However, it could be argued that any time one assumed the risk, it was not considered usury.\n\nThere was always some confusion, and variance, in this teaching during the Middle Ages. The Fifth Lateran Council, (1515) decreed that a \"reasonable degree of return\" was allowable. (Denzinger p. 238). The social evil that was associated with usury was the fact that poor tenant farmers and city dwellers were often thrown into prison, or even killed if they could not repay the money they borrowed, and the interest charged. In these cases, the lenders of the money had assumed no risk. The Franciscan St. Anthony of Padua (1195–1231 AD) preached against this evil.\n\nThese events were occurring at a time when the Ecclesiastical Courts had great judicial power. There were several philosophical cross currents at play. On the one hand, the Canon Lawyers looked favorably on the products of labor, wages and profit, while holding suspect speculation, banking and finance. The Church discountenanced the fluctuations of wages and prices caused by the law of supply and demand. There was an attempt to maintain fixed standards of value. At the same time, there was a liberal and equitable view toward the old Roman idea of \"contract\". The Church Courts invented and refined the idea of \"consideration\" ; the quid pro quo in modern contract. This was something that was lacking in Roman contract. Insurance, assignability and negotiability were developments in the Church Courts. These areas were largely ignored by the Common Law, or secular law of the day, especially in England (Plucknett p. 302,304).\n\nThe Catholic Church's teaching on social doctrine has grown significantly more complicated since that time. It is beyond the scope of this article to delve into modern teaching. A summary can be found in the new Catechism of the Catholic Church, sections 2419–2463.\n\nThe question frequently arose whether the children of Jews and other heretics and non-believers should be baptized against the will of their parents. Two schools of thought were generally followed:\n\nTherefore, even if children were being reared in error, the Church had no authority to intervene. This was the position taken by Aquinas. From Summa Theologica II-II Q. 10 Art. 12:\n\nThe question was again addressed by Aquinas in Summa Theologica III Q. 68 Art. 10:\n\nThe issue was discussed in a papal bull by Pope Benedict XIV (1747) where both schools were addressed. The pope noted that the position of Aquinas had been more widely held among theologians and canon lawyers, than that of John Duns Scotus (See Denzinger).\n\n\nA primary goal of all philosophy is the proof of existence: the existence of God, the universe, and the self (see Colish, Macdonald-Cornford, Russell, Nahm, Pieper, Gilson). Although St. Thomas \"five proofs\" are the most referenced, they are targeted toward a Catholic audience. In Summa Contra Gentiles, Thomas provides a much lengthier and detailed proof that does not rely on divine revelation. God's existence is established based on the proposition that man's reason is capable of apprehending a cause from its effects. After analyzing motion, it becomes apparent that the first mover must be unmoved, without cause, and uncreated. From this, it then follows that the unmoved mover must be without change, and, therefore, must be eternal. The understanding that goodness and being are interchangeable leads to the realization that God is goodness. God is also found to be intelligent because he is not composed of matter nor is the form of any body. Since God is the first cause, His effects can be observed by the diversity found in creation, and the study of this is the study of Divine Providence. After building a foundation of proofs based upon natural reasoning, Aquinas then demonstrates that the Catholic Faith cannot be disproved and goes on to defend various positions against the Incarnation, the sacraments, and the Resurrection. This line of thought is also followed in the Summa Theologica and the Compendium of Theology.\n\nA basic question of Greek Philosophy: Can an organized hierarchy (as is seen in nature) exist in the absence of an intelligence? In the atheistic view, the answer is \"yes\". If one answers \"no\", then there is a necessity of an intelligent God. The Greeks called this ultimate intelligence the \"gnos\" or \"nous\" (Nahm pp. 1–28). However, the intimate nature of this intelligence cannot be delineated by human contemplation. Many philosophers concluded that the Universe itself, was the God (Gilson). It was basically indifferent the needs of the human. This is very different from the Judeo-Christian concept of an intimate and loving God, aware of all.\n\nSome Greek philosophers such as Zeno of Citium, Chrysippus, Plotinus, Thales of Miletus, Heraclitus, Parmenides, Socrates, Plato and Aristotle came to the conclusion that there had to be a God. Their conclusions were based on various physical observations: there could be no infinity of actions, therefore, there must be an unmoving mover, which moves without moving. This is the prime mover. There has to be a beginning and an end, otherwise, everything would have happened long ago and not now. This is also seen in Jewish philosophy (which may be based on Greek philosophy). There must be an ultimate smallness, of which there can be nothing smaller: the atomus (Leucippus, Democritus). This was in response to the Paradoxes of Zeno: there could be no motion, since every moving body would have to pass through half the distance, then one-quarter the distance, etc. A body could not pass through an infinite number of points. This led to the conclusion that all nature was united: the doctrine of the \"One\". Therefore, the human mind could reasonably conclude that there was a single God, and that this God existed (For an overview see Gilson p. 29-83; Russell pp. 453–463). This God had to be intelligent.\n\nWhen Moses wished to know the name of God in order to reveal it to the Jewish people, he asked God directly. Exodus 3, 13-14: \"'Lo! I go to the children of Israel, and I shall say to them: the God of your fathers sent me to you. If they ask me His name what shall I say to them?' God replied: 'I Am Who Am.' Then He added, 'Thus will you reply to the children of Israel: He Who Is sends me to you.'\" Therefore, the proper name of God is \"I Am\" or \"Who Is\". This was a remarkable exposition on several levels. First, the idea that the great, unapproachable God of the Hebrews would provide His name was exceptional. Recall that in these ancient cultures, to know the name of a person was to possess them, or a part of them, in some way. Also, the name is unusual. What did this mean? (Gilson) The only means available to the early Christians for evaluating philosophy was provided by the Greeks. Largely, this was within the Stoic school, which had been re-invigorated by the Persians whom Alexander the Great had brought back to Greece. These in turn, influenced the Roman Stoic Schools which affected both pagan and Christian thought (Colish pp. 9, 12,21, 179-180, 300-301; Russell pp. 252–270). Christianity has been described as a religion without a need for a philosophic basis. The Stoics gave it one (Gilson, p. 84).\n\nSt. Augustine was convinced that the God of Exodus was Plato's being. He speculated that Plato must have known of Exodus. \"But what makes me almost subscribe to the idea that Plato was not completely ignorant of the Old Testament is that when the Angel conveys the words of God to the holy man Moses, who asks the name of the one who is sending him to proceed to the deliverance of the Hebrew people, the reply is: 'I Am Who Am', and you are to say to the children of Israel: 'it is He Who is Who has sent me to you.' It was as if, in comparison with him who truly is because he is immovable, he who has been made movable did not exist. Now Plato was intensely convinced of this and he took great care to say so.\" (Augustine De Civ. Dei 8:11, PL 41,236). The Being in Exodus was the same immovable entity of Plato, according to Augustine. he called the immovable being of Plato, \"The first and highest being is that which is entirely immovable, and which can say by full right: 'I Am Who Am'; and you will tell them, 'He Who Is has sent me to you.'\" (St. Augustine, De doctrina christiana, I, 32,5; PL 34, 32).\n\nSt. Augustine had a very deep sense of the difficulty of the problem presented by this tract. He asked the question \"I Am\" what? From John 8, 24: \"If you do not believe that I Am, you will die in your sins.\" But Augustine asked, \"si non credideritis quia ego sum?\" (I Am What?) There was nothing added. Augustine found this embarrassing. \"We were waiting for Him to say what He was, and He says nothing.\" Augustine: \"If you do not believe that I Am the Christ; if you do not believe that I Am the Son of God; if you do not believe that I Am the Word of the Father; if you do not believe that I Am the author of the world; if you do not believe that I Am the former and the reformer of man, his creator and recreator, He Who made him and remade him; if you do not believe that I Am that, you will die in your sins. This I Am, He says He Is, is embarrassing. Even if Moses could understand this, how could the people to whom he was being sent understand it? In point of fact, he did add: 'I Am the God of Abraham, and the God of Isaac, and the God of Jacob (Exodus 3, 13-15)(Augustine on the Gospel of St. John) (Gilson, p. 85)\n\nThis is the source of the doctrine of divine essentialitas, or essential theology of Augustine which would influence Richard of St. Victor, Alexander of Hales and St. Bonaventure. By this method, the essence of God is defined by what God is, and also by describing what God is not (negative theology). St. Thomas took the text of Exodus beyond the explanation of essential theology. He bridged the gap of understanding between the being of essence and the being of existence. In Summa Theologica, the way is prepared with the proofs for the existence of God. All that remained was to recognize the God of Exodus as having the nature of \"Him Who is the supreme act of being\". God is simple, there is no composition in God. In this regard, Aquinas relied on Boethius who in turn followed the path of Platonism, something Aquinas usually avoided. The conclusion was that the meaning of \"I Am Who Am\" is not an enigma to be answered, but the statement of the essence of God. This is the discovery of Aquinas: the essence of God is not described by negative analogy, but the \"essence of God is to exist\". This is the basis of \"existential theology\" and leads to what Gilson calls the first and only existential philosophy. In Latin, this is called \"Haec Sublimis Veritas\", \"the sublime truth\". The revealed essence of God is to exist, or in the words of Aquinas, I am the pure Act of Being. This has been described as the key to understanding Thomism. Thomism has been described (in terms of a philosophic movement), as either the emptiest, or the fullest of philosophies. (For a full discussion, see Gilson, pp. 84–95)\n\n\n"}
{"id": "330241", "url": "https://en.wikipedia.org/wiki?curid=330241", "title": "Three generations of human rights", "text": "Three generations of human rights\n\nThe division of human rights into three generations was initially proposed in 1979 by the Czech jurist Karel Vasak at the International Institute of Human Rights in Strasbourg. He used the term at least as early as November 1977. Vasak's theories have primarily taken root in European law.\n\nHis divisions follow the three watchwords of the French Revolution: \"Liberty, Equality, Fraternity\". The three generations are reflected in some of the rubrics of the Charter of Fundamental Rights of the European Union. The Universal Declaration of Human Rights includes rights that are thought of as second generation as well as first generation ones, but it does not make the distinction in itself (the rights listed are not in specific order).\n\nFirst-generation human rights, sometimes called \"blue\" rights, deal essentially with liberty and participation in political life. They are fundamentally civil and political in nature: They serve negatively to protect the individual from excesses of the state. First-generation rights include, among other things, the right to life, equality before the law, freedom of speech, the right to a fair trial, freedom of religion, and voting rights. They were pioneered by the United States Bill of Rights and in France by the Declaration of the Rights of Man and of the Citizen in the 18th century, although some of these rights and the right to due process date back to the Magna Carta of 1215 and the Rights of Englishmen, which were expressed in the English Bill of Rights in 1689.\n\nThey were enshrined at the global level and given status in international law first by Articles 3 to 21 of the 1948 Universal Declaration of Human Rights and later in the 1966 International Covenant on Civil and Political Rights. In Europe, they were enshrined in the European Convention on Human Rights in 1953.\n\nSecond-generation human rights are related to equality and began to be recognized by governments after World War II. They are fundamentally economic, social, and cultural in nature. They guarantee different members of the citizenry equal conditions and treatment. Secondary rights would include a right to be employed in just and favorable condition, rights to food, housing and health care, as well as social security and unemployment benefits. Like first-generation rights, they were also covered by the Universal Declaration of Human Rights, and further embodied in Articles 22 to 28 of the Universal Declaration, and the International Covenant on Economic, Social, and Cultural Rights.\n\nIn the United States of America, President Franklin D. Roosevelt proposed a Second Bill of Rights, covering much the same grounds, during his State of the Union Address on January 11, 1944. Today, many nations, states, or groups of nations have developed legally binding declarations guaranteeing comprehensive sets of human rights, e.g. the European Social Charter.\n\nSome states have enacted some of these economic rights, e.g. the state of New York has enshrined the right to a free education, as well as \"the right to organize and to bargain collectively\", and workers' compensation, in its constitutional law.\n\nThese rights are sometimes referred to as \"red\" rights. They impose upon the government the duty to respect and promote and fulfill them, but this depends on the availability of resources. The duty is imposed on the state because it controls its own resources. No one has the direct right to housing and right to education. (In South Africa, for instance, the right is not, \"per se\", to housing, but rather \"to have access to adequate housing\", realised on a progressive basis.)\n\nThe duty of government is in the realization of these positive rights.\n\nThird-generation human rights are those rights that go beyond the mere civil and social, as expressed in many progressive documents of international law, including the 1972 Stockholm Declaration of the United Nations Conference on the Human Environment, the 1992 Rio Declaration on Environment and Development, and other pieces of generally aspirational \"soft law\". Because of the present-day tilting toward national sovereignty and the preponderance of would-be offender nations, these rights have been hard to enact in legally binding documents.\n\nThe term \"third-generation human rights\" remains largely unofficial, just as the also-used moniker of \"green\" rights, and thus houses an extremely broad spectrum of rights, including:\n\n\nThe African Charter on Human and Peoples' Rights ensures many of those: right to self-determination, right to development, right to natural resources and right to satisfactory environment. Some countries also have constitutional mechanisms for safeguarding third-generation rights. For example, the Hungarian Parliamentary Commissioner for Future Generations, the Parliament of Finland's Committee for the Future, and the erstwhile Commission for Future Generations in the Knesset in Israel.\n\nSome international organizations have offices for safeguarding such rights. An example is the High Commissioner on National Minorities of the Organization for Security and Co-operation in Europe. The Directorate-General for the Environment of the European Commission has as its mission \"protecting, preserving and improving the environment for present and future generations, and promoting sustainable development\".\n\nA few jurisdictions have enacted provisions for environmental protection, e.g. New York's \"forever wild\" constitutional article, which is enforceable by action of the New York State Attorney General or by any citizen \"ex rel.\" with the consent of the Appellate Division.\n\nMaurice Cranston argued that scarcity means that supposed second-generation and third-generation rights are not really rights at all. If one person has a right, others have a duty to respect that right, but governments lack the resources necessary to fulfill the duties implied by citizens' supposed second- and third-generation rights.\n\nCharles Kesler, a professor of government at Claremont McKenna College and senior fellow of the Claremont Institute, has argued that second- and third-generation human rights serve as an attempt to cloak political goals, which the majority may well agree are good things in and of themselves, in the language of rights, and thus grant those political goals inappropriate connotations. In his opinion, calling socio-economic goods \"rights\" inherently creates a related concept of \"duties\", so that other citizens have to be coerced by the government to give things to other people in order to fulfill these new rights. He also has stated that, in the US, the new rights create a \"nationalization\" of political decision-making at the federal level in violation of federalism. In his book \"Soft Despotism, Democracy's Drift\", Paul Rahe, the Charles O. Lee and Louise K. Lee Chair in Western Heritage at Hillsdale College, wrote that focusing on equality-based rights leads to a subordination to the initial civil rights to an ever-expanding government, which would be too incompetent to provide for its citizens correctly and would merely seek to subordinate more rights.\n\n19th century philosopher Frederic Bastiat summarized the conflict between these negative and positive rights by saying:\n\nEconomist F. A. Hayek has argued that the second generation concept of \"social justice\" cannot have any practical political meaning:\n\nNew York University School of Law professor of law Jeremy Waldron has written in response to critics of the second-generation rights:\n\nHungarian socialist and political economist Karl Polanyi made the antithetical argument to Hayek in the book \"The Great Transformation\". Polanyi wrote that an uncontrolled free market would lead to repressive economic concentration and then to a co-opting of democratic governance that degrades civil rights.\n\nThe World Conference on Human Rights opposed the distinction between civil and political rights (negative rights) and economic, social and cultural rights (positive rights) that resulted in the Vienna Declaration and Programme of Action proclaiming that \"all human rights are universal, indivisible, interdependent and interrelated\".\n\n\n"}
{"id": "18152904", "url": "https://en.wikipedia.org/wiki?curid=18152904", "title": "Visual analytics", "text": "Visual analytics\n\nVisual analytics is an outgrowth of the fields of information visualization and scientific visualization that focuses on analytical reasoning facilitated by interactive visual interfaces.\n\nVisual analytics is \"the science of analytical reasoning facilitated by interactive visual interfaces.\" It can attack certain problems whose size, complexity, and need for closely coupled human and machine analysis may make them otherwise intractable. Visual analytics advances science and technology developments in analytical reasoning, interaction, data transformations and representations for computation and visualization, analytic reporting, and technology transition. As a research agenda, visual analytics brings together several scientific and technical communities from computer science, information visualization, cognitive and perceptual sciences, interactive design, graphic design, and social sciences.\n\nVisual analytics integrates new computational and theory-based tools with innovative interactive techniques and visual representations to enable human-information discourse. The design of the tools and techniques is based on cognitive, design, and perceptual principles. This science of analytical reasoning provides the reasoning framework upon which one can build both strategic and tactical visual analytics technologies for threat analysis, prevention, and response. Analytical reasoning is central to the analyst’s task of applying human judgments to reach conclusions from a combination of evidence and assumptions.\n\nVisual analytics has some overlapping goals and techniques with information visualization and scientific visualization. There is currently no clear consensus on the boundaries between these fields, but broadly speaking the three areas can be distinguished as follows:\n\n\nVisual analytics seeks to marry techniques from information visualization with techniques from computational transformation and analysis of data. Information visualization forms part of the direct interface between user and machine, amplifying human cognitive capabilities in six basic ways:\n\n\nThese capabilities of information visualization, combined with computational data analysis, can be applied to analytic reasoning to support the sense-making process.\n\nVisual analytics is a multidisciplinary field that includes the following focus areas:\n\n\nAnalytical reasoning techniques are the method by which users obtain deep insights that directly support situation assessment, planning, and decision making. Visual analytics must facilitate high-quality human judgment with a limited investment of the analysts’ time. Visual analytics tools must enable diverse analytical tasks such as:\n\n\nThese tasks will be conducted through a combination of individual and collaborative analysis, often under extreme time pressure. Visual analytics must enable hypothesis-based and scenario-based analytical techniques, providing support for the analyst to reason based on the available evidence.\n\nData representations are structured forms suitable for computer-based transformations. These structures must exist in the original data or be derivable from the data themselves. They must retain the information and knowledge content and the related context within the original data to the greatest degree possible. The structures of underlying data representations are generally neither accessible nor intuitive to the user of the visual analytics tool. They are frequently more complex in nature than the original data and are not necessarily smaller in size than the original data. The structures of the data representations may contain hundreds or thousands of dimensions and be unintelligible to a person, but they must be transformable into lower-dimensional representations for visualization and analysis.\n\nTheories of visualization include:\n\nVisual representations translate data into a visible form that highlights important features, including commonalities and anomalies. These visual representations make it easy for users to perceive salient aspects of their data quickly. Augmenting the cognitive reasoning process with perceptual reasoning through visual representations permits the analytical reasoning process to become faster and more focused.\n\nThe input for the data sets used in the visual analytics process are heterogeneous data sources (i.e., the internet, newspapers, books, scientific experiments, expert systems). From these rich sources, the data sets \"S = S, ..., S\" are chosen, whereas each \"S , i ∈ (1, ..., m)\" consists of attributes A, ..., A. The goal or output of the process is insight \"I\". Insight is either directly obtained from the set of created visualizations \"V\" or through confirmation of hypotheses \"H\" as the results of automated analysis methods. This formalization of the visual analytics process is illustrated in the following figure. Arrows represent the transitions from one set to another one.\n\nMore formally the visual analytics process is a transformation \"F: S → I\", whereas \"F\" is a concatenation of functions \"f ∈ {D, V, H, U}\" defined as follows:\n\n\"D\" describes the basic data pre-processing functionality with \"D : S → S and W ∈ {T, C, SL, I}\" including data transformation functions \"D\", data cleaning functions \"D\", data selection functions \"D\" and data integration functions \"D\" that are needed to make analysis functions applicable to the data set.\n\n\"V, W ∈ {S, H}\" symbolizes the visualization functions, which are either functions visualizing data \"V : S → V\" or functions visualizing hypotheses \"V : H → V\".\n\n\"H, Y ∈ {S, V}\" represents the hypotheses generation process. We distinguish between functions that generate hyphotheses from data \"H : S → H\" and functions that generate hypotheses from visualizations \"H : V → H\".\n\nMoreover, user interactions \"U, Z ∈ {V, H, CV, CH}\" are an integral part of the visual analytics process. User interactions can either effect only visualizations \"U : V → V\" (i.e., selecting or zooming), or can effect only hypotheses \"U : H → H\" by generating a new hypotheses from given ones. Furthermore, insight can be concluded from visualizations \"U : V → I\" or from hypotheses \"U : H → I\".\n\nThe typical data pre-processing applying data cleaning, data integration and data transformation functions is defined as \"D = D(D(D(S, ..., S)))\". After the pre-processing step either automated analysis methods \"H = {f, ..., f}\" (i.e., statistics, data mining, etc.) or visualization methods \"V : S → V, V = {f, ..., f}\" are applied to the data, in order to reveal patterns as shown in the figure above.\n\nIn general the following paradigm is used to process the data:\n\n\"Analyse First – Show the Important – Zoom, Filter and Analyse Further – Details on Demand\"\n\n"}
