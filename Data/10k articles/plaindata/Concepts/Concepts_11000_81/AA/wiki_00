{"id": "11328773", "url": "https://en.wikipedia.org/wiki?curid=11328773", "title": "77 Million Paintings", "text": "77 Million Paintings\n\n77 Million Paintings is a digital art software/DVD combination by British musician Brian Eno, released in 2006.\n\nThe release consists of two discs, one containing the software that creates the randomized music and images that emulate a single screen of one of Eno's video installation pieces. The other is a DVD containing interviews with the artist.\n\nThe title is derived from the possible number of combinations of video and music which can be generated by the software, effectively ensuring that the same image/soundscape is never played twice.\n\nAn accompanying booklet includes a piece by Nick Robertson describing the intention behind the software, and an article by Brian Eno (\"My Light Years\") describing his experiments with light and music.\n\nThe software was developed by Jake Dowie for both Windows and Macintosh operating systems.\n\nFar from containing 77 million paintings, the software consists of 296 original works which are overlaid and combined up to four at a time in a simulation of simultaneous projection onto a common screen. The various images are slowly faded in and out asynchronously before being replaced by another random element. Also the music that accompanies the paintings, if played on a Mac G5 or a Windows PC, is randomly generated in a similar way, so the selection of elements and their duration in the piece are arbitrarily chosen, forming a virtually infinite number of variations.\n\nIn conjunction with this, Annabeth Robinson (AngryBeth Shortbread) recreated the performance in Second Life by building the performance in a multi-user virtual environment (MUVE).\n\nA second edition of \"77 Million Paintings\", featuring improved morphing and a further two layers of sound, was released on 14 January 2008.\n\n77 Million Paintings has evolved beyond the domestic environment. It continues to be shown in multiple-monitor configurations in art galleries and is projected onto iconic buildings around the world. In 2009, Eno was invited to project 77 Million Paintings onto the sails of the Sydney Opera House.\n\n\n"}
{"id": "42597133", "url": "https://en.wikipedia.org/wiki?curid=42597133", "title": "Adrishta", "text": "Adrishta\n\nThe Fifth Chapter of the Vaisheshika Sutras of Kanada deals with the notion of action and the connected concept of effort; and also deals with the various special phenomenon of nature to the supersensible force, called Adrishta.\n\nThe Sanskrit term, Adrishta (Sanskrit: अदृष्ट), as an adjective means - not seen, unseen, unobserved, unforeseen, unknown, invisible, unexpected, not experienced, destiny, fate, luck, not permitted or sanctioned, illegal, virtue or vice as the eventual cause of pleasure or pain. In Hindu philosophy it refers to the unseen force, and the invisible results of works which accrue to a person; it refers to the Doctrine of Apurva.\n\nAdrishta, literally meaning unseen, in the Mimamsa context refers to the invisible result of a ritual that accrues to a person, and in the Vaisheshika context, synonymous with Adharma, to the equally invisible negative karmic accrual, as the unknown quality of things and of the soul, and brings about the cosmic order and arranges for soul according to their merits or demerits. Adrishta is all the elements which are not known and verified with the help of the five senses, and which can be realized through mind, intelligence and soul.\n\nEach successive birth or incarnation and its possibilities are determined by the Adrishta and Samskara acquired in the previous incarnations – Adrishta and Samskara, without which the Atman has never been, because its series of incarnations never began. Adrishta is Potential worth which must have been acquired in a human state to relate to a human state; it gives unity to the multiplicity and infinite variety of beings, and of the things under their control, it binds them into a single system and an organic whole. Prashasta hints that the existence of the Universe itself though not due to Brahma’s Adrishta is not free from Adrishta (Moral merit). All current actions and planned future actions get planted in Adrishta.\n\nThe term Vaisheshika, appearing only once in Vaisheshika Sutra X.ii.7 and meaning characteristic or distinguishing, according to Pāṇini (Sutra IV.iii.87) is derived from the word Vishesha meaning species, distinction, difference, excellence or superiority. Uluka, who was before the birth of Gautama Buddha and is commonly known as Kanada, compiled the Vaisheshika sutras. Gautama who founded the Nyaya School came later. The term Adrishta appears in Vaisheshika Sutra V.i.15:\n\nThe reason of the movement of the jewel is not a particular volition but the efficient cause is the merit of the former possessor or the demerit of the thief. The non-combative cause is its conjunction with soul possessing adrishta (or results of actions in previous states of existence) and the combinative cause is the jewel. Adrishta is also the cause of attraction of the needle towards a loadstone (magnet). Owing to adrishta is the upwards flaming of fire, the sideward motion of air and the actions of atoms at the beginning of creation. Kanada, later on, tells us that even action in earth results from impulse, impact, and conjunction with the conjunct and is caused by Adrishta (Vaisheshika Sutra V.ii.1-2).\nThe fruits or rewards of yajnas or sacrifice are not dispensed by any beneficent God. Apurva bestows the reward on the sacrificer. Apurva is the essential link between work and its result; it is a positive and unseen force created by an act that leads to the attainment of the fruit of action. This is the view of Jaimini though not implicitly mentioned by him but accepted by Prabhakara and Kumarila as one the fundamental tenets of their respective schools. Later on, it came to be said that Apurva is the function of God. Kumarila insists that fruits of karmas accrue in this very life and not in some future life. Bharat Mitra, who lived long before Sabara who lived long before Kumarila, does not accept Apurva. However, Patanjali tells us –\n\nthat obstacles are the breeding ground for tendencies that give rise to actions and the consequences thereof; such obstacles are experienced as visible and invisible obstacles. Swami Prabhavananda translates this sutra as – \"A man’s latent tendencies have been created by his past thoughts and actions; these tendencies will bear fruits, both in this life and in lives to come.\" \n\nApurva is an epistemic mechanism that indicates knowledge of causal links between acts and their consequences. Sabara discusses this concept in his commentary on the Vaisheshika Sutras, and even claims that by the word \"codana\" (Sanskrit: चोदन -meaning precept or rule -the performative element of an injunction) Jaimini really meant Apurva; it is mentioned by Jaimini in passing, as part of purvapaksha argument in Mimamasa Sutra I.ii.9.\n\nThe early Mimamsakas believed in an adrishta that was the result of performing karmas and saw no need for an Ishvara in their system. However, the Atomic Theory which teaches that the world is produced by the successive formation of compounds due to the aggregation of atoms resulting from the motion of atoms, the primary motion brought about by the unseen the Adrishta residing in the primary atoms and residing in the individual souls is rejected by the followers of the Vedanta (Uttara Mimamsa) schools:\n\"In either case (viz the Adrishta, the unseen principle, inhering either in the atoms or in the soul) the activity (of the atoms) is not (possible), therefore the negation of that (viz of creation through the combination of atoms).\"\n\nThe Nyaya-Vaisheshika systems of philosophy derive the conception of moksha from the Upanishads but require a highly developed stage of logical thought, and care more for the instrument of knowledge than for knowledge itself. The Mimamsa system by the very nature of its ritualistic problems does not have much in common with Upanishadic philosophy.\n"}
{"id": "401719", "url": "https://en.wikipedia.org/wiki?curid=401719", "title": "Anahata", "text": "Anahata\n\nAnahata (, IAST: , ) or heart chakra is the fourth primary chakra, according to Hindu Yogic, Shakta and Buddhist Tantric traditions. In Sanskrit, \"anahata\" means \"unhurt, unstruck, and unbeaten\". \"Anahata Nad\" refers to the Vedic concept of \"unstruck sound\" (the sound of the celestial realm). Anahata is associated with balance, calmness, and serenity.\n\nIn Sanskrit Anahata means \"sound produced without touching two parts\" and at the same time it means \"pure\" or \"clean, stainless\". The name of this chakra signifies the state of freshness that appears when we are able to become detached and to look at the different and apparently contradictory experiences of life with a state of openness (expansion). Normally we are used that an effect is produced by the confrontation of the two opposite forces. At the level of Anahata chakra appears the possibility to integrate the two opposite forces and in this way to obtain the effect (sound, in this case), without the two forces to be confronted (without touching of the two parts). This energy is specific to cooperation and integration, which brings peace and a new perspective in a world which, up to this level (considering only the energies specific to the first three centres of force: Muladhara, Swasdhistana and Manipura) was made only of a more or less conscious confrontation between opposite forces. The name Anahata suggests, in fact, the synergic effect of the interaction of energies at this level.\n\nThe heart chakra is located in the central channel of the spine near the heart, with its kshetram \n\nAnahata is represented by a lotus flower with twelve petals. Inside there is a smoky region at the intersection of two triangles, creating a shatkona. The shatkona is a symbol used in Hindu Yantra, representing the union of male and female. Specifically, it is meant to represent Purusha (the Supreme Being) and Prakriti (Mother Nature) and is often represented by Shiva and Shakti. The deity of this area is Vayu, who is smoke-like and four-armed, holding a kusha and riding an antelope (this chakra's animal).\n\nThe seed syllable is the dark-grey mantra \"yam\". In the bindu (or dot) above the syllable is the deity Isha. Isha is bright white or blue in color. He has either one or five faces, with three eyes on each face. He may have two, four or ten arms. He is clad in a tiger skin, holds a trident and drum, grants blessings, and dispels fear. His shakti is Kakini, who is shining yellow or rose-coloured. She has a number of variations: one, three or six faces; two or four arms; and holds a variety of implements (occasionally a sword, shield, skull or trident). She is seated on a red lotus.\n\nThe twelve red petals are inscribed with the syllables \"kam\", \"kham\", \"gam\", \"gham\", \"ngam\", \"cham\", \"chham\", \"jam\", \"jham\", \"nyam\", \"tam\" and \"tham\" in Sanskrit. They match the vrittis of lust, fraud, indecision, repentance, hope, anxiety, longing, impartiality, arrogance, incompetence, discrimination and defiance.\n\nAnahata is considered to be the seat of the Jivatman and Parashakti. In the Upanishads, this is described as a tiny flame inside the heart. Anahata is named as such because sages were believed to hear the sound (Anahata – comes without the striking of two objects together). It is associated with air, touch and the actions of the hands.\n\nAnahata is associated with the ability to make decisions outside the realm of karma. In Manipura and below, man is bound by the laws of karma and fate. In Anahata one makes decisions (\"follows one's heart\") based on one's higher self, not the unfulfilled emotions and desires of lower nature. As such, it is known as the heart chakra. It is also associated with love and compassion, charity to others and psychic healing. Meditation on this chakra is said to bring about the following siddhis (abilities): he becomes a lord of speech, he is dear to women, his presence controls the senses of others, and he can leave and enter the body at will.\n\nImmediately below Anahata (at the solar plexus or, sometimes, on the near left side of the body) is a minor chakra known as Hrit (or Hridaya, \"heart\"), with eight petals. It has three regions: a vermilion sun region, within which is a white moon region, within which is a deep-red fire region. Within this is the red wish-fulfilling tree, kalpa taru, which symbolises the ability to manifest what one wishes to happen in the world.\n\nHrit chakra is sometimes known as the Surya (sun) chakra, which is located slightly to the left below the heart. Its role is to absorb energy from the sun and provide heat to the body and the other chakras (to Manipura in particular, to which it provides \"Agni' (fire).\n\nAnahata is said to be near the heart. Because of its connection to \"touch\" (sense) and \"actions\", it is associated with the skin and hands. In the endocrine system, Anahata is said to be associated with the thymus.\n\nIn Kundalini yoga, anahata is awakened and balanced by asanas, pranayamas and the practice of ajapa japa (japa, without the mental effort normally needed to repeat the mantra) and purified by \"bhakti\" (devotion).\n\nThe heart wheel in Tibetan Buddhism is the location of the indestructible red-and-white drop. At death, the winds of the body dissolve and enter this drop, which then leads the body into Bardo (the intermediate stage) and rebirth. The heart wheel in this model is circular, white and has eight petals (or channels) reaching downwards. These channels divide into three wheels (mind, speech and body) and go to 24 places in the body. They again divide into three and then into 1,000, producing 72,000 channels (known as Nadi) throughout the body.\n\nThe heart wheel is important in meditation; in the lower tantras, the mantra is recited from the heart. It is recited verbally and then mentally; then, in the heart, a tiny moon disc and flame are imagined from which the mantra rings. In the higher tantras (the Anuttarayoga Tantra of the Sarma schools) or the Inner Tantras of the Nyingma school, the practitioner attempts to dissolve the winds and drops into the central channel at the level of the heart to experience the Yoga of Clear Light; this is a practice of the Six Yogas of Naropa. In Tibetan Buddhism there is a chakra, the Fire Wheel, above the heart and below the throat.\n\nSufis have a system of Lataif-e-sitta at a number of points on the body; at the heart, there are three positioned horizontally. On the left side of the chest is the Qalb (the heart); the Ruh is on the right side of the chest, and the Sirr (innermost heart) is between them.\n\nThe Qalb is called the \"heart of the mystic\"; it is caught between the downward pull of the lower nafs, and the upward pull of the spirit of Allah and may be blackened by sin. It may be purified by reciting the names of God. The Ruh is the centre of the spirit, the breath of Allah; when awakened, it counteracts the negative pull of the nafs. The Sirr is the innermost heart, where Allah manifests his mystery to himself.\n\nIn Qigong, the middle Dantian (one of the three furnaces that transform energy in the body) is in this region. The middle Dantian transforms qi energy into shen (spiritual energy). This is also not a correct location of a Dantian. The Dantian is located on the Anterior of the body, not the posterior, as is this chakra.\n\n\n"}
{"id": "103533", "url": "https://en.wikipedia.org/wiki?curid=103533", "title": "Analogy", "text": "Analogy\n\nAnalogy (from Greek ἀναλογία, \"analogia\", \"proportion\", from \"ana-\" \"upon, according to\" [also \"against\", \"anew\"] + \"logos\" \"ratio\" [also \"word, speech, reckoning\"]) is a cognitive process of transferring information or meaning from a particular subject (the analog, or source) to another (the target), or a linguistic expression corresponding to such a process. In a narrower sense, analogy is an inference or an argument from one particular to another particular, as opposed to deduction, induction, and abduction, in which at least one of the premises, or the conclusion, is general rather than particular in nature. The term analogy can also refer to the relation between the source and the target themselves, which is often (though not always) a similarity, as in the biological notion of analogy.\nAnalogy plays a significant role in problem solving, as well as decision making, argumentation, perception, generalization, memory, creativity, invention, prediction, emotion, explanation, conceptualization and communication. It lies behind basic tasks such as the identification of places, objects and people, for example, in face perception and facial recognition systems. It has been argued that analogy is \"the core of cognition\". Specific analogical language comprises exemplification, comparisons, metaphors, similes, allegories, and parables, but \"not\" metonymy. Phrases like \"and so on\", \"and the like\", \"as if\", and the very word \"like\" also rely on an analogical understanding by the receiver of a message including them. Analogy is important not only in ordinary language and common sense (where proverbs and idioms give many examples of its application) but also in science, philosophy, law and the humanities. The concepts of association, comparison, correspondence, mathematical and morphological homology, homomorphism, iconicity, isomorphism, metaphor, resemblance, and similarity are closely related to analogy. In cognitive linguistics, the notion of conceptual metaphor may be equivalent to that of analogy. Analogy is also a basis for any comparative arguments as well as experiments whose results are transmitted to objects that have been not under examination (e.g., experiments on rats when results are applied to humans).\n\nAnalogy has been studied and discussed since classical antiquity by philosophers, scientists, theologists and lawyers. The last few decades have shown a renewed interest in analogy, most notably in cognitive science.\n\nWith respect to the terms \"source\" and \"target\" there are two distinct traditions of usage:\n\n\nIn ancient Greek the word \"αναλογια\" (\"analogia\") originally meant proportionality, in the mathematical sense, and it was indeed sometimes translated to Latin as \"proportio\". From there analogy was understood as identity of relation between any two ordered pairs, whether of mathematical nature or not. Kant's \"Critique of Judgment\" held to this notion. Kant argued that there can be exactly the same relation between two completely different objects. The same notion of analogy was used in the US-based SAT tests, that included \"analogy questions\" in the form \"A is to B as C is to \"what\"?\" For example, \"Hand is to palm as foot is to ____?\" These questions were usually given in the Aristotelian format: HAND : PALM : : FOOT : ____ While most competent English speakers will immediately give the right answer to the analogy question (\"sole\"), it is more difficult to identify and describe the exact relation that holds both between pairs such as \"hand\" and \"palm\", and between \"foot\" and \"sole\". This relation is not apparent in some lexical definitions of \"palm\" and \"sole\", where the former is defined as \"the inner surface of the hand\", and the latter as \"the underside of the foot\". Analogy and abstraction are different cognitive processes, and analogy is often an easier one. This analogy is not comparing \"all\" the properties between a hand and a foot, but rather comparing the \"relationship\" between a hand and its palm to a foot and its sole. While a hand and a foot have many dissimilarities, the analogy focuses on their similarity in having an inner surface. A computer algorithm has achieved human-level performance on multiple-choice analogy questions from the SAT test. The algorithm measures the similarity of relations between pairs of words (e.g., the similarity between the pairs HAND:PALM and FOOT:SOLE) by statistical analysis of a large collection of text. It answers SAT questions by selecting the choice with the highest relational similarity.\n\nGreek philosophers such as Plato and Aristotle actually used a wider notion of analogy. They saw analogy as a shared abstraction. Analogous objects did not share necessarily a relation, but also an idea, a pattern, a regularity, an attribute, an effect or a philosophy. These authors also accepted that comparisons, metaphors and \"images\" (allegories) could be used as arguments, and sometimes they called them \"analogies\". Analogies should also make those abstractions easier to understand and give confidence to the ones using them.\n\nThe Middle Age saw an increased use and theorization of analogy. Roman lawyers had already used analogical reasoning and the Greek word \"analogia\". Medieval lawyers distinguished \"analogia legis\" and \"analogia iuris\" (see below). In Islamic logic, analogical reasoning was used for the process of qiyas in Islamic sharia law and fiqh jurisprudence. In Christian theology, analogical arguments were accepted in order to explain the attributes of God. Aquinas made a distinction between \"equivocal\", \"univocal\" and \"analogical\" terms, the last being those like \"healthy\" that have different but related meanings. Not only a person can be \"healthy\", but also the food that is good for health (see the contemporary distinction between polysemy and homonymy). Thomas Cajetan wrote an influential treatise on analogy. In all of these cases, the wide Platonic and Aristotelian notion of analogy was preserved. James Francis Ross in \"Portraying Analogy\" (1982), the first substantive examination of the topic since Cajetan's \"De Nominum Analogia\", demonstrated that analogy is a systematic and universal feature of natural languages, with identifiable and law-like characteristics which explain how the meanings of words in a sentence are interdependent.\n\nOn the contrary, Ibn Taymiyya, Francis Bacon and later John Stuart Mill argued that analogy is simply a special case of induction. In their view analogy is an inductive inference from common known attributes to another probable common attribute, which is known only about the source of the analogy, in the following form:\n\nThis view does not accept analogy as an autonomous mode of thought or inference, reducing it to induction. However, autonomous analogical arguments are still useful in science, philosophy and the humanities (see below), which makes this reduction philosophically uninteresting. Moreover, induction tries to achieve general conclusions, while analogy looks for particular ones.\n\nContemporary cognitive scientists use a wide notion of analogy, extensionally close to that of Plato and Aristotle, but framed by Gentner's (1983) structure mapping theory. The same idea of mapping between source and target is used by conceptual metaphor and conceptual blending theorists. Structure mapping theory concerns both psychology and computer science. According to this view, analogy depends on the mapping or alignment of the elements of source and target. The mapping takes place not only between objects, but also between relations of objects and between relations of relations. The whole mapping yields the assignment of a predicate or a relation to the target. Structure mapping theory has been applied and has found considerable confirmation in psychology. It has had reasonable success in computer science and artificial intelligence (see below). Some studies extended the approach to specific subjects, such as metaphor and similarity.\n\nKeith Holyoak and Paul Thagard (1997) developed their multiconstraint theory within structure mapping theory. They defend that the \"coherence\" of an analogy depends on structural consistency, semantic similarity and purpose. Structural consistency is maximal when the analogy is an isomorphism, although lower levels are admitted. Similarity demands that the mapping connects similar elements and relations of source and target, at any level of abstraction. It is maximal when there are identical relations and when connected elements have many identical attributes. An analogy achieves its purpose insofar as it helps solve the problem at hand. The multiconstraint theory faces some difficulties when there are multiple sources, but these can be overcome. Hummel and Holyoak (2005) recast the multiconstraint theory within a neural network architecture. A problem for the multiconstraint theory arises from its concept of similarity, which, in this respect, is not obviously different from analogy itself. Computer applications demand that there are some \"identical\" attributes or relations at some level of abstraction. The model was extended (Doumas, Hummel, and Sandhofer, 2008) to learn relations from unstructured examples (providing the only current account of how symbolic representations can be learned from examples).\n\nMark Keane and Brayshaw (1988) developed their \"Incremental Analogy Machine\" (IAM) to include working memory constraints as well as structural, semantic and pragmatic constraints, so that a subset of the base analog is selected and mapping from base to target occurs in a serial manner. Empirical evidence shows that human analogical mapping performance is influenced by information presentation order.\n\nEqaan Doug and his team challenged the shared structure theory and mostly its applications in computer science. They argue that there is no line between perception, including high-level perception, and analogical thought. In fact, analogy occurs not only after, but also before and at the same time as high-level perception. In high-level perception, humans make representations by selecting relevant information from low-level stimuli. Perception is necessary for analogy, but analogy is also necessary for high-level perception. Chalmers et al. conclude that analogy actually is high-level perception. Forbus et al. (1998) claim that this is only a metaphor. It has been argued (Morrison and Dietrich 1995) that Hofstadter's and Gentner's groups do not defend opposite views, but are instead dealing with different aspects of analogy.\n\nAntoine Cornuéjols has presented analogy as a \"principle of economy\" and \"computational complexity\".\n\nReasoning by analogy is a process of, from a given pair \"(x,f(x))\", extrapolating the function \"f\". In the standard modeling, analogical reasoning involves two \"objects\": the \"source\" and the \"target\". The target is supposed to be incomplete and in need for a complete description using the source. The target has an existing part \"S\" and a missing part \"R\". We assume that we can isolate a situation of the source \"S\", which corresponds to a situation of target \"S\", and the result of the source \"R\", which correspond to the result of the target \"R\". With \"B\", the relation between \"S\" and \"R\", we want \"B\", the relation between \"S\" and \"R\".\n\nIf the source and target are completely known:\n\nUsing Kolmogorov complexity \"K(x)\", defined as the size of the smallest description of \"x\" and Solomonoff's approach to induction, Rissanen (89), Wallace & Boulton (68) proposed the principle of minimum description length. This principle leads to minimize the complexity \"K(target | Source)\" of producing the target from the source.\n\nThis is unattractive in Artificial Intelligence, as it requires a computation over abstract Turing machines. Suppose that \"M\" and \"M\" are local theories of the source and the target, available to the observer. The best analogy between a source case and a target case is the analogy that minimizes:\n\nIf the target is completely unknown:\n\nAll models and descriptions \"M\", \"M\", \"B\", \"S\", and \"S\" leading to the minimization of:\n\nare also those who allow to obtain the relationship \"B\", and thus the most satisfactory \"R\" for formula (1).\n\nThe analogical hypothesis, which solves an analogy between a source case and a target case, has two parts:\n\nHowever, a \"cognitive agent\" may simply reduce the amount of information necessary for the interpretation of the source and the target, without taking into account the cost of data replication. So, it may prefer to the minimization of (2) the minimization of the following simplified formula:\n\n\nLogicians analyze how analogical reasoning is used in arguments from analogy.\nAn analogy can be stated using \"is to\" and \"as\" to represent the analogous relationship between two pairs of expressions, for example, \"Smile is to mouth, as wink is to eye.\" In the field of mathematics and logic, this can be formalized with colon notation to represent the relationships, using single colon for ratio, and double colon for equality.\n\nIn the field of testing, the colon notation of ratios and equality is often borrowed, so that the example above might be rendered, \"Smile : mouth :: wink : eye\" and pronounced the same way.\n\n\n\n\nSome types of analogies can have a precise mathematical formulation through the concept of isomorphism. In detail, this means that given two mathematical structures of the same type, an analogy between them can be thought of as a bijection between them which preserves some or all of the relevant structure. For example, formula_1 and formula_2 are isomorphic as vector spaces, but the complex numbers, formula_2, have more structure than formula_1 does: formula_2 is a field as well as a vector space.\n\nCategory theory takes the idea of mathematical analogy much further with the concept of functors. Given two categories C and D, a functor \"f\" from C to D can be thought of as an analogy between C and D, because \"f\" has to map objects of C to objects of D and arrows of C to arrows of D in such a way that the compositional structure of the two categories is preserved. This is similar to the structure mapping theory of analogy of Dedre Gentner, in that it formalizes the idea of analogy as a function which satisfies certain conditions.\n\nSteven Phillips and William H. Wilson use category theory to mathematically demonstrate how the analogical reasoning in the human mind, that is free of the spurious inferences that plague conventional artificial intelligence models, (called \"systematicity\"), could arise naturally from the use of relationships between the internal arrows that keep the internal structures of the categories rather than the mere relationships between the objects (called \"representational states\"). Thus, the mind may use analogies between domains whose internal structures fit according with a natural transformation and reject those that do not.\n\nSee also case-based reasoning.\n\nIn anatomy, two anatomical structures are considered to be \"analogous\" when they serve similar functions but are not evolutionarily related, such as the legs of vertebrates and the legs of insects. Analogous structures are the result of convergent evolution and should be contrasted with homologous structures.\n\nOften a physical prototype is built to model and represent some other physical object. For example, wind tunnels are used to test scale models of wings and aircraft, which act as an analogy to full-size wings and aircraft.\n\nFor example, the MONIAC (an analog computer) used the flow of water in its pipes as an analog to the flow of money in an economy.\n\nWhere there is dependence and hence interaction between a pair or more of biological or physical participants communication occurs and the stresses produced describe internal models inside the participants. Pask in his Conversation Theory asserts there exists an analogy exhibiting both similarities and differences between any pair of the participants' internal models or concepts.\n\nAnalogical reasoning plays a very important part in morality. This may be in part because morality is supposed to be impartial and fair. If it is wrong to do something in a situation A, and situation B is analogous to A in all relevant features, then it is also wrong to perform that action in situation B. Moral particularism accepts analogical moral reasoning, rejecting both deduction and induction, since only the former can do without moral principles.\n\nIn law, analogy is primarily used to resolve issues on which there is no previous authority. A distinction can be made between analogical reasoning employed in statutory law and analogical reasoning present in precedential law (case law).\n\nIn statutory law analogy is used in order to fill the so-called lacunas or gaps or loopholes.\n\nFirst, a gap arises when a specific case or legal issue is not explicitly dealt with in written law. Then, one may try to identify a statutory provision which covers the cases that are similar to the case at hand and apply to this case this provision by analogy. Such a gap, in civil law countries, is referred to as a gap extra legem (outside of the law), while analogy which liquidates it is termed analogy extra legem (outside of the law). The very case at hand is named: an unprovided case.\n\nSecond, a gap comes into being when there is a statutory provision which applies to the case at hand but this provision leads in this case to an unwanted outcome. Then, upon analogy to another statutory provision that covers cases similar to the case at hand, this case is resolved upon this provision instead of the provision that applies to it directly. This gap is called a gap contra legem (against the law), while analogy which fills this gap is referred to as analogy contra legem (against the law).\n\nThird, a gap occurs when there is a statutory provision which regulates the case at hand, but this provision is vague or equivocal. In such circumstances, to decide the case at hand, one may try to ascertain the meaning of this provision by recourse to statutory provisions which address cases that are similar to the case at hand or other cases that are regulated by vague/equivocal provision. A gap of this type is named gap intra legem (within the law) and analogy which deals with it is referred to as analogy intra legem (within the law).\n\nThe similarity upon which statutory analogy depends on may stem from the resemblance of raw facts of the cases being compared, the purpose (the so-called ratio legis which is generally the will of the legislature) of a statutory provision which is applied by analogy or some other sources.\n\nStatutory analogy may be also based upon more than one statutory provision or even a spirit of law. In the latter case, it is called analogy iuris (from the law in general) as opposed to analogy legis (from a specific legal provision or provisions).\n\nIn statutory law analogy is also sometimes applied in order to liquidate the so-called conflicting or logical gap (i.e. the situation when two or more statutory provisions contradict each other) or the sui generis gap which stems from the lack of statutory regulation enabling the delivering of a decision whose passing is required by the law. Some other - less common as so-called ‘pertinent application of law’, ejusdem generis, typological notions or presence of analogical pattern of reasoning in an a fortiori and comparative argument - usages are also distinguished.\n\nFirst, in precedential law (case law), analogies can be drawn from precedent cases (cases decided in past). The judge who decides the case at hand may find that the facts of this case are similar to the facts of one of precedential cases to an extent that the outcomes of these cases are justified to be the same or similar. Such use of analogy in precedential law pertains mainly to the so-called: cases of first impression, i.e. the cases which as yet have not been regulated by any binding judicial precedent (are not covered by a ratio decidendi of such a precedent).\n\nSecond, in precedential law, reasoning from (dis)analogy is amply employed, while a judge is distinguishing a precedent. That is, upon the discerned differences between the case at hand and the precedential case, a judge reject to decide the case upon the precedent whose ratio decidendi (precedential rule) embraces the case at hand.\n\nThird, there is also much room for some other usages of analogy in the province of precedential law. One of them is resort to analogical reasoning, while resolving the conflict between two or more precedents which all apply to the case at hand despite dictating different legal outcome for that case. Analogy can also take part in ascertaining the contents of ratio decidendi, deciding upon obsolete precedents or quoting precedents form other jurisdictions. It is too visible in legal eductaion, notably in the US (the so-called 'case method').\n\nAn argument from analogy employed in precedential law is called case analogy as opposed to analogy employed in statutory law which is accordingly termed statutory analogy.\n\nIn precedential law as well as in statutory law, analogy is also considered as a means of application of legal rules (statutory and precedential), serving thus as an alternative to legal deduction (legal syllogism). Then, there are compared instances to which a given rule applies with certainty with the facts of the case at hand. If the sufficient (relevant) similarity between them obtains, the rule is applied to the case at hand. Otherwise, the rule is deemed as inadequate for this case. Such analogy becomes a legal method.\n\nApplication of legal rules through analogy is more typical of the common law legal systems, especially when one deals with the so-called holdings (the denotation of a binding element of a judicial precedent in the US), being in civil law legal systems rather a proposition than an official mode of applying the law.\n\nThe instances from which analogy starts here off are called: base points, typical instances or paradigmatic cases.\n\nIn legal matters, sometimes the use of analogy is forbidden (by the very law or common agreement between judges and scholars). The most common instances concern criminal, administrative and tax law.\n\nAnalogy should not be resorted to in criminal matters whenever its outcome would be unfavorable to the accused or suspect. Such a ban finds its footing in the very principle: “\"nullum crimen, nulla poena sine lege\"”, a principle which is understood in the way that there is no crime (punishment) unless it is expressly provided for in a statutory provision or an already existing judicial precedent.\n\nAnalogy should be applied with caution in the domain of tax law. Here, the principle: “\"nullum tributum sine lege\"” justifies a general ban on the employment of analogy that would lead to an increase in taxation or whose results would – for some other reason(s) – be to the detriment to the interests of taxpayers.\n\nExtending by analogy those provisions of administrative law that restrict human rights and the rights of the citizens (particularly the category of the so-called “individual rights” or “basic rights”) is as a rule prohibited. Analogy generally should also not be resorted to in order to make the citizen's burdens and obligations larger or more vexatious.\n\nThe other limitations on the use of analogy in law, among many others, pertain to:\n\n\nIn civil (private) law, the use of analogy is as a rule permitted or even ordered by law. But also in this branch of law there are some restrictions confining the possible scope of the use of an analogical argument. Such is, for instance, the prohibition to use analogy in relation to provisions regarding time limits or a general ban on the recourse to analogical arguments which lead to extension of those statutory provisions which envisage some obligations or burdens or which order (mandate) something. The other examples concern the usage of analogy in the field of property law, especially when one is going to create some new property rights by it or to extend these statutory provisions whose terms are unambiguous (unequivocal) and plain (clear), e.g.: be of or under cartian age.\n\nThe aforementioned bans on the use of analogy concern rather analogy which goes beyond the possible linguistic meaning of a statutory provision in question and do not pertain to analogy whose conclusions would remain within this meaning.\n\nAnalogy in law – apart from the terminological distinctions mentioned above – can be found also under such Latin names and phrases as:\n\n\nLegal analogy is sometimes claimed to be of a different nature than analogy that occurs in empirical science and everyday life. It is due to several peculiar factors. First, there is the lack of possibility of verification of conclusions of legal analogy on empirical grounds, which entails the necessity of performance of a legal analogical argument both heuristic and probative function. Second, legal analogy, as the law itself, is by definition prescriptive, non-descriptive. Third, it has an obligatory character: a judge is in many circumstances obliged to reason by analogy (treat similar cases in a similar manner). Fourth, the use of analogy in law rather does not hinge on complex underling doctrines or theories. Fifth, serious practical consequences flow from the use of analogy in law. Sixth, the points of comparison are easily recognizable in case of legal analogy. Seventh, analogy in law becomes a vehicle for extension of authority. Eighth, how to reason by analogy is a subject of legal training and education. Ninth, legal analogy has gained enormous amount of attention and scrutiny amongst scholars.\n\nLegal analogy usually assumes the classical structure:\n\nA case A possesses features X, Y, Z and has ascribed legal consequence G (the first premise).\n\nAn unregulated (unprovided) case B possesses features X, Y, Z (the second premise).\n\nTherefore, the case B should be ascribed the legal consequence G (the analogical conclusion).\n\nor:\n\nThere is a rule in force which addresses cases which features are A, B, C, D (the first premise).\n\nThere are unregulated (unprovided) cases which features are A, B, C and E or cases which features are A, B, C, D and E or cases which features are A, B, C and non-D (the second premise).\n\nTherefore, there should be also a rule in force which addresses cases which features are A, B, C and E or A, B, C, D and E or A, B, C and non-D that prescribes the same or similar legal consequece for these cases as the rule which addresses cases which features are A, B, C, D (the analogical conclusion).\n\nLegal analogy can, however, assume also the structure of (mathematical) proportion, i.e.: A is to B as C is to D or A is to B as B is to C.\n\nThe contemporary proponents of proportional analogy, including legal one, are Chaïm Perelman and Lucie Olbrechts Tyteca.,\n\nSpecifically, in law, analogy of proportion takes the form:\n\n1) Determination of the relation that obtains between the facts of the regulated (provided) case and its legal consequence.\n\n2) Determination of the relation that obtains between the facts of the case at hand and their posited legal consequence (i.e. the consequence that is supposed to be potentially adequate for this case).\n\n3) Having ascertained that the relations pointed out in points 1 and 2 are identical or similar to each other, attribution to the case at hand the legal consequence which has been posited for that case.\n\nAnalogies as defined in rhetoric are a comparison between words, but an analogy can be used in teaching as well. An analogy as used in teaching would be comparing a topic that students are already familiar with, with a new topic that is being introduced so that students can get a better understanding of the topic and relate back to previous knowledge. Shawn Glynn, a professor in the department of educational psychology and instructional technology at the University of Georgia, developed a theory on teaching with analogies and developed steps to explain the process of teaching with this method. The steps for teaching with analogies are as follows: Step one is introducing the new topic that is about to be taught and giving some general knowledge on the subject. Step two is reviewing the concept that the students already know to ensure they have the proper knowledge to assess the similarities between the two concepts. Step three is finding relevant features within the analogy of the two concepts. Step four is finding similarities between the two concepts so students are able to compare and contrast them in order to understand. Step five is indicating where the analogy breaks down between the two concepts. And finally, step six is drawing a conclusion about the analogy and comparison of the new material with the already learned material. Typically this method is used to learn topics in science.\n\nIn 1989 Kerry Ruef, a teacher, began an entire program, which she titled The Private Eye Project. It is a method of teaching that revolves around using analogies in the classroom to better explain topics. She thought of the idea to use analogies as a part of curriculum because she was observing objects once and she said, \"my mind was noting what else each object reminded me of...\" This led her to teach with the question, \"what does [the subject or topic] remind you of?\" The idea of comparing subjects and concepts led to the development of The Private Eye Project as a method of teaching. The program is designed to build critical thinking skills with analogies as one of the main themes revolving around it. While Glynn focuses on using analogies to teach science, The Private Eye Project can be used for any subject including writing, math, art, social studies, and invention. It is now used by thousands of schools around the country.\nThere are also various pedagogic innovations now emerging that use visual analogies for cross-disciplinary teaching and research, for instance between science and the humanities.\n\nThe Fourth Lateran Council of 1215 taught: \"For between creator and creature there can be noted no similarity so great that a greater dissimilarity cannot be seen between them.\"\n\nThe theological exploration of this subject is called the \"analogia entis\". The consequence of this theory is that all true statements concerning God (excluding the concrete details of Jesus' earthly life) are analogical and approximations, without that implying any falsity. Such analogical and true statements would include \"God is\", \"God is Love\", \"God is a consuming fire\", \"God is near to all who call him\", or God as Trinity, where \"being\", \"love\", \"fire\", \"distance\", \"number\" must be classed as analogies that allow human cognition of what is infinitely beyond positive or negative language.\n\nThe use of theological statements in syllogisms must take into account their essential analogical character, in that every analogy breaks down when stretched beyond its intended meaning.\n\n\nVisual analogies have been developed that enable researchers to \"investigate literary studies by means of attractive analogies taken principally from science and mathematics. These analogies bring to literary discourse a stock of exciting visual ideas for teaching and research...\" \n\n\n\n"}
{"id": "14616797", "url": "https://en.wikipedia.org/wiki?curid=14616797", "title": "Basking in reflected glory", "text": "Basking in reflected glory\n\nBasking in reflected glory (BIRGing) is a self-serving cognition whereby an individual associates themselves with known successful others such that the winner's success becomes the individual's own accomplishment.\nThe affiliation of another's success is enough to stimulate self glory. The individual does not need to be personally involved in the successful action. To BIRG, they must simply associate themselves with the success. Examples of BIRGing include anything from sharing a home state with a past or present famous person, to religious affiliations, to sports teams. For example, when a fan of a football team wears the team's jersey and boasts after a win, this fan is engaging in BIRGing. A parent with a bumper sticker reading \"My child is an honor student\" is basking in the reflected glory of their child. While many people have anecdotal accounts of BIRGing, social psychologists seek to find experimental investigations delving into BIRGing. Within social psychology, BIRGing is thought to enhance self-esteem and to be a component of self-management.\n\nBIRGing has connections to social identity theory, which explains how self-esteem and self-evaluation can be enhanced by the identification with another person's success by basking in reflected glory not earned (The American Heritage Dictionary of the English Language: Fourth Edition, 2000). Social identity is the individual's self-concept derived from perceived membership of social groups. High self-esteem is typically a perception of oneself as attractive, competent, likeable and a morally good person. The perception of having these attributes makes the person feel as if they are more attractive to the outside social world and thus more desirable to others to be in a social relationship.( Shavelson, Richard J.; Bolus, Roger (1982))\n\nBIRGing is a widespread and important impression management technique to counter any threats to self-esteem and maintain positive relations with others. Some positive effects of BIRGing include increasing individual self-esteem and a sense of accomplishment. It can show pride of self, and pride for the other person's success, which in turn boosts one's own self-esteem. BIRGing can be negative when done too extensively that the individual engaging in BIRGing becomes delusional or forgets the reality that they did not actually accomplish the successful event.\n\nThe opposite of BIRGing is cutting off reflected failure (CORFing). This is the idea that people tend to disassociate themselves from lower-status individuals because they do not want their reputations \naffected by associating with the people who are considered failures.\n\nOne of the most influential studies of this phenomenon was done by Robert Cialdini in 1976 known as The Three (Football) Field Study. He discovered that the students sought to have the success of their football team linked to them by wearing school-identified apparel. These students associated themselves with a success, even though they in no way affected or caused the success. Through three different experiments, Cialdini was able to demonstrate the BIRGing phenomenon. \nThe first experiment demonstrated BIRGing by showing that students have a greater tendency to wear apparel with the university's colors and name after the football team had won a game. In the second experiment, subjects used the pronoun \"we\" to associate themselves more with a positive than a negative source. This was shown most prominently when their public reputation was at risk. When the subjects failed a task, they had a greater tendency to affiliate themselves with a winner, and less of a tendency to associate themselves with a loser. The third experiment replicated the finding that students used the pronoun \"we\" more when describing a victory compared to a non-victory by their school's football team. The researchers found that BIRGing is an attempt to enhance one's public image. The tendency to proclaim a connection with a positive source was strongest when one's public image was threatened. Thus, people bask in reflected glory to boost their self-esteem by associating themselves with a positive source.\n\nA feeling of involvement is also necessary for BIRGing to occur. It is frequently seen as a cognitive process that affects behavior. In Bernhardt's \"et al.\" (1998) study, researchers examined physiological processes related to Basking in Reflected Glory, specifically, changes in the production of endocrine hormones. Endocrine system Fans watched their favorite sports teams (basketball and soccer) win or lose. The men's testosterone levels increased while watching their team win, but decreased while watching their team lose. Thus, this study shows that physiological processes may be involved with BIRGing, in addition to the known changes in self-esteem and cognition.\n\nThe opposite of BIRGing is cutting off reflected failure (CORFing). This is the idea that people tend to disassociate themselves from lower-status individuals because they do not want their reputations affected by associating with the people who are considered failures. Boen \"et al.\" (2002) demonstrate this effect in a political context. They examined houses with at least a poster or lawn sign supporting a political candidate days before elections in Belgium. The houses that showed support for the winning candidate displayed their posters and lawn signs for a longer period after the elections than did those who supported the loser. CORFing behavior was studied in basketball fans after a defeat (Bizman & Yinzon, 2002), where the fans refuse to take a team poster, removed their posters or paraphernalia, avoided other fans and stayed in a bad mood after a defeat. Thus, the tendency for individuals to display their association with a successful source and a tendency for individuals to conceal their association with a losing team was empirically supported.\n\nThese empirical studies show how even in controlled situations, people unconsciously seek acceptance by associating themselves with successful individuals. Whether this is accomplished by wearing brand names or parents covering their car with stickers about how talented their child is, basking in reflected glory has been found in both the naturalistic and experimental setting.\n\nAlthough Cialdini's studies introduced the concept of BIRGing to the public and its relevance to social psychology, an operational definition is quite difficult to form. With such a wide range of possible examples, there is no set criteria by which to clearly recognize BIRGing. Rather, by a classical definition, it is more described as a subjective feeling possessed by one individual who seeks to gain acceptance or respect by associating themselves with the successes of others. However, over recent years, advances in technology (among other domains) have challenged the classic definition of BIRGing. For example, when Apple Computers became very successful, many individuals not only purchased Apple products, but many more sought jobs or other associations with the company. Contemporary BIRGing in today's world can be seen by individuals not only associating themselves with the success of other people or groups, as was originally thought by Cialdini among others; Rather, BIRGing is the association of oneself to any company, business, or activity which is popular or highly regarded.\n\nFacebook, Twitter, and other social networking sites have increased BIRGing with popular brands, as it allows everyone to post their affinity for or their associations with popular companies, media, businesses, etc. Furthermore, the ability for everyone to follow their favorite athletes, actors, etc. on Facebook or Twitter allows for a closer connection to and knowledge of these celebrities, therefore leading to more BIRGing. Thus, the spread of technology has not only increased the realms under which BIRGing may fall, but also increased the ease with which individuals may partake in BIRGing.\n\nPsychological approaches to BIRGing would include Ludwig Lewisohn's behavioral approach, Charles Darwin's evolutionary approach, and to some extent even Sigmund Freud's psychodynamic approach. The behavioral approach is relevant to BIRGing as it analyzes the behavior and success of others. If one partakes in observing this behavior, they can learn which actions and people are successful or popular and can then engage in BIRGing by associating themselves with these actions or people. Darwin's evolutionary approach can also be used to analyze BIRGing due to the idea behind survival of the fittest. In contemporary psychology, survival of the fittest applies to achieving the greatest successes possible in order to ensure the passage of one's genes into future generations. From this biological perspective, it is favorable to be popular and respected, as more mating opportunities will present themselves. This can be seen in BIRGing as individuals associate themselves with popular, attractive, or respected actions and people in order to be perceived as having more successes. Freud's psychodynamic theory can be applied to BIRGing in terms of the super ego's relationship to the ego. The super ego refers to the ideal self-image; it constitutes a view of one's self as perfect. The ego refers to the real self, meaning our consciousness and perceptions of our current selves. Thus, if an individual seeks to gain more respect or popularity, the super ego may lead to BIRGing, as that individual will associate themselves with popular and respected entities in order to increase that individual's notion of ego.\n\nAnother equally important contributing influence is deindividuation, a psychological state characterized by partial or complete loss of self-awareness, diffused responsibility, and decreased concern about our own behavior resulting in the abandonment of norms, restraints and inhibitions due to the involvement in a group.( Diener, E., Fraser, S. C., Beaman, A. L., & Kelem, R. T. (1976)) The individual loses their sense of self as they participate in the group's activities and choices. Deindividuation involves a loss of self-awareness which is essentially the degree to which one's attention is focused on the self, resulting in comparisons against meaningful standards. When spectators become deindividuated, their self-awareness decreases and they cease to compare their behavior against these social norms. The group's norms become their only focus, and therefore the social norms. Consequentially, situational forces are more influential. Without the comparison process of self-awareness, behavior is more likely to be inconsistent with attitude.\n\nBIRGing is a common aspect of everyday life. Anecdotal evidence explains how people make connections with highly positive or successful people. States and cities list the names of famous entertainers, political candidates, beauty contest winners, etc. who were born there. In encounters with a successful individual or famous celebrity one may recount the story several times in order to bask in the glory because one has a sense of pride after meeting such an individual. People associate with certain companies and schools in order to have a connection to a famous individual who represents these organizations. Humans are always trying to boost their self-esteem, so they continually attempt to bask in reflected glory.\n\nExtra real-world examples:\n\nMost psychologists hold this theory to be true based on substantial research and evidence. However, it is difficult to define and operationalize basking in reflected glory (discussed in \"Major Theoretical Approaches\"). Because examples of BIRGing are so different and unique, there is no set criterion. The classical definition of BIRGing describes it as a subjective feeling possessed by one individual who seeks to gain acceptance or respect by associating themselves with the successes of others. However, in recent years changes in culture and industry have challenged this classic definition. With these changes people are not only associating with other people, but with companies, brands, and organizations. This ability to associate with more than just the public to gain status has created the need for a new definition of Basking in Reflected Glory.\n\nLimitations that apply to both CORFing and BIRGing are perceptions and expectations about performance and how they have an impact. Many scholars have found that the confirmation and disconfirmation of the expected victory or loss has a significant effect on BIRGing and CORFing. For example, if one predicts that one's favorite team is going to lose, one is less likely to be afraid to associate with that team because they predicted the loss. This supports that a person is more likely to participate in BIRGing or CORFing if their public image is being highly threatened.\nIn addition, most studies only test for the identification with one favorite team, there haven't been many studies on the effects of having multiple favorite teams. In one article it suggests that, \"some sport fans have more than one 'favorite team' and choose to identify with a winning team to afford more opportunities to BIRG\" (Spinda, 2011). This suggestion could impact the occurrences of BIRGing and CORFing and therefore needs to be investigated further.\n\nA study done by Spinda (2011), found significant differences between male and female BIRGing and CORFing constructs.\n\nBasking in Reflected Glory is most often noted through the act of BIRGing. Whether it is the sticker on a parent's van that says \"Proud parent of an Honor Roll student\" or having jerseys/posters of one's favorite sports team, humans attempt to improve their self-esteem and self-worth through basking in other's triumphs and broadcasting their association with powerful/successful people. Basking in reflected glory has the potential to create self glory and is connected with social identity theory.\n\nThere have been psychological studies done that confirm the ideas and theories of basking in reflected glory. The first major study was done by Cialdini as he researched BIRGing in winning/losing football fans. Research by Boen \"et al.\" has also confirmed the opposite of BIRGing, cutting off reflected failure (the idea that people tend to disassociate themselves with people of lower status). Basking in reflected glory is not necessarily negative unless it is taken to the extreme and a person only views himself in terms of his affiliations with his BIRGing group. Increases in technology have led to an increase in the ability to bask in reflected glory; a person can now advertise their associations on Facebook, Twitter, and other social networking sites.\n\n\n"}
{"id": "49333", "url": "https://en.wikipedia.org/wiki?curid=49333", "title": "Cultural bias", "text": "Cultural bias\n\nCultural bias is the phenomenon of interpreting and judging phenomena by standards inherent to one's own culture. The phenomenon is sometimes considered a problem central to social and human sciences, such as economics, psychology, anthropology, and sociology. Some practitioners of the aforementioned fields have attempted to develop methods and theories to compensate for or eliminate cultural bias.\n\nCultural bias occurs when people of a culture make assumptions about conventions, including conventions of language, notation, proof and evidence. They are then accused of mistaking these assumptions for laws of logic or nature. Numerous such biases exist, concerning cultural norms for color, mate selection, concepts of justice, linguistic and logical validity, the acceptability of evidence, and taboos.\n\nCultural bias has no a priori definition. Instead, its presence is inferred from differential performance of socioracial (e.g., Blacks, Whites), ethnic (e.g., Latinos/Latinas, Anglos), or national groups (e.g., U.S. Americans, Japanese) on measures of psychological constructs such as cognitive abilities, knowledge or skills (CAKS), or symptoms of psychopathology (e.g., depression). Historically, the term grew out of efforts to explain between‐group score differences on CAKS tests primarily of African American and Latino/Latina American test takers relative to their White American counterparts and concerns that test scores should not be interpreted in the same manner across these groups. Although the concept of cultural bias in testing and assessment also pertains to score differences and potential misdiagnoses with respect to a broader range of psychological concepts, particularly in applied psychology and other social and behavioral sciences, this aspect of cultural bias has received less attention in the relevant literature.\n\nCultural bias in psychological testing refers to the standardized psychological tests that are conducted to determine the level of intelligence among the test-takers. Limitations of such verbal or non-verbal intelligence tests have been observed since their introduction. However, the limitations they put forth, due to their particular culture-friendliness, has been realized much later. Many tests have been objected to, as they produced poor results for the ethnic or racial minorities (students), as compared to the racial majorities. The problem lies not with the test-taker, but with the test itself. As discussed above, the learning environment, the questions posed or situations given in the test may be familiar and strange at the same time to students from different backgrounds.\n\nCultural bias in economic exchange is often overlooked. A study done at the Northwestern University suggests that the cultural perception that two countries have of each other plays a large factor in the economic activity between them. This study suggests that low bilaterial trust between two countries will result in less trade, less portfolio investment, and less direct investment. This effect is amplified for goods, as they are more trust intensive.\n\nThe concept of culture theory in anthropology explains that cultural bias is a critical piece of human group formation.\n\nIt is thought that societies with conflicting beliefs will more likely have cultural bias as it is dependent on the group's standing in society, where the social constructions affect how a problem is produced. One example of cultural bias within the context of sociology can be seen in a study done at the University of California by Jane R. Mercer of how test \"validity\", \"bias\", and \"fairness\" in different cultural belief systems affect one's future in a pluralistic society. A definition of the cultural bias was given as \"the extent that the test contains cultural content that is generally peculiar to the members of one group but not to the members of another group\", which leads to a belief that \"the internal structure of the test will differ for different cultural groups\". In addition, the different types of errors made on culture-biased tests are dependent on different cultural groups. This idea progressed to the conclusion that a non-cultural-test will represent the ability of a population as intended and will not reflect the abilities of a group that is not represented.\n\nCultural bias may also arise in historical scholarship, when the standards, assumptions and conventions of the historian's own era are anachronistically used to report and assess events of the past. This tendency is sometimes known as presentism, and is regarded by many historians as a fault to be avoided. Arthur Marwick has argued that \"a grasp of the fact that past societies are very different from our own, and ... very difficult to get to know\" is an essential and fundamental skill of the professional historian; and that \"anachronism is still one of the most obvious faults when the unqualified (those expert in other disciplines, perhaps) attempt to do history\".\n\n"}
{"id": "5584228", "url": "https://en.wikipedia.org/wiki?curid=5584228", "title": "Declaration of Delhi", "text": "Declaration of Delhi\n\nThe New Delhi Congress or Declaration of Delhi was an international gathering of over 185 judges, lawyers, and law professors from 53 countries all over the world, united as the International Commission of Jurists that took place in New Delhi, India in 1959. The theme of the New Delhi Congress was \"The Rule of Law in a Free Society\". The Congress further developed the principles and procedures underlying the Rule of Law as well as defining and clarifying the concept itself.\n\nIn Anglo-American tradition, the most influential version of the rule of law has been that popularized by British jurist A.V. Dicey in 1885. Dicey's doctrine on the rule of law is a threefold one:\n\n\nModern lawyers would regard the rule of law as essentially a political or moral idea, although nonetheless important for that, since it affects the way the law is developed and applied. It concerns ideas of regularity, access to the courts, fair procedure and honoring expectations. The 'rule of law' in Dicey's sense was a political factor that led to the enactment of the Crown Proceedings Act 1947 in the United Kingdom. Before that Act the Crown, that is, the central government, was immune from liability in the courts for breach of contract or for injuries inflicted by its servants.\n\nSince the Second World War there have been several attempts to draw up Internationally binding codes of basic human rights. The Nurenberg Trials of Nazi war criminals that were organized by the victorious allies were based upon the assumption that some of the laws of Nazi Germany were not valid as they were repugnant to the standards of morality accepted by all civilized nations. This approach to law raises profound philosophical problems, but the role of modern human rights treaties and declarations is a less dramatic one. These include the United Nations Universal Declaration of Human Rights (1948), and the Declaration of Delhi or New Delhi Congress (1959).\n\nThe Delhi Congress gave rise to three important elements in the concept of the Rule of Law.\n\n\nIn preparation of the Congress, the Commission held a preparatory meeting in The Hague, Netherlands on 7 and 8 July 1958, where the drafting of the Congress Working Paper on the Rule of Law was mandated to former ICJ Secretary-General, Mr Norman Marsh. The 134 page paper was based on information gathered in an international survey of lawyers and legal institutions conducted by the ICJ Secretariat in the course of 1957. The information gathered was divided into the following sections:\n\n\nThe committees set up during the congress were each dedicated to one of the four themes with the Working Paper providing the basis of the discussions. The reports and conclusions of the committees were presented in two plenary sessions and the texts were subsequently referred to a steering committee, which issued the conclusions at the closing plenary session.\n\nIn its conclusions, the committee on the legislative stated that under the Rule of Law, the legislature carried out the function of creating and maintaining conditions that would uphold the dignity of man. This would include recognition of civil and political rights as well as the establishment of the social, economic, educational and cultural conditions, which the committee deemed essential to the full development of the individual's personality.\n\nThe committee also stated that minimum standards and principles regulating the individual within society were essential for the Rule of Law. Such standards would, however, imply certain limitations on legislative power. The limitations on the legislative should be enshrined in a constitution and safeguarded by an independent judicial tribunal.\n\nAccording to the conclusions of the committee, the legislative had the responsibility to: abstain from enacting retroactive penal legislation; not discriminate in its laws between one citizen and another; not interfere with freedom of religious belief; not deny members of society the right to responsible government; not place restrictions on the freedom of speech, assembly or association; not impair the exercise of fundamental rights and freedoms of the individual; and provide the procedural mechanisms to protect the above-mentioned freedoms (\"procedure of due process\").\n\nThe committee on the executive concluded that the granting of power by the legislative to the executive should be undertaken within the narrowest possible limits and that legislature should define the extent and purpose of such delegated powers, as well as the procedures by which such delegated power was to be brought into effect. An independent judicial body should be given the power to review the legislation passed by the executive (Judicial review).\n\nWhen the executive directly and adversely affected a person or the property rights of an individual, he or she should have the right to present his or her case before a court as well as the right to an adequate remedy. In the absence of a judicial review mechanism, antecedent procedures of hearing, inquiry and consultation should be established, through which parties whose rights or interests would be affected can have an adequate opportunity to make representation.\n\nThe committee also concluded that the Rule of Law would be strengthened if the executive were to be required to formulate its reasons when reaching its decisions, and at the request of a concerned party, to communicate them.\n\nThe committee considered the practical application of the Rule of Law in the field of criminal process. The committee clarified rules which it regarded as the minimum necessary to ensure the observance of the Rule of Law.\n\nThe committee made its conclusions regarding the prohibition of retrospective enactment of penal legislation (certainty of the law) as well as on the principle of presumption of innocence, which in the committee's view required that the burden of proof should only be shifted once facts creating a contrary presumption had been established.\n\nConcerning the arrest of an individual, the power to arrest should be regulated and the arrested person should be told at once the grounds of his or her arrest. He or she should be entitled to a legal adviser and be brought before a judicial authority within a short period of time.\n\nIn relation to pre-trial detention, the committee listed the rights of the arrested, including the right to apply for bail.\n\nConclusions were also made in respect to the preparation and conduct of the defense and the minimum duties of the prosecution. These included the requirement that the prosecution not withhold favorable evidence from the accused.\n\nRegarding the examination of the accused, the committee laid down minimum standards, such as respect for the right not to incriminate oneself and provisions that guarantee the physical and psychological integrity of the accused.\n\nThe committee also made conclusions regarding trial in public for criminal cases and the right to appeals and remedies.\n\nLastly, the committee concluded that the Rule of Law did not require any particular theory regarding punishment, but must necessarily condemn cruel, inhuman or excessive preventive measures or punishments and thus the committee supported the adoption of reformative measures wherever possible.\n\nThe committee on the Judiciary and the Legal Profession emphasized the importance of an independent judiciary in upholding the Rule of Law. The independence of the judiciary would be safeguarded by certain measures, including co-operation between at least two branches of the state (i.e. judiciary and legislative) on the appointment of judges. Furthermore, the committee perceived the \"irremovability\" of the judiciary as an important safeguard of the Rule of Law.\n\nRegarding the legal profession, the committee deemed an organized legal profession free to manage its own affairs to be essential. While a lawyer should be free to accept any case which is offered to him, he should also in some cases be obliged to defend persons with whom he does not sympathize.\n\nThe committee also addressed the issue of equal access to the justice. It was perceived to be the primary obligation of the legal profession to use its best efforts to ensure that adequate legal advice and representation were provided. The state and community would however have the obligation to assist the legal profession in carrying out this responsibility.\n\n\"This International Congress of Jurists, consisting of 185 judges, practicing lawyers and teachers of law from 53 countries, assembled in New Delhi in January 1959 under the aegis of the International Commission of Jurists, having discussed freely and frankly the Rule of Law and the administration of justice throughout the world, and having reached conclusions regarding the legislative, the executive, the criminal process, the judiciary and the legal profession, (which conclusions are annexed to this Declaration),\"\n\n\"Now solemnly\"\n\n\"Reaffirms the principles expressed in the Act of Athens adopted by the International Congress of Jurists in 1955, particularly that independent judiciary and legal profession are essential to the maintenance of the Rule of Law and to the proper administration of justice;\"\n\n\"Recognizes that the Rule of Law is a dynamic concept for the expansion and fulfillment of which jurists are primarily responsible and which should be employed not only to safeguard and advance the civil and political rights of the individual in a free society, but also to establish social, economic, educational and cultural conditions under which his legitimate aspirations and dignity may be realized;\"\n\n\"Calls on the jurists in all countries to give effect in their own communities to the principles expressed in the conclusions of the Congress; and finally\"\n\n\"Requests the International Commission of Jurists\"\n\n\n\"This Declaration shall be known as the Declaration of Delhi.\"\n\n\"Done at Delhi this 10th day of January 1959\"\n\n"}
{"id": "13877593", "url": "https://en.wikipedia.org/wiki?curid=13877593", "title": "Decommunization", "text": "Decommunization\n\nDecommunization is a process of dismantling the legacies of the communist state establishments, culture, and psychology in the post-communist states. It is sometimes referred to as political cleansing. The term is most commonly applied to the former countries of the Eastern Bloc and the post-Soviet states to describe a number of legal and social changes during their periods of postcommunism.\n\nIn some states decommunization included bans on Communist symbols. While sharing common traits the processes of decommunization have run differently in different states.\n\n\nLustration came to refer to government policies of limiting the participation of former communists, and especially informants of the communist secret police, in the successor political appointee positions or even in civil service positions.\n\n\nCommunist parties outside the Baltic states were not outlawed and their members were not prosecuted. Just a few places attempted to exclude even members of communist secret services from decision-making. In a number of countries, the communist party simply changed its name and continued to function.\n\nStephen Holmes of the University of Chicago argued in 1996 that after a period of active decommunization, it was met with a near-universal failure. After the introduction of lustration, demand for scapegoats has become relatively low, and former communists have been elected for high governmental and other administrative positions. Holmes notes that the only real exception was former East Germany, where thousands of former Stasi informers have been fired from public positions.\n\nHolmes suggests the following reasons for the turnoff of decommunization:\n\nMatthew White found an \"LA Times\" article from 1998 and a \"Times of London\" article from 2000, which both reported that from 3 to 6 million Russians and natives of other former Communist states died or were not born due to decreased living conditions after the fall of communism.\n\n"}
{"id": "840273", "url": "https://en.wikipedia.org/wiki?curid=840273", "title": "Depression (mood)", "text": "Depression (mood)\n\nDepression, a state of low mood and aversion to activity, can affect a person's thoughts, behavior, tendencies, feelings, and sense of well-being. A depressed mood is a normal temporary reaction to life events - such as loss of a loved one. It is also a symptom of some physical diseases and a side effect of some drugs and medical treatments. Depressed mood may also be a symptom of some mood disorders such as major depressive disorder or dysthymia.\n\nAdversity in childhood, such as bereavement, neglect, mental abuse, physical abuse, sexual abuse, and unequal parental treatment of siblings can contribute to depression in adulthood. Childhood physical or sexual abuse in particular significantly correlates with the likelihood of experiencing depression over the life course.\n\nLife events and changes that may precipitate depressed mood include (but are not limited to): childbirth, menopause, financial difficulties, unemployment, stress (such as from work, education, family, living conditions etc.), a medical diagnosis (cancer, HIV, etc.), bullying, loss of a loved one, natural disasters, social isolation, rape, relationship troubles, jealousy, separation, and catastrophic injury. Adolescents may be especially prone to experiencing depressed mood following social rejection, peer pressure and bullying.\n\nHigh scores on the personality domain neuroticism make the development of depressive symptoms as well as all kinds of depression diagnoses more likely, and depression is associated with low extraversion. Other personality indicators could be: temporary but rapid mood changes, short term hopelessness, loss of interest in activities that used to be of a part of one's life, sleep disruption, withdrawal from previous social life, appetite changes, and difficulty concentrating.\n\nPeople who are marginalized due to either their gender identity or sexual orientation are more prone to depression.\n\nDepression may also be the result of healthcare, such as with medication induced depression. Therapies associated with depression include interferon therapy, beta-blockers, isotretinoin, contraceptives, cardiac agents, anticonvulsants, antimigraine drugs, antipsychotics, and hormonal agents such as gonadotropin-releasing hormone agonist.\n\nSeveral drugs of abuse can cause or exacerbate depression, whether in intoxication, withdrawal, and from chronic use. These include alcohol, sedatives (including prescription benzodiazepines), opioids (including prescription pain killers and illicit drugs such as heroin), stimulants (such as cocaine and amphetamines), hallucinogens, and inhalants.\n\nDepressed mood can be the result of a number of infectious diseases, nutritional deficiencies, neurological conditions and physiological problems, including hypoandrogenism (in men), Addison's disease, Cushing's syndrome, hypothyroidism, Lyme disease, multiple sclerosis, Parkinson's disease, chronic pain, stroke, diabetes, and cancer.\n\nA number of psychiatric syndromes feature depressed mood as a main symptom. The mood disorders are a group of disorders considered to be primary disturbances of mood. These include major depressive disorder (MDD; commonly called major depression or clinical depression) where a person has at least two weeks of depressed mood or a loss of interest or pleasure in nearly all activities; and dysthymia, a state of chronic depressed mood, the symptoms of which do not meet the severity of a major depressive episode. Another mood disorder, bipolar disorder, features one or more episodes of abnormally elevated mood, cognition and energy levels, but may also involve one or more episodes of depression. When the course of depressive episodes follows a seasonal pattern, the disorder (major depressive disorder, bipolar disorder, etc.) may be described as a seasonal affective disorder.\nOutside the mood disorders: borderline personality disorder often features an extremely intense depressive mood; adjustment disorder with depressed mood is a mood disturbance appearing as a psychological response to an identifiable event or stressor, in which the resulting emotional or behavioral symptoms are significant but do not meet the criteria for a major depressive episode; and posttraumatic stress disorder, a mental disorder that sometimes follows trauma, is commonly accompanied by depressed mood.\n\nResearchers have begun to conceptualize ways in which the historical legacies of racism and colonialism may create depressive conditions.\n\nDepressed mood may not require professional treatment, and may be a normal temporary reaction to life events, a symptom of some medical condition, or a side effect of some drugs or medical treatments. A prolonged depressed mood, especially in combination with other symptoms, may lead to a diagnosis of a psychiatric or medical condition which may benefit from treatment. The UK National Institute for Health and Care Excellence (NICE) 2009 guidelines indicate that antidepressants should not be routinely used for the initial treatment of mild depression, because the risk-benefit ratio is poor.\n"}
{"id": "1785024", "url": "https://en.wikipedia.org/wiki?curid=1785024", "title": "Direct experience", "text": "Direct experience\n\nDirect experience or immediate experience generally denotes experience gained through immediate sense perception. Many philosophical systems hold that knowledge or skills gained through direct experience cannot be fully put into words.\n\n"}
{"id": "53231", "url": "https://en.wikipedia.org/wiki?curid=53231", "title": "Discovery (observation)", "text": "Discovery (observation)\n\nDiscovery is the act of detecting something new, or something previously unrecognized as meaningful. With reference to sciences and academic disciplines, discovery is the observation of new phenomena, new actions, or new events and providing new reasoning to explain the knowledge gathered through such observations with previously acquired knowledge from abstract thought and everyday experiences. A discovery may sometimes be based on earlier discoveries, collaborations, or ideas. Some discoveries represent a radical breakthrough in knowledge or technology.\n\nNew discoveries are acquired through various senses and are usually assimilated, merging with pre-existing knowledge and actions. Questioning is a major form of human thought and interpersonal communication, and plays a key role in discovery. Discoveries are often made due to questions. Some discoveries lead to the invention of objects, processes, or techniques. A discovery may sometimes be based on earlier discoveries, collaborations or ideas, and the process of discovery requires at least the awareness that an existing concept or method can be modified or transformed. However, some discoveries also represent a radical breakthrough in knowledge.\n\nWithin scientific disciplines, discovery is the observation of new phenomena, actions, or events which helps explain knowledge gathered through previously acquired scientific evidence. In science, exploration is one of three purposes of research, the other two being description and explanation. Discovery is made by providing observational evidence and attempts to develop an initial, rough understanding of some phenomenon.\n\nDiscovery within the field of particle physics has an accepted definition for what constitutes a discovery: a five-sigma level of certainty. Such a level defines statistically how unlikely it is that an experimental result is due to chance. The combination of a five-sigma level of certainty, and independent confirmation by other experiments, turns findings into accepted discoveries.\n\nWithin the field of education, discovery occurs through observations. These observations are common and come in various forms. Observations can occur as observations of students done by the teacher or observations of teachers done by other professionals. Student observations help teachers to identify where the students are developmentally and cognitively in the realm of their studies. Teacher observations are used by administrators to hold teachers accountable as they stay on target with their learning goals and treat the students with respect. From these different types of observations we discover the best possible education practices.\n\nTeachers observe students throughout the day in the classroom. These observations can be informal or formal. Teachers often use checklist, anecdotal notes, videos, interviews, written work or assessment, etc. In completing these observations, teachers can determine at which level the student is understanding the lessons. Using the information from observations, then allows teachers to make the necessary adaptations for the students in the classroom. These observations can also provide the foundation for strong relationships between teachers and students. When students have these relationships they feel safer and more comfortable in the classroom and are more willing and eager to learn. Through observations teachers discover the most developmentally appropriate practices to implement in their classrooms. These discoveries encourage and promote healthier learning styles and positive classroom atmospheres.\n\nWithin the education system, there are a set of standards put in place by government officials. Teachers are responsible for following these academic standards as a guideline for developmentally appropriate instruction. Within following those academic goals, teachers are also observed by administrators to ensure positive classroom environments. One of the tools that teachers could be graded with is called the nationally recognized CLASS tool. After using this tool \"over 150 research studies prove that students in classrooms with high CLASS scores have better academic and social outcomes\" (Touchstone Training, LLC., 2018). The tool itself is known for encouraging positive classroom environments, regard for the students perspectives, behavior management skills, quality of feedback, and language modeling. The administrators rate each of the ten categories with the number scale of one to seven. One being the lowest score and seven being the highest score that the teacher may receive. It is through tools such as this one that administrators are able to hold their teachers to high standards and ensure the best educational practices for the students.\n\nDiscovery can also be used to describe the first incursions of peoples from one culture into the geographical and cultural environment of others. Western culture has used the term \"discovery\" in their histories to subtly emphasize the importance of \"exploration\" in the history of the world, such as in the \"Age of Exploration\".\n\n\n"}
{"id": "16136723", "url": "https://en.wikipedia.org/wiki?curid=16136723", "title": "Discursive dilemma", "text": "Discursive dilemma\n\nDiscursive dilemma or doctrinal paradox is a paradox in social choice theory. The paradox is that aggregating judgments with majority voting can result in self-contradictory judgments.\n\nConsider a community voting on a road repairs. The same group may return a \"Yes\" if asked three questions, but a \"No\" if asked one question. This paradox emerges because the community may vote 'Yes' - the roads are important, and 'Yes' - the weather is right for road repair, and 'Yes' - there are available funds for the repairs. However, due to complexity of individual opinion and disagreement, the majority may at the same time rule that \"No, all three requirements for road repair are not present\". Thus the road repair team gets different feedback depending on how they poll their community.\n\nPhilosopher Philip Pettit believes the discursive dilemma makes it impossible to make simple statements about the beliefs of a collective.\n\nPrinceton philosopher Philip Pettit says there are hidden challenges of describing the group as though it were a single individual - a metaphorical agent - the way the law sometimes talks about corporations. It is a mistake, he says, to think things can be that simple.\n\nIn reality, it can be quite difficult to construct a model of the \"group mind\" by merely asking for a majority opinion. This is because contradictory conceptions of a group can emerge depending on the type of questioning that is chosen.\n\nTo see how, imagine that a three-member court must decide whether someone is liable for a breach of contract. For example, a lawn caretaker is accused of violating a contract not to mow over the land-owner's roses. The judges have to decide which of the following propositions are true:\nAdditionally, all judges accept the proposition formula_1. In other words, the judges agree that a defendant should be liable if and only if the two propositions, P and Q, are both true.\n\nEach judge could make consistent (non-contradictory) judgments, and the paradox will still emerge. Most judges could think P is true, and most judges could think Q is true. In this example, that means they would vote that the caretaker probably mowed over the roses, and that the contract did indeed forbid that action. This suggests the caretaker is \"liable\". \n\nAt the same time, most judges may think that P and Q are not both true at once. In this example, that means most judges conclude the caretaker is \"not liable\". The table above illustrates how majority decisions can contradict (because the judges vote in favor of the premises, and yet reject the conclusion). The paradox lies in choosing between two group liability opinions.\n\nThis dilemma results because an actual decision-making procedure might be premise-based or conclusion-based. In a premise-based procedure, the judges decide by voting whether the conditions for liability are met. In a conclusion-based procedure, the judges decide directly whether the defendant should be liable. In the above formulation, the paradox is that the two procedures don't necessarily lead to the same result; the two procedures can even lead to opposite results.\n\nPettit believes that the lesson of this paradox is that there is no simple way to aggregate individual opinions into a single, coherent \"group entity\". These ideas are relevant to sociology, which endeavors to understand and predict group behaviour. Petitt warns that we need to understand groups because they can be very powerful, can effect greater change, and yet the group as a whole may not have a strong conscience (see Diffusion of responsibility). He says we sometimes fail to hold groups (e.g. corporations) responsible because of the difficulties described above. Collective responsibility is important to sort out, and Petitt insists that groups should have limited rights, and various obligations and checks on their power.\n\nThe discursive dilemma (which concerns general proposition sets) can be seen as a generalization of the Condorcet paradox (which concerns preference sets, a kind of proposition set). Furthermore, the Condorcet paradox can be generalized to Arrow's theorem. List and Pettit argue that the discursive dilemma can be likewise generalized to a sort of \"List-Pettit theorem\". Their theorem states that the inconsistencies remain for any aggregation method which meets a few natural conditions.\n\n"}
{"id": "1744818", "url": "https://en.wikipedia.org/wiki?curid=1744818", "title": "Explodingdog", "text": "Explodingdog\n\nexplodingdog is the name of a web site run by Sam Brown, pseudonym of Adam Culbert. From 2000 to 2015, viewers e-mailed Brown short phrases for inspiration and he illustrated certain ones. The drawings are usually rendered digitally and are known for their simplistic style, and their poignant and sometimes unexpected take on the phrases on which they are based.\n\nexplodingdog was started in 2000.\n\nSam Brown has published limited-run print books of his explodingdog illustrations. He also sells merchandise with explodingdog illustrations and prints of the daily drawings to help offset costs.\n\nLike many artists, Sam Brown uses many recurring themes and visual motifs in his explodingdog work.\n\nA short list of visual motifs:\n\nA short list of recurring themes:\n\nOver the years there have been a number of different artistic projects inspired by explodingdog. These sites usually utilize the same \"submitted by random people, and selected for inspiration\" concept that explodingdog pioneered.\n\n\n\n\n"}
{"id": "2612748", "url": "https://en.wikipedia.org/wiki?curid=2612748", "title": "Flashforward", "text": "Flashforward\n\nA flashforward (also spelled flash-forward) is a scene that temporarily takes the narrative forward in time from the current point of the story in literature, film, television and other media. Flashforwards are often used to represent events expected, projected, or imagined to occur in the future. They may also reveal significant parts of the story that have not yet occurred, but soon will in greater detail. It is similar to foreshadowing, in which future events are not shown but rather implicitly hinted at. It is primarily a postmodern narrative device, named by analogy to the more traditional flashback, which reveals events that occurred in the past.\n\nAn early example of prolepsis which predates the postmodern period is Charles Dickens' novel \"A Christmas Carol\", in which the protagonist Ebenezer Scrooge is shown the future following his death. The subsequent events of the story imply that this future will be averted by this foreknowledge.\n\nTerry Brooks' \"Word & Void\" series features a protagonist who, when he sleeps, moves forwards and backwards through time to before and after a great cataclysm. This is both analepsis and prolepsis.\n\nMuriel Spark makes extensive use of prolepsis in her novel \"The Prime of Miss Jean Brodie\".\n\nEvery season of \"Damages\" makes an extensive use of flashforwards, revealing the outcome of the season to the viewer. The whole season then revolves around discovering the circumstances that led to this outcome. For instance, the first season starts with a flashforward of the protagonist, Ellen Parsons, running in the streets of New York, covered in blood. 6 months earlier, she was only a naive young woman who had just become a lawyer in the firm of a powerful attorney, Patty Hewes. What led Ellen to the situation presented in the flashforwards is revealed little by little throughout the season. Furthermore, the series is known for its misleading use of flashforwards, which are often examples of the red herring device.\n\nAfter making extensive use of flashbacks in the first two seasons, the TV series \"Lost\" used flashforwards throughout the remainder of the series. The first use of this was in the third-season finale: what appeared to be a flashback to before the characters were stranded on the island, was revealed at the end to be a flashforward of them returned to civilization. A later episode featured what appeared to be flashforwards involving the couple Jin and Sun, showing them safely returned home and awaiting the birth of their baby, but it is then revealed that Jin's scenes were flashbacks and only Sun's were flashforwards.\n\nThe series finale of \"\", \"\", uses a technique similar to a flashforward. It depicts a future in which the U.S.S. \"Voyager\" has returned home after decades lost in deep space with various personal tragedies, prompting the ship's captain to use time travel to return to the timeframe of the series and return the crew home more directly.\n\nThe U.S. sci-fi TV series \"FlashForward\" revolves around everyone on Earth losing consciousness for 137 seconds, during which each person experiences a glimpse of events 6 months in the future. The series was itself based loosely on the novel Flashforward by Robert J. Sawyer.\n\nBritish soap opera \"Hollyoaks\" flashed forward six months in May 2010 for a special episode.\n\nThe last episode of \"Six Feet Under\" has an extensive flashforward depicting the deaths of all the central characters for several decades in the future.\n\n\"Breaking Bad\" uses flashforwards throughout its second season showing a mystery regarding debris and corpses in Walter White's house and neighborhood, revealed to be the result of two planes crashing overhead. The first half of the fifth season begins with a flashforward one year into the future where Walter is fifty-two years old, and the second half begins with a continuation of the story, where he returns to his abandoned home. The plot of these flashforwards is resumed in the series finale.\n\n\"How to Get Away with Murder\" uses in every episode flashforwards of scenes from future episodes until episode 9.\n\n\"Quantico\" used flashforwards in order to unravel the future events that have occurred in the first and second season.\n\nMidway through the film \"They Shoot Horses, Don't They?\", there is an abrupt flashforward when Robert, the character played by Michael Sarrazin, is seen being thrust into a jail cell by a police officer, even though he has done nothing to provoke such treatment. The audience is notified, later in the story, that Sarrazin's character would have indeed made choices that warrant his arrest.\n\nThe film \"Arrival\" relies extensively on prolepsis throughout the movie. The main character gains this ability after learning the language of the aliens, and proceeds to use it to prevent the outbreak of war. She uses information revealed to her in the future to convince an important official not to attack the aliens, and to give her said information in the future.\n\nIn \"Until Dawn\", players may find artifacts left by the Native American tribe who lived on the mountain that show premonitions of possible future events. Whether they come true is dependent on player actions; for example, one shows another character's death in a scene that can be avoided.\n\n"}
{"id": "309664", "url": "https://en.wikipedia.org/wiki?curid=309664", "title": "Fog of war", "text": "Fog of war\n\nThe fog of war () is the uncertainty in situational awareness experienced by participants in military operations. The term seeks to capture the uncertainty regarding one's own capability, adversary capability, and adversary intent during an engagement, operation, or campaign. Military forces try to reduce the fog of war through military intelligence and friendly force tracking systems. The term is also used to define uncertainty mechanics in wargames.\n\nThe word \"fog\" in reference to uncertainty in war was introduced by the Prussian military analyst Carl von Clausewitz in his posthumously published book, \"Vom Kriege\" (1832), which appeared in English translation in 1873 under the title \"On War\":\n\nIt has been pointed out that von Clausewitz does not use the exact phrase \"fog of war,\" using multiple similar metaphors such as \"twilight\" and \"moonlight\" to describe lack of clarity. It was not until 1896 when the exact phrase \"fog of war\" was used in text, described as \"the state of ignorance in which commanders frequently find themselves as regards the real strength and position, not only of their foes, but also of their friends.\"\n\nThe fog of war is a reality in all military conflict. Precision and certainty are unattainable goals, but modern military doctrine suggests a trade off of precision and certainty for speed and agility. Militaries employ command and control (C2) systems and doctrine to partially alleviate the fog of war.\n\nThe term also applies to the experience of individual soldiers in battle: often cited is the pure confusion of direction, location, and perspective on a battlefield. Officers and soldiers become separated, orders become confused and subject to revision with poor communication. Sounds and vision are limited from the perspective of the individual and may not be easily resolved, resulting in a continuing uncertainty, a perceptual \"fog\".\n\nThe fog of war has been decreasing as intelligence, surveillance and reconnaissance technology is improving. In 2016, Chief of Staff of the United States Army Gen. Mark A. Milley stated that \"On the future battlefield, if you stay in one place longer than two or three hours, you will be dead..With enemy drones and sensors constantly on the hunt for targets, there won’t even be time for four hours’ unbroken sleep.\"\n\nAbstract and military board games sometimes try to capture the effect of the fog of war by hiding the identity of playing pieces, by keeping them face down or turned away from the opposing player (as in \"Stratego\") or covered (as in \"Squad Leader\"). Other games, such as the \"Kriegspiel\" chess-variant, playing pieces could be hidden from the players by using a duplicate, hidden game board.\n\nAnother version of fog of war emulation is used by block wargaming where, much like \"Stratego\", the blocks face each player, hiding their value. However, this also allows for incremental damage, where the block is rotated up to four times to indicate battle damage before the unit is eliminated from the playing field.\n\nSolitaire games also by their nature attempt to recreate fog of war using random dice rolls or card draws to determine events. Complex double-blind miniature wargames, including military simulations, may make use of two identical maps or model landscapes, one or more referees providing limited intelligence to the opposing sides, participants in the roles of sub-unit leaders, and the use of radio sets or intercoms.\n\nA computer's ability to effectively hide information from a player is seen as a distinct advantage over board games when simulating war. Fog of war in strategy video games refers to enemy units, and often terrain, being hidden from the player; this is lifted once the area is explored, but the information is often fully or partially re-hidden whenever the player does not have a unit in that area.\n\nThe earliest use of fog of war was in the 1977 game \"Empire\" by Walter Bright. Another early use of fog of war was the 1978 game \"Tanktics\" designed by Chris Crawford, which was criticized for its unreliable and \"confusing\" fog of war system. Crawford in 1982 suggested \"limit[ing] the amount of information available to the human player\" to compensate for the computer's lack of intelligence. In a 1988 \"Computer Gaming World\" article Dave Arneson called fog of war \"one of the biggest 'plus' factors in computer simulations\", while Crawford concluded, using \"Tanktics\" as an example, that video game fog of war systems became less \"fun\" the more realistic they were, leading the medium to instead use simplified systems.\n\nTwo large Blizzard franchises, \"Warcraft\" and \"StarCraft\", use a fog of war which only reveals terrain features and enemy units through a player's reconnaissance. Without a unit actively observing, previously revealed areas of the map are subject to a shroud through which only terrain is visible, but changes in enemy units or bases are not. This is also common in both turn-based and real-time strategy games, such as the \"Total War\" series, \"Age of Empires\" series, , \"Advance Wars\" series, \"Fire Emblem\" series and Sid Meier's \"Civilization\" series.\n\nFog of war gives players an incentive to uncover a game's world. A compulsion to reveal obscured parts of a map has been described to give a sense of exploring the unknown. Crawford said that \"reasonable\" uses of fog of war, such as needing to send out scouts, \"not only seem natural, but ... add to the realism and excitement of the game\" \"Merchant Prince\" displays over unexplored territory what \"Computer Gaming World\" described as a \"renaissance-style map of dubious accuracy\". In some strategy games that make use of fog of war, enemy AI can get access to complete visibility of the map, which a player may associate with cheating when discovered. A designer may use fog of war to keep a game that has become impossible to win enjoyable, by hiding this fact from the player.\n\n\n"}
{"id": "65651", "url": "https://en.wikipedia.org/wiki?curid=65651", "title": "Holocaust denial", "text": "Holocaust denial\n\nHolocaust denial is the act of denying the genocide of Jews in the Holocaust during World War II. Holocaust denial claims include: that Nazi Germany's Final Solution was aimed only at deporting Jews from the Reich and did not include their extermination; that Nazi authorities did not use extermination camps and gas chambers to mass murder Jews; or that the actual number of Jews killed was significantly lower than the historically accepted figure of 5 to 6 million, typically around a tenth of that figure. Because Holocaust denial is a common facet of certain racist propaganda, it is considered a serious societal problem in many places where it occurs and is illegal in several European countries and Israel. Holocaust denial is sponsored by some Middle Eastern governments, including Iran and Syria.\n\nIn some post-Soviet states, Holocaust deniers do not deny the very fact of mass murder of Jews, but they deny some national or regional elements of the Holocaust. Scholars use the term \"denial\" to describe the views and methodology of Holocaust deniers in order to distinguish them from legitimate historical revisionists, who challenge orthodox interpretations of history using established historical methodologies. Holocaust deniers generally do not accept \"denial\" as an appropriate description of their activities and use the euphemism \"revisionism\" instead. The methodologies of Holocaust deniers are often based on a predetermined conclusion that ignores overwhelming historical evidence to the contrary.\n\nMost Holocaust deniers claim, either explicitly or implicitly, that the Holocaust is a hoax—or at best an exaggeration—arising from a deliberate Jewish conspiracy designed to advance the interest of Jews at the expense of other people. For this reason, Holocaust denial is generally considered to be an antisemitic conspiracy theory.\n\nHolocaust deniers prefer to refer to their work as historical revisionism, and object to being referred to as \"deniers\". Emory University professor Deborah Lipstadt has written that: \"The deniers' selection of the name revisionist to describe themselves is indicative of their basic strategy of deceit and distortion and of their attempt to portray themselves as legitimate historians engaged in the traditional practice of illuminating the past.\" Scholars consider this misleading since the methods of Holocaust denial differ from those of legitimate historical revision. Legitimate historical revisionism is explained in a resolution adopted by the Duke University History Department, November 8, 1991, and reprinted in \"Duke Chronicle\", November 13, 1991 in response to an advertisement produced by Bradley R Smith's Committee for Open Debate on the Holocaust:\n\nLipstadt writes that modern Holocaust denial draws its inspiration from various sources, including a school of thought which used an established method to question government policies.\n\nIn 1992 Donald L. Niewyk gave some examples of how legitimate historical revisionism—the re-examination of accepted history and its updating with newly discovered, more accurate, or less-biased information—may be applied to the study of the Holocaust as new facts emerge to change the historical understanding of it:\n\nIn contrast, the Holocaust denial movement bases its approach on the predetermined idea that the Holocaust, as understood by mainstream historiography, did not occur. Sometimes referred to as \"negationism\", from the French term \"négationnisme\" introduced by Henry Rousso, Holocaust deniers attempt to rewrite history by minimizing, denying or simply ignoring essential facts. Koenraad Elst writes:\n\nWhile the Second World War was still underway, the Nazis had already formed a contingency plan that in case of defeat they would carry out the total destruction of German records.\n\nHistorians have documented evidence that as Germany's defeat became imminent and Nazi leaders realized they would most likely be captured and brought to trial, great effort was made to destroy all evidence of mass extermination. Heinrich Himmler instructed his camp commandants to destroy records, crematoria, and other signs of mass extermination. As one of many examples, the bodies of the 25,000 mostly Latvian Jews whom Friedrich Jeckeln and the soldiers under his command had shot at Rumbula (near Riga) in late 1941 were dug up and burned in 1943. Similar operations were undertaken at Belzec, Treblinka and other death camps. In the infamous Posen speeches of October 1943 such as the one on October 4, Himmler explicitly referred to the extermination of the Jews of Europe and further stated that the genocide must be permanently kept, secret:\n\nIn occupied France, the situation with respect to preserving war records was not much better, partly as a result of French state secrecy rules dating back to well before the war aimed at protecting the French government and the state from embarrassing revelations, and partly to avoid culpability. For example, at Liberation, the Prefecture of Police destroyed nearly all of the massive archive of Jewish arrest and deportation.\n\nOne of the earliest efforts to save historical record of the Holocaust occurred during the war, in France, where Drancy internment camp records were carefully preserved and turned over to the new ; however, the bureau then held them in secret, refusing to release copies later, even to the Center of Contemporary Jewish Documentation (CDJC).\n\nIn 1943, Isaac Schneersohn, anticipating the need for a center to document and preserve the memory of the persecution for historical reasons and also support claims post-war, gathered together 40 representatives from Jewish organizations in Grenoble which was under Italian occupation at the time in order to form a \"centre de documentation\". Exposure meant the death penalty, and as a result little actually happened before liberation. Serious work began after the center moved to Paris in late 1944 and was renamed the CDJC.\n\nIn 1945, General Dwight D. Eisenhower, Supreme Allied Commander, anticipated that someday an attempt would be made to recharacterize the documentation of Nazi crimes as propaganda and took steps against it:\n\nEisenhower, upon finding the victims of the death camps, ordered all possible photographs to be taken, and for the German people from surrounding villages to be ushered through the camps and even made to bury the dead. He wrote the following to General George Marshall after visiting a German internment camp near Gotha, Germany:\n\nThe Nuremberg trials took place in Germany after the war in 1945–1946. The stated aim was to dispense justice in retribution for atrocities of the German government. This Allied intention to administer justice post-war was first announced in 1943 in the Declaration on German Atrocities in Occupied Europe and reiterated at the Yalta Conference and at Berlin in 1945. While the intention was not specifically to preserve the historical record of the Holocaust, some of the core documents required to prosecute the cases were provided to them by the CDJC, and much of the huge trove of archives were then transferred to the CDJC after the trials and became the core of future Holocaust historiography.\n\nThe Nuremberg trials were important historically, but the events were still very recent, television was in its infancy and not present, and there was a little public impact. There were isolated moments of limited public awareness from Hollywood films such as \"The Diary of Anne Frank\" (1959) or the 1961 \"Judgment at Nuremberg\" which had some newsreel footage of actual scenes from liberated Nazi concentration camps including scenes of piles of naked corpses laid out in rows and bulldozed into large pits, which was considered exceptionally graphic for the time.\nPublic awareness changed when the Eichmann trial riveted the world's attention fifteen years after Nuremberg.\n\nIn 1961, the Israeli government captured Adolf Eichmann in Argentina and brought him to Israel to stand trial for war crimes.\nChief prosecutor Gideon Hausner's intentions were not only to demonstrate Eichmann's guilt personally but to present material about the entire Holocaust, thus producing a comprehensive record.\n\nThe Israeli government arranged for the trial to have prominent media coverage.\nMany major newspapers from all over the globe sent reporters and published front-page coverage of the story.\nIsraelis had the opportunity to watch live television broadcasts of the proceedings, and videotape was flown daily to the United States for broadcast the following day.\n\nIn the immediate aftermath of the war, prior to the extensive documentation efforts by the allied forces, a sense of disbelief caused many to deny the initial reports of the Holocaust. Compounding this disbelief was the memory of forged newspaper accounts of the German Corpse Factory, an anti-German atrocity propaganda campaign during WWI, which was widely known to be false by 1945.\n\nDuring the 1930s, the Nazi government used this propaganda against the British, claiming allegations of concentration camps were malicious lies put forward by the British government, and historians Joachim Neander and Randal Marlin note that this story \"encouraged later disbelief when early reports circulated about the Holocaust under Hitler\". Victor Cavendish-Bentinck, chairman of the British Joint Intelligence Committee, noted that these reports were similar to \"stories of employment of human corpses during the last war for the manufacture of fat which was a grotesque lie\"; likewise, \"The Christian Century\" commented that \"The parallel between this story and the 'corpse factory' atrocity tale of the First World War is too striking to be overlooked.\" Neander notes that \"There can be no doubt that the reported commercial use of the corpses of the murdered Jews undermined the credibility of the news coming from Poland and delayed action that might have rescued many Jewish lives.\"\n\nThe Neo-Nazi movement has been revitalized by Holocaust denial. Small but vocal numbers of Neo-Nazis realized that recreation of a Hitlerite-style regime may be impossible, but a replica might be produced in the future and realized that to rehabilitate Nazism required the discrediting of the Holocaust.\n\nHarry Elmer Barnes, at one time a mainstream American historian, assumed a Holocaust-denial stance in his later years. Between World War I and World War II, Barnes was an anti-war writer and a leader of the historical revisionism movement. Starting in 1924, Barnes worked closely with the Centre for the Study of the Causes of the War, a German government-funded think tank whose sole purpose was to disseminate the official government position that Germany was the victim of Allied aggression in 1914 and that the Versailles Treaty was morally invalid. Headed by Major Alfred von Wegerer, a \"völkisch\" activist, the organization portrayed itself as a scholarly society, but historians later described it as \"a clearinghouse for officially desirable views on the outbreak of the war.\"\n\nFollowing World War II, Barnes became convinced that allegations made against Germany and Japan, including the Holocaust, were wartime propaganda which had been used to justify the United States' involvement in World War II. Barnes claimed that there were two false claims made about World War II, namely that Germany started the war in 1939, and the Holocaust, which Barnes claimed did not happen.\n\nIn his 1962 pamphlet, \"Revisionism and Brainwashing\", Barnes claimed that there was a \"lack of any serious opposition or concerted challenge to the atrocity stories and other modes of defamation of German national character and conduct\". Barnes argued that there was \"a failure to point out the atrocities of the Allies were more brutal, painful, mortal and numerous than the most extreme allegations made against the Germans\". He claimed that in order to justify the \"horrors and evils of the Second World War\", the Allies made the Nazis the \"scapegoat\" for their own misdeeds.\n\nBarnes cited the French Holocaust denier Paul Rassinier, whom Barnes called a \"distinguished French historian\" who had exposed the \"exaggerations of the atrocity stories\". In a 1964 article, \"Zionist Fraud\", published in the \"American Mercury\", Barnes wrote: \"The courageous author [Rassinier] lays the chief blame for misrepresentation on those whom we must call the swindlers of the crematoria, the Israeli politicians who derive billions of marks from nonexistent, mythical and imaginary cadavers, whose numbers have been reckoned in an unusually distorted and dishonest manner.\" Using Rassinier as his source, Barnes claimed that Germany was the victim of aggression in both 1914 and 1939 and that reports of the Holocaust were propaganda to justify a war of aggression against Germany.\n\nIn 1961, a protégé of Barnes, David Hoggan, published \"Der erzwungene Krieg\" (\"The Forced War\") in West Germany, which claimed that Germany had been the victim of an Anglo-Polish conspiracy in 1939. Though \"Der erzwungene Krieg\" was primarily concerned with the origins of World War II, it also down-played or justified the effects of Nazi antisemitic measures in the pre-1939 period. For example, Hoggan justified the huge one billion \"Reich\"-mark fine imposed on the entire Jewish community in Germany after the 1938 \"Kristallnacht\" as a reasonable measure to prevent what he called \"Jewish profiteering\" at the expense of German insurance companies and alleged that no Jews were killed in the \"Kristallnacht\" (in fact, 91 German Jews were killed in the \"Kristallnacht\"). Subsequently, Hoggan explicitly denied the Holocaust in 1969 in a book entitled \"The Myth of the Six Million\", which was published by the Noontide Press, a small Los Angeles publisher specializing in antisemitic literature.\n\nIn 1964, Paul Rassinier published \"The Drama of the European Jews\". Rassinier was himself a concentration camp survivor (he was held in Buchenwald for having helped French Jews escape the Nazis), and modern-day deniers continue to cite his works as scholarly research that questions the accepted facts of the Holocaust. Critics argued that Rassinier did not cite evidence for his claims and ignored information that contradicted his assertions; he nevertheless remains influential in Holocaust denial circles for being one of the first deniers to propose that a vast Zionist/Allied/Soviet conspiracy faked the Holocaust, a theme that would be picked up in later years by other authors.\n\nAustin App, a La Salle University medieval English literature professor, is considered the first major mainstream American holocaust denier. App defended the Germans and Nazi Germany during World War II. He published numerous articles, letters, and books on Holocaust denial, quickly building a loyal following. App's work inspired the Institute for Historical Review, a California center founded in 1978 whose sole task is the denial of the Holocaust.\n\nThe publication of Arthur Butz's \"The Hoax of the Twentieth Century: The case against the presumed extermination of European Jewry\" in 1976; and David Irving's \"Hitler's War\" in 1977 brought other similarly inclined individuals into the fold. Butz was a tenured associate professor of electrical engineering at Northwestern University. In December 1978 and January 1979, Robert Faurisson, a French professor of literature at the University of Lyon, wrote two letters to \"Le Monde\" claiming that the gas chambers used by the Nazis to exterminate the Jews did not exist. A colleague of Faurisson, Jean-Claude Pressac, who initially shared Faurisson's views, later became convinced of the Holocaust's evidence while investigating documents at Auschwitz in 1979. He published his conclusions along with much of the underlying evidence in his 1989 book, \"Auschwitz: Technique and operation of the gas chambers\".\n\nHenry Bienen, the former president of Northwestern University, has described Arthur Butz's view of the Holocaust as an \"embarrassment to Northwestern\". In 2006, sixty of Butz's colleagues from the Department of Electrical Engineering and Computer Science faculty signed a censure describing Butz's Holocaust denial as \"an affront to our humanity and our standards as scholars\". The letter also called for Butz to \"leave our Department and our University and stop trading on our reputation for academic excellence\".\n\nIn 1978 Willis Carto founded the Institute for Historical Review (IHR), an organization dedicated to publicly challenging the commonly accepted history of the Holocaust. The IHR's founding was inspired by Austin App, a La Salle professor of medieval English literature and considered the first major American holocaust denier. The IHR sought from the beginning to establish itself within the broad tradition of historical revisionism, by soliciting token supporters who were not from a neo-Nazi background such as James J. Martin and Samuel Edward Konkin III, and by promoting the writings of French socialist Paul Rassinier and American anti-war historian Harry Elmer Barnes, in an attempt to show that Holocaust denial had a base of support beyond neo-Nazis. The IHR republished most of Barnes's writings, which had been out of print since his death. While it included articles on other topics and sold books by mainstream historians, the majority of material published and distributed by IHR was devoted to questioning the facts surrounding the Holocaust.\n\nIn 1980, the IHR promised a $50,000 reward to anyone who could prove that Jews were gassed at Auschwitz. Mel Mermelstein wrote a letter to the editors of the \"LA Times\" and others including \"The Jerusalem Post\". The IHR wrote back, offering him $50,000 for proof that Jews were, in fact, gassed in the gas chambers at Auschwitz. Mermelstein, in turn, submitted a notarized account of his internment at Auschwitz and how he witnessed Nazi guards ushering his mother and two sisters and others towards (as he learned later) gas chamber number five. Despite this, the IHR refused to pay the reward. Represented by public interest attorney William John Cox, Mermelstein subsequently sued the IHR in the Superior Court of Los Angeles County for breach of contract, anticipatory repudiation, libel, injurious denial of established fact, intentional infliction of emotional distress, and declaratory relief (see case no. C 356 542). On October 9, 1981, both parties in the Mermelstein case filed motions for summary judgment in consideration of which Judge Thomas T. Johnson of the Superior Court of Los Angeles County took \"judicial notice of the fact that Jews were gassed to death at the Auschwitz Concentration Camp in Poland during the summer of 1944,\" judicial notice meaning that the court treated the gas chambers as common knowledge, and therefore did not require evidence that the gas chambers existed. On August 5, 1985, Judge Robert A. Wenke entered a judgment based upon the Stipulation for Entry of Judgment agreed upon by the parties on July 22, 1985. The judgment required IHR and other defendants to pay $90,000 to Mermelstein and to issue a letter of apology to \"Mr. Mel Mermelstein, a survivor of Auschwitz-Birkenau and Buchenwald, and all other survivors of Auschwitz\" for \"pain, anguish and suffering\" caused to them.\n\nIn the \"About the IHR\" statement on their website, the IHR states, \"The IHR does not 'deny' the Holocaust. Indeed, the IHR as such has no 'position' on any specific event...\" Commentators and historians have noted the misleading nature of statements by the IHR that they are not Holocaust deniers. Paul Rauber writes that:\n\nAccording to British historian of Germany Richard J. Evans:\n\nIn 1987, Bradley R. Smith, a former media director of the Institute for Historical Review, founded the Committee for Open Debate on the Holocaust (CODOH). In the United States, CODOH has repeatedly tried to place advertisements questioning whether the Holocaust happened, especially in college campus newspapers, which have not always been rejected as a large number of colleges accepted the ads because they felt not doing so would undercut the First Amendment.\n\nBradley Smith has sought other avenues to promote Holocaust denial – with little success. On September 8, 2009, student newspaper \"The Harvard Crimson\" ran a paid ad from Bradley R Smith. It was quickly criticized and an apology was issued from the editor, claiming it was a mistake. College newspapers refused Smith's ads from that point until his death in 2016, generally concluding that refusing to accept his paid advertisements did not comprise a violation of Smith's First Amendment rights.\n\nSmith referred to his tactics as the CODOH campus project. He said, \"I don't want to spend time with adults anymore, I want to go to students. They are superficial. They are empty vessels to be filled.\" \"What I wanted to do was I wanted to set forth three or four ideas that students might be interested in, that might cause them to think about things or to have questions about things. And I wanted to make it as simple as possible, and to set it up in a way that could not really be debated.\" Holocaust deniers have placed \"Full page advertisements in college and university newspapers, including those of Brandeis University, Boston College, Pennsylvania State University, and Queens College (part of CUNY). Some of these ads arguing that the Holocaust never happened ran without comment; others generated op-ed pieces by professors and students\".\n\nIn 1984, James Keegstra, a Canadian high-school teacher, was charged under the Canadian \"Criminal Code\" for \"promoting hatred against an identifiable group by communicating anti-Semitic statements to his students\". During class, he would describe Jews as a people of profound evil who had \"created the Holocaust to gain sympathy.\" He also tested his students in exams on his theories and opinion of Jews.\n\nKeegstra was charged under s 281.2(2) of the \"Criminal Code\" (now s 319(2), which provides that \"Every one who, by communicating statements, other than in private conversation, wilfully promotes hatred against any identifiable group\" commits a criminal offense. He was convicted at trial before the Alberta Court of Queen's Bench. The court rejected the argument, advanced by Keegstra and his lawyer, Doug Christie, that promoting hatred is a constitutionally protected freedom of expression as per s 2(b) of the Canadian Charter of Rights and Freedoms. Keegstra appealed to the Alberta Court of Appeal. That court agreed with Keegstra, and he was acquitted. The Crown then appealed the case to the Supreme Court of Canada, which ruled by a 4–3 majority that promoting hatred could be justifiably restricted under s 1 of the Charter. The Supreme Court restored Keegstra's conviction. He was fired from his teaching position shortly afterward.\n\nThe Toronto-based photo retoucher Ernst Zündel operated a small-press called Samisdat Publishers, which published and distributed Holocaust-denial material such as \"Did Six Million Really Die?\" by Richard Harwood (a pseudonym of Richard Verrall – a British neo-Nazi). In 1985, he was tried in \"R. v. Zundel\" and convicted under a \"false news\" law and sentenced to 15 months imprisonment by an Ontario court for \"disseminating and publishing material denying the Holocaust\". The Holocaust historian Raul Hilberg was a witness for the prosecution at the 1985 trial. Zündel's conviction was overturned in an appeal on a legal technicality, leading to a second trial in 1988, in which he was again convicted. The 1988 trial included, as witnesses for the defense, Fred A. Leuchter, David Irving and Robert Faurisson. The pseudo-scientific Leuchter report was presented as a defense document and was published in Canada in 1988 by Zundel's Samisdat Publishers, and in Britain in 1989 by Irving's Focal Point Publishing. In both of his trials, Zündel was defended by Douglas Christie and Barbara Kulaszka. His conviction was overturned in 1992 when the Supreme Court of Canada declared the \"false news\" law unconstitutional.\n\nZündel has a website, web-mastered by his wife Ingrid, which publicises his viewpoints. In January 2002, the Canadian Human Rights Tribunal delivered a ruling in a complaint involving his website, in which it was found to be contravening the Canadian Human Rights Act. The court ordered Zündel to cease communicating hate messages. In February 2003, the American INS arrested him in Tennessee, USA, on an immigration violations matter, and few days later, Zündel was sent back to Canada, where he tried to gain refugee status. Zündel remained in prison until March 1, 2005, when he was deported to Germany and prosecuted for disseminating hate propaganda. On February 15, 2007, Zündel was convicted on 14 counts of incitement under Germany's \"Volksverhetzung\" law, which bans the incitement of hatred against a portion of the population, and given the maximum sentence of five years in prison.\n\nThe German philosopher and historian Ernst Nolte, starting in the 1980s, advanced a set of theories, which though not denying the Holocaust appeared to flirt with an Italian Holocaust denier, Carlo Mattogno, as a serious historian. In a letter to the Israeli historian Otto Dov Kulka of December 8, 1986, Nolte criticized the work of the French Holocaust denier Robert Faurisson on the ground that the Holocaust did occur, but went on to argue that Faurisson's work was motivated by what Nolte claimed were the admirable motives of sympathy towards the Palestinians and opposition to Israel. In his 1987 book \"Der europäische Bürgerkrieg\" (\"The European Civil War\"), Nolte claimed that the intentions of Holocaust deniers are \"often honourable\", and that some of their claims are \"not obviously without foundation\". Nolte himself, though he has never denied the occurrence of the Holocaust, has claimed that the Wannsee Conference of 1942 never happened, and that the minutes of the conference were post-war forgeries done by \"biased\" Jewish historians designed to discredit Germany.\n\nThe British historian Ian Kershaw has argued that Nolte was operating on the borderlines of Holocaust denial with his implied claim that the \"negative myth\" of the Third Reich was created by Jewish historians, his allegations of the domination of Holocaust scholarship by \"biased\" Jewish historians, and his statements that one should withhold judgment on Holocaust deniers, whom Nolte takes considerable pains to stress are not exclusively Germans or fascists. In Kershaw's opinion, Nolte is attempting to imply that perhaps Holocaust deniers are on to something.\n\nIn a 1990 interview, Nolte implied that there was something to the Leuchter report: \"If the revisionists [Holocaust deniers] and Leuchter among them have made it clear to the public that even 'Auschwitz' must be an object of scientific inquiry and controversy then they should be given credit for this. Even if it finally turned out that the number of victims was even greater and the procedures were even more horrific than has been assumed until now.\" In his 1993 book \"Streitpunkte\" (\"Points of Contention\"), Nolte praised the work of Holocaust deniers as superior to \"mainstream scholars\". Nolte wrote that \"radical revisionists have presented research which, if one is familiar with the source material and the critique of the sources, is probably superior to that of the established historians of Germany\". In a 1994 interview with \"Der Spiegel\" magazine, Nolte stated \"I cannot rule out the importance of the investigation of the gas chambers in which they looked for remnants of the [chemical process engendered by Zyklon B]\", and that \"'Of course, I am against revisionists, but Fred Leuchter's 'study' of the Nazi gas ovens has to be given attention, because one has to stay open to 'other' ideas.\"\n\nThe British historian Richard J. Evans in his 1989 book \"In Hitler's Shadow\" expressed the view that Nolte's reputation as a scholar was in ruins as a result of these and other controversial statements on his part. The American historian Deborah Lipstadt in a 2003 interview stated: \n\nIn 1988, the American historian Arno J. Mayer published a book entitled \"Why Did the Heavens Not Darken?\", which did not explicitly deny the Holocaust, but according to Lucy Dawidowicz lent support to Holocaust denial by stating that most people who died at Auschwitz were the victims of \"natural causes\" such as disease, not gassing. Dawidowicz argued that Mayer's statements about Auschwitz were \"a breathtaking assertion\". Holocaust historian Robert Jan van Pelt has written that Mayer's book is as close as a mainstream historian has ever come to supporting Holocaust denial. Holocaust deniers such as David Irving have often cited Mayer's book as one reason for embracing Holocaust denial. Though Mayer has been often condemned for his statement about the reasons for the Auschwitz death toll, his book does not deny the use of gas chambers at Auschwitz, as Holocaust deniers often claim.\n\nSome mainstream Holocaust historians have labeled Mayer a denier. The Israeli historian Yehuda Bauer wrote that Mayer \"popularizes the nonsense that the Nazis saw in Marxism and Bolshevism their main enemy, and the Jews unfortunately got caught up in this; when he links the destruction of the Jews to the ups and downs of German warfare in the Soviet Union, in a book that is so cocksure of itself that it does not need a proper scientific apparatus, he is really engaging in a much more subtle form of Holocaust denial\".\n\nDefenders of Mayer argue that his statement that \"Sources for the study of the gas chambers are at once rare and unreliable\" has been taken out of context, particularly by Holocaust deniers. Michael Shermer and Alex Grobman observe that the paragraph from which the statement is taken asserts that the SS destroyed the majority of the documentation relating to the operation of the gas chambers in the death camps, which is why Mayer feels that sources for the operation of the gas chambers are \"rare\" and \"unreliable\".\n\nKen McVay, an American resident in Canada, was disturbed by the efforts of organizations like the Simon Wiesenthal Center to suppress the speech of the Holocaust deniers, feeling that it was better to confront them openly than to try to censor them. On the Usenet newsgroup \"alt.revisionism\" he began a campaign of \"truth, fact, and evidence\", working with other participants on the newsgroup to uncover factual information about the Holocaust and counter the arguments of the deniers by proving them to be based upon misleading evidence, false statements, and outright lies. He founded the Nizkor Project to expose the activities of the Holocaust deniers, who responded to McVay with personal attacks, slander, and death threats.\n\nDeborah Lipstadt's 1993 book \"Denying the Holocaust\" sharply criticized various Holocaust deniers, including British author David Irving, for deliberately misrepresenting evidence to justify their preconceived conclusions. In 1996 Irving filed a libel suit against Lipstadt and her publisher, Penguin Books. American historian Christopher Browning, an expert witness for the defense, wrote a comprehensive essay for the court summarizing the voluminous evidence for the reality of the Holocaust, and under cross-examination, effectively countered all of Irving's principal arguments to the contrary. Cambridge historian Richard J. Evans, another defense expert witness, spent two years examining Irving's writings, and confirmed his misrepresentations, including evidence that he had knowingly used forged documents as source material. The judge, Justice Charles Gray, ultimately delivered a long and decisive verdict in favor of Lipstadt that referred to Irving as a \"Holocaust denier\" and \"right-wing pro-Nazi polemicist.\"\n\nThe focus on supposed Allied atrocities during the war has been a theme in Holocaust denial literature, particularly in countries where outright denial of the Holocaust is illegal. According to historian Deborah Lipstadt, the concept of \"comparable Allied wrongs\", such as the expulsion of Germans after World War II and the bombing of Dresden, is at the center of, and a continuously repeated theme of, contemporary Holocaust denial; a phenomenon she calls \"immoral equivalencies\". Pierre Vidal-Naquet pointed out the same phenomenon in the earlier version of \"Les Assassins de la mémoire\" under the title \"Auschwitz et le tiers monde\" (\"Les Assassins de la mémoire\", Paris, 2005, pp. 170–180), and accurately about the declarations of Klaus Barbie's lawyer Jacques Vergès. In 1977, Martin Broszat, in a review of David Irving's book \"Hitler's War\", maintained that the picture of World War II drawn by Irving was done in a such way to imply moral equivalence between the actions of the Axis and Allied states with both sides equally guilty of terrible crimes, leading to Hitler's \"fanatical, destructive will to annihilate\" being downgraded to being \"no longer an exceptional phenomenon\".\n\nAccording to James Najarian, Holocaust deniers working for the Institute for Historical Review are not trained in history and \"put out sham scholarly articles in the mock-academic publication, the \"Journal of Historical Review\"\". They appeal to \"our objectivity, our sense of fair play, and our distrust of figurative language\". Thus, they rely on facts to grab the readers' attention. These facts, however, are strung by what Najarian calls \"fabricated decorum\" and are re-interpreted for their use. For example, they pay particular attention to inconsistencies in numbers.\n\nHolocaust denial propaganda in all forms has been shown to influence the audiences that it reaches. In fact, even the well-educated—that is, college graduates and current university students alike—are susceptible to such propaganda when it is presented before them. This stems from the growing disbelief that audiences feel after being exposed to such information, especially since Holocaust witnesses themselves are decreasing in number. Studies centered on the psychological effects of Holocaust denial propaganda confirm this assertion. Linda M. Yelland and William F. Stone, in particular, show that Denial essays decrease readers' belief in the Holocaust, regardless of their prior Holocaust awareness.\n\nIn February 1995 the Japanese magazine \"Marco Polo\", a 250,000-circulation monthly published by Bungei Shunju, ran a Holocaust denial article by physician Masanori Nishioka which stated:\n\nThe Los Angeles-based Simon Wiesenthal Center instigated a boycott of Bungei Shunju advertisers, including Volkswagen, Mitsubishi, and Cartier. Within days, Bungei Shunju shut down \"Marco Polo\" and its editor, Kazuyoshi Hanada, quit, as did the president of Bungei Shunju, Kengo Tanaka.\n\nIn Turkey, in 1996, the Islamic preacher Harun Yahya distributed thousands of copies of a book which was originally published the previous year, entitled \"Soykırım Yalanı\" (\"The Holocaust Lie\") and mailed unsolicited texts to American and European schools and colleges. The publication of \"Soykırım Yalanı\" sparked much public debate. This book claims, \"what is presented as Holocaust is the death of some Jews due to the typhus plague during the war and the famine towards the end of the war caused by the defeat of the Germans.\" In March 1996, a Turkish painter and intellectual, Bedri Baykam, published a strongly worded critique of the book in the Ankara daily newspaper \"Siyah-Beyaz\" (\"Black and White\"). A legal suit for slander was brought against him. During the trial in September, Baykam exposed the real author of the book as Adnan Oktar. The suit was withdrawn in March 1997.\n\nIn France, Holocaust denial became more prominent in the 1990s as \"négationnisme\", though the movement has existed in ultra-left French politics since at least the 1960s, led by figures such as Pierre Guillaume (who was involved in the bookshop La Vieille Taupe during the 1960s). Recently, elements of the extreme far right in France have begun to build on each other's negationist arguments, which often span beyond the Holocaust to cover a range of antisemitic views, incorporating attempts to tie the Holocaust to the Biblical massacre of the Canaanites, critiques of Zionism, and other material fanning what has been called a \"conspiratorial Judeo-phobia\" designed to legitimize and \"banalize\" antisemitism.\n\nIn Belgium in 2001, Roeland Raes, the ideologue and vice-president of one of the country's largest political parties, the Vlaams Belang (formerly named Vlaams Blok, Flemish Bloc), gave an interview on Dutch TV where he cast doubt over the number of Jews murdered by the Nazis during the Holocaust. In the same interview he questioned the scale of the Nazis' use of gas chambers and the authenticity of Anne Frank's diary. In response to the media assault following the interview, Raes was forced to resign his position but vowed to remain active within the party. Three years later, the Vlaams Blok was convicted of racism and chose to disband. Immediately afterwards, it legally reformed under the new name Vlaams Belang (Flemish Interest) with the same leaders and the same membership.\n\nThe trial of a Canadian woman, Monika Schaefer and her German-Canadian brother, Alfred Schaefer started in Germany in early July 2018. They were charged with \"Volksverhetzung\", \"incitement to hatred\". The pair had published video clips on YouTube of their denial of the genocide of Jews. In the clips, Alfred Schaefer said that Jews wanted to destroy Germans, blamed them for starting both World Wars, and referred to the Holocaust as a \"Jewish fantasy\".\n\nMonika Schaefer was arrested in January 2018 in Germany while attending a court hearing of Sylvia Stolz. Schaefer had been the Green Party candidate in the Alberta riding of Yellowhead during the federal elections in 2006, 2008, and 2011, but was expelled from the party after news reports surfaced of a July 2016 video where she describes the Holocaust as \"the most persistent lie in all of history\" and insisted that those in concentration camps had been kept as healthy and as well-fed as possible.\n\nIn late October 2018, Monika Schaefer was convicted of the charge of \"incitement of the people\" (often reworded as \"incitement of hatred\" by the news media). She was sentenced to ten months while Alfred Schaefer, also convicted, received a sentence of three years and two month.\n\nDenials of the Holocaust have been promoted by various Middle Eastern figures and media. Holocaust denial is sponsored by some Middle Eastern governments, including Iran and Syria. Prominent figures from the Middle East have rarely made publicized visits to Auschwitz—Israel's Arab community being the exception. In 2010, Hadash MK Mohammed Barakeh visited, following a previous visit of two other Arab-Israeli lawmakers, and a group of about 100 Arab-Israeli writers and clerics in 2003. Individuals from the Syrian government, the Palestinian Authority, and a number of Palestinian groups have all engaged in various aspects of Holocaust denial. In 2006 Robert Satloff writing in \"The Washington Post\", reported that \"A respected Holocaust research institution recently reported that Egypt, Qatar and Saudi Arabia all promote Holocaust denial and protect Holocaust deniers.\"\n\nHamas leaders have promoted Holocaust denial; Abdel Aziz al-Rantissi held that the Holocaust never occurred, that Zionists were behind the action of Nazis, and that Zionists funded Nazism. A press release by Hamas in April 2000 decried \"the so-called Holocaust, which is an alleged and invented story with no basis\". In August 2009, Hamas' told UNRWA that it would \"refuse\" to allow Palestinian children to study the Holocaust, which it called \"a lie invented by the Zionists\" and referred to Holocaust education as a \"war crime\". Hamas continued to hold this position in 2011, when the organization's Ministry for Refugee Affairs said that Holocaust education was \"intended to poison the minds of our children.\"\n\nGamal Abdel Nasser, the President of Egypt, told a German newspaper in 1964 that \"no person, not even the most simple one, takes seriously the lie of the six million Jews that were murdered [in the Holocaust].\"\n\nThe thesis of the 1982 doctoral dissertation of Mahmoud Abbas, a co-founder of Fatah and president of the Palestinian National Authority, was \"The Secret Connection between the Nazis and the Leaders of the Zionist Movement\". In his 1983 book \"\" based on the dissertation, Abbas denied that six million Jews had died in the Holocaust; dismissing it as a \"myth\" and a \"fantastic lie\". At most, he wrote, 890,000 Jews were killed by the Germans. Abbas claimed that the number of deaths has been exaggerated for political purposes. \"It seems that the interest of the Zionist movement, however, is to inflate this figure [of Holocaust deaths] so that their gains will be greater. This led them to emphasize this figure [six million] in order to gain the solidarity of international public opinion with Zionism. Many scholars have debated the figure of six million and reached stunning conclusions—fixing the number of Jewish victims at only a few hundred thousand.\" In his March 2006 interview with \"Haaretz\", Abbas stated, \"I wrote in detail about the Holocaust and said I did not want to discuss numbers. I quoted an argument between historians in which various numbers of casualties were mentioned. One wrote there were 12 million victims and another wrote there were 800,000. I have no desire to argue with the figures. The Holocaust was a terrible, unforgivable crime against the Jewish nation, a crime against humanity that cannot be accepted by humankind. The Holocaust was a terrible thing and nobody can claim I denied it.\" While acknowledging the existence of the Holocaust in 2006 and 2014, Abbas has defended the position that Zionists collaborated with the Nazis to perpetrate it. In 2012, Abbas told Al Mayadeen, a Beirut TV station affiliated with Iran and Hezbollah, that he \"challenges anyone who can deny that the Zionist movement had ties with the Nazis before World War II\".\n\nSurveys conducted by Sammy Smooha of the University of Haifa found that the fraction of Israeli Arabs denying that millions of Jews were murdered by the Nazis increased from 28% in 2006 to 40% in 2008. Smooha commented:\n\nIn Arab eyes disbelief in the very happening of the Shoah is not hate of Jews (embedded in the denial of the Shoah in the West) but rather a form of protest. Arabs not believing in the event of Shoah intend to express strong objection to the portrayal of the Jews as the ultimate victim and to the underrating of the Palestinians as a victim. They deny Israel's right to exist as a Jewish state that the Shoah gives legitimacy to. Arab disbelief in the Shoah is a component of the Israeli-Palestinian conflict, unlike the ideological and anti-Semitic denial of the Holocaust and the desire to escape guilt in the West.\n\nFormer Iranian President Mahmoud Ahmadinejad frequently denied the Holocaust, formally 'questioning' the reliability of the historical evidence, although he on occasion confirmed belief in it. In a December 2005 speech, Ahmadinejad said that a legend was fabricated and had been promoted to protect Israel. He said:\n\nThe remarks immediately provoked international controversy as well as swift condemnation from government officials in Israel, Europe, and the United States. All six political parties in the German parliament signed a joint resolution condemning this Holocaust denial. In contrast, Hamas political leader Khaled Mashaal described Ahmadinejad's comments as \"courageous\" and stated, \"Muslim people will defend Iran because it voices what they have in their hearts, in particular the Palestinian people.\" In the United States, the Muslim Public Affairs Council condemned Ahmadinejad's remarks. In 2005 the Egyptian Muslim Brotherhood leader, Mohammed Mahdi Akef, denounced what he called \"the myth of the Holocaust\" in defending Ahmadinejad's denial of the Holocaust.\n\nOn December 11, 2006, the Iranian state-sponsored \"International Conference to Review the Global Vision of the Holocaust\" opened to widespread condemnation. The conference, called for by and held at the behest of Ahmadinejad, was widely described as a \"Holocaust denial conference\" or a \"meeting of Holocaust deniers\", though Iran denied it was a Holocaust denial conference. A few months before it opened, the Iranian Foreign Ministry spokesman Hamid Reza Asefi stated: \"The Holocaust is not a sacred issue that one can't touch. I have visited the Nazi camps in Eastern Europe. I think it is exaggerated.\"\n\nIn 2013, in an interview with CNN, newly elected Iranian President Hassan Rouhani was quoted as condemning the Holocaust, stating, \"I can tell you that any crime that happens in history against humanity, including the crime the Nazis created towards the Jews as well as non-Jews is reprehensible and condemnable. Whatever criminality they committed against the Jews, we condemn.\" Iranian media later accused CNN of fabricating Rouhani's comments.\n\nIn his official 2013 Nowruz address, Supreme Leader of Iran Grand Ayatollah Ali Khamenei questioned the veracity of the Holocaust, remarking that \"The Holocaust is an event whose reality is uncertain and if it has happened, it's uncertain how it has happened.\" This was consistent with Khamenei's previous comments regarding the Holocaust.\n\nIn 2015, the House of Cartoon and the Sarcheshmeh Cultural Complex in Iran organized the International Holocaust Cartoon Competition, a competition in which artists were encouraged to submit cartoons on the theme of Holocaust denial. The winner of the contest will receive $12,000. \"Hamshahri\", a popular Iranian newspaper, held a similar contest in 2006.\n\nScholarly response to Holocaust denial can be roughly divided into three categories. Some academics refuse to engage Holocaust deniers or their arguments at all, on grounds that doing so lends them unwarranted legitimacy. A second group of scholars, typified by the American historian Deborah Lipstadt, have tried to raise awareness of the methods and motivations of Holocaust denial without legitimizing the deniers themselves. \"We need not waste time or effort answering the deniers' contentions,\" Lipstadt wrote. \"It would be never-ending... Their commitment is to an ideology and their 'findings' are shaped to support it.\" A third group, typified by the Nizkor Project, responds to arguments and claims made by Holocaust denial groups by pointing out inaccuracies and errors in their evidence.\n\nEven scholarly responses, however, can trigger vigorous rebuttals. In 1996, the British Holocaust denier David Irving brought a civil defamation suit against Lipstadt and her publisher, stemming from Lipstadt's book \"Denying the Holocaust\", in which she named Irving as \"one of the more dangerous\" Holocaust deniers, because he was a published author, and was viewed by some as a legitimate military historian. He was \"familiar with historical evidence\", she wrote, and \"bends it until it conforms with his ideological leanings and political agenda\". Irving, who appeared as a defense witness in Ernst Zündel's trial in Canada, and once declared at a rally of Holocaust deniers that \"more women died in the back seat of Edward Kennedy's car than ever died in a gas chamber at Auschwitz,\" claimed that Lipstadt's allegation damaged his reputation. After a two-month trial in London, the trial judge issued a 333-page ruling against Irving.\n\nIn December 1991 the American Historical Association issued the following statement: \"The American Historical Association Council strongly deplores the publicly reported attempts to deny the fact of the Holocaust. No serious historian questions that the Holocaust took place.\" This followed a strong reaction by many of its members and commentary in the press against a near-unanimous decision that the AHA had made in May 1991 that studying the \"significance of the Holocaust\" should be encouraged. The association's May 1991 statement was in response to an incident where certain of its members had questioned the reality of the Holocaust. The December 1991 declaration is a reversal of the AHA's earlier stance that the association should not set a precedent by certifying historical facts.\n\nA number of public figures and scholars have spoken out against Holocaust denial, with some – such as literary theorist Jean Baudrillard – likening Holocaust denial to \"part of the extermination itself\". The American Historical Association, the oldest and largest society of historians and teachers of history in the United States, states that Holocaust denial is \"at best, a form of academic fraud\". In 2006, UN Secretary General Kofi Annan said: \"Remembering is a necessary rebuke to those who say the Holocaust never happened or has been exaggerated. Holocaust denial is the work of bigots; we must reject their false claims whenever, wherever and by whomever they are made.\" Holocaust survivor and Nobel Prize winner Elie Wiesel, during a 1999 discussion at the White House in Washington D.C., called the Holocaust \"the most documented tragedy in recorded history. Never before has a tragedy elicited so much witness from the killers, from the victims and even from the bystanders—millions of pieces here in the museum what you have, all other museums, archives in the thousands, in the millions.\"\n\nIn January 2007, the United Nations General Assembly condemned \"without reservation any denial of the Holocaust\", though Iran disassociated itself from the resolution. In July 2013, Iran's then president-elect Hassan Rohani described Ahmadinejad's remarks about the Holocaust and Israel as \"hate rhetoric\" and in September 2013 Rohani stated that \"The Nazis carried out a massacre that cannot be denied, especially against the Jewish people\" and \"The massacre by the Nazis was condemnable. We never want to sit by side with the Nazis..They committed a crime against Jews — which is a crime against..all of humanity.\" While declining to give a specific number of Jewish victims, Iranian analysts suggested that \"Rouhani pushed the envelope as far as it could go..without infuriating the supreme leader, Ayatollah Ali Khamenei, and other conservatives back home.\"\n\nCritics of Holocaust denial also include members of the Auschwitz SS. Camp physician and SS-\"Untersturmführer\" Hans Münch considered the facts of Auschwitz \"so firmly determined that one cannot have any doubt at all\", and described those who negate what happened at the camp as \"malevolent\" people who have \"personal interest to want to bury in silence things that cannot be buried in silence\". Zyklon B handler and SS-\"Oberscharführer\" Josef Klehr said that anyone who maintains that nobody was gassed at Auschwitz must be \"crazy or in the wrong\". SS-\"Unterscharführer\" Oswald Kaduk stated that he did not consider those who maintain such a thing as normal people. Hearing about Holocaust denial compelled former SS-\"Rottenführer\" Oskar Gröning to publicly speak about what he witnessed at Auschwitz, and denounce Holocaust deniers, stating:\n\nThe \"Encyclopedia of Genocide and Crimes Against Humanity\" defines Holocaust denial as \"a new form of anti-Semitism, but one that hinges on age-old motifs\". The Anti-Defamation League has stated that \"Holocaust denial is a contemporary form of the classic anti-Semitic doctrine of the evil, manipulative and threatening world Jewish conspiracy\" and French historian Valérie Igounet has written that \"Holocaust denial is a convenient polemical substitute for anti-semitism.\"\n\nAccording to Walter Reich, psychiatrist and then senior scholar at the Woodrow Wilson International Center for Scholars, one-time director of the United States Holocaust Memorial Museum, and now professor of international affairs at George Washington University:\n\nThe French historian Pierre Vidal-Naquet described the motivation of deniers more succinctly:\n\nIn 2005, the European Monitoring Centre on Racism and Xenophobia (EUMC) published a working definition of antisemitism which gave as an example of the way that antisemitism might manifest itself.\n\nA definition based on the EUMC definition was later adopted by the U.S. Department of State.\n\nIn November 2013 the Fundamental Rights Agency (FRA) the successor agency to the EUMC removed the definition from the organisation's website in 'a clear-out of non-official documents'. A spokesperson stated that the document had never been viewed as a valid definition and that \"We are not aware of any official definition\". On 26 May 2016 the International Holocaust Remembrance Alliance adopted a working definition of antisemitism and called on the EU to adopt this definition. The United Kingdom was the first country to adopted the definition followed by Israel, Austria, Scotland, Romania, Germany and Bulgaria. The European Parliament voted in favor of a resolution calling for member states to adopt the definition on 1 June 2017. The definition includes as one example of contemporary antisemitism the following.\n\nThe key claims which cause Holocaust denial to differ from established fact are:\n\n\nOther claims include the following:\n\nHolocaust denial is widely viewed as failing to adhere to principles for the treatment of evidence that mainstream historians (as well as scholars in other fields) regard as basic to rational inquiry.\n\nThe Holocaust was well documented by the bureaucracy of the Nazi government itself. It was further witnessed by the Allied forces who entered Germany and its associated Axis states towards the end of World War II. It was also witnessed from the inside by non-Jewish captives such as Catholic French Resistance member André Rogerie who wrote extensively and testified about his experiences in seven camps including Auschwitz-Birkenau and also produced the oldest contemporary sketch of a camp crematorium.\n\nAccording to researchers Michael Shermer and Alex Grobman, there is a \"convergence of evidence\" that proves that the Holocaust happened. This evidence includes:\n\nMuch of the controversy surrounding the claims of Holocaust deniers centers on the methods used to present arguments that the Holocaust allegedly \"never happened as commonly accepted\". Numerous accounts have been given by Holocaust deniers (including evidence presented in court cases) of claimed facts and evidence; however, independent research has shown these claims to be based upon flawed research, biased statements, or even deliberately falsified evidence. Opponents of Holocaust denial have documented numerous instances in which such evidence was altered or manufactured (see Nizkor Project and David Irving). According to Pierre Vidal-Naquet, \"in our society of image and spectacle, extermination on paper leads to extermination in reality.\"\n\nHolocaust denial is explicitly or implicitly illegal in 17 countries: Austria, Belgium, Czech Republic, France, Germany, Hungary, Israel, Liechtenstein, Lithuania, Luxembourg, Netherlands, Poland, Portugal, Romania, Russia, Slovakia, and Switzerland. Romania officially denied the Holocaust occurred on its territory up until the Wiesel Commission in 2004. The European Union's Framework decision on Racism and Xenophobia states that denying or grossly trivializing \"crimes of genocide\" should be made \"punishable in all EU Member States\". Slovakia criminalized denial of fascist crimes in general in late 2001; in May 2005, the term \"Holocaust\" was explicitly adopted by the penal code and in 2009, it became illegal to deny any act regarded by an international criminal court as genocide. In 2010 the Parliament of Hungary adopted legislation punishing the denial of the genocides committed by National Socialist or Communist systems, without mentioning the word \"Holocaust\".\n\nSuch legislation remains controversial. In October 2007, a tribunal declared Spain's Holocaust denial law unconstitutional. In 2007 Italy rejected a denial law proposing a prison sentence of up to four years. In 2006 the Netherlands rejected a draft law proposing a maximum sentence of one year on denial of genocidal acts in general, although specifically denying the Holocaust remains a criminal offense there. The United Kingdom has twice rejected Holocaust denial laws. Denmark and Sweden have also rejected such legislation.\n\nA number of deniers have been prosecuted under various countries' denial laws. French literature professor Robert Faurisson, for example, was convicted and punished under the Gayssot Act in 1990. Some historians oppose such laws, among them Pierre Vidal-Naquet, an outspoken critic of Faurisson, on the grounds that denial legislation imposes \"historical truth as legal truth\". Other academics favor criminalization. Holocaust denial, they contend, is \"the worst form of racism and its most respectable version because it pretends to be a research\".\n\nIn February 2006 Irving was convicted in Austria, where Holocaust denial is illegal, for a speech he had made in 1989 in which he denied the existence of gas chambers at Auschwitz. Irving was aware of the outstanding arrest warrant, but chose to go to Austria anyway \"to give a lecture to a far-right student fraternity\". Although he pleaded guilty to the charge, Irving said he had been \"mistaken\", and had changed his opinions on the Holocaust. \"I said that then, based on my knowledge at the time, but by 1991 when I came across the Eichmann papers, I wasn't saying that anymore and I wouldn't say that now. The Nazis did murder millions of Jews.\" Irving served 13 months of a 3-year sentence in an Austrian prison, including the period between his arrest and conviction, and was deported in early 2007. The episode sparked intense international debate over the limits of freedom of speech. Upon hearing of Irving's sentence, Lipstadt said, \"I am not happy when censorship wins, and I don't believe in winning battles via censorship... The way of fighting Holocaust deniers is with history and with truth.\"\n\nAccording to \"CNN\", upon Irving's return to the UK, he \"vow[ed] to repeat views denying the Holocaust that led to his conviction\" stating he felt \"no need any longer to show remorse\" for his Holocaust views.\n\nOther acts of genocide have met similar attempts to deny and minimize them. Gregory H. Stanton, formerly of the US State Department and the founder of Genocide Watch, lists denial as the final stage of a genocide development: \"Denial is the eighth stage that always follows a genocide. It is among the surest indicators of further genocidal massacres. The perpetrators of genocide dig up the mass graves, burn the bodies, try to cover up the evidence and intimidate the witnesses. They deny that they committed any crimes, and often blame what happened on the victims.\"\n\nHolocaust:\n\nOther sources:\n\nNotes\n\nBibliography\n\n"}
{"id": "1793732", "url": "https://en.wikipedia.org/wiki?curid=1793732", "title": "Hong Kong 1956 riots", "text": "Hong Kong 1956 riots\n\nThe Hong Kong 1956 riots were the result of escalating provocations between pro-Nationalist and pro-Communist factions in Hong Kong during Double Ten Day, 10 October 1956.\n\nMost violence took place in the town of Tsuen Wan, five miles from central Kowloon. A mob stormed and ransacked a clinic and welfare centre, killing four people. Some foreigners became involved, including a Swiss national who lost his life while travelling in a taxi on Nathan Road.\n\nTo quell the rioting, Colonial Secretary Edgeworth B. David ordered extra manpower from the British Forces Hong Kong, including armoured troops of 7th Hussars, to reinforce the Hong Kong Police and disperse the rioters. In total, there were 59 deaths and approximately 500 injuries. Property damage was estimated at US$1,000,000.\n\nIn the subsequent trials four people were convicted of murder and given death penalties.\n\n"}
{"id": "2800592", "url": "https://en.wikipedia.org/wiki?curid=2800592", "title": "Irritability", "text": "Irritability\n\nIrritability is the excitatory ability that living organisms have to respond to changes in their environment. The term is used for both the physiological reaction to stimuli and for the pathological, abnormal or excessive sensitivity to stimuli. It is usually used to refer to anger or frustration. In individuals with autism disorder for example, they tend to be marked by aggression patterns. \n\nIrritability can be a growing response to the objective stimuli of hunger or thirst in animals or humans which then reaches some level of awareness of that need. Irritability may be demonstrated in behavioral responses to both physiological and behavioral stimuli including environmental, situational, sociological, and emotional stimuli.\n\nIrritability is the state of feeling aggravated, frustrated, or being prone to simple anger. This type of state is commonly found when in stressful or pressured situations. These states can coincide with social lives and daily routines, making it more difficult to maintain. It is considered for someone to be \"irritable\" when they have a short temper and immediately becomes frustrated in their situation. Not knowing how to stay calm in the situation can show the state of being irritable. This signifies that something is not right and needs to be brought to attention. It is important to know how to handle and where to seek help when feeling heavy irritation. Irritability is considered an emotion and can affect the mood in a negative way.\n\nIrritability is commonly developed from anxiety disorders. The fight or flight responses triggered in the brain can make irritability easily developed and result in severe grouchiness and aggravation towards other people. Stress hormones take over and lead to attitudes of negative reactions. Feelings of fatigue and difficulty of concentrating plays a part of this type of mood.\n\nSymptoms of irritability may include:\n\n\nClose irritability can be classified as either physical or emotionally close. Having a physically close irritability can be due to individuals being too close for your comfort. This may lead to a state of panic because you may not have enough space for yourself and feel pressured of other taking over your personal space. Having an emotionally close irritability means you may regret or wished to have worded things in a different way when having a conversation with someone that you strongly care for. It causes emotion because you may think that the other person may dislike you or not care for you anymore. It is the feeling of thinking that you have a loss and can't seem to find the right way to rebuild it.\n\nCauses of Irritability are classified as either physical or psychological. Physical causes can be things such as having a lack of sleep, low blood sugar, or any negative health results. Physiological causes include depression, anxiety, or bipolar disorders. Other potential causes may be from the use of drugs, alcohol, or any side medications.\n\nReasons behind the development of irritability:\n\n\nThe first step of resolving irritation from your life is to evaluate where it comes from and what mainly caused it. Finding the answer to questions such as where you find yourself the most calm, what makes you uncomfortable, or things that cause you worries, can help find the solution to heal the irritability.\n\nHow to resolve irritability is by addressing the problem and communicating to a therapist (or a significant individual in your life) and explain the situation that they may be in. Evaluating on the problem is recommended instead of hiding it in and ignoring it before it builds up and gets worse. Addressing issues is important so that others can help support the one that is under stress. Never ignore the situation and make sure to reach a therapeutic individual to assist.\n\nA change of lifestyle habits can assist in relieving the condition of irritability. Recommendations include reducing dietary intake of sodium and sugar. These diets don't need to be strict; small changes can help significantly over time. Physical activity can help distract oneself from stressors. Managing sleep is crucial so that your body and mind both get enough rest. \n\nIn order to calm our minds and frustration down, there are a few ways in which we can maintain the stress that has taken over. Taking time to sit in silence can help clear our minds and not think about things that would stress us out more. Taking a short walk to gain more perspective in life and enjoy the nature of outdoors. Being able to appreciate the small things we may take for granted every day. Offering help to others and be more sympathetic can change our emotions to positive feelings. Reducing caffeine intake so that our body can fully rest during the night and so no addiction is developed. Substituting caffeinated or sugary drinks for water and tea; Making sure to control cravings and eating in moderation.\n\n"}
{"id": "16187", "url": "https://en.wikipedia.org/wiki?curid=16187", "title": "John Dewey", "text": "John Dewey\n\nJohn Dewey (; October 20, 1859 – June 1, 1952) was an American philosopher, psychologist, and educational reformer whose ideas have been influential in education and social reform. Dewey is one of the primary figures associated with the philosophy of pragmatism and is considered one of the fathers of functional psychology. A \"Review of General Psychology\" survey, published in 2002, ranked Dewey as the 93rd most cited psychologist of the 20th century. A well-known public intellectual, he was also a major voice of progressive education and liberalism. Although Dewey is known best for his publications about education, he also wrote about many other topics, including epistemology, metaphysics, aesthetics, art, logic, social theory, and ethics. He was a major educational reformer for the 20th century.\n\nThe overriding theme of Dewey's works was his profound belief in democracy, be it in politics, education, or communication and journalism. As Dewey himself stated in 1888, while still at the University of Michigan, \"Democracy and the one, ultimate, ethical ideal of humanity are to my mind synonymous.\"\n\nKnown for his advocacy of democracy, Dewey considered two fundamental elements—schools and civil society—to be major topics needing attention and reconstruction to encourage experimental intelligence and plurality. Dewey asserted that complete democracy was to be obtained not just by extending voting rights but also by ensuring that there exists a fully formed public opinion, accomplished by communication among citizens, experts, and politicians, with the latter being accountable for the policies they adopt.\n\nJohn Dewey was born in Burlington, Vermont to a family of modest means. He was one of four boys born to Archibald Sprague Dewey and Lucina Artemisia Rich Dewey. Their second son was also named John, but he died in an accident on January 17, 1859. The second John Dewey was born October 20, 1859, forty weeks after the death of his older brother. Like his older, surviving brother, Davis Rich Dewey, he attended the University of Vermont, where he was initiated into Delta Psi, and graduated Phi Beta Kappa in 1879. A significant professor of Dewey's at the University of Vermont was Henry Augustus Pearson Torrey (H. A. P. Torrey), the son-in-law and nephew of former University of Vermont president Joseph Torrey. Dewey studied privately with Torrey between his graduation from Vermont and his enrollment at Johns Hopkins University.\n\nAfter two years as a high-school teacher in Oil City, Pennsylvania and one teaching elementary school in the small town of Charlotte, Vermont, Dewey decided that he was unsuited as a primary or secondary school teacher. After studying with George Sylvester Morris, Charles Sanders Peirce, Herbert Baxter Adams, and G. Stanley Hall, Dewey received his Ph.D. from the School of Arts & Sciences at Johns Hopkins University. In 1884, he accepted a faculty position at the University of Michigan (1884–88 and 1889–94) with the help of George Sylvester Morris. His unpublished and now lost dissertation was titled \"The Psychology of Kant.\"\n\nIn 1894 Dewey joined the newly founded University of Chicago (1894–1904) where he developed his belief in Rational Empiricism, becoming associated with the newly emerging Pragmatic philosophy. His time at the University of Chicago resulted in four essays collectively entitled \"Thought and its Subject-Matter\", which was published with collected works from his colleagues at Chicago under the collective title \"Studies in Logical Theory\" (1903). During that time Dewey also initiated the University of Chicago Laboratory Schools, where he was able to actualize the pedagogical beliefs that provided material for his first major work on education, \"The School and Society\" (1899). Disagreements with the administration ultimately caused his resignation from the university, and soon thereafter he relocated near the East Coast. In 1899, Dewey was elected president of the American Psychological Association. From 1904 until his retirement in 1930 he was professor of philosophy at Columbia University. In 1905 he became president of the American Philosophical Association. He was a longtime member of the American Federation of Teachers.\n\nAlong with the historians Charles A. Beard and James Harvey Robinson, and the economist Thorstein Veblen, Dewey is one of the founders of The New School. Dewey's most significant writings were \"The Reflex Arc Concept in Psychology\" (1896), a critique of a standard psychological concept and the basis of all his further work; \"Democracy and Education\" (1916), his celebrated work on progressive education; \"Human Nature and Conduct\" (1922), a study of the function of habit in human behavior; \"The Public and its Problems\" (1927), a defense of democracy written in response to Walter Lippmann's \"The Phantom Public\" (1925); \"Experience and Nature\" (1925), Dewey's most \"metaphysical\" statement; \"Impressions of Soviet Russia and the Revolutionary World\" (1929), a glowing travelogue from the nascent USSR; \"Art as Experience\" (1934), Dewey's major work on aesthetics; \"A Common Faith\" (1934), a humanistic study of religion originally delivered as the Dwight H. Terry Lectureship at Yale; \"\" (1938), a statement of Dewey's unusual conception of logic; \"Freedom and Culture\" (1939), a political work examining the roots of fascism; and \"Knowing and the Known\" (1949), a book written in conjunction with Arthur F. Bentley that systematically outlines the concept of trans-action, which is central to his other works (see Transactionalism). While each of these works focuses on one particular philosophical theme, Dewey included his major themes in most of what he published. He published more than 700 articles in 140 journals, and approximately 40 books.\n\nReflecting his immense influence on 20th-century thought, Hilda Neatby wrote \"Dewey has been to our age what Aristotle was to the later Middle Ages, not a philosopher, but \"the\" philosopher.\"\n\nDewey married to Alice Chipman in 1886 shortly after Chipman graduated with her PhB from the University of Michigan. The two had six children: Frederick Archibald Dewey, Evelyn Riggs Dewey, Morris (who died young), Gordon Chipman Dewey, Lucy Alice Chipman Dewey, and Jane Mary Dewey. Alice Chipman died in 1927 at the age of 68; weakened by a case of malaria contracted during a trip to Turkey in 1924 and a heart attack during a trip to Mexico City in 1926, she died from cerebral thrombosis on July 13, 1927. Dewey married Estelle Roberta Lowitz Grant, \"a longtime friend and companion for several years before their marriage\" on December 11, 1946. At Roberta's behest, the couple adopted two siblings, Lewis (changed to John, Jr.) and Shirley. John Dewey died of pneumonia on June 1, 1952 at his home in New York City after years of ill-health. and was cremated the next day.\n\nThe United States Postal Service honored Dewey with a Prominent Americans series 30¢ postage stamp in 1968.\n\nIn 1919, while traveling in Japan on sabbatical leave, Dewey was invited by Peking University to visit China, probably at the behest of his former students, Hu Shih and Chiang Monlin. Dewey and his wife Alice arrived in Shanghai on April 30, 1919, just days before student demonstrators took to the streets of Peking to protest the decision of the Allies in Paris to cede the German held territories in Shandong province to Japan. Their demonstrations on May Fourth excited and energized Dewey, and he ended up staying in China for two years, leaving in July 1921.\n\nIn these two years, Dewey gave nearly 200 lectures to Chinese audiences and wrote nearly monthly articles for Americans in \"The New Republic\" and other magazines. Well aware of both Japanese expansionism into China and the attraction of Bolshevism to some Chinese, Dewey advocated that Americans support China's transformation and that Chinese base this transformation in education and social reforms, not revolution. Hundreds and sometimes thousands of people attended the lectures, which were interpreted by Hu Shih. For these audiences, Dewey represented \"Mr. Democracy\" and \"Mr. Science,\" the two personifications which they thought of representing modern values and hailed him as \"Second Confucius\". Perhaps Dewey's biggest impact, however, was on the forces for progressive education in China, such as Hu Shih and Chiang Monlin, who had studied with him, and Tao Xingzhi, who had studied at Teachers College, Columbia University.\n\nTheir letters from China and Japan describing their experiences to their family were published in 1920, edited by their daughter Evelyn. During and after his visit his commentaries on China would be published in such periodicals as the New Republic, Asia, the China Review, and sometimes in Newspapers like the Baltimore Sun. Though discussing Chinese philosophy but rarely, one article in 1922, \"As the Chinese Think\", discusses the teachings of Laozi and Confucius in an attempt to improve understanding of the Chinese in international business relations.\n\nDewey and his daughter Jane went to South Africa in July 1934, at the invitation of the World Conference of New Education Fellowship in Cape Town and Johannesburg, where he delivered several talks. The conference was opened by the South African Minister of Education Jan Hofmeyr, and Deputy Prime Minister Jan Smuts. Other speakers at the conference included Max Eiselen and Hendrik Verwoerd, who would later become prime minister of the Nationalist government that introduced Apartheid. John and Jane's expenses were paid by the Carnegie Foundation. He also traveled to Durban, Pretoria and Victoria Falls in what was then Rhodesia (now Zimbabwe) and looked at schools, talked to pupils, and gave lectures to the administrators and teachers. In August 1934, Dewey accepted an honorary degree from the University of the Witwatersrand.\n\nAt the University of Michigan, Dewey published his first two books, \"Psychology\" (1887), and \"Leibniz's New Essays Concerning the Human Understanding\" (1888), both of which expressed Dewey's early commitment to British neo-Hegelianism. In \"Psychology\", Dewey attempted a synthesis between idealism and experimental science.\n\nWhile still professor of philosophy at Michigan, Dewey and his junior colleagues, James Hayden Tufts and George Herbert Mead, together with his student James Rowland Angell, all influenced strongly by the recent publication of William James' \"Principles of Psychology\" (1890), began to reformulate psychology, emphasizing the social environment on the activity of mind and behavior rather than the physiological psychology of Wilhelm Wundt and his followers.\n\nBy 1894, Dewey had joined Tufts, with whom he would later write \"Ethics\" (1908) at the recently founded University of Chicago and invited Mead and Angell to follow him, the four men forming the basis of the so-called \"Chicago group\" of psychology.\n\nTheir new style of psychology, later dubbed functional psychology, had a practical emphasis on action and application. In Dewey's article \"The Reflex Arc Concept in Psychology\" which appeared in \"Psychological Review\" in 1896, he reasons against the traditional stimulus-response understanding of the reflex arc in favor of a \"circular\" account in which what serves as \"stimulus\" and what as \"response\" depends on how one considers the situation, and defends the unitary nature of the sensory motor circuit. While he does not deny the existence of stimulus, sensation, and response, he disagreed that they were separate, juxtaposed events happening like links in a chain. He developed the idea that there is a coordination by which the stimulation is enriched by the results of previous experiences. The response is modulated by sensorial experience.\n\nDewey was elected president of the American Psychological Association in 1899.\n\nIn 1984, the American Psychological Association announced that Lillian Moller Gilbreth (1878–1972) had become the first psychologist to be commemorated on a United States postage stamp. However, psychologists Gary Brucato Jr. and John D. Hogan later made the case that this distinction actually belonged to John Dewey, who had been celebrated on an American stamp 17 years earlier. While some psychology historians consider Dewey more of a philosopher than a bona fide psychologist, the authors noted that Dewey was a founding member of the A.P.A., served as the A.P.A.'s eighth president in 1899, and was the author of an 1896 article on the reflex arc which is now considered a basis of American functional psychology.\n\nDewey also expressed interest in work in the psychology of visual perception performed by Dartmouth research professor Adelbert Ames Jr. He had great trouble with listening, however, because it is known Dewey could not distinguish musical pitches—in other words was tone deaf.\n\nDewey sometimes referred to his philosophy as instrumentalism rather than pragmatism, and would have recognized the similarity of these two schools to the newer school named consequentialism. He defined with precise brevity the criterion of validity common to these three schools, which lack agreed-upon definitions:\n\nHis concern for precise definition led him to detailed analysis of careless word usage, reported in \"Knowing and the Known\" in 1949.\n\nThe terminology problem in the fields of epistemology and logic is partially due, according to Dewey and Bentley, to inefficient and imprecise use of words and concepts that reflect three historic levels of organization and presentation. In the order of chronological appearance, these are:\n\nA series of characterizations of Transactions indicate the wide range of considerations involved.\n\nDewey sees paradox in contemporary logical theory. Proximate subject matter garners general agreement and advancement, while the ultimate subject matter of logic generates unremitting controversy. In other words, he challenges confident logicians to answer the question of the truth of logical operators. Do they function merely as abstractions (e.g., pure mathematics) or do they connect in some essential way with their objects, and therefore alter or bring them to light?\n\nLogical positivism also figured in Dewey's thought. About the movement he wrote that it \"eschews the use of 'propositions' and 'terms', substituting 'sentences' and 'words'.\" (\"General Theory of Propositions\", in \"Logic: The Theory of Inquiry\") He welcomes this changing of referents \"in as far as it fixes attention upon the symbolic structure and content of propositions.\" However, he registers a small complaint against the use of \"sentence\" and \"words\" in that without careful interpretation the act or process of transposition \"narrows unduly the scope of symbols and language, since it is not customary to treat gestures and diagrams (maps, blueprints, etc.) as words or sentences.\"\nIn other words, sentences and words, considered in isolation, do not disclose intent, which may be inferred or \"adjudged only by means of context.\"\n\nYet Dewey was not entirely opposed to modern logical trends. Concerning traditional logic, he states:\n\nLouis Menand argues in \"\" that Jane Addams had been critical of Dewey's emphasis on antagonism in the context of a discussion of the Pullman strike of 1894. In a later letter to his wife, Dewey confessed that Addams' argument was:\n\nHe went on to add:\n\nIn a letter to Addams, clearly influenced by his conversation with her, Dewey wrote:\n\n\"Art as Experience\" (1934) is Dewey's major writing on aesthetics.\n\nIt is, in accordance with his place in the Pragmatist tradition that emphasizes community, a study of the individual art object as embedded in (and inextricable from) the experiences of a local culture. In the original illustrated edition, Dewey drew on the modern art and world cultures collection assembled by Albert C. Barnes at the Barnes Foundation, whose own ideas on the application of art to one's way of life was influenced by Dewey's writing. Barnes was particularly influenced by \"Democracy and Education\" (1916) and then attended Dewey's seminar on political philosophy at Columbia University in the fall semester of 1918.\n\nDewey founded the University of Chicago laboratory school, supported educational organizations, and supported settlement houses especially Jane Addams' Hull House.\n\nThrough his work at the Hull House serving on its first board of trustees, Dewey was not only an activist for the cause but also a partner working to serve the large immigrant community of Chicago and women's suffrage. Dewey experienced the lack of children's education while contributing in the classroom at the Hull House and the lack of education and skills of immigrant women. Stengel argues:\n\nHis leading views on democracy included: \"First, Dewey believed that democracy is an ethical ideal rather than merely a political arrangement. Second, he considered participation, not representation, the essence of democracy. Third, he insisted on the harmony between democracy and the scientific method: ever-expanding and self-critical communities of inquiry, operating on pragmatic principles and constantly revising their beliefs in light of new evidence, provided Dewey with a model for democratic decision making ... Finally, Dewey called for extending democracy, conceived as an ethical project, from politics to industry and society\". This helped to shape his understanding of human action and the unity of human experience.\n\nDewey believed that a woman's place in society was determined by her environment and not just her biology. On women he says, \"You think too much of women in terms of sex. Think of them as human individuals for a while, dropping out the sex qualification, and you won't be so sure of some of your generalizations about what they should and shouldn't do\". John Dewey's support helped to increase the support and popularity of Jane Addams' Hull House and other settlement houses as well. With growing support, involvement of the community grew as well as the support for the women's suffrage movement.\n\nAs commonly argued by Dewey's greatest critics, he was not able to come up with strategies in order to fulfill his ideas that would lead to a successful democracy, educational system, and a successful women's suffrage movement. While knowing that traditional beliefs, customs, and practices needed to be examined in order to find out what worked and what needed improved upon, it was never done in a systematic way. \"Dewey became increasingly aware of the obstacles presented by entrenched power and alert to the intricacy of the problems facing modern cultures\". With the complex of society at the time, Dewey was criticized for his lack of effort in fixing the problems.\n\nWith respect to technological developments in a democracy:\n\nHis work on democracy influenced B.R. Ambedkar, one of his students, who later became one of the founding fathers of independent India.\n\nDewey's educational theories were presented in \"My Pedagogic Creed\" (1897), \"The School and Society\" (1900), \"The Child and the Curriculum\" (1902), \"Democracy and Education\" (1916), \"Schools of To-morrow\" (c1915) with Evelyn Dewey, and \"Experience and Education\" (1938). Several themes recur throughout these writings. Dewey continually argues that education and learning are social and interactive processes, and thus the school itself is a social institution through which social reform can and should take place. In addition, he believed that students thrive in an environment where they are allowed to experience and interact with the curriculum, and all students should have the opportunity to take part in their own learning.\n\nThe ideas of democracy and social reform are continually discussed in Dewey's writings on education. Dewey makes a strong case for the importance of education not only as a place to gain content knowledge, but also as a place to learn how to live. In his eyes, the purpose of education should not revolve around the acquisition of a pre-determined set of skills, but rather the realization of one's full potential and the ability to use those skills for the greater good. He notes that \"to prepare him for the future life means to give him command of himself; it means so to train him that he will have the full and ready use of all his capacities\" (\"My Pedagogic Creed\", Dewey, 1897). In addition to helping students realize their full potential, Dewey goes on to acknowledge that education and schooling are instrumental in creating social change and reform. He notes that \"education is a regulation of the process of coming to share in the social consciousness; and that the adjustment of individual activity on the basis of this social consciousness is the only sure method of social reconstruction\".\n\nIn addition to his ideas regarding what education is and what effect it should have on society, Dewey also had specific notions regarding how education should take place within the classroom. In \"The Child and the Curriculum\" (1902), Dewey discusses two major conflicting schools of thought regarding educational pedagogy. The first is centered on the curriculum and focuses almost solely on the subject matter to be taught. Dewey argues that the major flaw in this methodology is the inactivity of the student; within this particular framework, \"the child is simply the immature being who is to be matured; he is the superficial being who is to be deepened\" (1902, p. 13). He argues that in order for education to be most effective, content must be presented in a way that allows the student to relate the information to prior experiences, thus deepening the connection with this new knowledge.\n\nAt the same time, Dewey was alarmed by many of the \"child-centered\" excesses of educational-school pedagogues who claimed to be his followers, and he argued that too much reliance on the child could be equally detrimental to the learning process. In this second school of thought, \"we must take our stand with the child and our departure from him. It is he and not the subject-matter which determines both quality and quantity of learning\" (Dewey, 1902, pp. 13–14). According to Dewey, the potential flaw in this line of thinking is that it minimizes the importance of the content as well as the role of the teacher.\n\nIn order to rectify this dilemma, Dewey advocated for an educational structure that strikes a balance between delivering knowledge while also taking into account the interests and experiences of the student. He notes that \"the child and the curriculum are simply two limits which define a single process. Just as two points define a straight line, so the present standpoint of the child and the facts and truths of studies define instruction\" (Dewey, 1902, p. 16). It is through this reasoning that Dewey became one of the most famous proponents of hands-on learning or experiential education, which is related to, but not synonymous with experiential learning. He argued that \"if knowledge comes from the impressions made upon us by natural objects, it is impossible to procure knowledge without the use of objects which impress the mind\" (Dewey, 1916/2009, pp. 217–18). Dewey's ideas went on to influence many other influential experiential models and advocates. Problem-Based Learning (PBL), for example, a method used widely in education today, incorporates Dewey's ideas pertaining to learning through active inquiry.\n\nDewey not only re-imagined the way that the learning process should take place, but also the role that the teacher should play within that process. Throughout the history of American schooling, education's purpose has been to train students for work by providing the student with a limited set of skills and information to do a particular job. The works of John Dewey provide the most prolific examples of how this limited vocational view of education has been applied to both the K–12 public education system and to the teacher training schools who attempted to quickly produce proficient and practical teachers with a limited set of instructional and discipline-specific skills needed to meet the needs of the employer and demands of the workforce. In \"The School and Society\" (Dewey, 1899) and \"Democracy of Education\" (Dewey, 1916), Dewey claims that rather than preparing citizens for ethical participation in society, schools cultivate passive pupils via insistence upon mastery of facts and disciplining of bodies. Rather than preparing students to be reflective, autonomous and ethical beings capable of arriving at social truths through critical and intersubjective discourse, schools prepare students for docile compliance with authoritarian work and political structures, discourage the pursuit of individual and communal inquiry, and perceive higher learning as a monopoly of the institution of education (Dewey, 1899; 1916).\n\nFor Dewey and his philosophical followers, education stifles individual autonomy when learners are taught that knowledge is transmitted in one direction, from the expert to the learner. Dewey not only re-imagined the way that the learning process should take place, but also the role that the teacher should play within that process. For Dewey, \"The thing needful is improvement of education, not simply by turning out teachers who can do better the things that are not necessary to do, but rather by changing the conception of what constitutes education\" (Dewey, 1904, p. 18). Dewey's qualifications for teaching—a natural love for working with young children, a natural propensity to inquire about the subjects, methods and other social issues related to the profession, and a desire to share this acquired knowledge with others—are not a set of outwardly displayed mechanical skills. Rather, they may be viewed as internalized principles or habits which \"work automatically, unconsciously\" (Dewey, 1904, p. 15). Turning to Dewey's essays and public addresses regarding the teaching profession, followed by his analysis of the teacher as a person and a professional, as well as his beliefs regarding the responsibilities of teacher education programs to cultivate the attributes addressed, teacher educators can begin to reimagine the successful classroom teacher Dewey envisioned.\n\nFor many, education's purpose is to train students for work by providing the student with a limited set of skills and information to do a particular job. As Dewey notes, this limited vocational view is also applied to teacher training schools who attempt to quickly produce proficient and practical teachers with a limited set of instructional and discipline skills needed to meet the needs of the employer and demands of the workforce (Dewey, 1904). For Dewey, the school and the classroom teacher, as a workforce and provider of a social service, have a unique responsibility to produce psychological and social goods that will lead to both present and future social progress. As Dewey notes, \"The business of the teacher is to produce a higher standard of intelligence in the community, and the object of the public school system is to make as large as possible the number of those who possess this intelligence. Skill, ability to act wisely and effectively in a great variety of occupations and situations, is a sign and a criterion of the degree of civilization that a society has reached. It is the business of teachers to help in producing the many kinds of skill needed in contemporary life. If teachers are up to their work, they also aid in the production of character.\"(Dewey, TAP, 2010, pp. 241–42).\n\nAccording to Dewey, the emphasis is placed on producing these attributes in children for use in their contemporary life because it is \"impossible to foretell definitely just what civilization will be twenty years from now\" (Dewey, MPC, 2010, p. 25). However, although Dewey is steadfast in his beliefs that education serves an immediate purpose (Dewey, DRT, 2010; Dewey, MPC, 2010; Dewey, TTP, 2010), he is not ignorant of the impact imparting these qualities of intelligence, skill, and character on young children in their present life will have on the future society. While addressing the state of educative and economic affairs during a 1935 radio broadcast, Dewey linked the ensuing economic depression to a \"lack of sufficient production of intelligence, skill, and character\" (Dewey, TAP, 2010, p. 242) of the nation's workforce. As Dewey notes, there is a lack of these goods in the present society and teachers have a responsibility to create them in their students, who, we can assume, will grow into the adults who will ultimately go on to participate in whatever industrial or economical civilization awaits them. According to Dewey, the profession of the classroom teacher is to produce the intelligence, skill, and character within each student so that the democratic community is composed of citizens who can think, do and act intelligently and morally.\n\nDewey believed that the successful classroom teacher possesses a passion for knowledge and an intellectual curiosity in the materials and methods they teach. For Dewey, this propensity is an inherent curiosity and love for learning that differs from one's ability to acquire, recite and reproduce textbook knowledge. \"No one,\" according to Dewey, \"can be really successful in performing the duties and meeting these demands [of teaching] who does not retain [her] intellectual curiosity intact throughout [her] entire career\" (Dewey, APT, 2010, p. 34). According to Dewey, it is not that the \"teacher ought to strive to be a high-class scholar in all the subjects he or she has to teach,\" rather, \"a teacher ought to have an unusual love and aptitude in some one subject: history, mathematics, literature, science, a fine art, or whatever\" (Dewey, APT, 2010, p. 35). The classroom teacher does not have to be a scholar in all subjects; rather, a genuine love in one will elicit a feel for genuine information and insight in all subjects taught.\n\nIn addition to this propensity for study into the subjects taught, the classroom teacher \"is possessed by a recognition of the responsibility for the constant study of school room work, the constant study of children, of methods, of subject matter in its various adaptations to pupils\" (Dewey, PST, 2010, p. 37). For Dewey, this desire for the lifelong pursuit of learning is inherent in other professions (e.g. the architectural, legal and medical fields; Dewey, 1904 & Dewey, PST, 2010), and has particular importance for the field of teaching. As Dewey notes, \"this further study is not a side line but something which fits directly into the demands and opportunities of the vocation\" (Dewey, APT, 2010, p. 34).\n\nAccording to Dewey, this propensity and passion for intellectual growth in the profession must be accompanied by a natural desire to communicate one's knowledge with others. \"There are scholars who have [the knowledge] in a marked degree but who lack enthusiasm for imparting it. To the 'natural born' teacher learning is incomplete unless it is shared\" (Dewey, APT, 2010, p. 35). For Dewey, it is not enough for the classroom teacher to be a lifelong learner of the techniques and subject-matter of education; she must aspire to share what she knows with others in her learning community.\n\nThe best indicator of teacher quality, according to Dewey, is the ability to watch and respond to the movement of the mind with keen awareness of the signs and quality of the responses he or her students exhibit with regard to the subject-matter presented (Dewey, APT, 2010; Dewey, 1904). As Dewey notes, \"I have often been asked how it was that some teachers who have never studied the art of teaching are still extraordinarily good teachers. The explanation is simple. They have a quick, sure and unflagging sympathy with the operations and process of the minds they are in contact with. Their own minds move in harmony with those of others, appreciating their difficulties, entering into their problems, sharing their intellectual victories\" (Dewey, APT, 2010, p. 36). Such a teacher is genuinely aware of the complexities of this mind to mind transfer, and she has the intellectual fortitude to identify the successes and failures of this process, as well as how to appropriately reproduce or correct it in the future.\n\nAs a result of the direct influence teachers have in shaping the mental, moral and spiritual lives of children during their most formative years, Dewey holds the profession of teaching in high esteem, often equating its social value to that of the ministry and to parenting (Dewey, APT, 2010; Dewey, DRT, 2010; Dewey, MPC, 2010; Dewey, PST, 2010; Dewey, TTC, 2010; Dewey, TTP, 2010). Perhaps the most important attributes, according to Dewey, are those personal inherent qualities which the teacher brings to the classroom. As Dewey notes, \"no amount of learning or even of acquired pedagogical skill makes up for the deficiency\" (Dewey, TLS, p. 25) of the personal traits needed to be most successful in the profession.\n\nAccording to Dewey, the successful classroom teacher occupies an indispensable passion for promoting the intellectual growth of young children. In addition, they know that their career, in comparison to other professions, entails stressful situations, long hours and limited financial reward; all of which have the potential to overcome their genuine love and sympathy for their students. For Dewey, \"One of the most depressing phases of the vocation is the number of care worn teachers one sees, with anxiety depicted on the lines of their faces, reflected in their strained high pitched voices and sharp manners. While contact with the young is a privilege for some temperaments, it is a tax on others, and a tax which they do not bear up under very well. And in some schools, there are too many pupils to a teacher, too many subjects to teach, and adjustments to pupils are made in a mechanical rather than a human way. Human nature reacts against such unnatural conditions\" (Dewey, APT, 2101, p. 35).\n\nIt is essential, according to Dewey, that the classroom teacher has the mental propensity to overcome the demands and stressors placed on them because the students can sense when their teacher is not genuinely invested in promoting their learning (Dewey, PST, 2010). Such negative demeanors, according to Dewey, prevent children from pursuing their own propensities for learning and intellectual growth. It can therefore be assumed that if teachers want their students to engage with the educational process and employ their natural curiosities for knowledge, teachers must be aware of how their reactions to young children and the stresses of teaching influence this process.\n\nDewey's passions for teaching—a natural love for working with young children, a natural propensity to inquire about the subjects, methods and other social issues related to the profession, and a desire to share this acquired knowledge with others—are not a set of outwardly displayed mechanical skills. Rather, they may be viewed as internalized principles or habits which \"work automatically, unconsciously\" (Dewey, 1904, p. 15). According to Dewey, teacher education programs must turn away from focusing on producing proficient practitioners because such practical skills related to instruction and discipline (e.g. creating and delivering lesson plans, classroom management, implementation of an assortment of content-specific methods) can be learned over time during their everyday school work with their students (Dewey, PST, 2010). As Dewey notes, \"The teacher who leaves the professional school with power in managing a class of children may appear to superior advantage the first day, the first week, the first month, or even the first year, as compared with some other teacher who has a much more vital command of the psychology, logic and ethics of development. But later 'progress' may with such consist only in perfecting and refining skill already possessed. Such persons seem to know how to teach, but they are not students of teaching. Even though they go on studying books of pedagogy, reading teachers' journals, attending teachers' institutes, etc., yet the root of the matter is not in them, unless they continue to be students of subject-matter, and students of mind-activity. Unless a teacher is such a student, he may continue to improve in the mechanics of school management, but he cannot grow as a teacher, an inspirer and director of soul-life\" (Dewey, 1904, p. 15). For Dewey, teacher education should focus not on producing persons who know how to teach as soon as they leave the program; rather, teacher education should be concerned with producing professional students of education who have the propensity to inquire about the subjects they teach, the methods used, and the activity of the mind as it gives and receives knowledge. According to Dewey, such a student is not superficially engaging with these materials, rather, the professional student of education has a genuine passion to inquire about the subjects of education, knowing that doing so ultimately leads to acquisitions of the skills related to teaching. Such students of education aspire for the intellectual growth within the profession that can only be achieved by immersing one's self in the lifelong pursuit of the intelligence, skills and character Dewey linked to the profession.\n\nAs Dewey notes, other professional fields, such as law and medicine cultivate a professional spirit in their fields to constantly study their work, their methods of their work, and a perpetual need for intellectual growth and concern for issues related to their profession. Teacher education, as a profession, has these same obligations (Dewey, 1904; Dewey, PST, 2010). As Dewey notes, \"An intellectual responsibility has got to be distributed to every human being who is concerned in carrying out the work in question, and to attempt to concentrate intellectual responsibility for a work that has to be done, with their brains and their hearts, by hundreds or thousands of people in a dozen or so at the top, no matter how wise and skillful they are, is not to concentrate responsibility—it is to diffuse irresponsibility\" (Dewey, PST, 2010, p. 39). For Dewey, the professional spirit of teacher education requires of its students a constant study of school room work, constant study of children, of methods, of subject matter in its various adaptations to pupils. Such study will lead to professional enlightenment with regard to the daily operations of classroom teaching.\n\nAs well as his very active and direct involvement in setting up educational institutions such as the University of Chicago Laboratory Schools (1896) and The New School for Social Research (1919), many of Dewey's ideas influenced the founding of Bennington College and Goddard College in Vermont, where he served on the Board of Trustees. Dewey's works and philosophy also held great influence in the creation of the short-lived Black Mountain College in North Carolina, an experimental college focused on interdisciplinary study, and whose faculty included Buckminster Fuller, Willem de Kooning, Charles Olson, Franz Kline, Robert Duncan, Robert Creeley, and Paul Goodman, among others. Black Mountain College was the locus of the \"Black Mountain Poets\" a group of avant-garde poets closely linked with the Beat Generation and the San Francisco Renaissance.\n\nSince the mid-1980s, Deweyan ideas have experienced revival as a major source of inspiration for the public journalism movement. Dewey's definition of \"public,\" as described in \"The Public and its Problems\", has profound implications for the significance of journalism in society. As suggested by the title of the book, his concern was of the transactional relationship between publics and problems. Also implicit in its name, public journalism seeks to orient communication away from elite, corporate hegemony toward a civic public sphere. \"The 'public' of public journalists is Dewey's public.\"\n\nDewey gives a concrete definition to the formation of a public. Publics are spontaneous groups of citizens who share the indirect effects of a particular action. Anyone affected by the indirect consequences of a specific action will automatically share a common interest in controlling those consequences, i.e., solving a common problem. Since every action generates unintended consequences, publics continuously emerge, overlap, and disintegrate.\n\nIn \"The Public and its Problems\", Dewey presents a rebuttal to Walter Lippmann's treatise on the role of journalism in democracy. Lippmann's model was a basic transmission model in which journalists took information given to them by experts and elites, repackaged that information in simple terms, and transmitted the information to the public, whose role was to react emotionally to the news. In his model, Lippmann supposed that the public was incapable of thought or action, and that all thought and action should be left to the experts and elites.\n\nDewey refutes this model by assuming that politics is the work and duty of each individual in the course of his daily routine. The knowledge needed to be involved in politics, in this model, was to be generated by the interaction of citizens, elites, experts, through the mediation and facilitation of journalism. In this model, not just the government is accountable, but the citizens, experts, and other actors as well.\n\nDewey also said that journalism should conform to this ideal by changing its emphasis from actions or happenings (choosing a winner of a given situation) to alternatives, choices, consequences, and conditions, in order to foster conversation and improve the generation of knowledge. Journalism would not just produce a static product that told what had already happened, but the news would be in a constant state of evolution as the public added value by generating knowledge. The \"audience\" would end, to be replaced by citizens and collaborators who would essentially be users, doing more with the news than simply reading it. Concerning his effort to change journalism, he wrote in \"The Public and Its Problems\": \"Till the Great Society is converted in to a Great Community, the Public will remain in eclipse. Communication can alone create a great community\" (Dewey, p. 142).\n\nDewey believed that communication creates a great community, and citizens who participate actively with public life contribute to that community. \"The clear consciousness of a communal life, in all its implications, constitutes the idea of democracy.\" (\"The Public and its Problems\", p. 149). This Great Community can only occur with \"free and full intercommunication.\" (p. 211) Communication can be understood as journalism.\n\nAs an atheist and a secular humanist in his later life, Dewey participated with a variety of humanistic activities from the 1930s into the 1950s, which included sitting on the advisory board of Charles Francis Potter's First Humanist Society of New York (1929); being one of the original 34 signatories of the first \"Humanist Manifesto\" (1933) and being elected an honorary member of the Humanist Press Association (1936).\n\nHis opinion of humanism is summarized in his own words from an article titled \"What Humanism Means to Me\", published in the June 1930 edition of \"Thinker 2\":\n\nAs a major advocate for academic freedom, in 1935 Dewey, together with Albert Einstein and Alvin Johnson, became a member of the United States section of the International League for Academic Freedom, and in 1940, together with Horace M Kallen, edited a series of articles related to the Bertrand Russell Case.\n\nAs well as being active in defending the independence of teachers, and opposing a communist takeover of the New York Teachers' Union, Dewey was involved in the organization that eventually became the National Association for the Advancement of Colored People (NAACP).\n\nHe was an avid supporter of Henry George's proposal for taxing land values. Of George, he wrote, \"No man, no graduate of a higher educational institution, has a right to regard himself as an educated man in social thought unless he has some first-hand acquaintance with the theoretical contribution of this great American thinker.\" As honorary president of the Henry George School of Social Science, he wrote a letter to Henry Ford urging him to support the school.\n\nHe directed the famous Dewey Commission held in Mexico in 1937, which cleared Leon Trotsky of the charges made against him by Joseph Stalin, and marched for women's rights, among many other causes.\n\nIn 1939, John Dewey was elected President of the League for Industrial Democracy, an organization with the goal of educating college students about the labor movement. The Student Branch of the L.I.D. would later become Students for a Democratic Society.\n\nIn 1950, Dewey, Bertrand Russell, Benedetto Croce, Karl Jaspers, and Jacques Maritain agreed to act as honorary chairmen of the Congress for Cultural Freedom, a false-front anti-communist advocacy group founded that year and funded by the CIA.\n\nDewey's interests and writings included many topics, and according to the Stanford Encyclopedia of Philosophy, \"a substantial part of his published output consisted of commentary on current domestic and international politics, and public statements on behalf of many causes. (He is probably the only philosopher in this encyclopedia to have published both on the Treaty of Versailles and on the value of displaying art in post offices.)\"\n\nIn 1917, Dewey met F. M. Alexander in New York City and later wrote introductions to Alexander's \"Man's Supreme Inheritance\" (1918), \"Constructive Conscious Control of the Individual\" (1923) and \"The Use of the Self\" (1932). Alexander's influence is referenced in \"Human Nature and Conduct\" and \"Experience and Nature.\"\n\nAs well as his contacts with people mentioned elsewhere in the article, he also maintained correspondence with Henri Bergson, William M. Brown, Martin Buber, George S. Counts, William Rainey Harper, Sidney Hook, and George Santayana.\n\nDewey is considered the epitome of liberalism by historians, and sometimes was portrayed as \"dangerously radical.\" Meanwhile, Dewey was critiqued strongly by American communists because he argued against Stalinism and had philosophical differences with Marx, identifying himself as a democratic socialist.\n\nHistorians have examined his religious beliefs. Biographer Steven C. Rockefeller traced Dewey's democratic convictions to his childhood attendance at the Congregational Church, with its strong proclamation of social ideals and the Social Gospel. Historian Edward A. White suggested in \"Science and Religion in American Thought\" (1952) that Dewey's work led to the 20th century rift between religion and science.\n\n\n\nBesides publishing prolifically himself, Dewey also sat on the boards of scientific publications such as \"Sociometry\" (advisory board, 1942) and \"Journal of Social Psychology\" (editorial board, 1942), as well as having posts at other publications such as \"New Leader\" (contributing editor, 1949).\n\nThe following publications by John Dewey are referenced or mentioned in this article. A more complete list of his publications may be found at List of publications by John Dewey.\n\nSee also\n\nDewey's Complete Writings is available in 4 multi-volume sets (38 volumes in all) from Southern Illinois University Press:\n\n\"The Collected Works of John Dewey: 1882–1953\"', \"The Correspondence of John Dewey 1871–1952\", and \"The Lectures of John Dewey\" are available online via monographic purchase to academic institutions and via subscription to individuals, and also in TEI format for university servers in the \"Past Masters series\". (The CD-ROM has been discontinued).\n\n\n\n\n"}
{"id": "11572442", "url": "https://en.wikipedia.org/wiki?curid=11572442", "title": "Joseph V. Brady", "text": "Joseph V. Brady\n\nJoseph Vincent Brady (March 28, 1922 – July 29, 2011) was a behavioral neuroscientist at the Walter Reed Army Institute of Research in the United States. While at the Walter Reed Institute he performed the experiment \"Ulcers in Executive Monkeys\" that suggested a link between stress and peptic ulcers. This research was significant in establishing the idea that stress was a physical illness, with important influence in the development of Psychology and Neuroscience.\n\nAfter the launch of Sputnik he became responsible for training monkeys for the space program, in particular Ham. Ham was the first hominid in space and rode aboard a Redstone launch vehicle. The training of Ham was performed in a similar way to his earlier studies on executive monkeys.\n\nHe founded the Programmed Environment Research Center as well as the Division of Behavioral Biology in the Department of Psychiatry and Behavioral Sciences at the Johns Hopkins University School of Medicine. He continued to work there for three decades and received the P.B. Dews Lifetime Achievement Award in Behavioral Pharmacology in 2004. Based upon his seminal work in programmed environments, he continued to explore the potential application of behavioral management principles to long-duration space flight.\n\nIn 2011, Brady was honored for his 50 years of leadership of the Institutes for Behavior Resources, Inc. located in Baltimore, Maryland.\n\nOn July 29, 2011, Brady died of cardiorespiratory arrest.\n\n"}
{"id": "35590381", "url": "https://en.wikipedia.org/wiki?curid=35590381", "title": "Justice and the Market", "text": "Justice and the Market\n\nJustice and the market is an ethical perspective based upon the allocation of scarce resources within a society. The allocation of resources depends upon governmental policies and the societal attitudes of the individuals who exist within the society. Personal perspectives are based upon ones circle of moral concern or those who the individual deems worthy of moral consideration.\n\nPhilosophers, economists and politicians have sought to answer the question of which members of society deserve material rewards and how to decide what deserving is based upon. Perspectives of distributive justice vary from collectivism to extreme self-sufficiency; these perspectives vary between the importance of the group or individual respectively. Positions on distributive justice incorporate moral and political philosophies to form the extremes of communism (left wing) and libertarianism (right-wing) that exist on a continuum scale.\n\n20th century philosopher John Rawls attempted to create a thought experiment that would allow for the consideration of a societal design that is best for all involved. Mechanisms of redistribution vary among countries and governmental roles within societies determine the redistributive mechanisms that are used.\n\nDistributive justice relates to the principle of fairness in the allocation of wealth, income, power and opportunities. Many theoretical paradigms have been developed to approach distributive justice such as Adam Smith’s invisible hand, Karl Marx’s Socialist view of Communism and John Rawls Original position on Inequality.\n\nThe Libertarian philosophy refers to freedom, and particularly individual liberty which dictates the right and ability to govern one's self. In an economic sense the libertarian view assumes a free market, left to its own accord, is a fair market and that redistributive taxation is unjust. Many libertarian schools of thought exist with differing views on many principles, such as the role of government in the market place.\n\nAdam Smith's idea of the invisible hand was a founding contribution to explain resource allocation within a society. The invisible hand metaphor portrayed an aggregated market created by the self-interest of those involved, and grounded in the notion that through fulfillment of one's own aspirations, society would benefit. This idea formed the foundation of laissez-faire economic philosophy and subsequent neoclassical economics, where Milton Friedman’s ideas about economic systems lay. The free market originated from the concept of the invisible hand, and eventuates in a meritocratic society with resources allocated on the basis of merit. Modern representations of this exemplify perfect free market capitalism.\n\nThe invisible hand approach, or pure free market capitalism, assumes that a competitive market allocates resources in an appropriate manner, however Stephen LeRoy highlighted the debate that ensued following the recent financial crisis upon whether this assumption holds true for modern economies. Thorstein Veblen in The Theory of the Leisure Class (1899) argued that some wealth is conspicuously consumed to display success to others. This proclivity to purchase luxury goods has been viewed as an inefficiency of the capitalist system. Galbraith’s writings centered mostly, however, on the market power of large corporations. He posited that the power of corporations and their associated advertising, would make the markets espoused in classical economic theory ineffectual, requiring a new economic theory to be developed. Critics of Galbraith in turn objected to the fact that the focus of his writings were lay readers, as opposed to expert academics, implying that his answers to economic problems are too simplistic. Social inequality and unfair distribution of wealth, are often attributed to capitalism and a pure free market is built upon a principle of rewarding effort. However, this ignores persons born with greater natural abilities or greater opportunities. Thus, successive iterations of pure free market capitalism would lead to a market based upon feudal aristocracy.\n\nPrice controls are a government initiative to mitigate exploitative market power. Specifically in response to systems of pricing that capitalise on the dependency of one market entity upon another, such as monopolistic markets in which the supplier is a price maker and consumers assume the role of price taker. Price controls as a strategy provide relief from the price exploitation of the dominant player in a market transaction, albeit a short term abatement of this power which is a common criticism of this method.\n\nKarl Marx in The Communist Manifesto postulated that the era of feudal aristocracy and the capitalism experienced in 1847 at the time of its writing, would be replaced with communism, or as we now know it, a socialist society. Communists from a Marxian perspective are described as persons that understand the world and are enlightened to the interests of the proletariat. Marx surmised that the \"dictatorship of the proletariat\" refers to rule by the working class and would see the battle of democracy as won.\n\nIn this scenario members of a society share common ownership of the means of production and rewards from that production. The resultant society gains and allocates resources according to the quote \"From each according to his ability, to each according to his needs!\". The communist approach eliminates scarcity in all respects, and represents a society from a pure collectivism school of thought, based upon the utilitarian moral perspective.\n\nThe impact of Marxist theories continues to this day, Alan Taylor compares The Communist Manifesto to a holy script, being acted upon and quoted by supporters that do not know the source of their belief.\n\nA Communist society utilises a utilitarian based moral approach as a means to preserve the society. In this system the rights of the collective are placed above the rights of individuals. The utilitarian paradigm represents \"the greatest happiness principle\" as theorized by John Stuart Mill. This theory holds that the best course of action is that which benefits the majority, and may require the sacrifice of some to maximise happiness overall.\n\nWithin a Communist Society the sole purpose of production is in maintaining the subsistence of the collective. Removing any role for self-interest also removes this incentive to exert effort by individuals because reward is not allocated proportionate to effort or in a meritocratic manner. Introduction of a rewards system (be it economic or otherwise) breaches the basis of the communist society, because reward places value on individual achievement. An additional criticism flows from Adam Smith's discovery of the effect of market signals on resource allocation. With no consumers to express demand, optimal resource levels cannot be maintained. Instead production occurs on the basis of need only and need is not measured by willingness to pay .\n\nMeritocracy is an ideology founded in the works of Confucius, whereby the allocation of rewards, positions and responsibilities is objective and upon the merit of an individual. Merit is predominantly assessed via examinations and evaluations, however a perfect meritocracy is near impossible to achieve. The attainment of a university degree is purportedly an example of a meritocratic system, however the inability to ensure equal opportunity to access university by all refutes this point. Inequalities exist in access to prior education, socio-economic factors and as Rawls argues natural abilities and talents. Criticism of meritocracy comes from the reproduction of traditional hierarchies and inequality, when merit is not awarded in a meritocratic manner but instead on the basis of opportunity. Distribution based upon the arbitrary nature of desert faces criticism from egalitarianism, that dictates justice without equality is futile and that equality in itself is the highest form of justice.\n\nJohn Rawls conceived the notion of ‘The Original Position’ based upon the thought experiment whereby participants must agree to a hypothetical social contract under a veil of ignorance. In this approach to the question of societal design, removal of the knowledge of particular abilities, tastes and position within society creates a veil of ignorance. The application of this veil in the thought experiment determines the basic structure of society subjectively, because knowledge of the outcome and participant’s subsequent position in the society is deprived. From this naive perspective, an evaluation of resource allocation can be made from a morally arbitrary point of view.\nThe veil of ignorance favours the selection of ‘the original position’ a point in between self-sufficiency and collectivism, whereby two fundamental principles of justice would be agreed upon.\n\n\"They are the principles that free and rational persons concerned to further their own interests would accept in an initial position of equality as defining the fundamental terms of their association.\"\n\nRawls’ conclusion to the regulation of inequality, was a society based upon his proposed ‘difference principle’ - permitting inequalities that work to the advantage of the worst off. Not to be confused with trickle-down economics, this compensates for the natural abilities of individuals through a redistributive exercise. The society that results is therefore fair on the basis of opportunity regardless of natural ability.\n\nRawls arranged the fundamental principles of the Original Position in lexical priority: the liberty principle, fair equality of opportunity and lastly the difference principle. This prioritisation encounters criticism, as the importance of the first principle is awarded greater weighting and must be satisfied prior to subsequent principles. So whilst liberty is said to be the dominant principle, the difference principle that results from the acceptance of inequalities (the second principle) operates in violation of the first principle. This is exemplified by redistributive taxes as discussed by Robert Nozick in Anarchy, State and Utopia which criticises the use of this tax as a levelling mechanism, impinging upon an individual’s basic liberties, the mainstay of the original position's principles.\n\nThree objections to the difference principle are identified by Michael Sandel as follows:\n1. A decreased incentive to work when top tier earners are taxed proportionately greater than lower tier earners. Reaching an equilibrium point demonstrates the difference principle. At equilibrium, top tier earners are provided with enough incentive so to remain in their positions of employment and thus continue to produce benefits also received by bottom tier earners.\n2. A Meritocratic allocation of reward.\n3. Self-Ownership of one’s natural talents and abilities, violated by redistributive practises that treat these natural assets as public or communal.\n\nRedistribution of wealth is attained through many forms such as taxation, monetary policies, welfare and nationalisation of private enterprise. Taxation as a means to redistribute wealth seeks to establish a level playing field for its constituents. Sweden has one of the highest income tax rates in the world, which translates to a high level of social welfare in the areas of education, healthcare and pensions. This is a mostly utalitarian form of society and results in a low gini coefficient, a measure of equality of income 0.25. The United States of America has a relatively high gini coefficient opposed to Sweden of 0.41. As such the USA faces a problematic history in public sector services. Accessibility issues exist in healthcare and education in particular. Private sector ownership of these services advantage those that can afford it and for those that cannot, inequality is exacerbated further.\n\nThe inequality of wealth distribution in the United States was the precursor to the Occupy Wall Street Movement that spread to up to 80 countries. The protest’s slogan \"We are the 99%\" aimed to draw attention to the financial power held by a minority. This power is perpetuated by the supposedly corrupt nature of large corporations said to hold overwhelming financial and political control.\n\nA poverty trap, acts as a self-reinforcing mechanism which causes poverty to persist. This vicious cycle of poverty remains a common experience of billions and the emergence of these traps can arise from both market failure and institution failure. On the opposite side to poverty traps are welfare traps, or an over-reliance upon welfare, that creates a perverse incentive to work.\n\nMarket failures are the inefficient allocation of goods and services, that can occur in a free market economy. These failures often arise in the pursuit of goals of self-interest that lead to inefficient market outcomes such as Veblen’s theory of conspicuous consumption.\n"}
{"id": "35991378", "url": "https://en.wikipedia.org/wiki?curid=35991378", "title": "Kim Young-sam", "text": "Kim Young-sam\n\nKim Young-sam (; or ; 20 December 1927 – 22 November 2015) was a South Korean politician and democratic activist, who served as President of South Korea from 1993 to 1998. From 1961, he spent almost 30 years as one of the leaders of the South Korean opposition, and one of the most powerful rivals to the authoritarian regimes of Park Chung-hee and Chun Doo-hwan.\n\nElected president in 1992, Kim became the first civilian to hold the office in over 30 years. He was inaugurated on 25 February 1993, and served a single five-year term, presiding over a massive anti-corruption campaign, the arrest of his two predecessors, and an internationalization policy called \"Segyehwa\".\n\nKim was born in Geoje Island, by the southeastern tip of the Korean peninsula, to a rich fishing family on 20 December 1927, when Korea was under Imperial Japanese rule. He was the eldest of one son and five daughters in his family. During the Korean War, Kim served in the South Korean military as a student soldier (or Officer candidate). In 1952, he graduated with a Bachelor of Arts in Philosophy from Seoul National University.\n\nIn 1954, Kim was elected to the National Assembly of South Korea, as a member of the party led by Syngman Rhee, the first president of South Korea. At the time of his election, Kim was the youngest member of the national assembly. A few months after his electoral victory, Kim left his party and joined the opposition when Rhee attempted to amend the constitution of South Korea. Kim then became a leading critic, along with Kim Dae-jung, of the military governments of Park Chung-hee and Chun Doo-hwan.\n\nIn 1974, he was elected as the president of the New Democratic Party. While he temporarily lost his power within the national assembly in 1976, Kim made a political comeback during the final year of Park Chung-hee's rule. Kim took a hardline policy of never compromising or cooperating with Park's Democratic Republican Party until the Yushin Constitution was repealed and boldly criticized Park's dictatorship, which could be punished with imprisonment under the new constitution.\n\nIn August 1979, Kim allowed around 200 female workers at the Y.H. Trading Company to use the headquarters of New Democratic Party as a place for their sit-in demonstration and pledged to protect them. One thousand policemen raided the party headquarters and arrested the workers. One female worker died in the process and many lawmakers trying to protect them were severely beaten, some requiring hospitalization. The YH Incident garnered widespread criticism and led to Kim's condemnation, with an assertion that Park's dictatorship would soon collapse. After this incident, Park was determined to remove Kim from the political scene, like the imprisoned Kim Dae-jung, and instructed the South Korean Central Intelligence Agency (KCIA) to engineer such a move. In September 1979, a court order suspended Kim's presidency of the New Democratic Party.\n\nWhen Kim called on the United States to stop supporting Park's dictatorship in an interview with the \"New York Times\", Park wanted to have Kim imprisoned while the Carter Administration, concerned over increasing human right violations, issued a strong warning not to persecute members of the opposition party. When Kim was expelled from the National Assembly in October 1979, the United States recalled its ambassador back to Washington, D.C., and all 66 lawmakers of the New Democratic Party resigned from the National Assembly.\n\nWhen it became known that the South Korean government was planning to accept the resignations selectively, uprisings broke out in Kim's hometown of Pusan. It was the biggest demonstration since the Syngman Rhee presidency, and spread to nearby Masan and other cities, with students and citizens calling for an end to the dictatorship. The crisis was one of the causes for the assassination of Park Chung-hee on 26 October 1979 by KCIA Director Kim Jae-gyu.\n\nThe government's oppressive stance towards the opposition continued under Chun Doo-hwan, who seized power with a military coup on 12 December 1979. Kim Young-Sam was expelled from the National Assembly for his democratic activities and banned from politics from 1980 to 1985. In 1983, he undertook a 21-day hunger strike protesting the dictatorship of Chun Doo-hwan.\n\nWhen the first democratic presidential election was held in 1987 after Chun's retirement, Kim Young-sam and Kim Dae-jung ran against each other, splitting the opposition vote and enabling ex-general Roh Tae-woo, Chun's hand-picked successor, to win the election. This was also despite support from the first female presidential candidate, Hong Sook-ja, who resigned her candidacy in order to support Kim. In 1990, he unexpectedly merged his Democratic Reunification Party with Roh's ruling Democratic Justice Party to form the Democratic Liberal Party, now the Liberty Korea Party.\n\nAs the candidate of the governing party, he defeated Kim Dae-jung in the 1992 presidential election. He was only the third civilian to hold the office, and the first since 1962.\n\nThe Kim Young-sam administration attempted to reform the government and the economy. One of the first acts of his government was to start an anti-corruption campaign, which began at the very top, as Kim promised not to use political slush funds.\n\nKim's government required government and military officials to publish their financial records, precipitating the resignation of several high-ranking officers and cabinet members. He had his two predecessors as president, Chun and Roh, arrested and indicted on charges of corruption and treason for their role in military coups, although they would be pardoned near the end of his term. Kim also granted amnesty to thousands of political prisoners, and removed the criminal convictions of pro-democracy protesters who had been arrested during the Gwangju massacre in the aftermath of the Coup d'état of December Twelfth. The anti-corruption campaign was also part of an attempt to reform the \"chaebol\", the large South Korean conglomerates which dominated the economy. However, Kim's anti-corruption message was damaged after his son was arrested for bribery and tax evasion related to the Hanbo scandal.\n\nIn 1994, when American president Bill Clinton mulled over attacking Nyongbyon, the centre of North Korea's nuclear program, Kim advised him to back down to prevent renewal of fighting.\n\nKim's new ministerial party, the DLP lost its narrow majority in the National Assembly in 1996. Kia Motors collapsed soon thereafter, setting off a chain of events which embroiled South Korea in the 1997 Asian Financial Crisis during the last year of his presidency.\n\nDuring the financial crisis, the collapse of Kia and other conglomerates led Kim to accept a $58 billion USD bailout from the International Monetary Fund.\n\nAfter his presidency, Kim travelled the world promoting democracy, and speaking at events such as \"Towards a Global Forum on New Democracies\" in Taiwan in January 2007.\n\nHe died in Seoul National University Hospital on 22 November 2015, from heart failure, at the age of 87. On 26 November 2015, a televised state funeral was held for Kim at the National Assembly lawn, during which Prime Minister Hwang Kyo-ahn delivered the opening remarks. Later that day, Kim was buried in the Seoul National Cemetery.\n\nKim was a member of the Chunghyun Presbyterian Church and was fluent in Japanese and his native language, Korean. He was married to Son Myung-soon. He was survived by his children, two sons and three daughters, as well as his five younger sisters.\n\n"}
{"id": "36554534", "url": "https://en.wikipedia.org/wiki?curid=36554534", "title": "List of charting software", "text": "List of charting software\n\nThere are many different types of software available to produce charts.\n\nA number of notable examples (with their own Wikipedia articles) are given below and organized according to the programming language or other context in which they are used.\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "46695405", "url": "https://en.wikipedia.org/wiki?curid=46695405", "title": "Little Miss Nobody case", "text": "Little Miss Nobody case\n\nLittle Miss Nobody is the name posthumously given to a young girl whose body was found in Congress, Yavapai County, Arizona on July 31, 1960. Her body is estimated to have been discovered between one and two weeks of the date of her death.\n\nDue to the advanced state of decomposition of the child's remains, the specific cause of her death has never been established, although it has always been considered to be a homicide. Furthermore, despite extensive local and national efforts to discover the identity of this child, her identity remains unknown, and the case remains unsolved.\n\nThis unidentified decedent became known as \"Little Miss Nobody\" after no family or friends came forward to either report her missing, or to claim her body. Following recent advances in technology, a forensic facial reconstruction of \"Little Miss Nobody\" was released to the media in 2018 in renewed efforts to identify this unidentified child murder victim's remains.\n\nThe partially buried body of a female child was found in Sand Wash Creek Bed on Old Alamo Road in Congress, Arizona on July 31, 1960. Her body was discovered by a Las Vegas schoolteacher named Russell Allen, who had been searching for rocks to decorate his garden, and was found buried in a sitting position, with her arms stretched outwards.\n\nInvestigators at the scene observed that the individual or individuals responsible for the child's burial had possibly made two separate attempts to dig an alternate grave for her body. This was determined by two evident disturbances in the sand close to the actual burial site.\n\nThe body was clothed in white shorts and a checkered blouse with a distinctive chain pattern, along with a pair of adult rubber thong sandals that had been cut to fit the child's feet and fastened with leather straps. The child's toes and fingernails had reportedly been painted a bright red color. Investigators also found an apparently bloodstained pocket knife near the body, but were unable to definitively determine whether this utensil held any relation to the crime scene.\n\nThe forensic pathologist who performed the autopsy determined that the body was that of a white girl between the ages of 5- and 7-years old, 3 feet–6 inches to 4 feet–5 inches in height, and likely weighing 50 to 60 pounds (later examinations of the child's remains indicated she may have been as old as 9 or as young as 2 at the time of her death). The child had been deceased for between one and two weeks prior to the discovery of her remains. Her hair color was brown, possibly having been tinted or dyed auburn, and she had a full set of intact milk teeth described as being in a markedly good condition. (Although the actual race of the decedent has since been described as being indeterminable, the highest likelihood of her actual age at the time of her death has since been determined as being 3 to 6 years.)\n\nThe actual cause of death of the decedent was never determined by medical examiners, although her death was officially declared to be a homicide. Furthermore, the forensic pathologist was able to definitively state that she had not suffered any bone fractures at the time of her death, or in her lifetime. In addition, the contemporary report pertaining to the child's autopsy indicates her remains were charred, presumably from her body having been set alight around the time of her death.\n\nBecause the decedent had been in an advanced state of decomposition at the time of her discovery, creating an actual composite drawing of the child's facial features was not possible.\n\nWith active assistance from the local media, private citizens, and (later) assistance from officials as eminent as individuals within the FBI, the Yavapai County sheriff's office worked tirelessly in their efforts to discover the decedent's identity. An all-points bulletin was initially broadcast across all sheriff radio and teletype networks following the discovery of this child's body, and Yavapai County Sheriff Jim Cramer, Deputy County Attorney George Ireland and other local law enforcement personnel would subsequently travel hundreds of miles in radius via both air and land in their efforts to discover her identity. Individuals previously convicted of various offenses involving young children would be subjected to prolonged interrogations, and the sheriff's office also received dozens of letters, telephone calls, and telegrams in response to their public appeals for information in their efforts to discover the child's identity. Furthermore, any possibility the decedent had been any known missing young girl was investigated, and discounted.\nBy August 1960, investigators began to suspect the remains may have been those of a four-year-old girl named Sharon Lee Gallegos, who had been abducted in New Mexico ten days before the discovery of the child's body. Despite the fact that the clothing the victim wore was inconsistent to that Gallegos was last seen wearing, they could not eliminate Gallegos as being the decedent due to this fact, as the clothing could have easily been changed in the intervening week. Gallegos currently remains a missing person. However, police later released a statement that they believed the unidentified child was older than Gallegos.\n\nInitial speculation that the child may have been a member of a family of transients, also from New Mexico. Police also subjected one Lester Davidson and two of his four children to in excess of an hour of questioning. Davidson and his children had been known to have been hitchhiking near Prescott in late July 1960. This questioning concluded that the family likely had no connection to either the unidentified child or Sharon Gallegos.\n\nFollowing the verification of the Davidsons' alibis, police sent the clothing, knife, and footprints found with or near the child's body to an FBI laboratory to undergo further examination.\n\nIn March 1961, a possibility arose that the decedent may have been one Debbie Dudley; a four-year-old girl missing from Virginia. Investigators had failed to find the bodies of Dudley and her remaining siblings after the body of her seven-year-old sister, Carol Ann, was found wrapped in a blanket on February 9, 1961, she having died due to a combination of the malnutrition, exposure, and neglect she had endured from her parents. Debbie's remains were later found in Southern Virginia. She was later interred alongside her sister. The parents of the sisters were later charged with both murders.\n\nOn August 8, 1961, Sheriff Cramer led a party of law enforcement officers and a camera crew to film the location where the child's body had been found. Later that afternoon, Sheriff Cramer and Yavapai County Attorney George Ireland presented evidence—including the adult-sized rubber sandals which had been purposely cut to fit the child's feet—to the media, with Sheriff Cramer stating: \"Somewhere, there is someone who has the answer that we have been looking for; maybe this will be the thing that will bring that person forward.\" The footage of this scene and the interview with Sheriff Cramer was later broadcast on television in the hope fresh leads toward establishing the identity of the child would ensue, although the program brought no significant new information.\n\nDespite the numerous and extensive local and national efforts conducted to identify the decedent, all contemporary efforts to either identify the child, or trace any of her relatives, failed.\nThe funeral of this unidentified child was conducted on August 10, 1960. She was laid to rest in Mountain View Cemetery, with the campaign for funds to provide a dignified burial—as opposed to anonymous interment inside a pauper's grave—being spearheaded by a local radio announcer named Dave Palladin, who successfully initiated a fundraising and donations appeal to local businesses, funeral homes and residents to ensure the child received a respectful burial. Palladin referred to his primary motivation for this fundraising campaign as being that he found the thought of a \"little girl buried in Boot Hill\" as an insufferable one, adding of his insistence the child received a decent Christian burial. Prior to her funeral, the child had become colloquially known within and around Yavapai County as \"Little Miss Nobody\".\n\nThe funeral service for Little Miss Nobody was conducted at the Congregational Church in Prescott, Arizona, and was officiated by Dr. Charles Franklin Parker, with over 70 mourners in attendance. At this service, a placard was placed upon Little Miss Nobody's pale blue casket, with the inscription reading: \"God's little child, date of birth unknown, date of death unknown.\" Her headstone is inscribed with a section of a quote from St. Matthew, which reads, \"Blessed are the Pure in Heart.\"\n\nDuring the eulogy at the funeral of Little Miss Nobody, Dr. Parker recited a poem entitled \"For a Little Girl Unknown\" before addressing those in attendance with a speech in which he stated: \"Here is a little wanderer who has been in our midst. We don't know her name; we can only guess her age. It occurs to me we may not know, but God knows. There are no unknowns, no orphans in God's world. ... She doesn't need a name today. She has the name of an angel somewhere in eternity ... we may never know the why's and wherefores, but, somewhere, someone is going to be watching the paper to learn what happened to a little girl left on the desert. If there has been a misdeed, probably a disquieted conscience will go on and on.\"\nDue to recent advances in technology and DNA profiling, a decision to exhume the body of Little Miss Nobody to obtain a DNA sample was made in 2018, with The National Center for Missing and Exploited Children offering to pay for the exhumation and required testing. Resultingly, samples of the girl's DNA were successfully obtained from her body, and entered into both the National Missing and Unidentified Persons System and the National Center for Missing and Exploited Children databases for comparison with nationwide unsolved murders and missing person reports. Furthermore, the University of North Texas Center for Human Identification also created a detailed forensic facial reconstruction of the decedent, depicting how she may have appeared in life, before her body was reburied at Mountain View Cemetery.\n\n\n\n\n"}
{"id": "57203576", "url": "https://en.wikipedia.org/wiki?curid=57203576", "title": "Marriage of Lunatics Act 1811", "text": "Marriage of Lunatics Act 1811\n\nThe Marriage of Lunatics Act (1811) was an act of Parliament of the United Kingdom implemented under the reign of George III of Great Britain. It was intended \"to prevent the marriage of Lunatics\" and make all marriages to Lunatics prior to and after the bill, whether diagnosed before marriage or otherwise, \"null and void to all intents and purposes whatsoever\".\n\nThe Act reads as follows:\n\nThe Act was fully repealed in 2015 by the Assisted Decision-Making (Capacity) Act 2015 \n"}
{"id": "53183984", "url": "https://en.wikipedia.org/wiki?curid=53183984", "title": "Mary the Younger", "text": "Mary the Younger\n\nSaint Mary the Younger (, to distinguish her from Saint Mary of Egypt; 875 – 16 February 902) is a Byzantine saint of Armenian origin, the daughter of an Armenian noble. Some details of her life, including her following after the mid-10th century, are not known for certain; the text documenting some of her most noteworthy accomplishments was most likely written after 1025.\n\nHer family originated from Greater Armenia, where her father was among the local grandees. They had settled in Constantinople, probably at the start of the reign of Basil I the Macedonian (), who called her father along with other Armenian grandees to enter his service. Maria was born in 875, probably in Constantinople, shortly after the death of her father. She had four older siblings, two brothers and two sisters; the latter were already married, indicating that Maria was a late child of her parents. She was raised by her mother, and as soon as she was of age (), she married the \"droungarios\" Nikephoros, an acquaintance of her brother-in-law Bardas Bratzes. Nikephoros distinguished himself in the 894–896 war against the Bulgarians, and was rewarded with a posting (probably as commander) to the division (\"tourma\") of Bizye.\n\nThe couple had four sons: Orestes, born , who died at the age of five; Bardanes, born after Orestes' death, who himself died in ; and the twins Baanes and Stephen, born between 897 and 900, of whom Baaners became a soldier and Stephen a monk, under the monastic name Symeon. Around 900 she was accused by the siblings of her husband, Helena and Alexios, of being profligate with money and of a liaison with their servant Demetrios. Mary vehemently denied these allegations, but Nikephoros posted a guard at her room and tortured her maidservant, Agathe, for interrogation. He furthermore removed the supervision of the household finances from Mary and gave it to the steward Drosos and a female servant, with express instructions not to give Mary any money. The latter was so distressed by her husband's treatment of her, that she developed a stomach ailment.\n\nIn 902, according to her hagiography, she expressed her disapproval that her husband, along with his siblings and servants, did not observe the fasting of Lent. Her disapproval was transmitted to Nikephoros in much exaggerated form, according to which she claimed that he was no real Christian, but a devil. Enraged, he manhandled Mary, who hit her head trying to escape. She died ten days later, on 16 February. Her funeral was led by the Bishop of Bizye, and was attended by almost the entire population of the town, who accompanied the funeral procession to the local cathedral, where she was buried. In 927, her son Stephen had her corpse, which had been miraculously preserved until that time, removed from her wooden coffin and placed in the marble sarcophagus of his father, whose corpse on the other hand had rotted away and was reburied outside the church.\n\nMary the Younger was a symbol of female virtue. She is described as being merciful, having a pattern of divine love, and having high self-control, which was a stereotypical male quality. She also had duties as a wife and mother, while having a strong sense of loyalty to God. One of Mary the Younger’s defining characteristics was that she was highly charitable. She would send money to a tax collector who eased punishment for those imprisoned for not being able to pay the diokete- which was a public tribute tax for housekeeping. In addition, she sought gold to help individuals who were suffering, and protected widows and orphans. From a strictly religious perspective, Mary the Younger was steadfast in her faith to God, even through times of struggle. For example, after her son Orestes died, she praised the Lord in a sincere manner for having let her experience this. From a perspective of gender, the fact that she had a “Married” status was not a significant issue to those who admired her. At the same time, Mary the Younger was looked down upon and underestimated, particularly by males in high places of authority. One of the men who underestimated her was the Bishop of Bizye, who did not believe that a woman who died in a married state could perform miracles the way that a man could.\n"}
{"id": "106121", "url": "https://en.wikipedia.org/wiki?curid=106121", "title": "Modesty", "text": "Modesty\n\nModesty, sometimes known as demureness, is a mode of dress and deportment which intends to avoid the encouraging of sexual attraction in others. The word \"modesty\" comes from the Latin word \"modestus\" which means \"keeping within measure\". Standards of modesty are culturally and context dependent and vary widely. In this use, it may be considered inappropriate or immodest to reveal certain parts of the body. In some societies, modesty may involve women covering their bodies completely and not talking to men who are not immediate family members; in others, a fairly revealing but one-piece bathing costume is considered modest when other women wear bikinis. In some countries, exposure of the body in breach of community standards of modesty is also considered to be public indecency, and public nudity is generally illegal in most of the world and regarded as indecent exposure. For example, Stephen Gough a lone man attempting to walk naked from south to north Britain was repeatedly imprisoned. However, nudity is at times tolerated in some societies; for example, during a World Naked Bike Ride.\n\nIn semi-public contexts standards of modesty vary. Nudity may be acceptable in public single-sex changing rooms at swimming baths, for example, or for mass medical examination of men for military service. In private, standards again depend upon the circumstances. A person who would never disrobe in the presence of a physician of the opposite sex in a social context might unquestioningly do so for a medical examination; others might allow examination, but only by a person of the same sex.\n\nStandards of modesty discourage or forbid exposure of parts of the body, varying between societies, which may include areas of skin, the hair, undergarments, and intimate parts. The standards may also require obscuring the shape of the body or parts of it by wearing non-form-fitting clothing. There are also customs regarding the changing of clothes (such as on a beach with no enclosed facilities), and the closing or locking of the door when changing or taking a shower.\n\nStandards of modesty vary by culture or generation and vary depending on who is exposed, which parts of the body are exposed, the duration of the exposure, the context, and other variables. The categories of persons who could see another's body could include:\n\nThe context would include matters such as whether it is in one's own home, at another family member's home, at a friend's home, at a semi-public place, at a beach, swimming pool (including whether such venues are considered clothes-optional), changing rooms or other public places. For instance, wearing a bathing suit at the beach would not be considered immodest, while it likely would be in a street or an office.\n\nExcessive modesty is called prudishness. As a medical condition, it is also called gymnophobia. Excessive \"immodesty\" is called exhibitionism.\n\nAt times of public or private emergency, expectations of modest dress may be suspended if necessary. For example, during suspected anthrax attacks in 1998 and 2001 in the United States, groups of people had to strip to their underwear in tents set up in parking lots and other public places for hosing down by fire departments. On the other hand, even in an emergency situation, some people are unable to abandon their need to hide their bodies, even at the risk of their life. This may apply to decontamination after a chemical or biological attack, where removal of contaminated clothing is important, or escaping from a night-time fire without time to dress.\n\nMost discussion of modesty involves clothing. The criteria for acceptable modesty and decency have relaxed continuously in much of the world since the nineteenth century, with shorter, form-fitting, and more revealing clothing and swimsuits, more for women than men. Most people wear clothes that they consider not to be unacceptably immodest for their religion, culture, generation, occasion, and the people present. Some wear clothes which they consider immodest, due to exhibitionism, the desire to create an erotic impact, or for publicity.\n\nAppropriate modesty depends on context and place. For example, in single-sex public changing rooms, nudity is often acceptable.\nIn Western and some other societies, there are differences of opinion as to how much body exposure is acceptable in public. In contemporary Western society, the extent to which a woman may expose cleavage depends on social, cultural and regional context. Women's swimsuits and bikinis commonly may reveal the tops and sides of the breasts, or they may be topless as is common on the beaches of French Riviera. Displaying cleavage is considered permissible in many settings, and is even a sign of elegance and sophistication on many formal social occasions, but it may be considered inappropriate in settings such as workplaces, churches and schools. Showing the nipples or areolae is almost always considered toplessness or partial nudity. However, in some circumstances partial breast exposure may be officially sanctioned in church as in 2014, newly elected Pope Francis drew world-wide commentary when he encouraged mothers to breastfeed in church if their babies were hungry.\n\nIn private homes, the standards of modesty apply selectively. For instance, nudity among close family members in the home can take place, especially in the bedroom and bathroom, and wearing of undergarments only in the home is common.\n\nIn many cultures it is not acceptable to bare the buttocks in public; deliberately doing so is sometimes intended as an insult. In public, Western standards of decency expect people to cover their genitalia, and women to cover their breasts. In the early twenty-first century, public breastfeeding has become increasingly acceptable, sometimes protected by law. President Barack Obama's health care bill from 2010 provides additional support to nursing mothers, requiring employers to provide a private and shielded space for employees to use in order to nurse.\n\nSince the 1980s it has become more common for young and/or fashionable women in Western societies to wear clothing that bared the midriff, \"short shorts,\" backless tops, sheer and other styles considered to be immodest.\n\nMen and women are subject to different standards of modesty in dress. While both men and women, in Western culture, are generally expected to keep their genitals covered at all times, women are also expected to keep their breasts covered. Some body parts are normally more covered by men than women—e.g., the midriff and the upper part of the back. Organizations such as the Topfree Equal Rights Association advocate for gender equality regarding display of the body. In 1992 New York State's highest court accepted 14th Amendment arguments and struck down the provision in New York's \"Exposure of the Person\" statute that made it illegal for women to bare their chests where men were permitted to do so.\n\nTraditional indigenous cultures, such as some African and traditional Australian aboriginal cultures, are more relaxed on issues of clothing, though how much clothing is expected varies greatly, from nothing for some women, to everything except the glans penis for men of some tribes. In some African cultures, body painting is considered to be body coverage, and is considered by many an attire.\n\nModesty doesn't have to be related to having more clothes especially in the case of natives tribes. Some feel exposed when seen in certain clothes even though normal attire is much more revealing. Having ear or lip stoppers is seen as modest with the opposite being true as well.\n\nMost world religions have sought to address the moral issues that arise from people's sexuality in society and in human interactions. Each major religion has developed moral codes covering issues of sexuality, morality, ethics etc. Besides other aspects of sexuality, these moral codes seek to regulate the situations which can give rise to sexual interest and to influence people's behaviour and practices which could arouse such interest, or which overstate a person's sexuality. These religious codes have always had a strong influence on peoples' attitudes to issues of modesty in dress, behavior, speech etc.\n\nModesty in dress is important in Buddhism. The Sekhiya rules of Buddhist Monastic code, for example, provide guidelines on proper clothing as well as recommended ways of dressing for monks.\n\nThe 'robes hitched up' phrase above refers to lifting one's 1 or 2 piece cloth robe, thereby exposing either side or both sides of one's body to other human beings in an inhabited area. Such exhibitionism is not recommended to monks. Beyond monks, the Buddhist belief is that modesty has a purifying quality to everyone.\n\nAccording to the New Testament, () Whose adorning let it not be that outward adorning of plaiting the hair, and of wearing of gold, or of putting on of apparel; But let it be the hidden man of the heart, in that which is not corruptible, even the ornament of a meek and quiet spirit, which is in the sight of God of great price.\n\n() In like manner also, that women adorn themselves in modest apparel, with shamefacedness and sobriety; not with broided hair, or gold, or pearls, or costly array.\n\nMany Trinitarian Christians consider modesty extremely important, though considerable differences of opinion exist about its requirements and purposes.\n\nHistorically, communicants of traditional Christian denominations (including Anglican, Baptist, Eastern Orthodox, Lutheran, Methodist, Oriental Orthodox, Reformed, and Roman Catholic women) wore a Christian headcovering while worshipping, or, all the time, in keeping with their interpretation of ; although this practice has waned in some parts of the world, such as in North America, it is commonplace in other regions, such as Eastern Europe and South Asia.\n\nMany Anabaptist Christians, such as Amish groups and some Mennonite groups like Conservative Mennonites, are known for their adherence to plain dress, a modest fashion style. The Hutterites and the Bruderhof, both Christian intentional communities of the Anabaptist tradition, wear modest clothing (often plain dress), and the women wear Christian headcoverings.\n\nCatholics are expected to dress modestly; it is recognised that the forms taken by modesty vary from one culture to another. The wearing of a Christian headcovering at Mass was for the first time mandated as a universal rule for the Latin Rite by the Code of Canon Law of 1917, abrogated by the 1983 Code of Canon Law. Apart from that, there have never been any \"official\" guidelines issued by the Catholic Church. But from time to time the Church hierarchy, and some popes, have given opinions on various matters; although these guidelines are not binding, they are often followed. Pope Pius XII stated that women should cover their upper arms and shoulders, that their skirts should cover at least as far as the knee, and the neckline should not reveal anything. Giuseppe Cardinal Siri of Genoa stated that trousers were unacceptable dress for women. Many traditional Catholics have attempted to further expand on this latter standard.\n\nSome Catholics have attempted to form cohesive theories of modesty. Sometimes this is from a sociological perspective, while at other times it takes a more systematic, Thomistic approach, combined with the writings of the Church Fathers. Approaches arguing primarily from traditional practices and traditional authorities, such as the Saints, can also be found.\n\nAround 1913, it became fashionable for dresses to be worn with a modest round or V-shaped neckline. In the German Empire, for example, all Roman Catholic bishops joined in issuing a pastoral letter attacking the new fashions.\n\nThe Catholic Legion of Decency has been active from 1933 in monitoring morally objectionable content in films. It has condemned a number of films including several on account of the clothing worn. For example, the Legion has condemned the display of cleavage in \"The Outlaw\" (1941) and in \"The French Line\" (1954).\n\nMethodists belonging to the conservative holiness movement, such as the Allegheny Wesleyan Methodist Connection and Evangelical Wesleyan Church, have guidelines on modest apparel, in accordance with the Wesleyan-Arminian doctrine of outward holiness. The 2015 \"Discipline of the Evangelical Wesleyan Church\", for example, states:\nConservative Friends and Holiness-Orthodox Friends, two associations of Quaker Christians, wear plain dress as part of their testimony of simplicity. \n\nThe Church of Jesus Christ of Latter-day Saints (LDS Church) has issued official statements on modest dress for its members. Clothing such as \"short shorts and short skirts, shirts that do not cover the stomach, and clothing that does not cover the shoulders or is low-cut in the front or the back\" are discouraged. Men and women are also encouraged to avoid extremes in clothing or hairstyles. Rules on modesty also include women being asked to wear no more than one pair of earrings. Women are generally expected to wear skirts or dresses for church services. Most LDS members do not wear sleeveless shirts or shorts that do not reach the knee.\n\nThe church-funded university, Brigham Young University (BYU), requires students and tenants of BYU housing to sign an agreement to live according to these standards of modesty.\n\nThe premise and concepts of modesty have evolved under Hinduism. During Vedic times, both women and men wore at least two pieces of draped dress that was largely undifferentiated, voluntary and flexible. Stitched clothes such as skirts and bodices were also common in the Vedic period. However, modesty was not determined by the precepts of religion, but by local traditions, social codes, profession, circumstances and occasion. The multiple pieces of draped dress for women evolved into a single length of draped cloth among Indian Hindus, now called sari; but remained two or more pieces in Southeast Asian Hindus. For men, the draped dress reduced to one piece now called by various names such as dhoti, \"lungi\", \"pancha\", \"laacha\" and other names among Indian Hindus, and \"kamben\" among Balinese Hindu.\n\nThe Hindu belief, suggests Christopher Bayly, is that modesty through appropriate dress has the energy to transmit spirit and substance in a social discourse, the dress serves as a means of expression or celebration, with some dressing elements such as saffron threads or white dress worn by men as moral, transformative and a means to identify and communicate one’s social role in a gathering, or one's state of life such as mourning in days or weeks after the passing away of a loved one.\n\nThe canons of modesty for Hindus in South Asia underwent significant changes with the arrival of Islam in the 12th century. The Islamic rulers imposed a dress code in public places for Hindu dhimmis, per their Islamic mores of modesty. The \"sari\" worn by Hindu women extended to provide a veil, as well as a complete cover of her navel and legs. In the early 18th century, Tryambakayajvan—a court official in south central India—issued an edict called \"Stridharmapaddhati\". The ruling outlined required dress code for orthodox Hindus in that region. \"Stridharmapaddhati\" laced social trends with Hindu religion to place new rules on modesty for women, but gave much freedom to men.\n\nThe concept of modesty evolved again during colonial times when the British administration required Indians to wear dresses to help identify and segregate the local native populations. Bernard Cohn, and others remark that dress during colonial era became part of a wider issue in India about respect, honor and modesty, with the dress code intentionally aimed by the administration to reflect the nature of relationship between the British ruler and the Indian ruled. The British colonial empire, encouraged and sometimes required Indians to dress in an 'oriental manner', to help define and enforce a sense of modesty, identify roles and a person's relative social status. Among Indonesian Hindus, the accepted practice of toplessness among teenage Hindu girls changed during the Dutch colonial rule, with women now wearing a blouse or colorful cloth.\n\nInside most Hindu temples, there is an expectation of modesty rather than sexual allurement. Men and women typically wear traditional dress during religious ceremonies and rituals in a temple, with women wearing \"sari\" or regional Indian dress. In Indonesia and Cambodia, Hindu temple visitors are often requested to wrap their waist with traditional single piece cloth called \"kamben\", \"wastra\" or \"sarung\", with or without \"saput\".\n\nHindus have diverse views on modesty, with significant regional and local variations. Among orthodox Hindu populations, sexually revealing dress or any sexual behavior in public or before strangers is considered immodest, particularly in rural areas. In contrast, the dress of deities and other symbolism in Hindu temples, the discussion of dress and eroticism in ancient Hindu literature, and art works of Hinduism can be explicit, celebrating eroticism and human sexuality.\n\nIn general, a disregard of modesty can be confusing or distressing, in particular to traditional Hindu women. Even in health care context, some Hindu women may express reluctance to undress for examination. If undressing is necessary, the patient may prefer to be treated by a doctor or nurse of the same sex.\n\nIslam has strongly emphasized the concept of decency and modesty. In many authentic hadiths, it has been quoted that \"modesty is a part of faith\". Modesty is verily required in the interaction between members of the opposite sex and in some case between the members of same sex also. Dress code is part of that overall teaching.\n\n\"And tell the believing women to cast down their glances and guard their private parts and not expose their adornment except that which [necessarily] appears thereof and to wrap [a portion of] their headcovers over their chests and not expose their adornment except to their husbands, their fathers, their husbands' fathers, their sons, their husbands' sons, their brothers, their brothers' sons, their sisters' sons, their women, that which their right hands possess, or those male attendants having no physical desire, or children who are not yet aware of the private aspects of women.\" -Quran 24:31.\n\n“O Prophet! Say to your wives, your daughters, and the women of the believers that: they should let down upon themselves their jalabib.” -Quran 33:59. Jalabib is an Arabic word meaning \"loose outer garment\".\n\nIn some Muslim societies, women wear the niqab, a veil that covers the whole face except the eyes, or the full burqa, a full-body covering garment that occasionally does cover the eyes. Wearing these garments is common in some, but not all, countries with a predominantly Muslim population.\nThough by some scholars these expressions of modesty are interpreted as mandatory, most countries do not enforce modesty by law. However, a few countries, such as Saudi Arabia, Afghanistan and Iran, enforce specified standards of dress for women.\n\n\"Tell the believing men to cast down their glances and guard their private parts. That is purer for them. Indeed, Allah is [well] acquainted with what they do.\" -Quran 24:30\n\nMost scholars agree that men are required to cover everything from the navel to the knees; some men choose also to wear the traditional Islamic cap (taqiyah), similar to but larger than the Jewish yarmulke or kippah. The taqiyah may vary in shape, size and color, with differences according to tradition, region, and personal taste.\n\nModesty in Judaism, called Tzniut (), is important beyond aspects of clothing. It extends to behaviour in public and in private, and depends on the context.\n\nOrthodox and ultra-Orthodox Jewish women usually wear skirts to their knees, with blouses covering the collarbone and sleeves coming to or covering elbows. See-through materials may not be used and clothes are expected not to be tight-fitting, provocative, loud in color, or display texts. These rules are relaxed to allow for color and text in less strict communities. Some modern Orthodox communities allow the collarbone to be shown (so long as cleavage is amply covered), and sleeves not to reach the elbow. There are many different opinions on these issues. Some communities apply these standards to girls as young as three. Less strict Conservative Judaism recommends modest dress, but this is not broadly observed. Less restrictive branches of Judaism tend to adopt the fashions of the society in which they live.\n\nIt is the custom for an observant married Orthodox Jewish woman to cover her hair in public, and sometimes at home. The hair covering may be a scarf, hat, snood called a Tichel, or a wig called a Sheitel.\n\nWomen who do not follow all the regulations in everyday life, often do so during religious observances in a synagogue or elsewhere.\n\nStandards of modesty also apply to men. While some men will wear shorts and short-sleeve shirts, however strictly orthodox men will not. More modern Orthodox Jewish Men will be more lax in their dress when surrounded by other men (if it is not in a religious environment). Modesty for men most often translates to covering the torso and legs with loose clothing. Different groups of Orthodox Jews have different dress norms. But most have men dress in black suits, white dress shirts, and a Black hat (along with religious clothing).\n\nSome individuals adopt modesty standards of other groups or standards of previous generations. An example includes the Noahides who follow Jewish laws but are not themselves Jewish.\n\nStandards of modesty in art have varied at different times and in different places. Nudity and various types of behavior were sometimes depicted, sometime not. In many cases where society did not allow nudity or immodest dress, nudity was accepted in art. Where nudity in art was not acceptable, full nudity was not displayed; otherwise nude subjects had their intimate parts hidden by apparently accidental draped fabric, flowers, other people, a fig leaf, etc. In films, very brief nudity was accepted. Some nude artworks had fig leaves added when standards became less permissive.\n\nIn a given society, the criteria varied according to the circumstances; for example artworks on public display were more restrained than those for private display to adults.\n\nNudity in art was sometimes suggested without actual depiction by:\n\nIn cartoons, even in cases where the genital area is not covered with clothing, genitals are often simply not drawn, as is the case in Family Guy and other animated sitcoms. In the film \"Barnyard\", showing anthropomorphized cattle of both sexes walking on two legs, instead of either showing genitals of male cattle or not showing them, the concept of a \"male cow\" was used, with an udder. In \"Underdog\" a partly animated anthropomorphized dog is shown with penis when a real dog is filmed, and without penis in the animated parts.\n\nPaintings are sometimes changed because of changed modesty standards, and later sometimes changed back. During the Counter-Reformation there was a \"fig-leaf campaign\" aiming to cover all representations of human genitals in paintings and sculptures that started with Michelangelo's works. Works covered in this way include the marble statue of \"Cristo della Minerva\" (church of Santa Maria sopra Minerva, Rome) which was covered by added drapery, as it remains today, and the statue of the naked child Jesus in \"Madonna of Bruges\" (The Church of Our Lady in Bruges, Belgium) remained covered for several decades. Also, the plaster copy of the David in the Cast Courts (Victoria and Albert Museum) in London, has a fig leaf in a box at the back of the statue. It was there to be placed over the statue's genitals so that they would not upset visiting female royalty. The statue of Achilles at Hyde Park Corner now has an incongruous figleaf permanently attached, after it was stolen several times. \nMany fairytales and other related media feature women from or ethnic origin from Western Europe and Northern Europe to be demure due to their typically soft features. Famous examples include Snow White, Cinderella, Sleeping Beauty, Beauty and the Beast, Little Red Riding Hood, Wendy Darling from Peter Pan, Maid Marian from Robin Hood, Christine Daaé from The Phantom of the Opera, Ophelia from Hamlet, and Dorothy Gale from The Wonderful Wizard of Oz.\n\n"}
{"id": "1003628", "url": "https://en.wikipedia.org/wiki?curid=1003628", "title": "Mutants in fiction", "text": "Mutants in fiction\n\nThe concept of a mutant is a common trope in comic books and science fiction. The new phenotypes that appear in fictional mutations generally go far beyond what is typically seen in biological mutants and often result in the mutated life form exhibiting superhuman abilities or qualities.\n\nIn Marvel Comics, genetic mutation has been used as an explanation for super-powers since the 1950s. Mutants have played a major role in Marvel Comics, particularly the X-Men and related series. In the Marvel Comics universe, they are a heavily persecuted minority where most people fear and hate them. The Marvel Universe redefines the term to beings who are in a higher stage of evolution known as \"Homo superior\" and are not yet accepted by the human race.\n\n\n\n\n"}
{"id": "30418359", "url": "https://en.wikipedia.org/wiki?curid=30418359", "title": "Narcissistic abuse", "text": "Narcissistic abuse\n\nParental narcissistic abuse is where parents require the child to give up their own wants and feelings in order to serve the parent's needs for esteem. \nThe term emerged in the late twentieth century due to the works of Alice Miller and other Neo-Freudians, rejecting psychoanalysis as being similar to the poisonous pedagogies.\n\nSelf-help culture assumes that someone abused by narcissistic parenting as a child likely struggles with codependency issues in adulthood. An adult who is or has been in a relationship with a narcissist likely struggles with not knowing what constitutes a \"normal\" relationship.\n\nNarcissistic abuse was originally just defined as a specific form of emotional abuse of children by narcissistic parents. In recent years the term has been applied more broadly to refer to any abuse by a narcissist, in particular adult-to-adult relationships – adult-to-adult narcissistic abuse.\n\nThe roots of current concern with narcissistic abuse may be traced back to the later work of Sándor Ferenczi. In Ferenczi's fervid, restless, and inchoate attempts to help people over whom other analysts had thrown up their hands in despair lie the seeds of all the modern psychoanalytic theories of \"schizoid,\" \"narcissistic,\" and \"borderline\" personality disorders.\nIn his seminal paper \"Confusion of Tongues Between Adults and the Child\", Ferenczi observed that patients often displayed \"a striking, almost helpless compliance and willingness to accept my interpretations\" even if he encouraged them not to agree with him. Ferenczi traced his patient's behavior to childhood trauma. He found that in cases of sexual abuse, children often misinterpreted the emotional responses of adults and responded to them by becoming passive toward the adult. The child developed an \"anxiety-fear-ridden identification\" with the adult, as well as \"introjection of the guilt feelings of the adult\": \"The same anxiety, however, if it reaches a certain maximum, compels them to subordinate themselves like automata to the will of the aggressor, to divine each one of his desires and to gratify these; completely oblivious of themselves they identify themselves with the aggressor.\" Ferenczi also argued that a child's tender love for a caretaker often involves a fantasy of \"taking the role of mother to the adult\". In what he identified as the \"terrorism of suffering\", the child has a \"compulsion\" to right the wrongs of the family by taking on responsibilities that are far beyond the child's maturity level. In this manner, \"a mother complaining of her constant miseries can create a nurse for life out of her child, i.e. a real mother substitute, neglecting the true interests of the child.\" Within such distorted patterns of parent/child interaction, 'Ferenczi believed the silence, lies, and hypocrisy of the caregivers were the most traumatic aspects of the abuse'—ultimately producing what he called 'narcissistic mortification'.\n\nFerenczi also looked at such distortions in the therapist/patient relationship, accusing himself of sadistic (and, implicitly, narcissistic) abuse of his patients.\n\nA half-century later, in the wake of Kohut's innovative pronouncement that the age of \"normal narcissism\" and normal narcissistic entitlement had arrived – the age, that is, of the normative parental provision of narcissistic supply – the concept of its inverse appeared: narcissistic abuse. According to Kohut, maternal misrecognition amounts to a failure to perform the narcissistic \"selfobject\" functions of \"mirroring\"...the cause of a narcissistic disturbance. Paternal misrecognition could produce the same result: Kohut explored for example a son's transference reproaches directed at the non mirroring father who was preoccupied with his own self-enhancement and thus refused to respond to his son's originality.\nKaren Horney had already independently highlighted the character disorder – particularly the compulsive striving for love and power – resulting from the childhood hurts bred of parental narcissism and abuse. She thus heralded today's work in this area by Alice Miller and others.\n\nAlice Miller lays special emphasis on the process of reproduction of narcissistic abuse, the idea that love relations and relations to children are repetitions of previous narcissistic distortions. Miller's early work in particular was very much in line with Kohut's tale of deficits in empathy and mirroring, with a stress on the way adults revisit and perpetuate the narcissistic wounds of their own early years in an intergenerational cycle of narcissistic abuse. In Miller's view, when abused for the sake of adults' needs, children could develop an amazing ability to perceive and respond intuitively, that is, unconsciously, to this need of the mother, or of both parents, for him to take on the role that had unconsciously been assigned to him.\n\nMiller's work, in its emphasis on the real-life interaction of parent and child, challenged the orthodox Freudian account of Oedipal fantasy, in a sustained indictment of the moral and pedagogical underpinnings of the therapy industry; and did so at a point when 'the keyword of the 1980s was invariably \"abuse\".\n\nWith the passing of time (and of the polemical edge), a more slimmed-down, pragmatic version of the concept of narcissistic abuse gradually came to permeate most of the wider culture of psychotherapy.\n\n\nOnly in the Freudian heartland of mainstream psychoanalysis has the term retained a more restricted, pre-Ferenczi usage. Thus in a \"comprehensive dictionary of psychoanalysis\" of 2009, the only appearance of the term is in connection with misuse of the couch for narcissistic gain: The fact that it is seen by some patients and therapists as a \"status symbol\" lends it to narcissistic abuse.\n\nNarcissistic abuse may also occur in adult-to-adult relationships, where the narcissistic person tends to seek out an empathetic partner in order to gain admiration of their own attributes and feelings of power and control – narcissistic supply. The narcissist creates a dynamic abuser and victim relationship through a cycle of abuse resulting in traumatic bonding that makes it hard for their partner to leave the increasingly abusive relationship.\n\nPeople with codependent-type traits may seek relationships with narcissists.\n\nThe narcissists' relationships are characterized by a period of intense involvement and idealization of their partner, followed by devaluation, and a rapid discarding of the partner. Alternatively, that scenario can loop, with ghosting (ceasing communication with the codependent) and hoovering (luring the codependent back) instead of discarding. At the beginning of a relationship (or its new cycle) with a narcissist, the partner is only shown the ideal self of the narcissist, which includes pseudo-empathy, kindness, and charm. Once the partner has committed to the relationship (e.g., through marriage or a business partnership), the true self of the narcissist will begin to emerge. The initial narcissistic abuse begins with belittling comments and grows to contempt, ignoring behavior, adultery, triangulation (forming any relationship triangles), sabotage, and, at times, physical abuse. \n\nAt the core of a narcissist is a combination of entitlement and low self-esteem. These feelings of inadequacy are projected onto the victim. If the narcissistic person is feeling unattractive they will belittle their romantic partner's appearance. If the narcissist makes an error, this error becomes the partner's fault. Narcissists also engage in insidious, manipulative abuse by giving subtle hints and comments that result in the victim questioning their own behavior and thoughts. This is termed gaslighting. Another common abusive tactic is underhanded public humiliation, when the narcissist says something seemingly neutral but offensive to the victim and enjoys the emotional reaction. This is called dog-whistling. Any slight criticism of the narcissist, whether actual or perceived, often triggers narcissistic rage and full-blown annihilation from the narcissistic person. This can take the form of screaming tirades, silent treatment or quiet sabotage (setting traps, refusing communication, hiding belongings, spreading rumors, etc.). \n\nThe discard phase can be swift and occurs once the narcissistic supply is obtained elsewhere. In romantic relationships, the narcissistic supply can be acquired by having affairs. The new partner is in the idealization phase and only witnesses the ideal self; thus once again the cycle of narcissistic abuse begins. Narcissists do not take responsibility for relationship difficulties and exhibit no feelings of remorse. Instead they believe themselves to be the victim in the relationship as because of their self-debasing projections, their partner can only ever fail to meet their expectations.\n\n"}
{"id": "23053", "url": "https://en.wikipedia.org/wiki?curid=23053", "title": "Periodic table", "text": "Periodic table\n\nThe periodic table, or periodic table of elements, is a tabular arrangement of the chemical elements, ordered by their atomic number, electron configuration, and recurring chemical properties, whose structure shows \"periodic trends\". Generally, within one row (period) the elements are metals to the left, and non-metals to the right, with the elements having similar chemical behaviours placed in the same column. Table rows are commonly called periods and columns are called groups. Six groups have accepted names as well as assigned numbers: for example, group 17 elements are the halogens; and group 18 are the noble gases. Also displayed are four simple rectangular areas or blocks associated with the filling of different atomic orbitals.\n\nThe organization of the periodic table can be used to derive relationships between the various element properties, but also the predicted chemical properties and behaviours of undiscovered or newly synthesized elements. Russian chemist Dmitri Mendeleev was the first to publish a recognizable periodic table in 1869, developed mainly to illustrate periodic trends of the then-known elements. He also predicted some properties of unidentified elements that were expected to fill gaps within the table. Most of his forecasts proved to be correct. Mendeleev's idea has been slowly expanded and refined with the discovery or synthesis of further new elements and the development of new theoretical models to explain chemical behaviour. The modern periodic table now provides a useful framework for analyzing chemical reactions, and continues to be widely used in chemistry, nuclear physics and other sciences.\n\nAll the elements from atomic numbers 1 (hydrogen) through 118 (oganesson) have been either discovered or synthesized, completing the first seven rows of the periodic table. The first 98 elements exist in nature, although some are found only in trace amounts and others were synthesized in laboratories before being found in nature. Elements 99 to 118 have only been synthesized in laboratories or nuclear reactors. The synthesis of elements having higher atomic numbers is currently being pursued: these elements would begin an eighth row, and theoretical work has been done to suggest possible candidates for this extension. Numerous synthetic radionuclides of naturally occurring elements have also been produced in laboratories.\n\nEach chemical element has a unique atomic number (\"Z\") representing the number of protons in its nucleus. Most elements have differing numbers of neutrons among different atoms, with these variants being referred to as isotopes. For example, carbon has three naturally occurring isotopes: all of its atoms have six protons and most have six neutrons as well, but about one per cent have seven neutrons, and a very small fraction have eight neutrons. Isotopes are never separated in the periodic table; they are always grouped together under a single element. Elements with no stable isotopes have the atomic masses of their most stable isotopes, where such masses are shown, listed in parentheses.\n\nIn the standard periodic table, the elements are listed in order of increasing atomic number \"Z\" (the number of protons in the nucleus of an atom). A new row (\"period\") is started when a new electron shell has its first electron. Columns (\"groups\") are determined by the electron configuration of the atom; elements with the same number of electrons in a particular subshell fall into the same columns (e.g. oxygen and selenium are in the same column because they both have four electrons in the outermost p-subshell). Elements with similar chemical properties generally fall into the same group in the periodic table, although in the f-block, and to some respect in the d-block, the elements in the same period tend to have similar properties, as well. Thus, it is relatively easy to predict the chemical properties of an element if one knows the properties of the elements around it.\n\n, the periodic table has 118 confirmed elements, from element 1 (hydrogen) to 118 (oganesson). Elements 113, 115, 117 and 118, the most recent discoveries, were officially confirmed by the International Union of Pure and Applied Chemistry (IUPAC) in December 2015. Their proposed names, nihonium (Nh), moscovium (Mc), tennessine (Ts) and oganesson (Og) respectively, were announced by the IUPAC in June 2016 and made official in November 2016.\n\nThe first 94 elements occur naturally; the remaining 24, americium to oganesson (95–118), occur only when synthesized in laboratories. Of the 94 naturally occurring elements, 83 are primordial and 11 occur only in decay chains of primordial elements. No element heavier than einsteinium (element 99) has ever been observed in macroscopic quantities in its pure form, nor has astatine (element 85); francium (element 87) has been only photographed in the form of light emitted from microscopic quantities (300,000 atoms).\n\nA \"group\" or \"family\" is a vertical column in the periodic table. Groups usually have more significant periodic trends than periods and blocks, explained below. Modern quantum mechanical theories of atomic structure explain group trends by proposing that elements within the same group generally have the same electron configurations in their valence shell. Consequently, elements in the same group tend to have a shared chemistry and exhibit a clear trend in properties with increasing atomic number. In some parts of the periodic table, such as the d-block and the f-block, horizontal similarities can be as important as, or more pronounced than, vertical similarities.\n\nUnder an international naming convention, the groups are numbered numerically from 1 to 18 from the leftmost column (the alkali metals) to the rightmost column (the noble gases). Previously, they were known by roman numerals. In America, the roman numerals were followed by either an \"A\" if the group was in the s- or p-block, or a \"B\" if the group was in the d-block. The roman numerals used correspond to the last digit of today's naming convention (e.g. the group 4 elements were group IVB, and the group 14 elements were group IVA). In Europe, the lettering was similar, except that \"A\" was used if the group was before group 10, and \"B\" was used for groups including and after group 10. In addition, groups 8, 9 and 10 used to be treated as one triple-sized group, known collectively in both notations as group VIII. In 1988, the new IUPAC naming system was put into use, and the old group names were deprecated.\n\nSome of these groups have been given trivial (unsystematic) names, as seen in the table below, although some are rarely used. Groups 3–10 have no trivial names and are referred to simply by their group numbers or by the name of the first member of their group (such as \"the scandium group\" for group 3), since they display fewer similarities and/or vertical trends.\n\nElements in the same group tend to show patterns in atomic radius, ionization energy, and electronegativity. From top to bottom in a group, the atomic radii of the elements increase. Since there are more filled energy levels, valence electrons are found farther from the nucleus. From the top, each successive element has a lower ionization energy because it is easier to remove an electron since the atoms are less tightly bound. Similarly, a group has a top-to-bottom decrease in electronegativity due to an increasing distance between valence electrons and the nucleus. There are exceptions to these trends: for example, in group 11, electronegativity increases farther down the group.\n\nA \"period\" is a horizontal row in the periodic table. Although groups generally have more significant periodic trends, there are regions where horizontal trends are more significant than vertical group trends, such as the f-block, where the lanthanides and actinides form two substantial horizontal series of elements.\n\nElements in the same period show trends in atomic radius, ionization energy, electron affinity, and electronegativity. Moving left to right across a period, atomic radius usually decreases. This occurs because each successive element has an added proton and electron, which causes the electron to be drawn closer to the nucleus. This decrease in atomic radius also causes the ionization energy to increase when moving from left to right across a period. The more tightly bound an element is, the more energy is required to remove an electron. Electronegativity increases in the same manner as ionization energy because of the pull exerted on the electrons by the nucleus. Electron affinity also shows a slight trend across a period. Metals (left side of a period) generally have a lower electron affinity than nonmetals (right side of a period), with the exception of the noble gases.\n\nSpecific regions of the periodic table can be referred to as \"blocks\" in recognition of the sequence in which the electron shells of the elements are filled. Each block is named according to the subshell in which the \"last\" electron notionally resides. The s-block comprises the first two groups (alkali metals and alkaline earth metals) as well as hydrogen and helium. The p-block comprises the last six groups, which are groups 13 to 18 in IUPAC group numbering (3A to 8A in American group numbering) and contains, among other elements, all of the metalloids. The d-block comprises groups 3 to 12 (or 3B to 2B in American group numbering) and contains all of the transition metals. The f-block, often offset below the rest of the periodic table, has no group numbers and comprises lanthanides and actinides.\n\nAccording to their shared physical and chemical properties, the elements can be classified into the major categories of metals, metalloids and nonmetals. Metals are generally shiny, highly conducting solids that form alloys with one another and salt-like ionic compounds with nonmetals (other than noble gases). A majority of nonmetals are coloured or colourless insulating gases; nonmetals that form compounds with other nonmetals feature covalent bonding. In between metals and nonmetals are metalloids, which have intermediate or mixed properties.\n\nMetal and nonmetals can be further classified into subcategories that show a gradation from metallic to non-metallic properties, when going left to right in the rows. The metals may be subdivided into the highly reactive alkali metals, through the less reactive alkaline earth metals, lanthanides and actinides, via the archetypal transition metals, and ending in the physically and chemically weak post-transition metals. Nonmetals may be simply subdivided into the polyatomic nonmetals, being nearer to the metalloids and show some incipient metallic character; the essentially nonmetallic diatomic nonmetals, nonmetallic and the almost completely inert, monatomic noble gases. Specialized groupings such as refractory metals and noble metals, are examples of subsets of transition metals, also known and occasionally denoted.\n\nPlacing elements into categories and subcategories based just on shared properties is imperfect. There is a large disparity of properties within each category with notable overlaps at the boundaries, as is the case with most classification schemes. Beryllium, for example, is classified as an alkaline earth metal although its amphoteric chemistry and tendency to mostly form covalent compounds are both attributes of a chemically weak or post-transition metal. Radon is classified as a nonmetallic noble gas yet has some cationic chemistry that is characteristic of metals. Other classification schemes are possible such as the division of the elements into mineralogical occurrence categories, or crystalline structures. Categorizing the elements in this fashion dates back to at least 1869 when Hinrichs wrote that simple boundary lines could be placed on the periodic table to show elements having shared properties, such as metals, nonmetals, or gaseous elements.\n\nThe electron configuration or organisation of electrons orbiting neutral atoms shows a recurring pattern or periodicity. The electrons occupy a series of electron shells (numbered 1, 2, and so on). Each shell consists of one or more subshells (named s, p, d, f and g). As atomic number increases, electrons progressively fill these shells and subshells more or less according to the Madelung rule or energy ordering rule, as shown in the diagram. The electron configuration for neon, for example, is 1s 2s 2p. With an atomic number of ten, neon has two electrons in the first shell, and eight electrons in the second shell; there are two electrons in the s subshell and six in the p subshell. In periodic table terms, the first time an electron occupies a new shell corresponds to the start of each new period, these positions being occupied by hydrogen and the alkali metals.\n\nSince the properties of an element are mostly determined by its electron configuration, the properties of the elements likewise show recurring patterns or periodic behaviour, some examples of which are shown in the diagrams below for atomic radii, ionization energy and electron affinity. It is this periodicity of properties, manifestations of which were noticed well before the underlying theory was developed, that led to the establishment of the periodic law (the properties of the elements recur at varying intervals) and the formulation of the first periodic tables.\n\nAtomic radii vary in a predictable and explainable manner across the periodic table. For instance, the radii generally decrease along each period of the table, from the alkali metals to the noble gases; and increase down each group. The radius increases sharply between the noble gas at the end of each period and the alkali metal at the beginning of the next period. These trends of the atomic radii (and of various other chemical and physical properties of the elements) can be explained by the electron shell theory of the atom; they provided important evidence for the development and confirmation of quantum theory.\n\nThe electrons in the 4f-subshell, which is progressively filled across the lanthanide series, are not particularly effective at shielding the increasing nuclear charge from the sub-shells further out. The elements immediately following the lanthanides have atomic radii that are smaller than would be expected and that are almost identical to the atomic radii of the elements immediately above them. Hence hafnium has virtually the same atomic radius (and chemistry) as zirconium, and tantalum has an atomic radius similar to niobium, and so forth. This is known as the lanthanide contraction. The effect of the lanthanide contraction is noticeable up to platinum (element 78), after which it is masked by a relativistic effect known as the inert pair effect. The d-block contraction, which is a similar effect between the d-block and p-block, is less pronounced than the lanthanide contraction but arises from a similar cause.\n\nThe first ionization energy is the energy it takes to remove one electron from an atom, the second ionization energy is the energy it takes to remove a second electron from the atom, and so on. For a given atom, successive ionization energies increase with the degree of ionization. For magnesium as an example, the first ionization energy is 738 kJ/mol and the second is 1450 kJ/mol. Electrons in the closer orbitals experience greater forces of electrostatic attraction; thus, their removal requires increasingly more energy. Ionization energy becomes greater up and to the right of the periodic table.\n\nLarge jumps in the successive molar ionization energies occur when removing an electron from a noble gas (complete electron shell) configuration. For magnesium again, the first two molar ionization energies of magnesium given above correspond to removing the two 3s electrons, and the third ionization energy is a much larger 7730 kJ/mol, for the removal of a 2p electron from the very stable neon-like configuration of Mg. Similar jumps occur in the ionization energies of other third-row atoms.\n\nElectronegativity is the tendency of an atom to attract a shared pair of electrons. An atom's electronegativity is affected by both its atomic number and the distance between the valence electrons and the nucleus. The higher its electronegativity, the more an element attracts electrons. It was first proposed by Linus Pauling in 1932. In general, electronegativity increases on passing from left to right along a period, and decreases on descending a group. Hence, fluorine is the most electronegative of the elements, while caesium is the least, at least of those elements for which substantial data is available.\n\nThere are some exceptions to this general rule. Gallium and germanium have higher electronegativities than aluminium and silicon respectively because of the d-block contraction. Elements of the fourth period immediately after the first row of the transition metals have unusually small atomic radii because the 3d-electrons are not effective at shielding the increased nuclear charge, and smaller atomic size correlates with higher electronegativity. The anomalously high electronegativity of lead, particularly when compared to thallium and bismuth, appears to be an artifact of data selection and data availability. Methods of calculation other than the Pauling method show the normal periodic trends for these elements.\n\nThe electron affinity of an atom is the amount of energy released when an electron is added to a neutral atom to form a negative ion. Although electron affinity varies greatly, some patterns emerge. Generally, nonmetals have more positive electron affinity values than metals. Chlorine most strongly attracts an extra electron. The electron affinities of the noble gases have not been measured conclusively, so they may or may not have slightly negative values.\n\nElectron affinity generally increases across a period. This is caused by the filling of the valence shell of the atom; a group 17 atom releases more energy than a group 1 atom on gaining an electron because it obtains a filled valence shell and is therefore more stable.\n\nA trend of decreasing electron affinity going down groups would be expected. The additional electron will be entering an orbital farther away from the nucleus. As such this electron would be less attracted to the nucleus and would release less energy when added. In going down a group, around one-third of elements are anomalous, with heavier elements having higher electron affinities than their next lighter congenors. Largely, this is due to the poor shielding by d and f electrons. A uniform decrease in electron affinity only applies to group 1 atoms.\n\nThe lower the values of ionization energy, electronegativity and electron affinity, the more metallic character the element has. Conversely, nonmetallic character increases with higher values of these properties. Given the periodic trends of these three properties, metallic character tends to decrease going across a period (or row) and, with some irregularities (mostly) due to poor screening of the nucleus by d and f electrons, and relativistic effects, tends to increase going down a group (or column or family). Thus, the most metallic elements (such as caesium and francium) are found at the bottom left of traditional periodic tables and the most nonmetallic elements (oxygen, fluorine, chlorine) at the top right. The combination of horizontal and vertical trends in metallic character explains the stair-shaped dividing line between metals and nonmetals found on some periodic tables, and the practice of sometimes categorizing several elements adjacent to that line, or elements adjacent to those elements, as metalloids.\n\nFrom left to right across the four blocks of the long- or 32-column form of the periodic table are a series of linking or bridging groups of elements, located approximately between each block. These groups, like the metalloids, show properties in between, or that are a mixture of, groups to either side. Chemically, the group 3 elements, scandium, yttrium, lanthanum and actinium behave largely like the alkaline earth metals or, more generally, \"s\" block metals but have some of the physical properties of \"d\" block transition metals. Lutetium and lawrencium, at the end of the end of the \"f\" block, may constitute another linking or bridging group. Lutetium behaves chemically as a lanthanide but shows a mix of lanthanide and transition metal physical properties. Lawrencium, as an analogue of lutetium, would presumably display like characteristics. The coinage metals in group 11 (copper, silver, and gold) are chemically capable of acting as either transition metals or main group metals. The volatile group 12 metals, zinc, cadmium and mercury are sometimes regarded as linking the \"d\" block to the \"p\" block. Notionally they are \"d\" block elements but they have few transition metal properties and are more like their \"p\" block neighbors in group 13. The relatively inert noble gases, in group 18, bridge the most reactive groups of elements in the periodic table—the halogens in group 17 and the alkali metals in group 1.\n\nIn 1789, Antoine Lavoisier published a list of 33 chemical elements, grouping them into gases, metals, nonmetals, and earths. Chemists spent the following century searching for a more precise classification scheme. In 1829, Johann Wolfgang Döbereiner observed that many of the elements could be grouped into triads based on their chemical properties. Lithium, sodium, and potassium, for example, were grouped together in a triad as soft, reactive metals. Döbereiner also observed that, when arranged by atomic weight, the second member of each triad was roughly the average of the first and the third; this became known as the Law of Triads. German chemist Leopold Gmelin worked with this system, and by 1843 he had identified ten triads, three groups of four, and one group of five. Jean-Baptiste Dumas published work in 1857 describing relationships between various groups of metals. Although various chemists were able to identify relationships between small groups of elements, they had yet to build one scheme that encompassed them all.\n\nIn 1857, German chemist August Kekulé observed that carbon often has four other atoms bonded to it. Methane, for example, has one carbon atom and four hydrogen atoms. This concept eventually became known as valency; different elements bond with different numbers of atoms.\n\nIn 1862, Alexandre-Emile Béguyer de Chancourtois, a French geologist, published an early form of periodic table, which he called the telluric helix or screw. He was the first person to notice the periodicity of the elements. With the elements arranged in a spiral on a cylinder by order of increasing atomic weight, de Chancourtois showed that elements with similar properties seemed to occur at regular intervals. His chart included some ions and compounds in addition to elements. His paper also used geological rather than chemical terms and did not include a diagram; as a result, it received little attention until the work of Dmitri Mendeleev.\n\nIn 1864, Julius Lothar Meyer, a German chemist, published a table with 44 elements arranged by valency. The table showed that elements with similar properties often shared the same valency. Concurrently, English chemist William Odling published an arrangement of 57 elements, ordered on the basis of their atomic weights. With some irregularities and gaps, he noticed what appeared to be a periodicity of atomic weights among the elements and that this accorded with \"their usually received groupings\". Odling alluded to the idea of a periodic law but did not pursue it. He subsequently proposed (in 1870) a valence-based classification of the elements.\n\nEnglish chemist John Newlands produced a series of papers from 1863 to 1866 noting that when the elements were listed in order of increasing atomic weight, similar physical and chemical properties recurred at intervals of eight; he likened such periodicity to the octaves of music. This so termed Law of Octaves was ridiculed by Newlands' contemporaries, and the Chemical Society refused to publish his work. Newlands was nonetheless able to draft a table of the elements and used it to predict the existence of missing elements, such as germanium. The Chemical Society only acknowledged the significance of his discoveries five years after they credited Mendeleev.\n\nIn 1867, Gustavus Hinrichs, a Danish born academic chemist based in America, published a spiral periodic system based on atomic spectra and weights, and chemical similarities. His work was regarded as idiosyncratic, ostentatious and labyrinthine and this may have militated against its recognition and acceptance.\n\nRussian chemistry professor Dmitri Mendeleev and German chemist Julius Lothar Meyer independently published their periodic tables in 1869 and 1870, respectively. Mendeleev's table was his first published version; that of Meyer was an expanded version of his (Meyer's) table of 1864. They both constructed their tables by listing the elements in rows or columns in order of atomic weight and starting a new row or column when the characteristics of the elements began to repeat.\n\nThe recognition and acceptance afforded to Mendeleev's table came from two decisions he made. The first was to leave gaps in the table when it seemed that the corresponding element had not yet been discovered. Mendeleev was not the first chemist to do so, but he was the first to be recognized as using the trends in his periodic table to predict the properties of those missing elements, such as gallium and germanium. The second decision was to occasionally ignore the order suggested by the atomic weights and switch adjacent elements, such as tellurium and iodine, to better classify them into chemical families.\n\nMendeleev published in 1869, using atomic weight to organize the elements, information determinable to fair precision in his time. Atomic weight worked well enough to allow Mendeleev to accurately predict the properties of missing elements.\n\nFollowing the discovery, in 1911, by Ernest Rutherford of the atomic nucleus, it was proposed that the integer count of the nuclear charge is identical to the sequential place of each element in the periodic table. In 1913, Henry Moseley using X-ray spectroscopy confirmed this proposal experimentally. Moseley determined the value of the nuclear charge of each element, and showed that Mendeleev's ordering actually places the elements in sequential order by nuclear charge. Nuclear charge is identical to proton count, and determines the value of the atomic number (Z) of each element. Using atomic number gives a definitive, integer-based sequence for the elements. Moseley predicted, in 1913, that the only elements still missing between aluminium (Z=13) and gold (Z=79) were Z = 43, 61, 72, and 75, all of which were later discovered. The atomic number is the absolute definition of an element, and gives a factual basis for the ordering of the periodic table. The periodic table is used to predict the properties of new synthetic elements before they are produced and studied.\n\nIn 1871, Mendeleev published his periodic table in a new form, with groups of similar elements arranged in columns rather than in rows, and those columns numbered I to VIII corresponding with the element's oxidation state. He also gave detailed predictions for the properties of elements he had earlier noted were missing, but should exist. These gaps were subsequently filled as chemists discovered additional naturally occurring elements. It is often stated that the last naturally occurring element to be discovered was francium (referred to by Mendeleev as \"eka-caesium\") in 1939. Plutonium, produced synthetically in 1940, was identified in trace quantities as a naturally occurring element in 1971.\n\nThe popular periodic table layout, also known as the common or standard form (as shown at various other points in this article), is attributable to Horace Groves Deming. In 1923, Deming, an American chemist, published short (Mendeleev style) and medium (18-column) form periodic tables. Merck and Company prepared a handout form of Deming's 18-column medium table, in 1928, which was widely circulated in American schools. By the 1930s Deming's table was appearing in handbooks and encyclopaedias of chemistry. It was also distributed for many years by the Sargent-Welch Scientific Company.\n\nWith the development of modern quantum mechanical theories of electron configurations within atoms, it became apparent that each period (row) in the table corresponded to the filling of a quantum shell of electrons. Larger atoms have more electron sub-shells, so later tables have required progressively longer periods.\n\nIn 1945, Glenn Seaborg, an American scientist, made the suggestion that the actinide elements, like the lanthanides, were filling an f sub-level. Before this time the actinides were thought to be forming a fourth d-block row. Seaborg's colleagues advised him not to publish such a radical suggestion as it would most likely ruin his career. As Seaborg considered he did not then have a career to bring into disrepute, he published anyway. Seaborg's suggestion was found to be correct and he subsequently went on to win the 1951 Nobel Prize in chemistry for his work in synthesizing actinide elements.\n\nAlthough minute quantities of some transuranic elements occur naturally, they were all first discovered in laboratories. Their production has expanded the periodic table significantly, the first of these being neptunium, synthesized in 1939. Because many of the transuranic elements are highly unstable and decay quickly, they are challenging to detect and characterize when produced. There have been controversies concerning the acceptance of competing discovery claims for some elements, requiring independent review to determine which party has priority, and hence naming rights. In 2010, a joint Russia–US collaboration at Dubna, Moscow Oblast, Russia, claimed to have synthesized six atoms of tennessine (element 117), making it the most recently claimed discovery. It, along with nihonium (element 113), moscovium (element 115), and oganesson (element 118), are the four most recently named elements, whose names all became official on 28 November 2016.\n\nThe modern periodic table is sometimes expanded into its long or 32-column form by reinstating the footnoted f-block elements into their natural position between the s- and d-blocks. Unlike the 18-column form this arrangement results in \"no interruptions in the sequence of increasing atomic numbers\". The relationship of the f-block to the other blocks of the periodic table also becomes easier to see. Jensen advocates a form of table with 32 columns on the grounds that the lanthanides and actinides are otherwise relegated in the minds of students as dull, unimportant elements that can be quarantined and ignored. Despite these advantages the 32-column form is generally avoided by editors on account of its undue rectangular ratio (compared to a book page ratio), and the familiarity of chemists with the modern form (as introduced by Seaborg).\n\nWithin 100 years of the appearance of Mendeleev's table in 1869, Edward G. Mazurs had collected an estimated 700 different published versions of the periodic table. As well as numerous rectangular variations, other periodic table formats have been shaped, for example, like a circle, cube, cylinder, building, spiral, lemniscate, octagonal prism, pyramid, sphere, or triangle. Such alternatives are often developed to highlight or emphasize chemical or physical properties of the elements that are not as apparent in traditional periodic tables.\nA popular alternative structure is that of Otto Theodor Benfey (1960). The elements are arranged in a continuous spiral, with hydrogen at the centre and the transition metals, lanthanides, and actinides occupying peninsulas.\n\nMost periodic tables are two-dimensional; three-dimensional tables are known to as far back as at least 1862 (pre-dating Mendeleev's two-dimensional table of 1869). More recent examples include Courtines' Periodic Classification (1925), Wringley's Lamina System (1949),\nGiguère's Periodic helix (1965) and Dufour's Periodic Tree (1996). Going one further, Stowe's Physicist's Periodic Table (1989) has been described as being four-dimensional (having three spatial dimensions and one colour dimension).\n\nThe various forms of periodic tables can be thought of as lying on a chemistry–physics continuum. Towards the chemistry end of the continuum can be found, as an example, Rayner-Canham's \"unruly\" Inorganic Chemist's Periodic Table (2002), which emphasizes trends and patterns, and unusual chemical relationships and properties. Near the physics end of the continuum is Janet's Left-Step Periodic Table (1928). This has a structure that shows a closer connection to the order of electron-shell filling and, by association, quantum mechanics. A somewhat similar approach has been taken by Alper, albeit criticized by Eric Scerri as disregarding the need to display chemical and physical periodicity. Somewhere in the middle of the continuum is the ubiquitous common or standard form of periodic table. This is regarded as better expressing empirical trends in physical state, electrical and thermal conductivity, and oxidation numbers, and other properties easily inferred from traditional techniques of the chemical laboratory. Its popularity is thought to be a result of this layout having a good balance of features in terms of ease of construction and size, and its depiction of atomic order and periodic trends.\n\nSimply following electron configurations, hydrogen (electronic configuration 1s) and helium (1s) should be placed in groups 1 and 2, above lithium (1s2s) and beryllium (1s2s). While such a placement is common for hydrogen, it is rarely used for helium outside of the context of electron configurations: When the noble gases (then called \"inert gases\") were first discovered around 1900, they were known as \"group 0\", reflecting no chemical reactivity of these elements known at that point, and helium was placed on the top of that group, as it did share the extreme chemical inertness seen throughout the group. As the group changed its formal number, many authors continued to assign helium directly above neon, in group 18; one of the examples of such placing is the current IUPAC table.\n\nHydrogen's chemical properties are not very close to those of the alkali metals, which occupy group 1. On this basis it is sometimes placed elsewhere. A common alternative is at the top of group 17 given hydrogen's strictly univalent and largely non-metallic chemistry, and the strictly univalent and non-metallic chemistry of fluorine (the element otherwise at the top of group 17). Sometimes, to show hydrogen has properties corresponding to both those of the alkali metals and the halogens, it is shown at the top of the two columns simultaneously. Another suggestion is above carbon in group 14: placed that way, it fits well into the trends of increasing ionization potential values and electron affinity values, and is not too far from the electronegativity trend, even though hydrogen cannot show the tetravalence characteristic of the heavier group 14 elements. Finally, hydrogen is sometimes placed separately from any group; this is based on its general properties being different from those of the elements in any other group. The other period 1 element, helium, is sometimes placed separately from any group as well. The property that distinguishes helium from the rest of the noble gases (even though the extraordinary inertness of helium is extremely close to that of neon and argon) is that in its closed electron shell, helium has only two electrons in the outermost electron orbital, while the rest of the noble gases have eight.\n\nAlthough scandium and yttrium are always the first two elements in group 3, the identity of the next two elements is not completely settled. They are commonly lanthanum and actinium, and less often lutetium and lawrencium. The two variants originate from historical difficulties in placing the lanthanides in the periodic table, and arguments as to where the \"f\" block elements start and end. It has been claimed that such arguments are proof that, \"it is a mistake to break the [periodic] system into sharply delimited blocks\". A third variant shows the two positions below yttrium as being occupied by the lanthanides and the actinides.\n\nChemical and physical arguments have been made in support of lutetium and lawrencium but the majority of authors seem unconvinced. Most working chemists are not aware there is any controversy. In December 2015 an IUPAC project was established to make a recommendation on the matter.\n\nLanthanum and actinium are commonly depicted as the remaining group 3 members. It has been suggested that this layout originated in the 1940s, with the appearance of periodic tables relying on the electron configurations of the elements and the notion of the differentiating electron. The configurations of caesium, barium and lanthanum are [Xe]6s, [Xe]6s and [Xe]5d6s. Lanthanum thus has a 5d differentiating electron and this establishes it \"in group 3 as the first member of the d-block for period 6\". A consistent set of electron configurations is then seen in group 3: scandium [Ar]3d4s, yttrium [Kr]4d5s and lanthanum [Xe]5d6s. Still in period 6, ytterbium was assigned an electron configuration of [Xe]4f5d6s and lutetium [Xe]4f5d6s, \"resulting in a 4f differentiating electron for lutetium and firmly establishing it as the last member of the f-block for period 6\". Later spectroscopic work found that the electron configuration of ytterbium was in fact [Xe]4f6s. This meant that ytterbium and lutetium—the latter with [Xe]4f5d6s—both had 14 f-electrons, \"resulting in a d- rather than an f- differentiating electron\" for lutetium and making it an \"equally valid candidate\" with [Xe]5d6s lanthanum, for the group 3 periodic table position below yttrium. Lanthanum has the advantage of incumbency since the 5d electron appears for the first time in its structure whereas it appears for the third time in lutetium, having also made a brief second appearance in gadolinium.\n\nIn terms of chemical behaviour, and trends going down group 3 for properties such as melting point, electronegativity and ionic radius, scandium, yttrium, lanthanum and actinium are similar to their group 1–2 counterparts. In this variant, the number of \"f\" electrons in the most common (trivalent) ions of the f-block elements consistently matches their position in the f-block. For example, the f-electron counts for the trivalent ions of the first three f-block elements are Ce 1, Pr 2 and Nd 3.\n\nIn other tables, lutetium and lawrencium are the remaining group 3 members. Early techniques for chemically separating scandium, yttrium and lutetium relied on the fact that these elements occurred together in the so-called \"yttrium group\" whereas La and Ac occurred together in the \"cerium group\". Accordingly, lutetium rather than lanthanum was assigned to group 3 by some chemists in the 1920s and 30s. Several physicists in the 1950s and '60s favoured lutetium, in light of a comparison of several of its physical properties with those of lanthanum. This arrangement, in which lanthanum is the first member of the f-block, is disputed by some authors since lanthanum lacks any f-electrons. It has been argued that this is not valid concern given other periodic table anomalies—thorium, for example, has no f-electrons yet is part of the f-block. As for lawrencium, its gas phase atomic electron configuration was confirmed in 2015 as [Rn]5f7s7p. Such a configuration represents another periodic table anomaly, regardless of whether lawrencium is located in the f-block or the d-block, as the only potentially applicable p-block position has been reserved for nihonium with its predicted configuration of [Rn]5f6d7s7p.\n\nChemically, scandium, yttrium and lutetium (and presumably lawrencium) behave like trivalent versions of the group 1–2 metals. On the other hand, trends going down the group for properties such as melting point, electronegativity and ionic radius, are similar to those found among their group 4–8 counterparts. In this variant, the number of \"f\" electrons in the gaseous forms of the f-block atoms usually matches their position in the f-block. For example, the f-electron counts for the first five f-block elements are La 0, Ce 1, Pr 3, Nd 4 and Pm 5.\n\nA few authors position all thirty lanthanides and actinides in the two positions below yttrium (usually via footnote markers).\nThis variant, which is the IUPAC-agreed version, emphasizes similarities in the chemistry of the 15 lanthanide elements (La–Lu), possibly at the expense of ambiguity as to which elements occupy the two group 3 positions below yttrium, and a 15-column wide \"f\" block (there can only be 14 elements in any row of the \"f\" block).\n\nThe definition of a transition metal, as given by IUPAC, is an element whose atom has an incomplete d sub-shell, or which can give rise to cations with an incomplete d sub-shell. By this definition all of the elements in groups 3–11 are transition metals. The IUPAC definition therefore excludes group 12, comprising zinc, cadmium and mercury, from the transition metals category.\n\nSome chemists treat the categories \"d-block elements\" and \"transition metals\" interchangeably, thereby including groups 3–12 among the transition metals. In this instance the group 12 elements are treated as a special case of transition metal in which the d electrons are not ordinarily involved in chemical bonding. The 2007 report of mercury(IV) fluoride (HgF), a compound in which mercury would use its d electrons for bonding, has prompted some commentators to suggest that mercury can be regarded as a transition metal. Other commentators, such as Jensen, have argued that the formation of a compound like HgF can occur only under highly abnormal conditions; indeed, its existence is currently disputed. As such, mercury could not be regarded as a transition metal by any reasonable interpretation of the ordinary meaning of the term.\n\nStill other chemists further exclude the group 3 elements from the definition of a transition metal. They do so on the basis that the group 3 elements do not form any ions having a partially occupied d shell and do not therefore exhibit any properties characteristic of transition metal chemistry. In this case, only groups 4–11 are regarded as transition metals. Though the group 3 elements show few of the characteristic chemical properties of the transition metals, they do show some of their characteristic physical properties (on account of the presence in each atom of a single d electron).\n\nAlthough all elements up to oganesson have been discovered, of the elements above hassium (element 108), only copernicium (element 112), nihonium (element 113), and flerovium (element 114) have known chemical properties, and only for copernicium is there enough evidence for a conclusive categorisation at present. The other elements may behave differently from what would be predicted by extrapolation, due to relativistic effects; for example, flerovium has been predicted to possibly exhibit some noble-gas-like properties, even though it is currently placed in the carbon group. The current experimental evidence still leaves open the question of whether flerovium behaves more like a metal or a noble gas.\n\nIt is unclear whether new elements will continue the pattern of the current periodic table as period 8, or require further adaptations or adjustments. Seaborg expected the eighth period to follow the previously established pattern exactly, so that it would include a two-element s-block for elements 119 and 120, a new g-block for the next 18 elements, and 30 additional elements continuing the current f-, d-, and p-blocks, culminating in element 168, the next noble gas. More recently, physicists such as Pekka Pyykkö have theorized that these additional elements do not follow the Madelung rule, which predicts how electron shells are filled and thus affects the appearance of the present periodic table. There are currently several competing theoretical models for the placement of the elements of atomic number less than or equal to 172. In all of these it is element 172, rather than element 168, that emerges as the next noble gas after oganesson, although these must be regarded as speculative as no complete calculations have been done beyond element 122.\n\nThe number of possible elements is not known. A very early suggestion made by Elliot Adams in 1911, and based on the arrangement of elements in each horizontal periodic table row, was that elements of atomic weight greater than circa 256 (which would equate to between elements 99 and 100 in modern-day terms) did not exist. A higher—more recent—estimate is that the periodic table may end soon after the island of stability, which is expected to centre around element 126, as the extension of the periodic and nuclides tables is restricted by proton and neutron drip lines. Other predictions of an end to the periodic table include at element 128 by John Emsley, at element 137 by Richard Feynman, and at element 155 by Albert Khazan.\n\nThe Bohr model exhibits difficulty for atoms with atomic number greater than 137, as any element with an atomic number greater than 137 would require 1s electrons to be travelling faster than \"c\", the speed of light. Hence the non-relativistic Bohr model is inaccurate when applied to such an element.\n\nThe relativistic Dirac equation has problems for elements with more than 137 protons. For such elements, the wave function of the Dirac ground state is oscillatory rather than bound, and there is no gap between the positive and negative energy spectra, as in the Klein paradox. More accurate calculations taking into account the effects of the finite size of the nucleus indicate that the binding energy first exceeds the limit for elements with more than 173 protons. For heavier elements, if the innermost orbital (1s) is not filled, the electric field of the nucleus will pull an electron out of the vacuum, resulting in the spontaneous emission of a positron. This does not happen if the innermost orbital is filled, so that element 173 is not necessarily the end of the periodic table.\n\nThe many different forms of periodic table have prompted the question of whether there is an optimal or definitive form of periodic table. The answer to this question is thought to depend on whether the chemical periodicity seen to occur among the elements has an underlying truth, effectively hard-wired into the universe, or if any such periodicity is instead the product of subjective human interpretation, contingent upon the circumstances, beliefs and predilections of human observers. An objective basis for chemical periodicity would settle the questions about the location of hydrogen and helium, and the composition of group 3. Such an underlying truth, if it exists, is thought to have not yet been discovered. In its absence, the many different forms of periodic table can be regarded as variations on the theme of chemical periodicity, each of which explores and emphasizes different aspects, properties, perspectives and relationships of and among the elements.\n\n\n"}
{"id": "36245650", "url": "https://en.wikipedia.org/wiki?curid=36245650", "title": "Pod (sculpture)", "text": "Pod (sculpture)\n\nPod is the name of a 2002 modern sculpture by American artist Pete Beeman, currently installed at Southwest 10th Avenue and West Burnside Street in downtown Portland, Oregon. The sculpture, intended to represent the \"infrastructure, energy, and vibrancy of Portland,\" is supported by its static tripod base with a diameter. It is constructed from stainless steel, galvanized steel, bronze, titanium, lead and other materials. \"Pod\" was fabricated by Beeman and David Bermudez, and engineered by Beeman and Peterson Structural Engineers. It is considered interactive and kinetic, with a central, vertical pendulum that swings back and forth when pushed. The sculpture cost as much as $50,000 and was funded by the Portland Streetcar Project. \"Pod\" is part of the City of Portland and Multnomah County Public Art Collection courtesy of the Regional Arts & Culture Council.\n\n\"Pod\" was designed by native Portland resident Pete Beeman as a public art project for the Portland Streetcar. According to Beeman and the Regional Arts & Culture Council, the modern sculpture is designed to represent the \"infrastructure, energy, and vibrancy of Portland\". Of the work's design, Beeman said:\n\nI was thinking about how Portland is designed and planned and built, and how the planning and infrastructure of Portland is really important in what makes Portland great. I was thinking of the static tripod as the infrastructure. The moving part was the vibrancy and life... The most interesting part of the sculpture will be watching people try to move it.\n\n\"Pod\" is constructed from stainless steel, galvanized steel, bronze, titanium, lead, plastic and rubber. The sculpture is supported by its static tripod base with a 14- to 15-foot diameter. Each of the three \"legs,\" cut to size by BBC Steel, stand tall and are grounded by of concrete. The central pendulum structure consists of 73 titanium rods; each of these connects to a \"star fruit\"-shaped bronze bulb at the base of the pendulum. \"Pod\" was fabricated by Beeman and David Bermudez, and engineered by Beeman and Peterson Structural Engineers. The work is considered interactive and kinetic; the central, vertical pendulum swings back and forth when pushed. The upper and lower parts of the pendulum \"swing and flex in different rhythms, affecting each other\" until returning to a resting position. \"Pod\" cost $40,000–$50,000 and was funded by the Portland Streetcar Project. \n\nThe sculpture was installed at a triangular traffic island at a busy street intersection (Southwest 10th Avenue and West Burnside Street) in downtown Portland in November 2002. In 2003, \"Pod\" was included in a walking tour by the Americans for the Arts Public Art Conference. It was cleaned and underwent maintenance for approximately two weeks in August 2010. \"Dual Pendulum\" (2000), Beeman's kinetic prototype of \"Pod\", was installed at Oregon State University for Da Vinci Days in 2007.\n\nIn 2002, D. K. Row of \"The Oregonian\" called \"Pod\" a \"complex, funny piece,\" comparing it to a \"mechanical spider with an unlikely spine sticking in the air\". Row said the sculpture evoked the curves of sculptor Richard Serra and design style of architect Frank Gehry. Michael Powell, owner of Powell's City of Books (located across the street from \"Pod\"), called the sculpture \"wonderful\". \"Pod\" has been compared to a scrotum and has even been referred to as the \"Ass tickler of God\", \"Satan's Testicle\" and \"The Nutsack\".\n\n\n"}
{"id": "46597469", "url": "https://en.wikipedia.org/wiki?curid=46597469", "title": "Privacy engineering", "text": "Privacy engineering\n\nPrivacy engineering is an emerging discipline within, at least, the software or information systems domain which aims to provide methodologies, tools, and techniques such that the engineered systems provide acceptable levels of privacy. In the US acceptable level of privacy is defined in terms of compliance to the functional and non-functional requirements set out through a privacy policy, while in the EU, the General Data Protection Regulation sets the requirements that need to be fulfilled. In the rest of the world, the requirements change depending on local implementations of privacy and data protection laws.\n\nThe definition of privacy engineering given by National Institute of Standards and Technology (NIST) is:\n\nWhile privacy has been developing as a legal domain, privacy engineering has only really come to the fore in recent years as the necessity of implementing said privacy laws in information systems has become a definite requirement to the deployment of such information systems. For example, IPEN outlines their position in this respect as:\n\nPrivacy engineering involves aspects such as process management, security, ontology and software engineering. The actual application of these derives from necessary legal compliances, privacy policies and `manifestos' such as Privacy-by-Design.\n\nTowards the more implementation levels, privacy engineering employs privacy enhancing technologies to enable anonymisation and de-identification of data. Privacy engineering requires suitable security engineering practices to be deployed, and some privacy aspects can be implemented using security techniques. A privacy impact assessment is another tool within this context and its use does not imply that privacy engineering is being practiced.\n\nOne area of concern is the proper definition and application of terms such as personal data, personally identifiable information, anonymisation and pseudo-anonymisation which lack sufficient and detailed enough meanings when applied to software, information systems and data sets.\n\nAnother facet of information system privacy has been the ethical use of such systems with particular concern on surveillance, big data collection, artificial intelligence etc. Some members of the privacy and privacy engineering communication advocate the idea of Ethics engineering or reject the possibility of engineering privacy into systems intended for surveillance.\n\nAs this particular field is still in its infancy and somewhat dominated by the legal aspects, the following list just outlines the primary areas on which privacy engineering is based:\n\n\nDespite the lack of a cohesive development of the above areas, courses already exist for the training of privacy engineering. The International Workshop on Privacy Engineering co-located with IEEE Symposium on Security and Privacy provides a venue to address \"the gap between research and practice in systematizing and evaluating approaches to capture and address privacy issues while engineering information systems\".\n\nAs an area privacy engineering is particular concerned with the processing of information over the following aspects or ontologies and their relations to their implementation in software:\n\n\nFurther to this how the above then affect the security classification, risk classification and thus the levels of protection and flow within a system can then the metricised or calculated.\n\nAs already stated, privacy is an area dominated by legal aspects but requiring implementation using, ostensibly, engineering techniques, disciplines and skills. Privacy Engineering as an overall discipline takes its basis from considering privacy not just as a legal aspect or engineering aspect and their unification but also utilising the following areas:\n\n\nThe impetus for technological progress in privacy engineering stems from general privacy laws and various particular legal acts:\n\n"}
{"id": "20765204", "url": "https://en.wikipedia.org/wiki?curid=20765204", "title": "Reciprocity (engineering)", "text": "Reciprocity (engineering)\n\nReciprocity in linear systems is the principle that a response Rab, measured at a location (and direction if applicable) a, when the system has an excitation signal applied at a location (and direction if applicable) b, is exactly equal to Rba which is the response at location b, when that same excitation is applied at a. This applies for all frequencies of the excitation signal. If Hab is the transfer function between a and b then Hab = Hba, if the system is linear.\n\nIn the special case of a modal analysis this is known as Maxwell's reciprocity theorem. In electromagnetism the concept is known as Lorentz reciprocity.\n\nThe reciprocity principle is also used in the analysis of structures. When combined with superposition, symmetry and anti-symmetry, it can be used to resolve complex load conditions.\n"}
{"id": "219575", "url": "https://en.wikipedia.org/wiki?curid=219575", "title": "Remorse", "text": "Remorse\n\nRemorse is a distressing emotion experienced by a person who regrets actions which they deem to be shameful, hurtful, or violent. Remorse is closely allied to guilt and self-directed resentment. When a person regrets an earlier action or failure to act, it may be because of remorse or in response to various other consequences, including being punished for the act or omission. People may express remorse through apologies, trying to repair the damage they've caused, or self-imposed punishments.\n\nIn a legal context, the perceived remorse of an offender is assessed by Western justice systems during trials, sentencing, parole hearings, and in restorative justice. However, there are epistemological problems with assessing an offender's level of remorse.\n\nA person who is incapable of feeling remorse is often diagnosed with antisocial personality disorder, as characterized in the DSM IV-TR. In general, a person needs to be unable to feel fear, as well as remorse, in order to develop psychopathic traits. Legal and business professions such as insurance have done research on the expression of remorse via apologies, primarily because of the potential litigation and financial implications.\n\nTwo studies on apologising are \"The Five Languages of Apology\" by Gary Chapman and Jennifer Thomas and \"On Apology\" by Aaron Lazare. These studies indicate that effective apologies that express remorse typically include a detailed account of the offense; acknowledgment of the hurt or damage done; acceptance of the responsibility for, and ownership of, the act or omission; an explanation that recognises one's role. As well, apologies usually include a statement or expression of regret, humility, or remorse; a request for forgiveness; and an expression of a credible commitment to change or a promise that it will not happen again. Apologies may also include some form of restitution, compensation or token gesture in line with the damage that one has caused. John Kleefeld has encapsulated this into \"four Rs\" that typically make for a fully effective apology: remorse, responsibility, resolution and reparation. When an apology is delayed, for instance if a friend has been wronged and the offending party does not apologise, the perception of the offense can compound over time. This is sometimes known as compounding remorse. Compunction refers to the act of actively expressing remorse, usually requiring the remorseful individual to physically approach the person to whom he is expressing regret.\n\nIn a study led by Leanne ten Brinke, a professor at the University of British Columbia, participants' genuine and falsified emotions were studied to investigate behavioral and facial cues. Brinke and others found a significant difference in the presence of facial expressions in real and false remorse. With falsified emotions of remorse, they found that the participants experienced a greater range of emotions, which are close to genuine feelings, while deceptive descriptions of remorse were associated with positive emotions, such as happiness and surprise. The positive emotions felt by participants demonstrating a deceptive description of remorse are likely due to the leakage of genuine feelings from incomplete deception. Brinke and others established that participants appeared surprised because they could only raise their eyebrows when trying to appear sad, which then caused the participants to feel embarrassed, feel genuine happiness, and let a smile slip. In contrast to deceptive and falsified accounts, genuine accounts were expressed with fewer emotions. Participants showing deceptive or falsified emotions overcompensated their emotional performance. Genuine negative feelings of remorse leaked by the lower face were immediately covered up with a neutral expression. Brinke recorded a small number of body language and verbal cues for deceptive participants; instead, she recorded a large number of speech hesitations that cued deceptive and falsified accounts of remorse. Current findings about deceptive and falsified remorse have practical use for measuring veracity of remorseful displays for judges, jurors, parole officers, and psychologists when sentencing offenders.\n\nPsychopathic individuals are best known for their flagrant disregard for social and moral norms. Psychopaths have dysfunctional personal relationships, characterized by violence, exploitation, and philandering. Emotionally, they are incapable of feeling guilt or empathy, they respond abnormally to fear and pain, and other emotions are shallow compared to population norms. Psychopaths refuse to adopt social and moral norms because they are not swayed by the emotions, such as guilt, remorse, or fear of retribution, that influence other human beings.\n\nAs human beings, we hold dear to the value of remorse. The lack of remorse leads us to all believe a person to be despicable. It is widely accepted that remorse is the proper reaction to any misconduct. Remorse may originate in from either actual or contrived regret for the misconduct that results in getting caught or causing harm. Research has shown that the facial expressions of offenders on trial affect the jury's attitude and, in turn, the sentencing decision. While remorse may present guilt that may influence a jury's decision, a lack of remorse influences the jury even more because it is one trait of psychopathy.\n\nPsychopathy represents a configuration of traits that are missing within a person's personality, such as a lack of empathy and remorse. Knowledge of psychopathic traits has been shown to affect how jurors perceive adult and juvenile offenders. Assessments of psychopathy are introduced to direct a relatively wide variety of questions in the legal system, so investigators have started examining the effects of psychopathy evidences. Through simulations in studies by John Edens, who is a psychology professor at Texas A&M University, data suggests that attributing psychopathic traits to adult and juvenile offenders can have a noticeable negative effect on how these individuals are viewed by others. Remorselessness, a key feature of psychopathy, proves to be a strong predictor of juror attitudes. In the study by John Edens, a pool of offenders were labeled as either having a \"disorder\" condition or having \"no disorder.\" Those labeled as \"disorder\" were given death verdicts by mock jurors. In the study, traits, such as callousness, remorselessness, and superficial charm, were a strong predictor of negative consequences for the offenders. This study found that remorselessness has the largest effect on the mock jurors' opinions of the \"disorder\" offenders and it explains support for the death sentence. The results of this study suggest that, free of mental health testimonies, perceptions of a defendant's personality traits may have serious implications in the sentencing decisions of a capital case.\n\nThe perception of remorse is essential to an apology, and the greater the perception of remorse the more effective the apology. An effective apology reduces negative consequences and facilitates cognitive and behavioral changes associated with forgiveness. With empathy as the mediator between apologies and forgiveness and remorse as the essential part to an apology, one can expect empathy to mediate perceived remorse forgiveness. Remorse may signal that one is suffering psychologically because of one's negative behavior, which leads to empathy from the victim, who may then express forgiveness. In a study by James Davis and Greg Gold, 170 university students filled out questionnaires about forgiveness within interpersonal relationships. Davis and Greg's findings suggest that when a victim perceives an apology to be remorseful then he/she believes the negative behavior will not occur again, and they'll be more willing to forgive them.\n\nRemorse is closely linked with the willingness to humble oneself and to repent for one's misdeeds. Remorse is not as such when defined through the view of self-condemnation. Self-condemnation, more so than remorse, is said to be associated with poor psychological well-being. Remorse captures feelings of guilt, regret, and sorrow. Forgiveness does not eliminate all negative feelings, but it may entail the reduction of bitter and angry feelings, not feelings of disappointment, regret, or sorrow. A study by Mickie Fisher found that people who forgive themselves for serious offenses may continue to harbor remorse or regret. In contrast to remorse, self-condemnation reflects a more global, negative, severe stance toward oneself. Remorse may convey a sense of sorrow, while self-condemnation suggests the kind of loathing and desire for punishment that characterizes interpersonal grudges. Fisher suggests that self-forgiveness does not necessarily require one to get rid of feelings or regret or remorse. Based on the study by Fisher, self-forgiveness seems to relate more closely to self-condemnation and not remorse. When trying to convince people to forgive themselves, it is crucial not to erase the potentially adaptive feelings of remorse along with the more destructive self-condemnation. People can grow and experience prosocial behaviors once they accept responsibility for their own transgressions. For genuine self-forgiveness, one must first accept responsibility for their offenses and not rush to rid themselves of guilty feelings.\n\nPurchases can be divided into two different categories: material or experiential. A material good is made to be kept in the buyer's possession, while an experiential good provides the buyer with a life experience. A material good provides the buyer with a more enduring pleasure compared with an experiential, as these two purchases also result in different types of regret. While experiential purchases bring about regrets of a missed opportunity, material purchases result in buyer's remorse, which means that a person dwells on how their material purchase measure up to other purchases they could have made and how it compares with other people's purchases. These comparisons diminish satisfaction from the original purpose. Past research explains that regrets of action are intense, but only in the short term, while regrets of inaction gains intensity over time and dominates people's experience. Major life choices, such as marriage, jobs, and education, are often the focus of regret. Everyday experience suggests that everyday decisions are the most frequent causes of regret. Marketing directors know the effects of buyer's remorse, and use it to their advantage when planning marketing strategies. The regret felt over choosing a material over an experiential purchase depends on the pain of the factors underlying the purchase. Based on research by Thomas Gilovich and Emily Rosenzwig, material purchases are more likely to lead to regret, while experiential purchases give the buyer more satisfaction even over time.\n"}
{"id": "20112903", "url": "https://en.wikipedia.org/wiki?curid=20112903", "title": "Ren (Confucianism)", "text": "Ren (Confucianism)\n\nRen () is the Confucian virtue denoting the good feeling a virtuous human experiences when being altruistic. \"Ren\" is exemplified by a normal adult's protective feelings for children. It is considered the outward expression of Confucian ideals.\n\nYan Hui, one of the Four Sages, once asked his master to describe the rules of \"ren\". Confucius replied, \"One should see nothing improper, hear nothing improper, say nothing improper, do nothing improper.\" Confucius also defined \"ren\" in the following way: \"wishing to be established himself, seeks also to establish others; wishing to be enlarged himself, he seeks also to enlarge others.\" Confucius also said, \"\"Ren\" is not far off; he who seeks it has already found it.\" \"Ren\" is close to man and never leaves him.\n\nThe single logogram for \"ren\" is a composite of two distinct common hanzi, 人 (Man, a man, a person ) and 二 (two), with 人 assuming its common form inside another character, to which various interpretations have been assigned. One often hears that \"ren\" means \"how two people should treat one another\". While such folk etymologies are common in discussions of Chinese characters, they often are as misleading as they are entertaining. In the case of \"ren\" - usually translated as \"benevolence\" or \"humaneness\" - Humaneness is Human-ness, the essence of being human. For Confucius the interaction of completely dependent infant and caring parent is the most emotionally charged human interaction, “To love a thing means wanting it to live…”. The Way of humaneness is human interaction and through shared experience knowing one’s family. “Fan Chi asked about humaneness. The Master said it is loving people. Fan Chi asked about wisdom. The Master said it is knowing people”. In other words, human love and interaction is the source of humaneness, the source of the human self. Another common interpretation of the graphical elements is Man or a man connecting Heaven and Earth.\n\n人+二=仁 (Rén) man on left two on right, the relationship between two human beings, means humanity, benevolence, seed. Originally the character was just written as丨二 representing yin yang, the vertical line is yang (male, penis, heaven, odd numbers), the two horizontal lines are yin (female, vagina, earth, even numbers), 仁 is the seed and core of everything. The character 人 (man, rén) and 仁 have the same pronunciation. When a human is unable to be humane, he or she does not qualify to be a human but an animal. But when a human is able to be humane, he or she qualifies to be a human. For example, when Buddhism was first introduced to China in the Han Dynasty the Chinese people translated the Buddha's name into \"able to be human\" or someone with ”ability and humanity\" (能人，能仁) because Confucius's teachings and Buddha's teachings are \"one to two, two to one.\"\n\nPre-imperial epigraphic sources testify to alternative writings of the same character: 忎 (given as a variant of 仁 in the Shuowen dictionary), 身 with 心 below, and the latter compound with 人 on the right.\n\nThe principle of \"ren\" is related to the concepts of \"li\" and \"yi\". \"Li\" is often translated as \"ritual\" while \"yi\" is often translated as \"righteousness\". These three interrelated terms deal with agency as Confucians conceive it. \"Li\" is the action which has been deemed appropriate by society, \"yi\" is the action that is indeed correct, while \"ren\" deals with the relationship between the agent and object of the action. Often \"li\" and \"yi\" are the same; however, that is not always the case.\n\n\"Li\" is the outward expression of Confucian ideals, while \"ren\" is both the inward and outward expressions of those same ideals. According to Hopfe and Woodward: \"Basically, \"li\" seems to mean 'the course of life as it is intended to go'. \"Li\" also has religious and social connotations. When a society lives by \"li\", it moves smoothly: men and women respect their elders and superiors; the proper rituals and ceremonies are performed; everything and everyone is in its proper place.\"\n\n\"Ren\" relies heavily on the relationships between two people, but at the same time encompasses much more than that. It represents an inner development towards an altruistic goal, while simultaneously realizing that one is never alone, and that everyone has these relationships to fall back on, being a member of a family, the state, and the world.\n\n\"Ren\" is not a concept that is learned; it is innate, that is to say, everyone is born with the sense of \"ren\". Confucius believed that the key to long-lasting integrity was to constantly think, since the world is continually changing at a rapid pace.\n\nThere have been a variety of definitions for the term \"ren\". \"Ren\" has been translated as \"benevolence\", \"perfect virtue\", \"goodness\" or even \"human-heartedness\". When asked, Confucius defined it by the ordinary Chinese word for love, \"ai\", saying that it meant to \"love others\".\n\n\"Ren\" also has a political dimension. Confucianism says that if the ruler lacks \"ren\", it will be difficult for his subjects to behave humanely. \"Ren\" is the basis of Confucian political theory; the ruler is exhorted to refrain from acting inhumanely towards his subjects. An inhumane ruler runs the risk of losing the Mandate of Heaven or, in other words, the right to rule. A ruler lacking such a mandate need not be obeyed, but a ruler who reigns humanely and takes care of the people is to be obeyed, for the benevolence of his dominion shows that he has been mandated by heaven. Confucius himself had little to say on the active will of the people, though he believed the ruler should definitely pay attention to the wants and needs of the people and take good care of them. Mencius, however, did state that the people's opinion on certain weighty matters should be polled.\n\n\"Ren\" also includes traits that are a part of being righteous, such as \"hsin\", meaning to make one's words compliment one's actions; \"li\", which means to properly participate in everyday rituals; \"ching\", or \"seriousness\"; and \"yi\", which means right action. When all these qualities are present, then one can truly be identified as a \"junzi\" (君子), or \"superior man,\" which means a morally superior human being. Confucians basically held the view that government should be run by \"junzi\" who concentrate solely on the welfare of the people they govern.\n\n\n\n"}
{"id": "41706", "url": "https://en.wikipedia.org/wiki?curid=41706", "title": "Signal-to-noise ratio", "text": "Signal-to-noise ratio\n\nSignal-to-noise ratio (abbreviated SNR or S/N) is a measure used in science and engineering that compares the level of a desired signal to the level of background noise. SNR is defined as the ratio of signal power to the noise power, often expressed in decibels. A ratio higher than 1:1 (greater than 0 dB) indicates more signal than noise.\n\nWhile SNR is commonly quoted for electrical signals, it can be applied to any form of signal, for example isotope levels in an ice core, biochemical signaling between cells, or financial trading signals. Signal-to-noise ratio is sometimes used metaphorically to refer to the ratio of useful information to false or irrelevant data in a conversation or exchange. For example, in online discussion forums and other online communities, off-topic posts and spam are regarded as \"noise\" that interferes with the \"signal\" of appropriate discussion.\n\nThe signal-to-noise ratio, the bandwidth, and the channel capacity of a communication channel are connected by the Shannon–Hartley theorem.\n\nSignal-to-noise ratio is defined as the ratio of the power of a signal (meaningful information) to the power of background noise (unwanted signal):\nwhere \"P\" is average power. Both signal and noise power must be measured at the same or equivalent points in a system, and within the same system bandwidth.\n\nIf the variance of the signal and noise are known, and the signal and noise are both zero-mean, SNR can be:\n\nIf the signal and the noise are measured across the same impedance, the SNR can be obtained by calculating the square of the amplitude ratio:\n\nwhere \"A\" is root mean square (RMS) amplitude (for example, RMS voltage).\n\nBecause many signals have a very wide dynamic range, signals are often expressed using the logarithmic decibel scale. Based upon the definition of decibel, signal and noise may be expressed in decibels (dB) as\n\nand\n\nIn a similar manner, SNR may be expressed in decibels as\n\nUsing the definition of SNR\n\nUsing the quotient rule for logarithms\n\nSubstituting the definitions of SNR, signal, and noise in decibels into the above equation results in an important formula for calculating the signal to noise ratio in decibels, when the signal and noise are also in decibels:\n\nIn the above formula, P is measured in units of power, such as watts (W) or milliwatts (mW), and the signal-to-noise ratio is a pure number.\n\nHowever, when the signal and noise are measured in volts (V) or amperes (A), which are measures of amplitude, they must first be squared to obtain a quantity proportional to power, as shown below:\n\nThe concepts of signal-to-noise ratio and dynamic range are closely related. Dynamic range measures the ratio between the strongest un-distorted signal on a channel and the minimum discernible signal, which for most purposes is the noise level. SNR measures the ratio between an arbitrary signal level (not necessarily the most powerful signal possible) and noise. Measuring signal-to-noise ratios requires the selection of a representative or \"reference\" signal. In audio engineering, the reference signal is usually a sine wave at a standardized nominal or alignment level, such as 1 kHz at +4 dBu (1.228 V).\n\nSNR is usually taken to indicate an \"average\" signal-to-noise ratio, as it is possible that (near) instantaneous signal-to-noise ratios will be considerably different. The concept can be understood as normalizing the noise level to 1 (0 dB) and measuring how far the signal 'stands out'.\n\nIn physics, the average power of an AC signal is defined as the average value of voltage times current; for resistive (non-reactive) circuits, where voltage and current are in phase, this is equivalent to the product of the rms voltage and current:\n\nBut in signal processing and communication, one usually assumes that formula_13 so that factor is usually not included while measuring power or energy of a signal. This may cause some confusion among readers, but the resistance factor is not significant for typical operations performed in signal processing, or for computing power ratios. For most cases, the power of a signal would be considered to be simply\nwhere 'A' is the amplitude of the AC signal.\n\nAn alternative definition of SNR is as the reciprocal of the coefficient of variation, i.e., the ratio of mean to standard deviation of a signal or measurement:\n\nwhere formula_16 is the signal mean or expected value and formula_17 is the standard deviation of the noise, or an estimate thereof. Notice that such an alternative definition is only useful for variables that are always non-negative (such as photon counts and luminance). It is commonly used in image processing, where the SNR of an image is usually calculated as the ratio of the mean pixel value to the standard deviation of the pixel values over a given neighborhood. Sometimes SNR is defined as the square of the alternative definition above.\n\nThe \"Rose criterion\" (named after Albert Rose) states that an SNR of at least 5 is needed to be able to distinguish image features at 100% certainty. An SNR less than 5 means less than 100% certainty in identifying image details.\n\nYet another alternative, very specific and distinct definition of SNR is employed to characterize sensitivity of imaging systems; see Signal-to-noise ratio (imaging).\n\nRelated measures are the \"contrast ratio\" and the \"contrast-to-noise ratio\".\n\nChannel signal-to-noise ratio is given by\nwhere W is the bandwidth and formula_19 is modulation index\n\nOutput signal-to-noise ratio (of AM receiver) is given by\n\nChannel signal-to-noise ratio is given by\n\nOutput signal-to-noise ratio is given by\n\nAll real measurements are disturbed by noise. This includes electronic noise, but can also include external events that affect the measured phenomenon — wind, vibrations, gravitational attraction of the moon, variations of temperature, variations of humidity, etc., depending on what is measured and of the sensitivity of the device. It is often possible to reduce the noise by controlling the environment. Otherwise, when the characteristics of the noise are known and are different from the signals, it is possible to filter it or to process the signal.\n\nFor example, it is sometimes possible to use a lock-in amplifier to modulate and confine the signal within a very narrow bandwidth and then filter the detected signal to the narrow band where it resides, thereby eliminating most of the broadband noise. When the signal is constant or periodic and the noise is random, it is possible to enhance the SNR by averaging the measurement. In this case the noise goes down as the square root of the number of averaged samples.\n\nAdditionally, internal noise of electronic systems can be reduced by low-noise amplifiers.\n\nWhen a measurement is digitized, the number of bits used to represent the measurement determines the maximum possible signal-to-noise ratio. This is because the minimum possible noise level is the error caused by the quantization of the signal, sometimes called Quantization noise. This noise level is non-linear and signal-dependent; different calculations exist for different signal models. Quantization noise is modeled as an analog error signal summed with the signal before quantization (\"additive noise\").\n\nThis theoretical maximum SNR assumes a perfect input signal. If the input signal is already noisy (as is usually the case), the signal's noise may be larger than the quantization noise. Real analog-to-digital converters also have other sources of noise that further decrease the SNR compared to the theoretical maximum from the idealized quantization noise, including the intentional addition of dither.\n\nAlthough noise levels in a digital system can be expressed using SNR, it is more common to use E/N, the energy per bit per noise power spectral density.\n\nThe modulation error ratio (MER) is a measure of the SNR in a digitally modulated signal.\n\nFor \"n\"-bit integers with equal distance between quantization levels (uniform quantization) the dynamic range (DR) is also determined.\n\nAssuming a uniform distribution of input signal values, the quantization noise is a uniformly distributed random signal with a peak-to-peak amplitude of one quantization level, making the amplitude ratio 2/1. The formula is then:\n\nThis relationship is the origin of statements like \"16-bit audio has a dynamic range of 96 dB\". Each extra quantization bit increases the dynamic range by roughly 6 dB.\n\nAssuming a full-scale sine wave signal (that is, the quantizer is designed such that it has the same minimum and maximum values as the input signal), the quantization noise approximates a sawtooth wave with peak-to-peak amplitude of one quantization level and uniform distribution. In this case, the SNR is approximately\n\nFloating-point numbers provide a way to trade off signal-to-noise ratio for an increase in dynamic range. For n bit floating-point numbers, with n-m bits in the mantissa and m bits in the exponent:\n\nNote that the dynamic range is much larger than fixed-point, but at a cost of a worse signal-to-noise ratio. This makes floating-point preferable in situations where the dynamic range is large or unpredictable. Fixed-point's simpler implementations can be used with no signal quality disadvantage in systems where dynamic range is less than 6.02m. The very large dynamic range of floating-point can be a disadvantage, since it requires more forethought in designing algorithms.\n\nOptical signals have a carrier frequency that is much higher than the modulation frequency (about 200 THz and more). This way the noise covers a bandwidth that is much wider than the signal itself. The resulting signal influence relies mainly on the filtering of the noise. To describe the signal quality without taking the receiver into account, the optical SNR (OSNR) is used. The OSNR is the ratio between the signal power and the noise power in a given bandwidth. Most commonly a reference bandwidth of 0.1 nm is used. This bandwidth is independent of the modulation format, the frequency and the receiver. For instance an OSNR of 20 dB/0.1 nm could be given, even the signal of 40 GBit DPSK would not fit in this bandwidth. OSNR is measured with an optical spectrum analyzer.\n\nSignal to noise ratio may be abbreviated as SNR and less commonly as S/N. PSNR stands for Peak signal-to-noise ratio. GSNR stands for Geometric Signal-to-Noise Ratio. SINR is the Signal-to-noise-plus-interference ratio.\n\n"}
{"id": "32836040", "url": "https://en.wikipedia.org/wiki?curid=32836040", "title": "Social class differences in food consumption", "text": "Social class differences in food consumption\n\nPeople from different social classes eat different foods. Not all foods are available to everyone. People start to learn to like foods that are appropriate to their class while they are children. Based on the food that people decide to consume, their social class position is often revealed.\n\nPeople from the middle classes generally enjoy healthier diets than their lower class counterparts. Part of the explanation for this is that middle-class parents tend to be less permissive in their food choices, are less concerned with the cost of food products, and are more attuned to issues of health. However, permissiveness, health and cost considerations are insufficient to account for the social class variation in food consumption.\n\nThe significance of a food surplus in class demarcation ought to be highlighted in this section. In antiquity, those (typically upper classes) hoarding a sizeable surplus of harvests were granted experimental agencies leading to the development of elite cuisines. This principle may be contextualized by food historian Rachel Laudan’s assertion that “the humble, constantly at risk of real hunger, had every reason not to experiment with innovative cooking techniques” due to a scarce reserve of harvests. \n\nSocial class differences in food consumption are not necessarily static. A study of Finnish consumption patterns for the period from 1979 to 1990 found that across all classes the consumption of butter, high-fat milk, coffee and sugar had decreased and the consumption of vegetables had increased. From the mid-1980s, social class differences in food consumption had diminished with the lower social classes following consumption patterns established by the upper classes.\n\nAuthor of \"Distinction: A Social Critique of the Judgment of Taste,\" French sociologist Pierre Bourdieu wrote extensively on how people of different social classes (specifically the working class) choose what they eat. According to Bourdieu, there isn't much of a choice when it comes to food regarding the working class. The middle class decides which foods are \"good\" and \"bad\", which in turn influences what the working class consumes. While the middle class can afford to eat whatever they'd like, the working class simply has a \"taste for necessity\" and eats what they can afford.\n\nA food desert is a geographical area that lacks adequate grocery stores or markets that provide fresh and nutritious foods that are financially accessible to the people within the area. Food deserts are often found in lower income neighborhoods, which in turn limits the availability of higher quality foods to residents of these neighborhoods. Since the residents of these areas are not able to consistently shop for groceries within a reasonable distance from where they reside, this results in their regular consumption of foods considered unsuitable for maintaining a healthy and nutritious diet (i.e. fast food or food from convenience stores).\n\nPeople tend to define types of foods as belonging to a certain class based on how expensive (or inexpensive) they are. In a study done on students who were asked to categorize restaurant menu items into each of the different social classes, students considered cheap, simple meals lower-class while meals that were much more expensive and came with a choice of wine were considered upper-class.\n\nSince the early 2000s, restaurants and fast-food chains have been incorporating gourmet hamburgers into their menus which often consist of high-end or exotic ingredients. While people of all social classes have access to fast-food restaurants that sell \"better burgers\" (which are burgers that are considered to be of greater quality than the traditional burger), some restaurants sell expensive burgers that are exclusive to those who can afford them.\n\nFood-secure Canadians perceive Kraft Dinners as comforting while food insecure Canadians find it discomforting. This is due to the fact that the food-secure Canadians can afford to eat meals other than those made by Kraft, while food-insecure Canadians have very few options. Furthermore, Kraft meal kits are often found at food banks and charities which contributes to the reason why food-insecure people who visit these places find them undesirable.\n\n"}
{"id": "53366267", "url": "https://en.wikipedia.org/wiki?curid=53366267", "title": "Soft power of China", "text": "Soft power of China\n\nChina Central Television is a soft power of China. CCTV is a state-owned media organization and under supervised by SARPPFT. The organization and directors inside the media company are assigned by the government. The government control the news and supervised the directors in order to show their perspectives to the world.\n\nSoft power, according to Joseph Nye, who coined the term in his book in 1990: “ is the ability to get others to want the outcomes that you want, and the ability to achieve goals through attraction rather than coercion”(Nye, 1990). Indeed, soft power enables a change of behavior in others, without competition or conflict, by using persuasion and attraction. In this modern day, soft power becomes vital for a country. Media industry plays an essential role among all the industries, and it’s the most influential power.\n\nChina Central Television (CCTV) is a state-owned ministerial level institution of China, used to be called Beijing Television before 1978. China Central Television owns 50 television channels, and the broadcaster provides programming in six different languages. Among the 50 television channels, 16 of them are public while 21 are pay channels, and with 13 channels of foreign languages, which are English, French, Russian, Arabic as well as Spanish. It is one of the largest official mouthpieces of the Propaganda Department of the Communist Party of China (CPC) and under the supervision of State Administration of Press, Publication, Radio, Film, and Television of the People’s Republic of China (SAPPRFT), a department within the State Council. State Council is the main department that supervising and censoring the whole China’s television industry. SAPPRFT is an executive branch under the State Council. Its main task is the administration and supervision of state-owned enterprise engaged in the television, radio and film industries. It performs the actual daily oversight, including censorship of sensitive content. Government related media organizations like CCTV, Xinhua News Agency and China National Radio must have permissions from SAPPRFT to broadcast the new content to the public.\n\nIn June 2017, CCTV \"relaunched and rebranded its stable of foreign-language TV channels. The six are now labeled as China Global Television Network (CGTN) with CGTN English as its flagship channel. \"\n\nThe directors on CCTV also have positions in related government organizations and all of them are the members of Communist Party of China. Nie Chenxi, who is the main director of CCTV since 2015. He’s also the vice director of the Propaganda Department of the Communist Party of China (CPC), main director of SAPPRFT as well as the director of the National Copyright Administration of the People’s Republic of China. Nie was born in 1957 and from Hebei Province. He worked for the local government since 1974. In the duration, he studied a master degree in management and engineering. In February 1993, He joined the Communist Party of China and worked towards to the CCP. During Nie’s time, the government has issued repeated orders telling television channels to focus on “uplifting, patriotic programs and screen out ‘base and vulgar’ content” (Reuters, 2015). Historically, directors of CCTV made cultural revolutions. In December 1991, Yang Weiguang was assigned as president of CCTV. With his peasant family background, it’s no doubt helped him secure a steady position in the government related broadcaster organizations. He left his CCTV post in 1999, and the ten years of his management of CCTV were considered as the best days. In Yang’s decade, CCTV was “unquestionably the network’s high point in terms of party approval, market position, and public sphere” (Zhu, 2012). It was the first decade of CCTV’s transformation from state-funded proselytizer to commercial broadcaster.\n\nThe main financial support to CCTV is from advertising. In 2013, CCTV earned a total of 15.88 billion Yuan, and increased its revenues 11.4% each year. The graph (Figure 2) showing the most of the advertisers is liquor companies. Within those companies, liquor company JNC Group had spent the most money on advertising. The company spent 608 million Yuan by placing their logo on four daily slots on the news bulletins for eight months. Other liquor companies like Kweichow Moutai Co and Wuliangye Group Co also are the main advertiser of CCTV. Kweichow Moutai Co spent 352 million Yuan on placing their advertising on CCTV before Xinwen Lianbo (National News broadcasting, which airing the CCTV news in local channel everyday between 7pm to 7:30pm), and Wuliangye Group Co spent 499 million Yuan on the same time slots (China Daily, 2012). Those companies provided a steady financial support to CCTV. CCTV’s New Year’s Gala is popular and attracted among the country, even internationally. CCTV’s New Year’s Gala is on Chinese New Year’s Eve and it’s a tradition that nearly every family in China participates in to ring in the New Year. The tickets of Gala doesn’t open for the public, but CCTV sennd invitations to some celebrities, such as people who hold a high post in the government, annually influenced people like Jack Ma (CEO of Alibaba) as well as their family members. At the same time, CCTV will air the Gala on every local channel as well as in its foreign channels. People over the world will have a chance to watch this well-known performance. As a result, the advertisings during Gala are incredibly expensive but it still attracts a lot of companies to engage. CCTV also orients different kinds of event that open to the public, such as Skits, Xiangsheng, and Chinese Opera. (Mack, 2017), which tickets are available to the public. CCTV earns profits mainly through advertisements as well as its events.\n\nChina Central Television, China Radio International (CRI), Xinhua news agency, and \"The China Daily\" newspaper and website are the largest four state-owned media corporations. They all under control by SAPPRFT and rely on each other for producing news to the public. Xinhua News Agency is the main news source of CCTV. As they both are the official press agencies of the state, they have been tightly controlled and packaged by the government. In 2008, an earthquake measuring 8 on the Richter scale hit Sichuan Province. China Central Television was reporting on the disaster within minutes of the quake and had reporters airing with the updates within half an hour. “Domestic disaster of any sort were too hot to handle without instruction from the state and could harm the national image” (Zhu, 2012). This earthquake was a milestone of China as the Olympics was opened in a few months later in Beijing. In the chaos of the disaster, the Propaganda Department of the Communist Party of China requested other Chinese news organizations not to broadcast their reports of the disaster, but instead only used information released by either CCTV or the Xinhua News Agency. This process reveals that the government controls the news.\n\nIn 2001, a project called “Going Out” came up by president Jiang Zemin and launched by Xu Guangchun, who was the deputy head of the Propaganda Ministry and the head of SAPPRFT. This was a new start for CPC develop its power overseas. The project aims to bring China’s voice to the world. “Going Out” program was proposed to “land China’s TV and radio channels overseas within five years and provide multi languages and regionalized broadcasting and coverage by 2011” (Zhu, 2012). The image of China globally was misrepresent and misunderstand by other international medias like BBC, as result CPC wishes to erase its national image and present its voice to the world.\n\nAt the beginning of the “Going Out” Program CPC realized CCTV would meet some obstacles in western countries, because media organizations like CNN and BBC are dominants in western world while CCTV is an Asian broadcaster. Besides, westerners have some kind of stereotyped opinions to Asian, especially to Chinese. It is not an easy job to change their perspective to Chinese, as a result China moved to Africa, where western medias did not cover too much. That’s why CCTV moved their attention to Africa in 2012. As Zhang mentioned that “the Africa-oriented ‘channel’ is a ‘testing ground’ for the construction of an expand state-centered Sino centric media discourse aimed at showcasing China’s soft power and challenging the perceived Western-centric world order” (Zhang, 2013). China understands that the Africans are facing the same problem, which is the misrepresenting image in the world, so it is much easier for CPC to bring the voice there. It is an essential as well as a significant step that push Chinese media steps to global.\n"}
{"id": "908106", "url": "https://en.wikipedia.org/wiki?curid=908106", "title": "Sophrosyne", "text": "Sophrosyne\n\nSophrosyne () is an ancient Greek concept of an ideal of excellence of character and soundness of mind, which when combined in one well-balanced individual leads to other qualities, such as temperance, moderation, prudence, purity, decorum and self-control. In other languages there is no equivalent word.\n\nIn Greek literature sophrosyne is considered an important quality, and is sometimes expressed in opposition to the concept of hubris. A noted example of this occurs in Homer's \"The Iliad\". When Agamemnon decides to take the queen, Briseis, away from Achilles, it is seen as Agamemnon behaving with hubris and lacking sophrosyne. \nIn Homer's \"Odyssey\", Odysseus avoids being turned by Circe the enchantress into an animal by means of a magical herb, moly (symbolizing, by some accounts, sophrosyne), given to him by Athena (Wisdom) and Hermes (Reason). \nHeraclitus's fragment 112 states: \"Sophrosyne is the greatest virtue, and wisdom is speaking and acting the trust, paying heed to the nature of things.\" (σωφρονεῖν ἀρετὴ μεγίστη, καὶ σοφίη ἀληθέα λέγειν καὶ ποιεῖν κατὰ φύσιν ἐπαίοντας.)\n\nThemes connected with \"sophrosyne\" and hubris figure prominently in plays of Aeschylus, Sophocles and Euripides; \"sophrosyne\" is recognized as a virtue, although debased forms like prudery are criticized. \n\nSophrosyne is an important topic for Plato. It is main subject of the dialogue \"Charmides\", wherein several definitions are proposed but no conclusion reached; however the dramatic context connotes moral purity and innocence. An etymological meaning of sophrosyne as \"moral sanity\" is proposed in \"Cratylus\" 411e. Plato's view of sophrosyne is related to Pythagorean \"harmonia\" (\"Republic\" 430e−432a, 442c) and closely linked with Plato’s \ntripartite division of the soul: \"sophrosyne\" is the harmonious moderation of the appetitive and spirited parts of the soul by the rational part (e.g., \"Phaedrus\" 237c−238e).\n\nFor the Stoic, Zeno of Citium, \"sophrosyne\" is one of the four chief virtues. Later Stoics like Musonius Rufus, Seneca, Epictetus, and Marcus Aurelius took a practical view of \"sophrosyne\" and share a definition of it as the restraint of the appetites. \n\nDemophilus, a Pythagorean philosopher of uncertain date, wrote: \"the vigor of the soul is sophrosyne, the light of a soul free of disturbing passions.\" (Ρώμη ψυχής σωφροσύνη αύτη γαρ ψυχής απαθούς φώς εστιν.)\n\nCicero considered four Latin terms to translate \"sophrosyne\": \"temperantia\" (temperance), \"moderatio\" (moderateness), \"modestia\" (modesty) and \"frugalitas\" (frugality). Through the writings of Lactantius, St. Ambrose and St. Augustine, the virtue's meaning as temperance or \"proper mixture\" became the dominant view in subsequent Western European thought.\n\nSophrosyne is one of the cardinal virtues.\n\nAn adjectival form is \"sophron\".\n\n\n\n\n"}
{"id": "1348254", "url": "https://en.wikipedia.org/wiki?curid=1348254", "title": "Space launch", "text": "Space launch\n\nSpace launch is the earliest part of a flight that reaches space. Space launch involves liftoff, when a rocket or other space launch vehicle leaves the ground, floating ship or midair aircraft at the start of a flight. Liftoff is of two main types: rocket launch (the current conventional method), and non-rocket spacelaunch (where other forms of propulsion are employed, including airbreathing jet engines or other kinds).\n\nSpace has no physical edge to it as the atmospheric pressure gradually reduces with altitude; instead, the edge of space is defined by convention, often the Kármán line of 100 km. Other definitions have been created as well, in the US for example space has been defined as 50 miles.\n\nTherefore, by definition for spaceflight to occur, sufficient altitude is necessary. This implies a minimum gravitational potential energy needs to be overcome: for the Kármán line this is approximately 1 MJ/kg.\nW=mgh, m=1 kg, g=9.82 m/s, h=10m.\nW=1*9.82*10≈10J/kg=1MJ/kg\n\nIn practice, a higher energy than this is needed to be expended due to losses such as airdrag, propulsive efficiency, cycle efficiency of engines that are employed and gravity drag.\n\nIn the past fifty years spaceflight has usually meant remaining in space for a period of time, rather than going up and immediately falling back to earth. This entails orbit, which is mostly a mater of velocity, not altitude, although that does not mean air friction and relevant altitudes in relation to that and orbit don't have to be taken into account. At much, much, higher altitudes than many orbital ones maintained by satellites, altitude begins to become a larger and larger factor and speed a lesser one. At lower altitudes, due to the high speed required to remain in orbit, air friction is a very important consideration affecting satellites, much more than in the popular image of space. At even lower altitudes, balloons, with no forward velocity, can serve many of the roles satellites play.\n\nMany cargoes, particularly humans have a limiting g-force that they can survive. For humans this is about 3-6 g. Some launchers such as gun launchers would give accelerations in the hundred or thousands of g and thus are completely unsuitable.\n\nLaunchers vary with respect to their reliability for achieving the mission.\n\nSafety is the probability of causing injury or loss of life. Unreliable launchers are not necessarily unsafe, whereas reliable launchers are usually, but not invariably safe.\n\nApart from catastrophic failure of the launch vehicle itself other safety hazards include depressurisation, and the Van Allen radiation belts which preclude orbits which spend long periods within them.\n\nTrajectory optimization is the process of designing a trajectory that minimizes or maximizes some measure of performance within prescribed constraint boundaries. While not exactly the same, the goal of solving a trajectory optimization problem is essentially the same as solving an optimal control problem. This problem was first studied by Robert H. Goddard and is also known as the Goddard problem.\nThe selection of flight profiles that yield the greatest performance plays a substantial role in the preliminary design of flight vehicles, since the use of ad-hoc profile or control policies to evaluate competing configurations may inappropriately penalize the performance of one configuration over another. Thus, to guarantee the selection of the best vehicle design, it is important to optimize the profile and control policy for each configuration early in the design process.\n\nFor example, for tactical missiles, the flight profiles are determined by the thrust and load factor (lift) histories. These histories can be controlled by a number of means including such techniques as using an angle of attack command history or an altitude/downrange schedule that the missile must follow. Each combination of missile design factors, desired missile performance, and system constraints results in a new set of optimal control parameters.\n\nSub-orbital space flight is any space launch that reaches space without doing a full orbit around the planet, and requires a maximum speed of around 1 km/s just to reach space, and up to 7 km/s for longer distance such as an intercontinental space flight. An example of a sub-orbital flight would be a ballistic missile, or future tourist flight such as Virgin Galactic, or an intercontinental transport flight like SpaceLiner. Any space launch without an orbit-optimization correction to achieve a stable orbit will result in a suborbital space flight, unless there is sufficient thrust to leave orbit completely. (See Space gun#Getting to orbit)\n\nIn addition, if orbit is required, then a much greater amount of energy must be generated in order to give the craft some sideways speed. The speed that must be achieved depends on the altitude of the orbit – less speed is needed at high altitude. However, after allowing for the extra potential energy of being at higher altitudes, overall more energy is used reaching higher orbits than lower ones.\n\nThe speed needed to maintain an orbit near the Earth's surface corresponds to a sideways speed of about 7.8 km/s (17,400 mph), an energy of about 30MJ/kg. This is several times the energy per kg of practical rocket propellant mixes.\n\nGaining the kinetic energy is awkward as the airdrag tends to slow the spacecraft, so rocket-powered spacecraft generally fly a compromise trajectory that leaves the thickest part of the atmosphere very early on, and then fly on for example, a Hohmann transfer orbit to reach the particular orbit that is required. This minimises the airdrag as well as minimising the time that the vehicle spends holding itself up. Airdrag is a significant issue with essentially all proposed and current launch systems, although usually less so than the difficulty of obtaining enough kinetic energy to simply reach orbit at all.\n\nIf the Earth's gravity is to be overcome entirely then sufficient energy must be obtained by a spacecraft to exceed the depth of the gravity potential energy well. Once this has occurred, provided the energy is not lost in any non-conservative way, then the vehicle will leave the influence of the Earth. The depth of the potential well depends on the vehicle's position, and the energy depends on the vehicle's speed. If the kinetic energy exceeds the potential energy then escape occurs. At the Earth's surface this occurs at a speed of 11.2 km/s (25,000 mph), but in practice a much higher speed is needed due to airdrag.\n\nRocket launch is the only current way to reach space. In some cases an airbreathing (jet engine) first stage has been used as well.\n\nNon-rocket space launch is a launch into space where some or all of the needed speed and altitude are provided by something other than expendable rockets. A number of alternatives to expendable rockets have been proposed. In some systems such as Skyhooks, rocket sled launch, and air launch, a rocket is used to reach orbit, but it is only part of the system.\n\n"}
{"id": "4684361", "url": "https://en.wikipedia.org/wiki?curid=4684361", "title": "Stimming", "text": "Stimming\n\nSelf-stimulatory behavior, also known as stimming and self-stimulation, is the repetition of physical movements, sounds, or words, or the repetitive movement of objects common in individuals with developmental disabilities and most prevalent in people with autism spectrum disorders. It is also commonly seen in people with anxiety disorders such as obsessive–compulsive disorder, ADHD, and Tourette syndrome, and in people with neurological disorders or brain infections. It is considered a protective response to over-stimulation, in which people calm themselves by blocking less predictable environmental stimuli, to which they have a heightened sensitivity. Sensory processing disorder is also given as a reason by some therapists for the behavior. Another theory is that stimming is a way to relieve anxiety and other emotions.\n\nCommon stimming behaviors (sometimes called stims) include hand flapping, rocking, excessive or hard blinking, pacing, head banging, repeating noises or words, snapping fingers, and spinning objects. Stimming is almost always present in autism, but does not necessarily indicate its presence. The biggest difference between autistic and non-autistic stimming is in the type of \"stim\" and the quantity of stimming. When the need to stim or the amount of stimming interferes with normal behavior, it becomes diagnosable as autism, Asperger's or SPD (not recognized in the \"Diagnostic and Statistical Manual of Mental Disorders\").\n\nIn the \"Diagnostic and Statistical Manual of Mental Disorders\", published by the American Psychiatric Association, this type of behavior is described as \"stereotyped and repetitive motor mannerisms\" and listed as one of the symptoms of autism. There are numerous ways to reduce or eliminate stereotypic behaviors, including providing alternative forms of stimulation and the use of medication (however, it is not clear whether medication is actually beneficial or restricts the individual from finding relief). \n\nThe majority of the autistic community opposes attempts to reduce or eliminate stimming, as it is an important tool for self-regulation. Many contend that attempts to stop people from stimming are potentially abusive. \n\nStimming can sometimes be self-injurious, such as when it involves head-banging, hand-biting, and excessive self-rubbing and scratching. However, viewed through the lens of SPD and autism, these behaviours can be seen as an adaptive response to over- and underwhelming interpretation of sensory stimuli\n\nStimming can sometimes be mistaken for a sign of drug abuse.\n\n"}
{"id": "359052", "url": "https://en.wikipedia.org/wiki?curid=359052", "title": "Structure (category theory)", "text": "Structure (category theory)\n\nIn mathematics, progress often consists of recognising the same structure in different contexts, so that one method exploiting it has multiple applications. In fact this is a normal way of proceeding; in the absence of recognisable structure (which might be hidden) problems tend to fall into the combinatorics classification of matters requiring special arguments.\n\nIn category theory \"structure\" is discussed \"implicitly\" — as opposed to the \"explicit\" discussion typical with the many algebraic structures. Starting with a given class of algebraic structure, such as groups, one can build the category in which the objects are groups and the morphisms are group homomorphisms: that is, of structures on one type, and mappings respecting that structure. Starting with a category \"C\" given abstractly, the challenge is to infer what structure it is on the objects that the morphisms 'preserve'. \n\nThe term \"structure\" was much used in connection with the Bourbaki group's approach. There is even a definition. Structure must definitely include topological space as well as the standard abstract algebra notions. Structure in this sense is probably commensurate with the idea of concrete category that can be presented in a definite way — the topological case means that infinitary operations will be needed. \"Presentation of a category\" (analogously to presentation of a group) can in fact be approached in a number of ways, the \"category\" structure not being (quite) an algebraic structure in its own right.\n\nThe term \"transport of structure\" is the 'French' way of expressing \"covariance\" or \"equivariance\" as a constraint: transfer structure by a surjection and then (if there is an existing structure) compare.\n\nSince any group is a one-object category, a special case of the question about \"what the morphisms preserve\" is this: how to consider any group G as a symmetry group? That is answered, as best we can by Cayley's theorem. The analogue in category theory is the Yoneda lemma. One concludes that knowledge on the 'structure' is bound up with what we can say about the representable functors on \"C\". Characterisations of them, in interesting cases, were sought in the 1960s, for application in particular in the moduli problems of algebraic geometry; showing in fact that these are very subtle matters.\n"}
{"id": "246184", "url": "https://en.wikipedia.org/wiki?curid=246184", "title": "Superhuman", "text": "Superhuman\n\nSuperhuman qualities are qualities that exceed those found in humans. \n\nThe \"Übermensch\" or \"Superman\" was postulated by Friedrich Nietzsche as a type of supreme, ultra-aristocratic achievement which becomes possible in the transcendence of modernity, morals or nihilism.\n\nIn transhumanism and futurology, superhuman abilities are the technological aim either of human enhancement by genetic modification or cybernetic implants or of future superhuman artificial intelligence.\n\nSpeculation about human nature and the possibilities of both human enhancement and future human evolution have made superhumans a popular subject of science fiction.\n\nSuperhuman abilities are also associated with the genre of superheroes. \n\nHuman enhancement is an attempt to temporarily or permanently overcome the current limitations of the human body through natural or artificial means. Human enhancement may be through the use of technological means to select or alter human characteristics and capacities, whether or not the alteration results in characteristics and capacities that lie beyond the existing human range.\n\nSome bioethicists restrict the term to the non-therapeutic application of specific technologies — neuro-, cyber-, gene- and nano-technologies — to human biology.\n\nAccording to transhumanist thinkers, a posthuman is a hypothetical future being \"whose basic capacities so radically exceed those of present humans as to be no longer unambiguously human by our current standards.\"\n\n\"Superhuman\" is one of the stages in classification of progress in artificial intelligence where an entity of artificial intelligence performs better than most humans do in a specific task. Examples of where computers have achieved superhuman performance include Backgammon, Bridge, Chess, Reversi, Scrabble, Go and Jeopardy!.\n"}
{"id": "10688611", "url": "https://en.wikipedia.org/wiki?curid=10688611", "title": "Teind", "text": "Teind\n\nIn Scotland a teind was a tithe derived from the produce of the land for the maintenance of the clergy.\n\nIt is also an old lowland term for a tribute due to be paid by the fairies to the devil every seven years. It is known for the devil to give bad luck in the world and the fary to be wiser and grant good luck and a just future. Found in the story of Tam Lin as well as in the ballad of Thomas the Rhymer.\n\nTeind is a Scots word for tithe, meaning a tenth part.\n\n"}
{"id": "18961138", "url": "https://en.wikipedia.org/wiki?curid=18961138", "title": "Tensor rank decomposition", "text": "Tensor rank decomposition\n\nIn multilinear algebra, the tensor rank decomposition or canonical polyadic decomposition (CPD) may be regarded as a generalization of the matrix singular value decomposition (SVD) to tensors, which has found application in statistics, signal processing, psychometrics, linguistics and chemometrics. It was introduced by Hitchcock in 1927 and later rediscovered several times, notably in psychometrics. \nFor this reason, the tensor rank decomposition is sometimes historically referred to as PARAFAC or CANDECOMP.\n\nThe tensor rank decomposition expresses a tensor as a minimum-length linear combination of rank-1 tensors. Such rank-1 tensors are also called simple or pure. A pure tensor is the tensor product of a collection of vectors.\n\nConsider a tensor space formula_1, where formula_2 is either the real field formula_3 or the complex field formula_4. Every (order-formula_5) tensor in this space may then be represented with a suitably large formula_6 as a linear combination of formula_6 rank-1 tensors:\n\nwhere formula_9 and formula_10; note that the superscript formula_11 should not be interpreted as an exponent, it is merely another index. When the number of terms formula_6 is minimal in the above expression, then formula_6 is called the rank of the tensor, and the decomposition is often referred to as a \"(tensor) rank decomposition\", \"minimal CP decomposition\", or \"Canonical Polyadic Decomposition (CPD)\". Contrariwise, if the number of terms is not minimal, then the above decomposition is often referred to as \"formula_6-term decomposition\", \"CANDECOMP/PARAFAC\" or \"Polyadic decomposition\".\n\nContrary to the case of matrices, the rank of a tensor is presently not understood well. It is known that the problem of computing the rank of a tensor is NP-hard. The only notable well-understood case consists of tensors in formula_15, whose rank can be obtained from the Kronecker–Weierstrass normal form of the linear matrix pencil that the tensor represents. A simple polynomial-time algorithm exists for certifying that a tensor is of rank 1, namely the higher-order singular value decomposition.\n\nThe rank of the tensor of zeros is zero by convention. The rank of a tensor formula_16 is one, provided that formula_17.\n\nThe rank of a tensor depends on the field over which the tensor is decomposed. It is known that some real tensors may admit a complex decomposition whose rank is strictly less than the rank of a real decomposition of the same tensor. As an example, consider the following real tensor\n\nwhere formula_19. The rank of this tensor over the reals is known to be 3, while its complex rank is only 2 because it is the sum of a complex rank-1 tensor with its complex conjugate, namely\n\nwhere formula_21.\n\nIn contrast, the rank of real matrices will never decrease under a field extension to formula_4: real matrix rank and complex matrix rank coincide for real matrices.\n\nThe generic rank formula_23 is defined as the least rank formula_6 such that the closure in the Zariski topology of the set of tensors of rank at most formula_6 is the entire space formula_26. In the case of complex tensors, tensors of rank at most formula_23 form a dense set formula_28: every tensor in the aforementioned space is either of rank less than the generic rank, or it is the limit in the Euclidean topology of a sequence of tensors from formula_28. In the case of real tensors, the set of tensors of rank at most formula_23 only forms an open set of positive measure in the Euclidean topology. There may exist Euclidean-open sets of tensors of rank strictly higher than the generic rank. All ranks appearing on open sets in the Euclidean topology are called typical ranks. The smallest typical rank is called the generic rank; this definition applies to both complex and real tensors. The generic rank of tensor spaces was initially studied in 1983 by Volker Strassen.\n\nAs an illustration of the above concepts, it is known that both 2 and 3 are typical ranks of formula_31 while the generic rank of formula_32 is 2. Practically, this means that a randomly sampled real tensor (from a continuous probability measure on the space of tensors) of size formula_33 will be a rank-1 tensor with probability zero, a rank-2 tensor with positive probability, and rank-3 with positive probability. On the other hand, a randomly sampled complex tensor of the same size will be a rank-1 tensor with probability zero, a rank-2 tensor with probability one, and a rank-3 tensor with probability zero. It is even known that the generic rank-3 real tensor in formula_31 will be of complex rank equal to 2.\n\nThe generic rank of tensor spaces depends on the distinction between balanced and unbalanced tensor spaces. A tensor space formula_26, where formula_36,\nis called unbalanced whenever\n\nand it is called balanced otherwise.\n\nWhen the first factor is very large with respect to the other factors in the tensor product, then the tensor space essentially behaves as a matrix space. The generic rank of tensors living in an unbalanced tensor spaces is known to equal\n\nalmost everywhere. More precisely, the rank of every tensor in an unbalanced tensor space formula_39, where formula_40 is some indeterminate closed set in the Zariski topology, equals the above value.\n\nThe generic rank of tensors living in a balanced tensor space is expected to equal\n\nalmost everywhere for complex tensors and on a Euclidean-open set for real tensors, where\n\nMore precisely, the rank of every tensor in formula_43, where formula_40 is some indeterminate closed set in the Zariski topology, is expected to equal the above value. For real tensors, formula_45 is the least rank that is expected to occur on a set of positive Euclidean measure. The value formula_45 is often referred to as the expected generic rank of the tensor space formula_47 because it is only conjecturally correct. It is known that the true generic rank always satisfies\n\nThe Abo–Ottaviani–Peterson conjecture states that equality is expected, i.e., formula_49, with the following exceptional cases:\n\n\nIn each of these exceptional cases, the generic rank is known to be formula_53. The conjecture has been proved completely in a number of special cases. Lickteig showed already in 1985 that formula_54, provided that formula_55. In 2011, a major breakthrough was established by Catalisano, Geramita, and Gimigliano who proved that formula_56, except for the space formula_57.\n\nThe maximum rank that can be admitted by any of the tensors in a tensor space is unknown in general; even a conjecture about this maximum rank is missing. Presently, the best general upper bound states that the maximum rank formula_58 of formula_26, where formula_36, satisfies\n\nwhere formula_23 is the (least) \"generic rank\" of formula_26.\nIt is well-known that the foregoing inequality may be strict. For instance, the generic rank of tensors in formula_64 is two, so that the above bound yields formula_65, while it is known that the maximum rank equals 3.\n\nA rank-formula_66 tensor formula_67 is called a border tensor if there exists a sequence of tensors of rank at most formula_68 whose limit is formula_67. If formula_66 is the least value for which such a convergent sequence exists, then it is called the border rank of formula_67. For order-2 tensors, i.e., matrices, rank and border rank \"always\" coincide, however, for tensors of order formula_72 they may differ. Border tensors were first studied in the context of fast \"approximate\" matrix multiplication algorithms by Bini, Lotti, and Romani in 1980.\n\nA classic example of a border tensor is the rank-3 tensor\n\nIt can be approximated arbitrarily well by the following sequence of rank-2 tensors\n\nas formula_75. Therefore, its border rank is 2, which is strictly less than its rank. When the two vectors are orthogonal, this example is also known as a W state.\n\nIt follows from the definition of a pure tensor that formula_76 if and only if there exist formula_77 such that formula_78 and formula_79 for all \"k\". For this reason, the parameters formula_80 of a rank-1 tensor formula_67 are called identifiable or essentially unique. A rank-formula_6 tensor formula_83 is called identifiable if every of its tensor rank decompositions is the sum of the same set of formula_6 distinct tensors formula_85 where the formula_86's are of rank 1. An identifiable rank-formula_6 thus has only one essentially unique decomposition formula_88and all formula_89 tensor rank decompositions of formula_67 can be obtained by permuting the order of the summands. Observe that in a tensor rank decomposition all the formula_86's are distinct, for otherwise the rank of formula_67 would be at most formula_93.\n\nOrder-2 tensors in formula_94, i.e., matrices, are not identifiable for formula_95. This follows essentially from the observation formula_96where formula_97 is an invertible formula_98 matrix, formula_99 , formula_100, formula_101 and formula_102. It can be shown that for every formula_103, where formula_40 is a closed set in the Zariski topology, the decomposition on the right-hand side is a sum of a different set of rank-1 tensors than the decomposition on the left-hand side, entailing that order-2 tensors of rank formula_105 are generically not identifiable.\n\nThe situation changes completely for higher-order tensors in formula_106 with formula_107 and all formula_108. For simplicity in notation, assume without loss of generality that the factors are ordered such that formula_109. Let formula_110denote the set of tensors of rank bounded by formula_6. Then, the following statement was proved to be correct using a computer-assisted proof for all spaces of dimension formula_112, and it is conjectured to be valid in general: \n\nThere exists a closed set formula_113 in the Zariski topology such that \"every tensor\" formula_114\"is identifiable\" (formula_115 is called generically identifiable in this case), unless either one of the following exceptional cases holds: \nIn these exceptional cases, the generic (and also minimum) number of \"complex\" decompositions is \nIn summary, the generic tensor of order formula_135 and rank formula_136 that is not identifiability-unbalanced is expected to be identifiable (modulo the exceptional cases in small spaces).\n\nThe rank approximation problem asks for the rank-formula_6 decomposition closest (in the usual Euclidean topology) to some rank-formula_66 tensor formula_67, where formula_68. That is, one seeks to solve\n\nwhere formula_142 is the Frobenius norm.\n\nIt was shown in a 2008 paper by de Silva and Lim that the above standard approximation problem may be \"ill-posed\". A solution to aforementioned problem may sometimes not exist because the set over which one optimizes is not closed. As such, a minimizer may not exist, even though an infimum would exist. In particular, it is known that certain so-called \"border tensors\" may be approximated arbitrarily well by a sequence of tensor of rank at most formula_6, even though the limit of the sequence converges to a tensor of rank strictly higher than formula_6. The rank-3 tensor\n\ncan be approximated arbitrarily well by the following sequence of rank-2 tensors\n\nas formula_75. This example neatly illustrates the general principle that a sequence of rank-formula_6 tensors that converges to a tensor of strictly higher rank needs to admit at least two individual rank-1 terms whose norms become unbounded. Stated formally, whenever a sequence\n\nhas the property that formula_150 (in the Euclidean topology) as formula_151, then there should exist at least formula_152 such that\n\nas formula_151. This phenomenon is often encountered when attempting to approximate a tensor using numerical optimization algorithms. It is sometimes called the problem of \"diverging components\". It was, in addition, shown that a random low-rank tensor over the reals may not admit a rank-2 approximation with positive probability, leading to the understanding that the ill-posedness problem is an important consideration when employing the tensor rank decomposition.\n\nA common partial solution to the ill-posedness problem consists of imposing an additional inequality constraint that bounds the norm of the individual rank-1 terms by some constant. Other constraints that result in a closed set, and, thus, well-posed optimization problem, include imposing positivity or a bounded inner product strictly less than unity between the rank-1 terms appearing in the sought decomposition.\n\nAlternating algorithms:\n\nDirect algorithms:\n\nGeneral optimization algorithms:\n\nGeneral polynomial system solving algorithms:\n\n\nIn machine learning, the CP-decomposition is the central ingredient in learning probabilistic latent variables models via the technique of moment-matching. For example, consider the multi-view model which is a probabilistic latent variable model. In this model, the generation of samples are posited as follows: there exists a hidden random variable that is not observed directly, given which, there are several conditionally independent random variables known as the different \"views\" of the hidden variable. For simplicity, assume there are three symmetrical views formula_155 of a formula_11-state categorical hidden variable formula_157. Then the empirical third moment of this latent variable model can be written as:\nformula_158.\n\nIn applications such as topic modeling, this can be interpreted as the co-occurrence of words in a document. Then the eigenvalues of this empirical moment tensor can be interpreted as the probability of choosing a specific topic and each column of the factor matrix formula_159 corresponds to probabilities of words in the vocabulary in the corresponding topic.\n\n\n"}
{"id": "28267215", "url": "https://en.wikipedia.org/wiki?curid=28267215", "title": "Terry O'Gorman", "text": "Terry O'Gorman\n\nTerry O'Gorman is a lawyer in Queensland, Australia and is the president of the Australian Council for Civil Liberties. In 1979, O'Gorman was elected President of the Queensland Council for Civil Liberties and served as president until 1985. He again held presidency from 1990 to 1994. He is currently the Vice President of the QCCL. \n\nO'Gorman specialises in criminal law, yet it was the area of Aboriginal Aid in which he first commenced his legal career. An influential member of the QCCL, \"it was during the days as a university student and under the rule of Joh Bjelke-Petersen that he first became aware of the need to protect civil rights.\" In 2003 he pleaded guilty to drink driving after the vehicle he was driving rolled in to a police car. In 2008 O'Gorman commented that \"civil liberties on the streets have improved, but the battle has moved to a 'law and order auction' being played out in the media, which used to be centred around the political cycle but now appears to be a permanent fixture.\"\n\nRaised in Brisbane, he was one of 15 children raised in a Catholic family which included two police officers, another lawyer, and three nuns. His upbringing could be described as right wing. As a university student during the Bjelke Petersen years, O'Gorman became aware of the need to fight for human rights. His early working years were spent with Aboriginal Legal Aid. It was there that he noticed the brutal treatment of indigenous Australians at the hands of the police. Taking matters into their own hands, O'Gorman and colleagues began secretly taping the police. This resulted in a number of miscarriage of justice cases being proved. \n\nBy cross-examining Joh Bjelke Petersen during the Fitzgerald Inquiry, he was instrumental in changing the thinking and mindset of judges and politicians who refused to believe that the police were abusing their positions of power.\n\nIn later years O'Gorman became involved in the Australian Council of Civil Liberties. He has also been involved in a number of issues involving racism, treatment of asylum-seekers, the introduction of the Smart Card and the Go card. He has also been critical of the way that Australia's police have dealt with indigenous Australians, and the resulting Deaths in custody.\n\nAt present he is a lawyer with Robertson O'Gorman Solicitors. He is President of the Australian Council for Civil Liberties and also the Vice President of the Queensland Council for Civil Liberties.\n\nIn July 2010 it was reported in major newspapers around Australia that people have had their movements tracked by using the Go Card. It had turned out that Australian police had been accessing the Go Card records to find out about the movements of certain people. O'Gorman had commented that he wasn't surprised that the police were accessing Go Card records, stating that previous concerns asserting that Go Cards would be used for surveillance had been justified. O'Gorman also stated that he was unsure if his Go Card was registered, as his wife had obtained it for him, but added that he would be de-registering it. As of August 2010, Queensland Police were set to appeal to the state’s privacy commissioner not to cut their access to the movements of Brisbane's commuters that were recorded on the Go Cards. \nAs a result, O'Gorman has been watching closely the developments that have been taking place.\n"}
{"id": "15732918", "url": "https://en.wikipedia.org/wiki?curid=15732918", "title": "The eclipse of Darwinism", "text": "The eclipse of Darwinism\n\nJulian Huxley used the phrase “the eclipse of Darwinism” to describe the state of affairs prior to what he called the modern synthesis, when evolution was widely accepted in scientific circles but relatively few biologists believed that natural selection was its primary mechanism. Historians of science such as Peter J. Bowler have used the same phrase as a label for the period within the history of evolutionary thought from the 1880s to around 1920, when alternatives to natural selection were developed and explored—as many biologists considered natural selection to have been a wrong guess on Charles Darwin's part, or at least as of relatively minor importance. An alternative term, the interphase of Darwinism, has been proposed to avoid the largely incorrect implication that the putative eclipse was preceded by a period of vigorous Darwinian research.\n\nWhile there had been multiple explanations of evolution including vitalism, catastrophism, and structuralism through the 19th century, four major alternatives to natural selection were in play at the turn of the 20th century:\n\n\nTheistic evolution largely disappeared from the scientific literature by the end of the 19th century as direct appeals to supernatural causes came to be seen as unscientific. The other alternatives had significant followings well into the 20th century; mainstream biology largely abandoned them only when developments in genetics made them seem increasingly untenable, and when the development of population genetics and the modern synthesis demonstrated the explanatory power of natural selection. Ernst Mayr wrote that as late as 1930 most textbooks still emphasized such non-Darwinian mechanisms.\n\nEvolution was widely accepted in scientific circles within a few years after the publication of \"On the Origin of Species\", but acceptance of natural selection as its driving mechanism was much less. Six objections were raised to the theory in the 19th century:\n\n\nBoth Darwin and his close supporter Thomas Henry Huxley freely admitted, too, that selection might not be the whole explanation; Darwin was prepared to accept a measure of Lamarckism, while Huxley was comfortable with both sudden (mutational) change and directed (orthogenetic) evolution.\n\nBy the end of the 19th century, criticism of natural selection had reached the point that in 1903 the German botanist, , wrote that \"We are now standing at the death bed of Darwinism\", and in 1907 the Stanford University entomologist Vernon Lyman Kellogg, who supported natural selection, asserted that \"... the fair truth is that the Darwinian selection theory, considered with regard to its claimed capacity to be an independently sufficient mechanical explanation of descent, stands today seriously discredited in the biological world.\" He added, however, that there were problems preventing the widespread acceptance of any of the alternatives, as large mutations seemed too uncommon, and there was no experimental evidence of mechanisms that could support either Lamarckism or orthogenesis. Ernst Mayr wrote that a survey of evolutionary literature and biology textbooks showed that as late as 1930 the belief that natural selection was the most important factor in evolution was a minority viewpoint, with only a few population geneticists being strict selectionists.\n\nA variety of different factors motivated people to propose other evolutionary mechanisms as alternatives to natural selection, some of them dating back before Darwin's \"Origin of Species\". Natural selection, with its emphasis on death and competition, did not appeal to some naturalists because they felt it was immoral, and left little room for teleology or the concept of progress in the development of life. Some of these scientists and philosophers, like St. George Jackson Mivart and Charles Lyell, who came to accept evolution but disliked natural selection, raised religious objections. Others, such as Herbert Spencer, the botanist George Henslow (son of Darwin's mentor John Stevens Henslow also a botanist), and Samuel Butler, felt that evolution was an inherently progressive process that natural selection alone was insufficient to explain. Still others, including the American paleontologists Edward Drinker Cope and Alpheus Hyatt, had an idealist perspective and felt that nature, including the development of life, followed orderly patterns that natural selection could not explain.\n\nAnother factor was the rise of a new faction of biologists at the end of the 19th century, typified by the geneticists Hugo DeVries and Thomas Hunt Morgan, who wanted to recast biology as an experimental laboratory science. They distrusted the work of naturalists like Darwin and Alfred Russel Wallace, dependent on field observations of variation, adaptation, and biogeography, considering these overly anecdotal. Instead they focused on topics like physiology, and genetics that could be easily investigated with controlled experiments in the laboratory, and discounted natural selection and the degree to which organisms were adapted to their environment, which could not easily be tested experimentally.\n\nBritish science developed in the early 19th century on a basis of natural theology which saw the adaptation of fixed species as evidence that they had been specially created to a purposeful divine design. The philosophical concepts of German idealism inspired concepts of an ordered plan of harmonious creation, which Richard Owen reconciled with natural theology as a pattern of homology showing evidence of design. Similarly, Louis Agassiz saw the recapitulation theory as symbolising a pattern of the sequence of creations in which humanity was the goal of a divine plan. In 1844 \"Vestiges\" adapted Agassiz's concept into theistic evolutionism. Its anonymous author Robert Chambers proposed a \"law\" of divinely ordered progressive development, with transmutation of species as an extension of recapitulation theory. This popularised the idea, but it was strongly condemned by the scientific establishment. Agassiz remained forcefully opposed to evolution, and after he moved to America in 1846 his idealist argument from design of orderly development became very influential. In 1858 Owen cautiously proposed that this development could be a real expression of a continuing creative law, but distanced himself from transmutationists. Two years later in his review of Darwin's \"On the Origin of Species\" Owen attacked Darwin while at the same time openly supporting evolution, expressing belief in a pattern of transmutation by law-like means. This idealist argument from design was taken up by other naturalists such as George Jackson Mivart, and the Duke of Argyll who rejected natural selection altogether in favor of laws of development that guided evolution down preordained paths.\n\nMany of Darwin's supporters accepted evolution on the basis that it could be reconciled with design. In particular, Asa Gray considered natural selection to be the main mechanism of evolution and sought to reconcile it with natural theology. He proposed that natural selection could be a mechanism in which the problem of evil of suffering produced the greater good of adaptation, but conceded that this had difficulties and suggested that God might influence the variations on which natural selection acted to guide evolution. For Darwin and Thomas Henry Huxley such pervasive supernatural influence was beyond scientific investigation, and George Frederick Wright, an ordained minister who was Gray's colleague in developing theistic evolution, emphasised the need to look for secondary or known causes rather than invoking supernatural explanations: \"If we cease to observe this rule there is an end to all science and all sound science.\"\n\nA secular version of this methodological naturalism was welcomed by a younger generation of scientists who sought to investigate natural causes of organic change, and rejected theistic evolution in science. By 1872 Darwinism in its broader sense of the fact of evolution was accepted as a starting point. Around 1890 only a few older men held onto the idea of design in science, and it had completely disappeared from mainstream scientific discussions by 1900. There was still unease about the implications of natural selection, and those seeking a purpose or direction in evolution turned to neo-Lamarckism or orthogenesis as providing natural explanations.\n\nJean-Baptiste Lamarck had originally proposed a theory on the transmutation of species that was largely based on a progressive drive toward greater complexity. Lamarck also believed, as did many others at the time, that characteristics acquired during the course of an organism's life could be inherited by the next generation, and he saw this as a secondary evolutionary mechanism that produced adaptation to the environment. Typically, such characteristics included changes caused by the use or disuse of a particular organ. It was this mechanism of evolutionary adaptation through the inheritance of acquired characteristics that much later came to be known as Lamarckism. Although Alfred Russel Wallace completely rejected the concept in favor of natural selection, Charles Darwin always included what he called \"Effects of the increased Use and Disuse of Parts, as controlled by Natural Selection\" in \"On the Origin of Species\", giving examples such as large ground feeding birds getting stronger legs through exercise, and weaker wings from not flying until, like the ostrich, they could not fly at all.\n\nIn the late 19th century the term neo-Lamarckism came to be associated with the position of naturalists who viewed the inheritance of acquired characteristics as the most important evolutionary mechanism. Advocates of this position included the British writer and Darwin critic Samuel Butler, the German biologist Ernst Haeckel, the American paleontologists Edward Drinker Cope and Alpheus Hyatt, and the American entomologist Alpheus Packard. They considered Lamarckism to be more progressive and thus philosophically superior to Darwin's idea of natural selection acting on random variation. Butler and Cope both believed that this allowed organisms to effectively drive their own evolution, since organisms that developed new behaviors would change the patterns of use of their organs and thus kick-start the evolutionary process. In addition, Cope and Haeckel both believed that evolution was a progressive process. The idea of linear progress was an important part of Haeckel's recapitulation theory of evolution, which held that the embryological development of an organism repeats its evolutionary history. Cope and Hyatt looked for, and thought they found, patterns of linear progression in the fossil record. Packard argued that the loss of vision in the blind cave insects he studied was best explained through a Lamarckian process of atrophy through disuse combined with inheritance of acquired characteristics. Packard also wrote a book about Lamarck and his writings.\n\nMany American proponents of neo-Lamarckism were strongly influenced by Louis Agassiz and a number of them, including Hyatt and Packard, were his students. Agassiz had an idealistic view of nature, connected with natural theology, that emphasized the importance of order and pattern. Agassiz never accepted evolution; his followers did, but they continued his program of searching for orderly patterns in nature, which they considered to be consistent with divine providence, and preferred evolutionary mechanisms like neo-Lamarckism and orthogenesis that would be likely to produce them.\n\nIn Britain the botanist George Henslow, the son of Darwin's mentor John Stevens Henslow, was an important advocate of neo-Lamarckism. He studied how environmental stress affected the development of plants, and he wrote that the variations induced by such environmental factors could largely explain evolution. The historian of science Peter J. Bowler writes that, as was typical of many 19th century Lamarckians, Henslow did not appear to understand the need to demonstrate that such environmentally induced variations would be inherited by descendants that developed in the absence of the environmental factors that produced them, but merely assumed that they would be.\n\nCritics of neo-Lamarckism pointed out that no one had ever produced solid evidence for the inheritance of acquired characteristics. The experimental work of the German biologist August Weismann resulted in the germ plasm theory of inheritance. This led him to declare that inheritance of acquired characteristics was impossible, since the Weismann barrier would prevent any changes that occurred to the body after birth from being inherited by the next generation. This effectively polarised the argument between the Darwinians and the neo-Lamarckians, as it forced people to choose whether to agree or disagree with Weismann and hence with evolution by natural selection. Despite Weismann's criticism, neo-Lamarckism remained the most popular alternative to natural selection at the end of the 19th century, and would remain the position of some naturalists well into the 20th century.\n\nAs a consequence of the debate over the viability of neo-Lamarckism, in 1896 James Mark Baldwin, Henry Fairfield Osborne and C. Lloyd Morgan all independently proposed a mechanism where new learned behaviors could cause the evolution of new instincts and physical traits through natural selection without resort to the inheritance of acquired characteristics. They proposed that if individuals in a species benefited from learning a particular new behavior, the ability to learn that behavior could be favored by natural selection, and the end result would be the evolution of new instincts and eventually new physical adaptations. This became known as the Baldwin effect and it has remained a topic of debate and research in evolutionary biology ever since.\n\nOrthogenesis was the theory that life has an innate tendency to change, in a unilinear fashion in a particular direction. The term was popularized by Theodor Eimer, a German zoologist, in his 1898 book \"On Orthogenesis: And the Impotence of Natural Selection in Species Formation\". He had studied the coloration of butterflies, and believed he had discovered non-adaptive features which could not be explained by natural selection. Eimer also believed in Lamarckian inheritance of acquired characteristics, but he felt that internal laws of growth determine which characteristics would be acquired and guided the long term direction of evolution down certain paths.\n\nOrthogenesis had a significant following in the 19th century, its proponents including the Russian biologist Leo S. Berg, and the American paleontologist Henry Fairfield Osborn. Orthogenesis was particularly popular among some paleontologists, who believed that the fossil record showed patterns of gradual and constant unidirectional change. Those who accepted this idea, however, did not necessarily accept that the mechanism driving orthogenesis was teleological (goal-directed). They did believe that orthogenetic trends were non-adaptive; in fact they felt that in some cases they led to developments that were detrimental to the organism, such as the large antlers of the Irish elk that they believed led to the animal's extinction.\n\nSupport for orthogenesis began to decline during the modern synthesis in the 1940s, when it became apparent that orthogenesis could not explain the complex branching patterns of evolution revealed by statistical analysis of the fossil record by paleontologists. A few biologists however hung on to the idea of orthogenesis as late as the 1950s, claiming that the processes of macroevolution, the long term trends in evolution, were distinct from the processes of microevolution.\n\nMutationism was the idea that new forms and species arose in a single step as a result of large mutations. It was seen as a much faster alternative to the Darwinian concept of a gradual process of small random variations being acted on by natural selection. It was popular with early geneticists such as Hugo de Vries, who along with Carl Correns helped rediscover Gregor Mendel's laws of inheritance in 1900, William Bateson a British zoologist who switched to genetics, and early in his career, Thomas Hunt Morgan.\n\nThe 1901 mutation theory of evolution held that species went through periods of rapid mutation, possibly as a result of environmental stress, that could produce multiple mutations, and in some cases completely new species, in a single generation. Its originator was the Dutch botanist Hugo de Vries. De Vries looked for evidence of mutation extensive enough to produce a new species in a single generation and thought he found it with his work breeding the evening primrose of the genus \"Oenothera\", which he started in 1886. The plants that de Vries worked with seemed to be constantly producing new varieties with striking variations in form and color, some of which appeared to be new species because plants of the new generation could only be crossed with one another, not with their parents. DeVries himself allowed a role for natural selection in determining which new species would survive, but some geneticists influenced by his work, including Morgan, felt that natural selection was not necessary at all. De Vries's ideas were influential in the first two decades of the 20th century, as some biologists felt that mutation theory could explain the sudden emergence of new forms in the fossil record; research on \"Oenothera\" spread across the world. However, critics including many field naturalists wondered why no other organism seemed to show the same kind of rapid mutation.\n\nMorgan was a supporter of de Vries's mutation theory and was hoping to gather evidence in favor of it when he started working with the fruit fly \"Drosophila melanogaster\" in his lab in 1907. However, it was a researcher in that lab, Hermann Joseph Muller, who determined in 1918 that the new varieties de Vries had observed while breeding \"Oenothera\" were the result of polyploid hybrids rather than rapid genetic mutation. While they were doubtful of the importance of natural selection, the work of geneticists like Morgan, Bateson, de Vries and others from 1900 to 1915 established Mendelian genetics linked to chromosomal inheritance, which validated August Weismann's criticism of neo-Lamarckian evolution by discounting the inheritance of acquired characteristics. The work in Morgan's lab with \"Drosophila\" also undermined the concept of orthogenesis by demonstrating the random nature of mutation.\n\nDuring the period 1916–1932, the discipline of population genetics developed largely through the work of the geneticists Ronald Fisher, J.B.S. Haldane, and Sewall Wright. Their work recognized that the vast majority of mutations produced small effects that served to increase the genetic variability of a population rather than creating new species in a single step as the mutationists assumed. They were able to produce statistical models of population genetics that included Darwin's concept of natural selection as the driving force of evolution.\n\nDevelopments in genetics persuaded field naturalists such as Bernhard Rensch and Ernst Mayr to abandon neo-Lamarckian ideas about evolution in the early 1930s. By the late 1930s, Mayr and Theodosius Dobzhansky had synthesized the ideas of population genetics with the knowledge of field naturalists about the amount of genetic diversity in wild populations, and the importance of genetically distinct subpopulations (especially when isolated from one another by geographical barriers) to create the early 20th century modern synthesis. In 1944 George Gaylord Simpson integrated paleontology into the synthesis by statistically analyzing the fossil record to show that it was consistent with the branching non-directional form of evolution predicted by the modern synthesis, and in particular that the linear trends cited by earlier paleontologists in support of Lamarckism and orthogenesis did not stand up to careful analysis. Mayr wrote that by the end of the synthesis natural selection together with chance mechanisms like genetic drift had become the universal explanation for evolutionary change.\n\nThe concept of eclipse suggests that Darwinian research paused, implying in turn that there had been a preceding period of vigorously Darwinian activity among biologists. However, historians of science such as Mark Largent have argued that while biologists broadly accepted the extensive evidence for evolution presented in \"The Origin of Species\", there was less enthusiasm for natural selection as a mechanism. Biologists instead looked for alternative explanations more in keeping with their worldviews, which included the beliefs that evolution must be directed and that it constituted a form of progress. Further, the idea of a dark eclipse period was convenient to scientists such as Julian Huxley, who wished to paint the modern synthesis as a bright new achievement, and accordingly to depict the preceding period as dark and confused. Huxley's 1942 book \"\" therefore, argued Largent, suggested that the so-called modern synthesis began after a long period of eclipse lasting until the 1930s, in which Mendelians, neo-Lamarckians, mutationists, and Weismannians, not to mention experimental embryologists and Haeckelian recapitulationists fought running battles with each other. The idea of an eclipse also allowed Huxley to step aside from what was to him the inconvenient association of evolution with aspects such as social Darwinism, eugenics, imperialism, and militarism. Accounts such as Michael Ruse's very large book \"Monad to Man\" ignored, claimed Largent, almost all the early 20th century American evolutionary biologists. Largent has suggested as an alternative to eclipse a biological metaphor, the interphase of Darwinism, interphase being an apparently quiet period in the cycle of cell division and growth.\n\n\n"}
{"id": "41911440", "url": "https://en.wikipedia.org/wiki?curid=41911440", "title": "Thermodynamic solar panel", "text": "Thermodynamic solar panel\n\nA thermodynamic solar panel is a type of air source heat pump. Instead of a large fan to take energy from the air, it has a flat plate collector. This means the system gains energy from the sun as well as the ambient air. Thermodynamic water heaters use a compressor to transfer the collected heat from the panel to the hot water system using refrigerant fluid that circulates in a closed cycle.\n\nIn the UK, thermodynamic solar panels cannot be used to claim the Renewable Heat Incentive. This is due to the lack of technical standards for the testing and installation. The UK Microgeneration Certification Scheme is working to develop a testing standard, either based on MIS 3001 or MIS 3005 or a brand new scheme document if appropriate.\n\nLab testing has been carried out by Das Wärmepumpen-Testzentrum Buchs (WPZ) in Buchs Switzerland on an Energi Eco 200esm/i thermodynamic solar panel system. This showed a Coefficient of performance of 2.8 or 2.9 (depending on tank volume).\nIn the UK, the first independent test is under-way at Narec Distributed Energy. So far data is available for January to April 2014. As with the Carnot cycle, the achievable efficiency is strongly dependent on the temperatures on both side of the system.\n\n"}
{"id": "51002290", "url": "https://en.wikipedia.org/wiki?curid=51002290", "title": "Walking Artists Network", "text": "Walking Artists Network\n\nThe Walking Artists Network (WAN) is an international network dedicated to walking as a critical and artistic practice; it reflects the growth and increased interest in walking art. It is based at the University of East London's Centre for Performing Arts Development and contains a network of over 500 members from across the globe, though predominantly based in the United Kingdom.\n\nWAN originated in late 2007 when a small group of artists in central London invited ‘all those who are interested in walking as a critical spatial practice’ to its first meeting. It was further developed in 2011 through a successful Arts and Humanities Research Council bid, which provided funding for international development of the network. This enabled it to open up to a wider membership, develop a website and fund the Footwork research group. \nWAN currently runs the Step by Step seminar series at the University of East London, bringing together artists and academics to discuss ideas around walking, and maintains an active email discussion community through JISCmail.\n\nIn 2014 the Walking Artists Network collaborated with Airspace Gallery in Stoke-on-Trent, to produce The Walking Encyclopaedia (2014) a gallery exhibition and online archive of walking practices that includes more than 150 walking practitioners and artworks. In 2015, a collection of walk suggestions, experiences, techniques and case studies by members of the Walking Artists' Network was published by Triarchy Press with the title \"Ways to Wander\".\n\nClare Qualmann (co-founder Walking Artists Network)\n\nDeirdre Heddon\n\nSimone Kenyon\n\nKaren McCoy\n\nAmy Sharrocks\n\nCathy Turner (member of Wrights & Sites).\n\nViv Corringham\n\nMelissa Bliss\n\nPhil Smith\n\nClaire Hind\n\nJess Allen\n\nLucy Frears\n\nBram Arnold\n\nMark Hunter\n\nSimon Pope\n\nJennie Savage\n\nClaire Hind and Clare Qualmann: \"Ways to Wander: 54 intriguing ideas for different ways to take a walk\" Triarchy Press, 2015\n\n"}
{"id": "24004882", "url": "https://en.wikipedia.org/wiki?curid=24004882", "title": "Yakay-Der", "text": "Yakay-Der\n\nYakay-Der (; \"The Association of Solidarity and Assistance for the Families of Missing Persons\") is a Turkish activist group. It was founded on 9 March 2001 to help the families of disappeared Kurds in Turkey. \n\nAccording to Yakar-Der, more than 1,500 persons are unaccounted for following the \"special war\" period in Turkey from 1993 to 1998, in the context of actions taken to root out the PKK. These activities were brought to light in the Susurluk scandal which surfaced in 1996 and resulted in several high-level resignations in the Turkish Government.\n\nThe President of Yakar-Der is Pervin Buldan. \n\nIts stated objectives are:\n\n\nYakar-Der was established as a result of a long struggle organised by what came to be known as the Saturday Mothers, a group of women who protested every Saturday for about two years in front of the Galatasaray High School in Taksim in Istanbul.\nIt is a successor to the Association Mag-Der, which was closed down by the Turkish authorities because of alleged irregularities with respect to the Turkish Law of Associations.\n\nEach year, Yakar-Der, together with the Turkish Human Rights Association (İHD) and the International Committee Against Disappearances (ICAD), organise a series of special events to mark the Week of Disappeared People. In May 2006, they organised the 5th International Conference against Disappearances, in Diyarbakir.\nIn 2008 they organized sit-down strikes, a photo exhibition and panel discussions with the relatives of missing persons. They also filed a complaint with the public prosecutor and demanded the punishment of officials responsible for the disappearance of the missing persons.\n\nIn May 2009, they began a campaign to urge Turkey to ratify the International Convention for the Protection of All Persons from Enforced Disappearances.\n\n\n"}
