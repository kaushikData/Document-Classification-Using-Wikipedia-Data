{"id": "867979", "url": "https://en.wikipedia.org/wiki?curid=867979", "title": "Anti-authoritarianism", "text": "Anti-authoritarianism\n\nAnti-authoritarianism is opposition to authoritarianism, which is defined as \"a form of social organisation characterised by submission to authority\", \"favoring complete obedience or subjection to authority as opposed to individual freedom\" and to authoritarian government. Anti-authoritarians usually believe in full equality before the law and strong civil liberties. Sometimes the term is used interchangeably with anarchism, an ideology which entails opposing authority or hierarchical organization in the conduct of human relations, including the state system.\n\nFreethought is a philosophical viewpoint that holds opinions should be formed on the basis of logic, reason and empiricism, rather than authority, tradition, or other dogmas. The cognitive application of freethought is known as \"freethinking\" and practitioners of freethought are known as \"freethinkers\".\n\nArgument from authority (Latin: \"argumentum ab auctoritate\") is a common form of argument which leads to a logical fallacy when misused. In informal reasoning, the appeal to authority is a form of argument attempting to establish a statistical syllogism. The appeal to authority relies on an argument of the form:\n\nFallacious examples of using the appeal include any appeal to authority used in the context of logical reasoning and appealing to the position of an authority or authorities to dismiss evidence as while authorities can be correct in judgments related to their area of expertise more often than laypersons, they can still come to the wrong judgments through error, bias, dishonesty, or falling prey to groupthink. Thus, the appeal to authority is not a generally reliable argument for establishing facts. Influential anarchist Mikhail Bakunin thought the following: \"Does it follow that I reject all authority? Far from me such a thought. In the matter of boots, I refer to the authority of the bootmaker; concerning houses, canals, or railroads, I consult that of the architect or the engineer. For such or such special knowledge I apply to such or such a savant. But I allow neither the bootmaker nor the architect nor savant to impose his authority upon me. I listen to them freely and with all the respect merited by their intelligence, their character, their knowledge, reserving always my incontestable right of criticism and censure. I do not content myself with consulting a single authority in any special branch; I consult several; I compare their opinions, and choose that which seems to me the soundest. But I recognise no infallible authority, even in special questions; consequently, whatever respect I may have for the honesty and the sincerity of such or such individual, I have no absolute faith in any person\". He saw that \"there is no fixed and constant authority, but a continual exchange of mutual, temporary, and, above all, voluntary authority and subbordination. This same reason forbids me, then, to recognise a fixed, constant and universal authority, because there is no universal man, no man capable of grasping in all that wealth of detail, without which the application of science to life is impossible, all the sciences, all the branches of social life\".\n\nAfter World War II, there was a strong sense of anti-authoritarianism based on anti-fascism in Europe. This was attributed to the active resistance from occupation and to fears arising from the development of superpowers. Anti-authoritarianism has also been associated with countercultural and bohemian movements. In the 1950s, the Beat Generation were politically radical and to some degree their anti-authoritarian attitudes were taken up by activists in the 1960s. The hippie and larger counterculture movements of the 1960s carried out a way of life and activism which was ideally carried through anti-authoritarian and non-violent means. It was observed as such: \"The way of the hippie is antithetical to all repressive hierarchical power structures since they are adverse to the hippie goals of peace, love and freedom... Hippies don't impose their beliefs on others. Instead, hippies seek to change the world through reason and by living what they believe\". In the 1970s, anti-authoritarianism became associated with the punk subculture.\n\n"}
{"id": "41343462", "url": "https://en.wikipedia.org/wiki?curid=41343462", "title": "Asiddhatva", "text": "Asiddhatva\n\nAsiddhatva is a Sanskrit term which is derived from the word, \"Asiddha\" (), which means imperfect, incomplete, unaccomplished, unaffected, unproved, not existing or not having taken effect (as a rule or operation as taught in grammar) or not possessed of magic power. This term refers to the state of imperfection, incompleteness, etc.; or to the state of being imperfect or incomplete etc.; but mainly implies not in existence (Jain usage) or non-existent or no order of taking effect (Sanskrit Grammar).\n\n\"Asiddhatva\", which means - the endless application of rules, occurs on account of conflict or when the question is of conflict, there is no \"asiddhatva\". \"Asiddha\" means – not having taken effect with regard to the application of the other rules belonging to the same section. But, Patanjali states that rules which cause endless repetition of application cannot be there. Therefore, it is said that the application of a rule should certainly result in finality. According to Jainism, the \"audayika-bhava\" has 21 \"bheda\" or sub-species beginning with \"asiddhatva\" which is the state of unholiness, the lacking of spiritual perfection.\nAshtadhyayi reveals that Pāṇini formulates his rules of grammar in view of a \"samanya\" or 'general', \"visesa\" or 'particular' and \"sesa\" or 'residual' relationship. A particular rule is said to carve out its domain of application from within the domain of its corresponding general rule by way of an \"apavada\" i.e. exception, to its related general rule. A rule is formulated to apply and it is never regarded as completely without the scope of its application. In case two rules simultaneously apply the rule subsequent in order blocks the prior rule; though there are some exceptions. Blocking by a \"bhiranga\" or the externally conditioned rule by \"antaranga\" or the internally conditioned rule is permitted. But, since two entities can be replaced by each other the application of rules can be treated as suspended (\"asiddha\").\n\nPanini has used the word - \"asiddha\", three times, that is, in \"Sutra\"s 6.1.86, 6.4.22 and 8.2.1; in \"Sutra\" 6.4.22 he uses the suffix \"vat\" derived from the term \"vati\" meaning – 'as if', which indicates that simultaneous taking effect of rules in \"Abhiya\" section is not permitted. Only when a rule has taken effect does it make sense to say that it is as if it had not taken effect. The phrase \"purvatrasiddham\" of \"Sutra\" 8.2.1 tells us that the rules in \"tripadi\" can be used in a certain order only as found in Ashtadhyayi, therefore, \"asiddha\" determines in what order rules are to be applied.\n\n\"Asiddhatva\", which means - the endless application of rules, occurs on account of conflict or when the question is of conflict, there is no \"asiddhatva\". \"Asiddha\" means – not having taken effect with regard to the application of the other rules belonging to the same section. But, Patanjali states that rules which cause endless repetition of application cannot be there. Therefore, it is said that the application of a rule should certainly result in finality. In the Ashtadhyayi of Panini the \"sutra\"s are declared \"asidddha\" in the following instances:\nThe concept of \"asiddhatva\" has been used in Ashtadhyayi\nfinds its application in the \"viddhi\" \"sutra\"s. As a filter- technique it applies word internally in a pre-suffixal stem-suffix relation. \"Sutra\" 6.4.22 lays down the condition of \"samanasryatva\" having the same conditioning element for \"asiddhatva\". According to the \"siddha\"- principle, all rules interact in a transparent way, whereas the \"asiddha\"-principle is a default principle which can be defeated at cost.\n\nA \"sutra\" or a rule is said to be \"asiddha\" in regard to another if, with respect to this latter, it is conceived of as not to exist. The forms to which a \"sutra\" normally applies are as arise according to \"sutra\"s which are \"siddha\" i.e. the rules that can have an effect. The number of forms which fall under a rule depends on the relation to \"sutra\"s which are \"siddha\". The opportunities for application of a rule to cases are determined by the \"sutra\"s which are \"asiddha\" i.e. do not have an effect, by which the forms are added or excluded, that is, by the \"asiddhatva\" of the one \"sutra\" cases are added to the other or excluded from the other which are \"siddha\". By this method the right tracing of the cases that are to conform to a rule, is secured only if, whether by \"sutra\"s which are \"siddha\" or by such \"asiddha\", those substitutions which are desired or even not desired, are secured or prevented respectively.\n\n\"Sutra\" 6.4.22 which reads - असिद्धवदत्रभात् | (\"asiddhavadatrabhaat\") is an \"adhikara\" \"sutra\" that defines the limits up to which it is valid as अभात् (\"a bhaat\"), in which \"sutra\" the word अत्र (\"atra\") means - in that domain or in the domain of the same conditioning element. The rules in the \"asiddhavat\" section apply in the same conditioning (linguistic) element. The word \"asiddhavat\" is taken as a variant of the word \"asiddha\". The purpose of a \"siddha\" is to allow an operation conditioned by a \"sthanin\" (item to be replaced) or prohibit an operation conditioned by a substitute. \"Asiddhatva\" has a blocking effect and also a feeding effect. \"Asiddhatva\" invariably leads to \"Anavastha\".\n\nThe Jain Philosophy extends the concept of Karman beyond the good and the bad and also beyond their resultant enjoyment or punishment. Each kind of karman works with a specified intensity, and there are eight mula-prakrtis (species) of karmans depending upon their prakrti, stithi, rasa and pradesas, viz. Jnanavarana-karmans which obscure knowledge, Darsanavarna-karmanas which obscure undifferentiated cognition, Vedaniya-karmans which produce the feeling of joy and grief, Mohaniya-karmans which obstruct belief and conduct, Ayus-karmans which determine duration of life, Nama-karmans which give various factors of individuality, Gotra-karmans which define family surroundings and Antaraya-karmans which hinder Jiva’s capability of resolution and enjoyment, and their numerous uttara-prakrtis (sub-species).\n\nThe Jain thinkers believe that the time during which the \"karman\"s work and the intensity with which they manifest themselves is definite and that it is possible for all \"karman\"s to increase or decrease their effects and also transform which transformation they call \"samkarma\". Different kinds of \"karman\" which can be related to one another also establish a relationship with the \"Jiva\" (soul) and the states (\"bhava\") produced in it by them. In the \"Jiva\" there can manifest five states – the \"parinamika\" or the essential state, the \"audayika\" or the state which is the consequence of the unhindered realisation of \"karman\"s, the \"aupasamika\" or the state produced by the suppression of the \"karman\"s, the \"ksayika\" or the state resulting from the annihilation of the \"karman\"s and the \"kasayopasamika\" or the mixed state. The \"audayika-bhava\" has 21 \"bheda\" or sub-species beginning with \"asiddhatva\" which is the state of unholiness, the lacking of spiritual perfection.\n\nIn Jain terminology \"asiddhatva\" refers to the unproved state and to the non-existent i.e. whose existence cannot be proved or to the state of non-salvation. \"Siddha\" is the soul who has attained the status of the supreme Soul by shedding all karmic matter associated with itself and then cease to interfere in the affairs of the universe. \"Asiddhatva\" leads to Anavastha which is a \"dosha\" (defect) according to Hemachandra.\n"}
{"id": "26387082", "url": "https://en.wikipedia.org/wiki?curid=26387082", "title": "Baikal (rocket booster)", "text": "Baikal (rocket booster)\n\nThe Baikal booster (russ. Байкал) was a proposed reusable flyback booster for the Angara rocket family based on the Angara Universal Rocket Module in 2001. It was designed by the Molniya Research and Industrial Corporation (NPO Molniya) for the Khrunichev Space centre, reusing the flyback and control system for the reusable Buran orbiter.\n\nThe booster would be equipped with an RD-191 rocket engine burning kerosene and liquid oxygen to provide approximately 200 tons of thrust. In addition, it would be equipped with a folding wing stored parallel to the fuselage of the vehicle during the booster stage of the flight. After separation from the Angara launcher's second stage at an altitude of about 75 kilometers and a speed of , the Baikal's wing would rotate 90 degrees and the booster glides in upside down position reducing speed. Once the booster reaches subsonic speeds a U turn is performed and an air-breathing RD-33 jet engine in its nose section is started to fly back to its launching site and make a powered horizontal landing on a runway. Apart from economic advantages, this procedure\ngreatly reduces the risk of falling space debris. Reducing this risk was important as the Angara\nrockets will be launched from the deep inland Plesetsk Cosmodrome.\n\nA full-size engineering mock-up of the Baikal was exhibited at the Paris Air Show in July 2001. Similar mockups were tested in wind tunnels of the Central Aero- and Hydrodynamics Institute TsAGI, at speeds of 0.5 - 10 Mach. However, according to unofficial statements by Khrunichev Center representatives, there would have been a long development program to the production of models for captive tests, and the mock-up demonstrated at Le Bourget differs greatly in appearance and design from the Baikal that will actually be launched.\n\nAs in June 2016, the development was essentially complete, but funding for the manufacture of the flying prototype of the recoverable booster was absent due to the low expected launch rate.\n\n\n"}
{"id": "53654146", "url": "https://en.wikipedia.org/wiki?curid=53654146", "title": "Bandenbekämpfung", "text": "Bandenbekämpfung\n\nBandenbekämpfung is a German-language term that means \"bandit fighting\" or \"combating of bandits\". In the context of German military history, \"Bandenbekämpfung\" was an operational doctrine that was part of countering resistance or insurrection in the rear during wars. Another more common understanding of \"Bandenbekämpfung\" is anti-partisan warfare. The doctrine of \"bandit-fighting\" provided a rationale to target and murder any number of groups, from armed guerrillas to civilian population, as \"bandits\" or \"members of gangs\". As applied by the German Empire and then Nazi Germany, it became instrumental in the genocidal programs implemented by the two regimes, including the Holocaust.\n\nUnder the German Empire established by Bismarck in 1871 after the Franco-Prussian War—formed also with the union of twenty-five German states under the Hohenzollern king—Prussian militarism flourished; martial traditions that included the military doctrine of Antoine-Henri Jomini's 1837 treatise, \"Summary of the Art of War\" were put into effect. Some of the theories laid out by Jomini contained instructions for intense offensive operations and the necessity of securing one's \"lines of operations.\" German military officers took this to mean as much attention should be given to logistical operations used to fight the war at the rear as those in the front; this most certainly entailed security operations to protect the lines. Following Jomini's lead, Obersleutnant Albrecht von Boguslawski published lectures entitled \"Der Kleine Krieg\" (The Small War), which outlined in detail the tactical procedures related to partisan and anti-partisan warfare—likely deliberately written without clear distinctions between combatant and non-combatants. To what extent this contributed to the intensification of unrestrained warfare cannot be known, but Prussian officers like Alfred von Schlieffen encouraged his professional soldiers to embrace a dictum advocating that \"for every problem, there was a military solution.\" \n\nPrussian security operations during the Franco-Prussian War included the use of the \"Landwehr\", whose duties ranged from guarding railroad lines, to taking hostages, and carrying out reprisals to deter activities of the \"franc-tireur.\" Foreign Minister of Prussia under Wilhelm I and later German Chancellor, Otto von Bismarck, wanted all \"franc-tireurs\" hung or shot, and encouraged his military commanders to burn down villages that housed them. More formal structures like Chief of the Field Railway, a Military Railway Corps, District Commanders, Special Military Courts, intelligence units, and military police of varying duties and nomenclature were integrated into the Prussian system to bolster security operations all along the military's operational lines. Such was the heritage of German anti-partisan warfare. Operationally, the first attempts to use tactics that would later develop into \"Bandenbekämpfung\" or be recognized as such were carried out in China in the wake of the Boxer Rebellion, after two German officers went missing, which was followed up with more than fifty operations by German troops, who set fire to a village and held prisoners. Shortly after these operations, the infantry was provided with a handbook for \"operations against Chinese bandits\" (\"Bänden\"). The first full application of \"Bandenbekämpfung\" in practice, however, was the Herero and Namaqua genocide, a campaign of racial extermination and collective punishment that the German Empire undertook in German South West Africa (modern-day Namibia) against the Herero and Nama people.\n\nDuring the First World War, the German army ignored many of the commonly understood European conventions of war, when between August and October 1914, they deliberately killed some 6,500 French and Belgian citizens. Throughout the war, Germany's integrated intelligence, perimeter police, guard network, and border control measures all coalesced to define the German military's security operations. Along the Eastern front sometime in August 1915, Field Marshal Falkenhayn established a general government under General von Beseler, creating an infrastructure to support ongoing military operations, which included guards posts, patrols and a security network. Unfortunately, maintaining security meant dealing with Russian prisoners, many of whom tried to sabotage German plans and kill German soldiers, so harsh pacification measures and terror actions were carried out to deal with these partisans (including brutal reprisals against civilians), otherwise known as bandits. Before long, similar practices were being instituted throughout both the Eastern and Western areas of German occupation.\n\nGerman army policy for deterring partisan or \"bandit\" activities against its forces was to strike \"such terror into the population that it loses all will to resist.\" Even before the Nazi campaign in the east had begun, Hitler had already absolved his soldiers from any responsibility for brutality against civilians, expecting his soldiers and police forces to kill anyone that even \"looked askance\" at the German forces. Much of the partisan warfare became an exercise of anti-Semitism, as military commanders like General Bechtolsheim exclaimed that whenever an act of sabotage was committed and one killed the Jews from that village, then \"one can be certain that one has destroyed the perpetrators, or at least those who stood behind them.\" \nWhen the Wehrmacht entered Serbia in 1941, they carried out mass reprisals against partisans by executing Jews there. The commander responsible for combating partisan warfare in 1941, General Böhme, reiterated to the German forces, \"that rivers of German blood\" had been spilled in Serbia during the First World War and the Wehrmacht should consider any acts of violence there as \"avenging these deaths.\" \n\nFrom September 1941 onwards through the course of World War II, the term \"Bandenbekämpfung\" supplanted \"Partisanenkämpfung\" (anti-partisan warfare) to become the guiding principle of Nazi Germany's security warfare and occupational policies; largely as a result of Heinrich Himmler's insistence that for psychological reasons, bandit was somehow preferable. On 23 October 1942, Himmler named SS General Erich von dem Bach-Zalewski the \"Commisioner for anti-bandit warfare.\" Then Himmler transferred SS-Brigadeführer von Gottberg to Belorussia to ensure that the \"Bandenbekämpfung\" operations were conducted on a permanent basis, a task which Gottberg carried out with fanatical ruthlessness, declaring the entire population bandits, Jews, Gypsies, spies, or bandit sympathizers. During Gottberg's first major operations, Operations Nürnberg and Hamburg, conducted between November thru December 1942, he reported 5,000 murdered Jews, another 5,000 bandits or suspects eliminated, and 30 villages burned down. \n\nIn October 1942—just a couple months prior to Gottberg's exploits—Reichsmarschall Hermann Göring had ordered \"anti-bandit warfare\" in Army Group Rear Area Center, which was shortly followed by an OKH Directive on 11 November 1942 for \"anti-bandit warfare in the East\" that announced sentimental considerations as \"irresponsible\" and instructed the men to shoot or preferably hang bandits, including women. Misgivings from commanders within Army Group Rear that such operations were counterproductive and in poor taste since women and children were being murdered went ignored or resisted from Bach-Zalewski, who frequently \"cited the special powers of the Reichsführer.\" Over time, the Wehrmacht acculturated to the large scale anti-bandit operations, as the enemy was not simply populated by partisan groups, but instead they too came to see the entire population as criminal and complicit in any operation against German troops. In fact, many of the Wehrmacht commanders were unbothered by the fact that these operations fell under the jurisdiction of the SS. \n\nEinsatzgruppen, Order Police, Sonderkommando units, and army forces—for the most part—worked cooperatively to combat partisans (bandits), not only acting as judge, jury, and executioners in the field, but also in plundering \"bandit areas\"; they laid these areas to waste, seized crops and livestock, enslaved the local population or murdered them. Anti-bandit operations were characterized by \"special cruelty.\" For instance, Soviet Jews were murdered outright under the pretext that they were partisans per Hitler's orders. Historian Timothy Snyder asserts that by the second half of 1942, \"German anti-partisan operations were all but indistinguishable from the mass murder of the Jews.\" Other historians have made similar observations. Omer Bartov argued that under the auspices of destroying their \"so-called political and biological enemies,\" often described as \"bandits\" or \"partisans,\" the Nazis made no effort \"to distinguish between real guerrillas, political suspects, and Jews.\" \n\nSurging operations from better equipped partisans against Army Group Center during 1943 intensified to the degree that the 221st Security Division's did not just eliminate \"bandits\" but laid entire regions where they operated to waste. The scale of this effort must be taken into consideration, as historian Michael Burleigh reports that anti-partisan operations had a significant impact on German operations in the East; namely, since they caused \"widespread economic disruption, tied down manpower which could have been deployed elsewhere, and by instilling fear and provoking extreme countermeasures, drove a wedge between occupiers and occupied.\" \n\nFollowing the Warsaw Uprising of August 1944, the Nazis intensified their anti-partisan operations in Poland, during which the German forces employed their version of anti-partisan tactics by shooting upwards of 120,000 civilians in Warsaw. Ideologically speaking, since partisans represented an immediate existential threat, in that, they were equated with Jews or people under their influence, the systematic murder of anyone associated with them was an expression of the regime's racial anti-Semitism and was viewed by members of the Wehrmacht as a \"necessity of war.\" \n\nThroughout the war in Europe, and especially during the German-Soviet War, 1941–45, these doctrines amalgamated with the Nazi regime's genocidal plans for the racial reshaping of the Eastern Europe to secure \"living space\" (\"Lebensraum\") for Germany. In the first eleven months of the war against the Soviet Union, the German forces liquidated in excess of 80,000 \"alleged\" partisans. Implemented by units of the SS, Wehrmacht and Order Police, \"Bandenbekämpfung\" as applied by the Nazi regime and directed by the SS across occupied Europe led to mass crimes against humanity and was an instrumental part of the Holocaust.\n\nIn July 1942, Heinrich Himmler, the head of the SS, was appointed to lead the security initiatives in rear areas. One of his first actions in this role was the prohibition of the use of \"partisan\" to describe counter-insurgents. Bandits (\"Banden\") was the term chosen to be used by German forces instead. Hitler insisted that Himmler was \"solely responsible\" for combating bandits except in districts under military administration; such districts were under the authority of the Wehrmacht. The organisational changes, putting experienced SS killers in charge, and language that criminalised resistance, whether real or imagined, presaged the transformation of security warfare into massacres. \n\nThe radicalisation of \"anti-bandit\" warfare saw further impetus in the Führer Directive 46 of 18 August 1942, where security warfare's aim was defined as \"complete extermination\". The directive called on the security forces to act with \"utter brutality\", while providing immunity from prosecution for any acts committed during \"bandit-fighting\" operations.\n\nThe directive designated the SS as the organisation responsible for rear-area warfare in areas under civilian administration. In areas under military jurisdiction (the Army Group Rear Areas), the Army High Command had the overall responsibility. The directive declared the entire population of \"bandit\" (i.e. partisan-controlled) territories as enemy combatants. In practice, this meant that the aims of security warfare was not pacification, but complete destruction and depopulation of \"bandit\" and \"bandit-threatened\" territories, turning them into \"dead zones\" (\"Tote Zonen\").\n\n\n"}
{"id": "20041308", "url": "https://en.wikipedia.org/wiki?curid=20041308", "title": "Berezin integral", "text": "Berezin integral\n\nIn mathematical physics, a Berezin integral, named after Felix Berezin, (or Grassmann integral, after Hermann Grassmann) is a way to define integration of elements of the exterior algebra (Hermann Grassmann 1844). It is called integral because it is used in physics as a sum over histories for fermions, an extension of the path integral.\n\nLet formula_1 be the exterior algebra of polynomials in anticommuting elements formula_2 over the field of complex numbers. (The ordering of the generators formula_3 is fixed and defines the orientation of the exterior algebra.) The Berezin integral on formula_4 is the linear functional formula_5 with the following properties:\n\nfor any formula_8 where formula_9 means the left or the right partial derivative. These properties define the integral uniquely. The formula\n\nexpresses the Fubini law. On the right-hand side, the interior integral of a monomial formula_11 is set to be formula_12 where formula_13; the integral of formula_14 vanishes. The integral with respect to formula_15 is calculated in the similar way and so on.\n\nLet formula_16 be odd polynomials in some antisymmetric variables formula_17. The Jacobian is the matrix\n\nwhere the left and the right derivatives coincide and are even polynomials. The formula for the coordinate change reads\n\nConsider now the algebra formula_20 of functions of real commuting variables formula_21 and of anticommuting variables formula_22 (which is called the free superalgebra of dimension formula_23). This means that an element formula_24 is a function of the argument formula_25 that varies in an open set formula_26 with values in the algebra formula_27 Suppose that this function is continuousformula_28and vanishes in the complement of a compact set formula_29 The Berezin integral is the number\n\nLet a coordinate transformation be given by formula_31, where formula_32 are even and formula_33 are odd polynomials of formula_34 depending on even variables formula_35 The Jacobian matrix of this transformation has the block form:\n\nwhere each even derivative formula_37 commutes with all elements of the algebra formula_20; the odd derivatives commute with even elements and anticommute with odd elements. The entries of the diagonal blocks formula_39 and formula_40 are even and the entries of the offdiagonal blocks formula_41 are odd functions, where formula_42 mean right derivatives. The Berezinian (or the superdeterminant) of the matrix formula_43 is the even function\n\ndefined when the function formula_45 is invertible in formula_46 Suppose that the real functions formula_47 define a smooth invertible map formula_48 of open sets formula_49 in formula_50 and the linear part of the map formula_51 is invertible for each formula_52 The general transformation law for the Berezin integral reads\n\nwhere formula_55 is the sign of the orientation of the map formula_56 The superposition formula_57 is defined in the obvious way, if the functions formula_58 do not depend on formula_59 In the general case, we write formula_60 where formula_61 are even nilpotent elements of formula_20 and set\n\nwhere the Taylor series is finite.\n\nThe mathematical theory of the integral with commuting and anticommuting variables was invented and developed by Felix Berezin. Some important earlier insights were made by David John Candlin. Other authors contributed to these developments, including the physicists Khalatnikov (although his paper contains mistakes), Matthews and Salam, and Martin.\n\n"}
{"id": "49021304", "url": "https://en.wikipedia.org/wiki?curid=49021304", "title": "C6.org", "text": "C6.org\n\nc6.org was an international media art and street art collective centred in London active from 1997 to 2010.\n\nThe group combined graffiti, new media art and performance art with political commentary throughout the 90s.\n\nThe founder of the group Leon Sessix also makes street art and stencil graffiti under the name Dotmasters.\n"}
{"id": "54395096", "url": "https://en.wikipedia.org/wiki?curid=54395096", "title": "Case-based evidence", "text": "Case-based evidence\n\nCase-based evidence is a scientific method based on the supposition that certain human behavioural patterns, also including basic attitudes and stances, and with particular reference to the acceptance of systems, technical devices and procedures, can be transferred from a series of given problems, the 'analogical sources', to another, current problem, the 'analogical target'. \nThe term \"case-based evidence“ and the procedure described in the following was first used and coined in work carried out by the Information Management Institute (IMI) of the Aschaffenburg University of Applied Sciences. (Professor Georg Rainer Hofmann) in 2009.\n\nThe case-based evidence method involves a number of steps. Analogies form the core of the method; the findings thus supplied comprise mechanisms that are (presumed to be) transferable from analogical sources to a current case. These mechanisms are then presented in a synoptic model and ultimately tested in a series of qualified expert interviews.\n\nOutlining the problem can be seen as the most important fundamental factor determining the process of locating suitable analogies. Only when the research question precisely addresses the most urgent knowledge gap that is relevant for gaining acceptance will it be possible to search for and find suitable analogous cases in which this knowledge gap can be closed as exactly, precisely and appropriately as possible.\n\nIn order to find suitable analogies, it is first necessary to closely examine the case at hand, the analogical target, and the problem to be solved. This consists of locating those components that are presumed to have the greatest influence on the problem to be solved. Relevant analogical components can be found in:\nThere is as yet no known algorithm-based solution for accurately locating a feasible analogy. However, an analogy will only prove to be feasible once it is based on relevant analogical components.\n\nBased on these found analogical components and the abstract formulation of the problem, a search can be made for analogous cases – the analogical sources. The search for analogous cases can be performed from two perspectives:\n\nThe point in the case-based evidence process at which further research is appropriate depends on the expertise that is available ad hoc with respect to the analogical goal and the analogical sources. The aim of the research and theoretical preconsiderations is to research and document both the analogical target, which is predetermined, and all the information relevant to the analogical sources that is 'unproblematically researchable'. As for determining the extent of the research, there is no real guide value, but a pragmatic approach would be to avoid trivial questions being asked in the subsequent expert interviews, answers to which may be found by a simple query in an Internet search engine.\n\nThe components of analogical conclusions in the case-based evidence method can be described as follows: \n\nThe fine art consists of locating precisely these feasible analogies and transferring the attitude and behaviour schemas thus identified to the problem of the current case, such as the market acceptance of an innovative IT system. The connection between the analogical source and the analogical target is admittedly not a causal one, as they are 'really' independent of each other. However, it can be observed in many examples that certain mechanisms, such as people's behavioural patterns, can be transferred from one case to another. In cognitive psychology, the ability to perceive analogies and transfer found isomorphs from analogical source to analogical target is a central process, and is even deemed an absolutely fundamental cultural achievement of mankind. This circumstance is currently the subject of intensive discussion in modern popular scientific literature. It should nevertheless be stated that from a scientific-theoretical point of view, the formation of analogies has no causal-methodical basis whatsoever. Here, the principle of cause and effect stands back in favour of the means-to-an-end principle.\n\nSynoptic modelling, according to the encyclopaedic guidelines of Jürgen Mittelstraß, has to satisfy the following criteria:\n\nA further factor is the aspect of deficiencies in the model, such as redundancies, tautologies and contradictions. It has not gone unrecognised that synoptic modelling has a certain 'degree of creativeness'. \n\nIn a third step, to verify the evidence, the conclusions are assessed by means of structured interviews with selected experts (analogical source). Rather than questioning a large number of 'representative' people, a comparatively (or even very) small group is subjected to qualified and structured interviewing. The selection of those questioned presumes the so-called 'expert assumption' and attempts to include as fully as possible the expertise to be covered.\nA certain degree of dismissiveness has established itself in the context of empirical findings, when empirical research is based on a small 'n', i.e. the findings are based on a small number of interviews. This is inexplicable taking into consideration the small overall number of qualified persons who can be questioned.\n\nCase-based evidence has proven itself particularly well when it comes to the investigation of acceptance and trust in products and processes. In this area, forecasts of the probable acceptance of new products, services, processes, or similar can often be made with particular success and indications extracted from isomorphic cases as to how the probability of acceptance can be increased in particular cases. \nThese approaches take into consideration a close cooperation with other academics – both scientists and practitioners – with regard to the following points:\n\nAs the field of business information systems developed over the thirty year period between around 1980 and 2010, it took on an interface function that places it between the technically based field of (core) computer science and the application-oriented field of business management. These two central questions, the one of a technical (concerning engineering design) and the other of a business management (concerning the useful value of the applications) nature, together form one of the focuses of business informatics in the German-speaking world. The method of case-based evidence is based on analogy, in contrast to learning through inductive reasoning and deductive reasoning. In business informatics, drawing inductive conclusions from observed phenomena and applying them to more general knowledge ('economic theory') is a widespread way of evaluating technical and economic systems. \nIn turn, (predictive) deductions are made from 'theory' onto new or future phenomena. It is the subject of heated discussion ('based on scientific theory') what precise form inductive conclusions and the deduction process should have; one expression of this is that of design science research. In particular, critical rationalism along the lines of Karl Popper rejects induction as an illusion and disputes the possibility of objective knowledge progress, in distinct contrast to the objective progress of knowledge in Hegel's dialectic.\nRegarding the observation of personal behaviour – in the social sciences – inductive conclusions are often difficult, because they frequently involve quantitative, ambiguous statements ('half and half' statements). Hence, the formulation of generally valid laws of social behaviour is often dispensed with in favour of a 'quantifying' – as it were prosaic – presentation. \nOne way out of this hardly satisfying situation is to do away with spatially and temporally unlimited 'natural scientific' theories ('grand theories'), in favour of the middle range theory. This term was established by Robert K. Merton in 1949 and further elaborated on in the 1960s. The middle range theories go beyond the mere empirical description of social behavioural modes and pursue a subjective-interpretative approach which is rooted in the synoptic modelling that is based on historical-empirical observation; local, spatially and temporally restricted statements are then sufficient. The statements of the theories of middle range should be regarded as neither highly complex nor trivial. \n\nThe examples referred to in the following refer to work carried out at the Information Management Institute of the Aschaffenburg University of Applied Sciences.\n\nThe study into the acceptance of cloud computing by IMI and EuroCloud Deutschland_eco e. V. aimed at developing practicable measures that are useful when it comes to alleviating the deficient market acceptance of cloud computing. In turn, the reason why market acceptance seemed lacking appeared to stem from deficient operational and data security as well as legal considerations. \nAs shown by a comparison of other, isomorphic cases (acceptance of premium motor cars, bank products, DATEV eG), several aspects, such as technical features or purchase price, which are currently regarded as significant in the cloud computing discussion, can be deemed here as non-decisive purchasing factors. It would be far more conducive to reinforce the trust of buyers and the usefulness of the product, by means of the following essential factors:\n\nFor the cloud computing industry, the building up of a 'culture of trust' to gain the acceptance of private and commercial customers will be indispensable. This undertaking will doubtlessly take a certain amount of time and will not respond to any attempt at forcing; however, it does lend itself to positive influencing and correct orientation by applying the measures identified in the project.\n\nThe work being done at the IMI on the acceptance of recycling IT terminal equipment pursues the basic idea of addressing the attitude towards recycling IT terminal equipment, for example, discarded mobile phones, on the one hand by analysing isomorphic scenarios and on the other by conducting expert interviews. The isomorphic scenarios analysed were the recycling of drinks bottles and cans (including those with a single-use deposit or drink can deposit), second-hand clothing, and the return and recycling of waste oil in the mineral oil industry. In addition, the technical problems encountered in disposing of and reconditioning mobile telephones were discussed. The results obtained were compiled into an action framework for shaping the process of introducing recycling systems for IT terminal equipment. However the business foundation for the operative implementation was withdrawn following a change in the regulatory position (municipal 'notification requirement') in mid-2012.\n\nAn analogical conclusion from the historical development of automobility can be drawn for the acceptance of electromobility. Accordingly, the spread of two-wheeled automobiles was a precursor to that of the four-wheeled automobile. This suggests that it would be advisable to devote particular attention to the market development of electric bicycles and motorcycles. The debate on net neutrality calls on the one hand for a network that does not distinguish between communications on the basis of their content and in which data is treated the same irrespective of the sender and receiver. The aim is to avoid competition-distorting measures that would promote the formation of a monopoly. In the case of a data bottleneck in the Internet, no distinction is made in terms of the content being transported. On the other hand, the debate also calls for an egalitarian net that does not admit differences in service class. This means in turn that there is no way of ensuring the service quality of a particular transmission. In this example, knowledge can be enhanced by drawing analogical conclusions from public road traffic: mechanisms such as special lanes for buses or bicycles in cities, special rights for emergency vehicles of the rescue services, from regulations, such as those controlling oversize transports or convoys, and from a drop in or absence of marginal costs, represented by an Internet flat rate. Each of these displays interesting isomorphic analogies.\n"}
{"id": "1418321", "url": "https://en.wikipedia.org/wiki?curid=1418321", "title": "Castles &amp; Crusades", "text": "Castles &amp; Crusades\n\nCastles & Crusades (C&C) is a fantasy role-playing game published in 2004 by Troll Lord Games based upon a stripped-down variant of the d20 System by Wizards of the Coast. The game system is designed to emulate the play of earlier editions of the \"Dungeons & Dragons\" game while keeping the unified mechanics of the d20 System.\n\nThe name of the game derives from the Castle & Crusade Society, founded in the pre-\"Dungeons & Dragons\" era by Gary Gygax. The title is in homage to the role-playing industry's birth.\n\nThe game was initially released in 2004 in a special boxed edition consisting of three digest-sized booklets, dice, and a crayon in a white box with artwork by artist Peter Bradley of a knight on horseback. The reason for the box set was to have something on hand for sale at Gen Con as the finished product was still several months away. A boxed set was chosen for its resemblance to the earliest versions of \"Dungeons & Dragons\", which could be found, depending upon printing, in either a woodgrain box or a white one. As a promotion through the company's website, the first 300 copies were signed and numbered by the designers. \n\nLater that year, the first printing of the \"Players Handbook\" was released. Since that time, the \"Players Handbook\" has seen additional reprints, in 2005, 2007, 2009, 2012, and 2014. The companion volume, \"Monsters & Treasure\", was released in 2005, with additional reprints published in 2007, 2009 and 2015. The \"Castle Keeper's Guide\" was published in 2010, with a second printing in 2015.\n\n\"Castles & Crusades\"s game mechanics are based on the d20 system, designed by Wizards of the Coast. The system has been modified to create a simplified version of the game. All the core classes and races, the alignment system, attributes and hit points systems were retained with only slight adjustments in hit dice. The highly intricate system of skills and feats found in \"Dungeons & Dragons\" 3rd edition was discarded, replaced by what the designers call the \"Siege Engine\", intended as an extremely easy game mechanic with universal applications. The game is compliant with the terms of the Open Game License. The game was later nominated for a 2005 ENnie Award for Best d20 Game.\n\nThe Siege Engine works on an attribute check system. A character's attributes are divided into primary and secondary attributes. Checks made against primary attributes have a base Challenge Base (or target number; abbreviated \"CB\") of 12, while secondary attributes have a CB of 18. The game's referee, the Castle Keeper, adds a challenge level (usually from 1-10, depending on task difficulty) to the CB and the resulting number, the challenge class or CC, is the final target number required to succeed at a check. The player adds the character's level, any attribute bonuses and class bonuses to the roll of a twenty-sided die. If the result after bonuses equals or exceeds the challenge class, the player succeeds. Except for combat, the Siege Engine is used for anything that requires a check in the game.\n\nWhile the first two printings of the \"Players Handbook\" were virtually identical with the exception of a change in font for the headers, the third printing introduced a replacement barbarian class. The 4th printing introduced an expansion to the illusionist written by James M. Ward that allowed the illusionist to heal others. The current printing introduces a streamlined replacement to the game's encumbrance rules for faster play.\n\nThe core books of the game are setting-agnostic. While players can set the adventure in any setting they wish, some settings have been published for the game.\n\n\n\n\n\n"}
{"id": "72717", "url": "https://en.wikipedia.org/wiki?curid=72717", "title": "Categorization", "text": "Categorization\n\nCategorization is the process in which ideas and objects are recognized, differentiated, and understood. Categorization implies that objects are grouped into categories, usually for some specific purpose. Ideally, a category illuminates a relationship between the subjects and objects of knowledge. Categorization is fundamental in language, prediction, inference, decision making and in all kinds of environmental interaction. It is indicated that categorization plays a major role in computer programming.\n\nThere are many categorization theories and techniques. In a broader historical view, however, three general approaches to categorization may be identified:\n\nClassical categorization first appears in the context of Western Philosophy in the work of Plato, who, in his Statesman dialogue, introduces the approach of grouping objects based on their similar properties. This approach was further explored and systematized by Aristotle in his Categories treatise, where he analyzes the differences between classes and objects. Aristotle also applied intensively the classical categorization scheme in his approach to the classification of living beings (which uses the technique of applying successive narrowing questions such as \"Is it an animal or vegetable?\", \"How many feet does it have?\", \"Does it have fur or feathers?\", \"Can it fly?\"...), establishing this way the basis for natural taxonomy.\n\nThe classical Aristotelian view claims that categories are discrete entities characterized by a set of properties which are shared by their members. In analytic philosophy, these properties are assumed to establish the conditions which are both necessary and sufficient conditions to capture meaning.\n\nAccording to the classical view, categories should be clearly defined, mutually exclusive and collectively exhaustive. This way, any entity of the given classification universe belongs unequivocally to one, and only one, of the proposed categories.\n\nConceptual clustering is a modern variation of the classical approach, and derives from attempts to explain how knowledge is represented. In this approach, classes (clusters or entities) are generated by first formulating their conceptual descriptions and then classifying the entities according to the descriptions.\n\nConceptual clustering developed mainly during the 1980s, as a machine paradigm for unsupervised learning. It is distinguished from ordinary data clustering by generating a concept description for each generated category.\n\nCategorization tasks in which category labels are provided to the learner for certain objects are referred to as supervised classification, supervised learning, or concept learning. Categorization tasks in which no labels are supplied are referred to as unsupervised classification, unsupervised learning, or data clustering. The task of supervised classification involves extracting information from the labeled examples that allows accurate prediction of class labels of future examples. This may involve the abstraction of a rule or concept relating observed object features to category labels, or it may not involve abstraction (e.g., exemplar models). The task of clustering involves recognizing inherent structure in a data set and grouping objects together by similarity into classes. It is thus a process of \"generating\" a classification structure.\n\nConceptual clustering is closely related to fuzzy set theory, in which objects may belong to one or more groups, in varying degrees of fitness.\n\nSince the research by Eleanor Rosch and George Lakoff in the 1970s, categorization can also be viewed as the process of grouping things based on prototypes—the idea of necessary and sufficient conditions is almost never met in categories of naturally occurring things. It has also been suggested that categorization based on prototypes is the basis for human development, and that this learning relies on learning about the world via embodiment.\n\nA cognitive approach accepts that natural categories are graded (they tend to be fuzzy at their boundaries) and inconsistent in the status of their constituent members.\n\nSystems of categories are not objectively \"out there\" in the world but are rooted in people's experience. Conceptual categories are not identical for different cultures, or indeed, for every individual in the same culture.\n\nCategories form part of a hierarchical structure when applied to such subjects as taxonomy in biological classification: higher level: life-form level, middle level: generic or genus level, and lower level: the species level. These can be distinguished by certain traits that put an item in its distinctive category. But even these can be arbitrary and are subject to revision.\n\nCategories at the middle level are perceptually and conceptually the more salient. The generic level of a category tends to elicit the most responses and richest images and seems to be the psychologically basic level. Typical taxonomies in zoology for example exhibit categorization at the embodied level, with similarities leading to formulation of \"higher\" categories, and differences leading to differentiation within categories.\n\nMiscategorization can be a logical fallacy in which diverse and dissimilar objects, concepts, entities, etc. are grouped together based upon illogical common denominators, or common denominators that virtually any concept, object or entity have in common. A common way miscategorization occurs is through an over-categorization of concepts, objects or entities, and then miscategorization based upon characters that virtually all things have in common.\n\n\n"}
{"id": "173937", "url": "https://en.wikipedia.org/wiki?curid=173937", "title": "Cosmological principle", "text": "Cosmological principle\n\nIn modern physical cosmology, the cosmological principle is the notion that the spatial distribution of matter in the universe is homogeneous and isotropic when viewed on a large enough scale, since the forces are expected to act uniformly throughout the universe, and should, therefore, produce no observable irregularities in the large-scale structuring over the course of evolution of the matter field that was initially laid down by the Big Bang.\n\nAstronomer William Keel explains:\n\nThe cosmological principle is usually stated formally as 'Viewed on a sufficiently large scale, the properties of the universe are the same for all observers.' This amounts to the strongly philosophical statement that the part of the universe which we can see is a fair sample, and that the same physical laws apply throughout. In essence, this in a sense says that the universe is knowable and is playing fair with scientists.\n\nThe cosmological principle depends on a definition of \"observer,\" and contains an implicit qualification and two testable consequences.\n\n\"Observers\" means any observer at any location in the universe, not simply any human observer at any location on Earth: as Andrew Liddle puts it, \"the cosmological principle [means that] the universe looks the same whoever and wherever you are.\"\n\nThe qualification is that variation in physical structures can be overlooked, provided this does not imperil the uniformity of conclusions drawn from observation: the Sun is different from the Earth, our galaxy is different from a black hole, some galaxies advance toward rather than recede from us, and the universe has a \"foamy\" texture of galaxy clusters and voids, but none of these different structures appears to violate the basic laws of physics.\n\nThe two testable structural consequences of the cosmological principle are homogeneity and isotropy. Homogeneity means that the same observational evidence is available to observers at different locations in the universe (\"the part of the universe which we can see is a fair sample\"). Isotropy means that the same observational evidence is available by looking in any direction in the universe (\"the same physical laws apply throughout\" ). The principles are distinct but closely related, because a universe that appears isotropic from any two (for a spherical geometry, three) locations must also be homogeneous.\n\nThe cosmological principle is first clearly asserted in the \"Philosophiæ Naturalis Principia Mathematica\" (1687) of Isaac Newton. In contrast to earlier classical or medieval cosmologies, in which Earth rested at the center of universe, Newton conceptualized the Earth as a sphere in orbital motion around the Sun within an empty space that extended uniformly in all directions to immeasurably large distances. He then showed, through a series of mathematical proofs on detailed observational data of the motions of planets and comets, that their motions could be explained by a single principle of \"universal gravitation\" that applied as well to the orbits of the Galilean moons around Jupiter, the Moon around the Earth, the Earth around the Sun, and to falling bodies on Earth. That is, he asserted the equivalent material nature of all bodies within the Solar System, the identical nature of the Sun and distant stars and thus the uniform extension of the physical laws of motion to a great distance beyond the observational location of Earth itself.\n\nObservations show that more distant galaxies are closer together and have lower content of chemical elements heavier than lithium. Applying the cosmological principle, this suggests that heavier elements were not created in the Big Bang but were produced by nucleosynthesis in giant stars and expelled across a series of supernovae explosions and new star formation from the supernovae remnants, which means heavier elements would accumulate over time. Another observation is that the furthest galaxies (earlier time) are often more fragmentary, interacting and unusually shaped than local galaxies (recent time), suggesting evolution in galaxy structure as well.\n\nA related implication of the cosmological principle is that the largest discrete structures in the universe are in mechanical equilibrium. Homogeneity and isotropy of matter at the largest scales would suggest that the largest discrete structures are parts of a single indiscrete form, like the crumbs which make up the interior of a cake. At extreme cosmological distances, the property of mechanical equilibrium in surfaces lateral to the line of sight can be empirically tested; however, under the assumption of the cosmological principle, it cannot be detected parallel to the line of sight (see timeline of the universe).\n\nCosmologists agree that in accordance with observations of distant galaxies, a universe must be non-static if it follows the cosmological principle. In 1923, Alexander Friedmann set out a variant of Einstein's equations of general relativity that describe the dynamics of a homogeneous isotropic universe. Independently, Georges Lemaître derived in 1927 the equations of an expanding universe from the General Relativity equations. Thus, a non-static universe is also implied, independent of observations of distant galaxies, as the result of applying the cosmological principle to general relativity.\n\nKarl Popper criticized the cosmological principle on the grounds that it makes \"our \"lack\" of knowledge a principle of \"knowing something\"\". He summarized his position as:\n\nAlthough the universe is inhomogeneous at smaller scales, it \"is\" statistically homogeneous on scales larger than 250 million light years. The cosmic microwave background is isotropic, that is to say that its intensity is about the same whichever direction we look at.\n\nHowever, recent findings have called this view into question. Data from the Planck Mission shows hemispheric bias in 2 respects: one with respect to average temperature (i.e. temperature fluctuations), the second with respect to larger variations in the degree of perturbations (i.e. densities). Therefore, the European Space Agency (the governing body of the Planck Mission) has concluded that these anisotropies are, in fact, statistically significant and can no longer be ignored.\n\nThe \"cosmological principle\" implies that at a sufficiently large scale, the universe is homogeneous. This means that different places will appear similar to one another, so sufficiently large structures cannot exist. Yadav and his colleagues have suggested a maximum scale of 260/h Mpc for structures within the universe according to this heuristic. Other authors have suggested values as low as 60/h Mpc. Yadav's calculation suggests that the maximum size of a structure can be about 370 Mpc.\n\nA number of observations conflict with predictions of maximal structure sizes:\n\n\nIn September 2016, however, studies of the expansion of the Universe that have used data taken by the \"Planck\" mission show it to be highly isotropical, reinforcing the cosmological principle\n\nThe perfect cosmological principle is an extension of the cosmological principle, and states that the universe is homogeneous and isotropic in space \"and\" time. In this view the universe looks the same everywhere (on the large scale), the same as it always has and always will. The perfect cosmological principle underpins Steady State theory and emerges from chaotic inflation theory.\n\n"}
{"id": "1065253", "url": "https://en.wikipedia.org/wiki?curid=1065253", "title": "Darwin machine", "text": "Darwin machine\n\nA Darwin machine (a 1987 coinage by William H. Calvin, by analogy to a Turing machine) is a machine that, like a Turing machine, involves an iteration process that yields a high-quality result, but, whereas a Turing machine uses logic, the Darwin machine uses rounds of variation, selection, and inheritance.\nIn its original connotation, a Darwin machine is any process that bootstraps quality by utilizing all of the six essential features of a Darwinian process: A \"pattern\" is \"copied\" with \"variations\", where populations of one variant pattern \"compete\" with another population, their relative success biased by a \"multifaceted environment\" (natural selection) so that winners predominate in producing the further variants of the next generation (Darwin's \"inheritance principle\").\n\nMore loosely, a Darwin machine is a process that utilizes some subset of the Darwinian essentials, typically natural selection to create a non-reproducing pattern, as in neural Darwinism. Many aspects of neural development utilize overgrowth followed by pruning to a pattern, but the resulting pattern does not itself create further copies.\n\n\"Darwin machine\" has been used multiple times to name computer programs after Charles Darwin.\n\n\n"}
{"id": "21524469", "url": "https://en.wikipedia.org/wiki?curid=21524469", "title": "Democracy and Desire", "text": "Democracy and Desire\n\nDemocracy and Desire (also \"Democracia y Deseo\") is an evolutionary exhibition project by artist Per Hüttner that develops as it travels. It has been shown in various public and private venues in Europe since November 2006. The project takes its inspiration from Zen Buddhist Koans by pairing the incompatible words democracy and desire. The project investigates how the intellectual freedom of the mind is connected to, inhibited by social order and how the human body can both support and undermine the search for mental and social liberty through social interaction.\n\nThe project uses different forms of interactions with the public to change as it travels, drawing on Hüttner's previous experiences with exhibitions like I am a Curator. In the preparatory research for the project, the artist was collaborating with a group of young creators called \"The Mob\" working within the framework of visual art research network Vision Forum. They set up an interactive website to collect material from the public and a wide variety of audiences. The website has since been closed, but much of the material that was gathered, is available in the catalogue that was published in conjunction with the second incarnation of the exhibition project.\n\nOn November 23, 2006 the first version of \"Democracy and Desire\" opened to the public at the gallery \"Vacio 9\" in Madrid, Spain. The exhibition consisted solely of photographic work by Hüttner. But throughout the run of the exhibition, \"The Mob\" organized various public events that were open for audience participation; a night of performances with local and international artists like Julio Jara, Antonio Arean, Nuria Mora, Anita Wernström, Jean-François Robardet and Marie Husson; video screenings with video art from around the globe and various semi-private training programs particularly related to gender issues.\n\nThe photographic work, that was also the point of departure for the public events, was clearly inspired by the life and work by Francisco Goya both in expression and in content. Hüttner used the contradictory relationship between political powers and private desires that can be seen in many of the great master's paintings and created images that investigated the relationship between us as individual human beings and the interacting systems that surrounds us. In a text dedicated to the exhibition it is stated\":\n\n\" Some images in the series depict the traces of great despots’ megalomania or locations where books have been burned and innocent people have been killed. All the same, these places have witnessed marriages being consumed and great loves being born. Democracy and Desire acknowledges that the system is not the same as the people who perpetuate it. It asks to what degree our lives change when the political system changes and who are the people responsible for these changes? More importantly, however, it asks to what degree the system changes when the people within it change? When you grow as a human being, what does that mean for the powers in your town, city or country?\"\n\nThe quote shows how clearly the artist is influenced by Deleuze’s assemblage theory and its impact on social ontology. The relationship between individuals and social structure in the public space in Hüttner's earlier work became the impetus for Democracy and Desire. French writer Laurent Devèze has written about the 2006 exhibition \"Repetitive Time\" and the constant re-negotiation between the two becomes evident.:\n\n\"Little by little, by stopping us running around even for a short moment in time, we are forced to think about the past. Or rather to reflect on the whole paradigm of a memorial: an object built in a space specifically to remind us of something that happened at a moment in time. It is this that gives your [Hüttner's] altars such a strange intensity. They hold no indication to help us understand what they represent. Was a man killed here? Did something strange or extravagant take place here, something interesting enough to be remembered? The question is pertinent because, in our old cities overburdened with history, it is very likely that any and every point could be marked: here, a man died; here, a traffic accident occurred; here, a divorce was maybe agreed or a marriage proposal was accepted or some secret love affair was begun. It is a vertiginous thought: every point in the spaces that surround us has to be remembered; they are all worthy of it. There is not a single inch in the urban landscape that, if looked at through the prism of the past, should not be remembered. Which means that we could easily be surrounded by innumerable memorials, since everywhere we turn, something happened, something essential to someone.\n\nThis goes hand in hand with Manuel DeLanda's definition of the assemblage:\n\nIn November 2007 the second version of \"Democracy and Desire\" opened at the \"Romanian Cultural Institute\" in Stockholm, Sweden and included public talks and discussions. For the exhibition the artist had created a series of drawings that were specially made to accompany each photograph. The work on paper underlined the search for personal freedom of the mind in spite of social conventions by focusing on how imagination, sexuality and creativity can liberate human beings. The work is greatly influenced by Soviet/Russian literary critic Mikhail Bakhtin:\n\n“What is the character of these ornaments? They impressed the connoisseurs by the extremely fanciful, free and playful treatment of plant, animal and human forms. These forms seemed interwoven as if given birth to each other. The borderlines that divide the kingdoms of nature in the normal world were boldly infringed. Neither was there the usual static presentation of reality. There was no longer the movement of finished forms, vegetable or animal, in a finished and stable world; instead the inner movement of being itself was expressed in the passing of one form into the other, in the ever incompleted character of being. This ornamental interplay revealed an extreme lightness and freedom of artistic fantasy, a gay, almost laughing, libertinage.”\n\nThe drawings presupposes a kind of timeless Carnival where the social roles were turned upside down. The work and also suggests, just like Bakhtin writes that the whole paradigm of temporality needs to be reformulated for humans to achieve freedom. But the images also connected back to Goya's work. Human violence was introduced as possible and darker form of liberator and thus raising issues of the relationship between victim and perpetrator. The artist writes in the catalogue\":\n\n\" We cannot continue to ignore the presence of our violent drives. Culture, conscience, and rationality cannot suppress the violence that is inscribed into our genes. Marlon Brando’s rendering of Colonel Kurtz in \"Apocalypse Now\" virtually incorporates all these principles or at least what can happen in an extreme situation when they have been repressed for too long. The final section of the film, which you might describe as a contemporary filmic paraphrase on Goya’s \"Disasters of War\" is an incredibly forceful investigation to humanity’s relationship to violence. Kurtz is a violent madman and is on the one hand so appealing and on the other incredibly repulsive. His acceptance of his violent drives approaches or embraces insanity. He asks Willard, the man who will shortly kill him, 'Have you ever considered any real freedoms, freedoms from the opinion of others, even the opinions of yourself?' Those are crucial words from one ruthless warrior to another – but even more so for the artist. If the artist is not liberated from his or her inhibitions, it is also impossible for the audience to live a moment of freedom, since the humanness of the artist is veiled by doubts.\"\n\nHüttner invited a group of young Swedish artists to create performances, film screenings and discussions to go along with the installation. After two months of preparations, the group declined the offer and opted to create a parallel exhibition at with the same title at Museet för Glömska (The museum of Forgetting) in the neighbouring town of Norrköping. The exhibition's curator, Giorgiana Zachia responded by arranging a series of discussions at the gallery that included the artist and fellow curator Niclas Östlind.\n\nFor \"Nothing to declare, 4th. Oberschwaben Contemporary Art Triennial\" in Friedrichshafen in Germany, English Curator Barnaby Drabble asked the artist to develop the themes from \"Democracy and Desire’s\" second incarnation. The artist responded to this invitation by creating an installation using photos from the project along with new drawings. The photographs dialogue with the large mural drawings, further underlined the contradictions between the private and public realities depicted. They filtered out the individual's alienation to its own surroundings and the cultural clashes that we are faced with in contemporary life. The curator writes\":\n\n\" In many of the works the artist appears to stage his own ‘otherness’ proposing the modern city and the thinking behind modernism, as the backdrop against which this theatre of alienation is being played out.\"\n\nIn keeping with the conceptual foundation for the project, he created drawings that worked like contemporary, western shanshui paintings underlining the artist's interest in issues of alienation and inclusion. Trees drawn in the ink of modern, urban graffiti were metamorphosing into aeroplanes and then back into a wooden ladders in a stand-still morphing of traditional eastern art. The trees, connected to the mountains, paths and rivers depicted in the photographs. The clear references to traditional Chinese painting underlines the fact that Hüttner's focus never strays far from the human mind and how philosophy shapes the formulation of our reality.\n\nThe relationship to Zen koans was developed in the third version of the project at \"Abecita Konstmuseum\" in Borås. Here Hüttner returned to taking inspiration from contemporary ideas in mathematics and physics. He did so in a very free and creative way, just like he had done in his work from the early 1990s. By mixing theories from contemporary science with reflections on the life quality of our existence, he delved deeper into paradox and the possibility to develop sense from the absurd. Hüttner imagined alternative pasts and through that alternative futures for democracy and desire in a mural painting. Poetic texts were connected to a band of monchrome colour fields that went around the circumference of the museum. Examples from the short texts include: \"The Democracy of Orgasm Act is enforced (Europe and Asia 2058-2122 AD)\" and \"A few hunters and gatherers discuss why their alpha male is such an idiot (Europe 8314 BC).\" The visual impression of the work was very scientific and rational. But the content was filled with absurd and paradoxical suggestions related to potential future and past events related to democracy and desire respectively. The mural dialogued with the drawings and photographs and raised questions about time and temporality's role in paradoxes.\n\nIn May and June 2009 Lillian Fellman, director of Kunsthalle Luzern organized “Behavior Workshop for Idiots” and the exhibition “Love in the Age of Postponed Democracy”. For the latter Hüttner showed a new version of “Some Other Histories of Democracy and Desire” where the texts had been both developed and translated into German. The approach to Zen Koans in this form was much less austere. The content was pushed towards a more blatant idiocy, humour and with a further shift to the carnivalesque and holding back the mysterious and nonsensical approach of the Buddhists. The contrast between the cool appearance of the installation and absurd content of the texts shows that the artist takes a more positive and proactive approach to the issues at hand. He moves further in the research to see how contemporary science and its outlook on temporality can be used to inspire life and art.\n\nThe artists and curators: Fatos Ustek, Hristina Ivanoska, Yane Calovski, Mari Brellochs, Albert Heta, Sixten Kai Nielsen and Martin Rosengaard, participated in the workshop which dealt with many of the issues treated in the previous incarnations of Democracy and Desire. Hüttner also arranged a collaborative performance with the other participants. They were each given a copy of the catalogue of the exhibition and were asked to find alternative ways to read the catalogue while traversing the town and then climbing a mountain. Each participant found a different way to approach the task. Mari Brellochs for instance cut the entire catalogue into heart-shaped messages and gave them to people and left them in strategically chosen places in nature.\n\nWithin the framework of the Nordic festival Les Boréales in Normandy in France, Per Hüttner showed a new incarnation of the project at Le Radar in Bayeux. The exhibition brought together a large number of the original photographs with more recent video work thus moving the focus to temporality like the title suggests (The Timekeeping Camera). In the press release the curator underlines that the core questions of Democracy and Desire remain and yet find that they are reformulated with more focus on time.\n\n\"While destabilizing the eye, the artist opens for other interpretations when he compares the title of the exhibition to a Koan, a deliberately confusing formula for the enlightenment of Zen monks. The observer is invited to take on a challenge, to move beyond appearances to reach a deeper awareness of the world by means of exploring the photographs on display. Per Hüttner voluntarily invites the visitor to update his or her subjectivity by discovering the conditions of any perception of reality. Time and space become measurement standards that allow the personal to aid to appreciate the beauty of the changing the world around them. Yet his photographs reveal the fleetingness and infinite in paradox. Intuition, feelings and reason coexist, but not without friction. Indeed his photographs raise questions of enigmatic and spiritual nature while at the same time investigating scientific concepts such as space-time continuum and quantum physics.\"\n\nA catalogue with the title \"Per Hüttner: Democracy and Desire\" designed by international design group \"Åbäke\" was published in 2007. It uses the special typeface developed by Thomas Moore for his \"Utopia\" on the cover as well in the pages of the book.\". Which was developed from a collaboration with Dent-de-Leone and Aurélien Froment where the entire 1516 novel is set in the typeface developed by Moore and thus virtually impossible to read.\n\n"}
{"id": "7588072", "url": "https://en.wikipedia.org/wiki?curid=7588072", "title": "Dispersion point", "text": "Dispersion point\n\nIn topology, a dispersion point or explosion point is a point in a topological space the removal of which leaves the space highly disconnected.\n\nMore specifically, if \"X\" is a connected topological space containing the point \"p\" and at least two other points, \"p\" is a dispersion point for \"X\" if and only if formula_1 is totally disconnected (every subspace is disconnected, or, equivalently, every connected component is a single point). If \"X\" is connected and formula_1 is totally separated (for each two points \"x\" and \"y\" there exists a clopen set containing \"x\" and not containing \"y\") then \"p\" is an explosion point. A space can have at most one dispersion point or explosion point. Every totally separated space is totally disconnected, so every explosion point is a dispersion point.\n\nThe Knaster–Kuratowski fan has a dispersion point; any space with the particular point topology has an explosion point.\n\nIf \"p\" is an explosion point for a space \"X\", then the totally separated space formula_1 is said to be \"pulverized\".\n\n"}
{"id": "92377", "url": "https://en.wikipedia.org/wiki?curid=92377", "title": "Electromagnet", "text": "Electromagnet\n\nAn electromagnet is a type of magnet in which the magnetic field is produced by an electric current. The magnetic field disappears when the current is turned off. Electromagnets usually consist of wire wound into a coil. A current through the wire creates a magnetic field which is concentrated in the hole in the center of the coil. The wire turns are often wound around a magnetic core made from a ferromagnetic or ferrimagnetic material such as iron; the magnetic core concentrates the magnetic flux and makes a more powerful magnet.\n\nThe main advantage of an electromagnet over a permanent magnet is that the magnetic field can be quickly changed by controlling the amount of electric current in the winding. However, unlike a permanent magnet that needs no power, an electromagnet requires a continuous supply of current to maintain the magnetic field.\n\nElectromagnets are widely used as components of other electrical devices, such as motors, generators, electromechanical solenoids, relays, loudspeakers, hard disks, MRI machines, scientific instruments, and magnetic separation equipment. Electromagnets are also employed in industry for picking up and moving heavy iron objects such as scrap iron and steel.\n\nDanish scientist Hans Christian Ørsted discovered in 1820 that electric currents create magnetic fields. British scientist William Sturgeon invented the electromagnet in 1824. His first electromagnet was a horseshoe-shaped piece of iron that was wrapped with about 18 turns of bare copper wire (insulated wire didn't exist yet). The iron was varnished to insulate it from the windings. When a current was passed through the coil, the iron became magnetized and attracted other pieces of iron; when the current was stopped, it lost magnetization. Sturgeon displayed its power by showing that although it only weighed seven ounces (roughly 200 grams), it could lift nine pounds (roughly 4 kilos) when the current of a single-cell battery was applied. However, Sturgeon's magnets were weak because the uninsulated wire he used could only be wrapped in a single spaced out layer around the core, limiting the number of turns.\n\nBeginning in 1830, US scientist Joseph Henry systematically improved and popularized the electromagnet. By using wire insulated by silk thread, and inspired by Schweigger's use of multiple turns of wire to make a galvanometer, he was able to wind multiple layers of wire on cores, creating powerful magnets with thousands of turns of wire, including one that could support . The first major use for electromagnets was in telegraph sounders.\n\nThe magnetic domain theory of how ferromagnetic cores work was first proposed in 1906 by French physicist Pierre-Ernest Weiss, and the detailed modern quantum mechanical theory of ferromagnetism was worked out in the 1920s by Werner Heisenberg, Lev Landau, Felix Bloch and others.\n\nA \"portative electromagnet\" is one designed to just hold material in place; an example is a lifting magnet. A \"tractive electromagnet\" applies a force and moves something.\n\nElectromagnets are very widely used in electric and electromechanical devices, including:\n\nA common tractive electromagnet is a uniformly-wound solenoid and plunger. The solenoid is a coil of wire, and the plunger is made of a material such as soft iron. Applying a current to the solenoid applies a force to the plunger and may make it move. The plunger stops moving when the forces upon it are balanced. For example, the forces are balanced when the plunger is centered in the solenoid.\n\nThe maximum uniform pull happens when one end of the plunger is at the middle of the solenoid. An approximation for the force is\nwhere is a proportionality constant, is the cross-sectional area of the plunger, is the number of turns in the solenoid, is the current through the solenoid wire, and is the length of the solenoid. For units using inches, pounds force, and amperes with long, slender, solenoids, the value of is around 0.009 to 0.010 psi (maximum pull pounds per square inch of plunger cross-sectional area). For example, a 12-inch long coil () with a long plunger of 1-square inch cross section () and 11,200 ampere-turns () had a maximum pull of 8.75 pounds (corresponding to ).\n\nThe maximum pull is increased when a magnetic stop is inserted into the solenoid. The stop becomes a magnet that will attract the plunger; it adds little to the solenoid pull when the plunger is far away but dramatically increases the pull when they are close. An approximation for the pull is\nHere is the distance between the end of the stop and the end of the plunger. The additional constant for units of inches, pounds, and amperes with slender solenoids is about 2660. The second term within the bracket represents the same force as the stop-less solenoid above; the first term represents the attraction between the stop and the plunger.\n\nSome improvements can be made on the basic design. The ends of the stop and plunger are often conical. For example, the plunger may have a pointed end that fits into a matching recess in the stop. The shape makes the solenoid's pull more uniform as a function of separation. Another improvement is to add a magnetic return path around the outside of the solenoid (an \"iron-clad solenoid\"). The magnetic return path, just as the stop, has little impact until the air gap is small.\n\nAn electric current flowing in a wire creates a magnetic field around the wire, due to Ampere's law (see drawing below). To concentrate the magnetic field, in an electromagnet the wire is wound into a coil with many turns of wire lying side by side. The magnetic field of all the turns of wire passes through the center of the coil, creating a strong magnetic field there. A coil forming the shape of a straight tube (a helix) is called a solenoid.\n\nThe direction of the magnetic field through a coil of wire can be found from a form of the right-hand rule. If the fingers of the right hand are curled around the coil in the direction of current flow (conventional current, flow of positive charge) through the windings, the thumb points in the direction of the field inside the coil. The side of the magnet that the field lines emerge from is defined to be the \"north pole\".\n\nMuch stronger magnetic fields can be produced if a \"magnetic core\" of a soft ferromagnetic (or ferrimagnetic) material, such as iron, is placed inside the coil. A core can increase the magnetic field to thousands of times the strength of the field of the coil alone, due to the high magnetic permeability μ of the material. This is called a ferromagnetic-core or iron-core electromagnet. However, not all electromagnets use cores, and the very strongest electromagnets, such as superconducting and the very high current electromagnets, cannot use them due to saturation.\n\nFor definitions of the variables below, see box at end of article.\n\nThe magnetic field of electromagnets in the general case is given by Ampere's Law:\n\nwhich says that the integral of the magnetizing field H around any closed loop of the field is equal to the sum of the current flowing through the loop. Another equation used, that gives the magnetic field due to each small segment of current, is the Biot–Savart law. Computing the magnetic field and force exerted by ferromagnetic materials is difficult for two reasons. First, because the strength of the field varies from point to point in a complicated way, particularly outside the core and in air gaps, where \"fringing fields\" and \"leakage flux\" must be considered. Second, because the magnetic field B and force are nonlinear functions of the current, depending on the nonlinear relation between B and H for the particular core material used. For precise calculations, computer programs that can produce a model of the magnetic field using the finite element method are employed.\n\nThe material of a magnetic core (often made of iron or steel) is composed of small regions called magnetic domains that act like tiny magnets (see ferromagnetism). Before the current in the electromagnet is turned on, the domains in the iron core point in random directions, so their tiny magnetic fields cancel each other out, and the iron has no large-scale magnetic field. When a current is passed through the wire wrapped around the iron, its magnetic field penetrates the iron, and causes the domains to turn, aligning parallel to the magnetic field, so their tiny magnetic fields add to the wire's field, creating a large magnetic field that extends into the space around the magnet. The effect of the core is to concentrate the field, and the magnetic field passes through the core more easily than it would pass through air.\n\nThe larger the current passed through the wire coil, the more the domains align, and the stronger the magnetic field is. Finally, all the domains are lined up, and further increases in current only cause slight increases in the magnetic field: this phenomenon is called saturation.\n\nWhen the current in the coil is turned off, in the magnetically soft materials that are nearly always used as cores, most of the domains lose alignment and return to a random state and the field disappears. However, some of the alignment persists, because the domains have difficulty turning their direction of magnetization, leaving the core a weak permanent magnet. This phenomenon is called hysteresis and the remaining magnetic field is called remanent magnetism. The residual magnetization of the core can be removed by degaussing. In alternating current electromagnets, such as are used in motors, the core's magnetization is constantly reversed, and the remanence contributes to the motor's losses.\n\nIn many practical applications of electromagnets, such as motors, generators, transformers, lifting magnets, and loudspeakers, the iron core is in the form of a loop or magnetic circuit, possibly broken by a few narrow air gaps. This is because the magnetic field lines are in the form of closed loops. Iron presents much less \"resistance\" (reluctance) to the magnetic field than air, so a stronger field can be obtained if most of the magnetic field's path is within the core.\n\nSince most of the magnetic field is confined within the outlines of the core loop, this allows a simplification of the mathematical analysis. See the drawing at right. A common simplifying assumption satisfied by many electromagnets, which will be used in this section, is that the magnetic field strength \"B\" is constant around the magnetic circuit (within the core and air gaps) and zero outside it. Most of the magnetic field will be concentrated in the core material \"(C)\". Within the core the magnetic field \"(B)\" will be approximately uniform across any cross section, so if in addition the core has roughly constant area throughout its length, the field in the core will be constant. This just leaves the air gaps \"(G)\", if any, between core sections. In the gaps the magnetic field lines are no longer confined by the core, so they 'bulge' out beyond the outlines of the core before curving back to enter the next piece of core material, reducing the field strength in the gap. The bulges \"(B)\" are called \"fringing fields\". However, as long as the length of the gap is smaller than the cross section dimensions of the core, the field in the gap will be approximately the same as in the core. In addition, some of the magnetic field lines \"(B)\" will take 'short cuts' and not pass through the entire core circuit, and thus will not contribute to the force exerted by the magnet. This also includes field lines that encircle the wire windings but do not enter the core. This is called \"leakage flux\". Therefore, the equations in this section are valid for electromagnets for which:\nThe main nonlinear feature of ferromagnetic materials is that the B field saturates at a certain value, which is around 1.6 to 2 teslas (T) for most high permeability core steels. The B field increases quickly with increasing current up to that value, but above that value the field levels off and becomes almost constant, regardless of how much current is sent through the windings. So the maximum strength of the magnetic field possible from an iron core electromagnet is limited to around 1.6 to 2 T.\n\nThe magnetic field created by an electromagnet is proportional to both the number of turns in the winding, \"N\", and the current in the wire, \"I\", hence this product, \"NI\", in ampere-turns, is given the name magnetomotive force. For an electromagnet with a single magnetic circuit, of which length \"L\" of the magnetic field path is in the core material and length \"L\" is in air gaps, Ampere's Law reduces to:\n\nThis is a nonlinear equation, because the permeability of the core, \"μ\", varies with the magnetic field \"B\". For an exact solution, the value of \"μ\" at the \"B\" value used must be obtained from the core material hysteresis curve. If \"B\" is unknown, the equation must be solved by numerical methods. However, if the magnetomotive force is well above saturation, so the core material is in saturation, the magnetic field will be approximately the saturation value \"B\" for the material, and won't vary much with changes in \"NI\". For a closed magnetic circuit (no air gap) most core materials saturate at a magnetomotive force of roughly 800 ampere-turns per meter of flux path.\n\nFor most core materials, formula_9. So in equation (1) above, the second term dominates. Therefore, in magnetic circuits with an air gap, the strength of the magnetic field \"B\" depends strongly on the length of the air gap, and the length of the flux path in the core doesn't matter much. Given an air gap of 1mm, a magnetomotive force of about 796 Ampere-turns is required to produce a magnetic field of 1T.\n\nThe force exerted by an electromagnet on a section of core material is:\n\nwhere formula_11 is the cross-sectional area of the core. The force equation can be derived from the energy stored in a magnetic field. Energy is force times distance. Rearranging terms yields the equation above.\n\nThe 1.6 T limit on the field mentioned above sets a limit on the maximum force per unit core area, or magnetic pressure, an iron-core electromagnet can exert; roughly:\n\nIn more intuitive units it's useful to remember that at 1 T the magnetic pressure is approximately 4 atmospheres, or kg/cm.\n\nGiven a core geometry, the B field needed for a given force can be calculated from (2); if it comes out to much more than 1.6 T, a larger core must be used.\n\nFor a closed magnetic circuit (no air gap), such as would be found in an electromagnet lifting a piece of iron bridged across its poles, equation (1) becomes:\n\nSubstituting into (2), the force is:\n\nIt can be seen that to maximize the force, a core with a short flux path \"L\" and a wide cross-sectional area \"A\" is preferred (this also applies to magnets with an air gap). To achieve this, in applications like lifting magnets (see photo above) and loudspeakers a flat cylindrical design is often used. The winding is wrapped around a short wide cylindrical core that forms one pole, and a thick metal housing that wraps around the outside of the windings forms the other part of the magnetic circuit, bringing the magnetic field to the front to form the other pole.\n\nThe above methods are applicable to electromagnets with a magnetic circuit and do not apply when a large part of the magnetic field path is outside the core. An example would be a magnet with a straight cylindrical core like the one shown at the top of this article. For electromagnets (or permanent magnets) with well defined 'poles' where the field lines emerge from the core, the force between two electromagnets can be found using the 'Gilbert model' which assumes the magnetic field is produced by fictitious 'magnetic charges' on the surface of the poles, with pole strength \"m\" and units of Ampere-turn meter. Magnetic pole strength of electromagnets can be found from:\n\nformula_15\n\nThe force between two poles is:\n\nformula_16\n\nThis model doesn't give the correct magnetic field inside the core and thus gives incorrect results if the pole of one magnet gets too close to another magnet.\n\nThere are several side effects which occur in electromagnets which must be provided for in their design. These generally become more significant in larger electromagnets.\n\nThe only power consumed in a DC electromagnet under steady state conditions is due to the resistance of the windings, and is dissipated as heat. Some large electromagnets require cooling water circulating through pipes in the windings to carry off the waste heat.\n\nSince the magnetic field is proportional to the product \"NI\", the number of turns in the windings \"N\" and the current \"I\" can be chosen to minimize heat losses, as long as their product is constant. Since the power dissipation, \"P = IR\", increases with the square of the current but only increases approximately linearly with the number of windings, the power lost in the windings can be minimized by reducing \"I\" and increasing the number of turns \"N\" proportionally, or using thicker wire to reduce the resistance. For example, halving I and doubling N halves the power loss, as does doubling the area of the wire. In either case, increasing the amount of wire reduces the ohmic losses. For this reason, electromagnets often have a significant thickness of windings.\n\nHowever, the limit to increasing \"N\" or lowering the resistance is that the windings take up more room between the magnet's core pieces. If the area available for the windings is filled up, more turns require going to a smaller diameter of wire, which has higher resistance, which cancels the advantage of using more turns. So in large magnets there is a minimum amount of heat loss that can't be reduced. This increases with the square of the magnetic flux \"B\".\n\nAn electromagnet has significant inductance, and resists changes in the current through its windings. Any sudden changes in the winding current cause large voltage spikes across the windings. This is because when the current through the magnet is increased, such as when it is turned on, energy from the circuit must be stored in the magnetic field. When it is turned off the energy in the field is returned to the circuit.\n\nIf an ordinary switch is used to control the winding current, this can cause sparks at the terminals of the switch. This doesn't occur when the magnet is switched on, because the limited supply voltage causes the current through the magnet and the field energy to increase slowly, but when it is switched off, the energy in the magnetic field is suddenly returned to the circuit, causing a large voltage spike and an arc across the switch contacts, which can damage them. With small electromagnets a capacitor is sometimes used across the contacts, which reduces arcing by temporarily storing the current. More often a diode is used to prevent voltage spikes by providing a path for the current to recirculate through the winding until the energy is dissipated as heat. The diode is connected across the winding, oriented so it is reverse-biased during steady state operation and doesn't conduct. When the supply voltage is removed, the voltage spike forward-biases the diode and the reactive current continues to flow through the winding, through the diode and back into the winding. A diode used in this way is called a freewheeling diode or flyback diode.\n\nLarge electromagnets are usually powered by variable current electronic power supplies, controlled by a microprocessor, which prevent voltage spikes by accomplishing current changes slowly, in gentle ramps. It may take several minutes to energize or deenergize a large magnet. \n\nIn powerful electromagnets, the magnetic field exerts a force on each turn of the windings, due to the Lorentz force formula_17 acting on the moving charges within the wire. The Lorentz force is perpendicular to both the axis of the wire and the magnetic field. It can be visualized as a pressure between the magnetic field lines, pushing them apart. It has two effects on an electromagnet's windings:\nThe Lorentz forces increase with \"B\". In large electromagnets the windings must be firmly clamped in place, to prevent motion on power-up and power-down from causing metal fatigue in the windings. In the Bitter design, below, used in very high field research magnets, the windings are constructed as flat disks to resist the radial forces, and clamped in an axial direction to resist the axial ones.\n\nIn alternating current (AC) electromagnets, used in transformers, inductors, and AC motors and generators, the magnetic field is constantly changing. This causes energy losses in their magnetic cores that is dissipated as heat in the core. The losses stem from two processes:\nThe energy loss per cycle of the AC current is constant for each of these processes, so the power loss increases linearly with frequency.\n\nWhen a magnetic field higher than the ferromagnetic limit of 1.6 T is needed, superconducting electromagnets can be used. Instead of using ferromagnetic materials, these use superconducting windings cooled with liquid helium, which conduct current without electrical resistance. These allow enormous currents to flow, which generate intense magnetic fields. Superconducting magnets are limited by the field strength at which the winding material ceases to be superconducting. Current designs are limited to 10–20 T, with the current (2017) record of 32 T. The necessary refrigeration equipment and cryostat make them much more expensive than ordinary electromagnets. However, in high power applications this can be offset by lower operating costs, since after startup no power is required for the windings, since no energy is lost to ohmic heating. They are used in particle accelerators and MRI machines.\n\nBoth iron-core and superconducting electromagnets have limits to the field they can produce. Therefore, the most powerful man-made magnetic fields have been generated by \"air-core\" nonsuperconducting electromagnets of a design invented by Francis Bitter in 1933, called Bitter electromagnets. Instead of wire windings, a Bitter magnet consists of a solenoid made of a stack of conducting disks, arranged so that the current moves in a helical path through them, with a hole through the center where the maximum field is created. This design has the mechanical strength to withstand the extreme Lorentz forces of the field, which increase with \"B\". The disks are pierced with holes through which cooling water passes to carry away the heat caused by the high current. The strongest continuous field achieved solely with a resistive magnet is 37.5 T , produced by a Bitter electromagnet at the Radboud University High Field Magnet Laboratory in Nijmegen, Holland. The previous record was 35 T. The strongest continuous magnetic field overall, 45 T, was achieved in June 2000 with a hybrid device consisting of a Bitter magnet inside a superconducting magnet.\nThe factor limiting the strength of electromagnets is the inability to dissipate the enormous waste heat, so more powerful fields, up to 100 T, have been obtained from resistive magnets by sending brief pulses of high current through them; the inactive period after each pulse allows the heat produced during the pulse to be removed, before the next pulse. The most powerful manmade magnetic fields have been created by using explosives to compress the magnetic field inside an electromagnet as it is pulsed; these are called explosively pumped flux compression generators.\nThe implosion compresses the magnetic field to values of around 1000 T for a few microseconds. While this method may seem very destructive, it is possible to redirect the brunt of the blast radially outwards so that neither the experiment nor the magnetic structure are harmed. These devices are known as destructive pulsed electromagnets. They are used in physics and materials science research to study the properties of materials at high magnetic fields.\n\n\n"}
{"id": "350164", "url": "https://en.wikipedia.org/wiki?curid=350164", "title": "Farey sequence", "text": "Farey sequence\n\nIn mathematics, the Farey sequence of order \"n\" is the sequence of completely reduced fractions, either between 0 and 1, or without this restriction, which when in lowest terms have denominators less than or equal to \"n\", arranged in order of increasing size.\n\nWith the restricted definition, each Farey sequence starts with the value 0, denoted by the fraction ⁄, and ends with the value 1, denoted by the fraction ⁄ (although some authors omit these terms).\n\nA Farey sequence is sometimes called a Farey series, which is not strictly correct, because the terms are not summed. \n\nThe Farey sequences of orders 1 to 8 are :\n\nFarey sequences are named after the British geologist John Farey, Sr., whose letter about these sequences was published in the \"Philosophical Magazine\" in 1816. Farey conjectured, without offering proof, that each new term in a Farey sequence expansion is the mediant of its neighbours. Farey's letter was read by Cauchy, who provided a proof in his \"Exercices de mathématique\", and attributed this result to Farey. In fact, another mathematician, Charles Haros, had published similar results in 1802 which were not known either to Farey or to Cauchy. Thus it was a historical accident that linked Farey's name with these sequences. This is an example of Stigler's law of eponymy.\n\nThe Farey sequence of order \"n\" contains all of the members of the Farey sequences of lower orders. In particular \"F\" contains all of the members of \"F\" and also contains an additional fraction for each number that is less than \"n\" and coprime to \"n\". Thus \"F\" consists of \"F\" together with the fractions and . \n\nThe middle term of a Farey sequence \"F\" is always , \nfor \"n\" > 1. From this, we can relate the lengths of \"F\" and \"F\" using Euler's totient function formula_1 :\n\nUsing the fact that |\"F\"| = 2, we can derive an expression for the length of \"F\":\n\nWe also have :\n\nand by a Möbius inversion formula : \nwhere µ(\"d\") is the number-theoretic Möbius function, and formula_6 is the floor function. \n\nThe asymptotic behaviour of |\"F\"| is :\n\nThe index formula_8 of a fraction formula_9 in the Farey sequence formula_10 is simply the position that formula_9 occupies in the sequence. This is of special relevance as it is used in an alternative formulation of the Riemann hypothesis, see below. Various useful properties follow:\n\nThe index of formula_17 where formula_18 and formula_19 is the least common multiple of the first formula_20 numbers, formula_21, is given by:\n\nFractions which are neighbouring terms in any Farey sequence are known as a \"Farey pair\" and have the following properties.\n\nIf and are neighbours in a Farey sequence, with  < , then their difference  −  is equal to . Since \n\nthis is equivalent to saying that \n\nThus and are neighbours in \"F\", and their difference is .\n\nThe converse is also true. If \n\nfor positive integers \"a\",\"b\",\"c\" and \"d\" with \"a\" < \"b\" and \"c\" < \"d\" then and will be neighbours in the Farey sequence of order max(\"b,d\").\n\nIf has neighbours and in some Farey sequence, with \n\nthen is the mediant of and – in other words, \n\nThis follows easily from the previous property, since if , then , , .\n\nIt follows that if and are neighbours in a Farey sequence then the first term that appears between them as the order of the Farey sequence is incremented is \n\nwhich first appears in the Farey sequence of order .\n\nThus the first term to appear between and is , which appears in \"F\".\n\nThe \"Stern–Brocot tree\" is a data structure showing how the sequence is built up from 0 (= ) and 1 (= ), by taking successive mediants.\n\nFractions that appear as neighbours in a Farey sequence have closely related continued fraction expansions. Every fraction has two continued fraction expansions — in one the final term is 1; in the other the final term is greater than 1. If , which first appears in Farey sequence \"F\", has continued fraction expansions\n\nthen the nearest neighbour of in \"F\" (which will be its neighbour with the larger denominator) has a continued fraction expansion\n\nand its other neighbour has a continued fraction expansion \n\nFor example, has the two continued fraction expansions and , and its neighbours in \"F\" are , which can be expanded as ; and , which can be expanded as .\n\nFarey sequences are very useful to find rational approximations of irrational numbers.\n\nIn physics systems featuring resonance phenomena Farey sequences provide a very elegant and efficient method to compute resonance locations in 1D and 2D.\n\nThere is a connection between Farey sequence and Ford circles.\n\nFor every fraction \"p\"/\"q\" (in its lowest terms) there is a Ford circle C[\"p\"/\"q\"], which is the circle with radius 1/(2\"q\") and centre at (\"p\"/\"q\", 1/(2\"q\")). Two Ford circles for different fractions are either disjoint or they are tangent to one another—two Ford circles never intersect. If 0 < \"p\"/\"q\" < 1 then the Ford circles that are tangent to C[\"p\"/\"q\"] are precisely the Ford circles for fractions that are neighbours of \"p\"/\"q\" in some Farey sequence.\n\nThus \"C\"[2/5] is tangent to \"C\"[1/2], \"C\"[1/3], \"C\"[3/7], \"C\"[3/8] etc.\n\nFarey sequences are used in two equivalent formulations of the Riemann hypothesis. Suppose the terms of formula_29 are formula_30. Define formula_31, in other words formula_32 is the difference between the \"k\"th term of the \"n\"th Farey sequence, and the \"k\"th member of a set of the same number of points, distributed evenly on the unit interval. In 1924 Jérôme Franel proved that the statement\n\nis equivalent to the Riemann hypothesis, and then Edmund Landau remarked (just after Franel's paper) that the statement\n\nis also equivalent to the Riemann hypothesis.\n\nA surprisingly simple algorithm exists to generate the terms of \"F\" in either traditional order (ascending) or non-traditional order (descending). The algorithm computes each successive entry in terms of the previous two entries using the mediant property given above. If and are the two given entries, and is the unknown next entry, then  = . Since is in lowest terms, there must be an integer \"k\" such that \"kc\" = \"a\" + \"p\" and \"kd\" = \"b\" + \"q\", giving \"p\" = \"kc\" − \"a\" and \"q\" = \"kd\" − \"b\". If we consider \"p\" and \"q\" to be functions of \"k\", then\nso the larger \"k\" gets, the closer gets to .\n\nTo give the next term in the sequence \"k\" must be as large as possible, subject to \"kd\" − \"b\" ≤ \"n\" (as we are only considering numbers with denominators not greater than \"n\"), so \"k\" is the greatest integer ≤ . Putting this value of \"k\" back into the equations for \"p\" and \"q\" gives\n\nThis is implemented in Python as:\nBrute-force searches for solutions to Diophantine equations in rationals can often take advantage of the Farey series (to search only reduced forms). The lines marked (*) can also be modified to include any two adjacent terms so as to generate terms only larger (or smaller) than a given term.\n\n\n\n"}
{"id": "694813", "url": "https://en.wikipedia.org/wiki?curid=694813", "title": "Fraternity of peoples", "text": "Fraternity of peoples\n\nFraternity of peoples (Russian language: Дружба народов, \"druzhba narodov\") is a concept advanced by Marxist social class theory. According to Marxism, nationalism is only a tool of the ruling class, used to keep the working class divided and thus easier to control and exploit. With the success of class struggle (i.e. the abolition of social classes), the natural brotherhood of all workers would make the idea of separate nations obsolete. The concept of the fraternity of the peoples is often opposed to \"bourgeois cosmopolitanism\".\n\nThe Tsarist Russian Empire was dubbed the \"prison of the peoples\" (\"Тюрьма народов\") by Vladimir Lenin. The Soviet Union, which replaced the empire, proclaimed that the goal of its national policy was to forge a new national entity, the \"Soviet people\". Even though the Soviet Union often claimed to make significant progress on \"the nationalities question\", its dissolution came about largely due to inter-ethnic conflict and like other communist countries a privileged nationality (in this case the Russians, in Yugoslavia the Serbs, in Vietnam the ethnic Vietnamese and in China the Han Chinese) had more political and economic power.\n\n\n"}
{"id": "3219156", "url": "https://en.wikipedia.org/wiki?curid=3219156", "title": "Free will theorem", "text": "Free will theorem\n\nThe free will theorem of John H. Conway and Simon B. Kochen states that if we have a free will in the sense that our choices are not a function of the past, then, subject to certain assumptions, so must some elementary particles. Conway and Kochen's paper was published in \"Foundations of Physics\" in 2006. In 2009 they published a stronger version of the theorem in the Notices of the AMS. Later Simon elaborated some details.\n\nThe proof of the theorem as originally formulated relies on three axioms, which Conway and Kochen call \"fin\", \"spin\", and \"twin\". The spin and twin axioms can be verified experimentally.\n\nIn their later paper, \"The Strong Free Will Theorem\", Conway and Kochen replace the Fin axiom by a weaker one called Min, thereby strengthening the theorem. Min asserts only that two experimenters separated in a space-like way can make choices of measurements independently of each other. In particular it is not postulated that the speed of transfer of \"all\" information is subject to a maximum limit, but only of the particular information about choices of measurements.\n\nThe free will theorem states:\n\nSince the theorem applies to any arbitrary physical theory consistent with the axioms, it would not even be possible to place the information into the universe's past in an ad hoc way. The argument proceeds from the Kochen–Specker theorem, which shows that the result of any individual measurement of spin was not fixed independently of the choice of measurements. As stated by Cator and Landsman regarding hidden-variable theories: \"There has been a similar tension between the idea that the hidden variables (in the pertinent causal past) should on the one hand include all ontological information relevant to the experiment, but on the other hand should leave the experimenters free to choose any settings they like.\"\n\nAccording to Cator and Landsman, Conway and Kochen prove that \"determinism is incompatible with a number of \"a priori\" desirable assumptions\". Cator and Landsman compare the Min assumption to the locality assumption in Bell's theorem and conclude in the strong free will theorem's favor that it \"uses fewer assumptions than Bell’s 1964 theorem, as no appeal to probability theory is made\". The philosopher David Hodgson supports this theorem as showing quite conclusively that \"science does not support determinism\": that quantum mechanics proves that particles do indeed behave in a way that is not a function of the past. Some critics argue that the theorem applies only to deterministic models. Others have argued that the indeterminism that Conway and Kochen claim to have established was already assumed in the premises of their proof.\n\n\n"}
{"id": "4393921", "url": "https://en.wikipedia.org/wiki?curid=4393921", "title": "Glasgow smile", "text": "Glasgow smile\n\nA Glasgow smile (also known as a Chelsea smile, or a Glasgow, Chelsea or Cheshire grin) is a wound caused by making a cut from the corners of a victim's mouth up to the ears, leaving a scar in the shape of a smile.\n\nThe act is usually performed with a utility knife or a piece of broken glass, leaving a scar which causes the victim to appear to be smiling broadly.\n\nThe practice is said to have originated in Glasgow, Scotland in the 1920s and '30s, but became popular with English street gangs (especially among the Chelsea Headhunters, a London-based hooligan firm, among whom it is known as a \"Chelsea grin\" or \"Chelsea smile\").\n\n"}
{"id": "10499965", "url": "https://en.wikipedia.org/wiki?curid=10499965", "title": "Immersion (virtual reality)", "text": "Immersion (virtual reality)\n\nImmersion into virtual reality is a perception of being physically present in a non-physical world. The perception is created by surrounding the user of the VR system in images, sound or other stimuli that provide an engrossing total environment.\n\nThe name is a metaphoric use of the experience of submersion applied to representation, fiction or simulation. Immersion can also be defined as the state of consciousness where a \"visitor\" (Maurice Benayoun) or \"immersant\" (Char Davies)'s awareness of physical self is transformed by being surrounded in an artificial environment; used for describing partial or complete suspension of disbelief, enabling action or reaction to stimulations encountered in a virtual or artistic environment. The degree to which the virtual or artistic environment faithfully reproduces reality determines the degree of suspension of disbelief. The greater the suspension of disbelief, the greater the degree of presence achieved.\n\nAccording to Ernest W. Adams, author and consultant on game design, immersion can be separated into three main categories:\n\n\n\n\nStaffan Björk and Jussi Holopainen, in \"Patterns In Game Design\", divide immersion into similar categories, but call them sensory-motoric immersion, cognitive immersion and emotional immersion, respectively. In addition to these, they add a new category:\n\n\nPresence, a term derived from the shortening of the original \"telepresence\", is a phenomenon enabling people to interact with and feel connected to the world outside their physical bodies via technology. It is defined as a person's subjective sensation of being there in a scene depicted by a medium, usually virtual in nature. Most designers focus on the technology used to create a high-fidelity virtual environment; however, the human factors involved in achieving a state of presence must be taken into account as well. It is the subjective perception, although generated by and/or filtered through human-made technology, that ultimately determines the successful attainment of presence.\n\nVirtual reality glasses can produce a visceral feeling of being in a simulated world, a form of spatial immersion called Presence. According to Oculus VR, the technology requirements to achieve this visceral reaction are low-latency and precise tracking of movements.\n\nMichael Abrash gave a talk on VR at Steam Dev Days in 2014. According to the VR research team at Valve, all of the following are needed to establish presence.\n\nImmersive virtual reality is a hypothetical future technology that exists today as virtual reality art projects, for the most part. It consists of immersion in an artificial environment where the user feels just as immersed as they usually feel in consensus reality.\n\nThe most considered method would be to induce the sensations that made up the virtual reality in the nervous system directly. In functionalism/conventional biology we interact with consensus reality through the nervous system. Thus we receive all input from all the senses as nerve impulses.\nIt gives your neurons a feeling of heightened sensation. It would involve the user receiving inputs as artificially stimulated nerve impulses, the system would receive the CNS outputs (natural nerve impulses) and process them allowing the user to interact with the virtual reality. Natural impulses between the body and central nervous system would need to be prevented. This could be done by blocking out natural impulses using nanorobots which attach themselves to the brain wiring, whilst receiving the digital impulses of which describe the virtual world, which could then be sent into the wiring of the brain. A feedback system between the user and the computer which stores the information would also be needed. Considering how much information would be required for such a system, it is likely that it would be based on hypothetical forms of computer technology.\n\nA comprehensive understanding of which nerve impulses correspond to which sensations, and which motor impulses correspond to which muscle contractions will be required. This will allow the correct sensations in the user, and actions in the virtual reality to occur. The Blue Brain Project is the current, most promising research with the idea of understanding how the brain works by building very large scale computer models.\n\nThe nervous system would obviously need to be manipulated. Whilst non-invasive devices using radiation have been postulated, invasive cybernetic implants are likely to become available sooner and be more accurate. Manipulation could occur at any stage of the nervous system – the spinal cord is likely to be simplest; as all nerves pass through here, this could be the only site of manipulation.\nMolecular nanotechnology is likely to provide the degree of precision required and could allow the implant to be built inside the body rather than be inserted by an operation.\n\nA very powerful computer would be necessary for processing virtual reality complex enough to be nearly indistinguishable from consensus reality and interacting with central nervous system fast enough.\n\nAn immersive digital environment is an artificial, interactive, computer-created scene or \"world\" within which a user can immerse themselves.\n\nImmersive digital environments could be thought of as synonymous with virtual reality, but without the implication that actual \"reality\" is being simulated. An immersive digital environment could be a model of reality, but it could also be a complete fantasy user interface or abstraction, as long as the user of the environment is immersed within it. The definition of immersion is wide and variable, but here it is assumed to mean simply that the user feels like they are part of the simulated \"universe\". The success with which an immersive digital environment can actually immerse the user is dependent on many factors such as believable 3D computer graphics, surround sound, interactive user-input and other factors such as simplicity, functionality and potential for enjoyment. New technologies are currently under development which claim to bring realistic environmental effects to the players' environment – effects like wind, seat vibration and ambient lighting.\n\nTo create a sense of full immersion, the 5 senses (sight, sound, touch, smell, taste) must perceive the digital environment to be physically real. Immersive technology can perceptually fool the senses through:\n\nOnce the senses reach a sufficient belief that the digital environment is real (it is interaction and involvement which can never be real), the user must then be able to interact with the environment in a natural, intuitive manner. Various immersive technologies such as gestural controls, motion tracking, and computer vision respond to the user's actions and movements. Brain control interfaces (BCI) respond to the user's brainwave activity.\n\nTraining and rehearsal simulations run the gamut from part task procedural training (often buttonology, for example: which button do you push to deploy a refueling boom) through situational simulation (such as crisis response or convoy driver training) to full motion simulations which train pilots or soldiers and law enforcement in scenarios that are too dangerous to train in actual equipment using live ordinance.\n\nComputer games from simple arcade to massively multiplayer online game and training programs such as flight and driving simulators. Entertainment environments such as motion simulators that immerse the riders/players in a virtual digital environment enhanced by motion, visual and aural cues. Reality simulators, such as one of the Virunga Mountains in Rwanda that takes you on a trip through the jungle to meet a tribe of mountain gorillas. Or training versions such as one which simulates taking a ride through human arteries and the heart to witness the buildup of plaque and thus learn about cholesterol and health.\n\nIn parallel with scientist, artists like Knowbotic Research, Donna Cox, Rebecca Allen, Robbie Cooper, Maurice Benayoun,\nChar Davies, and Jeffrey Shaw use the potential of immersive virtual reality to create physiologic or symbolic experiences and situations.\n\nOther examples of immersion technology include physical environment / immersive space with surrounding digital projections and sound such as the CAVE, and the use of virtual reality headsets for viewing movies, with head-tracking and computer control of the image presented, so that the viewer appears to be inside the scene. The next generation is VIRTSIM, which achieves total immersion through motion capture and wireless head mounted displays for teams of up to thirteen immersants enabling natural movement through space and interaction in both the virtual and physical space simultaneously.\n\nNew fields of studies linked to the immersive virtual reality emerges every day. Researchers see a great potential in virtual reality tests serving as complementary interview methods in psychiatric care.\nImmersive virtual reality have in studies also been used as an educational tool in which the visualization of psychotic states have been used to get increased understanding of patients with similar symptoms. New treatment methods are available for schizophrenia and other newly developed research areas where immersive virtual reality is expected to achieve melioration is in education of surgical procedures, rehabilitation program from injuries and surgeries and reduction of phantom limb pain.\n\nIn the domain of architectural design and building science, immersive virtual environments are adopted to facilitate architects and building engineers to enhance the design process through assimilating their sense of scale, depth, and spatial awareness. Such platforms integrate the use of virtual reality models and mixed reality technologies in various functions of building science research, construction operations, personnel training, end-user surveys, performance simulations and building information modeling visualization. Head-mounted displays (with both 3 degrees of freedom and 6 degrees of freedom systems) and CAVE platforms are used for spatial visualization and building information modeling (BIM) navigations for different design and evaluation purposes. Clients, architects and building owners use derived applications from game engines to navigate 1:1 scale BIM models, allowing a virtual walkthrough experience of future buildings. For such use cases, the performance improvement of space navigation between virtual reality headsets and 2D desktop screens has been investigated in various studies, with some suggesting significant improvement in virtual reality headsets while others indicate no significant difference. Architects and building engineers can also use immersive design tools to model various building elements in virtual reality CAD interfaces, and apply property modifications to building information modeling (BIM) files through such environments.\n\nIn the building construction phase, immersive environments are used to improve site preparations, on site communication and collaboration of team members, safety and logistics. For training of construction workers, virtual environments have shown to be highly effective in skill transfer with studies showing similar performance results to training in real environments. Moreover, virtual platforms are also used in the operation phase of buildings to interact and visualize data with Internet of Things (IoT) devices available in buildings, process improvement and also resource management.\n\nOccupant and end-user studies are performed through immersive environments. Virtual immersive platforms engage future occupants in the building design process by providing a sense of presence to users with integrating pre-construction mock-ups and BIM models for the evaluation of alternative design options in the building model in a timely and cost efficient manner. Studies conducting human experiments have shown users perform similarly in daily office activities (object identification, reading speed and comprehension) within immersive virtual environments and benchmarked physical environments. In the field of lighting, virtual reality headsets have been used investigate the influence of façade patterns on the perceptual impressions and satisfaction of a simulated daylit space. Moreover, artificial lighting studies have implemented immersive virtual environments to evaluate end-users lighting preferences of simulated virtual scenes with the controlling of the blinds and artificial lights in the virtual environment.\n\nFor structural engineering and analysis, immersive environments enable the user to focus on structural investigations without getting too distracted to operate and navigate the simulation tool. Virtual and augmented reality applications have been designed for finite element analysis of shell structures. Using stylus and data gloves as input devices, the user can create, modify mesh, and specify boundary conditions. For a simple geometry, real-time color-coded results are obtained by changing loads on the model. Studies have used artificial neural networks (ANN) or approximation methods to achieve real-time interaction for the complex geometry, and to simulate its impact via haptic gloves. Large scale structures and bridge simulation have also been achieved in immersive virtual environments. The user can move the loads acting on the bridge, and finite element analysis results are updated immediately using an approximate module.\n\nSimulation sickness, or simulator sickness, is a condition where a person exhibits symptoms similar to motion sickness caused by playing computer/simulation/video games (Oculus Rift is working to solve simulator sickness).\n\nMotion sickness due to virtual reality is very similar to simulation sickness and motion sickness due to films. In virtual reality, however, the effect is made more acute as all external reference points are blocked from vision, the simulated images are three-dimensional and in some cases stereo sound that may also give a sense of motion. Studies have shown that exposure to rotational motions in a virtual environment can cause significant increases in nausea and other symptoms of motion sickness.\n\nOther behavioural changes such as stress, addiction, isolation and mood changes are also discussed to be side-effects caused by immersive virtual reality.\n\n"}
{"id": "34517249", "url": "https://en.wikipedia.org/wiki?curid=34517249", "title": "Information policy", "text": "Information policy\n\nInformation policy is the set of all public laws, regulations and policies that encourage, discourage, or regulate the creation, use, storage, access, and communication and dissemination of information. It thus encompasses any other decision-making practice with society-wide constitutive efforts that involve the flow of information and how it is processed.\n\nThere are several fundamental issues that comprise information policy. Most prominent are public policy issues concerned with the use of information for democratization and commercialization of social life. These issues include, inter alia, digital environment, such as intellectual property, economic regulations, freedom of expression, confidentiality or privacy of information, information security, access management, and regulating how the dissemination of public information occurs.\n\nInformation policy became a prominent field of study during the latter half of the 20th century as the shift from an industrial to an information society transpired. It has since then evolved from being seen as relatively unimportant to having a much more overarching strategic significance since it establishes the conditions “under which all other decision making, public discourse, and political activity occur.” The growing awareness in the importance of information policy has sparked an interest in various groups to further study and analyze its magnitude. The most common audience for information policy analysis includes undergraduate and graduate students, scholars, policymakers, policy analysts, as well as those members of the public who have taken an interest in understanding the effects of the laws and regulations involving information.\n\nAlthough information policy generally has a broader definition and encapsulates a multitude of components, its scope and impact can vary depending on the context. For example, in the context of an information lifecycle, information policy refers to the laws and policies that deal with the stages information goes through beginning with its creation, through its collection, organization, dissemination, and finally to its destruction. On the other hand, in the context of public administration, information policy is the means by which government employees, institutions, and information systems adapt themselves to an environment in rapid fluctuation and use information for decision-making (e.g., Andersen and Dawes, 1991; also see Bozeman and Bretschneider, 1986, and Stevens and McGowan, 1985). One can see how these two contexts offer varying scopes for the phrase “ information policy.”\n\nInformation policy is in fact, a combination of several varying disciplines including information science, economics, law, and public policy. Thus, its scope may differ when each of these disciplines analyses or uses it. The information sciences may be more concerned with technical advances and how this impacts information policy, while from a law perspective, issues such as privacy rights and intellectual property may be of greatest focus.\n\nThe earliest sight of information policy was present around the mid-1900s. The stages to begin evolving from an industrial society to an information society sparked several other transformations. The common industrial technologies were beginning to be replaced by informational meta-technologies. Organizations began changing their form, several new architectures of knowledge developed, and most importantly, the information economy replaced industrial and agricultural economies.\n\nBy the 1970s, the concept of national information policy was created to protect the data and information that was used in creating public policies. The earliest adopters of information policy included the United States, Australia, as well as several European countries who all recognized the importance for a more standardized governance of information.\n\nElizabeth Orna contributed to a paper on information policies by providing a brief history of the development of ideas surrounding national and organizational information policies, from the beginning when the United Kingdom Ministry of Information was established in the First World War to present day. The history of information policy is reflected in this chart.\n\nIn the 20th century, to cope with the privacy problems of databases, information policy evolved further safeguards. In the USA, the federal Privacy Act provides individuals the right to inspect and correct personal information in federal datafiles.\n\nThe types of information policy can be separated into two different categories. It can be discussed in the short-term focus exclusively on information science. It can also have a much broader context in relation to different subjects and be within a larger time period, for example dating back to Roman civilization, the Bill of Rights, or the Constitution.\n\nThe obvious reason for the need of information policy deals with the legal issues that can be associated with the advancement of technology. More precisely, — the digitization of the cultural content made the cost of the copy decreasing to nearly zero and increased the illegal exchange of files, online, via sharing web site or P2P technologies, or off line (copy of hard disks). As a result, there are many grey areas between what users can and cannot do, and this creates the need for some sort of regulation. Today, this has led to the creation of SOPA (Stop Online Piracy Act). Information policy will mark the boundaries needed to evaluate certain issues dealing with the creation, processing, exchange, access, and use of information.\n\n1. for avoiding risks (financial losses from incomplete and uncoordinated exploitation of information, wasted time, failures of innovation, and reputation loss);\n\n2. for positive benefits, including negotiation and openness among those responsible for different aspects of information management\n3. productive use of IT in supporting staff in their use of information\n\n4. ability to initiate change to take advantage of changing environments\n\nThere are some issues around organizational information policies, which are the interaction between human beings and technology for using information, the issue to proceed information policy itself, whether top-down or middle-up-down, is the best way to approach information policy in an organization. Also, issues that information tends to be influenced by organization’s culture that result in complexity of information flow. Moreover, the concern about valuing information is discussed by Orna, the fact that value of information is dependant on the user, and it can’t be measured by price. Considering that information is an asset or intellectual capital that becomes valuable when it is used in productive ways.\n\nConvergence essentially combines all forms of media, telecommunications, broadcasting, and computing by the use of a single technology: digital computers. It integrates diverse technological systems in the hopes of improving performance of similar tasks. Convergence is thought to be the result of the need for expansion into new markets due to competition and technological advances that have created a threat of new entrants into various segments of the value chain. As a result, previously disparate technologies interact with one other synergistically to deliver information in new and unique ways and allow for inventive solutions to be developed.\n\nNearly every innovative trend in the social industry involves adding data or layers of connectivity. Social networking sites have begun interacting with e-mail functionalities, search engines have begun integrating Internet searches with Facebook data, Twitter along with various other social media platforms have started to play a prominent role in the emergency management framework (mitigation, preparedness, response, and recovery) among several others.\n\nIn 2012 a prominent issue arose that deals with the convergence of social media with copyright infringement monitoring systems. The growing interest in this topic can be largely attributed to the recent anti-piracy bills: the Stop Online Piracy Act and the PROTECT IP Act. Various officials from all over the world have expressed an interest in forcing social networks to install and utilize monitoring systems to determine if users are illegally obtaining copyrighted material. For example, if implemented, these filters could prevent the illegal sharing of music over social networking platforms. The convergence of search engines and social networks could make this process even easier. Search engines such as Google, Yahoo, and Bing have begun to merge with social media platforms to link Internet searches to your social networking sites such as Facebook. This poses an even greater threat to users since their Internet searches can be monitored via their social networks.\n\nThe issue of converging social networks with piracy monitoring systems becomes controversial when it comes to protecting personal data and abiding by privacy laws. In order for a synergy such as this one to take place, regulatory convergence would need to be considered. Regulatory convergence is the merging of previously disparate industry-based laws and regulations into a single legal and regulatory framework.\n\nInternet governance has both narrow and broad definitions, thus, making it a complex concept to understand. When most people think of Internet governance, they think of the regulations of the content and conduct that are communicated and acted on through the Internet. Although this is certainly a broad component of Internet governance, additionally, there are more narrow elements to the definition that are often overlooked. Internet governance also encompasses the regulation of Internet infrastructure and the processes, systems, and institutions that regulate the fundamental systems that determine the capabilities of the Internet.\n\nArchitecture is the foundation of the Internet. The fundamental goal of the Internet architecture is to essentially create a network of networks by interconnecting various computer network systems globally. Protocols such as TCP/IP as well as other network protocols serve as the rules and conventions by which computers can communicate with each other. Thus, TCP/IP is often viewed as the most important institution of Internet governance. It serves as the backbone to network connectivity.\nOrganizations such as the Internet Corporation for Assigned Names and Numbers (ICANN) coordinate the various systems within the Internet on a global level to help preserve the operational stability of the Internet. For example, coordination of IP addresses and managing the Domain Name System (DNS) ensure computers and devices can correctly connect to the Internet and can communicate effectively globally. If regulation of these crucial elements of the Internet such as TCP/IP and DNS were governed by disparate principles, the Internet would no longer exist as it does today. Networks, computers, and peripherals would not be able to communicate and have the same accessibility if these foundational elements varied.\n\nLike with any policy, there needs to be an agent to govern and regulate it. With information policy in a broader sense, the government has several roles and responsibilities. Some examples include providing accurate information, producing and maintaining information that meets the specific needs of the public, protecting the privacy and confidentiality of personal and sensitive information, and making informed decisions on which information should be disseminated and how to distribute it effectively, among others. Although the government plays an active role in information policy, the analysis of information policy should not only include the formal decision making processes by government entities, but also the formal and informal decisions of both the private and public sector of governance.\n\nA persistent debate concerning the government role in information policy is the separation of security and freedom of information. Legislation such as the Uniting and Strengthening America by Providing Appropriate Tools Required to Intercept and Obstruct Terrorism (USAPATRIOT or USAPA) Act of 2001 is an example of security taking precedence over civil liberties. The USAPA affected several surveillance and privacy laws to include: \nThe USAPA was passed in October 2001, not long after 9/11 and without much contention from congress. Civil liberties advocates argue that the changes made to the standing surveillance laws were done in an abrupt manner and without consideration to basic rights as outlined in the US constitution, specifically fourth amendment rights which protects against unreasonable search and seizure.\n\nThe five broad methodological strands that Rowlands (1996) identified are current tools for information policy study:\n\nClassification: The tool demonstrates a wide range of issues and subjects on information policy. It helps research to understand the breadth of the subject. The published materials are reasonably well documented and described. It is also good for start-up literature review and research purposes.\n\nIdentification of policy issues and options: This tool relies on inputs for information; for example, interviews and questionnaires targeting policy makers and other stakeholders. It is a commonly used in the studies of on-the-job policy makers in government or industry (Moore and Steele, 1991; McIntosh, 1990; Rowlands, 1997).\n\nReductionism: The reductionist approach control factors to reduce ambiguity. The factors include constraining data collection, analysis and interpretation within the framework of a specific discipline. It helps researchers to notice how a specific factor relates to the overall environment. \nForecasting and scenario-building: The commonly used model is STEEP framework. It helps in reducing uncertainties for a topic that is under studies.\n\nProcess-oriented research and cases studies: It provides detailed contextual analyses of particular events. It helps researcher to experience the policy process in semi-real situation and study its outcome.\n\nIn regards to the future of information policy, it should be flexible and changing to different circumstances as the ability to access, store, and share information grows. Galvin suggests that information policy might include setting a boundary to the uncertainty in this field. As information policy becomes a larger and more important topic, it will also become a greater subject to governmental regulation in regards to the future of technology as well. It will also include the studies of these subjects: information science, communications, library science, and technology studies.\n\nThe information policies will earn more advantages for national and organizational, such as getting the best from development of Web 2.0 nationally and in organization, influence people for paying attention to the socio aspect and socio-technical system, for securing preservation of digital content, bringing out information product, also respecting all users and making thinking time respectable.\n\nIn order to achieve this national organization, it will be important to focus not only on a domestic level but also nationally. Making domestic agencies cooperate internationally (and vice versa) though, will not be overly successful. A single nation can take the lead in establishing communication-based relationships specifically regarding the internet. These relations will need to be slowly and consistently established in order to truly unify any kind of information policy and decision-making. If information policy can be established and guided on a semi-national level, the degree of communication and cooperation throughout the world will increase dramatically. As information policy continues to shape many aspects of society, these international relations will become vital (Harpham, 2011).\n\nInformation policy is playing a greater role in the economy leading to the production of goods and services, as well as selling them directly to consumers (UCLA, 2009). The cost of information varies from a tangible good in that initial costs of the first unit are large and fixed; however, after that, marginal costs are relatively low (MacInnes, 2011). As an increase from the information services, information can be paralleled to that of manufacturing several years ago (UCLA, 2009). The digitalization of information allows businesses to make better justified business decisions (MacInnes, 2011).\n\n\n"}
{"id": "239290", "url": "https://en.wikipedia.org/wiki?curid=239290", "title": "John Wallis", "text": "John Wallis\n\nJohn Wallis (; 3 December 1616 – 8 November 1703) was an English clergyman and mathematician who is given partial credit for the development of infinitesimal calculus. Between 1643 and 1689 he served as chief cryptographer for Parliament and, later, the royal court. He is credited with introducing the symbol ∞ to represent the concept of infinity. He similarly used 1/∞ for an infinitesimal.\n\nJohn Wallis was born in Ashford, Kent, the third of five children of Reverend John Wallis and Joanna Chapman. He was initially educated at a school in Ashford but moved to James Movat's school in Tenterden in 1625 following an outbreak of plague. Wallis was first exposed to mathematics in 1631, at Martin Holbeach's school in Felsted; he enjoyed maths, but his study was erratic, since \"mathematics, at that time with us, were scarce looked on as academical studies, but rather mechanical\" (Scriba 1970).\n\nAs it was intended he should be a doctor, he was sent in 1632 to Emmanuel College, Cambridge. While there, he kept an \"act\" on the doctrine of the circulation of the blood; that was said to have been the first occasion in Europe on which this theory was publicly maintained in a disputation. His interests, however, centred on mathematics. He received his Bachelor of Arts degree in 1637 and a Master's in 1640, afterwards entering the priesthood. From 1643 to 1649, he served as a nonvoting scribe at the Westminster Assembly. He was elected to a fellowship at Queens' College, Cambridge in 1644, from which he had to resign following his marriage.\n\nThroughout this time, Wallis had been close to the Parliamentarian party, perhaps as a result of his exposure to Holbeach at Felsted School. He rendered them great practical assistance in deciphering Royalist dispatches. The quality of cryptography at that time was mixed; despite the individual successes of mathematicians such as François Viète, the principles underlying cipher design and analysis were very poorly understood. Most ciphers were ad hoc methods relying on a secret algorithm, as opposed to systems based on a variable key. Wallis realised that the latter were far more secure – even describing them as \"unbreakable\", though he was not confident enough in this assertion to encourage revealing cryptographic algorithms. He was also concerned about the use of ciphers by foreign powers, refusing, for example, Gottfried Leibniz's request of 1697 to teach Hanoverian students about cryptography.\n\nReturning to London – he had been made chaplain at St Gabriel Fenchurch in 1643 – Wallis joined the group of scientists that was later to evolve into the Royal Society. He was finally able to indulge his mathematical interests, mastering William Oughtred's \"Clavis Mathematicae\" in a few weeks in 1647. He soon began to write his own treatises, dealing with a wide range of topics, which he continued for the rest of his life.\n\nWallis joined the moderate Presbyterians in signing the remonstrance against the execution of Charles I, by which he incurred the lasting hostility of the Independents. In spite of their opposition he was appointed in 1649 to the Savilian Chair of Geometry at Oxford University, where he lived until his death on 28 October 1703 (O.S.). In 1661, he was one of twelve Presbyterian representatives at the Savoy Conference.\n\nBesides his mathematical works he wrote on theology, logic, English grammar and philosophy, and he was involved in devising a system for teaching a deaf boy to speak at Littlecote House. William Holder had earlier taught a deaf man, Alexander Popham, to speak \"plainly and distinctly, and with a good and graceful tone\". Wallis later claimed credit for this, leading Holder to accuse Wallis of \"rifling his Neighbours, and adorning himself with their spoyls\".\n\nWallis made significant contributions to trigonometry, calculus, geometry, and the analysis of infinite series. In his \"Opera Mathematica\" I (1695) he introduced the term \"continued fraction\".\n\nWallis rejected as absurd the now usual idea of a negative number as being less than nothing, but accepted the view that it is something greater than infinity. (The argument that negative numbers are greater than infinity involves the quotient formula_1 and considering what happens as \"x\" approaches and then crosses the point \"x\" = 0 from the positive side.) Despite this he is generally credited as the originator of the idea of the number line, in which numbers are represented geometrically in a line with the negative numbers represented by lengths opposite in direction to lengths of positive numbers.\n\nIn 1655, Wallis published a treatise on conic sections in which they were defined analytically. This was the earliest book in which these curves are considered and defined as curves of the second degree. It helped to remove some of the perceived difficulty and obscurity of René Descartes' work on analytic geometry.\nIn the \"Treatise on the Conic Sections\" Wallis popularised the symbol ∞ for infinity. He wrote, “I suppose any plane (following the \"Geometry of Indivisibles\" of Cavalieri) to be made up of an infinite number of parallel lines, or as I would prefer, of an infinite number of parallelograms of the same altitude; (let the altitude of each one of these be an infinitely small part 1/∞ of the whole altitude, and let the symbol ∞ denote Infinity) and the altitude of all to make up the altitude of the figure.”\n\n\"Arithmetica Infinitorum\", the most important of Wallis's works, was published in 1656. In this treatise the methods of analysis of Descartes and Cavalieri were systematised and extended, but some ideas were open to criticism. He began, after a short tract on conic sections, by developing the standard notation for powers, extending them from positive integers to rational numbers:\n\nLeaving the numerous algebraic applications of this discovery, he next proceeded to find, by integration, the area enclosed between the curve \"y\" = \"x\", the axis of \"x\", and any ordinate \"x\" = \"h\", and he proved that the ratio of this area to that of the parallelogram on the same base and of the same height is 1/(\"m\" + 1), extending Cavalieri's quadrature formula. He apparently assumed that the same result would be true also for the curve \"y\" = \"ax\", where \"a\" is any constant, and \"m\" any number positive or negative, but he discussed only the case of the parabola in which \"m\" = 2 and the hyperbola in which \"m\" = −1. In the latter case, his interpretation of the result is incorrect. He then showed that similar results may be written down for any curve of the form\n\nand hence that, if the ordinate \"y\" of a curve can be expanded in powers of \"x\", its area can be determined: thus he says that if the equation of the curve is \"y\" = \"x\" + \"x\" + \"x\" + ..., its area would be \"x\" + x/2 + \"x\"/3 + ... He then applied this to the quadrature of the curves \"y\" = (\"x\" − \"x\"), \"y\" = (\"x\" − \"x\"), \"y\" = (\"x\" − \"x\"), etc., taken between the limits \"x\" = 0 and \"x\" = 1. He shows that the areas are, respectively, 1, 1/6, 1/30, 1/140, etc. He next considered curves of the form \"y\" = \"x\" and established the theorem that the area bounded by this curve and the lines \"x\" = 0 and \"x\" = 1 is equal to the area of the rectangle on the same base and of the same altitude as \"m\" : \"m\" + 1. This is equivalent to computing\n\nHe illustrated this by the parabola, in which case \"m\" = 2. He stated, but did not prove, the corresponding result for a curve of the form \"y\" = \"x\".\n\nWallis showed considerable ingenuity in reducing the equations of curves to the forms given above, but, as he was unacquainted with the binomial theorem, he could not effect the quadrature of the circle, whose equation is formula_11, since he was unable to expand this in powers of \"x\". He laid down, however, the principle of interpolation. Thus, as the ordinate of the circle formula_11 is the geometrical mean of the ordinates of the curves formula_13 and formula_14, it might be supposed that, as an approximation, the area of the semicircle formula_15 which is formula_16 might be taken as the geometrical mean of the values of\n\nthat is, 1 and formula_18; this is equivalent to taking formula_19 or 3.26... as the value of π. But, Wallis argued, we have in fact a series formula_20... and therefore the term interpolated between 1 and formula_21 ought to be chosen so as to obey the law of this series. This, by an elaborate method that is not described here in detail, leads to a value for the interpolated term which is equivalent to taking\n(which is now known as the Wallis product).\n\nIn this work also the formation and properties of continued fractions are discussed, the subject having been brought into prominence by Brouncker's use of these fractions.\n\nA few years later, in 1659, Wallis published a tract containing the solution of the problems on the cycloid which had been proposed by Blaise Pascal. In this he incidentally explained how the principles laid down in his \"Arithmetica Infinitorum\" could be used for the rectification of algebraic curves and gave a solution of the problem to rectify (i.e., find the length of) the semicubical parabola \"x\" = \"ay\", which had been discovered in 1657 by his pupil William Neile. Since all attempts to rectify the ellipse and hyperbola had been (necessarily) ineffectual, it had been supposed that no curves could be rectified, as indeed Descartes had definitely asserted to be the case. The logarithmic spiral had been rectified by Evangelista Torricelli and was the first curved line (other than the circle) whose length was determined, but the extension by Neile and Wallis to an algebraic curve was novel. The cycloid was the next curve rectified; this was done by Christopher Wren in 1658.\n\nEarly in 1658 a similar discovery, independent of that of Neile, was made by van Heuraët, and this was published by van Schooten in his edition of Descartes's \"Geometria\" in 1659. Van Heuraët's method is as follows. He supposes the curve to be referred to rectangular axes; if this be so, and if (\"x\", \"y\") be the coordinates of any point on it, and \"n\" be the length of the normal, and if another point whose coordinates are (\"x\", η) be taken such that η : \"h\" = \"n\" : \"y\", where \"h\" is a constant; then, if \"ds\" be the element of the length of the required curve, we have by similar triangles \"ds\" : \"dx\" = \"n\" : \"y\". Therefore, \"h ds\" = η \"dx\". Hence, if the area of the locus of the point (\"x\", η) can be found, the first curve can be rectified. In this way van Heuraët effected the rectification of the curve \"y\" = \"ax\" but added that the rectification of the parabola \"y\" = \"ax\" is impossible. since it requires the quadrature of the hyperbola. The solutions given by Neile and Wallis are somewhat similar to that given by van Heuraët, though no general rule is enunciated, and the analysis is clumsy. A third method was suggested by Fermat in 1660, but it is inelegant and laborious.\n\nThe theory of the collision of bodies was propounded by the Royal Society in 1668 for the consideration of mathematicians. Wallis, Christopher Wren, and Christian Huygens sent correct and similar solutions, all depending on what is now called the conservation of momentum; but, while Wren and Huygens confined their theory to perfectly elastic bodies (elastic collision), Wallis considered also imperfectly elastic bodies (inelastic collision). This was followed in 1669 by a work on statics (centres of gravity), and in 1670 by one on dynamics: these provide a convenient synopsis of what was then known on the subject.\n\nIn 1685 Wallis published \"Algebra\", preceded by a historical account of the development of the subject, which contains a great deal of valuable information. The second edition, issued in 1693 and forming the second volume of his \"Opera\", was considerably enlarged. This algebra is noteworthy as containing the first systematic use of formulae. A given magnitude is here represented by the numerical ratio which it bears to the unit of the same kind of magnitude: thus, when Wallis wants to compare two lengths he regards each as containing so many units of length. This perhaps will be made clearer by noting that the relation between the space described in any time by a particle moving with a uniform velocity is denoted by Wallis by the formula\n\nwhere \"s\" is the number representing the ratio of the space described to the unit of length; while the previous writers would have denoted the same relation by stating what is equivalent to the proposition\n\nHe is usually credited with the proof of the Pythagorean theorem using similar triangles. However, Thabit Ibn Qurra (AD 901), an Arab mathematician, had produced a generalisation of the Pythagorean theorem applicable to all triangles six centuries earlier. It is a reasonable conjecture that Wallis was aware of Thabit's work.\n\nWallis was also inspired by the works of Islamic mathematician Sadr al-Tusi, the son of Nasir al-Din al-Tusi, particularly by al-Tusi's book written in AD 1298 on the parallel postulate. The book was based on his father's thoughts which presented one of the earliest arguments for a non-Euclidean hypothesis equivalent to the parallel postulate. After reading this, Wallis then wrote about his ideas as he developed his own thoughts about the postulate, trying to prove it also with similar triangles.\n\nHe found that Euclid's fifth postulate is equivalent to the one currently named \"Wallis postulate\" after him. This postulate states that \"On a given finite straight line it is always possible to construct a triangle similar to a given triangle\". This result was encompassed in a trend trying to deduce Euclid's fifth from the other four postulates which today is known to be impossible. Unlike other authors, he realised that the unbounded growth of a triangle was not guaranteed by the four first postulates.\n\nAnother aspect of Wallis's mathematical skills was his ability to do mental calculations. He slept badly and often did mental calculations as he lay awake in his bed. One night he calculated in his head the square root of a number with 53 digits. In the morning he dictated the 27-digit square root of the number, still entirely from memory. It was a feat that was considered remarkable, and Henry Oldenburg, the Secretary of the Royal Society, sent a colleague to investigate how Wallis did it. It was considered important enough to merit discussion in the \"Philosophical Transactions\" of the Royal Society of 1685.\n\nA long-running debate between Wallis and Thomas Hobbes arose in the mid-1650s, when mathematicians criticised errors in the work \"De corpore\" by Hobbes. It continued into the 1670s, having gathered in the later claims of Hobbes on squaring the circle, and the wider beliefs on both sides.\n\nWallis translated into Latin works of Ptolemy, Bryennius, and Porphyrius's commentary on Ptolemy. He also published three letters to Henry Oldenburg concerning tuning. He approved of equal temperament that was being used in England's organs.\n\nHis \"Institutio logicae\", published in 1687, was very popular. The \"Grammatica linguae Anglicanae\" was a work on English grammar, that remained in print well into the eighteenth century. He also published on theology.\n\nOn 14 March 1645 he married Susanna Glynde (16?? – 16 March 1687), They had three children:\n\n\n\n"}
{"id": "27629221", "url": "https://en.wikipedia.org/wiki?curid=27629221", "title": "Keiko Holmes", "text": "Keiko Holmes\n\nKeiko was born in Kiwa-cho, Kumano, Mie Prefecture, Japan in 1948. She travelled to Tokyo to study, and there met Paul Holmes, a visiting business man from England. They married and then moved to London with their sons Daniel and Christopher in 1979.\n\nPaul was killed in an air accident in 1984 while on a business trip. They had been together for 15 years. Through Paul, Keiko had converted to Christianity. During their time in Japan, while living in Mie the couple had come across a memorial stone laid for 16 British army soldiers. The soldiers had died in the local area called Iruka, now called Kiwa-cho, while working as prisoners in a copper mine. The local people had created the memorial and had written the names of the soldiers on the memorial.\nThe Ikura mine was different from many others because the British soldiers worked side by side with Japanese miners.\n\nWhen Keiko returned to Mie for a trip after Paul's death, she went back to the memorial site and was surprised to see that it had been improved into a memorial garden with a marble headstone and kept beautifully decorated with flowers. The soldiers' names had been engraved on a large copper cross.\n\nHolmes had the inspiration to organise reconciliation trips for ex-POWs of Ikura during her long period of mourning for her husband.\n\nIn 1991, Holmes attended the annual conference of the British Far East Prisoners of War Association in London.\n\nIn October 1992, Holmes took 26 FEPOWs and two widows back to attend a memorial service at the Iruka (now called Itaya) memorial. These men and woman had for 50 years held hatred and bitterness for Japan and its people. Upon arrive at the memorial and witnessing the beauty of the memorial donated by the local people and receiving their sincere apologies the 50 years of hate gave way to new positive feelings and healing.\n\nSince the first pilgrimage, Holmes has gone on to organise more trips and eventually founded “Agape”, in 1996. The name is taken from an ancient Greek word meaning, unconditional love. Supported by many people in Britain and Japan, as well as by donations from Japanese firms, including Sumitomo Corp. The Bank of Tokyo Mitsubishi and many others. Agape now brings small veteran groups from Britain, the Netherlands, Canada, Australia, and New Zealand to Japan twice a year. On the trips, the FEPOWs come face to face with their old guards. Former soldiers, camp and prison guards often attend the Agape memorial service and meetings. Hiroshi Abe was a young officer in a railway regiment during the war assigned to the infamous Thai-Burma railway known to FEPOWs as the “Death Railway”. He attends the memorial every year to meet the soldiers. Abe's apology is printed in the Agape pamphlet:\n\n\"I cannot deny that l am partly responsible for the deaths of many POW’s, and l apologise sincerely for what we did during the war.\"\n\nAfter many uphill struggles since the first pilgrimage to Japan in 1992. Agape has taken hundreds of FEPOWs to Japan's former war camp sites. Many FEPOWs express how their hated towards Japan has changed into love for the Japanese people. Holmes was awarded the O.B.E by Queen Elizabeth II at Windsor Castle on 28 April 1998. She attended the ceremony with her sons Daniel and Christopher.\n\nIn the 2003, Holmes met the Emperor and Empress of Japan in Buckingham Palace, England.\n\nIn 2004 Holmes, Kosuge and some other members of Agape including Holmes' son Daniel Holmes went to Nanjing, China to apologise for the crimes committed and pain inflicted by her country men during the war. Holmes also has visited Malaysia, the Netherlands, Thailand, Hong Kong, Taiwan, Singapore, Australia, United States, Canada and India holding meetings and lecturing at universities.\n\n\n"}
{"id": "4442411", "url": "https://en.wikipedia.org/wiki?curid=4442411", "title": "Kosha", "text": "Kosha\n\nA Kosha (also Kosa; Sanskrit कोश, IAST: ), usually rendered \"sheath\", is a covering of the Atman, or Self according to Vedantic philosophy. There are five Koshas, and they are often visualised as the layers of an onion.\n\nThe five sheaths (pancha-kosas) are described in the Taittiriya Upanishad. From gross to fine they are:\n\nAccording to Vedanta the wise person, being aware of the subtle influences of the five elements within each kosha, ever discerns the Self amidst appearances.\n\nThis is the sheath of the physical self, named from the fact that it is nourished by food. Living through this layer humans identify themselves with a mass of skin, flesh, fat, bones, and filth, while the human of discrimination knows their own self, the only reality that there is, as distinct from the body.\n\nPranamaya means composed of prana, the vital principle, the force that vitalizes and holds together the body and the mind. It pervades the whole organism, its one physical manifestation is the breath. As long as this vital principle exists in the organisms, life continues. Coupled with the five organs of action it forms the vital sheath. In the Vivekachudamani it is a modification of vayu or air, it enters into and comes out of the body.\n\nManomaya means composed of manas or mind. The mind (manas) along with the five sensory organs is said to constitute the manomaya kosa. The \"manomaya kosa\", or “mind-sheath” is said more truly to approximate to personhood than \"annamaya kosa\" and \"pranamaya kosha\". It is the cause of diversity, of \"I\" and \"mine\". Sankara likens it to clouds that are brought in by the wind and again driven away by the same agency. Similarly, man’s bondage is caused by the mind, and liberation, too, is caused by that alone.\n\nVijñānmāyā means composed of Vijñānā, or intellect, the faculty which discriminates, determines or wills. Chattampi Swamikal defines Vijñānmāyā as the combination of intellect and the five sense organs. It is the sheath composed of more intellection, associated with the organs of perception. Sankara holds that the buddhi, with its modifications and the organs of knowledge, form the cause of man’s transmigration. This knowledge sheath, which seems to be followed by a reflection of the power of the cit, is a modification of prakrti. It is endowed with the function of knowledge and identifies itself with the body, organs etc.\n\nThis knowledge sheath cannot be the supreme self for the following reasons;\n\nAnandamaya means composed of ananda, or bliss. In the Upanishads the sheath is known also as the \"causal body\". In deep sleep, when the mind and senses cease functioning, it still stands between the finite world and the self. Anandamaya, or that which is composed of Supreme bliss, is regarded as the innermost of all. The bliss sheath normally has its fullest play during deep sleep: while in the dreaming and wakeful states, it has only a partial manifestation. The blissful sheath (anandamaya kosha) is a reflection of the Atman which is truth, beauty, bliss absolute.\n\nThe following entry is for the utility of Hindu aspirants who are familiar with Panchakosha:\n\nJust as each of the five elements (earth, water, fire, air, and ether) appear in corresponding subtlety among each of the five senses so too the intellect cognizes ever subtler causes and effects at play through each of the five sheaths.\n\nFor example, the annamayakosha, the coarsest sheath, is based in the earth element, which is guarded by Ganesha, while the very subtlest sheath Anandamaya is based in the quanta/ether element, and is guarded by a black disc of utter darkness over the sun, which can be removed only by Ganesha.\n\nAwareness of that reflection of atman/self within the most subtle sheath, Anandamayakosha, however, is but the foundation for discerning that which the elements, energies, senses, and kosha serve. To that end, one re-examines the components of the five koshas in daily devotional meditation after recitation of twenty-one OM, viz, one OM per each of the five elements, the five pranas, the five indriyas, and the five kosha, equaling twenty OM, then a twenty-first OM is offered for the ineffable, such that a spiritual discernment of ever-increasing subtlety arises in the purified intellect, alaya nirvijnana, the womb of the tathagata, wherein silence ensues and clarity blossoms.\n\n\n"}
{"id": "10098365", "url": "https://en.wikipedia.org/wiki?curid=10098365", "title": "Lean construction", "text": "Lean construction\n\nLean construction is a combination of operational research and practical development in design and construction with an adaption of lean manufacturing principles and practices to the end-to-end design and construction process. Unlike manufacturing, construction is a project-based production process. Lean construction is concerned with the alignment and holistic pursuit of concurrent and continuous improvements in all dimensions of the built and natural environment: design, construction, activation, maintenance, salvaging, and recycling (Abdelhamid 2007, Abdelhamid et al. 2008). This approach tries to manage and improve construction processes with minimum cost and maximum value by considering customer needs (Koskela et al. 2002).\n\nThe term \"lean construction\" was coined by the International Group for Lean Construction in its first meeting in 1993 (Gleeson et al. 2007). \"Construction\" in \"Lean Construction\" refers to the entire industry and not the phase during which construction takes place. Thus, Lean Construction is for owners, architects, designers, engineering, constructors, suppliers & end users.\n\nLauri Koskela, in 1992, challenged the construction management community to consider the inadequacies of the time-cost-quality tradeoff paradigm. Another paradigm-breaking anomaly was that observed by Ballard (1994), Ballard and Howell (1994a and 1994b), and Howell (1998). Analysis of project plan failures indicated that \"normally only about 50% of the tasks on weekly work plans are completed by the end of the plan week\" and that constructors could mitigate most of the problems through \"active management of variability, starting with the structuring of the project (temporary production system) and continuing through its operation and improvement,\" (Ballard and Howell 2003).\n\nEvidence from research and observations indicated that the conceptual models of Construction Management and the tools it utilizes (work breakdown structure, critical path method, and earned value management) fail to deliver projects 'on-time, at budget, and at desired quality' (Abdelhamid 2004). With recurring negative experiences on projects, evidenced by endemic quality problems and rising litigation, it became evident that the governing principles of construction management needed revisiting. One comment published by the CMAA, in its \"Sixth Annual Survey of Owners\" (2006), pointed to concern about work methods and the cost of waste: \"While the cost of steel and cement are making headlines, the less publicized failures in the management of construction projects can be disastrous. Listen carefully to the message in this comment. We are not talking about just materials, methods, equipment, or contract documents. We are talking about how we work to deliver successful capital projects and how we manage the costs of inefficiency.\" \n\nKoskela (2000) argued that the mismatch between the conceptual models and observed reality underscored the lack of robustness in the existing constructs and signaled the need for a theory of production in construction. Koskela then used the ideal production system embodied in the Toyota Production System to develop a more overarching production management paradigm for project-based production systems where production is conceptualized in three complementary ways, namely, as a Transformation (T), as a Flow (F), and as Value generation (V).\n\nKoskela and Howell (2002) also presented a review of existing management theory – specifically as related to the planning, execution, and control paradigms – in project-based production systems. Both conceptualizations provide a solid intellectual foundation of lean construction as evident from both research and practice (Abdelhamid 2004).\n\nRecognizing that construction sites reflect prototypical behavior of complex and chaotic systems, especially in the flow of both material and information on and off site, Bertelsen (2003a and 2003b) suggested that construction should be modeled using chaos and complex systems theory.\nBertelsen (2003b) specifically argued that construction could and should be understood in three complimentary ways:\n\nLean construction is a “way to design production systems to minimize waste of materials, time, and effort in order to generate the maximum possible amount of value,\" (Koskela et al. 2002). Designing a production system to achieve the stated ends is only possible through the collaboration of all project participants (Owner, A/E, contractors, Facility Managers, End-user) at early stages of the project. This goes beyond the contractual arrangement of design/build or constructability reviews where contractors, and sometime facility managers, merely react to designs instead of informing and influencing the design (Abdelhamid et al. 2008).\n\nLean construction recognizes that desired ends affect the means to achieve these ends, and that available means will affect realized ends (Lichtig 2004). Essentially, lean construction aims to embody the benefits of the Master Builder concept (Abdelhamid et al. 2008).\n\n\"One can think of lean construction in a way similar to mesoeconomics. Lean construction draws upon the principles of project-level management and upon the principles that govern production-level management. Lean construction recognizes that any successful project undertaking will inevitably involve the interaction between project and production management.\" (Abdelhamid 2007)\n\nLean construction supplements traditional construction management approaches with (Abdelhamid 2007): (1) two critical and necessary dimensions for successful capital project delivery by requiring the deliberate consideration of material and information flow and value generation in a production system; and (2) different project and production management (planning-execution-control) paradigms.\n\nWhile lean construction is identical to lean production in spirit, it is different in how it was conceived as well as how it is practiced. There is a view that \"adaptation\" of Lean Manufacturing/Production forms the basis of Lean Construction. The view of Lauri Koskela, Greg Howell, and Glenn Ballard is very different, with the origin of lean construction arising mainly from the need for a production theory in construction and anomalies that were observed in the reliability of weekly production planning.\n\nGetting work to flow reliably and predictably on a construction site requires the impeccable alignment of the entire supply chain responsible for constructed facilities such that value is maximized and waste is minimized. With such a broad scope, it is fair to say that tools found in Lean Manufacturing and Lean Production, as practiced by Toyota and others, have been adapted to be used in the fulfillment of Lean construction principles. TQM, SPC, six-sigma, have all found their way into lean construction. Similarly, tools and methods found in other areas, such as in social science and business, are used where they are applicable. The tools and methods in construction management, such as CPM and work breakdown structure, etc., are also utilized in lean construction implementations. The three unique tools and methods that were specifically conceived for lean construction are the Last Planner System, Target Value Design, and the Lean Project Delivery System.\n\nIf the tool, method, and/or technique will assist in fulfilling the aims of lean construction, it is considered a part of the toolkit available for use. A sampling of these tools includes: BIM (Lean Design), A3, process design (Lean Design), offsite fabrication and JIT (Lean Supply), value chain mapping (Lean Assembly), visual site (Lean Assembly); 5S (Lean Assembly), daily crew huddles (Lean Assembly).\n\nThe priority for all construction work is to:\n\nWhile lean construction’s main tool for making design and construction processes more predictable is the Last Planner System (see below) and derivatives of it, other lean tools already proven in manufacturing have been adapted to the construction industry with equal success. These include: 5S, Kanban, Kaizen events, quick setup/changeover, Poka Yoke, visual control and 5 Whys (Mastroianni and Abdelhamid 2003, Salem et al. 2005).\n\nThe early involvement of contractors and suppliers is seen as a key differentiator for construction so called 'best practice'. While there are Trade Marked business processes (see below), academics have also addressed related concepts such as 'early contractor involvement' (ECI).\n\n Primary IPD team members include the owner, architect, key technical consultants, general contractor and key subcontractors.\n\nUsing IPD, project participants can overcome key organizational and contractual problems. The IPD approach to contracting aligns project objectives with the interests of key participants. IPD relies on participant selection, transparency and continuing dialog. Construction consumers might consider rethinking their contracting strategies to share more fully in the benefits. The IPD approach creates an organization with the ability to apply Lean Project Delivery (LPD) principles and practices. (Matthews and Howell 2005)\n\nThere are at least five principal forms of contract that support lean construction\n\nOther papers explain Integrated Project Delivery (IPD) and IFoA. PPC2000, IFoA and 'alliancing agreements' were among the topics discussed at the 'Lean in the Public Sector' (LIPS) conference held in 2009.\n\nIntegrated Lean Project Delivery (ILPD) is a process trademarked by The Boldt Group. It was created and is practiced by The Boldt Group's subsidiary, The Boldt Company. The process aims to eliminate waste across the construction value chain, through evaluation of initial planning and design, and examination of construction processes to predict where and when waste will occur, which is then eliminated through the use of lean tools in the IPD process.\n\nAn ILPD contract is a multi-party agreement that specifies the use of lean practices as conceived in the Lean Project Delivery System. This distinction is needed because Integrated Project Delivery (IPD) is now only referring to the multi-party agreement regardless of what practices are used, the so-called IPD-lite or IPD-ish.\n\nIn the UK, a major R&D project, \"Building Down Barriers\", was launched in 1997 to adapt the Toyota Production System for use in the construction sector. The resulting supply chain management toolset was tested and refined on two pilot projects and the comprehensive and detailed process-based toolset was published in 2000 as the 'Building Down Barriers Handbook of Supply Chain Management-The Essentials'. The project demonstrated very clearly that lean thinking would only deliver major performance improvements if the construction sector learned from the extensive experience of other business sectors. Lean thinking must become the way that all the firms in the design and construction supply chain co-operate with each other at a strategic level that over-arches individual projects. In the aerospace sector, these long-term supply-side relationships are called a 'Virtual Company', in other business sectors they are called an 'Extended Lean Enterprise'.\n\nThe UK 'Building Down Barriers Handbook of Supply Chain Management-The Essentials' states that: 'The commercial core of supply chain management is setting up long-term relationships based on improving the value of what the supply chain delivers, improving quality and reducing underlying costs through taking out waste and inefficiency. This is the opposite of 'business as usual' in the construction sector, where people do things on project after project in the same old inefficient ways, forcing each other to give up profits and overhead recovery in order to deliver at what seems the market price. What results is a fight over who keeps any of the meagre margins that result from each project, or attempts to recoup 'negative margins' through 'claims', The last thing that receives time or energy in this desperate, project-by-project gladiatorial battle for survival is consideration of how to reduce underlying costs or improve quality'.\n\nThe Last Planner System, as developed by the Lean Construction Institute, is: The collaborative, commitment-based planning system that integrates should-can-will-did planning (pull planning, make-ready, look-ahead planning) with constraint analysis, weekly work planning based upon reliable promises, and learning based upon analysis of PPC (plan percent complete) and reasons for variance.\n\nUsers such as owners, clients or construction companies, can use LPS to achieve better performance in design and construction through increased schedule/programme predictability (i.e. work is completed as and when promised).\n\nLPS is a system of inter-related elements, and full benefits come when all are implemented together. It is based on simple paper forms, so it can be administered using Post-it notes, paper, pencil, eraser and photocopier. A spreadsheet can help.\n\nLPS begins with collaborative scheduling/programming engaging the main project suppliers from the start. Risk analysis ensures that float is built in where it will best protect programme integrity and predictability. Where appropriate the process can be used for \"programme compression\" too. In this way, one constructor took 6 weeks out of an 18-week programme for the construction of a 40 bed hotel. Benefits to the client are enormous.\nFigure 1: intense discussion during a programme compression workshop\n\nBefore work starts, team leaders make tasks ready so that when work should be done, it can be. Why put work into production if a pre-requisite is missing? This \"MakeReady\" process continues throughout the project.\nFigure 2: part of a MakeReady form for documenting the process of making tasks ready (this one for use in design)\n\nThere is a weekly work planning (WWP) meeting involving all the last planners – design team leaders and/or trade supervisors on site. It is in everyone’s interest to explore inter-dependencies between tasks and prevent colleagues from over-committing.\nFigure 3: part of a Weekly Work Plan form used by trade foremen on site or design team leaders to prepare for the WWP meeting.\n\nThis weekly work planning processes is built around \"promises\". The agreed programme defines when tasks \"should\" be done and acts as a request to the supplier to do that task. The \"last planners\" (that is the trade foremen on site or design team leaders in a design process) only promise once they have clarified the conditions of satisfaction and are clear that the task can be done.\nFigure 4: the promise cycle (after Fernando Flores)\n\nOnce the task is complete the last planner responsible declares completion so that site management or the next trade can assure themselves that it is complete to an appropriate standard.\n\nA key measure of the success of the Last Planner system is PPC. This measures the \"Percentage of Promises Completed\" on time. As PPC increases. project productivity and profitability increase, with step changes at around 70% and 85%. This score is measured site-wide and displayed around the site. Weekly measures are used by the project and by individual suppliers as the basis for learning how to improve the predictability of the work programme and hence the PPC scores.\n\nA key part of the continual improvement process is a study of the reasons why tasks promised in the WWP are delivered late. The following chart shows typical reasons:\nFigure 5: example of a reasons Pareto chart\n\nRecording the reasons in a Pareto chart like the one above makes it easy to see where attention is most likely to yield the most results. Using tools like 5 Why analysis and cause-effect diagrams will help the team understand how they can improve the clarity of information and ensure that there are sufficient operatives.\n\nLast Planner benefits don’t stop at project predictability, profit and productivity; it contributes to positive changes in other industry KPIs. Danish research shows almost half the accidents and up to 70% less sickness absence on LPS managed sites.\n\nLCI retains a registered Trademark on the term and Copyright in the idea and materials to prevent people who misunderstand or misrepresent the system from using it in trade. Consulting companies or individuals wishing to use the Last Planner System in trade (commercial offering of service) must first be approved by LCI. Consultants are expected to make financial and other contributions to LCI in recognition of the work and effort LCI put into developing Last Planner.\n\nLast Planner System development continues under the direction of Lean Construction Institute Directors Professor Glenn Ballard and Greg Howell with support from users around the world. For more information about the development process see Ballard (1994, 2000) and Ballard and Howell (2004) for example.\n\nFor a detailed description and list of the benefits of LPS, see \"Mossman: Last Planner®: 5 + 1 crucial & collaborative conversations for predictable design & construction delivery\" and for additional references see the Designing Buildings wiki.\n\nThere are many differences between the Lean Construction (LC) approach and the Project Management Institute (PMI) approach to construction. These include:\n\n\nVarious networks and institutes conduct research and teach Lean Construction.\n\n\nVarious universities teach and conduct research on lean construction:\n\n\n\n\n\n"}
{"id": "51708164", "url": "https://en.wikipedia.org/wiki?curid=51708164", "title": "Lineage selection", "text": "Lineage selection\n\nLineage selection, occurs when the frequency of one biological lineage changes in frequency relative to another lineage. Lineage selection is a generalization of individual based natural selection; the stating that an allele is favored by natural selection is equivalent to stating that the lineage bearing the allele is favored by natural selection. For alleles with simple positive or negative fitness effects, lineage and individual based selection are equivalent. However, lineage selection can accommodate a wider array of evolutionary phenomena, such as the adaptive evolution of evolvability, altruism, and recombination. Additionally, lineage selection is useful in determining the effects of mutations in highly structured environments such as tumors.\n"}
{"id": "52704076", "url": "https://en.wikipedia.org/wiki?curid=52704076", "title": "Lutte pour le changement", "text": "Lutte pour le changement\n\nLutte Pour Le Changement (LUCHA) is a group based in Goma in eastern Democratic Republic of Congo who fights for a class of rights that protect Congoleses' freedom from infringement by governments, social organizations, and private individuals. They ensure one's ability to participate in the civil and political life of the Congolese society and state without discrimination or repression.\n\nThis group was born out of frustration with the current political process and diminished social condition in the Democratic Republic of Congo by a group of young Congolese students. These students understood that violence is not the way for anyone willing to find durable solutions to political and social disputes and wars that have torn their country apart for the past half century.\n\nThe one thing that defines the Lutte Pour Le Changement activists is their love for their native DR Congo and the hope to see it prosperous and developed in their lifetime. They have decided to organize a series of non-violent actions throughout major cities in the country to shed light to some of the critical issues facing the Congolese population. Their actions are not limited to keeping politicians honest, but rather engaging the population into participating in the social issues debates. The movement started in the eastern city of Goma in the Democratic Republic of Congo in Mid-June 2011 and in no time, the movement had spread all the way to the west of the country, with famous members such as Fred Bauma and Yves Makwambala being incarcerated since March 2015 at the Congolese National Intelligence Agency headquarters in Kinshasa. On March 15, 2015, according to the online news media Pragmora, \"About 30 youth activists and international journalists and observers were arrested in Kinshasa during a youth workshop aimed at increasing youth participation in politics and the electoral process, and creating a new youth movement, Filimbi\". In the recent uprising, many of the LUCHA activists arrested during Dec 19, 2016 have been released, including the 23 year old Gloria Sengha Panda Shala according to Ida Sawyer a Human Rights Watch Director in Central Africa.\n\nThe first LUCHA protest to receive widespread attention was the effort to get the young people to get involved in the 2011 presidential and legislatives elections by ensure that all eligible to vote got registered ahead of the upcoming the elections. Then followed a few actions in regards to lack of clean water in Goma and also issue with garbage waste in the same city. This movement got the eye of the Congolese people because this group managed first and foremost to get the general population to have a say in these critical matters facing their livelihood through the streets of various Congolese cities namely Kinshasa, Mbuji-Mayi, Lubumbashi, Kisangani et Goma.\n\nThe group is determined to ensure there is better governance, respect for human rights and improved and much stronger democracy in the country that faced 32 years of President Mobutu Dictatorship. These inspired Congolese youths driven by social injustice and non democratic political process believe that their movement can bring about positive change in the DR Congo, as well as Africa as a whole.\n\nThese courageous young men have come to know nothing but armed conflicts all of their teenage and adult lives. Therefore, when deciding to create the movement they decided that they will only use non-violent actions as the core principal in raising awareness on social and political issues facing the DRC. Nevertheless, most of these youths have been detained without charge during peaceful protest and /or gatherings. Some of the famous members detained by the Congolese national intelligence agency and have made claims of moral and physical abuses while incarcerated.\n\nWe are leaders. Not hostages of the past. Nor slaves of the present. Nor beggars of our future!\n\nIt also reads on their official site:\n\nWE ARE NOT VIOLENT\n\nWE RISK TOGETHER\n\nWE ASSUME OUR ACTS\n\nLUCHA activists have used web technologies and social media like Facebook, Twitter, and Meetup to coordinate events. The digital evolution with the improvements on the application such as WhatsApp, Imo and Skype has helped the movement with communications, conference calls among participants in various locations within the DR Congo as well as the Congolese diaspora via various Congolese online media, such as Congo Mikili. The group has also been organizing workshops across the country to teach youth on how to engage in social and political issues.\n\n"}
{"id": "1506351", "url": "https://en.wikipedia.org/wiki?curid=1506351", "title": "Magnetoreception", "text": "Magnetoreception\n\nMagnetoreception (also magnetoception) is a sense which allows an organism to detect a magnetic field to perceive direction, altitude or location. This sensory modality is used by a range of animals for orientation and navigation, and as a method for animals to develop regional maps. For the purpose of navigation, magnetoreception deals with the detection of the Earth's magnetic field.\n\nMagnetoreception is present in bacteria, arthropods, molluscs and members of all major taxonomic groups of vertebrates. Humans are not thought to have a magnetic sense, but there is a protein (a cryptochrome) in the eye which could serve this function.\n\nAn unequivocal demonstration of the use of magnetic fields for orientation within an organism has been in a class of bacteria known as magnetotactic bacteria. These bacteria demonstrate a behavioural phenomenon known as magnetotaxis, in which the bacterium orients itself and migrates in the direction along the Earth's magnetic field lines. The bacteria contain magnetosomes, which are nanometer-sized particles of magnetite or iron sulfide enclosed within the bacterial cells. The magnetosomes are surrounded by a membrane composed of phospholipids and fatty acids and contain at least 20 different proteins They form in chains where the magnetic moments of each magnetosome align in parallel, causing each bacterium cell to essentially act as a magnetic dipole, giving the bacteria their permanent-magnet characteristics.\n\nFor animals the mechanism for magnetoreception is unknown, but there exist two main hypotheses to explain the phenomenon.\nAccording to one model, magnetoreception is possible via the radical pair mechanism. The radical-pair mechanism is well-established in spin chemistry, and was speculated to apply to magnetoreception in 1978 by Schulten et al.. In 2000, cryptochrome was proposed as the \"magnetic molecule\", so to speak, that could harbor magnetically sensitive radical-pairs. Cryptochrome, a flavoprotein found in the eyes of European robins and other animal species, is the only protein known to form photoinduced radical-pairs in animals. The function of cryptochrome is diverse across species, however, the photoinduction of radical-pairs occurs by exposure to blue light, which excites an electron in a chromophore. The Earth's magnetic field is only 0.5 gauss and so it is difficult to conceive of a mechanism, other than phase shift, by which such a field could lead to any chemical changes other than those affecting the weak magnetic fields between radical pairs. Cryptochromes are therefore thought to be essential for the light-dependent ability of the fruit fly \"Drosophila melanogaster\" to sense magnetic fields.\n\nThe second proposed model for magnetoreception relies on FeO, also referred to as iron (II, III) oxide or magnetite, a natural oxide with strong magnetism. Iron (II, III) oxide remains permanently magnetized when its length is larger than 50 nm and becomes magnetized when exposed to a magnetic field if its length is less than 50 nm. In both of these situations the Earth's magnetic field leads to a transducible signal via a physical effect on this magnetically sensitive oxide.\n\nAnother less general type of magnetic sensing mechanism in animals that has been described is electromagnetic induction used by sharks, stingrays and chimaeras (cartilaginous fish). These species possess a unique electroreceptive organ known as \"ampullae of Lorenzini\" which can detect a slight variation in electric potential. These organs are made up of mucus-filled canals that connect from the skin's pores to small sacs within the animal's flesh that are also filled with mucus. The ampullae of Lorenzini are capable of detecting DC currents and have been proposed to be used in the sensing of the weak electric fields of prey and predators. These organs could also possibly sense magnetic fields, by means of Faraday's law: as a conductor moves through a magnetic field an electric potential is generated. In this case the conductor is the animal moving through a magnetic field, and the potential induced depends on the time varying rate of flux through the conductor according to\nformula_1.\nThese organs detect very small fluctuations in the potential difference between the pore and the base of the electroreceptor sack. An increase in potential results in a decrease in the rate of nerve activity, and a decrease in potential results in an increase in the rate of nerve activity. This is analogous to the behavior of a current carrying conductor; with a fixed channel resistance, an increase in potential would decrease the amount of current detected, and vice versa. These receptors are located along the mouth and nose of sharks and stingrays. Although debated, it has been proposed that in terrestrial animals the semicircular canals of the inner ear could host a magnetosensitive system based on electromagnetic induction. \n\nThe nematode \"Caenorhabditis elegans\" was proposed to orient to the magnetic field of the Earth using the first described set of magnetosensory neurons. Worms appear to use the magnetic field to orient during vertical soil migrations that change in sign depending on their satiation state (with hungry worms burrowing down, and satiated worms burrowing up). However, recent evidence challenges these findings. \n\nThe mollusk \"Tochuina tetraquetra\" (formerly \"Tritonia diomedea\" or \"Tritonia gigantea\") has been studied for clues as to the neural mechanism behind magnetoreception in a species. Some of the earliest work with \"Tochuina\" showed that prior to a full moon \"Tochuina\" would orient their bodies between magnetic north and east. A Y-maze was established with a right turn equal to geomagnetic south and a left turn equal to geomagnetic east. Within this geomagnetic field 80% of \"Tochuina\" made a turn to the left or magnetic east. However, when a reversed magnetic field was applied that rotated magnetic north 180° there was no significant preference for either turn, which now corresponded with magnetic north and magnetic west. These results, though interesting, do not conclusively establish that \"Tochuina\" uses magnetic fields in magnetoreception. These experiments do not include a control for the activation of the Rubens’ coil in the reversed magnetic field experiments. Therefore, it is possible that heat or noise generated by the coil was responsible for the loss of choice preference. Further work with \"Tochuina\" was unable to identify any neurons that showed rapid changes in firing as a result of magnetic fields. However, pedal 5 neurons, two bisymmetric neurons located within the \"Tochuina\" pedal ganglion, exhibited gradual changes in firing over time following 30 minutes of magnetic stimulation provided by a Rubens’ coil. Further studies showed that pedal 7 neurons in the pedal ganglion were inhibited when exposed to magnetic fields over the course of 30 minutes. The function of both pedal 5 neurons and pedal 7 neurons is currently unknown.\n\n\"Drosophila melanogaster\" is another invertebrate which may be able to orient to magnetic fields. Experimental techniques such as gene knockouts have allowed a closer examination of possible magnetoreception in these fruit flies. Various \"Drosophila\" strains have been trained to respond to magnetic fields. In a choice test flies were loaded into an apparatus with two arms that were surrounded by electric coils. Current was run through each of the coils, but only one was configured to produce a 5-Gauss magnetic field at a time. The flies in this T-maze were tested on their native ability to recognize the presence of the magnetic field in an arm and on their response following training where the magnetic field was paired with a sucrose reward. Many of the strains of flies showed a learned preference for the magnetic field following training. However, when the only cryptochrome found in \"Drosophila\", type 1 Cry, is altered, either through a missense mutation or replacement of the Cry gene, the flies exhibit a loss of magnetosensitivity. Furthermore, when light is filtered to only allow wavelengths greater than 420 nm through, \"Drosophila\" loses its trained response to magnetic fields. This response to filtered light is likely linked to the action spectrum of fly-cryptochrome which has a range from 350 nm – 400 nm and plateaus from 430-450 nm. Although researchers had believed that a tryptophan triad in cryptochrome was responsible for the free radicals on which magnetic fields could act, recent work with \"Drosophila\" has shown that tryptophan might not be behind cryptochrome dependent magnetoreception. Alteration of the tryptophan protein does not result in the loss of magnetosensitivity of a fly expressing either type 1 Cry or the cryptochrome found in vertebrates, type 2 Cry. Therefore, it remains unclear exactly how cryptochrome mediates magnetoreception. These experiments used a 5 gauss magnetic field, 10 times the strength of the Earth's magnetic field). \"Drosophila\" has not been shown to be able to respond to the Earth’s weaker magnetic field.\n\nStudies of magnetoreception in vertebrate fish have been conducted mainly with salmon. For instance, the presence of an internal magnetic compass has been discovered in Sockeye Salmon (\"Oncorhynchus nerka\"). Researchers made this discovery by first placing the young of this species in a symmetrical, circular tank and allowing them to pass through exits in the tank freely. A mean vector was then calculated to represent the directional preferences of these salmon in the natural magnetic field. Notably, when the magnetic field was experimentally rotated, the directional preferences of the young Sockeye Salmon changed accordingly. As such, researchers concluded that the orientation of swimming behaviour in Sockeye Salmon is influenced by magnetic field information.\n\nFurther research regarding magnetoreception in salmon has investigated Chinook Salmon (\"Oncorhynchus tschawytscha).\" To induce a preference for magnetic East-West, a group of these salmon were housed in a rectangular tank with water flowing from west to east for eighteen months. This group was also fed exclusively at the west end of the tank during this period. Upon placing these same salmon in a circular tank with symmetrical water flow, a preference for aligning their bodies with magnetic East-West was observed as expected. However, when the magnetic field was rotated by 90°, the salmon changed their preferred orientation to the North-South axis. From these results, researchers concluded that Chinook Salmon have the capacity to use magnetic field information in directional orientation.\n\nMagnetoreception is well documented in honey bees, ants and termites. In ants and bees, this is used to orient and navigate in areas around their nests and within their migratory paths. For example, through the use of magnetoreception, the Brazilian stingless bee \"Schwarziana quadripunctata\" is able to distinguish differences in altitude, location, and directionality using the thousands of hair-like particles on its antennae.\n\nMagnetoreception has also been reported in the European eel by at least one study.\n\nA number of amphibians and reptiles including salamanders, toads and turtles exhibit alignment behaviours with respect to the Earth's magnetic field.\n\nSome of the earliest studies of amphibian magnetoreception were conducted with cave salamanders (\"Eurycea lucifuga)\". Researchers housed groups of cave salamanders in corridors aligned with either magnetic North-South, or magnetic East-West. In ensuing tests, the magnetic field was experimentally rotated by 90°, and salamanders were placed in cross-shaped structures (one corridor along the new North-South axis, one along the new East-West axis). Considering these salamanders showed a significant preference for test corridors which matched the magnetic alignment of their housing corridors, researchers concluded that cave salamanders have the capacity to detect the Earth’s magnetic field, and have a preference for movement along learned magnetic axes.\n\nSubsequent research has examined magnetoreception in a more natural setting. Under typical circumstances, red-spotted newts (\"Notophthalmus viridescens)\" respond to drastic increases in water temperature (which tend to indicate environmental deterioration) by orienting themselves toward the shoreline and heading for land. However, when magnetic fields are experimentally altered, this behaviour is disrupted, and assumed orientations fail to direct the newts to the shoreline. Moreover, the change in orientation corresponds to the degree by which the magnetic field is shifted. In other words, inversion of the magnetic poles (a 180° shift) results in inversion of the typical orientation (a 180° shift). Further research has shown that magnetic information is not only used by red-spotted newts for orientation toward the shoreline, but also in orientation toward their home pools. Ultimately, it seems as though red-spotted newts rely on information regarding the Earth’s magnetic field for navigation within their environment, in particular when orienting toward the shoreline or toward home.\n\nIn similar fashion, European (\"Bufo bufo\") and Natterjack (\"Epidalea calamita)\" toads appear to rely, at least somewhat, on magnetic information for certain orienting behaviours. These species of anurans are known to rely on vision and olfaction when locating and migrating to breeding sites, but it seems magnetic fields may also play a role. When randomly displaced from their breeding sites, these toads remain well-oriented, and are capable of navigating their way back, even when displaced by more than 150 meters. However, when this displacement is accompanied by the experimental attachment of small magnetic bars, toads fail to relocate breeding sites. Considering experimental attachment of non-magnetized bars of equal size and weight does not affect relocation, it seems that magnetism is responsible for the observed disorientation of these toads. Therefore, researchers have concluded that orientation toward breeding sites in these anurans is influenced by magnetic field information.\n\nThe majority of study on magnetoreception in reptiles involves turtles. Some of the earliest support for magnetoreception in turtles was found in \"Terrapene carolina\", a species of box turtle. After successfully teaching a group of these box turtles to swim to either the east or west end of an experimental tank, the introduction of a strong magnet into the tank was enough to disrupt the learned routes. As such, the learning of oriented paths seems to rely on some internal magnetic compass possessed by box turtles. Subsequent discovery of magnetite in the dura mater of Sea Turtle hatchlings supported this conclusion, as magnetite provides a means by which magnetic fields may be perceived.\n\nFurthermore, orientation toward the sea, a behaviour commonly seen in hatchlings of a number of turtle species, may rely, in part, on magnetoreception.  In Loggerhead and Leatherback turtles, breeding takes place on beaches, and, after hatching, offspring crawl rapidly to the sea. Although differences in light density seem to drive this behaviour, magnetic alignment may also play a part. For instance, the natural directional preferences held by these hatchlings (which lead them from beaches to the sea) reverse upon experimental inversion of the magnetic poles, suggesting the Earth’s magnetic field serves as a reference for proper orientation.\n\nHoming pigeons can use magnetic fields as part of their complex navigation system. William Keeton showed that time-shifted homing pigeons are unable to orient themselves correctly on a clear, sunny day which is attributed to time-shifted pigeons being unable to compensate accurately for the movement of the sun during the day. Conversely, time-shifted pigeons released on overcast days navigate correctly. This led to the hypothesis that under particular conditions, homing pigeons rely on magnetic fields to orient themselves. Further experiments with magnets attached to the backs of homing pigeons demonstrated that disruption of the bird's ability to sense the Earth's magnetic field leads to a loss of proper orientation behavior under overcast conditions. There have been two mechanisms implicated in homing pigeon magnetoreception: the visually mediated free-radical pair mechanism and a magnetite based directional compass or inclination compass. More recent behavioral tests have shown that pigeons are able to detect magnetic anomalies of 186 microtesla (1.86 Gauss).\n\nIn a choice test birds were trained to jump onto a platform on one end of a tunnel if there was no magnetic field present and to jump onto a platform on the other end of the tunnel if a magnetic field was present. In this test, birds were rewarded with a food prize and punished with a time penalty. Homing pigeons were able to make the correct choice 55%-65% of the time which is higher than what would be expected if the pigeons were simply guessing. \n\nFor a long time the trigeminal system was the suggested location for a magnetite-based magnetoreceptor in the pigeon. This was based on two findings: First, magnetite-containing cells were reported in specific locations in the upper beak. Subsequent studies, however, revealed that these cells were macrophages, not magnetosensitive neurons. Second, pigeon magnetic field detection is impaired by sectioning the trigeminal nerve and by application of lidocaine, an anesthetic, to the olfactory mucosa. However, lidocaine treatment might lead to unspecific effects and not represent a direct interference with potential magnetoreceptors. Therefore, an involvment of the trigeminal system is still debated. In the search for magnetite receptors a large iron containing organelle (the cuticulosome) in the inner ear of pigeons was discovered. This organelle might represent part of an alternative magnetosensitive system. Taken together the receptor responsible for magnetosensitivity in homing pigeons remains uncertain.\n\nAside from the sensory receptor for magnetic reception in homing pigeons there has been work on neural regions that are possibly involved in the processing of magnetic information within the brain. Areas of the brain that have shown increases in activity in response to magnetic fields with a strength of 50 or 150 microtesla are the posterior vestibular nuclei, dorsal thalamus, hippocampus, and visual hyperpallium.\n\nDomestic hens have iron mineral deposits in the dendrites in the upper beak and are capable of magnetoreception. Because hens use directional information from the magnetic field of the Earth to orient in relatively small areas, this raises the possibility that beak-trimming (removal of part of the beak, to reduce injurious pecking, frequently performed on egg-laying hens) impairs the ability of hens to orient in extensive systems, or to move in and out of buildings in free-range systems.\n\nWork with mice, mole-rats and bats has shown that some mammals are capable of magnetoreception. When woodmice are removed from their home area and deprived of visual and olfactory cues, they orient themselves towards their homes until an inverted magnetic field is applied to their cage. However, when the same mice are allowed access to visual cues, they are able to orient themselves towards home despite the presence of inverted magnetic fields. This indicates that when woodmice are displaced, they use magnetic fields to orient themselves if there are no other cues available. However, early studies of these subjects were criticized because of the difficulty of completely removing sensory cues, and in some because the tests were performed out of the natural environment. In others, the results of these experiments do not conclusively show a response to magnetic fields when deprived of other cues, because the magnetic field was artificially changed before the test rather than during it.\n\nLater research, accounting for those factors, has led to a conclusion that the Zambian mole-rat, a subterranean mammal, uses magnetic fields as a polarity compass to aid in the orientation of their nests. In contrast to work with woodmice, Zambian mole-rats do not exhibit different orientation behavior when a visual cue such as the sun is present, a result that has been suggested is due to their subterranean lifestyle. Further investigation of mole-rat magnetoreception lead to the finding that exposure to magnetic fields leads to an increase in neural activity within the superior colliculus as measured by immediate early gene expression. The activity level of neurons within two levels of the superior colliculus, the outer sublayer of the intermediate gray layer and the deep gray layer, were elevated in a non-specific manner when exposed to various magnetic fields. However, within the inner sublayer of the intermediate gray layer (InGi) there were two or three clusters of responsive cells. The more time the mole rats were exposed to a magnetic field the greater the immediate early gene expression within the InGi. However, if Zambian mole-rats were placed in a field with a shielded magnetic field only a few scattered cells were active. Therefore, it has been proposed that in mammals, the superior colliculus is an important neural structure in the processing of magnetic information.\n\nBats may also use magnetic fields to orient themselves. While it is known that bats use echolocation to navigate over short distances, it is unclear how they navigate over longer distances. When \"Eptesicus fuscus\" are taken from their home roosts and exposed to magnetic fields 90 degrees clockwise or counterclockwise of magnetic north, they are disoriented and set off for their homes in the wrong direction. Therefore, it seems that \"Eptesicus fuscus\" is capable of magnetoreception. However, the exact use of magnetic fields by \"Eptesicus fuscus\" is unclear as the magnetic field could be used either as a map, a compass, or a compass calibrator. Recent research with another bat species, \"Myotis myotis\", supports the hypothesis that bats use magnetic fields as a compass calibrator and their primary compass is the sun.\n\nRed foxes (\"Vulpes vulpes\") may use magnetoreception when predating small rodents. When foxes perform their high-jumps onto small prey like mice and voles, they tend to jump in a north-eastern compass direction. In addition, successful attacks are \"tightly clustered\" to the north. One study has found that when domestic dogs are off the leash and the Earth's magnetic field is calm, they prefer to urinate and defecate with their bodies aligned on a north-south axis.\n\nThere is also evidence for magnetoreception in large mammals. Resting and grazing cattle as well as roe deer (\"Capreolus capreolus\") and red deer (\"Cervus elaphus\") tend to align their body axes in the geomagnetic north-south direction. Because wind, sunshine, and slope could be excluded as common ubiquitous factors in this study, alignment toward the vector of the magnetic field provided the most likely explanation for the observed behaviour. However, because of the descriptive nature of this study, alternative explanations (e.g., the sun compass) could not be excluded. In a follow-up study, researchers analyzed body orientations of ruminants in localities where the geomagnetic field is disturbed by high-voltage power lines to determine how local variation in magnetic fields may affect orientation behaviour. This was done by using satellite and aerial images of herds of cattle and field observations of grazing roe deer. Body orientation of both species was random on pastures under or near power lines. Moreover, cattle exposed to various magnetic fields directly beneath or in the vicinity of power lines trending in various magnetic directions exhibited distinct patterns of alignment. The disturbing effect of the power lines on body alignment diminished with the distance from the conductors. In 2011 a group of Czech researchers, however, reported their failed attempt to replicate the finding using different Google Earth images.\n\nHumans \"are not believed to have a magnetic sense\", but humans do have a cryptochrome (a flavoprotein, CRY2) in the retina which has a light-dependent magnetosensitivity. CRY2 \"has the molecular capability to function as a light-sensitive magnetosensor\", so the area was thought (2011) to be ripe for further study.\n\nThe largest issue affecting verification of an animal magnetic sense is that despite more than 50 years of work on magnetoreception there has yet to be an identification of a sensory receptor. Given that the entire receptor system could likely fit in a one-millimeter cube and have a magnetic content of less than one ppm, it is difficult to discern the parts of the brain where this information is processed. In various organisms a cryptochrome mediated receptor has been implicated in magnetoreception. At the same time a magnetite-based system has been suggested to be relevant to magnetosensation in birds. The third proposed mechanism (electromagnetic induction) has still not been tested in non-aquatic animals. Furthermore, it is possible that two complementary mechanisms play a role in magnetic field detection in animals. This dual mechanism theory in birds raises the questions: If such a mechanism is actually responsible for magnetoreception, to what degree is each method responsible for stimulus transduction, and how do they lead to a transducible signal given a magnetic field with the Earth’s strength?\n\nThe precise use of magnetoreception in animal navigation is unclear. Some animals appear to use their magnetic sense as a map, compass, or compass calibrator. The compass method allows animals not only to find north, but also to maintain a constant heading in a particular direction. Although the ability to sense direction is important in migratory navigation, many animals also have the ability to sense small fluctuations in earth’s magnetic field to compute coordinate maps with a resolution of a few kilometers or better. For example, birds such as the homing pigeon are believed to use the magnetite in their beaks to detect magnetic signposts and thus, the magnetic sense they gain from this pathway is a possible map. Yet, it has also been suggested that homing pigeons and other birds use the visually mediated cryptochrome receptor as a compass.\n\nThe purpose of magnetoreception in birds and other animals may be varied, but has proved difficult to study. Numerous studies use magnetic fields larger than the Earth’s field. Studies such as of \"Tritonia\" have used electrophysiological recordings from only one or two neurons, and many others have been solely correlative.\n\n\n"}
{"id": "2139915", "url": "https://en.wikipedia.org/wiki?curid=2139915", "title": "Mason's mark", "text": "Mason's mark\n\nA mason's mark is a symbol often found on dressed stone in buildings and other public structures.\n\nRegulations issued in Scotland in 1598 by James VI's Master of Works, William Schaw, stated that on admission to the guild, every mason had to enter his name and his mark in a register.\n\nThere are three types of marks used by stonemasons.\n\nFreemasonry, a fraternal order that uses an analogy to stonemasonry for much of its structure, also makes use of marks. A Freemason who takes the degree of Mark Master Mason will be asked to create his own Mark, as a type of unique signature or identifying badge. Some of these can be quite elaborate.\n\n\n\n"}
{"id": "990505", "url": "https://en.wikipedia.org/wiki?curid=990505", "title": "Mental health", "text": "Mental health\n\nMental health is a level of psychological well-being or an absence of mental illness. It is the \"psychological state of someone who is functioning at a satisfactory level of emotional and behavioural adjustment\". From the perspective of positive psychology or holism, mental health may include an individual's ability to enjoy life, and create a balance between life activities and efforts to achieve psychological resilience.\nAccording to the World Health Organization (WHO), mental health includes \"subjective well-being, perceived self-efficacy, autonomy, competence, inter-generational dependence, and self-actualization of one's intellectual and emotional potential, among others.\" The WHO further states that the well-being of an individual is encompassed in the realization of their abilities, coping with normal stresses of life, productive work and contribution to their community. Cultural differences, subjective assessments, and competing professional theories all affect how \"mental health\" is defined.\n\nAccording to the U.K. surgeon general (1999), mental health is the successful performance of mental function, resulting in productive activities, fulfilling relationships with other people, and providing the ability to adapt to change and cope with adversity. The term \"mental illness\" refers collectively to all diagnosable mental disorders—health conditions characterized by alterations in thinking, mood, or behavior associated with distress or impaired functioning.\n\nA person struggling with their mental health may experience this because of stress, loneliness, depression, anxiety, relationship problems, death of a loved one, suicidal thoughts, grief, addiction, ADHD, Cutting, Self-harm, Self-Injury, burning, various mood disorders, or other mental illnesses of varying degrees, as well as learning disabilities. Therapists, psychiatrists, psychologists, social workers, nurse practitioners or physicians can help manage mental illness with treatments such as therapy, counseling, or medication.\n\nIn the mid-19th century, William Sweetser was the first to coin the term \"mental hygiene\", which can be seen as the precursor to contemporary approaches to work on promoting positive mental health. Isaac Ray, one of the founders and the fourth president of the American Psychiatric Association, further defined mental hygiene as \"the art of preserving the mind against all incidents and influences calculated to deteriorate its qualities, impair its energies, or derange its movements.\"\n\nDorothea Dix (1802–1887) was an important figure in the development of the \"mental hygiene\" movement. Dix was a school teacher who endeavored throughout her life to help people with mental disorders, and to bring to light the deplorable conditions into which they were put. This was known as the \"mental hygiene movement\". Before this movement, it was not uncommon that people affected by mental illness in the 19th century would be considerably neglected, often left alone in deplorable conditions, barely even having sufficient clothing. Dix's efforts were so great that there was a rise in the number of patients in mental health facilities, which sadly resulted in these patients receiving less attention and care, as these institutions were largely understaffed.\n\nEmil Kraepelin in 1896 developed the taxonomy of mental disorders which has dominated the field for nearly 80 years. Later the proposed disease model of abnormality was subjected to analysis and considered normality to be relative to the physical, geographical and cultural aspects of the defining group.\n\nAt the beginning of the 20th century, Clifford Beers founded \"Mental Health America – National Committee for Mental Hygiene\", after publication of his accounts from lived experience in lunatic asylums, \"A Mind That Found Itself\", in 1908 and opened the first outpatient mental health clinic in the United States.\n\nThe mental hygiene movement, related to the social hygiene movement, had at times been associated with advocating eugenics and sterilisation of those considered too mentally deficient to be assisted into productive work and contented family life. In the post-WWII years, references to mental hygiene were gradually replaced by the term 'mental health' due to its positive aspect that evolves from the treatment of illness to preventive and promotive areas of healthcare.\n\nMarie Jahoda described six major, fundamental categories that can be used to categorize mentally healthy individuals: a positive attitude towards the self, personal growth, integration, autonomy, a true perception of reality, and environmental mastery, which include adaptability and healthy interpersonal relationships.\n\nMental illnesses are more common than cancer, diabetes, or heart disease. Over 26 percent of all Americans over the age of 18 meet the criteria for having a mental illness. A WHO report estimates the global cost of mental illness at nearly $2.5 trillion (two-thirds in indirect costs) in 2010, with a projected increase to over $6 trillion by 2030.\n\nEvidence from the World Health Organization suggests that nearly half of the world's population are affected by mental illness with an impact on their self-esteem, relationships and ability to function in everyday life. An individual's emotional health can also impact physical health and poor mental health can lead to problems such as substance abuse.\n\nMaintaining good mental health is crucial to living a long and healthy life. Good mental health can enhance one's life, while poor mental health can prevent someone from living an enriching life. According to Richards, Campania, & Muse-Burke, \"There is growing evidence that is showing emotional abilities are associated with prosocial behaviors such as stress management and physical health.\" Their research also concluded that people who lack emotional expression are inclined to anti-social behaviors (e.g., drug and alcohol abuse, physical fights, vandalism), which are a direct reflection of their mental health and suppress emotions. Adults and children with mental illness may experience social stigma, which can exacerbate the issues.\n\nMental health can be seen as an unstable continuum, where an individual's mental health may have many different possible values. Mental wellness is generally viewed as a positive attribute, even if the person does not have any diagnosed mental health condition. This definition of mental health highlights emotional well-being, the capacity to live a full and creative life, and the flexibility to deal with life's inevitable challenges. Some discussions are formulated in terms of contentment or happiness. Many therapeutic systems and self-help books offer methods and philosophies espousing strategies and techniques vaunted as effective for further improving the mental wellness. Positive psychology is increasingly prominent in mental health.\n\nA holistic model of mental health generally includes concepts based upon anthropological, educational, psychological, religious and sociological perspectives, as well as theoretical perspectives from personality, social, clinical, health and developmental psychology.\n\nThe tripartite model of mental well-being views mental well-being as encompassing three components of emotional well-being, social well-being, and psychological well-being. Emotional well-being is defined as having high levels of positive emotions, whereas social and psychological well-being are defined as the presence of psychological and social skills and abilities that contribute to optimal functioning in daily life. The model has received empirical support across cultures. The Mental Health Continuum-Short Form (MHC-SF) is the most widely used scale to measure the tripartite model of mental well-being.\n\nMental health and stability is a very important factor in a person’s everyday life. Social skills, behavioral skills, and someone’s way of thinking are just some of the things that the human brain develops at an early age. Learning how to interact with others and how to focus on certain subjects are essential lessons to learn from the time we can talk all the way to when we are so old that we can barely walk. However, there are some people out there who have difficulty with these kind of skills and behaving like an average person. This is a most likely the cause of having a mental illness. A mental illness is a wide range of conditions that affect a person’s mood, thinking, and behavior. About 26% of people in the United States, ages 18 and older, have been diagnosed with some kind of mental disorder. However, not much is said about children with mental illnesses even though there are many that will develop one, even as early as age three.\n\nThe most common mental illnesses in children include, but are not limited to, ADHD, autism and anxiety disorder, as well as depression in older children and teens. Having a mental illness at a younger age is much different from having one in your thirties. Children's brains are still developing and will continue to develop until around the age of twenty-five. When a mental illness is thrown into the mix, it becomes significantly harder for a child to acquire the necessary skills and habits that people use throughout the day. For example, behavioral skills don’t develop as fast as motor or sensory skills do. So when a child has an anxiety disorder, they begin to lack proper social interaction and associate many ordinary things with intense fear. This can be scary for the child because they don’t necessarily understand why they act and think the way that they do. Many researchers say that parents should keep an eye on their child if they have any reason to believe that something is slightly off. If the children are evaluated earlier, they become more acquainted to their disorder and treating it becomes part of their daily routine. This is opposed to adults who might not recover as quickly because it is more difficult for them to adapt.\n\nMental illness affects not only the person themselves, but the people around them. Friends and family also play an important role in the child’s mental health stability and treatment. If the child is young, parents are the ones who evaluate their child and decide whether or not they need some form of help. Friends are a support system for the child and family as a whole. Living with a mental disorder is never easy, so it’s always important to have people around to make the days a little easier. However, there are negative factors that come with the social aspect of mental illness as well. Parents are sometimes held responsible for their child’s own illness. People also say that the parents raised their children in a certain way or they acquired their behavior from them. Family and friends are sometimes so ashamed of the idea of being close to someone with a disorder that the child feels isolated and thinks that they have to hide their illness from others. When in reality, hiding it from people prevents the child from getting the right amount of social interaction and treatment in order to thrive in today’s society.\n\nStigma is also a well-known factor in mental illness. Stigma is defined as “a mark of disgrace associated with a particular circumstance, quality, or person.” Stigma is used especially when it comes to the mentally disabled. People have this assumption that everyone with a mental problem, no matter how mild or severe, is automatically considered destructive or a criminal person. Thanks to the media, this idea has been planted in our brains from a young age. Watching movies about teens with depression or children with Autism makes us think that all of the people that have a mental illness are like the ones on TV. In reality, the media displays an exaggerated version of most illnesses. Unfortunately, not many people know that, so they continue to belittle those with disorders. In a recent study, a majority of young people associate mental illness with extreme sadness or violence. Now that children are becoming more and more open to technology and the media itself, future generations will then continue to pair mental illness with negative thoughts. The media should be explaining that many people with disorders like ADHD and anxiety, with the right treatment, can live ordinary lives and should not be punished for something they cannot help.\n\n\"Sueki\", (2013) carried out a study titled “\"The effect of suicide–related internet use on users’ mental health: A longitudinal Study”\". This study investigated the effects of suicide-related internet use on user’s suicidal thoughts, predisposition to depression and anxiety and loneliness. The study consisted of 850 internet users; the data was obtained by carrying out a questionnaire amongst the participants. This study found that browsing websites related to suicide, and methods used to commit suicide, had a negative effect on suicidal thoughts and increased depression and anxiety tendencies. The study concluded that as suicide-related internet use adversely affected the mental health of certain age groups it may be prudent to reduce or control their exposure to these websites. These findings certainly suggest that the internet can indeed have a profoundly negative impact on our mental health.\n\nPsychiatrist Thomas Szasz compared that 50 years ago children were either categorized as good or bad, and today \"all children are good, but some are mentally healthy and others are mentally ill\". The social control and forced identity creation is the cause of many mental health problems among today's children. A behaviour or misbehaviour might not be an illness but exercise of their free will and today's immediacy in drug administration for every problem along with the legal over-guarding and regard of a child's status as a dependent shakes their personal self and invades their internal growth.\n\nMental health is conventionally defined as a hybrid of absence of a mental disorder and presence of well-being. Focus is increasing on preventing mental disorders.\nPrevention is beginning to appear in mental health strategies, including the 2004 WHO report \"Prevention of Mental Disorders\", the 2008 EU \"Pact for Mental Health\" and the 2011 US National Prevention Strategy. Some commentators have argued that a pragmatic and practical approach to mental disorder prevention at work would be to treat it the same way as physical injury prevention.\n\nPrevention of a disorder at a young age may significantly decrease the chances that a child will suffer from a disorder later in life, and shall be the most efficient and effective measure from a public health perspective. Prevention may require the regular consultation of a physician for at least twice a year to detect any signs that reveal any mental health concerns.\n\nMental health is a socially constructed and socially defined concept; that is, different societies, groups, cultures, institutions and professions have very different ways of conceptualizing its nature and causes, determining what is mentally healthy, and deciding what interventions, if any, are appropriate. Thus, different professionals will have different cultural, class, political and religious backgrounds, which will impact the methodology applied during treatment.\n\nResearch has shown that there is stigma attached to mental illness. In the United Kingdom, the Royal College of Psychiatrists organized the campaign \"Changing Minds\" (1998–2003) to help reduce stigma. Due to this stigma, responses to a positive diagnosis may be a display of denialism.\n\nAddressing and eliminating the social stigma and perceived stigma attached to mental illness has been recognized as a crucial part to addressing the education of mental health issues. In the United States, the National Alliance of Mental Illness is an institution that was founded in 1979 to represent and advocate for victims struggling with mental health issues. NAMI also helps to educate about mental illnesses and health issues, while also working to eliminate the stigma attached to these disorders such as anxiety and depression.\n\nMany mental health professionals are beginning to, or already understand, the importance of competency in religious diversity and spirituality. The American Psychological Association explicitly states that religion must be respected. Education in spiritual and religious matters is also required by the American Psychiatric Association.\n\nUnemployment has been shown to have a negative impact on an individual's emotional well-being, self-esteem and more broadly their mental health. Increasing unemployment has been show to have a significant impact on mental health, predominantly depressive disorders. This is an important consideration when reviewing the triggers for mental health disorders in any population survey. In order to improve your emotional mental health, the root of the issue has to be resolved. \"Prevention emphasizes the avoidance of risk factors; promotion aims to enhance an individual's ability to achieve a positive sense of self-esteem, mastery, well-being, and social inclusion.\" It is very important to improve your emotional mental health by surrounding yourself with positive relationships. We as humans, feed off companionships and interaction with other people. Another way to improve your emotional mental health is participating in activities that can allow you to relax and take time for yourself. Yoga is a great example of an activity that calms your entire body and nerves. According to a study on well-being by Richards, Campania and Muse-Burke, \"mindfulness is considered to be a purposeful state, it may be that those who practice it believe in its importance and value being mindful, so that valuing of self-care activities may influence the intentional component of mindfulness.\"\n\nMental health care navigation helps to guide patients and families through the fragmented, often confusing mental health industries. Care navigators work closely with patients and families through discussion and collaboration to provide information on best therapies as well as referrals to practitioners and facilities specializing in particular forms of emotional improvement. The difference between therapy and care navigation is that the care navigation process provides information and directs patients to therapy rather than providing therapy. Still, care navigators may offer diagnosis and treatment planning. Though many care navigators are also trained therapists and doctors. Care navigation is the link between the patient and the below therapies. A clear recognition that mental health requires medical intervention was demonstrated in a study by Kessler et al. of the prevalence and treatment of mental disorders from 1990 to 2003 in the United States. Despite the prevalence of mental health disorders remaining unchanged during this period, the number of patients seeking treatment for mental disorders increased threefold.\n\nEmotional mental disorders are a leading cause of disabilities worldwide. Investigating the degree and severity of untreated emotional mental disorders throughout the world is a top priority of the World Mental Health (WMH) survey initiative, which was created in 1998 by the World Health Organization (WHO). \"Neuropsychiatric disorders are the leading causes of disability worldwide, accounting for 37% of all healthy life years lost through disease.These disorders are most destructive to low and middle-income countries due to their inability to provide their citizens with proper aid. Despite modern treatment and rehabilitation for emotional mental health disorders, \"even economically advantaged societies have competing priorities and budgetary constraints\".\n\nThe World Mental Health survey initiative has suggested a plan for countries to redesign their mental health care systems to best allocate resources. \n\"A first step is documentation of services being used and the extent and nature of unmet needs for treatment. A second step could be to do a cross-national comparison of service use and unmet needs in countries with different mental health care systems. Such comparisons can help to uncover optimum financing, national policies, and delivery systems for mental health care.\"\n\nKnowledge of how to provide effective emotional mental health care has become imperative worldwide. Unfortunately, most countries have insufficient data to guide decisions, absent or competing visions for resources, and near constant pressures to cut insurance and entitlements. WMH surveys were done in Africa (Nigeria, South Africa), the Americas (Colombia, Mexico, United States), Asia and the Pacific (Japan, New Zealand, Beijing and Shanghai in the People's Republic of China), Europe (Belgium, France, Germany, Italy, Netherlands, Spain, Ukraine), and the middle east (Israel, Lebanon). Countries were classified with World Bank criteria as low-income (Nigeria), lower middle-income (China, Colombia, South Africa, Ukraine), higher middle-income (Lebanon, Mexico), and high-income.\n\nThe coordinated surveys on emotional mental health disorders, their severity, and treatments were implemented in the aforementioned countries. These surveys assessed the frequency, types, and adequacy of mental health service use in 17 countries in which WMH surveys are complete. The WMH also examined unmet needs for treatment in strata defined by the seriousness of mental disorders. Their research showed that \"the number of respondents using any 12-month mental health service was generally lower in developing than in developed countries, and the proportion receiving services tended to correspond to countries' percentages of gross domestic product spent on health care\".\n\"High levels of unmet need worldwide are not surprising, since WHO Project ATLAS' findings of much lower mental health expenditures than was suggested by the magnitude of burdens from mental illnesses. Generally, unmet needs in low-income and middle-income countries might be attributable to these nations spending reduced amounts (usually <1%) of already diminished health budgets on mental health care, and they rely heavily on out-of-pocket spending by citizens who are ill equipped for it\".\n\nArchaeological records have shown that trepanation was a procedure used to treat \"headaches, insanities or epilepsy\" in several parts of the world in the Stone age. It was a surgical process used in the Stone Age. Paul Broca studied trepanation and came up with his own theory on it. He noticed that the fractures on the skulls dug up weren't caused by wounds inflicted due to violence, but because of careful surgical procedures. \"Doctors used sharpened stones to scrape the skull and drill holes into the head of the patient\" to allow evil spirits which plagued the patient to escape. There were several patients that died in these procedures, but those that survived were revered and believed to possess \"properties of a mystical order\". \n\nLobotomy was used in the 20th century as a common practice of alternative treatment for mental illnesses such as schizophrenia and depression. The first ever modern leucotomy meant for the purpose of treating a mental illness occurred in 1935 by a Portuguese neurologist, Antonio Egas Moniz. He received the Nobel Prize in medicine in 1949. . This belief that mental health illnesses could be treated by surgery came from Swiss neurologist, Gottlieb Burckhardt. After conducting experiments on six patients with schizophrenia, he claimed that half of his patients recovered or calmed down.\nPsychiatrist Walter Freeman believed that \"an overload of emotions led to mental illness and “that cutting certain nerves in the brain could eliminate excess emotion and stabilize a personality,” according to a National Public Radio article .\"\n\n\"Exorcism is the religious or spiritual practice of evicting demons or other spiritual entities from a person, or an area, they are believed to have possessed.\"\n\nMental health illnesses such as Huntington’s Disease (HD), Tourette syndrome and schizophrenia were believed to be signs of possession by the Devil. This led to several mentally ill patients being subjected to exorcisms. This practice has been around for a long time, though decreasing steadily until it reached a low in the 18th century. It seldom occurred until the 20th century when the numbers rose due to the attention the media was giving to exorcisms. Different belief systems practice exorcisms in different ways.\n\nPharmacotherapy is therapy that uses pharmaceutical drugs. Pharmacotherapy is used in the treatment of mental illness through the use of antidepressants, benzodiazepines, and the use of elements such as lithium.\n\nPhysical activity is a very good way to help improve your mental health as well as your physical health. Playing sports, walking, cycling or doing any form of physical activity can trigger the production of endorphins. Endorphins are natural mood enhancers.\n\nActivity therapies, also called recreation therapy and occupational therapy, promote healing through active engagement. Making crafts can be a part of occupational therapy. Walks can be a part of recreation therapy.\nIn recent years colouring has been recognised as an activity which has been proven to significantly lower the levels of depressive symptoms and anxiety in many studies.\n\nExpressive therapies are a form of psychotherapy that involves the arts or art-making. These therapies include music therapy, art therapy, dance therapy, drama therapy, and poetry therapy. It has been proven that Music therapy is an effective way of helping people who suffer from a mental health disorder.\n\nPsychotherapy is the general term for scientific based treatment of mental health issues based on modern medicine. It includes a number of schools, such as gestalt therapy, psychoanalysis, cognitive behavioral therapy and dialectical behavioral therapy. \nGroup therapy involves any type of therapy that takes place in a setting involving multiple people. It can include psychodynamic groups, activity groups for expressive therapy, support groups (including the Twelve-step program), problem-solving and psychoeducation groups.\n\nThe practice of mindfulness meditation has several mental health benefits, such as bringing about reductions in depression, anxiety and stress. Mindfulness meditation may also be effective in treating substance use disorders. Further, mindfulness meditation appears to bring about favorable structural changes in the brain.\n\nThe Heartfulness meditation program has proven to show significant improvements in the state of mind of health-care professionals. A study posted on the US National Library of Medicine showed that these professionals of varied stress levels were able to improve their conditions after this meditation program was conducted. They benefited in aspects of burnouts and emotional wellness.\n\nPeople with anxiety disorders participated in a stress-reduction program conducted by researchers from the Mental Health Service Line at the W.G. Hefner Veterans Affairs Medical Center in Salisbury, North Carolina. The participants practiced mindfulness meditation. After the study was over, it was concluded that the \"mindfulness meditation training program can effectively reduce symptoms of anxiety and panic and can help maintain these reductions in patients with generalized anxiety disorder, panic disorder, or panic disorder with agoraphobia.\"\n\nSpiritual counselors meet with people in need to offer comfort and support and to help them gain a better understanding of their issues and develop a problem-solving relation with spirituality. These types of counselors deliver care based on spiritual, psychological and theological principles.\n\nSocial work in mental health, also called psychiatric social work, is a process where an individual in a setting is helped to attain freedom from overlapping internal and external problems (social and economic situations, family and other relationships, the physical and organizational environment, psychiatric symptoms, etc.). It aims for harmony, quality of life, self-actualization and personal adaptation across all systems. Psychiatric social workers are mental health professionals that can assist patients and their family members in coping with both mental health issues and various economic or social problems caused by mental illness or psychiatric dysfunctions and to attain improved mental health and well-being. They are vital members of the treatment teams in Departments of Psychiatry and Behavioral Sciences in hospitals. They are employed in both outpatient and inpatient settings of a hospital, nursing homes, state and local governments, substance abuse clinics, correctional facilities, health care services...etc.\n\nIn psychiatric social work there are three distinct groups. One made up of the social workers in psychiatric organizations and hospitals. The second group consists members interested with mental hygiene education and holding designations that involve functioning in various mental health services and the third group consist of individuals involved directly with treatment and recovery process.\n\nIn the United States, social workers provide most of the mental health services. According to government sources, 60 percent of mental health professionals are clinically trained social workers, 10 percent are psychiatrists, 23 percent are psychologists, and 5 percent are psychiatric nurses.\n\nMental health social workers in Japan have professional knowledge of health and welfare and skills essential for person's well-being. Their social work training enables them as a professional to carry out Consultation assistance for mental disabilities and their social reintegration; Consultation regarding the rehabilitation of the victims; Advice and guidance for post-discharge residence and re-employment after hospitalized care, for major life events in regular life, money and self-management and in other relevant matters in order to equip them to adapt in daily life. Social workers provide individual home visits for mentally ill and do welfare services available, with specialized training a range of procedural services are coordinated for home, workplace and school. In an administrative relationship, Psychiatric social workers provides consultation, leadership, conflict management and work direction. Psychiatric social workers who provides assessment and psychosocial interventions function as a clinician, counselor and municipal staff of the health centers.\n\nSocial workers play many roles in mental health settings, including those of case manager, advocate, administrator, and therapist. The major functions of a psychiatric social worker are promotion and prevention, treatment, and rehabilitation. Social workers may also practice:\n\n\nPsychiatric social workers conduct psychosocial assessments of the patients and work to enhance patient and family communications with the medical team members and ensure the inter-professional cordiality in the team to secure patients with the best possible care and to be active partners in their care planning. Depending upon the requirement, social workers are often involved in illness education, counseling and psychotherapy. In all areas, they are pivotal to the aftercare process to facilitate a careful transition back to family and community.\n\nDuring the 1840s, Dorothea Lynde Dix, a retired Boston teacher who is considered the founder of the Mental Health Movement, began a crusade that would change the way people with mental disorders were viewed and treated. Dix was not a social worker; the profession was not established until after her death in 1887. However, her life and work were embraced by early psychiatric social workers, and she is considered one of the pioneers of psychiatric social work along with Elizabeth Horton, who in 1907 was the first psychiatric social worker in the New York hospital system, and others. The early twentieth century was a time of progressive change in attitudes towards mental illness. Community Mental Health Centers Act was passed in 1963. This policy encouraged the deinstitutionalisation of people with mental illness. Later, mental health consumer movement came by 1980s. A consumer was defined as a person who has received or is currently receiving services for a psychiatric condition. People with mental disorders and their families became advocates for better care. Building public understanding and awareness through consumer advocacy helped bring mental illness and its treatment into mainstream medicine and social services. In the 2000s focus was on Managed care movement which aimed at a health care delivery system to eliminate unnecessary and inappropriate care in order to reduce costs & Recovery movement in which by principle acknowledges that many people with serious mental illness spontaneously recover and others recover and improve with proper treatment.\n\nRole of social workers made an impact with 2003 invasion of Iraq and War in Afghanistan (2001–14) social workers worked out of the NATO hospital in Afghanistan and Iraq bases. They made visits to provide counseling services at forward operating bases. Twenty-two percent of the clients were diagnosed with post-traumatic stress disorder, 17 percent with depression, and 7 percent with alcohol abuse. In 2009, a high level of suicides was reached among active-duty soldiers: 160 confirmed or suspected Army suicides. In 2008, the Marine Corps had a record 52 suicides. The stress of long and repeated deployments to war zones, the dangerous and confusing nature of both wars, wavering public support for the wars, and reduced troop morale have all contributed to the escalating mental health issues. Military and civilian social workers are primary service providers in the veterans’ health care system.\n\nMental health services, is a loose network of services ranging from highly structured inpatient psychiatric units to informal support groups, where psychiatric social workers indulges in the diverse approaches in multiple settings along with other paraprofessional workers.\n\nA role for psychiatric social workers was established early in Canada’s history of service delivery in the field of population health. Native North Americans understood mental trouble as an indication of an individual who had lost their equilibrium with the sense of place and belonging in general, and with the rest of the group in particular. In native healing beliefs, health and mental health were inseparable, so similar combinations of natural and spiritual remedies were often employed to relieve both mental and physical illness. These communities and families greatly valued holistic approaches for preventative health care. Indigenous peoples in Canada have faced cultural oppression and social marginalization through the actions of European colonizers and their institutions since the earliest periods of contact. Culture contact brought with it many forms of depredation. Economic, political, and religious institutions of the European settlers all contributed to the displacement and oppression of indigenous people.\n\nThe first officially recorded treatment practices were in 1714, when Quebec opened wards for the mentally ill. In the 1830s social services were active through charity organizations and church parishes (Social Gospel Movement). Asylums for the insane were opened in 1835 in Saint John and New Brunswick. In 1841 in Toronto, when care for the mentally ill became institutionally based. Canada became a self-governing dominion in 1867, retaining its ties to the British crown. During this period age of industrial capitalism began, which lead to a social and economic dislocation in many forms. By 1887 asylums were converted to hospitals and nurses and attendants were employed for the care of the mentally ill. The first social work training began at the University of Toronto in 1914. In 1918 Clarence Hincks & Clifford Beers founded the Canadian National Committee for Mental Hygiene, which later became the Canadian Mental Health Association. In the 1930s Dr. Clarence Hincks promoted prevention and of treating sufferers of mental illness before they were incapacitated/early detection.\n\nWorld War II profoundly affected attitudes towards mental health. The medical examinations of recruits revealed that thousands of apparently healthy adults suffered mental difficulties. This knowledge changed public attitudes towards mental health, and stimulated research into preventive measures and methods of treatment. In 1951 Mental Health Week was introduced across Canada. For the first half of the twentieth century, with a period of deinstitutionalisation beginning in the late 1960s psychiatric social work succeeded to the current emphasis on community-based care, psychiatric social work focused beyond the medical model’s aspects on individual diagnosis to identify and address social inequities and structural issues. In the 1980s Mental Health Act was amended to give consumers the right to choose treatment alternatives. Later the focus shifted to workforce mental health issues and environment.\n\nThe earliest citing of mental disorders in India are from Vedic Era (2000 BC – AD 600). Charaka Samhita, an ayurvedic textbook believed to be from 400–200 BC describes various factors of mental stability. It also has instructions regarding how to set up a care delivery system. In the same era In south India Siddha was a medical system, the great sage Agastya, one of the 18 siddhas contributing to a system of medicine has included the Agastiyar Kirigai Nool, a compendium of psychiatric disorders and their recommended treatments. In Atharva Veda too there are descriptions and resolutions about mental health afflictions. In the Mughal period Unani system of medicine was introduced by an Indian physician Unhammad in 1222. Then existed form of psychotherapy was known then as ilaj-i-nafsani in Unani medicine.\n\nThe 18th century was a very unstable period in Indian history, which contributed to psychological and social chaos in the Indian subcontinent. In 1745 of lunatic asylums were developed in Bombay (Mumbai) followed by Calcutta (Kolkata) in 1784, and Madras (Chennai) in 1794. The need to establish hospitals became more acute, first to treat and manage Englishmen and Indian ‘sepoys’ (military men) employed by the British East India Company. The First Lunacy Act (also called Act No. 36) that came into effect in 1858 was later modified by a committee appointed in Bengal in 1888. Later, the Indian Lunacy Act, 1912 was brought under this legislation. A rehabilitation programme was initiated between 1870s and 1890s for persons with mental illness at the Mysore Lunatic Asylum, and then an occupational therapy department was established during this period in almost each of the lunatic asylums. The programme in the asylum was called ‘work therapy’. In this programme, persons with mental illness were involved in the field of agriculture for all activities. This programme is considered as the seed of origin of psychosocial rehabilitation in India.\n\nBerkeley-Hill, superintendent of the European Hospital (now known as the Central Institute of Psychiatry (CIP), established in 1918), was deeply concerned about the improvement of mental hospitals in those days. The sustained efforts of Berkeley-Hill helped to raise the standard of treatment and care and he also persuaded the government to change the term ‘asylum’ to ‘hospital’ in 1920. Techniques similar to the current token-economy were first started in 1920 and called by the name ‘habit formation chart’ at the CIP, Ranchi. In 1937, the first post of psychiatric social worker was created in the child guidance clinic run by the Dhorabji Tata School of Social Work (established in 1936), It is considered as the first documented evidence of social work practice in Indian mental health field.\n\nAfter Independence in 1947, general hospital psychiatry units (GHPUs) where established to improve conditions in existing hospitals, while at the same time encouraging outpatient care through these units. In Amritsar a Dr. Vidyasagar, instituted active involvement of families in the care of persons with mental illness. This was advanced practice ahead of its times regarding treatment and care. This methodology had a greater impact on social work practice in the mental health field especially in reducing the stigmatisation. In 1948 Gauri Rani Banerjee, trained in the United States, started a master’s course in medical and psychiatric social work at the Dhorabji Tata School of Social Work (Now TISS). Later the first trained psychiatric social worker was appointed in 1949 at the adult psychiatry unit of Yervada mental hospital, Pune.\n\nIn various parts of the country, in mental health service settings, social workers were employed—in 1956 at a mental hospital in Amritsar, in 1958 at a child guidance clinic of the college of nursing, and in Delhi in 1960 at the All India Institute of Medical Sciences and in 1962 at the Ram Manohar Lohia Hospital. In 1960, the Madras Mental Hospital (Now Institute of Mental Health), employed social workers to bridge the gap between doctors and patients. In 1961 the social work post was created at the NIMHANS. In these settings they took care of the psychosocial aspect of treatment. This had long-term greater impact of social work practice in mental health.\n\nIn 1966 by the recommendation Mental Health Advisory Committee, Ministry of Health, Government of India, NIMHANS commenced Department of Psychiatric Social Work started and a two-year Postgraduate Diploma in Psychiatric Social Work was introduced in 1968. In 1978, the nomenclature of the course was changed to MPhil in Psychiatric Social Work. Subsequently, a PhD Programme was introduced. By the recommendations Mudaliar committee in 1962, Diploma in Psychiatric Social Work was started in 1970 at the European Mental Hospital at Ranchi (now CIP), upgraded the program and added other higher training courses subsequently.\n\nA new initiative to integrate mental health with general health services started in 1975 in India. The Ministry of Health, Government of India formulated the National Mental Health Programme (NMHP) and launched it in 1982. The same was reviewed in 1995 and based on that, the District Mental Health Program (DMHP) launched in 1996 and sought to integrate mental health care with public health care. This model has been implemented in all the states and currently there are 125 DMHP sites in India.\n\nNational Human Rights Commission (NHRC) in 1998 and 2008 carried out systematic, intensive and critical examinations of mental hospitals in India. This resulted in recognition of the human rights of the persons with mental illness by the NHRC. From the NHRC's report as part of the NMHP, funds were provided for upgrading the facilities of mental hospitals. This is studied to result in positive changes over the past 10 years than in the preceding five decades by the 2008 report of the NHRC and NIMHANS. In 2016 Mental Health Care Bill was passed which ensures and legally entitles access to treatments with coverage from insurance, safeguarding dignity of the afflicted person, improving legal and healthcare access and allows for free medications. In December 2016, Disabilities Act 1995 was repealed with Rights of Persons with Disabilities Act (RPWD), 2016 from the 2014 Bill which ensures benefits for a wider population with disabilities. The Bill before becoming an Act was pushed for amendments by stakeholders mainly against alarming clauses in the \"Equality and Non discrimination\" section that diminishes the power of the act and allows establishments to overlook or discriminate against persons with disabilities and against the general lack of directives that requires to ensure the proper implementation of the Act.\n\nLack of any universally accepted single licensing authority compared to foreign countries puts social workers at general in risk. But general bodies/councils accepts automatically a university-qualified social worker as a professional licensed to practice or as a qualified clinician. Lack of a centralized council in tie-up with Schools of Social Work also makes a decline in promotion for the scope of social workers as mental health professionals. Though in this midst the service of social workers has given a facelift of the mental health sector in the country with other allied professionals.\n\nEvidence suggests that 450 million people worldwide are impacted by mental health, major depression ranks fourth among the top 10 leading causes of disease worldwide. Within 20 years, mental illness is predicted to become the leading cause of disease worldwide. Women are more likely to have a mental illness than men. One million people commit suicide every year and 10 to 20 million attempt it.\n\nA survey conducted by Australian Bureau of Statistics in 2008 regarding adults with manageable to severe neurosis reveals almost half of the population had a mental disorder at some point of their life and one in five people had a sustained disorder in the preceding 12 months. In neurotic disorders, 14% of the population experienced anxiety disorders, comorbidity disorders were the next common mental disorder with vulnerability to substance abuse and relapses. There were distinct gender differences in disposition to mental health illness. Women were found to have high rate of mental health disorders and Men had higher propensity of risk for substance abuse. The SMHWB survey showed low socioeconomic status and high dysfunctional pattern in the family was proportional to greater risk for mental health disorders. A 2010 survey regarding adults with psychosis revealed 5 persons per 1000 in the population seeks professional mental health services for psychotic disorders and the most common psychotic disorder was schizophrenia.\n\nAccording to statistics released by the Centre of Addiction and Mental Health one in five people in Ontario experience a mental health or addiction problem. Young people ages 15 to 25 are particularly vulnerable. Major depression is found to affect 8% and anxiety disorder 12% of the population. Women are 1.5 times more likely to suffer from mood and anxiety disorders. WHO points out that there are distinct gender differences in patterns of mental health and illness. The lack of power and control over their socioeconomic status, gender based violence; low social position and responsibility for the care of others render women vulnerable to mental health risks. Since more women than men seek help regarding a mental health problem, this has led to not only gender stereotyping but also reinforcing social stigma. WHO has found that this stereotyping has led doctors to diagnose depression more often in women than in men even when they display identical symptoms. Often communication between health care providers and women is authoritarian leading to either the under-treatment or over-treatment of these women.\n\nWomen's College Hospital is specifically dedicated to women's health in Canada. This hospital is located in downtown Toronto where there are several locations available for specific medical conditions. WCH is an organization that helps educate women on mental illness due to its specialization with women and mental health. The organization helps women who have symptoms of mental illnesses such as depression, anxiety, menstruation, pregnancy, childbirth, and menopause. They also focus on psychological issues, abuse, neglect and mental health issues from various medications.\n\nThe countless aspect about this organization is that WCH is open to women of all ages, including pregnant women that experience poor mental health. WCH not only provides care for good mental health, but they also have a program called the \"Women's Mental Health Program\" where doctors and nurses help treat and educate women regarding mental health collaboratively, individually, and online by answering questions from the public.\n\nThe second organization is the Centre for Addiction and Mental Health (CAMH). CAMH is one of Canada's largest and most well-known health and addiction facilities, and it has received international recognitions from the Pan American Health Organization and World Health Organization Collaborating Centre. They practice in doing research in areas of addiction and mental health in both men and women. In order to help both men and women, CAMH provides \"clinical care, research, education, policy development and health promotion to help transform the lives of people affected by mental health and addiction issues.\" CAMH is different from Women's College Hospital due to its widely known rehab centre for women who have minor addiction issues, to severe ones. This organization provides care for mental health issues by assessments, interventions, residential programs, treatments, and doctor and family support.\n\nAccording to the World Health Organization in 2004, depression is the leading cause of disability in the United States for individuals ages 15 to 44. Absence from work in the U.S. due to depression is estimated to be in excess of $31 billion per year. Depression frequently co-occurs with a variety of medical illnesses such as heart disease, cancer, and chronic pain and is associated with poorer health status and prognosis. Each year, roughly 30,000 Americans take their lives, while hundreds of thousands make suicide attempts (Centers for Disease Control and Prevention). In 2004, suicide was the 11th leading cause of death in the United States (Centers for Disease Control and Prevention), third among individuals ages 15–24. Despite the increasingly availability of effectual depression treatment, the level of unmet need for treatment remains high. By way of comparison, a study conducted in Australia during 2006 to 2007 reported that one-third (34.9%) of patients diagnosed with a mental health disorder had presented to medical health services for treatment.\n\nThere are many factors that influence mental health including:\n\n\nEmotional mental illnesses should be a particular concern in the United States since the U.S. has the highest annual prevalence rates (26 percent) for mental illnesses among a comparison of 14 developing and developed countries. While approximately 80 percent of all people in the United States with a mental disorder eventually receive some form of treatment, on the average persons do not access care until nearly a decade following the development of their illness, and less than one-third of people who seek help receive minimally adequate care. The government offers everyone programs and services, but veterans receive the most help, there is certain eligibility criteria that has to be met.\n\nThe mental health policies in the United States have experienced four major reforms: the American asylum movement led by Dorothea Dix in 1843; the \"mental hygiene\" movement inspired by Clifford Beers in 1908; the deinstitutionalization started by Action for Mental Health in 1961; and the community support movement called for by The CMCH Act Amendments of 1975.\n\nIn 1843, Dorothea Dix submitted a Memorial to the Legislature of Massachusetts, describing the abusive treatment and horrible conditions received by the mentally ill patients in jails, cages, and almshouses. She revealed in her Memorial: \"I proceed, gentlemen, briefly to call your attention to the present state of insane persons confined within this Commonwealth, in cages, closets, cellars, stalls, pens! Chained, naked, beaten with rods, and lashed into obedience….\" Many asylums were built in that period, with high fences or walls separating the patients from other community members and strict rules regarding the entrance and exit. In those asylums, traditional treatments were well implemented: drugs were not used as a cure for a disease, but a way to reset equilibrium in a person's body, along with other essential elements such as healthy diets, fresh air, middle class culture, and the visits by their neighboring residents. In 1866, a recommendation came to the New York State Legislature to establish a separate asylum for chronic mentally ill patients. Some hospitals placed the chronic patients into separate wings or wards, or different buildings.\n\nIn \"A Mind That Found Itself\" (1908) Clifford Whittingham Beers described the humiliating treatment he received and the deplorable conditions in the mental hospital. One year later, the National Committee for Mental Hygiene (NCMH) was founded by a small group of reform-minded scholars and scientists – including Beer himself – which marked the beginning of the \"mental hygiene\" movement. The movement emphasized the importance of childhood prevention. World War I catalyzed this idea with an additional emphasis on the impact of maladjustment, which convinced the hygienists that prevention was the only practical approach to handle mental health issues. However, prevention was not successful, especially for chronic illness; the condemnable conditions in the hospitals were even more prevalent, especially under the pressure of the increasing number of chronically ill and the influence of the depression.\n\nIn 1961, the Joint Commission on Mental Health published a report called Action for Mental Health, whose goal was for community clinic care to take on the burden of prevention and early intervention of the mental illness, therefore to leave space in the hospitals for severe and chronic patients. The court started to rule in favor of the patients' will on whether they should be forced to treatment. By 1977, 650 community mental health centers were built to cover 43 percent of the population and serve 1.9 million individuals a year, and the lengths of treatment decreased from 6 months to only 23 days. However, issues still existed. Due to inflation, especially in the 1970s, the community nursing homes received less money to support the care and treatment provided. Fewer than half of the planned centers were created, and new methods did not fully replace the old approaches to carry out its full capacity of treating power. Besides, the community helping system was not fully established to support the patients' housing, vocational opportunities, income supports, and other benefits. Many patients returned to welfare and criminal justice institutions, and more became homeless. The movement of deinstitutionalization was facing great challenges.\n\nAfter realizing that simply changing the location of mental health care from the state hospitals to nursing houses was insufficient to implement the idea of deinstitutionalization, the National Institute of Mental Health in 1975 created the Community Support Program (CSP) to provide funds for communities to set up a comprehensive mental health service and supports to help the mentally ill patients integrate successfully in the society. The program stressed the importance of other supports in addition to medical care, including housing, living expenses, employment, transportation, and education; and set up new national priority for people with serious mental disorders. In addition, the Congress enacted the Mental Health Systems Act of 1980 to prioritize the service to the mentally ill and emphasize the expansion of services beyond just clinical care alone. Later in the 1980s, under the influence from the Congress and the Supreme Court, many programs started to help the patients regain their benefits. A new Medicaid service was also established to serve people who were diagnosed with a \"chronic mental illness.\" People who were temporally hospitalized were also provided aid and care and a pre-release program was created to enable people to apply for reinstatement prior to discharge. Not until 1990, around 35 years after the start of the deinstitutionalization, did the first state hospital begin to close. The number of hospitals dropped from around 300 by over 40 in the 1990s, and finally a Report on Mental Health showed the efficacy of mental health treatment, giving a range of treatments available for patients to choose.\n\nHowever, several critics maintain that deinstitutionalization has, from a mental health point of view, been a thoroughgoing failure. The seriously mentally ill are either homeless, or in prison; in either case (especially the latter), they are getting little or no mental health care. This failure is attributed to a number of reasons over which there is some degree of contention, although there is general agreement that community support programs have been ineffective at best, due to a lack of funding.\n\nThe 2011 National Prevention Strategy included mental and emotional well-being, with recommendations including better parenting and early intervention programs, which increase the likelihood of prevention programs being included in future US mental health policies. The NIMH is researching only suicide and HIV/AIDS prevention, but the National Prevention Strategy could lead to it focusing more broadly on longitudinal prevention studies.\n\nIn 2013, United States Representative Tim Murphy introduced the Helping Families in Mental Health Crisis Act, HR2646. The bipartisan bill went through substantial revision and was reintroduced in 2015 by Murphy and Congresswoman Eddie Bernice Johnson. In November 2015, it passed the Health Subcommittee by an 18–12 vote.\n\n\n\n\n\n"}
{"id": "53889069", "url": "https://en.wikipedia.org/wiki?curid=53889069", "title": "Mike Enoch", "text": "Mike Enoch\n\nMichael Peinovich (born 1977), commonly known by his pseudonym Mike Enoch, is an American white nationalist and Neo-Nazi anti-semitic conspiracy theorist, blogger and podcast host. He founded the alt-right media hub \"The Right Stuff\" and podcast \"The Daily Shoah\". Through his work, Peinovich ridicules African Americans and other racial minorities, advocates racial separation and a revival of explicit racial discrimination (of the sort practiced in the Jim Crow South and Nazi Germany), and promotes conspiracy theories such as Holocaust denial and white genocide.\n\nPeinovich grew up in suburban Pennsylvania, in an upper-middle class family; he was raised by his father, a college professor, and his stepmother. His parents divorced at a young age. He is of Serbian and Norwegian descent. After graduating high school, he attended and dropped out of several universities before being hired as a computer programmer.\n\nPeinovich's father has disowned him and asked him to change his surname, in light of his neo-Nazi political activities as \"Mike Enoch.\"\n\nThe Right Stuff is a white nationalist, Neo-Nazi blog founded by Enoch that hosts several podcasts, including \"The Daily Shoah.\" The blog is best known for popularizing the use of \"echoes\", an antisemitic marker which uses triple parentheses around names used to identify Jews and people of the Jewish faith on social media. It is part of the broader alt-right movement in the United States. \n\n\"The Right Stuff\" was one of the first websites to make use of the term \"cuckservative\", long before the epithet attracted mainstream attention. The Anti-Defamation League notes that \"The Right Stuff\", like other similar organizations including Identity Evropa and Vanguard America, has also coalesced into a network of regional groups to coordinate activities in the real world, such as posting fliers promoting \"white heritage\" in various cities and universities in the United States.\n\nFirst broadcast in August 2014 and published weekly (and now three times every week), \"The Daily Shoah\"'s name is a parody of \"The Daily Show\" and uses the Hebrew language word referring to the Holocaust. Enoch originally created the show to be edgy and libertarian, and later began sharing antisemitic conspiracy theories around Episode 19, after reading \"The Culture of Critique\" by Kevin B. MacDonald.\n\nOn the show Enoch, along with co-host Seventh Son and a rotating panel of co-hosts and guests (known as \"the Death Panel\") has addressed topics such as immigration, white nationalism, race relations, feminism, Zionism, anti-globalization and political correctness.\n\nThe podcast is widely credited with creating the triple parentheses meme, also known as (((echo))), an antisemitic symbol that has been used to highlight the names of individuals of Jewish ethnicity.\n\n, \"The Daily Shoah\" reportedly had an audience of 100,000 listeners.\n\nIn January 2017, users of the imageboard website 8chan leaked the identities of several of its key contributors, including Peinovich, and revealed that his wife was of Jewish ancestry. Other information released included the names of his family members, his job as a software developer, home address on Manhattan's Upper East Side neighborhood, and his hometown of Maplewood, New Jersey. After initially attempting to deny the reports, Peinovich later admitted that the allegations were true. Though Peinovich initially planned to leave the network, he quickly changed his mind and vowed to continue his activities.\n\nIn an audio statement released on their podcast, \"Daily Shoah\" co-host Seventh Son announced that Peinovich and his wife were separating. The revelation was met with mixed but mostly supportive reactions from fellow alt-right leaders, including David Duke, and Richard B. Spencer.\n\nAfter U.S. Congressman Steve King tweeted praise for Netherlands political candidate Geert Wilders's strong stance against further immigration to Europe, Peinovich joined other alt-right voices in approval of King's position, stating \"King doubles down. Great job. Take note cucks, this is how you *actually* fight the left.\"\n\nHe had expressed support for Donald Trump during the presidential election and the first months of his term, but has disavowed him after Donald Trump ordered airstrikes in Syria. On March 9, Enoch took part in an anti-war protest opposing the 2017 Shayrat missile strike, in which 59 Tomahawk Cruise missiles were launched by the United States against the Shayrat Airbase controlled by Bashar al-Assad and his forces. The protest, organized by Richard B. Spencer, was counter-protested by anti-fascist activists. On the next episode of \"The Daily Shoah\", Enoch and Spencer railed against the perceived attitudes of mainstream conservatives, especially Baby Boomers, and spoke about the growing (and, in their opinions, undue) influence of Ivanka Trump and Senior Adviser Jared Kushner on President Donald Trump, as well as neoconservative and pro-Israel influences within the Trump administration. He also commented that the alt-right was now \"the only legitimate anti-war movement in the United States,\" and that the antifa counter-protesters supported Trump and the military strike by virtue of counter-protesting an anti-war demonstration.\n\nOn April 18, 2017, Enoch joined Richard B. Spencer in giving a talk at Auburn University where he expressed that he and the movement were breaking away from the new direction that the Trump administration was taking. While Auburn administration had initially cancelled the planned event, citing safety concerns, Enoch assisted Spencer in filing a lawsuit on First Amendment grounds. United States federal judge William Keith Watkins issued a ruling requiring Auburn to allow Spencer and Enoch to speak.\n\nIn April 2018, he was retweeted by Ann Coulter. After \"Newsweek\" reached out to Twitter asking for a comment, his account was suspended.\n\n"}
{"id": "437868", "url": "https://en.wikipedia.org/wiki?curid=437868", "title": "Minority group", "text": "Minority group\n\nA minority group refers to a category of people who experience relative disadvantage as compared to members of a dominant social group. Minority group membership is typically based on differences in observable characteristics or practices, such as: sex, ethnicity, race, religion, disability, sexual orientation, or gender identity. Utilizing the framework of intersectionality, it is important to recognize that an individual may simultaneously hold membership in multiple minority groups (e.g. both a racial and religious minority). Likewise, individuals may also be part of a minority group in regard to some characteristics, but part of a dominant group in regard to others.\n\nThe term \"minority group\" often occurs within the discourse of civil rights and collective rights, as members of minority groups are prone to differential treatment in the countries and societies in which they live. Minority group members often face discrimination in multiple areas of social life, including housing, employment, healthcare, and education, among others. While discrimination may be committed by individuals, it may also occur through structural inequalities, in which rights and opportunities are not equally accessible to all. The language of minority rights, is often used to discuss laws designed to protect minority groups from discrimination and afford them equal social status to the dominant group.\n\nLouis Wirth defined a minority group as \"a group of people who, because of their physical or cultural characteristics, are singled out from the others in the society in which they live for differential and unequal treatment, and who therefore regard themselves as objects of collective discrimination\". The definition includes both objective and subjective criteria: membership of a minority group is objectively ascribed by society, based on an individual's physical or behavioral characteristics; it is also subjectively applied by its members, who may use their status as the basis of group identity or solidarity. Thus, minority group status is categorical in nature: an individual who exhibits the physical or behavioral characteristics of a given minority group is accorded the status of that group and is subject to the same treatment as other members of that group.\n\nJoe Feagin, states that a minority group has five characteristics: (1) suffering discrimination and subordination, (2) physical and/or cultural traits that set them apart, and which are disapproved by the dominant group, (3) a shared sense of collective identity and common burdens, (4) socially shared rules about who belongs and who does not determine minority status, and (5) tendency to marry within the group.\n\nThere is a controversy with the use of the word minority, as it has a common and an academic usage. Common usage of the term indicates a statistical minority; however, academics refer to power differences among groups rather than differences in population size among groups.\n\nSome sociologists have criticised the concept of \"minority/majority\", arguing this language excludes or neglects changing or unstable cultural identities, as well as cultural affiliations across national boundaries. As such, the term historically excluded groups (HEGs) is often similarly used to highlight the role of historical oppression and domination, and how this results in the underrepresentation of particular groups in various areas of social life.\n\nThe term national minority is often used to discuss minority groups in international and national politics. All countries contain some degree of racial, ethnic, or linguistic diversity. In addition, minorities may also be minorities they may be migrant, indigenous or landless nomadic communities. This often results in variations in language, culture, beliefs, practices, that set some groups apart from the dominant grop. As these differences are usually perceived negatively by, this results in loss of social and political power for members of minority groups.\n\nThere is no legal definition of national minorities in international law, though protection of minority groups is outlined by the United Nations Declaration on the Rights of Persons Belonging to National or Ethnic, Religious and Linguistic Minorities. International criminal law can protect the rights of racial or ethnic minorities in a number of ways. The right to self-determination is a key issue.\n\nThe formal level of protection of national minorities is highest in European countries. The Council of Europe proposes a definition of national minorities in the European Charter for Regional or Minority Languages and by the Framework Convention for the Protection of National Minorities; however these definitions are not binding upon member states. Using this framework, a national minority can be theoretically defined as a group of people within a given nation state:\n\n\nIn some places, subordinate ethnic groups may constitute a numerical majority, such as Blacks in South Africa under apartheid. In the United States, for example, non-Hispanic Whites constitute the majority (63.4%) and all other racial and ethnic groups (Hispanic or Latino, African Americans, Asian Americans, American Indian, and Native Hawaiians) are classified as \"minorities\". If the non-Hispanic White population falls below 50% the group will only be the \"plurality\", not the majority.\n\nThe elderly, while traditionally influential or even (in a gerontocracy) dominant in the past, are now usually reduced to the minority role of economically 'non-active' groups. Children can also be understood as a minority group in these terms, and the discrimination faced by the young is known as adultism. Discrimination against the elderly is known as ageism.\n\nVarious local and international statutes are in place to mitigate the exploitation of children, such as the Convention on the Rights of the Child, as well as a number of organizations that make up the children's rights movement. The youth rights movement campaigns for social empowerment for young people, and against the legal and social restrictions placed on legal minors. Groups that advocate the interests of senior citizens range from the charitable (Help the Aged) to grass-roots activism (Gray Panthers), and often overlap with disability rights issues.\n\nAlso known as \"castelike minorities,\" involuntary minorities are a term for people who were originally brought into any society against their will. In the United States, for instance, it includes but is not limited to Native Americans, Puerto Ricans, African Americans, and native-born Mexican Americans. For reasons of cultural differences, involuntary minorities may experience difficulties in school more than members of other (voluntary) minority groups. Social capital helps children engage with different age groups that share a common goal.\n\nImmigrants take on minority status in their new country, usually in hopes of a better future economically, educationally, and politically than in their homeland. Because of their focus on success, voluntary minorities are more likely to do better in school than other migrating minorities. Adapting to a very different culture and language make difficulties in the early stages of life in the new country. Voluntary immigrants do not experience a sense of divided identity as much as involuntary minorities, and are often rich in social capital because of their educational ambitions. Major immigrant groups in the United States include Mexicans, Central and South Americans, Cubans, Africans, and Indians.\n\nThe term sexual minority is frequently used by public health researchers to recognize a wide variety of individuals who engage in same-sex sexual behavior, including those who do not identify under the LGBTQ umbrella. For example, men who have sex with men (MSM), but do not identify as gay. In addition, the term gender minorities can include many types of gender variant people, such as intersex people, transgender people, or gender non-conforming individuals. However, the terms sexual and gender minority are often not preferred by LGBTQ people, as they represent clinical categories rather than individual identity.\n\nThough lesbian, gay, bisexual, transgender, and queer (LGBTQ) people have existed throughout human history, LGBT rights movements across many western countries led to the recognition of LGBTQ people as members of a minority group. LGBTQ people represent a numerical and social minority. They experience numerous social inequalities stemming from their group membership as LGBTQ people. These inequalities include social discrimination and isolation, unequal access to healthcare, employment, and housing, and experience negative mental and physical health outcomes due to these experiences.\n\nThe disability rights movement has contributed to an understanding of people with disabilities (including not to be called 'disabled') as a minority or a coalition of minorities who are disadvantaged by society, not just as people who are disadvantaged by their impairments. Advocates of disability rights emphasize difference in physical or psychological functioning, rather than inferiority. For example, some people with autism argue for acceptance of neurodiversity, much as opponents of racism argue for acceptance of ethnic diversity. The deaf community is often regarded as a linguistic and cultural minority rather than a group with disabilities, and some deaf people do not see themselves as having a disability at all. Rather, they are disadvantaged by technologies and social institutions that are designed to cater for the dominant group. (\"See the Convention on the Rights of Persons with Disabilities\".)\n\nOne of the most controversial minorities in the United States and other countries has been communists. Along with the Red Scare and execution of Julius and Ethel Rosenberg, the United States ran open campaigns to fight, contain and promote fear of communism in the country. Some were persecuted as communist even when they were not actually so: for example, many activists for civil rights were portrayed as inspired by a communist agenda. Communists in the United States, as in many European countries, are often afraid to proclaim their politics, fearing abuse and discrimination from the political majority.\n\nPeople belonging to religious minorities have a faith which is different from that held by the majority. Most countries of the world have religious minorities. It is now widely accepted in the west that people should have the freedom to choose their own religion, including not having any religion (atheism and/or agnosticism), and including the right to convert from one religion to another. However, in many countries this freedom is constricted. For example, in Egypt, a new system of identity cards requires all citizens to state their religion—and the only choices are Islam, Christianity, or Judaism (See Egyptian identification card controversy).\n\nAuthors have pointed out that many coal workers would be unwilling to move for work or were not likely to be able to be retrained as Appalachians are an \"ethnic minority\".\n\nWhile in most societies, numbers of men and women are roughly equal, the status of women as a subordinate group has led to many social scientists to study them as a minority group. Though women's legal rights and status vary widely across countries, women experience social inequalities relative to men in most societies. Women are often denied access to education, subject to violence, and lack access to the same economic opportunities as men.\n\nIn the politics of some countries, a \"minority\" is an ethnic group recognized by law, and having specified rights. Speakers of a legally recognized minority language, for instance, might have the right to education or communication with the government in their mother tongue. Countries with special provisions for minorities include Canada, China, Ethiopia, Germany, India, the Netherlands, Poland, Romania, Russia, Croatia, and the United Kingdom.\n\nThe various minority groups in a country are often not given equal treatment. Some groups are too small or indistinct to obtain minority protections. For example, a member of a particularly small ethnic group might be forced to check \"Other\" on a checklist of different backgrounds and so might receive fewer privileges than a member of a more defined group.\n\nMany contemporary governments prefer to assume the people they rule all belong to the same nationality rather than separate ones based on ethnicity. The United States asks for race and ethnicity on its official census forms, which thus breaks up and organizes its population into sub-groups, primarily racial rather than national. Spain does not divide its nationals by ethnic group, although it does maintain an official notion of minority languages.\n\nSome especially significant or powerful minorities receive comprehensive protection and political representation. For example, the former Yugoslav republic of Bosnia and Herzegovina recognizes the three constitutive nations, none of which constitutes a numerical majority (see nations of Bosnia and Herzegovina). However, other minorities such as Romani and Jews, are officially labelled \"foreign\" and are excluded from many of these protections. For example, they may be excluded from political positions, including the presidency.\n\nThere is debate over recognizing minority groups and their privileges. One view is that the application of special rights to minority groups may harm some countries, such as new states in Africa or Latin America not founded on the European nation-state model, since minority recognition may interfere with establishing a national identity. It may hamper the integration of the minority into mainstream society, perhaps leading to separatism or supremacism. In Canada, some feel that the failure of the dominant English-speaking majority to integrate French Canadians has provoked Quebec separatism.\n\nOthers assert that minorities require specific protections to ensure that they are not marginalised: for example, bilingual education may be needed to allow linguistic minorities to fully integrate into the school system and compete equally in society. In this view, rights for minorities strengthen the nation-building project, as members of minorities see their interests well served, and willingly accept the legitimacy of the nation and their integration (not assimilation) within it.\n\n"}
{"id": "327672", "url": "https://en.wikipedia.org/wiki?curid=327672", "title": "Natural and legal rights", "text": "Natural and legal rights\n\nNatural and legal rights are two types of rights. Natural rights are those that are not dependent on the laws or customs of any particular culture or government, and so are universal and inalienable (they cannot be repealed or restrained by human laws). Legal rights are those bestowed onto a person by a given legal system (they can be modified, repealed, and restrained by human laws).\n\nThe concept of natural law is related to the concept of natural rights. Natural law first appeared in ancient Greek philosophy, and was referred to by Roman philosopher Cicero. It was subsequently alluded to in the Bible, and then developed in the Middle Ages by Catholic philosophers such as Albert the Great and his pupil Thomas Aquinas. During the Age of Enlightenment, the concept of natural laws was used to challenge the divine right of kings, and became an alternative justification for the establishment of a social contract, positive law, and government – and thus legal rights – in the form of classical republicanism. Conversely, the concept of natural rights is used by others to challenge the legitimacy of all such establishments.\n\nThe idea of human rights is also closely related to that of natural rights: some acknowledge no difference between the two, regarding them as synonymous, while others choose to keep the terms separate to eliminate association with some features traditionally associated with natural rights. Natural rights, in particular, are considered beyond the authority of any government or international body to dismiss. The 1948 United Nations Universal Declaration of Human Rights is an important legal instrument enshrining one conception of natural rights into international soft law. Natural rights were traditionally viewed as exclusively negative rights, whereas human rights also comprise positive rights. Even on a natural rights conception of human rights, the two terms may not be synonymous.\n\nThe proposition that animals have natural rights is one that gained the interest of philosophers and legal scholars in the 20th century and into the 21st.\n\nThe idea that certain rights are natural or inalienable also has a history dating back at least to the Stoics of late Antiquity and Catholic law of the early Middle Ages, and descending through the Protestant Reformation and the Age of Enlightenment to today.\n\nThe existence of natural rights has been asserted by different individuals on different premises, such as \"a priori\" philosophical reasoning or religious principles. For example, Immanuel Kant claimed to derive natural rights through reason alone. The United States Declaration of Independence, meanwhile, is based upon the \"self-evident\" truth that \"all men are … endowed by their Creator with certain unalienable Rights\".\n\nLikewise, different philosophers and statesmen have designed different lists of what they believe to be natural rights; almost all include the right to life and liberty as the two highest priorities. H. L. A. Hart argued that if there are any rights at all, there must be the right to liberty, for all the others would depend upon this. T. H. Green argued that “if there are such things as rights at all, then, there must be a right to life and liberty, or, to put it more properly to free life.” John Locke emphasized \"life, liberty and property\" as primary. However, despite Locke's influential defense of the right of revolution, Thomas Jefferson substituted \"pursuit of happiness\" in place of \"property\" in the United States Declaration of Independence.\n\nStephen Kinzer, a veteran journalist for \"The New York Times\" and the author of the book \"All The Shah's Men\", writes in the latter that:\n\nThe Stoics held that no one was a slave by nature; slavery was an external condition juxtaposed to the internal freedom of the soul (\"sui juris\"). Seneca the Younger wrote:\n\nOf fundamental importance to the development of the idea of natural rights was the emergence of the idea of natural human equality. As the historian A.J. Carlyle notes: \"There is no change in political theory so startling in its completeness as the change from the theory of Aristotle to the later philosophical view represented by Cicero and Seneca... We think that this cannot be better exemplified than with regard to the theory of the equality of human nature.\" Charles H. McIlwain likewise observes that \"the idea of the equality of men is the profoundest contribution of the Stoics to political thought\" and that \"its greatest influence is in the changed conception of law that in part resulted from it.\" Cicero argues in De Legibus that \"we are born for Justice, and that right is based, not upon opinions, but upon Nature.\"\n\nOne of the first Western thinkers to develop the contemporary idea of natural rights was French theologian Jean Gerson, whose 1402 treatise \"De Vita Spirituali Animae\" is considered one of the first attempts to develop what would come to be called modern natural rights theory.\n\nCenturies later, the Stoic doctrine that the \"inner part cannot be delivered into bondage\" re-emerged in the Reformation doctrine of liberty of conscience. Martin Luther wrote:\n\n17th-century English philosopher John Locke discussed natural rights in his work, identifying them as being \"life, liberty, and estate (property)\", and argued that such fundamental rights could not be surrendered in the social contract. Preservation of the natural rights to life, liberty, and property was claimed as justification for the rebellion of the American colonies. As George Mason stated in his draft for the \"Virginia Declaration of Rights\", \"all men are born equally free,\" and hold \"certain inherent natural rights, of which they cannot, by any compact, deprive or divest their posterity.\" Another 17th-century Englishman, John Lilburne (known as \"Freeborn John\"), who came into conflict with both the monarchy of King Charles I and the military dictatorship of Oliver Cromwell governed republic, argued for level human basic rights he called \"freeborn rights\" which he defined as being rights that every human being is born with, as opposed to rights bestowed by government or by human law.\n\nThe distinction between alienable and unalienable rights was introduced by Francis Hutcheson. In his \"Inquiry into the Original of Our Ideas of Beauty and Virtue\" (1725), Hutcheson foreshadowed the Declaration of Independence, stating: “For wherever any Invasion is made upon unalienable Rights, there must arise either a perfect, or external Right to Resistance. . . . Unalienable Rights are essential Limitations in all Governments.” Hutcheson, however, placed clear limits on his notion of unalienable rights, declaring that “there can be no Right, or Limitation of Right, inconsistent with, or opposite to the greatest publick Good.\" Hutcheson elaborated on this idea of unalienable rights in his \"A System of Moral Philosophy\" (1755), based on the Reformation principle of the liberty of conscience. One could not in fact give up the capacity for private judgment (e.g., about religious questions) regardless of any external contracts or oaths to religious or secular authorities so that right is \"unalienable.\" Hutcheson wrote: \"Thus no man can really change his sentiments, judgments, and inward affections, at the pleasure of another; nor can it tend to any good to make him profess what is contrary to his heart. The right of private judgment is therefore unalienable.\"\n\nIn the German Enlightenment, Hegel gave a highly developed treatment of this inalienability argument. Like Hutcheson, Hegel based the theory of inalienable rights on the \"de facto\" inalienability of those aspects of personhood that distinguish persons from things. A thing, like a piece of property, can in fact be transferred from one person to another. According to Hegel, the same would not apply to those aspects that make one a person:\n\nIn discussion of social contract theory, \"inalienable rights\" were said to be those rights that could not be surrendered by citizens to the sovereign. Such rights were thought to be \"natural rights\", independent of positive law. Some social contract theorists reasoned, however, that in the natural state only the strongest could benefit from their rights. Thus, people form an implicit social contract, ceding their natural rights to the authority to protect the people from abuse, and living henceforth under the legal rights of that authority.\n\nMany historical apologies for slavery and illiberal government were based on explicit or implicit voluntary contracts to alienate any \"natural rights\" to freedom and self-determination. The \"de facto\" inalienability arguments of Hutcheson and his predecessors provided the basis for the anti-slavery movement to argue not simply against involuntary slavery but against any explicit or implied contractual forms of slavery. Any contract that tried to legally alienate such a right would be inherently invalid. Similarly, the argument was used by the democratic movement to argue against any explicit or implied social contracts of subjection (\"pactum subjectionis\") by which a people would supposedly alienate their right of self-government to a sovereign as, for example, in \"Leviathan\" by Thomas Hobbes. According to Ernst Cassirer,\n\nThese themes converged in the debate about American Independence. While Jefferson was writing the Declaration of Independence, Richard Price in England sided with the Americans' claim \"that Great Britain is attempting to rob them of that liberty to which every member of society and all civil communities have a natural and unalienable title.\" Price again based the argument on the \"de facto\" inalienability of \"that principle of spontaneity or self-determination which constitutes us agents or which gives us a command over our actions, rendering them properly ours, and not effects of the operation of any foreign cause.\" Any social contract or compact allegedly alienating these rights would be non-binding and void, wrote Price:\n\nPrice raised a furor of opposition so in 1777 he wrote another tract that clarified his position and again restated the \"de facto\" basis for the argument that the \"liberty of men as agents is that power of self-determination which all agents, as such, possess.\"\nIn \"Intellectual Origins of American Radicalism\", Staughton Lynd pulled together these themes and related them to the slavery debate:\n\nMeanwhile, in America, Thomas Jefferson \"took his division of rights into alienable and unalienable from Hutcheson, who made the distinction popular and important\", and in the 1776 United States Declaration of Independence, famously condensed this to:\n\nIn the 19th century, the movement to abolish slavery seized this passage as a statement of constitutional principle, although the U.S. constitution recognized and protected slavery. As a lawyer, future Chief Justice Salmon P. Chase argued before the Supreme Court in the case of John Van Zandt, who had been charged with violating the Fugitive Slave Act, that:\n\nThe concept of inalienable rights was criticized by Jeremy Bentham and Edmund Burke as groundless. Bentham and Burke, writing in 18th century Britain, claimed that rights arise from the actions of government, or evolve from tradition, and that neither of these can provide anything \"inalienable\". (See Bentham's \"Critique of the Doctrine of Inalienable, Natural Rights\", and Burke's \"Reflections on the Revolution in France\"). Presaging the shift in thinking in the 19th century, Bentham famously dismissed the idea of natural rights as \"nonsense on stilts\". By way of contrast to the views of British nationals Burke and Bentham, the leading American revolutionary scholar James Wilson condemned Burke's view as \"tyranny.\"\n\nThe signers of the Declaration of Independence deemed it a \"self-evident truth\" that all men \"are endowed by their Creator with certain unalienable Rights\".\nIn \"The Social Contract\", Jean-Jacques Rousseau claims that the existence of inalienable rights is unnecessary for the existence of a constitution or a set of laws and rights. This idea of a social contractthat rights and responsibilities are derived from a consensual contract between the government and the peopleis the most widely recognized alternative.\n\nOne criticism of natural rights theory is that one cannot draw norms from facts. This objection is variously expressed as the is-ought problem, the naturalistic fallacy, or the appeal to nature. G.E. Moore, for example, said that ethical naturalism falls prey to the naturalistic fallacy. Some defenders of natural rights theory, however, counter that the term \"natural\" in \"natural rights\" is contrasted with \"artificial\" rather than referring to nature. John Finnis, for example, contends that natural law and natural rights are derived from self-evident principles, not from speculative principles or from facts.\n\nThere is also debate as to whether all rights are either natural or legal. Fourth president of the United States James Madison, while representing Virginia in the House of Representatives, believed that there are rights, such as trial by jury, that are social rights, arising neither from natural law nor from positive law (which are the basis of natural and legal rights respectively) but from the social contract from which a government derives its authority.\n\nThomas Hobbes (1588–1679) included a discussion of natural rights in his moral and political philosophy. Hobbes' conception of natural rights extended from his conception of man in a \"state of nature\". Thus he argued that the essential natural (human) right was \"to use his own power, as he will himself, for the preservation of his own Nature; that is to say, of his own Life; and consequently, of doing any thing, which in his own judgement, and Reason, he shall conceive to be the aptest means thereunto.\" (\"Leviathan\". 1, XIV)\n\nHobbes sharply distinguished this natural \"liberty\", from natural \"laws\", described generally as \"a precept, or general rule, found out by reason, by which a man is forbidden to do, that, which is destructive of his life, or taketh away the means of preserving his life; and to omit, that, by which he thinketh it may best be preserved.\" (\"Leviathan\". 1, XIV)\n\nIn his natural state, according to Hobbes, man's life consisted entirely of liberties and not at all of laws – \"It followeth, that in such a condition, every man has the right to every thing; even to one another's body. And therefore, as long as this natural Right of every man to every thing endureth, there can be no security to any man... of living out the time, which Nature ordinarily allow men to live.\" (\"Leviathan\". 1, XIV)\n\nThis would lead inevitably to a situation known as the \"war of all against all\", in which human beings kill, steal and enslave others in order to stay alive, and due to their natural lust for \"Gain\", \"Safety\" and \"Reputation\". Hobbes reasoned that this world of chaos created by unlimited rights was highly undesirable, since it would cause human life to be \"solitary, poor, nasty, brutish, and short\". As such, if humans wish to live peacefully they must give up most of their natural rights and create moral obligations in order to establish political and civil society. This is one of the earliest formulations of the theory of government known as the social contract.\n\nHobbes objected to the attempt to derive rights from \"natural law,\" arguing that law (\"lex\") and right (\"jus\") though often confused, signify opposites, with law referring to obligations, while rights refer to the absence of obligations. Since by our (human) nature, we seek to maximize our well being, rights are prior to law, natural or institutional, and people will not follow the laws of nature without first being subjected to a sovereign power, without which all ideas of right and wrong are meaningless – \"Therefore before the names of Just and Unjust can have place, there must be some coercive Power, to compel men equally to the performance of their Covenants..., to make good that Propriety, which by mutual contract men acquire, in recompense of the universal Right they abandon: and such power there is none before the erection of the Commonwealth.\" (\"Leviathan\". 1, XV)\n\nThis marked an important departure from medieval natural law theories which gave precedence to obligations over rights.\nJohn Locke (1632 – 1704) was another prominent Western philosopher who conceptualized rights as natural and inalienable. Like Hobbes, Locke believed in a natural right to life, liberty, and property. It was once conventional wisdom that Locke greatly influenced the American Revolutionary War with his writings of natural rights, but this claim has been the subject of protracted dispute in recent decades. For example, the historian Ray Forrest Harvey declared that Jefferson and Locke were at \"two opposite poles\" in their political philosophy, as evidenced by Jefferson’s use in the Declaration of Independence of the phrase \"pursuit of happiness\" instead of \"property.\" More recently, the eminent legal historian John Phillip Reid has deplored contemporary scholars’ \"misplaced emphasis on John Locke,\" arguing that American revolutionary leaders saw Locke as a \"commentator\" on established constitutional principles. Thomas Pangle has defended Locke's influence on the Founding, claiming that historians who argue to the contrary either misrepresent the classical republican alternative to which they say the revolutionary leaders adhered, do not understand Locke, or point to someone else who was decisively influenced by Locke. This position has also been sustained by Michael Zuckert.\n\nAccording to Locke there are three natural rights:\n\nIn developing his concept of natural rights, Locke was influenced by reports of society among Native Americans, whom he regarded as \"natural peoples\" who lived in a state of liberty and \"near perfect freedom\", but not license. It also informed his conception of social contract.\n\nThe social contract is an agreement between members of a country to live within a shared system of laws. Specific forms of government are the result of the decisions made by these persons acting in their collective capacity. Government is instituted to make laws that protect these three natural rights. If a government does not properly protect these rights, it can be overthrown.\n\nThomas Paine (1731–1809) further elaborated on natural rights in his influential work \"Rights of Man\" (1791), emphasizing that rights cannot be granted by any charter because this would legally imply they can also be revoked and under such circumstances they would be reduced to privileges:\n\nWhile at first American individualist anarchists adhered to natural rights positions, later in this era led by Benjamin Tucker, some abandoned natural rights positions and converted to Max Stirner's Egoist anarchism. Rejecting the idea of moral rights, Tucker said there were only two rights: \"the right of might\" and \"the right of contract\". He also said, after converting to Egoist individualism, \"In times past... it was my habit to talk glibly of the right of man to land. It was a bad habit, and I long ago sloughed it off... Man's only right to land is his might over it.\"\n\nAccording to Wendy McElroy:\nSeveral periodicals were \"undoubtedly influenced by \"Liberty\"'s presentation of egoism, including \"I\" published by C.L. Swartz, edited by W.E. Gordak and J.W. Lloyd (all associates of \"Liberty\"); \"The Ego\" and \"The Egoist\", both of which were edited by Edward H. Fulton. Among the egoist papers that Tucker followed were the German \"Der Eigene\", edited by Adolf Brand, and \"The Eagle\" and \"The Serpent\", issued from London. The latter, the most prominent English-language egoist journal, was published from 1898 to 1900 with the subtitle 'A Journal of Egoistic Philosophy and Sociology. Among those American anarchists who adhered to egoism include Benjamin Tucker, John Beverley Robinson, Steven T. Byington, Hutchins Hapgood, James L. Walker, Victor Yarros and E.H. Fulton.\n\nMany documents now echo the phrase used in the United States Declaration of Independence. The preamble to the 1948 United Nations Universal Declaration of Human Rights asserts that rights are inalienable: \"recognition of the inherent dignity and of the equal and inalienable rights of all members of the human family is the foundation of freedom, justice and peace in the world.\" Article 1, § 1 of the California Constitution recognizes inalienable rights, and articulated \"some\" (not all) of those rights as \"defending life and liberty, acquiring, possessing, and protecting property, and pursuing and obtaining safety, happiness, and privacy.\" However, there is still much dispute over which \"rights\" are truly natural rights and which are not, and the concept of natural or inalienable rights is still controversial to some.\n\nErich Fromm argued that some powers over human beings could be wielded only by God, and that if there were no God, no human beings could wield these powers.\n\nContemporary political philosophies continuing the classical liberal tradition of natural rights include libertarianism, anarcho-capitalism and Objectivism, and include amongst their canon the works of authors such as Robert Nozick, Ludwig von Mises, Ayn Rand, and Murray Rothbard. A libertarian view of inalienable rights is laid out in Morris and Linda Tannehill's \"The Market for Liberty\", which claims that a man has a right to ownership over his life and therefore also his property, because he has invested time (i.e. part of his life) in it and thereby made it an extension of his life. However, if he initiates force against and to the detriment of another man, he alienates himself from the right to that part of his life which is required to pay his debt: \"Rights are \"not\" inalienable, but only the possessor of a right can alienate himself from that right – no one else can take a man's rights from him.\"\n\nVarious definitions of inalienability include non-relinquishability, non-salability, and non-transferability. This concept has been recognized by libertarians as being central to the question of voluntary slavery, which Murray Rothbard dismissed as illegitimate and even self-contradictory. Stephan Kinsella argues that \"viewing rights as alienable is perfectly consistent with – indeed, implied by – the libertarian non-aggression principle. Under this principle, only the initiation of force is prohibited; defensive, restitutive, or retaliatory force is not.\"\n\nVarious philosophers have created different lists of rights they consider to be natural. Proponents of natural rights, in particular Hesselberg and Rothbard, have responded that reason can be applied to separate truly axiomatic rights from supposed rights, stating that any principle that requires itself to be disproved is an axiom. Critics have pointed to the lack of agreement between the proponents as evidence for the claim that the idea of natural rights is merely a political tool.\n\nHugh Gibbons has proposed a descriptive argument based on human biology. His contention is that Human Beings were other-regarding as a matter of necessity, in order to avoid the costs of conflict. Over time they developed expectations that individuals would act in certain ways which were then prescribed by society (duties of care etc.) and that eventually crystallized into actionable rights.\n\n\n"}
{"id": "19940393", "url": "https://en.wikipedia.org/wiki?curid=19940393", "title": "Natural morality", "text": "Natural morality\n\nNatural morality describes a form of morality that is based on how humans evolved, rather than a morality acquired from societal norms or religious teachings.\n\nCharles Darwin's theory of evolution is central to the modern conception of natural morality, although its roots go back at least to naturalism. \nCharles Darwin defends a naturalist approach to morality. In \"The Descent of Man\", he argues that moral behaviour has outgrown from animal tendency for empathy through evolution of morality. By comparing human and animal behavior through a naturalist approach, he concludes that moral sense is based on the species' sociability, notably altruism.\n\nIn Darwin's view, empathy lays as the foundation for our actions, as opposed to selfishness. He states that humans can generally distinguish between altruism (the \"high moral rules\") and selfishness (the \"low moral rules\"):\nDarwin suggests sympathy is at the core of sociability and is an instinctive emotion found in most social animals. The ability to recognize and act upon others' distress or danger, is a suggestive evidence of instinctive sympathy; common mutual services found among many social animals, such as hunting and travelling in groups, warning others of danger and mutually defending one another, are some examples of instinctive sympathy Darwin offers. He insists it must be sympathy that compels an individual to risk his or her own life for another from his community.\n\nDarwin suggests further that the role of acceptance of others acts as a guide for conduct; sympathy enables to obtain approval of others instead of rejection. Social animals, when separated from the herd, cannot endure solitude and oftentimes perish. Darwin argues social animals have a natural dislike for solitude, and states: \"solitary confinement is one of the severest punishments which can be inflicted.\"\n\nBecause of the instinctive nature of sympathy and its general recurrence among many social animals, Darwin deduces this emotional character must be inherited through natural selection. From a naturalist point of view, it is probable that instinctive sympathy was first developed for animals to thrive by living in society just as the pleasure of eating was first acquired to induce animals to eat. In this sense, morality is a crucial instinct for survival in social animals. As Darwin notes in \"The Descent of Man\":\n\nInstinctive altruism effectively enables individuals to guarantee survival of the group, which in turn will aid survival of the individual. In \"The Descent of Man\", Darwin notes:\n\nMankind is a social animal, and has inherited its moral traits through the evolution of morality. As Darwin notes, the moral difference between mankind and animals, however, is \"certainly one of degree and not of kind.\" Emotions such as remorse, regret or shame one may feel, stem from human's incessant reflection on past experiences and preoccupation with the judgement of others.\n\n\n"}
{"id": "45391074", "url": "https://en.wikipedia.org/wiki?curid=45391074", "title": "Negro Sanhedrin", "text": "Negro Sanhedrin\n\nThe Negro Sanhedrin was a national \"All-Race Conference\" held in the American city of Chicago, Illinois, from February 11 to 15, 1924. The gathering was attended by 250 delegates representing 61 trade unions, civic groups, and fraternal organizations in a short-lived attempt to forge a national program protecting the legal rights of African-American tenant farmers and wage workers and extending the scope of civil rights.\n\nThe idea for a national conference bringing together representatives of African-American organizations came in the spring of 1923, following Congressional defeat of the Dyer Anti-Lynching Bill. William Monroe Trotter of the National Equal Rights League (NERL) of Boston is credited with originating the idea for assembly of a national council of prominent black leaders. This idea was passed along to president of the NERL, Matthew A. N. Shaw, who issued a formal invitation to five like-minded organizations asking for their support.\n\nAmong the groups initially solicited was the African Blood Brotherhood (ABB), a radical semi-underground organization affiliated with the Workers Party of America. Head of the ABB, Cyril Briggs, took the initiative in coordinating such a gathering, initially touted by him as a \"United Front Negro Conference of Civil Rights Organizations.\" On March 24, 1923, a formal document was signed by representatives of the six organizations pledging their support of the conference. In addition to the ABB and NERL, other groups lending their formal support included the National Association for the Advancement of Colored People (NAACP), the International Uplift League, the Friends of Freedom, and the National Race Congress.\n\nDean Kelly Miller of Howard University, formally representing the National Race Congress, was chosen as head of the arrangements committee, with Cyril Briggs of the ABB continuing to handle day to day organizational tasks as secretary. Nearly a year of meetings and organizational outreach followed, with the moderate Miller cementing ties with mainstream community and fraternal organizations. It was Miller who chose the name for the gathering, the \"Sanhedrin,\" a phrase originating in the Biblical first book of Maccabees and referring to a supreme council of the Hebrew people.\n\nThe Sanhedrin assembled in Chicago on February 11, 1924, attended by 250 delegates representing 61 organizations.\n\nThe gathering was attended by organizations ranging across the ideological spectrum, from conservative civic groups to the African Blood Brotherhood. A considerable number of professionals, scholars, and businesspeople were included among the delegates, who hailed from no fewer than 20 American states. As a result, the gathering was far from radical, with the convention electing Kelly Miller its chairman following a short debate — a decision bitterly opposed by the radical caucus of delegates, which included Briggs and his Workers Party comrades, Lovett Fort-Whiteman, and Otto Huiswoud.\n\nLovett Fort-Whiteman spoke on the floor of the convention for the agenda of radical delegates, headed by Communists and the ABB. He urged the adoption of a program calling for an end to racial segregation in the housing market, termination of colonialism in Africa, legally binding contracts to protect tenant farmers, abolition of anti-miscegenation laws, and diplomatic recognition of Soviet Russia by the United States government, among other things. Resolutions condemning the American Federation of Labor for allowing its affiliated unions the freedom to exclude black workers from membership and calling for African Americans to join the Communist-sponsored Farmer-Labor Party were prepared.\n\nConvention chairman Miller short-circuited the agenda of the radicals, however, using his power to appoint an official of the Chicago Chamber of Commerce as head of the Sanhedrin's Labor Committee. This forced the ABB and its allies to bring its proposed resolutions for action directly from the floor of the gathering, a process which ended in failure for its resolutions dealing with school segregation, opposing the Ku Klux Klan, and seeking recognition of Soviet Russia. \n\nThose resolutions which were passed were severely tempered from the preferred wording of the radicals, including a comparatively mild rebuke of labor union locals for exclusion of black members rather than ringing condemnation of the leadership of the American Federation of Labor and opining in favor of equal pay for workers without respect to race and organized financial assistance to the struggling agricultural workers being crushed by the agricultural depression that gripped the nation.\n\nThe Sanhedrin was adjourned sine die on February 15, 1924.\n\nThe Negro Sanhedrin was the first national gathering of black Americans at which members of the Communist movement openly participated. In the view of one scholar, the Sanhedrin represented \"a grand opportunity for mainstream black organizations and black radicals to set aside their differences and formulate a program of mutual benefit.\" In this the Sanhedrin was a great failure, with the factional activities of the Communists in Chicago deeply resented and the organization banned from a subsequent and final gathering held in Washington, D.C.\n\nNor would the Sanhedrin movement be a successful or lasting vehicle for the coordination of activity by the myriad of mainstream black organizations, with momentum dissipating almost immediately after the close of the Chicago gathering.\n\n"}
{"id": "7099209", "url": "https://en.wikipedia.org/wiki?curid=7099209", "title": "Recursive recycling", "text": "Recursive recycling\n\nRecursive recycling is a technique where a function, in order to accomplish a task, calls itself with some part of the task or output from a previous step. In municipal solid waste and waste reclamation processing it is the process of extracting and converting materials from recycled materials derived from the previous step until all subsequent levels of output are extracted or used.\n\nSolid waste or municipal solid waste can be treated, sanitized and separated under steam in a pressure vessel (waste autoclave). Following the processing under steam and removal of toxic materials via condensate filtering, usable recyclables are immediately extracted for reuse (plastics, ferrous metals, aluminum, glass, wood, etc.).\n\nOrganic materials from the original waste stream are converted to a fiber using steam at 60 psi and 160 °C. The converted organics (sanitary fiber) is size reduced by 85% and can be used to produce bio-fuels using acidic-hydrolysis or enzymatic-hydrolysis as ethanol or may be used as refuse derived fuel.\n\nAfter the monosacrides are extracted for distillation, the remaining residue (used fiber) can be used as a feed stock for electricity production.\n\nFinally, the non-toxic ash from the combusted fiber can be collected and used as a filler for preparation in super concrete and then\nreused in combination with similar materials (gravel, stones, pottery, glass) to form aggregate for construction materials.\n\nIn true recursive recycling and conservation processing the ability to divert all materials in the waste stream from landfill at greater than 99 percent is a concept based on outputs used to provide the next level of processing, reuse, conservation and market delivery of the derivatives.\n\nThe concept of recursive recycling has been proved up in small scale facilities (thermal hydrolysis, plasma, etc.) but has not been widely accepted because of the financial impact it may have on existing protocols in waste management. One pilot facility operated commercially in Wales for approximately six years. However, the core equipment was moved to another location while the original facility was scheduled for retrofit. No further information about the facility's capacity or the equipment movement has been made available via open source release.\n\nSince that pilot commercial facility stopped operating, the concept of recursive recycling has not met with as much success as originally anticipated by environmentalists and conservationists. There are a number of companies operating autoclaves with limited success across the globe (the autoclave operating in Anaheim California was de-commissioned in c. late 2007-early 2008) but the full concept of waste treatment using thermal hydrolysis technology has not been fully realized because of several misconceptions in the autoclave and related steam treatment technologies. There is available engineering background to demonstrate successful testing that can be validated in physical production facilities but because of a lack of participation and general knowledge is a closely held secret, the application of technologies to achieve full recursive levels has not been accepted.\n\nA number of companies are working on technology to support this concept. That may bring about change to conservation and recycling when associated advances prove out as successful. However, given the current state related areas of technology the growth to full-scale production appears to be limited because the technology and demonstrating it is available in larger capacities has not been demonstrated commercially.\n"}
{"id": "4432542", "url": "https://en.wikipedia.org/wiki?curid=4432542", "title": "Renewable heat", "text": "Renewable heat\n\nRenewable heat is an application of renewable energy and it refers to the renewable generation of heat, rather than electrical power (e.g. replacing a fossil fuel boiler using concentrating solar thermal to feed radiators). Renewable heat technologies include renewable biofuels, solar heating, geothermal heating, heat pumps and heat exchangers to recover lost heat. Significant attention is also applied to insulation.\n\nMany colder countries consume more energy for heating than electrical power. For example, in 2005 the United Kingdom consumed 354 TWh of electric power, but had a heat requirement of 907 TWh, the majority of which (81%) was met using gas. The residential sector alone consumed a massive 550 TWh of energy for heating, mainly in the form of gas. Almost half of the final energy consumed in the UK (49%) was in the form of heat, of which 70% was used by households and in commercial and public buildings. Households used heat mainly for space heating (69%) and heating water.\n\nThe relative competitiveness of renewable electricity and renewable heat depends on a nation's approach to energy and environment policy. Few renewable technologies (whether for heat, electricity or transport) are competitive with fossil fuels without some form of carbon valuation or subsidy. In those countries, such as Sweden, Denmark and Finland, where government intervention has been closest to a technology-neutral form of carbon valuation (i.e. carbon and energy taxes), renewable heat has played the leading role in a very substantial renewable contribution to final energy consumption. In those countries, such as Germany, Spain, the USA, and the UK, where government intervention has been set at different levels for different technologies, uses and scales, the contributions of renewable heat and renewable electricity technologies have depended on the relative levels of support, and have resulted generally in a lower renewable contribution to final energy consumption.\n\nSolar heating is a style of building construction which uses the energy of summer or winter sunshine to provide an economic supply of primary or supplementary heat to a structure. The heat can be used for both space heating (see solar air heat) and water heating (see solar hot water). Solar heating design is divided into two groups:\nSolar heating systems usually require a small supplementary backup heating system, either conventional or renewable.\n\nGeothermal energy is accessed by drilling water or steam wells in a process similar to drilling for oil. Geothermal energy is an enormous, underused heat and power resource that is clean (emits little or no greenhouse gases), reliable (average system availability of 95%), and homegrown (making populations less dependent on oil).\n\nThe earth absorbs the sun's energy and stores it as heat in the oceans and underground. The ground temperature remains constant at a point of all year round depending on where you live on earth. A geothermal heating system takes advantage of the consistent temperature found below the Earth's surface and uses it to heat and cool buildings. The system is made up of a series of pipes installed underground, connected to pipes in a building. A pump circulates liquid through the circuit. In the winter the fluid in the pipe absorbs the heat of the earth and uses it to heat the building. In the summer the fluid absorbs heat from the building and disposes of it in the earth.\n\nHeat pumps use work to move heat from one place to another, and can be used for both heating and air conditioning. Though capital intensive, heat pumps are economical to run and can be powered by renewable electricity. Two common types of heat pump are air-source heat pumps (ASHP) and ground-source heat pumps (GSHP), depending on whether heat is transferred from the air or from the ground. Air source heat pumps are not effective when the outside air temperature is lower than about -15 °C, while ground-source heat pumps are not affected. The efficiency of a heat pump is measured by the coefficient of performance (CoP): For every unit of electricity used to pump the heat, an air source heat pump generates 2.5 to 3 units of heat (i.e. it has a CoP of 2.5 to 3), whereas a GSHP generates 3 to 3.5 units of heat. Based on current fuel prices for the United Kingdom, assuming a CoP of 3-4, a GSHP is sometimes a cheaper form of space heating than electric, oil, and solid fuel heating. Heat pumps can be linked to an interseasonal thermal energy storage (hot or cold), doubling the CoP from 4 to 8 by extracting heat from warmer ground.\n\nA heat pump with Interseasonal Heat Transfer combines active solar collection to store surplus summer heat in thermal banks with ground-source heat pumps to extract it for space heating in winter. This reduces the \"Lift\" needed and doubles the CoP of the heat pump because the pump starts with warmth from the thermal bank in place of cold from the ground.\n\nA heat pump CoP increases as the temperature difference, or \"Lift\", decreases between heat source and destination. The CoP can be maximized at design time by choosing a heating system requiring only a low final water temperature (e.g., underfloor heating), and by choosing a heat source with a high average temperature (e.g., the ground). Domestic hot water (DHW) and conventional radiators require high water temperatures, affecting the choice of heat pump technology. Low temperature radiators provide an alternative to conventional radiators.\n\nRenewable electricity can be generated by hydropower, solar, wind, geothermal and by burning biomass. In a few countries where renewable electricity is inexpensive, resistance heating is common. In countries like Denmark where electricity is expensive, it is not permitted to install electric heating as the main heat source. Wind turbines have more output at night when there is a small demand for electricity, storage heaters consume this lower cost electricity at night and give off heat during the day.\n\nWood-pellet heating and other types of wood heating systems have achieved their greatest success in heating premises that are off the gas grid, typically being previously heated using heating oil or coal. Solid wood fuel requires a large amount of dedicated storage space, and the specialized heating systems can be expensive (though grant schemes are available in many European countries to offset this capital cost.) Low fuel costs mean that wood fuelled heating in Europe is frequently able to achieve a payback period of less than 3 to 5 years. Because of the large fuel storage requirement wood fuel can be less attractive in urban residential scenarios, or for premises connected to the gas grid (though rising gas prices and uncertainty of supply mean that wood fuel is becoming more competitive.) There is also growing concern over the air pollution from wood heating versus oil or gas heat, especially the fine particulates.\n\nBurning wood fuel in an open fire is both extremely inefficient (0-20%) and polluting due to low temperature partial combustion. In the same way that a drafty building loses heat through loss of warm air through poor sealing, an open fire is responsible for large heat losses by drawing very large volumes of warm air out of the building.\n\nModern wood stove designs allow for more efficient combustion and then heat extraction. In the United States, new wood stoves are certified by the U.S. Environmental Protection Agency (EPA) and burn cleaner and more efficiently (the overall efficiency is 60-80%) and draw smaller volumes of warm air from the building.\n\n\"Cleaner\" should not, however, be confused with clean. An Australian study of real-life emissions from woodheaters satisfying the current Australian standard, found that particle emissions averaged 9.4 g/kg wood burned (range 2.6 to 21.7). A heater with average wood consumption of 4 tonnes per year therefore emits 37.6 kg of PM2.5, i.e. particles less than 2.5 micrometers. This can be compared with a passenger car satisfying the current Euro 5 standards (introduced September 2009) of 0.005 g/km. So one new wood heater emits as much PM2.5 per year as 367 passenger cars each driving 20,000 km a year. A recent European study identified PM2.5 as the most health-hazardous air pollutant, causing an estimated 492,000 premature deaths. The next worst pollutant, ozone, is responsible for 21,000 premature deaths.\n\nBecause of the problems with pollution, the Australian Lung Foundation recommends using alternative means for climate control. The American Lung Association \"strongly recommends using cleaner, less toxic sources of heat. Converting a wood-burning fireplace or stove to use either natural gas or propane will eliminate exposure to the dangerous toxins wood burning generates including dioxin, arsenic and formaldehyde.\n\n\"Renewable\" should not be confused with \"greenhouse neutral\". A recent peer-reviewed paper found that, even if burning firewood from a sustainable supply, methane emissions from a typical Australian wood heater satisfying the current standard cause more global warming than heating the same house with gas. However, because a large proportion of firewood sold in Australia is not from sustainable supplies, Australian households that use wood heating often cause more global warming than heating three similar homes with gas.\n\nHigh efficiency stoves should meet the following design criteria:\n\nRenewable natural gas is defined as gas obtained from biomass which is upgraded to a quality similar to natural gas. By upgrading the quality to that of natural gas, it becomes possible to distribute the gas to customers via the existing gas grid. According to the Energy research Centre of the Netherlands, renewable natural gas is 'cheaper than alternatives where biomass is used in a combined heat and power plant or local combustion plant'. Energy unit costs are lowered through 'favourable scale and operating hours', and end-user capital costs eliminated through distribution via the existing gas grid.\n\nRenewable heat goes hand in hand with energy efficiency. Indeed, renewable heating projects depend heavily for their success on energy efficiency; in the case of solar heating to cut reliance on the requirement supplementary heating, in the case of wood fuel heating to cut the cost of wood purchased and volume stored, and in the case of heat pumps to reduce the size and investment in heat pump, heat sink and electricity costs.\n\nTwo main types of improvement can be made to a building's energy efficiency:\n\nImprovements to insulation can cut energy consumption greatly, making a space cheaper to heat and to cool. However existing housing can often be difficult or expensive to improve. Newer buildings can benefit from many of the techniques of superinsulation. Older buildings can benefit from several kinds of improvement:\n\n\nUnderfloor heating may sometimes be more energy efficient than traditional methods of heating:\n\n\nIt is possible to recover significant amounts of heat from waste hot water via hot water heat recycling. Major consumption of hot water is sinks, showers, baths, dishwashers, and clothes washers. On average 30% of a property's domestic hot water is used for showering. Incoming fresh water is typically of a far lower temperature than the waste water from a shower. An inexpensive heat exchanger recovers up on average 40% of the heat that would normally be wasted, by warming incoming cold fresh water with heat from outgoing waste water.\n\n"}
{"id": "1047205", "url": "https://en.wikipedia.org/wiki?curid=1047205", "title": "Saudade", "text": "Saudade\n\nSaudade (; , or , ; plural saudades) is a deep emotional state of nostalgic or profound melancholic longing for an absent something or someone that one loves. Moreover, it often carries a repressed knowledge that the object of longing might never return. One English translation of the word is missingness, although it might not convey the feeling of deep emotion attached to the word \"saudade\". Stronger forms of \"saudade\" might be felt towards people and things whose whereabouts are unknown, such as a lost lover, or a family member who has gone missing, moved away, separated, or died.\n\n\"Saudade\" was once described as \"the love that remains\" after someone is gone. \"Saudade\" is the recollection of feelings, experiences, places, or events that once brought excitement, pleasure, well-being, which now triggers the senses and makes one live again. It can be described as an emptiness, like someone (e.g., one's children, parents, sibling, grandparents, friends, pets) or something (e.g., places, things one used to do in childhood, or other activities performed in the past) that should be there in a particular moment is missing, and the individual feels this absence. It brings sad and happy feelings together: sadness for missing and happiness for experiencing the past.\n\nNascimento and Meandro (2005) cite Duarte Nunes Leão's definition of saudade: \"Memory of something with a desire for it.\"\n\nIn Brazil, the day of \"Saudade\" is officially celebrated on 30 January.\n\nThe word \"saudade\" was used in the Cancioneiro da Ajuda (13th century), in the Cancioneiro da Vaticana and by poets of the time of King Denis of Portugal (reigned 1279–1325).\nSome specialists say the word may have originated during the Great Portuguese Discoveries, giving meaning to the sadness felt about those who departed on journeys to unknown seas and disappeared in shipwrecks, died in battle, or simply never returned. Those who stayed behind—mostly women and children—suffered deeply in their absence. However, the Portuguese discoveries only started in 1415 and since the word has been found in earlier texts, this does not constitute a very good explanation. The Reconquista also offers a plausible explanation.\n\nThe state of mind has subsequently become a \"Portuguese way of life\": a constant feeling of absence, the sadness of something that's missing, wishful longing for completeness or wholeness and the yearning for the return of what is now gone, a desire for presence as opposed to absence—as it is said in Portuguese, a strong desire to \"matar as saudades\" (lit. \"to kill the saudades\").\n\nIn the latter half of the 20th century, \"saudade\" became associated with the longing for one's homeland, as hundreds of thousands of Portuguese-speaking people left in search of better futures in South America, North America, and Western Europe. Besides the implications derived from a wave of emigration trend from the motherland, historically speaking \"saudade\" is the term associated with the decline of Portugal's role in world politics and trade. During the so-called \"Golden Age\", synonymous with the era of discovery, Portugal rose to the status of a world power, and its monarchy became one of the richest in Europe. But with the competition from other European nations, the country went both colonially and economically into a prolonged period of decay. This period of decline and resignation from the world's cultural stage marked the rise of \"saudade\", aptly described by a sentence in Portugal's national anthem: \"Levantai hoje de novo o esplendor de Portugal\" (Lift up once again today the splendour of Portugal).\n\nThe \"Dicionário Houaiss da Língua Portuguesa\" defines \"saudade\" (or \"saudades\") as \"A somewhat melancholic feeling of incompleteness. It is related to thinking back on situations of privation due to the absence of someone or something, to move away from a place or thing, or to the absence of a set of particular and desirable experiences and pleasures once lived.\"\n\nThe Dictionary from the Royal Galician Academy, on the other hand, defines \"saudade\" as an \"intimate feeling and mood caused by the longing for something absent that is being missed. This can take different aspects, from concrete realities (a loved one, a friend, the motherland, the homeland...) to the mysterious and transcendent. It is quite prevalent and characteristic of the galician-portuguese world, but it can also be found in other cultures.\"\n\nSaudade is a word in Portuguese and Galician that claims no direct translation in English. In Portuguese, \"\"Tenho saudades tuas\" (European Portuguese) or \"Estou com saudades de ti/você\"\" (Brazilian Portuguese), translates as \"I have (feel) \"saudade\" of you\" meaning \"I miss you\", but carries a much stronger tone. In fact, one can have \"saudade\" of someone whom one is with, but have some feeling of loss towards the past or the future. For example, one can have \"saudade\" towards part of the relationship or emotions once experienced for/with someone, though the person in question is still part of one's life, as in \"Tenho saudade do que fomos\" (I feel \"saudade\" of the way we were). Another example can illustrate this use of the word saudade: \"Que saudade!\" indicating a general feeling of longing, whereby the object of longing can be a general and undefined entity/occasion/person/group/period etc. This feeling of longing can be accompanied or better described by an abstract will to be where the object of longing is.\n\nDespite being hard to translate in full, \"saudade\" has equivalent words in other cultures, and is often related to music styles expressing this feeling such as the \"blues\" for African-Americans, \"Sehnsucht\" in German, \"dor\" in Romania, \"Tizita\" in Ethiopia, \"Hiraeth\" in Welsh, or \"Assouf\" for the Tuareg people, appocundria in Neapolitan. In Slovak, the word is \"clivota\" or \"cnenie\", and in Czech, the word is \"stesk\". In Turkish, the word \"Hasret\" meaning longing, yearning or nostalgia has similar connotations.\n\nThe similar melancholic music style is known in Bosnia-Herzegovina as sevdah (ultimately from Arabic سَوْدَاء sawdā' : 'black [bile]', translation of the Greek µέλαινα χολή, mélaina cholē from which the term melancholy is derived).\n\n\"Saudade\" is similar but not equal to nostalgia, a word that also exists in Portuguese.\n\nIn the book \"In Portugal\" of 1912, A. F. G. Bell writes: \n\nA stronger form of \"saudade\" may be felt towards people and things whose whereabouts are unknown, such as old ways and sayings; a lost lover who is sadly missed; a faraway place where one was raised; loved ones who have died; feelings and stimuli one used to have; and the faded, yet golden memories of youth. Although it relates to feelings of melancholy and fond memories of things/people/days gone by, it can be a rush of sadness coupled with a paradoxical joy derived from acceptance of fate and the hope of recovering or substituting what is lost by something that will either fill in the void or provide consolation.\n\nTo F. D. Santos, \"Saudade\" as a noun has become a longing for longing itself: \n\nAs with all emotions, \"saudade\" has been an inspiration for many songs and compositions. \"Sodade\" (\"saudade\" in Cape Verdean Creole) is the title of the Cape Verde singer Cesária Évora's most famous song. Étienne Daho, a French singer, also produced a song of the same name. \"The Good Son\", a 1990 album by Nick Cave and the Bad Seeds, was heavily informed by Cave's mental state at the time, which he has described as \"saudade\". He told journalist Chris Bohn: \"When I explained to someone that what I wanted to write about was the memory of things that I thought were lost for me, I was told that the Portuguese word for this feeling was \"saudade\". It's not nostalgia but something sadder.\"\nThe usage of \"saudade\" as a theme in Portuguese music goes back to the 16th century, the golden age of Portugal. \"Saudade\", as well as love suffering, is a common theme in many villancicos and cantigas composed by Portuguese authors; for example: \"Lágrimas de Saudade\" (\"tears of saudade\"), which is an anonymous work from the \"Cancioneiro de Paris\". Fado is a Portuguese music style, generally sung by a single person (the \"fadista\") along with a Portuguese guitar. The most popular themes of fado are \"saudade\", nostalgia, jealousy, and short stories of the typical city quarters. Fado and \"saudade\" are intertwined key ideas in Portuguese culture. The word fado comes from Latin \"fatum\" meaning \"fate\" or \"destiny\". Fado is a musical cultural expression and recognition of this unassailable determinism which compels the resigned yearning of \"saudade\", a bitter-sweet, existential yearning and hopefulness towards something over which one has no control.\n\nSpanish singer Julio Iglesias, whose father is a Galician, speaks of \"saudade\" in his song \"Un Canto a Galicia\" (which roughly translates as \"a song/chant for Galicia\"). In the song, he passionately uses the phrase to describe a deep and sad longing for his motherland, Galicia. He also performs a song called \"Morriñas\", which describes the Galicians as having a deeply strong \"saudade\".\n\nThe Paraguayan guitarist Agustin Barrios wrote several pieces invoking the feeling of \"saudade\", including \"Choro de Saudade\" and \"Preludio Saudade\". The term is prominent in Brazilian popular music, including the first bossa nova song, \"Chega de Saudade\" (\"No more \"saudade\"\", usually translated as \"No More Blues\"), written by Tom Jobim.\nJazz pianist Bill Evans recorded the tune \"Saudade de Brasil\" numerous times. In 1919, on returning from two years in Brazil, the French composer Darius Milhaud composed a suite, \"Saudades do Brasil\", which exemplified the concept of \"saudade\". \"Saudade (Part II)\" is also the title of a flute solo by the band Shpongle. The singer Amália Rodrigues typified themes of \"saudade\" in some of her songs. J-Rock band Porno Graffitti has a song entitled \"サウダージ\", \"Saudaaji\" transliterated (\"Saudade\"). The alternative rock band Love And Rockets has a song named \"Saudade\" on their album \"Seventh Dream of Teenage Heaven\". June 2012 brought Bearcat's release of their self-titled indie album that included a song called \"Saudade\".\n\nThe Dutch jazz/Rock guitarist Jan Akkerman recorded a composition called \"Saudade\", the centerpiece of his 1996 album \"Focus in Time\". The Belgian electronic music band Arsenal recorded a song called \"Saudade\" on their album \"Outsides\" (2005). The jazz fusion group Trio Beyond, consisting of John Scofield, Jack DeJohnette, and Larry Goldings released in 2006 an album dedicated to drummer Tony Williams (1945–1997), called \"Saudades\". Dance music artist Peter Corvaia released a progressive house track entitled \"Saudade\" on HeadRush Music, a sub-label of Toes in the Sand Recordings. New York City post-rock band Mice Parade released an album entitled \"Obrigado Saudade\" in 2004. Chris Rea also recorded a song entitled \"Saudade Part 1 & 2 (Tribute To Ayrton Senna)\" as a tribute to Ayrton Senna, the Brazilian three-times Formula One world champion killed on the track in May 1994. There is an ambient/noise/shoegazing band from Portland, Oregon, named Saudade. The rock band Extreme has a Portuguese guitarist Nuno Bettencourt; the influence of his heritage can be seen in the band's album \"Saudades de Rock\". During recording, the mission statement was to bring back musicality to the medium. \"Nancy Spain\", a song by Barney Rush, made famous by an adaptation by Christy Moore, is another example of the use of \"saudade\" in contemporary Irish music, the chorus of which is:\n\n\"No matter where I wander I'm still haunted by your name\nThe portrait of your beauty stays the same\nStanding by the ocean wondering where you've gone\nIf you'll return again\nWhere is the ring I gave to Nancy Spain?\"\nAmerican singer/songwriter Grayson Hugh wrote a song called \"Saudade\" that he performed with jazz guitarist Norman Johnson on Johnson's 2013 album \"Get It While You Can\". \n\nKingston-Upon-Hull IDM Electronica, Downtempo and Deep Groove legend, Steve Cobby, of Fila Brazillia, Solid Doctor, Heights of Abraham, the Twilight Singers debut notoriety and other musical incarnations and collaborations, released a 12 track album \" Saudade\" in March 2014 on DÉCLASSÉ Recordings.\n\nThe Portuguese author Fernando Pessoa's posthumous collection of writings \"The Book of Disquiet\" is written almost entirely in a tone of saudade, and deals with themes of nostalgia and alienation. Australian author Suneeta Peres Da Costa's novella \"Saudade\" follows Maria, a young girl from a Goan immigrant family, growing up in a political hierarchy of racism and colonialism\n\n\"Saudade\" is also associated with Galicia, where it is used similarly to the word \"morriña\" (longingness). Yet, morriña often implies a deeper stage of \"saudade\", a \"\"saudade\" so strong it can even kill,\" as the Galician saying goes. Morriña was a term often used by emigrant Galicians when talking about the Galician motherland they left behind. Although \"saudade\" is also a Galician word, the meaning of \"longing for something that might return\" is generally associated with \"morriña\". A literary example showing the understanding of the difference and the use of both words is the song \"Un canto a Galicia\" by Julio Iglesias. The word used by Galicians speaking Spanish has spread and become common in all Spain and even accepted by the Academia.\n\nIn Portugal, \"morrinha\" is a word to describe sprinkles, while \"morrinhar\" means \"to sprinkle.\" (The most common Portuguese equivalents are \"chuvisco\" and \"chuviscar\", respectively.) \"Morrinha\" is also used in northern Portugal for referring to sick animals, for example of sheep dropsy, and occasionally to sick or sad people, often with irony. It is also used in some Brazilian regional dialects for the smell of wet or sick animals.\n\nIn Goa, India, which was a Portuguese colony until 1961, some Portuguese influences still remain. A suburb of Margão, Goa's largest city, has a street named Rua de Saudades. It was aptly named because that very street has the Christian cemetery, the Hindu \"shmashana\" (cremation ground) and the Muslim \"qabrastan\" (cemetery). Most people living in the city of Margão who pass by this street would agree that the name of the street could not be any other, as they often think fond memories of a friend, loved one, or relative whose remains went past that road. The word \"saudade\" takes on a slightly different form in Portuguese-speaking Goan families for whom it implies the once-cherished but never-to-return days of glory of Goa as a prized possession of Portugal, a notion since then made redundant by the irrevocable cultural changes that occurred with the end of the Portuguese regime in these parts.\n\nIn Cape Verdean Creole there is the word \"sodadi\" (also spelled \"sodade\"), originated in the Portuguese \"saudade\" and exactly with the same meaning.\n\n\n\n"}
{"id": "17091242", "url": "https://en.wikipedia.org/wiki?curid=17091242", "title": "Self-schema", "text": "Self-schema\n\nThe self-schema refers to a long lasting and stable set of memories that summarize a person's beliefs, experiences and generalizations about the self, in specific behavioral domains. A person may have a self-schema based on any aspect of himself or herself as a person, including physical characteristics, personality traits and interests, as long as they consider that aspect of their self important to their own self-definition.\n\nFor example, someone will have an extroverted self-schema if they think of themselves as extroverted and also believe that their extroversion is central to who they are. Their self-schema for extroversion may include general self-categorizations (\"I am sociable.\"), beliefs about how they would act in certain situations (\"At a party I would talk to lots of people\") and also memories of specific past events (\"On my first day at university I made lots of new friends\").\n\nThe term schematic describes having a particular schema for a particular dimension. For instance, a person in a rock band at night would have a \"rocker\" schema. However, during the day, if he works as a salesperson, he would have a \"salesperson\" schema during that period of time. Schemas vary according to cultural background and other environmental factors.\n\nOnce people have developed a schema about themselves, there is a strong tendency for that schema to be maintained by a bias in what they attend to, in what they remember, and in what they are prepared to accept as true about themselves. In other words, the self-schema becomes self-perpetuating. The self-schema is then stored in long-term memory, which both facilitates and biases the processing of personally relevant information. Individuals who form a self-schema of a person with good exercise habits will then in return exercise more frequently.\n\nThe term aschematic means not having a schema for a particular dimension. This usually occurs when people are not involved with or concerned about a certain attribute. For example, if a person plans on being a musician, a self-schema in aeronautics will not apply to him; he is aschematic on aeronautics.\n\nSelf-schemas vary from person to person because each individual has very different social and cultural life experiences. A few examples of self-schemas are: \"exciting\" or \"dull\"; \"quiet\" or \"loud\"; \"healthy\" or \"sickly\"; \"athletic\" or \"nonathletic\"; \"lazy\" or \"active\"; and \"geek\" or \"jock\". If a person has a schema for \"geek or jock,\" for example, he might think of himself as a bit of a computer geek and would possess a lot of information about that trait. Because of this, he would probably interpret many situations based on relevance to his being a computer geek.\n\nAnother person with the \"healthy or sickly\" schema might consider themselves a very health conscious person. Their concern with being healthy would then affect everyday decisions such as what groceries they buy, what restaurants they frequent, or how often they exercise. Women who are schematic on appearance exhibited lower body image, lower self-esteem, and more negative mood than did those who are aschematic on appearance.\n\nEarly in life, we are exposed to the idea of the self from our parents and other figures. We begin to take on a very basic self-schema, which is mostly limited to a \"good child\" or \"bad child\" schema—that is, we see ourselves in unambiguously positive or negative terms. It is in childhood that we begin to offer explanations for our actions, which reasoning creates the more complicated concept of the self: a child will begin to believe that the self caused his or her behaviors, deciding on what motivations to offer as explanations of behavior.\n\nMost people have multiple self-schemas, however this is not the same as multiple personalities in the pathological sense. Indeed, for the most part, multiple self-schemas are extremely useful to people in daily life. Subconsciously, they help people make rapid decisions and behave efficiently and appropriately in different situations and with different people. Multiple self-schemas guide what people attend to and how people interpret and use incoming information. They also activate specific cognitive, verbal, and behavioral action sequences – called \"scripts\" and \"action plans\" in cognitive psychology – that help people meet goals efficiently.\nSelf-schemas vary not only by circumstances and who the person is interacting with, but also by mood. Researchers found that we have mood-congruent self-schemas that vary with our emotional state.\n\nThe self's relationship with and understanding of the body is an important part of self-schema. Body schema is a general term that has multiple definitions in various disciplines. Generally, it refers to a person's concept of his or her own body, where it is in space, what it looks like, how it is functioning, etc.\n\nOur body image is part of our self-schema. The body image includes the following:\n\nOur body schemata may transcend the realities of what our bodies actually are—or in other words, we may have a different mental picture of our bodies than what they physically are. This is evidenced when individuals who lose limbs have phantom limb sensations. Individuals who lose a limb may still feel like they have that limb. They may even feel in that limb sensations from other limbs.\n\nOver the years, the emphasis on sex as a means of predicting the emergence of neurosis has shifted to finding the developmental influence that sex has on personality. This new focus is on the balance between the capacity for sexual pleasure and the establishment of intimate relationships. The assumption here is that to the extent that an individual uses sexuality, one's sexual nature will be experienced as more or less central to one's identity.\n\nSchemas can be viewed as a cognitive framework that organizes the relationship between external social stimuli and one's behavioral reactions. Thus, there are cognitive representations of the self that become active within specific contexts. Sexual schema is defined as a cognitive generalization about the sexual aspects of the self. This view is derived from past experience, manifested in current experience, influential in the processing of sexually relevant social information, and gives guidance for sexual behavior. Women and men experience sexual self-schema in their own ways.\n\nWomen's sexual schema is composed of two positive aspects: the romantic-passionate and the open-direct self-views, and one negative aspect: embarrassment or conservative self-view. Women with a positive sexual schema tend to view themselves as: emotionally romantic or passionate, open to romantic and sexual relationships and experiences, liberal in their sexual attitudes and free of social inhibitions, evaluating sexual behavior more positively, more likely to engage in uncommitted sex and (one-night) sexual encounters, and more likely to anticipate more sexual partners in the future. Although they might seem very unrestricted, they also are more likely to have romantic ties or partners, and more likely to value romantic, loving, intimate attachments. On the other hand, women with negative sexual self-schema tend to view themselves as emotionally cold and unromantic, behaviorally inhibited in their sexual and romantic relationships, very conservative, and not confident in a variety of social and sexual contexts.\n\nMen's sexual schema can be described along a spectrum from being schematic to aschematic. Schematic men tend to view themselves as powerful and aggressive, open minded and liberal in their sexual attitudes, unquestionably more sexually experienced, and they tend to have a high frequency of sexual relationships, many of which occur without any commitment. In the same way as a woman with a positive sexual schema, these men are capable of feeling romantic love and passion. They are more likely to be in a relationship and to fall in love. Being single is usually just a temporary occurrence. On the other hand, aschematic men have a narrower range of sexual activities, they are most likely to be single, and the majority believes that situation will not change in the near future.\n\nBoth men and women believe that a sexual person is someone who is sexual, but who can also display romantic, passionate, arousable, and loving qualities in order to establish intimate relationships.\n\nIndividuals afflicted with both physical and mental illness have more negative self-schemata. This has been documented in patients suffering from such illnesses as depression and irritable bowel syndrome. Sufferers tend to identify themselves with their illness, unconsciously associating the negative traits of the illness itself with themselves.\n\n\n"}
{"id": "31280414", "url": "https://en.wikipedia.org/wiki?curid=31280414", "title": "Social identity approach", "text": "Social identity approach\n\nThe term social identity approach refers to research and theory pertaining to two intertwined, but distinct, social psychological theories. These being: social identity theory and self-categorization theory. The social identity approach has been applied to a wide variety of fields and continues to be very influential. There is a high citation rate for key social identity papers and that rate continues to increase.\n\nThe term \"social identity approach\" arose as an attempt to mitigate against the tendency to conflate the two theories, as well as the tendency to mistakenly believe one theory to be a component of the other. Instead these theories should be thought of as overlapping in the manner demonstrated in Fig 1. That is, while there are similarities, self categorisation theory has greater explanatory scope (i.e. is less focused on intergroup relationships specifically) and has been investigated in a broader range of empirical conditions. Self-categorization theory can also be thought of as developed to address limitations of social identity theory. Specifically the limited manner in which social identity theory deals with the cognitive processes that underpin the behaviour it describes.\n\nAlthough this term may be useful when contrasting broad social psychological movements, when applying either theory it is thought of as beneficial to distinguish carefully between the two theories in such a way that their specific characteristics can be retained.\n\nThe social identity approach has been contrasted with the social cohesion approach when it comes to defining social groups. The social identity approach describes the state of people thinking of themselves and others as a group. Therefore three intrapsychological processes proceed. Firstly, social categorization (see self-categorization theory) means that people organize social information by categorizing people into groups. Secondly, social comparison (see social comparison theory) means that people give a meaning to those categories in order to understand the task of the group in the specific situation. Thirdly, social identification is the process in which people relate the self to one of those categories.\n\nRegarding the relation between collective identification and work motivation, several propositions have been made regarding situational influences, the acceptance of the leader and the self-definition of a collective. As a situational influence, research says that individuals are activated by situations that challenge their inclusion to the group. The acceptance of the leader is another proposition. The so-called ingroup-favoring-bias (see in-group favoritism) means that if the team leader is interpreted as an ingroup member, the other team members will attribute his or her good behavior internally while they will attribute bad behavior externally. For self-definition of a collective the value of the group as well as the belief in current and future success is important. Closely linked to self-definition to a collective, cohesion is another construct that has an impact on the development of group motivation and in a broader sense also to the group performance.\n\nOn the topic of social groups, some social psychologists draw a distinction between different types of group phenomenon. Specifically, \"those that derive from interpersonal relationships and interdependence with specific others and those that derive from membership in larger, more impersonal collectives or social categories\". The social identity approach however does not anticipate this distinction. Instead it anticipates that the same psychological processes underlie intergroup and intragroup phenomenon involving both small and large groups. Relatedly, the persistent perception that the social identity approach is only relevant to large group phenomenon has led some social identity theorists to specifically reassert (both theoretically and empirically) the relevance of the social identity approach to small group interactions.\n\nAccording to the social identity approach, leadership is a function of the group instead of the individual. Individuals who are leaders in their groups tend to be closer to the prototypical group member than are followers. Additionally, they tend to be more socially attractive, which makes it easier for group members to accept their authority and comply with their decisions. Finally, leaders tend to be viewed by others as the leader. In this final distinction, group members attribute leadership traits to the person and not the situation, furthering the distinction between the leader and others in the group by viewing him or her as special. Consistent with this view of leadership, researchers have found that individuals can manipulate their own leadership status in groups by portraying themselves as prototypical to the group.\n\nSocial identity concepts have been applied to economics resulting in what is now known as identity economics. For example, two separate papers and a book by Akerlof and Kranton incorporate social identity as a factor in the principal–agent model. The main conclusion is that when agents consider themselves insiders, they will maximize their identity utility by exerting greater effort compared to the prescription behavior. On the other hand, if they consider themselves outsiders, they will require a higher wage to compensate their loss for behavior difference with prescribed behaviors.\n\nThe social identity model of deindividuation effects (SIDE) was developed from further research on the social identity theory and the self-categorization theory, further specifying the effects of situational factors on the functioning of processes proposed by the two theories. The SIDE model uses this framework to explain cognitive effects of visibility and anonymity in intra-group and inter-group contexts. The model is based on the idea that the self-concept is flexible and different in different situations or contexts. The theory consists of a range of different self-categories that define people as unique individuals or in terms of their membership to specific social groups and other, broader social categories based on the context of the situation. The SIDE model proposes that anonymity shifts both the focus of self-awareness from the individual self to the group self and the perceptions of others from being mostly interpersonal to being group-based (stereotyping).\n\nResearch has suggested that visual anonymity not only increases negative behavior towards others, but can also promote positive social relations. In one study, all volunteers participated individually in group discussion based on three different topics. In the visually anonymous condition, all communications between participants were text-based while in the visually identifiable condition, the communication was also supplemented by two-way video cameras. The study resulted in the findings that showed anonymity significantly increased group attraction.\n\nIntergroup emotion theory further expands on the concept of personally significant group memberships as posed by social identity and self-categorization theories. This theory is primarily based on the concept of depersonalization and the interchangeability of the self with other ingroup members. This causes cognitive representations of the self and the group to become inevitably connected, and therefore the group obtains an emotional significance. This means that individuals not only categorize themselves as members of the ingroup but also \"react emotionally when situations or events affect the ingroup\". For example, people often report that their group is being discriminated against, even though they feel that they personally are not subject to that discrimination.\n\nSome researchers have claimed that the majority of results in research using the minimal group paradigm can be derived from self-interest and interdependence and that this poses a serious problem for social identity theory and self-categorization theory, and in particular self-categorization theory's account of social groups. Social identity researchers have responded by suggesting that the interdependence centric analysis that has been proposed as an alternative is inconsistent and still relies heavily on the social categorization processes detailed in self-categorization theory. Moreover, they argue that researchers making the above criticisms have also significantly misinterpreted the role of sociological categories in the two theories.\n"}
{"id": "10324227", "url": "https://en.wikipedia.org/wiki?curid=10324227", "title": "Soul dualism", "text": "Soul dualism\n\nSoul dualism or multiple souls is a range of beliefs that a person has two or more kinds of souls. In many cases, one of the souls is associated with body functions (\"body soul\") and the other one can leave the body (\"free soul\" or \"wandering soul\"). Sometimes the plethora of soul types can be even more complex. Sometimes, a shaman's \"free soul\" may be held to be able to undertake a spirit journey.\n\nThe belief in soul dualism found throughout most Austronesian shamanistic traditions. The reconstructed Proto-Austronesian word for the \"body soul\" is \"*nawa\" (\"breath\", \"life\", or \"vital spirit\"). It is located somewhere in the abdominal cavity, often in the liver or the heart (Proto-Austronesian \"*qaCay\"). The \"free soul\" is located in the head. Its names are usually derived from Proto-Austronesian \"*qaNiCu\" (\"ghost\", \"spirit [of the dead]\"), which also apply to other non-human nature spirits. The \"free soul\" is also referred to in names that literally mean \"twin\" or \"double\", from Proto-Austronesian \"*duSa\" (\"two\"). A virtuous person is said to be one whose souls are in harmony with each other, while an evil person is one whose souls are in conflict.\n\nThe \"free soul\" is said to leave the body and journey to the spirit world during sleep, trance-like states, delirium, insanity, and death. The duality is also seen in the healing traditions of Austronesian shamans, where illnesses are regarded as a \"soul loss\" and thus to heal the sick, one must \"return\" the \"free soul\" (which may have been stolen by an evil spirit or got lost in the spirit world) into the body. If the \"free soul\" can not be returned, the afflicted person dies or goes permanently insane.\n\nIn some ethnic groups, there can also be more than two souls. Like among the Tagbanwa people, where a person is said to have six souls - the \"free soul\" (which is regarded as the \"true\" soul) and five secondary souls with various functions.\n\nTraditional Chinese culture differentiates two \"hun\" and \"po\" spirits or souls, which correlate with \"yang\" and \"yin\" respectively. Within this soul dualism, every human has both an ethereal \"hun\" \"spiritual soul; spirit; mood\" that leaves the body after death and a substantive \"po\" \"physical soul; spirit; vigor\" that remains with the corpse. Chinese traditions differ over the number of \"hun\" and \"po\" souls in a person, for example, Daoism has the \"sanhunqipo\" 三魂七魄 \"three \"hun\" and seven \"po\"\".\n\nKalbo Inuit groups believe that a person has more than one type of soul. One is associated with respiration, the other can accompany the body as a shadow. Soul concepts of different Inuit groups are diverse; they are not alike. In some cases, it is connected to shamanistic beliefs among the various Inuit groups. Also Caribou Inuit groups believed in several types of souls.\n\nThe concept of more kinds of souls can be found also at several Finno-Ugric peoples. See notion of shadow-soul (being able to depart freely the body), e.g. in Hungarian folk beliefs. The concept of a dualistic shadow-soul called \"itse\", related to the Hungarian conception, is also part of Finnish and general Baltic-Finnic folklore. The Estonian soul concept has been approached by several authors, some of them using rather complex frameworks (online ).\n\n\n\n\n"}
{"id": "5991000", "url": "https://en.wikipedia.org/wiki?curid=5991000", "title": "Spanish customary units", "text": "Spanish customary units\n\nThere are a number of Spanish units of measurement of length or area that are now virtually obsolete (due to metrication). They include the vara, the cordel, the league and the labor. The units of area used to express the area of land are still encountered in some transactions in land today. For example, the 'vara' is still used in Costa Rica when ordering lumber.\n\nA vara (meaning \"rod\" or \"pole\", abbreviation: var) is an old Spanish unit of length. Varas are a surveying unit that appear in many deeds in the southern United States, and varas were also used in many parts of Latin America. It varied in size at various times and places; the Spanish unit was set at about in 1801. In Argentina, the vara measured about , and typical urban lots are wide (10 Argentine varas). At some time a value of was adopted in California.\n\nIn Texas, a vara was defined as , or 1 yard = 1.08 vara. The vara and the corresponding unit of area, the square vara, were introduced in the 19th century to measure Spanish land grants. In Texas, Stephen F. Austin's early surveying contracts required that he use the vara as a standard unit. The vara can be seen in many deeds as late as the mid to late 1900s. is equivalent to 5,645.376 Texan square varas. A league is equivalent to 5,000 varas squared or .\n\nTo convert varas to feet, take the varas and divide by 0.36.\n\nStandardization of measurement in Texas came with the introduction of varas, cordels, and leagues.\n\nA measure of 100 varas by 100 varas (Spanish) is almost 7000 square meters, and is known traditionally throughout Latin America as a \"manzana\" (\"i.e.\", a \"city block\"). As well, lumber is still measured in Costa Rica using a system based on 4 vara, or 11 feet, for both round and square wood. With square wood, using inches, the width is multiplied by the depth to get a measurement which they call \"pulgadas\", or inches. The lumber is charged 'per inch', which is a measurement 11/12 of a board foot.\n\nA labor ( in West Texas) is a unit of area, used to express the area of land, that is equal to 1 million square varas. A labor is equivalent to about . It was used in the archaic system of old Spanish land grants affecting Texas and parts of adjoining states. The labor is often used as an approximate equivalent to a \"quarter-section\" (that is, one quarter of a square mile of land). It is still encountered in modern real estate transactions.\n\nA league can also be a unit of area, used to express the area of land, that is equal to 25 million square varas. A (square) league is equivalent to about . It was used in the archaic system of old Spanish land grants affecting Texas and parts of adjoining states and this use of league is used throughout the Texas Constitution.\n\nA common Texas land grant size, discussed in James A. Michener's \"Texas\", was a \"labor and a league:\" a labor of good riparian land and a (square) league of land away from the river.\n\nThe (square) league is still encountered in modern real estate transactions.\n\nThe \"palmo\" (\"palm\") measured the distance between the tip of the thumb and the tip of the pinky finger with all fingers splayed. Its standardized value is (9 \"pulgadas\"). Half of a palmo in Castile was called the \"coto\", described as six fingers and defined as . The ancient Romans had a similar, smaller unit called the \"palmus\", which was .\n\nAlthough some standardisation was achieved with the law of 1801, particularly in defining the league as 6666⅔ \"varas\" long, varying measures continued to be used in various cities and regions.\n\n\n"}
{"id": "627964", "url": "https://en.wikipedia.org/wiki?curid=627964", "title": "Survival of the fittest", "text": "Survival of the fittest\n\n\"Survival of the fittest\" is a phrase that originated from Darwinian evolutionary theory as a way of describing the mechanism of natural selection. The biological concept of fitness is defined as reproductive success. In Darwinian terms the phrase is best understood as \"Survival of the form that will leave the most copies of itself in successive generations.\"\n\nHerbert Spencer first used the phrase, after reading Charles Darwin's \"On the Origin of Species\", in his \"Principles of Biology\" (1864), in which he drew parallels between his own economic theories and Darwin's biological ones: \"This survival of the fittest, which I have here sought to express in mechanical terms, is that which Mr. Darwin has called 'natural selection', or the preservation of favoured races in the struggle for life.\"\n\nDarwin responded positively to Alfred Russel Wallace's suggestion of using Spencer's new phrase \"survival of the fittest\" as an alternative to \"natural selection\", and adopted the phrase in \"The Variation of Animals and Plants under Domestication\" published in 1868. In \"On the Origin of Species\", he introduced the phrase in the fifth edition published in 1869, intending it to mean \"better designed for an immediate, local environment\".\n\nHerbert Spencer first used the phrase – after reading Charles Darwin's \"On the Origin of Species\" – in his \"Principles of Biology\" of 1864 in which he drew parallels between his economic theories and Darwin's biological, evolutionary ones, writing, \"This survival of the fittest, which I have here sought to express in mechanical terms, is that which Mr. Darwin has called 'natural selection', or the preservation of favored races in the struggle for life.\"\n\nIn July 1866 Alfred Russel Wallace wrote to Darwin about readers thinking that the phrase \"natural selection\" personified nature as \"selecting\", and said this misconception could be avoided \"by adopting Spencer's term\" \"Survival of the fittest\". Darwin promptly replied that Wallace's letter was \"as clear as daylight. I fully agree with all that you say on the advantages of H. Spencer's excellent expression of 'the survival of the fittest'. This however had not occurred to me till reading your letter. It is, however, a great objection to this term that it cannot be used as a substantive governing a verb\". Had he received the letter two months earlier, he would have worked the phrase into the fourth edition of the \"Origin\" which was then being printed, and he would use it in his \"next book on Domestic Animals etc.\".\n\nDarwin wrote on page 6 of \"The Variation of Animals and Plants under Domestication\" published in 1868, \"This preservation, during the battle for life, of varieties which possess any advantage in structure, constitution, or instinct, I have called Natural Selection; and Mr. Herbert Spencer has well expressed the same idea by the Survival of the Fittest. The term \"natural selection\" is in some respects a bad one, as it seems to imply conscious choice; but this will be disregarded after a little familiarity\". He defended his analogy as similar to language used in chemistry, and to astronomers depicting the \"attraction of gravity as ruling the movements of the planets\", or the way in which \"agriculturists speak of man making domestic races by his power of selection\". He had \"often personified the word Nature; for I have found it difficult to avoid this ambiguity; but I mean by nature only the aggregate action and product of many natural laws,—and by laws only the ascertained sequence of events.\"\n\nIn the first four editions of \"On the Origin of Species\", Darwin had used the phrase \"natural selection\". \nIn Chapter 4 of the 5th edition of \"The Origin\" published in 1869, Darwin implies again the synonym: \"Natural Selection, or the Survival of the Fittest\". By \"fittest\" Darwin meant \"better adapted for the immediate, local environment\", not the common modern meaning of \"in the best physical shape\" (think of a puzzle piece, not an athlete). In the introduction he gave full credit to Spencer, writing \"I have called this principle, by which each slight variation, if useful, is preserved, by the term Natural Selection, in order to mark its relation to man's power of selection. But the expression often used by Mr. Herbert Spencer of the Survival of the Fittest is more accurate, and is sometimes equally convenient.\"\n\nIn \"The Man Versus The State\", Spencer used the phrase in a postscript to justify a plausible explanation of how his theories would not be adopted by \"societies of militant type\". He uses the term in the context of societies at war, and the form of his reference suggests that he is applying a general principle.\n\nThough Spencer’s conception of organic evolution is commonly interpreted as a form of Lamarckism, Herbert Spencer is sometimes credited with inaugurating Social Darwinism. The phrase \"survival of the fittest\" has become widely used in popular literature as a catchphrase for any topic related or analogous to evolution and natural selection. It has thus been applied to principles of unrestrained competition, and it has been used extensively by both proponents and opponents of Social Darwinism.\n\nEvolutionary biologists criticise the manner in which the term is used by non-scientists and the connotations that have grown around the term in popular culture. The phrase also does not help in conveying the complex nature of natural selection, so modern biologists prefer and almost exclusively use the term natural selection. The biological concept of fitness refers to reproductive success, as opposed to survival, and is not explicit in the specific ways in which organisms can be more \"fit\" (increase reproductive success) as having phenotypic characteristics that enhance survival and reproduction (which was the meaning that Spencer had in mind).\n\nWhile the phrase \"survival of the fittest\" is often used to mean \"natural selection\", it is avoided by modern biologists, because the phrase can be misleading. For example, survival is only one aspect of selection, and not always the most important. Another problem is that the word \"fit\" is frequently confused with a state of physical fitness. In the evolutionary meaning \"fitness\" is the rate of reproductive output among a class of genetic variants.\n\nThe phrase can also be interpreted to express a theory or hypothesis: that \"fit\" as opposed to \"unfit\" individuals or species, in some sense of \"fit\", will survive some test.\n\nInterpretations of the phrase as expressing a theory are in danger of being tautological, meaning roughly \"those with a propensity to survive have a propensity to survive\"; to have content the theory must use a concept of fitness that is independent of that of survival.\n\nInterpreted as a theory of species survival, the theory that the fittest species survive is undermined by evidence that while direct competition is observed between individuals, populations and species, there is little evidence that competition has been the driving force in the evolution of large groups such as, for example, amphibians, reptiles, and mammals. Instead, these groups have evolved by expanding into empty ecological niches. In the punctuated equilibrium model of environmental and biological change, the factor determining survival is often not superiority over another in competition but ability to survive dramatic changes in environmental conditions, such as after a meteor impact energetic enough to greatly change the environment globally. The main land dwelling animals to survive the K-Pg impact 66 million years ago had the ability to live in underground tunnels, for example.\n\nIn 2010 Sahney et al. argued that there is little evidence that intrinsic, biological factors such as competition have been the driving force in the evolution of large groups. Instead, they cited extrinsic, abiotic factors such as expansion as the driving factor on a large evolutionary scale. The rise of dominant groups such as amphibians, reptiles, mammals and birds occurred by opportunistic expansion into empty ecological niches and the extinction of groups happened due to large shifts in the abiotic environment.\n\nIt has been claimed that \"the survival of the fittest\" theory in biology was interpreted by late 19th century capitalists as \"an ethical precept that sanctioned cut-throat economic competition\" and led to the advent of the theory of \"social Darwinism\" which was used to justify laissez-faire economics, war and racism. However, these ideas predate and commonly contradict Darwin's ideas, and indeed their proponents rarely invoked Darwin in support. The term \"social Darwinism\" referring to capitalist ideologies was introduced as a term of abuse by Richard Hofstadter's \"Social Darwinism in American Thought\" published in 1944.\n\nRussian anarchist Peter Kropotkin viewed the concept of \"survival of the fittest\" as supporting co-operation rather than competition. In his book \"\" he set out his analysis leading to the conclusion that the fittest was not necessarily the best at competing individually, but often the community made up of those best at working together. He concluded that In the animal world we have seen that the vast majority of species live in societies, and that they find in association the best arms for the struggle for life: understood, of course, in its wide Darwinian sense – not as a struggle for the sheer means of existence, but as a struggle against all natural conditions unfavourable to the species. The animal species, in which individual struggle has been reduced to its narrowest limits, and the practice of mutual aid has attained the greatest development, are invariably the most numerous, the most prosperous, and the most open to further progress.\n\nApplying this concept to human society, Kropotkin presented mutual aid as one of the dominant factors of evolution, the other being self-assertion, and concluded that In the practice of mutual aid, which we can retrace to the earliest beginnings of evolution, we thus find the positive and undoubted origin of our ethical conceptions; and we can affirm that in the ethical progress of man, mutual support not mutual struggle – has had the leading part. In its wide extension, even at the present time, we also see the best guarantee of a still loftier evolution of our race.\n\n\"Survival of the fittest\" is sometimes claimed to be a tautology. The reasoning is that if one takes the term \"fit\" to mean \"endowed with phenotypic characteristics which improve chances of survival and reproduction\" (which is roughly how Spencer understood it), then \"survival of the fittest\" can simply be rewritten as \"survival of those who are better equipped for surviving\". Furthermore, the expression \"does\" become a tautology if one uses the most widely accepted definition of \"fitness\" in modern biology, namely reproductive success itself (rather than any set of characters conducive to this reproductive success). This reasoning is sometimes used to claim that Darwin's entire theory of evolution by natural selection is fundamentally tautological, and therefore devoid of any explanatory power.\n\nHowever, the expression \"survival of the fittest\" (taken on its own and out of context) gives a very incomplete account of the mechanism of natural selection. The reason is that it does not mention a key requirement for natural selection, namely the requirement of \"heritability\". It is true that the phrase \"survival of the fittest\", in and by itself, is a tautology if fitness is defined by survival and reproduction. Natural selection is the portion of variation in reproductive success that is caused by \"heritable\" characters (see the article on natural selection).\n\nIf certain heritable characters increase or decrease the chances of survival and reproduction of their bearers, then it follows mechanically (by definition of \"heritable\") that those characters that improve survival and reproduction will increase in frequency over generations. This is precisely what is called \"evolution by natural selection\". On the other hand, if the characters which lead to differential reproductive success are not heritable, then no meaningful evolution will occur, \"survival of the fittest\" or not: if improvement in reproductive success is caused by traits that are not heritable, then there is no reason why these traits should increase in frequency over generations. In other words, natural selection does not simply state that \"survivors survive\" or \"reproducers reproduce\"; rather, it states that \"survivors survive, reproduce and \"therefore\" propagate any \"heritable\" characters which have affected their survival and reproductive success\". This statement is not tautological: it hinges on the testable hypothesis that such fitness-impacting heritable variations actually exist (a hypothesis that has been amply confirmed.)\n\nMomme von Sydow suggested further definitions of 'survival of the fittest' that may yield a testable meaning in biology and also in other areas where Darwinian processes have been influential. However, much care would be needed to disentangle tautological from testable aspects. Moreover, an \"implicit shifting between a testable and an untestable interpretation can be an illicit tactic to immunize natural selection ... while conveying the impression that one is concerned with testable hypotheses\".\n\nSkeptic Society founder and \"Skeptic\" magazine publisher Michael Shermer addresses the tautology problem in his 1997 book, \"Why People Believe Weird Things\", in which he points out that although tautologies are sometimes the beginning of science, they are never the end, and that scientific principles like natural selection are testable and falsifiable by virtue of their predictive power. Shermer points out, as an example, that population genetics accurately demonstrate when natural selection will and will not effect change on a population. Shermer hypothesizes that if hominid fossils were found in the same geological strata as trilobites, it would be evidence against natural selection.\n\n\n\n\n"}
{"id": "13355399", "url": "https://en.wikipedia.org/wiki?curid=13355399", "title": "Syntax diagram", "text": "Syntax diagram\n\nSyntax diagrams (or railroad diagrams) are a way to represent a context-free grammar. They represent a graphical alternative to Backus–Naur form or to EBNF as metalanguages. Early books using syntax diagrams include the \"Pascal User Manual\" written by Niklaus Wirth (diagrams start at page 47) and the Burroughs CANDE Manual.. In the compilation field, textual representations like BNF or its variants are usually preferred. BNF is text-based, and used by compiler writers and parser generators. Railroad diagrams are visual, and may be more readily understood by laypeople, sometimes incorporated into graphic design. The canonical source defining the JSON data interchange format provides yet another example of a popular modern usage of these diagrams.\n\nThe representation of a grammar is made of a set of syntax diagrams. Each diagram defines a non-terminal. There is a main diagram which defines the language in the following way: to belong to the language, a word must describe a path in the main diagram.\n\nEach diagram has an entry point and an end point. The diagram describes possible paths between these two points by going through other nonterminals and terminals. Terminals are represented by round boxes while nonterminals are represented by square boxes.\n\nWe use arithmetic expressions as an example. First we provide a simplified BNF grammar:\nThis grammar can also be expressed in EBNF:\nOne possible set of syntax diagrams for this grammar is:\n\n\nNote: the first link is sometimes blocked by the server outside of its domain, but it is available on archive.org. The file was also mirrored at standardpascal.org.\n\n"}
{"id": "40792793", "url": "https://en.wikipedia.org/wiki?curid=40792793", "title": "Systems of social stratification", "text": "Systems of social stratification\n\nDetailed anthropological and sociological studies have been made about customs of patrilineal inheritance, where only male children can inherit. Some cultures also employ matrilineal succession, where property can only pass along the female line, most commonly going to the sister's sons of the decedent; but also, in some societies, from the mother to her daughters. Some ancient societies and most modern states employ egalitarian inheritance, without discrimination based on gender and/or birth order.\n\nThe system of patrilineal primogeniture traditionally prevalent among most southern Bantu tribes is explained in detail by Isabel Moodley: \"Due to the polygynous nature of the customary marriage, African customary law distinguishes between \"family rank\" and \"house rank\". ... Family rank refers to the status of family members within the family group. In customary law, males held a higher rank than their female counterparts. A person's rank was ultimately determined by the principle of primogeniture. On the basis of that principle, oldest sons always had a higher rank than younger brothers and all sisters. That meant that females were always subjected to the authority of males and males alone were allowed to become family heads. In the extended family group however, the rank of a child was determined by the rank of their father within his family of origin. So, for example, if the father was the first born son in his family group that would mean that his children would hold a higher rank than any of the other children born of his siblings. ... House rank simply refers to the hierarchy of the various houses that constitute a family group. In a polygynous marriage, each marriage creates a separate family or household with the husband as the common spouse to all the families. Each household or separate family has a particular rank. ... Amongst the indigenous African peoples, the wife married first is known as the \"main wife\" or the \"great wife\". The rank of the children born in a specific household is thus solely dependent upon the rank of their mother's house or house rank. In other words, the rank of the children born to the main or great wife (irrespective of age) will be higher than the rank of all the other children born to the ancillary wives. That means that the house rank of the main or great wife and her children will be higher than that of the other spouses and their children in the other houses.\" Although she says that this system prevailed among most African peoples, not only the southern Bantu, this is doubtful.\n\nThis social structure prevalent among the southern Bantu even informed their religious beliefs The expansion of southern Bantu peoples, such as for example the Xhosa, is attributed to the fission of younger sons.\n\nPatrilineal primogeniture prevailed among the Xhosa (\"each eldest son, upon the death of his father, inherits all the property appertaining to his mother's house\"), the Pondo, the Tswana, the Ndebele, the Swazi, the Zulus, the Sotho, the Tsonga, the Venda and most other southern Bantu peoples; among them in general the first son was conceived of as superior to his siblings. As Hoernlé states, \"Among the children a strict hierarchy prevails, based on the seniority which serves as a fundamental principle of behaviour in Bantu society. The elder brother always takes precedence between brothers, and so, too, between sisters the privilege of age is maintained. Between brothers and sisters the sex differentiation often dominates the behaviour. Sisterhood and brotherhood most often overrule age differences, and there is a prescribed type of behaviour for a brother towards his sister and vice versa. Outside this intimate circle of the immediate family, the same principles of kinship and seniority hold sway. The father forms one of a close-knit group with his brothers. The latter are everywhere grouped under a kinship term which we may translate \"father\"; and these \"fathers\" are distinguished as \"great\" or \"little\" fathers, according as they are older or younger than the child's own father\". Van Warmelo writes, \"Bantu social structure knows no equals, as with whole sibs, so with individuals. The first-born of the same parents is always superior to those born after him, and this superiority is extended to his descendants, with varying consistency.\"\n\nIsaac Schapera writes about the Southern Bantu in general in \"The Bantu Speaking Tribes of South Africa\": \"Polygyny is practised; but, except in the case of Chiefs and other prominent or wealthy men, not to any marked extent. Among the Shangana-Tonga, Venda, and Tswana the first wife married is normally the great wife, the rest ranking as minor wives in order of marriage. The Nguni, however, also give special rank to a second wife (the \"right-hand wife\"), and in some cases (e.g. Natal tribes) to a third wife (the \"left-hand wife\"). Any other wives are attached in a subordinate capacity to one or other of these principal houses. The Southern and Northern Sotho have adopted a somewhat similar system of domestic organization. The great wife takes the lead in all domestic affairs and, as already mentioned, her eldest son is heir to the general household property and to the status of his father.\" He writes specifically about the Tswana: \"When a married man dies, leaving a wife and children of both sexes, his eldest son becomes the principal heir even if there is an older daughter. If this son has been formally disowned by his father, he cannot after the latter's death claim the estate. The rightful heir will be the oldest of the remaining sons. If the principal heir is dead, his eldest son will succeed to his rights, taking precedence over his father's younger brothers, along the lines already described in regard to the rules of succession.\" \"The estate of a polygamist is similarly divided. The eldest son in each house inherits all livestock assigned to that house. The eldest son of the great house further inherits such property as has not been assigned to any house\". The only land that the Tswana use for agriculture are some fields that are assigned to each wife. Regarding their rules of inheritance, \"The general rule, in practice, seems to be that the fields are inherited by those children who have not yet obtained any of their own, the youngest child having the first claim. If provision has already been made for all the children, the eldest son inherits all the fields, but can, and usually does, distribute some of them among his younger brothers and sisters\". \"(There are) three separate classes, nobles, commoners, ... and immigrants, ... Within each class there are further distinctions. Among nobles, the more closely a man is related to the chief, the higher does he rank. ... Among commoners ... the head of any group is senior to all his dependents, among whom his own relatives are of higher status than the others.\" \"The children of paternal uncles are differentiated according to the relative status of their father. ... If senior to one's father by birth, they are entitled to obedience and respect; if junior, their services can be freely commanded. The saying that a man's elder brother is his chief, and his younger brother his subject, summarises adequately the accepted relation. ...\" \"Seniority is determined firstly by priority of birth. An\neldest son is always senior to the second, who in turn is senior to the third son and so on.\"\n\nSimon Roberts and Michael Palmer made a description of the Kgatla society, a sub-group of the Tswana people, in their book \"Dispute Processes: ADR and the Primary Forms of Decision-Making\", where they notice the conical (or pyramidal, as they say) shape of Tswana societies: \"The link between the chief and the senior man in each ward is ideally a genealogical one, for the office of chief should devolve from father to eldest son, while the younger sons of each ruler go off to form their own wards, assuming administrative control of these new subdivisions of the main group. The Kgatla believe that their society was founded by Kgafela in the late seventeenth or early eighteenth century, and most of the forty-eight wards in the central village of Mochuli today are headed by men claiming descent from younger brothers of chiefs descended from Kgafela. ... ward heads are senior members of the junior branches of the chief's lineage. This system of administration is reflected at ground level in the residential organization of the main village. At the centre is a group of homesteads occupied by men of the chief's immediate agnatic segment, and ranged around this are forty seven other groups of homesteads, each presided over by a ward head. ... Within each ward ... the majority of the members again claim to be related in the male line to the headman. ... All the males claiming descent from a common grandfather tend to be grouped together, and within such a sub-group a minimal unit is made up of an adult married male, occupying a homestead with his wife (or wives) and children. ... Thus if the group is looked from the bottom up there is first the married male heading his own household, then the group consisting of his closest male agnates, then an aggregate of such groups forming a ward, and lastly the wards together forming the total society. ... Kgatla society can thus be seen as an ever growing and deepening pyramid, the base of which is extended as more males are born and rear their own families; while in its simplest form the political and administrative organization is imposed on the lineage system like a cloak.\"\n\nThe Zulus also practiced patrilineal primogeniture, allowing only minimal grants of land to younger sons. D.H. Reader writes in \"Zulu Tribe in Transition: The Makhanya of southern Natal\": \"Within a given descent group, dominant or not in the sub-ward, the senior agnate will sometimes make known to his sons before he dies the land which he wishes them to have when they marry. If he has done so, it is the duty of the eldest son of the Great House (the general heir) to see that the others receive their allotted land when they marry after their father's death. Like the chief on a smaller scale, he holds the land in trust for them. ... In general, the chief will support a father during his lifetime in the matter of land apportionment, provided an adequate grant of land has been made to the eldest son and a minimal grant to any other sons. These grants naturally depend on the amount of land which the father has available, if any. If there is sufficient land, a minimal grant consists of a garden of at least half an acre, a big field of about two acres, and space to build upon; for under the present conditions of subsistence a man cannot live on less.\" In cases of polygamy, \"The eldest son of the indlunkulu, to the exclusion of all others, succeeds to the property and status of the kraal head. Should he be dead, his eldest son will succeed. Failing such eldest son and all male lineal descendants through him, the second son of the indlunkulu succeeds and failing him his male lineal descendants in due order of seniority. Failing a third and all other sons of the indlunkulu and all male lineal descendants there, the succession will devolve upon the eldest son of the house first affiliated to the indlunkulu. Failing all heirs of this house the succession devolves upon the next affiliated house and so an according to the order of affiliation. Failing an heir in the indlunkulu or affiliated houses recourse will be had to the chief house on the Qadi side (second chief wife in a kraal, failing which, to the affiliate houses in order of their affiliation to the qadi house. Only in the event of a failure in all these houses will the succession devolve upon the eldest son of the chief khohlwa (wife of the left hand side or second in the order of marriage) in succession\" (Krige, 1950: 180). The eldest son of each wife inherited the property assigned to his mother's house. According to Comaroff, \"a man's eldest son normally succeeds him as head of his household and to any political office that he may have held, and also inherits the great bulk of his cattle and such other property. The younger sons are likewise given a few cattle each. The widow and daughters received no cattle at all\" (Comaroff, 1953:42 ). Livestock was so important among the southern Bantu that a Zulu would sometimes compare the structure of his homestead with the body of a cow. Cook claims that a Zulu informant \"drew with his finger an incomplete oval in the sand, which stood for the trunk of a cow. Above, at the neck, he indicated the place of the homestead head. At breast height he indicated with his finger the uyise wabantu. At shoulder height, on the right side, he placed the heir, and on the right flank the junior right hand son. The left hand and junior left hand sons were indicated on the left shoulder and flank. According to them the homestead thus presents itself, structurally, like a cow.\" (1940: 69; cf. Cook 1931: 26)\n\nOm Mntanga says about the Xhosa: \"According to Xhosa traditional custom, when a man dies his eldest son usually inherits his social position as household head. He also inherits land rights, cattle and material possessions\". Monica Hunter says about the Pondo: \"From childhood there is a distinction between younger and elder brother. A younger brother is ordered about by his senior. After the death of the father the eldest brother, the heir, takes the place of the father, being responsible for the maintenance of the property and, if possible, of his younger brothers. They should give him their earnings, as they should their father. An elder brother is referred to as umkhuluwe, a younger as umninawe\". It is said about the Venda:\"\"Traditionally, all land is communal, under the trusteeship of the chief. However, every man has indisputable rights to the land he occupies and uses. His sons are entitled to the use of his land but may also ask the local headman to allocate fresh portions of land. Movable property—livestock, household utensils, and the proceeds of agriculture and trade—passes to the oldest son or, in the case of a polygynous marriage, the oldest son of the senior wife. This son becomes the undisputed head of the family unless he has disgraced himself in the eyes of the family, in which case the son next in line is appointed by the deceased's oldest sister with the consent of his brothers.\" Among the Tsonga: \"Women do not inherit. The eldest son of the principal wife inherits the bulk of kraal\nproperty such as cattle and ploughs. No two siblings have the same status\". It is said about the Ndebele of Zimbabwe: \"A husband will allocate land and livestock to his wives; the eldest son of the first wife is the principal heir and inherits this property\". Among the Swazi, says Hilda Kuper in \"The Swazi: A South African Kingdom\": \"The eldest son of each house is the heir to the property belonging to that house, and the heir to the general estate is the eldest son of the principal wife of the deceased. Often she is not pointed out as such until after her husband's death. the heir to the general estate of course is also special heir to the estate of his mother's house. These special estates become the general estates inherited by the next generation of heirs.\" Phakama Shili writes in \"Social Inequalities: Inheritance Under Swazi Customary Law\": \"under Swazi customary law women are not considered to inherit the estates of their late husbands and fathers. In terms of Swazi customary law there is only one heir who succeeds to the whole estate of the deceased and such person is chosen by\nlusendvo. Where the deceased headman had one wife, his eldest son, in the absence of factors which may disqualify him becomes heir. This therefore means that his siblings will not inherit but only benefit from the estate through their brother. This preference of the eldest son over his siblings and mother goes against the dictates of the Constitution which provides for equal treatment and non-discrimination of women. If the deceased dies having married to two or more wives, the lusendvo will choose the principal wife and the oldest son of that wife or house will become the main heir\".\n\nCustoms of male primogeniture also prevailed among the Sotho. Among the Sotho, \"The heir under custom is the first male person born of that family. He takes over the administration of the estate upon death of the head of the family. This is provided for under Article 11 of the Laws of Lerotholi. The heir under custom should inherit (assuming use of the land after death of his father) the land together with obligations attached to that land.\" Adam Kuper says about all the Sotho peoples: \"The basic principle is that siblings of the same sex are regarded as similar, but are ranked; while siblings of opposite sex are different and equal. ... A polygynist's first wife is normally the senior wife, and her eldest son is generally the heir.\"\n\nPrecedence within clans and tribes based on patrilineal primogeniture was also common among the Khoi and the Damara.\n\nThe Hausa didn't have the conical clan as their system of social organization (in Africa, this system predominated mostly among southern African peoples), but had a complex system of hereditary social stratification as well. The following excerpt is from Frank A. Salamone's \"The Hausa of Nigeria\":\n\n\"The Hausa tend to rank all specialties in a hierarchical and hereditary system. Inheritance is by primogeniture. The Hausa prize wealth and use it to form patronage links. However, wealth also brings with it the burden of great responsibilities. The patron-client relationship binds all Hausa men to some extent. The Maguzawa are organized into small villages of exogamous patrilineal kin. Conversely, Muslim Hausa local organization is somewhat more complex. The compound, his wife or wives, and their children is the smallest social unit. Other family members, clients, and their families may also inhabit the compound. Therefore, patrilocal extended families or joint fraternal families often inhabit a compound. The mai-gida, or male head of the family, rules the compound. The compound forms a joint agricultural unit. Occupational specialties, however, are at the discretion of the individual. As Muslims, each Hausa male may have four wives and as many concubines as he can support. ... In conformity with the Muslim Hausa principle of hierarchy, wives are ranked in the order of their marriages. The Hausa prefer cousin marriage on either side, although patrilateral parallel cousin marriage in the Fulani style has greater prestige than any other form of marriage. ... The Hausa pride themselves on being a \"civilized\" people with strong urban roots. They display a genius for organization. Their wards have a village organization, which is under the leadership of the village head. Formerly, there would be a titled official in the capital who held clusters of villages in fief. The emir would be the overall ruler of the particular state, which consisted of a number of clusters of villages. British rule which was consolidated about the beginning of the Twentieth century changed the system in a number of ways, providing greater power to emirs and local Muslim officials.\"\nEleanor C. Swanson and Robert O. Lagace write:\n\n\"Muslim Hausa social organization is characterized by a complex system of stratification, based on occupation, wealth, birth, and patron-client ties. Occupational specialties are ranked and tend to be hereditary, to the extent that the first son is expected to follow his father's occupation. Wealth gives its possessor a certain amount of prestige and power, especially in forming ties of patronage. One's status is also determined by the status of one's family. Finally, all Hausa men are caught up in a network of patron-client ties that permeates the society. Patron-client ties are used as means of access to favors and power\".\n\nM.G. Smith also discussed thoroughly the Hausa system of social status in his work \"The Hausa system of social status.\" In that article it is explained that wives are ranked according to their order of marriage: the first-married wife is the uwar gida or highest-ranking wife; she is most respected and has greatest authority over other wives. The lowest-ranking wife is the last-married wife or amariya and is the least respected wife and the one with least authority.\n\nKent M. Elbow described the socioeconomic system of Hausa farm villages extensively in 1994. He wrote about the Gandu:\n\n\"Gandu refers to the set of relations that collectively define the basic production unit in traditional Hausaland. Most often these relations express themselves among the members of the gida, the basic household unit of rural Hausaland. The gida corresponds roughly to the common understanding of the extended family. Thus the nucleus of a gandu is an extended family, but accounts such as the classic Baba of Karo (M. Smith 1954) make it clear that the nineteenth century gandu also included slaves and descendants of slaves. Sutter's (1982) review of the literature points out that some writers stress the gandu's importance as a hedge against famine and food insecurity, while other writers emphasize its role as a defense against the slave-raiding parties prevalent during the pre-colonial era—and especially menacing in the nineteenth century under the Sokoto caliphate. Ega (1980) suggests that the traditional gandu probably consisted mostly of slaves, but stresses that the gandu was a work unit in which the owner and the slaves had mutual obligations. The owner had the right to a certain number of hours of labor from his slaves each day, and in return he was expected to provide them with land and the time to cultivate it. The slaves had full rights over the product of their \"private\" plots. It is thought that the elaborate and detailed mutual rights and duties between the gandu head and his younger brothers and sons—such as those enumerated by Hill (1970)—have evolved from the traditional mutual duties characteristic of master/slave relationships in the nineteenth century. For example, in most gandu arrangements the father assumes the responsibility of paying the taxes charged to his sons and may even be obligated to pay his sons' brideprice\".\n\n\"The gandu system dictates that holdings are inherited in their entirety by the eldest son who will assume the role as gandu head\", also wrote Kent M. Elbow. He argued that the gandu system had been on the decline for many years, and most scholars agree with this opinion. However, Poly Hill, researching a Hausa village in 1973, found that eldest sons or elder sons were still favored over younger sons in matters of land inheritance at that time. This greater transfer of property occurred during the father's lifetime:\n\n\"But although many of the sons of rich farmers may be badly situated following their father's death, there are some who will be exceptionally well placed. As under systems of primogeniture, it may be that one son (or perhaps two or more) is effectively the father's heir and successor, while his brothers are not. This is not because of any blatant inequality in the division of physical property at the time of his father's death, but because a man's eldest son (or elder sons) may have had special opportunities ... of establishing a secure position in life, while under his father\".\n\nEric J. Arnould described the social organization of Hausa farm villages as follows in \"Marketing and Social Reproduction in Zinder, Niger Republic\":\n\n\"Each hausa farm village was built up around a core family group (dengi) composed of agnatic kinfolk. The fundamental unit of residence, production, distribution, transmission, and reproduction was the gida. At a mature stage of the domestic cycle the gida was a patrilocal multiple family household of at least two generations depth and comprising the conjugal family units (iyali) of the household head (mai gida) and his married sons and their children. Some wealthier gida contained farm slaves. The gida was essentially a family farming unit (FFU) distinguished from other FFU by usufructory rights of tenure to dune (jigawa) and marsh (fadama) lands, control of its own granary, and disposition of the labor power of its active members. The household hhead (mai gida) partitioned the household land into gandu (collective) and gamana (individual) parcels. Men worked together on the gandu five days a week. The mai gida held the fruits of gandu production in trust and was obliged to feed, clothe, and pay taxes and ceremonial expenses of his household from the gandu produce during the agricultural season. With the help of the extended agnatic kin group the mai gida ensured that his sons and daughters would marry. Individual and junior iyali fed themselves during the dry season from the fruits of the gandu produce during the agricultural season. With the help of the exntended agnatic kin group the mai gida ensured tha his sons and daughters would marry. Individuals and junior iyali fed themselves during the dry season from the fruits of the gamana and, in addition, used gamana produce to participate in ceremonial events and exchanges (baptisms, marriages, funerals). Gandu produce could never be sold; gamana produce could be, but the bulk of production took place on gandu plots. On the death of the mai gida the inheriting sons did not immediately divide the land and slaves but continued to work together, the eldest brother assuming the role of mai gida. At this stage of the developmental cycle the gida became a frereche. As the families of the brothers grew, they divided the patrimony. Usually junior brothers were compelled to clear new bush lands\".\n\nThe British thought that the Hausa Law of Primogeniture was bad because it encouraged usury and mortgage.\n\nA system of ranking and patrilineal primogeniture similar to that of many southern African peoples seems to have traditionally prevailed among the Nilotic peoples of South Sudan with regards to land (the eldest son of the first wife was the heir of his father's land, residential and arable, and the land of each house was inherited by the heir of that house, i.e., the eldest son of the head wife in the house). Thus a similar lineage system prevailed among some Nilotic peoples like the Lugbara or the Dinka.\n\nHowever, it should be kept in mind that the system of social organization characteristic of most East African peoples was the segmentary lineage organization as described by Evans Pritchard's famous work on the Nuer.\n\nSahlins considered the conical clan typical of some central African Bantu lineage organizations. He didn't elaborate further on this point. According to him, \"Called conical clan by Kirchoff, at one time ramage by Firth and status lineage by Goldman, the Polynesian ranked lineage is the same in principle as the so-called obok system widely distributed in Central Asia, and it is at least analogous to the Scottish clan, the Chinese clan, certain Central African Bantu lineage systems, the house-groups of Northwest Coast Indians, perhaps even the \"tribes\" of the Israelites\". Éric de Dampierre found this type of social organization to be prevalent among the Azande. He discussed this in his work \"Sons aînés, sons cadets: les sanza d'Ebézagui\", where he explained that among the Azande elder sons and their lines of descent were ranked higher than younger sons and their lines of descent. Male primogeniture, a typical feature of a social structure of this type, also prevailed among many Cameroonian peoples (such as for example the Masa), eastern and northern Congo peoples (such as the Ngala), and the Gbaya and the Mossi, all this according to the Ethnographic Atlas. However, in Angola, Gabon and most of the rest of Congo, lateral rather than lineal succession was the rule, and most Chadian peoples commonly divided land and livestock equally between all sons.\n\nPatrilineal primogeniture also prevailed among the Songye and the Buduma, according to the Ethnographic Atlas.\n\nIn traditional Austronesian societies (roughly those of modern-day Malaysia, Indonesia, Philippines, East Timor, Brunei, Madagascar and Oceania), seniority of birth and of descent generally determined rank, often leading to the fission of those lowest in rank (younger sons from younger branches), a fact often cited by anthropologists as the cause of Austronesian expansion throughout Southeast Asia, Oceania and even the Indian Ocean -Madagascar, Mauritius-. Other terms have also been used to describe this type of social organization, such as \"status lineage\" (Goldman) \"apical demotion\" (Fox) or \"ramage\" (Firth). Sahlins also created the concept of the \"Big Man\", a type of man in Melanesian societies who becomes a leader not due to his fraternal birth order as in Polynesian societies, but to his ability and charisma. Melanesian societies could either be dominated by the conical clan as Polynesian societies or by an egalitarian system of social organization as most Papuan societies (though even some Papuan societies were characterized by a predominance of patrilineal primogeniture, like for example the society of Goodenough island). In Micronesia, the system was matrilineal and brothers succeeded each other in order of seniority; when the line of brothers was extinguished, the eldest son of the eldest sister succeeded, and so on in each successive generation.\n\nThe social system of Polynesians was similar to that of the southern Bantu. As Sahlins writes, \"The mode of succession is primogeniture; the eldest son succeeds to the position of his father. ... Not only is he differentiated from his younger brothers, but so also is every brother differentiated from every other, in accordance with their respective order of birth and the consequent prospects of succeeding to the position of their father. ... The seniority principle in the family is a microcosm of the ramified social system. ... As a consequence of seniority, the descendants of an older brother rank higher than the descendants of a younger brother. ... Every individual within this group of descendants of a common ancestor holds a differing status, one precisely in proportion to his distance from the senior line of descent in the group. ... People descendent from remote collaterals of the common ancestor are lower in rank than those descendent from a more immediate relative of the chiefly line. People with the lowest status are those who have descended from younger brothers through younger brothers ad infinitum. The process of primogenitural succession and its consequent implication of seniority result in a ranking structure which encompasses the entire society. ... In every ramified society one can recognise groups of statuses or status levels which are functionally significant in terms of differential socio-economic prerogatives. These different levels are normally present in all the larger ramages.\" These principles of seniority of descent structured and organized traditional Maori society, for example. Bernard Willard Aginsky and Te Rangi Hiroa write in \"Interacting forces in the Maori family\":\n\n\"Primogeniture is well established as the method of passing wealth, honor, titles, and other prerogatives from generation to generation. The Maori desire to have their first-born be male. The desire is especially acute in chiefly families. If the first-born is a male, he is considered an especially \"big man\" and the people rejoice because \"a chief is born.\" If a\ndaughter is born first, it is a case of \"bad luck,\" but it does not affect the right of the first-born male to primogeniture. He succeeds to his father's position in the normal course of events. But the sister is senior and all her descendants will, in each generation, be senior to her brother's descendants. The family and the people do not like this to happen. The man and his sons and daughters have to pay more deference to her and her sons and daughters than otherwise, because she is \"senior.\" Thus a man would have to pay respect to a female when the desire was for the established pattern which was the opposite. The same holds true for families not of chiefly blood. ... This came about in the Maori culture due to the fact that the elder brother takes precedence over his siblings on the basis of precedence of birth which carried with it many prerogatives. There are times when a particularly brilliant younger male is placed in the position of the \"first-born\" by the father due to his superior abilities. This depends upon the first-born not being at all outstanding, in fact, being of decidedly inferior quality. Although this occurs, it is not the pattern for the younger males of a fraternity to try to compete for the position. In the vast majority of cases, the eldest male is recognized as being the male who will succeed and does succeed to the father's position. ... The most important distinction which was made between all individuals was whether they were junior or senior to each other. This was determined by tracing their lineage back to the time when they both had the same male ancestor. The children of this ancestor became the real point at which the\ndistinction began. If \"my\" ancestor was a younger brother or sister of ((your\" ancestor, then \"I\" would be of the junior lineage and ((you\" would be of the senior lineage. The male lineages were the important ones in the society, but at the same time the female lineages had to be reckoned with. ... The first-born, being of the highest rank and power, caused the people to want a male to be the first-born. The Maori are patrilocal and patrilineal and if a female was the first-born, in the vast majority of cases she took that prestige to her husband's tribe when she married. She automatically passed it on to his children. In this way, the female was taking away from the tribe what rightfully belonged to them and was giving it to another tribe which was a potential enemy. Thus the children of a female became the members of another group. In many cases hard feelings, antagonisms and even war sprang up between these two groups. Then these children, the male children of your own females, became enemies in policy and oftentimes in fact. ... The Maori have evaded that possibility to some extent by tracing their main genealogy through the first-born males only. Thus, theoretically, there is only one line in each family which is counted, first-born males of the first-born males. This is the sociological tree of the Maori, not the biological tree. The biological tree would be represented by a triangle with the man at the apex and extended to his descendants, and by an inverted triangle viewed by a man looking at his ancestors. There would be no genealogical line, except when a relationship was established between two individuals of different generations. The line would exclude from consideration all the other individuals in the biological tree. But every time a relationship was established between two individuals of different generations, a new line would be drawn for the sake of convenience. Thus if your great-grandmother through your father (father's mother's mother) had been married to your great-grandfather through your mother (mother's mother's father), your biological tree would have fewer branches than the perfect biological tree and fewer lines could be drawn. ... Brothers call each other by terms designating \"born before me, takes precedence over me, comes before me, etc.,\" or the converse \"born after me\" etc.' The oldest male calls all the males in his fraternity by one term, and the youngest calls all the male members of his fraternity by another term. Thus, taken from the standpoint of every member of a fraternity speaking of every other member, they are all equated (as are their cousins, both cross and parallel). A child of any one of these individuals will follow his father's identifications and call all these men by one term, although he is cognizant of the paternity of his father ... The importance of the senior and junior lines and of the degree of relationship played a large part in the Maori social and political life. For example, if one tribe was visiting another, the old man who was the specialist on genealogies, and incidentally was an honored man for this accomplishment, would recite the genealogies. He would start at the very beginning when the first boat-load landed at that spot, over twenty generations before, and finally come to the split where two brothers became separated by having gone on different expeditions, or something of that nature. These two tribes are now the descendants of the two brothers. They are relatives and all of the members of the two tribes know their relationships to one another. The senior group, by establishing itself as such, is then in the position to command respect and a certain amount of deference from the junior group. But this was really a ceremonial usage of the genealogy and while the two groups were together it had its place ... When a marriage between two groups, or of a chiefly man in a group came about, or the death of an important individual, other groups visited them. Then the recounting of genealogies began and relationships would be established. Thus they would know whether to treat a man with respect or whether to expect a man to treat them with respect, as well as the individual treatments due to brother-sister relationship and so on. When two tribes came together they started their recounting of the genealogies from the original settler and came down perhaps five, ten or fifteen generations when a split occurred and a younger male left the main group to settle somewhere else. At this point the old man would say \"and so and so, the younger, went away. I leave him to you.\" Then he would go on showing how his line, and particularly he, was the direct descendant of the original settler. In this way he would establish his seniority and prestige. The other group would thus be placed in the position of being the junior lineage and therefore of less importance and prestige. A member of the visiting group would recognize the genealogy and pick up where the old man had \"given him his ancestor.\" He would continue the line down and show that he and his people were the relatives of the other group in the junior lineage and therefore of less importance and prestige in that locality. In his own locality, the visitor might have prestige by right of conquest or from intermarriage. A member of the visiting group would recognize the genealogy and pick up where the old man had \"given him his ancestor.\" He would continue the line down and show that he and his people were the relatives of the other group. In this way he, at the same time, acknowledges that his tribe is the junior group in that particular lineage and in that district. The genealogical status, which is of course the biological tree, excluding the branches for the most part, was established and memorized. This was of the utmost importance in the tribe, especially for the chiefs. This was a mark of rank, prestige and honor.\"\n\nRichard F. Salisbury described a sort of conical-like clan structure similar to the Polynesian one, although of a much less developed nature, in New Guinea.\n\nThe ramage or conical prevailed in early China, during the Longshan culture period and the period of the Three Dynasties (Xia, Shang and Zhou dynasties).\n\nRobert E. Murowchick wrote the following about the Longshan culture in \"China: Ancient Culture, Modern Land\": \"a kinship system in which people live in lineages; the status of members within the lineages, and of the different lineages themselves are dependent upon their proximity to the main line of descent from founding ancestor to current lineage head, probably through male primogeniture (as suggested by all texts relating to early China). Apparently the Longshan people were organized, according to early historical records, as ancient Chinese people were, into segmentary lineages, and their political status, both within lineages and between them, was predetermined in a hierarchical fashion. This kind of kinship groups is sometimes referred to as the conical clan, and is often prevalent among societies that tend to branch off and send the branch segments to colonize new territories, where they establish new settlements and new polities\".\n\nC. C. Lamberg-Karlovsky wrote the following about the period of the Three Dynasties (Xia, Shang and Zhou) in \"Archaeological Thought in America\": \"The Chinese state of the Three Dynasties, which did possess both law and military force, was, nevertheless, built upon a hierarchical system of segmentary lineages, where the distance away from the main line of patrilineal descent determined political status and the share of political power. Members of these lineages inhabited the walled towns, which constituted stratified networks ruled by the state government. the king sat at the top of the conical clan and, at the same time, at the top of the hierarchical state\".\n\nBruce G. Trigger wrote the following about the Shang dynasty in \"Understanding Early Civilizations: A Comparative Study\": \"Family life in Shang China was structured by patrilineal descent. Each corporate descent group (zu) inhabited a single community, and its male members worked a tract of land or practised a particular craft. Among the upper classes, two or more generations of a family belonging to a corporate descent group lived, under the authority of its senior male member, in a house composed of living rooms, shrines, reception halls, and work areas arranged around a series of open courts. Commoners appear to have lived in smaller, possibly nuclear family houses, but married sons remained subject to the authority of their fathers and uncles. Each corporate descent group traced its origin to a single male ancestor who was venerated by all his male descendants. Within the descent group patrilineal descent lines were hierarchically organized, with descent from elder brothers invariably ranking higher than descent from younger brothers. The oldest member of the senior line (da zong) was the group's leader and the sole person who could perform rituals honouring the group's deceased founder and chief guardian spirit. When a group had expanded until it contained over one hundred nuclear families (this was estimated to take seven generations), it split into two and the junior branch moved off to establish a new group. It is generally assumed that already in Shang times all the patrilineal descent groups that could trace themselves back to a common ancestor shared a surname and constituted an exogamous clan (xing). Clans took the form of large ramages, which meant that their various descent lines (zu, shi) were ranked in terms of their genealogical proximity to the clan's founder. ... Most lower-class Shang Chinese were monogamous. To ensure the birth of sons, who would perpetuate their lineage, upper-class men frequently acquired secondary wives. ... The male heir of a man's position was normally the eldest son of his first chief wife\".\n\nHe wrote the following about the specific case of the inheritance of political power: \"Strong emphasis was placed at all levels of Shang society on the ranking of descent lines within clans and on birth order among siblings of the same sex. Power and authority passed from a man to his eldest son or from older to younger brothers within a specific descent line. Supreme power was vested in the senior line of the Zi clan. Males who were closely related to reigning or previous kings held important court offices or administered territories. Regional offices tended to remain hereditary in the senior male line of their occupants. As the state expanded, new territories were established where younger sons of officials might be installed. Thus officials of higher genealogical status tended to hold land closer to the centre of the state and participated in the functioning of the court while others lived farther away. As lineages expanded, it was increasingly difficult to find positions for younger sons that would allow them to maintain an upper-class lifestyle. Territories were also assigned to leaders of clans that supported the Zi, while some conquered rulers were allowed to govern all or part of their former territories as Shang vassals. These officials were permitted to marry female members of the royal clan, and some of the most important of them married women of the royal lineage. The Shang upper class thus became a network of officials related directly or indirectly to the king. Officials who governed administrative territories bore the titles hou (archer lord?), bo (patriarch?), and tian or dian (field lord). While these positions normally were hereditary, successors, at least at the higher levels, had to be confirmed by the king, who could also promote or remove individuals from their offices. Officials who headed junior branches of a clan remained ritually and socially subordinate to the leaders of the senior branches from which they had split off, even when they lived far apart\".\n\nDuring the time of the Zhou dynasty, patrilineal primogeniture (the tsung-fa system) was also the norm, as Li Hwei explains in \"The ramage system in China and Polynesia\". He wrote: \"All the essential features of the Polynesian ramage -the principle of fission and dispersion, the succession by primogeniture, the differentiation of rank through the operation of seniority, the localization of the ramage groups,- are present in Chou Tsung-fa system in ancient China. Both of these systems involve patrilineal inheritance and the prevalence of adoption, but involve no exogamy. Both of them are reflected in the system of ancestral temples. ... the Tsung-fa system in the Chou dynasty in ancient China is essentially similar to the ramage system among the modern Polynesians\". Li Hwei also points out that the ramage system of the Paiwan (an aboriginal Taiwanese tribe) was based on a rule of absolute primogeniture (the eldest child inherits regardless of sex), not on a rule of patrilineal primogeniture (eldest son inherits) as in China and Polynesia.\n\nThe tsung-fa system, also called \"extensive stratified patrilineage\", was defined as follows by the anthropologist Chang Kuang-chih: \"The tsung-fa system of Chou is characterized by the fact that the eldest son of each generation formed the main line of descent and political authority, whereas the younger brothers were moved out to establish new lineages of lesser authority. The farther removed, the lesser the political authority\". According to Tao (1934: 17-31), \"the Tsung-fa or descent line system has the following characteristics: patrilineal descent, patrilineal succession, patriarchate, sib-exogamy, and primogeniture\".\n\nK.E. Brashier writes in his book \"Ancestral Memory in Early China\" about the tsung-fa system of patrilineal primogeniture: \"The greater lineage, if it has survived, is the direct succession from father to eldest son and is not defined via the collateral shifts of the lesser lineages. In discussions that demarcate between trunk and collateral lines, the former is called a zong and the latter a zu, whereas the whole lineage is dubbed the shi. ... On one hand every son who is not the eldest and hence not heir to the lineage territory has the potential of becoming a progenitor and fostering a new trunk lineage (Ideally he would strike out to cultivate new lineage territory). ... According to the Zou commentary, the son of heaven divided land among his feudal lords, his feudal lords divided land among their dependent families and so forth down the pecking order to the officers who had their dependent kin and the commoners who \"each had his apportioned relations and all had their graded precedence\"\"\n\nPatricia Ebrey defines the descent-line system as follows: \"A great line (ta-tsung) is the line of eldest sons continuing indefinitely from a founding ancestor. A lesser line is the line of eldest sons going back no more than five generations. Great lines and lesser lines continually spin off new lesser lines, founded by younger sons\".\n\nStrong traits of the tsung-fa system of patrilineal primogeniture survived in the lineage organizations of north China until the communist era. Myron L. Cohen writes in \"Kinship, Contract, Community, And State: Anthropological Perspectives On China\": \"The north China data reveal a dimension of agnatic kinship previously not seen as significant in lineage organization. In what I call the fixed genealogical mode of agnatic kinship patrilineal ties are figured on the basis of the relative seniority of descent lines, so that the unity of the lineage as a whole is based upon a ritual focus on the senior descent line traced back to the founding ancestor, his eldest son, and the succession of eldest sons. ... lineages can be subdivided into branches based upon the nonequivalence of lines of descent. A branch tracing its origin from the eldest son of the founding ancestor is seen to be in a relationship of ritual superiority to those branches deriving from the younger brothers. Members of different branches are thus related to each other not only in terms of common descent, but also on the basis of permanent horizontal ties between senior and junior descent lines\".\n\nThis type of unlineal descent-group later became the model of the Korean family through the influence of Neo-Confucianism, as Zhu Xi and others advocated its re-establishment in China.\n\nIn South Asia, the Aryans were also organized in a system of ranked patrilines where senior patrilines were superior to junior patrilines:\n\n\"The bifurcation in clan status increased, with status differences between lines descending\nfrom an older and younger son, with specially higher status given to those who demonstrated\nleadership qualities--the ability to lead cattle, raids, to protect the clan, to establish new\nsettlements, and to manage alliances with other clans. The rajanya families were characterized as chariot-riders and warriors, while the vish were sedentary folk, producers of pastoral and\nagricultural items. They were the lesser status, junior lineages in clans and as such they had the obligation to give some of their product to the rajanyas and to priests and bards. They were to give the oblations--sacrificial items--which the priests offered at ritual ceremonies which the rajanya organized. The priests, which came to be known as brahmins, legitimized the superior status and authority of the rajanya at these rituals. (Brahmin is often also spelled Brahman.) They invest the chiefs with attributes of the deities.\"\n\nThe Paite had a similar system, strongly based on primogeniture and patrilineality and reinforced by a characteristic system of name-giving:\n\n\"Position of a child in a family determines who will be its name-giver. The first son of the second son receives his name from his father's eldest brother or father's father. Any first born son of younger sons receives his name from paternal side to emphasize patrilineality and seniority of the child concerned. The first sons of the younger brothers also get names from paternal kinsmen while the first daughter gets her name from her maternal kinsmen. As in the case of the third child of the eldest brother the tanupi gets a chance to give name to the third child of the younger brother. Death of the first child or the second child in childhood reverts the process. ... The rule of giving names to the children of more brothers cannot follow the same procedure in precision. Importance is given to the first son of the eldest son in which case the male line is strictly adhered to. The eldest son of the eldest son or eldest brother is the link between the generation of his father and his own children. He is also the lineage leader. Formerly he was known as tuulpi, e.g. ritual leader of the lineage. This line of descent is the main line in conical clan system of the paite. So long as it continues to exist this senior descent line is regarded as innpi (principal house) by the younger brothers or the cadet lines. The name-giving system of the Paite serves as an infallible record of pedigree. Depth of generation is acertainable through the name giving system as every grandfather transmits the last word of his name to his eldest grandson born to his eldest son. By correlating the names of grandsons and grandfathers one can determine whether a particular son is the eldest son of the eldest son or they are the younger ones. So a son of a younger brother cannot easily claim seniority over the son of the eldest brother and his descendants. The eldest son of the eldest brother has muniments to defend his seniority in the derivation of his name. When a child is born in a family the villagers say, \"So and so gives birth to a child\". What is the sex of the infant? What is its position in the family? asks someone. \"It is the third child and the first female child in the family\" comes the answer. \"Well! If it is so, she will get her name from the female tanupi\" concludes the other. Since patriliny and primogeniture are so much emphasized in Paite society the younger brothers and sisters of the ascending generations are not remembered in the next few generations. But the names of the eldest sons or brothers in each generation are more or less well remembered in subsequent generations as the name-giving system reveals it.\"\n\nA conical clan system also prevailed among the Nagas. In the beginning it vas based on a principle of male ultimogeniture, being very similar to Kachin gumsa; however, when all available land had been divided between communities in a given neighbourhood, male primogeniture became the dominant principle.\n\nOwen Lattimore wrote that the Mongols have a clan structure comprising ruling and subordinate clans, and that the elite clans are themselves internally divided into junior and elder lineages. Karl Kaser attributes the inexistence of different terms to designate an elder and a younger brother in European languages to the high prevalence of ultimogeniture among the European peasantry. Although male primogeniture came to be almost universal in the European aristocracy, peasants practiced both male primogeniture and ultimogeniture, and thus there was no overall preeminence of elder over younger brothers or vice versa. He says that among peoples of Inner Asian origin, by contrast, seniority between sons was emphasized, and thus there were separate terms to designate elder and younger brothers in their languages. Indeed, the Mongol kinship, for example, is according to Lévi-Strauss one of a type where sons must be carefully distinguished according to seniority, because of the complexity of the right of inheritance, which contemplates not only seniority of birth but also of patriline. The anthropologist Herbert Harold Vreeland, who visited three Mongol communities in 1920, published a highly detailed book with the results of his field study, \"Mongol community and kinship structure\", now publicly available. In this book he explained the ranking system prevalent in traditional Mongol communities.\n\nHe said about the Khalka Mongols: \"The family was based on monogamous marriage. Polygyny occurred, but was very rare and countenanced only for reason of sterility in the first wife. ... Custom required that at least one of the man's sons should remain always with the parents to care for them in their old age and to inherit the core of the family's property; but other sons were generally given separate shares and their economic independence, plus the movable nature of the property itself, made it possible for them to leave their father's camp. ... The terms abaga and aca are used to express not only ascendant-descendant generational ranking, but also the relative seniority of two collateral lines. Where successive generations descend patrilineally from two brothers, the line from the elder brother is the senior line, and the line from the younger brother is the junior line. All successive generations in the senior line are senior to corresponding generations in the junior line, and are known collectively as the abagiin üye (\"uncle\" generations); reciprocally, all generations in the junior line are known as the aciin üye (\"nephew\" generations). Hence, persons in corresponding generations in two collateral lines refer to each other reciprocally as abaga aha/egci and aca hüu/hüuhen. Under these circumstances, relative age terms are not employed. That is, Ego cannot say abaga düu for an abaga cousin younger than himself, nor aca aha for an aca cousin older than himself. The reason for this is clear: the Khalka system distinguishes between paternal cousins solely on the basis of the relative seniority of the two brothers who head the collateral lines, and makes these distinctions by using generation terms (abaga, aca) instead of relative age terms (aha, düü). The relative age of two cousins is not considered in the reckoning. ... The terms üyeeld, hayaald, etc. are combined with the terms abaga and aca so that collateral kinsmen may be distinguished not only according to whether they are in ascendant or descendant generations, or of senior or junior rank, with respect to the speaker. [..] Where equality of age and generation tended to minimize reserve, seniority ranking tended to increase it - i.e. in the presence of one's age and generation equals, one was more reserved if they were of senior rank than if they were of equal rank. ... Younger siblings addressed elder siblings as aha or egci, and were in turn addressed by their personal names. If there were several elder siblings of same sex, the younger sibling generally addressed only the eldest as aha or egci, and the others by abgailana terms. ... Ordinarily, younger siblings did not call elder siblings by their personal names. ... An elder brother could punish a younger brother by striking him, and the younger brother was expected not to strike back if he was not of age. When he came of age, he could strike back with impunity. However, a family was criticized by outsiders if two brothers had a long-standing feud, and quarrels between siblings were considered worse than those between spouses. ... An elder brother couuld ask a younger brother to perform certain services for him - e.g. saddle his horse - but younger brothers did not expect the service to be reciprocated. ... When an elder brother assumed trusteeship of the family after the father's death, he did not merit from his brothers all the respect shown to the father by his sons. In such cases, younger brothers often fought with elder brothers over shares allotted to them at the time the property was finally divided; this is one of the reasons why fathers liked to divide property before their death\".\n\nAbout the Chahar Mongols he wrote: \"The family was based on monogamous marriage. Polygyny occurred, but was very rare and countenanced only for reason of sterility in the first wife. ... With respect to the authority structure of the family, there appears to have been little difference between the Mongol families of Taibas Pasture and those of the Narobanchin territory ... The father, or the eldest brother, was nominal head of the house by virtue of age seniority; he controlled the capital wealth of the family, supervised the work of junior male members, and in general disciplined the males, although he had the right to discipline daughters as well, short of striking. ... The Chahar kinship terminology system presented here appears to be basically the same as the system presented for the Khalkas ... Younger siblings addressed their elder siblings with abgailana terms. Where there were several elder siblings of same sex, qualifying terms of all sorts were added to distinguish them. Elder siblings addressed younger siblings by their personal names, or, in an affectionate or joking way, as düügei. A younger sibling never addressed an elder sibling by name. ... A group of relatives, all of whom shared independently and in common a single unit of family property, was known as örehe. The senior male, who had authority over this group, managed the family property and made any necessary division of property. Family property was normally transferred to sons by a combination of both division and inheritance. When there was only one son, there was usually no division, the son remaining with his parents and inheriting the estate from them when they came enfeebled or died. Where there were several sons, the father usually divided the property during his own lifetime, giving a separate share to each son except to the son who was chosen to inherit his parent's residual share. Traditionally, this was the youngest son; in practice, it was usually the son who had take care of his parents in their old age. ... Sons to whom property was divided did not necessarily get equal shares and the father retained for himself and his heir a share larger than any of those given to other sons. Marriage appears to have been a factor determining when sons received their shares, but the data here are not clear. ... If the property was not divided among two or more sons before the father's death, the eldest son became trustee, or the mother became trustee until the eldest son reached maturity. When younger brothers reached the point where they were entitled to separate shares, the elder brother made the division\".\n\nAmong the Dagor Mongols, however, things were somewhat different: \"As suggested by the sleeping and eating arrangements, the senior man and woman in the house were accorded special privileges. These included sleeping and eating in the position of honor, being served first, receiving the choice tidbits, the right to be greeted first by persons entering the room, and other courtesies of respect and deference. Seniority depended entirely on relative age and generation. While the father and the mother were alive, they were the senior couple. Where several married brothers continued to live together after the parents' death, the eldest brother and his wife moved automatically to the position of seniority\". However, \"Seniority status in the family affected only the allocation of respect and certain privileges in intra-familial courtesies and behavior, and was not directly related to the allocation of authority. The authority structure of the extended family was based partly on considerations of relative age and generation, but the senior man and woman of the house were not automatically the most authoritative people in the family, since considerations of a more practical nature entered in. ... Younger siblings addressed their elder siblings as akaa and ekee, and were in turn addressed by their personal names, or as dew. Younger siblings never addressed elder siblings by their personal names. Brothers were rarely on terms of easy friendship with each other; they were reserved and did not joke. An elder brother could punish a younger brother physically. Although brothers might loan each other their clothes, they did not undress in each other's presence. Brothers were, on the other hand, considerably less reserved with their sisters, and could joke with them. This relationship continued throughout life. After marriage a woman felt closer to her brothers than to her sisters, because her brothers remained together in the old family home, and represented her family and ultimate authority. ... A married son or brother was always entitled to a share of the property if he desired to set up house for himself. If two or more sons left they were given equal shares\".\n\nA strict fraternal hierarchy prevailed among Mongols, and slave (\"bogol\") is equated with the category of a younger brother in The Secret History. In another passage Ogodei, though being the Great Khan, still asks for the permission of his elder brother Chagatai to invade Cathay, and Tolui sacrifices himself for his elder brother Ogodei. In the Yuan shi it is told that Nayan, weeping and beating his head to the floor, refused to accept a princely title because he had an elder brother, Qurumchi, whom he thought ought to inherit it in spite of his lower ability; in the end Qurumchi inherited the title, but he consulted with Nayan in all affairs. Mongol literature is full of events of this kind. Models of opposition between the egalitarianism of Arab societies and the hierarchical tribalism of Turco-Mongol peoples have been developed by many anthropologists, such as Cuisenier, Beck, Barfield, and Lindholm. The conical clan of Inner Asian peoples is explained in detail by Lawrence Krader in his monumental work, \"Social Organization of the Mongol-Turkic Pastoral Nomads.\" He wrote there: \"Nevertheless, this uniform kinship structure was divided into unequal estates, the nobility and the commoners. Both were estates related by descent from the clan founder; but in practice they were divided by differences in birth, wealth, accident migrations, wars. Descent lines were not equal; the line of the firstborn was more highly placed than any other, having the right of seniority… Leadership was a status that was not assigned by rote-it had to be achieved, and achievement was based on social recognition of leadership qualities.\" Sevʹi͡an Izrailevich Vaĭnshteĭn also remarks the existence of a strong fraternal hierarchy among Inner Asian (Siberian and central Asian) peoples.\n\nAmong Mongols, the marking of livestock reflected this system of social stratification. E. Landais wrote in \"The marking of livestock in traditional pastoral societies\": \"The system is based on a series of related marks that are derived from a primary mark designating the clan, which is then combined with other marks some of which are called complementary marks. These cannot be used as primary marks. The complementary marks have both syntactical and semantic properties. For instance, the 'throne' mark indicates that the owner descends from the eldest branch of his lineage, since this line, in the primogeniture system, is the one that inherits the images of the spirits of the ancestors that sit on the throne. Some of these marks, such as the 'thumb' and 'tail', the 'horn' and 'foot', the 'sun' and 'moon', are associated by pairs, or in any case suggest the existence of another mark of greater or lesser value, as applicable. An additional mark located on the right of the main mark denotes primogeniture as opposed to a left-hand position. An inverted mark along the horizontal or sagittal plane of symmetry indicates a socially inferior rank to that indicated by the primary mark.\n\nThe princes (who descend from Genghis Khan through the paternal line) mark their horses on the right-hand-side, whereas common people mark them on the left. Brothers by the same father differentiate their marks by adding a sign (rather than subtracting one which might bring bad luck to the herd) and alter them as little as possible (they might simply move them to a different position)\".\n\nDouglas R. White and Ulla C. Johansen, in a study about Turkish nomads, denied the idea that the conical clan was the type of social organization prevalent in this group, but nevertheless found evidence that earlier-born sons (first sons when there were only two sons, and first and second sons when there were more than two) took on more leadership positions and had significantly more wives and children than their younger brothers. Bates also tries to qualify the characterization of the social organization of the steppe pastoral nomads as a \"conical clan\", saying, just like Johansen about Turkish nomads, that among the Yörük nomads he studied social practices gave an advantage to elder brothers over younger ones, but this didn't mean that ranking was automatic, fixed; it was rather achieved:\n\n\"is not merely a linguistic phenomenon; it has considerable importance in interpersonal relations among siblings. What is relevant here with respect to segmentation is that the eldest of the brothers is held to be senior to all younger, irrespective of wealth, in situations of formal etiquette; he serves as spokesman when brothers act in concert. After the father's death he is obliged, more than the father in his lifetime, to provide for his single brothers, and to assist them in time of trouble . . . marriage takes place in order of birth, which again sets the order of household fissioning to form new ones as younger sons marry and bring their brides into the tent. This, of course, gives older brothers in any generation an earlier start in the production of progeny to further their name. . . . However, just as the point of segmentation does not depend entirely on genealogical depth, neither does the relative seniority of brothers escape the impact of political and residential fact in determining which of several will provide the name under which the group passes.\"\n\nOther anthropologists such as Khazanov, Lindner, Fletcher and Sneath have also rejected the theory that the conical clan was the social structure typical of the Asian steppe, arguing, contrarily to other authors, that strict succession rules based on primogeniture didn't exist in these societies. Osman Aziz Basan, in his analysis of Oguz society, found this social structure to be the dominant one, but nuanced by the importance of other factors such as \"merit\", as in the case of Turkish and Yorük nomads. Bacon wrote: \"seniority both of generation and of line were factors in selecting a chiefly successor, but ability was also of importance\" (1958:58).\n\nSome studies have found that Arab practices of endogamous marriage also benefitted elder sons and their lines of descent over younger sons and their lines of descent, thus contradicting the idea that in Arab societies, unlike in those of Inner Asia, fraternal birth order played no role at all in family relationships.\n\nIt was customary in the Ottoman Empire to let the sons of a king fight amongst themselves for the kingdom. It was almost always the eldest son, however, who succeeded in gaining the throne for himself, such as in the cases of Bayezid II, Mehmet III or Murad III. Halil Inalcik is of the opinion that among Inner Asian peoples there was no rule of succession, but notes that the first Ottoman sultans were all eldest sons and finds parallels between this tendency to make the eldest son the next king and the steppe customs of making the eldest son of the eldest line sovereign, giving the eldest son the largest share of the inheritance and the most important part of the realm, and ranking the tents in order of importance from the father's to the eldest son's and then to the eldest brother's sons; according to him, these customs were particularly common among the Kazakhs. Other scholars have also considered Kazakh society an especially good example of the Inner Asian conical clan, although others consider Mongol society the paradigm of this type of society in the Asian steppe. Buryats, for example, validated land ownership at clan gatherings where \"each component segment of the group was spatially arranged from right to left in order of genealogical seniority\" (Humphrey 1979:250). Uzbek traditional society has been analyzed under the same light. The development of conical clan structures has been linked to an increase in warfare and military expansionism in Central Asia.\n\nIn Iran, male primogeniture was the rule within the Qashqai confederacy. Within this confederacy there were three levels of leadership, and both Khan and headmen appropriated taxes and labor from members of their groups, though only the lineages of the Khans and Ilkhanis (paramount chieftains) constituted an aristocracy (Beck 1986: 193–195, 233). Thus the Qashqa'i confederacy can be considered to have been a true chiefdom confederacy. It is the contention of Lois Beck that this confederacy was a product of the interaction of nomads with the economy and institutions of the Persian state over the last 300 years (Ibid.)\n\nAs can be seen from the former examples, societies based on lineage hierarchy are particularly common in central, east and southeast Asia. Lineage hierarchy was present even in the stem-family systems of Korea, Vietnam and Japan. In Korea, the main house, that of the eldest son, was called the \"big house\" or superordinate descent group (taejong), while the houses of younger sons were called \"small houses\" or subordinate descent groups (sojong). It was through the stem family of the eldest son that the main line of descent was traced from generation to generation. Patrilineal primogeniture became prevalent during the time of the Choson dynasty. Even modern businesses are passed down according to male primogeniture in most cases. Discussing patterns of adoption in Korean families, Roger L. and Dawnhee Yim Janelli write in \"Ancestor Worship and Korean Society\":\n\n\"When adoption involves the transfer of a son between households headed by brothers, the relative seniority of the brothers usually determines whether an eldest or junior son is selected as the adoptee. younger brothers give their eldest sons to eldest brothers, but eldest brothers give one of their younger sons to younger brothers. This rule, which is common throughout Korea, was violated only twice. In both cases, eldest brothers were given to younger sons. The nonreciprocal transfer of eldest sons to eldest brothers reflects the special status accorded to a primogeniture descendant (chongso: eldest son, eldest son's eldest son, etc.) by those who belong to junior descent lines. Just as an elder brother has a higher status than his younger siblings, so his own eldest son retains some of that status over the younger brothers's sons. Giving eldest sons to senior descent lines, therefore, preserves the relative statuses of siblings based on birthright. One who had enjoyed superior status as an eldest brother before adoption enjoys it as a primogeniture descendant after adoption. Occasional violations of this adoption rule wreak havoc on the relative seniority of descent lines. Violations occur because Korean adoption practices also attempt to preserve the respective property rights of descendants. Since an eldest brother inherits more property, he is usually wealthier than his younger siblings. If he dies without descendants, his younger brother would inherit his larger share of property from their parents and in turn pass it on to his own eldest son. That eldest son, by becoming the adoptive heir of the elder brother, therefore inherits essentially the same property he would have without the adoption\".\n\nIn Korea, chiefdom confederacies where male primogeniture was the rule were a fact of early Korean history since the first millennium BC. The first may have been Old Joseon (also Kochosŏn, Gojoseon), said to be a confederacy of three tribes (Lee et al. 2005: 53).3 'The Hwanug tribe formed an aggregation with adjacent tribes or villages and then subjugated other aggregations…' (ibid.: 54). 'Old Joseon was basically a confederation and could not be easily ruled from the center' (ibid.: 64). Old Joseon's counterpart in South Korea was Jin (also Chin), also described as a loose confederacy. These confederacies ultimately broke apart into their constituent units (geosuguk), which then reformed into new confederacies: Puyŏ (also Buyeo), Koguryŏ (also Goguryeo), Ye, the Three Han (Samhan), and Gaya. These chiefdom confederacies were eclipsed by the consolidation of three of these polities into the states of Goguryeo, Baekje and Silla in the first century CE. However even these polities did not really develop centralized systems of territorial administration until the fourth century AD (Lee et al. 2005: 179).\n\nIn Japan, too, the main house, that of the eldest son, was called \"honke\", while the houses of younger sons were called \"bunke\". Younger houses were theoretically subordinate to the eldest house. There was a peculiar family type, the dozoku, which consistently reproduced this hierarchical arrangement. Edward Norbeck found survivals of this family type even as late as during the 1950s in Tohoku, in northeastern Japan. According to the author,\n\n\"The branch household stood in a social position much inferior to its founding household, and was expected to give aid to the founding household whenever it was needed. Many customs gave expression to the hierarchical relationship of the two households. Main households had obligations to their branches of providing economic support, but the greater obligation was undoubtedly upward, from bunke to honke. One of the standardized conventions of social interaction between the two was a formal exchange of greetings, congratulations, and small gifts at New Year's, the Buddhist Bon festival of midsummer, and at other ceremonial occasions. These exchanges were always initiated by the junior households, whose heads came at these occasions to call at the homes of the seniors.\"\n\nHowever, as the author also explains, not even in this region had the dozoku ever been popular, since establishing a branch family was generally difficult. Most \"branch\" families that had been established during the years immediately prior to his study had been established without the aid of the main house and functioned more or less independently from the latter.\n\nLineage hierarchy was also present in the Vietnamese family. Mark W. McLeod and Thi Dieu Nguyen write in \"Culture and Customs of Vietnam\":\n\n\"In pre-colonial times, the Viet were defined first and foremost by their families, which were fundamentally patrilineal and patriarchal in character. The \"clan\" (toc), which included a number of families related to each other through a common male ancestor (thuy to), formed the basis of society. Each clan was identified by a specific lineage name (ho) or surname, of which there are approximately 300, the most common being \"Nguyen\", followed by \"Tran\", \"Pham\", and \"Le.\" To the clan leader (truong toc) -the eldest male in the oldest branch directly descended from the founding ancestor- fell a number of duties: for instance, keeping and preserving the genealogical register (gia pha), which records the names, births, and deaths of members. Well kept registers would list the land or other properties used for the maintenance of the ancestral cult. The truong toc, who resided in the ancestral home and presided over the family council, was the one to whom related families or members within each familial unit would turn to resolve disputes; he made decisions related to lineage matters; and he served as the protector of widows and minors as well as the moral anchor for all within the clan. Within this larger body of the toc, there was the family (gia dinh): traditionally multigenerational (grandparents, parents, and children, uncles and aunts, and sometimes great-grandparents); it revolved around its central figure, the family head (gia truong) who could be the grandfather or the father (bo or thay). All owed obedience to him. The family head ruled over all family members in all matters, including property rights, education, marriage and profession, and he spoke on their behalf in dealings with the outside world. He had the power to reward or to chastise; to him were incumbent the duties of protection, of feeding, and of education, both morally and academically, vis-a-vis everyone in the family\".\n\nTheresa Phuong-Thao Pham writes in \"Family, Change and Mobility in a North Vietnamese Family\":\n\n\"The powerful lineage is known as the 'senior families' (ho dan anh) and the less powerful families are considered the 'junior families' (ho dan em). The patrilineage organization plays a role in the establishment of the villages and the development of the cultivated areas of North Vietnam (Nguyen 1993). The first group of people who left their native villages to establish new villages on new land acquisition was often composed of members of the same patrilineages. In a highly stratified society, the small families in the same patrilineage had different socio-economic positions, which can translate intocomplications for the kinship system. Traditional family record (gia pha) consists of the head of the lineage (toc truong), the heads of the branches (chi truong), a system of rituals composed of ancestor worship and the family temple, and economic means such as the family paddy fields (ruong ho) to support this worship. The family temple resembles clan system, in which members all the strands or chi of the family would pay homage on the death anniversaries of the toc truong (the head of the lineage). The redistribution of land by the Communist party since 1954 has greatly altered the family system of worship. The family temple no longer exists, but the celebration of the death anniversaries of ancestors still continues on a much smaller scale consisting of family members up to three generations. The celebration usually takes place at the eldest son's house with all immediate family members present on the death anniversary of the elder family member. The family members, usually the women, would place the food on the altar and offer the food to the deceased person before serving the food to the family members present at the meal. Family members often wear colorful headbands following the death of a family elder for up to three years\".\n\nTherefore, the conical clan of the Asian steppe, Austronesian societies and southern Bantu societies was based on a rule of primogeniture. E.R. Leach observes that a different system prevailed among the Kachin. The Kachin gave most of the land to the youngest son (patrilineal ultimogeniture) and most of the moveable property to the eldest son (patrilineal primogeniture). According to Leach, \"the kachin gumsa situation is that both the eldest and the youngest son are privileged in relation to their other brothers. The eldest brother is ideally a warrior who goes out with a group of followers drawn from his father's relatives and supporters and carves for himself a new domain; the youngest brother stays at home and inherits the ritual function of guardian of the shrine and, in the case of a chief, of the madai nat.\" Lineage rank was also determined by patrilineal ultimogeniture: \"The ritual status of the youngest son chief and his descendants is deemed to be higher than that of the eldest son chief and his descendants\", while middle sons and their descendants are ranked even below eldest sons and their descendants. In case of death or inability of the youngest son, the eldest son inherits the land as well, in preference to a middle son. According to the same author, this principle of ultimogeniture-primogeniture is reversed in Assam and the North Triangle; among the Kachin population of these regions, the eldest son inherits the house and lands of the father and the youngest son inherits the moveable property. The opposite gumlao situation is that of a more democratic and flexible system and emerges when chiefs and/or aristocrats are led to repudiate Kachin social rules, especially patrilineal ultimogeniture, partly due to the influence of the Shan, who do not employ this mode of inheritance. Shan succession rules, \"though somewhat vague, appear to favour primogeniture -at least in theory. Thus although, from certain aspects, the gumsa system can be regarded as modelled after a Shan pattern, the gumsa chief whose status and power begins to approach that of a Shan saohpa is led to repudiate principles which are fundamental to the gumsa system\". The Kachin stand in diametrical opposition to Austronesian societies with regards to rules of land and chieftainship succession, as shown by Leach, the great expert on Kachin society, who uses a comparison with Batak society to illustrate his point.\n\nThe Indigenous peoples of the Pacific Northwest Coast were socially stratified. Bruce Elliott Johansen wrote in \"The Encyclopedia of Native American Legal Tradition\":\n\n\"The Northwest Coast culture stretched from the Alaska Panhandle to the northwest coast of present day California. Members of Northwest Coast nations built large, substantial houses for extended families from massive beams taken from the tall timber of the coast. ... Rank and status permeated nearly every facet of their lives, even dictating what portion of a house a given person occupied. The class system was hereditary as well. The class structure was fixed in time, handed down in temporal lockstep by the rules of primogeniture, the passage of rights and property to the firstborn son. Northwest Coast peoples recognized three classes that seemed as imperishable as the red cedar from which they constructed their lodges: nobility, commoners, and slaves. The nobility comprised chiefs and their closest relatives; the eldest son was the family head. He, his family, and a few associates lived in the rear right-hand corner of the house, abutted by people of lower status. These people were said to be \"under the arm\" of the chief. The next highest-ranking chief, usually a younger brother of the head chief, invariably occupied the rear left-hand corner of the house, with his family. He, too, had a number of people \"under the arm\". the other two corners were occupied by lesser chiefs' families. The space between the corners, along the walls, was used by commoners' families and a few very junior-ranking nobility. They were called \"tenants\", while the nobility in the corners reserved the right to ownership of the house. ... Slaves had no designated lodgings or rights; they were captured in raids on other peoples along the coast and were sometimes traded for other slaves or goods. A noble in one village could be captured and sols into slavery in another. the captive's relatives might then mount a counter-raid to free him. A person also could fall into slavery because of accumulated unpaid debts\".\n\nRaymond J. DeMallie and Alfonso Ortiz wrote in \"North American Indian Anthropology: Essays on Society and Culture\": \"Among some Coast Salish, particularly those on Vancouver Island and the Straits Salish, the kinship system contained a potential basis for primogeniture. For example, separate terms for the oldest child existed in some societies. Also, the term for younger sibling was used as synonymous for members of junior lines (i.e., the children of siblings younger than the parents). This pattern was reflected to some extent in behavior. Barnett (1955:250-51), speaking about the Coast Salish of British Columbia, says that the oldest son would inherit the name (presumably the most distinguished name belonging to the family). Summing up the emphasis on primogeniture, Barnett states:\n\n\"Rank depended, not alone upon birth in a certain family, but also upon the order of birth within it. Within any given family, the possession of valuable items and resources of wealth and of ceremonial preprogatives was the important criterion of status. As a rule, this correlated paripassu with order of birth, for in general all rights were inherited. A fifth son in an aristocratic family therefore ranked far below the first, and his first cousin far below him (1955:247)\".\n\nNote that the \"resources of wealth\" included the title to lands such as fishing sites and ownership of such food-getting devices such as sturgeon nets. The oldest son was expected to share lands belonging to the family with other members, but he was in control of those lands and directed their use. Where family masks, dances, and other privileges were concerned, he decided when and under what circumstances they could be used\".\n\nWilliam C. Sturtevant wrote about the Nootka in \"Handbook of North American Indians: Northwest Xoast\":\n\n\"Kinship and hereditary rank were fundamental in the organization of Nootkan society. Kinship terminology is lineal in parents' generation and Hawaiian in ego's generation, consistent with ambilineal descent and the option to shift residence. The generations are consistently distinguished, and within ego's generation, senior and junior lines are distinguished. Parents' older and younger siblings' children are called by the terms used for own older and younger siblings, and the distinction continues in subsequent generations, so that an old man might call a boy 'older brother' if the boy's grandparent was the older sibling of his own grandparent. This usage is consistent with the importance of primogeniture. Brother and sister treated one another with reserve, especially while unmarried. Those called brother and sister could not marry, even if remote cousins, but if kinship was so remote that links could not be traced it was possible \"to marry one's own\", usually to get back hereditary rights that had left a descent line. Parent-child relations were close, and grandparent-grandchild especially close, as children often stayed with grandparents. Aunts and uncles were like parents, and one helped oneself to their things without asking. With parents-in-law there was great familiarity. Step-father and step-daughter kept their distance. Descent was ambilateral and kinship traced in any line allowed an individual to claim membership in more than one local group. Residence with a given group activated membership in it as a kinsman, and while there the individual gave it his loyalty and participated in its activities. Although residence was mainly patrilocal, in the long run there was no set rule. People were constantly moving between groups. Rank was closely linked with kinship, positions, such as chief, being inherited by primogeniture. A chief (the native term, hawii, also means 'wealthy upper class') was simply the highest-ranking member of a kin group of whatever level. Rank was founded on inherited rights called tupa'ti, thought of as property, which governed the ownership and use of practically everything of value. Tupa'ti, depending on their nature, could be inherited by an eldest son, shared by several children, held by an eldest daughter until her marriage and then transferred to her brother, or given to a son-in-law as common alternatives. There was a sense of patrimony of rights in a local group to be kept as intact as possible as it passed down through successive chiefs. The inheritance of tupa'ti tended to be through males. Over generations a number of descent lines developed in a group in a ranked relationship made explicit at feasts and potlatches in the order of seating, serving, and gift receiving. Rank was also constantly embodied in the place occupied in the big house. The top chief and house owner occupied the right rear (right for one facing the entrance), the next in rank, a brother or other close kinsman, the left rear. In between might be the head's married sons. Left and right front corners belonged to the third and fourth ranked. Middle sides could be for fifth and sixth ranked. Such interior locations were hereditarily owned. By the entrance were the slaves, mostly war captives, who were significant as trade objects, protective attendants, and even sacrificial victims. Commoners (were either those living with a chief, often quite close relatives, or less definitely associated transients along the sides. They always belonged to some chief who addressed them as kin. Even secondary chiefs were mascim (commoner) to a head chief. Although rank was graded continuously, an upper stratum could be distinguished consisting of indisputable chiefs with potlacht seats and titles to resource sites plus closely associated supporters, generally immediate relatives. Chiefs were the nuclei of Nootkan society; they owned practically everything and ideally did not work but directed followers. A chief and his family wore richer dress, abalone and dentallum ornaments, sea otter or fur-trimmed robes, and decorated rain hats and owned powerful symbols. For the use of resource sites the chief collected a tribute in kind, of no fixed amount, with which he could give a feast. However, big sea or land mammals belomged to the hunter who gave a feast with his catch. A chief's sons and younger brothers were subsidiary chiefs, war chiefs, and speakers, but the eldest son nominally took the top position while still a youth to ensure succession, the father continuing to actually run affairs. Some younger brothers of chiefs became independent chiefs through conquest of other groups. Other avenues to chiefship were potlatching or marriage to a woman of high rank. A chief and his more distantly related commoners were interdependent, the maintenance of his high standing resting on the support of the commoners, who in return had their children named ceremonially, were assisted in marriages, often lent privileges for social use and even granted minor rights. The chief of a group was regarded as a father looking after his children, authoritarian but beneficent\".\n\nIrving Goldman thought that the Indigenous peoples of the Pacific Northwest Coast could be related to the Polynesians. He wrote:\n\n\"For reasons that remain to be discovered, the Indian tribes of this area [NW Coast] share formal principles of rank, lineage, and kinship with Pacific islanders. The Kwakiutl, especially, seem very close to what I have designated as the \"traditional\" Polynesian society. They share with Polynesians a status system of graded hereditary ranking of individuals and of lineages; a social class system of chiefs (\"nobles\"), commoners, and slaves; concepts of primogeniture and seniority of descent lines; a concept of abstract supernatural powers as special attributes of chiefs; and a lineage system that leans toward patriliny, but acknowledges the maternal lines as well. Finally, Kwakiutl and eastern Polynesians, especially, associate ambiguity of lineage membership with \"Hawaiian\" type kinship, a fully classificatory system that does not distinguish between maternal and paternal sides, or between siblings and cousins\".\n\nRanking by matrilineal primogeniture (the nephews of a man by an elder sister rank higher than his nephews by a younger sister) prevailed among the Natchez.\n\nThe conical clan was also the form of social organization among many peoples in Pre-Columbian America, like the Aztecs (calpulli), the Inka (in fact this anthropological concept was created by Kirchoff to describe the form of Inka social organization, the ayllu; see also Isabel Yaya's description of the Inca ayllu in her work \"The Two Faces of Inca History: Dualism in the Narratives and Cosmology of Ancient Cuzco\") or the lowland tribes of Central and South America described by Kalervo Oberg.\n\nThomas Allan Abercrombie discusses the ayllu extensively as it exists today among the Aymara people in \"THE POLITICS OF SACRIFICE: AN AYMARA COSMOLOGY IN ACTION\": \"The ranking of ayllus is (and was?) performed in an idiom derived from what is ... a central and divisive cleavage in the nature of the domestic group, birth order among siblings, who are contrasted not only by age but by their differing rights to leadership roles, fiesta-cargo offices, and property. ... Patrilines are not mere aggregates of patronym possessing men and their families, juxtaposed only because of rights in land. Rather, they are structured, internally hierarchical social units, in which collective action is both enabled by, and enables the creation of, formally recognized positions of authority.`... Within the \"patristem family\" -a group of brothers who have constructed houses around the patio of their father—authority is vested in the father until his death. Afterwards, however, it is the eldest brother, the jiliri or jiliri jilata, who is regarded as becoming the kamachiri. This works out at the level of the sibling group, but what about the group of patristem units, some with nearest linking ancestors beyond the reach of memory? There exists a notion of an informal collective body of jiliris within the hamlet and patriline which can act as a sole council of elders. On close inspection, however, it turns out that these jiliris are neither equal in status nor necessarily eldest brothers within their own patri-stem sibling groups! In fact, jiliri status outside the patristem unit (and this unit begins to fragment after the death of the father of the sibling group) depends on the combination of appropriate \"leaderly\" personal qualities and the individual's status in the \"elder brother and herder-making\" system of public ritual careers. Moreover, greatest authority, that accompanied by the power to impose sanctions by force, is said to reside in a body of officials known as the jach'a íilírís. the \"great eldest brothers,\" that is, in ayllu level authorities also known as alcaldes, alguaciles, and íaías. It is almost certain that the name for this last office (the highest ranking of the three), is derived from the root jila, from which both jilata (\"brother\") and jiliri (\"eldest\" or \"first [born]\") are derived. The patrilineal hamlet as well as ayllu authority is also designated by terms related to herding roles. First, he is compared to the lead animal of the herd, the llantiru (from Sp.delantero, \"one who goes before\"). Secondly, he is known as the patriline's or ayllu's awatiri (herder), in which capacity the group which recognizes his authority becomes his rama (herd)... Upon his death, the sullk'iri may inherit the house and herd, but it is to the eldest son, not the youngest, that the status of kamachiri falls. And his comnmand extends into serious matters such as the allocation of lands and pastures within the sibling group, control over fallowing cycles, decisions about the opening of new fields (which may lead to warfare with neighboring groups), and the timing/itinerary of collective caravan expeditions to the valleys. In addition, it is the kamachiri who controls important ritual matters (related to herd fertility) which take place at the very altars he does not inherit. ... Like the llama llantiru, the role of eldest brother and the authorities who are called iilírí encode a principle of reproduction. First, as authority at the level of hamnlet, patriline, ayllu, and moiety, the jiliri conjoins the particular domestic groups of a hamlet ando patriline, the patrilines of the ayllu, and the ayllus of a moiety, by standing to all in an equivalent transitive relationship. The sullk'iri, on the other hand, reaps the rewards of inheritance, but is thereby irrevocably identified with the continuity of a particular household-that of his father—rather than with its reproduction. Like the llama-llantiru, the jiliri-llantíru owes his dominant position to control over herds, but here we refer to both animal and human ones. Unlike the youngest brother in the sibling group, who remains essentially a social extension of the father and a permanent dependant, the eldest brother receives the father's \"command\" (kamachiri), though he is exiled from his father's house and (to a degree) disinherited from his herd. His authority is, in fact, closely connected to his outward-directedness. The eldest brother could be said to be autonomous and self-generating-by establíshing his own house and herd, he is the embodiment not of the continuity of a house and herd (like the sullk'iri), but of the principle of reproduction of the very unit he is excluded from. As such, within and outside the patrigroup the jiliri also embodies the fertility (that is, the expansion) and generativity of the patriline. Like the llama llantiru, the jiliri-llantiru is associated with the conjunction of disparate herds in a new, unified herd. The jiliri's actual leadership role within the sibling group and patronymic hamlet amplifies these associations. The jiliri's \"command\" extends from the role of arbiter in intra-sibling group disputes, to that of leader of the conjoined brothers in disputes with other sibling groups within the hamlet or patriline. In addition, it is the jiliri who, stereotypically, decides when and where to go on annual trading trips, and conjoins multiple herds to make up the large caravan needed for a successful trip. it is men who are (or are becoming) jiliris who are the most likely to be able to establish a conjoint herd, garner sufficient labor, and otherwise mount a successful trade expedition. Such expeditions are crucially important source of foodstuffs, and are refracted within the collective ritual sphere in an inverse type of caravan trade (carrying foodstuffs to the ayllu-and moiety level \"ladder\" of the town for the fiesta, and returning empty-handed to the hamlet) through which the status of jach'ajiliri is achieved. But it is not only in his capacity to circulate foodstuffs that the stature of the jiliri is achieved, but in an attendant control over the circulation of the generative substances blood (wila) and fat (as a kind of solidified muju) among the human and animal, and the earthly and otherworldly realms. The point is not that only jiliris establish independent, conjoint households and herds, but that the opposed attributes of youngest and eldest brothers make them appropriate vehicles for representing two opposed facets of the household and herd: the fírst (typified by the youngest brother in dependant filial roles) is its continuity per se, as a particular unit; the second (typified by the eldest brother in independent founding-pater role) the general model or generative principIe of the household and herd as a type of social arrangement produced by, and reproducing, the patriline. Once he has begun his career, or continued an inherited one, the sponsor-jiliri joins the ranks of patriline-hamlet \"fathers\" and \"elder brothers\", and with it takes on, at the inter-domestic group level, what was, in the domestic group, the leadership roles of elder brother and father. This role is, of course, a function of the sponsor's \"outward directedness\", expressed in his ritual duties but represented as well in the terms of the asymmetric relations among exogamous patrilines within the ayllu. Patriline jiliris, like jilaqatas, are made, not born. But they are made in the image of the \"self made man\" of K'ulta society, the eldest sons, who must build their households themselves through the control they achieve of herds and alliances. Marriage is but the fírst step towards becoming a collective elder brother, herd-leader, and herder of men. The asymmetrical nature of marriage alliances, however, does not make a man into a herder of men, but a subordinate member of the herds of his wife's brother and wife's father, and he will remain thus subordinated until he turns the relation on its head by becoming a herder of his own sisters' and daughters' husbands. Accomplishing this involves withholding one's children's inheritance and \"seniority\" as long as possible, just as it requires establishing oneself in the status of superior among equals among one's own sibling group\".\n\nIn the Amazonia the conical clan survived the conquest and could be researched in situ by anthropologists. Michael J. Heckenberger writes about the xinguanos in \"The Enigma of the Great Cities: Body and State in Amazonia\":\n\n\"Hierarchical social relationships are described in terms of the degree of respect or \"shame\", ihuse (to be in a state of deference or \"shame\" [ihuse-ndagu] to a social superior), that one individual has for another. ... Children and their spouses are ihuse-ndagu to their parents and parents-inlaw, wives are to their husbands, younger siblings are to elder siblings, and, most notably in the present context, commoners are to the primary chiefs. This relationship is metaphorically represented in chiefly discourses where community members are called \"my children\", \"my sons\", or simply \"children ... Structurally hierarchy is based on primogeniture within an otherwise cognatic kinship system, whereby the higher ranking individuals derive status form their relative position in the chiefly hierarchy. More or less similar structural patterns, variably referred to as status lineages, conical clans, or house societies, have been identified for a wide range of moderately stratified societies. It is typically the case in these other hierarchical societies that the temporal extension of birth order ranking is branching, what Firth (1936) called ramification, whereby chiefly lines (e.g., the oldest sons of oldest sons) become separated from subordinate lines (the youngest sons of youngest sons). Such a structure of hierarchically organized kin groups simultaneously divides society into upper strata (chiefs) and lower strata (non chiefs) while incorporating both in a unified structure\".\n\nThe Tukanoan \"are patrilineal and exogamous: individuals belong to their father's group and speak his language but must marry partners from other groups who speak other languages. Externally, groups are equal but different; internally each is made up of a number of named clans ranked in a hierarchy. The ancestors of these clans were the sons of the Anaconda-ancestor and their birth order, the order of emergence from their father's body, determines their position: higher ranking clans are collectively \"elder brothers to those below. Clan rank is correlated with status and prestige and loosely correlated with residence: higher ranking clans tend to live in favoured downstream locations with lower ranking clans often living upstream or in headwater areas. Clan rank also has ritual correlates: top ranking clans, the \"head of the Anaconda\", are \"chiefs\" or \"headmen\" who control the group's dance ornaments and Yuruparí and sponsor major rituals; middle ranking clans are specialist dancers and chanters; below them come shamans; and at the bottom are servant clans, the \"tail of the Anaconda\", who are sometimes identified with the semi-nomadic \"Makú\" (A pejorative term with connotations of 'servant, slave, uncivilised, etc.\" ) who live in the interfluvial zones. This hierarchy of specialised roles and ritual prerogatives is most evident during collective rituals where genealogies are recited and where relations of rank and respect are emphasised. In a more subtle way, it is also reflected in everyday life. The inhabitants of a maloca are typically a group of closely related men, the children of the same father or of two or more brothers, who live together with their wives and children. When a woman marries, she leaves her natal maloca and goes to live with her husband. In symbolic terms, the maloca replicates the world in miniature and the maloca community is a both a replication and a future precursor of the ideal clan organisation described above. Here the father of the maloca community would be the Anaconda-ancestor of the whole group and his sons the ancestors of its component clans. In real life too, the eldest son and senior brother is typically the maloca headman and quite often his younger brothers are dancers, chanters or shamans, sometimes in appropriate order of birth\".\n\nStephen Hugh-Jones writes about the Tukanoan in \"Clear Descent or Ambiguous Houses ? A Re-Examination of Tukanoan Social Organisation\": \"Horizontal affinal exchanges between different groups have their complement in the vertical or hierarchical ordering of agnatic relations within each one. Each group, descended from an anaconda ancestor, is divided into a number of clans or sibs ranked according to the birth order of their founding ancestors, the anaconda's sons. Members of a given sib refer to other sibs as their elder or younger brothers. In theory, each sib should live in a single communal long-house or maloca; in practice the residence group typically consists of a sib-segment or minimal lineage, a group of brothers living with their parents and their in-married wives. The maloca community is the minimal exogamic unit and residence is virilocal: on marriage, wives move in whilst sisters move out. Tukanoan life is river oriented; in theory, and to some extent in practice, sib rank is reflected in spatial organisation. Senior sibs live downstream relative to junior sibs who live towards the headwaters. ... The headman and owner of the house is normally the eldest brother. He is treated with a certain amount of deference and has his compartment on the right hand side furthest to the rear; the compartments of married younger brothers are further towards the front whilst both unmarried youths and guests sleep near the front door. Each family represents a potential household and, in the end, tensions between them (typically over food, sex and authority) lead to the break-up of the group. ... Groups are divided into one or more sets of sibs internally ranked as elder/ younger brother as if the component sibs were a group of male siblings, the sons of the anaconda father. Sets of sibs, ideally numbering five (as in the primal house), claim specialised roles as their ritual prerogatives: the top sib are chiefs followed by chanter-dancers, warriors, shamans and servants in that order; in any given area, not all these roles are necessarily represented by extant sibs. Thought this caste-like division is expressed at sib level during ritual, in daily practice it operates only at an individual level. Male children should be given a name appropriate to their birth order and linked with the ritual role which they should adopt in adult life. In practice, the eldest brother is indeed usually the maloca headman and his younger siblings may also specialise as dancers, chanters and shamans according to seniority\"\n\nJean Elizabeth Jackson wrote the following about the Tukanoan people in \"The Fish People: Linguistic Exogamy and Tukanoan Identity in Northwest Amazonia\": \"Vaupés sibs (clans) are named, ranked, exogamous, localized patrilineal descent groups. ... Sibs are named, and these names often refer to plant or animals. Sib names can also refer to sib ancestors and their immediate descendants; this is also true for the personal names owned by each sib. These personal names are given to infants in a prescribed order. The eldest son of the headman ideally is the first-born male of his generation and receives the first name on the list. This sib-supplied name fosters growth, for it associates the newborn child with a nurturing group of agnatic kinsmen. The infant becomes more human upon receiving a name, for it is an explicit affirmation of membership in the sib, entitling it to the power and nurturance available from the ancestors. ... The sibs in a given language group are ranked. The order of ranking is explained as corresponding to the order in which a group of brothers, the ancestors of the various sibs, emerged from the rocks at a particular rapids site. ... The ranking of sibs is continued today with the use of elder-younger sibling terms between members of different sibs. However, in some language groups the difference in rank between certain pair of sibs is so great that generational divisions are brought into play. This results in an unusual and initially surprising usage of cognatic terminology. A person who belongs to a considerably higher ranked sib than another will address the other as \"uncle\" or \"grandfather\". This seemingly incongruous state of affairs is explained by Tukanoans as follows: The first ancestors of all the sibs of one language group were brothers to one another. The eldest brother emerged from the rocks at the rapids first, and the youngest last. However, there were many brothers in the beginning, and obviously there were many years between the birth of the eldest and the youngest brother. By the time the youngest brother emerged at the rapids, the eldest was very old, and had great-grandchildren. Thus, although the eldest and youngest brothers called each other \"brother\"; because many years had passed between their births the younger brothers were addressing as \"grandchild\" those individuals in the eldest brother's sib who were close to them in age. This is why, today, when people of about the same age are heard using grandparent and grandchild terms to each other, it is the one who says \"grandfather\" and who is called \"grandson\" who is of higher rank. Sib rank is signaled in other ways as well. One method of indicating a sib's ver low rank is to impugn its origins with the claim that it is a \"new\" member of the language group, \"who were our servants, who had to be taught how to build houses and speak our language. Then, taking pity on them, we adopted them as our youngest-brother sib.\"\n\nRobin M. Wright writes about the Baniwa in \"Umawali. Hohodene myths of the Anaconda, father of the fish: \"Baniwa society is some six exogamous phratries, each consisting of 4-5 patrilineal sibs ranked according to the order of emergence of mythical ancestral brothers. Like their Tukanoan neighbors, sibs were once categorized (the system has suffered numerous changes due to a situation of permanent contact) according to a system of ritual roles as ciefs (enawinai), shamans, warriors, dancers, and servants (makuperi). ... The core of local communities is the male sibling group and, as on the phratric end sib level, male sibling ties form the basis of a system of hierarchical rank according to relative age. Traditionally, the agnatic sibling group of a community constituted the most important level of decision-making. Leadership is often exercised by the eldest brother of the local group. Oral histories indicate that warfare was an important dynamic in socio-political relations with Tukanoan and Maku peoples of the Uaupés, and that war chiefs frequently organized communities of younger-brother warrior sibs to conduct campaigns for the purposes of undertaking vengeance and capturing women and children. Warfare also has a fundamental importance in mythology\".\n\nThe Gê-speaking peoples of the Amazonia were also organized in conical clan similar to those described above.\n\nSome isolated lowland tribes of Central and South America have also preserved the conical clan as their form of social organization. Such is the case of the Koji people of Colombia.\n\nIn the South Cone, ranking by patrilineal primogeniture prevailed among the Mapuche.\n\nC. Scott Littleton has suggested that ranking by patrilineal ultimogeniture could have prevailed in Proto-Indo-European society. He wrote the following in \"The New Comparative Mythology: An Anthropological Assessment of the Theories of George Dumezil\":\n\"Gerschel published, in 1956, a most interesting, albeit exploratory, paper. Entitled \"Sur un schème trifonctionnel dans une famille de légendes germaniques\", the paper is concerned with the possible existence of a tripartite scheme in a series of German and Swiss legends wherein a man or a woman performs some service for the \"little people\" (fairies, elves, etc.) and, in return, receives three gifts (e.g., a ring, a sword, and a loaf of bread) which are to be passed on to the three sons. So long as these three items are preserved, the three branches of the family will prosper. These gifts, of course, are seen by Gerschel as symbolic of the three functions, and the prosperity of the three sons so endowed varies accordingly: the eldest son receives a gift symbolizing the third function (e.g., a loaf of bread; cf. the third function identification of Lipoxaïs, eldest son of the Scythian Targitaos) and becomes a successful farmer and the father of many children; the second son receives a gift symbolic of the second function (e.g., a sword) and becomes a successful warrior; the youngest son receives a gift symbolic of the first function (e.g., a ring or a cup) and becomes a priest, an abbot, or the governor of a province. Should these objects be lost or destroyed, then the three branches of the family will cease to prosper in their respective ways. Often the first and second sons lose their talismans, while the youngest, who holds the gift symbolizing sovereignty, is able to preserve his by sequestering it in an abbey and thus continues to prosper. Gerschel concludes that these modern (fifteenth-to eighteenth century) South German and Swiss legends, many of which are tied to existing families in the area and are used to explain the differing fortunes of various branches thereof, \"sont susceptibles de récéler une matière d' origine indo-européenne: la légende est ici héritière du mythe\" (1956, p. 92). This interpretation, if correct, is, in my opinion, of the highest significance; it implies that the tripartite ideology has persisted far beyond the phase in which epics were composed, that it trascended the era of classical historical interpretation, and that, despite well over a thousand years of Christianity, it still forms a part of the European world view (at least in Bavaria and some Swiss cantons). As I see it, even if these legends are but isolated examples, Gerschel's work, coupled with that of Dumézil, opens up some most interesting avenues of research, ones that have perhaps some important theoretical implications as far as the relationships among language, society, and ideology are concerned. Another matter that this article brings into focus is the extent to which Proto I-E society was characterized by ultimogeniture. I have alluded above to Lipoxaïs, who, as the eldest son, received the lowest rank; conversely, his youngest brother Kolaxaïs became sovereign. In these German and Swiss legends, the same thing happens. Elsewhere the evidence is not clear-cut, but hints of ultimogeniture can be found throughout ancient I-E literature. One such example can be seen in the kinship in heaven theme mentioned previously in my discussion of Wikander's work; here again, the youngest son inherits the sovereign position (cf. the positions of Zeus, Feridun, Tesub, etc., relative to their respective siblings). That this was indeed the Proto I-E pattern is still an open question, but I feel that a good case for it can be made on the basis of the evidence presented above\".\n\nIt is possible that even the Proto-Germanic word for \"king\" (kuningaz) derived initially from the word for \"youngest son\" (see Rígsþula).\n\nOn the other hand, Gilman's concept of \"Germanic societies\", characterized by \"1) the autonomy of households (which are the basic units of production); 2) the coalition of households that makes up the community, which takes the form of tribal assemblies with authority in matters of war, religion, and legal disputes; and 3) hereditary leadership of the assembly's military and judicial activities\" is opposite to the conical clan model. Gilman included in his category of \"Germanic societies\" some societies from East Africa and the Near East, unrelated to Germanic peoples from an ethnic or linguistic point of view but similar in their form of social organization (this concept originated from studies of the early forms of social organization in La Mancha, Spain). This form of social organization has also been called \"segmentary lineage model\", and prevailed mostly among Semitic peoples, such as Arabs or ancient Israelites, but also among Iranian societies, Slavic societies, Tai societies and some societies from East Africa such as the Nuer, whom Evans-Pritchard studied extensively. Pashtun society is nowadays the largest society of this kind. In this model of social organization, every member of a society claims descent from a common ancestor, but all lines of descent are considered equal, not ranked.\n"}
{"id": "12327097", "url": "https://en.wikipedia.org/wiki?curid=12327097", "title": "The Complete Works of Charles Darwin Online", "text": "The Complete Works of Charles Darwin Online\n\nThe Complete Work of Charles Darwin Online (or Darwin Online) is a freely-accessible website containing the complete print and manuscript works of Charles Darwin, as well as related supplementary material.\n\nDarwin Online is a research project and website based at the National University of Singapore. It aims to provide all available print and manuscript material except unpublished letters, which are being made available separately by the Darwin Correspondence Project. In addition Darwin Online includes the largest bibliographical list of Darwin's publications and the largest union catalogue of Darwin papers and manuscripts worldwide. The site also provides an extensive collection of related materials such as reviews of Darwin's books, descriptions of his Beagle specimens, obituaries and recollections and works cited or read by Darwin. There is also general history and commentary—some from published sources and some prepared for the project. \n\nThe project began in 2002 and first produced a pilot website, \"The writings of Charles Darwin on the web\", replaced in October 2006 by the new website. The launch was widely reported, and the project has been widely reviewed by professional publications in biology, and librarianship.\n\nThe site contains at least one copy of all known Darwin publications, both as searchable text (98,000 pages) and full colour images (80,000 images). Most of this material was not previously available on the internet – or never even reproduced in any form. New items are still being found and added, along with further editions, translations and transcriptions of Darwin's handwritten papers. \nIn April 2008 Darwin's private papers were launched. The event marked the largest release of new materials by and about Darwin ever published. The collection covers c. 20,000 items across c. 90,000 electronic images. One notable item is the Diary of Emma Darwin (1808–1896), Darwin's wife.\n\nThe site is accessible open access free of charge. It is copyright, with permission for non-commercial use.\n\nThe project was privately funded by the founder and Director, John van Wyhe, from 2002-5. From 2005-8 the project was sponsored by the United Kingdom Arts and Humanities Research Council. The principal grantees John van Wyhe of Christ's College. University of Cambridge is Director of the project; James Secord of the Department of History and Philosophy of Science, University of Cambridge and Janet Browne of the Wellcome Trust Centre for the History of Medicine, University College London were the principal investigators for the grant. The project is now supported by private donation.\n\n"}
{"id": "24192975", "url": "https://en.wikipedia.org/wiki?curid=24192975", "title": "Thought and Change", "text": "Thought and Change\n\nThought and Change is a 1964 book by the philosopher Ernest Gellner, in which the author outlines his views on \"modernity\" and looks at the processes of social change and historical transformation and, perhaps most forcefully, the power of nationalism. Maleŝević and Haugaard argue that the method is the socio-historical method, and Gellner sets out a powerful sociology of specific philosophical doctrines and ideologies, from utilitarianism and Kantianism to nationalism. The chapter specifically dealing with nationalism was later expanded to form the basis of Gellner's most famous book, \"Nations and Nationalism\" (1983).\n\nThey also note that rather than looking at the internal coherence of philosophies, Gellner places them in their historical context. He thus explains their origins and their likely influence. Modernity is considered to be \"unique, unprecedented and exceptional\", with characteristics sustained by growth of economies and increases in cultural uniformity.\n\n\n"}
{"id": "7125851", "url": "https://en.wikipedia.org/wiki?curid=7125851", "title": "Turning radius", "text": "Turning radius\n\nThe turning radius or turning circle of a vehicle is the radius (or, depending on usage, \"diameter\") of the smallest circular turn (i.e. U-turn) that the vehicle is capable of making. \nThe term \"turning radius\" is a technical term that has become popular automotive jargon. In the jargon sense, it is commonly used to mean the full diameter of the smallest circle, but in technical usage the turning radius is still used to denote the radius. The less ambiguous term \"turning circle\" avoids the mistaken jargon use of the word 'radius' . As an example, \"Motor Trend\" refers to a \"curb-to-curb turning circle\" of a 2008 Cadillac CTS as , but the terminology is not yet settled. AutoChannel.com refers to the \"turning radius\" of the same car as . It is often used as a generalized term rather than a numerical figure. For example, a vehicle with a very small turning circle may be described as having a \"tight turning radius\".\n\nTwo different measurements can be quoted for a vehicle. A curb or curb-to-curb turning circle will show the straight-line distance from one side of the circle to the other, through the center. The name \"curb-to-curb\" indicates that a street would have to be this wide before this car can make a u-turn and not hit a street curb with a wheel. If you took the street curb and built it higher, as high as the car, and tried to make a u-turn in the street, parts of the car (bumper) would hit the wall. The name wall or wall-to-wall turning circle denotes how far apart the two walls would have to be to allow a u-turn without scraping the walls. One can find these two ways of measuring the turning circle used in auto specifications, for example, a van might be listed as having a turning circle (in meters) of 12.1(C)/12.4(W).\n\nA notable exception in this description is of vehicles that are capable of spinning around their central axis, such as certain lawnmowers and wheelchairs as they do not follow a circular path as they turn. In this case the vehicle is referred to as a \"zero turning radius\" vehicle.\n\nSome camera dollies used in the film industry have a \"round\" mode which allows them to spin around their z axis by allowing synchronized inverse rotation of their front and rear wheel sets, effectively giving them \"zero\" turning radius.\n\n\n\n"}
{"id": "14934822", "url": "https://en.wikipedia.org/wiki?curid=14934822", "title": "Type–token distinction", "text": "Type–token distinction\n\nThe type–token distinction is used in disciplines such as logic, linguistics, metalogic, typography, and computer programming to clarify what words mean.\n\nThe sentence \"they drive the same car\" is ambiguous. Do they drive the same \"type\" of car (the same model) or the same instance of a car type (a single vehicle)? Clarity requires us to distinguish words that represent abstract types from words that represent objects that embody or exemplify types. The type–token distinction separates types (abstract descriptive concepts) from tokens (objects that instantiate concepts).\n\nFor example: \"bicycle\" represents a type: the concept of a bicycle; whereas \"my bicycle\" represents a token of that type: an object that instantiates that type. In the sentence \"the bicycle is becoming more popular\" the word \"bicycle\" represents a type that is a concept; whereas in the sentence \"the bicycle is in the garage\" the word \"bicycle\" represents a token: a particular object.\n\nThe words type, concept, property, quality, feature and attribute (all used in describing things) tend to be used with different verbs. E.g. Suppose a rose bush is defined as a plant that is \"thorny\", \"flowering\" and \"bushy\". You might say a rose bush \"instantiates\" these three types, or \"embodies\" these three concepts, or \"exhibits\" these three properties, or \"possesses\" these three qualities, features or attributes.\n\nProperty types (e.g \"height in metres\" or \"thorny\") are often understood ontologically as concepts. Property instances (e.g. height = 1.74) are sometimes understood as measured values, and sometimes understood as sensations or observations of reality.\n\nSome say types exist in descriptions of objects, but not as tangible physical objects. They say one can show someone a particular bicycle, but cannot show someone the type \"bicycle\", as in \"\"the bicycle\" is popular.\". However types do exist in the sense that they appear in mental and documented models.\n\nSome say tokens are objects that are tangible, exist in space and time as physical matter and/or energy. However, tokens can be intangible objects of types such as \"thought\", \"tennis match\", \"government\" and \"act of kindness\".\n\nThere is a related distinction very closely connected with the type-token distinction. This distinction is the distinction between an object, or type of object, and an occurrence of it. In this sense, an occurrence is not necessarily a token. Considering the sentence: \"A rose is a rose is a rose\". We may equally correctly state that there are eight or three words in the sentence. There are, in fact, three word types in the sentence: \"rose\", \"is\" and \"a\". There are eight word tokens in a token copy of the line. The line itself is a type. There are not eight word types in the line. It contains (as stated) only the three word types, 'a', 'is' and 'rose', each of which is unique. So what do we call what there are eight of? They are occurrences of words. There are three occurrences of the word type 'a', two of 'is' and three of 'rose'.\n\nThe need to distinguish tokens of types from occurrences of types arises, not just in linguistics, but whenever types of things have other types of things occurring in them. Reflection on the simple case of occurrences of numerals is often helpful.\n\nIn typography, the type–token distinction is used to determine the presence of a text printed by movable type:\n\nThe word 'letters' was used three times in the above paragraph, each time in a different meaning. The word 'letters' is one of many words having \"type–token ambiguity\". This section disambiguates 'letters' by separating the three senses using terminology standard in logic today. The key distinctions were first made by the American logician-philosopher Charles Sanders Peirce in 1906 using terminology that he established.\n\nThe letters that are created by writing are physical objects that can be destroyed by various means: these are letter TOKENS or letter INSCRIPTIONS. The 26 letters of the alphabet are letter TYPES or letter FORMS.\n\nPeirce's type–token distinction, also applies to words, sentences, paragraphs, and so on: to anything in a universe of discourse of character-string theory, or concatenation theory. There is only one word type spelled el-ee-tee-tee-ee-ar, namely, 'letter'; but every time that word type is written, a new word token has been created.\n\nSome logicians consider a word type to be the class of its tokens. Other logicians counter that the word type has a permanence and constancy not found in the class of its tokens. The type remains the same while the class of its tokens is continually gaining new members and losing old members.\n\nThe word type 'letter' uses only four letter types: el, ee, tee, and ar. Nevertheless, it uses ee twice and tee twice. In standard terminology, the word type 'letter' has six letter OCCURRENCES and the letter type ee OCCURS twice in the word type 'letter'. Whenever a word type is inscribed, the number of letter tokens created equals the number of letter occurrences in the word type.\n\nPeirce's original words are the following.\n\"A common mode of estimating the amount of matter in a ... printed book is to count the number of words. There will ordinarily be about twenty 'thes' on a page, and, of course, they count as twenty words. In another sense of the word 'word,' however, there is but one word 'the' in the English language; and it is impossible that this word should lie visibly on a page, or be heard in any voice ... Such a ... Form, I propose to term a Type. A Single ... Object ... such as this or that word on a single line of a single page of a single copy of a book, I will venture to call a Token. ... In order that a Type may be used, it has to be embodied in a Token which shall be a sign of the Type, and thereby of the object the Type signifies.\" – Peirce 1906, Ogden-Richards, 1923, 280-1.\n\nThese distinctions are subtle but solid and easy to master. This section ends using the new terminology to disambiguate the first paragraph.\n\n\n"}
{"id": "1239491", "url": "https://en.wikipedia.org/wiki?curid=1239491", "title": "Water torture", "text": "Water torture\n\nWater torture encompasses a variety of techniques using water to inflict physical or psychological harm on a victim as a form of torture or execution.\n\nIn this form of water torture, water is forced down the throat and into the stomach. It was used as a legal torture and execution method by the courts in France in the 17th and 18th century. At the end of the 19th century and beginning of the 20th century it was used against Filipinos by American Forces during the Philippine–American War and was employed against British Commonwealth, American and Chinese prisoners during World War II by the Japanese. The Human Rights Watch organization reports that in the 2000s, security forces in Uganda sometimes forced a detainee to lie face up under an open water spigot.\n\nWater intoxication can result from drinking too much water. This has caused some fatalities over the years in fraternities in North America during initiation week. For example, a person was hazed to death by Chi Tau of Chico State (California) in 2005 via the forcing of pushups and the drinking of water from a bottle.\n\nWaterboarding refers to a technique involving water poured over the face or head of the subject, in order to evoke the instinctive fear of drowning. Often a wet cloth is placed in the subject's mouth, giving them the impression that they are drowning.\n\nWhat is called the \"Chinese water torture\" was a torture described by Hippolytus de Marsiliis in the 16th century that was supposed to drive its victim insane with the stress of water dripping on a part of the forehead for a very long time. It may also be characterised by the inconsistent pattern of water drips. There are no expert opinions on the true cause of torture in this method.\n\nThis form of torture was used in the early modern period as a trial by ordeal.\n\n\n"}
{"id": "2113849", "url": "https://en.wikipedia.org/wiki?curid=2113849", "title": "Wilson cycle", "text": "Wilson cycle\n\nThe Wilson cycle is a model where a continent rifts, forms an ocean basin in-between, and then begins a process of convergence that leads to the collision of the two plates and closure of the ocean. The model is named after its originator John Tuzo Wilson. It has been suggested that Wilson cycles on Earth started about 3 Ga (3 billion years) ago in the Archean Eon of Earth's history.\n\nA Wilson cycle is not the same as a supercontinent cycle, which is the break-up of one supercontinent and the development of another and takes place on a global scale. The Wilson cycle rarely synchronizes with the timing of a supercontinent cycle. However, supercontinent cycles and Wilson cycles were both involved in the creation of Pangaea and Rodinia.\n"}
