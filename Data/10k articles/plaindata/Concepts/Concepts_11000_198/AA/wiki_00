{"id": "177092", "url": "https://en.wikipedia.org/wiki?curid=177092", "title": "Active galactic nucleus", "text": "Active galactic nucleus\n\nAn active galactic nucleus (AGN) is a compact region at the center of a galaxy that has a much higher than normal luminosity over at least some portion of the electromagnetic spectrum with characteristics indicating that the luminosity is not produced by stars. Such excess non-stellar emission has been observed in the radio, microwave, infrared, optical, ultra-violet, X-ray and gamma ray wavebands. A galaxy hosting an AGN is called an \"active galaxy\". The radiation from an AGN is believed to result from the accretion of matter by a supermassive black hole at the center of its host galaxy.\n\nActive galactic nuclei are the most luminous persistent sources of electromagnetic radiation in the universe, and as such can be used as a means of discovering distant objects; their evolution as a function of cosmic time also puts constraints on models of the cosmos.\n\nThe observed characteristics of an AGN depend on several properties such as the mass of the central black hole, the rate of gas accretion onto the black hole, the orientation of the accretion disk, the degree of obscuration of the nucleus by dust, and presence or absence of jets.\n\nNumerous subclasses of AGN have been defined based on their observed characteristics; the most powerful AGN are classified as quasars. A blazar is an AGN with a jet pointed toward the Earth, in which radiation from the jet is enhanced by relativistic beaming.\n\nEarly photographic observations of nearby galaxies detected some characteristic signatures of AGN emission, although there was not yet a physical understanding of the nature of the AGN phenomenon. Some early observations included the first spectroscopic detection of emission lines from the nuclei of NGC 1068 and Messier 81 by Edward Fath (published in 1909), and the discovery of the jet in Messier 87 by Heber Curtis (published in 1918). Further spectroscopic studies by astronomers including Vesto Slipher, Milton Humason, and Nicholas Mayall noted the presence of unusual emission lines in some galaxy nuclei. In 1943, Carl Seyfert published a paper in which he described observations of nearby galaxies having bright nuclei that were sources of unusually broad emission lines. Galaxies observed as part of this study included NGC 1068, NGC 4151, NGC 3516, and NGC 7469. Active galaxies such as these are known as Seyfert galaxies in honor of Seyfert's pioneering work.\n\nThe development of radio astronomy was a major catalyst to understanding AGN. Some of the earliest detected radio sources are nearby active elliptical galaxies such as Messier 87 and Centaurus A. Another radio source, Cygnus A, was identified by Walter Baade and Rudolph Minkowski as a tidally distorted galaxy with an unusual emission-line spectrum, having a recessional velocity of 16,700 kilometers per second. The 3C radio survey led to further progress in discovery of new radio sources as well as identifying the visible-light sources associated with the radio emission. In photographic images, some of these objects were nearly point-like or quasi-stellar in appearance, and were classified as quasi-stellar radio sources (later abbreviated as \"quasars\").\n\nA major breakthrough was the measurement of the redshift of the quasar 3C 273 by Maarten Schmidt, published in 1963. Schmidt noted that if this object was extragalactic (outside the Milky Way, at a cosmological distance) then its large redshift of 0.158 implied that it was the nuclear region of a galaxy about 100 times more powerful than other radio galaxies that had been identified. Shortly afterward, optical spectra were used to measured the redshifts of a growing number of quasars including 3C 48, even more distant at redshift 0.37.\n\nThe enormous luminosities of these quasars as well as their unusual spectral properties indicated that their power source could not be ordinary stars. Accretion of gas onto a supermassive black hole was suggested as the source of quasars' power in papers by Edwin Salpeter and Yakov Zel'Dovich in 1964. In 1969 Donald Lynden-Bell proposed that nearby galaxies contain supermassive black holes at their centers as relics of \"dead\" quasars, and that black hole accretion was the power source for the non-stellar emission in nearby Seyfert galaxies. In the 1960s and 1970s, early X-ray astronomy observations demonstrated that Seyfert galaxies and quasars are powerful sources of X-ray emission, which originates from the inner regions of black hole accretion disks.\n\nToday, AGN are a major topic of astrophysical research, both observational and theoretical. AGN research encompasses observational surveys to find AGN over broad ranges of luminosity and redshift, examination of the cosmic evolution and growth of black holes, studies of the physics of black hole accretion and the emission of electromagnetic radiation from AGN, examination of the properties of jets and outflows of matter from AGN, and the impact of black hole accretion and quasar activity on galaxy evolution.\n\nFor a long time it has been argued that an AGN must be powered by accretion of mass onto massive black holes (10 to 10 times the Solar mass). AGN are both compact and persistently extremely luminous. Accretion can potentially give very efficient conversion of potential and kinetic energy to radiation, and a massive black hole has a high Eddington luminosity, and as a result, it can provide the observed high persistent luminosity. Supermassive black holes are now believed to exist in the centres of most if not all massive galaxies since the mass of the black hole correlates well with the velocity dispersion of the galactic bulge (the M-sigma relation) or with bulge luminosity. Thus AGN-like characteristics are expected whenever a supply of material for accretion comes within the sphere of influence of the central black hole.\n\nIn the standard model of AGN, cold material close to a black hole forms an accretion disc. Dissipative processes in the accretion disc transport matter inwards and angular momentum outwards, while causing the accretion disc to heat up. The expected spectrum of an accretion disc peaks in the optical-ultraviolet waveband; in addition, a corona of hot material forms above the accretion disc and can inverse-Compton scatter photons up to X-ray energies. The radiation from the accretion disc excites cold atomic material close to the black hole and this in turn radiates at particular emission lines. A large fraction of the AGN's radiation may be obscured by interstellar gas and dust close to the accretion disc, but (in a steady-state situation) this will be re-radiated at some other waveband, most likely the infrared.\n\nSome accretion discs produce jets of twin, highly collimated, and fast outflows that emerge in opposite directions from close to the disc. The direction of the jet ejection is determined either by the angular momentum axis of the accretion disc or the spin axis of the black hole. The jet production mechanism and indeed the jet composition on very small scales are not understood at present due to the resolution of astronomical instruments being too low. The jets have their most obvious observational effects in the radio waveband, where very-long-baseline interferometry can be used to study the synchrotron radiation they emit at resolutions of sub-parsec scales. However, they radiate in all wavebands from the radio through to the gamma-ray range via the synchrotron and the inverse-Compton scattering process, and so AGN jets are a second potential source of any observed continuum radiation.\n\nThere exists a class of 'radiatively inefficient' solutions to the equations that govern accretion. The most widely known of these is the Advection Dominated Accretion Flow (ADAF), but other theories exist. In this type of accretion, which is important for accretion rates well below the Eddington limit, the accreting matter does not form a thin disc and consequently does not efficiently radiate away the energy that it acquired as it moved close to the black hole. Radiatively inefficient accretion has been used to explain the lack of strong AGN-type radiation from massive black holes at the centres of elliptical galaxies in clusters, where otherwise we might expect high accretion rates and correspondingly high luminosities. Radiatively inefficient AGN would be expected to lack many of the characteristic features of standard AGN with an accretion disc.\n\nAGN are a candidate source of high and ultra-high energy cosmic rays \"(see also Centrifugal mechanism of acceleration)\".\n\nThere is no single observational signature of an AGN. The list below covers some of the features that have allowed systems to be identified as AGN.\n\n\nIt is convenient to divide AGN into two classes, conventionally called radio-quiet and radio-loud. Radio-loud objects have emission contributions from both the jet(s) and the lobes that the jets inflate. These emission contributions dominate the luminosity of the AGN at radio wavelengths and possibly at some or all other wavelengths. Radio-quiet objects are simpler since jet and any jet-related emission can be neglected at all wavelengths.\n\nAGN terminology is often confusing, since the distinctions between different types of AGN sometimes reflect historical differences in how the objects were discovered or initially classified, rather than real physical differences.\n\n\nSee main article Radio galaxy for a discussion of the large-scale behaviour of the jets. Here, only the active nuclei are discussed.\n\n\nUnified models propose that different observational classes of AGN are a single type of physical object observed under different conditions. The currently favoured unified models are 'orientation-based unified models' meaning that they propose that the apparent differences between different types of objects arise simply because of their different orientations to the observer. However, they are debated (see below).\n\nAt low luminosities, the objects to be unified are Seyfert galaxies. The unification models propose that in Seyfert 1s the observer has a direct view of the active nucleus. In Seyfert 2s the nucleus is observed through an obscuring structure which prevents a direct view of the optical continuum, broad-line region or (soft) X-ray emission. The key insight of orientation-dependent accretion models is that the two types of object can be the same if only certain angles to the line of sight are observed. The standard picture is of a torus of obscuring material surrounding the accretion disc. It must be large enough to obscure the broad-line region but not large enough to obscure the narrow-line region, which is seen in both classes of object. Seyfert 2s are seen through the torus. Outside the torus there is material that can scatter some of the nuclear emission into our line of sight, allowing us to see some optical and X-ray continuum and, in some cases, broad emission lines—which are strongly polarized, showing that they have been scattered and proving that some Seyfert 2s really do contain hidden Seyfert 1s. Infrared observations of the nuclei of Seyfert 2s also support this picture.\n\nAt higher luminosities, quasars take the place of Seyfert 1s, but, as already mentioned, the corresponding 'quasar 2s' are elusive at present. If they do not have the scattering component of Seyfert 2s they would be hard to detect except through their luminous narrow-line and hard X-ray emission.\n\nHistorically, work on radio-loud unification has concentrated on high-luminosity radio-loud quasars. These can be unified with narrow-line radio galaxies in a manner directly analogous to the Seyfert 1/2 unification (but without the complication of much in the way of a reflection component: narrow-line radio galaxies show no nuclear optical continuum or reflected X-ray component, although they do occasionally show polarized broad-line emission). The large-scale radio structures of these objects provide compelling evidence that the orientation-based unified models really are true. X-ray evidence, where available, supports the unified picture: radio galaxies show evidence of obscuration from a torus, while quasars do not, although care must be taken since radio-loud objects also have a soft unabsorbed jet-related component, and high resolution is necessary to separate out thermal emission from the sources' large-scale hot-gas environment. At very small angles to the line of sight, relativistic beaming dominates, and we see a blazar of some variety.\n\nHowever, the population of radio galaxies is completely dominated by low-luminosity, low-excitation objects. These do not show strong nuclear emission lines — broad or narrow — they have optical continua which appear to be entirely jet-related, and their X-ray emission is also consistent with coming purely from a jet, with no heavily absorbed nuclear component in general. These objects cannot be unified with quasars, even though they include some high-luminosity objects when looking at radio emission, since the torus can never hide the narrow-line region to the required extent, and since infrared studies show that they have no hidden nuclear component: in fact there is no evidence for a torus in these objects at all. Most likely, they form a separate class in which only jet-related emission is important. At small angles to the line of sight, they will appear as BL Lac objects.\n\nIn the recent literature on AGN, being subject to an intense debate, an increasing set of observations appear to be in conflict with some of the key predictions of the Unified Model, e.g. that each Seyfert 2 has an obscured Seyfert 1 nucleus (a hidden broad-line region).\n\nTherefore, one cannot know whether the gas in all Seyfert 2 galaxies is ionized due to photoionization from a single, non-stellar continuum source in the center or due to shock-ionization from e.g. intense, nuclear starbursts. Spectropolarimetric studies reveal that only 50% of Seyfert 2s show a hidden broad-line region and thus split Seyfert 2 galaxies into two populations. The two classes of populations appear to differ by their luminosity, where the Seyfert 2s without a hidden broad-line region are generally less luminous. This suggests absence of broad-line region is connected to low Eddington ratio, and not to obscuration.\n\nThe covering factor of the torus might play an important role. Some torus models predict how Seyfert 1s and Seyfert 2s can obtain different covering factors from a luminosity- and accretion rate- dependence of the torus covering factor, something supported by studies in the x-ray of AGN. The models also suggest an accretion-rate dependence of the broad-line region and provide a natural evolution from more active engines in Seyfert 1s to more “dead” Seyfert 2s and can explain the observed break-down of the unified model at low luminosities and the evolution of the broad-line region.\n\nWhile studies of single AGN show important deviations from the expectations of the unified model, results from statistical tests have been contradictory. The most important short-coming of statistical tests by direct comparisons of statistical samples of Seyfert 1s and Seyfert 2s is the introduction of selection biases due to anisotropic selection criteria.\n\nStudying neighbour galaxies rather than the AGN themselves first suggested the numbers of neighbours were larger for Seyfert 2s than for Seyfert 1s, in contradiction with the Unified Model. Today, having overcome the previous limitations of small sample sizes and anisotropic selection, studies of neighbours of hundreds to thousands of AGN have shown that the neighbours of Seyfert 2s are intrinsically dustier and more star-forming than Seyfert 1s and a connection between AGN type, host galaxy morphology and collision history. Moreover, angular clustering studies of the two AGN types confirm that they reside in different environments and show that they reside within dark matter halos of different masses. The AGN environment studies are in line with evolution-based unification models where Seyfert 2s transform into Seyfert 1s during merger, supporting earlier models of merger-driven activation of Seyfert 1 nuclei.\n\nWhile controversy about the soundness of each individual study still prevails, they all agree on that the simplest viewing-angle based models of AGN Unification are incomplete. Seyfert-1 and Seyfert-2 seem to differ in star formation and AGN engine power.\n\nWhile it still might be valid that an obscured Seyfert 1 can appear as a Seyfert 2, not all Seyfert 2s must host an obscured Seyfert 1. Understanding whether it is the same engine driving all Seyfert 2s, the connection to radio-loud AGN, the mechanisms of the variability of some AGN that vary between the two types at very short time scales, and the connection of the AGN type to small- and large-scale environment remain important issues to incorporate into any unified model of active galactic nuclei.\n\nFor a long time, active galaxies held all the records for the highest-redshift objects known either in the optical or the radio spectrum, because of their high luminosity. They still have a role to play in studies of the early universe, but it is now recognised that an AGN gives a highly biased picture of the \"typical\" high-redshift galaxy.\n\nMost luminous classes of AGN (radio-loud and radio-quiet) seem to have been much more numerous in the early universe. This suggests that massive black holes formed early on and that the conditions for the formation of luminous AGN were more common in the early universe, such as a much higher availability of cold gas near the centre of galaxies than at present. It also implies that many objects that were once luminous quasars are now much less luminous, or entirely quiescent. The evolution of the low-luminosity AGN population is much less well understood due to the difficulty of observing these objects at high redshifts.\n\n\nDusty surprise around giant black hole\n"}
{"id": "38780183", "url": "https://en.wikipedia.org/wiki?curid=38780183", "title": "AfriForum", "text": "AfriForum\n\nAfriForum is an organisation in South Africa linked to the Solidarity trade union. It was established in 2006 to encourage the re-engagement of the Afrikaners and other minorities in the public sphere. It promotes the protection of Afrikaner culture, and has opposed renaming streets and affirmative action. AfriForum has attracted significant controversy because of its views, particularly about Apartheid.\n\nAccording to AfriForum CEO, , AfriForum is a civil rights initiative to mobilise civil society and specifically minority communities, in order to take part in democratic debate. Kriel further stated that AfriForum would like to achieve balance in South Africa. “True democracy needs alternative voices in order to succeed. While we aren’t a political party, we give alternative ideas and suggestions, where applicable, to the government stance.” AfriForum's claim to be a civil rights organisation has been questioned in the South African media, and South African and international media often characterize Afriforum as a white nationalist or white supremacist group.\n\nThe movement's youth wing is called \"AfriForum Youth\".\n\nAfriForum was founded in 2006. AfriForum's Civil Rights Charter was officially adopted by the organization on 7 September 2006 during a discussion forum held in Pretoria. Its leader, Kallie Kriel, was previously a member of the Conservative Party, and a leader of the Freedom Front Plus (FF+) youth wing, and a large number of its executive leadership were formerly associated with Freedom Front Plus.\n\nThe organisation recruited its 100 000th member in July 2014  and its 200 000th member in November 2017.\n\nThe organisation's principal focus is inter alia on the following areas: civil, safety and security, community affairs, local government, environmental affairs, education as well as preserving the language, culture and heritage in South Africa.\n\nIn 2009, the group contested the presence of Robert Mugabe at the inauguration of Jacob Zuma's presidency. It was also involved in a bid to prevent the delivery of Alouette III Air Force helicopters to the Zimbabwean army.\n\nAfriForum has opposed fracking in the Karoo as well as poaching It has also campaigned against electronic road tolling in Gauteng.\n\nAfriForum has been a vocal critic of the ANC's response to the farm attack cases, claiming that the party bears a responsibility for \"remain[ing] silent\" about the violence, and lodging a complaint to the South African Human Rights Commission against the Police Minister for failing to do enough to protect farmers.\n\nAfriForum launched the book \"Kill the Boer\" written by Ernst Roets, Deputy CEO of AfriForum, on 28 June 2018.\n\nThe organisation has often criticised government for its lack of willingness to address the problem of farm murders. AfriForum is of the opinion that farm murders should be declared a priority crime, and has raised widespread local awareness and increasing international awareness of the problem by means of several campaigns, including the ‘Stop the Murders’ campaign. The organisation has also campaigned to address the overall problem of crime and corruption, especially with regard to municipal employees guilty of fraud.\n\nThe organisation formed a private prosecutions unit, headed by well-known former state prosecutor Gerrie Nel, amid allegations that the National Prosecuting Authority (NPA) was selective in prosecutions, and politically biased. In 2017, Nel undertook to assist the victim of an alleged assault by Grace Mugabe, wife of Robert Mugabe.\n\nIn 2018, AfriForum undertook a private prosecution of EFF leader Julius Malema on charges of fraud and corruption, after the NPA failed to continue prosecuting the case. AfriForum had initially laid the charges against Malema in 2011.\n\nAfriForum committed to undertake a private prosecution of Duduzane Zuma, son of then-President Jacob Zuma, for culpable homicide, after a vehicle driven by Duduzane Zuma was involved in a 2014 motor vehicle crash that killed two black female minibus taxi commuters, and the National Prosecuting Authority declined to prosecute, despite an inquest finding that the crash was caused by Zuma's negligence. Following AfriForum's move to privately prosecute Zuma, the National Prosecuting Authority decided to pursue a prosecution instead.\n\nThe organisation undertook a prosecution of the chairperson of the National Council of Provinces, Thandi Modise, after allegations of animal cruelty at her North West farm, where, in 2014, the NSPCA found \"scores\" of animals starving to death from apparent neglect, and the NPA failed to prosecute her.\n\nTwo of the core objectives of AfriForum Youth have been the promotion of multilingualism and mother tongue education in South Africa, and for youth in the country to be exempted from affirmative action.\n\nAfriForum has strongly opposed the proposed renaming of South Africa's capital from Pretoria to Tshwane, as well as street renaming in Pretoria.\n\nA campaign against racial quotas in higher education saw AfriForum Youth members paint themselves black to protest the alleged discrimination against 30 learners who were turned away from the University of Pretoria. Another campaign protesting racial quotas involved charging students of different races different prices for a cup of coffee, with white students paying R5 a cup, coloured and Indians R3, and blacks R1.\n\nIn 2014 AfriForum attempted to suppress a report into a Nazi-style initiation ceremony at the Potchefstroom Campus of North-West University, claiming that the report discriminated against Afrikaners.\n\nAfriForum continues to drive campaigns to, amongst other things, promote mother tongue education, keep religion in schools, and combat detrimental policies and regulations within the schooling system. \n\nThe group recently condemned Gauteng MEC for Basic Education Panyaza Lesufi’s newly proposed school regulations and says that the minister continues playing a political game at the expense of learners. AfriForum further stated that Lesufi was waging a war on Afrikaans schools.\n\nThe South African Institute of Race Relations (SAIRR) stated that land is a contentious issue in South Africa, and that the ruling ANC party is blaming whites for still owning 80% of the total land surface. In fact, the Government’s own land-ownership documentation shows that by the start of 2011 roughly 50% of all land was in the hands of Government and black communities.\n\nAs of March 2011, 31 million hectares or 25% of the 122 million hectares surface area of South Africa were in the hands of the State. The remaining 91 million hectares or 75% of the surface area was privately owned. The bulk of white-owned land is probably in the hands of commercial farmers, South Africa's food producers. Their numbers are dwindling rapidly. There are only an estimated 30 000 to 40 000 of these farmers left, down from 60 000 fifteen years ago.\n\nSouth African President, Jacob Zuma called for a review of the land policy, echoing the contents of the Green Paper on Land Reform, but AfriForum claims that the president’s statement regarding the review of willing buyer, willing seller principle as stated in Section 25 of the South African Constitution, as a means to speed up the land restitution process was misplaced. AfriForum has in the past joined the South African Progressive Civic Organisation (Sapco), a Khoisan community, in a protest over the land rights of the indigenous group, with both minority groups feeling they have no representation in the current government.\n\nDuring 2012, AfriForum's legal team represented the legitimate owners of land in the black community of Wallmansthal, North of Pretoria, in the North Gauteng High Court to take back their land from illegal squatters. The court ruled in favour of AfriForum. The squatters, who occupied the land between December 2011 and February 2012, were removed from the land.\n\nDuring a submission on 6 September 2018 to the Parliamentary Portfolio Committee charged with reviewing Section 25 of the Constitution, AfriForum argued that the ANC/EFF alliance’s initiative to carry through expropriation without compensation was nothing but an attempt to centralise as much power as possible in the State, and that the leaders of this policy had no respect for the pleas of poor South Africans.\n\nIn his submission on behalf of AfriForum, Ernst Roets, Deputy CEO of AfriForum, argued that the campaign of the ANC and its alliance partner, the EFF, was built on a series of false arguments.\n\nAfriForum unleashed a media and public storm when they published a list of farms that are said to be targeted by the government for expropriation without compensation that the organisation received from an anonymous source. Although the organisation received a backlash from some organisations and political parties regarding the legitimacy of the list, the South African Institute for Race Relations confirmed and corroborated the legitimacy of the list.\n\nAfriForum Youth opened a civil case against former ANC Youth League President (ANCYL), Julius Malema, in the Equality Court after his repeated singing of the words “dubul’ ibhunu”, which translate as “shoot the boer”, at a number of ANC Youth League gatherings. Judge Colin Lamont ruled in the South Gauteng High Court that the song constituted hate speech and undermined the dignity of Afrikaners, and was discriminatory and harmful. In 2012, AfriForum and the ANC reached a settlement before the appeal case was due to be argued in the Supreme Court of Appeal (SCA) in Bloemfontein.\n\nAfriForum has also brought charges of hate speech against individuals, among others Ronald Lamola, the then acting president of the ANC Youth League following a complaint regarding Lamola's remarks that the ANCYL could no longer guarantee the safety of the Van der Merwes and Van Tonders (traditional white Afrikaans family names) if white South Africans refused to voluntarily give up their land and mineral rights. In February 2013 AfriForum Youth brought a complaint of hate speech against Jason Mfusi, the leader of SASCO (The South African Students Congress) of the North-West University for his remark: \"My grandfather says 'n goeie boer is 'n dooie boer\", translated as “My grandfather says a good farmer is a dead farmer” which he posted on the social network, Facebook. The youth organisation reached an agreement with the SASCO leader by means of a mediation process, as requested by the Human Rights Commission (HRC) of the University. In terms of the agreement, Mfusi had to issue a written apology to the farming community.\n\nAfriForum adopted a similar stance towards the word Kaffir, stating that its use is a \"gross human rights violation\". \n\nAfriForum regularly seeks international platforms to speak to the international community regarding the minority rights situation in South Africa. AfriForum has on several occasions attended the United Nations' Human Rights Council's Forum on Minority Issues in Geneva, Switzerland regarding minority rights in South Africa. AfriForum has also been a delegate to a conference of the United Nations’ (UN) Human Rights Council regarding the prevention of the incitement of hatred on the grounds of nationality, race or religion.\n\nAfriForum has on numerous occasions criticised the ruling ANC about the denial of minority rights in the country. However, City Press journalist Adriaan Basson (now editor of the Afrikaans daily newspaper, Beeld) has accused the organisation of overreacting to the situation regarding minority rights in South Africa. Basson has mentioned in an open letter to AfriForum CEO, Kallie Kriel, that the premise of AfriForum’s campaigns is one of victimhood.\n\nAfriforum claimed credit for taking an Australian journalist on a tour of South Africa, and for the \"dozens\" of articles that subsequently appeared in the Australian media that included claims that white South Africans were \"trapped like frogs in boiling water\" and stating that white farmers were being “persecuted” because of their race. AfriForum also undertook a tour of the United States that included meetings with John Bolton, staffers for Senator Ted Cruz, and an interview on Fox News. AfriForum toured Australia in October 2018 to raise awareness of farm attacks, appearing on Sky News Australia program Outsiders where a member was interviewed by Ross Cameron and Rowan Dean, and they met Australian MP Andrew Hastie and delivered a presentation before the Parliament of Western Australia.\n\nOn 11 September 2018, AfriForum founded a unit against racism and hate speech. Roleplayers who have committed themselves to act as advisors on this unit include: Dr Frans Cronje, CEO of the Institute of Race Relations (IRR), The civil rights activist Rhoda Kadalie, Adv. Mark Oppenheimer, expert in freedom of speech and hate speech and Dr Llewellyn Curlewis, criminal law expert, explained the legal remedies available to citizens to fight racism.\n\nAfriForum submitted criminal charges against two police officials and a former member of the South African National Defence Force (SANDF) in January 2018 after they used social media to incite farm attacks and/or romanticise violence against farmers and minorities. AfriForum says that these incidents can be considered a form of complicity by the South African government and that it urgently needs to be tackled by the police to ensure that those responsible are prosecuted. Mseleni Mogolwane Gwabeni, who is a member of the SAPS according to his Facebook profile, said on this social media platform “then we must continue to kill more of their farmers at least to make up for what they did to us [sic]”. Chris Gumotso, who works at the SAPS youth crime prevention desk according to his Facebook profile, placed the following on Facebook: “All white man…deserve to die…in future..f*©k u..Mr white man.” He also placed photos of firearms on his police desk on his profile with this quote: “I predict th civil war.. in mzansi…by 2019…take out ur guns…fighters coz Asijiki [sic].”\n\nIn June 2017 AfriForum submitted criminal charges against a 100 social media users for incitement of violence.\n\nAfriForum has been consistent in condemning both white on black and black on white racism. The organisation released media statements in which they address racist incidents involving amongst others Penny Sparrow, Darren Scott, Dan Roodt, Adam Catzavelos, and the Kommandokorps. The organisation frequently condemns double standards in South Africa when it comes to dealing with racism. \n\nThis department addresses municipal service delivery problems in over 125 towns and cities across South Africa.\n\nIn order to achieve this goal, AfriForum attempts to establish partnerships with municipalities. The organisation allegedly submits wish lists to municipalities, and municipalities convert it into action plans to address issues. AfriForum says if municipalities do not cooperate in improving service delivery to residents, the organisation approaches courts to order municipalities to enforce service delivery. \n\nAn example of intervention by AfriForum in this regard, was the urgent order awarded to the organisation against the Vhembe District Municipality by the High Court in Pretoria, forcing the municipality to supply water to Makhado residents. In a similar case in 2013, the North Gauteng High Court in Pretoria granted AfriForum an order stopping the Madibeng Municipality from cutting electricity supply to Hartbeespoort.\n\nIn 2010 a legal team for AfriForum representing farmers in Zimbabwe won a court bid to sue Zimbabwe's government over its “cruel” and “vengeful” expropriation of South African-owned farms. In 2008 the regional court SADC tribunal ruled that Zimbabwe's land reform was illegal and racist, and that those who had suffered discrimination by having their farms expropriated had the right to compensation.\n\nAfriForum's local government interventions have been described positively, even by its critics.\n\nAfriForum’s Community Safety Department participates in endeavours which promote the safety of citizens within communities. A large emphasis is placed on assisting communities and neighbourhoods to establish safety structures. Some of these structures include neighbourhood watches, farm watches, radio networks and community forums.\n\nIn 2011 AfriForum commissioned Professor Rudolph Zinn of UNISA to conduct research into successful community safety structures in South Africa. The research has led to the compilation of a community safety handbook that has been implemented in all AfriForum branches countrywide.\nThe department also focuses on the role of government and in particular that of law enforcement agencies, and acts as a pressure group so that citizens get the best safety and security possible.\n\nIn 2015 AfriForum asserted that allegations of racism against Curro Foundation School are themselves racist. In a statement by the organisation's chair it was said \"To portray an Afrikaans class being transported as class group falsely as racial segregation, is beyond absurd\". An investigation into the matter came to the conclusion that the class was in fact segregated racially as was alleged because white parents had pressured the school.\n\nA group of AfriForum protestors were found by judge AJ Donen to have engaged in \"assault, sexual violence, sexual aggression and intimidation\" at Stellenbosch University, and the organisation initiated a boycott of Afrikaans newspapers that reported on Potchefstroom students that gave the Nazi salute during their initiation.\n\nIn 2016 AfriForum supporters protested in Pretoria together with the political party Freedom Front Plus's members because Steve Hofmeyr's scheduled event at Café Dudok, a restaurant in the Netherlands, was cancelled when the organisers were alerted of his alleged white supremacy by a left-wing group in Netherlands.\n\nIn 2016 eight students affiliated with AfriForum youth wing were suspended from Stellenbosch University Student Representative Council (SRC) elections after allegations of campaign irregularities. Posters that they produced and hanged around the campus were removed after they were deemed controversial and harmful to other students.\n\nIn May 2018, following criticism of Afriforum by a North-West University professor, Elmien du Plessis, Afriforum's deputy CEO, Ernst Roets, posted a YouTube video where he quoted Victor Klemperer, stating that \"if the tables were turned after the Holocaust he \"would have all the intellectuals strung up, and the professors three feet higher than the rest; they would be left hanging from the lamp posts for as long as was compatible with hygiene.\" Following the video posting, du Plessis and her family received threats of violence. A petition condemning the threats against academics was subsequently circulated.\n\nAfriForum CEO Kallie Kriel attracted widespread controversy in May 2018 when he denied that Apartheid was a crime against humanity, and its deputy leader Ernst Roets has described Apartheid as a \"wooly concept\". The organisation had previously described Apartheid as a \"so-called historical injustice\".\n\nThe organisation has been criticized, most notability by the ruling ANC as well as by media outlets such as City Press, including the paper’s editor Ferial Haffajee and academics such as University of Cape Town Professor Pierre de Vos. Survivalist groups such as the Kommandokorps have also criticised the organisation, alleging that the group is too moderate in their approach to problems facing South Africa.\n\nA Chapter 9 institution, the Commission for the Promotion and Protection of the Rights of Cultural, Religious and Linguistic Communities, launched an attack on AfriForum's campaign for the protection of Afrikaans medium schools in a press release. It was presumed by AfriForum that the Commission deliberately acted in contravention of its mandate as set out in Section 185 of the Constitution, which led AfriForum to suspect that the Commission was functioning as an extension of the ruling party.\n\nThe African National Congress Youth League has stated that AfriForum is \"the defender of white privilege\" while commentator and journalist Max du Preez has described AfriForum's position as \"reactionary identity politics\", and claimed that Afrikaners who criticised AfriForum are \"aggressively demonised, insulted, belittled and even threatened\".\n\nVice Chancellor of the University of the Witwatersrand Adam Habib condemned AfriForum in May 2018 and said in an interview that the AfriForum was building ties with \"proto-fascist groups\" including the French National Front, the Italian Five Star Movement, and Germany's AFD.\n\n"}
{"id": "42938624", "url": "https://en.wikipedia.org/wiki?curid=42938624", "title": "Biological motion perception", "text": "Biological motion perception\n\nBiological motion perception is the act of perceiving the fluid unique motion of a biological agent. The phenomenon was first documented by Swedish perceptual psychologist, Gunnar Johansson, in 1973. There are many brain areas involved in this process, some similar to those used to perceive faces. While humans complete this process with ease, from a computational neuroscience perspective there is still much to be learned as to how this complex perceptual problem is solved. One tool which many research studies in this area use is a display stimuli called a point light walker. Point light walkers are coordinated moving dots that simulate biological motion in which each dot represents specific joints of a human performing an action.\n\nCurrently a large topic of research, many different models of biological motion/perception have been proposed. The following models have shown that both form and motion are important components of biological motion perception. However, to what extent each of the components play is contrasted upon the models.\n\nResearch in this area seeks to identify the specific brain regions or circuits responsible for processing the information which the visual system perceives in the world. And in this case, specifically recognizing motion created by biological agents.\n\nThe most precise research is done using single-cell recordings in the primate brain. This research has yielded areas important to motion perception in primates such as area MT (middle temporal visual area), also referred to as V5, and area MST (medial superior temporal area). These areas contain cells characterized as direction cells, expansion/contraction cells, and rotation cells, which react to certain classes of movement.\n\nAdditionally, research on human participants is being conducted as well. While single-cell recording is not conducted on humans, this research uses neuroimaging methods such as fMRI, PET, EEG/ERP to collect information on what brain areas become active when executing biological motion perception tasks, such as viewing point light walker stimuli. Areas uncovered from this type of research are the dorsal visual pathway, extrastriate body area, fusiform gyrus, superior temporal sulcus, and premotor cortex. The dorsal visual pathway (sometimes referred to as the “where” pathway), as contrasted with the ventral visual pathway (“what” pathway), has been shown to play a significant role in the perception of motion cues. While the ventral pathway is more responsible for form cues.\n\nValuable information can also be learned from cases where a patient has suffered from some sort of neurological damage and consequently loses certain functionalities of neural processing. One patient with bilateral lesions that included the human homologue of area MT, lost their ability to see biological motion when the stimulus was embedded in noise, a task which the average observer is able to complete. Another study on stroke patients sustaining lesions to their superior temporal and premotor frontal areas showed deficits in their processing of biological motion stimuli, thereby implicating these areas as important to that perception process. A case study conducted on a patient with bilateral lesions involving the posterior visual pathways and effecting the lateral parietal-temporal-occipital cortex struggled with early motion tasks, and yet was able to perceive the biological motion of a point light walker, a higher-order task. This may be due to the fact that area V3B and area KO were still intact, suggesting their possible roles in biological motion perception.\n\nThe relative roles of form cues compared to motion cues in the process of perceiving biological motion is unclear. Previous research has not untangled the circumstances under which local motion cues are needed or only additive. This model looks at how form-only cues can replicate psychophysical results of biological motion perception.\n\n\"Template Creation\"\n\nSame as below. See 2.2.2 Template Generation\n\n\"Stage 1\"\n\nThe first stage compares stimulus images to the assumed library of upright human walker templates in memory. Each dot in a given stimulus frame is compared to the nearest limb location on a template and these combined, weighted distances are outputted by the function:\n\nwhere formula_2 gives the position of a particular stimulus dot and formula_3 represents the nearest limb position in the template. formula_4 represents the size of the receptor field to adjust for the size of the stimulus figure.\n\nThe best fitting template was then selected by a winner-takes-all mechanism and entered into a leaky integrator:\n\nwhere formula_6 and formula_7 are the weights for lateral excitation and inhibition, respectively, and the activities formula_8 provide the left/right decision for which direction the stimulus is facing.\n\n\"Stage 2\"\n\nThe second stage attempts to use the temporal order of the stimulus frames to change the expectations of what frame would be coming next. The equation\n\ntakes into account bottom-up input from stage 1 formula_10, the activities in decision stage 2 for the possible responses formula_11, and weights the difference between selected frame formula_12 and previous frame formula_13.\n\n\"Implications\"\n\nThis model highlights the abilities of form-related cues to detect biological motion and orientation in a neurologically feasible model. The results of the Stage 1 model showed that all behavioral data could be replicated by using form information alone - global motion information was not necessary to detect figures and their orientation. This model shows the possibility of the use of form cues, but can be criticized for a lack of ecological validity. Humans do not detect biological figures in static environments and motion is an inherent aspect in upright figure recognition.\n\nOld models of biological motion perception are concerned with tracking joint and limb motion relative to one another over time. However, recent experiments in biological motion perception have suggested that motion information is unimportant for action recognition. This model shows how biological motion may be perceived from sequences of posture recognition, rather than from the direct perception of motion information. An experiment was conducted to test the validity of this model, in which subjects are presented moving point-light and stick-figure walking stimuli. Each frame of the walking stimulus is matched to a posture template, the progression of which is recorded on a 2D posture–time plot that implies motion recognition.\n\n\"Template Generation\"\n\nPosture templates for stimulus matching were constructed with motion tracking data from nine people walking. 3D coordinates of the twelve major joints (feet, knees, hips, hands, elbows, and shoulders) were tracked and interpolated between to generate limb motion. Five sets of 2D projections were created: leftward, frontward, rightward, and the two 45° intermediate orientations. Finally, projections of the nine walkers were normalized for walking speed (1.39 seconds at 100 frames per cycle), height, and hip location in posture space. One of the nine walkers was chosen as the walking stimulus, and the remaining eight were kept as templates for matching.\n\n\"Template Matching\"\n\nTemplate matching is computed by simulating posture selective neurons as described by A neuron is excited by similarity to a static frame of the walker stimulus. For this experiment, 4,000 neurons were generated (8 walkers times 100 frames per cycle times 5 2D projections). A neuron's similarity to a frame of the stimulus is calculated as follows:\n\nwhere formula_15 describe a stimulus point and formula_16 describe the limb location at time formula_17; formula_18 describes the preferred posture; formula_19 describes a neuron's response to a stimulus of formula_20 points; and formula_4 describes limb width.\n\n\"Response Simulation\"\n\nThe neuron most closely resembling the posture of the walking stimulus changes over time. The neural activation pattern can be graphed in a 2D plot, called a posture-time plot. Along the x axis, templates are sorted chronologically according to a forward walking pattern. Time progresses along the y axis with the beginning corresponding to the origin. The perception of forward walking motion is represented as a line with a positive slope from the origin, while backward walking is conversely represented as a line with a negative slope.\n\n\"Motion Detection in Posture Space\"\n\nThe posture-time plots used in this model follow the established space-time plots used for describing object motion. Space-time plots with time at the y axis and the spatial dimension at the x axis, define velocity of an object by the slope of the line. Information about an object's motion can be detected by spatio-temporal filters. In this biological motion model, motion is detected similarly but replaces the spatial dimension for posture space along the x axis, and body motion is detected by using posturo-temporal filters rather than spatio-temporal filters.\n\n\"Posturo-Temporal Filters\"\n\nNeural responses are first normalized as described by \n\nwhere formula_23 describes the neural response; formula_24 describes the preferred posture at time formula_17; formula_26 describes the mean neural response over all neurons over formula_17; and formula_28 describes the normalized response. The filters are defined for forward and backward walking (formula_29 respectively). The response of the posturo-temporal filter is described\n\nwhere formula_31 is the response of the filter at time formula_32; and formula_33 describes the posture dimension. The response of the filter is normalized by\n\nwhere formula_20 describes the response of the neuron selecting body motion. Finally, body motion is calculated by\n\nwhere formula_37 describes body motion energy.\n\nThe following model suggests that biological motion recognition could be accomplished through the extraction of a single critical feature: dominant local optic flow motion. These following assumptions were brought about from results of both statistical analysis and psychophysical experiments.\n\nFirst, Principal component analysis was done on full body 2d walkers and point light walkers. The analysis found that dominant local optic flow features are very similar in both full body 2d stimuli and point light walkers (Figure 1). Since subjects can recognize biological motion upon viewing a point light walker, then the similarities between these two stimuli may highlight critical features needed for biological motion recognition.\n\nThrough psychophysical experiments, it was found that subjects could recognize biological motion using a CFS stimulus which contained opponent motion in the horizontal direction but randomly moving dots in the horizontal direction (Figure 2). Because of the movement of the dots, this stimulus could not be fit to a human skeleton model suggesting that biological motion recognition may not heavily rely on form as a critical feature. Also, the psychophysical experiments showed that subjects similarly recognize biological motion for both the CFS stimulus and SPS, a stimulus in which dots of the point light walker were reassigned to different positions within the human body shape for every nth frame thereby highlights the importance of form vs the motion (Fig.1.). The results of the following psychophysical experiments show that motion is a critical feature that could be used to recognize biological motion.\n\nThe following statistical analysis and psychophysical experiments highlight the importance of dominant local motion patterns in biological motion recognition.Furthermore, due to the ability of subjects to recognize biological motion given the CFS stimulus, it is postulated that horizontal opponent motion and coarse positional information is important for recognition of biological motion.\n\nThe following model contains detectors modeled from existing neurons that extracts motion features with increasing complexity. (Figure 4).\n\n\"Detectors of Local Motion\"\n\nThese detectors detect different motion directions and are modeled from neurons in monkey V1/2 and area MT\nThe output of the local motion detectors are the following:\n\nwhere formula_39 is the position with preferred direction formula_40, formula_41 is the velocity, formula_42 is the direction, and formula_43 is the rectangular speed tuning function such that\n\nThe direction-tuning of motion energy detectors are given by\n\nwhere formula_48 is a parameter that determines width of direction tuning function. (q=2 for simulation).\n\n\"Neural detectors for opponent motion selection\"\n\nThe following neural detectors are used to detect horizontal and vertical opponent motion due by pooling together the output of previous local motion energy detectors into two adjacent subfields. Local motion detectors that have the same direction preference are combined into the same subfield. These detectors were modeled after neurons sensitive to opponent motion such as the ones in MT and medial superior temporal (MST). Also, KO/V3B has been associated with processing edges, moving objects, and opponent motion. Patients with damage to dorsal pathway areas but an intact KO/V3B, as seen in patient AF can still perceive biological motion.\n\nThe output for these detectors are the following:\n\nwhere formula_50 is the position the output is centered at, direction preferences formula_51 and formula_52, and formula_53 signify spatial positions of two subfields.\n\nThe final output of opponent motion detector is given as\n\nwhere output is the pooled responses of detectors of type formula_55 at formula_56 different spatial positions.\n\n\"Detectors of optic flow patterns\"\n\nEach detector looks at one frame of a training stimulus and compute an instantaneous optic flow field for that particular frame. These detectors model neurons in Superior temporal sulcus and Fusiform face area\n\nThe input of these detectors is arranged from vector u and are comprised from the previous opponent motion detectors’ responses. The output is the following:\n\nsuch that formula_58 is the center of the radial basis function for each neuron and formula_59 is a diagonal matrix which contains elements that have been set during training and correspond to vector u. These elements equal zero if the variance over training doesn't exceed a certain threshold. Otherwise, these elements equal the inverse of variance.\n\nSince recognition of biological motion is dependent on the sequence of activity, the following model is sequence selective. The activity of the optic flow pattern neuron is modeled by the following equation of\n\nin which formula_61 is a specific frame in the formula_62-th training sequence, formula_32 is the time constant.formula_64 a threshold function, formula_65 is an asymmetric interaction kernel, and formula_66 is obtained from the previous section.\n\n\"Detectors of complete biological motion patterns\"\nThe following detectors sum the output of the optic flow pattern detectors in order to selectively activate for whole movement patterns (e.g. walking right vs. walking left). These detectors model similar neurons that optic flow pattern detectors model:\n\nSuperior temporal sulcus and Fusiform face area\n\nThe input of these detectors are the activity of the optic flow motion detectors, formula_67. The output of these detectors are the following:\n\nsuch that formula_69 is the activity of the complete biological motion pattern detector in response to pattern type formula_55 (e.g. walking to the left), formula_71 equals the time constant (used 150 ms in simulation), and formula_72 equals the activity of optic flow pattern detector at kth frame in sequence l.\n\nUsing correct determination of walking direction of both the CFS and SPS stimulus, the model was able to replicate similar results as the psychophysical experiments. (could determine walking direction of CFS and SPS stimuli and increasing correct with increasing number of dots). It is postulated that recognition of biological motion is made possible by the opponent horizontal motion information that is present in both the CFS and SPS stimuli.\n\nDemo of point light walker: \nReferences: \n"}
{"id": "39998035", "url": "https://en.wikipedia.org/wiki?curid=39998035", "title": "Centered world", "text": "Centered world\n\nA centered world, according to David Kellogg Lewis, consists of (1) a possible world, (2) an agent in that world, and (3) a time in that world. The concept of centered worlds has epistemic as well as metaphysical uses; for the latter, the three components of a centered world have connections to theories such as actualism, solipsism (especially egocentric presentism and perspectival realism), and presentism, respectively.\n"}
{"id": "29675785", "url": "https://en.wikipedia.org/wiki?curid=29675785", "title": "Certainty effect", "text": "Certainty effect\n\nThe certainty effect is the psychological effect resulting from the reduction of probability from certainty to probable . It is an idea introduced in prospect theory. \n\nNormally a reduction in the probability of winning a reward (e.g., a reduction from 80% to 20% in the chance of winning a reward) creates a psychological effect such as displeasure to individuals, which leads to the perception of loss from the original probability thus favoring a risk-averse decision. However, the same reduction results in a larger psychological effect when it is done from certainty than from uncertainty.\n\n illustrated the certainty effect by the following examples.\n\nFirst, consider this example:\n\nWhich of the following options do you prefer?\n\nIn this case, 78% of participants chose option A while only 22% chose option B. This demonstrates the typical risk-aversion phenomenon in prospect theory and framing effect because the expected value of option B ($45x0.8=$36) exceeds that of A by 20%.\n\nNow, consider this problem:\n\nWhich of the following options do you prefer?\n\n\nIn this case, 42% of participants chose option C while 58% chose option D. \n\nAs before, the expected value of the first option ($30x0.25=$7.50) was 20% lower than that of option D ($45x0.2=9) however, when neither option was certain, risk-taking increased.\n\n\n"}
{"id": "24414038", "url": "https://en.wikipedia.org/wiki?curid=24414038", "title": "Decuriae", "text": "Decuriae\n\nDecuriae was a Roman unit of measurement applied to civitas of native peoples. It had been mentioned by Pliny the Elder at 70 AD in his work, \"Natural History\".\n\n"}
{"id": "35903719", "url": "https://en.wikipedia.org/wiki?curid=35903719", "title": "Disruptive physician", "text": "Disruptive physician\n\nA disruptive physician is a physician whose obnoxious behaviour upsets patients or other staff. The American Medical Association defines this in their code of medical ethics as \"personal conduct, whether verbal or physical, that negatively affects or that potentially may affect patient care\". These behaviors are also noted as causing adverse effects such as morale, focus and concentration, team work, collaboration and communication. Starting in 2009, The Joint Commission which accredits hospitals in the United States requires them to have a written code of conduct addressing this issue. This code of conduct defines acceptable, disruptive, and unacceptable behavior in the workplace. Along with these definitions of behaviors the Joint Commission also wrote ways to manage these behaviors in order to fix them.\n\nSimon Sebag Montefiore has reported a remarkable tendency for doctors to become tyrannical dictators. Historical examples include:\n\n\n\nJacob DeLaRosa. The Disruptive Physician, \"How to Manage the Consequences of Being You\" Misner & Monroe, New York 2017\n\n"}
{"id": "529089", "url": "https://en.wikipedia.org/wiki?curid=529089", "title": "Dissociation (psychology)", "text": "Dissociation (psychology)\n\nIn psychology, dissociation is any of a wide array of experiences from mild detachment from immediate surroundings to more severe detachment from physical and emotional experiences. The major characteristic of all dissociative phenomena involves a detachment from reality, rather than a loss of reality as in psychosis.\n\nDissociation is commonly displayed on a continuum. In mild cases, dissociation can be regarded as a coping mechanism or defense mechanisms in seeking to master, minimize or tolerate stress – including boredom or conflict. At the nonpathological end of the continuum, dissociation describes common events such as daydreaming. Further along the continuum are non-pathological altered states of consciousness.\n\nMore pathological dissociation involves dissociative disorders, including dissociative fugue and depersonalization disorder with or without alterations in personal identity or sense of self. These alterations can include: a sense that self or the world is unreal (depersonalization and derealization); a loss of memory (amnesia); forgetting identity or assuming a new self (fugue); and separate streams of consciousness, identity and self (dissociative identity disorder, formerly termed multiple personality disorder) and complex post-traumatic stress disorder.\n\nDissociative disorders are sometimes triggered by trauma, but may be preceded only by stress, psychoactive substances, or no identifiable trigger at all. The ICD-10 classifies conversion disorder as a dissociative disorder. The Diagnostic and Statistical Manual of Mental Disorders groups all dissociative disorders into a single category.\n\nAlthough some dissociative disruptions involve amnesia, other dissociative events do not. Dissociative disorders are typically experienced as startling, autonomous intrusions into the person's usual ways of responding or functioning. Due to their unexpected and largely inexplicable nature, they tend to be quite unsettling.\n\nFrench philosopher and psychologist Pierre Janet (1859–1947) is considered to be the author of the concept of dissociation. Contrary to some conceptions of dissociation, Janet did not believe that dissociation was a psychological defense.\n\nPsychological defense mechanisms belong to Freud's theory of psychoanalysis, not to Janetian psychology. Janet claimed that dissociation occurred only in persons who had a constitutional weakness of mental functioning that led to hysteria when they were stressed. Although it is true that many of Janet's case histories described traumatic experiences, he never considered dissociation to be a defense against those experiences. Quite the opposite: Janet insisted that dissociation was a mental or cognitive deficit. Accordingly, he considered trauma to be one of many stressors that could worsen the already-impaired \"mental efficiency\" of a hysteric, thereby generating a cascade of hysterical (in today's language, \"dissociative\") symptoms.\n\nAlthough there was great interest in dissociation during the last two decades of the nineteenth century (especially in France and England), this interest rapidly waned with the coming of the new century. Even Janet largely turned his attention to other matters.\n\nOn the other hand, there was a sharp peak in interest in dissociation in America from 1890 to 1910, especially in Boston as reflected in the work of William James, Boris Sidis, Morton Prince, and William McDougall. Nevertheless, even in America, interest in dissociation rapidly succumbed to the surging academic interest in psychoanalysis and behaviorism.\n\nFor most of the twentieth century, there was little interest in dissociation. Despite this, a review of 76 previously published cases (from 1790’s – 1942),was published in 1944, describing clinical phenomena consistent with that seen by Janet and by therapists today. In 1971 Bowers and her colleagues presented a detailed, and still quite valid, treatment article. The authors of this article included leading thinkers of their time – John G. Watkins (who developed Ego-state therapy) and Zygmunt A. Piotrowski (famed for his work on the Rorschach test). Further interest in dissociation was evoked when Ernest Hilgard (1977) published his neodissociation theory in the 1970s. During the 1970's and 1980's an increasing number of clinicians and researchers wrote about dissociation, particularly multiple personality disorder.. \n\nCarl Jung described pathological manifestations of dissociation as special or extreme cases of the normal operation of the psyche. This structural dissociation, opposing tension, and hierarchy of basic attitudes and functions in normal individual consciousness is the basis of Jung's \"Psychological Types\". He theorized that dissociation is a natural necessity for consciousness to operate in one faculty unhampered by the demands of its opposite.\n\nAttention to dissociation as a clinical feature has been growing in recent years as knowledge of post-traumatic stress disorder increased, due to interest in dissociative identity disorder, and as neuroimaging research and population studies show its relevance.\n\nHistorically the psychopathological concept of dissociation has also another different root: the conceptualization of Eugen Bleuler that looks into dissociation related to schizophrenia.\n\nDissociation in community samples is most commonly measured by the Dissociative Experiences Scale. The \"DSM-IV\" considers symptoms such as depersonalization, derealization and psychogenic amnesia to be core features of dissociative disorders. However, in the normal population, dissociative experiences that are not clinically significant are highly prevalent with 60% to 65% of the respondents indicating that they have had some dissociative experiences. The SCID-D is a structured interview used to assess and diagnose dissociation.\n\nDissociation has been described as one of a constellation of symptoms experienced by some victims of multiple forms of childhood trauma, including physical, psychological, and sexual abuse. This is supported by studies which suggest that dissociation is correlated with a history of trauma.\n\nDissociation appears to have a high specificity and a low sensitivity to having a self-reported history of trauma, which means that dissociation is much more common among those who are traumatized, yet at the same time there are many people who have suffered from trauma but who do not show dissociative symptoms.\n\nAdult dissociation when combined with a history of child abuse and otherwise interpersonal violence-related posttraumatic stress disorder (PTSD) has been shown to contribute to disturbances in parenting behavior, such as exposure of young children to violent media. Such behavior may contribute to cycles of familial violence and trauma.\n\nSymptoms of dissociation resulting from trauma may include depersonalization, psychological numbing, disengagement, or amnesia regarding the events of the abuse. It has been hypothesized that dissociation may provide a temporarily effective defense mechanism in cases of severe trauma; however, in the long term, dissociation is associated with decreased psychological functioning and adjustment.\n\nOther symptoms sometimes found along with dissociation in victims of traumatic abuse (often referred to as \"sequelae to abuse\") include anxiety, PTSD, low self-esteem, somatization, depression, chronic pain, interpersonal dysfunction, substance abuse, self-harm and suicidal ideation or actions. These symptoms may lead the victim to present the symptoms as the source of the problem.\n\nChild abuse, especially chronic abuse starting at early ages, has been related to high levels of dissociative symptoms in a clinical sample, including amnesia for abuse memories. A non-clinical sample of adult women linked increased levels of dissociation to sexual abuse by a significantly older person prior to age 15, and dissociation has also been correlated with a history of childhood physical and sexual abuse. When sexual abuse is examined, the levels of dissociation were found to increase along with the severity of the abuse.\n\nA 2012 review article supports the hypothesis that current or recent trauma may affect an individual's assessment of the more distant past, changing the experience of the past and resulting in dissociative states.\n\nPsychoactive drugs can often induce a state of temporary dissociation. Substances with dissociative properties include ketamine, nitrous oxide, alcohol, tiletamine, amphetamine, dextromethorphan, MK-801, PCP, methoxetamine, salvia, muscimol, atropine, ibogaine, and minocycline.\n\n"}
{"id": "1248109", "url": "https://en.wikipedia.org/wiki?curid=1248109", "title": "Draft document", "text": "Draft document\n\nDrafting is the preliminary stage of a written work in which the author begins to develop a more cohesive product. A draft document is the product the writer creates in the initial stages of the writing process.\n\nIn the drafting stage, the author:\n\nIn a book that became popular in the 1950s, \"The Elements of Style\", famed authors Strunk and White describe the first draft as being a less edited version of the final draft. In their book, Strunk and White say, “the first principle of composition is to foresee or determine the shape of what is to come and pursue that shape.” This shape is the draft that eventually becomes the finished work.\n\nMore recently, Peter Elbow, in his book \"Writing Without Teachers\", presents a very different view of the drafting stage in the writing process. He describes his stance on the writing process, saying “Writing is a way to end up thinking something you couldn’t have started out thinking.” According to Elbow, the best way to accomplish this is a series of drafts which come together to produce an emerging “center of gravity” that then translates into the main focus on the work. This process should be a holistic process, not a linear process. Elbow’s reasoning behind this concept of multiple drafts follows the idea that, “if he learns to maximize the interaction among his own ideas or points of view, he can produce new ones that didn’t seem available to him.”\n\nWhether being used as the creation of a less-edited final product (Strunk and White) or as a tool during the prewriting stage (Elbow), drafting is a necessary stage for the writer in the writing process. Having created a draft, the author is then able to move onto the revision.\n\n"}
{"id": "9630", "url": "https://en.wikipedia.org/wiki?curid=9630", "title": "Ecology", "text": "Ecology\n\nEcology (from , \"house\", or \"environment\"; -λογία, \"study of\") is the branch of biology which studies the interactions among organisms and their environment. Objects of study include interactions of organisms with each other and with abiotic components of their environment. Topics of interest include the biodiversity, distribution, biomass, and populations of organisms, as well as cooperation and competition within and between species. Ecosystems are dynamically interacting systems of organisms, the communities they make up, and the non-living components of their environment. Ecosystem processes, such as primary production, pedogenesis, nutrient cycling, and niche construction, regulate the flux of energy and matter through an environment. These processes are sustained by organisms with specific life history traits. Biodiversity means the varieties of species, genes, and ecosystems, enhances certain ecosystem services.\n\nEcology is not synonymous with environmentalism, natural history, or environmental science. It overlaps with the closely related sciences of evolutionary biology, genetics, and ethology. An important focus for ecologists is to improve the understanding of how biodiversity affects ecological function. Ecologists seek to explain:\n\n\nEcology has practical applications in conservation biology, wetland management, natural resource management (agroecology, agriculture, forestry, agroforestry, fisheries), city planning (urban ecology), community health, economics, basic and applied science, and human social interaction (human ecology). For example, the \"Circles of Sustainability\" approach treats ecology as more than the environment 'out there'. It is not treated as separate from humans. Organisms (including humans) and resources compose ecosystems which, in turn, maintain biophysical feedback mechanisms that moderate processes acting on living (biotic) and non-living (abiotic) components of the planet. Ecosystems sustain life-supporting functions and produce natural capital like biomass production (food, fuel, fiber, and medicine), the regulation of climate, global biogeochemical cycles, water filtration, soil formation, erosion control, flood protection, and many other natural features of scientific, historical, economic, or intrinsic value.\n\nThe word \"ecology\" (\"Ökologie\") was coined in 1866 by the German scientist Ernst Haeckel. Ecological thought is derivative of established currents in philosophy, particularly from ethics and politics. Ancient Greek philosophers such as Hippocrates and Aristotle laid the foundations of ecology in their studies on natural history. Modern ecology became a much more rigorous science in the late 19th century. Evolutionary concepts relating to adaptation and natural selection became the cornerstones of modern ecological theory.\n\nThe scope of ecology contains a wide array of interacting levels of organization spanning micro-level (e.g., cells) to a planetary scale (e.g., biosphere) phenomena. Ecosystems, for example, contain abiotic resources and interacting life forms (i.e., individual organisms that aggregate into populations which aggregate into distinct ecological communities). Ecosystems are dynamic, they do not always follow a linear successional path, but they are always changing, sometimes rapidly and sometimes so slowly that it can take thousands of years for ecological processes to bring about certain successional stages of a forest. An ecosystem's area can vary greatly, from tiny to vast. A single tree is of little consequence to the classification of a forest ecosystem, but critically relevant to organisms living in and on it. Several generations of an aphid population can exist over the lifespan of a single leaf. Each of those aphids, in turn, support diverse bacterial communities. The nature of connections in ecological communities cannot be explained by knowing the details of each species in isolation, because the emergent pattern is neither revealed nor predicted until the ecosystem is studied as an integrated whole. Some ecological principles, however, do exhibit collective properties where the sum of the components explain the properties of the whole, such as birth rates of a population being equal to the sum of individual births over a designated time frame.\n\nThe main subdisciplines of ecology, population (or community) ecology and ecosystem ecology, exhibit a difference not only of scale, but also of two contrasting paradigms in the field. The former focus on organisms distribution and abundance, while the later focus on materials and energy fluxes.\n\nThe scale of ecological dynamics can operate like a closed system, such as aphids migrating on a single tree, while at the same time remain open with regard to broader scale influences, such as atmosphere or climate. Hence, ecologists classify ecosystems hierarchically by analyzing data collected from finer scale units, such as vegetation associations, climate, and soil types, and integrate this information to identify emergent patterns of uniform organization and processes that operate on local to regional, landscape, and chronological scales.\n\nTo structure the study of ecology into a conceptually manageable framework, the biological world is organized into a nested hierarchy, ranging in scale from genes, to cells, to tissues, to organs, to organisms, to species, to populations, to communities, to ecosystems, to biomes, and up to the level of the biosphere. This framework forms a panarchy and exhibits non-linear behaviors; this means that \"effect and cause are disproportionate, so that small changes to critical variables, such as the number of nitrogen fixers, can lead to disproportionate, perhaps irreversible, changes in the system properties.\"\n\nBiodiversity (an abbreviation of \"biological diversity\") describes the diversity of life from genes to ecosystems and spans every level of biological organization. The term has several interpretations, and there are many ways to index, measure, characterize, and represent its complex organization. Biodiversity includes species diversity, ecosystem diversity, and genetic diversity and scientists are interested in the way that this diversity affects the complex ecological processes operating at and among these respective levels. Biodiversity plays an important role in ecosystem services which by definition maintain and improve human quality of life. Conservation priorities and management techniques require different approaches and considerations to address the full ecological scope of biodiversity. Natural capital that supports populations is critical for maintaining ecosystem services and species migration (e.g., riverine fish runs and avian insect control) has been implicated as one mechanism by which those service losses are experienced. An understanding of biodiversity has practical applications for species and ecosystem-level conservation planners as they make management recommendations to consulting firms, governments, and industry.\n\nThe habitat of a species describes the environment over which a species is known to occur and the type of community that is formed as a result. More specifically, \"habitats can be defined as regions in environmental space that are composed of multiple dimensions, each representing a biotic or abiotic environmental variable; that is, any component or characteristic of the environment related directly (e.g. forage biomass and quality) or indirectly (e.g. elevation) to the use of a location by the animal.\" For example, a habitat might be an aquatic or terrestrial environment that can be further categorized as a montane or alpine ecosystem. Habitat shifts provide important evidence of competition in nature where one population changes relative to the habitats that most other individuals of the species occupy. For example, one population of a species of tropical lizards (\"Tropidurus hispidus\") has a flattened body relative to the main populations that live in open savanna. The population that lives in an isolated rock outcrop hides in crevasses where its flattened body offers a selective advantage. Habitat shifts also occur in the developmental life history of amphibians, and in insects that transition from aquatic to terrestrial habitats. Biotope and habitat are sometimes used interchangeably, but the former applies to a community's environment, whereas the latter applies to a species' environment.\n\nDefinitions of the niche date back to 1917, but G. Evelyn Hutchinson made conceptual advances in 1957 by introducing a widely adopted definition: \"the set of biotic and abiotic conditions in which a species is able to persist and maintain stable population sizes.\" The ecological niche is a central concept in the ecology of organisms and is sub-divided into the \"fundamental\" and the \"realized\" niche. The fundamental niche is the set of environmental conditions under which a species is able to persist. The realized niche is the set of environmental plus ecological conditions under which a species persists. The Hutchinsonian niche is defined more technically as a \"Euclidean hyperspace whose \"dimensions\" are defined as environmental variables and whose \"size\" is a function of the number of values that the environmental values may assume for which an organism has \"positive fitness\".\"\n\nBiogeographical patterns and range distributions are explained or predicted through knowledge of a species' traits and niche requirements. Species have functional traits that are uniquely adapted to the ecological niche. A trait is a measurable property, phenotype, or characteristic of an organism that may influence its survival. Genes play an important role in the interplay of development and environmental expression of traits. Resident species evolve traits that are fitted to the selection pressures of their local environment. This tends to afford them a competitive advantage and discourages similarly adapted species from having an overlapping geographic range. The competitive exclusion principle states that two species cannot coexist indefinitely by living off the same limiting resource; one will always out-compete the other. When similarly adapted species overlap geographically, closer inspection reveals subtle ecological differences in their habitat or dietary requirements. Some models and empirical studies, however, suggest that disturbances can stabilize the co-evolution and shared niche occupancy of similar species inhabiting species-rich communities. The habitat plus the niche is called the ecotope, which is defined as the full range of environmental and biological variables affecting an entire species.\n\nOrganisms are subject to environmental pressures, but they also modify their habitats. The regulatory feedback between organisms and their environment can affect conditions from local (e.g., a beaver pond) to global scales, over time and even after death, such as decaying logs or silica skeleton deposits from marine organisms. The process and concept of ecosystem engineering is related to niche construction, but the former relates only to the physical modifications of the habitat whereas the latter also considers the evolutionary implications of physical changes to the environment and the feedback this causes on the process of natural selection. Ecosystem engineers are defined as: \"organisms that directly or indirectly modulate the availability of resources to other species, by causing physical state changes in biotic or abiotic materials. In so doing they modify, maintain and create habitats.\"\n\nThe ecosystem engineering concept has stimulated a new appreciation for the influence that organisms have on the ecosystem and evolutionary process. The term \"niche construction\" is more often used in reference to the under-appreciated feedback mechanisms of natural selection imparting forces on the abiotic niche. An example of natural selection through ecosystem engineering occurs in the nests of social insects, including ants, bees, wasps, and termites. There is an emergent homeostasis or homeorhesis in the structure of the nest that regulates, maintains and defends the physiology of the entire colony. Termite mounds, for example, maintain a constant internal temperature through the design of air-conditioning chimneys. The structure of the nests themselves are subject to the forces of natural selection. Moreover, a nest can survive over successive generations, so that progeny inherit both genetic material and a legacy niche that was constructed before their time.\n\nBiomes are larger units of organization that categorize regions of the Earth's ecosystems, mainly according to the structure and composition of vegetation. There are different methods to define the continental boundaries of biomes dominated by different functional types of vegetative communities that are limited in distribution by climate, precipitation, weather and other environmental variables. Biomes include tropical rainforest, temperate broadleaf and mixed forest, temperate deciduous forest, taiga, tundra, hot desert, and polar desert. Other researchers have recently categorized other biomes, such as the human and oceanic microbiomes. To a microbe, the human body is a habitat and a landscape. Microbiomes were discovered largely through advances in molecular genetics, which have revealed a hidden richness of microbial diversity on the planet. The oceanic microbiome plays a significant role in the ecological biogeochemistry of the planet's oceans.\n\nThe largest scale of ecological organization is the biosphere: the total sum of ecosystems on the planet. Ecological relationships regulate the flux of energy, nutrients, and climate all the way up to the planetary scale. For example, the dynamic history of the planetary atmosphere's CO and O composition has been affected by the biogenic flux of gases coming from respiration and photosynthesis, with levels fluctuating over time in relation to the ecology and evolution of plants and animals. Ecological theory has also been used to explain self-emergent regulatory phenomena at the planetary scale: for example, the Gaia hypothesis is an example of holism applied in ecological theory. The Gaia hypothesis states that there is an emergent feedback loop generated by the metabolism of living organisms that maintains the core temperature of the Earth and atmospheric conditions within a narrow self-regulating range of tolerance.\n\nPopulation ecology studies the dynamics of species populations and how these populations interact with the wider environment. A population consists of individuals of the same species that live, interact, and migrate through the same niche and habitat.\n\nA primary law of population ecology is the Malthusian growth model which states, \"a population will grow (or decline) exponentially as long as the environment experienced by all individuals in the population remains constant.\" Simplified population models usually start with four variables: death, birth, immigration, and emigration.\n\nAn example of an introductory population model describes a closed population, such as on an island, where immigration and emigration does not take place. Hypotheses are evaluated with reference to a null hypothesis which states that random processes create the observed data. In these island models, the rate of population change is described by:\n\nwhere \"N\" is the total number of individuals in the population, \"b\" and \"d\" are the per capita rates of birth and death respectively, and \"r\" is the per capita rate of population change.\n\nUsing these modelling techniques, Malthus' population principle of growth was later transformed into a model known as the logistic equation:\n\nwhere \"N\" is the number of individuals measured as biomass density, \"a\" is the maximum per-capita rate of change, and \"K\" is the carrying capacity of the population. The formula states that the rate of change in population size (\"dN/dT\") is equal to growth (\"aN\") that is limited by carrying capacity (1 – \"N\"/\"K\").\n\nPopulation ecology builds upon these introductory models to further understand demographic processes in real study populations. Commonly used types of data include life history, fecundity, and survivorship, and these are analysed using mathematical techniques such as matrix algebra. The information is used for managing wildlife stocks and setting harvest quotas. In cases where basic models are insufficient, ecologists may adopt different kinds of statistical methods, such as the Akaike information criterion, or use models that can become mathematically complex as \"several competing hypotheses are simultaneously confronted with the data.\"\n\nThe concept of metapopulations was defined in 1969 as \"a population of populations which go extinct locally and recolonize\". Metapopulation ecology is another statistical approach that is often used in conservation research. Metapopulation models simplify the landscape into patches of varying levels of quality, and metapopulations are linked by the migratory behaviours of organisms. Animal migration is set apart from other kinds of movement; because, it involves the seasonal departure and return of individuals from a habitat. Migration is also a population-level phenomenon, as with the migration routes followed by plants as they occupied northern post-glacial environments. Plant ecologists use pollen records that accumulate and stratify in wetlands to reconstruct the timing of plant migration and dispersal relative to historic and contemporary climates. These migration routes involved an expansion of the range as plant populations expanded from one area to another. There is a larger taxonomy of movement, such as commuting, foraging, territorial behaviour, stasis, and ranging. Dispersal is usually distinguished from migration; because, it involves the one way permanent movement of individuals from their birth population into another population.\n\nIn metapopulation terminology, migrating individuals are classed as emigrants (when they leave a region) or immigrants (when they enter a region), and sites are classed either as sources or sinks. A site is a generic term that refers to places where ecologists sample populations, such as ponds or defined sampling areas in a forest. Source patches are productive sites that generate a seasonal supply of juveniles that migrate to other patch locations. Sink patches are unproductive sites that only receive migrants; the population at the site will disappear unless rescued by an adjacent source patch or environmental conditions become more favourable. Metapopulation models examine patch dynamics over time to answer potential questions about spatial and demographic ecology. The ecology of metapopulations is a dynamic process of extinction and colonization. Small patches of lower quality (i.e., sinks) are maintained or rescued by a seasonal influx of new immigrants. A dynamic metapopulation structure evolves from year to year, where some patches are sinks in dry years and are sources when conditions are more favourable. Ecologists use a mixture of computer models and field studies to explain metapopulation structure.\n\nCommunity ecology is the study of the interactions among a collections of species that inhabit the same geographic area. Community ecologists study the determinants of patterns and processes for two or more interacting species. Research in community ecology might measure species diversity in grasslands in relation to soil fertility. It might also include the analysis of predator-prey dynamics, competition among similar plant species, or mutualistic interactions between crabs and corals.\n\nEcosystems may be habitats within biomes that form an integrated whole and a dynamically responsive system having both physical and biological complexes. Ecosystem ecology is the science of determining the fluxes of materials (e.g. carbon, phosphorus) between different pools (e.g., tree biomass, soil organic material). Ecosystem ecologist attempt to determine the underlying causes of these fluxes. Research in ecosystem ecology might measure primary production (g C/m^2) in a wetland in relation to decomposition and consumption rates (g C/m^2/y). This requires an understanding of the community connections between plants (i.e., primary producers) and the decomposers (e.g., fungi and bacteria),\n\nThe underlying concept of ecosystem can be traced back to 1864 in the published work of George Perkins Marsh (\"Man and Nature\"). Within an ecosystem, organisms are linked to the physical and biological components of their environment to which they are adapted. Ecosystems are complex adaptive systems where the interaction of life processes form self-organizing patterns across different scales of time and space. Ecosystems are broadly categorized as terrestrial, freshwater, atmospheric, or marine. Differences stem from the nature of the unique physical environments that shapes the biodiversity within each. A more recent addition to ecosystem ecology are technoecosystems, which are affected by or primarily the result of human activity.\n\nA food web is the archetypal ecological network. Plants capture solar energy and use it to synthesize simple sugars during photosynthesis. As plants grow, they accumulate nutrients and are eaten by grazing herbivores, and the energy is transferred through a chain of organisms by consumption. The simplified linear feeding pathways that move from a basal trophic species to a top consumer is called the food chain. The larger interlocking pattern of food chains in an ecological community creates a complex food web. Food webs are a type of concept map or a heuristic device that is used to illustrate and study pathways of energy and material flows.\n\nFood webs are often limited relative to the real world. Complete empirical measurements are generally restricted to a specific habitat, such as a cave or a pond, and principles gleaned from food web microcosm studies are extrapolated to larger systems. Feeding relations require extensive investigations into the gut contents of organisms, which can be difficult to decipher, or stable isotopes can be used to trace the flow of nutrient diets and energy through a food web. Despite these limitations, food webs remain a valuable tool in understanding community ecosystems.\n\nFood webs exhibit principles of ecological emergence through the nature of trophic relationships: some species have many weak feeding links (e.g., omnivores) while some are more specialized with fewer stronger feeding links (e.g., primary predators). Theoretical and empirical studies identify non-random emergent patterns of few strong and many weak linkages that explain how ecological communities remain stable over time. Food webs are composed of subgroups where members in a community are linked by strong interactions, and the weak interactions occur between these subgroups. This increases food web stability. Step by step lines or relations are drawn until a web of life is illustrated.\n\nA trophic level (from Greek \"troph\", τροφή, trophē, meaning \"food\" or \"feeding\") is \"a group of organisms acquiring a considerable majority of its energy from the lower adjacent level (according to ecological pyramids) nearer the abiotic source.\" Links in food webs primarily connect feeding relations or trophism among species. Biodiversity within ecosystems can be organized into trophic pyramids, in which the vertical dimension represents feeding relations that become further removed from the base of the food chain up toward top predators, and the horizontal dimension represents the abundance or biomass at each level. When the relative abundance or biomass of each species is sorted into its respective trophic level, they naturally sort into a 'pyramid of numbers'.\n\nSpecies are broadly categorized as autotrophs (or primary producers), heterotrophs (or consumers), and Detritivores (or decomposers). Autotrophs are organisms that produce their own food (production is greater than respiration) by photosynthesis or chemosynthesis. Heterotrophs are organisms that must feed on others for nourishment and energy (respiration exceeds production). Heterotrophs can be further sub-divided into different functional groups, including primary consumers (strict herbivores), secondary consumers (carnivorous predators that feed exclusively on herbivores), and tertiary consumers (predators that feed on a mix of herbivores and predators). Omnivores do not fit neatly into a functional category because they eat both plant and animal tissues. It has been suggested that omnivores have a greater functional influence as predators, because compared to herbivores, they are relatively inefficient at grazing.\n\nTrophic levels are part of the holistic or complex systems view of ecosystems. Each trophic level contains unrelated species that are grouped together because they share common ecological functions, giving a macroscopic view of the system. While the notion of trophic levels provides insight into energy flow and top-down control within food webs, it is troubled by the prevalence of omnivory in real ecosystems. This has led some ecologists to \"reiterate that the notion that species clearly aggregate into discrete, homogeneous trophic levels is fiction.\" Nonetheless, recent studies have shown that real trophic levels do exist, but \"above the herbivore trophic level, food webs are better characterized as a tangled web of omnivores.\"\n\nA keystone species is a species that is connected to a disproportionately large number of other species in the food-web. Keystone species have lower levels of biomass in the trophic pyramid relative to the importance of their role. The many connections that a keystone species holds means that it maintains the organization and structure of entire communities. The loss of a keystone species results in a range of dramatic cascading effects that alters trophic dynamics, other food web connections, and can cause the extinction of other species.\n\nSea otters (\"Enhydra lutris\") are commonly cited as an example of a keystone species; because, they limit the density of sea urchins that feed on kelp. If sea otters are removed from the system, the urchins graze until the kelp beds disappear, and this has a dramatic effect on community structure. Hunting of sea otters, for example, is thought to have led indirectly to the extinction of the Steller's sea cow (\"Hydrodamalis gigas\"). While the keystone species concept has been used extensively as a conservation tool, it has been criticized for being poorly defined from an operational stance. It is difficult to experimentally determine what species may hold a keystone role in each ecosystem. Furthermore, food web theory suggests that keystone species may not be common, so it is unclear how generally the keystone species model can be applied.\n\nComplexity is understood as a large computational effort needed to piece together numerous interacting parts exceeding the iterative memory capacity of the human mind. Global patterns of biological diversity are complex. This biocomplexity stems from the interplay among ecological processes that operate and influence patterns at different scales that grade into each other, such as transitional areas or ecotones spanning landscapes. Complexity stems from the interplay among levels of biological organization as energy, and matter is integrated into larger units that superimpose onto the smaller parts. \"What were wholes on one level become parts on a higher one.\" Small scale patterns do not necessarily explain large scale phenomena, otherwise captured in the expression (coined by Aristotle) 'the sum is greater than the parts'.\n\n\"Complexity in ecology is of at least six distinct types: spatial, temporal, structural, process, behavioral, and geometric.\" From these principles, ecologists have identified emergent and self-organizing phenomena that operate at different environmental scales of influence, ranging from molecular to planetary, and these require different explanations at each integrative level. Ecological complexity relates to the dynamic resilience of ecosystems that transition to multiple shifting steady-states directed by random fluctuations of history. Long-term ecological studies provide important track records to better understand the complexity and resilience of ecosystems over longer temporal and broader spatial scales. These studies are managed by the International Long Term Ecological Network (LTER). The longest experiment in existence is the Park Grass Experiment, which was initiated in 1856. Another example is the Hubbard Brook study, which has been in operation since 1960.\n\nHolism remains a critical part of the theoretical foundation in contemporary ecological studies. Holism addresses the biological organization of life that self-organizes into layers of emergent whole systems that function according to non-reducible properties. This means that higher order patterns of a whole functional system, such as an ecosystem, cannot be predicted or understood by a simple summation of the parts. \"New properties emerge because the components interact, not because the basic nature of the components is changed.\"\n\nEcological studies are necessarily holistic as opposed to reductionistic. Holism has three scientific meanings or uses that identify with ecology: 1) the mechanistic complexity of ecosystems, 2) the practical description of patterns in quantitative reductionist terms where correlations may be identified but nothing is understood about the causal relations without reference to the whole system, which leads to 3) a metaphysical hierarchy whereby the causal relations of larger systems are understood without reference to the smaller parts. Scientific holism differs from mysticism that has appropriated the same term. An example of metaphysical holism is identified in the trend of increased exterior thickness in shells of different species. The reason for a thickness increase can be understood through reference to principles of natural selection via predation without need to reference or understand the biomolecular properties of the exterior shells.\n\nEcology and evolutionary biology are considered sister disciplines of the life sciences. Natural selection, life history, development, adaptation, populations, and inheritance are examples of concepts that thread equally into ecological and evolutionary theory. Morphological, behavioural, and genetic traits, for example, can be mapped onto evolutionary trees to study the historical development of a species in relation to their functions and roles in different ecological circumstances. In this framework, the analytical tools of ecologists and evolutionists overlap as they organize, classify, and investigate life through common systematic principals, such as phylogenetics or the Linnaean system of taxonomy. The two disciplines often appear together, such as in the title of the journal \"Trends in Ecology and Evolution\". There is no sharp boundary separating ecology from evolution, and they differ more in their areas of applied focus. Both disciplines discover and explain emergent and unique properties and processes operating across different spatial or temporal scales of organization. While the boundary between ecology and evolution is not always clear, ecologists study the abiotic and biotic factors that influence evolutionary processes, and evolution can be rapid, occurring on ecological timescales as short as one generation.\n\nAll organisms can exhibit behaviours. Even plants express complex behaviour, including memory and communication. Behavioural ecology is the study of an organism's behaviour in its environment and its ecological and evolutionary implications. Ethology is the study of observable movement or behaviour in animals. This could include investigations of motile sperm of plants, mobile phytoplankton, zooplankton swimming toward the female egg, the cultivation of fungi by weevils, the mating dance of a salamander, or social gatherings of amoeba.\n\nAdaptation is the central unifying concept in behavioural ecology. Behaviours can be recorded as traits and inherited in much the same way that eye and hair colour can. Behaviours can evolve by means of natural selection as adaptive traits conferring functional utilities that increases reproductive fitness.\n\nPredator-prey interactions are an introductory concept into food-web studies as well as behavioural ecology. Prey species can exhibit different kinds of behavioural adaptations to predators, such as avoid, flee, or defend. Many prey species are faced with multiple predators that differ in the degree of danger posed. To be adapted to their environment and face predatory threats, organisms must balance their energy budgets as they invest in different aspects of their life history, such as growth, feeding, mating, socializing, or modifying their habitat. Hypotheses posited in behavioural ecology are generally based on adaptive principles of conservation, optimization, or efficiency. For example, \"[t]he threat-sensitive predator avoidance hypothesis predicts that prey should assess the degree of threat posed by different predators and match their behaviour according to current levels of risk\" or \"[t]he optimal flight initiation distance occurs where expected postencounter fitness is maximized, which depends on the prey's initial fitness, benefits obtainable by not fleeing, energetic escape costs, and expected fitness loss due to predation risk.\"\n\nElaborate sexual displays and posturing are encountered in the behavioural ecology of animals. The birds-of-paradise, for example, sing and display elaborate ornaments during courtship. These displays serve a dual purpose of signalling healthy or well-adapted individuals and desirable genes. The displays are driven by sexual selection as an advertisement of quality of traits among suitors.\n\nCognitive ecology integrates theory and observations from evolutionary ecology and neurobiology, primarily cognitive science, in order to understand the effect that animal interaction with their habitat has on their cognitive systems and how those systems restrict behavior within an ecological and evolutionary framework. \"Until recently, however, cognitive scientists have not paid sufficient attention to the fundamental fact that cognitive traits evolved under particular natural settings. With consideration of the selection pressure on cognition, cognitive ecology can contribute intellectual coherence to the multidisciplinary study of cognition.\" As a study involving the 'coupling' or interactions between organism and environment, cognitive ecology is closely related to enactivism, a field based upon the view that \"...we must see the organism and environment as bound together in reciprocal specification and selection...\".\n\nSocial ecological behaviours are notable in the social insects, slime moulds, social spiders, human society, and naked mole-rats where eusocialism has evolved. Social behaviours include reciprocally beneficial behaviours among kin and nest mates and evolve from kin and group selection. Kin selection explains altruism through genetic relationships, whereby an altruistic behaviour leading to death is rewarded by the survival of genetic copies distributed among surviving relatives. The social insects, including ants, bees, and wasps are most famously studied for this type of relationship because the male drones are clones that share the same genetic make-up as every other male in the colony. In contrast, group selectionists find examples of altruism among non-genetic relatives and explain this through selection acting on the group; whereby, it becomes selectively advantageous for groups if their members express altruistic behaviours to one another. Groups with predominantly altruistic members survive better than groups with predominantly selfish members.\n\nEcological interactions can be classified broadly into a host and an associate relationship. A host is any entity that harbours another that is called the associate. Relationships within a species that are mutually or reciprocally beneficial are called mutualisms. Examples of mutualism include fungus-growing ants employing agricultural symbiosis, bacteria living in the guts of insects and other organisms, the fig wasp and yucca moth pollination complex, lichens with fungi and photosynthetic algae, and corals with photosynthetic algae. If there is a physical connection between host and associate, the relationship is called symbiosis. Approximately 60% of all plants, for example, have a symbiotic relationship with arbuscular mycorrhizal fungi living in their roots forming an exchange network of carbohydrates for mineral nutrients.\n\nIndirect mutualisms occur where the organisms live apart. For example, trees living in the equatorial regions of the planet supply oxygen into the atmosphere that sustains species living in distant polar regions of the planet. This relationship is called commensalism; because, many others receive the benefits of clean air at no cost or harm to trees supplying the oxygen. If the associate benefits while the host suffers, the relationship is called parasitism. Although parasites impose a cost to their host (e.g., via damage to their reproductive organs or propagules, denying the services of a beneficial partner), their net effect on host fitness is not necessarily negative and, thus, becomes difficult to forecast. Co-evolution is also driven by competition among species or among members of the same species under the banner of reciprocal antagonism, such as grasses competing for growth space. The Red Queen Hypothesis, for example, posits that parasites track down and specialize on the locally common genetic defense systems of its host that drives the evolution of sexual reproduction to diversify the genetic constituency of populations responding to the antagonistic pressure.\n\nBiogeography (an amalgamation of \"biology\" and \"geography\") is the comparative study of the geographic distribution of organisms and the corresponding evolution of their traits in space and time. The \"Journal of Biogeography\" was established in 1974. Biogeography and ecology share many of their disciplinary roots. For example, the theory of island biogeography, published by the Robert MacArthur and Edward O. Wilson in 1967 is considered one of the fundamentals of ecological theory.\n\nBiogeography has a long history in the natural sciences concerning the spatial distribution of plants and animals. Ecology and evolution provide the explanatory context for biogeographical studies. Biogeographical patterns result from ecological processes that influence range distributions, such as migration and dispersal. and from historical processes that split populations or species into different areas. The biogeographic processes that result in the natural splitting of species explains much of the modern distribution of the Earth's biota. The splitting of lineages in a species is called vicariance biogeography and it is a sub-discipline of biogeography. There are also practical applications in the field of biogeography concerning ecological systems and processes. For example, the range and distribution of biodiversity and invasive species responding to climate change is a serious concern and active area of research in the context of global warming.\n\nA population ecology concept is r/K selection theory, one of the first predictive models in ecology used to explain life-history evolution. The premise behind the r/K selection model is that natural selection pressures change according to population density. For example, when an island is first colonized, density of individuals is low. The initial increase in population size is not limited by competition, leaving an abundance of available resources for rapid population growth. These early phases of population growth experience \"density-independent\" forces of natural selection, which is called \"r\"-selection. As the population becomes more crowded, it approaches the island's carrying capacity, thus forcing individuals to compete more heavily for fewer available resources. Under crowded conditions, the population experiences density-dependent forces of natural selection, called \"K\"-selection.\n\nIn the \"r/K\"-selection model, the first variable \"r\" is the intrinsic rate of natural increase in population size and the second variable \"K\" is the carrying capacity of a population. Different species evolve different life-history strategies spanning a continuum between these two selective forces. An \"r\"-selected species is one that has high birth rates, low levels of parental investment, and high rates of mortality before individuals reach maturity. Evolution favours high rates of fecundity in \"r\"-selected species. Many kinds of insects and invasive species exhibit \"r\"-selected characteristics. In contrast, a \"K\"-selected species has low rates of fecundity, high levels of parental investment in the young, and low rates of mortality as individuals mature. Humans and elephants are examples of species exhibiting \"K\"-selected characteristics, including longevity and efficiency in the conversion of more resources into fewer offspring.\n\nThe important relationship between ecology and genetic inheritance predates modern techniques for molecular analysis. Molecular ecological research became more feasible with the development of rapid and accessible genetic technologies, such as the polymerase chain reaction (PCR). The rise of molecular technologies and influx of research questions into this new ecological field resulted in the publication \"Molecular Ecology\" in 1992. Molecular ecology uses various analytical techniques to study genes in an evolutionary and ecological context. In 1994, John Avise also played a leading role in this area of science with the publication of his book, \"Molecular Markers, Natural History and Evolution\". Newer technologies opened a wave of genetic analysis into organisms once difficult to study from an ecological or evolutionary standpoint, such as bacteria, fungi, and nematodes. Molecular ecology engendered a new research paradigm for investigating ecological questions considered otherwise intractable. Molecular investigations revealed previously obscured details in the tiny intricacies of nature and improved resolution into probing questions about behavioural and biogeographical ecology. For example, molecular ecology revealed promiscuous sexual behaviour and multiple male partners in tree swallows previously thought to be socially monogamous. In a biogeographical context, the marriage between genetics, ecology, and evolution resulted in a new sub-discipline called phylogeography.\n\nEcology is as much a biological science as it is a human science. Human ecology is an interdisciplinary investigation into the ecology of our species. \"Human ecology may be defined: (1) from a bioecological standpoint as the study of man as the ecological dominant in plant and animal communities and systems; (2) from a bioecological standpoint as simply another animal affecting and being affected by his physical environment; and (3) as a human being, somehow different from animal life in general, interacting with physical and modified environments in a distinctive and creative way. A truly interdisciplinary human ecology will most likely address itself to all three.\" The term was formally introduced in 1921, but many sociologists, geographers, psychologists, and other disciplines were interested in human relations to natural systems centuries prior, especially in the late 19th century.\n\nThe ecological complexities human beings are facing through the technological transformation of the planetary biome has brought on the Anthropocene. The unique set of circumstances has generated the need for a new unifying science called coupled human and natural systems that builds upon, but moves beyond the field of human ecology. Ecosystems tie into human societies through the critical and all encompassing life-supporting functions they sustain. In recognition of these functions and the incapability of traditional economic valuation methods to see the value in ecosystems, there has been a surge of interest in social-natural capital, which provides the means to put a value on the stock and use of information and materials stemming from ecosystem goods and services. Ecosystems produce, regulate, maintain, and supply services of critical necessity and beneficial to human health (cognitive and physiological), economies, and they even provide an information or reference function as a living library giving opportunities for science and cognitive development in children engaged in the complexity of the natural world. Ecosystems relate importantly to human ecology as they are the ultimate base foundation of global economics as every commodity, and the capacity for exchange ultimately stems from the ecosystems on Earth.\n\nEcology is an employed science of restoration, repairing disturbed sites through human intervention, in natural resource management, and in environmental impact assessments. Edward O. Wilson predicted in 1992 that the 21st century \"will be the era of restoration in ecology\". Ecological science has boomed in the industrial investment of restoring ecosystems and their processes in abandoned sites after disturbance. Natural resource managers, in forestry, for example, employ ecologists to develop, adapt, and implement ecosystem based methods into the planning, operation, and restoration phases of land-use. Ecological science is used in the methods of sustainable harvesting, disease, and fire outbreak management, in fisheries stock management, for integrating land-use with protected areas and communities, and conservation in complex geo-political landscapes.\n\nThe environment of ecosystems includes both physical parameters and biotic attributes. It is dynamically interlinked, and contains resources for organisms at any time throughout their life cycle. Like ecology, the term environment has different conceptual meanings and overlaps with the concept of nature. Environment \"includes the physical world, the social world of human relations and the built world of human creation.\" The physical environment is external to the level of biological organization under investigation, including abiotic factors such as temperature, radiation, light, chemistry, climate and geology. The biotic environment includes genes, cells, organisms, members of the same species (conspecifics) and other species that share a habitat.\n\nThe distinction between external and internal environments, however, is an abstraction parsing life and environment into units or facts that are inseparable in reality. There is an interpenetration of cause and effect between the environment and life. The laws of thermodynamics, for example, apply to ecology by means of its physical state. With an understanding of metabolic and thermodynamic principles, a complete accounting of energy and material flow can be traced through an ecosystem. In this way, the environmental and ecological relations are studied through reference to conceptually manageable and isolated material parts. After the effective environmental components are understood through reference to their causes; however, they conceptually link back together as an integrated whole, or \"holocoenotic\" system as it was once called. This is known as the dialectical approach to ecology. The dialectical approach examines the parts, but integrates the organism and the environment into a dynamic whole (or umwelt). Change in one ecological or environmental factor can concurrently affect the dynamic state of an entire ecosystem.\n\nEcosystems are regularly confronted with natural environmental variations and disturbances over time and geographic space. A disturbance is any process that removes biomass from a community, such as a fire, flood, drought, or predation. Disturbances occur over vastly different ranges in terms of magnitudes as well as distances and time periods, and are both the cause and product of natural fluctuations in death rates, species assemblages, and biomass densities within an ecological community. These disturbances create places of renewal where new directions emerge from the patchwork of natural experimentation and opportunity. Ecological resilience is a cornerstone theory in ecosystem management. Biodiversity fuels the resilience of ecosystems acting as a kind of regenerative insurance.\n\nThe Earth was formed approximately 4.5 billion years ago. As it cooled and a crust and oceans formed, its atmosphere transformed from being dominated by hydrogen to one composed mostly of methane and ammonia. Over the next billion years, the metabolic activity of life transformed the atmosphere into a mixture of carbon dioxide, nitrogen, and water vapor. These gases changed the way that light from the sun hit the Earth's surface and greenhouse effects trapped heat. There were untapped sources of free energy within the mixture of reducing and oxidizing gasses that set the stage for primitive ecosystems to evolve and, in turn, the atmosphere also evolved.\n\nThroughout history, the Earth's atmosphere and biogeochemical cycles have been in a dynamic equilibrium with planetary ecosystems. The history is characterized by periods of significant transformation followed by millions of years of stability. The evolution of the earliest organisms, likely anaerobic methanogen microbes, started the process by converting atmospheric hydrogen into methane (4H + CO → CH + 2HO). Anoxygenic photosynthesis reduced hydrogen concentrations and increased atmospheric methane, by converting hydrogen sulfide into water or other sulfur compounds (for example, 2HS + CO + h\"v\" → CHO + HO + 2S). Early forms of fermentation also increased levels of atmospheric methane. The transition to an oxygen-dominant atmosphere (the \"Great Oxidation\") did not begin until approximately 2.4–2.3 billion years ago, but photosynthetic processes started 0.3 to 1 billion years prior.\n\nThe biology of life operates within a certain range of temperatures. Heat is a form of energy that regulates temperature. Heat affects growth rates, activity, behaviour, and primary production. Temperature is largely dependent on the incidence of solar radiation. The latitudinal and longitudinal spatial variation of temperature greatly affects climates and consequently the distribution of biodiversity and levels of primary production in different ecosystems or biomes across the planet. Heat and temperature relate importantly to metabolic activity. Poikilotherms, for example, have a body temperature that is largely regulated and dependent on the temperature of the external environment. In contrast, homeotherms regulate their internal body temperature by expending metabolic energy.\n\nThere is a relationship between light, primary production, and ecological energy budgets. Sunlight is the primary input of energy into the planet's ecosystems. Light is composed of electromagnetic energy of different wavelengths. Radiant energy from the sun generates heat, provides photons of light measured as active energy in the chemical reactions of life, and also acts as a catalyst for genetic mutation. Plants, algae, and some bacteria absorb light and assimilate the energy through photosynthesis. Organisms capable of assimilating energy by photosynthesis or through inorganic fixation of HS are autotrophs. Autotrophs — responsible for primary production — assimilate light energy which becomes metabolically stored as potential energy in the form of biochemical enthalpic bonds.\n\nDiffusion of carbon dioxide and oxygen is approximately 10,000 times slower in water than in air. When soils are flooded, they quickly lose oxygen, becoming hypoxic (an environment with O concentration below 2 mg/liter) and eventually completely anoxic where anaerobic bacteria thrive among the roots. Water also influences the intensity and spectral composition of light as it reflects off the water surface and submerged particles. Aquatic plants exhibit a wide variety of morphological and physiological adaptations that allow them to survive, compete, and diversify in these environments. For example, their roots and stems contain large air spaces (aerenchyma) that regulate the efficient transportation of gases (for example, CO and O) used in respiration and photosynthesis. Salt water plants (halophytes) have additional specialized adaptations, such as the development of special organs for shedding salt and osmoregulating their internal salt (NaCl) concentrations, to live in estuarine, brackish, or oceanic environments. Anaerobic soil microorganisms in aquatic environments use nitrate, manganese ions, ferric ions, sulfate, carbon dioxide, and some organic compounds; other microorganisms are facultative anaerobes and use oxygen during respiration when the soil becomes drier. The activity of soil microorganisms and the chemistry of the water reduces the oxidation-reduction potentials of the water. Carbon dioxide, for example, is reduced to methane (CH) by methanogenic bacteria. The physiology of fish is also specially adapted to compensate for environmental salt levels through osmoregulation. Their gills form electrochemical gradients that mediate salt excretion in salt water and uptake in fresh water.\n\nThe shape and energy of the land is significantly affected by gravitational forces. On a large scale, the distribution of gravitational forces on the earth is uneven and influences the shape and movement of tectonic plates as well as influencing geomorphic processes such as orogeny and erosion. These forces govern many of the geophysical properties and distributions of ecological biomes across the Earth. On the organismal scale, gravitational forces provide directional cues for plant and fungal growth (gravitropism), orientation cues for animal migrations, and influence the biomechanics and size of animals. Ecological traits, such as allocation of biomass in trees during growth are subject to mechanical failure as gravitational forces influence the position and structure of branches and leaves. The cardiovascular systems of animals are functionally adapted to overcome pressure and gravitational forces that change according to the features of organisms (e.g., height, size, shape), their behaviour (e.g., diving, running, flying), and the habitat occupied (e.g., water, hot deserts, cold tundra).\n\nClimatic and osmotic pressure places physiological constraints on organisms, especially those that fly and respire at high altitudes, or dive to deep ocean depths. These constraints influence vertical limits of ecosystems in the biosphere, as organisms are physiologically sensitive and adapted to atmospheric and osmotic water pressure differences. For example, oxygen levels decrease with decreasing pressure and are a limiting factor for life at higher altitudes. Water transportation by plants is another important ecophysiological process affected by osmotic pressure gradients. Water pressure in the depths of oceans requires that organisms adapt to these conditions. For example, diving animals such as whales, dolphins, and seals are specially adapted to deal with changes in sound due to water pressure differences. Differences between hagfish species provide another example of adaptation to deep-sea pressure through specialized protein adaptations.\n\nTurbulent forces in air and water affect the environment and ecosystem distribution, form and dynamics. On a planetary scale, ecosystems are affected by circulation patterns in the global trade winds. Wind power and the turbulent forces it creates can influence heat, nutrient, and biochemical profiles of ecosystems. For example, wind running over the surface of a lake creates turbulence, mixing the water column and influencing the environmental profile to create thermally layered zones, affecting how fish, algae, and other parts of the aquatic ecosystem are structured. Wind speed and turbulence also influence evapotranspiration rates and energy budgets in plants and animals. Wind speed, temperature and moisture content can vary as winds travel across different land features and elevations. For example, the westerlies come into contact with the coastal and interior mountains of western North America to produce a rain shadow on the leeward side of the mountain. The air expands and moisture condenses as the winds increase in elevation; this is called orographic lift and can cause precipitation. This environmental process produces spatial divisions in biodiversity, as species adapted to wetter conditions are range-restricted to the coastal mountain valleys and unable to migrate across the xeric ecosystems (e.g., of the Columbia Basin in western North America) to intermix with sister lineages that are segregated to the interior mountain systems.\n\nPlants convert carbon dioxide into biomass and emit oxygen into the atmosphere. By approximately 350 million years ago (the end of the Devonian period), photosynthesis had brought the concentration of atmospheric oxygen above 17%, which allowed combustion to occur. Fire releases CO and converts fuel into ash and tar. Fire is a significant ecological parameter that raises many issues pertaining to its control and suppression. While the issue of fire in relation to ecology and plants has been recognized for a long time, Charles Cooper brought attention to the issue of forest fires in relation to the ecology of forest fire suppression and management in the 1960s.\n\nNative North Americans were among the first to influence fire regimes by controlling their spread near their homes or by lighting fires to stimulate the production of herbaceous foods and basketry materials. Fire creates a heterogeneous ecosystem age and canopy structure, and the altered soil nutrient supply and cleared canopy structure opens new ecological niches for seedling establishment. Most ecosystems are adapted to natural fire cycles. Plants, for example, are equipped with a variety of adaptations to deal with forest fires. Some species (e.g., \"Pinus halepensis\") cannot germinate until after their seeds have lived through a fire or been exposed to certain compounds from smoke. Environmentally triggered germination of seeds is called serotiny. Fire plays a major role in the persistence and resilience of ecosystems.\n\nSoil is the living top layer of mineral and organic dirt that covers the surface of the planet. It is the chief organizing centre of most ecosystem functions, and it is of critical importance in agricultural science and ecology. The decomposition of dead organic matter (for example, leaves on the forest floor), results in soils containing minerals and nutrients that feed into plant production. The whole of the planet's soil ecosystems is called the pedosphere where a large biomass of the Earth's biodiversity organizes into trophic levels. Invertebrates that feed and shred larger leaves, for example, create smaller bits for smaller organisms in the feeding chain. Collectively, these organisms are the detritivores that regulate soil formation. Tree roots, fungi, bacteria, worms, ants, beetles, centipedes, spiders, mammals, birds, reptiles, amphibians, and other less familiar creatures all work to create the trophic web of life in soil ecosystems. Soils form composite phenotypes where inorganic matter is enveloped into the physiology of a whole community. As organisms feed and migrate through soils they physically displace materials, an ecological process called bioturbation. This aerates soils and stimulates heterotrophic growth and production. Soil microorganisms are influenced by and feed back into the trophic dynamics of the ecosystem. No single axis of causality can be discerned to segregate the biological from geomorphological systems in soils. Paleoecological studies of soils places the origin for bioturbation to a time before the Cambrian period. Other events, such as the evolution of trees and the colonization of land in the Devonian period played a significant role in the early development of ecological trophism in soils.\n\nEcologists study and measure nutrient budgets to understand how these materials are regulated, flow, and recycled through the environment. This research has led to an understanding that there is global feedback between ecosystems and the physical parameters of this planet, including minerals, soil, pH, ions, water, and atmospheric gases. Six major elements (hydrogen, carbon, nitrogen, oxygen, sulfur, and phosphorus; H, C, N, O, S, and P) form the constitution of all biological macromolecules and feed into the Earth's geochemical processes. From the smallest scale of biology, the combined effect of billions upon billions of ecological processes amplify and ultimately regulate the biogeochemical cycles of the Earth. Understanding the relations and cycles mediated between these elements and their ecological pathways has significant bearing toward understanding global biogeochemistry.\n\nThe ecology of global carbon budgets gives one example of the linkage between biodiversity and biogeochemistry. It is estimated that the Earth's oceans hold 40,000 gigatonnes (Gt) of carbon, that vegetation and soil hold 2070 Gt, and that fossil fuel emissions are 6.3 Gt carbon per year. There have been major restructurings in these global carbon budgets during the Earth's history, regulated to a large extent by the ecology of the land. For example, through the early-mid Eocene volcanic outgassing, the oxidation of methane stored in wetlands, and seafloor gases increased atmospheric CO (carbon dioxide) concentrations to levels as high as 3500 ppm.\n\nIn the Oligocene, from twenty-five to thirty-two million years ago, there was another significant restructuring of the global carbon cycle as grasses evolved a new mechanism of photosynthesis, C photosynthesis, and expanded their ranges. This new pathway evolved in response to the drop in atmospheric CO concentrations below 550 ppm. The relative abundance and distribution of biodiversity alters the dynamics between organisms and their environment such that ecosystems can be both cause and effect in relation to climate change. Human-driven modifications to the planet's ecosystems (e.g., disturbance, biodiversity loss, agriculture) contributes to rising atmospheric greenhouse gas levels. Transformation of the global carbon cycle in the next century is projected to raise planetary temperatures, lead to more extreme fluctuations in weather, alter species distributions, and increase extinction rates. The effect of global warming is already being registered in melting glaciers, melting mountain ice caps, and rising sea levels. Consequently, species distributions are changing along waterfronts and in continental areas where migration patterns and breeding grounds are tracking the prevailing shifts in climate. Large sections of permafrost are also melting to create a new mosaic of flooded areas having increased rates of soil decomposition activity that raises methane (CH) emissions. There is concern over increases in atmospheric methane in the context of the global carbon cycle, because methane is a greenhouse gas that is 23 times more effective at absorbing long-wave radiation than CO on a 100-year time scale. Hence, there is a relationship between global warming, decomposition and respiration in soils and wetlands producing significant climate feedbacks and globally altered biogeochemical cycles.\n\nEcology has a complex origin, due in large part to its interdisciplinary nature. Ancient Greek philosophers such as Hippocrates and Aristotle were among the first to record observations on natural history. However, they viewed life in terms of essentialism, where species were conceptualized as static unchanging things while varieties were seen as aberrations of an idealized type. This contrasts against the modern understanding of ecological theory where varieties are viewed as the real phenomena of interest and having a role in the origins of adaptations by means of natural selection. Early conceptions of ecology, such as a balance and regulation in nature can be traced to Herodotus (died \"c\". 425 BC), who described one of the earliest accounts of mutualism in his observation of \"natural dentistry\". Basking Nile crocodiles, he noted, would open their mouths to give sandpipers safe access to pluck leeches out, giving nutrition to the sandpiper and oral hygiene for the crocodile. Aristotle was an early influence on the philosophical development of ecology. He and his student Theophrastus made extensive observations on plant and animal migrations, biogeography, physiology, and on their behaviour, giving an early analogue to the modern concept of an ecological niche.\n\nEcological concepts such as food chains, population regulation, and productivity were first developed in the 1700s, through the published works of microscopist Antoni van Leeuwenhoek (1632–1723) and botanist Richard Bradley (1688?–1732). Biogeographer Alexander von Humboldt (1769–1859) was an early pioneer in ecological thinking and was among the first to recognize ecological gradients, where species are replaced or altered in form along environmental gradients, such as a cline forming along a rise in elevation. Humboldt drew inspiration from Isaac Newton as he developed a form of \"terrestrial physics\". In Newtonian fashion, he brought a scientific exactitude for measurement into natural history and even alluded to concepts that are the foundation of a modern ecological law on species-to-area relationships. Natural historians, such as Humboldt, James Hutton, and Jean-Baptiste Lamarck (among others) laid the foundations of the modern ecological sciences. The term \"ecology\" () is of a more recent origin and was first coined by the German biologist Hans Reiter in his book \"Die Consolidation der Physiognomik: Als Versuch einer Oekologie der Gewaechse\" (1885). Reiter derived the term from the Greek oikos, \"household,\" and logia, \"teaching,\" in a footnote on page 5. Ernst Haeckel indepedently introduced the term a year later, in his book \"Generelle Morphologie der Organismen\" (1866). Haeckel was a zoologist, artist, writer, and later in life a professor of comparative anatomy.\n\nOpinions differ on who was the founder of modern ecological theory. Some mark Haeckel's definition as the beginning; others say it was Eugenius Warming with the writing of Oecology of Plants: An Introduction to the Study of Plant Communities (1895), or Carl Linnaeus' principles on the economy of nature that matured in the early 18th century. Linnaeus founded an early branch of ecology that he called the economy of nature. His works influenced Charles Darwin, who adopted Linnaeus' phrase on the \"economy or polity of nature\" in \"The Origin of Species\". Linnaeus was the first to frame the balance of nature as a testable hypothesis. Haeckel, who admired Darwin's work, defined ecology in reference to the economy of nature, which has led some to question whether ecology and the economy of nature are synonymous.\n\nFrom Aristotle until Darwin, the natural world was predominantly considered static and unchanging. Prior to \"The Origin of Species\", there was little appreciation or understanding of the dynamic and reciprocal relations between organisms, their adaptations, and the environment. An exception is the 1789 publication \"Natural History of Selborne\" by Gilbert White (1720–1793), considered by some to be one of the earliest texts on ecology. While Charles Darwin is mainly noted for his treatise on evolution, he was one of the founders of soil ecology, and he made note of the first ecological experiment in \"The Origin of Species\". Evolutionary theory changed the way that researchers approached the ecological sciences.\n\nModern ecology is a young science that first attracted substantial scientific attention toward the end of the 19th century (around the same time that evolutionary studies were gaining scientific interest). The scientist Ellen Swallow Richards may have first introduced the term \"oekology\" (which eventually morphed into home economics) in the U.S. as early 1892.\n\nIn the early 20th century, ecology transitioned from a more descriptive form of natural history to a more analytical form of \"scientific natural history\". Frederic Clements published the first American ecology book in 1905, presenting the idea of plant communities as a superorganism. This publication launched a debate between ecological holism and individualism that lasted until the 1970s. Clements' superorganism concept proposed that ecosystems progress through regular and determined stages of seral development that are analogous to the developmental stages of an organism. The Clementsian paradigm was challenged by Henry Gleason, who stated that ecological communities develop from the unique and coincidental association of individual organisms. This perceptual shift placed the focus back onto the life histories of individual organisms and how this relates to the development of community associations.\n\nThe Clementsian superorganism theory was an overextended application of an idealistic form of holism. The term \"holism\" was coined in 1926 by Jan Christiaan Smuts, a South African general and polarizing historical figure who was inspired by Clements' superorganism concept. Around the same time, Charles Elton pioneered the concept of food chains in his classical book \"Animal Ecology\". Elton defined ecological relations using concepts of food chains, food cycles, and food size, and described numerical relations among different functional groups and their relative abundance. Elton's 'food cycle' was replaced by 'food web' in a subsequent ecological text. Alfred J. Lotka brought in many theoretical concepts applying thermodynamic principles to ecology.\n\nIn 1942, Raymond Lindeman wrote a landmark paper on the trophic dynamics of ecology, which was published posthumously after initially being rejected for its theoretical emphasis. Trophic dynamics became the foundation for much of the work to follow on energy and material flow through ecosystems. Robert MacArthur advanced mathematical theory, predictions, and tests in ecology in the 1950s, which inspired a resurgent school of theoretical mathematical ecologists. Ecology also has developed through contributions from other nations, including Russia's Vladimir Vernadsky and his founding of the biosphere concept in the 1920s and Japan's Kinji Imanishi and his concepts of harmony in nature and habitat segregation in the 1950s. Scientific recognition of contributions to ecology from non-English-speaking cultures is hampered by language and translation barriers.\n\nEcology surged in popular and scientific interest during the 1960–1970s environmental movement. There are strong historical and scientific ties between ecology, environmental management, and protection. The historical emphasis and poetic naturalistic writings advocating the protection of wild places by notable ecologists in the history of conservation biology, such as Aldo Leopold and Arthur Tansley, have been seen as far removed from urban centres where, it is claimed, the concentration of pollution and environmental degradation is located. Palamar (2008) notes an overshadowing by mainstream environmentalism of pioneering women in the early 1900s who fought for urban health ecology (then called euthenics) and brought about changes in environmental legislation. Women such as Ellen Swallow Richards and Julia Lathrop, among others, were precursors to the more popularized environmental movements after the 1950s.\n\nIn 1962, marine biologist and ecologist Rachel Carson's book \"Silent Spring\" helped to mobilize the environmental movement by alerting the public to toxic pesticides, such as DDT, bioaccumulating in the environment. Carson used ecological science to link the release of environmental toxins to human and ecosystem health. Since then, ecologists have worked to bridge their understanding of the degradation of the planet's ecosystems with environmental politics, law, restoration, and natural resources management.\n\n\n\n"}
{"id": "2122862", "url": "https://en.wikipedia.org/wiki?curid=2122862", "title": "Expulsion of the Jews from Sicily", "text": "Expulsion of the Jews from Sicily\n\nThe expulsion of the Jews from Sicily began in 1493 when the Spanish Inquisition reached the island of Sicily and its population of more than 30,000 Jews.\n\nAt the time of expulsion from Sicily, the Jewish community in Sicily dated back to early Roman times, and they were relatively untroubled on the island until the acceptance of the Crown of Aragon in Sicily in 1412. A great number of Jews had reached Sicily after Pompey's 63 BC sacking of Jerusalem.\n\nAfter the enslavement under Roman rule, Jews in Sicily eventually assimilated into society, working in professions such as philosophy, medicine, artisanal pursuits, and farming.\n\nThe exact number of Jews in Sicily at the time of expulsion is not certain, However, some have put the number of Jewish refugees at 36,000.\nAlso, in 1492, it is known the Jewish populations of Palermo, Messina, and several other cities were considerable, and that there were \"Giudeccas\", or Jewish settlements, in over 50 places in Sicily, ranging in anywhere population from 350 to 5,000. At their height, Jewish Sicilians probably constituted from five to eight percent of the island's population.\n\nMuslims had ruled much of the Iberian Peninsula since the first invasion in 711. By the late Middle Ages, Christian kings had begun to wage war on the Moors and recapture some of the peninsula. After the marriage of Ferdinand II of Aragon to Queen Isabella I of Castile, the Moors were finally forced out of Granada in 1492, completing the so-called Reconquista of the Iberian Peninsula.\n\nIn 1479 Sicily and Malta came under Aragonese rule. In 1492, as part of an attempt to maintain Catholic orthodoxy and purify their kingdom of Moorish influence, Ferdinand and Isabella ordered the forced expulsion or conversion of all Jews on pain of death. The date of the expulsion was extended from 18 September 1492 to 12 January 1493, in order to allow the extortion of opportunist tax levies. \n\nMany Sicilian Jews fled to the neighboring mainland of Calabria, where the Spanish Inquisition caught up with them again fifty years later. Not all of the Sicilian Jews departed. A small number of Sicily's Jewish community converted to Catholicism and remained on the island. \n\nThe great part of the Sicilian Jewish community fled to the Ottoman Empire, especially to what is since the twentieth century Greece, Cyprus and Turkey. They were well received there. The settlements of these Jews were in Greece and Turkey were large enough great to build their own congregations and to print books.\n\nThe Jews have never returned en masse to Sicily. However, in 2005, for the first time since the Expulsion, a Passover seder was conducted in Sicily (in Palermo), held by the Milanese progressive Rabbi.\n\n\n\nhttp://www.dieli.net/SicilyPage/JewishSicily/JudaicaMessina1.html\n"}
{"id": "439227", "url": "https://en.wikipedia.org/wiki?curid=439227", "title": "Folk devil", "text": "Folk devil\n\nFolk devil is a person or group of people who are portrayed in folklore or the media as outsiders and deviant, and who are blamed for crimes or other sorts of social problems; see also: \"scapegoat\".\n\nThe pursuit of folk devils frequently intensifies into a mass movement that is called a moral panic. When a moral panic is in full swing, the folk devils are the subject of loosely organized but pervasive campaigns of hostility through gossip and the spreading of urban legends. The mass media sometimes get in on the act or attempt to create new folk devils in an effort to promote controversy. Sometimes the campaign against the folk devil influences a nation's politics and legislation.\n\nThe concept of the folk devil was introduced by sociologist Stanley Cohen in 1972, in his study \"Folk Devils and Moral Panics\", which analysed media controversies concerning Mods and Rockers in the United Kingdom of the 1960s.\n\nCohen’s research was based on the media storm over a violent clash between two youth subcultures, the mods and the rockers, on a bank holiday on a beach in England, 1964. Though the incident only resulted in some property damage without any serious physical injury to any of the individuals involved, several newspapers published sensationalist articles surrounding the event. \nCohen examined articles written about the topic and noted a pattern of distorted facts and misrepresentation, as well as a distinct, simplistic depiction of the respective images of both groups involved in the disturbance. He articulated three stages in the media's reporting on folk devils:\n\n\nIn the case of the mods and rockers, increased police presence the following year on the bank holiday led to another occurrence of violence. Cohen noted that the depiction of mods and rockers as violent, unruly troublemakers actually led in itself to a rise in “deviant behaviour” by the subcultures.\n\nThe basic pattern of agitations against folk devils can be seen in the history of witchhunts and similar manias of persecution; the histories of predominately Catholic and Protestant European countries present examples of adherents of the rival Western Christian faith as folk devils; minorities and immigrants have often been seen as folk devils; in the long history of anti-Semitism, which frequently targets Jews with allegations of dark, murderous practices, such as blood libel; or the Roman persecution of Christians that blamed the military reverses suffered by the Roman Empire on the Christians' abandonment of paganism.\n\nIn modern times, political and religious leaders in many nations have sought to present atheists and secularists as deviant outsiders who threaten the social and moral order. The identification of folk devils may reflect the efforts of powerful institutions to displace social anxieties.\n\nAnother example of religious and ethnic discrimination associated with Cohen's folk devil theory would be Islamophobia, the discrimination of Muslims and those perceived as being Middle Eastern in origin. Post-9/11 reactions by Western countries stereotyped Muslims as violent, hateful, and of possessing fanatical extremist ideology. The group was depicted as posing a threat to social peace and safety in the Western world, and was subject to much hostility politically, from the media and from society.\n\nIn a 2014 study, the media reaction to the Columbine massacre was applied to Cohen’s folk devil theory.\n\nOn April 20, 1999, Eric Harris and Dylan Klebold, two students from Columbine High School in Columbine, Colorado, went on a shooting spree which resulted in the deaths of 15 people. News reports in the weeks following the tragedy labelled the shooters as being “obsessed” with gothic subculture, and suggested a link between Harris and Klebold’s alleged identification with gothic subculture and their acts of violence.\n\nIn their attempt to make sense of the Columbine shootings, journalists and other media commentators linked goths to terrorism, Charles and Marilyn Manson, self-mutilation, hostage-taking, gang culture, the Waco cult, the Oklahoma City bombing, Satanism, mass murder, ethnic cleansing in Kosovo, suicide, the Internet, video games, skinhead music, white extremism, and Adolf Hitler.\n\nThe ABC news program 20/20 aired a special entitled “The Goth Phenomenon” in which it reinforced claims that the shooters were heavily submerged in goth culture, and suggested that individuals of gothic subculture were to blame for homicidal activity in the past. \nThe hostility and hysteria over the perceived ‘evil’ goth culture amplified in the years following the shooting. Goths were stereotyped in the media as being perpetuators or supporters of violence donned in black trench coats. Several high schools across the United States banned black trench coats and other apparel perceived as being linked to goth culture. Some police departments in the United States labelled gothic subculture as being “gang-based”, and as something that should be subjected to “increased police surveillance”. From the time of the Columbine shooting until 2003, there were reports of individuals sporting what was seen as gothic dress being interrogated, ticketed and arrested. In 2002, U.S. Representative Sam Graves caused Blue Springs, Missouri to be granted US$273,000 to combat the “new gothic threat”.\nThe backlash against goth subculture after the Columbine shooting draws many parallels to Stanley Cohen’s research on the mods and rockers, two other youth subcultures cast as folk devils by society. In both instances the groups were portrayed in one distinct, dumbed-down image, ostracized, stripped of any redeeming qualities, and blamed for wrongdoings in society.\n\n"}
{"id": "16803252", "url": "https://en.wikipedia.org/wiki?curid=16803252", "title": "Green national product", "text": "Green national product\n\nThere is a criticism of the gross national product. The criticism stems from the fact that this measurement of national product does not account for environmental degradation and resource depletion. A new approach to the situation of allocating these omitted environmental features in the national product has been the advent of the green national product.\n\nThe gross national product (GNP) measures the welfare of a nation's economy through the aggregate of products and services produced in that nation. Although GNP is a proficient measurement of the magnitude of the economy, many economists, environmentalists and citizens have been arguing the validity of the GNP in respect to measuring welfare. Joseph Stiglitz, Nobel Prize–winning economist, states that this standard measurement for any national economy has become deficient as a measure of long-term economic health in our recently resource-driven and globalizing world. Critics suggest that GNP often includes the environment on the wrong side of the balance sheet because if someone first pollutes and then another person cleans the pollution, both activities add to GNP making environmental degradation frequently look good for the economy. Critics of mainstream economics complain that GNP compiles spending that makes us worse off, spending that allows us to stay in the same place, and spending that makes us better off all in a single measure, giving a nation no clue if they are making progress or not. Manfred Max-Neef, Chilean economist, explains that politicians feel that it is irrelevant whether the spending is productive, unproductive, or destructive. In this sense, it is common to see political policies that call to depredate a natural resource in order to increase the GNP. To take into account the environmental depredation and resource depletion, there is a call to shift away from the traditional GNP and construct an assessment of national product that takes into account environmental effects.\n\nEver since the Industrial Revolution, scientists and economists have warned of an inflection point for the United States economy where expansion is inevitably limited by the steadily decreasing availability of natural resources. In 1973, William D. Nordhaus and James Tobin, Yale economists, were the first to question the GNP in \"is growth obsolete?\" Nordhaus and Tobin developed a Measure of Economic Welfare (MEW) and stated that welfare must be sustainable, in the sense that nations that devour their stock of capital are not as \"well\" as the national income would suggest.\n\nHowever, in \"The Green National Product\", Clifford Cobb and John Cobb argue that the Measure of Economic Welfare failed to encompass the depletion of natural capital. In 1989, Herman Daly, John Cobb, and Clifford Cobb created what is known as the Index of Sustainable Economic Welfare (ISEW). This new measurement of welfare was created in the hopes that it would replace the flawed GNP. Herman Daly stated that the key flaw of the traditional GNP was that it ignored core accounting principles of business where all revenues and expenses are allocated to income. ISEW called for ecological and economic sustainability to coincide since the economy is ultimately dependent on the natural resources that the earth provides. Rather than the original GNP, ISEW takes into account costs that are naturally unsustainable. By creating ISEW, they wanted to expand the current national product so that individuals, businesses, and governments could take actions that will generally enhance welfare, rather than merely enhancing the traditional GNP.\n\nIn 1995, Redefining Progress created the genuine progress indicator (GPI) as an alternative to the traditional GNP. This new measurement of national income would allow policymakers to gauge how well citizens are, economically and socially. Unlike welfare adjustments in the past like MEW and ISEW, GPI adjusts not only for environmental depredation, but also for income distribution, housework, volunteering, crime, changes in leisure time, and life-span of consumer durables and public infrastructure. This was one of the first alternatives to the traditional GNP to be used by the scientific community and governmental organizations globally.\n\nIn 1992, the Bureau of Economic Analysis (BEA) of the U.S. Department of Commerce initiated intensive work to create an environmental accounting system. The BEA began by creating satellite accounts with easily measurable commodities such as petroleum and coal. The first BEA publication was the U.S. Integrated Environmental and Economic Satellite Accounts (IEESA) in 1994. The initial results were quite significant, and showed how GNP was overestimating the impact of mining industries in respect to the nations economic wealth. Mining companies didn't care for the initial publications, for obvious reasons, and soon Alan Mollohan, a Democratic House Representative from West Virginia's coal country, sponsored an amendment to the 1995 Appropriation Bill. In response, Congress directed the BEA to suspend further work in environmental accounting, and to obtain an external review on their findings.\n\nMany people are calling for a green national product that would indicate if activities benefit or harm the economy and well-being. This green national product would revolve around the social and economic issues on which many green movements have focused: care for the earth and all that sustain it. This new national product would differ from the traditional GNP by addressing both the sustainability and well-being of the planet and its inhabitants. It is essential that this system takes into account natural capital, which is currently hidden from our traditional measurement.\n\n"}
{"id": "14769885", "url": "https://en.wikipedia.org/wiki?curid=14769885", "title": "Gualdrada", "text": "Gualdrada\n\nGualdrada was a member of the nobility in 12th century Florence, Italy. She was a daughter of Bellincion Berti, being a descendent of the Ravignani family, a branch of the Adimari family. \n\nGiovanni Boccaccio's \"On Famous Women (De mulieribus claris)\" biography 103 tells her twelfth century story. During a festival in a Florentine Church of Saint John the Baptist, the Holy Roman Emperor Otto IV came to the city and entered the church with his entourage. From his seat he spotted Gualdrada and was impressed with her beauty. He admired her innocence in youth, the way she dressed, and her personality. He asked an elderly gentleman that was near him, \"Who, pray tell, is that girl there facing us with the beautiful face that in my opinion surpasses all the others in dignity?\"\nThe emperor did not know that he was asking her father. Bellincion answered the emperor, saying, \"Your Majesty, whoever she may be, she will kiss you at my bidding if you desire.\" \n\nGualdrada overheard this and was embarrassed and wished that her father would not be so bold with his offers. She immediately replied,\"Father, please stop. Speak no more. For by Heaven, unless force is used, absolutely no one except the man to whom you will give me in lawful and holy matrimony shall receive what you are offering so freely.\"\n\nThe Emperor was both stunned and impressed by this response from Gualdrada. Learning that he was speaking to her father, he praised her in an eloquent speech to everyone of her virtue. As he was leaving the festival he summoned one of his barons, called Guido, and promoted him to a count. He then presented to Gualdrada a large dowry consisting of Casentino and a part of the territory of Romagna. Gualdrada was then given to Guido in marriage. \n\nFrom the marriage of Gualdrada and Guido came two sons, Guglielmo and Ruggieri. Ruggieri was the father of Guidoguerra, a leader of a group of four hundred Florentines of the Guelf party. They were contributory to the victory in 1265 of Charles of Anjou at Benevento over Manfred of Sicily. In 1266 Charles became King of Sicily.\n\n"}
{"id": "631188", "url": "https://en.wikipedia.org/wiki?curid=631188", "title": "Halton sequence", "text": "Halton sequence\n\nIn statistics, Halton sequences are sequences used to generate points in space for numerical methods such as Monte Carlo simulations. Although these sequences are deterministic, they are of low discrepancy, that is, appear to be random for many purposes. They were first introduced in 1960 and are an example of a quasi-random number sequence. They generalise the one-dimensional van der Corput sequences.\n\nThe Halton sequence is constructed according to a deterministic method that uses coprime numbers as its bases. As a simple example, let's take one dimension of the Halton sequence to be based on 2 and the other on 3. To generate the sequence for 2, we start by dividing the interval (0,1) in half, then in fourths, eighths, etc., which generates\n\nEquivalently, the nth number of this sequence is the number n written in binary representation, inverted, and written after the decimal point. This is true for any base. As an example, to find the sixth element of the above sequence, we'd write 6 = 1*2 + 1*2 + 0*2 = 110, which can be inverted and placed after the decimal point to give 0.011 = 0*2 + 1*2 + 1*2 = . So the sequence above is the same as\n\nTo generate the sequence for 3, we divide the interval (0,1) in thirds, then ninths, twenty-sevenths, etc., which generates\n\nWhen we pair them up, we get a sequence of points in a unit square:\n\nEven though standard Halton sequences perform very well in low dimensions, correlation problems have been noted between sequences generated from higher primes. For example, if we started with the primes 17 and 19, the first 16 pairs of points: (, ), (, ), (, ) ... (, ) would have perfect linear correlation. To avoid this, it is common to drop the first 20 entries, or some other predetermined quantity depending on the primes chosen. Several other methods have also been proposed. One of the most prominent solutions is the scrambled Halton sequence, which uses permutations of the coefficients used in the construction of the standard sequence. Another solution is the leaped Halton, which skips points in the standard sequence. Using, eg, only each 409th point (also other prime numbers not used in the Halton core sequence are possible), can achieve significant improvements.\n\n algorithm Halton-Sequence is\n\n\n"}
{"id": "35223708", "url": "https://en.wikipedia.org/wiki?curid=35223708", "title": "History of the center of the Universe", "text": "History of the center of the Universe\n\nThe center of the Universe is a concept that lacks a coherent definition in modern astronomy; according to standard cosmological theories on the shape of the universe, it has no center.\n\nHistorically, the center of the Universe had been believed to be a number of locations. Many mythological cosmologies included an \"axis mundi\", the central axis of a flat Earth that connects the Earth, heavens, and other realms together. In the 4th century BCE Greece, the geocentric model was developed based on astronomical observation, proposing that the center of the Universe lies at the center of a spherical, stationary Earth, around which the sun, moon, planets, and stars rotate. With the development of the heliocentric model by Nicolaus Copernicus in the 16th century, the sun was believed to be the center of the Universe, with the planets (including Earth) and stars orbiting it.\n\nIn the early 20th century, the discovery of other galaxies and the development of the Big Bang theory led to the development of cosmological models of a homogeneous, isotropic Universe (which lacks a central point) that is expanding at all points.\n\nIn religion or mythology, the \"axis mundi\" (also cosmic axis, world axis, world pillar, columna cerului, center of the world) is a point described as the center of the world, the connection between it and Heaven, or both.\n\nMount Hermon was regarded as the axis mundi in Caananite tradition, from where the sons of God are introduced descending in 1 Enoch (1En6:6). The ancient Greeks regarded several sites as places of earth's \"omphalos\" (navel) stone, notably the oracle at Delphi, while still maintaining a belief in a cosmic world tree and in Mount Olympus as the abode of the gods. Judaism has the Temple Mount and Mount Sinai, Christianity has the Mount of Olives and Calvary, Islam has Mecca, said to be the place on earth that was created first, and the Temple Mount (Dome of the Rock). In Shinto, the Ise Shrine is the omphalos. In addition to the Kun Lun Mountains, where it is believed the peach tree of immortality is located, the Chinese folk religion recognizes four other specific mountains as pillars of the world.\n\nSacred places constitute world centers (omphalos) with the altar or place of prayer as the axis. Altars, incense sticks, candles and torches form the axis by sending a column of smoke, and prayer, toward heaven. The architecture of sacred places often reflects this role. \"Every temple or palace--and by extension, every sacred city or royal residence--is a Sacred Mountain, thus becoming a Centre.\" The stupa of Hinduism, and later Buddhism, reflects Mount Meru. Cathedrals are laid out in the form of a cross, with the vertical bar representing the union of earth and heaven as the horizontal bars represent union of people to one another, with the altar at the intersection. Pagoda structures in Asian temples take the form of a stairway linking earth and heaven. A steeple in a church or a minaret in a mosque also serve as connections of earth and heaven. Structures such as the maypole, derived from the Saxons' Irminsul, and the totem pole among indigenous peoples of the Americas also represent world axes. The calumet, or sacred pipe, represents a column of smoke (the soul) rising form a world center. A mandala creates a world center within the boundaries of its two-dimensional space analogous to that created in three-dimensional space by a shrine.\n\nIn medieval times some Christians thought of Jerusalem as the center of the world (Latin: \"umbilicus mundi\", Greek: \"Omphalos\"), and was so represented in the so-called T and O maps. Byzantine hymns speak of the Cross being \"planted in the center of the earth.\"\n\nThe Flat Earth model is a belief that the Earth's shape is a plane or disk covered by a firmament containing heavenly bodies. Most pre-scientific cultures have had conceptions of a Flat Earth, including Greece until the classical period, the Bronze Age and Iron Age civilizations of the Near East until the Hellenistic period, India until the Gupta period (early centuries AD) and China until the 17th century. It was also typically held in the aboriginal cultures of the Americas, and a flat Earth domed by the firmament in the shape of an inverted bowl is common in pre-scientific societies.\n\n\"Center\" is well-defined in a Flat Earth model. A flat earth would have a definite geographic center. There would also be a unique point at the exact center of a spherical firmament (or a firmament that was a half-sphere).\n\nThe Flat Earth model gave way to an understanding of a Spherical Earth. Aristotle (384–322 BCE) provided observational arguments supporting the idea of a spherical Earth, namely that different stars are visible in different locations, travelers going south see southern constellations rise higher above the horizon, and the shadow of Earth on the Moon during a lunar eclipse is round, and spheres cast circular shadows while discs generally do not.\n\nThis understanding was accompanied by models of the Universe that depicted the Sun, Moon, stars, and naked eye planets circling the spherical Earth, including the noteworthy models of Aristotle (see Aristotelian physics) and Ptolemy. This geocentric model was the dominant model from the 4th century BCE until the 17th century CE.\n\nHeliocentrism, or heliocentricism, is the astronomical model in which the Earth and planets revolve around a relatively stationary Sun at the center of our Solar System. The word comes from the Greek ( \"helios\" \"sun\" and \"kentron\" \"center\").\n\nThe notion that the Earth revolves around the Sun had been proposed as early as the 3rd century BCE by Aristarchus of Samos, but had received no support from most other ancient astronomers.\n\nNicolaus Copernicus' major theory of a heliocentric model was published in \"De revolutionibus orbium coelestium\" (\"On the Revolutions of the Celestial Spheres\"), in 1543, the year of his death, though he had formulated the theory several decades earlier. Copernicus' ideas were not immediately accepted, but they did begin a paradigm shift away from the Ptolemaic geocentric model to a heliocentric model. The Copernican revolution, as this paradigm shift would come to be called, would last until Isaac Newton’s work over a century later.\n\nJohannes Kepler published his first two laws about planetary motion in 1609, having found them by analyzing the astronomical observations of Tycho Brahe. Kepler's third law was published in 1619. The first law was \"The orbit of every planet is an ellipse with the Sun at one of the two foci.\"\n\nOn 7 January 1610 Galileo used his telescope, with optics superior to what had been available before. He described \"three fixed stars, totally invisible by their smallness\", all close to Jupiter, and lying on a straight line through it. Observations on subsequent nights showed that the positions of these \"stars\" relative to Jupiter were changing in a way that would have been inexplicable if they had really been fixed stars. On 10 January Galileo noted that one of them had disappeared, an observation which he attributed to its being hidden behind Jupiter. Within a few days he concluded that they were orbiting Jupiter: Galileo stated that he had reached this conclusion on 11 January. He had discovered three of Jupiter's four largest satellites (moons). He discovered the fourth on 13 January.\n\nHis observations of the satellites of Jupiter created a revolution in astronomy: a planet with smaller planets orbiting it did not conform to the principles of Aristotelian Cosmology, which held that all heavenly bodies should circle the Earth, and many astronomers and philosophers initially refused to believe that Galileo could have discovered such a thing.\n\nNewton made clear his heliocentric view of the solar system – developed in a somewhat modern way, because already in the mid-1680s he recognised the \"deviation of the Sun\" from the centre of gravity of the solar system. For Newton, it was not precisely the centre of the Sun or any other body that could be considered at rest, but rather \"the common centre of gravity of the Earth, the Sun and all the Planets is to be esteem'd the Centre of the World\", and this centre of gravity \"either is at rest or moves uniformly forward in a right line\" (Newton adopted the \"at rest\" alternative in view of common consent that the centre, wherever it was, was at rest).\n\nBefore the 1920s, it was generally believed that there were no galaxies other than our own (see for example The Great Debate). Thus, to astronomers of previous centuries, there was no distinction between a hypothetical center of the galaxy and a hypothetical center of the universe.\nIn 1750 Thomas Wright, in his work \"An original theory or new hypothesis of the Universe\", correctly speculated that the Milky Way might be a body of a huge number of stars held together by gravitational forces rotating about a Galactic Center, akin to the solar system but on a much larger scale. The resulting disk of stars can be seen as a band on the sky from our perspective inside the disk. In a treatise in 1755, Immanuel Kant elaborated on Wright's idea about the structure of the Milky Way.\n\nThe 19th century astronomer Johann Heinrich von Mädler proposed the Central Sun Hypothesis, according to which the stars of the universe revolved around a point in the Pleiades.\n\nIn 1917, Heber Doust Curtis observed a nova within what then was called the \"Andromeda Nebula\". Searching the photographic record, 11 more novae were discovered. Curtis noticed that novas in Andromeda were drastically fainter than novas in the Milky Way. Based on this, Curtis was able to estimate that Andromeda was 500,000 light-years away. As a result, Curtis became a proponent of the so-called \"island Universes\" hypothesis, which held that objects previously believed to be spiral nebulae within the Milky Way were actually independent galaxies.\n\nIn 1920, the Great Debate between Harlow Shapley and Curtis took place, concerning the nature of the Milky Way, spiral nebulae, and the dimensions of the Universe. To support his claim that the Great Andromeda Nebula (M31) was an external galaxy, Curtis also noted the appearance of dark lanes resembling the dust clouds in our own Galaxy, as well as the significant Doppler shift. In 1922 Ernst Öpik presented a very elegant and simple astrophysical method to estimate the distance of M31. His result put the Andromeda Nebula far outside our Galaxy at a distance of about 450,000 parsec, which is about 1,500,000 ly. Edwin Hubble settled the debate about whether other galaxies exist in 1925 when he identified extragalactic Cepheid variable stars for the first time on astronomical photos of M31. These were made using the 2.5 metre (100 in) Hooker telescope, and they enabled the distance of Great Andromeda Nebula to be determined. His measurement demonstrated conclusively that this feature was not a cluster of stars and gas within our Galaxy, but an entirely separate galaxy located a significant distance from our own. This proved the existence of other galaxies.\n\nHubble also demonstrated that the redshift of other galaxies is approximately proportional to their distance from the Earth (Hubble's law). This raised the appearance of our galaxy being in the center of an expanding Universe, however, Hubble rejected the findings philosophically:\n\nThe redshift observations of Hubble, in which galaxies appear to be moving away from us at a rate proportional to their distance from us, are now understood to be a result of the metric expansion of space. This is the increase of the distance between two distant parts of the Universe with time, and is an intrinsic expansion whereby the scale of space itself changes. As Hubble theorized, all observers anywhere in the Universe will observe a similar effect.\n\nThe Copernican principle, named after Nicolaus Copernicus, states that the Earth is not in a central, specially favored position. Hermann Bondi named the principle after Copernicus in the mid-20th century, although the principle itself dates back to the 16th-17th century paradigm shift away from the geocentric Ptolemaic system.\n\nThe cosmological principle is an extension of the Copernican principle which states that the Universe is homogeneous (the same observational evidence is available to observers at different locations in the Universe) and isotropic (the same observational evidence is available by looking in any direction in the Universe). A homogeneous, isotropic Universe does not have a center.\n"}
{"id": "310914", "url": "https://en.wikipedia.org/wiki?curid=310914", "title": "Hodge star operator", "text": "Hodge star operator\n\nIn mathematics, the Hodge star operator or Hodge star is a linear map introduced by W. V. D. Hodge. It is defined on the exterior algebra of a finite-dimensional oriented vector space endowed with a nondegenerate symmetric bilinear form. The result when applied to an element of the algebra is called the element's Hodge dual.\n\nFor example, in 3-dimensional Euclidean space, every oriented plane has an unique normal vector, and every vector can be used to define a plane perpendicular to that vector. The Hodge star can be thought of as generalizing this relationship: in general, for an -dimensional vector space, the Hodge star maps -vectors to -vectors and vice versa.\n\nSuppose that is the dimension of the oriented inner product space and is an integer such that , then the Hodge star operator establishes a one-to-one mapping from the space of -vectors to the space of -vectors. The image of a -vector under this mapping is called its \"Hodge dual\". The former space, of -vectors, has dimension formula_1, while the latter has dimension formula_2, which are equal by the symmetry of the binomial coefficients. Equal-dimensional vector spaces are always isomorphic, but not necessarily in a natural or canonical way. In this case, however, Hodge duality exploits the nondegenerate symmetric bilinear form, hereafter referred to as the \"inner product\" (though it might not be positive definite), and a choice of orientation to single out a unique isomorphism, which parallels the combinatorial symmetry of binomial coefficients. This in turn induces an inner product on the space of -vectors. The naturalness of this definition means the duality can play a role in differential geometry.\n\nThe first interesting case is on three-dimensional Euclidean space . In this context the relevant row of Pascal's triangle reads\n\nand the Hodge star sets up an isomorphism between the two three-dimensional spaces, which are and the image space of the exterior product acting on pairs of vectors in . See \"\" for details. In this case the Hodge star allows the definition of the cross product of traditional vector calculus in terms of the exterior product. While the properties of the cross product are special to three dimensions, the Hodge star applies to an arbitrary number of dimensions.\n\nSince the space of alternating linear forms in arguments on a vector space is naturally isomorphic to the dual of the space of -vectors over that vector space, the Hodge star can be defined for these spaces as well. As with most constructions from linear algebra, the Hodge star can then be extended to a vector bundle. Thus a context in which the Hodge star is very often seen is the exterior algebra of the cotangent bundle, the space of differential forms on a manifold, where it can be used to construct the codifferential from the exterior derivative, and thus the Laplace–de Rham operator, which leads to the Hodge decomposition of differential forms in the case of compact Riemannian manifolds.\n\nThe Hodge star operator on a vector space with an inner product is a linear operator on the exterior algebra of , mapping -vectors to -vectors where , for . It has the following property, which defines it completely: given two -vectors ,\n\nwhere formula_4 denotes the inner product on -vectors and is the preferred unit -vector.\n\nThe inner product formula_4 on -vectors is extended from that on by requiring that for any decomposable -vectors formula_6 and formula_7 it equals the Gram determinant\n\nThe unit -vector is unique up to a sign. The preferred choice of defines an orientation on .\n\nLet be a vector space, with an inner product formula_9. The Riesz representation theorem states that for every continuous (even in the infinite-dimensional case) linear functional formula_10 there exists a unique vector in such that formula_11 for all in . The map formula_12 given by formula_13 is an isomorphism. (If is complex, the map is \"conjugate linear\" as opposed to complex linear.) This holds for \"all\" vector spaces with an inner product, and can be used to explain the Hodge star.\n\nLet be an -dimensional vector space with basis formula_14. For , consider the exterior power spaces formula_15 and formula_16. For\n\nwe have\n\nThere is, up to a scalar, only one -vector (an -form), namely formula_19. In other words, formula_20 must be a scalar multiple of formula_19 for all formula_22 and formula_23.\n\nConsider a \"fixed\" formula_22. There exists a unique linear function\n\nsuch that\n\nThis formula_27 is the scalar multiple mentioned in the previous paragraph. If formula_28 denotes the inner product on -vectors, then there exists a unique -vector, say\n\nsuch that\n\nThis -vector is the Hodge dual of , and is the image of the formula_31 under the isomorphism induced by the inner product,\n\nThus,\n\nGiven an orthonormal basis formula_34 ordered such that formula_35, for a positive-definite metric, we see that\n\nwhere formula_37 is an even permutation of \n\nOf these formula_38 relations, only formula_39 are independent. The first one in the usual lexicographical order reads\n\nUsing tensor index notation, the Hodge dual of an arbitrary wedge product of one-forms is given by the following:\n\nThe symbol formula_42 is the Levi-Civita symbol defined so that formula_43 and formula_44 is the inverse metric. Note that the factorial formula_45 had to be inserted to account for double counting, and cancels out if one orders the summation indices so that formula_46. The absolute value of the determinant is necessary since it may be negative, e.g. for tangent spaces to Lorentzian manifolds.\n\nAn arbitrary differential form can be expanded into its components as follows:\n\nThe factorial formula_48 is again included to account for double counting. We would like to define the dual of the component formula_49 so that the Hodge dual of the form is given by \n\nThus using the expression for the Hodge dual of formula_51 given at the beginning of this section we find\n\nIt is understood that indices are raised and lowered using the same inner product formula_53 as in the definition of the Levi-Civita tensor. Although one can apply this expression to any tensor formula_54, the result is antisymmetric, since contraction with the completely anti-symmetric Levi-Civita symbol cancels all but the totally antisymmetric part of the tensor. It is thus equivalent to antisymmetrization followed by applying the Hodge star.\n\nIn two dimensions with the normalized Euclidean metric and orientation given by the ordering , the Hodge star on -forms is given by\n\nThe complex plane has the remarkable property that it is invariant under holomorphic changes of coordinate.\nIf is a holomorphic function of , then by the Cauchy–Riemann equations and . In the new coordinates\n\nso that\n\nproving the claimed invariance.\n\nA common example of the star operator is the case , when it can be taken as the correspondence between the vectors and the skew-symmetric matrices of that size. This is used implicitly in vector calculus, for example to create the cross product vector from the wedge product of two vectors. Specifically, for Euclidean R, one easily finds that\n\nwhere , and are the standard orthonormal differential one-forms on R. The Hodge star in this case clearly relates the cross-product to the wedge product in three dimensions. A detailed presentation not restricted to differential geometry is provided next.\n\nApplied to three dimensions, the Hodge star provides an isomorphism between axial vectors and bivectors, so each axial vector a is associated with a bivector and vice versa, that is:\n\nwhere is the Hodge star. These dual relations can be implemented using multiplication by the unit pseudoscalar in , (the vectors are an orthonormal basis in three dimensional Euclidean space) according to the relations:\n\nThe dual of a vector is obtained by multiplication by , as established using the properties of the geometric product of the algebra as follows:\n\nand also, in the dual space spanned by \n\nIn establishing these results, the identities are used:\n\nand:\n\nThese relations between the dual and apply to any vectors. Here they are applied to relate the axial vector created as the cross product to the bivector-valued exterior product of two polar (that is, not axial) vectors and ; the two products can be written as determinants expressed in the same way:\n\nusing the notation . These expressions show these two types of vector are Hodge duals:\n\nas a result of the relations:\n\nwith cyclic,\n\nand:\n\nalso with cyclic.\n\nUsing the implementation of based upon , the commonly used relations are:\n\nIn case , the Hodge star acts as an endomorphism of the second exterior power (i.e. it maps two-forms to two-forms, since ). It is an involution, so it splits it into \"self-dual\" and \"anti-self-dual\" subspaces, on which it acts respectively as and .\n\nAnother useful example is Minkowski spacetime with metric signature and coordinates where (using formula_73)\n\nfor one-forms while\n\nfor two-forms. Because their determinants are the same in both and , the signs of the Minkowski space two-form duals depend only on the chosen orientation.\n\nAn easy rule to remember for the above Hodge operations is that given a form formula_54, its Hodge dual formula_77 may be obtained by writing the components not involved in formula_54 in an order such that formula_79. An extra minus sign will enter only if formula_54 does not contain formula_81. (The latter convention stems from the choice for the metric signature. For , one puts a minus sign only if formula_54 involves formula_81.)\n\nThe Hodge star induces an inner product on the space of -vectors, that is, on the exterior algebra of . Given two -vectors and , one has\n\nwhere is the normalised -form (i.e. ). In the calculus of exterior differential forms on a pseudo-Riemannian manifold of dimension , the normalised -form is called the volume form and can be written as\n\nwhere formula_86 is the matrix of components of the metric tensor on the manifold in the coordinate basis.\n\nIf an inner product is given on formula_87, then this equation can be regarded as an alternative definition of the Hodge star.\n\nThe ordered wedge products of k distinct orthonormal basis vectors of form an \"orthonormal\" basis on each subspace formula_88 of the exterior algebra of .\n\nApplying the Hodge star twice leaves a -vector unchanged, up to sign. Given a -vector in in an -dimensional space , one has\n\nwhere is related to the signature of the inner product on . Specifically, is the sign of the determinant of the matrix representation of the inner product tensor with respect to any basis. Thus, for example, if and the signature of the inner product is either or then . For Riemannian manifolds (including Euclidean spaces), the signature is always positive, and so .\n\nNote that the above identity implies that the inverse of can be given as\n\nNote that if is odd then is even for any , whereas if is even then has the parity of . Therefore:\n\nwhere is the degree of the element operated on.\n\nApplying the construction above to each cotangent space of an -dimensional oriented Riemannian or pseudo-Riemannian manifold, we can obtain an object known as the Hodge dual of a -form. To be explicit –\n\nFor any -form we define as the unique -form satisfying\n\nfor every -form (here the inner product on forms and the volume form are induced by the Riemannian metric tensor in the usual way; greater understanding of these objects can be found by learning about the inner product on -forms and the volume form).\n\nThe Hodge star is thus related to the inner product on -forms by the formula:\n\nfor -forms and . (Note that we can also see this as an inner product on sections of formula_94. The set of sections is frequently denoted as formula_95. Each element of formula_96 is a -form.)\n\nMore generally, in the non-oriented case, one can define the Hodge star of a -form as a -pseudo differential form; that is, a differential form with values in the canonical line bundle.\n\nThe most important application of the Hodge star on manifolds is to define the codifferential on -forms. Let\n\nwhere is the exterior derivative or differential, and for Riemannian manifolds.\n\nwhile\n\nThe codifferential is not an antiderivation on the exterior algebra, in contrast to the exterior derivative.\n\nThe codifferential is the adjoint of the exterior derivative, in that\n\nwhere is a -form and a -form. This identity follows from Stokes' theorem for smooth forms, when\n\ni.e. when has empty boundary or when or has zero boundary values (of course, true adjointness follows after continuous continuation to the appropriate topological vector spaces as closures of the spaces of smooth forms).\n\nNotice that since the differential satisfies , the codifferential has the corresponding property\n\nThe Laplace–deRham operator is given by\n\nand lies at the heart of Hodge theory. It is symmetric:\n\nand non-negative:\n\nThe Hodge star sends harmonic forms to harmonic forms. As a consequence of the Hodge theory, the de Rham cohomology is naturally isomorphic to the space of harmonic -forms, and so the Hodge star induces an isomorphism of cohomology groups\n\nwhich in turn gives canonical identifications via Poincaré duality of with its dual space.\n\nThe combination of the operator and the exterior derivative generates the classical operators , , and , in three-dimensional Euclidean space. This works out as follows: can take a 0-form (function) to a 1-form, a 1-form to a 2-form, and a 2-form to a 3-form (applied to a 3-form it just gives zero). For a 0-form, formula_107, the first case written out in components is identifiable as the grad operator:\n\nThe second case followed by is an operator on 1-forms (formula_109) that in components is the curl operator:\n\nApplying the Hodge star gives:\n\nThe final case prefaced and followed by , takes a 1-form (formula_109) to a 0-form (function); written out in components it is the divergence operator:\n\nOne advantage of this expression is that the identity , which is true in all cases, sums up two others, namely that and . In particular, Maxwell's equations take on a particularly simple and elegant form, when expressed in terms of the exterior derivative and the Hodge star.\n\nOne can also obtain the Laplacian. Using the information above and the fact that then for a 0-form, formula_107:\n\n"}
{"id": "293383", "url": "https://en.wikipedia.org/wiki?curid=293383", "title": "Huayan", "text": "Huayan\n\nThe Huayan or Flower Garland school of Buddhism (, from ) is a tradition of Mahayana Buddhist philosophy that first flourished in China during the Tang dynasty. The Huayen worldview is based primarily on the \"Avatamsaka Sutra\" (). The name \"Flower Garland\" is meant to suggest the crowning glory of a Buddha's profound understanding of ultimate reality.\n\nThe Huayan School is known as Hwaeom in Korea and Kegon in Japan. This tradition also had a strong influence on Chan Buddhism.\n\nThe earliest texts associated with the Avatamsaka sutra are the \"Dousha jing\" (Taisho 280), produced by Lokaksema in the latter part of the second century CE and the \"Pusa benye jing\" (T. 281), translated by Zhi Qian in the early to mid third century. There is evidence that these small Buddhavatamsaka sutras circulated on their own as individual scriptures. \n\nThe translation of the large Avatamsaka sutra is often dated to the Southern Dynasties (420-589) when a translation team led by Gandharan master, Buddhabhadra worked on the sutra. There is also evidence of this sutra tradition in the Northern Dynasties (386-581) where a certain Xuangao (402-444) taught the \"Huayan samadhi\". \n\nThe founding of the school is traditionally attributed to a series of five \"patriarchs\" who were instrumental in developing the schools' doctrines. These five are:\n\nThe five monks later honored as Huayan patriarchs were erudite scholar-practitioners who connected Buddhism with Chinese traditional culture closely, creating a Buddhist historical trend in developing multiple facets while the tradition’s essence remained the same. Based on their writings, exegeses, and oral teachings, these men each played a significant and distinct role in the development of the school, although there are certain aspects of this patriarchal scheme which are clearly contrived. For example, Chengguan was born 26 years after Fazang's death. According to Robert Gimello's dissertation on Chih-Yen (1976), \"most if not all of the major themes of Huayen thought\" can be found in the works of the second patriarch Chih-yen, particularly the classification of scriptures and theories on the Dharmadhatu. Thus he names the patriarch Chih-yen (602-668) as the crucial figure in the foundation of Huayan. The tradition reached the height of its influence under Fazang, who was the Buddhist teacher of the Empress Wu Zetian (684–705).\n\nAnother important figure in the development and popularization of Huayan thought was the lay scholar Li Tongxuan (, 635?-730), the author of the \"Huáyán lùn\" (), a popular and lengthy commentary on the Avatamsaka sutra. Fazang's disciple Huiyuan (673-743) also wrote a commentary on the Avatamsaka. \n\nSome accounts of the school also like to extend its patriarch-ship earlier to and Nāgārjuna.\n\nAfter the time of Zongmi and Li Tongxuan the Chinese school of Huayan generally stagnated in terms of new development, and then eventually began to decline. The school, which had been dependent upon the support it received from the government, suffered severely during the Buddhist purge of 841-845, initiated by Emperor Wuzong of Tang, never to recover its former strength. Nonetheless, its profound metaphysics, such as that of the Four Dharmadhātu () of interpenetration, had a deep impact on surviving East Asian schools.\n\nThe Huayan school's worldview was based primarily on the content of what it considered to be the supreme Buddhist revelation, the \"Avataṃsaka Sūtra\". The \"Avataṃsaka Sūtra\" is a compilation of sutras of various length. The earliest of these texts, the \"Ten Stages Sutra\", maybe dates from the first century CE. The Daśabhūmika Sūtra describes the ten stages on the Bodhisattva-path. The various sutras were probably joined together shortly before its translation into Chinese, at the beginning of the 5th century CE.\n\nThe \"Avataṃsaka Sūtra\" integrates the teachings on śūnyatā and Yogacara thinking.\n\nThe basic idea of the \"Avataṃsaka Sūtra\" is the unity of the absolute and the relative:\nEach part of the world reflects the totality of the cosmos:\n\nAll levels of reality are related and interpenetrated. This is depicted in the image of Indra's net. This \"unity in totality allows every individual entity of the phenomenal world its uniqueness without attributing an inherent nature to anything\".\n\nOther Mahayana texts such as the \"Awakening of Faith in the Mahayana\" (\"Dasheng Qixin Lun\" 大乘起信論), which was a condensation of Chinese thought on awakening and ultimate reality, influenced Huayan masters like Fazang and Zongmi, who both wrote commentaries on the text. The Lotus sutra was also seen as an important text in this school, though not as important as the Avatamsaka. The Sutra of Perfect Enlightenment was particularly important for Zongmi.\n\nThe Huayen patriarchs wrote numerous commentaries and original treatises on the Mahayana sutras and Huayen philosophy. Fazang for example, wrote commentaries on the Avatamsaka, the Lankavatara Sutra and the Awakening of Faith. \n\nOne of the key Huayen treatises is \"On the Meditation of the Dharmadhātu\" attributed to the first patriarch Dushun.\n\nAnother is Fazang’s \"Treatise on the Golden Lion\" which is said to have been written to explain Huayen's view of interpenetration to Empress Wu.\n\nHuayan thought is mainly focused on explaining the nature of the Dharmadhatu, the world as it is ultimately, from the point of view of a fully awakened being. It is often said to be the philosophical articulation of Chan meditation. It it influenced by the Avatamsaka and Buddha nature literature as well as by the Chinese Yogacara and Madhyamaka schools. Patriarchs of the school such as Zongmi were also influenced by Chinese philosophy, particularly the classics of Taoism.\n\nA key doctrine of Huayan is the mutual containment and interpenetration of all phenomena (\"dharmas\") or \"perfect interfusion\" (\"yuanrong\", 圓融). This is associated with what the Huayan sees as its unique contribution, the \"dharmadhatu pratityasamutpada\". This is described by Wei Daoru as the idea that \"countless dharmas (all phenomena in the world) are representations of the wisdom of Buddha without exception\" and that \"they exist in a state of mutual dependence, interfusion and balance without any contradiction or conflict. This thought essentially argues that there is no relationship of cause and result among phenomena and that things are not formed sequentially. Instead, they constitute the world by the mutual interfusion of complete equality.\" \n\nAccording to this theory, any phenomenon exists only as part of the total nexus of reality, its existence depends on the total network of all other things, which are all equally connected to each other and contained in each other. \nThe Huayan patriarchs used various metaphors to express this, such as Indra's net, a hall of mirrors and the world text. To illustrate the doctrine to Empress Wu, the patriarch Fazang:\n\n\"called for a candle and placed it surrounded by mirrors on every side. When lit, the candle was reflected in each mirror, and each of the reflections in every other mirror so that in any one mirror were the images of all the others.\" \n\nThis Buddhist doctrine also includes the views that:\n\nAnother important distinction used by Huayan patriarchs is that of \"li\" and \"shi\", noumenon and phenomenon which was explained using the metaphor of gold and lions, or water and waves. According to Paul Williams:\n\nFirst, noumenon and phenomena mutually interpenetrate and are (in a sense) identical. There is no opposition between the two. The one does not cancel out the other. Second, Fazang explains elsewhere that since all things arise interdependently (following Madhyamika), and since the links of interdependence expand throughout the entire universe and at all time (past, present, and future depend upon each other, which is to say the total dharmadhatu arises simultaneously), so in the totality of interdependence, the dharmadhatu, all phenomena are mutually interpenetrating and identical. \n\nThe theory of the Fourfold Dharmadhatu (\"sifajie\", 四法界) is explained in the \"Meditative Perspectives on the Huayan Dharmadhatu\" (\"Huayan Fajie Guanmen\", 華嚴法界觀門) and its commentaries. This theory is the central meditative framework for the Huayan tradition. Another key text is the \"Cessation and Contemplation in the Five Teachings of Huayan\" (\"Huayan wujiao zhiguan\" 華嚴五教止觀). The Dharmadhatu is the goal of the bodhisattva's practice, the ultimate nature of reality which must be known or entered into (\"ru\", 入). According to Fox, the Fourfold Dharmadhatu is \"four cognitive approaches to the world, four ways of apprehending reality\".The four ways of seeing reality are: \n\n\nThe three levels of Huayan meditation on the Dharmadhatu correspond to the last three views of the Dharmadhatu are:\n\n\nAccording to Fox, \"these dharmadhatus are not separate worlds – they are actually increasingly more holographic perspectives on a single phenomenological manifold...they more properly represent four types or orders of perspectives on experience.\" Furthermore for Huayan this practice is the solution to the problem of samsara which lies in the \"fixation or attachment to a particular perspective. What we think are the essences of objects are really therefore nothing but mere names, mere functional designations, and none of these contextual definitions need necessarily interfere with any of the others.\"\n\nAccording to Paul Williams, the reading and recitation of the Avatamsaka sutra was also a central practice for the tradition, for monks and laity.\n\nAnother practice which is highlighted in the Avatamsaka sutra is that of Buddhānusmṛti or \"nianfo\"- mindfulness of the Buddha. \n\nThe tradition also mentions two key samadhis, the ocean-seal samadhi (Ch. \"haiyin sanmei\") and the huayan samadhi (\"huayan sanmei\"). \n\nLayman Li Tongxuan developed a unique meditative practice based on the 9th chapter of the Avatamsaka sutra. The practice, named 'the contemplation of Buddhalight' (\"joguang guan\"), focused on tracing the universal light which is radiated by the Buddha in one's mind and expanding it further outwards. \nHuayan favored the teaching of sudden enlightenment. This is because the Buddha nature is already present in all sentient beings and also because their theory of interpenetration entails that Buddhahood is already present at the first stage of a Bodhisattva's path. According to Li Tongxuan:\n\n[T]he first access of faith in the mind of the practitioner is in itself the culmination of the entire path, the very realization of final Buddhahood... ‘Faith’ or confidence in the possibility of enlightenment is nothing but enlightenment itself, in an \"anticipatory and causative modality\".\n\nBuddhahood was seen as beyond language and stages of practice. Because practices cannot create something that is already not imminent, they were seen as simply revealing what was already there. The patriarch Zongmi formulated his own theory of awakening which was \"immediate awakening followed by gradual cultivation\" and the view that \"immediate and gradual are not only not contradictory, but are actually complementary\".\n\nHuayan makes extensive use of paradox in argument and literary imagery. All three types of paradox originate in the tension between conventional and absolute truth. Huayan uses three types of paradox:\n1. Emphasizing the concept of śūnyatā, first is asserted that a phenomenon X is empty, which implies that X is not X. An example from Fazang is the assertion:\n2. Reversing the first paradox by asserting that any empty phenomenon is an expression of the absolute non-duality between emptiness and form, or the identity between conditioned, relative reality and the ultimate truth of tathatā. \nThis paradox is derived from two doctrinal sources: \nFazang's paradoxical assertion illustrates this second type:\n\n3. The third variation of paradox is grounded in the Hua-yen doctrine of the \"nonobstruction of all phenomena\" (shih shih wu-ai(k)). Each phenomenon is perceived as interpenetrating with and containing all others. This paradoxical violation of the conventional order of time and space is exemplified by Fa-tsang's famous \"Essay on the Golden Lion\":\n\nBuddhism was introduced into China in bits and pieces. When the knowledge of Buddhism grew larger, various schools attempted to get a grip on the Buddhist tradition by developing classifications of teachings, such as the Five Periods and Eight Teachings of the Tiantai-school.\n\nThe Hua-yen school developed a fivefold classification:\n\nHuayan and Chán had doctrinal arguments regarding which would be the correct concept of sudden awakening. The teachings of the Chán-school were regarded as inferior by the Hua-yen teachers. The Chán-school polemitized against this classification, by devising its own rhetorics in defense.\n\nThe doctrines of the Huayan school ended up having profound impact on the philosophical attitudes of East Asian Buddhism. According to Wei Daoru their theory of perfect interfusion was \"gradually accepted by all Buddhist traditions and it eventually permeated all aspects of Chinese Buddhism.\" \n\nChinese Chán was profoundly influenced by it, though Chán also defined itself by distinguishing itself from Huayan. Tsung-mi, the Fifth Patriarch of the Hua-yen school, also occupies a prominent position in the history of Chán. During the Song, the Hua-yen metaphysics were completely assimilated by the Chán-school.\n\n\n"}
{"id": "1682086", "url": "https://en.wikipedia.org/wiki?curid=1682086", "title": "Hund's rules", "text": "Hund's rules\n\nIn atomic physics, Hund's rules refers to a set of rules that German physicist Friedrich Hund formulated around 1927, which are used to determine the term symbol that corresponds to the ground state of a multi-electron atom. The first rule is especially important in chemistry, where it is often referred to simply as Hund's Rule.\n\nThe three rules are:\n\nThese rules specify in a simple way how usual energy interactions determine which term includes the ground state. The rules assume that the repulsion between the outer electrons is much greater than the spin–orbit interaction, which is in turn stronger than any other remaining interactions. This is referred to as the LS coupling regime.\n\nFull shells and subshells do not contribute to the quantum numbers for total , the total spin angular momentum and for , the total orbital angular momentum. It can be shown that for full orbitals and suborbitals both the residual electrostatic energy (repulsion between electrons) and the spin–orbit interaction can only shift all the energy levels together. Thus when determining the ordering of energy levels in general only the outer valence electrons must be considered.\n\nDue to the Pauli exclusion principle, two electrons cannot share the same set of quantum numbers within the same system; therefore, there is room for only two electrons in each spatial orbital. One of these electrons must have, (for some chosen direction \"z\") \"m\" = ½, and the other must have \"m\" = −½. Hund's first rule states that the lowest energy atomic state is the one that maximizes the total spin quantum number for the electrons in the open subshell. The orbitals of the subshell are each occupied singly with electrons of parallel spin before double occupation occurs. (This is occasionally called the \"bus seat rule\" since it is analogous to the behaviour of bus passengers who tend to occupy all double seats singly before double occupation occurs.)\n\nTwo different physical explanations have been given for the increased stability of high multiplicity states. In the early days of quantum mechanics, it was proposed that electrons in different orbitals are further apart, so that electron–electron repulsion energy is reduced. However, accurate quantum-mechanical calculations (starting in the 1970s) have shown that the reason is that the electrons in singly occupied orbitals are less effectively screened or shielded from the nucleus, so that such orbitals contract and electron–nucleus attraction energy becomes greater in magnitude (or decreases algebraically).\n\nAs an example, consider the ground state of silicon. The electronic configuration of Si is (see spectroscopic notation). We need to consider only the outer 3p electrons, for which it can be shown (see term symbols) that the possible terms allowed by the Pauli exclusion principle are \"D\" , \"P\" , and \"S\". Hund's first rule now states that the ground state term is \"P\" (triplet P), which has \"S\" = 1. The superscript 3 is the value of the multiplicity = 2\"S\" + 1 = 3. The diagram shows the state of this term with \"M\" = 1 and \"M\" = 1.\n\nThis rule deals with reducing the repulsion between electrons. It can be understood from the classical picture that if all electrons are orbiting in the same direction (higher orbital angular momentum) they meet less often than if some of them orbit in opposite directions. In the latter case the repulsive force increases, which separates electrons. This adds potential energy to them, so their energy level is higher.\n\nFor silicon there is only one triplet term, so the second rule is not required. The lightest atom that requires the second rule to determine the ground state term is titanium (Ti,  = 22) with electron configuration . In this case the open shell is and the allowed terms include three singlets (S, D, and G) and two triplets (P and F). (Here the symbols S, P, D, F, and G indicate that the total orbital angular momentum quantum number has values 0, 1, 2, 3 and 4, respectively, analogous to the nomenclature for naming atomic orbitals.)\n\nWe deduce from Hund's first rule that the ground state term is one of the two triplets, and from Hund's second rule that this term is F (with formula_8) rather than P (with formula_9). There is no G term since its formula_10 state would require two electrons each with formula_11, in violation of the Pauli principle. (Here formula_12 and formula_13 are the components of the total orbital angular momentum L and total spin S along the z-axis chosen as the direction of an external magnetic field.)\n\nThis rule considers the energy shifts due to spin–orbit coupling. In the case where the spin–orbit coupling is weak compared to the residual electrostatic interaction, formula_4 and formula_3 are still good quantum numbers and the splitting is given by:\n\nformula_16\n\nThe value of formula_17 changes from plus to minus for shells greater than half full. This term gives the dependence of the ground state energy on the magnitude of formula_5.\n\nThe formula_19 lowest energy term of Si consists of three levels, formula_20. With only two of six possible electrons in the shell, it is less than half-full and thus formula_21 is the ground state.\n\nFor sulfur (S) the lowest energy term is again formula_22 with spin–orbit levels formula_20, but now there are four of six possible electrons in the shell so the ground state is formula_24.\n\nIf the shell is half-filled then formula_25, and hence there is only one value of formula_5 (equal to formula_3), which is the lowest energy state. For example, in phosphorus the lowest energy state has formula_28 for three unpaired electrons in three 3p orbitals. Therefore, formula_29 and the ground state is S.\n\nHund's rules work best for the determination of the ground state of an atom or molecule.\n\nThey are also fairly reliable (with occasional failures) for the determination of the lowest state of a given excited electronic configuration. Thus, in the helium atom, Hund's first rule correctly predicts that the 1s2s triplet state (S) is lower than the 1s2s singlet (S). Similarly for organic molecules, the same rule predicts that the first triplet state (denoted by T in photochemistry) is lower than the first excited singlet state (S), which is generally correct.\n\nHowever Hund's rules should not be used to order states other than the lowest for a given configuration. For example, the titanium atom ground state configuration is ...3d for which a naïve application of Hund's rules would suggest the ordering F < P < G < D < S. In reality, however, D lies below G.\n\n"}
{"id": "15566987", "url": "https://en.wikipedia.org/wiki?curid=15566987", "title": "Industrial metabolism", "text": "Industrial metabolism\n\nIndustrial metabolism is a concept to describe the material and energy turnover of industrial systems. It was proposed by Robert Ayres in analogy to the biological metabolism as \"the whole integrated collection of physical processes that convert raw materials and energy, plus labour, into finished products and wastes...\" In analogy to the biological concept of metabolism, which is used to describe the whole of chemical reactions in, for example, a cell to maintain its functions and reproduce itself, the concept of industrial metabolism describes the chemical reactions, transport processes, and manufacturing activities in industry. Industrial metabolism presupposes a connection between different industrial activities by seeing them as part of a larger system, such as a material cycle or the supply chain of a commodity. System scientists, for example in industrial ecology, use the concept as paradigm to study the flow of materials or energy through the industrial system in order to better understand supply chains, the sources and causes of emissions, and the linkages between the industrial and the wider socio-technological system. \n\nIndustrial metabolism is a subsystem of the anthropogenic or socioeconomic metabolism, which also comprises non-industrial human activities in households or the public sector. \n\n\n"}
{"id": "2585344", "url": "https://en.wikipedia.org/wiki?curid=2585344", "title": "International Day of the Disappeared", "text": "International Day of the Disappeared\n\nThe International Day of the Disappeared, on August 30 of each year, is a day created to draw attention to the fate of individuals imprisoned at places and under poor conditions unknown to their relatives and/or legal representatives. The impulse for the day came from the Latin American Federation of Associations for Relatives of Detained-Disappeared \"(Federación Latinoamericana de Asociaciones de Familiares de Detenidos-Desaparecidos,\" or FEDEFAM), a non-governmental organization founded in 1981 in Costa Rica as an association of local and regional groups actively working against secret imprisonment, forced disappearances and abduction in a number of Latin-American countries.\n\nWork on secret imprisonment is an important part of the activities for a number of international bodies and organizations in the fields of human rights activism and humanitarian aid, including for example Amnesty International (AI), the Office of the United Nations High Commissioner for Human Rights (OHCHR) and the International Committee of the Red Cross (ICRC). The International Day of the Disappeared is an opportunity to highlight these institutions' work, increase public awareness, and to call for donations and volunteers.\n\nOf those agencies, the ICRC has additional privileges due to its special status as a non-governmental sovereign entity and its strict policy of neutrality. In some cases, the ICRC is the only institution granted access to specific groups of prisoners, thereby enabling a minimum level of contact and inspection of their treatment. For affected families, messages transmitted by the ICRC are often the only hint about the fate of these prisoners.\n\nVisiting those detained in relation to conflicts and enabling them to restore and maintain contact with their families, is a very important part of the ICRC's mandate. But the definition of the Missing or the Disappeared goes far beyond the victims of enforced disappearance. It includes all those whose families have lost contact as the result of conflicts, natural disasters or other tragedies. \n\nThese missing may be detained, stranded in foreign countries, hospitalized or dead. Through its tracing services and working with the 189 national Red Cross and Red Crescent Societies around the world, the ICRC seeks to obtain information about their fate on behalf of their families. It reminds governments and other groups of their obligations to respect the families' right to know the fate of their loved ones. It also works with families of the missing to help them address their particular psychological, social legal and financial needs.\n\nImprisonment under secret or uncertain circumstances is a grave violation of some conceptions of human rights as well as, in the case of an armed conflict, of International Humanitarian Law. The General Assembly of the United Nations adopted a Declaration on the Protection of all Persons from Enforced Disappearance as resolution 47/133 on December 18, 1992. It is estimated that secret imprisonment is practiced in about 30 countries. The OHCHR Working Group on Enforced or Involuntary Disappearances has registered about 46,000 cases of people who disappeared under unknown circumstances.\n\nOn August 30, 2007, hundreds of Philippine relatives and supporters of desaparecidos, mostly activists, missing after being abducted or killed by Philippine security forces protested against the government to mark International Day of the Disappeared. Edita Burgos remembered her missing son, Jonas, a member of the Peasants' Movement of the Philippines.\n\nOn August 30, 2008 the International Coalition against Enforced Disappearances, which gathers family member organizations and human rights organizations from around the world, joined hands for a global campaign event to promote the ratification of the International Convention for the Protection of All Persons from Enforced Disappearance.\n\n"}
{"id": "33513636", "url": "https://en.wikipedia.org/wiki?curid=33513636", "title": "Jocasta complex", "text": "Jocasta complex\n\nIn psychoanalytic theory, the Jocasta complex is the incestuous sexual desire of a mother towards her son.\n\nRaymond de Saussure introduced the term in 1920 by way of analogy to its logical converse in psychoanalysis, the Oedipus complex, and it may be used to cover different degrees of attachment, including domineering but asexual mother love – something perhaps particularly prevalent with an absent father.\n\nThe Jocasta complex is named for Jocasta, a Greek queen who unwittingly married her son, Oedipus. The Jocasta complex is similar to the Oedipus complex, in which a child has sexual desire towards their parent(s). The term is a bit of an extrapolation, since in the original story Oedipus and Jocasta were unaware that they were mother and son when they married. The usage in modern contexts involves a son with full knowledge of who his mother is.\n\nTheodor Reik saw the \"Jocasta mother\", with an unfulfilled adult relationship of her own and an over-concern for her child instead, as a prime source of neurosis.\n\nGeorge Devereux went further, arguing that the child's Oedipal complex was itself triggered by a pre-existing parental complex (Jocasta/Laius).\n\nEric Berne also explored the other (parental) side of the Oedipus complex, pointing to related family dramas such as \"mother sleeping with daughter's boyfriend ... when mother has no son to play Jocasta with\".\n\n\n"}
{"id": "10104622", "url": "https://en.wikipedia.org/wiki?curid=10104622", "title": "Kuratowski's closure-complement problem", "text": "Kuratowski's closure-complement problem\n\nIn point-set topology, Kuratowski's closure-complement problem asks for the largest number of distinct sets obtainable by repeatedly applying the set operations of closure and complement to a given starting subset of a topological space. The answer is 14. This result was first published by Kazimierz Kuratowski in 1922. The problem gained wide exposure three decades later as an exercise in John L. Kelley's classic textbook \"General Topology\".\n\nLetting \"S\" denote an arbitrary subset of a topological space, write \"kS\" for the closure of \"S\", and \"cS\" for the complement of \"S\". The following three identities imply that no more than 14 distinct sets are obtainable:\n\nThe first two are trivial. The third follows from the identity \"kikiS\" = \"kiS\" where \"iS\" is the interior of \"S\" which is equal to the complement of the closure of the complement of \"S\", \"iS\" = \"ckcS\". (The operation \"ki\" = \"kckc\" is idempotent.)\n\nA subset realizing the maximum of 14 is called a 14-set. The space of real numbers under the usual topology contains 14-sets. Here is one example:\nwhere formula_2 denotes an open interval and formula_3 denotes a closed interval.\n\nDespite its origin within the context of a topological space, Kuratowski's closure-complement problem is actually more algebraic than topological. A surprising abundance of closely related problems and results have appeared since 1960, many of which have little or nothing to do with point-set topology.\n\nThe closure-complement operations yield a monoid which can be used to classify topological spaces.\n\n"}
{"id": "23280456", "url": "https://en.wikipedia.org/wiki?curid=23280456", "title": "Lamination (topology)", "text": "Lamination (topology)\n\nIn topology, a branch of mathematics, a lamination is a :\n\nA lamination of a surface is a partition of a closed subset of the surface into smooth curves.\n\nIt may or may not be possible to fill the gaps in a lamination to make a foliation.\n\n\n\n"}
{"id": "875547", "url": "https://en.wikipedia.org/wiki?curid=875547", "title": "Marital rape", "text": "Marital rape\n\nMarital rape or spousal rape is the act of sexual intercourse with one's spouse without the spouse's consent. The lack of consent is the essential element and need not involve violence. Marital rape is considered a form of domestic violence and sexual abuse. Although, historically, sexual intercourse within marriage was regarded as a right of spouses, engaging in the act without the spouse's consent is now widely recognized by law and society as a wrong and as a crime. It is recognized as rape by many societies around the world, repudiated by international conventions, and increasingly criminalized.\n\nThe issues of sexual and domestic violence within marriage and the family unit, and more specifically, the issue of violence against women, have come to growing international attention from the second half of the 20th century. Still, in many countries, marital rape either remains outside the criminal law, or is illegal but widely tolerated. Laws are rarely being enforced, due to factors ranging from reluctance of authorities to pursue the crime, to lack of public knowledge that sexual intercourse in marriage without consent is illegal.\n\nMarital rape is more widely experienced by women, though not exclusively. Marital rape is often a chronic form of violence for the victim which takes place within abusive relations. It exists in a complex web of state governments, cultural practices, and societal ideologies which combine to influence each distinct instance and situation in varying ways. The reluctance to criminalize and prosecute marital rape has been attributed to traditional views of marriage, interpretations of religious doctrines, ideas about male and female sexuality, and to cultural expectations of subordination of a wife to her husband—views which continue to be common in many parts of the world. These views of marriage and sexuality started to be challenged in most Western countries from the 1960s and 70s especially by second-wave feminism, leading to an acknowledgment of the woman's right to self-determination (i.e., control) of all matters relating to her body, and the withdrawal of the exemption or defense of marital rape.\n\nMost countries criminalized marital rape from the late 20th century onward—very few legal systems allowed for the prosecution of rape within marriage before the 1970s. Criminalization has occurred through various ways, including removal of statutory exemptions from the definitions of rape, judicial decisions, explicit legislative reference in statutory law preventing the use of marriage as a defense, or creating of a specific offense of marital rape. In many countries, it is still unclear whether marital rape is covered by the ordinary rape laws, but in some it may be covered by general statutes prohibiting violence, such as assault and battery laws.\n\nOne of the origins of the concept of a marital exemption from rape laws (a rule that a husband cannot be charged with the rape of his wife) is the idea that by marriage a woman gives irrevocable consent for her husband to have sex with her any time he demands it. This view was described by Sir Matthew Hale (1609–1676) in \"History of the Pleas of the Crown\", published posthumously in 1736, where he wrote that \"The husband cannot be guilty of a rape committed by himself upon his lawful wife, for by their mutual consent and contract the wife hath given up herself in this kind unto her husband, which she cannot retract\". Also, American and English law subscribed until the 20th century to the system of coverture, that is, a legal doctrine under which, upon marriage, a woman's legal rights were subsumed by those of her husband. The implication was that once unified by marriage, a spouse could no longer be charged with raping one's spouse, anymore than be charged with raping oneself. In the US, the wife's legal subordination to her husband was fully ended by the case of \"Kirchberg v. Feenstra\", , a United States Supreme Court case in which the Court held a Louisiana Head and Master law, which gave sole control of marital property to the husband, unconstitutional. English common law also had a great impact on many legal systems of the world through colonialism. (Bovarnik, 2007).\n\nMarriage was traditionally understood as an institution where a husband had control over his wife's life; control over her sexuality was only a part of the greater control that he had in all other areas concerning her. A husband's control over his wife's body could also be seen in the way adultery between a wife and another man was constructed; for example in 1707, English Lord Chief Justice John Holt described the act of a man having sexual relations with another man's wife as \"the highest invasion of property\". For this reason, in many cultures there was a conflation between the crimes of rape and adultery, since both were seen and understood as a violation of the rights of the husband. Rape as a crime was constructed as a property crime against a father or husband not as a crime against the woman's right to self-determination.\n\nThe property to be withheld in a female was her virginity; this was the commodity (Bergen, 2016). Following this line of logic, a woman was (and still is in many cultures across the globe) first the property of her father, then, upon marriage, the property of her husband (Bergen, 2016). Therefore, a man could not be prosecuted for raping his own wife because she was his possession (Schelong, 1994). However, if another man raped someone's wife, this was essentially stealing property (a women's sexuality) (Bergen, 2016). In English customs, \"bride capture\" (a man claiming a woman through rape) was thought to be stealing a father's property by raping his daughter. Therefore, rape laws were created to \"…protect the property interests men had in their women, not to protect women themselves\" (Schelong, 1994). This concept of women as property permeates current marital rape ideology and laws throughout the globe.\n\nIn some cultures, marriage is arranged for the purpose of creating access to procreation (Yllö, 2016). In these situations, the parties do not necessarily consent to marriage (in the case of forced marriage) (Yllö, 2016). Following this logic, if consent is not part of marriage, then it is not necessary for intercourse. The autonomy of the wife is also often compromised in cultures where bride price is paid. Under customary law in certain parts of Africa, forced sex in marriage was not prohibited, although some specific circumstances, such as during advanced pregnancy, immediately after childbirth, during menstruation, or during mourning for a deceased close relative, were recognized as giving the wife the right to refuse sex.\n\nRape has been, until recent decades, understood as a crime against honor and reputation – not only in domestic legislation, but also in international law; for example according to the Article 27 of the Fourth Geneva Convention, \"Women shall be especially protected against any attack on their honour, in particular against rape, enforced prostitution, or any form of indecent assault\". It was not until the 1990s that the ICC statute recognized crimes of sexual violence as violent crimes against the person; \"Not until the last half century was rape understood to be an offense against the woman, against her dignity, instead of against her family's or her husband's honor\".\n\nHistorically, many cultures have had a concept of spouses' conjugal rights to sexual intercourse with each other. This can be seen in English common law, in force in North America and the British Commonwealth, where the very concept of marital rape was treated as an impossibility. This was illustrated most vividly by Sir Matthew Hale, (1609-1676), in his legal treatise \"Historia Placitorum Coronæ\" or \"History of the Pleas of the Crown\" (posthumously, 1736) where he wrote that \"The husband cannot be guilty of a rape committed by himself upon his lawful wife, for by their mutual consent and contract the wife hath given up herself in this kind unto her husband, which she cannot retract.\"\n\nSir Matthew Hale's statement in \"History of the Pleas of the Crown\" did not cite any legal precedent though it likely relied on earlier standards. In a case of Lord Audley's (1488–1544), for instance, his citation of the jurist Bracton (c. 1210 – c. 1268) supports this rule, said to have derived from laws of King Æthelstan (r. 927–939) where upon the law holds that even \"were the party of no chaste life, but a whore, yet there may be ravishment: but it is a good plea to say she was his concubine\". The lawfulness of the conjugal act itself was understood as a logical consequence of a lawful marriage. Marriage created conjugal rights between spouses, and marriage could not be annulled except by a private Act of Parliament—it therefore follows that a spouse could not revoke conjugal rights from the marriage, and therefore there could be no rape between spouses. The principle was repeated in East's \"Treatise of the Pleas of the Crown\" in 1803 and in Archbold's \"Pleading and Evidence in Criminal Cases\" in 1822. The principle was framed as an exemption to the law of rape in an English courtroom in \"R v Clarence\", but it was not overturned until 1991 by the House of Lords in the case of \"R. v. R\" in 1991, where it was described as an anachronistic and offensive legal fiction.\n\nFrom the beginnings of the 19th century feminist movement, activists challenged the presumed right of men to engage in forced or coerced sex with their wives. In the United States, \"the nineteenth-century woman's rights movement fought against a husband's right to control marital intercourse in a campaign that was remarkably developed, prolific, and insistent, given nineteenth-century taboos against the public mention of sex or sexuality.\" Suffragists including Elizabeth Cady Stanton and Lucy Stone \"singled out a woman's right to control marital intercourse as the core component of equality.\"\n\nNineteenth century feminist demands centered on the right of women to control their bodies and fertility, positioned consent in marital sexual relations as an alternative to contraception and abortion (which many opposed), and also embraced eugenic concerns about excessive procreation. British liberal feminists John Stuart Mill and Harriet Taylor attacked marital rape as a gross double-standard in law and as central to the subordination of women.\n\nAdvocates of the Free Love Movement, including early anarcha-feminists such as Voltairine de Cleyre and Emma Goldman, as well as Victoria Woodhull, Thomas Low Nichols, and Mary S. Gove Nichols, joined a critique of marital rape to advocate women's autonomy and sexual pleasure. Moses Harman, a Kansas-based publisher and advocate for women's rights, was jailed twice under the Comstock laws for publishing articles (by a woman who was victimized and a doctor who treated marital rape survivors) decrying marital rape. De Cleyre defended Harman in a well-known article, \"Sexual Slavery.\" She refused to draw any distinction between rape outside of and within marriage: \"And that is rape, where a man forces himself sexually upon a woman whether he is licensed by the marriage law to do it or not.\"\n\nBertrand Russell (who was awarded the 1950 Nobel Prize in Literature) in his book \"Marriage and Morals\" (1929) deplored the situation of married women. He wrote \"Marriage is for woman the commonest mode of livelihood, and the total amount of undesired sex endured by women is probably greater in marriage than in prostitution.\"\n\nThe marital rape exemption or defence became more widely viewed as inconsistent with the developing concepts of human rights and equality. Feminists worked systematically since the 1960s to overturn the marital rape exemption and criminalize marital rape. Increasing criminalization of spousal rape is part of a worldwide reclassification of sexual crimes \"from offenses against morality, the family, good customs, honor, or chastity ... to offenses against liberty, self-determination, or physical integrity.\" In December 1993, the United Nations High Commissioner for Human Rights published the \"Declaration on the Elimination of Violence Against Women\". This establishes marital rape as a human rights violation.\n\nThe importance of the right to self sexual determination of women is increasingly being recognized as crucial to women's rights. In 2012, High Commissioner for Human Rights Navi Pillay stated that:\n\nDespite these trends and international moves, criminalization has not occurred in all UN member States. Determining the criminal status of marital rape may be challenging, because, while some countries \"explicitly criminalize\" the act (by stipulating in their rape laws that marriage is not a defense to a charge of rape; or by creating a specific crime of 'marital rape'; or, otherwise, by having statutory provisions that expressly state that a spouse can be charged with the rape of their other spouse) and other countries \"explicitly exempt\" spouses (by defining rape as forced sexual intercourse outside of marriage; or forced sexual intercourse with a woman not the perpetrator's wife; or by providing in their rape provisions that marriage is a defense to a charge of rape), in many countries the ordinary rape laws are silent on the issue (that is, they do not address the issue one way or another)—in such cases, in order to determine whether marital rape is covered by the ordinary rape laws it must be analyzed whether there are judicial decisions in this respect; and former definitions of the law are also important (for instance whether there was previously a statutory exemption that was removed by legislators for the purpose of implicitly including marital rape).\n\nIn 2006, the UN Secretary-General's in-depth study on all forms of violence against women stated that (page 113):\n\nIn 2011, the UN Women report Progress of the World's Women:In Pursuit of Justice stated that (page 17):\n\nTraditionally, rape was a criminal offense that could only be committed outside marriage, and courts did not apply the rape statutes to acts of forced sex between spouses. With changing social views, and international condemnation of sexual violence in marriage, courts have started to apply the rape laws in marriage. The current applicability in many countries of rape laws to spouses is currently unclear, since in many countries the laws have not been recently tested in court. In some countries, notably jurisdictions which have inherited the 1860 Indian Penal Code (such as Singapore, India, Bangladesh, Sri Lanka, Burma) and some countries in the Commonwealth Caribbean region, the laws explicitly exempt spouses from prosecution (for instance, under the 1860 Indian Penal Code, which has also been inherited by other countries in the region, the law on rape states that \"Sexual intercourse by a man with his own wife is not rape\").\n\nAn example of a country where the rape law \"explicitly excludes\" a husband as a possible perpetrator is Ethiopia; its rape law states: \"Article 620 - Rape: Whoever compels a woman to submit to sexual intercourse \"outside wedlock\", whether by the use of violence or grave intimidation, or after having rendered her unconscious or incapable of resistance, is punishable with rigorous imprisonment from five years to fifteen years\". Another example is South Sudan, where the law states: \"Sexual intercourse by a married couple is not rape, within the meaning of this section\". (Art 247). Conversely, an example of country where the rape law \"explicitly criminalizes\" marital rape is Namibia - The Combating of Rape Act (No. 8 of 2000) states that: \"No marriage or other relationship shall constitute a defence to a charge of rape under this Act\". An example of a jurisdiction where marital rape is a \"distinct\" criminal offense is Bhutan where 'Marital rape' is defined by Article 199 which reads: \"A defendant shall be guilty of marital rape, if the defendant engages in sexual intercourse with one's own spouse without consent or against the will of the other spouse\".\n\nBy 1986, in Europe, there was international pressure to criminalize marital rape: the \"European Parliament's Resolution on Violence Against Women of 1986\" called for its criminalization. This was reiterated by the Recommendation Rec(2002)5 of the Committee of Ministers to member states on the protection of women against violence. (see para 35) This recommendation provided detailed guidelines on how legislation regarding domestic violence, rape, and other forms of violence against women should operate. It also provided a definition of violence against women, and gave a list of non-exhaustive examples, including marital rape (see section \"Definition\" para 1). Although the approach on the issue of violence against women has varied significantly among European countries, the traditional view that acts of violence against a woman are crimes against honor and morality, and not against the self-determination of the woman, was still prevalent in the 1990s in many countries. The above recommendation stated that member states must \"ensure that criminal law provides that any act of violence against a person, in particular physical or sexual violence, constitutes a violation of that person's physical, psychological and/or sexual freedom and integrity, and not solely a violation of morality, honour or decency\" (para 34). The approach regarding sexual and other forms of violence against women in specific European countries did not necessarily mirror women's rights in other areas of life (such as public or political life) in those countries: in fact some countries otherwise known for advanced women's rights, such as Finland and Denmark, have received strong criticism for their policies in this area. A 2008 report produced by Amnesty International, described Danish laws on sexual violence as \"inconsistent with international human rights standards\", which has led to Denmark eventually reforming its sexual offenses legislation in 2013. (Until 2013, in Denmark \"the Penal Code reduce[d] the level of penalty or provide[d] for exclusion of punishment altogether for rape and sexual violence within marriage in certain instances [...] and if the perpetrator enter[ed] into or continu[ed] a marriage with his victim the punishment for rape c[ould] be reduced or remitted\"). Cultural and religious values which support female subordination and inequality are considered important in dealing with the issue of sexual violence against women; but there have been calls for analyses of cultural gender norms which tolerate violence against women to not be based on stereotypes; Mala Htun and Laurel Weldon write \"gender policy is not one issue but many\" and \"When [...] Latin American countries are quicker to adopt policies addressing violence against women than the Nordic countries, one at least ought to consider the possibility that fresh ways of grouping states would further the study of gender politics.\" The causes of the toleration - in law or in practice - of sexual violence inside marriage are complex; lack of understanding of the concept of consent and coercion due to lack of sexual education and public discussion about sexuality are often cited as causes of sexual abuse in general; but there has been criticism towards the idea that sex education about consent, in and of itself, is sufficient.\n\nThe countries which choose to ratify the Council of Europe Convention on preventing and combating violence against women and domestic violence, the first legally binding instrument in Europe in the field of violence against women, are bound by its provisions to ensure that non-consensual sexual acts committed against a spouse or partner are illegal. The convention came into force in August 2014. In its explanatory report (para 219) it acknowledges the long tradition of toleration, \"de jure\" or \"de facto\", of marital rape and domestic violence:\n\nCountries which were early to criminalize marital rape include the Soviet Union (1922), Poland (1932), Czechoslovakia (1950), some other members of the Communist Bloc, Sweden (1965), and Norway (1971). Slovenia, then a republic within federal Yugoslavia, criminalized marital rape in 1977. The Israeli Supreme Court affirmed that marital rape is a crime in a 1980 decision, citing law based on the Talmud (at least 6th century). Criminalization in Australia began with the state of New South Wales in 1981, followed by all other states from 1985 to 1992. Several formerly British-ruled countries followed suit: Canada (1983), New Zealand (1985), and Ireland (1990).\n\nMarital rape was criminalized in Austria in 1989 (and in 2004 it became a state offense meaning it can be prosecuted by the state even in the absence of a complaint from the spouse, with procedures being similar to stranger rape). In Switzerland marital rape became a crime in 1992 (and became a state offense in 2004). In Spain, the Supreme Court ruled in 1992 that sex within marriage must be consensual and that sexuality in marriage must be understood in light of the principle of the freedom to make one's own decisions with respect to sexual activity; in doing so it upheld the conviction of a man who had been found guilty of raping his wife by a lower court.\n\nIn Europe, Finland outlawed marital rape in 1994. The case of domestic violence in Finland has been the subject of interest and discussion, because Finland is otherwise considered a country where women have very advanced rights in regard to \"public\" life and participation in the public sphere (jobs, opportunities, etc.). The country has been made the object of international criticism in regard to its approach towards violence against women. A 2010 Eurobarometer survey on European attitudes on violence against women showed that victim blaming attitudes are much more common in Finland than in other countries: 74% of Finns blamed \"the provocative behaviour of women\" for violence against women, much higher than in other countries (for instance many countries that are popularly believed to be among the most patriarchal of Europe were significantly less likely to agree with that assertion: 33% in Spain, 46% in Ireland, 47% in Italy).\n\nBelgium was early to criminalize marital rape. In 1979, the Brussels Court of Appeal recognized marital rape and found that a husband who used serious violence to coerce his wife into having sex against her wishes was guilty of the criminal offense of rape. The logic of the court was that, although the husband did have a 'right' to sex with his wife, he could not use violence to claim it, as Belgian laws did not allow people to obtain their rights by violence. In 1989 laws were amended, the definition of rape was broadened, and marital rape is treated the same as other forms of rape.\n\nIn Ireland, the Criminal Law (Rape) Act, 1981 defined rape as \"unlawful sexual intercourse\" without consent; an attempt to explicitly include spouses within the definition was rejected by the Fianna Fáil government. Seán Doherty, the Minister for Justice, suggested that the courts might allow a charge of rape in some cases, and that various assault charges might be prosecuted in others. A 1987 discussion paper by the Law Reform Commission stated, \"In the absence of Irish decisions on the topic, the present law cannot be stated with any great degree of confidence. It would appear, however, that to the extent that the marital rape exemption exists, it is confined to circumstances where the spouses are cohabiting and there are no separation proceedings in being, or even, perhaps, in contemplation.\" The paper's call to abolish any marital exemption was \"on the whole, generally welcomed, although some misgivings were expressed as to whether it might not lead to fabricated complaints and unwarranted intrusions in the marital relationship.\" The Criminal Law (Rape) (Amendment) Act, 1990 removed the word \"unlawful\" from the 1981 definition of rape, and abolished \"any rule of law by virtue of which a husband cannot be guilty of the rape of his wife\". The first two convictions were in 2006 (upon retrial) and 2016.\n\nIn France, in 1990, following a case where a man had tortured and raped his wife, the Court of Cassation authorized prosecution of spouses for rape or sexual assault. In 1992 the Court convicted a man of the rape of his wife, stating that the presumption that spouses have consented to sexual acts that occur within marriage is only valid when the contrary is not proven. In 1994, Law 94-89 criminalized marital rape; a second law, passed 4 April 2006, makes rape by a partner (including in unmarried relationships, marriages, and civil unions) an aggravating circumstance in prosecuting rape.\n\nGermany outlawed spousal rape in 1997, which is later than other developed countries. Female ministers and women's rights activists lobbied for this law for over 25 years. Before 1997, the definition of rape was: \"Whoever compels a woman to have extramarital intercourse with him, or with a third person, by force or the threat of present danger to life or limb, shall be punished by not less than two years’ imprisonment\". In 1997 there were changes to the rape law, broadening the definition, making it gender-neutral, and removing the marital exemption. Before, marital rape could only be prosecuted as \"Causing bodily harm\" (Section 223 of the German Criminal Code), \"Insult\" (Section 185 of the German Criminal Code) and \"Using threats or force to cause a person to do, suffer or omit an act\" (Nötigung, Section 240 of the German Criminal Code) which carried lower sentences and were rarely prosecuted.\n\nBefore a new Criminal Code came into force in 2003, the law on rape in Bosnia and Herzegovina also contained a statutory exemption, and read: \"Whoever coerces a female not his wife into sexual intercourse by force or threat of imminent attack upon her life or body or the life or body of a person close to her, shall be sentenced to a prison term of one to ten years\". In Portugal also, before 1982, there was a statutory exemption.\n\nMarital rape was criminalized in Serbia in 2002; before that date rape was legally defined as forced sexual intercourse outside of marriage. The same was true in Hungary until 1997.\n\nIn 1994, in Judgment no. 223/94 V, 1994, the Court of Appeal of Luxembourg confirmed the applicability of the provisions of the Criminal Code regarding rape to marital rape.\n\nMarital rape was made illegal in the Netherlands in 1991. The legislative changes provided a new definition for rape in 1991, which removed the marital exemption, and also made the crime gender-neutral; before 1991 the legal definition of rape was a man forcing, by violence or threat of thereof, a woman to engage in sexual intercourse outside of marriage.\n\nIn Italy the law on rape, \"violenza carnale\" ('carnal violence', as it was termed) did not contain a statutory exemption, but was, as elsewhere, understood as inapplicable in the context of marriage. Although Italy has a reputation of a male dominated traditional society, it was quite early to accept that the rape law covers forced sex in marriage too: in 1976 in \"Sentenza n. 12857 del 1976\", the Supreme Court ruled that \"the spouse who compels the other spouse to carnal knowledge by violence or threats commits the crime of carnal violence\" (\"commette il delitto di violenza carnale il coniuge che costringa con violenza o minaccia l’altro coniuge a congiunzione carnale\").\n\nCyprus criminalized marital rape in 1994. Marital rape was made illegal in Macedonia in 1996. In Croatia marital rape was criminalized in 1998.\n\nIn 2006, Greece enacted \"Law 3500/2006\", entitled \"For combating domestic violence\", which punishes marital rape. It entered into force on 24 October 2006. This legislation also prohibits numerous other forms of violence within marriage and cohabiting relations, and various other forms of abuse of women.\n\nLiechtenstein made marital rape illegal in 2001.\n\nIn Colombia, marital rape was criminalized in 1996, in Chile in 1999.\n\nThailand outlawed marital rape in 2007. The new reforms were enacted amid strong controversy and were opposed by many. One opponent of the law was legal scholar Taweekiet Meenakanit who voiced his opposition to the legal reforms. He also opposed the making of rape a gender neutral offense. Meenakanit claimed that allowing a husband to file a rape charge against his wife is \"abnormal logic\" and that wives would refuse to divorce or put their husband in jail since many Thai wives are dependent on their husbands.\n\nPapua New Guinea criminalized marital rape in 2003. Namibia outlawed marital rape in 2000.\n\nSection 375 of the Indian Penal Code (IPC) considers the forced sex in marriages as a crime only when the wife is below age 15. Thus, marital rape is not a criminal offense under the IPC. Marital rape victims have to take recourse to the Protection of Women from Domestic Violence Act 2005 (PWDVA). The PWDVA, which came into force in 2006, outlaws marital rape. However, it offers only a civil remedy for the offence.\n\nRecent countries to criminalize marital rape include Zimbabwe (2001), Turkey (2005), Cambodia (2005), Liberia (2006), Nepal (2006),\nMauritius (2007), Ghana (2007), Malaysia (2007), Thailand (2007), Rwanda (2009), Suriname (2009), Nicaragua (2012), Sierra Leone (2012), South Korea (2013), Bolivia (2013), Samoa (2013), Tonga (1999/2013). Human rights observers have criticized a variety of countries for failing to effectively prosecute marital rape once it has been criminalized. South Africa, which criminalized in 1993, saw its first conviction for marital rape in 2012.\n\nThe legal history of marital rape laws in the United States is a long and complex one, that spans over several decades. Traditional rape laws in the US defined rape as forced sexual intercourse by a male with a \"female not his wife\", making it clear that the statutes did not apply to married couples. The 1962 Model Penal Code stated that \"A male who has sexual intercourse with a female not his wife is guilty of rape if: (...)\".\n\nThe criminalization of marital rape in the United States started in the mid-1970s and by 1993 marital rape was a crime in all 50 states, under at least one section of the sexual offense codes. The earlier laws of the 1970s often indicated that marital rape charges could only be brought about if the husband and wife were no longer living together. The case in the United States that first challenged this cohabitation clause was \"Oregon v. Rideout\" in 1978. During the 1990s, most states differentiated between the way marital rape and non-marital rape were treated. These differences were visible through shorter penalties, taking into account whether or not violence was used, and allowing for shorter reporting periods. (Bergen, 1996; Russell, 1990). \nThe laws have continued to change and evolve, with most states reforming their legislation in the 21st century, in order to bring marital rape laws in line with non-marital rape, but even today there remain differences in some states. With the removal, in 2005, of the requirement of a higher level of violence from the law of Tennessee, which now allows for marital rape in Tennessee to be treated like any other type of rape, South Carolina remains the only US state with a law requiring excessive force/violence (the force or violence used or threatened must be of a \"high and aggravated nature\").\n\nIn most states the criminalization has occurred by the removal of the exemptions from the general rape law by the legislature; or by the courts striking down the exemptions as unconstitutional. In some states, however, the legislature has created a distinct crime of spousal rape. This is, for example, the case in California, where there are two different criminal offenses: Rape (Article 261) and Spousal Rape (Article 262).\n\nAlthough the issue of marital rape was highlighted by feminists in the 19th century, and was also deplored by thinkers such as John Stuart Mill and Bertrand Russell (see above section 'Feminist critique in the 19th century'), it was not until the 1970s that this issue was raised at a political level. The late 1970s also saw the enactment of Sexual Offences (Amendment) Act of 1976, which provided the first statutory definition of rape (prior to this rape was an offense at common law). The Criminal Law Revision Committee in their 1984 Report on Sexual Offences rejected the idea that the offense of rape should be extended to marital relations; writing the following:\nThe Committee also expressed more general views on domestic violence arguing that \"Violence occurs in some marriages but the wives do not always wish the marital tie to be severed\" and reiterated the point that domestic incidents without physical injury would generally be outside the scope of the law: \"Some of us consider that the criminal law should keep out of marital relationships between cohabiting partners—especially the marriage bed—except where injury arises, when there are other offences which can be charged.\"\nFive years later, in Scotland, the High Court of Justiciary took a different view, abolishing marital immunity, in \"S. v. H.M. Advocate\", 1989. The same would happen in England and Wales in 1991, in \"R v R\" (see below). Very soon after this, in Australia, at the end of 1991, in \"R v L\", the High Court of Australia would rule the same, ruling that if the common law exemption had ever been part of the Australian law, it no longer was (by that time most Australian states and territories had already abolished their exemptions by statutory law).\n\nThe marital rape exemption was abolished in England and Wales in 1991 by the Appellate Committee of the House of Lords, in the case of \"R v R\". It had been promulgated in 1736 in Matthew Hale’s \"History of the Pleas of the Crown\" (see above).\nThe first attempted prosecution of a husband for the rape of his wife was \"R v Clarke\". Rather than try to argue directly against Hale’s logic, the court held that consent in this instance had been revoked by an order of the court for non-cohabitation. It was the first of a number of cases in which the courts found reasons not to apply the exemption, notably \"R v O’Brien\" (the obtaining of decree nisi), \"R v Steele\" (an undertaking by the husband to the court not to molest the wife) and \"R v Roberts\" (the existence of a formal separation agreement).\nThere are at least four recorded instances of a husband successfully relying on the exemption in England and Wales. The first was \"R v Miller\", where it was held that the wife had not legally revoked her consent despite having presented a divorce petition. \"R v Kowalski\" was followed by \"R v Sharples\", and the fourth occurred in 1991 in the case of \"R v J\", a judgment made after the first instance decision of the Crown Court in \"R v R\" but before the decision of the House of Lords that was to abolish the exemption. In \"Miller\", \"Kowalski\" and \"R v J\" the husbands were instead convicted of assault. The \"R v Kowalski\" case involved, among other acts, an instance of non-consensual oral sex. For this, the husband was convicted of indecent assault, as the court ruled that his wife's \"implied consent\" by virtue of marriage extended only to vaginal intercourse, not to other acts such as fellatio. [At that time the offense of 'rape' dealt only with vaginal intercourse]\n\nIn \"R v Sharples\" in 1990, it was alleged that the husband had raped his wife in 1989. Despite the fact that the wife had obtained a Family Protection Order before the alleged rape, the judge refused to accept that rape could legally occur, concluding that the Family Protection Order had not removed the wife's implied consent, ruling that: \"it cannot be inferred that by obtaining the order in these terms the wife had withdrawn her consent to sexual intercourse\".\n\"R v R\" in 1991 was the first occasion where the marital rights exemption had been appealed as far as the House of Lords, and it followed the trio of cases since 1988 where the marital rights exemption was upheld. The leading judgment, unanimously approved, was given by Lord Keith of Kinkel. He stated that the contortions being performed in the lower courts in order to avoid applying the marital rights exemption were indicative of the absurdity of the rule, and held, agreeing with earlier judgments in Scotland and in the Court of Appeal in \"R v R\", that “the fiction of implied consent has no useful purpose to serve today in the law of rape” and that the marital rights exemption was a “common law fiction” which had never been a true rule of English law. R’s appeal was accordingly dismissed, and he was convicted of the rape of his wife.\n\nBy 1991, when the exemption was removed, the Law Commission in its \"Working Paper\" of 1990 was already supporting the abolition of the exemption, a view reiterated in their \"Final Report\" that was published in 1992; and international moves in this direction were by now common. Therefore, the result of the \"R v R\" case was welcomed. But, while the removal of the exemption itself was not controversial, the way through which this was done was; since the change was not made through usual statutory modification. The cases of \"SW v UK\" and \"CR v UK\" arose in response to \"R v R\"; in which the applicants (convicted of rape and attempted rape of the wives) appealed to the European Court of Human Rights arguing that their convictions were a retrospective application of the law in breach of Article 7 of the European Convention on Human Rights. They claimed that at the time of the rape there was a common law exemption in force, therefore their convictions were \"post facto\". Their case was not successful, with their arguments being rejected by the European Court of Human Rights, which ruled that the criminalization of marital rape had become a reasonably foreseeable development of the criminal law in the light of the evolution of social norms; and that the Article 7 does not prohibit the gradual judicial evolution of the interpretation of an offense, provided the result is consistent with the essence of the offense and that it could be reasonably foreseen.\nA new definition of the offense of 'rape' was created in 1994 by the section 142 of the Criminal Justice and Public Order Act 1994, providing a broader definition that included anal sex; and an even broader definition was created by the Sexual Offences Act 2003, including oral sex. The law on rape does not—and did not ever since the removal of the marital exemption in 1991—provide for any different punishment based on the relation between parties. However, in 1993, in \"R v W 1993 14 Cr App R (S) 256\", the court ruled: \"It should not be thought a different and lower scale automatically attaches to the rape of a wife by her husband. All will depend upon the circumstances of the case. Where the parties are cohabiting and the husband insisted upon intercourse against his wife's will but without violence or threats this may reduce sentence. Where the conduct is gross and involves threats or violence the relationship will be of little significance.\"\nAt the time of \"R v R\", rape in Northern Ireland was a crime at common law. Northern Ireland common law is similar to that of England and Wales, and partially derives from the same sources; so any (alleged) exemption from its rape law was also removed by \"R v R\". In March 2000, a Belfast man was convicted for raping his wife, in the first case of its kind in Northern Ireland.\nUntil 28 July 2003, rape in Northern Ireland remained solely an offense at common law that could only be committed by a man against a woman only as vaginal intercourse. Between 28 July 2003 and 2 February 2009 rape was defined by the Criminal Justice (Northern Ireland) Order 2003 as \"any act of non-consensual intercourse by a man with a person\", but the common law offense continued to exist, and oral sex remained excluded. On 2 February 2009 the Sexual Offences (Northern Ireland) Order 2008 came into force, abolishing the common law offense of rape, and providing a definition of rape that is similar to that of the Sexual Offences Act 2003 of England and Wales. The Public Prosecution Service for Northern Ireland has the same policy for marital rape as for other forms of rape; it states in its \"Policy for Prosecuting Cases of Rape\" document that: \"The Policy applies to all types of rape, including marital and relationship rape, acquaintance and stranger rape, both against male and female victims\".\n\nThe criminalization of marital rape in Australia occurred in all states and territories, by both statutory and case law, from the late 1970s to the early 1990s.\nIn Australia, the offense of rape was based on the English common law offense of rape, being generally understood as \"carnal knowledge\", outside of marriage, of a female against her will. Some Australian states left rape to be defined at common law, but others had statutory definitions, with these definitions having marital exemptions. The definition of rape in Queensland, for instance, was: \"Any person who has carnal knowledge of a woman or girl, not his wife, without her consent, or with her consent, if the consent is obtained by force, or by means of threats or intimidation of any kind, or by fear of bodily harm, or by means of false and fraudulent representations as to the nature of the act, or, in the case of a married woman, by personating her husband, is guilty of a crime, which is called rape.\" Discussions of criminalization of marital rape were already taking place in the late 1970s in Queensland, but it was not until 1989 that it was criminalized.\n\nThe first Australian state to deal with marital rape was South Australia. The changes came in 1976, but these were only partly removing the exemption. The \"Criminal Law Consolidation Act Amendment Act 1976\" read: \"No person shall, by reason only of the fact that he is married to some other person, be presumed to have consented to sexual intercourse with that other person\". Nevertheless, the laws did not go as far as equating marital with non-marital rape; the law required violence, or other aggravating circumstances, in order for an act of marital intercourse to be rape; which remained law until 1992. The first Australian jurisdiction to completely remove the marital exemption was New South Wales in 1981. The same happened in Western Australia, Victoria, and ACT in 1985; and Tasmania in 1987. In 1991, in \"R v L\", the High Court of Australia ruled that if the common law exemption had ever been part of the Australian law, it no longer was.\n\nIn a variety of cultures, marriage after a rape of an unmarried woman has been treated historically as a \"resolution\" to the rape, that is, a \"reparatory marriage\". Although laws that exonerate the perpetrator if he marries his victim after the rape are often associated with the Middle East, such laws were very common around the world until the second half of the 20th century. For instance, as late as 1997, 14 Latin American countries had such laws, although most of these countries have now abolished them.\n\nWhether women were forced to marry their rapist, or the marriage was concluded before the violence began, many victims remain in chronically violent relationships. While there are many reasons for which victims of marital rape remain in their marriages, one important reason is that divorce may be hard to obtain and/or is stigmatized (Kwiatowski, 70). Cross-culturally, one of the barriers that keep victims within their marriages is the shame and guilt they feel surrounding marital rape (Bergen, 2016), or general taboos around sexuality(Kwiatkowski, 2016) (Torres, 2016). Lastly, some victims do not categorize their abuse as marital rape in order to minimize the violence they endure. This is used as a defense mechanism so they can continue to endure their abuse (Menjívar, 2016).\n\nThe earliest study in the Western World attempting to survey marital rape was an unpublished study by Joan Seites in the spring of 1975. Seites sent questionnaires to 40 rape-crisis centers from a list compiled by the Center for Women Policy Studies (Washington, DC). 16 Centers completed questionnaire for a response rate of 40%. Of the 3,709 reported calls dealing with rape and attempted rape received by the 16 centers, 12 calls dealt with marital rape (0.3%). Because rape-crisis centers did not always record the relationships of the callers, whether the 12 reported calls fully represent the number of married relationships cannot be certainly known.\n\nResearcher Richard Giles conducted research through in-depth interviews on violence between husbands and wives in a series of three studies between 1974 and 1976. Although the questions asked in the course of the interviews did not specifically pertain to the subject of marital rape, a subsequent analysis of the transcriptions of the interviews identified 4 women who discussed sex-related violence which might be viewed as instances of either attempted or completed marital rape. In all 4 cases, however, there was no instance a wife actually forced into having sex, although this may have been to avoid the possibility of force. Although the four women did not view themselves as having been raped, Giles raised the question of whether engaging in the sex act, as an act itself, constitutes violence.\n\nIn 1982 Diana E. H. Russell, a feminist writer and activist, conducted the seminal study on marital rape. Her study surveyed a total of 930 women from San Francisco, California (50% non-response rate, non-English speaking Asian women were specifically excluded as non-reliable respondents), of whom 644 were married, divorced, or who self-identified as having a husband although not married. Six of these women (1%) self-assessed that they had been raped by their husbands, ex-husband, or de facto husbands. The survey interviewers, however, classified 74 (12%) of these women as having been raped. Of the 286 non-married women in the sample, 228 (80%) were classified by the survey interviewers as having been raped. Russell found that when repeated instances of rape as classified by the survey interviewers, by husbands or ex-husbands, over the entire course of the marriage are included, these account for 38% of all rape instances, in comparison to the remaining 62% occurring in non-marital instances.\n\nDavid Finkelhor and Kersti Yllo published a study in 1985 on marital rape that drew on a scientifically-selected area probability sample from the metropolitan Boston area of 323 women who were either married or previously married who had a child living with them between the ages of six and fourteen. The study found that of the women who were married the instance of sexual relations through physical force or the threat thereof was 3%.\n\nIn 1994, Patricia Easteal, then Senior Criminologist at the Australian Institute of Criminology, published the results of survey on sexual assault in many settings. The respondents had all been victims of numerous forms of sexual assault. Of the victim sub-sample, 10.4% had been raped by husbands or \"de facto\" husbands, with a further 2.3% raped by estranged husbands/\"de factos\". \n\nIn 2002 Basile published research intended to address the lack of a nationally probability sample to-date that measured intimate sexual coercion faced by married women. Data were collected in a 1997 national poll by a random telephone survey of 1,108 residents in the continental U.S. of persons 18 years old or older. The survey had a 50% response rate. Of the 1,108 respondents, the 506 men were excluded from any inquiry into unwanted sexual experiences, leaving 602 (54%) women respondents for the study. 398 (66%) women indicated no unwanted sexual relations (their marital status is not given), and 204 (34%) women responded as having engaged in unwanted sex after being subject to some level of sexual coercion; types of sexual coercion included receiving ‘a gift’, ‘ a nice dinner’, ‘a back rub’, ‘kissing’, etc. through threatened harm and physical coercion. Of this group, a sub-sample of 120 (59%) were married, of which 9% responded as having been subject to physical force.\n\nNotwithstanding the six scientific studies specifically on marital rape by husbands in the Western world cited above, not one gives an estimation of a rate of marital rape. The first study, by Giles, does attempt to calculate a rate, but acknowledges that the study was not so designed, and the result (0%) may not be valid. The next study by Russell which is often cited as the seminal study, conflates ex-husbands and those whom, though unmarried, are counted as putative husbands or de facto “husbands.” While the data would allow estimation of a marital rape rate, it is not given. Moreover, the study's design classifies 80% of non-married women as having been raped is vastly inconsistent with other studies. The Yllo and Finkelhor 1985 study is not a nationally representative sample, i.e., limited to Boston, of women who are divorced or married, and who also have a child living with them between the ages of six and fourteen. The study did not separately estimate rates for claims of rape and situations deemed rape-threatening. In the Giles study, once threatening situations are distinguished, the findings differed significantly. Easteal's study restricts estimation of prevalence to within only the sub-sample of victims, even though the estimation could similarly be applied to the population. Basile study, which purportedly was to address the hitherto lack of a nationally probability sample regarding marital rape, omits the number of married women in the sample, thereby precluding the estimation of rape reports by married women in the sample population. The lack of such estimations make inter-study comparisons difficult, and citation of national statistics subject to the qualification made in the studies.\n\nThe prevalence of marital rape is difficult to assess, especially outside the Western World. Discussing sexual matters in many cultures is taboo. One problem with studies on marital rape is that the Western concept of consent is not understood in many parts of the world. Because many societies operate on social norms which create a dual system of sexual morality—one for sexual intercourse that is \"marital\" which is seen as an obligation that cannot be refused, and \"extra-marital\", which is seen as wrong (or illicit/illegal). Issues of consent are poorly understood, especially by young wives (which are often young girls who do not have a proper understanding of sexual rights). For instance in an interview in a study for the World Health Organization, a woman from Bangladesh who described being hit by her husband and forced to have sex said that: \"\"I thought this is only natural. This is the way a husband behaves\".\" Research has, nevertheless, associated specific regions with a very high level of violence, including sexual violence, against women by husbands/partners. An example of such a place is Ethiopia.\n\nThe prevalence of marital rape depends on the particularly legal, national, and cultural context. In 1999, the World Health Organization conducted a study on violence against women in Tajikistan, surveying 900 women above the age of 14 in three districts of the country and found that 47% of married women reported having been forced to have sex by their husband. In Turkey 35.6% of women have experienced marital rape sometimes and 16.3% often.\n\nRape by a spouse, partner or ex-partner is more often associated with physical violence. A nine-nation study within the European Union found that current or ex-partners were the perpetrators of around 25% of all sexual assaults, and that violence was more common in assaults by ex-partners (50% of the time) and partners (40%) than in assaults by strangers or recent acquaintances (25%). \n\nAttributing the effects of marital rape in research is problematic as it is nearly impossible to find a large enough sample of spouses to study who have experienced sexual violence but have not also been physically assaulted by their spouse. Marital rape can spread sexually transmitted diseases and HIV, adversely affecting a victim's physical and psychological health. In sub-Saharan countries with very high prevalence rates of HIV, such as Lesotho, instances of multiple partnerships and marital rape exacerbate the spread of HIV.\n\nWhile rape by a stranger is highly traumatic, it is typically a one-time event and is clearly understood as rape. In the case of rape by a spouse or long term sexual partner, the history of the relationship affects the victim's reactions. There is research showing that marital rape can be more emotionally and physically damaging than rape by a stranger. Marital rape may occur as part of an abusive relationship. Trauma from the rape adds to the effect of other abusive acts or abusive and demeaning talk. Furthermore, marital rape is rarely a one-time event, but a repeated if not frequent occurrence. Whether it takes place once or is part of an established pattern of domestic violence, trauma from rape has serious long term consequences for victims regardless of whether the assault is prosecuted or not.\n\nUnlike other forms of rape, where the victim can remove themselves from the company of the rapist and never interact with them again, in the case of marital rape the victim often has no choice but to continue living with their spouse: in many parts of the world divorce is very difficult to obtain and is also highly stigmatized. The researchers Finkelhor and Yllö remarked in their 1985 metropolitan Boston area study that:\n\nForced marriage and child marriage are prevalent in many parts of the world, especially in parts of Asia and Africa. A forced marriage is a marriage where one or both participants are married without their freely given consent; while a child marriage is a marriage where one or both parties are younger than 18. These types of marriages are associated with a higher rate of domestic violence, including marital rape. These forms of marriage are most common in traditional societies which have no laws against sexual violence in marriage, and where it is also very difficult to leave a marriage. Incidents taking place in some of these countries (such as Yemen) have received international attention. The World Health Organization states, under the rubric \"Customary forms of sexual violence\", (pp. 156):\n\nOne type of forced marriages occurs in Guatemala (called robadas) and Mexico (called rapto). Robadas refers to \"…abductions, in which women are ‘taken’ during the period of courtship, sometimes semivoluntarily but other times by force, by a suitor who wants to start a marital relationship with them\" (Menjívar, 2016). Rapto refers to \"…an abduction for sexual or erotic purposes or marriage\" (Bovarnik, 2007). Following the abduction, marriage is often encouraged to maintain the family honor (Bovarnik, 2007).\n\nIn these types of forced marriages, the marital union begins with the man's intense sense of control over the woman, combined with the understanding that the wife is the possession of her husband (Menjívar, 2016). This foundation of marriage had direct implications for sexual violence within the marriage. In reference to the practice of robadas, Cecilia Menjívar (2016) writes, \"…unions that start out from the violent act of a robada can continue to breed violence, abuse, and mistreatment in the union.\" In addition, women victims of robadas often face embarrassment and blame, despite the act usually being initiated by male perpetrators (Menjívar, 2016). Women are blamed for disobeying their parents or not resisting their abductor strong enough (Menjívar, 2016). This notion of blaming the woman also occurs in reference to rapto in rural Mexico. Silvie Bovarnik (2007) writes, \"In many cases, men and women alike look for the fault of responsibility in women's behavior due to traditional conceptualisations of women as ‘pillars of honour.’\" Abduction and rape compromises a woman's moral integrity, and therefore her honor (Bovarnik, 2007). Many of these women, who were given little choice in their marriage, are left to live with their abusers.\n\nThe historical (and present day in jurisdictions where it still applies) immunity of husbands to have sexual relations with their wives without consent was not the only marital immunity in regard to abuse; immunity from the use of violence was (and still is in some countries) common—in the form of a husband's right to use \"moderate chastisement\" against a 'disobedient' wife. In the US, many states, especially Southern ones, maintained this immunity until the mid-19th century. For instance, in 1824, in \"Calvin Bradley v. the State\", the Mississippi Supreme Court uphold this right of the husband; ruling as follows:\n\nAlthough by the late 19th century courts were unanimously agreeing that husbands no longer had the right to inflict \"chastisement\" on their wives, the public policy was set at ignoring incidents deemed not 'serious enough' for legal intervention. In 1874, the Supreme Court of North Carolina ruled:\n\nToday, husbands continue to be immune from prosecution in case of certain forms of physical abuse against their wives in some countries. For instance, in Iraq husbands have a legal right to \"punish\" their wives. The criminal code states that there is no crime if an act is committed while exercising a legal right. Examples of legal rights include: \"The punishment of a wife by her husband, the disciplining by parents and teachers of children under their authority within certain limits prescribed by law or by custom\". In 2010, the United Arab Emirates's Supreme Court ruled that a man has the right to physically discipline his wife and children as long as he does not leave physical marks.\n\nAlthough most research is focused on wives as victims of marital rape, husbands experience marital rape as well. Little research exists focusing on the specific situation of non-consensual wife-to-husband sexual relations, but evidence suggests that 13%-16% of men are victims of assault by marital or cohabitating partners in their lifetime (Tjaden and Thoennes, 2000). Research conducted by Morse (1995), Straus (1977-1978), and Straus and Gelles (1985) suggest that men and women have nearly the same annual rates of victimization of violence by a marital or cohabitating partner (Tjaden and Thoennes, 2000). One study that looked at lifetime experiences of marital and cohabitating partner violence found nearly equal rates of victimization among men and women (Tjaden and Thoennes, 2000). However, these statistics convey the larger topic of partner violence and do not reflect rates of marital rape.\n\nGiven that same-sex marriage is a relatively new concept, and only minimally accepted globally, little research has explored marital rape in same-sex relationships. More research must be conducted to look at these relationships within the marital context.\n\nLegally, governments have direct impact on the occurrence of marital rape. The state \"…engages in the definition, monitoring, and sanctioning of appropriate behavior\" (Torres, 2016). This can play out in criminalizing or not criminalizing marital rape and therefore deeming what is appropriate. Catharine MacKinnon argues that rape laws in male dominated societies exist to regulate access to women from a male perspective, not to protect women's right to freely decide whether to engage in sexual intercourse or not. Whatever the reason behind such laws, even when state laws have criminalized marital rape, state institutions perpetuate it. For example, although marital rape has been criminalized throughout the United States, the original laws of the 1980s and 1990s treated marital rape differently from non-marital rape, and in some states this continues to be the case even today (see Marital rape (United States law)). As these laws exemplify, marital rape is seen as somehow less reprehensible than rape outside of marriage (Bergen, 2016). Even when marital rape is prosecuted successfully, courts often pass shorter sentences - even if the law itself does not stipulate this - based on the view that sexual violation is less serious if it occurs within marriage. Following this same understanding, British courts often pass lower sentences to marital rape than to other cases of rape because it is believed that it causes less harm to the victim (Mandal, 2014).\n\nPolice departments are another state institution that treats domestic violence differently than other forms of violence. Police often label domestic abuse calls as low priority, respond slower, and focus on what provoked the abuse rather than the violent actions of the perpetrator (Schelong, 1994). Also, they often act as mediators in the situation because they may feel that domestic violence is a family matter and therefore not their business (Schelong, 1994).\n\nWhile government institutional influences are vast, marital rape is often sustained by cultural ideologies. According to Catharine MacKinnon and Andrea Dworkin, the issue of sexual violence, including within marriage, has not been a political spectrum issue - that is a left wing \"vs\". right wing issue - but a general ubiquitous part of the culture, \"The Left and the Right have consistently had different positions on rape; but neither has acknowledged rape from the point of view of the women who experienced it.\n\nFor many cultures, ideas of marital rape seem often foreign imposed and contradict the belief that such matters should be dealt with privately rather than by the government (Smith, 2016). In other instances, notably in the country of India, members of the government have spoken publicly that marital rape cannot be recognized in their culture. The Indian Minister of State for Home Affairs, Haribhai Parthibhai Chaudhary, stated in April 2015, \"The concept of marital rape, as understood internationally, cannot be suitably applied in the Indian context due to various factors, including levels of education, illiteracy, poverty myriad social customs and values, religious beliefs, [and] the mindset of the society to treat the marriage as sacrament\" (Torres, 2016).\nFor many other countries, the concept of marital rape is itself an oxymoron (Smith, 2016). Women in these cultures largely \"…share the cultural logic that marital rape is a contradiction in terms…\" while men simultaneously \"…see women's sexual consent in marriage as taken for granted…\" and therefore \"…reject the very concept of marital rape\" (Smith, 2016).\n\nThe act of imposing sexual intercourse against the will of the wife is often not identified as morally wrong, and so it is difficult to attempt to stop the practice, \"Often, men who coerce a spouse into a sexual act believe their actions are legitimate because they are married to the woman.\" (WHO, pp. 149). This idea that sexual intercourse in marriage is 'legitimate' and so it cannot be illegal even when forced, is in some parts of the world fueled by the custom of bride price: its paying is seen as earning the man the right to sexual and reproductive control of his wife. UN Women recommended the abolition of giving bride price, and stated that: \"Legislation should [...] State that a perpetrator of domestic violence, including marital rape, cannot use the fact that he paid bride price as a defense to a domestic violence charge. (pp. 25) \"\n\nYoung women from various settings in South Asia explained in surveys that even if they felt discomfort and didn't want to have sex, they accepted their husbands' wishes and submitted, fearing that otherwise they would be beaten. In many developing countries it is believed—by both men and women—that a husband is entitled to sex any time he demands it, and that if his wife refuses him, he has the right to use force. These women, most of them either illiterate or very poorly educated, are married at very young ages (in Bangladesh, for example, according to statistics from 2005, 45% of women then aged between 25–29 had been married by the age of 15), and depend on their husbands for their entire life. This situation leaves women with very little sexual autonomy. The notion that women are sexually autonomous and therefore have the ability to give or retract consent is not universally understood. Gabriella Torres writes, \"The degree to which women and men view themselves as unique social beings with a full ability to make choices and suffer consequences varies by culture\" (Torres, 2016). As a result, in cultures where women are not considered autonomous, they are not in a position to refuse sex: they have to choose between unwanted sex and being subjected to violence; or between unwanted sex and being abandoned by their husbands and ending up living in abject poverty.\n\nAccording to Sheila Jeffreys, in Western countries, \"sexual liberation\" ideologies have aggravated the problem of male sexual entitlement, leading to women submitting to unwanted sex not only due to physical force or illegal threat, but due to societal pressure: \"The force which has operated on them [women] all their lives and continues to operate on them within marriages and relationships remains largely invisible. [...] Such forces include the massive industry of sexology, sex therapy, sex advice literature, all of which make women feel guilty and inadequate for any unwillingness to fulfill a man's sexual desires.\"\n\nThe prohibition of rape serves other purposes, such as protection of the rights of male relatives or husband, enforcing of religious laws against sex outside of marriage, or preservation of a woman's respect and reputation in society. Under such ideologies it is difficult to accept the concept of marital rape. Richard A. Posner writes that, \"Traditionally, rape was the offense of depriving a father or husband of a valuable asset — his wife's chastity or his daughter's virginity\". In many countries of the world, including Morocco, Algeria, Tunisia, Jordan, the severity of the legal punishment for rape depends on whether the victim was a virgin. Rhonda Copleon writes that, \"Where rape is treated as a crime against honor, the honor of women is called into question and virginity or chastity is often a precondition.\"\n\nIn many cultures, marriages are still arranged for the purpose of procreation, property, and consolidation of extended family relations, often including a bride price or a dowry. In such situations, marriages are pre-arranged as an affair between families and clans. In some cultures, refusal of an arranged marriage is often a cause of an honor killing, because the family which has prearranged the marriage risks disgrace if the marriage does not proceed. Since consent to marriage is irrelevant, it follows that consent to marital sex is also irrelevant. Similarly, a woman attempting to obtain a divorce or separation without the consent of the husband/extended family can also be a trigger for honor killings. In cultures where marriages are arranged and goods are often exchanged between families, a woman's desire to seek a divorce is often viewed as an insult to the men who negotiated the deal.\n\nHowever, the fact that people in developing countries are increasingly selecting marriage partners by whether they are in love – a much more Western world view – does not necessarily improve the situation. These types of marriages, especially in southeastern Nigeria, are putting women in more difficult positions: if one chooses to marry based on love against their family's wishes, admitting violence in the relationship is a disgrace because it means admitting that one made the wrong judgement (Smith, 2016).\n\nMost of the Western World has been strongly influenced by Judeo-Christian Bible. The paradisaical narrative of man and woman in Genesis establishes a foundation of marriage: \nThis doctrine is repeated in the Gospel by Jesus, but with the added conclusion “so then they are no longer two, but one flesh\". The same doctrine is continued in the Epistles in the writings of the Apostle Paul. \n\nIt is further explicated by the Apostle Paul, writing, \n\nOn the standing of each party to determine how this biblical principle--denial of conjugal relations--was to be effected was codified as an ecclesiastical canon in 280 A.D. by St. Dionysian of Alexandria: \"Persons who are self-sufficient and married ought to be judges of themselves.\" The canon was given ecumenical application by the Sixth Ecumenical Council in 691 A.D. Ecclesiastical canons continued to adjudicate marital issues well into the modern era until all but entirely superseded by the civil courts. \n\nThe Christian religion teaches that pre-marital sex is fornication, and sexual relations by a married person with someone other than his or her spouse is adultery, both of which are sins, while sex within marriage is a duty. This concept of 'conjugal sexual rights' has the purpose to prevent sin (in the form of adultery and temptation) as well as to enable procreation.\n\nThe above is interpreted by some religious figures as to render marital rape an impossibility. However, not all religious figures hold this view.\n\nFurther, Pentecostal Christianity prescribes gender expectations for married individuals that \"…reestablish a patriarchal bargain…\" in which \"…women acquiesce to men's authority in return for certain kinds of support\" (Smith, 2016). Husbands are expected to provide for the family, and in return, wives are to submit to their husband's authority (Smith, 2016). Ultimately, this \"…strengthens some of the gender dynamics that make intimate partner violence possible in the first place\" (Smith, 2016).\n\nBy contrast, Pope Paul VI in his 1968 encyclical letter \"Humanae vitae\" wrote that \"Men rightly observe that a conjugal act imposed on one's partner without regard to his or her condition or personal and reasonable wishes in the matter, is no true act of love, and therefore offends the moral order in its particular application to the intimate relationship of husband and wife.\" This teaching, which has been reaffirmed more recently by Pope Francis, and has been interpreted by Bertrand de Margerie to condemn \"intra-marital rape\", and the use of force in marriage more generally.\n\nIn other areas around the world, religion is intertwined with the state and directs how people are governed. In Pakistan, there is legal pluralism where the state's legal system intertwines secular and religious law of Islam (Bovarnik, 2007). The result is Shari’a law which represents the religious aspects of the Pakistani legal system. This religious aspect of Pakistani law has many implications for marital rape. For example, Shari’a law requires a female rape victim to provide four Muslim adult male witnesses on her behalf (Bovarnik, 2007). Silvie Bovarnik (2007) argues that \"This law hence scrutinizes women's sexual behaviour by criminalising sex outside and decriminalising rape within the context of marriage, while failing to protect women from sexual violence in both contexts.\" In other words, there seems to be a preoccupation with a woman's sexual misconduct and a simultaneous lack of protection for victims of rape within their own marriage (Bovarnik, 2007). Religious ideologies emphasize a woman's honor, specifically, her virginity (Bovarnik, 2007). In general, \"…women are traditionally conceptualized as the property of and a symbol of honour for her own family and later that of her husband.\" (Bovoarnik, 2007). In addition, Islamic norms have traditionally placed restrictions on women's behavior (Bovarnik, 2007). Women are to stay at home, please the men in one's family, raise the children, and to not become involved with the world outside the home (Bovarnik, 2007). As a result, having no connection with the world outside one's family may isolate women victims of marital rape.\n\nUnlike Pakistan, the country of Sudan is ruled by Islamic law; there is no legal pluralism (Tonnesson, 2014). In Sudanese Islamic law, there is an understood exchange in marriage: A man is responsible for providing adequate support (food, shelter, etc.) and in return the woman is supposed to be obedient to her husband (Tonnesson, 2014). This follows the notion of qawama which states that male guardianship is ultimate and therefore a women's role is to obey her male guardianship (Tonnesson, 2014). In reference to marital rape, religious law in Sudan has implications for divorce. Under Sudanese Islamic law, disobedience from a wife is grounds for divorce, but a husband raping his wife is not (Tonnesson, 2014). \nDue to this understanding of a contractual exchange between husband and wife, forcing a wife to have sex without her consent is not considered rape (Tonnesson, 2014). However, activists with opposing views argue that consent is central to Islam (Tonnesson, 2014). Abdel Halim (2011) argues that without consent, \"…a sexual act loses its legitimacy\" (Tonnesson, 2014).\n\nIn India, classical Hindu law defines the state's understanding of marriage. Therefore, marriage is \"not viewed as a contract but as a sacrament\" (Mandal, 2014). This understanding is the basis for the lack of criminalization of marital rape. India's religious context defines marriages as \"divinely ordained\" and therefore the \"…rights and obligations of spouses in conjugal relations [are] beyond the scope of regulation by criminal law\" (Mandal, 2014). In other words, criminal law cannot touch that which is deemed sacred under the Hindu religion. As a result, marriage, divorce, adoption, inheritance, and other family practices are governed by religious law of each community (Mandal, 2014). However, this statement is controversial because legally marriage any person who is a Hindu, Buddhist, Jain or Sikh by religion is governed by The Hindu Marriage Act, 1955 in India, which has provisions to prohibit possession of multiple wives, and has a provision of divorce similar to other western marriage laws. These both provisions was not existing in classical Sanskrit law. This law faced religious opposition but yet implemented the government at that time. The law is now widely acceptable, and implemented in present Indian society. Therefore, stating \"In India, classical Hindu Law defines the states understanding of marriage\" can be a misleading statement.\n\nAnother sustaining factor is the obligatory roles placed on wives and what they come to understand as their \"duty\". For example, \"Vietnamese women are expected to sacrifice for their families, especially for their children, which includes, for some, acceding to husbands’ sexual demands\" (Kwiatkowski, 2016). Their \"duty\" is to maintain family harmony and happiness (Kwiatkowski, 2016). In Guatemala, violence within marriage is so normalized that wives come to believe that this is ‘the way things are’ and it is simply their role as a wife to endure the violence (Menjívar, 2016). This \"…normalization of violence…rests on a continuum of coercive power that makes possible the mistreatment of women not only in their homes but also in the community, neighborhood, and society at large\" (Menjívar, 2016). Further, because many of these women believe giving sex is their duty, they do not characterize their experience as marital rape (Bergen, 2016). However, \"…women who have experienced forced sex in marriage understand this experience as an abuse or violation\", they just may not characterize it as marital rape (Torres, 2016). Violence is so entrenched in many cultures it simply becomes a way of life, and wives are left to believe they must learn to endure it (Menjívar, 2016).\n\nOn the other hand, husbands are influenced by the expectations of their masculinity. In Africa, these expectations include being a husband, father, and head of the household which requires men to provide food, shelter and protection (Smith, 2016). Along with this \"…obligation of being the provider comes the privilege and authority of patriarchy\" (Smith, 2016). As a result, it is often the man's perception that his wife has challenged his authority that leads to the violence (Smith, 2016).\n\nIn the United States, masculinity is understood as a fixed entity that exists despite the changes of everyday life (Connell, 45). It is understood as being in comparison to femininity, and more specifically, in opposition to femininity: Masculinity is to superiority as femininity is to subservience (Connell). Therefore, masculinity is correlated with aggression in such a way that scholars argue violence is a way for men to show their masculine identity (Umberson et al., 2003). Another expectation of masculinity is that men are not to show their emotion (Umberson et al., 2003). Instead, as Robert Connell argues, the \"masculine prototype\" is a strong and stoic man who appears to remain in control of the situation and his emotions (Umberson et al., 2003). This sense of control in Western masculinity has direct implications for domestic violence. Scholars argue that some men use violence to regain this sense of control when it is lost (Umberson et al., 2003).\n\nHowever, not all men who subscribe to masculinity expectations are violent. In fact, most men, in general, are not violent (Umberson et al., 2003). For those who are violent, ideals of masculinity seem to play some causal role in their violence. Research shows that \"violence is more likely among men who experience a disconnection between their personal circumstances and their emotions\" (Umberson et al., 2003). Evidently, there seems to be some connection between the masculine expectation of suppressing or disconnecting from one's emotions, and one's tendency to be violent (Umberson et al., 2003).\n\nAlthough marital rape is not always defined as such in different cultures, there is a universal understanding of the violation that comes with rape. Yllö & Torres (2016) argue that \"…marital rape is regularly constituted across cultures as a locally recognized social violation—one that is understood to impede women in those particular cultural contexts from aspiring to a good human life.\" An aspect of this violation is the notion that the victim has not given their consent, however, historically and presently, consent is not always connected to marital sex. (Yllö &Torres, 2016). In the United States, a woman's personhood, and therefore her consent, only began with the suffragist movement that sought women's access to equal citizenship (Yllö & Torres, 2016). Globally, many cultures do not require a woman's consent in marriage because procreation is at the root of such an alliance (Yllö & Torres, 2016). Further, some women are forced into marriage where her consent is not considered or required (Yllö & Torres, 2016). Despite this cultural variance, \"women across many cultures do experience the violation of rape in marriage—even if the way that such violations are experienced and understood differs from culture to culture\" (Yllö & Torres, 2016).\n\nThe criminalization of marital rape does not necessary mean that these laws are enforced in practice, with lack of public awareness, as well as reluctance or outright refusal of authorities to prosecute being common in many countries. For instance, in Ireland, where marital rape was made illegal in 1990, by 2016 there had been only two persons convicted of marital rape. Additionally, gender norms that often place wives in subservient positions to their husbands, make it more difficult for women to recognize spousal rape or feel confident that it will be addressed by law enforcement. \n\nIn many countries, most often, in practice, there will be no prosecution except in extreme cases that involve a very high level of violence. There have been many problems with prosecuting the perpetrators of spousal rape, chief amongst them has been the reluctance of the various legal systems to recognize it as a crime at all. However, criminalization has opened a new set of problems. To take an example in the United Kingdom, such a category of rape was only recognized by a 1991 House of Lords decision known simply as \"R v R (1991 All ER 481)\". While most parties agreed with the House of Lords' motive in making the decision, there were many who were of the opinion that the decision involved \"post facto\" criminalization, since the House of Lords were imprisoning spouses for doing what was once, according to the law, their right.\n\nAnother problem results from prevailing social norms that exist in certain cultures. In order for any law to be successfully enforced, the acts which it prohibits must be perceived by society as abusive. As such, even if a jurisdiction enacts adequate laws against marital rape, in practice, these laws are ignored if the act is not socially considered a crime. For example, in many parts of the world, where women have few rights, it is considered unthinkable for a woman to refuse her husband's sexual demands; far from being seen as an act of abuse of a wife, marital rape is seen as an incident provoked by the wife who refused to perform her duty: for instance one survey found that 74% of women in Mali said that a husband is justified to beat his wife if she refuses to have sex with him.\n\nOther problems arise from the fact that, even in countries where marital rape is illegal, many people are not aware of the existing laws. Because in most parts of the world marital rape laws are very new, many people do not know of their existence. In many cultures, traditional ideas about marriage are deeply rooted in the conscience of the population, and few people know that forcing a spouse to have sex is illegal. For instance, a report by Amnesty International showed that although marital rape is illegal in Hungary, in a public opinion poll of nearly 1,200 people in 2006, a total of 62% did not know\nthat marital rape was a crime: over 41% of men and nearly 56% of women\nthought it was not punishable as a crime in Hungarian law, and nearly 12% did not know. In Hong Kong, in 2003, 16 months after the criminalization of marital rape, a survey showed that 40% of women did not know it was illegal. A 2010 study in South Africa (where marital rape was made illegal in 1993) showed that only 55% of respondents agreed with the affirmation \"I think it is possible for a woman to be raped by her husband\".\nAlthough in recent years some countries in Africa have enacted laws against marital rape, in most parts of the continent forced marital sex is not a criminal offense. A 2003 report by Human Rights Watch stated that: \"With few exceptions across Africa, marital rape is not recognized as a crime, and domestic violence is seen as a right of married men.\" The acceptability of domestic violence in most African countries is very high: surveys showed that the percentage of women aged 15–49 who think that a husband is justified in hitting or beating his wife under certain circumstances is, for example, 87% in Mali, 86% in Guinea, 80% in Central African Republic, 79% in South Sudan. Although more countries in Africa are now enacting laws against domestic violence, social norms make it difficult to enforce these laws; and many women are not aware of their rights: for instance in Ethiopia in a survey only 49% of women knew that wife-beating is illegal (it was made illegal under the 2004 Criminal Code). The lack of legal and social recognition of marital rape in Africa has been cited as making the fight against HIV harder.\n\n\"Note: The table can be sorted alphabetically or chronologically using the icons.\"\n\nTorres, G., Yllö, K. (2016). Marital Rape: Consent, Marriage and Social Change in Global Context. Torres, G., Yllö, K. (Ed.). London: Oxford University Press. \nUmberson, D., Anderson, K.L., Williams, K., Chen, M.D. (2003). Relationship dynamics, emotion state, and domestic violence: A stress and masculinities perspective. Journal of Marriage and Family, 65(1), 233-247. \nWaterman, C.K., Dawson, L.T., Bologna, M.J. (1989). Sexual coercion in gay male and lesbian relationships: Predictors and implications for support services. The Journal of Sex Research, 26(1), 118-124.\nWorld Health Organization (WHO). (2005). Multi-country Study of Women's Health and Domestic Violence against Women. Geneva, Switzerland: World Health Organization. \nYllö, Kersti. \"Prologue: Understanding Marital Rape in Global Context.\" Marital Rape: Consent, Marriage and Social Change in Global Context. Ed. Kersti Yllö, M.G. Torres. London: Oxford University Press, 2016. 1-6. Print.\n\n"}
{"id": "4944", "url": "https://en.wikipedia.org/wiki?curid=4944", "title": "Naive set theory", "text": "Naive set theory\n\nNaïve set theory is any of several theories of sets used in the discussion of the foundations of mathematics.\n\nUnlike axiomatic set theories, which are defined using formal logic, naïve set theory is defined informally, in natural language. It describes the aspects of mathematical sets familiar in discrete mathematics (for example Venn diagrams and symbolic reasoning about their Boolean algebra), and suffices for the everyday use of set theory concepts in contemporary mathematics.\n\nSets are of great importance in mathematics; in modern formal treatments, most mathematical objects (numbers, relations, functions, etc.) are defined in terms of sets. Naïve set theory suffices for many purposes, while also serving as a stepping-stone towards more formal treatments. \n\nA naïve theory in the sense of \"naïve set theory\" is a non-formalized theory, that is, a theory that uses a natural language to describe sets and operations on sets. The words and, or, if ... then, not, for some, for every are treated as in ordinary mathematics. As a matter of convenience, use of naïve set theory and its formalism prevails even in higher mathematics – including in more formal settings of set theory itself.\n\nThe first development of set theory was a naïve set theory. It was created at the end of the 19th century by Georg Cantor as part of his study of infinite sets and developed by Gottlob Frege in his \"Begriffsschrift\".\n\nNaïve set theory may refer to several very distinct notions. It may refer to\n\nThe assumption that any property may be used to form a set, without restriction, leads to paradoxes. One common example is Russell's paradox: there is no set consisting of \"all sets that do not contain themselves\". Thus consistent systems of naïve set theory must include some limitations on the principles which can be used to form sets.\n\nSome believe that Georg Cantor's set theory was not actually implicated in the set-theoretic paradoxes (see Frápolli 1991). One difficulty in determining this with certainty is that Cantor did not provide an axiomatization of his system. By 1899, Cantor was aware of some of the paradoxes following from unrestricted interpretation of his theory, for instance Cantor's paradox and the Burali-Forti paradox, and did not believe that they discredited his theory. Cantor's paradox can actually be derived from the above (false) assumption using for is a cardinal number\". Frege explicitly axiomatized a theory in which a formalized version of naïve set theory can be interpreted, and it is \"this\" formal theory which Bertrand Russell actually addressed when he presented his paradox, not necessarily a theory Cantor, who, as mentioned, was aware of several paradoxes, presumably had in mind.\n\nAxiomatic set theory was developed in response to these early attempts to understand sets, with the goal of determining precisely what operations were allowed and when.\n\nA naïve set theory is not \"necessarily\" inconsistent, if it correctly specifies the sets allowed to be considered. This can be done by the means of definitions, which are implicit axioms. It is possible to state all the axioms explicitly, as in the case of Halmos' \"Naïve Set Theory\", which is actually an informal presentation of the usual axiomatic Zermelo–Fraenkel set theory. It is \"naïve\" in that the language and notations are those of ordinary informal mathematics, and in that it doesn't deal with consistency or completeness of the axiom system.\n\nLikewise, an axiomatic set theory is not necessarily consistent: not necessarily free of paradoxes. It follows from Gödel's incompleteness theorems that a sufficiently complicated first order logic system (which includes most common axiomatic set theories) cannot be proved consistent from within the theory itself – even if it actually is consistent. However, the common axiomatic systems are generally believed to be consistent; by their axioms they do exclude \"some\" paradoxes, like Russell's paradox. Based on Gödel's theorem, it is just not known – and never can be – if there are \"no\" paradoxes at all in these theories or in any first-order set theory.\n\nThe term \"naïve set theory\" is still today also used in some literature to refer to the set theories studied by Frege and Cantor, rather than to the informal counterparts of modern axiomatic set theory.\n\nThe choice between an axiomatic approach and other approaches is largely a matter of convenience. In everyday mathematics the best choice may be informal use of axiomatic set theory. References to particular axioms typically then occur only when demanded by tradition, e.g. the axiom of choice is often mentioned when used. Likewise, formal proofs occur only when warranted by exceptional circumstances. This informal usage of axiomatic set theory can have (depending on notation) precisely the \"appearance\" of naïve set theory as outlined below. It is considerably easier to read and write (in the formulation of most statements, proofs, and lines of discussion) and is less error-prone than a strictly formal approach.\n\nIn naïve set theory, a set is described as a well-defined collection of objects. These objects are called the elements or members of the set. Objects can be anything: numbers, people, other sets, etc. For instance, 4 is a member of the set of all even integers. Clearly, the set of even numbers is infinitely large; there is no requirement that a set be finite.\nThe definition of sets goes back to Georg Cantor. He wrote 1915 in his article \"Beiträge zur Begründung der transfiniten Mengenlehre\":\n\n“Unter einer 'Menge' verstehen wir jede Zusammenfassung M von bestimmten wohlunterschiedenen Objekten unserer Anschauung oder unseres Denkens (welche die 'Elemente' von M genannt werden) zu einem Ganzen.” – Georg Cantor\n“A set is a gathering together into a whole of definite, distinct objects of our perception or of our thought—which are called elements of the set.” – Georg Cantor\n\nIt does \"not\" follow from this definition \"how\" sets can be formed, and what operations on sets again will produce a set. The term \"well-defined\" in \"well-defined collection of objects\" cannot, by itself, guarantee the consistency and unambiguity of what exactly constitutes and what does not constitute a set. Attempting to achieve this would be the realm of axiomatic set theory or of axiomatic class theory.\n\nThe problem, in this context, with informally formulated set theories, not derived from (and implying) any particular axiomatic theory, is that there may be several widely differing formalized versions, that have both different sets and different rules for how new sets may be formed, that all conform to the original informal definition. For example, Cantor's verbatim definition allows for considerable freedom in what constitutes a set. On the other hand, it is unlikely that Cantor was particularly interested in sets containing cats and dogs, but rather only in sets containing purely mathematical objects. An example of such a class of sets could be the von Neumann universe. But even when fixing the class of sets under consideration, it is not always clear which rules for set formation are allowed without introducing paradoxes.\n\nFor the purpose of fixing the discussion below, the term \"well-defined\" should instead be interpreted as an \"intention\", with either implicit or explicit rules (axioms or definitions), to rule out inconsistencies. The purpose is to keep the often deep and difficult issues of consistency away from the, usually simpler, context at hand. An explicit ruling out of \"all\" conceivable inconsistencies (paradoxes) cannot be achieved for an axiomatic set theory anyway, due to Gödel's second incompleteness theorem, so this does not at all hamper the utility of naïve set theory as compared to axiomatic set theory in the simple contexts considered below. It merely simplifies the discussion. Consistency is henceforth taken for granted unless explicitly mentioned.\n\nIf \"x\" is a member of a set \"A\", then it is also said that \"x\" belongs to \"A\", or that \"x\" is in \"A\". This is denoted by \"x\" ∈ \"A\". The symbol ∈ is a derivation from the lowercase Greek letter epsilon, \"ε\", introduced by Giuseppe Peano in 1889 and shall be the first letter of the word ἐστί (means \"is\"). The symbol ∉ is often used to write \"x\" ∉ \"A\", meaning \"x is not in A\".\n\nTwo sets \"A\" and \"B\" are defined to be equal when they have precisely the same elements, that is, if every element of \"A\" is an element of \"B\" and every element of \"B\" is an element of \"A\". (See axiom of extensionality.) Thus a set is completely determined by its elements; the description is immaterial. For example, the set with elements 2, 3, and 5 is equal to the set of all prime numbers less than 6.\nIf the sets \"A\" and \"B\" are equal, this is denoted symbolically as \"A\" = \"B\" (as usual).\n\nThe empty set, often denoted Ø and sometimes formula_1, is a set with no members at all. Because a set is determined completely by its elements, there can be only one empty set. (See axiom of empty set.) Although the empty set has no members, it can be a member of other sets. Thus Ø ≠ {Ø}, because the former has no members and the latter has one member. In mathematics, the only sets with which one needs to be concerned can be built up from the empty set alone.()\n\nThe simplest way to describe a set is to list its elements between curly braces (known as defining a set \"extensionally\"). Thus denotes the set whose only elements are and .\nNote the following points:\n(These are consequences of the definition of equality in the previous section.)\n\nThis notation can be informally abused by saying something like to indicate the set of all dogs, but this example would usually be read by mathematicians as \"the set containing the single element \"dogs\"\".\n\nAn extreme (but correct) example of this notation is , which denotes the empty set.\n\nThe notation , or sometimes , is used to denote the set containing all objects for which the condition holds (known as defining a set \"intensionally\").\nFor example, ∈ R} denotes the set of real numbers, denotes the set of everything with blonde hair.\n\nThis notation is called set-builder notation (or \"set comprehension\", particularly in the context of Functional programming).\nSome variants of set builder notation are:\n\nGiven two sets \"A\" and \"B\", \"A\" is a subset of \"B\" if every element of \"A\" is also an element of \"B\".\nIn particular, each set \"B\" is a subset of itself; a subset of \"B\" that is not equal to \"B\" is called a proper subset.\n\nIf \"A\" is a subset of \"B\", then one can also say that \"B\" is a superset of \"A\", that \"A\" is contained in \"B\", or that \"B\" contains \"A\". In symbols, \"A\" ⊆ \"B\" means that \"A\" is a subset of \"B\", and \"B\" ⊇ \"A\" means that \"B\" is a superset of \"A\".\nSome authors use the symbols ⊂ and ⊃ for subsets, and others use these symbols only for \"proper\" subsets. For clarity, one can explicitly use the symbols ⊊ and ⊋ to indicate non-equality.\n\nAs an illustration, let R be the set of real numbers, let Z be the set of integers, let \"O\" be the set of odd integers, and let \"P\" be the set of current or former U.S. Presidents.\nThen \"O\" is a subset of Z, Z is a subset of R, and (hence) \"O\" is a subset of R, where in all cases \"subset\" may even be read as \"proper subset\".\nNote that not all sets are comparable in this way. For example, it is not the case either that R is a subset of \"P\" nor that \"P\" is a subset of R.\n\nIt follows immediately from the definition of equality of sets above that, given two sets \"A\" and \"B\", \"A\" = \"B\" if and only if \"A\" ⊆ \"B\" and \"B\" ⊆ \"A\". In fact this is often given as the definition of equality. Usually when trying to prove that two sets are equal, one aims to show these two inclusions. Note that the empty set is a subset of every set (the statement that all elements of the empty set are also members of any set \"A\" is vacuously true).\n\nThe set of all subsets of a given set \"A\" is called the power set of \"A\" and is denoted by formula_2 or formula_3; the \"\"P\" is sometimes in a script font. If the set \"A\" has \"n\" elements, then formula_3 will have formula_5 elements.\n\nIn certain contexts, one may consider all sets under consideration as being subsets of some given universal set.\nFor instance, when investigating properties of the real numbers R (and subsets of R), R may be taken as the universal set. A true universal set is not included in standard set theory (see Paradoxes below), but is included in some non-standard set theories.\n\nGiven a universal set U and a subset \"A\" of U, the complement of \"A\" (in U) is defined as\nIn other words, \"A\" (\"A-complement\"; sometimes simply \"A, \"A-prime\"\" ) is the set of all members of U\"' which are not members of \"A\".\nThus with R, Z and \"O\" defined as in the section on subsets, if Z is the universal set, then \"O\" is the set of even integers, while if R is the universal set, then \"O\" is the set of all real numbers that are either even integers or not integers at all.\n\nGiven two sets \"A\" and \"B\", their union is the set consisting of all objects which are elements of \"A\" or of \"B\" or of both (see axiom of union). It is denoted by \"A\" ∪ \"B\".\n\nThe intersection of \"A\" and \"B\" is the set of all objects which are both in \"A\" and in \"B\". It is denoted by \"A\" ∩ \"B\".\n\nFinally, the relative complement of \"B\" relative to \"A\", also known as the set theoretic difference of \"A\" and \"B\", is the set of all objects that belong to \"A\" but \"not\" to \"B\". It is written as \"A\" \\ \"B\" or \"A\" − \"B\".\n\nSymbolically, these are respectively\n\nNotice that \"A\" doesn't have to be a subset of \"B\" for \"B\" \\ \"A\" to make sense; this is the difference between the relative complement and the absolute complement (\"A\" = \"U\" \\ \"A\") from the previous section.\n\nTo illustrate these ideas, let \"A\" be the set of left-handed people, and let \"B\" be the set of people with blond hair. Then \"A\" ∩ \"B\" is the set of all left-handed blond-haired people, while \"A\" ∪ \"B\" is the set of all people who are left-handed or blond-haired or both. \"A\" \\ \"B\", on the other hand, is the set of all people that are left-handed but not blond-haired, while \"B\" \\ \"A\" is the set of all people who have blond hair but aren't left-handed.\n\nNow let \"E\" be the set of all human beings, and let \"F\" be the set of all living things over 1000 years old. What is \"E\" ∩ \"F\" in this case? No living human being is over 1000 years old, so \"E\" ∩ \"F\" must be the empty set {}.\n\nFor any set \"A\", the power set formula_3 is a Boolean algebra under the operations of union and intersection.\n\nIntuitively, an ordered pair is simply a collection of two objects such that one can be distinguished as the \"first element\" and the other as the \"second element\", and having the fundamental property that, two ordered pairs are equal if and only if their \"first elements\" are equal and their \"second elements\" are equal.\n\nFormally, an ordered pair with first coordinate \"a\", and second coordinate \"b\", usually denoted by (\"a\", \"b\"), can be defined as the set <nowiki></nowiki>.\n\nIt follows that, two ordered pairs (\"a\",\"b\") and (\"c\",\"d\") are equal if and only if \"a\" = \"c\" and \"b\" = \"d\".\n\nAlternatively, an ordered pair can be formally thought of as a set {a,b} with a total order.\n\n(The notation (\"a\", \"b\") is also used to denote an open interval on the real number line, but the context should make it clear which meaning is intended. Otherwise, the notation ]\"a\", \"b\"[ may be used to denote the open interval whereas (\"a\", \"b\") is used for the ordered pair).\n\nIf \"A\" and \"B\" are sets, then the Cartesian product (or simply product) is defined to be:\nThat is, \"A\" × \"B\" is the set of all ordered pairs whose first coordinate is an element of \"A\" and whose second coordinate is an element of \"B\".\n\nThis definition may be extended to a set \"A\" × \"B\" × \"C\" of ordered triples, and more generally to sets of ordered n-tuples for any positive integer \"n\".\nIt is even possible to define infinite Cartesian products, but this requires a more recondite definition of the product.\n\nCartesian products were first developed by René Descartes in the context of analytic geometry. If R denotes the set of all real numbers, then R := R × R represents the Euclidean plane and R := R × R × R represents three-dimensional Euclidean space.\n\nThere are some ubiquitous sets that for which the notation is almost universal. Some of these are listed below. In the list, \"a\", \"b\", and \"c\" refer natural numbers, and \"r\" and \"s\" are real numbers.\n\nThe unrestricted formation principle of sets referred to as the axiom schema of unrestricted comprehension,\nis the source of several early appearing paradoxes:\n\nIf the axiom schema of unrestricted comprehension is weakened to the axiom schema of specification or axiom schema of separation,\nthen all the above paradoxes disappear. There is a corollary. With the axiom schema of separation as an axiom of the theory, it follows, as a theorem of the theory:\nOr, more spectacularly (Halmos' phrasing): There is no universe. \"Proof\": Suppose that it exists and call it . Now apply the axiom schema of separation with and for use . This leads to Russell's paradox again. Hence can't exist in this theory.\n\nRelated to the above constructions is formation of the set\n\nIt is (perhaps surprisingly) not the possibility of that is problematic. It is again the axiom schema of unrestricted comprehension allowing for . With the axiom schema of specification instead of unrestricted comprehension, the conclusion doesn't hold and, hence is not a logical consequence.\n\nNonetheless, the possibility of is often removed explicitly or, e.g. in ZFC, implicitly, by demanding the axiom of regularity to hold. One consequence of it is\nor, in other words, no set is an element of itself.\n\nThe axiom schema of separation is simply too weak (while unrestricted comprehension is a very strong axiom—too strong for set theory) to develop set theory with its usual operations and constructions outlined above. The axiom of regularity is of a restrictive nature as well. Therefore, one is led to the formulation of other axioms to guarantee the existence of enough sets to form a set theory. Some of these have been described informally above and many others are possible. Not all conceivable axioms can be combined freely into consistent theories. For example, the axiom of choice of ZFC is incompatible with the conceivable every set of reals is Lebesgue measurable. The former implies the latter is false.\n\n\n\n"}
{"id": "5416552", "url": "https://en.wikipedia.org/wiki?curid=5416552", "title": "Natura naturata", "text": "Natura naturata\n\nNatura naturata is a Latin term coined in the Middle Ages, mainly used later by Baruch Spinoza meaning \"Nature natured\", or \"Nature already created\". The term adds the suffix for the Latin feminine past participle (\"-ata\") to the verb \"naturo\", to create \"natured\". The term describes a passive God, or more specifically, the passivity of God (substance) when it is predicated into modes, and is contrasted with the second part of Spinoza's dichotomy, \"natura naturans\", meaning \"nature naturing\", or \"nature in the active sense\". \n\nThe distinction is expressed in Spinoza's \"Ethics\" as follows:\n[B]y \"Natura naturans\" we must understand what is in itself and is conceived through itself, \"or\" such attributes of substance as express an eternal and infinite essence, that is … God, insofar as he is considered as a free cause. <br> But by \"Natura naturata\" I understand whatever follows from the necessity of God's nature, \"or\" from God's attributes, that is, all the modes of God's attributes insofar as they are considered as things which are in God, and can neither be nor be conceived without God.\n"}
{"id": "81884", "url": "https://en.wikipedia.org/wiki?curid=81884", "title": "Newton's law of cooling", "text": "Newton's law of cooling\n\nNewton's law of cooling states that \"the rate of heat loss of a body is directly proportional to the difference in the temperatures between the body and its surroundings provided the temperature difference is small and the nature of radiating surface remains same.\" As such, it is equivalent to a statement that the heat transfer coefficient, which mediates between heat losses and temperature differences, is a constant. This condition is generally true in thermal conduction (where it is guaranteed by Fourier's law), but it is often only approximately true in conditions of convective heat transfer, where a number of physical processes make effective heat transfer coefficients somewhat dependent on temperature differences. Finally, in the case of heat transfer by thermal radiation, Newton's law of cooling is not true.\n\nSir Isaac Newton did not originally state his law in the above form in 1701, when it was originally formulated. Rather, using today's terms, Newton noted after some mathematical manipulation that \"the rate of temperature change\" of a body is proportional to the difference in temperatures between the body and its surroundings. This final simplest version of the law given by Newton himself, was partly due to confusion in Newton's time between the concepts of heat and temperature, which would not be fully disentangled until much later.\n\nWhen stated in terms of temperature differences, Newton's law (with several further simplifying assumptions, such as a low Biot number and temperature-independent heat capacity) results in a simple differential equation for temperature-difference as a function of time. This equation has a solution that specifies a simple negative exponential rate of temperature-difference decrease, over time. This characteristic time function for temperature-difference behavior, is also associated with Newton's law of cooling.\n\nConvection-cooling is sometimes called \"Newton's law of cooling.\" This use is based on a work by Isaac Newton published anonymously as \"Scala graduum Caloris. Calorum Descriptiones & signa.\" in \"Philosophical Transactions\", 1701.\n\nIn cases where the heat transfer coefficient is independent, or relatively independent, of the temperature difference between object and environment, Newton's law is followed. This independence is sometimes the case, but is not guaranteed to be so. The heat transfer coefficient is often relatively independent of temperature in purely conduction-type cooling, but becomes a function of the temperature in classical natural convective heat transfer. In this case, Newton's law only approximates the result when the temperature changes are relatively small. Newton himself realized this limitation.\n\nA correction to Newton's law concerning larger temperature differentials was made in 1817 by Dulong and Petit. (These men are better-known for their formulation of the Dulong–Petit law concerning the molar specific heat capacity of a crystal.)\n\nAnother situation with temperature-dependent transfer coefficient is radiative heat transfer, which also does not obey Newton's law.\n\nThe heat-transfer version of Newton's law, which (as noted) requires a constant heat transfer coefficient, states that \"the rate of heat loss of a body is proportional to the difference in temperatures between the body and its surroundings.\"\n\nThe rate of heat transfer in such circumstances is derived below:\n\nNewton's cooling law in convection is a restatement of the differential equation given by Fourier's law:\n\nwhere\n\nThe heat transfer coefficient h depends upon physical properties of the fluid and the physical situation in which convection occurs. Therefore, a single usable heat transfer coefficient (one that does not vary significantly across the temperature-difference ranges covered during cooling and heating) must be derived or found experimentally for every system that can be analyzed using the presumption that Newton's law will hold.\n\nFormulas and correlations are available in many references to calculate heat transfer coefficients for typical configurations and fluids. For laminar flows, the heat transfer coefficient is rather low compared to turbulent flows; this is due to turbulent flows having a thinner stagnant fluid film layer on the heat transfer surface. However, note that Newton's law breaks down if the flows should transition between laminar or turbulent flow, since this will change the heat transfer coefficient h which is assumed constant in solving the equation.\n\nThe Biot number, a dimensionless quantity, is defined for a body as:\n\nwhere:\n\nThe physical significance of Biot number can be understood by imagining the heat flow from a hot metal sphere suddenly immersed in a pool, to the surrounding fluid. The heat flow experiences two resistances: the first at the surface of the sphere, and the second within the solid metal (which is influenced by both the size and composition of the sphere). The ratio of these resistances is the dimensionless Biot number.\n\nIf the thermal resistance of the fluid/sphere interface exceeds that thermal resistance offered by the interior of the metal sphere, the Biot number will be less than one. For systems where it is much less than one, the interior of the sphere may be presumed always to have the same temperature, although this temperature may be changing, as heat passes into the sphere from the surface. The equation to describe this change in (relatively uniform) temperature inside the object, is the simple exponential one described in Newton's law of cooling expressed in terms of temperature difference (see below).\n\nIn contrast, the metal sphere may be large, causing the characteristic length to increase to the point that the Biot number is larger than one. In this case, thermal gradients within the sphere become important, even though the sphere material is a good conductor. Equivalently, if the sphere is made of a thermally insulating (poorly conductive) material, such as wood or styrofoam, the interior resistance to heat flow will exceed that of the fluid/sphere boundary, even with a much smaller sphere. In this case, again, the Biot number will be greater than one.\n\nValues of the Biot number smaller than 0.1 imply that the heat conduction inside the body is much faster than the heat convection away from its surface, and temperature gradients are negligible inside of it. This can indicate the applicability (or inapplicability) of certain methods of solving transient heat transfer problems. For example, a Biot number less than 0.1 typically indicates less than 5% error will be present when assuming a lumped-capacitance model of transient heat transfer (also called lumped system analysis). Typically, this type of analysis leads to simple exponential heating or cooling behavior (\"Newtonian\" cooling or heating) since the amount of thermal energy (loosely, amount of \"heat\") in the body is directly proportional to its temperature, which in turn determines the rate of heat transfer into or out of it. This leads to a simple first-order differential equation which describes heat transfer in these systems.\n\nHaving a Biot number smaller than 0.1 labels a substance as \"thermally thin,\" and temperature can be assumed to be constant throughout the material's volume. The opposite is also true: A Biot number greater than 0.1 (a \"thermally thick\" substance) indicates that one cannot make this assumption, and more complicated heat transfer equations for \"transient heat conduction\" will be required to describe the time-varying and non-spatially-uniform temperature field within the material body. Analytic methods for handling these problems, which may exist for simple geometric shapes and uniform material thermal conductivity, are described in the article on the heat equation.\n\nAs noted in the section above, accurate formulation for temperatures may require analysis based on changing heat transfer coefficients at different temperatures, a situation frequently found in free-convection situations, and which precludes accurate use of Newton's law.\n\nAs noted above, Newton's law behavior when stated in terms of \"temperature change\" in the body, also requires that internal heat conduction within the object be large in comparison to the loss/gain of heat by surface transfer (conduction and/or convection), which is the condition where the Biot number is less than about 0.1. This allows the presumption of a single \"temperature\" inside the body (as a function of time) to make sense, as otherwise the body would have many different temperatures inside it, at any one time. This single temperature will generally change exponentially, as time progresses (see below).\n\nAssumption of rapid internal conduction also allows use of the so-called lumped capacitance model. In this model, the amount of thermal energy in the body is calculated by assuming a constant heat capacity and thus thermal energy in the body is assumed to be a linear function of the body's temperature.\n\nGiven that the body is treated as a lumped capacitance thermal energy reservoir with a formula_2 (total thermal energy content) which is proportional to formula_11 (simple total heat capacity) and formula_5 (the temperature of the body), then formula_13. It is expected that the system will experience exponential decay in the temperature difference of body and surroundings as a function of time. This is proven in the following sections:\n\nFrom the definition of heat capacity formula_11 comes the relation formula_15. Differentiating this equation with regard to time gives the identity (valid so long as temperatures in the object are uniform at any given time): \n\nThis expression may be used to replace formula_17 in the first equation which begins this section, above. Then, if formula_18 is the temperature of such a body at time formula_19, and formula_20 is the temperature of the environment around the body:\n\nwhere formula_22 is a positive constant characteristic of the system, which must be in units of formula_23, and is therefore sometimes expressed in terms of a characteristic time constant formula_24 given by: \n\nThus, in thermal systems, formula_26. (The total heat capacity formula_11 of a system may be further represented by its mass-specific heat capacity formula_28 multiplied by its mass formula_29, so that the time constant formula_24 is also given by formula_31).\n\nThe solution of this differential equation, by standard methods of integration and substitution of boundary conditions, gives:\n\nIf formula_33 is defined as formula_34 where formula_35 is the initial temperature difference at time 0, then the Newtonian solution is written as:\n\nThis same solution is more immediately apparent if the initial differential equation is written in terms of formula_37, as a single function of time to be found, or \"solved for.\"\n\n\nSee also:\n\n"}
{"id": "49506542", "url": "https://en.wikipedia.org/wiki?curid=49506542", "title": "Noah W. Parden", "text": "Noah W. Parden\n\nNoah Walter Parden (c. 1868February 23, 1944) was an American attorney and politician who was active in Chattanooga, Tennessee, East St. Louis, Illinois, and St. Louis, Missouri between 1891 and 1940. In 1906 he became one of the first African-American attorneys to serve as lead counsel in a case before the United States Supreme Court, and he was among the first to make an oral argument before the Court. In 1935 he became the first African American to be appointed to the position of Assistant Prosecuting Attorney, a public office, in St. Louis.\n\nNoah Parden was born near Rome, Georgia, probably in 1868. His mother was a former slave who worked as a housekeeper and cook. His father was a white man. When he was about seven years old he was sent to an orphanage after the death of his mother, who had raised him as a single parent.\n\nIn 1884 he left Rome for Chattanooga, Tennessee, where he supported himself by working as a barber and at other odd jobs while he spent five years attending Howard High School. He graduated in May 1890, presenting the class oration on \"The Duty of a Citizen.\" He then enrolled as a senior in the law department at Central Tennessee College in Nashville, graduating in 1891.\n\nIn 1892 he married Mattie S. Broyles (March 29, 1870 – July 15, 1934), a native of Dalton, Georgia whom he had met in Nashville, and they settled in Chattanooga where they remained until 1906. They had two children, Frank B. Parden, who died August 22, 1925, and Lillian Parden Bracy. After leaving Chattanooga, Parden and his family moved briefly to Pueblo, Colorado and then settled in East St. Louis, Illinois. In 1922 the Pardens moved to neighboring St. Louis, Missouri, although Noah Parden continued to maintain a law office in East St. Louis.\n\nAfter Mattie Parden's death in 1934, Noah Parden married Elizabeth Polk, a divorcee from East St. Louis. Her former husband Tranne Polk, an East St. Louis detective and politician, had been acquitted on charges of assaulting Parden in 1933. During the trial, Polk testified that Parden had interfered in his personal affairs.\n\nParden was able to speak several languages, played the violin, and was knowledgeable about art, music and literature. He also remained connected to his rural roots. By the end of the 1920s he had acquired a 400-acre cotton plantation near Hickory, Mississippi, where he vacationed and to which he would briefly retire before returning to live in St. Louis until the end of his life. On the farm, he did agricultural work to relax; he also knew how to sew, knit and make his own clothing.\n\nParden died on February 23, 1944, and was buried at Booker Washington Cemetery in Centreville Station, Illinois. He was survived by his wife Elizabeth, his daughter, and a stepdaughter, Gertrude Polk.\n\nNoah Parden practiced law from 1891 to 1940, a career which spanned 49 years. At the end of 1929 he claimed to have defended 236 people accused of murder, of whom one had been legally executed and another lynched. In addition to his private legal practice he also worked as a prosecutor, serving for nine years (1908-1917) as an assistant state's attorney in St. Clair County, Illinois, and for five years (1935-1940) as an Assistant Prosecuting Attorney in St. Louis. He intermittently engaged in writing, editing and public speaking, and was involved in local politics in East St. Louis and St. Louis.\n\nAfter receiving his law degree in 1891 Noah Parden began his career as an attorney in Chattanooga. in 1892, he briefly established a partnership with another black attorney, James P. Easley. During 1895 Parden and Easley also published a newspaper, the \"Chattanooga\" \"Herald\", although Parden soon sold his share in the paper. He gained a reputation as an effective defense attorney who was able to obtain victories for his African-American clients in jury trials despite the all-white juries employed in local courts.\n\nIn 1906 Parden was asked to represent Ed Johnson, a black Chattanooga man who had been convicted of the rape of Nevada Taylor, a white woman, and sentenced to death. Together with Styles L. Hutchins, Jr., an African-American attorney and former Tennessee state legislator, and Lewis Shepherd, a white attorney and former judge, Parden began working to overturn Johnson's conviction. No concrete evidence linked Johnson to the crime, and, as Parden argued, the trial had been replete with errors including open demonstrations of bias against Johnson by a member of the jury, exclusion of blacks from the jury pool, and a so-called mob mentality in the courtroom during the trial. Nevertheless, the Chattanooga court refused to reopen the case and the Tennessee Supreme Court refused to authorize a stay of execution that would have allowed for a new trial, on the grounds that there had been no specific error in the trial to warrant it. Parden then filed a petition for a writ of habeas corpus with the U.S. Federal Court in Knoxville, citing the Habeas Corpus Act of 1867, which allowed defendants in state court cases to seek relief from federal courts if they believed their Constitutional rights had been violated. He argued that the state courts had violated Johnson's rights by excluding blacks from juries, a form of discrimination which the United States Supreme Court had determined to be illegal. Although the court rejected this argument, Judge C.D. Clark did stay Johnson's execution to allow Parden and his colleagues to appeal the case to the Supreme Court, which had the power to rule in favor of federal intervention in a state court case.\n\nOn March 17, 1906, Parden presented his petition before Justice John Marshall Harlan, arguing that the Johnson trial had included flagrant violations of the defendant's Constitutional rights. The following day the Court accepted the case, staying Johnson's sentence and ordering both sides to prepare for oral arguments. On the night of March 18, however, a mob in Chattanooga broke into the jail, kidnapped Johnson, and lynched him, hanging him from the Walnut Street bridge over the Tennessee River.\n\nThe federal government responded to the lynching as a violation of federal law, as Johnson had been under the protection of a Supreme Court order when it occurred. Hamilton County Sheriff Joseph F. Shipp, seven of his deputies, and a group of men thought to have belonged to the lynch mob were charged with criminal contempt of the United States Supreme Court, the mob members for their role in Johnson's murder and the law enforcement officers for willfully neglecting to protect him despite the likelihood of mob violence. In 1909 Shipp and five others were found guilty of contempt after the only criminal trial ever conducted by the Supreme Court. Noah Parden and Styles Hutchins worked with the Justice Department in gathering information and identifying witnesses for the case; however, both attorneys ended their involvement before the case went to trial, and neither returned to Chattanooga, where supporters of Shipp and the lynch mob had threatened and intimidated those they considered their enemies.\n\nNoah Parden spent the remainder of his professional life in the twin cities of East St. Louis, Illinois, where he settled in late 1906 or early 1907, and St. Louis, Missouri, where he relocated with his family in 1922. His practice included white as well as black clients, and he held elective office by serving on the St. Clair County Board of Supervisors, to which he was elected in 1907 and where he chaired the judiciary committee. However, this phase of his career also reflected the segregated character of the two cities' legal and political institutions.\n\nParden served as a prosecutor in both cities. He was appointed to multiple two-year terms as an Assistant State's Attorney in East St. Louis, serving from 1908 to 1917, and became the first black attorney to be appointed an Assistant Prosecuting Attorney in St. Louis, a position he held from 1935 until his retirement in 1940. In both jurisdictions he was assigned the task of trying African Americans brought before the court. In East St. Louis his work included prosecution of black suspects accused of carrying concealed weapons, an arrangement which, according to historian Charles Lumpkins, provided black people with \"access to legal redress\" that would not otherwise have been available. In St. Louis, his job was to prosecute black men accused of abandoning their families.\n\nParden quickly became politically active in East St. Louis. In 1910 he ran for the position of Assistant State's Attorney on the ticket of the Progressive Citizens' Party, a reform group which had coalesced in opposition to the Administration (Democratic regular) party allied with the political machine led by boss Locke Tarleton. His Administration opponent, dentist and activist Dr. Leroy Bundy, was also an African American, and black East St. Louisians anticipated that this support by white political leaders for black candidates would lead to greater black access to local government. However, the Progressive Citizens Party ran on an anti-corruption platform and did not extend patronage or access to African Americans, while the machine was perceived as stingy with its money and patronage. Both Parden and Bundy became part of a group of black professional men who responded by forming an all-black Republican organization, the St. Clair County Republican League, in 1916. This independent group sought to navigate between East St. Louis's white political factions and gain more benefits for black residents; sociologist Elliot Rudwick has argued that \"Bundy and his followers were demanding political equality\" via access to the same pool of money and city jobs that was available to white voters. In doing so they became involved in political corruption themselves.\n\nIn 1916 Parden worked for the Republican Party with the expectation of reappointment as Assistant State's Attorney after the election. In the lead-up to the 1917 mayoral election, incumbent Fred Mollman and his allies exerted pressure on black voters. Mollman promised to hire more black policemen and build a firehouse in a black neighborhood as incentives for their support, while Parden's boss, State's Attorney Hubert Schaumleffel, threatened them. Parden was enlisted to convey to African-American saloon owners and participants in the gambling and prostitution businesses that if Mollman won the election, a crackdown on their establishments which had taken effect early in 1917 would be lifted. After Mollman's victory Parden, along with hundreds of other politically-involved African Americans, participated in a post-election banquet attended by the mayor and his allies.\n\nOn July 2, 1917, East St. Louis was engulfed by a bloody race riot, characterized by violent attacks by white mobs on blacks to whom little protection was provided by law enforcement. Hundreds of black residents were killed and thousands left homeless by the riots. Although Noah Parden encouraged his client and one-time political rival Leroy Bundy to leave the city during the tense days before the riot, he himself remained at his home in East St. Louis, later testifying that on the night of July 1 he had responded to the arrival of a carload of white men cruising past his house in a Model T Ford and shooting from the car, by running to his own front door with a gun.\n\nThe Parden family survived the riot unharmed, but its aftermath was professionally damaging to Parden. He had lost his post as Assistant State's Attorney after an initial outbreak of white-on-black violence in May 1917, when the Board of Supervisors abolished the position. After the July riots he was arrested along with other black leaders, based on the assumption that they must have been promoting discontent among the black populace. Parden was among those charged with organizing a black militia. He was not convicted (and there was no evidence that a black militia had in fact been organized), and he was able to testify on Bundy's behalf when Bundy was tried for participating in a conspiracy to provoke the riots. However, other black East St. Louisians were convicted on riot-related charges and sent to prison. In 1924 Parden and other black Republicans supported the re-election campaign of Illinois governor Len Small, who not only appointed African Americans to public positions but had granted clemency to some of those convicted for their alleged roles in the riots.\n\nAfter relocating to St. Louis, Parden practiced law in both Illinois and Missouri. His successes as a defense attorney included the 1923 St. Louis case of Joseph Kyle, a black man who was found not guilty of murdering a white police officer by reason of self-defense, the officer and his partner having shot first at Kyle in the dark and without identifying themselves. He also remained involved in local politics, becoming active as a Democrat in St. Louis's Twenty-third Ward. He spent the final five years of his career working as an Assistant Prosecuting Attorney and was recognized as the first black attorney to be appointed to the position.\n\nNoah Parden was admitted to the bar of the United States Supreme Court in 1906 on the recommendation of Emanuel D. Molyneaux Hewlett, an African American attorney and member of the Supreme Court bar who acted as a co-counsel in many cases involving black southerners. His only appearance before the court was in connection with the Ed Johnson case, during which he made an emergency appeal before Justice John Marshall Harlan in chambers.\n\nParden's argument before Justice Harlan marked the first time that the Supreme Court involved itself in a lynching case. In his presentation, Parden argued that Johnson's trial had violated his Constitutional rights under the Fourth, Fifth, Sixth and Fourteenth Amendments. Legal analyst Mark Curriden and attorney Leroy Phillips note that all of the issues of Constitutional interpretation raised by Parden were later accepted by the Supreme Court. In terms of the Johnson case, Parden's most important argument was that the right to a fair trial guaranteed by the Sixth Amendment applied to state as well as federal courts. Prior to Parden's appearance before Harlan, the Court had been reluctant to claim federal jurisdiction over state courts, but the evidence of flagrant denial of Johnson's rights that Parden presented led them to do so, in what Curriden and Phillips describe as a \"precedent-setting\" intervention.\n\nParden was among a small number of African-American attorneys to present cases before the Supreme Court during the nineteenth and early twentieth centuries. In their 1999 study \"Contempt of Court\", Curriden and Phillips asserted that he was the first black attorney to reach two milestones: presentation of an oral argument before a member of the Court (rather than being part of a team of attorneys in which another, white lawyer made the oral arguments), and recognition as lead attorney on a case accepted by the full Supreme Court. However, other black attorneys preceded Parden in one or both of these categories. In 1890 Everett J. Waring, a black lawyer and educator from Columbus, Ohio, argued the case of Jones v. United States (137 U.S. 202 [1890]) before the Court; law professor J. Clay Smith and others describe Waring as the first African American to present an argument. Two other black attorneys argued cases before the court on December 13, 1895, both challenging laws excluding blacks from grand juries in Mississippi. Wilford H. Smith argued Gibson v. State of Mississippi (162 U.S. 565 [1896]), and Cornelius J. Jones, a lawyer and politician, argued Smith v. State of Mississippi (162 U.S. 592 [1896]). In \"Smith\", Jones was the sole representative of the plaintiff in error, while in \"Gibson\" that position was filled by Smith's co-counsel, Emanuel Molyneaux Hewlett. In 1900, Wilford Smith became the first African-American attorney to win a case before the Supreme Court, Carter v. Texas (177 U.S. 442 [1900]), in which he also served as lead attorney along with co-counsel Hewlett.\n\nSince the beginning of the twenty-first century, Parden's career and accomplishments have begun to receive public recognition. In 2003, the Illinois General Assembly adopted a resolution honoring Parden \"for his dedication and commitment to the causes of justice and equality,\" and recognizing \"his contributions to the citizens of Illinois and the country.\" In 2013 the Southern Center for Human Rights inaugurated the Noah Parden and Styles Hutchins Fellowships, three-year awards supporting attorneys working at the center, in honor of Parden and his partner in the Johnson appeal.\n\n\n"}
{"id": "47038630", "url": "https://en.wikipedia.org/wiki?curid=47038630", "title": "Old Russian Law", "text": "Old Russian Law\n\nOld Russian Law or Russian Law is a legal system in Kievan Rus' (since the 9th century), in later Old Rus' states (knyazhestva, or princedoms in the period of feudal fragmentation), in Grand Duchy of Lithuania and in Moscow Rus' (see: Grand Duchy of Moscow and Tsardom of Russia). Main source was Old Slavic customary law: Zakon Russkiy (Law of Rus') (it was partly written in Rus'–Byzantine Treaties). Another sources were Old Scandinavian customary law (see: Varangians) and Byzantine law (since the 10th century).\n\nThe main written sources were Russkaya Pravda (\"Russian Justice\") (since the 11th century) and Statutes of Lithuania (since the 16th century).\n\nAccording to Old Russian chronicles, in 862, Slavs and Finns invited Varangians under the leadership of prince Rurik to rule in their land:\n\nEarly Russian state settled on the oral treaty, or \"ryad\" (Old Russian: рядъ) between the prince (knyaz) with his armed force (druzhina) on the one hand, and tribal \"nobility\" and formally all people on the other hand. The prince and his druzhina defended people, decide lawsuits, provided trade and built towns. And people paid tribute and took part in irregular military. During the ensuing centuries the \"ryad\" was playing an important role in Old Russian princedoms: the prince and his administration (druzhina) found their relationship with people (\"all land\", \"all townsmen\" in Old Russian chronicles) on the treaty. A breach of the treaty could result in exile of the prince (Izyaslav Yaroslavich and Vsevolod Yaroslavich) or even in murder of the prince (Igor Rurikovich and Igor Olgovich).\n\nOne of the result of Rus'–Byzantine Wars was conclusion of Treaties with Byzantine in the 10th century, where, apart from Byzantine legal rules, also Zakon Russkiy (Law of Rus') - rules of Old Russian oral customary law reflected.\n\nYaroslav's Pravda of the beginning of the 11th century was the first written law in Rus'. This short code regulated the relationship between the princely druzhina (\"rusins\") and the people (\"slovenins\") concerning criminal law. After Yaroslav's death, his sons Izyaslav, Vsevolod, Svyatoslav and their druzhina got together and promulgated a code concerning the violation of property rights in princely lands (Pravda of Yaroslav's sons) in the middle of the 11th century. Yaroslav's Pravda and Pravda of Yaroslav's sons became a basis for the Short edition of Russkaya Pravda.\n\nIn the period of Vladimir Monomakh's reign at the beginning of the 12th century, the Vast edition of Russkaya Pravda was given, which contained rules of criminal, procedural and civil law, including trade, family law and rules of the bond of obligation.\n\nLater written secular law also included statutory charters, trade treaties, statutes of Grand Duchy of Lithuania, big codes of Moscow Rus' - Sudebniks (see below), and other texts.\n\nTranslations of Byzantine legal codes, including Nomocanon, were widely spread in Old Rus' (see: Kormchaia, Merilo Pravednoye), but it wasn't widely applied in secular or church legal practice, restricted mainly in canon law. The Church in Old Rus' did not have wide influence and depended on the power of the state. Thus, church law mainly dealt with family law and sanctions against moral violation.\n\nSee also: church statutes of prince Vladimir and prince Yaroslav.\n\n\nForeign sources\n\n\nNative sources\n\nIt was in part a record of oral law and revision of foreign sources:\n\n\n\n\n"}
{"id": "10225184", "url": "https://en.wikipedia.org/wiki?curid=10225184", "title": "Oxygen evolution", "text": "Oxygen evolution\n\nOxygen evolution is the process of generating molecular oxygen (O) by a chemical reaction, usually from water. Oxygen evolution from water is effected by oxygenic photosynthesis, electrolysis of water, and thermal decomposition of various oxides. The biological process supports aerobic life. When relatively pure oxygen is required industrially, it is isolated by distillation of liquified air.\n\nPhotosynthetic oxygen evolution is the fundamental process by which oxygen is generated in earth's biosphere. The reaction is part of the light-dependent reactions of photosynthesis in cyanobacteria and the chloroplasts of green algae and plants. It utilizes the energy of light to split a water molecule into its protons and electrons for photosynthesis. Free oxygen, generated as a by-product of this reaction, is released into the atmosphere.\n\nWater oxidation is catalyzed by a manganese-containing cofactor contained in photosystem II known as the oxygen-evolving complex (OEC) or water-splitting complex. Manganese is an important cofactor, and calcium and chloride are also required for the reaction to occur.The stoichiometry this reaction follows:\nThe protons are released into the thylakoid lumen, thus contributing to the generation of a proton gradient across the thylakoid membrane. This proton gradient is the driving force for ATP synthesis via photophosphorylation and coupling the absorption of light energy and oxidation of water to the creation of chemical energy during photosynthesis.\n\nIt was not until the end of the 18th century that Joseph Priestley discovered by accident the ability of plants to \"restore\" air that had been \"injured\" by the burning of a candle. He followed up on the experiment by showing that air \"restored\" by vegetation was \"not at all inconvenient to a mouse.\" He was later awarded a medal for his discoveries that: \"...no vegetable grows in vain... but cleanses and purifies our atmosphere.\" Priestley's experiments were followed up by Jan Ingenhousz, a Dutch physician, who showed that \"restoration\" of air only worked in the presence of light and green plant parts.\n\nIngenhousz suggested in 1796 that CO (carbon dioxide) is split during photosynthesis to release oxygen, while the carbon combined with water to form carbohydrates. While this hypothesis was attractive and reasonable and thus widely accepted for a long time, it was later proven incorrect. Graduate student C.B. Van Niel at Stanford University found that purple sulfur bacteria reduce carbon to carbohydrates, but accumulate sulfur instead of releasing oxygen. He boldly proposed that, in analogy to the sulfur bacteria's forming elemental sulfur from HS (hydrogen sulfide), plants would form oxygen from HO (water). In 1937, this hypothesis was corroborated by the discovery that plants are capable of producing oxygen in the absence of CO. This discovery was made by Robin Hill, and subsequently the light-driven release of oxygen in the absence of CO was called the \"Hill reaction\". Our current knowledge of the mechanism of oxygen evolution during photosynthesis was further established in experiments tracing isotopes of oxygen from water to oxygen gas.\n\nTogether with hydrogen (H), oxygen is evolved by electrolysis of water. \nElectrons (e) are transferred from the cathode to protons to form hydrogen gas. The half reaction, balanced with acid, is:\n\nAt the positively charged anode, an oxidation reaction occurs, generating oxygen gas and releasing electrons to the anode to complete the circuit:\n\nCombining either half reaction pair yields the same overall decomposition of water into oxygen and hydrogen:\n\nChemical oxygen generators consist of chemical compounds that release O upon some stimulation, usually heat. They are used in submarines and commercial aircraft, providing emergency oxygen. Oxygen is generated by high-temperature decomposition of sodium chlorate:\nPotassium permanganate also releases oxygen upon heating, but the yield is modest.\n\n\n"}
{"id": "47626304", "url": "https://en.wikipedia.org/wiki?curid=47626304", "title": "Penumbra (law)", "text": "Penumbra (law)\n\nIn United States constitutional law, the penumbra includes a group of rights derived, by implication, from other rights explicitly protected in the Bill of Rights. These rights have been identified through a process of \"reasoning-by-interpolation\", where specific principles are recognized from \"general idea[s]\" that are explicitly expressed in other constitutional provisions. Although researchers have traced the origin of the term to the nineteenth century, the term first gained significant popular attention in 1965, when Justice William O. Douglas's majority opinion in \"Griswold v. Connecticut\" identified a right to privacy in the penumbra of the constitution.\n\nCommentators disagree about the precise origin of the use of the term \"penumbra\" in American legal scholarship, but most believe it was first used in the late nineteenth century. Burr Henly, for example, traces the first use of the word to an 1873 law review article written by Oliver Wendell Holmes, in which he argued that it is better for new law to grow \"in the penumbra between darkness and light, than to remain in uncertainty\". Luis Sirico and Henry T. Greely, on the other hand, trace the term to Justice Stephen Johnson Field's 1871 circuit court opinion in \"Montgomery v. Bevans\", where Justice Field used the term to describe a period of time in which it was uncertain whether an individual could legally be considered deceased. Other commentators, including Glenn H. Reynolds and Brannon P. Denning, note that elements of penumbral reasoning can be found in much older cases that precede the first use of the term \"penumbra\"; they trace the origins of penumbral reasoning to United States Supreme Court cases from the early nineteenth century. For example, Reynolds and Denning describe Chief Justice John Marshall's opinion in \"McCulloch v. Maryland\" as \"the quintessential example of penumbral reasoning\".\n\nAlthough the meaning of the term has varied over time, scholars now generally agree that the term refers to a group of rights that are not explicitly stated in the constitution, but can be inferred from other enumerated rights. The definition of the term was originally derived from its primary scientific meaning, which is \"a space of partial illumination (as in an eclipse) between the perfect shadow on all sides and the full light\". By analogy, rights that exist in the constitution's penumbra can be found in the \"shadows\" of other portions constitution. Additionally, the process of identifying rights in constitutional penumbras is known as \"penumbral reasoning\". Brannon P. Denning and Glenn H. Reynolds have described this interpretive framework as the process of \"drawing logical inferences by looking at relevant parts of the Constitution as a whole and their relationship to one another.\" Glenn H. Reynolds has also characterized penumbral reasoning as a process of \"reasoning-by-interpolation\" where judges identify the full scope and extent of constitutional rights.\n\nThe term \"penumbra\" first appeared in an opinion published by the Supreme Court of the United States in 1916, and the term appeared ten more times in published opinions between 1916 and 1941. Between 1941 and the date of publication of \"Griswold v. Connecticut\", the term was used eight times by Justice William O. Douglas and four times by other Justices. Second Circuit Court of Appeals Judge Learned Hand also used the term eleven times between 1915 and 1950, usually to place emphasis on words or concepts that were ambiguous. For example, in \"Commissioner v. Ickelheimer\", Judge Hand wrote, \"[t]he colloquial words of a statute have not the fixed and artificial content of scientific symbols; they have a penumbra, a dim fringe, a connotation, for they express an attitude of will, into which it is our duty to penetrate and which we must enforce ungrudgingly when we can ascertain it, regardless of imprecision in its expression\".\n\nBefore \"Griswold\", different Supreme Court Justices would often utilize different definitions of the term in different contexts, possibly because the Justices did not understand the meaning of the word. In \"Schlesinger v. Wisconsin\", for example, Justice Oliver Wendell Holmes used the term to describe rights derived by implication. He wrote, \"the law allows a penumbra to be embraced that goes beyond the outline of its object in order that the object may be secured\". Likewise, in \"Olmstead v. United States\", Justice Holmes argued that evidence obtained through wire-tapping should not be admitted at trial, and that \"the penumbra of the Fourth and Fifth Amendments covers the defendant\". However, in \"A.L.A. Schecter Poultry Corp. v. United States\", Justice Benjamin Cardozo used the term to describe an area of uncertainty in the law. He wrote, \"[t]here is no penumbra of uncertainty obscuring judgment here. To find immediacy or directness here is to find it almost everywhere\". Additionally, in \"Coleman v. Miller\", Justice Felix Frankfurter used the term in a manner that was more closely related to its traditional definition. When arguing that a group of legislators lacked standing, he wrote, \"[n]o doubt the bounds of such legal interest have a penumbra which gives some freedom in judging fulfillment of our jurisdictional requirements\".\n\nJ. Christopher Rideout and Burr Henly note that the term achieved prominence after Justice Douglas' majority opinion in \"Griswold v. Connecticut\" held that a right to privacy existed in the penumbra of the constitution. In \"Griswold\", the Supreme Court ultimately held that a Connecticut law that criminalized the use of contraception was unconstitutional. Writing for a majority of the Court, Justice Douglas held that the Connecticut law violated a fundamental right to privacy. After reviewing a line of cases in which the Supreme Court identified rights not explicitly enumerated in the constitution, Justice Douglas declared that \"[t]he foregoing cases suggest that specific guarantees in the Bill of Rights have penumbras, formed by emanations from those guarantees that help give them life and substance\". Justice Douglas argued that the Court could infer a right to privacy by looking at \"zones of privacy\" protected by First, Third, Fourth, Fifth, and Ninth Amendments:\n\nConsequently, Justice Douglas argued that the constitution included \"penumbral rights of privacy and repose.\" Justice Douglas also remarked that without \"peripheral rights,\" the \"specific rights\" enumerated in the constitution would be \"less secure\". According to Burr Henly, Justice Douglas' majority opinion did not use the term to identify the articulable boundaries of language and the law, as Justice Holmes had done, but rather to connect the text of the constitution to unenumerated rights.\n\nHelen Hershkoff has described penumbral reasoning as \"an important feature of American constitutional practice in cases involving individual rights and government power\", and J. Christopher Rideout notes that many scholars have defended the \"conceptual integrity\" of penumbral reasoning. Likewise, Burr Henly has described the penumbra as \"the most important\" metaphor in American constitutional jurisprudence. Other scholars, including Judge A. Raymond Randolph of the United States Court of Appeals for the District of Columbia Circuit and historian David J. Garrow, also note that Justice Douglas' identification of the right to privacy in \"Griswold\" ultimately served as a doctrinal stepping-stone to \"Roe v. Wade\", where the United States Supreme Court ruled that the right to privacy protects the right to terminate a pregnancy.\n\nGlenn H. Reynolds has also observed that courts routinely engage in penumbral reasoning, regardless of their location on the political spectrum. However, Ninth Circuit Judge Alex Kozinski and UCLA School of Law professor Eugene Volokh note that the use of penumbral reasoning by courts \"cuts both ways\" because it can be used to both expand individual liberties and to expand the powers of the government at the expense of individual liberty. Richard E. Levy also argued that penumbral reasoning, fundamental rights analyses, and political-process theory can justify judicial intervention on behalf of individual liberty as well as judicial intervention to advance economic interests.\n\nDespite the \"pivotal\" role that penumbral reasoning has played in American constitutional jurisprudence, the Supreme Court's use of penumbral reasoning has also generated controversy. District of Columbia Circuit Judge Robert Bork, for example, was a particularly vocal critic of Supreme Court rulings that identified rights that are not explicitly enumerated in the text of the constitution. Likewise, in his dissenting opinion in \"Griswold\", Justice Hugo Black stated his concerns with finding a right to privacy in the penumbra of the constitution and that he disagreed with the majority's attempts to \"stretch\" the Bill of Rights. Additionally, Louis J. Sirico Jr. has described the term as \"intellectually confusing\", and William J. Watkins, Jr. wrote that the penumbra of the constitution is \"a seemingly strange place to discover constitutional guarantees\". Robert J. Pushaw Jr. also described penumbral reasoning as a \"transparently fictional\" process, and Jennifer Fahnestock has cautioned that \"implicit constitutional rights\" are vulnerable to being lost \"due to their lack of permanency\".\n\n"}
{"id": "27705822", "url": "https://en.wikipedia.org/wiki?curid=27705822", "title": "Putative father registry", "text": "Putative father registry\n\nIn the United States, the putative father registry is a state level legal option for unmarried men to document through a notary public any woman they engage with in intercourse, for the purpose of retaining parental rights for any child they may father.\n\nIn the United States, putative fathers will be notified when actions to terminate their parental rights as part of adoption proceedings are filed for a child they may have fathered and registered for. \nNon marital fathers are not guaranteed notice of an adoption or any rights in contesting the decision by the mother, nor are they guaranteed the ability to adopt or gain custody of the child. Typically, the father is only guaranteed notification, and the right to appear in court to testify about their child's best interests where he has registered timely. Registering timely with a state’s putative father registry guarantees notice. Timely legal establishment of paternity typically guarantees notice and an opportunity to be heard and may confer rights to consent or withhold consent to adoption. Prenatal support of the mother and fetus assures recognition of parental rights in 34 states.\n\nThere is no federal law in place regulating putative father registries. \nAmong all signatory countries only the United States refuses to ratify the Convention on the Rights of the Child and registries are not regulated under the U.N. Charter. Currently 33 states in the U.S. have putative father registries. The number of children adopted without consent or notice to the biological father under the registry program started in the 1970s is unknown.\n\nState putative father registries are intended to protect the non marital father from fraud by providing him with legal notice of a planned adoption of a child, provided he registers within a limited time-frame, usually any time prior to the birth or from 1 to 31 days after a birth. \nLack of knowledge of the pregnancy or birth is not an acceptable reason for failure to file; fraud by the birth mother typically does extend the father’s time to register.\n\nSome states require a putative father to file with multiple states, i.e. with the state possible conception might have occurred, state of residence (if different) and possible states the female might visit, \nor relocate to after the possible conception date that also have putative father registries. \nTo be valid at least one state requires a parent or guardian of the declarant to also sign when a minor under the age of 18 is documenting intercourse with a putative father registry.\n\n17 states (Alaska, California, Colorado, Connecticut, Hawaii, Kentucky, Maine, Maryland, Mississippi, Nevada, New Jersey, North Carolina, North Dakota, Rhode Island, South Dakota, Washington, West Virginia), as well as American Samoa, District of Columbia, Guam, Northern Mariana Islands, Puerto Rico, and the Virgin Islands, do not have putative father registries.\n\nPutative father registries are not always called such by individual states. Other names for registries include:\n\n\n\n\"20 states with a putative father registry and registration forms publicly posted online:\"\n\n\n\"13 states with a putative registry and no registration forms publicly posted online:\"\n\n\n"}
{"id": "25975", "url": "https://en.wikipedia.org/wiki?curid=25975", "title": "Reign of Terror", "text": "Reign of Terror\n\nThe Reign of Terror, or The Terror (), is the label given by most historians to a period during the French Revolution after the First French Republic was established.\n\nSeveral historians consider the \"reign of terror\" to have begun in 1793, placing the starting date at either 5 September, June or March (birth of the Revolutionary Tribunal), while some consider it to have begun in September 1792 (September Massacres), or even July 1789 (when the first lynchings took place), but there is a consensus that it ended with the fall of Maximilien Robespierre in July 1794.\n\nBetween June 1793 and the end of July 1794, there were 16,594 official death sentences in France, of which 2,639 were in Paris.\n\nThere was a sense of emergency among leading politicians in France in the summer of 1793 between the widespread civil war and counter-revolution. Bertrand Barère exclaimed on 5 September 1793 in the Convention: \"Let's make terror the order of the day!\" They were determined to avoid street violence such as the September Massacres of 1792 by taking violence into their own hands as an instrument of government.\n\nRobespierre in February 1794 in a speech explained the necessity of terror:\nSome historians argue that such terror was a necessary reaction to the circumstances. Others suggest there were additional causes, including ideological and emotional.\n\nEnlightenment thought emphasized the importance of rational thinking and began challenging legal and moral foundations of society, providing the leaders of the Terror with new ideas about the role and structure of government. Rousseau's Social Contract argued that each person was born with rights, and they would come together to form a government that would then protect those rights. Under the social contract, the government was required to act for the general will, which represented the interests of everyone rather than a few factions. Drawing from the idea of a general will, Robespierre felt that the French Revolution could result in a Republic built for the general will but only once those who fought this ideal were expelled. Those who resisted the government were deemed \"tyrants\" fighting against the virtue and honor of the general will. The leaders felt their ideal version of government was threatened from the inside and outside of France, and terror was the only way to preserve the dignity of the Republic created from French Revolution.\n\nRobespierre's ideology was not strictly derived from Rousseau. The writings of another Enlightenment thinker of the time, Baron de Montesquieu, greatly influenced Robespierre. One of Montesquieu’s writings, \"The Spirit of the Laws\", defines a core principle of a democratic government: virtue. He describes it as “the love of laws and of our country.” In Robespierre’s speech to theNational Convention on February 5, 1794, \"On Political Morality\", he talks about virtue being the “fundamental principle of popular or democratic government.\" This was, in fact, the same virtue defined by Montesquieu almost 50 years earlier. Robespierre believed that the virtue needed for any democratic government was extremely lacking in the French people. As a result, he decided to weed out those he believed could never possess this virtue. The result was a continual push towards Terror. The Convention used this as justification for the course of action to “crush the enemies of the revolution, ... let the laws be executed, … and let liberty be saved.”\n\nThese members of the Enlightenment movement greatly influenced revolutionary leaders; however, cautions from other Enlightenment thinkers were blatantly ignored. Voltaire’s warnings were often overlooked, though some of his ideas were used for justification of the Revolution and the start of the Terror. He protested against Catholic Dogmas and the ways of Christianity stating, “of all religions, the Christian should of course inspire the most toleration, but till now the Christians have been the most intolerant of all men.” These criticisms were often used by Robespierre and other leaders as justification for their anti-religious reforms. Voltaire also laid down some warnings. In his \"Philosophical Dictionary\", he states, “we are all steeped in weakness and error; let us forgive each other our follies; that is the first law of nature” and “every individual who persecutes a man, his brother, because he is not of his opinion, is a monster.\" The importance of forgiveness and understanding the failings of the human conditions were obviously lost on Robespierre and other leaders as they pursued Terror.\n\nAfter the beginning of the French Revolution, the surrounding monarchies did not show great hostility towards the rebellion. Though mostly ignored, Louis XVI was later able to find support in Leopold II of Austria (Marie Antionette’s brother) and Frederick William II of Prussia. On August 27, 1791, these foreign leaders made the Pillnitz Declaration saying they would restore the French monarch if other European rulers joined. In response to what they viewed to be the meddling of foreign powers, France declared war on April 20, 1792. However, at this point, the war was only Prussia and Austria against France. France began this war with a large series of defeats which set a precedent of fear of invasion in the people that would last throughout the war. Massive reforms of military institutions, while very effective in the long run, presented the initial problems of inexperienced forces and leaders of questionable political loyalty. In the time it took for officers of merit to use their new freedoms to climb the chain of command, France suffered. Many of the early battles were definitive losses for the French. There was the constant threat of the Austro-Prussian forces which were advancing easily toward the capital, threatening to destroy Paris if the monarch was harmed. This series of defeats, coupled with militant uprisings and protests within the borders of France pushed the government to resort to drastic measures to ensure the loyalty of every citizen to not only France but more importantly to the Revolution.\n\nWhile this series of losses was eventually broken, the reality of what might have happened if they persisted hung over France. The tide would not turn from them until September of 1792 when the French won a critical victory at Valmy preventing the Austro-Prussian invasion. While the French military had stabilized and was producing victories by the time the Reign of Terror officially began, the pressure to succeed in this international struggle acted as justification for the government to pursue its tyrannical actions. It was not until after the execution of Louis XVI and the annexation of the Rhineland that the other monarchies began to feel threatened enough to form the First Coalition. The Coalition, consisting of Russia, Austria, Prussia, Spain, Holland, and Sardinia, began attacking France from all directions besieging and capturing ports and retaking ground lost to France. With so many similarities to the first days of the Revolutionary Wars, the French government with threats on all sides, unification of the country became a top priority. As the war continued and the Reign of Terror began, leaders saw a correlation between using terror and achieving victory. Well phrased by Albert Soboul, “terror, at first an improvised response to defeat, once organized became an instrument of victory.” The threat of defeat and foreign invasion may have helped spur the origins of the terror, but the timely success of the Terror with French victories added justification to its growth and continuation.\n\nDuring the Reign of Terror, the sans-culottes and the Hébertists put pressure on the National Convention delegates and contributed to the overall instability of France. The National Convention was bitterly split between the Montagnards and the Girondins. The Girondins were more conservative leaders of the National Convention, while the Montagnards supported radical violence and pressures of the lower classes. Once the Montagnards gained control of the National Convention, they began demanding radical measures. Moreover, the sans-culottes, the scrappy, urban workers of France, agitated leaders to inflict punishments on those who opposed the interests of the poor. The sans-culottes’ violent demonstrations pushing their demands, created constant pressure for the Montagnards to enact reform. The sans-culottes fed the frenzy of instability and chaos by utilizing popular pressure during the Revolution. For example, the sans-culottes sent letters and petitions to the Committee of Public Safety urging them to protect their interests and rights with measures such as taxation of foodstuffs that favored workers over the rich. They advocated for arrests of those deemed to oppose reforms against those with privilege, and the more militant members would advocate pillage in order to achieve the desired equality. The resulting instability caused problems that made forming the new Republic and achieving full political support even more critical.\n\nThe Reign of Terror was characterized by a dramatic rejection of long-held religious authority, its hierarchical structure, and the corrupt and intolerant influence of the aristocracy and clergy. Religious elements that long stood as symbols of stability for the French people, were replaced by reason and scientific thought. The radical revolutionaries and their supporters desired a cultural revolution that would rid the French state of all Christian influence. This process began with the fall of the monarchy, an event that effectively defrocked the State of its sanctification by the clergy via the doctrine of Divine Right and ushered in an era of reason.\n\nMany long-held rights and powers were stripped from the Church and given to the State. In 1789, church lands were expropriated and priests killed and forced to leave France. A Festival of Reason was held in the Notre Dame Cathedral, which was renamed \"The Temple of Reason\", and the old traditional calendar was replaced with a new revolutionary one. The leaders of the Terror tried to address the call for these radical, revolutionary aspirations, while at the same time trying to maintain tight control on the de-Christianization movement that was threatening to the clear majority of the still devoted Catholic population of France. The tension sparked by these conflicting objectives laid a foundation for the \"justified\" use of terror to achieve revolutionary ideals and rid France of the religiosity that revolutionaries believed was standing in the way.\n\nOn 10 March 1793 the National Convention created the Revolutionary Tribunal. Among those charged by the tribunal, about a half were acquitted (though the number dropped to about a quarter after the enactment of the Law of 22 Prairial). In March rebellion broke out in the Vendée in response to mass conscription, which developed into a civil war that lasted until after the Terror.\n\nOn 6 April the Committee of Public Safety was created, which gradually became the de facto war-time government.\n\nOn 2 June, the Parisian sans-culottes surrounded the National Convention, calling for administrative and political purges, a low fixed price for bread, and a limitation of the electoral franchise to sans-culottes alone. With the backing of the national guard, they persuaded the convention to arrest 29 Girondist leaders. In reaction to the imprisonment of the Girondin deputies, some thirteen departments started the Federalist revolts against the National Convention in Paris, which were ultimately crushed. \n\nOn 24 June, the convention adopted the first republican constitution of France, the French Constitution of 1793. It was ratified by public referendum, but never put into force.\n\nOn 13 July the assassination of Jean-Paul Marat – a Jacobin leader and journalist – resulted in a further increase in Jacobin political influence. Georges Danton, the leader of the August 1792 uprising against the king, was removed from the committee. On July 27, 1793, Robespierre became part of the Committee of Public Safety. \n\nOn 23 August, the National Convention decreed the levée en masse, \"The young men shall fight; the married man shall forge arms and transport provisions; the women shall make tents and clothes and shall serve in the hospitals; the children shall turn all lint into linen; the old men shall betake themselves to the public square in order to arouse the courage of the warriors and preach hatred of kings and the unity of the Republic.\"\nOn 9 September, the convention established paramilitary forces, the \"revolutionary armies\", to force farmers to surrender grain demanded by the government. On 17 September, the Law of Suspects was passed, which authorized the imprisonment of vaguely defined \"suspects\". This created a mass overflow in the prison systems. On 29 September, the convention extended price fixing from grain and bread to other essential goods, and also fixed wages.\n\nOn 10 October, the Convention decreed that \"the provisional government shall be revolutionary until peace.\" On 24 October, the French Republican Calendar was enacted. The trial of the Girondins started on the same day and they were executed on 31 October.\n\nAnti-clerical sentiments increased during 1793 and a campaign of dechristianization occurred. On 10 November (20 Brumaire Year II of the French Republican Calendar), the Hébertists organized a Festival of Reason.\nOn 14 Frimaire (5 December 1793) was passed the Law of Frimaire, which gave the central government more control over the actions of the representatives on mission.\n\nOn 16 Pluviôse (4 February 1794), the National Convention decreed that slavery be abolished in all of France and French colonies.\n\nOn 8 and 13 Ventôse (26 February and 3 March), Saint-Just proposed decrees to confiscate the property of exiles and opponents of the revolution, known as the Ventôse Decrees.\n\nBy the end of 1793, two major factions had emerged, both threatening the Revolutionary Government: the Hébertists, who called for an intensification of the Terror and threatened insurrection, and the Dantonists, led by Georges Danton, who demanded moderation and clemency. The Committee of Public Safety took actions against both. The major Hébertists were tried before the Revolutionary Tribunal and executed on 24 March. The Dantonists were arrested on 30 March, tried on 3 to 5 April and executed on 5 April.\n\nOn 20 Prairial (8 June) was celebrated across the country the Festival of the Supreme Being, which was part of the Cult of the Supreme Being, a deist national religion. On 22 Prairial (10 June), the National Convention passed a law proposed by Georges Couthon, known as the Law of 22 Prairial, which simplified the judicial process and greatly accelerated the work of the Revolutionary Tribunal. With the enactment of the law, the number of executions greatly increased, and the period from this time to the Thermidorian Reaction became known as \"The Grand Terror\".\n\nOn 8 Messidor (26 June), the French army won the Battle of Fleurus, which marked a turning point in France's military campaign and undermined the necessity of wartime measures and the legitimacy of the Revolutionary Government.\n\nThe fall of Robespierre was brought about by a combination of those who wanted more power for the Committee of Public Safety (and a more radical policy than he was willing to allow) and the moderates who completely opposed the revolutionary government. They had, between them, made the Law of 22 Prairial one of the charges against him, so that, after his fall, to advocate terror would be seen as adopting the policy of a convicted enemy of the republic, putting the advocate's own head at risk. Between his arrest and his execution, Robespierre may have tried to commit suicide by shooting himself, although the bullet wound he sustained, whatever its origin, only shattered his jaw. Alternatively, he may have been shot by the gendarme Merda. The great confusion that arose during the storming of the municipal Hall of Paris, where Robespierre and his friends had found refuge, makes it impossible to be sure of the wound's origin.\nIn any case, Robespierre was guillotined the next day.\n\nThe reign of the standing Committee of Public Safety was ended. New members were appointed the day after Robespierre's execution, and limits on terms of office were fixed (a quarter of the committee retired every three months). The Committee's powers were gradually eroded.\n\n\n\"Battle of Valmy, (20 September 1792).\" Weapons and Warfare. April 09, 2018. Accessed October 30, 2018. https://weaponsandwarfare.com/2018/04/10/battle-of-valmy-20-september-1792/.\n\nBloy, Marjorie. \"The First Coalition 1793-1797.\" A Web of English History. Accessed October 21, 2018. http://www.historyhome.co.uk/c-eight/france/coalit1.htm.\n\nLeopold, II, and Frederick William. \"The Declaration of Pillnitz (1791).\" French Revolution. February 27, 2018. Accessed October 26, 2018. https://alphahistory.com/frenchrevolution/declaration-of-pillnitz-1791/.\nMcLetchie, Scott. \"Maximilien Robespierre, Master of the Terror.\" Maximilien Robespierre, Master of the Terror. Accessed October 23, 2018. http://people.loyno.edu/~history/journal/1983-4/mcletchie.htm#22.\n\nMontesquieu. \"Modern History Sourcebook: Montesquieu: The Spirit of the Laws, 1748.\" Internet History Sourcebooks. Accessed October 23, 2018. https://sourcebooks.fordham.edu/mod/montesquieu-spirit.asp.\n\nOzouf, Mona. \"War and Terror in French Revolutionary Discourse (1792-1794).\" \"The Journal of Modern History\" 56, no. 4 (1984): 580-97. http://www.jstor.org.du.idm.oclc.org/stable/1880323.\n\nPopkin, Jeremy D. \"A Short History of the French Revolution\". 6th ed. London: Routledge, 2016. \n\n“Robespierre, \"On Political Morality\",” Liberty, Equality, Fraternity, accessed October 19, 2018, \nhttp://chnm.gmu.edu/revolution/d/413.\nRothenberg, Gunther E. \"The Origins, Causes, and Extension of the Wars of the French Revolution and Napoleon.\" \"The Journal of Interdisciplinary History 18 \", no. 4 (1988): 771-93. doi:10.2307/204824. https://www.jstor.org/stable/204824.\n\n“\"Terror Is the Order of the Day\",” \"Liberty, Equality, Fraternity\", accessed October 26, 2018, http://chnm.gmu.edu/revolution/d/416.\n\nVoltaire. \"Voltaire, Selections from the Philosophical Dictionary.\" Omeka RSS. Accessed October 23, 2018. http://chnm.gmu.edu/revolution/d/273/.\n\n"}
{"id": "2063841", "url": "https://en.wikipedia.org/wiki?curid=2063841", "title": "Rob Dibble", "text": "Rob Dibble\n\nRobert Keith Dibble (born January 24, 1964) is an American former Major League Baseball (MLB) pitcher and television analyst. Between 1988 and 1995, Dibble played for the Cincinnati Reds, Chicago White Sox and Milwaukee Brewers. He was a two-time All-Star who recorded 89 saves during his career. Since retiring as a player, Dibble has held several roles in sports television broadcasting.\n\nDibble was born in Bridgeport, Connecticut. He attended St. Thomas School, a parochial school, and is a graduate of Southington High School in Southington, Connecticut. Dibble's father, Walt Dibble, was a longtime radio news director at WDRC and later WTIC in Hartford, Connecticut.\n\nDibble was drafted by the Cincinnati Reds in the first round of the 1983 amateur draft, and he made his debut with the Reds on June 29, 1988.\n\nOn June 4, 1989, Dibble struck out three batters on nine pitches in the eighth inning of a 5–3 win over the San Diego Padres. Dibble is one of 41 pitchers in Major League history to accomplish the nine-pitch/three-strikeout half-inning, a feat known as an immaculate inning.\n\nHe was an MLB All-Star in 1990 and 1991, and was the 1990 NLCS Most Valuable Player (along with fellow \"Nasty Boy\" Randy Myers). In 1990, Dibble and the Reds won the World Series by beating the Oakland Athletics in four consecutive games.\n\nDibble recorded his 500th career strikeout in fewer innings—368—than any other pitcher in modern baseball history up to that point (a record that is currently held by Craig Kimbrel).\n\nDuring his career Dibble was known for his temper. During a game in July 1989, he hit Mets second basemen Tim Teufel in the back with a pitch; Teufel then charged Dibble, causing a benches clearing brawl. After saving a game in April 1991 despite giving up two runs in relief, Dibble threw a baseball 400 feet into the center-field seats at Cincinnati, inadvertently striking a woman. He was also involved in a brawl in 1991 with Astros shortstop Eric Yelding. Later in the 1991 season, he threw a baseball into the back of Cubs outfielder Doug Dascenzo as he ran down the first base line and was subsequently ejected from the game. Dibble also was involved in a brawl with manager Lou Piniella in the Reds clubhouse after a game in 1992.\n\nDibble required surgery to his pitching arm in 1994, and missed the entire season as a result. Dibble signed with the Milwaukee Brewers and also played with the Chicago White Sox. He signed with the Chicago Cubs at the end of the 1995 season, but voluntarily retired from the team the following March after a rough spring. Weeks later, he opted to make a comeback, signing a minor league contract on April 14, 1996 with the Florida Marlins, but Dibble would ultimately see no game action with the Marlins or their minor league affiliates.\n\nIn 1998, Dibble joined ESPN as a baseball analyst, working mostly on Dan Patrick's radio show. He worked on \"The Best Damn Sports Show Period\" as a co-host until 2008, when he left to join FOX on their Saturday baseball program as an analyst. Dibble also spends time as a co-host/analyst of First Pitch on XM Channel 175/Sirius channel 210. He formerly hosted \"The Show\" (on the same channel) with Jody McDonald. Dibble served as co-analyst (with Kevin Kennedy) for FOXSports.com on a weekly video segment entitled \"Around the Bases.\" Dibble also is a co-host with former Major League player Denny Hocking on Fox Sports Radio Sunday night programming. In 2009, Dibble signed a three-year contract to replace Don Sutton as the color voice of the Washington Nationals on MASN.\n\nWhile broadcasting a game in August 2010, Dibble drew negative attention for focusing on a group of female spectators in the Nationals crowd, and questioning their focus on the game. He later apologized for the comments. Later in the month, Dibble criticized Nationals rookie pitcher Stephen Strasburg for missing a start due to an injury: \"Suck it up, kid. This is your profession. You chose to be a baseball player. You can't have the cavalry come in and save your butt every time you feel a little stiff shoulder, sore elbow.\" It was revealed shortly afterward that Strasburg had torn an elbow ligament and required Tommy John surgery. Dibble took a few days off from MASN after making the comments, and on September 1, 2010, MASN announced that Dibble would no longer be calling Nationals games. After losing his job with the Nationals, Dibble apologized for the Strasburg comments on his radio show.\n\nIn April 2011, Dibble said in an interview on FoxSports.com that the reason for his dismissal was because of an email Strasburg's father sent to the Lerner Family, the owners of the Nationals. Dibble also continued to express his belief that Strasburg should have pitched through his pain. Strasburg denied the claim about his father's e-mail, and Stan Kasten, the president of the Nationals, called Dibble's account \"fictional\" and \"sad\". As of October 31, 2011, Dibble became a member of Mike North's talk radio show.\n\nDibble had a brief stint as the varsity baseball head coach at Calabasas High School in Calabasas, California. He was fired from his head coaching job on March 27, 2013, only ten games into the season. As of December 18, 2013, he, along with Amy Van Dyken, were replaced on Fox Sports Radio's \"Fox Sports Tonight\".\n\nDibble currently calls Los Angeles Angels games for Compass Media.\n\nOn March 27, 2014, Dibble became the host of the 3–7 pm (Eastern) sports talk show on WUCS 97.9 FM and WAVZ 1300 AM in the ESPN stations in Hartford and New Haven, CT respectively. He joined interim host Paul Nanos who filled in when Mike Bower's contract was not renewed. Up until the end of October the show was billed as \"The Rob Dibble Show with Paul Nanos\". In October, the show was renamed \"The Rob Dibble Show\".[26]\n\n\n26. Radio Online March 30,2014\n"}
{"id": "50398478", "url": "https://en.wikipedia.org/wiki?curid=50398478", "title": "Selection principle", "text": "Selection principle\n\nIn mathematics, a selection principle is a rule asserting\nthe possibility of obtaining mathematically significant objects by \nselecting elements from given sequences of sets. The theory of selection principles\nstudies these principles and their relations to other mathematical properties.\nSelection principles mainly describe covering properties, \nmeasure- and category-theoretic properties, and local properties in \ntopological spaces, especially function spaces. Often, the \ncharacterization of a mathematical property using a selection \nprinciple is a nontrivial task leading to new insights on the \ncharacterized property.\n\nIn 1924, Karl Menger\nintroduced the following basis property for metric spaces: \nEvery basis of the topology contains a sequence of sets with vanishing \ndiameters that covers the space. Soon thereafter, \nWitold Hurewicz \nobserved that Menger's basis property is equivalent to the \nfollowing selective property: for every sequence of open covers of the space, \none can select finitely many open sets from each cover in the sequence, such that the selected sets cover the space.\nTopological spaces having this covering property are called Menger spaces.\n\nHurewicz's reformulation of Menger's property was the first important \ntopological property described by a selection principle. \nLet formula_1 and formula_2 be classes of mathematical objects.\nIn 1996, Marion Scheepers \nintroduced the following selection hypotheses,\ncapturing a large number of classic mathematical properties:\n\n\nIn the case where the classes formula_1 and formula_2 consist of covers of some ambient space, Scheepers also introduced the following selection principle.\n\n\nLater, Boaz Tsaban identified the prevalence of the following related principle:\n\nThe notions thus defined are \"selection principles\". An instantiation of a selection principle, by considering specific classes formula_1 and formula_2, gives a \"selection (or: selective) property\". However, these terminologies are used interchangeably in the literature.\n\nFor a set formula_25 and a family formula_26 of subsets of formula_27, the star of formula_28 in formula_26 is the set formula_30.\n\nIn 1999, Ljubisa D.R. Kocinac introduced the following \"star selection principles\":\n\n\nCovering properties form the kernel of the theory of selection principles. Selection properties that are not covering properties are often studied by using implications to and from selective covering properties of related spaces.\n\nLet formula_27 be a topological space. An \"open cover\" of formula_27 is a family of open sets whose union is the entire space formula_43 For technical reasons, we also request that the entire space formula_27 is not a member of the cover. The class of open covers of the space formula_27 is denoted by formula_46. (Formally, formula_47, but usually the space formula_27 is fixed in the background.) The above-mentioned property of Menger is, thus, formula_49. In 1942, Fritz Rothberger considered Borel's strong measure zero sets, and introduced a topological variation later called Rothberger space (also known as \"Cformula_50 space\"). In the notation of selections, Rothberger's property is the property formula_51.\n\nAn open cover formula_52 of formula_27 is point-cofinite if it has infinitely many elements, and every point formula_54 belongs to all but finitely many sets formula_55. (This type of cover was considered by Gerlits and Nagy, in the third item of a certain list in their paper. The list was enumerated by Greek letters, and thus these covers are often called formula_56-covers.) The class of point-cofinite open covers of formula_27 is denoted by formula_58. A topological space is a Hurewicz space if it satisfies formula_59.\n\nAn open cover formula_52 of formula_27 is an formula_62-cover if every finite subset of formula_27 is contained in some member of formula_52. The class of formula_62-covers of formula_27 is denoted by formula_67. A topological space is a γ-space if it satisfies formula_68.\n\nBy using star selection hypotheses one obtains properties such as star-Menger (formula_69), star-Rothberger (formula_70) and star-Hurewicz (formula_71).\n\nThere are 36 selection properties of the form formula_72, for formula_73 and formula_74. Some of them are trivial (hold for all spaces, or fail for all spaces). Restricting attention to Lindelöf spaces, the diagram below, known as the \"Scheepers Diagram\", presents nontrivial selection properties of the above form, and every nontrivial selection property is equivalent to one in the diagram. Arrows denote implications.\n\nSelection principles also capture important non-covering properties.\n\nLet formula_75 be a topological space, and formula_76. The class of sets formula_28 in the space formula_75 that have the point formula_79 in their closure is denoted by formula_80. The class formula_81 consists of the \"countable\" elements of the class formula_80. The class of sequences in formula_75 that converge to formula_79 is denoted by formula_85.\n\n\nThere are close connections between selection principles and Topological Games.\n\nLet formula_27 be a topological space. The Menger game formula_102 played on formula_27 is a game for two players, Alice and Bob. It has an inning per each natural number formula_104. At the formula_105 inning, Alice chooses an open cover formula_106 of formula_27,\nand Bob chooses a finite subset formula_108 of formula_52. \nIf the family formula_110 is a cover of the space formula_27, then Bob wins the game. Otherwise, Alice wins.\n\nA strategy for a player is a function determining the move of the player, given the earlier moves of both players. A strategy for a player is a winning strategy if each play where this player sticks to this strategy is won by this player.\n\nIn a similar way, we define games for other selection principles from the given Scheepers Diagram. In all these cases a topological space has a property from the Scheepers Diagram if and only if Alice has no winning strategy in the corresponding game.\n\n\nSubsets of the real line formula_125 (with the induced subspace topology) holding selection principle properties, most notably Menger and Hurewicz spaces, can be characterized by their continuous images in the Baire space formula_126. For functions formula_127, write formula_128 if formula_129 for all but finitely many natural numbers formula_130. Let formula_28 be a subset of formula_126. The set formula_133 is bounded if there is a function formula_134 such that formula_135 for all functions formula_136. The set formula_133 is dominating if for each function formula_138 there is a function formula_139 such that formula_135.\n\n\nLet P be a property of spaces. A space formula_27 is productively P if, for each space formula_75 with property P, the product space formula_146 has property P.\n\n\n\nLet formula_27 be a Tychonoff space, and formula_155 be the space of continuous functions formula_156 with pointwise convergence topology. \n\n"}
{"id": "1941913", "url": "https://en.wikipedia.org/wiki?curid=1941913", "title": "Self-knowledge (psychology)", "text": "Self-knowledge (psychology)\n\nSelf-knowledge is a term used in psychology to describe the information that an individual draws upon when finding an answer to the question \"What am I like?\".\n\nWhile seeking to develop the answer to this question, self-knowledge requires ongoing self-awareness and self-consciousness (which is not to be confused with consciousness). Young infants and chimpanzees display some of the traits of self-awareness and agency/contingency, yet they are not considered as also having self-consciousness. At some greater level of cognition, however, a self-conscious component emerges in addition to an increased self-awareness component, and then it becomes possible to ask \"What am I like?\", and to answer with self-knowledge.\n\nSelf-knowledge is a component of the self or, more accurately, the self-concept. It is the knowledge of oneself and one's properties and the \"desire\" to seek such knowledge that guide the development of the self-concept. Self-knowledge informs us of our mental representations of ourselves, which contain attributes that we uniquely pair with ourselves, and theories on whether these attributes are stable or dynamic.\n\nThe self-concept is thought to have three primary aspects:\n\nThe affective and executive selves are also known as the \"felt\" and \"active\" selves respectively, as they refer to the emotional and behavioral components of the self-concept.\nSelf-knowledge is linked to the cognitive self in that its motives guide our search to gain greater clarity and assurance that our own self-concept is an accurate representation of our \"true self\"; for this reason the cognitive self is also referred to as the \"known self\". The cognitive self is made up of everything we know (or \"think we know\" about ourselves). This implies physiological properties such as hair color, race, and height etc.; and psychological properties like beliefs, values, and dislikes to name but a few.\n\nSelf-knowledge and its structure affect how events we experience are encoded, how they are selectively retrieved/recalled, and what conclusions we draw from how we interpret the memory. The analytical interpretation of our own memory can also be called \"meta memory\", and is an important factor of \"meta cognition\".\n\nThe connection between our memory and our self-knowledge has been recognized for many years by leading minds in both philosophy and psychology, yet the precise specification of the relation remains a point of controversy.\n\n\nSelf-theories have traditionally failed to distinguish between different source that inform self-knowledge, these are \"episodic memory\" and \"semantic memory\". Both episodic and semantic memory are facets of \"declarative memory\", which contains memory of facts. Declarative memory is the explicit counterpart to \"procedural memory\", which is implicit in that it applies to skills we have learnt; they are not \"facts\" that can be \"stated\".\n\nEpisodic memory is the autobiographical memory that individuals possess which contains events, emotions, and knowledge associated with a given context.\n\nSemantic memory does not refer to concept-based knowledge stored about a specific experience like episodic memory. Instead it includes the memory of meanings, understandings, general knowledge about the world, and factual information etc. This makes semantic knowledge independent of context and personal information. Semantic memory enables an individual to know information, including information about their selves, without having to consciously recall the experiences that taught them such knowledge.\n\nPeople are able to maintain a sense of self that is supported by semantic knowledge of personal facts in the absence of direct access to the memories that describe the episodes on which the knowledge is based.\nThis evidence for the dissociation between episodic and semantic self-knowledge has made several things clear:\n\nPeople have goals that lead them to seek, notice, and interpret information about themselves. These goals begin the quest for self-knowledge.\nThere are three primary motives that lead us in the search for self-knowledge:\n\nSelf-enhancement refers to the fact that people seem motivated to experience positive emotional states and to avoid experiencing negative emotional states. People are motivated to feel good about themselves in order to maximize their feelings of self-worth, thus enhancing their self-esteem.\nThe emphasis on \"feelings\" differs slightly from how other theories have previously defined self-enhancement needs, for example the \"Contingencies of Self-Worth Model\".\nOther theorists have taken the term to mean that people are motivated to think about themselves in highly favorable terms, rather than feel they are \"good\".\nIn many situations and cultures, feelings of self-worth are promoted by thinking of oneself as highly capable or \"better\" than one's peers. However, in some situations and cultures, feelings of self-worth are promoted by thinking of oneself as \"average\" or even \"worse\" than others. In both cases, thoughts about the self still serve to enhance feelings of self-worth.\nThe universal need is not a need to think about oneself in any specific way, rather a need to maximize one's feelings of self-worth. This is the meaning of the self enhancement motive with respect to self-knowledge.\n\nIn Western societies, feelings of self-worth \"are\" in fact promoted by thinking of oneself in favorable terms.\n\nSee \"Self-verification theory\" section.\n\nAccuracy needs influence the way in which people search for self-knowledge. People frequently wish to know the truth about themselves without regard as to whether they learn something positive or negative.\nThere are three considerations which underlie this need:\nAccurate self-knowledge can also be instrumental in maximizing feelings of self-worth. Success is one of the number of things that make people feel good about themselves, and knowing what we are like can make successes more likely, so self-knowledge can again be adaptive. This is because self-enhancement needs can be met by knowing that one \"can not\" do something particularly well, thus protecting the person from pursuing a dead-end dream that is likely to end in failure.\n\nMany theorists believe that we have a motive to protect the self-concept (and thus our self-knowledge) from change. This motive to have consistency leads people to look for and welcome information that is consistent with what they believe to be true about themselves; likewise, they will avoid and reject information which presents inconsistencies with their beliefs. This phenomenon is also known as self-verification theory.\nNot everyone has been shown to pursue a self-consistency motive; but it has played an important role in various other influential theories, such as cognitive dissonance theory.\n\nThis theory was put forward by William Swann of the University of Texas at Austin in 1983 to put a name to the aforementioned phenomena. The theory states that once a person develops an idea about what they are like, they will strive to verify the accompanying self-views.\nTwo considerations are thought to drive the search for self-verifying feedback:\nThese factors of self-verification theory create controversy when persons suffering from low-self-esteem are taken into consideration. People who hold negative self-views about themselves \"selectively seek negative feedback\" in order to verify their self-views. This is in stark contrast to self-enhancement motives that suggest people are driven by the desire to feel good about themselves.\n\nThere are three sources of information available to an individual through which to search for knowledge about the self:\n\nThe physical world is generally a highly visible, and quite easily measurable source of information about one's self. Information one may be able to obtain from the physical world may include:\n\n\nThe comparative nature of self-views means that people rely heavily on the social world when seeking information about their selves. Two particular processes are important:\n\nPeople compare attributes with others and draw inferences about what they themselves are like. However, the conclusions a person ultimately draws depend on whom in particular they compare themselves with. The need for accurate self-knowledge was originally thought to guide the social comparison process, and researchers assumed that comparing with others who are similar to us in the \"important\" ways is more informative.\n\nPeople are also known to compare themselves with people who are slightly better off than they themselves are (known as an \"upward comparison\"); and with people who are slightly worse off or disadvantaged (known as a \"downward comparison\").\nThere is also substantial evidence that the need for \"accurate\" self-knowledge is neither the only, nor most important factor that guides the social comparison process, the need to feel good about ourselves affects the social comparison process.\n\nReflected appraisals occur when a person observes how others respond to them. The process was first explained by the sociologist Charles H. Cooley in 1902 as part of his discussion of the \"looking-glass self\", which describes how we see ourselves reflected in other peoples' eyes. He argued that a person's feelings towards themselves are socially determined via a three-step process:\n\n\"A self-idea of this sort seems to have three principled elements: the imagination of our appearance to the other person; the imagination of his judgment of that appearance; and some sort of self-feeling, such as pride or mortification. The comparison with a looking-glass hardly suggests the second element, the imagined judgment which is quite essential. The thing that moves us to pride or shame is not the mere mechanical reflection of ourselves, but an imputed sentiment, the imagined effect of this reflection upon another's mind.\" (Cooley, 1902, p.153)\n\nIn simplified terms, Cooley's three stages are:\nNote that this model is of a phenomenological nature.\n\nIn 1963, John W. Kinch adapted Cooley's model to explain how a person's \"thoughts\" about themselves develop rather than their \"feelings\".\n\nKinch's three stages were:\nThis model is also of a phenomenological approach.\n\nResearch has only revealed limited support for the models and various arguments raise their heads:\n\nThe sequence of reflected appraisals may accurately characterize patterns in early childhood due to the large amount of feedback infants receive from their parents, yet it appears to be less relevant later in life. This is because people are not passive, as the model assumes. People \"actively\" and \"selectively\" process information from the social world. Once a person's ideas about themselves take shape, these also influence the manner in which new information is gathered and interpreted, and thus the cycle continues.\n\nThe psychological world describes our \"inner world\". There are three processes that influence how people acquire knowledge about themselves:\n\nIntrospection involves looking inwards and directly consulting our attitudes, feelings and thoughts for meaning.\nConsulting one's own thoughts and feelings can sometimes result in meaningful self-knowledge. The accuracy of introspection, however, has been called into question since the 1970s. Generally, introspection relies on people's explanatory theories of the self and their world, the accuracy of which is not necessarily related to the form of self-knowledge that they are attempting to assess. \n\nComparing sources of introspection. People believe that spontaneous forms of thought provide more meaningful self-insight than more deliberate forms of thinking. Morewedge, Giblin, and Norton (2014) found that the more spontaneous a kind of thought, the more spontaneous a particular thought, and the more spontaneous thought a particular thought was perceived to be, the more insight into the self it was attributed. In addition, the more meaning the thought was attributed, the more the particular thought influenced their judgment and decision making. People asked to let their mind wander until they randomly thought of a person to whom they were attracted to, for example, reported that the person they identified provided them with more self-insight than people asked to simply think of a person to whom they were attracted to. Moreover, the greater self-insight attributed to the person identified by the (former) random thought process than by the latter deliberate thought process led those people in the random condition to report feeling more attracted to the person they identified.\n\nWhether introspection always fosters self-insight is not entirely clear. Thinking too much about why we feel the way we do about something can sometimes confuse us and undermine true self-knowledge. Participants in an introspection condition are less accurate when predicting their own future behavior than controls and are less satisfied with their choices and decisions. In addition, it is important to notice that introspection allows the exploration of the consious mind only, and does not take into account the unconscious motives and processes, as found and formulated by Freud. \n\nWilson's work is based on the assumption that people are not always aware of \"why\" they feel the way they do. Bem's self-perception theory makes a similar assumption.\nThe theory is concerned with how people \"explain\" their behavior. It argues that people don't always \"know\" why they do what they do. When this occurs, they infer the causes of their behavior by analyzing their behavior in the context in which it occurred. Outside observers of the behavior would reach a similar conclusion as the individual performing it. The individuals then draw logical conclusions about why they behaved as they did.\n\n\"Individuals come to \"know\" their own attitudes, emotions, and other internal states partially by inferring them from observations of their own overt behavior and/or the circumstances in which this behavior occurs. Thus, to the extent that internal cues are weak, ambiguous, or uninterpretable, the individual is functionally in the same position as an outside observer, an observer who must necessarily rely upon those same external cues to infer the individual's inner states.\" (Bem, 1972, p.2)\n\nThe theory has been applied to a wide range of phenomena. Under particular conditions, people have been shown to infer their attitudes, emotions, and motives, in the same manner described by the theory.\n\nSimilar to introspection, but with an important difference: with introspection we \"directly examine\" our attitudes, feelings and motives. With self-perception processes we \"indirectly infer\" our attitudes, feelings, and motives by \"analyzing our behavior\".\n\nCausal attributions are an important source of self-knowledge, especially when people make attributions for positive and negative events. The key elements in self-perception theory are explanations people give for their actions, these explanations are known as causal attributions.\n\nCausal attributions provide answers to \"Why?\" questions by attributing a person's behavior (including our own) to a cause.\n\nPeople also gain self-knowledge by making attributions for \"other people's\" behavior; for example \"If nobody wants to spend time with me it must be because I'm boring\".\n\nIndividuals think of themselves in many different ways, yet only some of these ideas are active at any one given time. The idea that is specifically active at a given time is known as the Current Self-Representation. Other theorists have referred to the same thing in several different ways:\nThe current self-representation influences information processing, emotion, and behavior and is influenced by both \"personal\" and \"situational\" factors.\n\nSelf-concept, or how people \"usually\" think of themselves is the most important personal factor that influences current self-representation. This is especially true for attributes that are important and self-defining.\n\nSelf-concept is also known as the self-schema, made of innumerable smaller self-schemas that are \"chronically accessible\".\n\nSelf-esteem affects the way people feel about themselves. People with high self-esteem are more likely to be thinking of themselves in positive terms at a given time than people suffering low self-esteem.\n\nMood state influences the accessibility of positive and negative self-views.\n\nWhen we are happy we tend to think more about our positive qualities and attributes, whereas when we are sad our negative qualities and attributes become more accessible.\n\nThis link is particularly strong for people suffering low self-esteem.\n\nPeople can deliberately activate particular self-views. We select appropriate images of ourselves depending on what role we wish to play in a given situation.\n\nOne particular goal that influences activation of self-views is the desire to feel good.\n\nHow a person thinks of themselves depends largely on the social role they are playing. Social roles influence our personal identities.\n\nPeople tend to think of themselves in ways that distinguish them from their social surroundings.\nDistinctiveness also influences the salience of group identities.\n\nThe size of the group affects the salience of group-identities. Minority groups are more distinctive, so group identity should be more salient among minority group members than majority group members.\n\nGroup status interacts with group size to affect the salience of social identities.\n\nThe social environment has an influence on the way people evaluate themselves as a result of social-comparison processes.\n\nPeople regard themselves as at the opposite end of the spectrum of a given trait to the people in their company. However, this effect has come under criticism as to whether it is a primary effect, as it seems to share space with the assimilation effect, which states that people evaluate themselves more positively when they are in the company of others who are exemplary on some dimension.\n\nImagining how one appears to others has an effect on how one thinks about oneself.\n\nRecent events can cue particular views of the self, either as a direct result of failure, or via mood.\nMemory for prior events influence how people think about themselves.\n\n\n\n\n\n"}
{"id": "18930", "url": "https://en.wikipedia.org/wiki?curid=18930", "title": "Subject (philosophy)", "text": "Subject (philosophy)\n\nA subject is a being who has a unique consciousness and/or unique personal experiences, or an entity that has a relationship with another entity that exists outside itself (called an \"object\").\n\nA \"subject\" is an observer and an \"object\" is a thing observed. This concept is especially important in Continental philosophy, where 'the subject' is a central term in debates over the nature of the self. The nature of the subject is also central in debates over the nature of subjective experience within the Anglo-American tradition of analytical philosophy.\n\nThe sharp distinction between subject and object corresponds to the distinction, in the philosophy of René Descartes, between thought and extension. Descartes believed that thought (subjectivity) was the essence of the mind, and that extension (the occupation of space) was the essence of matter.\n\n\"Subject\" as a key-term in thinking about human consciousness began its career with the German Idealists, in response to David Hume's radical skepticism. The idealists' starting point was Hume's conclusion that there is nothing to the self over and above a big, fleeting bundle of perceptions. The next step was to ask how this undifferentiated bundle comes to be experienced as a unity – as a single \"subject\". Hume had offered the following proposal:\n\nKant, Hegel and their successors sought to flesh out the process by which the subject is constituted out of the flow of sense impressions. Hegel, for example, stated in his Preface to the \"Phenomenology of Spirit\" that a subject is constituted by \"the process of reflectively mediating itself with itself.\"\n\nHegel begins his definition of the subject at a standpoint derived from Aristotelian physics: \"the unmoved which is also \"self-moving\"\" (Preface, para. 22). That is, what is not moved by an outside force, but which propels itself, has a \"prima facie\" case for subjectivity. Hegel's next step, however, is to identify this power to move, this unrest that is the subject, as \"pure negativity\". Subjective self-motion, for Hegel, comes not from any pure or simple kernel of authentic individuality, but rather, it is\n\nThe Hegelian subject's \"modus operandi\" is therefore cutting, splitting and introducing distinctions by injecting negation into the flow of sense-perceptions. Subjectivity is thus a kind of structural effect – what happens when Nature is diffused, refracted around a field of negativity and the \"unity of the subject\" for Hegel, is in fact a second-order effect, a \"negation of negation\". The subject experiences itself as a unity only by purposively negating the very diversity it itself had produced. The Hegelian subject may therefore be characterized either as \"self-restoring sameness\" or else as \"reflection in otherness within itself\" (Preface, para. 18).\n\nThe thinking of Karl Marx and Sigmund Freud provided a point of departure for questioning the notion of a unitary, autonomous Subject, which for many thinkers in the Continental tradition is seen as the foundation of the liberal theory of the social contract. These thinkers opened up the way for the deconstruction of the subject as a core-concept of metaphysics.\n\nSigmund Freud's explorations of the unconscious mind added up to a wholesale indictment of Enlightenment notions of subjectivity.\n\nAmong the most radical re-thinkers of human self-consciousness was Martin Heidegger, whose concept of \"Dasein\" or \"Being-there\" displaces traditional notions of the personal subject altogether. With Heidegger, phenomenology tries to go beyond the classical dichotomy between subject and object, because they are linked by an inseparable and original relationship, in the sense that there can be no world without a subject, nor the subject without world.\n\nJacques Lacan, inspired by Heidegger and Ferdinand de Saussure, built on Freud's psychoanalytic model of the subject, in which the \"split subject\" is constituted by a double bind: alienated from jouissance when he or she leaves the Real, enters into the Imaginary (during the mirror stage), and separates from the Other when he or she comes into the realm of language, difference, and demand in the Symbolic or the Name of the Father.\n\nThinkers such as structural Marxist Louis Althusser and poststructuralist Michel Foucault theorize the subject as a social construction, the so-called poststructuralist subject. According to Althusser, the \"subject\" is an ideological construction (more exactly, constructed by the \"Ideological State Apparatuses\"). One's subjectivity exists, \"always already\" and is discovered through the process of interpellation. Ideology inaugurates one into being a subject, and every ideology is intended to maintain and glorify its idealized subject, as well as the metaphysical category of the subject itself (see antihumanism). \n\nAccording to Foucault, it is the \"effect\" of power and \"disciplines\" (see \"Discipline and Punish\": construction of the subject (subjectivation or subjectification, ) as student, soldier, \"criminal\", etc.). Foucault believed it was possible to transform oneself; he used the word ethopoiein from the word \"ethos\" to describe the process. Subjectification was a central concept in Gilles Deleuze and Félix Guattari's work as well.\n\nIn contemporary analytic philosophy, the issue of subject—and more specifically the \"point of view\" of the subject, or \"subjectivity\"—has received attention as one of the major intractable problems in philosophy of mind (a related issue being the mind–body problem). In the essay \"What is it like to be a bat?\", Thomas Nagel famously argued that explaining subjective experience—the \"what it is like\" to be something—is currently beyond the reach of scientific inquiry, because scientific understanding by definition requires an objective perspective, which, according to Nagel, is diametrically opposed to the subjective first-person point of view. Furthermore, one cannot have a definition of objectivity without being connected to subjectivity in the first place since they are mutual and interlocked.\n\nIn Nagel's book \"The View From Nowhere\", he asks: \"What kind of fact is it that I am Thomas Nagel?\". Subjects have a perspective but each subject has a unique perspective and this seems to be a fact in Nagel's view from nowhere (i.e. the birds-eye view of the objective description in the universe). The Indian view of \"Brahman\" suggests that the ultimate and fundamental subject is existence itself, through which each of us as it were \"looks out\" as an aspect of a frozen and timeless everything, experienced subjectively due to our separated sensory and memory apparati. These additional features of subjective experience are often referred to as \"qualia\" (see Frank Cameron Jackson and Mary's room).\n\n\n"}
{"id": "58413483", "url": "https://en.wikipedia.org/wiki?curid=58413483", "title": "Substantive equality", "text": "Substantive equality\n\nSubstantive equality is a fundamental aspect of human rights law that is concerned with equitable outcomes and equal opportunities for disadvantaged and marginalized people and groups in society. Scholars define substantive equality as an output or outcome of the policies, procedures, and practices used by nation states and private actors in addressing and preventing systematic discrimination. Substantive equality recognizes that the law must take elements such as discrimination, marginalization, and unequal distribution into account in order to achieve equal results for basic human rights, opportunities, and access to goods and services. Substantive equality is primarily achieved by implementing special measures in order to assist or advance the lives of disadvantaged individuals. Such measures are aimed at ensuring that they are given the same opportunities as everyone else.\n\nSubstantive equality has been criticized for not having a clear definition. Sandra Fredman has however argued that substantive equality should be viewed as a four dimensional concept of recognition, redistribution, participation, and transformation. The redistributive dimension seeks to redress disadvantage through affirmative action, while the recognition dimension aims to promote the right to equality and identify the stereotypes, prejudice and violence that affect marginalized and disadvantaged individuals. The participative dimension uses Ely's insight to argue that judicial review must compensate marginalized individuals for their lack of political power. The participative dimension may also implement positive duties to ensure that all those affected by discrimination can be active members of society. Lastly, the transformative dimension recognizes that equality is not achieved through equal treatment and that the societal structures which reinforce disadvantage and discrimination must be modified or transformed to accommodate difference. The transformative dimension may use both positive and negative duties to redress disadvantage. Fredman advocates for a four-dimensional approach to substantive equality as a way to address the criticisms and limitations it faces due to the lack of agreeance on its definition by scholars. \n\nAristotle was the first philosopher to articulate the connection between equality and justice. Aristotle believed equals were to be treated alike and unequals in an unlike manner. Aristotle's notion of equality influenced the conception of formal equality in western jurisprudence. Formal equality advocates for the neutral treatment of all people based on the norms of the dominant group in society. Substantive equality originated in western jurisprudence and politics in opposition to formal equality during the late 20th century. This approach was inspired by early landmark constitutional cases in America, which broke away from formal approaches to equality in favor of a more substantive process. For example, in Brown v Board of Education (1954) the US Supreme Court deemed it unlawful to segregate children’s access to education on the basis of race. This case was influential in transforming America’s anti-discrimination laws as it sought equitable outcomes and equal opportunities for African Americans. The substantive approach rejects earlier notions that claimed social, political, economic, and historical differences were a legitimate justification for the differential treatment of marginalised and disadvantaged groups in society.\n\nThe substantive approach to equality is entrenched in human rights treaties, laws, and jurisprudence, which is then adopted and implemented by nation states and private actors. This is present in Article 14 of the ECHR, which states that: \"The enjoyment of the rights and freedoms set forth in this Convention shall be secured without discrimination on any ground such as sex, race, color, language, religion, political or other opinion, national or social origin, association with a national minority, property, birth or other status\". (275)Article 14 prohibits discrimination in all aspects of public life on the basis of nominated attributes. Although article 14 fails to mention discrimination on the basis of sexuality, age, and disability recent developments in case law have shown that these grounds are illustrative but not exhaustive and can extend to include these factors. Nation states that have signed and ratified the ECHR have an obligation to enact legislation preventing discrimination by using special measures to protect and advance the lives of disadvantaged and marginalized individuals in society. Article 1(4) of the ICERD defines special measures as, \"securing adequate advancement of certain racial or ethnic groups or individuals requiring such protection as may be necessary in order to ensure such groups or individuals equal enjoyment or exercise of human rights and fundamental freedoms shall not be deemed racial discrimination\". (9) These two articles are the fundamental principles that define the practice of substantive equality. Failure to enact substantive legislation by signatories may result in heavy sanctions and scrutiny from the international community.    \n\nSubstantive equality is made apparent through the anti-discrimination laws of Australia, which aim to protect and advance the lives of marginalized and disadvantaged individuals. Anti-discrimination laws are enacted by commonwealth, state, and territory parliaments and are then interpreted by courts and tribunals. These laws are covered under the following four key commonwealth statutes: the Racial Discrimination Act (1975), Sex Discrimination Act (1984), Disability Discrimination Act (1992), and Age Discrimination Act (2004). \n\nAll Australian states and territories have enacted one statute called the anti-discrimination or equal opportunities act which prohibits all forms of discrimination in public life on the basis of nominated attributes identified in Article 26 of the ICCPR. This statute makes it unlawful to discriminate against others both directly, which is when a person is treated unfairly based on a nominated attribute, or indirectly which occurs when something is fair in form but discriminatory in practice. For example, indirect discrimination may occur in the workforce when employees or potential employees are expected to comply with a condition or requirement of the job (i.e. height restrictions) but are unable to meet them because they are unreasonable or unfair. Failure to comply to anti-discrimination laws are enforceable in civil proceedings which may result in heavy fines or penalties. However, these laws have been criticized for focusing too much on compensation and not enough on preventing discrimination from occurring.\n\nAnti-discrimination laws use substantive measures by promoting equal opportunities and implementing special measures identified in Article 1(4) ICERD to overcome discrimination in the Australian society. Private actors, organizations, and governments use special measures in the form of affirmative action programs to ensure disadvantaged individuals are given the same opportunities as everyone else. The Australian government has identified women, Aboriginal and Torres Strait Islanders, people with disabilities, and non-English speaking migrants as high priority groups for the administration of special measures programs. The Northern Territory government has recognized Aboriginal and Torres Strait Islanders, and people with disabilities as high priority groups for their affirmative action programs by focusing on employment opportunities for these groups. These programs use substantive measures as they acknowledge that there is a need to treat people differently by prioritizing these groups as they have been unfairly discriminated upon. For example, in 2011 the ABS reported that Indigenous peoples were 3 times more likely to be unemployed than non-indigenous people. This demonstrates the need for affirmative action policies to protect and advance the lives of Aboriginal people, as they do not have the same access or opportunities to employment.    \n\nIn Canada, the government of the Northwest Territories announced in October 2018 that it would be implementing two new programs to increase employment and pay rates for Indigenous Canadian staff. The first, Indigenous career gateway program for entry-level staff, aims to increase the number of Indigenous people working for the territorial government. The second, Indigenous management development and training program, aims to help Indigenous government employees gain further training so that they can advance to higher-paid positions.\n\nThe case of R v Kapp was instrumental in shifting the focus from formal equality to substantive equality in Canadian jurisprudence. In 1998, the Canadian government granted a communal fishing license exclusively to members of three Aboriginal bands for a period of 24 hours in the Fraser river that allowed them the right to fish and sell their catch. The appellants consisted mainly of a group of non-Aboriginal commercial fishermen who protested against the license and were subsequently charged with fishing at a prohibited time. The fishermen argued that they were being unfairly discriminated against on the basis of race under section 15(1) of the Canadian charter of rights. However, the crown upheld decision that the government did not violate section 15 of the charter. The crown found that decision could not be discriminatory as section 15(1) and 15(2) work together to prevent discrimination and protect vulnerable individuals in society. Section 15(1) aims to prevent discrimination against marginalized and disadvantaged groups, while section 15(2) aims to combat discrimination through affirmative action. The crown dismissed the appeal as under section 15(2) the Government has the power to implement affirmative action programs in order to advance the aboriginal bands access to jobs and resources. The law can be understood as using substantive measures in R v Kapp as it recognizes that equal treatment does not result in the same opportunities across groups. Instead, the law acknowledged that substantive equality is necessary to ensure the development of disadvantaged and marginalized individual’s access to opportunities. \n\nThe seminal case of Z v Z highlighted the issues with equal sharing of relationship property at the end of a relationship. In this the case, the couple had been married for 28 years. During this time the primary caregiver Mrs Z gave up her career to care for the couple's children. At the end of the relationship, the couple had a property valued at $900,000. Mr Z was on a salary of over $300,000 per annum, while Mr Z received $7,000 in assistance from the government. In Z v Z, the court failed to protect the primary caregiver by not taking into account her future earning capacity and her past sacrifices. The property (relationships) amendment act (2001) was introduced to rectify the problems of equal sharing highlighted in Z v Z. The property act uses substantive equality to recognize that equal treatment can lead to disadvantage. The act recognizes the impact relationships can have on the earning capacities of individuals and it aims to place them in more substantive position at the end of the relationship. However, the property act has been criticized for its ability to achieve substantive equality, as it does not state how economic disparity should be quantified. Scholars have argued that it does not protect the most vulnerable as it is skewed towards relationships with high incomes because it more difficult to establish an economic disparity in lower income cases. \n\nSubstantive equality has been criticized in the past for its vague definition and its ability to help combat discrimination for marginalized and disadvantaged individuals. Scholars have argued that the meaning of substantive equality remains elusive, which makes it difficult to implement change due to the lack of consensus. The meaning of equality itself has been labeled as subjective as there are too many conflicting opinions within society to find one underlying definition. Substantive equality has also been criticized for its lack of ability to protect individuals from discrimination and for placing too much emphasis on compensation rather than preventing discrimination from occurring. Welfare and affirmative action programs have been recognized as areas of concern, as the way in which they are delivered can be discriminatory in nature because they can reinforce and perpetuate stigmas that are held within society. Substantive equality is a well contested concept in which scholars, nations, and the law must work together in order to agree on a definition and appropriate framework for implementation. \n"}
{"id": "2104649", "url": "https://en.wikipedia.org/wiki?curid=2104649", "title": "Supersoldier", "text": "Supersoldier\n\nThe supersoldier (or super soldier) is a concept soldier, often fictional, capable of operating beyond normal human limits or abilities. \n\nSupersoldiers are common in science fiction literature, films and video games. In 2012, DARPA was reported to be developing an externally powered XOS exoskeleton design for greatly increased strength and endurance. Fictional supersoldiers are usually heavily augmented, either through eugenics, genetic engineering, cybernetic implants, drugs, brainwashing, traumatic events, an extreme training regimen or other scientific and pseudoscientific means. Occasionally, some instances also use paranormal methods, such as black magic or technology and science of extraterrestrial origin. In entertainment, the creators of such programs are viewed often as mad scientists or stern military personnel depending on the emphasis, as their programs would typically go past ethical boundaries in the pursuit of science or military might.\n\nSome fictional supersoldiers can also be categorized as cyborgs or cybernetic organisms because of augmentations that are intended to enhance human capabilities or to exceed physical human restrictions.\n\nIn the book \"The Men Who Stare at Goats\" (2004), Welsh journalist Jon Ronson documented how the U.S. military repeatedly tried and failed to train soldiers in the use of parascientific combat techniques during the Cold War, experimenting with New Age tactics and psychic phenomena such as remote viewing, astral projections, \"death touch\" and mind reading against various Soviet targets. The book inspired also a war comedy of the same name (2009) directed by Grant Heslov, starring George Clooney.\n\n"}
{"id": "17443489", "url": "https://en.wikipedia.org/wiki?curid=17443489", "title": "Tact (psychology)", "text": "Tact (psychology)\n\nTact is a term that B.F. Skinner used to describe a verbal operant which is controlled by a nonverbal stimulus (such as an object, event, or property of an object) and is maintained by nonspecific social reinforcement (praise).\n\nLess technically, a tact is a label. For example, a child may see their pet dog and say \"dog\"; the nonverbal stimulus (dog) evoked the response \"dog\" which is maintained by praise (or generalized conditioned reinforcement) \"you're right, that is a dog!\"\n\nChapter five of Skinner's \"Verbal Behavior\" discusses the tact in depth. A tact is said to \"make contact with\" the world, and refers to behavior that is under the control of generalized reinforcement. The controlling antecedent stimulus is nonverbal, and constitutes some portion of \"the whole of the physical environment.\" \n\nThe tact described by Skinner includes three important and related events, known as the 3-term-contingency: a stimulus, a response, and a consequence, in this case reinforcement. A verbal response is occasioned by the presence of a stimulus, such as when you say \"ball\" in the presence of a ball. In this scenario, \"ball\" is more likely to be reinforced by the listener than saying \"cat\", showing the importance of the third event, reinforcement, in relation to the stimulus (ball) and response (\"ball\"). Although the stimulus controls the response, it is the verbal community which establishes the stimulus' control over the verbal response of the speaker. For example, a child may say \"ball\" in the presence of a ball (stimulus), the child's parent may respond \"yes, that is a ball\", (reinforcement) thereby increasing the probability that the child will say ball in the presence of a ball in the future. On the other hand, if the parent never responds to the child saying \"ball\" in the presence of a ball then the probability of that response will decrease in the future.\n\nA tact may be pure or impure. For example, if the environmental stimulus evokes the response, the tact would be considered pure. If the tact is evoked by a verbal stimulus the resulting tact would be considered impure. For example, if a child is shown a picture of a dog, and emits the response \"dog\" this would be an example of a pure tact. If a child is shown a picture of a dog, and is given the verbal instruction \"what is this?\" then the response \"dog\" would be considered an impure tact.\n\nThe tact can be extended, as in generic, metaphorical, metonymical, solecistic, nomination, and \"guessing\" tact. It can also be involved in abstraction. Lowe, Horne, Harris & Randle (2002) would be one example of recent work in tacts.\n\nThe tact is said to be capable of generic extension. Generic extension is essentially an example of stimulus generalization. The novel stimulus contains all of the relevant features of the original stimulus. For example, we may see a red car and say \"car\" as well as see a white car and say \"car\". Different makes and models of cars will all evoke the same response \"car\".\n\nTacts can be extended metaphorically; in this case the novel stimulus has only some of the defining features of the original stimulus. For example, when we describe something as \"exploding with taste\" by drawing the common property of an explosion with the response to our having eaten something (perhaps a strong response, or a sudden one).\n\nTacts can undergo metonymical extension when some irrelevant but related feature of the original stimulus controls a response. In metonymical extension, one word often replaces another; we may replace a part for a whole. For example, saying \"refrigerator\" when shown a picture of a kitchen, or saying \"White house\" in place of \"President.\"\n\nWhen controlling variables unrelated to standard or immediate reinforcement take over control of the tact, it is said to be solecistically extended. Malapropisms, solecism and catachresis are examples of this.\n\nSkinner notes things like serial order, or conspicuous features of an object, may come to play as nominative tacts. A proper name may arise as a result of the tact. For example, a house that is haunted becomes \"The Haunted House\" as a nominative extension to the tact of its being haunted.\n\nA guess may seemingly be the emission of a response in the absence of controlling stimuli. Skinner notes that this may simply be a tact under more subtle or hidden controlling variables, although this is not always the case in something like guessing the landing side of a coin toss, where the possible alternatives are fixed and there is no subtle or hidden stimuli to control responses.\n\nSkinner deals with factors that interfere with, or change, generalized reinforcement. It is these conditions which, in turn, affect verbal behavior which may depend largely or entirely on generalized reinforcement. In children with developmental disabilities, tacts may need intensive training procedures to develop. Factors such as deprivation, emotional conditions and personal history may interfere with or change verbal behavior. Skinner mentions alertness, irrelevant emotional variables, \"special circumstances\" surrounding particular listeners or speakers, etc. (He refers to the conditions which are said to produce objective and subjective responses for example). We would now look at these as motivating operations/establishing conditions.\n\nUnder emersion conditions tacts will frequently emerge. However, in children with disabilities, more intensive training procedures are often needed.\n\nDistorted stimulus control may be minor as when a description (tact) is a slight exaggeration. Under stronger conditions of distortion, it may appear when the original stimulus is absent, as in the case of the response called a lie. Skinner notes that troubadours and fiction writers are perhaps both motivated by similar forms of tact distortion. Initially, they may recount real events, but as differential reinforcement affects the account we may see distortion and then total fabrication.\n\nOften, individuals with autism, developmental disabilities, or language delays have difficulty acquiring novel tacts. Many researchers in the field of verbal behavior and developmental disabilities have examined more intensive training procedures in order to teach tacts to these individuals. Specific types of prompts can be used in order to make a tact response more likely. For example, asking the student the question \"what is this?\" (this would be an example of an impure tact) has been used to prompt a correct tact response (this prompt can be faded until the learner can emit a pure tact). Echoic prompts (teacher repeats the correct answer which the learner must echo) have also been used to train tact responses. Kodak and Clements (2009) found that echoic training sessions before tact training was more effective at increasing independent tact responses.\n\nSkinner (1957) suggested that verbal operants were functionally independent, meaning that after teaching one verbal operant the individual may not be able to emit the topographically same response under different stimulus conditions. For example, a child may be able to request water, but may not be able to tact water. Researchers are currently examining procedures that may facilitate the generalization across verbal operants. Some studies have indicated, for example, that after teaching a child to mand for items, they could then tact them as well without direct instruction. Multiple studies have found support for the emergence of tact responses without direct instruction. These teaching procedures are especially important for individuals with autism and developmental disabilities because the learner can gain additional skills without direct instruction time.\n"}
{"id": "50932781", "url": "https://en.wikipedia.org/wiki?curid=50932781", "title": "Taylor diagram", "text": "Taylor diagram\n\nTaylor diagrams are mathematical diagrams designed to graphically indicate which of several approximate representations (or models) of a system, process, or phenomenon is most realistic. This diagram, invented by Karl E. Taylor in 1994 (published in 2001) facilitates the comparative assessment of different models. It is used to quantify the degree of correspondence between the modeled and observed behavior in terms of three statistics: the Pearson correlation coefficient, the root-mean-square error (RMSE) error, and the standard deviation.\n\nAlthough Taylor diagrams have primarily been used to evaluate models designed to study climate and other aspects of Earth’s environment, they can be used for purposes unrelated to environmental science (e.g., to quantify and visually display how well fusion energy models represent reality).\n\nTaylor diagrams can be constructed with a number of different open source and commercial software packages, including: GrADS, IDL, MATLAB, NCL, Python, R, and UV-CDAT.\n\nThe sample Taylor diagram shown in Figure 1 provides a summary of the relative skill with which several global climate models simulate the spatial pattern of annual mean precipitation. Eight models, each represented by a different letter on the diagram, are compared, and the distance between each model and the point labeled “observed” is a measure of how realistically each model reproduces observations. For each model, three statistics are plotted: the Pearson correlation coefficient (gauging similarity in pattern between the simulated and observed fields) is related to the azimuthal angle (blue contours); the centered RMS error in the simulated field is proportional to the distance from the point on the x-axis identified as “observed” (green contours); and the standard deviation of the simulated pattern is proportional to the radial distance from the origin (black contours). It is evident from this diagram, for example, that for Model F the correlation coefficient is about 0.65, the RMS error is about 2.6 mm/day and the standard deviation is about 3.3 mm/day. Model F’s standard deviation is clearly greater than the standard deviation of the observed field (indicated by the dashed contour at radial distance 2.9 mm/day). \nThe relative merits of various models can be inferred from Figure 1. Simulated patterns that agree well with observations will lie nearest the point marked \"observed\" on the x-axis. These models have relatively high correlation and low RMS errors. Models lying on the dashed arc have the correct standard deviation (which indicates that the pattern variations are of the right amplitude). In Figure 1 it can be seen that models A and C generally agree best with observations, each with about the same RMS error. Model A, however, has a slightly higher correlation with observations and has the same standard deviation as the observed, whereas model C has too little spatial variability (with a standard deviation of 2.3 mm/day compared to the observed value of 2.9 mm/day). Of the poorer performing models, model E has a low pattern correlation, while model D has variations that are much larger than observed, in both cases resulting in a relatively large (~3 mm/day) centered RMS error in the precipitation fields. Note also that although models D and B have about the same correlation with observations, model B simulates the amplitude of the variations (i.e., the standard deviation) much better than model D, resulting in a smaller RMS error.\n\nTaylor diagrams display statistics useful for assessing the similarity of a variable simulated by a model (more generally, the “test” field) to its observed counterpart (more generally, the “reference” field). Mathematically, the three statistics displayed on a Taylor diagram are related by the following formula (which can be derived directly from the definition of the statistics appearing in it):\n\nNote that the means of the fields are subtracted out before computing their second-order statistics, so the diagram does not provide information about overall biases, but solely characterizes the centered pattern error.\n\nAmong the several minor variations on the diagram that have been suggested are (see, Taylor, 2001):\n\n"}
{"id": "48081863", "url": "https://en.wikipedia.org/wiki?curid=48081863", "title": "Teresa Toda", "text": "Teresa Toda\n\nTeresa Toda (Porto Alegre, Brazil, June 24, 1950) is a Basque journalist. \nHer father was a Spanish diplomat. During her childhood and youth, she lived in Chile, in Brazil, in the United States (Los Angeles), and in London. In 1968, she began studying journalism in Spain, at the University of Navarre, which was run by the Catholic Opus Dei. \nShe became involved in left-wing, nationalist and anti-Franco politics, for which she was expelled together with around 40 students more. \nShe returned to London where she worked for The Law Society Gazette and then at Visnews (television news agency). In 1971, she returned to Madrid to finish her career and worked at the daily paper ABC, thus getting to know the difficulties of journalism under Franco. \nLater on, she moved to Barcelona, where she worked at the Press Office of CCOO, a left wing trade union, during the first years of the Spanish \"transition\". She collaborated in a Catalan weekly as well.\n\nShe began working as a correspondent for Egin, the Basque independentist newspaper, in Madrid in 1984. In 1989, after the shooting of two Basque MP’s in Madrid as they were having supper, (one of them, Josu Muguruza, was also her Editor in Egin), she had to move to the Basque Country. She worked first as Editor of the Basque political section and, from 1992 to 1998, as Assistant Editor in Chief. Egin was shut down by the Spanish Government in July 1998. \nThe shutting down of the paper entailed judicial proceedings against the Editor in Chief, 8 members of the Board and Teresa Toda. While awaiting trial, she worked at the magazine of LAB, an independentist Basque trade union. During those years, she became a member of the Board of Basque PEN, and became involved in activities in defence of freedom of speech and expression at diverse levels.\n\nThe trial began in 2005 at the Special Anti-Terrorist Court in Madrid. They received harsh sentences, which the Supreme Court later on cut down. She finally served six full years, all of them in prisons very far from her home. \nDuring that time, she kept up her relationship with Basque PEN and, through them, with PEN International; She received tens of letters and cards every Christmas from writers all over the world, and she herself wrote letters supporting imprisoned Kurdish journalists.\nShe was released in 2013, and since then she has resumed her activities at the Board of Basque PEN and in favour of freedom of speech.\n\nShe has also translated several books on conflict resolution, from English to Spanish.\n"}
{"id": "30636", "url": "https://en.wikipedia.org/wiki?curid=30636", "title": "Terrorism", "text": "Terrorism\n\nTerrorism is, in the broadest sense, the use of intentionally indiscriminate violence as a means to create terror among masses of people; or fear to achieve a religious or political aim. It is used in this regard primarily to refer to violence against peacetime targets or in war against non-combatants. The terms \"terrorist\" and \"terrorism\" originated during the French Revolution of the late 18th century but gained mainstream popularity during the U.S. presidency of Ronald Reagan (1981–89) after the 1983 Beirut barracks bombings and again after the 2001 September 11 attacks and the 2002 Bali bombings.\n\nThere is no commonly accepted definition of \"terrorism\". Being a charged term, with the connotation of something \"morally wrong\", it is often used, both by governments and non-state groups, to abuse or denounce opposing groups. Broad categories of political organisations have been claimed to have been involved in terrorism to further their objectives, including right-wing and left-wing political organisations, nationalist groups, religious groups, revolutionaries and ruling governments. Terrorism-related legislation has been adopted in various states, regarding \"terrorism\" as a crime. There is no universal agreement as to whether or not \"terrorism\", in some definition, should be regarded as a war crime.\n\nAccording to the Global Terrorism Database maintained by the University of Maryland, College Park, more than 61,000 incidents of non-state terrorism, resulting in at least 140,000 deaths, have been recorded from 2000 to 2014.\n\nEtmologically, the word terror is derived from the Latin verb \"Tersere\", which later becomes \"Terrere\". The latter form appears in European languages as early as the 12th century; its first known use in French is the word \"terrible\" in 1160. By 1356 the word \"terreur\" is in use. \"Terreur\" is the origin of the Middle English term \"terrour\", which later becomes the modern word \"terror\".\n\nThe term \"terroriste\", meaning \"terrorist\", is first used in 1794 by the French philosopher François-Noël Babeuf, who denounces Maximilien Robespierres Jacobin regime as a dictatorship. In the years leading up to the Reign of Terror, the Brunswick Manifesto threatened Paris with an \"exemplary, never to be forgotten vengeance: the city would be subjected to military punishment and total destruction\" if the royal family was harmed, but this only increased the Revolution's will to abolish the monarchy. Some writers attitudes about French Revolution grew less favorable after the French monarchy was abolished in 1792. During the Reign of Terror, which began in July 1793 and lasted thirteen months, Paris was governed by the Committee of Public safety who oversaw a regime of mass executions and public purges.\n\nPrior to the French Revolution, ancient philosophers wrote about tyrannicide, as tyranny was seen as the greatest political threat to Greco-Roman civilization. Medieval philosophers were similarly occupied with the concept of tyranny, though the analysis of some theologians like Thomas Aquinas drew a distinction between usurpers, who could be killed by anyone, and legitimate rulers who abused their power — the latter, in Aquinas' view, could only be punished by a public authority. John of Salisbury was the first medieval Christian scholar to defend tyrannicide.\nMost scholars today trace the origins of the modern tactic of terrorism to the Jewish Sicarii Zealots who attacked Romans and Jews in 1st century Palestine. They follow its development from the Persian Order of Assassins through to 19th-century anarchists. The \"Reign of Terror\" is usually regarded as an issue of etymology. The term terrorism has generally been used to describe violence by non-state actors rather than government violence since the 19th-century Anarchist Movement.\n\nIn December 1795, Edmund Burke used the word \"Terrorists\" in a description of the new French government called 'Directory':\n\nAt length, after a terrible struggle, the [Directory] Troops prevailed over the Citizens (…) To secure them further, they have a strong corps of irregulars, ready armed. Thousands of those Hell-hounds called Terrorists, whom they had shut up in Prison on their last Revolution, as the Satellites of Tyranny, are let loose on the people.(emphasis added)\n\nThere are over 109 different definitions of terrorism. American political philosopher Michael Walzer in 2002 wrote: \"Terrorism is the deliberate killing of innocent people, at random, to spread fear through a whole population and force the hand of its political leaders\". Bruce Hoffman, an American scholar, has noted that\n\nIt is not only individual agencies within the same governmental apparatus that cannot agree on a single definition of terrorism. Experts and other long-established scholars in the field are equally incapable of reaching a consensus.\n\nC.A.J. Coady has written that the question of how to define terrorism is \"irresolvable\" because \"its natural home is in polemical, ideological and propagandist contexts\".\n\nFrench historian distinguishes between the revolutionary terror of the French Revolution and the terrorists of the September 11 attacks:\n\nRevolutionary terror is not terrorism. To make a moral equivalence between the Revolution's year II and September 2001 is historical and philosophical nonsense . . . The violence exercised on 11 September 2001 aimed neither at equality nor liberty. Nor did the preventive war announced by the president of the United States. \n\nExperts disagree about \"whether terrorism is wrong by definition or just wrong as a matter of fact; they disagree about whether terrorism should be defined in terms of its aims, or its methods, or both, or neither; they disagree about whether or not states can perpetrate terrorism; they even disagree about the importance or otherwise of \"terror\" for a definition of \"terrorism\".\"\n\nAlternatively, responding to developments in modern warfare, Paul James and Jonathan Friedman distinguish between state terrorism against non-combatants and state terrorism against combatants, including 'Shock and Awe' tactics:\n\nShock and Awe\" as a subcategory of \"rapid dominance\" is the name given to massive intervention designed to strike terror into the minds of the enemy. It is a form of state-terrorism. The concept was however developed long before the Second Gulf War by Harlan Ullman as chair of a forum of retired military personnel.\n\nIn November 2004, a Secretary-General of the United Nations report described terrorism as any act \"intended to cause death or serious bodily harm to civilians or non-combatants with the purpose of intimidating a population or compelling a government or an international organization to do or abstain from doing any act\". The international community has been slow to formulate a universally agreed, legally binding definition of this crime. These difficulties arise from the fact that the term \"terrorism\" is politically and emotionally charged. In this regard, Angus Martyn, briefing the Australian parliament, stated,\nThe international community has never succeeded in developing an accepted comprehensive definition of terrorism. During the 1970s and 1980s, the United Nations attempts to define the term floundered mainly due to differences of opinion between various members about the use of violence in the context of conflicts over national liberation and self-determination.\n\nThese divergences have made it impossible for the United Nations to conclude a Comprehensive Convention on International Terrorism that incorporates a single, all-encompassing, legally binding, criminal law definition of terrorism. The international community has adopted a series of sectoral conventions that define and criminalize various types of terrorist activities.\n\nSince 1994, the United Nations General Assembly has repeatedly condemned terrorist acts using the following political description of terrorism:\nCriminal acts intended or calculated to provoke a state of terror in the public, a group of persons or particular persons for political purposes are in any circumstance unjustifiable, whatever the considerations of a political, philosophical, ideological, racial, ethnic, religious or any other nature that may be invoked to justify them.\n\nVarious legal systems and government agencies use different definitions of terrorism in their national legislation.\n\nU.S. Code Title 22 Chapter 38, Section 2656f(d) defines terrorism as:\n\"Premeditated, politically motivated violence perpetrated against noncombatant targets by subnational groups or clandestine agents, usually intended to influence an audience\".\n\n18 U.S.C. § 2331 defines \"international terrorism\" and \"domestic terrorism\" for purposes of Chapter 113B of the Code, entitled \"Terrorism\":\n\n\"International terrorism\" means activities with the following three characteristics:\n\nInvolve violent acts or acts dangerous to human life that violate federal or state law;\nAppear to be intended (i) to intimidate or coerce a civilian population; (ii) to influence the policy of a government by intimidation or coercion; or (iii) to affect the conduct of a government by mass destruction, assassination, or kidnapping; and\noccur primarily outside the territorial jurisdiction of the U.S., or transcend national boundaries in terms of the means by which they are accomplished, the persons they appear intended to intimidate or coerce, or the locale in which their perpetrators operate or seek asylum.\n\nA definition proposed by Carsten Bockstette at the George C. Marshall European Center for Security Studies, underlines the psychological and tactical aspects of terrorism:\n\nTerrorists also attack national symbols, which may negatively affect a government, while increasing the prestige of the given terrorist group or its ideology.\n\nTerrorist acts frequently have a political purpose. Some official, governmental definitions of terrorism use the criterion of the illegitimacy or unlawfulness of the act. to distinguish between actions authorized by a government (and thus \"lawful\") and those of other actors, including individuals and small groups. For example, carrying out a strategic bombing on an enemy city, which is designed to affect civilian support for a cause, would not be considered terrorism if it were authorized by a government. This criterion is inherently problematic and is not universally accepted, because: it denies the existence of state terrorism. An associated term is violent non-state actor.\n\nAccording to Ali Khan, the distinction lies ultimately in a political judgment.\n\nHaving the moral charge in our vocabulary of 'something morally wrong', the term 'terrorism' is often used to abuse or denounce opposite parties, either governments or non-state-groups.\n\nThose labeled \"terrorists\" by their opponents rarely identify themselves as such, and typically use other terms or terms specific to their situation, such as separatist, freedom fighter, liberator, revolutionary, vigilante, militant, paramilitary, guerrilla, rebel, patriot, or any similar-meaning word in other languages and cultures. Jihadi, mujaheddin, and fedayeen are similar Arabic words that have entered the English lexicon. It is common for both parties in a conflict to describe each other as terrorists.\n\nOn whether particular terrorist acts, such as killing non-combatants, can be justified as the lesser evil in a particular circumstance, philosophers have expressed different views: while, according to David Rodin, utilitarian philosophers can (in theory) conceive of cases in which the evil of terrorism is outweighed by the good that could not be achieved in a less morally costly way, in practice the \"harmful effects of undermining the convention of non-combatant immunity is thought to outweigh the goods that may be achieved by particular acts of terrorism\". Among the non-utilitarian philosophers, Michael Walzer argued that terrorism can be morally justified in only one specific case: when \"a nation or community faces the extreme threat of complete destruction and the only way it can preserve itself is by intentionally targeting non-combatants, then it is morally entitled to do so\".\n\nIn his book \"Inside Terrorism\" Bruce Hoffman offered an explanation of why the term \"terrorism\" becomes distorted:\n\nThe pejorative connotations of the word can be summed up in the aphorism, \"One man's terrorist is another man's freedom fighter\". This is exemplified when a group using irregular military methods is an ally of a state against a mutual enemy, but later falls out with the state and starts to use those methods against its former ally. During World War II, the Malayan People's Anti-Japanese Army was allied with the British, but during the Malayan Emergency, members of its successor (the Malayan Races Liberation Army), were branded \"terrorists\" by the British. More recently, Ronald Reagan and others in the American administration frequently called the mujaheddin \"freedom fighters\" during the Soviet–Afghan War yet twenty years later, when a new generation of Afghan men were fighting against what they perceive to be a regime installed by foreign powers, their attacks were labelled \"terrorism\" by George W. Bush. Groups accused of terrorism understandably prefer terms reflecting legitimate military or ideological action. Leading terrorism researcher Professor Martin Rudner, director of the Canadian Centre of Intelligence and Security Studies at Ottawa's Carleton University, defines \"terrorist acts\" as unlawful attacks for political or other ideological goals, and said:\nSome groups, when involved in a \"liberation\" struggle, have been called \"terrorists\" by the Western governments or media. Later, these same persons, as leaders of the liberated nations, are called \"statesmen\" by similar organizations. Two examples of this phenomenon are the Nobel Peace Prize laureates Menachem Begin and Nelson Mandela. WikiLeaks editor Julian Assange has been called a \"terrorist\" by Sarah Palin and Joe Biden.\n\nSometimes, states that are close allies, for reasons of history, culture and politics, can disagree over whether or not members of a certain organization are terrorists. For instance, for many years, some branches of the United States government refused to label members of the Provisional Irish Republican Army (IRA) as terrorists while the IRA was using methods against one of the United States' closest allies (the United Kingdom) that the UK branded as terrorism. This was highlighted by the \"Quinn v. Robinson\" case.\n\nMedia outlets who wish to convey impartiality may limit their usage of \"terrorist\" and \"terrorism\" because they are loosely defined, potentially controversial in nature, and subjective terms.\n\nDepending on how broadly the term is defined, the roots and practice of terrorism can be traced at least to the 1st-century AD. Sicarii Zealots, though some dispute whether the group, a radical offshoot of the Zealots which was active in Judaea Province at the beginning of the 1st century AD, was in fact terrorist. According to the contemporary Jewish-Roman historian Josephus, after the Zealotry rebellion against Roman rule in Judea, when some prominent Jewish collaborators with Roman rule were killed, Judas of Galilee formed a small and more extreme offshoot of the Zealots, the Sicarii, in 6 AD. Their terror was also directed against Jewish \"collaborators\", including temple priests, Sadducees, Herodians, and other wealthy elites.\n\nThe term \"terrorism\" itself was originally used to describe the actions of the Jacobin Club during the \"Reign of Terror\" in the French Revolution. \"Terror is nothing other than justice, prompt, severe, inflexible\", said Jacobin leader Maximilien Robespierre. In 1795, Edmund Burke denounced the Jacobins for letting \"thousands of those hell-hounds called Terrorists ... loose on the people\" of France.\n\nIn January 1858, Italian patriot Felice Orsini threw three bombs in an attempt to assassinate French Emperor Napoleon III. Eight bystanders were killed and 142 injured. The incident played a crucial role as an inspiration for the development of the early terrorist groups.\n\nArguably the first organization to utilize modern terrorist techniques was the Irish Republican Brotherhood, founded in 1858 as a revolutionary Irish nationalist group that carried out attacks in England. The group initiated the Fenian dynamite campaign in 1881, one of the first modern terror campaigns. Instead of earlier forms of terrorism based on political assassination, this campaign used modern, timed explosives with the express aim of sowing fear in the very heart of metropolitan Britain, in order to achieve political gains.\n\nAnother early terrorist group was Narodnaya Volya, founded in Russia in 1878 as a revolutionary anarchist group inspired by Sergei Nechayev and \"propaganda by the deed\" theorist Carlo Pisacane. The group developed ideas—such as targeted killing of the 'leaders of oppression'—that were to become the hallmark of subsequent violence by small non-state groups, and they were convinced that the developing technologies of the age—such as the invention of dynamite, which they were the first anarchist group to make widespread use of—enabled them to strike directly and with discrimination.\n\nScholars of terrorism refer to four major waves of global terrorism: \"the Anarchist, the Anti-Colonial, the New Left, and the Religious. The first three have been completed and lasted around 40 years; the fourth is now in its third decade.\"\n\nDepending on the country, the political system, and the time in history, the types of terrorism are varying.\n\nIn early 1975, the Law Enforcement Assistant Administration in the United States formed the National Advisory Committee on Criminal Justice Standards and Goals. One of the five volumes that the committee wrote was titled \"Disorders and Terrorism\", produced by the Task Force on Disorders and Terrorism under the direction of H. H. A. Cooper, Director of the Task Force staff.\n\nThe Task Force defines terrorism as \"a tactic or technique by means of which a violent act or the threat thereof is used for the prime purpose of creating overwhelming fear for coercive purposes\". It classified disorders and terrorism into six categories:\n\nOther sources have defined the typology of terrorism in different ways, for example, broadly classifying it into domestic terrorism and international terrorism, or using categories such as vigilante terrorism or insurgent terrorism. One way the typology of terrorism may be defined:\n\nAs well as there being no one agreed definition of terrorism, there is a similar lack of consensus regarding the causes - or motivations behind - terrorism. Numerous studies have identified certain behavioural and situational characteristics that are common, and perhaps causal, to the consequence of terrorism, specific analysis of case studies have lead to suggested motivations to individual historical acts.\n\nA report conducted by Paul Gill, John Horgan and Paige Deckert on behalf of The Department of security of UK highlights the vast discrepencies between individual cases of terrorism recorded. To begin with, 43% of lone wolf terrorism is motivated by religious beliefs. The same report indicates that just less than a third (31.9%) have pre-existing mental health disorders, while many more are found to have these problems upon arrest. At least 37% lived alone at the time of their event planning and/or execution, a further 26.1% lived with others, and no data were available for the remaining cases. 40.2% were unemployed at the time of their arrest or terrorist event. 19.3% subjectively experienced being disrespected by others, while 14.3% experienced being the victim of verbal or physical assault. \nAttacks on 'collaborators' are used to intimidate people from cooperating with the state in order to undermine state control. This strategy was used in Ireland, in Kenya, in Algeria and in Cyprus during their independence struggles. \n\nThis strategy was used by Al-Qaeda in its attacks on the World Trade Center and the Pentagon in the United States on September 11, 2001. These attacks are also used to draw international attention to struggles that are otherwise unreported, such as the Palestinian airplane hijackings in 1970 and the 1975 Dutch train hostage crisis.\n\nAbrahm suggests that terrorist organizations do not select terrorism for its political effectiveness. Individual terrorists tend to be motivated more by a desire for social solidarity with other members of their organization than by political platforms or strategic objectives, which are often murky and undefined.\n\nAdditionally, Michael Mousseau shows possible relationships between the type of economy within a country and ideology associated with terrorism. Many terrorists have a history of domestic violence.\n\nSome terrorists like Timothy McVeigh were motivated by revenge against a state for its actions against its citizens.\n\nAccording to Paul Gill, John Horgan and Paige Deckert on behalf of The Department of security of UK, 43% of lone wolf terrorism is motivated by religious beliefs. The same report indicates that Just less than a third (31.9%) have pre-existing mental health disorders, while many are found to have these problems upon arrest. At least 37% lived alone at the time of their event planning and/or execution, a further 26.1% lived with others, and no data were available for the remaining cases. 40.2% were unemployed at the time of their arrest or terrorist event. Many were chronically unemployed and consistently struggled to hold any form of employment for a significant amount of time. 19.3% subjectively experienced being disrespected by others, while 14.3% experienced being the victim of verbal or physical assault. \nAriel Merari, a psychologist who has studied the psychological profiles of suicide terrorists since 1983 through media reports that contained biographical details, interviews with the suicides’ families, and interviews with jailed would-be suicide attackers, concluded that they were unlikely to be psychologically abnormal.\n\nIn comparison to economic theories of criminal behaviour, Scott Atran found that suicide terrorists exhibit none of the socially dysfunctional attributes - such as fatherless, friendless, jobless situations - or suicidal symptoms. By which he means, they do not kill themselves simply out of hopelessness or a sense of 'having nothing to lose'.\n\nAlthough a common factor in terrorism is a strong religious belief there are other factors such as cultural, social and \npolitical that wholly preclude religion. For example, the drive behind these Chechen terrorists are quite distinct and unique from others. Many of the Chechens considered themselves secular freedom fighters, nationalist insurgents seeking to establish an independent secular state of Chechnya. Although a distinction should be made between national Chechen terrorists and non-Chechen fighters who have adopted the idea from abroad. Few Chechen fighters fought for the jihads whereas most of the non-Chechen fighters did (Janeczko, 2014)\nAnother factor are perceived assurances of financial stability for the actor's families, that they are given when they join a terrorist organization or complete an attempt of terror. An extra grant is provided for the families of suicide bombers.\n\nTerrorism is most common in nations with intermediate political freedom, and it is least common in the most democratic nations.\nHowever, one study suggests that suicide attacks may be an exception to this general rule. Evidence regarding this particular method of terrorism reveals that every modern suicide campaign has targeted a democracy–a state with a considerable degree of political freedom. The study suggests that concessions awarded to terrorists during the 1980s and 1990s for suicide attacks increased their frequency. There is a connection between the existence of civil liberties, democratic participation and terrorism. According to Young and Dugan, these things encourage terrorist groups to organize and generate terror.\n\nSome examples of \"terrorism\" in non-democratic nations include ETA in Spain under Francisco Franco (although the group's terrorist activities increased sharply after Franco's death), the Organization of Ukrainian Nationalists in pre-war Poland, the Shining Path in Peru under Alberto Fujimori, the Kurdistan Workers Party when Turkey was ruled by military leaders and the ANC in South Africa. Democracies, such as Japan, the United Kingdom, the United States, Israel, Indonesia, India, Spain, Germany, Italy and the Philippines, have also experienced domestic terrorism.\n\nWhile a democratic nation espousing civil liberties may claim a sense of higher moral ground than other regimes, an act of terrorism within such a state may cause a dilemma: whether to maintain its civil liberties and thus risk being perceived as ineffective in dealing with the problem; or alternatively to restrict its civil liberties and thus risk delegitimizing its claim of supporting civil liberties. For this reason, homegrown terrorism has started to be seen as a greater threat, as stated by former CIA Director Michael Hayden. This dilemma, some social theorists would conclude, may very well play into the initial plans of the acting terrorist(s); namely, to delegitimize the state and cause a systematic shift towards anarchy via the accumulation of negative sentiments towards the state system.\n\nTerrorist acts throughout history have been performed on religious grounds with the goal to either spread or enforce a system of belief, viewpoint or opinion. The validity and scope of religious terrorism is limited to an individual's view or a group's view or interpretation of that belief system's teachings.\n\nAccording to the Global Terrorism Index by the University of Maryland, College Park, religious extremism has overtaken national separatism and become the main driver of terrorist attacks around the world. Since 9/11 there has been a five-fold increase in deaths from terrorist attacks. The majority of incidents over the past several years can be tied to groups with a religious agenda. Before 2000, it was nationalist separatist terrorist organizations such as the IRA and Chechen rebels who were behind the most attacks. The number of incidents from nationalist separatist groups has remained relatively stable in the years since while religious extremism has grown. The prevalence of Islamist groups in Iraq, Afghanistan, Pakistan, Nigeria and Syria is the main driver behind these trends.\n\nFour of the terrorist groups that have been most active since 2001 are Boko Haram, Al Qaeda, the Taliban and ISIL. These groups have been most active in Iraq, Afghanistan, Pakistan, Nigeria and Syria. 80% of all deaths from terrorism occurred in one of these five countries.\n\nTerrorism in Pakistan has become a great problem. From the summer of 2007 until late 2009, more than 1,500 people were killed in suicide and other attacks on civilians for reasons attributed to a number of causes – sectarian violence between Sunni and Shia Muslims; easy availability of guns and explosives; the existence of a \"Kalashnikov culture\"; an influx of ideologically driven Muslims based in or near Pakistan, who originated from various nations around the world and the subsequent war against the pro-Soviet Afghans in the 1980s which blew back into Pakistan; the presence of Islamist insurgent groups and forces such as the Taliban and Lashkar-e-Taiba. Pakistan is the 10th most dangerous country by criminality index. On July 2, 2013 in Lahore, 50 Muslim scholars of the Sunni Ittehad Council (SIC) issued a collective fatwa against suicide bombings, the killing of innocent people, bomb attacks, and targeted killings declaring them as Haraam or forbidden.\n\nIn 2015, the Southern Poverty Law Center released a report on terrorism in the United States. The report (titled \"The Age of the Wolf\") found that during that period, \"more people have been killed in America by non-Islamic domestic terrorists than jihadists.\" The \"virulent racist and anti-semitic\" ideology of the ultra-right wing Christian Identity movement is usually accompanied by anti-government sentiments. Adherents of Christian Identity believe that whites of European descent can be traced back to the \"Lost Tribes of Israel\" and many consider Jews to be the Satanic offspring of Eve and the Serpent. This group has committed hate crimes, bombings and other acts of terrorism. Its influence ranges from the Ku Klux Klan and neo-nazi groups to the anti-government militia and sovereign citizen movements. Christian Identity's origins can be traced back to Anglo-Israelism. Anglo-Israelism held the view that Jews were descendants of ancient Israelites who had never been lost. By the 1930s, the movement had been infected with anti-Semitism, and eventually Christian Identity theology diverged from traditional Anglo-Israelism, and developed what is known as the \"two seed\" theory. According to the two-seed theory, the Jewish people are descended from Cain and the serpent (not from Shem). The white European seedline is descended from the \"lost tribes\" of Israel. They hold themselves to \"God's laws\", not to \"man's laws\", and they do not feel bound to a government that they consider run by Jews and the New World Order.\nIsrael has also had problems with Jewish religious terrorism. Yigal Amir assassinated Israeli Prime Minister Yitzhak Rabin in 1995. For Amir, killing Rabin was an exemplary act that symbolized the fight against an illegitimate government that was prepared to cede Jewish Holy Land to the Palestinians. \n\nThe perpetrators of acts of terrorism can be individuals, groups, or states. According to some definitions, clandestine or semi-clandestine state actors may also carry out terrorist acts outside the framework of a state of war. However, the most common image of terrorism is that it is carried out by small and secretive cells, highly motivated to serve a particular cause and many of the most deadly operations in recent times, such as the September 11 attacks, the London underground bombing, 2008 Mumbai attacks and the 2002 Bali bombing were planned and carried out by a close clique, composed of close friends, family members and other strong social networks. These groups benefited from the free flow of information and efficient telecommunications to succeed where others had failed.\n\nOver the years, much research has been conducted to distill a terrorist profile to explain these individuals' actions through their psychology and socio-economic circumstances. Others, like Roderick Hindery, have sought to discern profiles in the propaganda tactics used by terrorists. Some security organizations designate these groups as \"violent non-state actors\". A 2007 study by economist Alan B. Krueger found that terrorists were less likely to come from an impoverished background (28% vs. 33%) and more likely to have at least a high-school education (47% vs. 38%). Another analysis found only 16% of terrorists came from impoverished families, vs. 30% of male Palestinians, and over 60% had gone beyond high school, vs. 15% of the populace.A study into the poverty-stricken conditions and whether or not,terrorists are more likely to come from here,show that people who grew up in these situations tend to show aggression and frustration towards others. This theory is largely debated for the simple fact that just because one is frustrated,does not make them a potential terrorist.\n\nTo avoid detection, a terrorist will look, dress, and behave normally until executing the assigned mission. Some claim that attempts to profile terrorists based on personality, physical, or sociological traits are not useful. The physical and behavioral description of the terrorist could describe almost any normal person. However, the majority of terrorist attacks are carried out by military age men, aged 16–40.\n\nGroups not part of the state apparatus of in opposition to the state are most commonly referred to as a \"terrorist\" in the media.\n\nAccording to the Global Terrorism Database, the most active terrorist group in the period 1970 to 2010 was Shining Path (with 4,517 attacks), followed by Farabundo Marti National Liberation Front (FMLN), Irish Republican Army (IRA), Basque Fatherland and Freedom (ETA), Revolutionary Armed Forces of Colombia (FARC), Taliban, Liberation Tigers of Tamil Eelam, New People's Army, National Liberation Army of Colombia (ELN), and Kurdistan Workers Party (PKK).\n\nA state can sponsor terrorism by funding or harboring a terrorist group. Opinions as to which acts of violence by states consist of state-sponsored terrorism vary widely. When states provide funding for groups considered by some to be terrorist, they rarely acknowledge them as such.\n\nAs with \"terrorism\" the concept of \"state terrorism\" is controversial. The Chairman of the United Nations Counter-Terrorism Committee has stated that the Committee was conscious of 12 international Conventions on the subject, and none of them referred to State terrorism, which was not an international legal concept. If States abused their power, they should be judged against international conventions dealing with war crimes, international human rights law, and international humanitarian law. Former United Nations Secretary-General Kofi Annan has said that it is \"time to set aside debates on so-called 'state terrorism'. The use of force by states is already thoroughly regulated under international law\". However, he also made clear that, \"regardless of the differences between governments on the question of the definition of terrorism, what is clear and what we can all agree on is that any deliberate attack on innocent civilians [or non-combatants], regardless of one's cause, is unacceptable and fits into the definition of terrorism.\"\nState terrorism has been used to refer to terrorist acts committed by governmental agents or forces. This involves the use of state resources employed by a state's foreign policies, such as using its military to directly perform acts of terrorism. Professor of Political Science Michael Stohl cites the examples that include the German bombing of London, the Japanese bombing of Pearl Harbor, the British and American firebombing of Dresden, and the U.S. atomic bombings of Hiroshima and Nagasaki during World War II. He argues that \"the use of terror tactics is common in international relations and the state has been and remains a more likely employer of terrorism within the international system than insurgents.\" He also cites the first strike option as an example of the \"terror of coercive diplomacy\" as a form of this, which holds the world hostage with the implied threat of using nuclear weapons in \"crisis management\" and he argues that the institutionalized form of terrorism has occurred as a result of changes that took place following World War II. In this analysis, state terrorism exhibited as a form of foreign policy was shaped by the presence and use of weapons of mass destruction, and the legitimizing of such violent behavior led to an increasingly accepted form of this behavior by the state .\n\nThe connection between terrorism and tourism has been widely studied since the Luxor massacre in Egypt. In the 1970s, the targets of terrorists were politicians and chiefs of police while now, international tourists and visitors are selected as the main targets of attacks. The attacks on the World Trade Center and the Pentagon on September 11, 2001, were the symbolic epicenter, which marked a new epoch in the use of civil transport against the main power of the planet. From this event onwards, the spaces of leisure that characterized the pride of West, were conceived as dangerous and frightful.\n\nState sponsors have constituted a major form of funding; for example, Palestine Liberation Organization, Democratic Front for the Liberation of Palestine and other groups considered to be terrorist organizations, were funded by the Soviet Union. The Stern Gang received funding from Italian Fascist officers in Beirut to undermine the British Mandate for Palestine. Pakistan has created and nurtured terrorist groups as policy for achieving tactical objectives against its neighbours, especially India.\n\n\"Revolutionary tax\" is another major form of funding, and essentially a euphemism for \"protection money\". Revolutionary taxes \"play a secondary role as one other means of intimidating the target population\".\n\nOther major sources of funding include kidnapping for ransoms, smuggling (including wildlife smuggling), fraud, and robbery. The Islamic State in Iraq and the Levant has reportedly received funding \"via private donations from the Gulf states\".\n\nThe Financial Action Task Force is an inter-governmental body whose mandate, since October 2001, has included combating terrorist financing.\n\nTerrorist attacks are often targeted to maximize fear and publicity, usually using explosives or poison.\nTerrorist groups usually methodically plan attacks in advance, and may train participants, plant undercover agents, and raise money from supporters or through organized crime. Communications occur through modern telecommunications, or through old-fashioned methods such as couriers. There is also concern about terrorist attacks employing weapons of mass destruction.\n\nTerrorism is a form of asymmetric warfare, and is more common when direct conventional warfare will not be effective because forces vary greatly in power.\n\nThe context in which terrorist tactics are used is often a large-scale, unresolved political conflict. The type of conflict varies widely; historical examples include:\n\nResponses to terrorism are broad in scope. They can include re-alignments of the political spectrum and reassessments of fundamental values.\n\nSpecific types of responses include:\n\nThe term \"counter-terrorism\" has a narrower connotation, implying that it is directed at terrorist actors.\n\nAccording to a report by Dana Priest and William M. Arkin in The Washington Post, \"Some 1,271 government organizations and 1,931 private companies work on programs related to counterterrorism, homeland security and intelligence in about 10,000 locations across the United States.\"\n\nAmerica's thinking on how to defeat radical Islamists is split along two very different schools of thought. Republicans, typically follow what is known as the Bush Doctrine, advocate the military model of taking the fight to the enemy and seeking to democratize the Middle East. Democrats, by contrast, generally propose the law enforcement model of better cooperation with nations and more security at home. In the introduction of the \"U.S. Army / Marine Corps Counterinsurgency Field Manual\", Sarah Sewall states the need for \"U.S. forces to make securing the civilian, rather than destroying the enemy, their top priority. The civilian population is the center of gravity—the deciding factor in the struggle... Civilian deaths create an extended family of enemies—new insurgent recruits or informants––and erode support of the host nation.\" Sewall sums up the book's key points on how to win this battle: \"Sometimes, the more you protect your force, the less secure you may be... Sometimes, the more force is used, the less effective it is... The more successful the counterinsurgency is, the less force can be used and the more risk must be accepted... Sometimes, doing nothing is the best reaction.\" This strategy, often termed \"courageous restraint\", has certainly led to some success on the Middle East battlefield, yet it fails to address the central truth: the terrorists we face are mostly homegrown.\n\nTerrorism research, also called terrorism and counter-terrorism research, is an interdisciplinary academic field which seeks to understand the causes of terrorism, how to prevent it as well as its impact in the broadest sense. Terrorism research can be carried out in both military and civilian contexts, for example by research centres such as the British Centre for the Study of Terrorism and Political Violence, the Norwegian Centre for Violence and Traumatic Stress Studies, and the International Centre for Counter-Terrorism (ICCT). There are several academic journals devoted to the field.\n\nOne of the agreements that promote the international legal anti-terror framework is the Code of Conduct Towards Achieving a World Free of Terrorism that was adopted at the 73rd session of the United Nations General Assembly in 2018. The Code of Conduct was initiated by Kazakhstan President Nursultan Nazarbayev. Its main goal is to implement a wide range of international commitments to counter terrorism and establish a broad global coalition towards achieving a world free of terrorism by 2045. The Code was signed by more than 70 countries.\n\nMass media exposure may be a primary goal of those carrying out terrorism, to expose issues that would otherwise be ignored by the media. Some consider this to be manipulation and exploitation of the media.\n\nThe Internet has created a new channel for groups to spread their messages. This has created a cycle of measures and counter measures by groups in support of and in opposition to terrorist movements. The United Nations has created its own online counter-terrorism resource.\n\nThe mass media will, on occasion, censor organizations involved in terrorism (through self-restraint or regulation) to discourage further terrorism. However, this may encourage organizations to perform more extreme acts of terrorism to be shown in the mass media. Conversely James F. Pastor explains the significant relationship between terrorism and the media, and the underlying benefit each receives from the other.\n\nFormer British Prime Minister Margaret Thatcher also famously spoke of the close connection between terrorism and the media, calling publicity 'the oxygen of terrorism'.\n\nJones and Libicki (2008) created a list of all the terrorist groups they could find that were active between 1968 and 2006. They found 648. of those, 136 splintered and 244 were still active in 2006. Of the ones that ended, 43 percent converted to nonviolent political actions, like the Irish Republican Army in Northern Ireland. Law enforcement took out 40 percent. Ten percent won. Only 20 groups, 7 percent, were taken out by military force.\n\nForty-two groups became large enough to be labeled an insurgency; 38 of those had ended by 2006. Of those, 47 percent converted to nonviolent political actors. Only 5 percent were taken out by law enforcement. 26 percent won. 21 percent succumbed to military force. Jones and Libicki concluded that military force may be necessary to deal with large insurgencies but are only occasionally decisive, because the military is too often seen as a bigger threat to civilians than the terrorists. To avoid that, the rules of engagement must be conscious of collateral damage and work to minimize it.\n\nAnother researcher, Audrey Cronin, lists six primary ways that terrorist groups end:\n\nThe following terrorism databases are or were made publicly available for research purposes, and track specific acts of terrorism:\nThe following public report and index provides a summary of key global trends and patterns in terrorism around the world\nThe following publicly available resources index electronic and bibliographic resources on the subject of terrorism\n\nThe following terrorism databases are maintained in secrecy by the United States Government for intelligence and counter-terrorism purposes:\n\nJones and Libicki (2008) includes a table of 268 terrorist groups active between 1968 and 2006 with their status as of 2006: still active, splintered, converted to nonviolence, removed by law enforcement or military, or won. (These data are not in a convenient machine-readable format but are available.)\n\n\n"}
{"id": "6491422", "url": "https://en.wikipedia.org/wiki?curid=6491422", "title": "The Case of the Speluncean Explorers", "text": "The Case of the Speluncean Explorers\n\n\"The Case of the Speluncean Explorers\" is an article by legal philosopher Lon L. Fuller first published in the \"Harvard Law Review\" in 1949. Largely taking the form of a fictional judgment, it presents a legal philosophy puzzle to the reader and five possible solutions in the form of judicial opinions that are attributed to judges sitting on the fictional \"Supreme Court of Newgarth\" in the year 4300.\n\nThe case involves five explorers who are caved in following a landslide. They learn via intermittent radio contact that, without food, they are likely to starve to death before they can be rescued. They decide to engage in cannibalism, and select one of their number to be killed and eaten so that the others may survive. They decide who should be killed by throwing a pair of dice. After the four survivors are rescued, they are charged and found guilty of the murder of the fifth explorer. If their appeal to the Supreme Court of Newgarth fails, they face a mandatory death sentence. Although the wording of the statute is clear and unambiguous, there is intense public pressure for the men to avoid facing the death penalty.\n\nThe article offers five possible judicial responses. Each differs in its reasoning and on whether the survivors should be found guilty of breaching the law. Two judges affirm the convictions, emphasising the importance of the separation of powers and literal approach to statutory interpretation. Two other judges overturn the convictions; one focuses on \"common sense\" and the popular will while the other uses arguments drawn from the natural law tradition, emphasizing the purposive approach. A fifth judge, who is unable to reach a conclusion, recuses himself. As the Court's decision is a tie, the original convictions are upheld and the men are sentenced to death.\n\nFuller's account has been described as \"a classic in jurisprudence\" and \"a microcosm of [the 20th] century's debates\" in legal philosophy. It allows for contrasts to be drawn between different legal philosophies, with the main two being natural law and legal positivism. In the 50 years following the article's publication, a further 25 hypothetical judgments were written by various authors whose perspectives include natural law theory, consequentialism, plain meaning positivism or textualism, purposivism, historical contextualism, realism, pragmatism, critical legal studies, feminism, critical race theory, process theory and minimalism.\n\nThe facts of the case are recounted in the first judicial opinion, which is given by Chief Justice Truepenny.\n\nFive cave explorers became trapped inside a cave following a landslide. They have limited food supplies and no sources of nutrition inside the cave. Above ground, substantial resources are spent to rescue them, with 10 workmen killed in subsequent landslides near the blocked entrance. Radio contact is eventually established with the cavers on the 20th day of the cave-in, and the cavers learn that another 10 days would be required in order to free them. They then consult with medical experts, who inform them that they are unlikely to survive to the rescue given the likelihood of starvation.\n\nOne of the cavers, Roger Whetmore, then asks on the cavers' behalf if the cavers could survive 10 days longer \"if they consumed the flesh of one of their number\". The medical experts reluctantly confirm this to be the case. Whetmore then asks if they should draw lots to select a person to be killed and eaten. No one outside the cave is willing to answer this question. Radio contact is subsequently lost.\n\nOnce the cave-in is cleared, it is discovered that only four cavers have survived; Roger Whetmore had been killed and eaten by the others. The survivors state that Whetmore had originally come up with the ideas of cannibalism and choosing the victim through random chance, offering a pair of dice in his possession.\n\nBefore the dice are cast, Whetmore allegedly expresses a wish to withdraw from the arrangement, preferring to wait another week \"before embracing an expedient so frightful and odious\". The others refuse to accept his change of mind, and cast the dice on his behalf. The survivors claim that Whetmore conceded that the dice were thrown fairly. He is subsequently killed and eaten.\n\nFollowing their rescue and recovery, the survivors are charged with the murder of Whetmore. The relevant statute provides that \"Whoever shall willfully take the life of another shall be punished by death\", offering no exceptions which would be relevant to the case. The jury seek a special verdict, so that they can make limited findings of fact without having to return a verdict on whether it constitutes murder. The cavers are ultimately convicted of murder.\n\nThe mandatory sentence for murder in Newgarth is death by hanging. Both the trial judge and members of the jury petition the Chief Executive to commute the sentence of the surviving spelunkers from the death penalty to six months' imprisonment. The Chief Executive refuses to act while the Supreme Court of Newgarth considers the appeal.\n\nThe first opinion is largely expository; it is used to recount the facts of the case. The Chief Justice states that the statute is unambiguous, with no applicable legal defences, so it must be applied by the court. He adds that granting mercy is a decision for the executive branch of government to make, rather than the judiciary. However, the Chief Justice suggests that the judges of the court should add their names to the petition of the trial judge and jury requesting the Chief Executive to show mercy to the defendants. This would allow justice to be achieved \"without impairing either the letter or spirit of our statutes and without offering any encouragement for the disregard of law\".\n\nThe second opinion takes a different approach to the Chief Justice's. In determining that the convictions should be overturned, Justice Foster makes two main points. Firstly, the defendants were in a \"state of nature\" at the time of the killing, so the laws of nature applied to them. The laws of nature allowed to agree to sacrifice one person for the survival of the rest. Secondly, assuming the laws of Newgarth did apply, a should be used in applying the statute. As its main purpose is deterrence, the judge concluded that, just as with a case of self-defence, the purpose of the statute would not be served by upholding the convictions.\n\nThe judge counters potential objections of judicial activism by suggesting that although judges must obey the will of legislators, they must do so intelligently. He draws analogies to servants who need to \"read between the lines\" of their masters' instructions; strict literal compliance may not always be the actual intention. Thus the \"correction of obvious legislative errors or oversights is not to supplant the legislative will, but to make that will effective.\"\n\nIn the third opinion, Justice Tatting is emotionally \"torn between sympathy for [the defendants] and a feeling of abhorrence and disgust at the monstrous act they committed\". He ultimately finds himself unable to decide the case.\n\nJustice Tatting disagrees strongly with Justice Foster's rationales in overturning the convictions. He criticizes the \"state of nature\" concept and is not satisfied with Justice Foster's formulation placing the law of contract above the law against murder. He also notes the difficulty of applying the purposive approach to the criminal statute which has multiple purposes, including retribution and rehabilitation. He distinguishes the self-defence exception that was created by past judges on the basis that it is not a \"willful\" killing, so it does not contradict the wording of the statute. He finds that the self-defence exception could not be applied to the present case as it would raise \"a quagmire of hidden difficulties\". \n\nThe judge cites the case of \"Commonwealth v Valjean\", in which starvation was held not to justify the theft of a loaf of bread, let alone homicide. These combined objections lead Justice Tatting to reject Justice Foster's reasoning as \"intellectually unsound and approaching mere rationalization.\"\n\nDespite rejecting Justice Foster's reasoning, Justice Tatting cannot bring himself to reach the alternative view, that the defendants' convictions should be upheld. He states that \"almost every consideration that bears on the decision of the case\nis counterbalanced by an opposing consideration leading in the opposite direction.\" Concluding with a criticism of the prosecutor for deciding to bring the prosecution in the first place, the judge makes the \"unprecedented\" decision of withdrawing from the case.\n\nThe fourth opinion begins by excluding executive clemency and the morality of the defendants' actions as relevant factors to the court's deliberations. Rather, the question before the court is purely one of applying the legislation of Newgarth and determining whether the defendants wilfully took the life of Whetmore. He criticizes the other judges for failing to distinguish the legal from the moral aspects of the case. While he shares their preference that the defendants be spared from death, he respects the obligations of his office to put his \"personal predilections\" of what constitutes justice out of mind when interpreting and applying the law.\n\nJustice Keen objects vehemently to Justice Foster's purposive approach allowing the plain words of the law to be ignored. He emphasizes that laws may have many possible purposes, with difficulties arising in divining the actual \"purpose\" of a piece of legislation.\n\nJustice Keen recalls that earlier instances of judicial activism in Newgarth had ultimately led to civil war, which established the supremacy of the legislature over the judiciary. He concludes by criticizing the courts' creation of the self-defence excuse, stating that waiting for the legislature to enact such revisions would have led to a stronger legal system.\n\nIn contrast to the other judges, Justice Handy prefers to use a \"pragmatic, common-sense approach\", rather than abstract legal theories, to resolve the case. He criticizes his colleagues' \"obscuring curtain of legalisms\" when the case simply requires the application of \"practical wisdom\" of \"human realities\". He emphasizes the need for the courts to maintain public confidence, which requires them to follow the 90% majority in favour of applying a token punishment or releasing the defendants altogether. He is prepared to use Justice Foster's purposive approach doctrine as the legal rationale.\n\nJustice Handy notes that apart from the ambivalent Justice Tatting, the other judges share the majority public opinion. The judges voting to uphold the convictions simply differ from Justices Foster and Handy on whose role it is to spare the defendants from the death penalty.\n\n\n\n"}
{"id": "30239225", "url": "https://en.wikipedia.org/wiki?curid=30239225", "title": "The Lampshade: A Holocaust Detective Story from Buchenwald to New Orleans", "text": "The Lampshade: A Holocaust Detective Story from Buchenwald to New Orleans\n\nThe Lampshade: A Holocaust Detective Story from Buchenwald to New Orleans is a 2010 nonfiction book by U.S. author Mark Jacobson. It recounts the attempt to ascertain the origin of a lampshade claimed to be made out of human skin.\n\nIn the aftermath of Hurricane Katrina, a lampshade, purported to be made from the skin of a Jewish Holocaust victim, turned up in a sidewalk rummage sale in New Orleans. Purchased for $35 by Skip Henderson, the lampshade was sent to his friend Mark Jacobson, a writer living in New York. Jacobson embarked on a quest to discover the origin of the lampshade. Genetic testing initially confirmed it was made from human skin. However, because of the condition of the tanned skin, there was no way to determine the ethnic origin of the person whose skin was used, or if it was indeed a relic of the Holocaust.\n\nOver the course of the next few years, Jacobson attempted to track down the origin of and examine the meaning of the lampshade, how it ended up in New Orleans, and to decide what to ultimately do with the gruesome object. Both the United States Holocaust Memorial Museum in Washington, D.C., and the Yad Vashem museum in Jerusalem, declined to take possession of the lampshade, saying that the concentration camp lampshades made of human skin were probably a \"myth\". Over the course of his investigation, Jacobson examines the history of the Buchenwald concentration camp, where such objects were reputed to have been made, as well as the racial and post-Katrina history of New Orleans, the world of Holocaust deniers, the black market trafficking in such goods, and the mythology surrounding objects made from human skin.\n\nIn 2012 the lampshade was subjected to more sophisticated next-generation DNA testing and was found to be most likely cow skin.\n"}
{"id": "1011679", "url": "https://en.wikipedia.org/wiki?curid=1011679", "title": "Transferred intent", "text": "Transferred intent\n\nTransferred intent (or transferred malice in English law) is a legal doctrine that holds that, when the intention to harm one individual inadvertently causes a second person to be hurt instead, the perpetrator is still held responsible. To be held legally responsible under the law, usually the court must demonstrate that the person has criminal intent, that is, that the person knew another would be harmed by his or her actions and wanted this harm to occur. If a murderer intends to kill John, but accidentally kills George instead, the intent is transferred from John to George, and the killer is held to have had criminal intent.\n\nTransferred intent also applies to tort law. In tort law, there are generally five areas in which transferred intent is applicable: battery, assault, false imprisonment, trespass to land, and trespass to chattels. Generally, any \"intent\" to cause any one of these five torts which results in the completion of any of the five tortious acts will be considered an intentional act, even if the actual target of the tort is one other than the intended target of the original tort.\n\nSee cases of \"Carnes v. Thompson\", (1932) Supreme Court of Missouri. 48 S.W. 2d 903 and \"Bunyan v. Jordan\" (1937), 57 C.L.R. 1, 37 S.R.N.S.W. 119 for examples.\n\nIn US criminal law, transferred intent is sometimes explained by stating that \"the intent follows the bullet.\" That is, the intent to kill \"person A\" with a bullet will apply even when the bullet kills the unintended victim, \"person B\" (\"see mens rea\"). Thus, the \"intent\" is \"transferred\" between victims. However, intent only transfers between harms of a similar nature. For example, if the defendant shoots at \"Person A\" intending to kill \"A\" but the bullet misses and instead hits a vase, causing it to break, the defendant is not deemed to have intended to break the vase. This is because destruction of property is a kind of harm different from that contemplated by defendant. The rationale underlying this distinction is that the defendant has only one intent. If the law were to deem that the defendant intended to destroy property, it would be placing on him an intent he never had—he would now have both the intent to kill and the intent to destroy property. In contrast, where the defendant intends to kill one person but ends up killing another, there's still only one intent—the intent to kill.\n\nIt is interesting to compare the principle underlying the Unborn Victims of Violence Act 2004 in the United States which applies only to offenses over which the U.S. government has jurisdiction, namely crimes committed on Federal properties, against certain Federal officials and employees, and by members of the military, but treats the fetus as a separate person for the purposes of all levels of assault including murder and attempted murder:\n\"Sec. 1841. Protection of unborn children\n\nIn the UK the transferred malice doctrine is not without controversy. The House of Lords in \"Attorney General's Reference No 3 of 1994\" reversed the Court of Appeal decision (reported at (1996) 2 WLR 412), holding that the doctrine of transferred malice could not apply to convict an accused of murder in English law when the defendant had stabbed a pregnant woman in the face, back and abdomen. Some days after she was released from hospital in an apparently stable condition, she went into labour and gave birth to a premature child, who died four months later. The child had been wounded in the original attack but the more substantial cause of death was her prematurity. It was argued that the fetus was part of the mother so that any intention to cause grievous bodily harm (GBH) to the mother was also an intent aimed at the fetus. Lord Mustill criticised the doctrine as having no sound intellectual basis, saying that it was related to the original concept of malice, i.e. that a wrongful act displayed a malevolence which could be attached to any adverse consequence, and this had long been out of date. Nevertheless, it would sometimes provide a justification to convict when that was a common sense outcome and so could sensibly be retained. The present case was not a simple \"transfer\" from mother to uterine child, but sought to create an intention to cause injury to the child after birth. This would be a double transfer: first from the mother to the fetus, and then from the fetus to the child when it was born. Then one would have to apply the fiction which converts an intention to commit GBH into the \"mens rea\" of murder. That was too much. But the accused could be convicted of manslaughter.\n\nIn \"R v Gnango\", the Supreme Court controversially held that under the doctrines of joint enterprise and transferred malice D2 is guilty of V's murder if D1 and D2 voluntarily engage in fighting each other, each intending to kill or cause grievous bodily harm to the other and each foreseeing that the other has the reciprocal intention, and if D1 mistakenly kills V in the course of the fight.\n\n"}
{"id": "4919653", "url": "https://en.wikipedia.org/wiki?curid=4919653", "title": "Truth-bearer", "text": "Truth-bearer\n\nA truth-bearer is an entity that is said to be either true or false and nothing else. The thesis that some things are true while others are false has led to different theories about the nature of these entities. Since there is divergence of opinion on the matter, the term \"truth-bearer\" is used to be neutral among the various theories. Truth-bearer candidates include propositions, sentences, sentence-tokens, statements, concepts, beliefs, thoughts, intuitions, utterances, and judgements but different authors exclude one or more of these, deny their existence, argue that they are true only in a derivative sense, assert or assume that the terms are synonymous,\nor seek to avoid addressing their distinction or do not clarify it.\n\nSome distinctions and terminology as used in this article, based on Wolfram 1989\n(Chapter 2 Section1) follow. \n\"It should be understood that the terminology described is not always used in the ways set out, and it is introduced solely for the purposes of discussion in this article.\" Use is made of the type–token and use–mention distinctions. Reflection on occurrences of numerals might be helpful.\nIn grammar a sentence can be a declaration, an explanation, a question, a command. In logic a declarative sentence is considered to be a sentence that can be used to communicate truth. Some sentences which are grammatically declarative are not logically so.\n\nA character is a typographic character (printed or written) etc.\n\nA word-token is a pattern of characters.\nA word-type\nis an identical pattern of characters.\nA meaningful-word-token\nis a meaningful word-token.\nTwo word-tokens which mean the same are of the same word-meaning\n\nA sentence-token is a pattern of word-tokens.\nA meaningful-sentence-token\nis a meaningful sentence-token or a meaningful pattern of meaningful-word-tokens.\nTwo sentence-tokens are of the same sentence-type if they are identical patterns of word-tokens characters\nA declarative-sentence-token is a sentence-token which that can be used to communicate truth or convey information.\nA meaningful-declarative-sentence-token is a meaningful declarative-sentence-token\nTwo meaningful-declarative-sentence-tokens are of the same meaningful-declarative-sentence-type\nif they are identical patterns of word-tokens.\nA nonsense-declarative-sentence-token\nis a declarative-sentence-token which is not a meaningful-declarative-sentence-token.\nA meaningful-declarative-sentence-token-use\noccurs when and only when a meaningful-declarative-sentence-token is used declaratively.\n\nA referring-expression\nis expression that can be used to pick out or refer to particular entity.\nA referential success\nis a referring-expression’s success in identifying a particular entity.\nA referential failure\nis a referring-expression’s failure to identify a particular entity.\nA referentially-successful-meaningful-declarative-sentence-token-use\nis a meaningful-declarative-sentence-token-use containing no referring-expression that fails to identify a particular entity.\n\nAs Aristotle pointed out, since some sentences are questions, commands, or meaningless, not all can be truth-bearers.\nIf in the proposal \"What makes the sentence \"Snow is white\" true is the fact that snow is white\" it is assumed that sentences like \"Snow is white\" are truth-bearers, then it would be more clearly stated as \"What makes the meaningful-declarative-sentence \"Snow is white\" true is the fact that snow is white\".\n\nTheory 1a: \n\nAll and only meaningful-declarative-sentence-types)\nare truth-bearers \nCriticisms of Theory 1a\n\nSome meaningful-declarative-sentence-types will be both truth and false, contrary to our definition of truth-bearer, e.g. (i) the liar-paradox sentences such as \"This sentence is false\". (see Fisher 2008) (ii) Time, place and person dependent sentences e.g. \"It is noon\". \"This is London\", \"I'm Spartacus\".\n\n\"Anyone may ..ascribe truth and falsity to the deterministic propositional signs we here call utterances. But if he takes this line, he must, like Leibniz, recognise that truth cannot be an affair solely of actual utterances, since it makes sense to talk of the discovery of previously un-formulated truths.\" (Kneale, W&M (1962))\n\nRevision to Theory 1a, by making a distinction between type and token.\n\nTo escape the time, place and person dependent criticism the theory can be revised, making use or the type–token distinction, as follows\n\nTheory 1b: \n\nAll and only meaningful-declarative-sentence-tokens are truth-bearers \n\nQuine argued that the primary truth-bearers are utterances \nHaving now recognised in a general way that what are true are sentences, we must turn to certain refinements. What are best seen as primarily true or false are not sentences but events of utterances. If a man utters the words 'It is raining' in the rain, or the words 'I am hungry' while hungry, his verbal performance counts as true. Obviously one utterance of a sentence may be true and another utterance of the same sentence be false.\n\nQUINE 1970 page 13\n\nCriticisms of Theory 1b\n\n(i) Theory 1b prevents sentences which are meaningful-declarative-sentence-types from being truth-bearers. If all meaningful-declarative-sentence-types typographically identical to \"The whole is greater than the part\" are true then it surely follows that the meaningful-declarative-sentence-type \"The whole is greater than the part\" is true (just as all meaningful-declarative-sentence-tokens typographically identical to \"The whole is greater than the part\" are English entails the meaningful-declarative-sentence-types \"The whole is greater than the part\" is English) (ii) Some meaningful-declarative-sentences-tokens will be both truth and false, or neither, contrary to our definition of truth-bearer. E.g. A token, t, of the meaningful-declarative-sentence-type ‘P: I'm Spartacus’, written on a placard. The token t would be true when used by Spartacus, false when used by Bertrand Russell, neither true nor false when mentioned by Spartacus or when being neither used nor mentioned.\n\nTheory 1b.1\n\nAll meaningful-declarative-sentence-token-uses are truth-bearers; some meaningful-declarative-sentence-types are truth-bearers\n\nTo allow that at least some meaningful-declarative-sentence-types can be truth-bearers Quine allowed so-called eternal sentences to be truth-bearers.\n\nIn Peirces's terminology, utterances and inscriptions are \"tokens\" of the sentence or other linguistic expression concerned; and this linguistic expression is the \"type\" of those utterances and inscriptions. In Frege's terminology, truth and falsity are the two \"truth values\". Succinctly then, an eternal sentence is a sentence whose tokens have the same truth values... What are best regarded as true and false are not propositions but sentence tokens, or sentences if they are eternal \nQuine 1970 pages 13–14\n\nTheory 1c\n\nAll and only meaningful-declarative-sentence-token-uses are truth-bearers \n\nArguments for Theory 1c\n\nBy respecting the use–mention Theory 1c avoids criticism (ii) of Theory 1b.\n\nCriticisms of Theory 1c\n\n(i) Theory 1c does not avoid criticism (i) of Theory 1b. (ii) meaningful-declarative-sentence-token-uses are events (located in particular positions in time and space) and entail a user. This implies that (a) nothing (no truth-bearer) exists and hence nothing (no truth-bearer) is true (of false) anytime anywhere (b) nothing (no truth-bearer) exists and hence nothing (no truth-bearer) is true (of false) in the absence of a user. This implies that (a) nothing was true before the evolution of users capable of using meaningful-declarative-sentence-tokens and (b) nothing is true (or false) accept when being used (asserted) by a user. Intuitively the truth (or falsity) of ‘The tree continues to be in the quad’ continues in the absence of an agent to asset it.\n\nReferential Failure\nA problem of some antiquity is the status of sentences such as \nU: The King of France is bald\nV: The highest prime has no factors\nW: Pegasus did not exist \nSuch sentences purport to refer to entitles which do not exist (or do not always exist). They are said to suffer from referential failure. We are obliged to choose either (a) That they are not truth-bearers and consequently neither true nor false or (b) That they are truth-bearers and per se are either true of false.\n\nTheory 1d\n\nAll and only referentially-successful-meaningful-declarative-sentence-token-uses are truth-bearers. \n\nTheory 1d takes option (a) above by declaring that meaningful-declarative-sentence-token-uses that fail referentially are not truth-bearers.\n\nTheory 1e\n\nAll referentially-successful-meaningful-declarative-sentence-token-uses are truth-bearers; some meaningful-declarative-sentence-types are truth-bearers\n\nArguments for Theory 1e\n\nTheory 1e has the same advantages as Theory 1d. Theory 1e allows for the existence of truth-bearers (i.e., meaningful-declarative-sentence-types) in the absence of users and between uses. If for any x, where x is a use of a referentially successful token of a meaningful-declarative-sentence-type y x is a truth-bearer then y is a truth-bearer otherwise y is not a truth bearer. E.g. If all uses of all referentially successful tokens of the meaningful-declarative-sentence-type ‘The whole is greater than the part’ are truth-bearers (i.e. true or false) then the meaningful-declarative-sentence-type ‘The whole is greater than the part’ is a truth-bearer. If some but not all uses of some referentially successful tokens of the meaningful-declarative-sentence-type ‘I am Spartacus’ are true then the meaningful-declarative-sentence-type ‘I am Spartacus’ is not a truth-bearer.\n\nCriticisms of Theory 1e\n\nTheory 1e makes implicit use of the concept of an agent or user capable of using (i.e. asserting) a referentially-successful-meaningful-declarative-sentence-token. Although Theory 1e does not depend on the actual existence (now, in the past or in the future) of such users, it does depend on the possibility and cogency of their existence. Consequently, the concept of truth-bearer under Theory 1e is dependent upon giving an account of the concept of a ‘user’. In so far as referentially-successful-meaningful-declarative-sentence-tokens are particulars (locatable in time and space) the definition of truth-bearer just in terms of referentially-successful-meaningful-declarative-sentence is attractive to those who are (or would like to be) nominalists. The introduction of ‘use’ and ‘users’ threatens the introduction of intentions, attitudes, minds &c. as less-than=welcome ontological baggage\n\nIn classical logic a sentence in a language is true or false under (and only under) an interpretation and is therefore a truth-bearer. For example, a language in the first-order predicate calculus might include one of more predicate symbols and one or more individual constants and one or more variables. The interpretation of such a language would define a domain (universe of discourse); assign an element of the domain to each individual constant; assign the donation in the domain of some property to each unary (one-place) predicate symbol.\n\nFor example, if a language L consisted in the individual constant \"a\", two unary predicate letters \"F\" and \"G\" and the variable \"x\", then an interpretation I of L might define the Domain D as animals, assign Socrates to \"a\", the denotation of the property being a man to \"F\" and the denotation of the property being mortal to \"G\". Under the interpretation I of L then \"Fa\" would be true if, and only if Socrates is a man, and the sentence \"(Fx Gx)\" would be true if, and only if all men (in the domain) are mortal. In some texts an interpretation is said to give \"meaning\" to the symbols of the language. Since \"Fa\" has the value true under some (but not all interpretations) it is not the sentence-type \"Fa\" which is said to be true but only some sentence-tokens of \"Fa\" under particular interpretations. A token of \"Fa\" without an interpretation is neither true nor false. Some sentences of a Language like L are said to be true under all interpretations of the sentence, e.g. \"(Fx Fx),\" such sentences being termed logical truths, but again such sentences are neither true nor false in the absence of an interpretation.\n\nMany authors use the term proposition as truth-bearers. There is no single definition or usage. Sometimes it is used to mean a \"meaningful declarative sentence\" itself; sometimes it is used to mean the meaning of a meaningful declarative sentence. This provides two possible definitions for the purposes of discussion as below\n\nTheory 2a: \nAll and only meaningful-declarative-sentences are propositions\n\nTheory 2b:\nA meaningful-declarative-sentence-token expresses a proposition; two meaningful-declarative-sentence-tokens which have the same meaning express the same proposition; two meaningful-declarative-sentence-tokens with different meanings express different propositions.\n\n\"Proposition\" is not always used in one or other of these ways.\n\nCriticisms of Theory 2a. \n\nCriticisms of Theory 2b\n\nsee also Willard Van Orman Quine, Proposition, \"The Russell-Myhill Antinomy\", also known as the \"Principles of Mathematics Appendix B Paradox\"\n\nsee also Internet Encycypedia of Philosophy \"Propositions are abstract entities; they do not exist in space and time. They are sometimes said to be “timeless”, “eternal”, or “omnitemporal” entities. Terminology aside, the essential point is that propositions are not concrete (or material) objects. Nor, for that matter, are they mental entities; they are not “thoughts” as Frege had suggested in the nineteenth century. The theory that propositions are the bearers of truth-values also has been criticized. Nominalists object to the abstract character of propositions. Another complaint is that it’s not sufficiently clear when we have a case of the same propositions as opposed to similar propositions. This is much like the complaint that we can’t determine when two sentences have exactly the same meaning. The relationship between sentences and propositions is a serious philosophical problem.\"\n\nMany authors consider \"statements\" as truth-bearers, though as with the term \"proposition\" there is divergence in definition and usage of that term. Sometimes 'statements' are taken to be meaningful-declarative-sentences; sometimes they are thought to be what is asserted by a meaningful-declarative-sentence. It is not always clear in which sense the word is used. This provides two possible definitions for the purposes of discussion as below.\n\nA particular concept of a statement was introduced by Strawson in the 1950s.,\n\nConsider the following:\n\nOn the assumption that the same person wrote Waverley and Ivanhoe, the two distinct patterns of characters (meaningful-declarative-sentences) I and J make the same statement but express different propositions. \nThe pairs of meaningful-declarative-sentences (K, L) & (M, N) have different meanings, but they are not necessarily contradictory, since K & L may have been asserted by different people, and M & N may have been asserted about different conductors.\n\n\"What these examples show is that we cannot identify that which is true or false (the statement) with the sentence used in making it; for the same sentence may be used to make different statements, some of them true and some of them false.\" (Strawson, P.F. (1952))\n\nThis suggests:\n\n\nTheory 3a\n\nAll and only statements are meaningful-declarative-sentences. \n\nTheory 3b\n\nAll and only meaningful-declarative-sentences can be used to make statements \n\n\"Statement\" is not always used in one or other of these ways.\n\nArguments for Theory 3a\n\nCriticisms of Theory 3a\n\n\nArguments for Theory 3b\n\nFrege (1919) argued that an indicative sentence in which we communicate or state something, contains both a thought and an assertion, it expresses the thought, and the thought is the sense of the sentence.\n\n"}
{"id": "810708", "url": "https://en.wikipedia.org/wiki?curid=810708", "title": "Universal Declaration of Linguistic Rights", "text": "Universal Declaration of Linguistic Rights\n\nThe Universal Declaration of Linguistic Rights (known also as the Barcelona Declaration) is a document signed by the International PEN Club, and several non-governmental organizations in 1996 to support linguistic rights, especially those of endangered languages. The document was adopted at the conclusion of the World Conference on Linguistic Rights held 6–9 June 1996 in Barcelona, Spain. It was also presented to the UNESCO Director General in 1996 but the Declaration has not gained formal approval from UNESCO.\n\nAlthough the 1948 Universal Declaration of Human Rights (UDHR) has language as one of its categories for equal rights, it does not explicitly list and elaborate on linguistic rights. Even with declarations and rules on protecting specific languages and their rights, there was no binding document at that time that referred to all the languages or to world linguistic rights. As such, there have been attempts to fill this gap by expanding on the importance of linguistic rights in the global scene.\n\nIn addition, the Universal Declaration of Linguistic Rights (UDLR) holds regards to several policies that motivated the respect of linguistic rights. Some of the documents include:\n\nThe idea of a Declaration was first proposed in 1984, where a Brazilian by the name of Francisco Gomes de Matos introduced to the International Federation of Modern Language Teachers (FIPLV), a plea for a Universal Declaration of Linguistic Rights. He listed some of the principal linguistic rights, together with their educational implications.\n\nOne of the most significant motivations stemmed from the 12th Seminar of the International Association for the Development of Intercultural Communication of 1987, held in Recife, Brazil, which also recommended the introduction of a declaration for linguistic rights. The Seminar then adopted a preliminary declaration that indexed some fundamental types of linguistic rights.\n\nThe main objective of penning a Declaration was to define equality in linguistic rights, regardless of differences in political or territorial statuses. It serves to promote international commitment in respecting the rights of linguistic groups, especially those of historicity, as well as individuals who do not reside within their native communities.\n\nAs such, the UDLR does not distinguish among official, non-official, majority, local, regional, and minority languages. There was much complexity tied to the drafting process because it was not easy to come up with equal measures, definitions and reasons, especially since it required an international consensus. For instance, one of the most common problems lie in clarifying concepts and their terminologies. Subsequently, follow-up meetings and feedback sessions were held in Paris, Portugal and Frankfurt.\n\nIn 1990, the FIPLV drafted a working document. On August 1991, the FIPLV organised a workshop in Pécs, Hungary. It was there that they managed to consolidate an agenda on fundamental principles for a UDLR. The Declaration was also discussed in December 1993, during a session of the Translations and Linguistic Rights Commission of the International PEN.\n\nAt the beginning of 1994, a team was rooted to facilitate the process of writing the official document. About 40 experts from different countries and fields were involved in the first 12 drafts of the Declaration. Progressively, there were continuous efforts in revising and improving the Declaration as people contributed ideas to be included in it.\n\nIt was on 6 June 1996, during the World Conference on Linguistic Rights in Barcelona, Spain, that the Declaration was acknowledged. The Conference, which was an initiative of the Translations and Linguistic Rights Commission of the International PEN Club and the CIEMEN (Escarre International Center for Ethnic Minorities and the Nations), comprised 61 NGOs, 41 PEN Centers and 40 experts. The document was signed and presented to a representative of the UNESCO Director General. However, this does not mean that the Declaration has gained approval.\n\nIn the same year, the Declaration was published in Catalan, English, French and Spanish. It was later translated into other languages, some of which include Galician, Basque, Bulgarian, Hungarian, Russian, Portuguese, Italian, Nynorsk, Sardinian.\n\nEven so, there have been continuous efforts to bring the Declaration through as UNESCO did not officially endorse the UDLR at its General Conference in 1996, and also in subsequent years, although they morally supported it.\n\nAs a result, a Follow-up Committee of the Universal Declaration of Linguistic Rights (FCUDLR) was created by the World Conference on Linguistic Rights. The FCUDLR is also represented by the CIEMEN, which is a non-profit and non-government organisation. The main objectives of having a follow-up committee was to 1) garner support, especially from international bodies, so as to lend weight to the Declaration and see it through to UNESCO, 2) to maintain contact with UNESCO and take into account the many viewpoints of its delegates, and 3) to spread awareness of the UDLR and establish a web of support.\n\nConsequently, the committee started a Scientific Council consisting of professionals in Linguistic Law. The duty of the Council is to update and improve the Declaration from time to time by gathering suggestions from those who are keen on the issue of linguistic rights.\n\nThe following summarises the progress of the UDLR:\n\nThe preamble of the Declaration provides six reasons underlying the motivations to promote the stated principles.\n\nTo ensure clarity in applicability across diverse linguistic environments, the declaration has included a preliminary title that addresses the definitions of concepts used in its articles (Articles 1-6). Title One (Articles 7-14) lists general principles asserting equal linguistic rights for language communities and for the individual. Besides the main principles, the second title delves into an overall linguistic régime and is further divided into 6 sections. Section 1 (Articles 15-22) addresses language usage related to public administration and official bodies. Section 2 (Articles 23-30) touches on linguistic rights involving educational fields. \nSection 3 (Articles 31-34) defines linguistic rights concerning naming, while Section 4 (Articles 35-40) asserts the entitlement of language groups to mass media resources and new technologies. Section 5 (Articles 41-46) outlines the rights related to cultural artifacts. The last section of the second title, Section 6 (Article 47-52), touches on the individual or language group's rights in the socioeconomic sphere.\n\nThe Additional Dispositions call for the obligation of public powers to take measures ensuring the application of these rights and to inform other related bodies of these proclamations. As for the Final Dispositions, the founding of a Council of the Languages within the United Nations Organization is put forth, as well as the creation of a World Commission for Linguistic Rights, which is to be an unofficial, consultative council composed of experts in non-governmental organizations and those in the field of linguistic law.\n\nPreliminary Title: Article 1\n\n1. This Declaration considers as a language community any human society established historically\nin a particular territorial space, whether this space be recognized or not, which identifies itself as a\npeople and has developed a common language as a natural means of communication and cultural\ncohesion among its members. The term language specific to a territory refers to the language of the\ncommunity historically established in such a space.\n\nOne of the comments made was on the idealistic nature of the Declaration. As the Declaration considers all languages equal, it rejects terms such as ‘official’, ‘regional’ or ‘minority’ languages and strongly advocates the full use of all historic community languages.\n\nDrawing from the articles pertaining to the educational issues (Articles 25, 26 and 30), it is stated that the education system should fully support the development of their community languages and other languages they wish to know in schools to the point of fluency and capability to use it in all social situations. In addition, research on language and culture of language communities is to be done at the university level. It has been argued that the 'rights' stated in those articles will remain the privilege of powerful language communities. The reason is that since the Declaration requires authorities to issue sanctions in the event of violation of the proclaimed rights, doubts have arisen regarding the likelihood of any government adopting the document. Many governmental groups (other than the regional authorities in Spain such as Catalonia, Menorca and Basque) in most countries find it hard to reconcile these fundamental principles of the Declaration with their current language policies and practices.\nThere is a need to balance between regulations imposed by governments and the protection of the rights of the people in different language communities. Considerations such as acknowledging the primary human rights of minority peoples (e.g. issues of physical survival) are, instead, regarded as more dire than an issue like linguistic rights. Linguistic rights will hence be ignored before primary human rights can be properly attended to. Furthermore, the cost involved in executing sanctions is another cause of concern. The main issue, however, is the fact that the article is not legally binding and duty-holders are never specified.\n\nOther responses include the issue that more rights are given to ‘language communities’ in the Declaration. In the context of education, it is observed that other than language communities (equivalent to ‘national territorially based minorities'), those who do not fit under this category will have to ‘assimilate’, as having the right to education in the language of the territory does not necessarily equate to having the right to an education in one’s own language.\n\nThe Declaration is not constitutional and has not been ratified by the UN General Assembly, unlike the Universal Declaration of Human Rights. Despite the Follow-up Committee’s publication of the text in 1998, which was backed by letters of support from world leaders, UNESCO has not ratified the document. On 19 April 2002, CIEMEN and International PEN convoked a summit during the World Congress on Language Policies in Barcelona. The FIPLV suggested that it would modify the Declaration so that it would be accepted and implemented. There were also further efforts to foster support for the UDLR through proposals and conferences in 2003.\n\nSince 2008, CIEMEN has been lobbying to place linguistic rights on the agenda of the states that are currently members of the United Nations Human Rights Council (UNHRC). Despite the positive responses to the document, member states perceived a lack of consensus on the matter and did not wish to be among the first to adopt the proposal. An event organised in Geneva in 2008, entitled \"Linguistic Rights to enhance Human Rights\", which coincided with the Eighth Session of the UNHRC, aimed to garner support for a draft resolution for the UDLR to be presented at the September session of the UNHRC conference. Ambassadors from Mexico, Bolivia, Chile, Armenia and Nigeria expressed their support in a series of interviews. Later in September, the Advisory Committee of the UNHRC was called upon to take steps to present a proposal, in hopes that the UDLR could be added to the Universal Declaration of Human Rights.\n\nThe Girona Manifesto was developed by International PEN's Translation and Linguistic Rights in May 2011 to commemorate the fifteenth anniversary of the Declaration. The Girona Manifesto is an updated version that condenses the primary principles of the UDLR to aid its implementation. In September 2011, the manifesto was ratified by the International PEN Assembly of Delegates at the 77th Congress.\n\nThe content of the manifesto is based on the Universal Declaration’s 10 central principles. In contrast to the comprehensive and complex declaration which plays an important role in the field of linguistics and politics, the manifesto is laid out in a concise and practical way, intended to be ‘translated and disseminated as a tool to defend linguistic diversity around the world'. The goal is to bring attention the issue of language rights back to the international agenda.\n\nIt is thought to be an important step toward protecting and promoting all of the world's languages, including the ones at risk of extinction. As John Ralston Saul, President of International PEN mentioned, \"[It] could give us a clear public document with which to defend and advance languages with smaller populations as well as endangered languages\".\n\nOn 5 March 2012, the Girona Manifesto and its translated versions were presented at an event organized by Catalan PEN Centre. It was held at the Palau de la Generalitat, Barcelona. The manifesto has been translated in 32 languages to date.\n\nText of the Girona Manifesto on Linguistic Rights:\n\n1. Linguistic diversity is a world heritage that must be valued and protected.\n\n2. Respect for all languages and cultures is fundamental to the process of constructing and maintaining dialogue and peace in the world.\n\n3. All individuals learn to speak in the heart of a community that gives them life, language, culture and identity.\n\n4. Different languages and different ways of speaking are not only means of communication; they are also the milieu in which humans grow and cultures are built.\n\n5. Every linguistic community has the right for its language to be used as an official language in its territory.\n\n6. School instruction must contribute to the prestige of the language spoken by the linguistic community of the territory.\n\n7. It is desirable for citizens to have a general knowledge of various languages, because it favours empathy and intellectual openness, and contributes to a deeper knowledge of one’s own tongue.\n\n8. The translation of texts, especially the great works of various cultures, represents a very important element in the necessary process of greater understanding and respect among human beings.\n\n9. The media is a privileged loudspeaker for making linguistic diversity work and for competently and rigorously increasing its prestige.\n\n10. The right to use and protect one’s own language must be recognized by the United Nations as one of the fundamental human rights\n\nToday, the UDLR has the support of many international personalities, some of whom include: Nelson Mandela, Buthelezi Mangosuthu Gatsha, Ronald Harwood, Homero Aridjis, Noam Chomsky, José Ramos-Horta, Dalai Lama, Dr. M. Aram, Desmond Tutu, László Tőkés, Ricardo María Carles Gordó, Adolfo Pérez Esquivel, José Carreras, Seamus Heaney, Ngũgĩ wa Thiong'o, Shimon Peres, Judit Mascó, Peter Gabriel and Joan Oró.\n\n\n"}
{"id": "45107264", "url": "https://en.wikipedia.org/wiki?curid=45107264", "title": "Vector addition system", "text": "Vector addition system\n\nA vector addition system (VAS) is one of several mathematical modeling languages for the description of distributed systems. Vector addition systems were introduced by Richard M. Karp and Raymond E. Miller in 1969, and generalized to vector addition systems with states (VASS) by John E. Hopcroft and Jean-Jacques Pansiot in 1979. Both VAS and VASS are equivalent in many ways to Petri nets introduced earlier by Carl Adam Petri. \n\nA \"vector addition system\" consists of a finite set of integer vectors. An initial vector is seen as the initial values of multiple counters, and the vectors of the VAS are seen as updates. These counters may never drop below zero. More precisely, given an initial vector with non negative values, the vectors of the VAS can be added componentwise, given that every intermediate vector has non negative values. A \"vector addition system with states\" is a VAS equipped with control states. More precisely, it is a finite directed graph with arcs labelled by integer vectors. VASS have the same restriction that the counter values should never drop below zero.\n\n\n\n"}
