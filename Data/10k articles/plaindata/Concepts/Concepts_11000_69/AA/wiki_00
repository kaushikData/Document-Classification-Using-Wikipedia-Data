{"id": "2613929", "url": "https://en.wikipedia.org/wiki?curid=2613929", "title": "Almost convergent sequence", "text": "Almost convergent sequence\n\nA bounded real sequence formula_1 is said to be \"almost convergent\" to formula_2 if each Banach limit assigns\nthe same value formula_2 to the sequence formula_1.\n\nLorentz proved that formula_1 is almost convergent if and only if\nuniformly in formula_7.\n\nThe above limit can be rewritten in detail as\nAlmost convergence is studied in summability theory. It is an example of a summability method\nwhich cannot be represented as a matrix method.\n\n\n"}
{"id": "51877652", "url": "https://en.wikipedia.org/wiki?curid=51877652", "title": "Anchored Instruction", "text": "Anchored Instruction\n\nAnchored Instruction is a technology centered learning approach, which falls under the social constructionism paradigm. It is a form of situated learning that emphasizes problem-solving within an integrated learning context, which can be examined from multiple perspectives. \"In other words, the learning is contextualized to provide students with realistic roles that serve to enhance the learning process\", (Fried, Zannini, Wheeler, Lee, & Cortez, 2005). During teaching, activities are designed or tied around an \"anchor\", such as an adventure or story, with a problem at the end, that needs to be resolved. The connection made between the content and the authentic context is referred to as \"anchoring\". These models typically embed all the information needed for the problem to be solved, such data and hints. Anchored instruction is akin to Problem-based learning (P.B.L.) with the exception of its open-endedness.\n\nThe seven principles outlined, are used to govern the design of anchored instruction (Biswas, Goldman, & Bransford, 1997).\n\n\nAnchored instruction highlights the use of Instructional technology. Teachers are moved from the source of information to a coach. It is widely used at primary levels, and is applied to Mathematics, Reading and Language skills.\n\nAnchored instruction, promotes active learning, by motivating and challenging learners. The story or anchor contains embedded data along with other extraneous information; it is the learner's responsibility to decipher, extract and organize pertinent information. The problem that needs to be solved, often requires the learner to take multiple steps, by generating a man smaller questions, that ought to support and guide their thinking. Small groups of learners are the appropriate size for this type of instruction. Members of the group often provide multiple opinions, thus having multiple solutions to the problem. Students are responsible for establishing their learning goals\n\nThe facilitators are responsible for providing the anchor, the problem statement and embedded data in the story. Anchored stories also contain hints that act as instructional scaffolding to resolve problems. Scaffolding provides a temporary framework to support learning. The facilitator coaches and guides the learners through the learning process. They assist students to establish their own learning goals. And accept that they are no longer the major source of knowledge.\n\n"}
{"id": "511014", "url": "https://en.wikipedia.org/wiki?curid=511014", "title": "Attribution bias", "text": "Attribution bias\n\nIn psychology, an attribution bias or attributional bias is a cognitive bias that refers to the systematic errors made when people evaluate or try to find reasons for their own and others' behaviors. People constantly make attributions regarding the cause of their own and others' behaviors; however, attributions do not always accurately reflect reality. Rather than operating as objective perceivers, people are prone to perceptual errors that lead to biased interpretations of their social world.\n\nAttribution biases were first discussed in the 1950s and '60s by psychologists such as Fritz Heider, who studied attribution theory. Other psychologists, such as Harold Kelley and Ed Jones expanded Heider's early work by identifying conditions under which people are more or less likely to make different types of attributions.\n\nAttribution biases are present in everyday life, and therefore are an important and relevant topic to study. For example, when a driver cuts us off, we are more likely to attribute blame to the reckless driver (e.g., \"What a jerk!\"), rather than situational circumstances (e.g., \"Maybe they were in a rush and didn't notice me\"). Additionally, there are many different types of attribution biases, such as the ultimate attribution error, fundamental attribution error, actor-observer bias, and hostile attribution bias. Each of these biases describes a specific tendency that people exhibit when reasoning about the cause of different behaviors.\n\nSince the early work, researchers have continued to examine how and why people exhibit biased interpretations of social information. Many different types of attribution biases have been identified, and more recent psychological research on these biases has examined how attribution biases can subsequently affect emotions and behavior.\n\nResearch on attribution biases is founded in attribution theory, which was proposed to explain why and how we create meaning about others' and our own behavior. This theory focuses on identifying how an observer uses information in his/her social environment in order to create a causal explanation for events. Attribution theory also provides explanations for why different people can interpret the same event in different ways and what factors contribute to attribution biases.\n\nPsychologist Fritz Heider first discussed attributions in his 1958 book, \"The Psychology of Interpersonal Relations\". Heider made several important contributions that laid the foundation for further research on attribution theory and attribution biases. He noted that people tend to make distinctions between behaviors that are caused by personal disposition versus environmental or situational conditions. He also predicted that people are more likely to explain others' behavior in terms of dispositional factors (i.e., caused by a given person's personality), while ignoring the surrounding situational demands.\n\nBuilding on Heider's early work, other psychologists in the 1960s and 70s extended work on attributions by offering additional related theories. In 1965, social psychologists Edward E. Jones and Keith Davis proposed an explanation for patterns of attribution termed \"correspondent inference theory\". A 'correspondent inference' assumes that a person's behavior reflects a stable disposition or personality characteristic. They explained that certain conditions make us more likely to make a correspondent inference about someone's behavior:\n\n\nSoon after Jones and Davis first proposed their correspondent inference theory, Harold Kelley, a social psychologist famous for his work on interdependence theory as well as attribution theory, proposed a \"covariation model\" to explain the way people make attributions. This model helped to explain how people choose to attribute a behavior to an internal disposition versus an environmental factor. Kelley used the term 'covariation' to convey that when making attributions, people have access to information from many observations, across different situations, and at many time points; therefore, people can observe the way a behavior varies under these different conditions. He proposed three factors that influence the way we explain behavior:\n\n\nKelley proposed that people are more likely to make dispositional attributions when consensus is low (most other people don't behave in the same way), consistency is high (a person behaves this way across most situations), and distinctiveness is low (a person's behavior is not unique to this situation). Alternatively, situational attributions are more likely reached when consensus is high, consistency is low, and distinctiveness is high. His research helped to reveal the specific mechanisms underlying the process of making attributions.\n\nAs early researchers explored the way people make causal attributions, they also recognized that attributions do not necessarily reflect reality and can be colored by a person's own perspective. Certain conditions can prompt people to exhibit attribution bias, or draw inaccurate conclusions about the cause of a given behavior or outcome. In his work on attribution theory, Fritz Heider noted that in ambiguous situations, people make attributions based on their own wants and needs, which are therefore often skewed. He also explained that this tendency was rooted in a need to maintain a positive self-concept, later termed the self-serving bias.\n\nKelley's covariation model also led to the acknowledgment of attribution biases. The model explained the conditions under which people will make informed dispositional versus situational attributions. But, it assumed that people had access to such information (i.e., the consensus, consistency, and distinctiveness of a person's behavior). What about when we don't have access to such information, for example, when interacting with someone we don't know well? Lack of information results in a tendency to take cognitive shortcuts, resulting in different types of attribution biases, such as the actor-observer bias that will be discussed below.\n\nAlthough psychologists agreed that people are prone to these cognitive biases, there existed disagreement concerning the cause of such biases. On one hand, supporters of a \"cognitive model\" argued that biases were a product of human information processing constraints. One major proponent of this view was Yale psychologist Michael Storms, who proposed this cognitive explanation following his 1973 study of social perception. In his experiment, participants viewed a conversation between two individuals; we'll call them Actor one and Actor two. Some participants viewed the conversation while facing Actor one, such that they were unable to see the front of Actor two, while other participants viewed the conversation while facing Actor two, obstructed from the front of Actor one. Following the conversation, participants were asked to make attributions about the conversationalists. He found that participants ascribed more causal influence to the person they were looking at. In other words, participants made different attributions about people depending on the information they had access to. Storms used these results to bolster his theory of cognitively driven attribution biases; because we have no access to the world except for through our own eyes, we are inevitably constrained and consequently prone to biases. Similarly, social psychologist Anthony Greenwald described humans as possessing a \"totalitarian ego\", meaning that we view the world through our own personal selves. Therefore, different people inevitably interpret the world differently and in turn reach different conclusions.\n\nThese views of attributional biases as being a sole product of information processing constraints received criticism from researchers who argued that humans do not just passively interpret their world and make attributions; rather, they are active and goal-driven. Building on this criticism, research began to focus on the role of motives in driving attribution biases. Researchers such as Ziva Kunda drew attention to the motivated aspects of attributions and attribution biases. Kunda in particular argued that certain biases only appear when people are presented with motivational pressures; therefore, they can't be exclusively explained by an objective cognitive process. More specifically, we're more likely to construct biased social judgments when we're motivated to arrive at a particular conclusion, so long as we can justify this conclusion.\n\nEarly researchers explained attribution biases as cognitively driven and a product of information processing errors. In the early 1980s, studies demonstrated that there may also be a motivational component to attribution biases, such that our own desires and emotions affect how we interpret social information. Current research continues to explore the validity of both of these explanations by examining the function of specific types of attribution biases and their behavioral correlates through a variety of methods (e.g., research with children or using brain imaging techniques).\n\nRecent research on attribution biases has focused on identifying specific types of these biases and their effect on people's behavior. Additionally, some psychologists have taken an applied approach and demonstrated how these biases can be understood in real-world contexts (e.g., the workplace or school). Researchers have also used the theoretical framework of attributions and attribution biases in order to modify the way people interpret social information. Studies have implemented attributional retraining to help, for example, students have more positive perceptions of their own academic abilities.\n\nThere is much inconsistency in the claims made by scientists and researchers that attempt to prove or disprove attribution theories and the concept of attributional biases. The theory was formed as a comprehensive explanation of the way people interpret the basis of behaviors in human interactions. However, there have been studies that indicate cultural differences in the attribution biases between people of Eastern and Western societies. Also, some scientists believe that attributional biases are only exhibited in certain contexts of interaction where possible outcomes or expectations make the forming of attributions necessary. These criticisms of the attribution model reveal that the theory may not be a general, universal principle.\n\nResearchers have identified many different specific types of attribution biases, all of which describe ways in which people exhibit biased interpretations of information. Note that this is not an exhaustive list (see List of attributional biases for more).\n\nThe fundamental attribution error refers to a bias in explaining others' behaviors. According to this error, when we make attributions about another person's actions, we are likely to overemphasize the role of dispositional factors, while minimizing the influence of situational factors. For example, if we see a coworker bump into someone on his way to a meeting, we are more likely to explain this behavior in terms of our coworker's carelessness or hastiness, rather than considering that he was running late to a meeting.\n\nThis term was first proposed in the early 1970s by psychologist Lee Ross following an experiment he conducted with Edward E. Jones and Victor Harris in 1967. In this study, participants were instructed to read two essays; one expressed pro-Castro views, and the other expressed anti-Castro views. Participants were then asked to report their attitudes towards the writers under two separate conditions. When participants were informed that the writers voluntarily chose their position towards Castro, participants predictably expressed more positive attitudes towards the anti-Castro writer. However, when participants were told that the writers' positions were determined by a coin toss, rather than their own free will, participants continued to express more positive attitudes towards the anti-Castro writer. These results demonstrated that participants did not take situational factors into account when evaluating a third party, providing evidence of what was later coined the fundamental attribution error.\n\nThe actor-observer bias (also actor–observer asymmetry) can be thought of as an extension of the fundamental attribution error. According to the actor-observer bias, in addition to over-valuing dispositional explanations of others' behaviors, we tend to under-value dispositional explanations and over-value situational explanations of our \"own\" behavior. For example, a student who studies may explain her behavior by referencing situational factors (e.g., \"I have an exam coming up\"), whereas others will explain her studying by referencing dispositional factors (e.g., \"She's ambitious and hard-working\"). This bias was first proposed by Edward E. Jones and Richard E. Nisbett in 1971, who explained that \"actors tend to attribute the causes of their behavior to stimuli inherent in the situation, while observers tend to attribute behavior to stable dispositions of the actor.\"\n\nThere has been some controversy over the theoretical foundation of the actor-observer bias. In a 2006 meta-analysis of all published studies of the bias since 1971, the author found that Jones' and Nisbett's original explanation did not hold. Whereas Jones and Nisbett proposed that actors and observers explain behaviors as attributions to either dispositions or situational factors, examining past studies revealed that this assumption may be flawed. Rather, the theoretical reformulation posits that the way we explain behavior depends on whether or not it is intentional, among other things. For more information on this theoretical reformulation, see actor-observer asymmetry, or refer to Malle's meta-analysis in #Further reading.\n\nA self-serving bias refers to people's tendency to attribute their successes to internal factors but attribute their failures to external. This bias helps to explain why we tend to take credit for our successes while often denying any responsibility for failures. For example, a tennis player who wins his match might say, \"I won because I'm a good athlete,\" whereas the loser might say, \"I lost because the referee was unfair.\"\n\nThe self-serving bias has been thought of as a means of self-esteem maintenance. In other words, we feel better about ourselves by taking credit for successes and creating external blames for failure. This is further reinforced by research showing that as self-threat increases, people are more likely to exhibit a self-serving bias. For example, participants who received negative feedback on a laboratory task were more likely to attribute their task performance to external, rather than internal, factors. Therefore, the self-serving bias seems to function as an ego-protection mechanism, helping people to better cope with personal failures.\n\nHostile attribution bias (HAB) has been defined as an interpretive bias wherein individuals exhibit a tendency to interpret others' ambiguous behaviors as hostile, rather than benign. For example, if a child witnesses two other children whispering and assumes they are talking about him/her, that child makes an attribution of hostile intent, even though the other children's behavior was potentially benign. Research has indicated that there is an association between hostile attribution bias and aggression, such that people who are more likely to interpret someone else's behavior as hostile are also more likely to engage in aggressive behavior. See the following section on aggression for more details on this association.\n\nExtensive research in both social and developmental psychology has examined the relationship between aggressive behavior and attribution biases, with a specific focus on the hostile attribution bias.\n\nIn particular, researchers have consistently found that children who exhibit a hostile attribution bias (tendency to perceive others' intent as hostile, as opposed to benign) are more likely to engage in aggressive behaviors. More specifically, hostile attribution bias has been associated with reactive aggression, as opposed to proactive aggression, as well as victimization. Whereas proactive aggression is unprovoked and goal-driven, reactive aggression is an angry, retaliatory response to some sort of perceived provocation. Therefore, children who are victims of aggression may develop views of peers as hostile, leading them to be more likely to engage in retaliatory, or reactive, aggression.\n\nResearch has also indicated that children can develop hostile attribution bias by engaging in aggression in the context of a video game. In a 1998 study, participants played either a very violent or non-violent video game and were then asked to read several hypothetical stories where a peer's intent was ambiguous. For example, participants may read about their peer hitting someone in the head with a ball, but it is unclear whether or not the peer did this intentionally or not. Participants then responded to questions about their peer's intent (e.g., \"Do you think your peer hit someone with the ball on purpose?\"). The children who played the violent video game, as compared to participants who played the nonviolent game, were more likely to say that their peer harmed someone on purpose. This finding provided evidence that just playing a violent video game could cause children to develop a short-term hostile attribution bias.\n\nResearch has found that we often exhibit attribution biases when interpreting the behavior of others, and specifically when explaining the behavior of in-group versus out-group members. More specifically, a review of the literature on intergroup attribution biases noted that people generally favor dispositional explanations of an in-group member's positive behavior and situational explanations for an in-group's negative behavior. Alternatively, people are more likely to do the opposite when explaining the behavior of an out-group member (i.e., attribute positive behavior to situational factors and negative behavior to disposition). Essentially, group members' attributions tend to favor the in-group. This finding has important implications for understanding other social psychological topics, such as the development and persistence of out-group stereotypes.\n\nAttribution biases in intergroup relations are also observed as early as childhood. In particular, elementary school students are more likely to make dispositional attributions when their friends perform positive behaviors, but situational attributions when disliked peers perform positive behaviors. Similarly, children are more likely to attribute friends' negative behaviors to situational factors, whereas they attribute disliked peers' negative behaviors to dispositional factors. These findings provide evidence that attribution biases emerge as early as childhood.\n\nAlthough certain attribution biases are associated with maladaptive behaviors, such as aggression, some research has also indicated that these biases are flexible and can be altered to produce positive outcomes. Much of this work falls within the domain of improving academic achievement through attributional retraining. For example, one study found that students who were taught to modify their attributions actually performed better on homework assignments and lecture materials. The retraining process specifically targeted students who tended to attribute poor academic performance to external factors and taught them that poor performance was often attributable to internal and unstable factors, such as effort and ability. Therefore, the retraining helped students perceive greater control over their own academic success by altering their attributional process.\n\nMore recent research has extended these findings and examined the value of attributional retraining for helping students adjust to an unfamiliar and competitive setting. In one study, first year college students went through attributional retraining following their first exam in a two-semester course. Similar to the previous study, they were taught to make more controllable attributions (e.g., \"I can improve my test grade by studying more\") and less uncontrollable attributions (e.g., \"No matter what I do, I'll fail\"). For students who performed low or average on their first exam, attributional retraining resulted in higher in-class test grades and GPA in the second semester. Students who performed well on the first exam were found to have more positive emotions in the second semester, following attributional retraining. Taken together, these studies provide evidence for the flexibility and modifiability of attributional biases.\n\n\n"}
{"id": "291112", "url": "https://en.wikipedia.org/wiki?curid=291112", "title": "Bacha Khan", "text": "Bacha Khan\n\nAbdul Ghaffār Khān (6 February 1890 – 20 January 1988), nicknamed Fakhr-e-Afghān, lit. \"pride of Afghans\"), Bādshāh Khān, or Bāchā Khān, \"king of chiefs\"), was a Pashtun independence activist who worked to end the rule of the British Raj. He was a political and spiritual leader known for his nonviolent opposition; he was a lifelong pacifist and devout Muslim. A close friend of Mohandas Gandhi, Bacha Khan was nicknamed the \"Frontier Gandhi\" in British India by his close associate Amir Chand Bombwal. Bacha Khan founded the Khudai Khidmatgar (\"Servants of God\") movement in 1929. Its success triggered a harsh crackdown by the British Raj against him and his supporters, and they suffered some of the most severe repression of the Indian independence movement.\n\nBacha Khan strongly opposed the All-India Muslim League's demand for the partition of India. When the Indian National Congress declared its acceptance of the partition plan without consulting the Khudai Khidmatgar leaders, he felt very sad and told the Congress \"you have thrown us to the wolves.\" In June 1947, Khan and other Khudai Khidmatgars declared the Bannu Resolution, demanding that the Pashtuns be given a choice to have an independent state of Pashtunistan, composing all Pashtun territories of British India, instead of being made to join Pakistan. However, the British Raj refused to comply with the demand of this resolution.\n\nAfter the partition, Bacha Khan pledged allegiance to Pakistan, but was frequently arrested by the Pakistani government between 1948 and 1954. In 1956, he was again arrested for his opposition to the One Unit program, under which the government announced its plan to merge all provinces of West Pakistan into a single province. Khan was jailed or in exile during much of the 1960s and 1970s. Upon his death in 1988 in Peshawar under house arrest, following his will, he was buried at his house in Jalalabad, Afghanistan. Tens of thousands of mourners attended his funeral, marching through the Khyber Pass from Peshawar to Jalalabad. It was marred by two bomb explosions that killed 15 people. Despite the heavy fighting at the time during the Soviet–Afghan War, both sides, namely the communist army and the mujahideen, declared a ceasefire to allow Khan's burial.\n\nBacha Khan was born on 6 February 1890 into a generally peaceful and prosperous Pashtun family from Utmanzai in the Peshawar Valley of British India. His father, Bahram Khan, was a land owner in the area commonly referred to as Hashtnaghar. Bacha Khan was the second son of Bahram to attend the British-run Edward's Mission School, the only fully functioning school in the region run by missionaries. At school the young Bacha Khan did well in his studies, and was inspired by his mentor Reverend Wigram to see the importance of education in service to the community. In his 10th and final year of high school, he was offered a highly prestigious commission in the Corps of Guides, a regiment of the British Indian Army. Bacha Khan refused the commission after realising that even Guides officers were still second-class citizens in their own country. He resumed his intention of university study, and Reverend Wigram offered him the opportunity to follow his brother, Khan Abdul Jabbar Khan, to study in London. An alumnus of Aligarh Muslim University, Bacha Khan eventually received the permission of his father. However, Bacha Khan's mother wasn't willing to let another son go to London, so Bacha Khan began working on his father's lands, attempting to discern what more he might do with his life.\n\nIn 1910, at the age of 20, Khan opened a mosque school in his hometown of Utmanzai. In 1911, he joined independence movement of the Pashtun independence activist Haji Sahib of Turangzai. However, in 1915, the British authorities banned his mosque school. Having witnessed the repeated failure of revolts against the British Raj, Khan decided that social activism and reform would be more beneficial for the Pashtuns. This led to the formation of \"Anjuman-e Islāh-e Afghānia\" (, \"Afghan Reform Society\") in 1921, and the youth movement \"Pax̌tūn Jirga\" (, \"Pashtun Assembly\") in 1927. After Khan's return from the Hajj pilgrimage to Mecca in May 1928, he founded the Pashto-language monthly political journal \"Pax̌tūn\" (, \"Pashtun\"). Finally, in November 1929, Khan founded the \"Khudāyī Khidmatgār\" (, \"Servants of God\") movement, whose success triggered a harsh crackdown by the British authorities against him and his supporters. They suffered some of the most severe repression of the Indian independence movement from the British Raj.\n\nIn response to his inability to continue his own education, Bacha Khan turned to helping others start theirs. Like many such regions of the world, the strategic importance of the newly formed North-West Frontier Province (now Khyber Pakhtunkhwa, Pakistan) as a buffer for the British Raj from Russian influence was of little benefit to its residents. The oppression of the British, the repression of the mullahs, and an ancient culture of violence and vendetta prompted Bacha Khan to want to serve and uplift his fellow men and women by means of education. At 20 years of age, Bacha Khan opened his first school in Utmanzai. It was an instant success and he was soon invited into a larger circle of progressively minded reformers.\n\nWhile he faced much opposition and personal difficulties, Bacha Khan Khan worked tirelessly to organise and raise the consciousness of his fellow Pushtuns. Between 1915 and 1918 he visited 500 villages in all part of the settled districts of Khyber-Pakhtunkhwa. It was in this frenzied activity that he had come to be known as \"Badshah (Bacha) Khan\" (King of Chiefs).\n\nBeing a secular Muslim he did not believe in religious divisions. He married his first wife Meharqanda in 1912; she was a daughter of Yar Mohammad Khan of the Kinankhel clan of the Mohammadzai tribe of Razzar, a village adjacent to Utmanzai. They had a son in 1913, Abdul Ghani Khan, who would become a noted artist and poet. Subsequently, they had another son, Abdul Wali Khan (17 January 1917–), and daughter, Sardaro. Meharqanda died during the 1918 influenza epidemic. In 1920, Bacha Khan remarried; his new wife, Nambata, was a cousin of his first wife and the daughter of Sultan Mohammad Khan of Razzar. She bore him a daughter, Mehar Taj (25 May 1921 – 29 April 2012), and a son, Abdul Ali Khan (20 August 1922 – 19 February 1997). Tragically, in 1926 Nambata died early as well from a fall down the stairs of the apartment they were staying at in Jerusalem.\n\nIn time, Bacha Khan's goal came to be the formulation of a united, independent, secular India. To achieve this end, he founded the \"Khudai Khidmatgar\" (\"Servants of God\"), commonly known as the \"Red Shirts\" (\"Surkh Pōsh\"), during the 1920s.\n\nThe \"Khudai Khidmatgar\" was founded on a belief in the power of Gandhi's notion of Satyagraha, a form of active non-violence as captured in an oath. He told its members:\nI am going to give you such a weapon that the police and the army will not be able to stand against it. It is the weapon of the Prophet, but you are not aware of it. That weapon is patience and righteousness. No power on earth can stand against it.\n\nThe organisation recruited over 100,000 members and became legendary in opposing (and dying at the hands of) the British-controlled police and army. Through strikes, political organisation and non-violent opposition, the \"Khudai Khidmatgar\" were able to achieve some success and came to dominate the politics of Khyber-Pakhtunkhwa. His brother, Dr. Khan Abdul Jabbar Khan (known as Dr. Khan Sahib), led the political wing of the movement, and was the Chief Minister of the province (from 1937 and then until 1947 when his government was dismissed by Mohammad Ali Jinnah of the Muslim League).\n\nOn 23 April 1930, Bacha Khan was arrested during protests arising out of the Salt Satyagraha. A crowd of Khudai Khidmatgar gathered in Peshawar's Kissa Khwani (Storytellers) Bazaar. The British ordered troops to open fire with machine guns on the unarmed crowd, killing an estimated 200–250. The Khudai Khidmatgar members acted in accord with their training in non-violence under Bacha Khan, facing bullets as the troops fired on them. Two platoons of The Garhwal Rifles regiment under Chandra Singh Garhwali refused to fire on the non-violent crowd. They were later court-martialled with heavy punishment, including life imprisonment.\n\nBacha Khan forged a close, spiritual, and uninhibited friendship with Gandhi, the pioneer of non-violent mass civil disobedience in India. The two had a deep admiration towards each other and worked together closely till 1947.\n\n\"Khudai Khidmatgar\" (servants of god) agitated and worked cohesively with the Indian National Congress, the leading national organisation fighting for independence, of which Bacha Khan was a senior and respected member. On several occasions when the Congress seemed to disagree with Gandhi on policy, Bacha Khan remained his staunchest ally. In 1931 the Congress offered him the presidency of the party, but he refused saying, \"I am a simple soldier and Khudai Khidmatgar, and I only want to serve.\" He remained a member of the Congress Working Committee for many years, resigning only in 1939 because of his differences with the Party's War Policy. He rejoined the Congress Party when the War Policy was revised.\n\nBacha Khan was a champion of women's rights and nonviolence. He became a hero in a society dominated by violence; notwithstanding his liberal views, his unswerving faith and obvious bravery led to immense respect. Throughout his life, he never lost faith in his non-violent methods or in the compatibility of Islam and nonviolence. He recognised as a jihad struggle with only the enemy holding swords. He was closely identified with Gandhi because of his non-violence principles and he is known in India as the 'Frontier Gandhi'. One of his Congress associates was Pandit Amir Chand Bombwal of Peshawar.\n\nKhan strongly opposed the partition of India. Accused as being anti-Muslim by some politicians, Khan was physically assaulted in 1946, leading to his hospitalisation in Peshawar. On June 21, 1947, in Bannu, a loya jirga was held consisting of Bacha Khan, the Khudai Khidmatgars, members of the Provincial Assembly, Mirzali Khan (Faqir of Ipi), and other tribal chiefs, just seven weeks before the partition. The loya jirga declared the Bannu Resolution, which demanded that the Pashtuns be given a choice to have an independent state of Pashtunistan composing all Pashtun territories of British India, instead of being made to join either India or Pakistan. However, the British Raj refused to comply with the demand of this resolution.\n\nThe congress party refused last-ditch compromises to prevent the partition, like the Cabinet Mission plan and Gandhi's suggestion to offer the position of Prime Minister to Jinnah. As a result, Bacha Khan and his followers felt a sense of betrayal by both Pakistan and India. Bacha Khan's last words to Gandhi and his erstwhile allies in the Congress party were: \"You have thrown us to the wolves.\"\n\nWhen the referendum over accession to Pakistan was held, Bacha Khan, the Khudai Khidmatgars and the Indian National Congress Party boycotted the referendum. Some have argued that a segment of the population voted was barred from voting.\n\nBacha Khan took the oath of allegiance to the new nation of Pakistan on 23 February 1948 at the first session of the Pakistan Constituent Assembly.\n\nHe pledged full support to the government and attempted to reconcile with the founder of the new state Muhammad Ali Jinnah. Initial overtures led to a successful meeting in Karachi, however a follow-up meeting in the Khudai Khidmatgar headquarters never materialised, allegedly due to the role of Khyber-Pakhtunkhwa Chief Minister, Abdul Qayyum Khan who warned Jinnah that Bacha Khan was plotting his assassination.\n\nFollowing this, Bacha Khan formed Pakistan's first National opposition party, on 8 May 1948, the Pakistan Azad Party. The party pledged to play the role of constructive opposition and would be non-communal in its philosophy.\n\nHowever, suspicions of his allegiance persisted and under the new Pakistani government, Bacha Khan was placed under house arrest without charge from 1948 till 1954. Released from prison, he gave a speech again on the floor of the constituent assembly, this time condemning the massacre of his supporters at Babrra.\n\nHe was arrested several times between late 1948 and in 1956 for his opposition to the One Unit scheme. The government attempted in 1958 to reconcile with him and offered him a Ministry in the government, after the assassination of his brother, he however refused. He remained in prison till 1957 only to be re-arrested in 1958 until an illness in 1964 allowed for his release.\n\nIn 1962, Bacha Khan was named an \"Amnesty International Prisoner of the Year\". Amnesty's statement about him said, \"His example symbolizes the suffering of upward of a million people all over the world who are prisoners of conscience.\"\n\nIn September 1964, the Pakistani authorities allowed him to go to United Kingdom for treatment. During the winter, his doctor advised him to go to United States. He then went into exile to Afghanistan, he returned from exile in December 1972 to popular support, following the establishment of a National Awami Party provincial government in North West Frontier Province and Balochistan.\n\nHe was arrested by Prime Minister Zulfiqar Ali Bhutto's government at Multan in November 1973 and described Bhuttos government as \"the worst kind of dictatorship\".\n\nIn 1984, increasingly withdrawing from politics he was nominated for the Nobel Peace Prize. He visited India and participated in the centennial celebrations of the Indian National Congress in 1985; he was awarded the Jawaharlal Nehru Award for International Understanding in 1967 and later Bharat Ratna, India's highest civilian award, in 1987.\n\nHis final major political challenge was against the Kalabagh dam project, fearing that the project would damage the Peshawar valley, his hostility to it would eventually lead to the project being shelved after his death.\n\nBacha Khan died in Peshawar under house arrest in 1988 and was buried in his house at Jalalabad, Afghanistan. Over 200,000 mourners attended his funeral, including the Afghan president Mohammad Najibullah. This was a symbolic move by Bacha Khan, as this would allow his dream of Pashtun unification to live even after his death. Then Indian Prime Minister Rajiv Gandhi went to Peshawar, to pay his tributes to Bacha Khan despite the fact that General Zia ul-Haq attempted to stall his attendance citing security reasons. Additionally, the Indian government declared a five-day period of mourning in his honour.\n\nAlthough he had been repeatedly imprisoned and persecuted, tens of thousands of mourners attended his funeral, described by one commentator as \"a caravan of peace, carrying a message of love\" from Pashtuns east of the Khyber to those on the west, marching through the historic Khyber Pass from Peshawar to Jalalabad. A cease-fire was announced in the Afghan Civil War to allow the funeral to take place, even though it was marred by bomb explosions killing 15.\n\nHis eldest son Ghani Khan was a poet, his other son Khan Abdul Wali Khan is the founder and leader of the Awami National Party and was the Leader of the Opposition in the Pakistan National Assembly.\n\nHis third son Khan Abdul Ali Khan was non-political and a distinguished educator, and served as Vice-Chancellor of University of Peshawar. Ali Khan was also the head of Aitchison College, Lahore and Fazle Haq college, Mardan.\n\nMohammed Yahya Education Minister of Khyber Pukhtunkhwa, was the only son in law of Bacha Khan.\n\nAsfandyar Wali Khan is the grandson of Khan Abdul Gaffar Khan, and leader of the Awami National Party. The party was in power from 2008 to 2013.\n\nSalma Ataullahjan is the great grand niece of Khan Abdul Gaffar Khan and a member of the Senate of Canada.\n\nBacha Khan's political legacy is renowned amongst Pashtuns and Hindus as a leader of a non-violent movement. Within Pakistan, however, the vast majority of society have questioned his stance with the All India Congress over the Muslim League as well as his opposition to Quaid-e-Azam. In particular, people have questioned where Bacha Khan's patriotism rests following his insistence that he be buried in Afghanistan after his death and not Pakistan.\n\nIn 2008, a documentary, titled \"The Frontier Gandhi: Badshah Khan, a Torch for Peace\", by filmmaker and writer T.C. McLuhan, premiered in New York. The film received the 2009 award for Best Documentary Film at the Middle East International Film Festival (see film page).\n\nBacha Khan was listed as one of 26 men who changed the world in a recent children's book published in the United States. He also wrote an autobiography (1969), and has been the subject of biographies by Eknath Easwaran (see article) and Rajmohan Gandhi (see \"References\" section, below). His philosophy of Islamic pacificism was recognised by US Secretary of State Hillary Clinton, in a speech to American Muslims.\n\nIn the Indian city of Delhi, the popular Khan Market is named in his honour and another market in the Karol Bagh of New Delhi is named after him called Ghaffar Market.\n\n\n"}
{"id": "46676", "url": "https://en.wikipedia.org/wiki?curid=46676", "title": "Banach fixed-point theorem", "text": "Banach fixed-point theorem\n\nIn mathematics, the Banach–Caccioppoli fixed-point theorem (also known as the contraction mapping theorem or contraction mapping principle) is an important tool in the theory of metric spaces; it guarantees the existence and uniqueness of fixed points of certain self-maps of metric spaces, and provides a constructive method to find those fixed points. The theorem is named after Stefan Banach (1892–1945) and Renato Caccioppoli (1904–1959), and was first stated by Banach in 1922. Caccioppoli independently proved the theorem in 1931.\n\n\"Definition.\" Let formula_1 be a metric space. Then a map formula_2 is called a contraction mapping on formula_3 if there exists formula_4 such that\nfor all formula_6 in formula_3.\n\nBanach Fixed Point Theorem. Let formula_1 be a non-empty complete metric space with a contraction mapping formula_2. Then \"T\" admits a unique fixed-point \"x*\" in \"X\" (i.e. \"T\"(\"x*\") = \"x*\"). Furthermore, \"x*\" can be found as follows: start with an arbitrary element \"x\" in \"X\" and define a sequence {\"x\"} by \"x\" = \"T\"(\"x\"), then .\n\n\"Remark 1.\" The following inequalities are equivalent and describe the speed of convergence:\n\nAny such value of \"q\" is called a \"Lipschitz constant\" for \"T\", and the smallest one is sometimes called \"the best Lipschitz constant\" of \"T\".\n\n\"Remark 2.\" \"d\"(\"T\"(\"x\"), \"T\"(\"y\")) < \"d\"(\"x\", \"y\") for all \"x\" ≠ \"y\" is in general not enough to ensure the existence of a fixed point, as is shown by the map \"T\" : [1, ∞) → [1, ∞), \"T\"(\"x\") = \"x\" + 1/\"x\", which lacks a fixed point. However, if \"X\" is compact, then this weaker assumption does imply the existence and uniqueness of a fixed point, that can be easily found as a minimizer of \"d\"(\"x\", \"T\"(\"x\")), indeed, a minimizer exists by compactness, and has to be a fixed point of \"T\". It then easily follows that the fixed point is the limit of any sequence of iterations of \"T\".\n\n\"Remark 3.\" When using the theorem in practice, the most difficult part is typically to define \"X\" properly so that \"T\"(\"X\") ⊆ \"X\".\n\nLet \"x\" ∈ \"X\" be arbitrary and define a sequence {\"x\"} by setting \"x\" = \"T\"(\"x\"). We first note that for all \"n\" ∈ N, we have the inequality\n\nThis follows by induction on \"n\", using the fact that \"T\" is a contraction mapping. Then we can show that {\"x\"} is a Cauchy sequence. In particular, let \"m\", \"n\" ∈ N such that \"m\" > \"n\":\n\nLet ε > 0 be arbitrary, since \"q\" ∈ [0, 1), we can find a large \"N\" ∈ N so that\n\nTherefore, by choosing \"m\" and \"n\" greater than \"N\" we may write:\n\nThis proves that the sequence {\"x\"} is Cauchy. By completeness of (\"X\",\"d\"), the sequence has a limit \"x*\" ∈ \"X\". Furthermore, \"x*\" must be a fixed point of \"T\":\n\nAs a contraction mapping, \"T\" is continuous, so bringing the limit inside \"T\" was justified. Lastly, \"T\" cannot have more than one fixed point in (\"X\",\"d\"), since any pair of distinct fixed points \"p\" and \"p\" would contradict the contraction of \"T\":\n\n\nSeveral converses of the Banach contraction principle exist. The following is due to Czesław Bessaga, from 1959:\n\nLet \"f\" : \"X\" → \"X\" be a map of an abstract set such that each iterate \"f\" has a unique fixed point. Let \"q\" ∈ (0, 1), then there exists a complete metric on \"X\" such that \"f\" is contractive, and \"q\" is the contraction constant.\n\nIndeed, very weak assumptions suffice to obtain such a kind of converse. For example if \"f\" : \"X\" → \"X\" is a map on a \"T\" topological space with a unique fixed point \"a\", such that for each \"x\" in \"X\" we have \"f\"(\"x\") → \"a\", then there already exists a metric on \"X\" with respect to which \"f\" satisfies the conditions of the Banach contraction principle with contraction constant 1/2. In this case the metric is in fact an ultrametric.\n\nThere are a number of generalizations (some of which are immediate corollaries).\n\nLet \"T\" : \"X\" → \"X\" be a map on a complete non-empty metric space. Then, for example, some generalizations of the Banach fixed-point theorem are:\nIn applications, the existence and unicity of a fixed point often can be shown directly with the standard Banach fixed point theorem, by a suitable choice of the metric that makes the map \"T\" a contraction. Indeed, the above result by Bessaga strongly suggests to look for such a metric. See also the article on fixed point theorems in infinite-dimensional spaces for generalizations.\n\nA different class of generalizations arise from suitable generalizations of the notion of metric space, e.g. by weakening the defining axioms for the notion of metric. Some of these have applications, e.g., in the theory of programming semantics in theoretical computer science.\n\n\nAn earlier version of this article was posted on Planet Math. This article is open content.\n"}
{"id": "32023533", "url": "https://en.wikipedia.org/wiki?curid=32023533", "title": "Bla Bla", "text": "Bla Bla\n\nBLA BLA is an interactive animated film for computer created by with Montreal studio AATOAA, and produced by the National Film Board of Canada. The online work has been described as exploring \"the principles of human communication,\" and follows Morisset's collaborations with Arcade Fire on \"Neon Bible\", considered the first interactive music video.\n\nThe characters in \"BLA BLA\" were designed by Caroline Robert using stop-motion puppetry and traditional animation as well as computer animation methods such as ActionScript animation and real-time 3D mapping. The work is designed to be principally non-linear, with users constructing the story through point-and-click choices.\n\nThe music by composer Philippe Lambert and characters' speech was broken into short clips and distributed randomly throughout the programming, which was created by Édouard Lanctôt-Benoit. As an added bonus, \"BLA BLA\" users can also access classic NFB animated films, including works by Ryan Larkin, René Jodoin, Michèle Cournoyer and Norman McLaren. \"BLA BLA\" was produced for the NFB by Hugues Sweeney.\n\nThe work stands apart in its emphasis on achieving an emotional response in the viewer/actor. \"I wanted to create moods and generate emotions through an interactive piece,\" Morriset says. \"It's quite hard to do dramatic crescendos on a website… I thought it would be an interesting challenge.\" \n\n\"BLA BLA\" was featured in spring 2012 at a month-long live interactive presentation in Paris.\n\nIn March 2012, \"BLA BLA\" received the SXSW Interactive Art Award as well as the Entertainment Award in the Communication Arts Interactive Competition. In May 2012, it received the Webby Award for best web art.\n\n"}
{"id": "6273584", "url": "https://en.wikipedia.org/wiki?curid=6273584", "title": "Conatus", "text": "Conatus\n\nIn early philosophies of psychology and metaphysics, conatus (; Latin for \"effort; endeavor; impulse, inclination, tendency; undertaking; striving\") is an innate inclination of a thing to continue to exist and enhance itself. This \"thing\" may be mind, matter, or a combination of both. Over the millennia, many different definitions and treatments have been formulated. Seventeenth-century philosophers René Descartes, Baruch Spinoza, Gottfried Leibniz, and Thomas Hobbes made important contributions. The \"conatus\" may refer to the instinctive \"will to live\" of living organisms or to various metaphysical theories of motion and inertia. Often the concept is associated with God's will in a pantheist view of Nature. The concept may be broken up into separate definitions for the mind and body and split when discussing centrifugal force and inertia.\n\nThe history of the term \"conatus\" is that of a series of subtle tweaks in meaning and clarifications of scope developed over the course of two and a half millennia. Successive philosophers to adopt the term put their own personal twist on the concept, each developing the term differently such that it now has no accepted definition. The earliest authors to discuss \"conatus\" wrote primarily in Latin, basing their usage on ancient Greek concepts. These thinkers therefore used \"conatus\" not only as a technical term but as a common word and in a general sense. In archaic texts, the more technical usage is difficult to discern from the more common one, and they are also hard to differentiate in translation. In English translations, the term is italicized when used in the technical sense or translated and followed by \"conatus\" in brackets. Today, \"conatus\" is rarely used in the technical sense, since modern physics uses concepts such as inertia and conservation of momentum that have superseded it. It has, however, been a notable influence on nineteenth- and twentieth-century thinkers such as Arthur Schopenhauer, Friedrich Nietzsche, and Louis Dumont.\n\nThe Latin \"cōnātus\" comes from the verb \"cōnor\", which is usually translated into English as, \"to endeavor\"; but the concept of the \"conatus\" was first developed by the Stoics (333–264 BCE) and Peripatetics (c. 335 BCE) before the Common Era. These groups used the word (\"hormê\", translated in Latin by \"impetus\") to describe the movement of the soul towards an object, and from which a physical act results. Classical thinkers, Marcus Tullius Cicero (106–43 BCE) and Diogenes Laertius (c. 235 BCE), expanded this principle to include an aversion to destruction, but continued to limit its application to the motivations of non-human animals. Diogenes Laertius, for example, specifically denied the application of the term to plants. Before the Renaissance, Thomas Aquinas (c. 1225–1274 CE), Duns Scotus (c. 1266–1308 CE) and Dante Alighieri (1265–1321 CE) expressed similar sentiments using the Latin words \"vult\", \"velle\" or \"appetit\" as synonyms of \"conatus\"; indeed, all four terms may be used to translate the original Greek . Later, Telesius and Campanella extended the ancient Greek notions and applied them to all objects, animate and inanimate.\n\nFirst Aristotle, then Cicero and Laertius each alluded to a connection between the \"conatus\" and other emotions. In their view, the former induces the latter. They maintained that humans do not wish to do something because they think it \"good\", but rather they think it \"good\" because they want to do it. In other words, the cause of human desire is the natural inclination of a body to augment itself in accordance with the principles of the \"conatus\".\n\nThere is a traditional connection between \"conatus\" and motion itself. Aquinas and Abravanel (1265–1321) both related the concept directly to that which Augustine (354–430 CE) saw to be the \"natural movements upward and downward or with their being balanced in an intermediate position\" described in his \"De Civitate Dei\", (c. 520 CE). They called this force that causes objects to rise or fall, \"amor naturalis\", or \"natural love\".\n\nIn the 6th century, John Philoponus (c. 490–c. 570 CE) criticized Aristotle's view of motion, noting the inconsistency between Aristotle's discussion of projectiles, where the medium of aether keeps projectiles going, and his discussion of the void, where there is no such medium and hence a body's motion should be impossible. Philoponus proposed that motion was not maintained by the action of some surrounding medium but by some property, or \"conatus\" implanted in the object when it was set in motion. This was not the modern concept of inertia, for there was still the need for an inherent power to keep a body in motion. This view was strongly opposed by Averroës and many scholastic philosophers who supported Aristotle. The Aristotelian view was also challenged in the Islamic world. For example, Ibn al-Haytham (Alhazen) seems to have supported Philoponus' views, while he developed a concept similar to inertia. The concept of inertia was developed more clearly in the work of his contemporary Avicenna, who conceived a permanent force whose effect is dissipated only as a result of external agents such as air resistance, making him \"the first to conceive such a permanent type of impressed virtue for non-natural motion.\" Avicenna's concept of \"mayl\" is almost the opposite of the Aristotelian conception of violent motion and is reminiscent of Newton's first law of motion. Avicenna also developed an idea similar to momentum, when he attempted to provide a quantitative relation between the weight and velocity of a moving body.\n\nJean Buridan (1300–1358) also rejected the notion that this motion-generating property, which he named \"impetus\", dissipated spontaneously. Buridan's position was that a moving object would be arrested by the resistance of the air and the weight of the body which would oppose its impetus. He also maintained that impetus increased with speed; thus, his initial idea of impetus was similar in many ways to the modern concept of momentum. Despite the obvious similarities to more modern ideas of inertia, Buridan saw his theory as only a modification to Aristotle's basic philosophy, maintaining many other peripatetic views, including the belief that there was still a fundamental difference between an object in motion and an object at rest. Buridan also maintained that impetus could be not only linear, but also circular in nature, causing objects such as celestial bodies to move in a circle.\n\nIn the first half of the seventeenth century, René Descartes (1596–1650) began to develop a more modern, materialistic concept of the \"conatus\", describing it as \"an active power or tendency of bodies to move, expressing the power of God\". Whereas the ancients used the term in a strictly anthropomorphic sense similar to voluntary \"endeavoring\" or \"struggling\" to achieve certain ends, and medieval Scholastic philosophers developed a notion of \"conatus\" as a mysterious intrinsic property of things, Descartes uses the term in a somewhat more mechanistic sense. More specifically, for Descartes, in contrast to Buridan, movement and stasis are two states of the same thing, not different things. Although there is much ambiguity in Descartes' notion of \"conatus\", one can see here the beginnings of a move away from the attribution of desires and intentions to nature and its workings toward a more scientific and modern view.\n\nDescartes rejects the teleological, or purposive, view of the material world that was dominant in the West from the time of Aristotle. The mind is not viewed by Descartes as part of the material world, and hence is not subject to the strictly mechanical laws of nature. Motion and rest, on the other hand, are properties of the interactions of matter according to eternally fixed mechanical laws. God only sets the whole thing in motion at the start, and later does not interfere except to maintain the dynamical regularities of the mechanical behavior of bodies. Hence there is no real teleology in the movements of bodies since the whole thing reduces to the law-governed collisions and their constant reconfigurations. The \"conatus\" is just the tendency of bodies to move when they collide with each other. God may set this activity in motion, but thereafter no \"new\" motion or rest can be created or destroyed.\n\nDescartes specifies two varieties of the \"conatus\": \"conatus a centro\" and \"conatus recedendi\". \"Conatus a centro\", or \"tendency towards the center\", is used by Descartes as a theory of gravity; \"conatus recendendi\", or \"tendency away from the center\", represents the centrifugal forces. These tendencies are not to be thought of in terms of animate dispositions and intentions, nor as inherent properties or \"forces\" of things, but rather as a unifying, external characteristic of the physical universe itself which God has bestowed.\n\nDescartes, in developing his First Law of Nature, also invokes the idea of a \"conatus se movendi\", or \"\"conatus\" of self-preservation\". This law is a generalization of the principle of inertia, which was developed and experimentally demonstrated earlier by Galileo. The principle was formalized by Isaac Newton and made into the first of his three Laws of Motion fifty years after the death of Descartes. Descartes' version states: \"Each thing, insofar as in it lies, always perseveres in the same state, and when once moved, always continues to move.\"\n\nThomas Hobbes (1588–1679), too, worked off of the previous notions of the \"conatus\" principle. However, he criticized the previous definitions for failing to explain the origin of motion. Working toward this end became the primary focus of Hobbes' work in this area. Indeed, Hobbes \"reduces all the cognitive functions of the mind to variations of its \"conative\" functions\".\n\nFurthermore, Hobbes describes emotion as the beginning of motion and the will as the sum of all emotions. This \"will\" forms the \"conatus\" of a body and its physical manifestation is the perceived \"will to survive\". In order that living beings may thrive, Hobbes says, \"they seek peace and fight anything that threatens this peace\". Hobbes also equates this \"conatus\" with \"imagination\", and states that a change in the \"conatus\", or will, is the result of \"deliberation\".\n\nI define [\"conatus\"] to be motion made in less space and time than can be given; that is, less than can be determined or assigned by exposition or number; that is, motion made through the length of a point, and in an instant or point of time.\nAs in his psychological theory, Hobbes's physical \"conatus\" is an infinitesimal unit of motion. It is the \"beginning\" of motion: an inclination in a specified direction. The concept of \"impetus\", as used by Hobbes, is defined in terms of this physical \"conatus\". It is \"a measure of the \"conatus\" exercised by a moving body over the course of time\". Resistance is caused by a contrary \"conatus\"; force is this motion plus \"the magnitude of the body\". Hobbes also uses the word \"conatus\" to refer to the \"restorative forces\" which may cause springs, for example, to contract or expand. Hobbes claims there is some force inherent in these objects that inclines them to return to their previous state. Today, science attributes this phenomenon to material elasticity.\n\nConatus is a central theme in the philosophy of Benedict de Spinoza (1632–1677). According to Spinoza, \"each thing, as far as it lies in itself, strives to persevere in its being\" (\"Ethics\", part 3, prop. 6). Spinoza presents a few reasons for believing this. First, particular things are, as he puts it, modes of God, which means that each one expresses the power of God in a particular way (\"Ethics\", part 3, prop. 6, dem.). Moreover, it could never be part of the definition of God that his modes contradict one another (\"Ethics\", part 3, prop. 5); each thing, therefore, \"is opposed to everything which can take its existence away\" (\"Ethics\", part 3, prop. 6, dem.). This resistance to destruction is formulated by Spinoza in terms of a striving to continue to exist, and \"conatus\" is the word he most often uses to describe this force.\n\nStriving to persevere is not merely something that a thing does in addition to other activities it might happen to undertake. Rather, striving is \"nothing but the actual essence of the thing\" (\"Ethics\", part 3, prop. 7). Spinoza also uses the term \"conatus\" to refer to rudimentary concepts of inertia, as Descartes had earlier. Since a thing cannot be destroyed without the action of external forces, motion and rest, too, exist indefinitely until disturbed.\n\nThe concept of the \"conatus\", as used in Baruch Spinoza's psychology, is derived from sources both ancient and medieval. Spinoza reformulates principles that the Stoics, Cicero, Laertius, and especially Hobbes and Descartes developed. One significant change he makes to Hobbes' theory is his belief that the \"conatus ad motum\", (\"conatus\" to motion), is \"not\" mental, but material.\n\nSpinoza, with his determinism, believes that man and nature must be unified under a consistent set of laws; God and nature are one, and there is no free will. Contrary to most philosophers of his time and in accordance with most of those of the present, Spinoza rejects the dualistic assumption that mind, intentionality, ethics, and freedom are to be treated as things separate from the natural world of physical objects and events. His goal is to provide a unified explanation of all these things within a naturalistic framework, and his notion of \"conatus\" is central to this project. For example, an action is \"free\", for Spinoza, only if it arises from the essence and \"conatus\" of an entity. There can be no absolute, unconditioned freedom of the will, since all events in the natural world, including human actions and choices, are determined in accord with the natural laws of the universe, which are inescapable. However, an action can still be free in the sense that it is not constrained or otherwise subject to external forces.\n\nHuman beings are thus an integral part of nature. Spinoza explains seemingly irregular human behaviour as really \"natural\" and rational and motivated by this principle of the \"conatus\". In the process, he replaces the notion of free will with the \"conatus\", a principle that can be applied to all of nature and not just man.\n\nSpinoza's view of the relationship between the \"conatus\" and the human affects is not clear. Firmin DeBrabander, assistant professor of philosophy at the Maryland Institute College of Art, and Antonio Damasio, professor of neuroscience at the University of Southern California, both argue that the human affects arise from the \"conatus\" and the perpetual drive toward perfection. Indeed, Spinoza states in his \"Ethics\" that happiness, specifically, \"consists in the human capacity to preserve itself\". This \"endeavor\" is also characterized by Spinoza as the \"foundation of virtue\". Conversely, a person is saddened by anything that opposes his \"conatus\".\n\nDavid Bidney (1908–1987), professor at Yale University, disagrees. Bidney closely associates \"desire\", a primary affect, with the \"conatus\" principle of Spinoza. This view is backed by the Scholium of IIIP9 of the \"Ethics\" which states, \"Between appetite and desire there is no difference, except that desire is generally related to men insofar as they are conscious of the appetite. So desire can be defined as appetite together with consciousness of the appetite.\" According to Bidney, this desire is controlled by the other affects, pleasure and pain, and thus the \"conatus\" strives towards that which causes joy and avoids that which produces pain.\n\nGottfried Leibniz (1646–1716) was a student of Erhard Weigel (1625–1699) and learned of the \"conatus\" principle from him and from Hobbes, though Weigel used the word \"tendentia\" (Latin: tendency). Specifically, Leibniz uses the word \"conatus\" in his \"Exposition and Defence of the New System\" (1695) to describe a notion similar that of Hobbes, but he differentiates between the \"conatus\" of the body and soul, the first of which may only travel in a straight line by its own power, and the latter of which may \"remember\" more complicated motions.\n\nFor Leibniz, the problem of motion comes to a resolution of the paradox of Zeno.\nSince motion is continuous, space must be infinitely divisible. In order for anything to begin moving at all, there must be some mind-like, voluntaristic property or force inherent in the basic constituents of the universe that propels them. This \"conatus\" is a sort of instantaneous or \"virtual\" motion that all things possess, even when they are static. Motion, meanwhile, is just the summation of all the \"conatuses\" that a thing has, along with the interactions of things. The \"conatus\" is to motion as a point is to space. The problem with this view is that an object that collides with another would not be able to bounce back, if the only force in play were the \"conatus\". Hence, Leibniz was forced to postulate the existence of an aether that kept objects moving and allowed for elastic collisions. Leibniz' concept of a mind-like memory-less property of \"conatus\", coupled with his rejection of atoms, eventually led to his theory of monads.\n\nLeibniz also uses his concept of a \"conatus\" in developing the principles of the integral calculus, adapting the meaning of the term, in this case, to signify a mathematical analog of Newton's accelerative \"force\". By summing an infinity of such \"conatuses\" (i.e., what is now called integration), Leibniz could measure the effect of a continuous force. He defines \"impetus\" as the result of a continuous summation of the \"conatus\" of a body, just as the \"vis viva\" (or \"living force\") is the sum of the inactive \"vis mortua\".\n\nBased on the work of Kepler and probably Descartes, Leibniz develops a model of planetary motion based on the \"conatus\" principle, the idea of aether and a fluid vortex. This theory is expounded in the work \"Tentamen de motuum coelestium causis\" (1689). According to Leibniz, Kepler's analysis of elliptical orbits into a circular and a radial component can be explained by a \"harmonic vortex\" for the circular motion combined with a centrifugal force and gravity, both of which are examples of \"conatus\", to account for the radial motion. Leibniz later defines the term \"monadic conatus\", as the \"state of change\" through which his monads perpetually advance.\n\nSeveral other uses of the term \"conatus\", apart from the primary ones mentioned above, have been formulated by various philosophers over the centuries. There are also some important related terms and concepts which have, more or less, similar meanings and usages. Giambattista Vico (1668–1744) defined \"conatus\" as the essence of human society, and also, in a more traditional, hylozoistic sense, as the generating power of movement which pervades all of nature. Nearly a century after the beginnings of modern science, Vico, inspired by Neoplatonism, explicitly rejected the principle of inertia and the laws of motion of the new physics. For him, nature was composed neither of atoms, as in the dominant view, nor of extension, as in Descartes, but of \"metaphysical points\" animated by a \"conatus\" principle provoked by God.\n\nArthur Schopenhauer (1788–1860) developed a philosophy that contains a principle notably similar to that of Hobbes's \"conatus\". This principle, \"Wille zum Leben\", or \"Will to Live\", described the specific phenomenon of an organism's self-preservation instinct. Schopenhauer qualified this, however, by suggesting that the Will to Live is not limited in duration. Rather, \"the will wills absolutely and for all time\", across generations. Friedrich Nietzsche (1844–1900), an early disciple of Schopenhauer, developed a separate principle which comes out of a rejection of the primacy of Schopenhauer's Will to Live and other notions of self-preservation. He called his version the Will to Power, or \"Wille zur Macht\". \n\nSigmund Freud (1856–1939), greatly depended on Spinoza's formulation of the \"conatus\" principle as a system of self-preservation, though he never cited him directly in any of his published works. Around the same time, Henri Bergson (1859–1941), developed the principle of the \"élan vital\", or \"vital impulse\", which was thought to aid in the evolution of organisms. This concept, which implies a fundamental driving force behind all life, is reminiscent of the \"conatus\" principle of Spinoza and others.\n\nFor Max Scheler, the concept of \"Drang\" is the centerpiece of philosophical anthropology and metaphysics. Though his concept has been important throughout his entire philosophical career, it was only developed later in his life when his focus shifted from phenomenology to metaphysics. Like Bergson's \"élan vital,\" \"Drang\" (drive or impulsion) is the impetus of all life; however, unlike in Bergson's vitalistic metaphysics, the significance of Drang is that it provides the motivation and driving force even of Spirit (\"Geist\"). Spirit, which includes all theoretical intentionality, is powerless without the movement of \"Drang\", the material principle, as well as \"Eros\", the psychological principle.\n\nThe cultural anthropologist Louis Dumont (1911–1988), described a \"cultural conatus\" built directly upon Spinoza's seminal definition in IIIP3 of his \"Ethics\". The principle behind this derivative concept states that any given culture, \"tends to persevere in its being, whether by dominating other cultures or by struggling against their domination\".\nAfter the advent of Newtonian physics, the concept of a \"conatus\" of all physical bodies was largely superseded by the principle of inertia and conservation of momentum. As Bidney states, \"It is true that logically desire or the \"conatus\" is merely a principle of inertia ... the fact remains, however, that this is not Spinoza's usage.\" Likewise, \"conatus\" was used by many philosophers to describe other concepts which have slowly been made obsolete. \"Conatus recendendi\", for instance, became the centrifugal force, and gravity is used where \"conatus a centro\" had been previously. Today, the topics with which \"conatus\" dealt are matters of science and are thus subject to inquiry by the scientific method.\n\nThe archaic concept of \"conatus\" is today being reconciled with modern biology by scientists such as Antonio Damasio. The \"conatus\" of today, however, is explained in terms of chemistry and neurology where, before, it was a matter of metaphysics and theurgy. This concept may be \"constructed so as to maintain the coherence of a living organism's structures and functions against numerous life-threatening odds\". \n\nThe Spinozistic conception of a \"conatus\" was a historical precursor to modern theories of autopoiesis in biological systems. In systems theory and the sciences in general, the concept of a \"conatus\" may be related to the phenomenon of emergence, whereby complex systems may spontaneously form from multiple simpler structures. The self-regulating and self-maintaining properties of biological and even social systems may thus be considered modern versions of Spinoza's \"conatus\" principle; however, the scope of the idea is definitely narrower today without the religious implications of the earlier variety.\n\n\n\n"}
{"id": "1311951", "url": "https://en.wikipedia.org/wiki?curid=1311951", "title": "Data dredging", "text": "Data dredging\n\nData dredging (also data fishing, data snooping, data butchery, and \"p\"-hacking) is the misuse of data analysis to find patterns in data that can be presented as statistically significant when in fact there is no real underlying effect. This is done by performing many statistical tests on the data and only paying attention to those that come back with significant results, instead of stating a single hypothesis about an underlying effect before the analysis and then conducting a single test for it.\n\nThe process of data dredging involves automatically testing huge numbers of hypotheses about a single data set by exhaustively searching—perhaps for combinations of variables that might show a correlation, and perhaps for groups of cases or observations that show differences in their mean or in their breakdown by some other variable.\n\nConventional tests of statistical significance are based on the probability that a particular result would arise if chance alone were at work, and necessarily accept some risk of mistaken conclusions of a certain type (mistaken rejections of the null hypothesis). This level of risk is called the \"significance\". When large numbers of tests are performed, some produce false results of this type, hence 5% of randomly chosen hypotheses turn out to be significant at the 5% level, 1% turn out to be significant at the 1% significance level, and so on, by chance alone. When enough hypotheses are tested, it is virtually certain that some will be statistically significant but misleading, since almost every data set with any degree of randomness is likely to contain (for example) some spurious correlations. If they are not cautious, researchers using data mining techniques can be easily misled by these results.\n\nThe multiple comparisons hazard is common in data dredging. Moreover, subgroups are sometimes explored without alerting the reader to the number of questions at issue, which can lead to misinformed conclusions.\n\nThe conventional frequentist statistical hypothesis testing procedure is to formulate a research hypothesis, such as \"people in higher social classes live longer\", then collect relevant data, followed by carrying out a statistical significance test to see how likely such results would be found if chance alone were at work. (The last step is called testing against the null hypothesis.)\n\nA key point in proper statistical analysis is to test a hypothesis with evidence (data) that was not used in constructing the hypothesis. This is critical because every data set contains some patterns due entirely to chance. If the hypothesis is not tested on a different data set from the same statistical population, it is impossible to assess the likelihood that chance alone would produce such patterns. See testing hypotheses suggested by the data.\n\nHere is a simple example. Throwing a coin five times, with a result of 2 heads and 3 tails, might lead one to hypothesize that the coin favors tails by 3/5 to 2/5. If this hypothesis is then tested on the existing data set, it is confirmed, but the confirmation is meaningless. The proper procedure would have been to form in advance a hypothesis of what the tails probability is, and then throw the coin various times to see if the hypothesis is rejected or not. If three tails and two heads are observed, another hypothesis, that the tails probability is 3/5, could be formed, but it could only be tested by a new set of coin tosses. It is important to realize that the statistical significance under the incorrect procedure is completely spurious – significance tests do not protect against data dredging.\n\nSuppose that a study of a random sample of people includes exactly two people with a birthday of August 7: Mary and John. Someone engaged in data snooping might try to find additional similarities between Mary and John. By going through hundreds or thousands of potential similarities between the two, each having a low probability of being true, an unusual similarity can almost certainly be found. Perhaps John and Mary are the only two people in the study who switched minors three times in college. A hypothesis, biased by data snooping, could then be \"People born on August 7 have a much higher chance of switching minors more than twice in college.\"\n\nThe data itself very strongly supports that correlation, since no one with a different birthday had switched minors three times in college. However, if (as is likely) this is a spurious hypothesis, this result will most likely not be reproducible; any attempt to check if others with an August 7 birthday have a similar rate of changing minors will most likely get contradictory results almost immediately.\n\nBias is a systematic error in the analysis. For example, doctors directed HIV patients at high cardiovascular risk to a particular HIV treatment, abacavir, and lower-risk patients to other drugs, preventing a simple assessment of abacavir compared to other treatments. An analysis that did not correct for this bias unfairly penalised abacavir, since its patients were more high-risk so more of them had heart attacks. This problem can be very severe, for example, in the observational study.\n\nMissing factors, unmeasured confounders, and loss to follow-up can also lead to bias.\nBy selecting papers with a significant \"p\"-value, negative studies are selected against—which is the publication bias. This is also known as File Cabinet Bias, because less significant p-value results are left in the file cabinet and never published.\n\nAnother aspect of the conditioning of statistical tests by knowledge of the data can be seen while using the frequency of data flow in a system or machine in the data analysis linear regression. A crucial step in the process is to decide which covariates to include in a relationship explaining one or more other variables. There are both statistical (see Stepwise regression) and substantive considerations that lead the authors to favor some of their models over others, and there is a liberal use of statistical tests. However, to discard one or more variables from an explanatory relation on the basis of the data, means one cannot validly apply standard statistical procedures to the retained variables in the relation as though nothing had happened. In the nature of the case, the retained variables have had to pass some kind of preliminary test (possibly an imprecise intuitive one) that the discarded variables failed. In 1966, Selvin and Stuart compared variables retained in the model to the fish that don't fall through the net—in the sense that their effects are bound to be bigger than those that do fall through the net. Not only does this alter the performance of all subsequent tests on the retained explanatory model—it may introduce bias and alter mean square error in estimation.\n\nIn meteorology, hypotheses are often formulated using weather data up to the present and tested against future weather data, which ensures that, even subconsciously, future data could not influence the formulation of the hypothesis. Of course, such a discipline necessitates waiting for new data to come in, to show the formulated theory's predictive power versus the null hypothesis. This process ensures that no one can accuse the researcher of hand-tailoring the predictive model to the data on hand, since the upcoming weather is not yet available.\n\nAs another example, suppose that observers note that a particular town appears to have a cancer cluster, but lack a firm hypothesis of why this is so. However, they have access to a large amount of demographic data about the town and surrounding area, containing measurements for the area of hundreds or thousands of different variables, mostly uncorrelated. Even if all these variables are independent of the cancer incidence rate, it is highly likely that at least one variable correlates significantly with the cancer rate across the area. While this may suggest a hypothesis, further testing using the same variables but with data from a different location is needed to confirm. Note that a \"p\"-value of 0.01 suggests that 1% of the time a result at least that extreme would be obtained by chance; if hundreds or thousands of hypotheses (with mutually relatively uncorrelated independent variables) are tested, then one is likely to obtain a \"p\"-value less than 0.01 for many null hypotheses.\n\nLooking for patterns in data is legitimate. Applying a statistical test of significance, or hypothesis test, to the same data that a pattern emerges from is wrong. One way to construct hypotheses while avoiding data dredging is to conduct randomized out-of-sample tests. The researcher collects a data set, then randomly partitions it into two subsets, A and B. Only one subset—say, subset A—is examined for creating hypotheses. Once a hypothesis is formulated, it must be tested on subset B, which was not used to construct the hypothesis. Only where B also supports such a hypothesis is it reasonable to believe the hypothesis might be valid. (This is a simple type of cross-validation and is often termed training-test or split-half validation.)\n\nAnother remedy for data dredging is to record the number of all significance tests conducted during the study and simply divide one's criterion for significance (\"alpha\") by this number; this is the Bonferroni correction. However, this is a very conservative metric. A family-wise alpha of 0.05, divided in this way by 1,000 to account for 1,000 significance tests, yields a very stringent per-hypothesis alpha of 0.00005. Methods particularly useful in analysis of variance, and in constructing simultaneous confidence bands for regressions involving basis functions are the Scheffé method and, if the researcher has in mind only pairwise comparisons, the Tukey method. The use of Benjamini and Hochberg's false discovery rate is a more sophisticated approach that has become a popular method for control of multiple hypothesis tests.\n\nWhen neither approach is practical, one can make a clear distinction between data analyses that are confirmatory and analyses that are exploratory. Statistical inference is appropriate only for the former.\n\nUltimately, the statistical significance of a test and the statistical confidence of a finding are joint properties of data and the method used to examine the data. Thus, if someone says that a certain event has probability of 20% ± 2% 19 times out of 20, this means that if the probability of the event is estimated \"by the same method\" used to obtain the 20% estimate, the result is between 18% and 22% with probability 0.95. No claim of statistical significance can be made by only looking, without due regard to the method used to assess the data.\n\nAcademic journals increasingly shift to the registered report format, which aims to counteract very serious issues such as data dredging and , which have made theory-testing research very unreliable: For example, Nature Human Behaviour has adopted the registered report format, as it “shift[s] the emphasis from the results of research to the questions that guide the research and the methods used to answer them”. The European Journal of Personality defines this format: “In a registered report, authors create a study proposal that includes theoretical and empirical background, research questions/hypotheses, and pilot data (if available). Upon submission, this proposal will then be reviewed prior to data collection, and if accepted, the paper resulting from this peer-reviewed procedure will be published, regardless of the study outcomes.”\n\nMethods and results can also be made publicly available, as in the open science approach, making it yet more difficult for data dredging to take place.\n\n\n"}
{"id": "44646461", "url": "https://en.wikipedia.org/wiki?curid=44646461", "title": "Devarishi", "text": "Devarishi\n\nDevarishi (Sanskrit: देवर्षि) means – 'the celestial sage'; it is one of the three categories of Rishis, the other two being – \"Brahmarishi\" (ब्रह्मर्षि) and \"Rajarishi\" (राजर्षि). \"Rajarishis\" were those Kshatriya kings who gained the status of Rishi; the difference between a \"Rishi\" and a \"Brahmarishi\" was that of the degree of penance and accomplishment, and their life-span.\n\nVāyu Purāņa (LXI.79-92) tells us that the root - ऋष, from which the word ऋषि (\"Rishi\") is derived, is used in the sense of motion (Knowledge), hearing truth and austerity, and gives the marks of a \"Devarishi\". It states that seers living in the celestial regions should be known as the blessed \"Devarishis\", and also those who are distinguished by their knowledge of the past, present and future and strict adherence to truth; they are the revealers of \"Mantra\" and by virtue of their \"Siddhis\" ('supernatural powers') have unrestricted access everywhere. The same text earlier states that:-\n\nthe two sons of Dharma, Nara and Nārāyaņa; Kratu’s sons, collectively known as Vālakhilyas; Kardama, son of Pulaha; Parvata, Nārada and the two sons of Kaśyapa, Asita and Vatsara, are called \"Devarishis\" because they can exercise control even over the celestials. \n"}
{"id": "54630740", "url": "https://en.wikipedia.org/wiki?curid=54630740", "title": "Edward Brown (barrister)", "text": "Edward Brown (barrister)\n\nEdward Francis Trevenen Brown QC (born January 1958) is an English barrister who specialises in international criminal law and human rights. He is one of the most senior prosecutors at the Old Bailey where he also served as a Recorder, as well as sitting as a part-time circuit judge at Southwark Crown Court. Brown has written extensively on gang violence and joint enterprise murder in \"The Times\".\n\nBrown was called to the Bar in 1983. He currently practises at QEB Hollis Whiteman in London, chambers of Mark Ellison QC, where he heads specialist criminal department. After beginning his career both prosecuting and defending, Brown specialised in prosecution work from 1986, including several cases of murder, terrorism and organised crime. He took silk (i.e. appointed Queen's Counsel) in 2008. For most of his career he has practiced at the Old Bailey.\n\nIn 2000 Brown was appointed Junior Treasury Counsel at the Old Bailey, where he served as a Recorder (judge) from 2001. In 2007 he was appointed Senior Treasury Counsel, serving in that capacity until 2014. In 2015 Brown became a Bencher of Gray’s Inn.\n\nIn 2014 Brown became a member of Detention Review Board of United Nations Interim Administration Mission in Kosovo.\n\nBrown has represented the prosecution, corporate entities and individuals in allegations of corporate crime, corruption, corporate manslaughter and tax investigations. In 2009 Brown acted for Labour Party politicians in Cash for Peerages police inquiry - no charges against MP's were brought. In 2016 Brown was appointed as leading Counsel to represent the CPS at the Independent Inquiry into Child Sexual Abuse.\n\n\nBrown was instructed by the CPS in many of the highest profile British criminal cases including prosecution of Kevin Hutchinson-Foster who passed the BBM Bruni Model 92 handgun to Mark Duggan shortly before the minicab in which Duggan was travelling was stopped by police in Ferry Lane in Tottenham Hale.\n\nBrown was also instructed in the inquest of Duggan's death. He prosecuted members of the GAS (Guns And Shanks) gang from Brixton who were charged with joint enterprise murder in a case of \"vicious, shocking and sickening case of gang violence outside a school at a time when pupils and staff were gathering at the start of a school day\", as well as Ben Hitchcock's murderers, whose actions were described as \"the direct result of what was a pitched battle between rival gangs.\" Co-defendant Royston Thomas was found not guilty after police detectives relaunched an investigation into the stabbing of 16-year-old Ben Hitchcock.\nHe prosecuted David Jeffs known as the \"Mayfair socialite murder\", child killer Ben Butler, hitman Jamie Marsh-Smith who was found guilty of murdering a gang boss, and MI5 official Katharine Gun in widely publicised case involving MI5 and GCHQ.\n\nIn February 2016, Brown was interviewed by The Lawyer magazine to analyse R v Jogee that reversed previous case law on joint enterprise murder, after a recent Supreme Court ruling indicating that it was not right that a person could be convicted of murder and subsequently sentenced to life imprisonment if they foresaw the murder could take place but did not deliver the fatal blow. Brown commented: \"It has always been the case that a person who intentionally assists another in a joint crime will be as guilty as the person who physically commits that crime. After the Chan Wing-Siu ruling in 1985, juries have since been directed that if a secondary party foresaw that the principal party might use a knife, for example, with intent to cause harm or murder, then they are guilty of murder as well.\"\nBrown also commented that the judgment in R v Jogee and Ruddock v The Queen will have a significant effect on the prosecution of multi-handed crime, and in particular cases of multi-handed serious violence that sometimes results in death. It will also result in many applications for leave to appeal against conviction out of time.\n\nOn 18 September 2012, Brown started prosecuting Kevin Hutchinson-Foster whose trial took place in Snaresbrook Crown Court. Duggan was shot dead while police officers were trying to arrest him in Tottenham, north London last August. The jury heard that the handgun allegedly supplied by Hutchinson-Foster was found near the spot where Duggan was shot. Giving evidence, Hutchinson-Foster who was accused of passing the gun to Mark Duggan, claimed Duggan already had a gun. Hutchinson-Foster is accused of \"selling or transferring\" a BBM Bruni Model 92 handgun to Duggan contrary to the Firearms Act 1968, between 28 July and 5 August 2011. Hutchinson-Foster was found guilty of suppying gun to Duggan. Chief Supt Dean Haydon, from the Metropolitan Police's Trident Serious Crime Command, said: \n\nIn 2011 Brown prosecuted two south London gangs known as Shanks and Guns, or SG, and the Black Mafia, also known as the Sydenham Boys. Gang members were found guilty of murder of Nicholas \"Nick\" Pearton who was thought to be their friend. In May 2011 Pearton, 17 year old schoolboy, was stabbed by gangsters being caught up in a clash between two gangs in Home Park, Sydenham. Pearton was attacked when he went to the park to help gangsters who he thought were his friends, after receiving a call from them. The jury at the Old Bailey saw CCTV footage from the Kentucky Fried Chicken shop of an injured Nicholas running in and collapsing.\nProsecuting, Brown commented that Pearton was \"the only white-skinned male participant in the incident\" when he was chased and eventually killed by a pack of \"animals.\" The court heard that hours earlier, Pearton's so-called friend, a member of Black Mafia gang known as the Sydenham Boys, had been involved in a row at school which led to a confrontation in the park between the two gangs. Brown told the jury:\nOnly one out of ten gangsters was identified as stabbing Pearton. The others claimed they had been wrongly convicted of murder and manslaughter. Belgian national Edward Conteh was convicted of Pearton's murder and deported after his conviction under joint enterprise law, whilst not being present at the scene. But Judge Anthony Morris said they had all taken part in \"a terrifying example of gang violence\". Morris also said not enough was being done to raise awareness of the consequences of gang violence. When the police commented that they already had a programme, Judge Morris said: \n\nIn 2016 Brown started prosecuting Hamad Mohammad and three of his associates who were accused of joint enterprise murder. Ionut Lazar, 28, was found shot dead in Shepherd’s Bush on 22 October 2016 two days after arriving in the UK from Romania. Lazar, 28, was killed after “a number of men” forced their way into a home in Shepherd's Bush, west London Police were called to Askew Road, W11 on 22 October at 2.40am to reports of an unconscious male at a residential property in Askew Road. Lazar was found suffering from what was initially thought to be a stab wound to the chest. He died at the scene a short while later. A post-mortem examination took place October 24 at Fulham Mortuary and established the cause of death as a bullet wound to the chest.\nIn January 2017 Brown prosecuted Gintare Suminaite, 29-year-old mother from Crawley, West Sussex, who was charged with murder of her newborn child.\nProsecuting, Brown told the jury that the child was the product of Suminaite's secret affair with a fellow Lithuanian. Suminaite kept her pregnancy hidden from authorities and her long-term partner, with whom she already had a young child. She attended a hearing at Crawley magistrates' court but did not enter a plea to the murder charge.\nSuminaite told police she \"most likely\" intended to kill her baby, but said she did not know why. At the trial held at the Old Bailey she pleaded guilty to a charge of infanticide.\nThe court heard that on April 5, 2016, Suminaite left work early saying she had ‘big problems’ and gave birth in the bathroom at home, with her partner in another room. Her partner found Suminaite lying naked in the bathroom surrounded by blood and a baby bath full of what appeared to be clothes.\nJurors at the Old Bailey heard that Suminaite was bleeding and pale when found by her boyfriend who eventually called an ambulance after she confessed what had happened. The court heard that the child lay undiscovered as medics initially did not spot the body in the baby bath and the couple did not mention it. Suminaite was subsequently treated in hospital for significant blood loss and injury from childbirth. Following her arrest, Suminaite said she strangled her baby with her lingerie, but did not know why. She described giving birth quickly and easily and said the baby was moving and trying to cry. Suminaite told the jury she cut the umbilical cord with a razor then passed out in the bath. When she came to pick the baby up, she said the baby was not moving and she tied a pair of her knickers around her neck and put her in the baby bath. She said she did not know why she did it as she had no mental problems. Emergency services were called to her home on Aldwick Road in Bognor. At the hearing, Mr Justice Nicol said that Suminaite's circumstances were \"tragic in themselves\". Sentencing Suminaite, he said: Suminaite followed proceedings with the aid of a translator as English was not her first language. In his closing speech Brown acknowledged that Suminaite been emotionally and socially isolated during her life in England. He told the court:\n\nSuminaite was sentenced to a 24-month community order with a rehabilitation requirement order. At the completion of the trial Mr Justice Nicol said: \n\nIn August 2017, Brown prosecuted male escort Jason Marshall who murdered his client Peter Fasoli who he met in December 2012 through gay social networking site called Badoo, where he advertised his services under his \"working\" name Gabriel. Marshall was arrested after the victim's relative found hidden footage of killing on his laptop. Peter Fasoli, a 58-year-old IT expert, from Northolt was terrorised and murdered in 2013 at his own house by Marshall who posed as a policeman. On the opening day of his trial at the Old Bailey, Marshall was described as a \"calculating and determined\" killer. Prosecuting, Mr Brown warned jurors that they would be asked to view the video, which showed the actual killing itself. The court heard that during sexual roleplay, Marshall stripped the victim and arrested him for “being a spy” and hacking into a government laptop, the court heard. Fasoli was threatened with a knife and forced to hand over his cash card pin numbers. The footage shower Marshall, 28, calmly standing over the body of his client Peter Fasoli and signing \"in the name of the father, the son and the Holy Ghost\" in Latin, after killing him. Marshall subsequently set fire to Fasoli's home in attempt to make Fasoli's death look like an accident.\n\nBut two years later when Fasoli's nephew was sorting through his belongings, he was horrified to discover a computer file containing CCTV footage of the entire event.\nThe court heard how Marshall, who denied murder, first got in contact with Peter Fasoli in December 2012 through gay social networking site called Badoo, inviting to set up a treesome and inventing the persona of a policeman.\nProsecuting, Mr Brown told jurors:\n\nThe Old Baily heard that Marshall arrived at the Fasoli's home at around 7pm on 6 January 2012, pretending to be a police officer kitted out with a police utility belt, handcuffs and a pistol holster.\nDuring sexual role play, Marshall stripped the victim and arrested him for “being a spy” and hacking into a Government laptop, the court heard.\nAfter Marshall fled the scene, he sent a “calculated and cynical” message to Fasoli on the Badoo chat line apologising for not seeing him the night before. He withdrew £750 in cash from the Fasoli's bank account and used his card to buy a flight to Rome. In February 2016 Marshal was arrested in Italy and extradited to United Kingdom to face trial for murder of Fasoli he committed four years ago. A Metropolitan Police spokesman commented: \nThe court has heard that Fasoli accidentally filmed his own bondage sex session murder at the hands of Jason Marshall dressed as policeman. Jurors at the Old Bailey watched footage of Fasoli begging for his life as he was attacked by fantasist Marshall while classical music played in the background. Camera footage showed Fasioli becoming visibly distressed as he was gagged and bound on his bed. He was threatened with a large hunting knife and forced to hand over his cash card pin numbers, the court heard. Prosecuting, Brown told the jury: \n\nThe court heard that during psychological evaluation Marshall told the psychiatrists that he is an incarnation of Archangel Gabriel and stated “You can’t judge me, only God can judge me.” In September 2017 Jason Marshall was imprisoned for 39 years for the murder of Peter Fasoli.\nHe has previously been convicted in the UK of impersonating MI5 and transport police officials while carrying out searches and of issuing fines on the Tube.\n\nIn 2011 Brown became a trustee of the Growing Against Violence, charity that delivers programmes in schools that address gang exploitation and seeks to educate young people and draw them away from gangs and violence. Brown also gave lectures to young south London gang members on law of joint enterprise and on the dangers of gang violence.\n\nIn September 2015 Brown, in his capacity of Senior Tresury Counsel, appeared on Guity by Association, BBC One documentary that examines law of joint enterprise. The programme raised questions about how the courts deal with gang violence, what constitutes a murder and whether young people are being sentenced for crimes they did not commit. Documentary follows Alex and his family as he is charged under the joint enterprise law and examines the increasing controversy surrounding the details of this law which some believe is creating criminals of the innocent.\n\n\n"}
{"id": "54792823", "url": "https://en.wikipedia.org/wiki?curid=54792823", "title": "Environmental issues of Jamaica's reefs", "text": "Environmental issues of Jamaica's reefs\n\nHuman behavior has a large impact on Jamaica's 479 square miles of coral reefs, which hosts 60 different species of coral. These reefs are a major tourist attraction for the country, accounting for 27 percent of its GDP. Due to Jamaica's economic reliance on its coastal reserves, the degradation of the coral reefs is much higher because of continuous habitat destruction.\n\nThe coral reefs are under threat due to environmental issues such as overfishing, pollution, hurricanes, and disease. Since the 1970s, Jamaica's coral reef cover has declined more than 50 percent. In 2005, up to 95 percent of the coral was bleached in some locations.\n\nJamaica's coral reefs house 135 different species of fish. Between 1995 and 1998, fishing licenses increased by 68 percent for the Montego Bay Marine Park where 69 percent of fishers rely on fishing as their full-time income. In 1970 on Jamaica's north coast, trap fishermen set 1800 traps which was at least two times above sustainability levels. Fish density dwindled to 9.8 fish per 100 m between 2001 and 2006. Overfishing has reduced the herbivorous fish that keep algae populations in check and it has caused a phase shift from coral reefs to algae reefs. Today, algae covers 24 percent of the reefs where corals once stood. By 1960, fish biomass was reduced by 80 percent due to overfishing. Fish that are vital to coral reef survival, such as the Parrot fish, have been driven to near extinction. In addition, overfishing has also been linked to the disappearance of the black sea urchin, \"Diadema antillarum,\" which also helped to reduce microalgal presence.\n\nSewage pollution has led to eutrophication which results in an abundance of nutrients for microalgal populations to bloom. The United Nations Environmental Program determined that 85 percent of the sewage entering the Caribbean ocean is untreated. This raw sewage contains dissolved inorganic nutrients, pathogens, heavy metals, and toxins that can cause coral bleaching, disease, increased mortality, and decreased coral growth. A study concluded that increased nutrients such as, inorganic nitrogen and phosphorus, doubled the probability of coral diseases and tripled the probability of bleaching. An increase of inorganic nitrogen was also linked to the presence of pathogens which can lead to coral mortality. The heavy metals prevent respiration and nerve communication within the coral which also leads to coral mortality.\n\nMajor hurricane events include Hurricane Allen in 1980, Hurricane Gilbert in 1988, and Hurricane Ivan in 2004. In 2005, there were a record breaking 26 storms recorded that caused 26 events of bleaching in 16 of Jamaica's coral reef sites. The hurricanes affected 68 percent of Jamaica's coral reefs and 38 percent of those corals later died. In September 2005, up to 95 percent of Jamaica's corals had bleached, but only 50 percent recovered later. As a result of the 2005 hurricane, microalgal blooms took over where the corals once were.\n\nThe Caribbean's coral reefs have been increasingly becoming diseased by 20 percent. Coral diseases can cause tissue damage or it could even destroy the entire colony. In 1980, white-band disease killed 95 percent of the \"Acroporid palmata\" and \"Acroporid cervicornis\" colonies which placed them on the Endangered Species Act. A 2010 study concluded that sewage runoff in was correlated to the white pox coral disease that destroyed the \"Acroporid palmata\" species.\n\n"}
{"id": "45434", "url": "https://en.wikipedia.org/wiki?curid=45434", "title": "Environmental movement", "text": "Environmental movement\n\nThe environmental movement (sometimes referred to as the ecology movement), also including conservation and green politics, is a diverse scientific, social, and political movement for addressing environmental issues. Environmentalists advocate the sustainable management of resources and stewardship of the environment through changes in public policy and individual behavior. In its recognition of humanity as a participant in (not enemy of) ecosystems, the movement is centered on ecology, health, and human rights.\n\nThe environmental movement is an international movement, represented by a range of organizations, from the large to grassroots and varies from country to country. Due to its large membership, varying and strong beliefs, and occasionally speculative nature, the environmental movement is not always united in its goals. The movement also encompasses some other movements with a more specific focus, such as the climate movement. At its broadest, the movement includes private citizens, professionals, religious devotees, politicians, scientists, nonprofit organizations and individual advocates.\n\nEarly interest in the environment was a feature of the Romantic movement in the early 19th century. The poet William Wordsworth had travelled extensively in the Lake District and wrote that it is a \"sort of national property in which every man has a right and interest who has an eye to perceive and a heart to enjoy\".\n\nThe origins of the environmental movement lay in the response to increasing levels of smoke pollution in the atmosphere during the Industrial Revolution. The emergence of great factories and the concomitant immense growth in coal consumption gave rise to an unprecedented level of air pollution in industrial centers; after 1900 the large volume of industrial chemical discharges added to the growing load of untreated human waste. Under increasing political pressure from the urban middle-class, the first large-scale, modern environmental laws came in the form of Britain's Alkali Acts, passed in 1863, to regulate the deleterious air pollution (gaseous hydrochloric acid) given off by the Leblanc process, used to produce soda ash.\n\nThe modern conservation movement was first manifested in the forests of India, with the practical application of scientific conservation principles. The conservation ethic that began to evolve included three core principles: that the human activity damaged the environment, that there was a civic duty to maintain the environment for future generations, and that scientific, empirically based methods should be applied to ensure this duty was carried out. Sir James Ranald Martin was prominent in promoting this ideology, publishing many medico-topographical reports that demonstrated the scale of damage wrought through large-scale deforestation and desiccation, and lobbying extensively for the institutionalization of forest conservation activities in British India through the establishment of Forest Departments. The Madras Board of Revenue started local conservation efforts in 1842, headed by Alexander Gibson, a professional botanist who systematically adopted a forest conservation program based on scientific principles. This was the first case of state management of forests in the world. Eventually, the government under Governor-General Lord Dalhousie introduced the first permanent and large-scale forest conservation program in the world in 1855, a model that soon spread to other colonies, as well the United States. In 1860, the Department banned the use shifting cultivation. Dr. Hugh Cleghorn's 1861 manual, \"The forests and gardens of South India\", became the definitive work on the subject and was widely used by forest assistants in the subcontinent.\n\nSir Dietrich Brandis joined the British service in 1856 as superintendent of the teak forests of Pegu division in eastern Burma. During that time Burma's teak forests were controlled by militant Karen tribals. He introduced the \"taungya\" system, in which Karen villagers provided labour for clearing, planting and weeding teak plantations. He formulated new forest legislation and helped establish research and training institutions. The Imperial Forestry School at Dehradun was founded by him.\n\nThe late 19th century saw the formation of the first wildlife conservation societies.\nThe zoologist Alfred Newton published a series of investigations into the \"Desirability of establishing a 'Close-time' for the preservation of indigenous animals\" between 1872 and 1903. His advocacy for legislation to protect animals from hunting during the mating season led to the formation of the Plumage League (later the Royal Society for the Protection of Birds) in 1889. The society acted as a protest group campaigning against the use of great crested grebe and kittiwake skins and feathers in fur clothing. The Society attracted growing support from the suburban middle-classes, and influenced the passage of the Sea Birds Preservation Act in 1869 as the first nature protection law in the world.\n\nFor most of the century from 1850 to 1950, however, the primary environmental cause was the mitigation of air pollution. The Coal Smoke Abatement Society was formed in 1898 making it one of the oldest environmental NGOs. It was founded by artist Sir William Blake Richmond, frustrated with the pall cast by coal smoke. Although there were earlier pieces of legislation, the Public Health Act 1875 required all furnaces and fireplaces to consume their own smoke.\nSystematic and general efforts on behalf of the environment only began in the late 19th century; it grew out of the amenity movement in Britain in the 1870s, which was a reaction to industrialization, the growth of cities, and worsening air and water pollution. Starting with the formation of the Commons Preservation Society in 1865, the movement championed rural preservation against the encroachments of industrialisation. Robert Hunter, solicitor for the society, worked with Hardwicke Rawnsley, Octavia Hill, and John Ruskin to lead a successful campaign to prevent the construction of railways to carry slate from the quarries, which would have ruined the unspoilt valleys of Newlands and Ennerdale. This success led to the formation of the Lake District Defence Society (later to become The Friends of the Lake District).\n\nIn 1893 Hill, Hunter and Rawnsley agreed to set up a national body to coordinate environmental conservation efforts across the country; the \"National Trust for Places of Historic Interest or Natural Beauty\" was formally inaugurated in 1894. The organisation obtained secure footing through the 1907 National Trust Bill, which gave the trust the status of a statutory corporation. and the bill was passed in August 1907.\n\nAn early \"Back-to-Nature\" movement, which anticipated the romantic ideal of modern environmentalism, was advocated by intellectuals such as John Ruskin, William Morris, and Edward Carpenter, who were all against consumerism, pollution and other activities that were harmful to the natural world. The movement was a reaction to the urban conditions of the industrial towns, where sanitation was awful, pollution levels intolerable and housing terribly cramped. Idealists championed the rural life as a mythical Utopia and advocated a return to it. John Ruskin argued that people should return to a \"small piece of English ground, beautiful, peaceful, and fruitful. We will have no steam engines upon it . . . we will have plenty of flowers and vegetables . . . we will have some music and poetry; the children will learn to dance to it and sing it.\"\n\nPractical ventures in the establishment of small cooperative farms were even attempted and old rural traditions, without the \"taint of manufacture or the canker of artificiality\", were enthusiastically revived, including the Morris dance and the maypole.\nThe movement in the United States began in the late 19th century, out of concerns for protecting the natural resources of the West, with individuals such as John Muir and Henry David Thoreau making key philosophical contributions. Thoreau was interested in peoples' relationship with nature and studied this by living close to nature in a simple life. He published his experiences in the book \"Walden\", which argues that people should become intimately close with nature. Muir came to believe in nature's inherent right, especially after spending time hiking in Yosemite Valley and studying both the ecology and geology. He successfully lobbied congress to form Yosemite National Park and went on to set up the Sierra Club in 1892. The conservationist principles as well as the belief in an inherent right of nature were to become the bedrock of modern environmentalism. However, the early movement in the U.S. developed with a contradiction; preservationists like John Muir wanted land and nature set aside for its own sake, and conservationists, such as Gifford Pinchot (appointed as the first Chief of the US Forest Service from 1905-1910), wanted to manage natural resources for human use.\n\nIn the 20th century, environmental ideas continued to grow in popularity and recognition. Efforts were beginning to be made to save the wildlife, particularly the American bison. The death of the last passenger pigeon as well as the endangerment of the American bison helped to focus the minds of conservationists and popularize their concerns. In 1916 the National Park Service was founded by US President Woodrow Wilson. Pioneers of the movement called for more efficient and professional management of natural resources. They fought for reform because they believed the destruction of forests, fertile soil, minerals, wildlife and water resources would lead to the downfall of society. The group that has been the most active in recent years is the climate movement.\n\nThe U.S movement began to take off after World War II as people began to recognize the costs of environmental negligence, disease, and the expansion of air and water pollution through the occurrence of several environmental disasters that occurred post-World War II. Aldo Leopold wrote \"A Sand County Almanac\" in the 1940s. He believed in a land ethic that recognized that maintaining the \"beauty, integrity, and health of natural systems\" as a moral and ethical imperative.\n\nAnother major literary force in the promotion of the environmental movement was Rachel Carson's \"Silent Spring\" about declining bird populations due to DDT, an insecticide, pollution and man's attempts to control nature through use of synthetic substances. Her core message for her readers, was to identify the complex and fragile ecosystem and the threats facing the people. In 1958 Carson started to work on her last book, with an idea that nature needs human protection. Her influence was radioactive fallout, smog, food additives, and pesticide use. Carson’s main focus was on pesticides, which led her to identify nature as fragile and the use of technology dangerous to humans and other species.\n\nBoth of these books helped bring the issues into the public eye Rachel Carson's \"Silent Spring\" sold over two million copies.\nThe first Earth Day was celebrated on 22 April 1970. Its founder, former Wisconsin Senator Gaylord Nelson, was inspired to create this day of environmental education and awareness after seeing the oil spill off the coast of Santa Barbara in 1969. Greenpeace was created in 1971 as an organization that believed that political advocacy and legislation were ineffective or inefficient solutions and supported non-violent action. 1980 saw the creation of Earth First!, a group with an ecocentric view of the world – believing in equality between the rights of humans to flourish, the rights of all other species to flourish and the rights of life-sustaining systems to flourish.\n\nIn the 1950s, 1960s, and 1970s, several events illustrated the magnitude of environmental damage caused by humans. In 1954, a hydrogen bomb test at Bikini Atoll exposed the 23 man crew of the Japanese fishing vessel \"Lucky Dragon 5\" to radioactive fallout. In 1967 the oil tanker ran aground off the coast of Cornwall, and in 1969 oil spilled from an offshore well in California's Santa Barbara Channel. In 1971, the conclusion of a lawsuit in Japan drew international attention to the effects of decades of mercury poisoning on the people of Minamata.\n\nAt the same time, emerging scientific research drew new attention to existing and hypothetical threats to the environment and humanity. Among them were Paul R. Ehrlich, whose book \"The Population Bomb\" (1968) revived Malthusian concerns about the impact of exponential population growth. Biologist Barry Commoner generated a debate about growth, affluence and \"flawed technology.\" Additionally, an association of scientists and political leaders known as the Club of Rome published their report \"The Limits to Growth\" in 1972, and drew attention to the growing pressure on natural resources from human activities.\n\nMeanwhile, technological accomplishments such as nuclear proliferation and photos of the Earth from outer space provided both new insights and new reasons for concern over Earth's seemingly small and unique place in the universe.\n\nIn 1972, the United Nations Conference on the Human Environment was held in Stockholm, and for the first time united the representatives of multiple governments in discussion relating to the state of the global environment. This conference led directly to the creation of government environmental agencies and the UN Environment Program.\n\nBy the mid-1970s anti-nuclear activism had moved beyond local protests and politics to gain a wider appeal and influence. Although it lacked a single co-ordinating organization the anti-nuclear movement's efforts gained a great deal of attention, especially in the United Kingdom and United States. In the aftermath of the Three Mile Island accident in 1979, many mass demonstrations took place. The largest one was held in New York City in September 1979 and involved 200,000 people.\n\nSince the 1970s, public awareness, environmental sciences, ecology, and technology have advanced to include modern focus points like ozone depletion, global climate change, acid rain, mutation breeding, genetically modified crops and genetically modified livestock. With mutation breeding, crop cultivars were created by exposing seeds to chemicals or radiation. Many of these cultivars are still being used today. Genetically modified plants and animals are said by some environmentalists to be inherently bad because they are unnatural. Others point out the possible benefits of GM crops such as water conservation through corn modified to be less \"thirsty\" and decreased pesticide use through insect - resistant crops. They also point out that some genetically modified livestock have accelerated growth which means there are shorter production cycles which again results in a more efficient use of feed. \nBesides genetically modified crops and livestock, synthetic biology is also on the rise and environmentalists argue that these also contain risks, if these organisms were ever to end up in nature. This, as unlike with genetically modified organisms, synthetic biology even uses base pairs that do not exist in nature.\n\nBeginning in the conservation movement at the beginning of the 20th century, the contemporary environmental movement's roots can be traced back to Murray Bookchin's \"Our Synthetic Environment\", Paul R. Ehrlich's The Population Bomb, and Rachel Carson's \"Silent Spring\". American environmentalists have campaigned against nuclear weapons and nuclear power in 1960s and 1970s, acid rain in the 1980s, ozone depletion and deforestation in the 1990s, and most recently climate change and global warming.\n\nThe United States passed many pieces of environmental legislation in the 1970s, such as the Clean Water Act, the Clean Air Act, the Endangered Species Act, and the National Environmental Policy Act. These remain as the foundations for current environmental standards.\n\n\nAfter the International Environmental Conference in Stockholm in 1972 Latin American officials returned with a high hope of growth and protection of the fairly untouched natural resources. Governments spent millions of dollars, and created departments and pollution standards. However, the outcomes have not always been what officials had initially hoped. Activists blame this on growing urban populations and industrial growth. Many Latin American countries have had a large inflow of immigrants that are living in substandard housing. Enforcement of the pollution standards is lax and penalties are minimal; in Venezuela, the largest penalty for violating an environmental law is 50,000 bolivar fine ($3,400) and 3 days in jail. In the 1970s or 1980s many Latin American countries were transitioning from military dictatorships to democratic governments.\n\nIn 1992, Brazil came under scrutiny with the United Nations Conference on Environment and Development in Rio de Janeiro. Brazil has a history of little environmental awareness. It has the highest biodiversity in the world and also the highest amount of habitat destruction. One-third of the world's forests lie in Brazil, and they have the largest river, The Amazon, and the largest rainforest, the Amazon Rainforest. The people have raised funds to create state parks and increase the consciousness of people who have destroyed forests and polluted waterways. They have several organizations that have fronted the environmental movement. The Blue Wave Foundation was created in 1989 and has partnered with advertising companies to promote national education campaigns to keep Brazil's beaches clean. Funatura was created in 1986 and is a wildlife sanctuary program. Pro-Natura International is a private environmental organization created in 1986.\n\nIn 1952 the Great London Smog episode killed thousands of people and led the UK to create the first Clean Air Act in 1956. In 1957 the first major nuclear accident occurred in Windscale in northern England. The supertanker \"Torrey Canyon\" ran aground off the coast of Cornwall in 1967 causing the first major oil leak that killed marine life along the coast. In 1972, in Stockholm, the United Nations Conference on the Human Environment created the UN Environment Programme. The EU's environmental policy was formally founded by a European Council declaration and the first five-year environment programme was adopted. The main idea of the declaration was that prevention is better than the cure and the polluter should pay. 1979 saw the partial meltdown of Three Mile Island in the USA.\n\nIn the 1980s the green parties that were created a decade before began to have some political success.. In 1986, there was a nuclear accident in Chernobyl, Ukraine. The end of the 1980s and start of the 1990s saw the fall of communism across central and Eastern Europe, the fall of the [Berlin Wall], and the Union of East and West Germany. In 1992 there was a UN summit held in Rio de Janeiro where Agenda 21 was adopted. The Kyoto Protocol was created in 1997 which set specific targets and deadlines to reduce global greenhouse gas emissions. In the early 2000s activists believed that environmental policy concerns were overshadowed by energy security, globalism, and terrorism.\n\nThe environmental movement is reaching the less developed world with different degrees of success. The Arab world, including the Middle East and North Africa, has different adaptations of the environmental movement. Countries on the Persian Gulf have high incomes and rely heavily on the large amount of energy resources in the area. Each country in the Arab world has varying combinations of low or high amounts of natural resources and low or high amounts of labor.\n\nThe League of Arab States has one specialized sub-committee, of 12 standing specialized subcommittee in the Foreign Affairs Ministerial Committees, which deals with Environmental Issues. Countries in the League of Arab States have demonstrated an interest in environmental issue, on paper some environmental activists have doubts about the level of commitment to environmental issues;; being a part of the world community may have obliged these countries to portray concern for the environment. Initial level of environmental awareness may be the creation of a ministry of the environment. The year of establishment of a ministry is also indicative of level of engagement. Saudi Arabia was the first to establish environmental law in 1992 followed by Egypt in 1994. Somalia is the only country without environmental law. In 2010 the Environmental Performance Index listed Algeria as the top Arab country at 42 of 163; Morocco was at 52 and Syria at 56. The Environmental Performance Index measures the ability of a country to actively manage and protect their environment and the health of their citizens. A weighted index is created by giving 50% weight for environmental health objective (health) and 50% for ecosystem vitality (ecosystem); values range from 0-100. No Arab countries were in the top quartile, and 7 countries were in the lowest quartile.\n\nSouth Korea and Taiwan experienced similar growth in industrialization from 1965-1990 with few environmental controls. South Korea's Han River and Nakdong River were so polluted by unchecked dumping of industrial waste that they were close to being classified as biologically dead. Taiwan's formula for balanced growth was to prevent industrial concentration and encourage manufacturers to set up in the countryside. This led to 20% of the farmland being polluted by industrial waste and 30% of the rice grown on the island was contaminated with heavy metals. Both countries had spontaneous environmental movements drawing participants from different classes. Their demands were linked with issues of employment, occupational health, and agricultural crisis. They were also quite militant; the people learned that protesting can bring results. The polluting factories were forced to make immediate improvements of the conditions or pay compensation to victims. Some were even forced to shut down or move locations. The people were able to force the government to come out with new restrictive rules on toxins, industrial waste, and air pollution. All of these new regulations caused the migration of those polluting industries from Taiwan and South Korea to China and other countries in Southeast Asia with more relaxed environmental laws.\n\nChina's environmental movement is characterized by both the rise of environmental NGOs and policy advocacy and spontaneous alliances and protests that often only occur at the local level. Environmental protests in China are increasingly expanding their scope of concerns, calling for broader participation \"in the name of the public.\" \n\nThe Chinese have realized the ability of riots and protests to have success and had led to an increase in disputes in China by 30% since 2005 to more than 50,000 events. Protests cover topics such as environmental issues, land loss, income, and political issues. They have also grown in size from about 10 people or fewer in the mid-1990s to 52 people per incident in 2004. China has more relaxed environmental laws than other countries in Asia, so many polluting factories have relocated to China causing pollution in China. \n\nWater pollution, water scarcity, soil pollution, soil degradation, and desertification are issues currently in discussion in China. The groundwater table of the North China Plain is dropping by 1.5 m (5 ft) per year. This groundwater table occurs in the region of China that produces 40% of the country's grain. The Center for Legal Assistance to Pollution Victims works to confront legal issues associated with environmental justice by hearing court cases that expose the narratives of victims of environmental pollution. As China continues domestic economic reforms and integration into global markets, there emerge new linkages between China's domestic environmental degradation and global econological crisis.\n\nComparing the experiend of China, South Korea, Japan and Taiwan reveals that the impact of environmental activism is heavily modified by domestic political context, particularly the level of integration of mass-based protests and policy advocacy NGOs. Hinted by the history of neighboring Japan and South Korea, the possible convergence of NGOs and anti-pollution protests will have significant implications for Chinese environmental politics in the coming years.\n\nEnvironmental and public health is an ongoing struggle within India. The first seed of an environmental movement in India was the foundation in 1964 of \"Dasholi Gram Swarajya Sangh\", a labour cooperative started by Chandi Prasad Bhatt. It was inaugurated by Sucheta Kriplani and founded on a land donated by Shyma Devi. This initiative was eventually followed up with the Chipko movement starting in 1974.\n\nThe most severe single event underpinning the movement was the Bhopal gas leakage on 3 December 1984. 40 tons of methyl isocyanate was released, immediately killing 2,259 people and ultimately affecting 700,000 citizens.\n\nIndia has a national campaign against Coca-Cola and Pepsi Cola plants due to their practices of drawing ground water and contaminating fields with sludge. The movement is characterized by local struggles against intensive aquaculture farms. The most influential part of the environmental movement in India is the anti-dam movement. Dam creation has been thought of as a way for India to catch up with the West by connecting to the power grid with giant dams, coal or oil-powered plants, or nuclear plants. Jhola Aandolan a mass movement is conducting as fighting against polyethylene carry bags uses and promoting cloth/jute/paper carry bags to protect environment & nature. Activists in the Indian environmental movement consider global warming, sea levels rising, and glaciers retreating decreasing the amount of water flowing into streams to be the biggest challenges for them to face in the early twenty-first century.\nEco Revolution movement has been started by Eco Needs Foundation in 2008 from Aurangabad Maharashtra state .The pioneer of Eco Revolution movement is Prof.Priyanand Agale more than 20,000 youths associated with this movement to strengthen this movement Eco Needs Foundation organized mass environmental awareness programmes. To sought participation of children, Youths, researchers, spiritual and political leaders.Foundation had conducted International conferences at India Eco Revolution 2011 which concluded with Aurangabad Declaration for River Conservation. Eco Revolution 2012 conference was conducted in Sri Lanka which concluded with Colombo Declaration on spirituality for environmental conservation in collaboration with Sri Lanka government. Eco Revolution 2013 was conducted at Nepal which concluded with the Phokhara Declaration for effect of climate change at high altitude .Foundation launched the worlds first environmental social networking site ecoface.in. Foundation developed model of sustainable development at Dhanora village of Dholpur, Rajasthan as a India's First smart village. Eco Needs Foundation started World Rights to Water Day 20 March 2017.\n\nMithun Roy Chowdhury, President, Save Nature & Wildlife (SNW), Bangladesh, insisted that the people of Bangladesh raise their voice against Tipaimukh Dam, being constructed by the Government of India. He said Tipaimukh Dam project will be another \"death trap for Bangladesh like the Farakka Barrage,\" that would lead to an environmental disaster for 50 million people in the Meghna River basin. He said that this project will start desertification in Bangladesh.\n\nEnvironmental science is the study of the interactions among the physical, chemical and biological components of the environment.\n\n\nThe environmental movement is broad in scope and can include any topic related to the environment, conservation, and biology, as well as preservation of landscapes, flora, and fauna for a variety of purposes and uses. See List of environmental issues. When an act of violence is committed against someone or some institution in the name of environmental defense it is referred to as eco terrorism.\n\n\nMany environmental lawsuits question the legal rights of property owners, and whether the general public has a right to intervene with detrimental practices occurring on someone else's land. Environmental law organizations exist all across the world, such as the Environmental Law and Policy Center in the midwestern United States.\n\nOne of the earliest lawsuits to establish that citizens may sue for environmental and aesthetic harms was \"Scenic Hudson Preservation Conference v. Federal Power Commission\", decided in 1965 by the Second Circuit Court of Appeals. The case helped halt the construction of a power plant on Storm King Mountain in New York State. See also United States environmental law and David Sive, an attorney who was involved in the case.\n\nChristopher D. Stone's 1972 essay, \"Should trees have standing?\" addressed the question of whether natural objects themselves should have legal rights. In the essay, Stone suggests that his argument is valid because many current rightsholders (women, children) were once seen as objects.\n\nNumerous criticisms and ethical ambiguities have led to growing concerns about technology, including the use of potentially harmful pesticides, water additives like fluoride, and the extremely dangerous ethanol-processing plants.\n\nNIMBY syndrome refers to public outcry caused by knee-jerk reaction to an unwillingness to be exposed to even necessary developments. Some serious biologists and ecologists created the scientific ecology movement which would not confuse empirical data with visions of a desirable future world.\n\nToday, the sciences of ecology and environmental science, in addition to any aesthetic goals, provide the basis of unity to some of the serious environmentalists. As more information is gathered in scientific fields, more scientific issues like biodiversity, as opposed to mere aesthetics, are a concern to environmentalists. Conservation biology is a rapidly developing field.\n\nIn recent years, the environmental movement has increasingly focused on global warming as one of the top issues. As concerns about climate change moved more into the mainstream, from the connections drawn between global warming and Hurricane Katrina to Al Gore's 2006 documentary film \"An Inconvenient Truth\", more and more environmental groups refocused their efforts. In the United States, 2007 witnessed the largest grassroots environmental demonstration in years, Step It Up 2007, with rallies in over 1,400 communities and all 50 states for real global warming solutions.\n\nMany religious organizations and individual churches now have programs and activities dedicated to environmental issues. The religious movement is often supported by interpretation of scriptures. Most major religious groups are represented including Jewish, Islamic, Anglican, Orthodox, Evangelical, Zoroastrian, Christian and Catholic.\n\nRadical environmentalism emerged from an ecocentrism-based frustration with the co-option of mainstream environmentalism. The radical environmental movement aspires to what scolar Christopher Manes calls \"a new kind of environmental activism: iconoclastic, uncompromising, discontented with traditional conservation policy, at times illegal ...\" Radical environmentalism presupposes a need to reconsider Western ideas of religion and philosophy (including capitalism, patriarchy and globalization) sometimes through \"resacralising\" and reconnecting with nature.\nGreenpeace represents an organisation with a radical approach, but has contributed in serious ways towards understanding of critical issues, and has a science-oriented core with radicalism as a means to media exposure. Groups like Earth First! take a much more radical posture. Some radical environmentalist groups, like Earth First! and the Earth Liberation Front, illegally sabotage or destroy infrastructural capital.\n\nConservative critics of the movement characterize it as radical and misguided. Especially critics of the United States Endangered Species Act, which has come under scrutiny lately, and the Clean Air Act, which they said conflict with private property rights, corporate profits and the nation's overall economic growth. Critics also challenge the scientific evidence for global warming. They argue that the environmental movement has diverted attention from more pressing issues.\n\n"}
{"id": "56571995", "url": "https://en.wikipedia.org/wiki?curid=56571995", "title": "Evelyn Thomas Butts", "text": "Evelyn Thomas Butts\n\nEvelyn Thomas Butts (May 22, 1924 - March 11, 1993) was an African American civil rights activist and politician in Virginia. She is best known for challenging the poll tax and took her case before the United States Supreme Court. Butts was part of the civil rights movement and later became an influential member of Norfolk politics.\n\nEvelyn Thomas was born May 22, 1924 in Norfolk, Virginia. When she was ten years old, her mother, Lottie Cornick Thomas, died and she was adopted and raised by a politically active aunt. She married Charles Herbert Butts in 1941 and her husband served in World War II. The couple had three daughters together. When Charles retired due to a war-injury, Butts worked as a seamstress and took in boarders to make money. The Butts family moved to the Oakwood neighborhood of Norfolk and Butts became the president of the neighborhood's civic league.\n\nButts became involved in Civil Rights in the 1950s. During her time as the Oakwood Civic League, she helped create the Rosemont Middle School in her neighborhood so that children wouldn't have to ride the bus to the segregated school. In 1960, she was involved in picketing the Be-Lo Supermarket for not employing black people in higher-level positions. She also protested against black people being told to sit in certain parts of the football stadium. In 1961, Butts was chosen to run against the incumbent president of the Norfolk NAACP. However, Butts withdrew when it became clear she would lose.\n\nButts and her lawyer, Joseph A. Jordan Jr., sued the state of Virginia for requiring the poll tax, filing in November of 1963. Butts' case was that the tax was unconstitutional since it imposed an \"undue financial burden\" that violated the equal protection clause of the 14th Amendment. In March 1964, this first case was dismissed, but Butts filed another case and the 4th U.S. Circuit Court of Appeals upheld the tax. Butts appealed the case and the United States Supreme Court decided to hear the appeal in October 1965. Butts' case was combined with a similar case filed by Annie E. Harper, which reached the Supreme Court first. The case, \"Harper v. Virginia State Board of Elections\", was decided in March of 1966, making poll taxes unconstitutional.\n\nAfter the Supreme Court decision, Butts went on to register black voters in Norfolk, signing up 2,882 \"in one six month period.\" Butts, along with Jordan and other community leaders, helped create the Concerned Citizens for Political Education group, which became a powerful political force in local politics in the 1970s.\n\nButts was appointed the commissioner of the Norfolk Redevelopment and Housing Authority (NRHA) in 1975. She would serve on the NRHA for twelve years. In 1982, she was appointed by the governor to the State Board of Housing and Community Development.\n\nButts ran for city council in Norfolk three times in 1980, 1982 and in 1984, but was never successful. Also in 1984, Butts was a witness in a court trial where she supported an at-large election system in Norfolk.\n\nButts was forced into retirement from politics in 1990 when she was ousted as the chair of the Concerned Citizens for Political Education. Butts died in her home on March 11, 1993. She is buried in Norfolk's Forest Lawn Cemetery.\n\nOn November of 1995, Norfolk named a street in her honor. On March 27, 1996, the city held a celebration to mark the 30th anniversary of the poll tax repeal. During the celebration, they honored Butts and other activists involved. In 2017, Butts' daughter, Charlene Butts Ligon, published a book about her mother called \"Fearless: How a Poor Virginia Seamstress Took on Jim Crow, Beat the Poll Tax and Changed Her City Forever\". The \"New Journal and Guide\" called the book \"thoughtful and information-filled.\" The book provides intimate details of Butts' life and her activism as seen through her daughter's eyes. \n\n"}
{"id": "21401843", "url": "https://en.wikipedia.org/wiki?curid=21401843", "title": "Freedom of speech", "text": "Freedom of speech\n\nFreedom of speech is a principle that supports the freedom of an individual or a community to articulate their opinions and ideas without fear of retaliation, censorship, or legal sanction. The term \"freedom of expression\" is sometimes used synonymously but includes any act of seeking, receiving, and imparting information or ideas, regardless of the medium used.\n\nFreedom of expression is recognized as a human right under article 19 of the Universal Declaration of Human Rights (UDHR) and recognized in international human rights law in the International Covenant on Civil and Political Rights (ICCPR). Article 19 of the UDHR states that \"everyone shall have the right to hold opinions without interference\" and \"everyone shall have the right to freedom of expression; this right shall include freedom to seek, receive and impart information and ideas of all kinds, regardless of frontiers, either orally, in writing or in print, in the form of art, or through any other media of his choice\". The version of Article 19 in the ICCPR later amends this by stating that the exercise of these rights carries \"special duties and responsibilities\" and may \"therefore be subject to certain restrictions\" when necessary \"[f]or respect of the rights or reputation of others\" or \"[f]or the protection of national security or of public order (order public), or of public health or morals\".\n\nFreedom of speech and expression, therefore, may not be recognized as being absolute, and common limitations to freedom of speech relate to libel, slander, obscenity, pornography, sedition, incitement, fighting words, classified information, copyright violation, trade secrets, food labeling, non-disclosure agreements, the right to privacy, the right to be forgotten, public security, and perjury. Justifications for such include the harm principle, proposed by John Stuart Mill in \"On Liberty\", which suggests that: \"the only purpose for which power can be rightfully exercised over any member of a civilized community, against his will, is to prevent harm to others.\"\n\nThe idea of the \"offense principle\" is also used in the justification of speech limitations, describing the restriction on forms of expression deemed offensive to society, considering factors such as extent, duration, motives of the speaker, and ease with which it could be avoided. With the evolution of the digital age, application of the freedom of speech becomes more controversial as new means of communication and restrictions arise, for example the Golden Shield Project, an initiative by Chinese government's Ministry of Public Security that filters potentially unfavorable data from foreign countries.\n\nFreedom of speech and expression has a long history that predates modern international human rights instruments. It is thought that ancient Athenian democratic principle of free speech may have emerged in the late 6th or early 5th century BC. The values of the Roman Republic included freedom of speech and freedom of religion.\n\nConcepts of freedom of speech can be found in early human rights documents. England's Bill of Rights 1689 legally established the constitutional right of 'freedom of speech in Parliament' which is still in effect. The Declaration of the Rights of Man and of the Citizen, adopted during the French Revolution in 1789, specifically affirmed freedom of speech as an inalienable right. The Declaration provides for freedom of expression in Article 11, which states that:\n\nThe free communication of ideas and opinions is one of the most precious of the rights of man. Every citizen may, accordingly, speak, write, and print with freedom, but shall be responsible for such abuses of this freedom as shall be defined by law.\n\nArticle 19 of the Universal Declaration of Human Rights, adopted in 1948, states that: Everyone has the right to freedom of opinion and expression; this right includes freedom to hold opinions without interference and to seek, receive and impart information and ideas through any media and regardless of frontiers.\n\nToday, freedom of speech, or the freedom of expression, is recognized in international and regional human rights law. The right is enshrined in Article 19 of the International Covenant on Civil and Political Rights, Article 10 of the European Convention on Human Rights, Article 13 of the American Convention on Human Rights and Article 9 of the African Charter on Human and Peoples' Rights. Based on John Milton's arguments, freedom of speech is understood as a multi-faceted right that includes not only the right to express, or disseminate, information and ideas, but three further distinct aspects:\n\nInternational, regional and national standards also recognize that freedom of speech, as the freedom of expression, includes any medium, be it orally, in written, in print, through the Internet or through art forms. This means that the protection of freedom of speech as a right includes not only the content, but also the means of expression.\n\nThe right to freedom of speech and expression is closely related to other rights, and may be limited when conflicting with other rights (see limitations on freedom of speech). The right to freedom of expression is also related to the right to a fair trial and court proceeding which may limit access to the search for information, or determine the opportunity and means in which freedom of expression is manifested within court proceedings. As a general principle freedom of expression may not limit the right to privacy, as well as the honor and reputation of others. However greater latitude is given when criticism of public figures is involved.\n\nThe right to freedom of expression is particularly important for media, which plays a special role as the bearer of the general right to freedom of expression for all. However, freedom of the press does not necessarily enable freedom of speech. Judith Lichtenberg has outlined conditions in which freedom of the press may constrain freedom of speech, for example where the media suppresses information or stifles the diversity of voices inherent in freedom of speech. Lichtenberg argues that freedom of the press is simply a form of property right summed up by the principle \"no money, no voice\".\n\nFreedom of speech is understood to be fundamental in a democracy. The norms on limiting freedom of expression mean that public debate may not be completely suppressed even in times of emergency. One of the most notable proponents of the link between freedom of speech and democracy is Alexander Meiklejohn. He has argued that the concept of democracy is that of self-government by the people. For such a system to work, an informed electorate is necessary. In order to be appropriately knowledgeable, there must be no constraints on the free flow of information and ideas. According to Meiklejohn, democracy will not be true to its essential ideal if those in power are able to manipulate the electorate by withholding information and stifling criticism. Meiklejohn acknowledges that the desire to manipulate opinion can stem from the motive of seeking to benefit society. However, he argues, choosing manipulation negates, in its means, the democratic ideal.\n\nEric Barendt has called this defense of free speech on the grounds of democracy \"probably the most attractive and certainly the most fashionable free speech theory in modern Western democracies\". Thomas I. Emerson expanded on this defense when he argued that freedom of speech helps to provide a balance between stability and change. Freedom of speech acts as a \"safety valve\" to let off steam when people might otherwise be bent on revolution. He argues that \"The principle of open discussion is a method of achieving a more adaptable and at the same time more stable community, of maintaining the precarious balance between healthy cleavage and necessary consensus.\" Emerson furthermore maintains that \"Opposition serves a vital social function in offsetting or ameliorating (the) normal process of bureaucratic decay.\"\n\nResearch undertaken by the Worldwide Governance Indicators project at the World Bank, indicates that freedom of speech, and the process of accountability that follows it, have a significant impact in the quality of governance of a country. \"Voice and Accountability\" within a country, defined as \"the extent to which a country's citizens are able to participate in selecting their government, as well as freedom of expression, freedom of association, and free media\" is one of the six dimensions of governance that the Worldwide Governance Indicators measure for more than 200 countries. Against this backdrop it is important that development agencies create grounds for effective support for a free press in developing countries.\n\nRichard Moon has developed the argument that the value of freedom of speech and freedom of expression lies with social interactions. Moon writes that \"by communicating an individual forms relationships and associations with others – family, friends, co-workers, church congregation, and countrymen. By entering into discussion with others an individual participates in the development of knowledge and in the direction of the community.\"\n\nLegal systems sometimes recognize certain limits on the freedom of speech, particularly when freedom of speech conflicts with other rights and freedoms, such as in the cases of libel, slander, pornography, obscenity, fighting words, and intellectual property. In Europe, blasphemy is a limitation to free speech. Justifications for limitations to freedom of speech often reference the \"harm principle\" or the \"offense principle\". Limitations to freedom of speech may occur through legal sanction or social disapprobation, or both. Certain public institutions may also enact policies restricting the freedom of speech, for example speech codes at state schools.\n\nIn \"On Liberty\" (1859), John Stuart Mill argued that \"...there ought to exist the fullest liberty of professing and discussing, as a matter of ethical conviction, any doctrine, however immoral it may be considered.\" Mill argues that the fullest liberty of expression is required to push arguments to their logical limits, rather than the limits of social embarrassment. However, Mill also introduced what is known as the harm principle, in placing the following limitation on free expression: \"the only purpose for which power can be rightfully exercised over any member of a civilized community, against his will, is to prevent harm to others.\"\n\nIn 1985, Joel Feinberg introduced what is known as the \"offense principle\", arguing that Mill's harm principle does not provide sufficient protection against the wrongful behaviors of others. Feinberg wrote \"It is always a good reason in support of a proposed criminal prohibition that it would probably be an effective way of preventing serious offense (as opposed to injury or harm) to persons other than the actor, and that it is probably a necessary means to that end.\" Hence Feinberg argues that the harm principle sets the bar too high and that some forms of expression can be legitimately prohibited by law because they are very offensive. But, as offending someone is less serious than harming someone, the penalties imposed should be higher for causing harm. In contrast, Mill does not support legal penalties unless they are based on the harm principle. Because the degree to which people may take offense varies, or may be the result of unjustified prejudice, Feinberg suggests that a number of factors need to be taken into account when applying the offense principle, including: the extent, duration and social value of the speech, the ease with which it can be avoided, the motives of the speaker, the number of people offended, the intensity of the offense, and the general interest of the community at large.\n\nAlong similar lines as Mill, Jasper Doomen argued that harm should be defined from the point of view of the individual citizen, not limiting harm to physical harm since nonphysical harm may also be involved; Feinberg's distinction between harm and offense is criticized as largely trivial.\n\nIn 1999, Bernard Harcourt wrote of the collapse of the harm principle: \"Today the debate is characterized by a cacophony of competing harm arguments without any way to resolve them. There is no longer an argument within the structure of the debate to resolve the competing claims of harm. The original harm principle was never equipped to determine the relative importance of harms.\"\n\nInterpretations of both the harm and offense limitations to freedom of speech are culturally and politically relative. For instance, in Russia, the harm and offense principles have been used to justify the Russian LGBT propaganda law restricting speech (and action) in relation to LGBT issues. A number of European countries that take pride in freedom of speech nevertheless outlaw speech that might be interpreted as Holocaust denial. These include Austria, Belgium, Czech Republic, France, Germany, Hungary, Israel, Liechtenstein, Lithuania, Luxembourg, Netherlands, Poland, Portugal, Slovakia, and Switzerland.\n\nIn the U.S., the standing landmark opinion on political speech is \"Brandenburg v. Ohio\" (1969), expressly overruling \"Whitney v. California\". In \"Brandenburg\", the US Supreme Court referred to the right even to speak openly of violent action and revolution in broad terms: The opinion in \"Brandenburg\" discarded the previous test of \"clear and present danger\" and made the right to freedom of (political) speech's protections in the United States almost absolute. Hate speech is also protected by the First Amendment in the United States, as decided in \"R.A.V. v. City of St. Paul\", (1992) in which the Supreme Court ruled that hate speech is permissible, except in the case of imminent violence. See the First Amendment to the United States Constitution for more detailed information on this decision and its historical background.\n\nJo Glanville, editor of the \"Index on Censorship\", states that \"the Internet has been a revolution for censorship as much as for free speech\". International, national and regional standards recognise that freedom of speech, as one form of freedom of expression, applies to any medium, including the Internet. The Communications Decency Act (CDA) of 1996 was the first major attempt by the United States Congress to regulate pornographic material on the Internet. In 1997, in the landmark cyberlaw case of \"Reno v. ACLU\", the US Supreme Court partially overturned the law. Judge Stewart R. Dalzell, one of the three federal judges who in June 1996 declared parts of the CDA unconstitutional, in his opinion stated the following:\n\nThe Internet is a far more speech-enhancing medium than print, the village green, or the mails. Because it would necessarily affect the Internet itself, the CDA would necessarily reduce the speech available for adults on the medium. This is a constitutionally intolerable result. Some of the dialogue on the Internet surely tests the limits of conventional discourse. Speech on the Internet can be unfiltered, unpolished, and unconventional, even emotionally charged, sexually explicit, and vulgar – in a word, \"indecent\" in many communities. But we should expect such speech to occur in a medium in which citizens from all walks of life have a voice. We should also protect the autonomy that such a medium confers to ordinary people as well as media magnates.[...] My analysis does not deprive the Government of all means of protecting children from the dangers of Internet communication. The Government can continue to protect children from pornography on the Internet through vigorous enforcement of existing laws criminalizing obscenity and child pornography. [...] As we learned at the hearing, there is also a compelling need for public educations about the benefits and dangers of this new medium, and the Government can fill that role as well. In my view, our action today should only mean that Government's permissible supervision of Internet contents stops at the traditional line of unprotected speech. [...] The absence of governmental regulation of Internet content has unquestionably produced a kind of chaos, but as one of the plaintiff's experts put it with such resonance at the hearing: \"What achieved success was the very chaos that the Internet is. The strength of the Internet is chaos.\" Just as the strength of the Internet is chaos, so that strength of our liberty depends upon the chaos and cacophony of the unfettered speech the First Amendment protects.\n\nThe World Summit on the Information Society (WSIS) Declaration of Principles adopted in 2003 makes specific reference to the importance of the right to freedom of expression for the \"Information Society\" in stating:\n\nWe reaffirm, as an essential foundation of the Information society, and as outlined in Article 19 of the Universal Declaration of Human Rights, that everyone has the right to freedom of opinion and expression; that this right includes freedom to hold opinions without interference and to seek, receive and impart information and ideas through any media and regardless of frontiers. Communication is a fundamental social process, a basic human need and the foundation of all social organisation. It is central to the Information Society. Everyone, everywhere should have the opportunity to participate and no one should be excluded from the benefits of the Information Society offers.\n\nAccording to Bernt Hugenholtz and Lucie Guibault the public domain is under pressure from the \"commodification of information\" as information with previously little or no economic value has acquired independent economic value in the information age. This includes factual data, personal data, genetic information and pure ideas. The commodification of information is taking place through intellectual property law, contract law, as well as broadcasting and telecommunications law.\n\nThe internet and freedom of speech have been in the spotlight quite often recently. With the removal of Alex Jones from Facebook and YouTube, questions are being raised about freedom of speech rights and how those liberties apply to the internet.\n\nFreedom of information is an extension of freedom of speech where the medium of expression is the Internet. Freedom of information may also refer to the right to privacy in the context of the Internet and information technology. As with the right to freedom of expression, the right to privacy is a recognised human right and freedom of information acts as an extension to this right. Freedom of information may also concern censorship in an information technology context, i.e. the ability to access Web content, without censorship or restrictions.\n\nFreedom of information is also explicitly protected by acts such as the Freedom of Information and Protection of Privacy Act of Ontario, in Canada.\n\nThe concept of freedom of information has emerged in response to state sponsored censorship, monitoring and surveillance of the internet. Internet censorship includes the control or suppression of the publishing or accessing of information on the Internet. The Global Internet Freedom Consortium claims to remove blocks to the \"free flow of information\" for what they term \"closed societies\". According to the Reporters without Borders (RWB) \"internet enemy list\" the following states engage in pervasive internet censorship: China, Cuba, Iran, Myanmar/Burma, North Korea, Saudi Arabia, Syria, Turkmenistan, Uzbekistan, and Vietnam.\n\nA widely publicized example of internet censorship is the \"Great Firewall of China\" (in reference both to its role as a network firewall and to the ancient Great Wall of China). The system blocks content by preventing IP addresses from being routed through and consists of standard firewall and proxy servers at the Internet gateways. The system also selectively engages in DNS poisoning when particular sites are requested. The government does not appear to be systematically examining Internet content, as this appears to be technically impractical. Internet censorship in the People's Republic of China is conducted under a wide variety of laws and administrative regulations, including more than sixty regulations directed at the Internet. Censorship systems are vigorously implemented by provincial branches of state-owned ISPs, business companies, and organizations.\n\nBefore the invention of the printing press a written work, once created, could only be physically multiplied by highly laborious and error-prone manual copying. No elaborate system of censorship and control over scribes existed, who until the 14th century were restricted to religious institutions, and their works rarely caused wider controversy. In response to the printing press, and the \"heresies\" it allowed to spread, the Roman Catholic Church moved to impose censorship. Printing allowed for multiple exact copies of a work, leading to a more rapid and widespread circulation of ideas and information (see print culture). The origins of copyright law in most European countries lie in efforts by the Roman Catholic Church and governments to regulate and control the output of printers.\nIn 1501 Pope Alexander VI issued a Bill against the unlicensed printing of books and in 1559 the Index Expurgatorius, or \"List of Prohibited Books\", was issued for the first time. The Index Expurgatorius is the most famous and long lasting example of \"bad books\" catalogues issued by the Roman Catholic Church, which presumed to be in authority over private thoughts and opinions, and suppressed views that went against its doctrines. The Index Expurgatorius was administered by the Roman Inquisition, but enforced by local government authorities, and went through 300 editions. Amongst others, it banned or censored books written by René Descartes, Giordano Bruno, Galileo Galilei, David Hume, John Locke, Daniel Defoe, Jean-Jacques Rousseau and Voltaire. While governments and church encouraged printing in many ways because it allowed for the dissemination of Bibles and government information, works of dissent and criticism could also circulate rapidly. As a consequence, governments established controls over printers across Europe, requiring them to have official licenses to trade and produce books.\nThe notion that the expression of dissent or subversive views should be tolerated, not censured or punished by law, developed alongside the rise of printing and the press. \"Areopagitica\", published in 1644, was John Milton's response to the Parliament of England's re-introduction of government licensing of printers, hence publishers. Church authorities had previously ensured that Milton's essay on the right to divorce was refused a license for publication. In Areopagitica, published without a license, Milton made an impassioned plea for freedom of expression and toleration of falsehood, stating:\n\nGive me the liberty to know, to utter, and to argue freely according to conscience, above all liberties.\nMilton's defense of freedom of expression was grounded in a Protestant worldview and he thought that the English people had the mission to work out the truth of the Reformation, which would lead to the enlightenment of all people. But Milton also articulated the main strands of future discussions about freedom of expression. By defining the scope of freedom of expression and of \"harmful\" speech Milton argued against the principle of pre-censorship and in favor of tolerance for a wide range of views. Freedom of the press ceased being regulated in England in 1695 when the Licensing Order of 1643 was allowed to expire after the introduction of the Bill of Rights 1689 shortly after the Glorious Revolution. The emergence of publications like the \"Tatler\" (1709) and the \"Spectator\" (1711) are given credit for creating a 'bourgeois public sphere' in England that allowed for a free exchange of ideas and information.\n\nAs the \"menace\" of printing spread, more governments attempted to centralize control. The French crown repressed printing and the printer Etienne Dolet was burned at the stake in 1546. In 1557 the British Crown thought to stem the flow of seditious and heretical books by chartering the Stationers' Company. The right to print was limited to the members of that guild, and thirty years later the Star Chamber was chartered to curtail the \"greate enormities and abuses\" of \"dyvers contentyous and disorderlye persons professinge the arte or mystere of pryntinge or selling of books.\" The right to print was restricted to two universities and to the 21 existing printers in the city of London, which had 53 printing presses. As the British crown took control of type founding in 1637 printers fled to the Netherlands. Confrontation with authority made printers radical and rebellious, with 800 authors, printers and book dealers being incarcerated in the Bastille in Paris before it was stormed in 1789.\n\nA succession of English thinkers was at the forefront of early discussion on a right to freedom of expression, among them John Milton (1608–74) and John Locke (1632–1704). Locke established the individual as the unit of value and the bearer of rights to life, liberty, property and the pursuit of happiness. However Locke's ideas evolved primarily around the concept of the right to seek salvation for one's soul, and was thus primarily concerned with theological matters. Locke neither supported a universal toleration of peoples nor freedom of speech; according to his ideas, some groups, such as atheists, should not be allowed.\nBy the second half of the 17th century philosophers on the European continent like Baruch Spinoza and Pierre Bayle developed ideas encompassing a more universal aspect freedom of speech and toleration than the early English philosophers. By the 18th century the idea of freedom of speech was being discussed by thinkers all over the Western world, especially by French philosophes like Denis Diderot, Baron d'Holbach and Claude Adrien Helvétius. The idea began to be incorporated in political theory both in theory as well as practice; the first state edict in history proclaiming complete freedom of speech was the one issued December 4, 1770 in Denmark-Norway during the regency of Johann Friedrich Struensee. However Struensee himself imposed some minor limitations to this edict in October 7, 1771, and it was even further limited after the fall of Struensee with legislation introduced in 1773, although censorship was not reintroduced.\n\nJohn Stuart Mill (1806–1873) argued that without human freedom there can be no progress in science, law or politics, which according to Mill required free discussion of opinion. Mill's \"On Liberty\", published in 1859 became a classic defence of the right to freedom of expression. Mill argued that truth drives out falsity, therefore the free expression of ideas, true or false, should not be feared. Truth is not stable or fixed, but evolves with time. Mill argued that much of what we once considered true has turned out false. Therefore, views should not be prohibited for their apparent falsity. Mill also argued that free discussion is necessary to prevent the \"deep slumber of a decided opinion\". Discussion would drive the onwards march of truth and by considering false views the basis of true views could be re-affirmed. Furthermore, Mill argued that an opinion only carries intrinsic value to the owner of that opinion, thus silencing the expression of that opinion is an injustice to a basic human right. For Mill, the only instance in which speech can be justifiably suppressed is in order to prevent harm from a clear and direct threat. Neither economic or moral implications, nor the speakers own well-being would justify suppression of speech.\n\nIn Evelyn Beatrice Hall's biography of Voltaire, she coined the following sentence to illustrate Voltaire's beliefs: \"I disapprove of what you say, but I will defend to the death your right to say it.\" Hall's quote is frequently cited to describe the principle of freedom of speech. In the 20th Century, Noam Chomsky states that: \"If you believe in freedom of speech, you believe in freedom of speech for views you don't like. Dictators such as Stalin and Hitler, were in favor of freedom of speech for views they liked only. If you're in favor of freedom of speech, that means you're in favor of freedom of speech precisely for views you despise.\" Lee Bollinger argues that \"the free speech principle involves a special act of carving out one area of social interaction for extraordinary self-restraint, the purpose of which is to develop and demonstrate a social capacity to control feelings evoked by a host of social encounters.\" Bollinger argues that tolerance is a desirable value, if not essential. However, critics argue that society should be concerned by those who directly deny or advocate, for example, genocide (see limitations above).\n\nThe 1928 novel \"Lady Chatterley's Lover\" by D. H. Lawrence was banned for obscenity in a number of countries, including the United Kingdom, the United States, Australia and Canada. In the late 1950s and early 1960s, it was the subject of landmark court rulings which saw the ban for obscenity overturned. Dominic Sandbrook of \"The Telegraph\" in the UK wrote, \"Now that public obscenity has become commonplace, it is hard to recapture the atmosphere of a society that saw fit to ban books such as \"Lady Chatterley’s Lover\" because it was likely to “deprave and corrupt” its readers.\" Fred Kaplan of \"The New York Times\" stated the overturning of the obscenity laws \"set off an explosion of free speech\" in the US.\n\nThe right to freedom of expression has been interpreted to include the right to take and publish photographs of strangers in public areas without their permission or knowledge.\n\n\n"}
{"id": "53762899", "url": "https://en.wikipedia.org/wiki?curid=53762899", "title": "Fusion category", "text": "Fusion category\n\nIn mathematics, a fusion category is a category that is rigid, semisimple, formula_1-linear, monoidal and has only finitely many isomorphism classes of simple objects, such that the monoidal unit is simple. If the ground field formula_1 is algebraically closed, then the latter is equivalent to formula_3 by Schur's lemma.\n\n\nUnder Tannaka-Krein duality, every fusion category arises as the representations of a weak Hopf algebra.\n"}
{"id": "48471703", "url": "https://en.wikipedia.org/wiki?curid=48471703", "title": "GNC hypothesis", "text": "GNC hypothesis\n\nThe GNC hypothesis or GNC-SNS primeval genetic code hypothesis refers to a hypothesis about the origin of genes. It suggests the universal genetic code originated not from a three-amino acid system, but from a four-amino acid system. It is this GNC code encoding [GADV]-proteins which is the most primitive genetic code. This hypothesis was first proposed by Kenji Ikehara at Nara Women's University.\n\nWhile almost all of the organisms on Earth share the universal genetic code, in the GNC hypothesis it is argued that two primeval genetic codes preceded the present genetic code as follows:\n\n\nThe GNC hypothesis is based on the following facts:\n\n\n"}
{"id": "995417", "url": "https://en.wikipedia.org/wiki?curid=995417", "title": "Geodetic datum", "text": "Geodetic datum\n\nA geodetic datum or geodetic system is a coordinate system, and a set of reference points, used to locate places on the Earth (or similar objects). An approximate definition of sea level is the datum WGS 84, an ellipsoid, whereas a more accurate definition is Earth Gravitational Model 2008 (EGM2008), using at least 2,159 spherical harmonics. Other datums are defined for other areas or at other times; ED50 was defined in 1950 over Europe and differs from WGS 84 by a few hundred meters depending on where in Europe you look. \nMars has no oceans and so no sea level, but at least two martian datums have been used to locate places there.\n\nDatums are used in geodesy, navigation, and surveying by cartographers and satellite navigation systems to translate positions indicated on maps (paper or digital) to their real position on Earth. Each starts with an ellipsoid (stretched sphere), and then defines latitude, longitude and altitude coordinates. One or more locations on the Earth's surface are chosen as anchor \"base-points\".\n\nThe difference in co-ordinates between datums is commonly referred to as \"datum shift\". The datum shift between two particular datums can vary from one place to another within one country or region, and can be anything from zero to hundreds of meters (or several kilometers for some remote islands). The North Pole, South Pole and Equator will be in different positions on different datums, so True North will be slightly different. Different datums use different interpolations for the precise shape and size of the Earth (reference ellipsoids).\n\nBecause the Earth is an imperfect ellipsoid, localised datums can give a more accurate representation of the area of coverage than WGS 84. OSGB36, for example, is a better approximation to the geoid covering the British Isles than the global WGS 84 ellipsoid. However, as the benefits of a global system outweigh the greater accuracy, the global WGS 84 datum is becoming increasingly adopted.\n\nHorizontal datums are used for describing a point on the Earth's surface, in latitude and longitude or another coordinate system. Vertical datums measure elevations or depths.\n\nIn surveying and geodesy, a \"datum\" is a reference system or an approximation of the Earth's surface against which positional measurements are made for computing locations. Horizontal datums are used for describing a point on the Earth's surface, in latitude and longitude or another coordinate system. Vertical datums are used to measure elevations or underwater depths.\n\nThe horizontal datum is the model used to measure positions on the Earth. A specific point on the Earth can have substantially different coordinates, depending on the datum used to make the measurement. There are hundreds of local horizontal datums around the world, usually referenced to some convenient local reference point. Contemporary datums, based on increasingly accurate measurements of the shape of the Earth, are intended to cover larger areas. The WGS 84 datum, which is almost identical to the NAD83 datum used in North America and the ETRS89 datum used in Europe, is a common standard datum.\n\nFor example, in Sydney there is a 200 metres (700 feet) difference between GPS coordinates configured in GDA (based on global standard WGS 84) and AGD (used for most local maps), which is an unacceptably large error for some applications, such as surveying or site location for scuba diving.\n\nA vertical datum is used as a reference point for elevations of surfaces and features on the Earth including terrain, bathymetry, water levels, and man-made structures. Vertical datums are either: tidal, based on sea levels; gravimetric, based on a geoid; or geodetic, based on the same ellipsoid models of the Earth used for computing horizontal datums.\n\nIn common usage, elevations are often cited in height above sea level, although what “sea level” actually means is a more complex issue than might at first be thought: the height of the sea surface at any one place and time is a result of numerous effects, including waves, wind and currents, atmospheric pressure, tides, topography, and even differences in the strength of gravity due to the presence of mountains etc.\n\nFor the purpose of measuring the height of objects on land, the usual datum used is mean sea level (MSL). This is a tidal datum which is described as the arithmetic mean of the hourly water elevation taken over a specific 19 years cycle. This definition averages out tidal highs and lows (caused by the gravitational effects of the sun and the moon) and short term variations. It will not remove the effects of local gravity strength, and so the height of MSL, relative to a geodetic datum, will vary around the world, and even around one country. Countries tend to choose the mean sea level at one specific point to be used as the standard “sea level” for all mapping and surveying in that country. (For example, in Great Britain, the national vertical datum, Ordnance Datum Newlyn, is based on what was mean sea level at Newlyn in Cornwall between 1915 and 1921). However, zero elevation as defined by one country is not the same as zero elevation defined by another (because MSL is not the same everywhere), which is why locally defined vertical datums differ from one another.\n\nA different principle is used when choosing a datum for nautical charts. For safety reasons, a mariner must be able to know the minimum depth of water that could occur at any point. For this reason, depths and tides on a nautical chart are measured relative to chart datum, which is defined to be a level below which tide rarely falls. Exactly how this is chosen depends on the tidal regime in the area being charted and on the policy of the hydrographic office producing the chart in question; a typical definition is Lowest Astronomical Tide (the lowest tide predictable from the effects of gravity), or Mean Lower Low Water (the average lowest tide of each day), although MSL is sometimes used in waters with very low tidal ranges.\n\nConversely, if a ship is to safely pass under a low bridge or overhead power cable, the mariner must know the minimum clearance between the masthead and the obstruction, which will occur at high tide. Consequently, bridge clearances etc. are given relative to a datum based on high tide, such as Highest Astronomical Tide or Mean High Water Springs.\n\nSea level does not remain constant throughout geological time, and so tidal datums are less useful when studying very long-term processes. In some situations sea level does not apply at all — for instance for mapping Mars' surface — forcing the use of a different \"zero elevation\", such as mean radius.\n\nA geodetic vertical datum takes some specific zero point, and computes elevations based on the geodetic model being used, without further reference to sea levels. Usually, the starting reference point is a tide gauge, so at that point the geodetic and tidal datums might match, but due to sea level variations, the two scales may not match elsewhere. An example of a gravity-based geodetic datum is NAVD88, used in North America, which is referenced to a point in Quebec, Canada. Ellipsoid-based datums such as WGS 84, GRS80 or NAD83 use a theoretical surface that may differ significantly from the geoid.\n\nIn geodetic coordinates, the Earth's surface is approximated by an ellipsoid, and locations near the surface are described in terms of latitude (formula_1), longitude (formula_2), and height (formula_3).\n\nGeodetic latitude (formula_1), resp. altitude, is different from geocentric latitude (formula_5), resp. altitude. Geodetic latitude is determined by the angle between the equatorial plane and normal to the ellipsoid, whereas geocentric latitude is determined by the angle between the equatorial plane and line joining the point to the centre of the ellipsoid (see figure). Unless otherwise specified, latitude is geodetic latitude.\n\nThe ellipsoid is completely parameterised by the semi-major axis formula_6 and the flattening formula_7.\n\nFrom formula_6 and formula_7 it is possible to derive the semi-minor axis formula_10, first eccentricity formula_11 and second eccentricity formula_12 of the ellipsoid\n\nAGD66 and AGD84 both use the parameters defined by Australian National Spheroid (see below)\n\nGDA94 uses the parameters defined by GRS80 (see below)\n\nSee GDA Technical Manual document for more details; the value given above for the flattening is not exact.\n\nThe Global Positioning System (GPS) uses the World Geodetic System 1984 (WGS 84) to determine the location of a point near the surface of the Earth.\n\nSee The official World Geodetic System 1984 document for more details.\n\nA more comprehensive list of geodetic systems can be found here\n\nDatum conversion is the process of converting the coordinates of a point from one datum system to another. Datum conversion may frequently be accompanied by a change of grid projection.\n\nA reference datum is a known and constant surface which is used to describe the location of unknown points on the Earth. Since reference datums can have different radii and different center points, a specific point on the Earth can have substantially different coordinates depending on the datum used to make the measurement. There are hundreds of locally developed reference datums around the world, usually referenced to some convenient local reference point. Contemporary datums, based on increasingly accurate measurements of the shape of the Earth, are intended to cover larger areas. The most common reference Datums in use in North America are NAD27, NAD83, and WGS 84.\n\nThe North American Datum of 1927 (NAD 27) is \"the horizontal control datum for the United States that was defined by a location and azimuth on the Clarke spheroid of 1866, with origin at (the survey station) Meades Ranch (Kansas).\" ... The geoidal height at Meades Ranch was assumed to be zero, as sufficient gravity data was not available, and this was needed to relate surface measurements to the datum. \"Geodetic positions on the North American Datum of 1927 were derived from the (coordinates of and an azimuth at Meades Ranch) through a readjustment of the triangulation of the entire network in which Laplace azimuths were introduced, and the Bowie method was used.\" (http://www.ngs.noaa.gov/faq.shtml#WhatDatum ) NAD27 is a local referencing system covering North America.\n\nThe North American Datum of 1983 (NAD 83) is \"The horizontal control datum for the United States, Canada, Mexico, and Central America, based on a geocentric origin and the Geodetic Reference System 1980 (GRS80). \"This datum, designated as NAD 83 ...is based on the adjustment of 250,000 points including 600 satellite Doppler stations which constrain the system to a geocentric origin.\" NAD83 may be considered a local referencing system.\n\nWGS 84 is the World Geodetic System of 1984. It is the reference frame used by the U.S. Department of Defense (DoD) and is defined by the National Geospatial-Intelligence Agency (NGA) (formerly the Defense Mapping Agency, then the National Imagery and Mapping Agency). WGS 84 is used by DoD for all its mapping, charting, surveying, and navigation needs, including its GPS \"broadcast\" and \"precise\" orbits. WGS 84 was defined in January 1987 using Doppler satellite surveying techniques. It was used as the reference frame for broadcast GPS Ephemerides (orbits) beginning January 23, 1987. At 0000 GMT January 2, 1994, WGS 84 was upgraded in accuracy using GPS measurements. The formal name then became WGS 84 (G730), since the upgrade date coincided with the start of GPS Week 730. It became the reference frame for broadcast orbits on June 28, 1994. At 0000 GMT September 30, 1996 (the start of GPS Week 873), WGS 84 was redefined again and was more closely aligned with International Earth Rotation Service (IERS) frame ITRF 94. It was then formally called WGS 84 (G873). WGS 84 (G873) was adopted as the reference frame for broadcast orbits on January 29, 1997. Another update brought it to WGS84(G1674).\n\nThe WGS 84 datum, within two meters of the NAD83 datum used in North America, is the only world referencing system in place today. WGS 84 is the default standard datum for coordinates stored in recreational and commercial GPS units.\n\nUsers of GPS are cautioned that they must always check the datum of the maps they are using. To correctly enter, display, and to store map related map coordinates, the datum of the map must be entered into the GPS map datum field.\n\nExamples of map datums are:\n\n\n\n"}
{"id": "14201348", "url": "https://en.wikipedia.org/wiki?curid=14201348", "title": "Geometry and topology", "text": "Geometry and topology\n\nIn mathematics, geometry and topology is an umbrella term for the historically distinct disciplines of geometry and topology, as general frameworks allow both disciplines to be manipulated uniformly, most visibly in local to global theorems in Riemannian geometry, and results like the Gauss–Bonnet theorem and Chern–Weil theory.\n\nSharp distinctions between geometry and topology can be drawn, however, as discussed below.\n\nIt is also the title of a journal \"Geometry & Topology\" that covers these topics.\n\nIt is distinct from \"geometric topology\", which more narrowly involves applications of topology to geometry.\n\nIt includes:\n\nIt does not include such parts of algebraic topology as homotopy theory, but some areas of geometry and topology (such as surgery theory, particularly algebraic surgery theory) are heavily algebraic.\n\nGeometry has \"local\" structure (or infinitesimal), while topology only has \"global\" structure. Alternatively, geometry has \"continuous\" moduli, while topology has \"discrete\" moduli.\n\nBy examples, an example of geometry is Riemannian geometry, while an example of topology is homotopy theory. The study of metric spaces is geometry, the study of topological spaces is topology.\n\nThe terms are not used completely consistently: symplectic manifolds are a boundary case, and coarse geometry is global, not local.\n\nBy definition, differentiable manifolds of a fixed dimension are all locally diffeomorphic to Euclidean space, so aside from dimension, there are no local invariants. Thus, differentiable structures on a manifold are topological in nature.\n\nBy contrast, the curvature of a Riemannian manifold is a local (indeed, infinitesimal) invariant (and is the only local invariant under isometry).\n\nIf a structure has a discrete moduli (if it has no deformations, or if a deformation of a structure is isomorphic to the original structure), the structure is said to be rigid, and its study (if it is a geometric or topological structure) is topology. If it has non-trivial deformations, the structure is said to be flexible, and its study is geometry.\n\nThe space of homotopy classes of maps is discrete, so studying maps up to homotopy is topology.\nSimilarly, differentiable structures on a manifold is usually a discrete space, and hence an example of topology, but exotic Rs have continuous moduli of differentiable structures.\n\nAlgebraic varieties have continuous moduli spaces, hence their study is algebraic geometry. These are finite-dimensional moduli spaces.\n\nThe space of Riemannian metrics on a given differentiable manifold is an infinite-dimensional space.\n\nSymplectic manifolds are a boundary case, and parts of their study are called symplectic topology and symplectic geometry.\n\nBy Darboux's theorem, a symplectic manifold has no local structure, which suggests that their study be called topology.\n\nBy contrast, the space of symplectic structures on a manifold form a continuous moduli, which suggests that their study be called geometry.\n\nHowever, up to isotopy, the space of symplectic structures is discrete (any family of symplectic structures are isotopic).\n"}
{"id": "5266910", "url": "https://en.wikipedia.org/wiki?curid=5266910", "title": "Giri (Japanese)", "text": "Giri (Japanese)\n\nGiri may be seen in many different aspects of modern Japanese behavior:\n\n\nSome social historians believe the pervasiveness of this concept in Japanese culture is a reflection of the static feudal order that defined Japanese society for centuries. \"Giri books\", or village registers that included all the unpaid obligations of one family or individual to another, were a cultural phenomenon that could only exist in a static agricultural culture, as opposed to a migrant or hunter/gatherer tradition.\n\n\n"}
{"id": "12616", "url": "https://en.wikipedia.org/wiki?curid=12616", "title": "Gossip", "text": "Gossip\n\nGossip is idle talk or rumor, especially about the personal or private affairs of others; the act is also known as dishing or tattling.\n\nGossip has been researched in terms of its origins in evolutionary psychology, which has found gossip to be an important means for people to monitor cooperative reputations and so maintain widespread indirect reciprocity. Indirect reciprocity is a social interaction in which one actor helps another and is then benefited by a third party. Gossip has also been identified by Robin Dunbar, an evolutionary biologist, as aiding social bonding in large groups.\n\nThe word is from Old English \"godsibb\", from \"god\" and \"sibb\", the term for the godparents of one's child or the parents of one's godchild, generally very close friends. In the 16th century, the word assumed the meaning of a person, mostly a woman, one who delights in idle talk, a newsmonger, a tattler. In the early 19th century, the term was extended from the talker to the conversation of such persons. The verb \"to gossip\", meaning \"to be a gossip\", first appears in Shakespeare.\n\nThe term originates from the bedroom at the time of childbirth. Giving birth used to be a social event exclusively attended by women. The pregnant woman's female relatives and neighbours would congregate and idly converse. Over time, gossip came to mean talk of others.\n\nOthers say that gossip comes from the same root as \"gospel\" -- it is a contraction of \"good spiel\", meaning a good story.\n\nGossip can:\n\nMary Gormandy White, a human resource expert, gives the following \"signs\" for identifying workplace gossip:\nWhite suggests \"five tips ... [to] handle the situation with aplomb:\n\nPeter Vajda identifies gossip as a form of workplace violence, noting that it is \"essentially a form of attack.\" Gossip is thought by many to \"empower one person while disempowering another\" (Hafen). Accordingly, many companies have formal policies in their employee handbooks against gossip. Sometimes there is room for disagreement on exactly what constitutes unacceptable gossip, since workplace gossip may take the form of offhand remarks about someone's tendencies such as \"He always takes a long lunch,\" or \"Don’t worry, that’s just how she is.\" TLK Healthcare cites as examples of gossip, \"tattletailing to the boss without intention of furthering a solution or speaking to co-workers about something someone else has done to upset us.\" Corporate email can be a particularly dangerous method of gossip delivery, as the medium is semi-permanent and messages are easily forwarded to unintended recipients; accordingly, a Mass High Tech article advised employers to instruct employees against using company email networks for gossip. Low self-esteem and a desire to \"fit in\" are frequently cited as motivations for workplace gossip.\nThere are five essential functions that gossip has in the workplace (according to DiFonzo & Bordia):\n\nAccording to Kurkland and Pelled, workplace gossip can be very serious depending upon the amount of power that the gossiper has over the recipient, which will in turn affect how the gossip is interpreted. There are four types of power that are influenced by gossip:\n\nSome negative consequences of workplace gossip may include:\nTurner and Weed theorize that among the three main types of responders to workplace conflict are attackers who cannot keep their feelings to themselves and express their feelings by attacking whatever they can. Attackers are further divided into up-front attackers and behind-the-back attackers. Turner and Weed note that the latter \"are difficult to handle because the target person is not sure of the source of any criticism, nor even always sure that there is criticism.\"\n\nIt is possible however, that there may be illegal, unethical, or disobedient behavior happening at the workplace and this may be a case where reporting the behavior may be viewed as gossip. It is then left up to the authority in charge to fully investigate the matter and not simply look past the report and assume it to be workplace gossip.\n\nInformal networks through which communication occurs in an organization are sometimes called the grapevine. In a study done by Harcourt, Richerson, and Wattier, it was found that middle managers in several different organizations believed that gathering information from the grapevine was a much better way of learning information than through formal communication with their subordinates (Harcourt, Richerson & Wattier).\n\nSome see gossip as trivial, hurtful and socially and/or intellectually unproductive. Some people view gossip as a lighthearted way of spreading information. A feminist definition of gossip presents it as \"a way of talking between women, intimate in style, personal and domestic in scope and setting, a female cultural event which springs from and perpetuates the restrictions of the female role, but also gives the comfort of validation.\" (Jones, 1990:243)\n\nIn Early Modern England the word \"gossip\" referred to companions in childbirth, not limited to the midwife. It also became a term for women-friends generally, with no necessary derogatory connotations. (OED n. definition 2. a. \"A familiar acquaintance, friend, chum\", supported by references from 1361 to 1873). It commonly referred to an informal local sorority or social group, who could enforce socially acceptable behaviour through private censure or through public rituals, such as \"rough music\", the cucking stool and the skimmington ride.\n\nIn Thomas Harman’s \"Caveat for Common Cursitors\" 1566 a ‘walking mort’ relates how she was forced to agree to meet a man in his barn, but informed his wife. The wife arrived with her “five furious, sturdy, muffled gossips” who catch the errant husband with “his hosen about his legs” and give him a sound beating. The story clearly functions as a morality tale in which the gossips uphold the social order.\n\nIn Sir Herbert Maxwell Bart's The Chevalier of the Splendid Crest [1900] at the end of chapter three the king is noted as referring to his loyal knight \"Sir Thomas de Roos\" in kindly terms as \"my old gossip\". Whilst a historical novel of that time the reference implies a continued use of the term \"Gossip\" as childhood friend as late as 1900.\n\nJudaism considers gossip spoken without a constructive purpose (known in Hebrew as an evil tongue, \"lashon hara\") as a sin. Speaking negatively about people, even if retelling true facts, counts as sinful, as it demeans the dignity of man — both the speaker and the subject of the gossip.\nAccording to \"Proverbs\" 18:8: \"The words of a gossip are like choice morsels: they go down to a man's innermost parts.\"\n\nThe Christian perspective on gossip is typically based on modern cultural assumptions of the phenomenon, especially the assumption that generally speaking, gossip is negative speech. However, due to the complexity of the phenomenon, biblical scholars have more precisely identified the form and function of gossip, even identifying a socially positive role for the social process as it is described in the New Testament. Of course, this does not mean that there are \"not\" numerous texts in the New Testament that see gossip as dangerous negative speech.\n\nThus, for example, the Epistle to the Romans associates gossips (\"backbiters\") with a list of sins including sexual immorality and with murder:\nAccording to Matthew 18, Jesus also taught that conflict resolution among church members ought to begin with the aggrieved party attempting to resolve their dispute with the offending party alone. Only if this did not work would the process escalate to the next step, in which another church member would become involved. After that if the person at fault still would not \"hear\", the matter was to be fully investigated by the church elders, and if not resolved to be then exposed publicly.\n\nBased on texts like these portraying gossip negatively, many Christian authors generalize on the phenomenon. So, in order to gossip, writes Phil Fox Rose, we \"must harden our heart towards the 'out' person. We draw a line between ourselves and them; define them as being outside the rules of Christian charity... We create a gap between ourselves and God's Love.\" As we harden our heart towards more people and groups, he continues, \"this negativity and feeling of separateness will grow and permeate our world, and we'll find it more difficult to access God’s love in any aspect of our lives.\"\n\nThe New Testament is also in favor of group accountability (Ephesians 5:11; 1st Tim 5:20; James 5:16; Gal 6:1-2; 1 Cor 12:26), which may be associated with gossip.\n\nIslam considers backbiting the equivalent of eating the flesh of one's dead brother. According to Muslims, backbiting harms its victims without offering them any chance of defense, just as dead people cannot defend against their flesh being eaten. Muslims are expected to treat others like brothers (regardless of their beliefs, skin color, gender, or ethnic origin), deriving from Islam's concept of brotherhood amongst its believers.\n\nBahais consider backbiting to be the \"worst human quality and the most great sin...\" Therefore, even murder would be considered less reprobate than backbiting. Baha'u'llah stated, \"Backbiting quencheth the light of the heart, and extinguisheth the life of the soul.\" When someone kills another, it only affects their physical condition. However, when someone gossips, it affects one in a different manner.\n\nFrom Dunbar's evolutionary theories, gossip originated to help bond the groups that were constantly growing in size. To survive, individuals need alliances; but as these alliances grew larger, it was difficult if not impossible to physically connect with everyone. Conversation and language were able to bridge this gap. Gossip became a social interaction that helped the group gain information about other individuals without personally speaking to them. It enabled people to keep up with what was going on in their social network. It also creates a bond between the teller and the hearer, as they share information of mutual interest and spend time together. It also helps the hearer learn about another individual’s behavior and helps them have a more effective approach to their relationship. Dunbar (2004) found that 65% of conversations consist of social topics.\n\nDunbar (1994) argues that gossip is the equivalent of social grooming often observed in other primate species. Anthropological investigations indicate that gossip is a cross-cultural phenomenon, providing evidence for evolutionary accounts of gossip. There is very little evidence to suggest meaningful sex differences in the proportion of conversational time spent gossiping, and when there is a difference, women are only very slightly more likely to gossip compared with men.\nFurther support for the evolutionary significance of gossip comes from a recent study published in the peer-reviewed journal, Science. Anderson and colleagues (2011) found that faces paired with negative social information dominate visual consciousness to a greater extent than positive and neutral social information during a binocular rivalry task. Binocular rivalry occurs when two different stimuli are presented to each eye simultaneously and the two percepts compete for dominance in visual consciousness. While this occurs, an individual will consciously perceive one of the percepts while the other is suppressed. After a time, the other percept will become dominant and an individual will become aware of the second percept. Finally, the two percepts will alternate back and forth in terms of visual awareness. The study by Anderson and colleagues (2011) indicates that higher order cognitive processes, like evaluative information processing, can influence early visual processing. That only negative social information differentially affected the dominance of the faces during the task alludes to the unique importance of knowing information about an individual that should be avoided. Since the positive social information did not produce greater perceptual dominance of the matched face indicates that negative information about an individual may be more salient to our behavior than positive.\n\nGossip also gives information about social norms and guidelines for behavior. Gossip usually comments on how appropriate a behavior was, and the mere act of repeating it signifies its importance. In this sense, gossip is effective regardless of whether it is positive or negative Some theorists have proposed that gossip is actually a pro-social behavior intended to allow an individual to correct their socially prohibitive behavior without direct confrontation of the individual. By gossiping about an individual’s acts, other individuals can subtly indicate that said acts are inappropriate and allow the individual to correct their behavior (Schoeman 1994).\n\nIndividuals who are perceived to engage in gossiping regularly are seen as having less social power and being less liked. The type of gossip being exchanged also affects likeability whereby those who engage in negative gossip are less liked than those who engage in positive gossip. In a study done by Turner and colleagues (2003), having a prior relationship with a gossiper were not found to protect the gossiper from less favorable personality ratings after gossip was exchanged. In the study, two individuals were brought in to the research lab to participate. Either the two individuals were friends prior to the study or they were strangers scheduled to participate at the same time. One of the individuals was a confederate of the study and they engaged in gossiping about the research assistant after she left the room. The gossip exchanged was either positive or negative. Regardless of gossip type (positive versus negative) or relationship type (friend versus stranger) the gossipers were rated as less trustworthy after sharing the gossip.\n\nBlock writes, \"In a sense, the gossip is much \"worse\" than the blackmailer, for the blackmailer has given the blackmailed a chance to silence him. The gossip exposes the secret without warning.\" The victim of a blackmailer is thus offered choices denied to the subject of gossip, such as deciding if the exposure of his or her secret is worth the cost the blackmailer demands. Moreover, in refusing a blackmailer's offer one is in no worse a position than with the gossip. Adds Block, \"It is indeed difficult, then, to account for the vilification suffered by the blackmailer, at least compared to the gossip, who is usually dismissed with slight contempt and smugness.\"\n\n\n"}
{"id": "7215424", "url": "https://en.wikipedia.org/wiki?curid=7215424", "title": "Government speech", "text": "Government speech\n\nThe government speech doctrine, in American constitutional law, says that the government is not infringing the free speech rights of individual people when the government declines to use viewpoint neutrality in its own speech. More generally, the degree to which governments have free speech rights remains unsettled, including the degree of free speech rights that states may have under the First Amendment versus federal speech restrictions.\n\nThe government speech doctrine establishes that the government may advance its own speech without requiring viewpoint neutrality when the government itself is the speaker. Thus, when the state is the speaker, it may make content based choices. The simple principle has broad implications, and has led to contentious disputes within the Supreme Court.\n\nThe doctrine was implied in \"Wooley v. Maynard\" in 1977, when the Supreme Court acknowledged a legitimate government interest in communicating an official, ideologically partial message to the public. In the 1991 case of \"Rust v. Sullivan\", government-funded doctors in a government health program were not allowed to advise patients on obtaining abortions, and the doctors challenged this law on Free Speech grounds. However, the Court held that because the program was government-funded, the doctors were therefore speaking on behalf of the government. Therefore, the government could say what it wishes, and “the Government has not discriminated based on viewpoint; it has merely chosen to fund one activity to the exclusion of the other.\"\n\nIn \"Legal Services Corp. v. Velazquez\", the Supreme Court held that, although providing government-funded legal services appeared similar to government-funded doctors, the speech of the lawyers was private speech because lawyers spoke on behalf of their clients. As a result, the government could not prevent these attorneys from filing constitutional suits against the government.\n\nWhen one sovereign tries to limit the speech of another sovereign, the First Amendment to the United States Constitution may protect the latter from the former. David Fagundes has argued that government speech deserves constitutional protection only where the speech is intrinsic to a\npublic function and furthers democratic self-government.\n\n"}
{"id": "12250231", "url": "https://en.wikipedia.org/wiki?curid=12250231", "title": "Green Dot (symbol)", "text": "Green Dot (symbol)\n\nThe Green Dot () is the license symbol of a European network of industry-funded systems for recycling the packaging materials of consumer goods. The logo is trademark protected worldwide.\n\nThe Green Dot was a system thought up by Klaus Töpfer, Germany's environment minister in the early 1990s. The basic idea of the Green Dot is that consumers who see the logo know that the manufacturer of the product contributes to the cost of recovery and recycling. This can be with household waste collected by the authorities (e.g. in special bags - in Germany these are yellow), or in containers in public places such as car parks and outside supermarkets.\n\nThe system is financed by the green dot licence fee paid by the producers of the products. Fees vary by country and are based on the material used in packaging (e.g. paper, plastic, metal, wood, cardboard). Each country also has different fees for joining the scheme and ongoing fixed and variable fees. Fees also take into account the cost of collection, sorting and recycling methods.\n\nIn simple terms, the system encourages manufacturers to cut down on packaging as this saves them the cost of licence fees.\n\nIn 1991, the German government passed a packaging law (Verpackungsverordnung) that requires manufacturers to take care of the recycling or disposal of any packaging material they sell. As a result of this law, German industry set up a \"dual system\" of waste collection, which picks up household packaging in parallel to the existing municipal waste-collection systems. This industry-funded system is operated in Germany by the Duales System Deutschland GmbH (German for \"Dual System Germany Ltd\") corporation, or short DSD.\n\nDSD only collects packaging material from manufacturers who pay a license fee to DSD. DSD license fee payers can then add the Green Dot logo to their package labeling to indicate that this package should be placed into the separate yellow bags or yellow wheelie bins that will then be collected and emptied by DSD-operated waste collection vehicles and sorted (and where possible recycled) in DSD facilities.\n\nGerman licence fees are calculated using the weight of packs, each material type used and the volumes of product produced per.\n\nWorldwide stewardship of the Green Dot logo is managed by PRO Europe (Packaging Recovery Organisation Europe) on behalf of the various national Green dot organizations across Europe.\n\nThe design of the Green Dot symbol has obvious links with the Chinese Taijitu (yin and yang) symbol and Gary Anderson's recycling symbol. Where full-color printing is available, its official form is printed in a light and a dark shade of green (Pantone 366C and 343C). For cost reasons or to avoid a visual clash with other symbols, many manufacturers chose a black-and-white or other color combination on their packages.\n\nThe Green Dot logo merely indicates that a company has joined the Green Dot scheme, and not necessarily that the package is fully recyclable. The logo is often confused with the recycling logo.\n\nIn Malta, Green Dot Malta Limited, a waste recovery company that is licensed from Der Grune Punkt Duales System Deutschland GmbH to use the Green Dot trademark in Malta, has successfully petitioned the Maltese courts on a number of occasions to protect the mark from free-riders and from competitors seeking to obtain unfair advantage from the international reputation and goodwill that it enjoys.\n\nIn February 2009, Smart Supermarket, a well established local supermarket based in Birkirkara, Malta, was ordered by a judge not to sell, manufacture or pack products bearing the trademark Green Dot without the necessary licenses. Green Dot Malta Limited had argued in court that the supermarket was not only blatantly infringing the trademark and contravening the Trademarks Act but was also taking unfair advantage of Green Dot's reputation and goodwill without having its authorisation. The First Hall of the Civil Court, presided over by Madam Justice Abigail Lofaro, upheld Green Dot Malta Limited's request and issued a warrant of prohibitory injunction. Lawyers Antoine Naudi and Victor G. Axiak appeared for Green Dot Malta Limited. Following this injunction, the two parties reached an agreement whereby Smart Supermarket entered into a royalty license agreement with Green Dot Malta Limited and registered all its own branded food items such as confectionery and freshly packed products. they agreed to cooperate. The two companies also agreed to cooperate in ensuring that the intellectual property rights relating to the Green Dot mark in Malta will be further protected from any unlawful use by third parties including suppliers of the various goods to the supermarket.\n\nIn April 2009, following a similar request for an injunction filed by Green Dot Malta Limited, the company Zamco Caterware Limited declared in open court that it was binding itself not to circulate any products in the market with the Green Dot symbol on their packaging without the required license. The company also declared that it would not be importing any product bearing the Green Dot mark unless the relative royalty contributions have been paid and unless they prove that the imported product will be recycled in terms of applicable environmental legislation.\n\nIn September 2009, Karta Converters Limited, a company which produces and distributes articles made of paper, cardboard and plastic, was ordered by the First Hall of the Civil Court not to manufacture, pack, sell or otherwise continue circulating in the local market products bearing the trademark “Green Dot” without the necessary licenses. Presiding Judge Dr. Geoffrey Valencia accepted Green Dot Malta Limited’s assertion that the company was conducting itself as a “free-rider” in the local market and that it was taking an unjust and unfair advantage of Green Dot’s reputation without having its consent. Following this injunction, Karta Converters Limited issued a press release whereby it declared that it would be adopting the internationally recognised Green Dot symbol on its paper, carton and plastic products in accordance with the law. Karta Converters also declared that it would be joining some three hundred other companies participating in GreenPak, a waste recovery scheme operated by Green Dot Malta Limited, for the recycling of its packaging.\n\nOut of court settlements have been reached on a number of occasions with various other Maltese companies to ensure that the international reputation of the mark is safeguarded.\n\nIn May 2010, Green Dot Malta Limited won a court case against Green.Mt Ltd, a local competitor which operates another waste recovery scheme in Malta. The latter was incorporated in 2007, a few years after Green Dot Malta Limited’s registration. Green Dot Malta Limited petitioned the Court to declare that the name Green.Mt Ltd amounted to unfair competition in terms of law since the use of the “.” coupled with the words “Green Mt” was intended to cause confusion in the market.\n\nIn delivering judgment, Mr. Justice Raymond Pace stated that the two schemes were obviously direct competitors operating in the same field of activity and that the name Green.Mt Ltd was creating confusion in terms of article 32 of Chapter 13 of the Laws of Malta. The court held that the law laid down that businesses could not use any name, mark or symbol which could create confusion with another name, mark or symbol used legally by others. The imitation did not need to be perfect. It was enough that in its entirety it could deceive a consumer. The Judge said that an examination of the words used left him in no doubt that the names could and indeed were creating confusion amongst consumers. The Court thus ordered Green.Mt Ltd to pay Green Dot Malta Limited a nominal sum by way of penalty and to destroy any offending material in its possession bearing the name Green.Mt Ltd within 30 days from date of judgment. Dr. Antoine Naudi and Dr. Victor G. Axiak appeared for Green Dot Malta Limited. Before final judgment was delivered, Green.Mt Ltd changed its name to Green MT Ltd.\n\n\n"}
{"id": "28200891", "url": "https://en.wikipedia.org/wiki?curid=28200891", "title": "Greenbelt Knoll", "text": "Greenbelt Knoll\n\nGreenbelt Knoll is a residential development in the Northeast section of Philadelphia, Pennsylvania. Planned and built from 1952 to 1957, it is notable as the first planned racially integrated development in Philadelphia and among the first in the United States.\n\nThe developer, Morris Milgram, a leader of the open housing movement, required that 55 percent of the homes be sold to whites, and 45 percent to non-whites. The first house sold in 1956 for $20,000. The isolated little neighborhood included its own swimming pool, which was filled in circa 1985, leaving no trace above ground.\n\nEighteen (originally nineteen) one-story single-family homes are arranged in a heavily wooded cul de sac on Longford Street off Holme Avenue, surrounded on three sides by Pennypack Park. The simple wood-frame homes were designed in a Modernist style by the architectural firm of Montgomery & Bishop in consultation with architects Louis Kahn and Harry Duncan and landscape architect Margaret Lancaster Duncan.\n\nGreenbelt Knoll won several awards for design excellence. For example, the American Institute of Architects, \"House and Home\", \"Better Homes and Gardens\", and the National Broadcasting Corporation bestowed its Homes for Better Living award on the development. Also, Philadelphia Mayor Richardson Dilworth, an ardent advocate of exceptional planning and design, conferred a City of Philadelphia Tribute on Montgomery & Bishop; he gave the tribute \"for the design of Greenbelt Knoll Homes, which ... brought new standards of contemporary residential architecture to Philadelphia.\"\n\nThe original residents included Milgram himself; Robert N.C. Nix, Sr., the first African American to represent Pennsylvania in Congress; Pulitzer Prize–winning African-American playwright Charles Fuller, who grew up here; the Rev. Leon Sullivan, the civil rights activist, who developed the Sullivan Principles and hastened the end of apartheid in South Africa; and Fire Captain Roosevelt Barlow, a civil rights activist who was one of a group of African-American firefighters to integrate the Philadelphia Fire Department.\n\nGreenbelt Knoll was listed as a historic district on the Philadelphia Register of Historic Places in 2006 and in the National Register of Historic Places in 2010. The site is marked with a plaque placed by the Pennsylvania Historical and Museum Commission.\n\nSeventeen of the existing homes are considered contributing properties; one home was completely rebuilt following a c. 1980 fire and is considered non-contributing. An additional lot (#17) is now open space, as the house was demolished 1997. Including the 5 detached garages, a studio, and the 2-acre community park that was part of the original neighborhood design, there are 26 resources: 22 contributing buildings and 1 contributing site (park), 2 non-contributing buildings and 1 non-contributing site (Lot #17). The development remains heavily wooded, and both the houses and landscape retain integrity.\n\n"}
{"id": "12612212", "url": "https://en.wikipedia.org/wiki?curid=12612212", "title": "Historical Thesaurus of the Oxford English Dictionary", "text": "Historical Thesaurus of the Oxford English Dictionary\n\nThe Historical Thesaurus of the Oxford English Dictionary (HTOED) is the print edition of the largest thesaurus in the world, the Historical Thesaurus of English (HTE), conceived and compiled by the English Language Department of the University of Glasgow. The \"HTE\" is a complete database of all the words in the second edition of \"The Oxford English Dictionary\", arranged by semantic field and date. In this way, the \"HTE\" arranges the whole vocabulary of English, from the earliest written records in Old English to the present, alongside types and dates of use. It is the first historical thesaurus to be compiled for any of the world's languages and contains 800,000 meanings for 600,000 words, within 230,000 categories, covering more than 920,000 words and meanings. As the \"HTE\" website states, \"in addition to providing hitherto unavailable information for linguistic and textual scholars, the \"Historical Thesaurus\" online is a rich resource for students of social and cultural history, showing how concepts developed through the words that refer to them.\"\n\nThe ambitious project was announced at a 1965 meeting of the Philological Society by its originator, Michael Samuels. Work on the \"HTE\" started in 1965.\n\nOn 22 October 2009, after 44 years of work, version 1.0 was published as a two-volume set as \"HTOED\". It consists of two slipcased hardcover volumes, totaling nearly 4,000 pages. The \"HTE\", released as version 4.2 in September 2014, is freely available online from the University of Glasgow.\n\nThe work is divided into three main sections: the External World, the Mind, and Society. These are broken down into successively narrower domains. The text eventually discriminates more than 236,000 categories.\nThe second order categories are:\n"}
{"id": "55480629", "url": "https://en.wikipedia.org/wiki?curid=55480629", "title": "Josie Badger", "text": "Josie Badger\n\nJosie Badger is the Co- Director at the national RAISE Center. She is active and engaged in the Pittsburgh community in spite of her disabilities caused by \ncongenital myastenic syndrome.\n\nBadger co-founded a community service club at age 12 to train service dogs for those with disabilities. Badger earned her degree in Disability Law and Advocacy from Geneva College in 2007. She received her graduate degree in Rehabilitation Counseling from the University of Pittsburgh and later earned her doctorate in Healthcare Ethics at Duquesne University in 2014. Badger is one of eight people in the world born with a rare form of the genetic disorder muscular dystrophy.\n\nBadger worked on \"Launching Into Adulthood: An Integrated Response to Support Transition of Youth With Chronic Health Conditions and Disabilities\", a project of the Centers for Disease Control and Prevention. She co-founded the Pennsylvania Youth Leadership Network and the Children’s Hospital Advisory Network for Guidance and Empowerment, serving as president and vice-president, and also was served as president and vice president of the National Youth Leadership Network. She has been recognized as an advocate on behalf of those with disabilities.\n\nBadger is the Youth Director at The Parent Education & Advocacy Leadership Center and co-director of the national Rehabilitation Services Administration Parent Training and Information Center technical assistance center. She is the author of the TedxPittsburgh talk \"Exceptional by Choice\". She filed a suit against Preit Associates, LP for violating the Americans with Disabilities Act on January 3, 2017.\n\n"}
{"id": "7536395", "url": "https://en.wikipedia.org/wiki?curid=7536395", "title": "Langue and parole", "text": "Langue and parole\n\nLangue (French, meaning \"language\") and parole (meaning \"speaking\") are linguistic terms distinguished by Ferdinand de Saussure in his \"Course in General Linguistics\". \"Langue\" encompasses the abstract, systematic rules and conventions of a signifying system; it is independent of, and pre-exists, individual users. \"Langue\" involves the principles of language, without which no meaningful utterance, \"parole\", would be possible. \"Parole\" refers to the concrete instances of the use of \"langue\". This is the individual, personal phenomenon of language as a series of speech acts made by a linguistic subject. Saussure did not concern himself overly with \"parole\"; however, the structure of \"langue\" is revealed through the study of \"parole\". The distinction is similar to that made about language by Wilhelm von Humboldt, between \"energeia\" (active doing) and \"ergon\" (the product of that doing), as well as the distinction between \"language\" and \"speech\" made by Jan Baudouin de Courtenay. Saussure drew an analogy to chess to explain the concept of \"langue\" and \"parole\". He compared \"langue\" to the rules of chess—the norms for playing the game—and compared the moves that an individual chooses to make—the individual's preferences in playing the game—to the \"parole\".\n\nWhen translated from the French term \"langue\" can mean language. However, it is known Saussure intended the term to mean internal, arrangement and relationship of rules understood by a social group, however, rarely thought of in everyday life. \"Langue\" is believed to be a universal structure and, while it may have variations as seen in foreign languages, with principal linguistic patterns.\n\n\"Parole\" typically when it is translated means speech. Saussure, on the other hand, intended for it to mean both the written and spoken language as experienced in everyday life. It is the precise utterances and use of \"langue\". Therefore, \"parole\", unlike \"langue\", is as diverse and varied as the number of people who share a language and the number of utterances and attempts to use that language. Furthermore, \"parole\" is known to have been changed and manipulated by a number of causes for example time, social groups, and age of users.\n\nThe underlying basis to \"langue\" is the interpretation that it is made up of signs and not sentences. Signs are thought to have a two part aspect in that each sign relates a notion with a sound pattern (or a written symbol). A sign cannot exist as a single part for if there is a sound pattern without a notion the sound becomes only noise. Similarly, a notion cannot be communicated without a sound pattern.\nThe sound pattern for each notion can be extremely diverse and vice versa. For example, the notion of oneself may use the sound patterns of 'I' or 'me' while the sound pattern of 'rose' may have the notion of a flower or the past of 'rise'. The notion or sound pattern remains unchanged even if the other changes. It is by understanding the relationship of the two parts of a sign through \"langue\" that the gist of communication or \"parole\" may be understood. Without the understanding of \"langue\", \"parole\" would be meaningless sounds or symbols grouped together haphazardly.\nSaussure used the example of chess to explain how \"langue\" and \"parole\" work together. \"Langue\" is the normative rules in a chess game while parole represents the individual's choice of moves. If one were to study the parole of a chess game an understanding could be derived but it would not be a universal understanding of chess. However, by studying the langue of a chess game the derived understanding may be applicable to further chess games.\nThus Saussure argued when studying language, especially a foreign language, it is more important to understand the \"langue\" than to gain a large vocabulary of \"parole\" so that sense may be made equal to that of native speaker.\n\nSaussure did not publish his notes in relation to linguistics and \"langue\" and \"parole\". Unfortunately Cours de linguistique générale was published after his death in 1916 (later translated into English in 1959 as \"Course in General Linguistics\") and was made up of remaining lecture notes by Saussure, course notes provided to students and notes taken by former students of his lectures he performed between 1907-1911 in Geneva. This was then published by two of his former colleagues Charles Bally and Albert Sechehaye. It was after this publication that the importance and revolutionary nature of his work truly was understood by linguists and philosophers of his time.\nReviews, commentaries and critics of both the \"Course in General Linguistics\" and original notes made by Saussure have revealed much controversy over time. One controversy is that many ideas and notions often accredited to Saussure may have been borrowed from other linguists and philosophers of the nineteenth century. Saussure's idea of language as a sign system had been proposed by other philosophers, however, he will always be known to have provided a strong, theoretical basis for a scientific approach to understanding language as a whole.\n\nSaussure's \"langue\" and \"parole\" form one of the theoretical foundations of structuralism. \"Langue\" and \"parole\" have allowed structuralists to separately examine the broad structures and formations of literature as well as the individual words. Structuralists achieved this by making a distinction within literary works between the words on a page (\"parole\") and the context behind these words (\"langue\"). Although the reader may appear to simply be reading the words in a book their ability to understand (or possibly misunderstand) the text is a result of a person's knowledge of the \"langue\" or rules of a certain language. Similarly, \"langue\" and \"parole\" have been highly influential in the study of the signs, termed semiotics. Saussure's most notable influence on semiotics was his belief that the rules and codes of a language (\"langue\") are vital in interpreting and gaining an understanding of that language system, while individual utterances (\"parole\") are of little significance. \"Langue\" and \"parole\" have also impacted the way language is taught. Since Saussure's terms have become well known, language teaching often emphasizes teaching the langue and how these rules are applied, rather than simply teaching the words of a certain language. Additionally, \"langue\" and \"parole\" have been applied to other fields of study. Anthropologist Claude Levi-Strauss used Structuralism and \"langue\" and \"parole\" to understand myths and tales within a broader context. In this case parole is a single tale or myth, while langue is considered the broader range of tales and myths from within a series or group. These may be myths from the same community, time period or geographical location.\n"}
{"id": "23630747", "url": "https://en.wikipedia.org/wiki?curid=23630747", "title": "Manhattan plot", "text": "Manhattan plot\n\nA Manhattan plot is a type of scatter plot, usually used to display data with a large number of data-points - many of non-zero amplitude, and with a distribution of higher-magnitude values, for instance in genome-wide association studies (GWAS). In GWAS Manhattan plots, genomic coordinates are displayed along the X-axis, with the negative logarithm of the association \"P\"-value for each single nucleotide polymorphism (SNP) displayed on the Y-axis, meaning that each dot on the Manhattan plot signifies a SNP. Because the strongest associations have the smallest \"P\"-values (e.g., 10), their negative logarithms will be the greatest (e.g., 15).\n\nIt gains its name from the similarity of such a plot to the Manhattan skyline: a profile of skyscrapers towering above the lower level \"buildings\" which vary around a lower height.\n"}
{"id": "1984214", "url": "https://en.wikipedia.org/wiki?curid=1984214", "title": "Martian scientist", "text": "Martian scientist\n\nA Martian scientist or Martian researcher is a hypothetical Martian frequently used in thought experiments as an outside observer of conditions on Earth. The most common variety is the Martian anthropologist, but Martians researching subjects such as philosophy, linguistics and biology have also been invoked.\n\nThe following extract from an essay by Richard Dawkins is more or less typical.\n\nIn American structuralist linguistics, the Martian approach is recommended for language description:\n\nThe hypothetical Martian anthropologist is described in the writings of Noam Chomsky as one who, upon studying the world's languages, would conclude that they are all dialects of a single language embodying a \"universal grammar\" reflecting a hardwired, genetically determined linguistic module inherent in the human brain.\n\nIn philosophy, especially philosophy of language and philosophy of mind, the Martian is often invoked as an example of an intelligent being with a cognitive apparatus that differs from that of humans, e.g. the following example given by Saul Kripke:\n\nIn a common rhetorical turn, invoking the Martian scientist forces the reader to observe an obvious state of affairs that is ordinarily overlooked:\n\nExtraordinary World War II era Hungarian scientists who emigrated to the United States in the early half of the 20th century. The most prominent Martians (scientists) included Theodore von Kármán, John von Neumann, Eugene Wigner, and Edward Teller. They were referred to as \"Martians\" due to their brilliant problem solving and invention talents that seemed \"out-of-this world \".\n"}
{"id": "5499512", "url": "https://en.wikipedia.org/wiki?curid=5499512", "title": "Matching law", "text": "Matching law\n\nIn operant conditioning, the matching law is a quantitative relationship that holds between the relative rates of response and the relative rates of reinforcement in concurrent schedules of reinforcement. For example, if two response alternatives A and B are offered to an organism, the ratio of response rates to A and B equals the ratio of reinforcements yielded by each response. This law applies fairly well when non-human subjects are exposed to concurrent variable interval schedules (but see below); its applicability in other situations is less clear, depending on the assumptions made and the details of the experimental situation. The generality of applicability of the matching law is subject of current debate.\n\nThe matching law can be applied to situations involving a single response maintained by a single schedule of reinforcement if one assumes that alternative responses are always available to an organism, maintained by uncontrolled \"extraneous\" reinforcers. For example, an animal pressing a lever for food might pause for a drink of water.\n\nThe matching law was first formulated by R.J. Herrnstein (1961) following an experiment with pigeons on concurrent variable interval schedules. Pigeons were presented with two buttons in a Skinner box, each of which led to varying rates of food reward. The pigeons tended to peck the button that yielded the greater food reward more often than the other button, and the ratio of their rates to the two buttons matched the ratio of their rates of reward on the two buttons.\n\nIf \"R\" and \"R\" are the rate of responses on two schedules that yield obtained (as distinct from programmed) rates of reinforcement \"Rf\" and \"Rf\", the strict matching law holds that the relative response rate \"R\" / (\"R\" + \"R\") \"matches\", that is, equals, the relative reinforcement rate \"Rf\" / (\"Rf\" + \"Rf\"). That is,\n\nThis relationship can also be stated in terms of response and reinforcement ratios:\n\nA recent review by McDowell reveals that Herrnstein's original equation fails to accurately describe concurrent-schedule data under a substantial range of conditions.Three deviations from matching have been observed: undermatching, overmatching and bias. Undermatching means that the response proportions are less extreme than the law predicts. Undermatching can happen if subjects too often switch between the two response options, a tendency that may be strengthened by reinforcers that happen to occur just after a subject switches. A changeover delay may be used to reduce the effectiveness of such post-switch reinforcers; typically, this is a 1.5 second interval after a switch when no reinforcer is presented. Overmatching is the opposite of undermatching, and is less common. Here the subjects response proportions are more extreme than reinforcement proportions. Overmatching may occur if there is a penalty for switching. A final deviation is bias, which occurs when subjects spend more time on one alternative than the matching equation predicts. This may happen if a subject prefers a certain environment, area in a laboratory or method of responding.\n\nThese failures of the matching law have led to the development of the \"generalized matching law\", which has parameters that reflect the deviations just described. This law is a power function generalization of the strict matching (Baum, 1974), and it has been found to fit a wide variety of matching data.\n\nThis is more conveniently expressed in logarithmic form\n\nThe constants \"b\" and \"s\" are referred to as \"bias\" and \"sensitivity\" respectively. \"Bias\" reflects any tendency the subject may have to prefer one response over the other. \"Sensitivity\" reflects the degree to which the reinforcement ratio actually impacts the choice ratio. When this equation is plotted, the result is straight line; sensitivity changes the slope and bias changes the intercept of this line.\n\nThe \"generalized matching law\" accounts for high proportions of the variance in most experiments on concurrent variable interval schedules in non-humans. Values of \"b\" often depend on details of the experiment set up, but values of \"s\" are consistently found to be around 0.8, whereas the value required for strict matching would be 1.0.\n\nThere are three ideas on how humans and animals maximize reinforcement, molecular maximizing, molar maximizing and melioration.\n\nThe matching law is theoretically important for several reasons. First, it offers a simple quantification of behavior that can be applied to a number of situations. Secondly, offers a lawful account of choice. As Herrnstein (1970) expressed it, under an operant analysis, choice is nothing but behavior set into the context of other behavior. The matching law thus challenges the idea that choice is an unpredictable outcome of free will, just as B.F. Skinner and others have argued. However this challenge becomes serious only if it applies to human behavior, as well as to the behavior of pigeons and other animals. When human participants perform under concurrent schedules of reinforcement, matching has been observed in some experiments, but wide deviations from matching have been found in others. Finally, if nothing else, the matching law is important because it has generated a great deal of research that has widened our understanding of operant control.\n\nThe matching law, and the generalized matching law, have helped behavior analysts to understand some complex human behaviors, especially the behavior of children in certain conflict situations. James Snyder and colleague have found that response matching predicts the use of conflict tactics by children and parents during conflict bouts. This matching rate predicts future arrests. Even children's use of deviant talk appears to follow a matching pattern.\n\n"}
{"id": "1458526", "url": "https://en.wikipedia.org/wiki?curid=1458526", "title": "National language", "text": "National language\n\nA national language is a language (or language variant, e.g. dialect) that has some connection—de facto or de jure—with people and the territory they occupy. There is little consistency in the use of this term. One or more languages spoken as first languages in the territory of a country may be referred to informally or designated in legislation as national languages of the country. National or national languages are mentioned in over 150 world constitutions.\n\nC.M.B. Brann, with particular reference to India, suggests that there are \"four quite distinctive meanings\" for national language in a polity:\nThe last is usually given the title of official language.\n\nStandard languages, such as Standard German, Standard French, and Standard Spanish, may serve as national (language-in-common), regional, and international languages.\n\n\"National language\" and \"official language\" are best understood as two concepts or legal categories with ranges of meaning that may coincide, or may be intentionally separate. Stateless nations are not in the position to legislate an official language, but their languages may be sufficiently distinct and well-preserved to be national languages. Some languages may be recognized popularly as \"national languages,\" while others may enjoy official recognition in use or promotion.\n\nIn many African countries, some or all indigenous African languages are officially used, promoted, or expressly allowed to be promoted (usually taught in schools and written in important publications) as semi-official languages whether by long-term legislation or short-term, case-by-case executive (government) measures. \nTo be official, spoken and written languages may enjoy government or federalised use, major tax-funded promotion or at least full tolerance as to their teaching and employers' recognition in public education, standing on equal footing with the official language(s). Further, they may enjoy recognition as a language used in compulsory schooling and treasury money may be spent to teach or encourage adults in learning a language which is a minority language in a particular area to restore its understanding and spread its moral stories, rhymes, poems, phrases, songs, and other literary heritage which will promote social cohesion (where other languages remain) or will promote nationalist differentiation where another, non-indigenous language is deprecated.\n\nAlbanian is a national language in Albania and Kosovo and a regional national language for parts of Macedonia, southern Montenegro and Serbia.\n\nArabic is the national language in Algeria. Berber is also an official language. French has no official status but is widely used in education, business and the media.\n\nAndorra's national language is Catalan; moreover Catalan is an official language in several territories in Spain (Catalonia, Valencian Community, Balearic Islands), and is spoken (without official recognition or status) in territories in Spain (the Catalan-Aragonese borderlands known as La Franja and the Murcian municipality of El Carche), France (Pyrénées Orientales) and in Italy (Alghero).\n\nArmenia's national language is a separate branch in the linguistic family of Indo-European languages, Armenian. Armenian is widely spoken in Armenia as well as in its diaspora. The Armenian spoken in Armenia is known as Eastern Armenian, and this dialect is spoken as well, in the Armenian communities of Russia and Iran. While on the other hand, other Armenian communities such as the Armenian communities of Lebanon, Syria, Jerusalem etc. speak the Western Armenian dialect. |°\n\nAustralia has no official language, but is largely monolingual with English being the \"de facto\" national language. A considerable proportion of first and second generation migrants are bilingual. According to Ethnologue, 81% of people spoke English at home, including L2 speakers. Other languages spoken at home included Chinese 2.9%, Italian 1.2%, Arabic 1.1%, Greek 1%, Vietnamese 0.9% and Spanish 0.4%.\n\nThere were almost 400 languages spoken by Indigenous Australians prior to the arrival of Europeans. Only about 70 of these languages have survived and all but 30 of these are now endangered.\n\nAzerbaijani language is the national language in Azerbaijan.\n\nBengali (or Bangla) is the sole official language of Bangladesh.\n\nBosnia and Herzegovina's \"de facto\" sole national language is Serbo-Croatian. It is officially defined under the three names Bosnian, Croatian and Serbian, corresponding to the country's constituent ethnic groups. The Latin and Cyrillic alphabets both have official status.\n\nBulgarian is the national language in Bulgaria.\n\nCanada's official languages since the Official Languages Act of 1969 are English (Canadian English) and French (Canadian French). Depending on one's views of what constitutes a \"nation\", these two languages may be considered two equal national languages of the nation of Canada, or the national languages of two nations within one state, English Canada and French Canada.\n\nQuebec nationalists consider Quebec French the language of the Quebec nation.\n\nTwo of Canada's northern territories legislate a variety of Indigenous languages. Nunavut holds Inuktitut and Inuinnaqtun as official languages, and Northwest Territories has nine official languages aside from English and French: Cree, Dënesųłiné, Gwich’in, Inuinnaqtun, Inuktitut, Inuvialuktun, North and South Slavey and Tłı̨chǫ. As these official languages are legislated at a territorial (sub-federal) level, they can be construed as national languages.\n\nBesides these there many Indigenous languages of Canada which are the national languages of one or more of Canada's First Nations groups, Inuit and Métis (mixed First Nations-European peoples); a number of First Nations legislate at the Indigenous government levels their language as an official language of the Nation, such is the case with the Nisg̱a’a language in Nisg̱a’a. Notably the Cree language is spoken (with variations) from Alberta to Labrador, Anishinaabemowin is spoken across central Canada and Inuktitut is spoken across the arctic.\n\nThere are many languages spoken across China, with most people speaking one of several varieties of Chinese. During successive imperial dynasties, the spoken language of the capital city served as the official spoken language and was used across the country by government officials who traveled to communicate with one another. Dialects used for this purpose in different eras included those of Xi'an, Luoyang, Nanjing, Beijing, and other historical capital cities.\n\nAfter the Xinhai Revolution in 1911, the Kuomintang (Chinese nationalists) founded the Republic of China. In order to promote a sense of national unity and enhance the efficiency of communications within the nation, the government decided to designate a national language. The Beijing dialect of Mandarin and Guangzhou dialect of Cantonese were each proposed as the basis for a national language for China. In the beginning, there were attempts to introduce elements from other Chinese varieties into the national language in addition to those from the Beijing dialect; this was reflected in the first official dictionary of the national language, given the name 國語 (Pinyin: Guóyǔ, literally \"national language\"). But this artificial language had no native speakers and was difficult to learn, so it was abandoned in 1924. Ultimately, the Beijing dialect was chosen as the national language and it continued to be referred to as 國語 in Chinese in the Republic of China. Since then, the Beijing dialect has become the main standard for pronunciation, due to its prestigious status during the preceding Qing Dynasty.\n\nStill, elements from other dialects do exist in the standard language, which is now defined as reflecting the pronunciation of Beijing, the grammatical patterns of Mandarin dialects spoken in the northern parts of China, and the vocabulary of modern vernacular Chinese literature. The People's Republic of China renamed the national language 普通话 (Pinyin: Pǔtōnghuà, literally \"common speech\"), without otherwise changing the definition of the standard national language.\n\nAmharic is the national language in Ethiopia.\n\nFinland has two national languages: namely the Finnish language and the Swedish language. The Constitution of Finland guarantees the right to use Finnish and Swedish in courts and other state institutions. Despite the large difference in the numbers of users, Swedish is not officially classified as a minority language but equal to Finnish. Both national languages are compulsory subjects in school (except for children with a third language as mother tongue) and a language test is a prerequisite for governmental offices where a university degree is required. The constitution also grants the Sami and the Roma peoples the right to maintain and develop their languages: The Sami have partial right to use Sami languages in official situations according to other laws.\n\nFrench is the official language of France, according to Article 2 of the French Republic's constitution.\n\nThe official and national language of Germany is Standard German, with over 95% of the country speaking Standard German or German dialects as their first language.\n\nHaiti's official languages are Haitian Creole and French. While French is the language used in the media, government and education, 90–95% of the country speak Haitian Creole as the home language while French is learned in school.\n\nThere is as such no national language of India as declared by the Constitution of India. Hindi and English are used for official purposes by the union government and in the parliament. Additionally, 22 official languages are accorded official status as mentioned in article 343/1 of the Indian constitution; all these languages carry equal official status and government documents can be in any of them. States of India are free to adopt one or more local languages for official purposes of that state.\n\nThe official language of Indonesia is Indonesian. Indonesia has more than 700 living languages, making it the second most linguistically diverse country after Papua New Guinea. These 700+ languages, however, are without official status, and some are in danger of extinction. The largest local language is Javanese.\n\nPersian (or Farsi) is recognised as the national language of Iran.\n\nIrish is recognised by the Constitution of Ireland as the national language and first official language of Ireland, and the English language is recognised as a second official language.\n\nHebrew became the only official and national language of Israel with the adoption of the Nation-State Bill in 2018. Arabic, formerly also an official language, became recognized as a language with \"special status\" used in state institutions.\n\nThe Italian language is the de jure and de facto official language of Italy. Italian is also referred to as national language for historical and cultural reasons, because since the 15th century, Italian became the language used in the courts of nearly every state in Italy and in general among educated Italians (scholars, writers, poets, philosophers, scientists, composers and artists) who contributed to what is nowadays the culture of Italy. Furthermore, Italian was often an official language of the various Italian states before unification, slowly replacing Latin, even when ruled by foreign powers (such as the Spaniards in the Kingdom of Naples, or the Austrians in the Kingdom of Lombardy-Venetia).\n\nWhile English and Swahili are official languages, Swahili also has a special status as national language. None of the country's biggest languages (Gikuyu, Luo, Kamba, Kalenjin, etc.) have any explicit legal status on the national level, however the 2010 constitution enjoins the state to \"promote and protect the diversity of language of the people of Kenya.\"\n\nIn Lebanon, the Arabic language is the \"official national\" language. Modern Standard Arabic is used for official purposes, while the everyday spoken language is Lebanese Arabic. French and English are also widespread in Lebanon.\n\nLuxembourg uses three official languages: Luxembourgish, French, and German. Previously Luxembourgish had no official status, but following a constitutional revision a law was passed on February 24, 1984 making Luxembourgish the national language. Furthermore, this law recognised the three languages of Luxembourg (Luxembourgish, French and German) as administrative languages.\n\nThe Maltese language is the national language of Malta. It is also the official language of the island, together with English. Maltese only is recognised as \"national\" in Chapter 1 of the Laws of Malta.\n\nAlthough English is the only nationwide official language in Namibia, there are also 20 \"National languages\", which are each spoken by more or less sizeable portions of the population and are considered Namibia's cultural heritage. All national languages have the rights of a minority language and may even serve as a lingua franca in certain regions. Among Namibia's national languages are German, Afrikaans, Oshiwambo, Otjiherero, Portuguese, as well as the languages of the Himba, Nama, San, Kavango and Damara.\n\nNepali is the official language of Nepal. Over 123 languages are spoken in Nepal. Some of the language spoken in Nepal are Nepal bhasa, Tamang, Sherpa, Rai, Magar, Gurung, Maithili, Purbeli, English, Limbu, Mongolian, etc.\n\nWhile the population of New Zealand is predominantly English-speaking, the language of the indigenous Polynesian people is the Māori language. Both these languages have official status in the country, along with New Zealand Sign Language, which is one of the few sign languages in the world to have such status.\n\nBesides official English (Nigerian Standard English), Nigeria recognizes three 'majority', or national, languages. These are Hausa, Igbo, and Yoruba, each with some 20 million speakers or more.\n\nArticle 251(1) of the 1973 Constitution of Pakistan, titled \"National language\", specifies: \"The National language of Pakistan is Urdu, and arrangements shall be made for its being used for official and other purposes within fifteen years from the commencing day.\" Although Urdu has been declared an official language, so far all government documents, legislation, legal orders, and other official records are written in Pakistani English. Most higher education instruction is in English.\" The National Language Authority is an organization established to make arrangements to promote Urdu since 1979.\n\nThe 1973 Philippine constitution hegemonically imposed Tagalog national language at the expense of all other ethnic nationalities in the country and mandated development and formal adoption of a common national language to be known as Filipino. English (Philippine English) was also designated as an official language, \"until otherwise provided by law\".\n\nThe 1987 constitution designated the Filipino language, which is based on Tagalog with the inclusion of terms from all recognized languages of the Philippines, as the national language. It also designated both Filipino and English as the official languages for purposes of communication and instruction, and designated the regional languages as auxiliary official languages in the regions to serve as auxiliary media of instruction therein.\n\nMore than 170 languages are spoken in the Philippines and almost all of them belong to the Borneo–Philippines languages group of the Austronesian language family. In 2007, a six-part series titled \"The Case of Ilokano as a National Language\" authored by Dr. Aurelio Solver Agcaoili of the University of Hawaii appeared in the Culture, Essays, Lifestyle of Tawid News Magazine. In September 2012, La Union became the first province in Philippine history to pass an ordinance proclaiming a local language and a vernacular, Ilokano, as an official language. This move aims to protect and revitalize the use of Ilokano in various government and civil affairs within the province.\n\nThe Filipino Sign Language is designated as the \"national sign language of the Filipino deaf\" as well as the official sign language for transactions of the Philippine government.\n\nArticle 27 of the Constitution states: \"Polish shall be the official language in the Republic of Poland\".\n\nThe official and national language of Romania is the Romanian language.\n\nThe Russian language is the only official language of Russia, but 27 other languages are considered official in different regions of Russia.\n\nThe Serbian language (a variety of Serbo-Croatian) is the national language of Serbia, written in the Cyrillic script. There are 15 minority languages.\n\nSingapore has four official languages: English (Singapore English), Chinese, Malay and Tamil. Although English is the primary language of business, government, and education, Malay is designated as the national language. This is due to the geographical and historical ties to Malaysia as well as the recognition of ethnic Malays (about 14% of the population) as the indigenous people of Singapore.\n\nTraditionally, the lingua franca among the different ethnic groups in Singapore was Bazaar Malay, a Malay-based creole. Since independence, the government has been promoting English as the main language of Singapore. The bilingual education policy requires students to study two languages: English and a \"mother tongue\" corresponding to the student's ethnicity. Malay is only offered to non-Malay students as an optional third language in secondary schools. As a result, English has displaced Bazaar Malay as the common language among Singaporeans. Therefore, despite the status of Malay as the national language, the majority doesn't speak it.\n\nThe Slovene language is the national language of Slovenia. There are 6 minority languages.\n\nSouth Africa has 11 official languages, namely Afrikaans, English, Ndebele, Northern Sotho, Sotho, Swazi, Tswana, Tsonga, Venda, Xhosa and Zulu. South African Sign Language and Dutch are distinct in South Africa though incompletely emerged national standard languages which also subsumes a cluster of semi-standardised dialects.\n\nSpain has one national constitutional language, Spanish, but there are four other languages that are co-official in some territories: Galician language in Galicia, Basque in Euskadi and part of Navarre, Catalan language in Cataluña, Balearic Islands and Valencia (as Valencian), and Aranese dialect in Val d'Aran.\n\nSwitzerland has four national languages: German, French, Italian and Romansh, all of which have official status at the national level within the Federal administration of Switzerland.\n\nA majority (74%) of the population speaks German, while most of the remainder (21%) speak French, and minorities speak Italian (4%) and Romansh (1%, not monolingually). German speakers are predominant in most of the country, while French speakers occupy the western parts near the border with France, and the Italian speakers are situated to the south near the border with Italy, mostly within the Canton of Ticino. The Romansh speakers are concentrated in the Canton of Grisons in the south-east.\n\nDuring Japanese rule (1895 to 1945), the promoted the Japanese language. After their defeat in the Chinese Civil War in 1949, the Kuomintang regime of the Republic of China retreated to the island of Taiwan, where they introduced Standard Chinese, which was spoken by few of the island population at the time, as the new \"national language\".\n\nIn 2017, the Indigenous languages and Taiwanese Hakka were recognized as national languages.\n\nThe official language of the Tunisian state is Arabic. However, that language is not the mother tongue of the population or used to communicate between Tunisian people, instead Tunisian Arabic plays these roles and is the national language of Tunisia. Also, even without an official status, French is also used extensively in its written and spoken form in the administration, education and business environment and known by 63.6% of the population. Also Berber minorities in the south-west and on Djerba Island use the Tunisian Chelha language to communicate between themselves.\n\nTurkish is the national language of Turkey per the Turkish constitution.\n\nThe English language (British English) is the \"de facto\" official language of the United Kingdom and is the sole language of an estimated 95% of the British population. The three Home Nations outside England have national languages of their own with varying degrees of recognition, which coexist with the dominant English language. Britain also has several Crown dependencies and Overseas Territories which are to some extent self-governing, but which are not recognized as independent states. Many of these have their own regional languages.\n\nIn Northern Ireland, both the Gaelic Irish language and the West Germanic Ulster Scots dialects are recognized by the Good Friday Agreement as \"part of the cultural wealth of the island of Ireland\" and are promoted by the Foras na Gaeilge (Irish Institute) and Tha Boord o Ulstèr-Scotch (the Ulster-Scots Agency) respectively.\n\nIn Scotland, Scottish Gaelic is a minority language spoken by 57,375 people (1.1% of the Scottish population aged over three years old). The Gaelic Language (Scotland) Act 2005 gives the language a limited official status, and the Bòrd na Gàidhlig is tasked with \"securing the status of the Gaelic language as an official language of Scotland commanding equal respect to the English language\". Scots, generally treated as a West Germanic language related to but separate from English, has no official status but is recognized as a minority language, and is the language of much Scottish literature, including the poetry of Robert Burns.\n\nThe Welsh language has official status within Wales, and as of the 2011 census, is spoken by 562,000 people, or 19% of the population. The Welsh Language Board (Bwrdd yr Iaith Gymraeg) is legally tasked with ensuring that, \"in the conduct of public business and the administration of justice, the English and Welsh languages should be treated on a basis of equality\".\n\nEnglish is \"de facto\" the only official language. However a few words of Manx Gaelic (the historical national language) are sometimes encountered in Government institutions, largely for symbolic and ceremonial purposes, and it is the main medium of instruction in one primary school.\n\nThe national language of Uganda is English.\n\nUkrainian is the only official language of Ukraine, but Russian is also widely spoken all over the country especially in the regions to the east of Dnieper.\n\nIn the United States, English (American English) is the national language only in an informal sense, by numbers and by historical and contemporary association. The United States Constitution does not explicitly declare any official language, although the constitution is written in English, as is all federal legislation.\n\n, Representative Peter T. King introduced H.R.997, the \"English Language Unity Act of 2015\", in the United States House of Representatives. This bill would establish English as the official language of the United States. A companion bill, S.678, was introduced by Senator Jim Inhofe in the United States Senate on March 9, 2015. Both bills were referred to committee. Similar legislation has been introduced every year since 1973.\n\nIn Vietnam, the Vietnamese language had been the de facto national language for many years, but it was not until Decree No. 5 of the 2013 constitution that the Vietnamese language was officially described as the National Language.\n\n"}
{"id": "34956958", "url": "https://en.wikipedia.org/wiki?curid=34956958", "title": "New Orleans Saints bounty scandal", "text": "New Orleans Saints bounty scandal\n\nThe New Orleans Saints bounty scandal, widely dubbed \"Bountygate,\" was an incident in which members of the New Orleans Saints team of the National Football League (NFL) were found guilty of paying out bonuses, or \"bounties\", for injuring opposing team players. The pool was alleged to have been in operation from 2009 (the year in which the Saints won Super Bowl XLIV) to 2011.\n\nLeague commissioner Roger Goodell responded with some of the most severe sanctions in the league's 92-year history, and among the most severe punishments for in-game misconduct in North American professional sports history. Defensive coordinator Gregg Williams was suspended indefinitely, though this would be overturned the following year. Head coach Sean Payton was suspended for the entire 2012 season—the first time since Chuck Fairbanks in 1978 that a head coach had been suspended. General manager Mickey Loomis was suspended for the first eight games of the 2012 season. Assistant head coach Joe Vitt was suspended for the first six games of the 2012 season. The Saints organization was penalized with a $500,000 fine and forced to forfeit their second-round draft selections in 2012 and 2013. In May 2012, four current and former Saints players were suspended after being named as ringleaders in the scandal, with linebacker Jonathan Vilma also being suspended for the entire 2012 season. However, former commissioner Paul Tagliabue overturned all sanctions against the players in December 2012 after finding that despite the players being \"very much involved\", the coaches and the Saints organization were primarily responsible for the scandal.\n\nThe NFL has long frowned upon bounties, or \"non-contract bonuses\" as it officially calls them; but an underground culture of bounties is alleged to exist, with teams, it is claimed, turning a blind eye to the practice. The league constitution specifically forbids payment of bonuses based on performances against an individual player or team, as well as bonuses for on-field misconduct; the NFL holds that such practices undermine the integrity of the game, and also would allow teams to use such payments to circumvent the salary cap. The collective bargaining agreement with the NFL Players Association also forbids this practice, as does the standard NFL player contract. Every year, the NFL sends a memo reiterating this ban to every team before training camp opens. However, according to many former players, bounty systems of some sort have been around the NFL for decades, with the percentage of players participating non-scientifically estimated to be between 30 and 40 percent. According to these players, such bounty programs were usually informal and often between players only, more with intent at locker-room braggadocio than systemic malice. What would draw attention to the Saints' bounty program was the alleged practice of methodically organizing such a concept at the coaches' level, with the primary intent to systematically and routinely injure opposing star players.\n\nAfter the Saints defeated the Minnesota Vikings in the , several Vikings players and coaches claimed that the Saints were deliberately trying to hurt Vikings quarterback Brett Favre. The Vikings were particularly angered when Saints defensive end Bobby McCray and defensive tackle Remi Ayodele knocked Favre to the ground with a high-low hit. McCray hit Favre below the knees, briefly knocking Favre out of the game with an ankle injury. No penalty was called on the play, though NFL vice president of officiating Mike Pereira said one should have been called, saying it was \"the type of hit we don't want.\" Vikings coach Brad Childress later said that there were at least 13 instances where he felt the Saints deliberately went after Favre. Later, CBSSports.com NFL columnist Clark Judge said several Vikings assistants told him they believed McCray was acting on direct orders from Williams, with at least one being so outraged that he threatened to \"punch [Williams] in the face\" the next time they met. Vikings owner Zygi Wilf even went as far as to complain to the league about what happened to Favre, though no action was taken at the time. Favre took such a severe beating that Vikings punter Chris Kluwe and placekicker Ryan Longwell wondered during the game if someone had put a bounty on him.\n\nFavre's agent, Bus Cook, later said that he also felt the Saints were deliberately trying to knock Favre out of the game, and claimed that several hits on Arizona Cardinals quarterback Kurt Warner in the divisional round a week earlier crossed the line as well. It initially appeared that Cook's argument was strengthened by the fact that Warner was knocked out of that game with a chest injury (although he later returned), and retired two weeks later. However, Warner later said that the hit which knocked him out was legal, and had nothing to do with his decision to retire.\n\nIn the 2010 offseason, an anonymous player told NFL officials that the Saints had targeted Favre and Warner as part of a bounty program administered by Williams; the NFL's security department found the allegations credible enough to open an investigation. However, the players and team officials interviewed all denied that any bounty program existed, and the player who made the initial report subsequently recanted his allegations.\n\nThe NFL began investigating the Saints in 2010 in response to allegations of deliberate attempts to injure players during the 2009–10 playoffs, but the investigation stalled until late in the 2011 season. On March 2, 2012, the NFL announced that it had evidence that defensive coordinator Gregg Williams had created the program soon after his arrival in 2009, and alleged that \"between 22 and 27 Saints players\" were involved. Williams and the players pooled their own money to pay out performance bonuses. It also asserted that head coach Sean Payton tried to cover up the scheme, and that he and general manager Mickey Loomis failed to shut it down when ordered to do so by team owner Tom Benson. Since then, Williams has been accused of operating similar schemes during his tenure as defensive coordinator of the Tennessee Oilers/Titans and Washington Redskins and as head coach of the Buffalo Bills; the NFL briefly investigated these allegations but elected to focus on the Saints.\n\nIn 2012, ESPN reported that former New Orleans Saints defensive assistant Mike Cerullo contacted the NFL regarding a bounty program after the 2009 postseason. Cerullo was released after the 2009 postseason for poor performance and lying about personal leave according to the New Orleans Saints. Cerullo testified that he kept track of payments and pledges made. Cerullo also states in the article, \"I was angry for being let go from the Saints\". In the summer of 2017, the NFL hired Mike Cerullo as Director of Football Administration. \n\nLate in the 2011 season, the NFL received what it called \"significant and credible new information\" that suggested there was indeed a \"bounty\" program in place. League officials, convinced that this information was irrefutable evidence a program was indeed in place, alerted Benson of their findings just before the Saints' first-round playoff game against the Detroit Lions. The investigation continued during the 2011–12 playoffs and continued through the 2012 offseason.\n\nOn March 2, 2012, ESPN's Adam Schefter reported that the NFL had indeed found evidence of a bounty program. Later that day, the NFL announced it had obtained irrefutable proof of a bounty pool dating back to the 2009 season, based on a review of 18,000 documents. It determined that Williams had initiated the fund soon after he arrived in New Orleans in 2009, in hopes of making the defense more aggressive. Between 22 and 27 Saints defensive players were involved. The players and Williams contributed their own cash to the pot, and received cash payments based on their performance in the previous week's game. For instance, a special teamer who downed a kick returner inside the receiving team's 20-yard-line earned $100. Players could also be fined for mental mistakes and penalties. Players also received \"bounties\" for \"cart-offs\" (plays in which an opponent was removed from the field on a stretcher or cart) and \"knockouts\" (plays that resulted in a player being unable to return for the rest of the game). Players usually earned $1,000 for \"cart-offs\" and $1,500 for \"knockouts\" during the regular season, though they were encouraged to put their winnings back into the pot in order to raise the stakes as the season went on. Payments were known to double or even triple during the playoffs.\n\nThe NFL sent a confidential and detailed memo to all 32 teams detailing its findings. It revealed that the Saints had not only targeted Warner and Favre during the 2009 playoffs, but had also targeted Green Bay Packers quarterback Aaron Rodgers and Carolina Panthers quarterback Cam Newton during the 2011 regular season. According to that memo, Saints linebacker Jonathan Vilma offered $10,000 cash to any teammate who knocked Favre out of the NFC Championship Game. Another source told CBSSports.com's Mike Freeman that Reggie Bush's agent at the time, Michael Ornstein, was closely involved in the scheme from the beginning. Ornstein contributed $10,000 to the pot in 2009, and an undisclosed amount in 2011.\n\nAfter later investigations in the 2012 offseason, the NFL also found evidence that the Saints put a bounty on then-Seattle Seahawks quarterback, Matt Hasselbeck during their 2011 wild-card playoffs game.\n\nThe league found that Payton not only knew about the scheme, but tried to cover it up during both league investigations. During the 2010 investigation, Payton told Williams and Vitt to \"make sure our ducks are in a row\" when the league interviewed them. Before the start of the 2011 season, Payton received an email from Ornstein detailing the broader lines of the scheme. In that same email, Ornstein offered $5,000 to anyone who knocked Rodgers out of the 2011 season opener. Payton initially denied knowing that this email existed, but subsequently admitted that in fact he had read it.\n\nWhen Benson was informed of the league's findings, he called in Payton and Loomis and ordered the program shut down immediately. However, they did not do so. Loomis had been interviewed during the 2010 investigation as well, and had stated that he knew of no such scheme and would stop it immediately if it was taking place. The league also found that Vitt, whom Payton had assigned to monitor Williams (the two reportedly didn't get along very well), also knew about the broader lines of the scheme and even witnessed Williams handing out payments to players. However, Vitt failed to tell anyone about it.\n\nThe NFL found that Payton and Loomis' misfeasance amounted to \"conduct detrimental\" to the league. The NFL found no club money had been used to fund the bounty pool, and praised Benson for doing what he could to shut down the slush fund. Nonetheless, it found the Saints organization as a whole guilty of conduct detrimental to the league as well due to Williams and the players' maintenance of the bounty pool, as well as Loomis and Payton's failure to act \"in a responsible manner\" to stop it.\n\nSeveral Chicago Bears players and fans believe that the Bears were targets of this program during the second game of the 2011 season, a 30–13 loss to the Saints. Quarterback Jay Cutler was sacked six times, and nearly lost his voice when a Saints player kicked him in the throat. Later in the game, offensive tackle Frank Omiyale yanked a Saints defender off Cutler when he saw what he later called \"some dirty stuff.\" Tampa Bay Buccaneers quarterback Josh Freeman reported that the Saints' tendency toward illegal hits was common knowledge among the Tampa Bay coaching staff. Preparations for Saints games included warnings to offensive players to keep their knees protected, especially on plays near the sidelines.\n\nIn June 2012, the league revealed that it possessed a ledger detailing the weekly earnings of the players, which are earned for cart-offs ($1000) and \"whacks\" ($400) and deducted for \"mental errors\".\n\nHowever, on July 26, 2012, Vilma and seven witnesses from the Saints testified in front of a federal judge in New Orleans that NFL commissioner Roger Goodell got his facts wrong in the bounty scandal.\"Everybody was sworn in under oath in front of a judge with the risk of perjury and jail time if we were lying, and categorically denied there was a bounty,\" Vilma said in a text message to ESPN's Ed Werder. \"Seven people testified, 2 sworn affidavits (one by Drew Brees) all saying the same thing. I ask that you and ESPN report the facts. No more bias or b.s. or hearsay. I gave you facts that you can report if so choose.\" Tulane University Sports Law Program Director Gabe Feldman (who attended the hearing in court) said, \"Clearly the judge, by her questions, indicated she thinks Goodell overstepped his authority, and this case was always going to be about if he executed his power fairly... The NFL's retort is that with all due deference, you don't get to second guess (commissioner Roger Goodell). Judges only have limited jurisdiction over arbitration issues.\"\n\nSaints All-Pro quarterback Drew Brees made a somewhat controversial tweet on June 20, 2012 stating, \"If NFL fans were told there were \"weapons of mass destruction\" enough times, they'd believe it. But what happens when you don't find any????\" Brees immediately issued another statement to clarify, \"My WMD comment has nothing to do with politics or our brave military. Merely an analogy to show how media influences public perception.\" He went on to say, \"I apologize if the WMD comment offended anyone. Especially our military. There is no one I respect more than our service men and women.\"\n\nShortly after the Saints' bounty system came to light, four former Washington Redskins players, as well as a coach, told \"The Washington Post\" that Williams operated a similar system while he was the Redskins' defensive coordinator from 2004 to 2007. The players said that Williams paid his crew thousands of dollars for aggressive play, with the biggest payouts—as much as $8,000—coming for \"kill shots\" that knocked opposing players out of games. \"Chicago Tribune\" NFL analyst Matt Bowen, who played for the Redskins at the time, later wrote in one of his regular columns that the bounty pool was funded by fines for mistakes made during practice and in games, and insisted similar systems operated on other teams. On March 4, \"The Post\" reported that the NFL was investigating the allegations against Williams with the Redskins.\n\nSeveral former Bills players subsequently told \"The Buffalo News\" of a similar system during Williams' tenure as Bills' head coach from 2001 to 2003. However, they didn't agree on whether there were rewards for intentionally injuring players. Coy Wire, a safety during Williams' tenure, said that Williams gave bonuses for hits that left opponents seriously injured, and two other players said that bonuses were also awarded for \"knockouts.\" However, linebacker Eddie Robinson, who played for Williams in Houston and Tennessee as well as in Buffalo, acknowledged an incentive pool but said he never heard Williams favor deliberately injuring other players. Ruben Brown, a guard for the Bills during Williams's time as coach there, denied there was any sort of bounty system in place in Buffalo, a position reiterated by linebacker London Fletcher and then-general manager Tom Donahoe. Chidi Ahanotu, who played one year under Williams in Buffalo, indicated that such a program was not within his character at the time and that Williams was \"the softest coach I've been around.\"\n\nFormer NFL coach Tony Dungy later told Profootballtalk.com he was certain that Williams operated a similar bounty system while he was defensive coordinator of the Oilers/Titans from 1997 to 2000. He also believes that Williams put a bounty on Indianapolis Colts quarterback Peyton Manning during Super Bowl XLIV, and targeted Manning on several occasions while with the Titans. The revelation of the bounty system also caused renewed speculation about a 2006 game between the Redskins and Colts, in which Manning was knocked down by a high-low hit from the Redskins' Phillip Daniels and Andre Carter and appeared to lose some feeling in his neck. While Dungy didn't speculate at the time about whether the Redskins targeted Manning on that play, he believes that hit ultimately caused the neck problems that sidelined Manning for the entire 2011 season and led to his departure for the Denver Broncos afterward.\n\nFormer safety Ryan Clark, who played under Williams in Washington from 2004–2005 and himself was fined by the NFL $40,000 for a helmet-to-helmet hit against Baltimore Ravens tight end Ed Dickson during the 2011 season, defended Williams, saying that he never ran a bounty program with the Redskins and has yet to see one during his time in the NFL. Clark added that he would've reported Williams or any coach that offered to run such a program. The Steelers released a statement on their official web site mentioning that the team does not condone any sort of bounty program.\n\nWilliams, who left after the season to become defensive coordinator of the St. Louis Rams, was summoned to NFL headquarters after the investigation concluded in mid-February. He initially denied any involvement, but recanted and admitted everything in a meeting with Goodell. After the story broke, Williams issued a statement calling his involvement \"a terrible mistake.\" Williams said that he knew all along the slush fund broke the rules, and that \"I should have stopped it\" rather than get further involved. Goodell said in a statement that he found it \"particularly disturbing\" that the Saints were deliberately trying to injure other players. He said that players and coaches involved in the scheme could face fines or suspensions, and the Saints could be docked picks in the 2012 NFL Draft and future drafts.\n\nBenson issued a statement on the Saints' Website saying, \"I have been made aware of the NFL’s findings relative to the “Bounty Rule” and how it relates to our club. I have offered and the NFL has received our full cooperation in their investigation. While the findings may be troubling, we look forward to putting this behind us and winning more championships in the future for our fans.\"\n\nOn March 3, Fox Sports' Jay Glazer reported that the NFL intended to hand down penalties before the owners' meeting in late March. The NFLPA asked the league to delay any sanctions until the union could conduct its own investigation.\n\nCBSSports.com's Pat Kirwan tweeted that within hours of the NFL releasing its report, lawyers for several players were already telling him that their clients were considering legal action against the Saints and Williams. Former San Francisco 49ers quarterback Steve Young, who has a law degree from BYU, suggested that anyone who had been injured during a Saints game during the scheme's existence has grounds for a lawsuit. Louisiana State University law professor William Corbett told Fox Sports that any legal action by players has a chance of succeeding. He cited a 1977 case in which Denver Broncos defensive back Dale Hackbart sued the Cincinnati Bengals for a late hit to the back by running back Boobie Clark that fractured three vertebrae four years earlier and ended his career. A Colorado court ruled against Hackbart, saying violence was part of the game. However, the 10th Circuit Court of Appeals disagreed, saying that \"the general customs of football\" do not include deliberately attempting to injure opposing players.\n\nOn March 6, Payton and Loomis issued a statement taking \"full responsibility\" for not stopping the alleged \"bounty\" program. Payton and Loomis also apologized to Benson and the Saints fans, and promised that such behavior would never happen again. Three days later, Drew Brees, the starting quarterback for the Saints, issued a statement denying any knowledge of or involvement in the program. On March 12, WWL-TV in New Orleans reported that Payton and Benson met with Goodell in New York for much of the morning to reiterate that the Saints would continue to cooperate fully with the NFL's investigation. On March 22, U.S. Senator Richard Durbin of Illinois announced he would invite Goodell and the heads of the other major American sports leagues to a hearing on bounty systems. He also said that unless the leagues themselves \"come up with standards to make sure this isn't going to happen again,\" he may consider drafting legislation that would extend federal sports bribery laws to cover bounties.\n\nOn April 5, documentary filmmaker Sean Pamphilon released audio of a meeting Williams held with his defense before their 2012 divisional playoff game against the San Francisco 49ers. In a profanity-laced speech, Williams instructed his players to deliberately try to injure several 49ers players. He ordered his men to try to knock out running back Kendall Hunter, even if it meant hitting him out of bounds. He specifically directed them to try to tear wide receiver Michael Crabtree's ACL, injure tight end Vernon Davis' ankles and go after kick returner Kyle Williams specifically because he had a history of concussions. He also appeared to put a bounty on quarterback Alex Smith; according to Pamphilon, after Williams told his men to hit Smith in the chin, \"then he rubs his thumb against his index and middle fingers – the cash sign – and says, \"I got the first one. I got the first one. Go get it. Go lay that motherfucker out.\"\" Pamphilon, who was doing a documentary on Steve Gleason and his fight against Lou Gehrig's Disease, released the audio to Yahoo! Sports without Gleason's approval. However, the Saints were not penalized for illegal hits during that game, which they lost 36–32.\n\nOn March 21, 2012, the NFL issued sanctions to Saints coaches and front-office personnel for their roles in the scandal.\n\nThe Saints were also fined $500,000—the maximum fine permitted under the league constitution, and had to forfeit their second-round draft picks in 2012 and 2013 (their first-round pick in 2012 had already been traded to the New England Patriots, and therefore, could not be forfeited; after the penalty; the Saints' first pick in the 2012 NFL Draft is a third-rounder) He also gave the league's clubs until March 30, 2012 to certify in writing that they do not have bounty programs. Clubs will also be required to certify that no bounty systems exist as part of the yearly certifications they must make under the league's Integrity of the Game Policy.\n\nIn a statement, Goodell said that the NFL would not tolerate \"conduct or a culture\" that put player safety at risk. He also said that the fact that the scheme went on for three years demanded that \"a strong and lasting message must be sent that such conduct is totally unacceptable and has no place in the game.\" He was particularly upset that those involved had lied about the scheme on two separate investigations, and had denied that there was ever a bounty program in place. In an interview with NFL Network's Rich Eisen, Goodell said that the threat to player safety, as well as the fact the Saints lied about it, demanded significant punishment. \"I don't think you can be too hard on people that put at risk our players' health and safety,\" Goodell told Eisen. He reiterated this in an interview later that day with ESPN's Schefter, saying that the fact those involved \"continued to mislead\" the league about it was a significant factor in the sanctions. \"You have to be accountable and responsible in the NFL,\" Goodell said. Goodell also implied that Payton would have faced significant punishment in any event, since his contractual obligation to supervise his assistants meant that he at least should have known about the scheme. He also said that there would be zero tolerance for payments for in-game performance in the future, saying that payments for good play eventually escalate to bounties for deliberately injuring players. Later, Schefter said on ESPN's SportsCenter that league officials felt Payton was at least as guilty as Williams, despite initial focus on Williams' role as the mastermind in the scheme.\n\nOn March 30, Payton, Vitt and Loomis appealed their suspensions, and the Saints also appealed the fine and loss of draft picks. Payton, Vitt and Loomis met with Goodell on April 5. After that meeting, Vitt's lawyer, David Cornwell, said that Payton and Loomis met with Williams before the divisional playoff game and ordered him to shut down the bounty program immediately. Cornwell contended that Williams was a \"rogue coach,\" and the recently released audio of his meeting with the defense only proved it.\n\nGoodell denied the appeals on April 9, meaning that Payton's suspension began as of April 16. However, depending on the Saints' cooperation and that of the individuals involved, Goodell could restore the Saints' second-round pick in 2013 (though the Saints would still lose a lower-round pick), as well as reduce the fine on the Saints and restore Payton, Vitt and Loomis' lost pay. However, all appeals were denied\n\nThe NFLPA requested that the league should hold off on any punishments for the players until it conducts its own investigation. Goodell told Schefter, however, that he would hand down punishments to the players involved very soon once he gets feedback from the NFLPA.\n\nHours after the sanctions were announced, Kluwe went on KSTP in the Twin Cities and demanded that any players involved in the scheme be severely punished, and that the NFLPA let it be known that \"there's no place in the league for that kind of behavior.\" He even went as far as to call for Vilma—the only player specifically named as being involved in the scheme in the NFL's initial announcements—to be banned from the league for life. His sentiments were echoed a day later by Vikings center John Sullivan, who told KFXN-FM in the Twin Cities that any Saint who deliberately tried to hurt Favre in that game should get a lifetime ban. Sullivan called the Saints' treatment of Favre \"despicable\" and \"the exact opposite of sportsmanship,\" and even called for the league to take some sort of action against players involved in that game who had since retired, such as McCray.\n\nOn May 2, 2012, the NFL suspended four then-current or former Saints players for their involvement in the bounty scandal:\n\nVilma's suspension took effect immediately, while the other three players are allowed to attend training camp. In announcing the suspensions, Goodell said that while a large number of players took part in the program, he chose to suspend those players who \"were in leadership positions at the Saints; contributed a particularly large sum of money toward the program; specifically contributed to a bounty on an opposing player; demonstrated a clear intent to participate in a program that potentially injured opposing players; sought rewards for doing so; and/or obstructed the 2010 investigation.\" The NFL determined that Vilma and Smith helped Williams start the bounty program. Hargrove lied to league officials during the 2010 investigation, but later signed a letter to the NFL admitting that he was active participant in the scheme. He also told at least one other player that the Saints had put a bounty on Favre in the 2009 NFC title game. Fujita, who left the team for the Browns immediately after the Saints won Super Bowl XLIV, pledged \"a significant amount of money\" into the bounty program.\n\nEarlier, Goodell had indicated that he was going to come down hard on the players involved, telling Eisen that they \"enthusiastically embraced\" the scheme. \"They are on the field, so so I don't think they are absolved from any responsibility because of that,\" he said.\n\nThe NFLPA released a statement calling the suspensions unjustified, claiming that Goodell had not furnished them with any evidence supporting the sanctions. The union lodged a formal grievance on May 4, contending that since the suspensions were for on-field misconduct, the players' appeals should be heard by Ted Cottrell and Art Shell, whom the collective bargaining agreement designates as the hearing officers for on-field sanctions. It also contended that since the alleged conduct took place before the most recent CBA was signed in August, Goodell should have deferred to NFL special master Stephen Burbank in ruling on the players' actions. Goodell issued the suspensions as part of his power to sanction any \"conduct detrimental to the integrity and public confidence in the NFL,\" a violation of Article 46 of the CBA. This provision is normally used to sanction off-field conduct. However, a league source told CBSSports.com's Judge that it also gives Goodell the power to rule on in-game conduct if he feels that it runs counter to the integrity of the game.\n\nOn July 26, 2012, Jonathan Vilma and seven witnesses from the Saints testified in front of a federal judge in New Orleans that Goodell got his facts wrong in the bounty scandal. \"Everybody was sworn in under oath in front of a judge with the risk of perjury and jail time if we were lying, and categorically denied there was a bounty,\" Vilma said in a text message to ESPN's Ed Werder. \"Seven people testified, 2 sworn affidavits (one by Drew Brees) all saying the same thing. I ask that you and ESPN report the facts. No more bias or b.s. or hearsay. I gave you facts that you can report if so choose.\" Tulane University Sports Law Program Director Gabe Feldman (who attended the hearing in court) said, \"Clearly the judge, by her questions, indicated she thinks Goodell overstepped his authority, and this case was always going to be about if he executed his power fairly... The NFL's retort is that with all due deference, you don't get to second guess (commissioner Roger Goodell). Judges only have limited jurisdiction over arbitration issues.\"\n\nAll four players appealed their suspensions. On September 7, 2012, the Burbank appeals panel vacated the suspensions imposed on the four, and the NFL confirmed that the ruling reinstated them in time for their first games of the 2012 season two days later. Two days after the fifth game of the season, on October 9, 2012, the league re-issued the suspensions without any changes or reductions; the players' appeals continued.\n\nOn October 27, 2012, former league commissioner Paul Tagliabue postponed the bounty appeals hearing, expecting to set a new schedule on October 29, 2012. On December 11, with three games left in the regular season, Tagliabue vacated the players' suspensions, saying in his ruling, \"I affirm Commissioner Goodell's factual findings as to the four players. I conclude that Hargrove, Smith and Vilma—but not Fujita—engaged in 'conduct detrimental to the integrity of, and public confidence in, the game of professional football ...\" He laid primary responsibility for the scandal on Williams and Payton.\n\nHad the suspensions of Vilma and Hargrove been upheld, they would have been the longest for an on-field incident in modern NFL history, topping the previous record set in 2006, when then-Titans defensive end Albert Haynesworth was given a five-game suspension for stomping on the head of Dallas Cowboys offensive lineman Andre Gurode.\n\nVilma played the final 11 games of the 2012 season for the Saints; Smith played all 16. Fujita played the first four games of the season for the Browns before suffering a season-ending (and ultimately, career-ending) neck injury; he would sign a ceremonial one-day contract with the Saints in the offseason and retire with the team. Hargrove, signed as a free agent by the Green Bay Packers in March 2012, did not play during the 2012 season. Nonetheless, the loss of Payton, combined with the distractions caused by the scandal, proved too much for the Saints to overcome. After finishing 13–3 and reaching the Divisional round of the playoffs a year earlier, they finished 7–9 and missed the playoffs.\n\nThe behavior detailed in the report was almost universally condemned in the press. In an editorial, New Orleans' local paper \"The Times-Picayune\" called the revelations \"an embarrassment for one of the most successful and beloved sports organizations of recent years,\" and that they were \"particularly hard to take for (Saints') fans\" in light of the Saints' rebound after Hurricane Katrina. ESPN columnist Gregg Easterbrook claimed that the Saints' behavior threatened the very integrity of the sport since high school and youth players have long emulated what they see in the NFL. He also claimed that NFL Network yanked its planned replay of the 2009 NFC Championship Game due to concern that fans might look more closely for late hits that should have been called.\n\nMost of the players who were the targets of questionable hits by the Saints, including Favre and Warner, claimed the bounties were merely part of the game. However, several former players interviewed by \"Sports Illustrated\" said that while payments for good hits and sacks were indeed considered part of the game, bounties for intentionally injuring opponents violated an unwritten code. One of those interviewed, Junior Seau, bluntly said that such practices crossed the line into threatening a person's livelihood. (Seau would commit suicide less than two months after the interview was published; it was discovered after his death that he suffered from chronic traumatic encephalopathy (CTE) as a result of the numerous head injuries Seau suffered during his 20-year NFL career.) Seau's sentiments were echoed by Hall of Fame quarterback Fran Tarkenton. In an op-ed for \"The Wall Street Journal\", Tarkenton wrote that he played against the likes of Mean Joe Greene, Ray Nitschke and Dick Butkus, and none of them even considered deliberately trying to hurt him. He also said that he discussed the issue with several players from his era, and they unanimously agreed that players who put bounties on opponents were \"cowards.\"\n\nKevin Seifert, who blogs on the NFC North for ESPN.com, wrote that neither he nor most Vikings fans were surprised at the discovery of the bounty program. Seifert argued that even before the findings were revealed, it was obvious that the Saints were determined to inflict a severe beating on Favre, even if it meant breaking the rules. The only difference in Seifert's mind was that he no longer believed the Saints were out of control. Rather, he wrote, they were acting as \"part of a larger mentality\" instilled by Williams.\n\nSpeculation quickly abounded about how severely Goodell, who has made player safety and the overall integrity of the game a point of emphasis during his six years as commissioner, would punish Williams and the Saints. In his weekly \"Monday Morning Quarterback\" column on March 5, \"SI\"s Peter King wrote that he believed Williams faced at least an eight-game suspension, and that Payton and Loomis would almost certainly be suspended as well. He also argued that Goodell would have no choice but to come down hard on the Saints, given that the league was facing numerous lawsuits brought by former players who suffered head injuries. Given the circumstances, King said, Goodell had a lot of incentive to \"issue a string of suspensions the likes of which the league has never seen.\" In an article written for the March 12 edition of \"SI\", King wrote that league officials were so outraged that they were likely to hand down penalties similar to the season-long bans Paul Hornung and Alex Karras received in 1963 for gambling. Freeman wrote that his sources in the league office had told him that the players, Williams, Payton and Loomis would all face suspensions of at least six games, as well as heavy fines. Freeman's sources also said that Payton's sanctions were likely to dwarf those handed down to the New England Patriots' Bill Belichick in the wake of the 2007 \"Spygate\" affair. He also believed that Goodell was going to use the scandal to \"end the practice of bounty football forever,\" much like the penalties imposed against the Patriots after \"Spygate\" effectively ended the longstanding practice of illicit videotaping.\n\nAfter the sanctions were announced, CBSSports.com's Gregg Doyel wrote that the severity of the punishments handed down to Williams, Payton and Loomis proved that Goodell was truly sincere in his desire to \"take the thuggishness out of the NFL.\" Doyel also said that while many players had chafed at what they saw as Goodell's heavy-handed approach to discipline, he was actually standing up for their safety in the Saints' case. Pereira, now an analyst for Fox Sports, wrote that based on his experience in the league office, he wasn't surprised that Goodell came down hard on the Saints. He recalled that Goodell was always upset when officials didn't penalize hits on defenseless players.\n\nThe revelation of Williams' pregame speech was also greeted with revulsion. ESPN NFL analyst and former Dallas Cowboys safety Darren Woodson said that much of Williams' speech was standard pregame rhetoric. According to Woodson, when Williams called for his men to \"attack the head\" of running back Frank Gore, he was saying that the 49ers' offense would be rendered ineffective if they managed to shut Gore down. However, Woodson felt that several parts of Williams' speech—particularly his calls to go after Crabtree's ACL and target Williams specifically because he had concussions in the past—went too far. His former teammate, NFL Network analyst Michael Irvin, said that he \"almost threw up\" when he heard Williams tell his men to go after Crabtree's ACL, saying that players are taught from youth football onward to \"never take out a man's knees.\" Fox Sports' Mark Kriegel argued that the tape proved Williams was \"woefully underpunished,\" especially since he made the speech after being alerted that the NFL had reopened its investigation. He called for Goodell to ban him from the league for life.\n\nNFL Network analyst Michael Lombardi wrote that the scandal happened in part because during Williams' previous stops as a defensive coordinator, the head coaches under which he worked—Fisher, Joe Gibbs and Payton—essentially ceded him complete authority over the defense. Lombardi claimed that as a result, Williams operated essentially as \"an independent contractor.\" Lombardi argued that such a situation is \"never fully sustainable,\" as it can easily lead to the head coach losing control.\n\nDespite the media outcry, an independent study speculated that Saints' players may have pretended to participate off the field but not put the tactics into action on the field. \"If the Saints tended to injure more players, then teams that played them would tend to list more injuries the following week. To test whether the Saints injured more players than a typical team, one need only compare the number of players added to injury reports after a Saints game to the league-wide average. Did the New Orleans Saints injure more players? The data-driven answer is a resounding 'no.' The Saints appear to have injured far fewer players over the 2009, 2010 and 2011 seasons. The numbers are striking.\"\n\n"}
{"id": "21904715", "url": "https://en.wikipedia.org/wiki?curid=21904715", "title": "Niele Toroni", "text": "Niele Toroni\n\nNiele Toroni (born March 15, 1937 in Muralto) is a Swiss painter. He lives and works in Paris.\n\nIn 1966 Toroni started a practice he calls \"Travail-Peinture\". Toroni's method, brushstrokes made with imprints of a no. 50 paintbrush repeated at perpendicular 30 centimeter intervals, was first shown at a debut in 1967 in Paris at an exhibition-performance at the Salon de la Jeune Peinture in the Musèe d'Art Moderne de la Ville de Paris. That same year, Toroni founded the BMPT (art group) together with Daniel Buren, Olivier Mosset, and Michel Parmentier. In works like \"Miroir d’Eau\" (1973) and \"Vert Wagon\" (1977), the imprints made with a n°50 paintbrush are repeated at regular intervals of 30 cm.\n\nToroni was included in documentas 7 (1982) and 9 (1992); São Paulo Art Biennial in 1991; and the Venice Biennale of 1976. Solo exhibitions include shows at Museum Kurhaus Kleve, Kleve, Germany in 2002; Niele Toroni: Histoires de Peinture at l'ARC/Musée d'Art Moderne de la Ville de Paris, in 2001; Musée Dhondt-Dhaenens, Deurle, and Avignon 2000, France in 2000. Other venues include: Base at Centro d'Arte, Florence and Niele Toroni, Siena Centro d'Arte Contemporani, Palazzo della Papesse, Siena in 1999; CAPC Musée d'Art Contemporain de Bordeaux in 1997; Gemeentemuseum Den Haag, and Stedelijk Museum, Amsterdam in 1994; Centre Georges Pompidou in 1991, and Musée d'Art Moderne de la Ville de Paris in 1990; Villa Arson, Nice and the Musée de Grenoble in 1987. In 1995 he completed a Public Art Project on Rochdale Canal, Manchester, England. \n\nToroni is represented by Yvon Lambert Gallery, Paris.\n\nToroni's works are part of major collections, including the Museum of Modern Art, New York; the Strasbourg Museum of Modern and Contemporary Art, Strasbourg; the Kupferstichkabinett, Berlin; the Kunstmuseum Luzern; Migros Museum für Gegenwartskunst, Zürich.\n\nToroni received the Wolfgang Hahn Prize, Cologne, Germany in 2003 and the French Vermeil Medal, awarded by the City of Paris in 2001.\n\n"}
{"id": "14285288", "url": "https://en.wikipedia.org/wiki?curid=14285288", "title": "Nirjara", "text": "Nirjara\n\nNirjara is one of the seven fundamental principles, or Tattva in Jain philosophy, and refers to the shedding or removal of accumulated karmas from the atma (soul), essential for breaking free from samsara, the cycle of birth-death and rebirth, by achieving moksha, liberation.\n\nLiterally meaning \"falling off\", the concept is described first in chapter 9 of the classical Jain text, Tattvartha Sutra (True nature of Reality) written by Acharya Umasvati, in 2nd century CE, the only text authoritative in both Svetambara and Digambara sects of Jainism. Later it also finds mention in Dravyasamgraha (Compendium of substances), a 10th-century Jain text by Acharya Nemichandra.\n\nNirjara is preceded by stoppage of karma accumulation, or \"samvara\", thereby ending \"asrava\" or influx of karma which leads to \"bandha\" or bondage due \"kasaya\" or passions of the soul, namely, \"krodha\" (anger), \"lobha\" (greed), \"mana\" (ego) and \"maya\" (deceit), besides \"raaga\" (attachment) and \"dvesa\" (hatred). \" Dravyasamgraha\" explains that the soul becomes dim due to the dust of karmic matter, thus nirjara itself offers a way to clear the soul, and ultimately leading to moksha, liberation.\n\nNirjara is of two types, \"Bhava Nirjara\", modification of soul which leads to separation of karmic matter from the soul, and \"Dravya Nirjara\", actual separation of karmic matter from the soul. In turn, \"bhava nirjara\" is of two types, \"Savipaka\" and \"Avipaka\".\n\nSavipaka - Passive Method - Also known as \"Akam\" or unintentional \"Nirjara\", equanimous submission to the fruition of karma, and involves natural maturing of past Karma, in due course of time and experiencing the results, both good and bad with equanimity. If the fruits of the past karmas are not received without attachment or agitation then the soul earns fresh karmic bondages. It is also not possible for the soul to know before-hand when and which karma will start to produce results and therefore require good discipline in practicing equanimity under all circumstances.\n\nThis passive method of exhaustion of karmic matter around the soul, after enjoyment of its fruits, is compared with emptying of a pond through evaporation, while water channels are still pouring in. Naturally it is a slow method, as by the time karmas become ripe and are exhausted, new karmas fill in, as karmic matter is constantly pouring into the \"karma sharira\" (karmic body), through asrava, influx of karma. Thus to achieve liberation, the active method of purging off karma, \"avipaka nirjara\" is advised.\n\nAvipaka - Active Method - Also known as \"Sakam\" or intentional \"Nirjara\", it involves individual exertion of ascetic practices, by practicing internal and external austerities, like penances or tapas, literally meaning heat, so as to accelerate the ripening process as well as reducing the effects produced. This is recommended approach as it prepares and conditions the soul and reminds it to be vigilant. Tapas is of two kinds, \"bahya\" or external, and \"antaranga\" or internal.\n\nThe \"Bahya\" or \"bahiranga tapa\", external austerities are meant to discipline the sensual cravings, and prepares the person for internal austerities, which come next.\n\n\nAt some places, alternative to this list include, \"Ichhanirodha\", control of desire for food and material things.\n\nThe \"antaranga tapa\", internal austerities which follow are:\n\n\nAll the first five internal austerities and all six external austerities are preparatory steps for the practice of dhyana, which is the primary cause of moksha.\n\nFor layman the journey begins with practicing the Triple gems of Jainism, \"Ratnatraya\", namely Right View or perception (\"Samyak Darshana\"), Right knowledge (\"Samyak Gyana\") and Right conduct (\"Samyak Charitra\"), which constitute the path to liberation. The monks in Jainism, who have dedicated their lives to achieve, moksha and acquiring the \"Kevala Jnana\", absolute knowledge, however go on to take the five \"Mahavrata\", literally Great Vows, of self-control:\n\nApart from that, the monks also practices, three \"Guptis\" and five \"Samitis\". Three Restraints (\"Gupti\"), i.e., Control of the mind (Managupti), Control of speech (Vacanagupti), Control of body (Kayagupti); and Five Carefulness (Samiti) i.e. Carefulness while walking (Irya Samiti), Carefulness while communicating (Bhasha Samiti), Carefulness while eating (Eshana Samiti), Carefulness while handling their fly-whisks, water gourds, etc. (Adana Nikshepana Samiti), Carefulness while disposing of bodily waste matter (Pratishthapana Samiti)\n\nAccording to Umaswati in \"Tattvartha Sutra\" 10.1.2, \"Kevala Jnana\", absolute knowledge or Omniscience, comes only after, the Mohaniya karma are first destroyed, followed by Jnanavaraniya karma, Darsanavarana karma and Antaraya karma. However after attaining the \"Kevala jnana\", the causes of bandha, bondage end, thus the influx of Karma, asrava, ends as well, thus the person is freed from the Aghatiya karmas namely, Ayu karma, Nama karma, Gotra karma and Vedaniya karma, which cause worldly existence. Emptied of karma the person attains liberation.\n\n\n\n"}
{"id": "18823653", "url": "https://en.wikipedia.org/wiki?curid=18823653", "title": "Orthogonality principle", "text": "Orthogonality principle\n\nIn statistics and signal processing, the orthogonality principle is a necessary and sufficient condition for the optimality of a Bayesian estimator. Loosely stated, the orthogonality principle says that the error vector of the optimal estimator (in a mean square error sense) is orthogonal to any possible estimator. The orthogonality principle is most commonly stated for linear estimators, but more general formulations are possible. Since the principle is a necessary and sufficient condition for optimality, it can be used to find the minimum mean square error estimator.\n\nThe orthogonality principle is most commonly used in the setting of linear estimation. In this context, let \"x\" be an unknown random vector which is to be estimated based on the observation vector \"y\". One wishes to construct a linear estimator formula_1 for some matrix \"H\" and vector \"c\". Then, the orthogonality principle states that an estimator formula_2 achieves minimum mean square error if and only if\nIf \"x\" and \"y\" have zero mean, then it suffices to require the first condition.\n\nSuppose \"x\" is a Gaussian random variable with mean \"m\" and variance formula_5 Also suppose we observe a value formula_6 where \"w\" is Gaussian noise which is independent of \"x\" and has mean 0 and variance formula_7 We wish to find a linear estimator formula_8 minimizing the MSE. Substituting the expression formula_9 into the two requirements of the orthogonality principle, we obtain\nand\nSolving these two linear equations for \"h\" and \"c\" results in\nso that the linear minimum mean square error estimator is given by\n\nThis estimator can be interpreted as a weighted average between the noisy measurements \"y\" and the prior expected value \"m\". If the noise variance formula_18 is low compared with the variance of the prior formula_19 (corresponding to a high SNR), then most of the weight is given to the measurements \"y\", which are deemed more reliable than the prior information. Conversely, if the noise variance is relatively higher, then the estimate will be close to \"m\", as the measurements are not reliable enough to outweigh the prior information.\n\nFinally, note that because the variables \"x\" and \"y\" are jointly Gaussian, the minimum MSE estimator is linear. Therefore, in this case, the estimator above minimizes the MSE among all estimators, not only linear estimators.\n\nLet formula_20 be a Hilbert space of random variables with an inner product defined by formula_21. Suppose formula_22 is a closed subspace of formula_20, representing the space of all possible estimators. One wishes to find a vector formula_24 which will approximate a vector formula_25. More accurately, one would like to minimize the mean squared error (MSE) formula_26 between formula_2 and formula_28.\n\nIn the special case of linear estimators described above, the space formula_20 is the set of all functions of formula_28 and formula_31, while formula_22 is the set of linear estimators, i.e., linear functions of formula_31 only. Other settings which can be formulated in this way include the subspace of causal linear filters and the subspace of all (possibly nonlinear) estimators.\n\nGeometrically, we can see this problem by the following simple case where formula_22 is a one-dimensional subspace:\n\nWe want to find the closest approximation to the vector formula_28 by a vector formula_2 in the space formula_22. From the geometric interpretation, it is intuitive that the best approximation, or smallest error, occurs when the error vector, formula_38, is orthogonal to vectors in the space formula_22. \n\nMore accurately, the general orthogonality principle states the following: Given a closed subspace formula_22 of estimators within a Hilbert space formula_20 and an element formula_28 in formula_20, an element formula_24 achieves minimum MSE among all elements in formula_22 if and only if formula_46 for all formula_47\n\nStated in such a manner, this principle is simply a statement of the Hilbert projection theorem. Nevertheless, the extensive use of this result in signal processing has resulted in the name \"orthogonality principle.\"\n\nThe following is one way to find the minimum mean square error estimator by using the orthogonality principle.\n\nWe want to be able to approximate a vector formula_28 by \n\nwhere\n\nis the approximation of formula_28 as a linear combination of vectors in the subspace formula_22 spanned by formula_53 Therefore, we want to be able to solve for the coefficients, formula_54, so that we may write our approximation in known terms.\n\nBy the orthogonality theorem, the square norm of the error vector, formula_55, is minimized when, for all \"j\",\n\nDeveloping this equation, we obtain\n\nIf there is a finite number formula_58 of vectors formula_59, one can write this equation in matrix form as\n\nAssuming the formula_59 are linearly independent, the Gramian matrix can be inverted to obtain\n\nthus providing an expression for the coefficients formula_63 of the minimum mean square error estimator.\n\n\n"}
{"id": "1718457", "url": "https://en.wikipedia.org/wiki?curid=1718457", "title": "Paramatman", "text": "Paramatman\n\nParamatman (Sanskrit: परमात्मन्, IAST: Paramātmāṇ) or Paramātmā is the Absolute Atman or Supreme self) in Vedanta and Yoga philosophies in the Hindu theology. The Paramatman is the “Primordial Self” or the “Self Beyond” who is spiritually practically identical with the Absolute, identical with the Brahman. Selflessness is the attribute of Paramatman, where all personality/individuality vanishes.\n\nThe word stem \"paramātma\" (परमात्मन्, pronounced , its nominative singular being \"paramātmā\" — परमात्मा, pronounced ) is formed from two words, \"parama\", meaning \"supreme\" or \"highest\", and \"ātma\", which means individual self.\n\nThe word “Ātman” generally denotes the Individual Self, but by the word “Paramatman” which word also expresses Boundless Life, Boundless Consciousness, Boundless Substance in Boundless Space, is meant the Atman of all atmans or the Supreme Self or the Universal Self. The word “Atman” which literally means non-darkness or light, is Brahman the subtlest indestructible Divine existence. The word “Paramatman” refers to the Creator all.\n\nIn Jainism, each atman or individual self is a potential Paramatman or God, both are essentially the same. It remains as atman only because of its binding \"karmic\" limitations, until such time as those limitations are removed. As Paramatman, the atman represents the ultimate point of spiritual evolution.\n\nEven though Jain mysticism centers around Atman and Paramatman because it believes in the existence of soul, in Jainism, which accepts neither Vedic authority nor Monism, all enlightened souls are referred to as Paramatman and regarded as gods. Jainism honours the soul of each man as its own eternally distinct savior. Since the Paramatman of Jainism is unable to create and govern the world, there is no place of God as a creator and bestower of fortune.\n\nBuddhism rejects a metaphysics of \"ground\" such as the paramatman.\n\nThe sage of the Brihadaranyaka Upanishad IV.4.2, though not using the word “Paramatman”, explains that at the time of release the portion (aspect) of the Paramatman and the portion (aspect) of the Jiva presiding in the right eye become unified with the Paramatman and the Jiva presiding in the heart, then the Jiva does not see, smell, taste, speak, hear, feel, touch and know; when Paramatman goes out, the Chief Prana goes out after Him, followed by the Lower Prana. Paramatman goes out riding on the Jiva following consciousness and work, knowledge of former life or natural capacity. In the Prashna Upanishad IV.11 the word “Atman” cannot refer to Jiva because the Jiva cannot of its own accord throw off its body or understand avidya, therefore, it refers to Paramatman. The Jiva attains Moksha when he actually knows the Paramatman, the Asarira Prajnatman, to be thousand-headed, to be the governor of all and to be superior to all. Thus, Paramatman is one of the many aspects of Brahman and has all attributes of Brahman. Atman (Spirit) and Paramatman (God) are one, some say they are distinct as well as one, they are one with reference to Shakti but distinct with reference to that power.\n\nThe word, Paramatman, is not to be found in the Rig Veda but through allusion referring to Paramatman as Isha. This distinction is made because all of its mantras which in the form of prayers are addressed to gods. In its great Riddle Hymn (Sukta I.164) is the famous mantra - R.V.I.164.20, that was revealed to Rishi Deergatamaah Auchathyah and borrowed by Mundaka Upanishad III.1.1-3, which belongs to Atharva Veda, to weave the parable of the Two Birds:-Two birds.\n\n-Translation of Verses 1-3 of Third Mundaka Upanishad by Sri Aurobindo.\n\nHere at, Aurobindo makes the Spirit or Purusha as the Source of everything, including Brahman. He makes Purusha more fundamental. Thus, he does not have to say Brahman to be the source of inferior Brahman, and he also dismisses the sense of Reality revealed in imaginative and emotional build-up.\n\nThe Dualistic School of Philosophy initiated by Anandatirtha draws its support from the afore-cited passage as well as from the passage of Katha Upanishad I.3.1 of an earlier Upanishad that speaks about two souls which taste the fruits of action, both of which are lodged in the recess of the human heart, and which are different from each other as light and shade, that carried the flaw – how could the Universal soul be regarded as enjoying the fruits of action? The followers of Madhava draw their support from the Bhagavad Gita XV.16 that speaks about two persons in this world, the Mutable and the Immutable; the Mutable is all these things, while the Immutable is the one who exists at the top of them, one is the Jivatman and the other, Paramatman. Jivatman is \"chit\", the sentient, and Paramatman is Isvara, both have the same attributes; they are inseparably present together on the tree which is \"achit\", the insentient, or the gross \"Avidya\" component of existence. Jivatman and Paramatman are both seated in the heart, the former is driven by the three modes of nature and acts, the latter simply witnesses as though approving the former’s activities. The relationship between Paramātmā, the Universal Self, and 'ātma, the Individual Self, is likened to the indwelling God and the soul within one's heart. Paramatman is one of the many aspects of Brahman. Paramatman is situated at the core of every individual jiva in the macrocosm. The Upanishads do compare Atman and Paramatman to two birds sitting like friends on the branch of a tree (body) where the Atman eats its fruits (karma), and the Paramatman only observes the Atman as a witness (sākṣin) of His friend's actions.\n\nIn Advaita philosophy, individual souls are called Jīvātman, and the Highest Brahman is called Paramātman. The Jivatman and the Paramatman are known to be one and the same when the Jivatman attains the true knowledge of the Brahman (Skt. \"Brahmajñāna\") . In the context of Advaita, the word Paramatman is invariably used to refer to Nirguna Brahman, with Ishvara and Bhagavan being terms used to refer to Brahman with qualities, or Saguna Brahman.\n\nBrahman and Isvara are not synonymous words, the apparent similarity is on account of similar looking attributes imagined with regard to the impressions these two words activate. According to Advaita, Isvara is Brahman associated with Maya in its excellent aspect, as the empirical reality it is the determinate Brahman; Isvara has no reality apart from Brahman. The Svetasvatara Upanishad developed the conception of a personal God. The Katha Upanishad states that never has any man been able to visualise Paramatman by means of sight, heart, imagination or mind. The Anandamaya-kosha is the Isvara of the Upanishads. Gaudapada called duality Maya, and non-duality, the only reality. Maya is the Cosmic Nescience that has in it the plurality of subject and object and therefore, Isvara is organically bound with the world. Beyond the Prana or Isvara is the state of the Infinite limitless Brahman which is why in the Bhagavad Gita VII.24, Krishna tells Arjuna – “not knowing My unsurpassable and undecaying supreme nature the ignorant believe Me to have assumed a finite form through birth.”\n\nWith regard to the cause of Samsāra, as to where it resides and the means of its removal, Adi Shankara in his Vivekachudamani.49. instructs that the individual self is the Paramatman in reality, the association of the individual self with \"ajnana\" i.e. with \"avidya\", which he terms as \"anatmabandhah\", bondage by the anatman or non-atman, makes it to identify itself with gross, subtle and causal bodies and from that arises Samsāra which is of the form of superimposition of qualities of \"sukha\", \"dukha\" etc., on itself, the atman.\n\nAccording to Brahma Kumaris religion, Paramatma (Supreme Soul) is called Shiva, or Shiva Baba. His form is a point of infinitesimal light and his abode is Paramdham or Nirvana.\n\nParamatman is beyond knowledge and ignorance, devoid of all material attributes (upadhi). In Chapter 13 of the Bhagavad Gita, Paramatman is described as Krishna residing in the hearts of all beings and in every atom of matter. He is the overseer and the permitter of their actions. Paramatman is different from five elements (pancha mahabhutas), the senses, mind, pradhana and jiva.\n\nVaishnava sects maintain that attaining knowledge of Brahman and identification of Atman with Brahman is an intermediate stage of self-realization, and only Bhakti Yoga can lead to the next step of Paramatman realization as the indwelling God, ultimately leading up to liberation (Mukti) by God-realization.\n\nThe Viṣṇu or the deity of the \"quality of goodness\" in the material world is the puruṣa-avatāra known as Kṣīrodakaśāyī Viṣṇu or \"Paramātmā\".\n\nIn Bengal, Vaishnava Krishna is viewed as one endowed with his essential svarupa-shakti, he is Bhagawat in full manifestation endowed with Jivasakti and Mayasakti, he the Paramatman and Brahman. Brahman, Paramatman and Bhagavan are 3 gradations of the ultimate reality.\n\nTime is described in Vedas:\n\n"}
{"id": "23479", "url": "https://en.wikipedia.org/wiki?curid=23479", "title": "Physicalism", "text": "Physicalism\n\nIn philosophy, physicalism is the metaphysical thesis that \"everything is physical\", that there is \"nothing over and above\" the physical, or that everything supervenes on the physical. Physicalism is a form of ontological monism—a \"one substance\" view of the nature of reality as opposed to a \"two-substance\" (dualism) or \"many-substance\" (pluralism) view. Both the definition of \"physical\" and the meaning of physicalism have been debated.\n\nPhysicalism is closely related to materialism. Physicalism grew out of materialism with advancements of the physical sciences in explaining observed phenomena. The terms are often used interchangeably, although they are sometimes distinguished, for example on the basis of physics describing more than just matter (including energy and physical law). Common arguments against physicalism include both the philosophical zombie argument and the multiple observers argument, that the existence of a physical being may imply zero or more distinct conscious entities.\n\nThe word \"physicalism\" was introduced into philosophy in the 1930s by Otto Neurath and Rudolf Carnap.\n\nThe use of \"physical\" in physicalism is a philosophical concept and can be distinguished from alternative definitions found in the literature (e.g. Karl Popper defined a physical proposition to be one which can at least in theory be denied by observation). A \"physical property\", in this context, may be a metaphysical or logical combination of properties which are physical in the ordinary sense. It is common to express the notion of \"metaphysical or logical combination of properties\" using the notion of supervenience: A property \"A\" is said to supervene on a property \"B\" if any change in \"A\" necessarily implies a change in \"B\". Since any change in a combination of properties must consist of a change in at least one component property, we see that the combination does indeed supervene on the individual properties. The point of this extension is that physicalists usually suppose the existence of various abstract concepts which are non-physical in the ordinary sense of the word; so physicalism cannot be defined in a way that denies the existence of these abstractions. Also, physicalism defined in terms of supervenience does not entail that all properties in the actual world are type identical to physical properties. It is, therefore, compatible with multiple realizability.\n\nFrom the notion of supervenience, we see that, assuming that mental, social, and biological properties supervene on physical properties, it follows that two hypothetical worlds cannot be identical in their physical properties but differ in their mental, social or biological properties.\n\nTwo common approaches to defining \"physicalism\" are the theory-based and object-based approaches. The theory-based conception of physicalism proposes that \"a property is physical if and only if it either is the sort of property that physical theory tells us about or else is a property which metaphysically (or logically) supervenes on the sort of property that physical theory tells us about\". Likewise, the object-based conception claims that \"a property is physical if and only if: it either is the sort of property required by a complete account of the intrinsic nature of paradigmatic physical objects and their constituents or else is a property which metaphysically (or logically) supervenes on the sort of property required by a complete account of the intrinsic nature of paradigmatic physical objects and their constituents\".\n\nPhysicalists have traditionally opted for a \"theory-based\" characterization of the physical either in terms of current physics, or a future (ideal) physics. These two theory-based conceptions of the physical represent both horns of Hempel's dilemma (named after the late philosopher of science and logical empiricist Carl Gustav Hempel): an argument against theory-based understandings of the physical. Very roughly, Hempel's dilemma is that if we define the physical by reference to current physics, then physicalism is very likely to be false, as it is very likely (by pessimistic meta-induction) that much of current physics is false. But if we instead define the physical in terms of a future (ideal) or completed physics, then physicalism is hopelessly vague or indeterminate.\n\nWhile the force of Hempel's dilemma against theory-based conceptions of the physical remains contested, alternative \"non-theory-based\" conceptions of the physical have also been proposed. Frank Jackson (1998) for example, has argued in favour of the aforementioned \"object-based\" conception of the physical. An objection to this proposal, which Jackson himself noted in 1998, is that if it turns out that panpsychism or panprotopsychism is true, then such a non-materialist understanding of the physical gives the counterintuitive result that physicalism is, nevertheless, also true since such properties will figure in a complete account of paradigmatic examples of the physical.\n\nDavid Papineau and Barbara Montero have advanced and subsequently defended a \"via negativa\" characterization of the physical. The gist of the via negativa strategy is to understand the physical in terms of what it is not: the mental. In other words, the via negativa strategy understands the physical as \"the non-mental\". An objection to the via negativa conception of the physical is that (like the object-based conception) it doesn't have the resources to distinguish neutral monism (or panprotopsychism) from physicalism.\n\nAdopting a supervenience-based account of the physical, the definition of physicalism as \"all properties are physical\" can be unravelled to:\n\n1) Physicalism is true at a possible world \"w\" if and only if any world that is a physical duplicate of \"w\" is also a duplicate of \"w simpliciter\".\n\nApplied to the actual world (our world), statement 1 above is the claim that physicalism is true at the actual world if and only if at \"every possible world\" in which the physical properties and laws of the actual world are instantiated, the non-physical (in the ordinary sense of the word) properties of the actual world are instantiated as well. To borrow a metaphor from Saul Kripke (1972), the truth of physicalism at the actual world entails that once God has instantiated or \"fixed\" the physical properties and laws of our world, then God's work is done; the rest comes \"automatically\".\n\nUnfortunately, statement 1 fails to capture even a necessary condition for physicalism to be true at a world \"w\". To see this, imagine a world in which there are \"only\" physical properties—if physicalism is true at any world it is true at this one. But one can conceive physical duplicates of such a world that are \"not\" also duplicates simpliciter of it: worlds that have the same physical properties as our imagined one, but with some additional property or properties. A world might contain \"epiphenomenal ectoplasm\", some additional pure experience that does not interact with the physical components of the world and is not necessitated by them (does not supervene on them). To handle the epiphenomenal ectoplasm problem, statement 1 can be modified to include a \"that's-all\" or \"totality\" clause or be restricted to \"positive\" properties. Adopting the former suggestion here, we can reformulate statement 1 as follows:\n\n2) Physicalism is true at a possible world \"w\" if and only if any world that is a \"minimal\" physical duplicate of \"w\" is a duplicate of \"w simpliciter\".\n\nApplied in the same way, statement 2 is the claim that physicalism is true at a possible world \"w\" if and only if any world that is a physical duplicate of \"w\" (without any further changes), is duplicate of \"w\" without qualification. This allows a world in which there are only physical properties to be counted as one at which physicalism is true, since worlds in which there is some extra stuff are \"not\" \"minimal\" physical duplicates of such a world, nor are they minimal physical duplicates of worlds that contain some non-physical properties that are metaphysically necessitated by the physical.\n\nBut while statement 2 overcomes the problem of worlds at which there is some extra stuff (sometimes referred to as the \"epiphenomenal ectoplasm problem\") it faces a different challenge: the so-called \"blockers problem\". Imagine a world where the relation between the physical and non-physical properties at this world (call the world \"w\") is slightly weaker than metaphysical necessitation, such that a certain kind of non-physical intervener—\"a blocker\"—could, were it to exist at \"w,\" prevent the non-physical properties in \"w\" from being instantiated by the instantiation of the physical properties at \"w.\" Since statement 2 rules out worlds which are physical duplicates of \"w\" that also contain non-physical interveners by virtue of the minimality, or that's-all clause, statement 2 gives the (allegedly) incorrect result that physicalism is true at \"w.\" One response to this problem is to abandon statement 2 in favour of the alternative possibility mentioned earlier in which supervenience-based formulations of physicalism are restricted to what David Chalmers (1996) calls \"positive properties\". A positive property is one that \"...if instantiated in a world W, is also instantiated by the corresponding individual in all worlds that contain W as a proper part.\" Following this suggestion, we can then formulate physicalism as follows:\n\n3) Physicalism is true at a possible world \"w\" if and only if any world that is a physical duplicate of \"w\" is a positive duplicate of \"w\".\n\nOn the face of it, statement 3 seems able to handle both the epiphenomenal ectoplasm problem and the blockers problem. With regard to the former, statement 3 gives the correct result that a purely physical world is one at which physicalism is true, since worlds in which there is some extra stuff are positive duplicates of a purely physical world. With regard to the latter, statement 3 appears to have the consequence that worlds in which there are blockers are worlds where positive non-physical properties of \"w\" will be absent, hence \"w\" will not be counted as a world at which physicalim is true. Daniel Stoljar (2010) objects to this response to the blockers problem on the basis that since the non-physical properties of \"w\" aren't instantiated at a world in which there is a blocker, they are not positive properties in Chalmers' (1996) sense, and so statement 3 will count \"w\" as a world at which physicalism is true after all.\n\nA further problem for supervenience-based formulations of physicalism is the so-called \"necessary beings problem\". A necessary being in this context is a non-physical being that exists in all possible worlds (for example what theists refer to as God). A necessary being is compatible with all the definitions provided, because it is supervenient on everything; yet it is usually taken to contradict the notion that everything is physical. So any supervenience-based formulation of physicalism will at best state a necessary but not sufficient condition for the truth of physicalism.\n\nAdditional objections have been raised to the above definitions provided for supervenience physicalism: one could imagine an alternate world that differs only by the presence of a single ammonium molecule (or physical property), and yet based on statement 1, such a world might be completely different in terms of its distribution of mental properties. Furthermore, there are differences expressed concerning the modal status of physicalism; whether it is a necessary truth, or is only true in a world which conforms to certain conditions (i.e. those of physicalism).\n\nClosely related to supervenience physicalism, is realisation physicalism, the thesis that every instantiated property is either physical or realised by a physical property.\n\nToken physicalism is the proposition that \"for every actual particular (object, event or process) x, there is some physical particular y such that x = y\". It is intended to capture the idea of \"physical mechanisms\". Token physicalism is compatible with property dualism, in which all substances are \"physical\", but physical objects may have mental properties as well as physical properties. Token physicalism is not however equivalent to supervenience physicalism. Firstly, token physicalism does not imply supervenience physicalism because the former does not rule out the possibility of non-supervenient properties (provided that they are associated only with physical particulars). Secondarily, supervenience physicalism does not imply token physicalism, for the former allows supervenient objects (such as a \"nation\", or \"soul\") that are not equal to any physical object.\n\nThere are multiple versions of reductionism. In the context of physicalism, the reductions referred to are of a \"linguistic\" nature, allowing discussions of, say, mental phenomena to be translated into discussions of physics. In one formulation, every concept is analysed in terms of a physical concept. One counter-argument to this supposes there may be an additional class of expressions which is non-physical but which increases the expressive power of a theory. Another version of reductionism is based on the requirement that one theory (mental or physical) be logically derivable from a second.\n\nThe combination of reductionism and physicalism is usually called reductive physicalism in the philosophy of mind. The opposite view is non-reductive physicalism. Reductive physicalism is the view that mental states are both nothing over and above physical states and reducible to physical states. One version of reductive physicalism is type physicalism or mind-body identity theory. Type physicalism asserts that \"for every actually instantiated property F, there is some physical property G such that F=G\". Unlike token physicalism, type physicalism entails supervenience physicalism.\n\nA common argument against reductive physicalism is multiple realizability, the possibility that a psychological process (say) could be instantiated by many different neurological processes (even non-neurological processes, in the case of machine or alien intelligence). For in this case, the neurological terms translating a psychological term must be disjunctions over the possible instantiations, and it is argued that no physical law can use these disjunctions as terms. Type physicalism was the original target of the multiple realizability argument.\n\nThere are two versions of emergentism, the strong version and the weak version. Supervenience physicalism has been seen as a strong version of emergentism, in which the subject's psychological experience is considered genuinely novel. Non-reductive physicalism, on the other side, is a weak version of emergentism because it does not need that the subject's psychological experience be novel. The strong version of emergentism is incompatible with physicalism. Since there are novel mental states, mental states are not nothing over and above physical states. However, the weak version of emergentism is compatible with physicalism. \n\nWe can see that emergentism is actually a very broad view. Some forms of emergentism appear either incompatible with physicalism or equivalent to it (e.g. posteriori physicalism), others appear to merge both dualism and supervenience. Emergentism compatible with dualism claims that mental states and physical states are metaphysically distinct while maintaining the supervenience of mental states on physical states. This proposition however contradicts supervenience physicalism, which asserts a denial of dualism.\n\nPhysicalists hold that physicalism is true. A natural question for physicalists, then, is whether the truth of physicalism is deducible a priori from the nature of the physical world (i.e., the inference is justified independently of experience, even though the nature of the physical world can itself only be determined through experience) or can only be deduced a posteriori (i.e., the justification of the inference itself is dependent upon experience). So-called \"a priori physicalists\" hold that from knowledge of the conjunction of all physical truths, a totality or that's-all truth (to rule out non-physical epiphenomena, and enforce the closure of the physical world), and some primitive indexical truths such as \"I am A\" and \"now is B\", the truth of physicalism is knowable a priori. Let \"P\" stand for the conjunction of all physical truths and laws, \"T\" for a that's-all truth, \"I\" for the indexical \"centering\" truths, and \"N\" for any [presumably non-physical] truth at the actual world. We can then, using the material conditional \"→\", represent a priori physicalism as the thesis that PTI → N is knowable a priori. An important wrinkle here is that the concepts in N must be possessed non-deferentially in order for PTI → N to be knowable a priori. The suggestion, then, is that possession of the concepts in the consequent, plus the empirical information in the antecedent is sufficient for the consequent to be knowable a priori.\n\nAn \"a posteriori physicalist\", on the other hand, will reject the claim that PTI → N is knowable a priori. Rather, they would hold that the inference from PTI to N is justified by metaphysical considerations that in turn can be derived from experience. So the claim then is that \"PTI and not N\" is metaphysically impossible.\n\nOne commonly issued challenge to a priori physicalism and to physicalism in general is the \"conceivability argument\", or zombie argument. At a rough approximation, the conceivability argument runs as follows:\n\nP1) PTI and not Q (where \"Q\" stands for the conjunction of all truths about consciousness, or some \"generic\" truth about someone being \"phenomenally\" conscious [i.e., there is \"something it is like\" to be a person x] ) is conceivable (i.e., it is not knowable a priori that PTI and not Q is false).\n\nP2) If PTI and not Q is conceivable, then PTI and not Q is metaphysically possible.\n\nP3) If PTI and not Q is metaphysically possible then physicalism is false.\n\nC) Physicalism is false.\n\nHere proposition P3 is a direct application of the supervenience of consciousness, and hence of any supervenience-based version of physicalism: If PTI and not Q is possible, there is some possible world where it is true. This world differs from [the relevant indexing on] our world, where PTIQ is true. But the other world is a minimal physical duplicate of our world, because PT is true there. So there is a possible world which is a minimal physical duplicate of our world, but not a full duplicate; this contradicts the definition of physicalism that we saw above.\n\nSince a priori physicalists hold that PTI → N is a priori, they are committed to denying P1) of the conceivability argument. The a priori physicalist, then, must argue that PTI and not Q, on ideal rational reflection, is incoherent or contradictory.\n\nA posteriori physicalists, on the other hand, generally accept P1) but deny P2)--the move from \"conceivability to metaphysical possibility\". Some a posteriori physicalists think that unlike the possession of most, if not all other empirical concepts, the possession of consciousness has the special property that the presence of PTI and the absence of consciousness will be conceivable—even though, according to them, it is knowable a posteriori that PTI and not Q is not metaphysically possible. These a posteriori physicalists endorse some version of what Daniel Stoljar (2005) has called \"the phenomenal concept strategy\". Roughly speaking, the phenomenal concept strategy is a label for those a posteriori physicalists who attempt to show that it is only the \"concept\" of consciousness—not the \"property\"—that is in some way \"special\" or sui generis. Other a posteriori physicalists eschew the phenomenal concept strategy, and argue that even ordinary macroscopic truths such as \"water covers 60% of the earth's surface\" are not knowable a priori from PTI and a non-deferential grasp of the concepts \"water\" and \"earth\" \"et cetera\". If this is correct, then we should (arguably) conclude that conceivability does not entail metaphysical possibility, and P2) of the conceivability argument against physicalism is false.\n\nGalen Strawson's \"realistic physicalism\" (or \"realistic monism\") entails panpsychism – or at least micropsychism. Strawson argues that \"many—perhaps most—of those who call themselves physicalists or materialists [are mistakenly] committed to the thesis that physical stuff is, in itself, in its fundamental nature, something wholly and utterly non-experiential... even when they are prepared to admit with Eddington that physical stuff has, in itself, 'a nature capable of manifesting itself as mental activity', i.e. as experience or consciousness\". Because experiential phenomena allegedly cannot be emergent from wholly non-experiential phenomena, philosophers are driven to substance dualism, property dualism, eliminative materialism and \"all other crazy attempts at wholesale mental-to-non-mental reduction\".\n\n\n"}
{"id": "45116986", "url": "https://en.wikipedia.org/wiki?curid=45116986", "title": "Polynomial Wigner–Ville distribution", "text": "Polynomial Wigner–Ville distribution\n\nIn signal processing, the polynomial Wigner–Ville distribution is a quasiprobability distribution that generalizes the Wigner distribution function. It was proposed by Boualem Boashash and Peter O'Shea in 1994.\n\nMany signals in nature and in engineering applications can be modeled as formula_1, where formula_2 is a polynomial phase and formula_3.\n\nFor example, it is important to detect signals of an arbitrary high-order polynomial phase. However, the conventional Wigner–Ville distribution have the limitation being based on the second-order statistics. Hence, the polynomial Wigner–Ville distribution was proposed as a generalized form of the conventional Wigner–Ville distribution, which is able to deal with signals with nonlinear phase.\n\nThe polynomial Wigner–Ville distribution formula_4 is defined as\n\nwhere formula_6 denotes the Fourier transform with respect to formula_7, and formula_8 is the polynomial kernel given by\n\nwhere formula_10 is the input signal and formula_11 is an even number.\nThe above expression for the kernel may be rewritten in symmetric form as\n\nThe discrete-time version of the polynomial Wigner–Ville distribution is given by the discrete Fourier transform of\n\nwhere formula_14 and formula_15 is the sampling frequency.\nThe conventional Wigner–Ville distribution is a special case of the polynomial Wigner–Ville distribution with formula_16\n\nOne of the simplest generalizations of the usual Wigner–Ville distribution kernel can be achieved by taking formula_17. The set of coefficients formula_18 and formula_19 must be found to completely specify the new kernel. For example, we set\n\nThe resulting discrete-time kernel is then given by\n\nGiven a signal formula_1, where formula_24is a polynomial function, its instantaneous frequency (IF) is formula_25.\n\nFor a practical polynomial kernel formula_8, the set of coefficients formula_27and formula_19should be chosen properly such thatformula_29formula_30\n\n\nformula_32formula_33formula_34formula_35\n\n\nformula_37formula_38\n\nNonlinear FM signals are common both in nature and in engineering applications. For example, the sonar system of some bats use hyperbolic FM and quadratic FM signals for echo location. In radar, certain pulse-compression schemes employ linear FM and quadratic signals. The Wigner–Ville distribution has optimal concentration in the time-frequency plane for linear frequency modulated signals. However, for nonlinear frequency modulated signals, optimal concentration is not obtained, and smeared spectral representations result. The polynomial Wigner–Ville distribution can be designed to cope with such problem.\n\n1. B. Boashash and P. O’Shea, “Polynomial Wigner–Ville distributions and their relationship to time varying high order spectra,”IEEE Trans. Signal Process., vol. 42, pp. 216–220, Jan. 1994.\n2. M. Benidir and B. Boashash, “On the polynomial Wigner–Ville dis-tribution,” in Proc. SPIE, June 1995, San Diego, CA, vol. 2563, pp. 69–79.\n3. “Polynomial Wigner–Ville distributions and time-varying higher spectra,” in Proc. Time-Freq. Time-Scale Anal., Victoria, B.C., Canada, Oct. 1992, pp. 31–34.\n\n4. Jian-Jiun Ding, Time frequency analysis and wavelet transform class notes, the Department of Electrical Engineering, National Taiwan University (NTU), Taipei, Taiwan, 2018.\n"}
{"id": "24973", "url": "https://en.wikipedia.org/wiki?curid=24973", "title": "Prime time", "text": "Prime time\n\nThe prime time or the peak time is the block of broadcast programming taking place during the middle of the evening for television programming.\n\nThe term \"prime time\" is often defined in terms of a fixed time period – for example (in the United States), from 8:00p.m. to 11:00p.m. (Eastern and Pacific Time) or 7:00p.m. to 10:00p.m. (Central and Mountain Time).\n\nIn Bangladeshi Television Channels, the 19:00-to-22:00 time slot is known as Prime Time. Several National Broadcasters like Maasranga Television, Gazi TV, Channel 9, Channel i broadcast their prime time shows from 20.00 to 23.00 after their Primetime news at 19.00. \nDuring Eid Season, most of the TV Stations broadcast their especially produced shows and World Television Premiers starting from 15.00 to 24.00.\nIn Ramadan, the broadcasters also air special Religious and Cooking shows starting from 14.00 to 20.00 affecting the primetime hours. Besides, Late Night Talkshows are also aired from 01.00 to 04.00 with Ramadan being exception. Religious shows are also broadcast simultaneously from 01.00 along with Talkshows and News Analysis.\n\nIn Chinese television, the 19:00-to-22:00 time slot is known as Golden Time (Traditional Chinese: 黄金時間; Simplified Chinese: 黄金时间; Pinyin: Huángjīn shíjiān). The term also influenced a nickname of a strip of holidays in known as Golden Week.\n\nPrime time usually takes place from 19:00 until 22:00. After that, programs classified as “PG” (Parental Guidance) are allowed to be broadcast. Frontline dramas appear during this time slot in Cantonese, as well as movies in English.\n\nIn India, prime time occurs between 20:00 and 22:30. The main news programs are broadcast at 20:30, and the highest-rated television program is preceded by it at 20:00. Usually, programmes during prime time are domestic dramas, foreign drama series (mostly American), movies and entertainment programmes.\n\nPrime time usually takes place from 18:00 to 23:00 WIB, preceded by a daily newscast at 17:00 (although some channels broadcast their daily evening newscasts earlier, usually at 16:00 or 16:30). After prime time, programs classified as Adult, as well as cigarette commercials, are allowed to be broadcast.\n\nLike another Muslim-majority country, there is also a 'midnight prime time' during sahur time in a month of Ramadan. It takes place from 02:00 (or 02:30 in some channels) and ends at the Fajr prayer call, varies between 04:30 and 05:00. The time slot is usually filled with comedy and religious programming.\n\nIn Iraq, prime time runs from 20:00 to 23:00. The main news programs are broadcast at 20:00 and the highest-rated television program airs at 21:00.\n\nIn Japanese television, the 19:00-to-22:00 time slot is also known as . The term also influenced a nickname of a strip of holidays in known as Golden Week.\n\nMalaysian prime time starts with the main news from 20:00 to 20:30 (now 20:00 to 21:00) and ends either at 23:00 or 0:30, or possibly later. Usually, programmes during prime time are domestic dramas, foreign drama series (mostly American), films and entertainment programmes. Programmes classified as 18 are not allowed to be broadcast before 10:00 p.m. but on RTM, most programmes on this slot are rated U (U means \"Umum\" in Malay and literally General Viewing or General Audiences in English) throughout the whole day. However, programmes broadcast after 23:00 are still considered prime time. As of December 2010, NTV7's prime time continues until 12:00 a.m. Programmes during prime time may have longer commercial breaks due to number of viewers.\n\nSome domestic prime time productions may be affected because of certain major sporting events such as FIFA World Cup. However, only FIFA World Cup in the Americas did not affect the domestic prime time programmes.\n\nIn Pakistan, The prime time begins between 20:00 - 22:00 Pakistan Standard Time. During this time majority of the local channels broadcast news and or drama serials, however on state channels it has been observed that they broadcast Khabarnama (New Bulletin) from past many decades.\n\nIn the Philippines, prime time blocks begin at 18:00 (now 17:50 or 17:00) and run until about 23:00 (or 23:30) on weekdays, and 19:00 to 23:00 on weekends. The weekday prime time blocks usually consists of local teleseryes (soap operas) and foreign television series. The network's highest-rated programs are usually aired right after the evening newscast at 20:00, while a foreign series usually precedes the late night newscast.\n\nOn weekends, non-scripted programming such as talent shows, reality shows and current affairs shows air in prime time. For the minor networks, prime time consists of American television series on weekdays, with encores of those shows on weekends. Prime time originally started earlier at around 19:00, but the evening newscasts were lengthened to 90 minutes and now start at 18:30, instead of the original one-hour newscast that starts at 18:00.\n\nIn Singapore, prime time begins at 18:30 on MediaCorp Channel 8 and 19:00 on MediaCorp Channel 5, MediaCorp Channel U, Channel NewsAsia, MediaCorp Suria, MediaCorp Vasantham and MediaCorp Okto. which are also the main (Free-to-air) television channels in Singapore.\n\nOn Channel 8, prime time ends at 24:00 or 0:15 on weekdays, at 0:30 on Saturday nights and at 23:30 on Sunday nights. On Channel 5, prime time ends at 0:00 on weekdays, at 1:30 (or later) on Saturday nights and at 0:30 on Sunday nights. On Suria, prime time ends at 23:30 on Monday to Thursday nights and at 23:00 on Friday to Sunday nights. On Vasantham, prime time ends at 23:00 on Mondays to Thursdays and at 24:00 (or later) on Fridays to Sundays. On Channel NewsAsia, prime time ends at 23:01, immediately after the news headlines, seven days a week. On Channel U, prime time ends at 23:00 seven days a week and on Okto, prime time ends at closedown at 24:00 or later. Generally, however, prime time is considered to be from 18:30 to 00:00.\n\nIn South Korea, prime time usually runs from 20:00 to 23:00 during the week, while on Saturdays and Sundays, it runs from 18:00 to 23:00. Family-oriented television shows are broadcast before 22:00, and adult-oriented television shows air after 22:00.\n\nIn Taiwan, prime time (called \"bādiǎn dàng\" - - in Mandarin Chinese) starts at 20:00 in the evening. Taiwanese drama series played then are called 8 o'clock series and are expected to have high viewer ratings.\n\nIn Thailand, prime time dramas (ละคร; la-korn) air from 20:30 to 22:30. Most dramas are soap operas. Prime time dramas are popular and influential to Thai society.\n\nIn Vietnam Prime time is also known as Golden Time (Tiếng Việt: Giờ vàng), prime time starts at 20:00 in the evening and ends at 23:00.\n\nIn Bosnia and Herzegovina, prime time starts at 20.00 and finishes at 22.00. It is preceded by a daily newscast (\"Dnevnik\") at 19.00 and followed by a late night newscast (\"Vijesti\") at 22.00.\n\nIn Croatia, prime time starts between 20.00 and 20.15. Croatian public broadcaster HRT broadcasts a daily newscast from 19.00 to 20.00. Also, many private broadcasters have daily newscasts either before or after the HTY newscast, at around 20.05, followed by the start of their own prime time. Many broadcasters without daily newscasts start their prime time at 20.00. Prime time generally ends between 22.00 and 23.00, followed by the late night edition of the network newscast and adult-oriented programming.\n\nIn Denmark, prime time starts at 20.00.\n\nIn Finland, prime time starts at 21.00. It is preceded by a daily newscast at 20.30.\n\nIn France prime time runs from 21.00 (after the main channels' evening news programmes) until around 22.30.\n\nIn Georgia, prime time starts between 18.45 and 20.00 and generallly ends at 24.00. However, on Friday night / Saturday morning prime time usually continues until 1.00.\n\nAt 20.00 each evening Das Erste (The First), Germany's oldest public television network, airs the country's most-watched news broadcast, the main edition of the \"Tagesschau\" – which is also simulcast on most of its other specialist and regional channels (The Third). The conclusion of the bulletin 15 minutes later marks the beginning of prime time, as it has since the 1950s. In consequence, most channels also choose to start their prime time at 20.15. In the 1990s, the commercial channel Sat.1 suffered a significant loss of audience share when it tried moving the start of its prime time to 20.00.\n\nIn Greece, prime time runs from 21.00 (usually following the news) to 24.00.\n\nIn Hungary, prime time on weekdays on the two big commercial stations (RTL Klub and TV2) starts at 19.00 with game shows, tabloid and docu-reality programmes. At 21.00, two popular soap operas air: \"Barátok közt\" and \"Jóban Rosszban\", which follows at 21.30. American and other series, movies, talk-shows and magazines run until 23.30. The prime-time lineup is preceded by daily news programmes at 18.30. At weekends prime time begins at 19.00, with blockbuster movies and television shows.\n\nBefore 15 March 2015, the public television station M1 began its prime time with a game show at 18.30, which was followed by the daily news programme \"Híradó\" at 19.30. After the news, the channel broadcast American and other series, talk shows, magazines, and news programmes until 22.00, after which came the daily news magazine \"Este\" and the late edition of \"Híradó\".\n\nFrom 15 March 2015, Duna began broadcasting all of the entertainment programming transferred to it from that date from M1, meaning that prime time on Duna now begins at 18.00, starting with the simulcast of the 18.00 edition of Híradó from the newly re-launched news channel, M1.\n\nIn Iceland, prime time starts at 19:30. It is preceded by a daily newscast at 19:00.\n\nIn Italy, prime time (called \"prima serata\") is from 21:00 to 23:30. It usually follows news and, on some networks (like Rai 1 and Canale 5), a slot called “access prime time”. Shows, movies, and sport events are usually shown during prime time.\n\nMuch like in Germany, prime time in the Netherlands usually begins at 20:30 in order to not compete with NOS's flagship 20:00 newscast.\n\nIn Norway, prime time starts at 19:45. On the NRK1 channel it is preceded by the daily newscast \"Dagsrevyen\" at 19:00. Locally, prime time is called (lit. \"best time for broadcasting\").\n\nIn Poland, prime time starts around 20:00 (sometimes 20:30). On (TVP 1) It is preceded by a daily newscast at 19:30, on (TVN) the newscast is aired at 19:00 followed by the newsmagazine Uwaga at 19:50 (weekdays)/19:45 (weekends) and then the soap Na Wspólnej at 20:05 (Monday to Thursday, from Friday to Sunday (at 20:00) various: movies on Friday, show or movies (Winter and Summer) at Saturday, and programme or movies (Winter and Summer) at Sunday), on (Polsat) the news is aired at 18:50, followed by a sitcom Świat według Kiepskich at 19:30.\n\nIn Russia television prime time is between 19:00 and 23:00 on working days and from 15:00 to 01:00 on holidays.\nOn radio stations there are morning, day and evening prime times. The most common division:\nmorning — 6:30 to 10:00;\nday — с 12:00 to 14:00;\nevening - 16:00 to 21:00.\n\nPublic television in Slovakia consists of two channels; on the main channel (Jednotka) prime time starts at 20:10, and on the second one (Dvojka) prime time programming starts at 20:00. The two biggest private broadcasters set the start of prime time programming at 20:20 (Markíza) and 20:30 (JOJ). Generally, however, prime time is considered to be from 20:00 to 23:00.\n\nIn Slovenia, prime time, the period in which the most-watched shows are broadcast, is from 8:00pm to 11:00pm. It is preceded by daily newscasts; Dnevnik RTV SLO (7:00pm–8:00pm) on TV SLO 1, 24ur (6:55pm–8:00pm) on POP TV, Svet na Kanalu A (6:00pm–7:00pm; 7:50pm–8:0pm), and Danes (7:30pm–8:00pm) on Planet TV.\n\nIn Spain, prime time refers to the time period in which the most-watched shows are broadcast. Prime time in Spain starts quite late when compared to most nations as it runs from 22:30 till 01:00. Most news programmes in Spain air at 21:00 for an hour and prime time follows. However, due to fierce competition, especially among the private stations prime time has even been delayed until 23:00. Most channels are delaying prime time in order to protect their top shows from sporting events.\n\nIn the 1990s, prime time in Spain began at 21:00, moving to 21:30 in the latter half of the 1990s and 22:00 in the early 2000s. Commercial broadcaster laSexta and the second channel from the Public broadcasting La 2 have attempted to shift prime time back to 21:30 in 2006 and Spring 2007, but these attempts have been unsuccessful. Fellow public channel La 1 also tried to pull prime time back to 21:00 in early 2015, to no avail.\n\nThe lateness in the start of prime time in Spain is also due to Spanish culture. Spanish people generally work from 09:00-14:00 and then from 17:00-20:00 as opposed to the standard 09:00-17:00. The popular late night show \"Crónicas Marcianas\" during the late 1990s–2000 also helped to extend prime time well into the early hours with the show being watched by a share of 40%, despite finishing at 02:00.\n\nSpain might also be unique in that it has a second prime time, running from 14:30-17:00 which coincides with the extended Spanish lunch break. Shows airing in the secondary prime time period on many occasions beat those prime time shows at night on a daily basis. The second prime time only occurs on weekdays, though and the slot is usually filled with The Simpsons, news, soap operas and talk shows.\n\nIn Sweden, prime time starts at 20:00. It is preceded by a daily newscast at 19:30 and local news at 19:50.\n\nIn the UK, the term used is peak time, early peak is 17:30 to 20:00 and late peak is 20:00 to 23:00.\n\nIn a great part of Latin American countries, prime time is considered to be from 6:00 or 7:00 p.m. to 10:00 or 11:00 p.m. The time slot is usually used for news, telenovelas and television series, and special time slots are used for reality shows, with great popularity, especially in Mexico and Brazil. In Mexico, Prime Time is known as \"horario estelar\" (\"Stellar Time\"). In Brazil, it is called \"horário nobre\" (“noble time”), which is the time the three most famous telenovelas in the country are shown each weekday and on Saturdays. There are also news programs, reality shows, and sitcoms.\n\nIn Argentina, prime time is considered to be from 8.00 p.m. until 12.00 a.m.; with the most successful series and telenovelas in the country (such as \"Los Roldán\" and \"Valientes\"), and entertainment shows, like CQC (Caiga Quien Caiga).\n\nIn Chile, prime time is considered to be from 10.30 p.m. until 01.00 a.m.; with the most successful series and telenovelas in the country (such as \"Socias\" and \"Las Vega's\"). Investigation entertainment shows (like \"Informe Especial\", \"Contacto\", \"Apuesto por tí\") also air.\n\nIn North America, television networks feed their prime time programming in two blocks: one for the Eastern, Central, and Mountain time zones, and one for the Pacific, Alaskan, and Hawaiian time zones, to their local network affiliates. In Atlantic Canada (including Newfoundland) as well as Alaska and Hawaii, there is no change in the interpretation or usage of “prime time” as the concept is not attached to time zones in any way. Affiliates in the Mountain, Alaskan, and Hawaii-Aleutian zones are either on their own to delay broadcast by an hour or two, or collectively form a small, regional network feed with others in the same time zone.\n\nPrime time is commonly defined as 8:00-11:00 p.m. Eastern/Pacific and 7:00-10:00 p.m. Central/Mountain. On Sundays, the major broadcast television networks traditionally begin their primetime programming at 7:00 p.m. (Eastern/Pacific, 6:00 p.m. Central/Mountain) instead. Some networks such as Fox, The CW, and MyNetworkTV only broadcast from 8:00-10:00 p.m., a time period known as \"common prime\". Most networks air primetime programming nightly, but the smaller MyNetworkTV only broadcasts prime time programs on weekdays, and The CW only broadcasts on weekdays and Sundays as of 2018, leaving weekends to their affiliates. In Canada, CTV and Global both follow the same model as the larger U.S. networks (although CTV may occasionally air programming in the 7:00 p.m. hour in the event of scheduling conflicts with other U.S. imports), while CBC Television, Citytv and CTV Two only schedule prime time programs within the common prime period (with the 10:00 p.m. p.m. hour dedicated to syndicated programming on City and CTV Two, and CBC airing its news program \"The National\").\n\nThe major networks have come to consider Saturday prime time as a graveyard slot, and have largely abandoned scheduling of new scripted programming on that night. The major networks still maintain a prime time programming schedule on Saturdays; while live sporting events (most commonly college football in the United States and ice hockey in Canada) are generally preferred to fill the time slot, they typically air encores of programs aired earlier in the week, films, non-scripted reality programs, true crime programs produced by their news divisions and, occasionally, burned off episodes of low-rated or cancelled series.\n\nPrime time can be extended or truncated if coverage of sporting events run past their allotted end time. Since the \"Heidi Game\" incident in 1968, in which NBC cut away from coverage of a New York Jets/Oakland Raiders football game on the east coast in order to show a movie (and, in the process, causing viewers to miss an unexpected comeback by the Raiders to win the game), the later National Football League mandated that all games be broadcast in their entirety in the markets of the teams involved. Due to this rule, game telecasts may sometimes overrun into the 7:00 p.m. ET hour. Fox previously scheduled repeats of its animated series in the 7:00 hour, allowing themselves to simply pre-empt the reruns if a game ran long. This was later replaced by a half-hour-long wrap-up show, \"The OT\". In contrast, CBS does not, as its weekly newsmagazine \"60 Minutes\" has traditionally aired as close to 7:00 p.m. ET as possible. Even if a game runs past that hour, CBS shows \"60 Minutes\" in its entirety after the conclusion of coverage, and the rest of the prime time schedule on the East Coast is shifted to compensate. For example, if game coverage were to end at 7:30 p.m., prime time would end at 11:30 p.m.\n\nHowever, in the rare case where the NFL game runs excessively late (8 p.m. or later), the series scheduled to air at 10 p.m. is preempted, with the West Coast usually receiving a repeat of the 10 p.m. series instead. In an extreme case, CBS's prime time can be extended past midnight during broadcasts of the NCAA Division I Men's Basketball Tournament. This does not necessarily apply universally; in 2001, after an XFL game went into double overtime, causing a 45-minute delay of a highly promoted episode of \"Saturday Night Live\", NBC made a decision to cut off all future XFL broadcasts at 11:00 p.m. ET. Since the launch of NBCSN, NBC has occasionally invoked this curfew by moving event overruns to the channel when allowed.\n\nUntil the U.S. Federal Communications Commission (FCC) regulated time slots prior to prime time with the now-defunct Prime Time Access Rule in the 1971–1972 season, networks began programming at 7:30 p.m. Eastern and Pacific/6:30 p.m. Central and Mountain on weeknights. The change helped instigate what is colloquially known as the \"rural purge\"—a long-term trend away from programs appealing to older and rural audiences in favor of programs catering towards younger, \"urban\" viewers. As a result, the hour became a lucrative timeslot for syndicated programming in the years that followed, with game and variety shows, as well as other syndicated reruns, becoming popular.\n\nThe vast majority of prime time programming in English-speaking North America comes from the United States, with only a limited amount produced in Canada. The Canadian Radio-television and Telecommunications Commission mandates quotas for Canadian content in prime time; these quotas indicate at least half of Canadian prime time programs must be Canadian in origin, but the majority of this is served by national and local news or localized entertainment gossip shows such as Global's \"ET Canada\" and CTV's \"eTalk\".\n\nLikewise, the vast majority of Spanish-language programming in North America comes from Mexico. Televisa, a Mexican network, provides the majority of programming to the dominant U.S.-based Spanish broadcaster, Univision. Univision does produce a fairly large amount of unscripted Spanish-language programming, the best known having been the long-running variety show \"Sábado Gigante\", hosted and created by Chilean national Don Francisco. Univision's distant second-place competitor, Telemundo, produces a much greater share of in-house content, including a long line of telenovelas.\n\nIn Quebec, the largest Francophone area of North America, French-language programming consists of originally produced programs (most of which are produced in Montreal, with a few produced in Quebec City) and a few French-language dubs of English language programs. On all of the Quebec networks, entertainment programming is scheduled only between 8 and 10 p.m., with the 10-11 p.m. hour given over to a network newscast or a nightly talk show.\n\nPrime time is the daypart (a block of a day's programming schedule) with the most viewers and is generally where television networks and local stations reap much of their advertising revenues. In recent years television advertising expenditure in the US has been highest during prime-time drama shows.\n\nThe Nielsen ratings system is explicitly designed for the optimum measurement of audience viewership by dayparts with prime time being of most interest. Most people tend to watch television at prime time, as most often, based on standard working time, the end of the work day coincides with prime time viewing hours. Most viewers sit down to watch TV after dinner. This is usually the main reason for the high ratings for television programming at this time, as well as the attraction of the timeslot for advertisers.\n\nThe existence of prime time in the United States is largely an artifact of now repealed regulations of the Federal Communications Commission, which limited the number of hours that a network can require its affiliates to broadcast.\n\nAdditionally, networks may also choose to provide local affiliates the opportunity to air sporting events or other special events which may fall outside of standard designated network broadcast times. Prime time for radio is called “Drive time” and, in Eastern and Pacific Time, is 6–10 a.m. and 3–7 p.m. and, for Mountain and Central Time, is 5–9 a.m. and 2–6 p.m.\n\nA survey by Nielsen revealed that viewers watched almost two hours worth of TV during prime time.\n\nPrime time in Australia is officially from 6:00 p.m. to midnight, following Australian Eastern Standard Time, with the highest ratings normally achieved between 6:00 p.m. to 9:00 p.m.\n\nTraditionally, prime time in New Zealand is considered to be 7:30pm to 10:30pm, but can be extended to cover the entire evening of television (5:30pm to 11:00pm).\n\n"}
{"id": "11018121", "url": "https://en.wikipedia.org/wiki?curid=11018121", "title": "Quaternion-Kähler symmetric space", "text": "Quaternion-Kähler symmetric space\n\nIn differential geometry, a quaternion-Kähler symmetric space or Wolf space is a quaternion-Kähler manifold which, as a Riemannian manifold, is a Riemannian symmetric space. Any quaternion-Kähler symmetric space with positive Ricci curvature is compact and simply connected, and is a Riemannian product of quaternion-Kähler symmetric spaces associated to compact simple Lie groups.\n\nFor any compact simple Lie group \"G\", there is a unique \"G\"/\"H\" obtained as a quotient of \"G\" by a subgroup\n\nHere, Sp(1) is the compact form of the SL(2)-triple associated with the highest root of \"G\", and \"K\" its centralizer in \"G\". These are classified as follows.\n\nThe twistor spaces of quaternion-Kähler symmetric spaces are the homogeneous holomorphic contact manifolds, classified by Boothby: they are the adjoint varieties of the complex semisimple Lie groups.\n\nThese spaces can be obtained by taking a projectivization of\na minimal nilpotent orbit of the respective complex Lie group.\nThe holomorphic contact structure is apparent, because\nthe nilpotent orbits of semisimple Lie groups \nare equipped with the Kirillov-Kostant holomorphic symplectic form. This argument also explains how one\ncan associate a unique Wolf space to each of the simple\ncomplex Lie groups.\n\n\n"}
{"id": "165449", "url": "https://en.wikipedia.org/wiki?curid=165449", "title": "Racialism", "text": "Racialism\n\nRacialism is the belief that the human species is naturally divided into races, that are ostensibly distinct biological categories. Most dictionaries define the term \"racialism\" as synonymous with racism.\n\nIn 1903, W. E. B. Du Bois said that racialism is the philosophical position that races existed, and that collective differences existed among such categories, the races. He further stated that racism required advancing the argument that one race is superior to other races of human beings. In \"In My Father’s House\" (1992), Kwame Anthony Appiah summarized Du Bois's philosophical stance that \"racialism\" is value-neutral term and that \"racism\" is a value-charged term.\n\nToday, some anthropologists and geneticists point to studies that suggest racialist beliefs are both compatible and incompatible with modern population genetics.\n\nAccording to Oxford Dictionaries Online, racialism is \"another term for racism\". The Merriam-Webster Dictionary defines racialism as \"a theory that race determines human traits and capacities\" and defines \"racism\" as \"a belief that race is the primary determinant of human traits and capacities and that racial differences produce an inherent superiority of a particular race\".\n\nRichard T. Ford claimed that although \"there is no necessary correspondence between the ascribed identity of race and one's culture or personal sense of self\" and \"group difference is not intrinsic to members of social groups but rather contingent o[n] the social practices of group identification\", the social practices of identity politics may coerce individuals into the \"compulsory\" enactment of \"prewritten racial scripts\".\n\nAccording to Yasuko Takezawa, there needs to be anticipation of various potential social and ethical problems associated with population descriptors when studying the genetic differences between populations.\n\nNotes\nFurther reading\n"}
{"id": "1806711", "url": "https://en.wikipedia.org/wiki?curid=1806711", "title": "Section 2 of the Canadian Charter of Rights and Freedoms", "text": "Section 2 of the Canadian Charter of Rights and Freedoms\n\nSection 2 of the \"Canadian Charter of Rights and Freedoms\" (\"Charter\") is the section of the Constitution of Canada that lists what the \"Charter\" calls \"fundamental freedoms\" theoretically applying to everyone in Canada, regardless of whether they are a Canadian citizen, or an individual or corporation. These freedoms can be held against actions of all levels of government and are enforceable by the courts. The fundamental freedoms are freedom of expression, freedom of religion, freedom of thought, freedom of belief, freedom of peaceful assembly and freedom of association.\n\nSection 1 of the \"Charter\" permits Parliament or the provincial legislatures to enact laws that place certain kinds of limited restrictions on the freedoms listed under section 2. Additionally, these freedoms can be temporarily invalidated by section 33, the \"notwithstanding clause\", of the \"Charter\".\n\nAs a part of the \"Charter\" and of the larger \"Constitution Act, 1982\", section 2 took legal effect on April 17, 1982. However, many of its rights have roots in Canada in the 1960 \"Canadian Bill of Rights\" (although this law was of limited effectiveness), and in traditions under a theorized Implied Bill of Rights. Many of these exemptions, such as freedom of expression, have also been at the centre of federalistic disputes.\n\nUnder the heading of \"Fundamental Freedoms\" the section states:\nAccording to Beverley McLachlin, freedom of religion in Canada may have originated as early as 1759, when French Canadian Roman Catholics were allowed rights of worship by their British conquerors; this was later reconfirmed in 1774 in the \"Quebec Act\". Later the \"Constitution Act, 1867\" provided for denominational school rights (these are reaffirmed by section 29 of the \"Charter\"). Discussions of church-state relations also took place in the Guibord case of 1874. In 1955, the Supreme Court ruled in \"Chaput v Romain\", regarding Jehovah's Witnesses, that different religions have rights, based upon tradition and the rule of law (at the time no statutes formed the basis for this argument).\n\nReligious freedom was later included in the \"Canadian Bill of Rights\". However, its effectiveness was limited. When Sunday closing laws compelling respect for the Christian Sabbath were challenged in \"R v Robertson and Rosetanni\", Justice Ritchie of the Supreme Court found that non-Christians merely lost money when denied rights to work on Sunday and were otherwise free to believe in and observe their own religions.\n\nFreedom of religion under section 2(a) of the \"Charter\" was first seriously considered by the Supreme Court in \"R v Big M Drug Mart Ltd\". In that case, Chief Justice Brian Dickson wrote that this freedom at least includes freedom of religious speech, including \"the right to entertain such religious beliefs as a person chooses, the right to declare religious beliefs openly and without fear of hindrance or reprisal, and the right to manifest religious belief by worship and practice or by teaching and dissemination.\" Freedom of religion would also prohibit imposing religious requirements. The immediate consequence of section 2, in this case, was the abolishment of federal Sunday closing laws.\n\nIn \"Syndicat Northcrest v Amselem\", the Supreme Court drew up a definition of freedom of religion under the \"Quebec Charter of Human Rights and Freedoms\", mindful of the overlap with section 2(a). The majority found freedom of religion encompasses a right to religious practices if the individual has a sincere belief that the practice is connected to religion. It would not matter whether the practice was needed according to religious authority. If courts can believe an individual is telling the truth in saying a practice is connected to religion, the courts then ask whether the infringement of freedom of religion is severe enough to trigger section 2. The Court also said religious beliefs are vacillating, so courts trying to determine an individual belief should be mindful that beliefs may change. Following this test in \"Multani v Commission scolaire Marguerite‑Bourgeoys\", the Court found freedom of religion should protect a non-violent Sikh student's right to wear a \"kirpan\" (dagger) in school.\n\nIn \"R v NS\", the Supreme Court sought to find a middle ground on the issue of whether a witness can wear a face-covering niqāb while testifying in a criminal trial. The court found that the right to religious freedom must be balanced against the right of the accused to a fair trial.\n\nIn addition to freedom of religion, section 2(a) also guarantees freedom of conscience. Professor Peter Hogg speculated this would include a right to atheism, despite the preamble to the Canadian Charter of Rights and Freedoms, which recognizes the \"supremacy of God\". The right has not spawned a great deal of case law, although Justice Bertha Wilson did rely on it in her opinion in \"R v Morgentaler\". Finding laws against abortion to be a breach of the rights to liberty and security of the person under section 7 of the \"Charter\", Wilson then argued this infringement could not be justified as being consistent with fundamental justice. The legal protections found under fundamental justice could be defined as including other rights under the \"Charter\", and in particular abortion laws breached freedom of conscience. As she wrote, the \"decision whether or not to terminate a pregnancy is essentially a moral decision, a matter of conscience\". She then said, \"[C]onscientious beliefs which are not religiously motivated are equally protected by freedom of conscience in s. 2(a).\" No other judges joined Wilson's opinion.\n\nJean Chrétien, who was the attorney general during negotiations of the \"Charter\", later recalled in his memoirs that freedom of conscience was nearly excluded from the \"Charter\". The federal and provincial negotiators found the right too difficult to define, and Chrétien eventually agreed to remove it. A legal advisor for the federal government, Pierre Genest, then kicked Chrétien's chair, prompting Chrétien to joke, \"I guess we leave it in. Trudeau's spy just kicked me in the ass.\"\n\nFreedom of expression, section 2(b), is perhaps one of the most significant \"Charter\" rights in influencing Canadian society. The right is expressly named in the charter because although \"Canadian criminal law uses the standard of the reasonable person as a ... definition for the threshold of criminality\", the \"Charter\" expressly limits some forms of expression. Justice Peter Cory wrote that it \"is difficult to imagine a guaranteed right more important to a democratic society\". The section has been at the centre of a great amount of case law.\n\nFreedom of speech had a limited background in Canada. It has been an issue in federalism disputes, as provincial legislation infringing upon free speech has been taken as criminal legislation, which only the Parliament of Canada can validly create under section 91(27) of the \"Constitution Act, 1867\". \"Switzman v Elbling\" is an example of a case in which this was discussed. An Implied Bill of Rights theory further stated governments were limited in their abilities to infringe upon free speech by virtue of the preamble of the \"Constitution Act, 1867\". This preamble states Canada's constitution would be based upon Britain's, and Britain had limited free speech in 1867. Furthermore, free speech is considered to be necessary for a parliamentary government to function.\n\nFree speech was later included in the \"Canadian Bill of Rights\".\n\nThe meaning of \"expression\" within section 2(b) has been read broadly as including any activity that conveys, or attempts to convey, meaning to the exception of acts of violence and threats of violence. However, the Courts have tried to maintain content neutrality by not considering the value of the expression. Instead, the content is only examined during the section 1 analysis.\n\nFreedom of expression is primarily seen as a negative right. In \"Native Women's Association of Canada v Canada\", the Court considered a claim that the government had to financially support an interest group in constitutional negotiations, as it had supported others. Section 28 (sexual equality under the \"Charter\") was used to reinforce this argument, since the rights claimants were an interest group. Still, while the Supreme Court agreed discussions with the government is \"unquestionably\" a form of expression, the government did not seem to be guilty of suppressing any expression and thus the claim was dismissed.\n\nA law will be found to violate the freedom of expression where the law either has the purpose or effect of violating the right.\n\nA law's purpose can limit the right either through limiting the content or form of expression. Limits on content are where the meaning of the expression is specifically forbidden by the law, such as hate-speech law, and is the most easily identifiable form of limitation. Limiting the form of the expression can often invoke section 2(b) as it will often have the effect of limiting the content as well.\n\nWhere a law does not intend to limit the freedom of expression it may still infringe section 2(b) through its effects. A law will be found to restrict expression if it has the effect of frustrating \"the pursuit of truth, participation in the community, or individual self-fulfillment and human flourishing\".\n\nCommercial expression is recognized as an activity protected under section 2(b). This includes advertising and any other similar means of expression used to sell goods and services. In fact, even false or misleading advertising is protected. The value of the expression does not come into play until the section 1 analysis.\n\nThe protection of commercial expression was first established in \"Ford v Quebec (AG)\", where the Court struck down a Quebec law requiring all signs to be exclusively in French. This was soon followed by \"Irwin Toy\", where the Court found that Quebec law prohibiting advertising to children to violate section 2(b) but was saved under section 1.\n\nThe Supreme Court has also found that restrictions on advertising by professionals to be protected. As well, even communications for the purpose of prostitution was found to be protected as commercial expression.\n\nProtesting by labour groups and trade unions have long been recognized as a protected form of expression.\n\nThere are not many instances of limiting primary picketing. Typically, the debate has been over whether secondary picketing can be restricted; the practice of picketing businesses not directly involved in a labour dispute has in the past been banned under the common law. The most significant decision on limiting primary picketing is \"British Columbia Government Employees' Union v British Columbia (AG)\", where employees at the British Columbia Supreme Court, who were protesting as part of a province-wide public service employee strike, were ordered back to work by the Chief Justice of the court. The order was found to clearly violate section 2(b) but the Supreme Court upheld it on section 1.\n\nSection 2(b) guarantees freedom of thought, belief and opinion in addition to freedom of expression. However, some have argued that freedoms of thought, belief and opinion in the \"Charter\" have had little practical consequence, and question whether governments have the capacity to stifle unspoken thoughts in any case.\n\nThe need to protect freedom of expression is considered a guiding principle of interpretation in civil cases between individuals. In \" Crookes v. Newton\", for example, the Supreme Court of Canada found that section 2(b) must be considered in determining the extent to which common law libel restrictions should apply to new technologies such as internet hyperlinks.\n\nFreedom of peaceful assembly under section 2(c) has not had a major impact on the case law. In \"Reference Re Public Service Employee Relations Act (Alta)\", the Supreme Court found that despite being written as a separate right, it was closely related to freedom of expression. The Nova Scotia Supreme Court defined it in \"Fraser et al v AGNS et al\" (1986) as including rights to meet as part of a committee or as workers. If there are membership fees to attend a meeting, prohibitions on being able to spend money for membership would be an abridgement of the right to peaceful assembly. In 2011, Occupy Canada's protests in public parks raised questions of whether their eviction was prohibited by freedom of assembly, as well as expression and association.\n\nFreedom of association is guaranteed under section 2(d). This right provides individuals the right to establish, belong to and maintain to any sort of organization, unless that organization is otherwise illegal. Generally, this is used in the labour context where employees are given the right to associate with certain unions or other similar group to represent their interests in labour disputes or negotiations.\n\nIt is important to note that this right only protects the right of individuals to form associations and not associations themselves. Consequently, government legislation affecting the powers of established labour associations do not necessarily invoke section 2(d). It is only where legislation restricts the associative nature of an activity will section 2 be invoked. However, in the landmark \"Health Services and Support – Facilities Subsector Bargaining Association v British Columbia\", the Supreme Court ruled that freedom of association guaranteed by section 2(d) includes a procedural right to collective bargaining. The Court ruled in this case that legislation that \"substantially interferes\" with the process of collective bargaining is a section 2(d) infringement. The test for \"substantial interference\" is twofold: (1) the importance of the matter affected to the process of collective bargaining, and more specifically, the capacity of union members to come together and pursue collective goals in concert; and (2) the manner in which the measure impacts on the collective right to good faith negotiation and consultation. It is not certain whether the decision in \"Health Services\" overturns jurisprudence arising from the so-called \"labour trilogy\" cases of 1987 which found that section 2(d) did not include a right to collective bargaining.\n\nThe Supreme Court has since found in \"Ontario (AG) v Fraser\", that the right to collective bargaining does not require government to take an active role in promoting and fostering collective bargaining, but merely to refrain from excessive interference with the collective bargaining process. In effect, the right to collective bargaining \"guarantees a process, not a result\". \"Fraser\" was affirmed and expanded upon by the Court of Appeal for Ontario in 2012 in \"Association of Justice Counsel v Canada (AG)\".\n\nTypically, where a union is denied a right it does not preclude the employees from forming a separate association. In \"Delisle v Canada (Deputy AG)\", members of the Royal Canadian Mounted Police were excluded from the public services legislation. The Supreme Court held that they were not precluded from forming their own association outside of the impugned legislation. However, in contrast the decision of \"Dunmore v Ontario (AG)\" indicated that agricultural workers who were excluded from provincial labour relations legislation were entitled to be included because individually they were unable to form their own associations, and consequently, this imposed a duty upon the government to include them.\n\nThe freedom of association also includes the freedom not to associate. In certain employment circumstances, employees are required to contribute to a union as conditions of their employment (see Rand formula). However, mandatory associations do not invoke section 2(d) in and of themselves. In \"Lavigne\", the Court found that the right not to be associated extended only to where the association supported causes that went beyond what is necessary for employee representation. More generally, the Supreme Court had stated that the right is violated only when the mandatory association imposes \"ideological conformity\". Such violations have also mostly been found by the Supreme Court to be justified under section 1, resulting in a right not to associate that has more theoretical than practical effects.\n\nIn \"Advance Cutting & Coring\", the Supreme Court was called to examine the constitutional validity of a Quebec law that required all persons working in the province's construction industry to join a designated union. Eight of nine judges (Justice Claire L'Heureux-Dubé dissenting) confirmed that section 2 includes, to at least some degree, the negative right to \"not\" associate. With a majority of five judges to four, the Court determined that the law at issue violated this right. But with the same majority (judge Frank Iacobucci \"switching camps\" on the two issues and citing a \"unique and complex historical context\" in Quebec), the Court deemed the law to be \"justified in a free and democratic society\" under section 1 and thus constitutional.\n\n\n"}
{"id": "3737625", "url": "https://en.wikipedia.org/wiki?curid=3737625", "title": "Self-monitoring", "text": "Self-monitoring\n\nSelf-monitoring is a concept introduced during the 1970s by Mark Snyder, that shows how much people monitor their self-presentations, expressive behavior, and nonverbal affective displays. Human beings generally differ in substantial ways in their abilities and desires to engage in expressive controls (see dramaturgy). It is defined as a personality trait that refers to an ability to regulate behavior to accommodate social situations. People concerned with their expressive self-presentation (see impression management) tend to closely monitor their audience in order to ensure appropriate or desired public appearances. Self-monitors try to understand how individuals and groups will perceive their actions. Some personality types commonly act spontaneously (low self-monitors) and others are more apt to purposely control and consciously adjust their behavior (high self-monitors). Recent studies suggest that a distinction should be made between acquisitive and protective self-monitoring due to their different interactions with metatraits. This differentiates the motive behind self-monitoring behaviours: for the purpose of acquiring appraisal from others (acquisitive) or protecting oneself from social disapproval (protective).\n\nThere are many cases in which self-monitoring is used a variable of interest. Many recent studies look into the relationship with on-task behavior, work-place utilization, and leadership positions.\n\nA pilot study regarding on-task behavior was done with two high school students with symptoms of learning disabilities. These students were trained using a self-monitoring application and given prompts and the results showed positive, stable improvements in their on-task behavior after each individual's self-monitoring was increased.\n\nWhen looking at theoretical and empirical evidence in self-monitoring in the work-place, research indicates that high self-monitors are proficient in meeting the social expectations and increasing their leadership outlook. Results from the study done by Day and Schleicher emphasize that the higher the individual scores on the scale, the more successful the individual tends to be as determined from the criteria of getting along, getting ahead, and making sense.\n\nThe relationship between self-monitoring and career mobility in particular was studied with a research pool of Masters of Business Administration graduates. High self-monitors are reported to be more likely to change employers, change work locations, and achieve promotions in comparison to low self-monitors.\n\nSelf-monitoring, despite all the research and theory behind it, has been shrouded with controversy and confusion with respect to its actual existence. The initial confusion arose because factor analyses were conducted which revealed that the structure of most items of the Self-Monitoring Scale was multifactorial. Three factors appeared necessary to account for the correlations between the items for the measure, interpreted as Acting (e.g. \"I would probably make a good actor\"), Extraversion (e.g. \"In a group of people, I am rarely the center of attention\"), and Other-Directedness (e.g. \"I guess I put on a show to entertain or impress other people\") (Snyder, M. & Gangestad, S. (2000)). Though these factor analyses are used as instruments to measure the level of self monitoring, they have prompted the question of the existence of self-monitoring. Mark Snyder and Steven W. Gangestad, (2000) argued through a series of quantitative experiments that it is indeed a real unitary phenomenon by showing that external criterion measures representing a wide array of phenomena relating to expressive control all point to self-monitoring as a real causal phenomena.\n\nAdditionally, they argue that the external criterion variables are generally most directly tapped by the Self-Monitoring Scale rather than being tapped by the measures of Extraversion, Social Surgency, or Other-Directedness, meaning that Self-Monitoring can better describe the factors that contribute to a person's personality than the combination of these. Measures of these three factors relate to the self-monitoring criterion only with respect to the fact that they have similar variance with the self-monitoring dimension, with Other-Directedness being the most highly related to Self-Monitoring. Hence, through answering these two questions, doubts regarding the existence of the Self-Monitoring phenomena were clearly dispelled.\n\nSnyder's self monitoring scale was developed in 1974. It measures whether or not an individual has the will and ability to change how they are perceived by utilizing impression management in various social interactions. The score is based on twenty five questions that the individual answers according to their thought process and is used to determine how an individual may manipulate nonverbal signals and adjusts theirs actions according to a situation. The score is calculated based on how the individuals responds to True and False questions.\n\nLow self-monitors tend to exhibit expressive controls congruent with their own internal states; i.e. beliefs, attitudes, and dispositions regardless of social circumstance. Low self-monitors are often less observant of social context and consider expressing a self-presentation dissimilar from their internal states as a falsehood and undesirable. People who are unwilling to self-monitor and adjust their behavior accordingly are often aggressive, uncompromising, and insistent with others. This may make them more prone to condemnation, rejection, and the possible consequent feelings of anger, anxiety, guilt, low self-concept, isolation, and depression. Even the occasional indiscretion can make social situations awkward, and could result in the loss of a friend, co-worker, client, or even job. Those who are willing to adjust their behavior will often find that others are more receptive, pleasant, and benevolent towards them.\n\nIndividuals who closely monitor themselves are categorized as high self-monitors. They often behave in a manner that is highly responsive to social cues and their situational context. High self-monitors can be thought of as social pragmatists who project images in an attempt to impress others and receive positive feedback. In comparison to low self-monitors, high self monitors participate in more expressive control and have concern for situational appropriateness. As these individuals are willing to adjust their behavior, others may perceive them to be more receptive, pleasant, and benevolent towards them.\n\nA low score on the self-monitoring scale can range anywhere from 0-8 and a high score ranges from 15-22. Some traits of high self-monitors include readily and easily modifying their behavior in response to the demands of the situation, whereas low self-monitors care little about modifying their behavior in response to the situation and tend to maintain the same opinions and attitudes regardless of the situation. High self-monitors find it much easier to modify their behavior based on the situation than low self-monitors do. High self-monitors would be more likely to change their beliefs and opinions depending on who they are talking to, while low self-monitors would tend to be consistent throughout all situations. This has been studied mainly in correspondence with relationships. Compared to low self-monitors, high self-monitors will have more dating and sexual partners, are more interested in having sex with people they are not in love with, and are more likely to have had sex with someone only once, as well as be more likely to deceive potential romantic partners. High self-monitors are more likely to choose a romantic partner who is attractive but unsociable, while low self-monitors are more likely to choose a partner who is unattractive but sociable. High self-monitors are also more likely to take on leadership positions than low self-monitors.\n\nDifferences in individuals' propensity for self-monitoring have a heritable component, but the likelihood that a person becomes a high (or low) self-monitor also varies between social contexts and groups. For example, on average, sexual minorities (such as gay men, lesbians, and bisexuals) are more likely to be high self-monitors than their otherwise similar heterosexual counterparts, but this difference exists primarily in geographic areas where the stigma against minority sexual orientations is strong. In the United States, for example, differences in self-monitoring based on sexual orientation have been documented in rural areas and small towns but do not seem to exist in the context of large cities, which tend to be more tolerant of minority sexual orientations.\n\nSelf-monitoring is useful for students from preschool to adulthood and can be taught to individuals at a variety of levels of cognitive functioning. Self-monitoring interventions foster independent functioning, which allows individuals with disabilities to rely less on prompts from others. Self-monitoring interventions are among the most flexible, useful, and effective strategies for students with academic and behavioral difficulties. They have demonstrated efficacy for targeting a range of academic abilities, self-help skills, behavioral problems, and social behaviors. Students with behavioral and academic difficulties typically have limited awareness and understanding of their own behavior and its effects on others. Self-monitoring interventions equip students to recognize and keep track of their own behavior. Using these strategies, students can learn to identify and increase positive, pro-social behaviors, the behaviors necessary for success in general education settings. Self-monitoring strategies are individualized plans used to increase independent functioning in academic, behavioral, self-help, and social areas. Rather than focusing on reducing a student’s undesired behavior, self-monitoring strategies develop skills that lead to an increase in appropriate behavior. When self-monitoring skills increase, corresponding reductions in undesired behaviors often occur, even without direct intervention. This collateral behavior change allows teachers and parents to address multiple behaviors with one efficient intervention.\nThe five steps involved in planning a self-monitoring intervention:\n\nIt's been argued that individualism should influence self-monitoring. Cultures high on individualism focus on the self, not others. In individualistic cultures, knowing the context is not necessary to predict others' behavior, thus people from individualistic cultures are more likely to be low self-monitors. Cultures low on individualism (i.e., collectivist cultures), in contrast, value conformity to ingroups and group memberships. In collectivistic cultures, knowing the context and social status of the other person is essential to predicting his or her behavior. Thus, people from collectivistic cultures are more likely to be high self-monitors.\n\nIt has been shown that there is a significant relation between an individual's performance at his job and his or her ability to change their self-presentation in order to most adapt to the situation. Self-monitoring was most important during early tenure. This history of finding individual difference variables that relate to job performance has been unsuccessful. Some of the reasons why it is difficult to use individual difference variables to predict job performance is because there is failure to consider contextual effects such as informational influence and pressures for conformity. Other difficulties are a result from attempting to use personality measures without having a good understanding of the nature of the job and the individual's development in the job. This results in the individual differences being assessed without fully understanding why they should affect job performance directly or how they may affect an individual's performance when you take into consideration increased job knowledge that an individual may gain through experience.\n\nOne case that shows how success could be related to individual predispositions is in organizations where individuals hold boundary-spanning positions. Boundary spanners purpose is to filter and transfer information across organizational boundaries. The individuals that are responsible for this transfer of information may be in a roles both inside and outside the organization. Therefore, they should be able to respond to social and informational stimuli, inside and outside the organization. The nature of this job makes it likely that an individual's performance in this role is likely to be influenced the degree to which that person can perceive, understand and adapt to different social situations as appropriate. In essence, an individual who is a high self-monitor would be better at responding to different social cues and hence be more equipped to transfer information effectively across organizational borders and consequently a higher performer.\n\nOver time, however, the competitive advantage that high self monitors have over low self monitors reduced as job knowledge increases through experience and poor performers leave boundary spanning roles.\n\nRiggio et al., (1982) suggests that the self-monitoring as monitored by the self-monitoring scale is a multidimensional construct and is composed of many elements central to social interaction. It was determined that the elements of self-monitoring appear to be \"charisma\", \"performance\", and \"social sensitivity\". Therefore, it is determinable that those with high levels of self-monitoring had greater skill at navigating and bridging social situations while in contrast, those with lower levels of self-monitoring may struggle in the same situations.\n\nThe differences between how high self monitors and low self monitors treat relationships and social situations stem from the differences in what they seek to gain out of their social life and their understanding of self. High self-monitors view their self as a product of social interactions and their own adaptability in various social settings. In contrast, low self-monitors view their self as a product of personal dispositions and their effects on social situations. High self-monitors look for friends with similar activity preferences, while low self-monitors look for friends with similar attitudes. High self-monitors also generally end up becoming close to other high self-monitors, and vice versa with low self-monitors.\n\nHigh self-monitors look for a social context that allows flexibility and adaptability to play a multitude of roles without role conflict. High self-monitors are more likely to believe in the idea that there are multiple people one can love, and focus on attributes such as physical attractiveness, sex appeal, social status, and financial resources. In turn, the attachments high self-monitors form with their significant others are more avoidant, and they can feel uncomfortable with significant others that have higher levels of intimacy than themselves. Low self-monitors on the other hand look for a social context that gives them the freedom and security to express their emotions and dispositions freely without any interpersonal conflicts. They are more likely to believe in the idea of “one true love”, and look for attributes such as personality desirability, similarity of values and beliefs, and other dispositions like honesty, responsibility, and kindness. This leads to more secure relationships being formed, and level of intimacy is not a problem.\n\nThere is a strong connection between self-monitoring and self-presentation, as it's proven that people who are high self-monitoring have greater cognitive access to self-presentation related concepts than people who are low self-monitoring. Through a 100-person experiment, it was found out that high-self monitors more quickly linked positive personality traits to themselves following exposure to impression-related words, proving high self-monitors possess a heightened capacity to cognitively process self-presentation information. High self-monitors rely on social information to guide their self-presentations since they vary their presentations based on different social cues. They are also, compared to low self-monitors, more likely to recall personal information about an upcoming interaction partner, are better able to judge emotional displays, are more skilled at decoding nonverbal behaviors, show better performance on interpersonal perception tasks, are more focused on their interaction partners, and they seek out and consider more information about an audience when trying to convey a particular identity.\n\nEssentially, Tyler, Kearns and McIntyres argue that high self-monitoring people are more likely to seek out social cues and information through interactions, following which they will employ this information in their behaviour, hence portraying a self presentation or image that they want to. Additionally, they are more sensitive to social cues and social information. People low in self-monitoring, however, would behave as themselves in most cases and hence not have an option in the self-presentation that they project, as well as being less sensitive to social information present around them.\n\nThere are several theories within social psychology that are closely related to the self-monitoring construct. Icek Ajzen argues that subjective norms are an important antecedent to determining behavioral intention in the theory of reasoned action/theory of planned behavior. High self-monitors tend to weigh subjective norms more heavily than low self-monitors. Studies that evaluate private attitudes and public actions include Ajzen, Timko and White, 1982; and DeBono and Omoto, 1993. Informational cascades theory is related to observation learning theory which was developed by Bikhchandani, S.; Hirshleifer, D. and Welch, I. (1992) and describes how people will follow, sometimes blindly, the actions of others. The self-monitoring construct would identify that high self-monitors may be more susceptible to informational cascades and herd mentality. This can be a problem if a culture of groupthink is part of the organizations decision making process. High self-monitors are more motivated to attain high social status than low self-monitors. Research drawing on the elaboration likelihood model suggests that high self-monitors, more than low self-monitors, react favorably to peripheral processing of advertising images consistent with high social status.\n\n\n"}
{"id": "341486", "url": "https://en.wikipedia.org/wiki?curid=341486", "title": "Stalking horse", "text": "Stalking horse\n\nA stalking horse is a figure that tests a concept with someone or mounts a challenge against someone on behalf of an anonymous third party. If the idea proves viable or popular, the anonymous figure can then declare its interest and advance the concept with little risk of failure. If the concept fails, the anonymous party will not be tainted by association with the failed concept and can either drop the idea completely or bide its time and wait until a better moment for launching an attack.\n\nIn hunting, it refers to a horse, or a figure of a horse, behind which a hunter hides when stalking game.\n\nThe term \"stalking horse\" originally derived from the practice of hunting, particularly of wildfowl. Hunters noticed that many birds would flee immediately on the approach of humans, but would tolerate the close presence of animals such as horses and cattle.\n\nHunters would therefore slowly approach their quarry by walking alongside their horses, keeping their upper bodies out of sight until the flock was within firing range. Animals trained for this purpose were called \"stalking horses\". Sometimes mobile hides are used for a similar purpose.\n\nAn example of the practice figures in the 1972 film \"Jeremiah Johnson\", when Johnson and Chris Lapp (\"Bear Claw\") are hunting elk in the Rockies:\n\n<poem>\"Jeremiah\": Wind's right, but he'll just run soon as we step out of these trees.\n\"Bear Claw\": Trick to it. Walk out on this side of your horse.\n\"Jeremiah\": What if he sees our feet?\n\"Bear Claw\": Elk don't know how many feet a horse has!</poem>\n\nThe term began appearing in Anglophone newspapers in the late 18th century. It was used to describe the Protestant branch of Christianity as \"a stalking horse to power\" in Ireland in 1785. Early examples of its use in a political context occurred in the London newspaper \"The Observer\" in 1796, the \"Connecticut Courant\" in the USA in 1808 and in the \"Sydney Morning Herald\" in Australia in 1822.\n\nThe expression is generally used in politics and business. In politics, the circumstances may include an attempt to bring down a powerful leader, usually by members of their own party. They may also include the presentation of a bill by a minor party representative, who is also acting in the interests of a silent partner such as a larger, more risk averse, political party. In business, the circumstances are an attempt at testing the market for a potential (hostile) takeover of a business. In each case, there is the clear understanding that the anonymous party, whether a company or an individual, has a valuable reputation that could be damaged by the failure. The stalking horse is an exercise in assessing accurately the degree of risk, so that a full-blooded challenge is only mounted by the main party when there is a real likelihood of success.\n\nThe loser in the exercise appears to be the stalking horse. If the idea is viable or popular, the stalking horse person will be sidelined and the anonymous figure will take over the concept themselves. If the concept proves unpopular, the stalking horse will suffer any negative reaction. The understanding is that the anonymous party is a major player, perhaps only a little weaker than the target itself, and the stalking horse is a minor figure who has little or no reputation to lose. The anonymous figure is not sufficiently powerful, or does not have sufficient confidence in that power, to risk a direct attack first off, and the stalking horse is a form of distraction tactic to enable better positioning.\n\nIn politics, the stalking horse figure can expect patronage from the senior figure they are assisting. In business, an associated company that acts as a stalking horse may be given a share in the contracts or the market share that will result from the demise of the business rival. The loyalty in volunteering, or agreeing to be \"volunteered\", will ensure that their name becomes known to those with power and should guarantee help in advancing their interests. As a weaker player, they can afford to wait a while for the due reward.\n\nAlternatively, the \"horse\" may be acting in a more altruistic and self-sacrificial manner, knowing that there is no possibility of realistic reward from the third party for the exercise, and instead being motivated by duty or loyalty to do so for the greater good of the party, organization, or cause to which they both belong. In this case, the \"horse\" will probably not be a young person hoping for advancement, but an older figure at the end of their career, who volunteers as a gesture of gratitude for all the benefits they believe the cause has given them, or as a chance to go out in a blaze of glory.\n\nIn the event of failure, the anonymous party is seen as being sufficiently powerful to protect the \"horse\" from any real retribution on the part of the target, particularly since the anonymity will allow the third party to step in and pretend to be an honest broker between the \"horse\" and the target. This is a further opportunity to enhance the reputation of the third party and boost their status at the expense of the target. If the exercise is viable, the third party gains power immediately, but even if it fails it engineers an opportunity to resolve a stalemate and enhance the contender's reputation, so that ultimate success is another step nearer, to the benefit of both the third party and the \"horse\", who expects to slipstream in its wake.\n\nOne related concept is the smoke screen. Like a stalking horse, smoke screens are used to screen and mask an attack. In the literal and genuine form, the smoke screen is still a device used in warfare (in defence as well as attack), but the term is also commonly used as a metaphor. A stalking horse would be a particular form of smoke screen.\n\nAnother concept is that of kite-flying. The stalking horse pretends to be interested in a concept themselves, but in reality they are testing an idea for another. Likewise, in journalism, the term \"flying a kite\" takes the metaphor of the child's toy to mean advancing a concept in which one has no personal belief, or for which one has no reliable evidence, as a similar exercise in \"testing the waters\". Another similar metaphor is that of a trial balloon. Different examples may provoke different responses. Some may be directed to play to the readers themselves. The idea is \"to provoke a response where otherwise there would be none\". Like the stalking horse, the means is to use a spurious debate to provoke a real one. The difference is that the concept is advanced, not an individual. In one form of \"flying a kite\", a journalist claims to be acting on a behalf of a real but anonymous person, while in reality they are acting for themselves; this would be the opposite of the stalking horse. \n\nAnother concept is collusion. The difference here is that collusion usually refers to the situation of the first and third parties both declaring themselves openly to the target, but each pretends to be independent of anyone else and acting solely for themselves, whilst in reality they are acting in concert, in joint enterprise and to mutual advantage, at the expense of the target. If one party acts aggressively and the other sympathetically towards the target, it may be an example of good cop/bad cop. In the stalking horse scenario, the first and third parties are still acting in concert and in joint enterprise and still at the expense of the target, but only the first party, the \"horse\", is openly dealing with the target. In addition, they are not acting to immediate mutual advantage; rather, they are acting to advantage only the third party (the anonymous party), who, at a later date, should in turn give reward to the first party (the \"horse\"). \n\nAnother related idiom is that of the puppet-master. One person (the \"horse\") dances like a puppet on the stage, but another (the anonymous figure) is the one who is actually pulling the strings, unseen by all. The stalking horse appears to be acting for and as themselves, but there are others in the shadows. The difference is that the éminence grise or puppet-master is definitely controlling the puppet, but the stalking horse may not always be acting on the orders of, or to the benefit of, a particular individual; they may instead be acting for a cause, in the hope that some individual will be inspired to enter the fray and take over. \n\nThe concept of a \"sacrificial pawn\" is also in some ways similar to that of the stalking horse. In the game of chess, a pawn may be advanced in the knowledge that it will definitely be lost, but will, in so doing, force out an enemy piece of much higher value and make that piece much more susceptible to attack. This image is also in common usage as an metaphor. The difference with the stalking horse is that not only is the outcome not known at the outset but, furthermore, that it cannot reasonably be estimated without a proper reconnaissance. Therefore, unlike the pawn, the horse might have a good chance of survival. Either way, the \"horse\" will not benefit from the initial exercise.\n\nThe phenomenon occurs particularly in politics, where a junior politician acts as the stalking horse to promote the interests of a senior politician, who remains unseen in case the actions would damage him or her but nevertheless wants to provoke a debate or challenge to a party colleague. In some cases, stalking horses are not working for a particular individual but may wish to provoke a response that leads others to join in. In politics, the truth about the relationship between an individual stalking horse and a candidate may never be known, as both sides may claim that the (alleged) stalking horse acted without the agreement of anyone else.\n\nFor example, in Britain, the elderly and largely unknown back-bench politician Anthony Meyer challenged and helped to bring about the eventual resignation of Margaret Thatcher in the Conservative Party leadership.\n\nIn American politics, George W. Romney believed that Nelson Rockefeller had used him as a stalking horse in the 1968 Republican Party presidential primaries by promising support, then not providing it and hinting at his own entry into the campaign.\n\nAnother suspected example: After the 2016 presidential election, Green Party candidate Jill Stein demanded recounts in Michigan, Wisconsin and Pennsylvania (all of which Donald Trump won in close contests), presumably for Hillary Clinton.\n\nIn bankruptcy, a stalking horse bid is a first, favorable bid solicited by the bankrupt company's creditors strategically to prevent low-ball offers.\n\n"}
{"id": "18696734", "url": "https://en.wikipedia.org/wiki?curid=18696734", "title": "Stellation diagram", "text": "Stellation diagram\n\nIn geometry, a stellation diagram or stellation pattern is a two-dimensional diagram in the plane of some face of a polyhedron, showing lines where other face planes intersect with this one. The lines cause 2D space to be divided up into regions. Regions not intersected by any further lines are called elementary regions. Usually infinite regions are excluded from the diagram, along with any infinite portions of the lines. Each elementary region represents a top face of one cell, and a bottom face of another.\n\nA collection of these diagrams, one for each face type, can be used to represent any stellation of the polyhedron, by shading the regions which should appear in that stellation.\n\nA stellation diagram exists for every face of a given polyhedron. In face transitive polyhedra, symmetry can be used to require all faces have the same diagram shading. Semiregular polyhedra like the Archimedean solids will have different stellation diagrams for different kinds of faces.\n\n\n\n"}
{"id": "845760", "url": "https://en.wikipedia.org/wiki?curid=845760", "title": "Traditional authority", "text": "Traditional authority\n\nTraditional authority (also known as traditional domination) is a form of leadership in which the authority of an organization or a ruling regime is largely tied to tradition or custom. The main reason for the given state of affairs is that it 'has always been that way'.\n\nIn sociology, the concept of traditional authority (domination) comes from Max Weber's tripartite classification of authority, the other two forms being charismatic authority and rational-legal authority. All of those three domination types represent an example of his ideal type concept. Weber noted that in history those ideal types of domination are always found in combinations.\n\nIn traditional authority, the legitimacy of the authority comes from tradition; in charismatic authority from the personality and leadership qualities of the individual; and in rational-legal authority from powers that are bureaucratically and legally attached to certain positions.\n\nWeber derives the traditional domination from patriarchys and their households—in other words, from the ancient tradition of family (the authority of a master over his household). The master is designated in accordance with the rules of inheritance. He has no administrative staff nor any machinery to enforce his will by force alone; he depends on the willingness of the group members to respect his authority. Those members stand in personal relations to him. They obey him based on the belief that this is their duty sanctioned by immemorial tradition and on feeling of filial piety for the person of the master.\n\nPatrimonial government occurs when the ruler's household expands with the household administration giving rise to governmental offices. All officials are personal dependents or favourites of the ruler, appointed by him. Their interactions with the ruler are based on paternal authority and filial dependence. The officials treat their work as a personal service to the ruler. The ruler has complete control over the officials; he empowers them from case to case, assigns specific tasks, promotes and demotes. They have no rights, rather they have privileges granted and withdrawn by the ruler. It is rare to discover any clear and stable hierarchy and responsibility in the deluge of official titles of most patrimonial administrations.\n\nMilitary force is an important instrument of a patrimonial rule. Weber distinguished five types of military organisations. In all of those cases the military is a tool of the ruler, solely for his use—but he is responsible for its upkeep (equipment, maintenance and wages).\n\nWith the growth of the territory organized and more independent administrative staff and military force became a necessity. This usually leads to decentralisation, and some individuals gain more independence in the form of certain rights (for example, the right to inheritance and marriage without the consent of the rulers, to be judged by independent courts instead of officials of the royal household, etc.).\n\nOne of the best examples of almost pure type of patrimonialism is ancient Egypt, where the population was entirely dependent upon the control of the waterways (Nile River). This facilitated the creation of centralised government. When the royal household required it, the individual had to perform the public duties, such as participate in labor-intensive project (rising of the pyramids). Thus the whole country was in fact the patriarchal household of the pharaoh.\n\nWhen land is given to military or officials for the performance of their duties, their independence increases and the power of the ruler weakens (consider the Mameluks and their rebellions, or the difference between Chinese Confucian literati who were never able to overthrow the power of the emperor and European knights who evolved into powerful aristocracy in many cases vastly limiting the power of the kings (especially in the Polish-Lithuanian Commonwealth)).\n\nPatrimonial dominance has often prevailed in the Orient, where land remained in the control of the ruler. However, in the Occident the ruler lost control of the lands given to the nobility, which according to Weber was a major reason for patrimonialism being replaced by feudalism.\n\nFeudalism when compared to patrimonalism, has one major similarity and several important differences.\n\nThe similarity is that both are based on tradition and have powerful rulers who grant rights in return for military and administrative services.\n\nThe differences are important for the subtler distinction:\n\nMost of the representatives of any dynasty ruling for more than one generation (kings, emperors, sultans, etc.) would fall into that category. Thus majority monarchies and some autocracies, oligarchies, and theocracies would be ruled by traditional leaders.\n\nOften male head of a common family should be considered a traditional leader. This could also be the case in a family-owned business, if its director and other leader positions are chosen based on family ties and/or age.\n\n\n"}
{"id": "457857", "url": "https://en.wikipedia.org/wiki?curid=457857", "title": "Traditional medicine", "text": "Traditional medicine\n\nTraditional medicine (also known as indigenous or folk medicine) comprises medical aspects of traditional knowledge that developed over generations within various societies before the era of modern medicine. The World Health Organization (WHO) defines traditional medicine as \"the sum total of the knowledge, skills, and practices based on the theories, beliefs, and experiences indigenous to different cultures, whether explicable or not, used in the maintenance of health as well as in the prevention, diagnosis, improvement or treatment of physical and mental illness\".\n\nIn some Asian and African countries, up to 80% of the population relies on traditional medicine for their primary health care needs. When adopted outside its traditional culture, traditional medicine is often considered a form of alternative medicine. Practices known as traditional medicines include traditional European medicine, traditional Chinese medicine, traditional Korean medicine, traditional African medicine, Ayurveda, Siddha medicine, Unani, ancient Iranian Medicine, Iranian (Persian), Islamic medicine, Muti, and Ifá. Scientific disciplines which study traditional medicine include herbalism, ethnomedicine, ethnobotany, and medical anthropology.\n\nThe WHO notes, however, that \"inappropriate use of traditional medicines or practices can have negative or dangerous effects\" and that \"further research is needed to ascertain the efficacy and safety\" of several of the practices and medicinal plants used by traditional medicine systems. Ultimately, the World Health Organization has implemented a nine year strategy to \"support Member States in developing proactive policies and implementing action plans that will strengthen the role traditional medicine plays in keeping populations healthy.\"\n\nIn the written record, the study of herbs dates back 5,000 years to the ancient Sumerians, who described well-established medicinal uses for plants. In Ancient Egyptian medicine, the Ebers papyrus from c. 1552 BC records a list of folk remedies and magical medical practices. The Old Testament also mentions herb use and cultivation in regards to Kashrut.\n\nMany herbs and minerals used in Ayurveda were described by ancient Indian herbalists such as Charaka and Sushruta during the 1st millennium BC. The first Chinese herbal book was the \"Shennong Bencao Jing\", compiled during the Han Dynasty but dating back to a much earlier date, which was later augmented as the \"Yaoxing Lun\" (\"Treatise on the Nature of Medicinal Herbs\") during the Tang Dynasty. Early recognised Greek compilers of existing and current herbal knowledge include Pythagoras and his followers, Hippocrates, Aristotle, Theophrastus, Dioscorides and Galen.\n\nRoman sources included Pliny the Elder's \"Natural History\" and Celsus's \"De Medicina\". Pedanius Dioscorides drew on and corrected earlier authors for his \"De Materia Medica\", adding much new material; the work was translated into several languages, and Turkish, Arabic and Hebrew names were added to it over the centuries. Latin manuscripts of \"De Materia Medica\" were combined with a Latin herbal by Apuleius Platonicus (\"Herbarium Apuleii Platonici\") and were incorporated into the Anglo-Saxon codex \"Cotton Vitellius C.III\". These early Greek and Roman compilations became the backbone of European medical theory and were translated by the Persian Avicenna (Ibn Sīnā, 980–1037), the Persian Rhazes (Rāzi, 865–925) and the Jewish Maimonides.\n\nArabic indigenous medicine developed from the conflict between the magic-based medicine of the Bedouins and the Arabic translations of the Hellenic and Ayurvedic medical traditions. Spanish indigenous medicine was influenced by the Arabs from 711 to 1492. Islamic physicians and Muslim botanists such as al-Dinawari and Ibn al-Baitar significantly expanded on the earlier knowledge of materia medica. The most famous Persian medical treatise was Avicenna's \"The Canon of Medicine\", which was an early pharmacopoeia and introduced clinical trials. The \"Canon\" was translated into Latin in the 12th century and remained a medical authority in Europe until the 17th century. The Unani system of traditional medicine is also based on the \"Canon\".\n\nTranslations of the early Roman-Greek compilations were made into German by Hieronymus Bock whose herbal, published in 1546, was called \"Kreuter Buch\". The book was translated into Dutch as \"Pemptades\" by Rembert Dodoens (1517–1585), and from Dutch into English by Carolus Clusius, (1526–1609), published by Henry Lyte in 1578 as \"A Nievve Herball\". This became John Gerard's (1545–1612) \"Herball or General Hiftorie of Plantes\". Each new work was a compilation of existing texts with new additions.\n\nWomen's folk knowledge existed in undocumented parallel with these texts. Forty-four drugs, diluents, flavouring agents and emollients mentioned by Dioscorides are still listed in the official pharmacopoeias of Europe. The Puritans took Gerard's work to the United States where it influenced American Indigenous medicine.\n\nFrancisco Hernández, physician to Philip II of Spain spent the years 1571–1577 gathering information in Mexico and then wrote \"Rerum Medicarum Novae Hispaniae Thesaurus\", many versions of which have been published including one by Francisco Ximénez. Both Hernandez and Ximenez fitted Aztec ethnomedicinal information into the European concepts of disease such as \"warm\", \"cold\", and \"moist\", but it is not clear that the Aztecs used these categories. Juan de Esteyneffer's \"Florilegio medicinal de todas las enfermedas\" compiled European texts and added 35 Mexican plants.\n\nMartín de la Cruz wrote an herbal in Nahuatl which was translated into Latin by Juan Badiano as \"Libellus de Medicinalibus Indorum Herbis\" or \"Codex Barberini, Latin 241\" and given to King Carlos V of Spain in 1552. It was apparently written in haste and influenced by the European occupation of the previous 30 years. Fray Bernardino de Sahagún's used ethnographic methods to compile his codices that then became the \"Historia General de las Cosas de Nueva España\", published in 1793. Castore Durante published his \"Herbario Nuovo\" in 1585 describing medicinal plants from Europe and the East and West Indies. It was translated into German in 1609 and Italian editions were published for the next century.\n\nIn 17th and 18th-century America, traditional folk healers, frequently women, used herbal remedies, cupping and leeching. Native American traditional herbal medicine introduced cures for malaria, dysentery, scurvy, non-venereal syphilis, and goiter problems. Many of these herbal and folk remedies continued on through the 19th and into the 20th century, with some plant medicines forming the basis for modern pharmacology.\n\nThe prevalence of folk medicine in certain areas of the world varies according to cultural norms. Some modern medicine is based on plant phytochemicals that had been used in folk medicine. Researchers state that many of the alternative treatments are \"statistically indistinguishable from placebo treatments\".\n\nIndigenous medicine is generally transmitted orally through a community, family and individuals until \"collected\". Within a given culture, elements of indigenous medicine knowledge may be diffusely known by many, or may be gathered and applied by those in a specific role of healer such as a shaman or midwife. Three factors legitimize the role of the healer – their own beliefs, the success of their actions and the beliefs of the community. When the claims of indigenous medicine become rejected by a culture, generally three types of adherents still use it – those born and socialized in it who become permanent believers, temporary believers who turn to it in crisis times, and those who only believe in specific aspects, not in all of it.\n\nTraditional medicine may sometimes be considered as distinct from folk medicine, and the considered to include formalized aspects of folk medicine. Under this definition folk medicine are longstanding remedies passed on and practised by lay people. Folk medicine consists of the healing practices and ideas of body physiology and health preservation known to some in a culture, transmitted informally as general knowledge, and practiced or applied by anyone in the culture having prior experience.\n\nMany countries have practices described as folk medicine which may coexist with formalized, science-based, and institutionalized systems of medical practice represented by conventional medicine. Examples of folk medicine traditions are traditional Chinese medicine, traditional Korean medicine, Arabic indigenous medicine, Uyghur traditional medicine, Japanese Kampō medicine, traditional Aboriginal bush medicine, and Georgian folk medicine, among others.\n\nA home remedy (sometimes also referred to as a granny cure) is a treatment to cure a disease or ailment that employs certain spices, vegetables, or other common items. Home remedies may or may not have medicinal properties that treat or cure the disease or ailment in question, as they are typically passed along by laypersons (which has been facilitated in recent years by the Internet). Many are merely used as a result of tradition or habit or because they are effective in inducing the placebo effect. One of the more popular examples of a home remedy is the use of chicken soup to treat respiratory infections such as a cold or mild flu. Other examples of home remedies include duct tape to help with setting broken bones; and duct tape or superglue to treat plantar warts; and Kogel mogel to treat sore throat. In earlier times, mothers were entrusted with all but serious remedies. Historic cookbooks are frequently full of remedies for dyspepsia, fevers, and female complaints. Components of the aloe vera plant are used to treat skin disorders. Many European liqueurs or digestifs were originally sold as medicinal remedies. In Chinese folk medicine, medicinal congees (long-cooked rice soups with herbs), foods, and soups are part of treatment practices.\n\nAlthough 130 countries have regulations on folk medicines, there are risks associated with the use of them. It is often assumed that because supposed medicines are herbal or natural that they are safe, but numerous precautions are associated with using herbal remedies.\n\nEndangered animals, such as the slow loris, are sometimes killed to make traditional medicines.\n\nShark fins have also been used in traditional medicine, and although its use has not been proven, it is hurting shark populations and their ecosystem.\n\n"}
{"id": "3445285", "url": "https://en.wikipedia.org/wiki?curid=3445285", "title": "Universal value", "text": "Universal value\n\nA value is a universal value if it has the same value or worth for all, or almost all, people. Spheres of human value encompass morality, aesthetic preference, human traits, human endeavour, and social order. Whether universal values exist is an unproven conjecture of moral philosophy and cultural anthropology, though it is clear that certain values are found across a great diversity of human cultures, such as primary attributes of physical attractiveness (e.g. youthfulness, symmetry) whereas other attributes (e.g. slenderness) are subject to aesthetic relativism as governed by cultural norms. This objection is not limited to aesthetics. Relativism concerning morals is known as moral relativism, a philosophical stance opposed to the existence of universal moral values. \n\nThe claim for universal values can be understood in two different ways. First, it could be that something has a universal value when everybody \"finds\" it valuable. This was Isaiah Berlin's understanding of the term. According to Berlin, \"...universal values...are values that a great many human beings in the vast majority of places and situations, at almost all times, do in fact hold in common, whether consciously and explicitly or as expressed in their behaviour...\" Second, something could have universal value when all people have \"reason\" to believe it has value. Amartya Sen interprets the term in this way, pointing out that when Mahatma Gandhi argued that non-violence is a universal value, he was arguing that all people have \"reason\" to value non-violence, not that all people \"currently\" value non-violence. Many different things have been claimed to be of universal value, for example, fertility, pleasure, and democracy. The issue of whether anything is of universal value, and, if so, what that thing or those things are, is relevant to psychology, political science, and philosophy, among other fields.\n\nPhilosophical study of universal value addresses questions such as the meaningfulness of universal value or whether universal values exist.\n\nSociological study of universal value addresses how such values are formed in a society.\n\nS. H. Schwartz, along with a number of psychology colleagues, has carried out empirical research investigating whether there are universal values, and what those values are. Schwartz defined 'values' as \"conceptions of the desirable that influence the way people select action and evaluate events\". He hypothesised that universal values would relate to three different types of human need: biological needs, social co-ordination needs, and needs related to the welfare and survival of groups. Schwartz's results from a series of studies that included surveys of more than 25,000 people in 44 countries with a wide range of different cultural types suggest that there are fifty-six specific universal values and ten types of universal value. Schwartz's ten types of universal value are: power, achievement, hedonism, stimulation, self-direction, universalism, benevolence, tradition, conformity, and security. Below are each of the value types, with the specific related values alongside: \nSchwartz also tested an eleventh possible universal value, 'spirituality', or 'the goal of finding meaning in life', but found that it does not seem to be recognised in all cultures.\n\n\n"}
{"id": "59020", "url": "https://en.wikipedia.org/wiki?curid=59020", "title": "Washboard (musical instrument)", "text": "Washboard (musical instrument)\n\nThere are three general ways of deploying the washboard for use as an instrument. The first, mainly used by American players like Washboard Chaz of the Washboard Chaz Blues Trio and Ralf Reynolds of the Reynolds Brothers Rhythm Rascals, is to drape it vertically down the chest. The second, used by European players like David Langlois of the Blue Vipers of Brooklyn, Ben Turner of Piedmont Bluz, and Stephane Seva of Paris Washboard, is to hold it horizontally across the lap, or, for more complex setups, to mount it horizontally on a purpose-built stand. The third (and least common) method, used by Washboard Sam, Súle Greg Wilson of the Carolina Chocolate Drops and Sankofa Strings, and Deryck Guyler, is to hold it in a perpendicular orientation between the legs while seated, so that both sides of the board might be played at the same time.\n\nThere is a Polish traditional jazz festival and music award named \"Złota Tarka\" (Golden Washboard). Washboards, called \"zatulas\", are also occasionally used in Ukrainian folk music.\n\nThe washboard as a percussion instrument ultimately derives from the practice of hamboning as practiced in West Africa and brought to the new world by African slaves. This led to the development of Jug bands which used jugs, spoons, and washboards to provide the rhythm. Jug bands became popular in the 1920s.\n\nThe frottoir, also called a Zydeco rub-board, is a mid-20th century invention designed specifically for Zydeco music. It is one of the few musical instruments invented entirely in the United States and represents a distillation of the washboard into essential elements (percussive surface with shoulder straps). It was designed in 1946 by Clifton Chenier and fashioned by Willie Landry, a friend and metalworker at the Texaco refinery in Port Arthur, Texas. Clifton's brother Cleveland Chenier famously played this newly designed rubboard using bottle openers. Likewise, Willie's son, Tee Don Landry, continues the traditional hand manufacturing of rubboards in his small shop in Sunset, Louisiana, between Lafayette and Opelousas.\n\nIn 2010 Saint Blues Guitar Workshop launched an electric washboard percussion instrument called the Woogie Board.\n\nIn British Columbia, Canada, Tony McBride, known as \"Mad Fingers McBride\", performs with a group called The Genuine Jug Band. Tony is referred to as \"The Canadian Washboard King\". His percussion set-up was created by Douglas Fraser, of the same band. The washboard set-up was seen in Modern Drummer magazine, August 2014 edition.\n\nMusician Steve Katz famously played washboard with the Even Dozen Jug Band. His playing can be heard on the group's legendary self-titled Elektra recording from 1964. Katz reprised his washboard playing on \"Played a Little Fiddle\", a 2007 recording featuring Steve Katz, Stefan Grossman and Danny Kalb. Katz's washboard approach is notable as he plays the instrument horizontally. Additionally, Katz uses fingerpicks instead of thimbles.\nIn their earliest incarnations as The Quarrymen, The Beatles were a skiffle band, featuring Pete Shotton on washboard.\n\nDuring their early years, Mungo Jerry frequently featured washboard on stage and on record, played by Joe Rush.\n\nJim \"Dandy\" Mangrum, lead singer of Southern rock band Black Oak Arkansas, is well known for incorporating the washboard into many of the band's songs, notably \"When Electricity Came to Arkansas\". Self-taught Elizabeth Bougerol has made the washboard a key element of The Hot Sardines jazz band.\n\nCody Dickinson, a member of hill country blues bands the North Mississippi Allstars and Country Hill Revue plays an electrified washboard on a self-written track, \"Psychedelic Sex Machine\". The song is almost entirely centered around the sound of the washboard, captured by a small clip-on microphone. The sound is then sent through a wah-wah and other effects pedals to create a fresher, more innovative and up-to-date sound for the washboard. A frottoir is played with a stroking instrument (usually with spoon handles or a pair of bottle-openers) in each hand. In a 4-beat measure, the frottoir will be stroked 8 to 16 times. It plays more like a Latin percussion instrument, rather than as a drum. The rhythms used are often similar to those played on Guiro.\n\nActor Deryck Guyler was well known for his washboard-playing skills.\n\n\n"}
