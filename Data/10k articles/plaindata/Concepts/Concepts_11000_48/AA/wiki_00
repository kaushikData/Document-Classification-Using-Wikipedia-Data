{"id": "44766421", "url": "https://en.wikipedia.org/wiki?curid=44766421", "title": "Alison Turnbull Hopkins", "text": "Alison Turnbull Hopkins\n\nAlison Turnbull Hopkins (May 20, 1880 – March 18, 1951) was an American suffrage activist, known as one of the \"Silent Sentinels\" for her protests at the White House.\n\nAlison Low Turnbull was born in 1880, to Frank and Marion Louise Bates Turnbull, in Morristown, New Jersey. Her father was a naval officer. She was privately tutored and received no other schooling.\n\nAlison Turnbull Hopkins was on the executive board of the Congressional Union for Woman Suffrage and was New Jersey state chair for the National Woman's Party. She was also active in local Morristown charities and women's clubs, and was a member of Heterodoxy, a women's debating club based in New York City. As a Woman's Party leader, she campaigned against Woodrow Wilson in the 1916 presidential election, while her husband campaigned for Wilson. Among her notable political stunts was a speaking tour through Illinois in a car bearing the slogan \"Don't Vote for Wilson,\" following William Jennings Bryan on his lecture tour.\n\nOn Bastille Day in 1917, she was part of a group of suffrage protesters arrested at the White House. She was sentenced to jail at Occoquan Workhouse, but she was pardoned after three days by Woodrow Wilson, at the request of her husband. She returned to her White House protest after this incident, displaying signs that read \"We ask not pardon for ourselves but justice for all American women\" and \"Mr. President How long must women wait for liberty.\" Having spent any time at all in Occoquan Workhouse was a matter of pride among American suffragists; Mrs. Hopkins posed in her prison garb for publicity photos, lectured on the experience, and received honors as an imprisoned picket for several years after the event.\n\nAfter suffrage was won, Alison Turnbull Hopkins opened a dress shop in New York City, called Marjane Ltd.\n\nAlison Turnbull married John Appleton Haven Hopkins, an insurance executive and suffrage supporter, on October 8, 1901; she was his second wife. The couple lived in New York City, with a second residence at Featherleigh Farms, her father's estate in New Jersey. They had three children, John (b. 1903), Marion (b. 1904), and Douglas (b. 1908). The Hopkinses divorced in 1927. Alison Turnbull Hopkins died in 1951, age 70. Her niece was socialite Marjorie Oelrichs.\n"}
{"id": "744176", "url": "https://en.wikipedia.org/wiki?curid=744176", "title": "Backwardness", "text": "Backwardness\n\nBackwardness is a lack of progress by a person or group to some perceived cultural norm of advancement, such as for example traditional societies relative to modern scientific and technologically advanced industrialized societies.\nThe Backwardness Model is a theory of economic growth created by Alexander Gerschenkron. The model postulates that the more backward an economy is at the outset of economic development, the more likely certain conditions are to occur:\n\n\nThe backwardness model is often contrasted with the Rostovian take-off model developed by W.W. Rostow, which presents a more linear and structuralist model of economic growth, planning it out in defined stages. The two models are not mutually exclusive, however, and many countries appear to follow both models rather adequately.\n\nThorstein Veblen's 1915 \"Imperial Germany and the Industrial Revolution\" is an extended essay comparing the United Kingdom and Germany, and concluding that the slowing of growth in Britain and the rapid advances in Germany were due to the \"penalty of taking the lead\".\n\nBritish industry worked out, in a context of small competing firms, the best ways to produce efficiently. Germany's backwardness gave it an advantage in that the best practice could be adopted in large-scale firms.\n"}
{"id": "938544", "url": "https://en.wikipedia.org/wiki?curid=938544", "title": "Bill Romanowski", "text": "Bill Romanowski\n\nWilliam Thomas Romanowski (born April 2, 1966) is a former American football linebacker. He played in the National Football League (NFL) for the San Francisco 49ers, Philadelphia Eagles, Denver Broncos, and Oakland Raiders.\n\nRomanowski was born in Vernon, Connecticut. He graduated from Rockville High School in 1984 and Boston College in 1988 with academic honors, and was a Scanlan Award recipient.\n\nRomanowski went on to a 16-year career in the NFL, playing for the San Francisco 49ers (1988–1993), Philadelphia Eagles (1994–1995), Denver Broncos (1996–2001), and Oakland Raiders (2002–2003). After his career, he was listed by ESPN as the fifth dirtiest player in professional team sports history.\n\nRomanowski played 243 consecutive games during the 1988-2003 seasons, an NFL record that stood until Chris Gardocki broke it during the 2006 season, finishing his career with 265, (256 reg. season and 9 playoff games). He won 4 Super Bowl Championships, and played 5 Super Bowls (Super Bowl XXIII, Super Bowl XXIV, Super Bowl XXXII, Super Bowl XXXIII and Super Bowl XXXVII). \n\nDuring his 16-year career, Romanowski compiled 1,105 tackles, 39.5 sacks, 18 forced fumbles, and 18 interceptions, which he returned for a net total of 98 yards and 1 career touchdown. Romanowski was a Pro Bowl selection twice, in 1996 and 1998, both during his tenure with the Denver Broncos.\n\nRomanowski was involved in numerous altercations with both teammates and opponents. In 1995, while with the Eagles, he was ejected from a game — and subsequently fined $4,500 — for kicking Arizona Cardinals fullback Larry Centers in the head.\n\nTwo more incidents occurred during the 1997 season while he played for the Broncos. In the first, he was fined $20,000 after a helmet-to-helmet hit on then-Carolina Panthers quarterback Kerry Collins in a preseason game resulting in Collins sustaining a broken jaw. \n\nIn the second incident, Romanowski spat in the face of 49ers wide receiver J. J. Stokes in a regular-season game played in December on a Monday night in response to Stokes' taunting. \n\nTwo years later, while still with the Broncos, he was fined a total of $42,500 for three illegal hits plus a punch thrown at Kansas City Chiefs tight end Tony Gonzalez, and was also fined an undisclosed amount for throwing a football at Bryan Cox of the New York Jets, the ball hitting him in the crotch area.\n\nIn 2003, Romanowski attacked and injured one of his teammates, Marcus Williams, during a scrimmage. Williams, a backup tight end for the Oakland Raiders, was forced to retire after Romanowski confronted Williams after a play, ripped off his helmet, and crushed his eye socket with a punch. \n\nWilliams sued for damages of $3.4 million, arguing that Romanowski had been suffering from \"roid rage\" when he attacked him. Williams was awarded $340,000 for lost wages and medical expenses by a jury. Williams was quoted as saying he and his lawyers \"just wanted to prove what was right and wrong about football\". Williams's attorney said he was very pleased with the verdict.\n\nRomanowski has been accused of being racist at many points during his career and after retirement. Various media critics have pointed to his fines for actions including kicking Larry Centers in the head in 1995, spitting on San Francisco 49er receiver J.J. Stokes in 1997, and ripping Eddie George's helmet off in 2002, as evidence. \n\nRomanowski called Carolina Panthers starting quarterback Cam Newton \"boy\" in a tweet after Newton's team lost in Super Bowl 50 and Newton conducted a very brief press interview. He later apologized after he was accused of being racist.\n\nRomanowski co-authored an autobiography in 2005 titled \"Romo My Life on the Edge: Living Dreams and Slaying Dragons\". The book became a \"New York Times\" best selling book in 2005. It chronicles his childhood, college, and his playing times in the NFL. \n\nHe was featured on the cover of the Midway Games title \"\" and adds his voice as Bruno Battaglia, a linebacker in the game who wears his 53. He also appears in NCAA Football Series indirectly as LB #53 for the 1984 Boston College Eagles. \n\nIn 2006, he founded Nutrition 53, a nutritional supplement company. He is also a minority owner of NASCAR's Swan Racing in 2013. His own company Nutrition53 sponsored the team in 10 races in 2013.\n\nIn 2008, Romanowski was the defensive coordinator for the Piedmont High School (California) Highlanders Freshman Football team, where his son played.\n\nIn January 2009, Romanowski threw his name into the search for Mike Shanahan's replacement as the head coach of the Denver Broncos. Romanowski sent a 30-page PowerPoint presentation to team owner Pat Bowlen, but was not considered for the job. The job was ultimately given to Josh McDaniels.\n\nRomanowski and his wife were investigated for prescription drug fraud, though the charges were later dropped. Records seized by the government belonging to the Bay Area Laboratory Co-operative, later discovered to be the source of a designer steroid, indicate that he had used the anabolic steroid \"The Clear\" and synthetic testosterone ointment \"The Cream\" provided by BALCO since 2003. Romanowski admitted to staying a step ahead of NFL drug testing policies. In an October 16, 2005 appearance on \"60 Minutes\", Romanowski admitted to using steroids and human growth hormone that he received from Victor Conte, BALCO owner.\n\nRomanowski starred in the remake of \"The Longest Yard\" as one of the prison guards.\n"}
{"id": "7016721", "url": "https://en.wikipedia.org/wiki?curid=7016721", "title": "Conflict resolution research", "text": "Conflict resolution research\n\nConflict resolution is any reduction in the severity of a conflict. It may involve conflict management, in which the parties continue the conflict but adopt less extreme tactics; settlement, in which they reach agreement on enough issues that the conflict stops; or removal of the underlying causes of the conflict. The latter is sometimes called \"resolution\", in a narrower sense of the term that will not be used in this article. Settlements sometimes end a conflict for good, but when there are deeper issues – such as value clashes among people who must work together, distressed relationships, or mistreated members of one's ethnic group across a border – settlements are often temporary.\n\nUnproductive conflict; this can be done by analyzing the three stages executed during this type of communication: the early stage, the middle stage, and the later stage. Generally speaking, an argument's potential is determined within the first 3 minutes of exchange, setting the tone for the early stage. It is in this stage where cross-complaining becomes present – countering one's complaint with another complaint – a negative environment is immediately set and hostility is likely to be mirrored. Exiting the early stage and entering the middle stage, we can see the kitchen-sinking concept come into, \"Once a negative climate has been set, it is stoked by other unconstructive communication. People often engage in kitchen-sinking, in which everything except the kitchen sink is thrown into the argument\" (Wood 234). Constant interruptions, underdeveloped thoughts and the continuation of cross-complaining is apparent, leaving no time, breath or desire to form resolutions. Eventually, the conflict floats into the later stage. By this stage participants are exhausted from arguing and individual prosperity is emphasized over mutual solution; counterproposals are exchanged. As you can see, unproductive conflict communication truly is ineffective and puts relationships in jeopardy.\n\nSimilar to the unproductive conflict communication cycle, the constructive conflict communication cycle can be divided into the same 3 parts – early stage, middle stage and later stage. To establish a positive early stage, it is crucial to acknowledge and confirm one another's concerns. Critical listening, open-mindedness and respect create a supportive climate. Once the solid groundwork is set, participants can shift into the middle stage and begin agenda building, that is, clarifying the concerns while staying on topic; interruptions are kept at a minimum and recognition is reinforced. Last but not least, solutions will be proposed as the conflict enters the later stage, where respect shall be maintained, ideas are exchanged, and resolutions are formed. Contrary to a negative climate, this form of communication seeks to create a positive, more tolerable environment.\n\nNegotiation, the most heavily researched approach to conflict resolution, has mainly been studied in laboratory experiments, in which undergraduate participants are randomly assigned to conditions. These studies have mostly looked at antecedents of the strategies adopted by negotiators and the outcomes attained, including whether agreement is reached, the joint benefit to both parties, and the individual benefit to each party.\n\nHere are some of the more prominent findings from these studies (see Pruitt & Carnevale, 1993):\n\n\nRecent experiments have found cultural differences in negotiation behavior (Gelfand & Brett, 2004):\n\n\nThird parties often become involved in conflict resolution, either being called in by the disputants or acting on their own because the conflict annoys them or the community they serve. Two common forms of third-party intervention are arbitration and mediation. In arbitration, the third party listens to both sides and then renders a decision, which can be either binding or advisory. Most mediation consists of third-party assistance with negotiation. When conflict is severe and the disputants have difficulty talking calmly with each other, mediators can put them into contact and help them develop a cease-fire or settlement. If the disputants cannot or will not meet each other, mediators commonly become intermediaries and shuttle between them. Sometimes a chain of two intermediaries is necessary because there is no single individual who can communicate effectively with both sides.\n\nMediation has been studied in both the laboratory and the field. Research (see Kressel & Pruitt, 1989) suggests that:\n\n\nMore than 100 distinct mediator tactics have been identified. Among the tactics that have been shown to work well, in the sense of producing long-lasting agreements beneficial to both sides are:\n\n\nInvestigators have looked at the impact of several kinds of third-party interventions in international and ethno-political conflict, including peacekeeping, mediation, and problem solving workshops. Peacekeeping is the use of lightly armed troops to manage conflict in a war zone. Most peacekeeping has been done by the United Nations, drawing on the military forces of its members. Traditional peacekeeping involved enforcing ceasefires, but in the last few years, the peacekeeper's duties have grown to include such services as the delivery of humanitarian aid, the supervision of elections, and maintenance of law and order. Research shows that as they go about these new responsibilities, peacekeepers – officers more so than enlisted men – often become heavily involved in negotiation and mediation. One study found that as conflict becomes more severe, peacekeeper mediators are more likely to meet separately with the disputants, to urge the disputants to relax, and to rely on force (Wall, Druckman, & Diehl, 2002).\n\nPeacekeeper mediation is done at the local level. Mediation at the intergovernmental level is a much older practice that has recently come under study with statistical analyses of large samples of historical mediations (Bercovitch & Houston, 2000). Among the findings in this research are:\n\n\nSeveral types of negotiation strategies have been developed for repairing faulty international and inter-group relations. Negotiations are usually held over a period of several days, and attended by mid-level opinion leaders and decision makers from both sides of a conflict, under the leadership of scholar and/or practitioners. The aims of these workshops are to teach the parties about conflict in general and their conflict in particular, to forge understanding between the parties and, if possible, to develop joint projects that will contribute to reconciliation. One evaluation study conducted showed that these workshops improved attitudes toward the other side, increase complexity of thinking about the conflict, and facilitate further communication with people on the other side (Fisher, 1997). There is also evidence that some alumni of these workshops have later contributed to high level negotiations between the conflicting parties.\n\n\n\n"}
{"id": "1202852", "url": "https://en.wikipedia.org/wiki?curid=1202852", "title": "Constructed wetland", "text": "Constructed wetland\n\nA constructed wetland (CW) is an artificial wetland to treat municipal or industrial wastewater, greywater or stormwater runoff. It may also be designed for land reclamation after mining, or as a mitigation step for natural areas lost to land development.\n\nConstructed wetlands are engineered systems that use natural functions vegetation, soil, and organisms to treat wastewater. Depending on the type of wastewater the design of the constructed wetland has to be adjusted accordingly. Constructed wetlands have been used to treat both centralized and on-site wastewater. Primary treatment is recommended when there is a large amount of suspended solids or soluble organic matter (measured as BOD and COD).\n\nSimilarly to natural wetlands, constructed wetlands also act as a biofilter and/or can remove a range of pollutants (such as organic matter, nutrients, pathogens, heavy metals) from the water. Constructed wetlands are a sanitation technology that have not been designed specifically for pathogen removal, but instead, have been designed to remove other water quality constituents such as suspended solids, organic matter and nutrients (nitrogen and phosphorus). All types of pathogens (i.e., bacteria, viruses, protozoan and helminths) are expected to be removed to some extent in a constructed wetland. Subsurface wetland provide greater pathogen removal than surface wetlands.\n\nThere are two main types of constructed wetlands: subsurface flow and surface flow constructed wetlands. The planted vegetation plays an important role in contaminant removal. The filter bed, consisting usually of sand and gravel, has an equally important role to play. Some constructed wetlands may also serve as a habitat for native and migratory wildlife, although that is not their main purpose. Subsurface flow constructed wetlands are designed to have either horizontal flow or vertical flow of water through the gravel and sand bed. Vertical flow systems have a smaller space requirement than horizontal flow systems.\n\nMany terms are used to denote constructed wetlands, such as reed beds, soil infiltration beds, treatment wetlands, engineered wetlands, man-made or artificial wetlands. A biofilter has some similarities with a constructed wetland, but is usually without plants.\n\nThe term of constructed wetlands can also be used to describe restored and recultivated land that was destroyed in the past through draining and converting into farmland, or mining.\n\nA constructed wetland is an engineered sequence of water bodies designed to filter and treat waterborne pollutants found in sewage, industrial effluent or storm water runoff. Constructed wetlands are used for wastewater treatment or for greywater treatment. They can be used after a septic tank for primary treatment (or other types of systems) in order to separate the solids from the liquid effluent. Some constructed wetland designs however do not use upfront primary treatment.\n\nVegetation in a wetland provides a substrate (roots, stems, and leaves) upon which microorganisms can grow as they break down organic materials. This community of microorganisms is known as the periphyton. The periphyton and natural chemical processes are responsible for approximately 90 percent of pollutant removal and waste breakdown. The plants remove about seven to ten percent of pollutants, and act as a carbon source for the microbes when they decay. Different species of aquatic plants have different rates of heavy metal uptake, a consideration for plant selection in a constructed wetland used for water treatment. Constructed wetlands are of two basic types: subsurface flow and surface flow wetlands.\n\nConstructed wetlands are one example of nature-based solutions and of phytoremediation.\n\nMany regulatory agencies list treatment wetlands as one of their recommended \"best management practices\" for controlling urban runoff.\n\nPhysical, chemical, and biological processes combine in wetlands to remove contaminants from wastewater. An understanding of these processes is fundamental not only to designing wetland systems but to understanding the fate of chemicals once they enter the wetland. Theoretically, wastewater treatment within a constructed wetland occurs as it passes through the wetland medium and the plant rhizosphere. A thin film around each root hair is aerobic due to the leakage of oxygen from the rhizomes, roots, and rootlets. Aerobic and anaerobic micro-organisms facilitate decomposition of organic matter. Microbial nitrification and subsequent denitrification releases nitrogen as gas to the atmosphere. Phosphorus is coprecipitated with iron, aluminium, and calcium compounds located in the root-bed medium. Suspended solids filter out as they settle in the water column in surface flow wetlands or are physically filtered out by the medium within subsurface flow wetlands. Harmful bacteria and viruses are reduced by filtration and adsorption by biofilms on the gravel or sand media in subsurface flow and vertical flow systems.\n\nThe dominant forms of nitrogen in wetlands that are of importance to wastewater treatment include organic nitrogen, ammonia, ammonium, nitrate and nitrite. Total nitrogen refers to all nitrogen species. Wastewater nitrogen removal is important because of ammonia’s toxicity to fish if discharged into watercourses. Excessive nitrates in drinking water is thought to cause methemoglobinemia in infants, which decreases the blood's oxygen transport ability. Moreover, excess input of N from point and non-point sources to surface water promotes eutrophication in rivers, lakes, estuaries, and coastal oceans which causes several problems in aquatic ecosystems e.g. toxic algal blooms, oxygen depletion in water, fish mortality, loss of aquatic biodiversity.\n\nAmmonia removal occurs in constructed wetlands – if they are designed to achieve biological nutrient removal – in a similar ways as in sewage treatment plants, except that no external, energy-intensive addition of air (oxygen) is needed. It is a two-step process, consisting of nitrification followed by denitrification. The nitrogen cycle is completed as follows: ammonia in the wastewater is converted to ammonium ions; the aerobic bacterium \"Nitrosomonas\" sp. oxidizes ammonium to nitrite; the bacterium \"Nitrobacter\" sp. then converts nitrite to nitrate. Under anaerobic conditions, nitrate is reduced to relatively harmless nitrogen gas that enters the atmosphere.\n\nNitrification is the biological conversion of organic and inorganic nitrogenous compounds from a reduced state to a more oxidized state, based on the action of two different bacteria types. Nitrification is strictly an aerobic process in which the end product is nitrate (). The process of nitrification oxidizes ammonium (from the wastewater) to nitrite (), and then nitrite is oxidized to nitrate ().\n\nDenitrification is the biochemical reduction of oxidized nitrogen anions, nitrate and nitrite to produce the gaseous products nitric oxide (NO), nitrous oxide () and nitrogen gas (), with concomitant oxidation of organic matter. The end product, , and to a lesser extent the intermediary by product, , are gases that re-enter the atmosphere.\n\nConstructed wetlands have been used to remove ammonia and other nitrogenous compounds from contaminated mine water, including cyanide and nitrate.\n\nPhosphorus occurs naturally in both organic and inorganic forms. The analytical measure of biologically available orthophosphates is referred to as soluble reactive phosphorus (SR-P). Dissolved organic phosphorus and insoluble forms of organic and inorganic phosphorus are generally not biologically available until transformed into soluble inorganic forms.\n\nIn freshwater aquatic ecosystems phosphorus is typically the major limiting nutrient. Under undisturbed natural conditions, phosphorus is in short supply. The natural scarcity of phosphorus is demonstrated by the explosive growth of algae in water receiving heavy discharges of phosphorus-rich wastes. Because phosphorus does not have an atmospheric component, unlike nitrogen, the phosphorus cycle can be characterized as closed. The removal and storage of phosphorus from wastewater can only occur within the constructed wetland itself. Phosphorus may be sequestered within a wetland system by:\n\nAquatic vegetation may play an important role in phosphorus removal and, if harvested, extend the life of a system by postponing phosphorus saturation of the sediments. Plants create a unique environment at the biofilm's attachment surface. Certain plants transport oxygen which is released at the biofilm/root interface, adding oxygen to the wetland system. Plants also increase soil or other root-bed medium hydraulic conductivity. As roots and rhizomes grow they are thought to disturb and loosen the medium, increasing its porosity, which may allow more effective fluid movement in the rhizosphere. When roots decay they leave behind ports and channels known as macropores which are effective in channeling water through the soil.\n\nConstructed wetlands have been used extensively for the removal of dissolved metals and metalloids. Although these contaminants are prevalent in mine drainage, they are also found in stormwater, landfill leachate and other sources (e.g., leachate or FDG washwater at coal-fired power plants), for which treatment wetlands have been constructed for mines.\n\nConstructed wetlands can also be used for treatment of acid mine drainage from coal mines.\n\nConstructed wetlands are a sanitation technology that have not typically been designed for pathogen removal, but instead, have been designed to remove other water quality constituents such as suspended solids, organic matter (BOD/COD) and nutrients (nitrogen and phosphorus).\n\nAll types of pathogens are expected to be removed in a constructed wetland; however, greater pathogen removal is expected to occur in a subsurface wetland. In a free water surface flow wetland one can expect 1 to 2 log10 reduction of pathogens; however, bacteria and virus removal may be less than 1 log10 reduction in systems that are heavily planted with vegetation. This is because constructed wetlands typically include vegetation which assists in removing other pollutants such as nitrogen and phosphorus. Therefore, the importance of sunlight exposure in removing viruses and bacteria is minimized in these systems.\n\nRemoval in a properly designed and operated free water surface flow wetland is reported to be less than 1 to 2 log10 for bacteria, less than 1 to 2 log10 for viruses, 1 to 2 log10 for protozoa:, and 1 to 2 log10 for helminths. In subsurface flow wetlands, the expected removal of pathogens is reported to be 1 to 3 log10 for bacteria, 1 to 2 log10 for viruses, 2 log10 for protozoa, and 2 log10 for helminths.\n\nThe log10 removal efficiencies reported here can also be understood in terms of the common way of reporting removal efficiencies as percentages: 1 log10 removal is equivalent to a removal efficiency of 90%; 2 log10 = 99%; 3 log10 = 99.9%; 4 log10 = 99.99% and so on.\n\nThe main three broad types of constructed wetlands include:\n\nThe former types are placed in a basin with a substrate to provide a surface area upon which large amounts of waste degrading biofilms form, while the latter relies on a flooded treatment basin upon which aquatic plants are held in flotation till they develop a thick mat of roots and rhizomes upon which biofilms form. In most cases, the bottom is lined with either a polymer geomembrane, concrete or clay (when there is appropriate clay type) in order to protect the water table and surrounding grounds. The substrate can be either gravel—generally limestone or pumice/volcanic rock, depending on local availability, sand or a mixture of various sizes of media (for vertical flow constructed wetlands).\n\nIn subsurface flow constructed wetlands the flow of wastewater occurs between the roots of the plants and there is no water surfacing (it is kept below gravel). As a result, the system is more efficient, does not attract mosquitoes, is less odorous and less sensitive to winter conditions. Also, less area is needed to purify water. A downside to the system are the intakes, which can clog or bioclog easily, although some larger sized gravel will often solve this problem.\n\nSubsurface flow wetlands can be further classified as horizontal flow or vertical flow constructed wetlands. In the vertical flow constructed wetland, the effluent moves vertically from the planted layer down through the substrate and out (requiring air pumps to aerate the bed). In the horizontal flow constructed wetland the effluent moves horizontally via gravity, parallel to the surface, with no surface water thus avoiding mosquito breeding. Vertical flow constructed wetlands are considered to be more efficient with less area required compared to horizontal flow constructed wetlands. However, they need to be interval-loaded and their design requires more know-how while horizontal flow constructed wetlands can receive wastewater continuously and are easier to build.\n\nDue to the increased efficiency a vertical flow subsurface constructed wetland requires only about of space per person equivalent, down to 1.5 square metres in hot climates.\n\nThe \"French System\" combines primary and secondary treatment of raw wastewater. The effluent passes various filter beds whose grain size is getting progressively smaller (from gravel to sand).\n\nSubsurface flow wetlands can treat a variety of different wastewaters, such as household wastewater, agricultural, paper mill wastewater, mining runoff, tannery or meat processing wastes, storm water.\n\nThe quality of the effluent is determined by the design and should be customized for the intended reuse application (like irrigation or toilet flushing) or the disposal method.\n\nDepending on the type of constructed wetlands, the wastewater passes through a gravel and more rarely sand medium on which plants are rooted. A gravel medium (generally limestone or volcanic rock lavastone) can be used as well (the use of lavastone will allow for a surface reduction of about 20% over limestone) is mainly deployed in horizontal flow systems though it does not work as efficiently as sand (but sand will clog more readily).\n\nConstructed subsurface flow wetlands are meant as secondary treatment systems which means that the effluent needs to first pass a primary treatment which effectively removes solids. Such a primary treatment can consist of sand and grit removal, grease trap, compost filter, septic tank, Imhoff tank, anaerobic baffled reactor or upflow anaerobic sludge blanket (UASB) reactor. The following treatment is based on different biological and physical processes like filtration, adsorption or nitrification. Most important is the biological filtration through a biofilm of aerobic or facultative bacteria. Coarse sand in the filter bed provides a surfaces for microbial growth and supports the adsorption and filtration processes. For those microorganisms the oxygen supply needs to be sufficient.\n\nEspecially in warm and dry climates the effects of evapotranspiration and precipitation are significant. In cases of water loss, a vertical flow constructed wetland is preferable to a horizontal because of an unsaturated upper layer and a shorter retention time, although vertical flow systems are more dependent on an external energy source. Evapotranspiration (as is rainfall) is taken into account in designing a horizontal flow system.\n\nThe effluent can have a yellowish or brownish colour if domestic wastewater or blackwater is treated. Treated greywater usually does not tend to have a colour. Concerning pathogen levels, treated greywater meets the standards of pathogen levels for safe discharge to surface water. Treated domestic wastewater might need a tertiary treatment, depending on the intended reuse application.\n\nPlantings of reedbeds are popular in European constructed subsurface flow wetlands, although at least twenty other plant species are usable. Many fast growing timer plants can be used, as well for example as Musa spp., Juncus spp., cattails (\"Typha\" spp.) and sedges.\n\nOverloading peaks should not cause performance problems while continuous overloading lead to a loss of treatment capacity through too much suspended solids, sludge or fats.\n\nSubsurface flow wetlands require the following maintenance tasks: regular checking of the pretreatment process, of pumps when they are used, of influent loads and distribution on the filter bed.\n\nSubsurface wetlands are less hospitable to mosquitoes compared to surface flow wetlands, as there is no water exposed to the surface. Mosquitos can be a problem in surface flow constructed wetlands. Subsurface flow systems have the advantage of requiring less land area for water treatment than surface flow. However, surface flow wetlands can be more suitable for wildlife habitat.\n\nFor urban applications the area requirement of a subsurface flow constructed wetland might be a limiting factor compared to conventional municipal wastewater treatment plants. High rate aerobic treatment processes like activated sludge plants, trickling filters, rotating discs, submerged aerated filters or membrane bioreactor plants require less space. The advantage of subsurface flow constructed wetlands compared to those technologies is their operational robustness which is particularly important in developing countries. The fact that constructed wetlands do not produce secondary sludge (sewage sludge) is another advantage as there is no need for sewage sludge treatment. However, primary sludge from primary settling tanks does get produced and needs to be removed and treated.\n\nThe costs of subsurface flow constructed wetlands mainly depend on the costs of sand with which the bed has to be filled. Another factor is the cost of land.\n\nSurface flow wetlands, also known as free water surface constructed wetlands, can be used for tertiary treatment or polishing of effluent from wastewater treatment plants. They are also suitable to treat stormwater drainage.\n\nSurface flow constructed wetlands always have horizontal flow of wastewater across the roots of the plants, rather than vertical flow. They require a relatively large area to purify water compared to subsurface flow constructed wetlands and may have increased smell and lower performance in winter.\n\nSurface flow wetlands have a similar appearance to ponds for wastewater treatment (such as \"waste stabilization ponds\") but are in the technical literature not classified as ponds.\n\nPathogens are destroyed by natural decay, predation from higher organisms, sedimentation and UV irradiation since the water is exposed to direct sunlight. The soil layer below the water is anaerobic but the roots of the plants release oxygen around them, this allows complex biological and chemical reactions.\n\nSurface flow wetlands can be supported by a wide variety of soil types including bay mud and other silty clays.\n\nPlants such as Water Hyacinth (\"Eichhornia crassipes\") and \"Pontederia\" spp. are used worldwide (although Typha and Phragmites are highly invasive).\n\nHowever, surface flow constructed wetlands may encourage mosquito breeding. They may also have high algae production that lowers the effluent quality and due to open water surface mosquitos and odours, it is more difficult to integrate them in an urban neighbourhood.\n\nA combination of different types of constructed wetlands is possible to use the specific advantages of each system.\n\nAn integrated constructed wetland (ICW) is an unlined free surface flow constructed wetland with emergent vegetated areas and local soil material. Its objectives is not only to treat wastewater from farmyards and other wastewater sources, but also to integrate the wetland infrastructure into the landscape and enhancing its biological diversity.\n\nIntegrated constructed wetland facilitates may be more robust treatment systems compared to other constructed wetlands. This is due to the greater biological complexity and generally relatively larger land area use and associated longer hydraulic residence time of integrated constructed wetland compared to conventional constructed wetlands.\n\nIntegreated constructed wetlands are used in Ireland, the UK and the United States since about 2007. Farm constructed wetlands, which are a subtype of integrated constructed wetlands, are promoted by the Scottish Environment Protection Agency and the Northern Ireland Environment Agency since 2008.\n\nTyphas and Phragmites are the main species used in constructed wetland due to their effectiveness, even though they can be invasive outside their native range.\n\nIn North America, cattails (\"Typha latifolia\") are common in constructed wetlands because of their widespread abundance, ability to grow at different water depths, ease of transport and transplantation, and broad tolerance of water composition (including pH, salinity, dissolved oxygen and contaminant concentrations). Elsewhere, Common Reed (\"Phragmites australis\") are common (both in blackwater treatment but also in greywater treatment systems to purify wastewater).\n\nPlants are usually indigenous in that location for ecological reasons and optimum workings.\n\nLocally grown non-predatory fish can be added to surface flow constructed wetlands to eliminate or reduce pests, such as mosquitos. \n\nStormwater wetlands provide habitat for amphibians but the pollutants they accumulate can affect the survival of larval stages, potentially making them function as \"ecological traps\".\n\nSince constructed wetlands are self-sustaining their lifetime costs are significantly lower than those of conventional treatment systems. Often their capital costs are also lower compared to conventional treatment systems. They do take up significant space, and are therefore not preferred where real estate costs are high.\n\nSubsurface flow constructed wetlands with sand filter bed have their origin in Europe and are now used all over the world. Subsurface flow constructed wetlands with a gravel bed are mainly found in North Africa, South Africa, Asia, Australia and New Zealand.\n\nThe total number of constructed wetlands in Austria is 5,450 (in 2015). Due to legal requirements (nitrification), only vertical flow constructed wetlands are implemented in Austria as they achieve better nitrification performance than horizontal flow constructed wetlands. Only about 100 of these constructed wetlands have a design size of 50 population equivalents or more. The remaining 5,350 treatment plants are smaller than that.\n\nThe Arcata Marsh in Arcata, California is a sewage treatment and wildlife protection marsh.\n\nThe Urrbrae Wetland in Australia was constructed for urban flood control and environmental education.\n\nAt the Ranger Uranium Mine, in Australia, ammonia is removed in \"enhanced\" natural wetlands (rather than fully engineered constructed wetlands), along with manganese, uranium and other metals.\n\n\n\n"}
{"id": "12527335", "url": "https://en.wikipedia.org/wiki?curid=12527335", "title": "Cosmic time", "text": "Cosmic time\n\nCosmic time (also known as time since the big bang) is the time coordinate commonly used in the Big Bang models of physical cosmology. It is defined for homogeneous, expanding universes as follows: Choose a time coordinate so that the universe has the same density everywhere at each moment in time (the fact that this is possible means that the universe is, by definition, homogeneous). Measure the passage of time using clocks moving with the Hubble flow. Choose the big bang singularity as the origin of the time coordinate. \n\nCosmic time formula_1 is a measure of time by a physical clock with zero peculiar velocity in the absence of matter over-/under-densities (to prevent time dilation due to relativistic effects or confusions caused by expansion of the universe). Unlike other measures of time such as temperature, redshift, particle horizon, or Hubble horizon, the cosmic time (similar and complementary to the comoving coordinates) is blind to the expansion of the universe. \n\nThere are two main ways for establishing a reference point for the cosmic time. The most trivial way is to take the present time as the cosmic reference point (sometimes referred to as the lookback time) or alternatively, take the Big Bang as formula_2 (also referred to as age of the universe). The big bang doesn't necessarily have to correspond to a physical event but rather it refers to the point at which the scale factor would vanish for a standard cosmological model such as ΛCDM. For instance, in the case of inflation, i.e. a non-standard cosmology, the hypothetical moment of big bang is still determined using the benchmark cosmological models which may coincide with the end of the inflationary epoch. For inflationary models, it is not possible to establish a well defined origin of time before the big bang since the universe does not require a beginning event in such models. For technical purposes, concepts such as the average temperature of the universe (in units of eV) or the particle horizon are used when the early universe is the objective of a study since understanding the interaction among particles is more relevant than their time coordinate or age. \n\nCosmic time is the standard time coordinate for specifying the Friedmann–Lemaître–Robertson–Walker solutions of Einstein's equations.\n\n"}
{"id": "238029", "url": "https://en.wikipedia.org/wiki?curid=238029", "title": "Crushing (execution)", "text": "Crushing (execution)\n\nDeath by crushing or pressing is a method of execution that has a history during which the techniques used varied greatly from place to place, generally involving the placement of intense weight upon a person with the intent to kill. This form of execution is no longer sanctioned by any governing body.\n\nA common method of death throughout South and South-East Asia for over 4,000 years was crushing by elephants. The Romans and Carthaginians used this method on occasion.\n\nIn Roman mythology, Tarpeia was a Roman maiden who betrayed the city of Rome to the Sabines in exchange for what she thought would be a reward of jewelry. She was instead crushed to death and her body cast from the Tarpeian Rock which now bears her name.\n\nCrushing is also reported from pre-Columbian America, notably in the Aztec Empire.\n\nPeine forte et dure (Law French for \"forceful and hard punishment\") was a method of torture formerly used in the common law legal system, in which a defendant who refused to plead (\"stood mute\") would be subjected to having heavier and heavier stones placed upon his or her chest until a plea was entered, or as the weight of the stones on the chest became too great for the condemned to breathe, fatal suffocation would occur.\n\nThe common law courts originally took a very limited view of their own jurisdiction. They considered themselves to lack jurisdiction over a defendant until he had voluntarily submitted to it by entering a plea seeking judgment from the court. Obviously, a criminal justice system that punished only those who volunteered for punishment was unworkable; this was the means chosen to coerce them.\n\nMany defendants charged with capital offences nonetheless refused to plead, since thereby they would escape forfeiture of property, and their heirs would still inherit their estate; but if the defendant pleaded guilty and was executed, their heirs would inherit nothing, their property escheating to the Crown. \"Peine forte et dure\" was abolished in Great Britain in 1772, and the last known use of the practice was in 1741. In 1772, refusing to plead was deemed to be equivalent to pleading guilty. This was changed in 1827 to being deemed a plea of not guilty. Today, in all common law jurisdictions, standing mute is treated by the courts as equivalent to a plea of not guilty.\n\nThe elaborate procedure was recorded by a 15th-century witness in an oft-quoted description: \"he will lie upon his back, with his head covered and his feet, and one arm will be drawn to one quarter of the house with a cord, and the other arm to another quarter, and in the same manner it will be done with his legs; and let there be laid upon his body iron and stone, as much as he can bear, or more ...\"\n\n\"Pressing to death\" might take several days, and not necessarily with a continued increase in the load. The Frenchman Guy Miege, who from 1668 taught languages in London says the following about the English practice:\nThe most famous case in the United Kingdom was that of Roman Catholic martyr St Margaret Clitherow, who (in order to avoid a trial in which her own children would be obliged to give evidence) was pressed to death on March 25, 1586, after refusing to plead to the charge of having harboured Catholic (then outlawed) priests in her house. She died within fifteen minutes under a weight of at least 700 pounds (320 kg). Several hardened criminals, including William Spigott (1721) and Edward Burnworth, lasted a half hour under 400 pounds (180 kg) before pleading to the indictment. Others, such as Major Strangways (1658) and John Weekes (1731), refused to plead, even under 400 pounds (180 kg), and were killed when bystanders, out of mercy, sat on them.\n\nThe only death by \"peine forte et dure\" in American history was Giles Corey, who was pressed to death on September 19, 1692, during the Salem witch trials, after he refused to enter a plea in the judicial proceeding. According to legend, his last words as he was being crushed were \"More weight\", and he was thought to be dead as the weight was applied. This is referred to in Arthur Miller's political drama \"The Crucible\" (1953), where Giles Corey is pressed to death after refusing to plead \"aye or nay\" to the charge of witchcraft. In the 1996 film version of this play, the screenplay also written by Arthur Miller, Corey is crushed to death for refusing to reveal the name of a source of information.\n\nIn medieval Europe, the slow crushing of body parts in screw-operated \"bone vises\" of iron was a common method of torture, and a tremendous variety of cruel instruments were used to savagely crush the head, the knee, the hand, and, most commonly, either the thumb or the naked foot. Such instruments were finely threaded and variously provided with spiked inner surfaces or heated red-hot before their application to the limb to be tortured.\n\n\n\n"}
{"id": "38133349", "url": "https://en.wikipedia.org/wiki?curid=38133349", "title": "DOT DOT DOT (artist)", "text": "DOT DOT DOT (artist)\n\nDOT DOT DOT (also styled \"...\" or dotdotdot) is the pseudonym for an anonymous Norwegian visual, public and conceptual artist.\n\nHis work has been displayed in galleries around the world, and in cities such as Oslo, Copenhagen, Berlin, Paris, Málaga, Los Angeles, Miami, New York City, Tokyo, Bangkok and more. \nDOT DOT DOT's age and real name are not publicly known.\n\nDOT DOT DOT was born in Oslo, Norway. He first started as a graffiti artist in the late 90s. He operated under several different pseudonyms over the years. In 2000 he started creating stencil art, but continued creating conventional graffiti works.\nDOT DOT DOT first gained notice for painting a rat in the town of Sandvika, outside Oslo.\n\nDOT DOT DOT appeared on TV channel NRK talking about the street art movement together with Martin Berdahl Aamundsen from Kontur Forlag, before the release of the book \"Street Art Norway Vol. 2\".\n\nDOT DOT DOT participated at LandArt in October 2012, curated by Norwegian artists Mari Meen Halsøy and Kine Lillestrøm, in Romerike/Gjerdrum, just outside Oslo.\nIn October 2012 DOT DOT DOT together with ARD (All Rights Destroyed) started the \"ARD*POP-UP Festival\" in Oslo, inviting national and international artists to decorate walls throughout the city.\n\n\n\n"}
{"id": "19361526", "url": "https://en.wikipedia.org/wiki?curid=19361526", "title": "Desire", "text": "Desire\n\nDesire is a sense of longing or hoping for a person, object, or outcome. The same sense is expressed by emotions such as \"craving\". When a person desires something or someone, their sense of longing is excited by the enjoyment or the thought of the item or person, and they want to take actions to obtain their goal. The motivational aspect of desire has long been noted by philosophers; Thomas Hobbes (1588–1679) asserted that human desire is the fundamental motivation of all human action.\n\nWhile desires are often classified as emotions by laypersons, psychologists often describe desires as different from emotions; psychologists tend to argue that desires arise from bodily structures, such as the stomach's need for food, whereas emotions arise from a person's mental state. Marketing and advertising companies have used psychological research on how desire is stimulated to find more effective ways to induce consumers into buying a given product or service. While some advertising attempts to give buyers a sense of lack or wanting, other types of advertising create desire associating the product with desirable attributes, by showing either a celebrity or a model with the product.\n\nThe theme of desire is at the core of romance novels, which often create drama by showing cases where human desire is impeded by social conventions, class, or cultural barriers. The theme of desire is also used in other literary genres, such as Gothic novels (e.g., \"Dracula\" by Bram Stoker, in which desire is mingled with fear and dread). Poets ranging from Homer to Toni Morrison have dealt with the theme of desire in their work. Just as desire is central to the written fiction genre of romance, it is the central theme of melodrama films, which use plots that appeal to the heightened emotions of the audience by showing \"crises of human emotion, failed romance or friendship\", in which desire is thwarted or unrequited.\n\nIn philosophy, desire has been identified as a philosophical problem since Antiquity. In \"The Republic\", Plato argues that individual desires must be postponed in the name of the higher ideal. In \"De Anima\", Aristotle claims that desire is implicated in animal interactions and the propensity of animals to motion; at the same time, he acknowledges that reasoning also interacts with desire.\n\nHobbes (1588–1679) proposed the concept of psychological hedonism, which asserts that the \"fundamental motivation of all human action is the desire for pleasure.\" Baruch Spinoza (1632–1677) had a view which contrasted with Hobbes, in that \"he saw natural desires as a form of bondage\" that are not chosen by a person of their own free will. David Hume (1711–1776) claimed that desires and passions are non-cognitive, automatic bodily responses, and he argued that reasoning is \"capable only of devising means to ends set by [bodily] desire\".\n\nImmanuel Kant (1724–1804) called any action based on desires a hypothetical imperative, meaning by this that it is a command of reason that applies only if one desires the goal in question. Kant also established a relation between the beautiful and pleasure in \"Critique of Judgment\". Georg Wilhelm Friedrich Hegel claimed that \"self-consciousness is desire\".\n\nBecause desire can cause humans to become obsessed and embittered, it has been called one of the causes of woe for mankind. Within the teachings of Buddhism, craving is thought to be the cause of all suffering that one experiences in human existence. The eradication of craving leads one to ultimate happiness, or Nirvana. However, desire for wholesome things is seen as liberating and enhancing. While the stream of desire for sense-pleasures must be cut eventually, a practitioner on the path to liberation is encouraged by the Buddha to \"generate desire\" for the fostering of skillful qualities and the abandoning of unskillful ones.\n\nIn Hinduism, the Rig Veda's creation myth Nasadiya Sukta states regarding the one (ekam) spirit: \"In the beginning there was Desire (kama) that was first seed of mind. Poets found the bond of being in non-being in their heart's thought\".\n\nIn Buddhism, for an individual to effect his or her liberation, the flow of sense-desire must be cut completely; however, while training, he or she must work with motivational processes based on skillfully applied desire. According to the early Buddhist scriptures, the Buddha stated that monks should \"generate desire\" for the sake of fostering skillful qualities and abandoning unskillful ones.\n\nThere is a double message here between what Buddha said, that desire must be created, and what some monks propose to their followers, that desire must be cut.\nTruth is Buddhism entails two aspects: the ideas monks taught to civilize peasantry, on the one hand, and the esoteric teachings of tantra (aimed at leaders) for self-realization, on the other, where—just as Buddha said—desire must be generated.\nDr. Oscar R. Gómez holds that teachings imparted privately by H.H. 14th Dalai Lama are meant for leaders to be able to choose a specific desire consciously by creating it previously from the inside. People have a tendency to live based on desires coming from the outside, and such desires are the ones making choices for them. As an alternative, tantric Tibetan Buddhism allows to choose a desire consciously; to create desire rather than being created by it.\n\nWithin Christianity, desire is seen as something that can either lead a person towards God and destiny or away from him. Desire is not considered to be a bad thing in and of itself; rather, it is a powerful force within the human that, once submitted to the Lordship of Christ, can become a tool for good, for advancement, and for abundant living.\n\nWhile desires are often classified as emotions by laypersons, psychologists often describe desires as different from emotions. For psychologists, desires arise from bodily structures and functions (e.g., the stomach needing food and the blood needing oxygen). On the other hand, emotions arise from a person's mental state. A 2008 study by the University of Michigan indicated that, while humans experience desire and fear as psychological opposites, they share the same brain circuit. A 2008 study entitled \"The Neural Correlates of Desire\" showed that the human brain categorizes stimuli according to its desirability by activating three different brain areas: the superior orbitofrontal cortex, the mid-cingulate cortex, and the anterior cingulate cortex.\n\nIn affective neuroscience, \"desire\" and \"wanting\" are operationally defined as motivational salience; the form of \"desire\" or \"wanting\" associated with a rewarding stimulus (i.e., a stimulus which acts as a positive reinforcer, such as palatable food, an attractive mate, or an addictive drug) is called \"incentive salience\" and research has demonstrated that incentive salience, the sensation of pleasure, and positive reinforcement are all derived from neuronal activity within the reward system. Studies have shown that dopamine signaling in the nucleus accumbens shell and endogenous opioid signaling in the ventral pallidum are at least partially responsible for mediating an individual's desire (i.e., incentive salience) for a rewarding stimulus and the subjective perception of pleasure derived from experiencing or \"consuming\" a rewarding stimulus (e.g., pleasure derived from eating palatable food, sexual pleasure from intercourse with an attractive mate, or euphoria from using an addictive drug). Research also shows that the orbitofrontal cortex has connections to both the opioid and dopamine systems, and stimulating this cortex is associated with subjective reports of pleasure.\n\nAustrian psychiatrist Sigmund Freud, who is best known for his theories of the unconscious mind and the defense mechanism of repression and for creating the clinical practice of psychoanalysis, proposed the notion of the Oedipus complex, which argues that desire for the mother creates neuroses in their sons. Freud used the Greek myth of Oedipus to argue that people desire incest and must repress that desire. He claimed that children pass through several stages, including a stage in which they fixate on the mother as a sexual object.\nThat this \"complex\" is universal has long since been disputed. Even if it were true, that would not explain those neuroses in daughters, but only in sons. While it is true that sexual confusion \"can\" be aberrative in a few cases, there is no credible evidence to suggest that it is a universal scenario. While Freud was correct in labeling the various symptoms behind most compulsions, phobias and disorders, he was largely incorrect in his theories regarding the etiology of what he identified.\n\nFrench psychoanalyst and psychiatrist Jacques Lacan (1901–1981) argues that desire first occurs during a \"mirror phase\" of a baby's development, when the baby sees an image of wholeness in a mirror which gives them a desire for that being. As a person matures, Lacan claims that they still feel separated from themselves by language, which is incomplete, and so a person continually strives to become whole. He uses the term \"jouissance\" to refer to the lost object or feeling of absence which a person believes to be unobtainable. For more details on the Lacanian conception of desire, see desire (psychoanalysis). \n\nIn the field of marketing, desire is the human appetite for a given object of attention. Desire for a product is stimulated by advertising, which attempts to give buyers a sense of lack or wanting. In store retailing, merchants attempt to increase the desire of the buyer by showcasing the product attractively, in the case of clothes or jewellery, or, for food stores, by offering samples. With print, TV, and radio advertising, desire is created by giving the potential buyer a sense of lacking (\"Are you still driving that old car?\") or by associating the product with desirable attributes, either by showing a celebrity using or wearing the product, or by giving the product a \"halo effect\" by showing attractive models with the product. Nike's \"Just Do It\" ads for sports shoes are appealing to consumers' desires for self-betterment.\n\nIn some cases, the potential buyer already has the desire for the product before they enter the store, as in the case of a decorating buff entering their favorite furniture store. The role of the salespeople in these cases is simply to guide the customer towards making a choice; they do not have to try to \"sell\" the general idea of making a purchase, because the customer already wants the products. In other cases, the potential buyer does not have a desire for the product or service, and so the company has to create the sense of desire. An example of this situation is for life insurance. Most young adults are not thinking about dying, so they are not naturally thinking about how they need to have accidental death insurance. Life insurance companies, though, are attempting to create a desire for life insurance with advertising that shows pictures of children and asks \"If anything happens to you, who will pay for the children's upkeep?\".\n\nMarketing theorists call desire the third stage in the hierarchy of effects, which occurs when the buyer develops a sense that if they felt the need for the type of product in question, the advertised product is what would quench their desire.\n\nThe theme of desire is at the core of the romance novel. Novels which are based around the theme of desire, which can range from a long aching feeling to an unstoppable torrent, include \"Madame Bovary\" by Gustave Flaubert; \"Love in the Time of Cholera\" by Gabriel Garcia Marquez; \"Lolita\" by Vladimir Nabokov; \"Jane Eyre\" by Charlotte Brontë, and \"Dracula\" by Bram Stoker. Brontë's characterization of Jane Eyre depicts her as torn by an inner conflict between reason and desire, because \"customs\" and \"conventionalities\" stand in the way of her romantic desires. E.M. Forster's novels use homoerotic codes to describe same-sex desire and longing. Close male friendships with subtle homoerotic undercurrents occur in every novel, which subverts the conventional, heterosexual plot of the novels. In the Gothic-themed \"Dracula\", Stoker depicts the theme of desire which is coupled with fear. When the Lucy character is seduced by Dracula, she describes her sensations in the graveyard as a mixture of fear and blissful emotion.\n\nPoet W.B. Yeats depicts the positive and negative aspects of desire in his poems such as \"The Rose for the World\", \"Adam's Curse\", \"No Second Troy\", \"All Things can Tempt me\", and \"Meditations in Time of Civil War\". Some poems depict desire as a poison for the soul; Yeats worked through his desire for his beloved, Maud Gonne, and realized that \"Our longing, our craving, our thirsting for something other than Reality is what dissatisfies us\". In \"The Rose for the World\", he admires her beauty, but feels pain because he cannot be with her. In the poem \"No Second Troy\", Yeats overflows with anger and bitterness because of their unrequited love. Poet T. S. Eliot dealt with the themes of desire and homoeroticism in his poetry, prose and drama. Other poems on the theme of desire include John Donne's poem \"To His Mistress Going to Bed\", Carol Ann Duffy's longings in \"Warming Her Pearls\"; Ted Hughes' \"Lovesong\" about the savage intensity of desire; and Wendy Cope's humorous poem \"Song\".\n\nPhilippe Borgeaud's novels analyse how emotions such as erotic desire and seduction are connected to fear and wrath by examining cases where people are worried about issues of impurity, sin, and shame.\n\nJust as desire is central to the written fiction genre of romance, it is the central theme of melodrama films, which are a subgenre of the drama film. Like drama, a melodrama depends mostly on in-depth character development, interaction, and highly emotional themes. Melodramatic films tend to use plots that appeal to the heightened emotions of the audience. Melodramatic plots often deal with \"crises of human emotion, failed romance or friendship, strained familial situations, tragedy, illness, neuroses, or emotional and physical hardship.\" Film critics sometimes use the term \"pejoratively to connote an unrealistic, bathos-filled, campy tale of romance or domestic situations with stereotypical characters (often including a central female character) that would directly appeal to feminine audiences.\" Also called \"women's movies\", \"weepies\", tearjerkers, or \"chick flicks\".\n\n\"Melodrama… is Hollywood's fairly consistent way of treating desire and subject identity\", as can be seen in well-known films such as \"Gone with the Wind\", in which \"desire is the driving force for both Scarlett and the hero, Rhett\". Scarlett desires love, money, the attention of men, and the vision of being a virtuous \"true lady\". Rhett Butler desires to be with Scarlett, which builds to a burning longing that is ultimately his undoing, because Scarlett keeps refuses his advances; when she finally confesses her secret desire, Rhett is worn out and his longing is spent.\n\nIn Cathy Cupitt's article on \"Desire and Vision in Blade Runner\", she argues that film, as a \"visual narrative form, plays with the voyeuristic desires of its audience\". Focusing on the dystopian 1980s science fiction film \"Blade Runner\", she calls the film an \"Object of Visual Desire\", in which it plays to an \"expectation of an audience's delight in visual texture, with the 'retro-fitted' spectacle of the post-modern city to ogle\" and with the use of the \"motif of the 'eye'\". In the film, \"desire is a key motivating influence on the narrative of the film, both in the 'real world', and within the text.\"\n\nBarry Long defined desire as stress or strain. It is a tension between an individual and the thing or state that that individual desires. As the thing does not feel this stress, the desiring is a one-way tension within the individual, an apparent reaching out towards the desired object or person.\n\nWhen the person responds in the way desired, or the object is attained, the desire settles down into a relationship. A relationship is identifiable by the presence of an attitude in yourself which reacts in terms of \"mine\".\n\nWhen a desire has been reduced to the level of a habit or idea it can be dealt with and eliminated fairly quickly by observation - seeing it for what it is. In that moment you suddenly realise you are free of the relationship as a need or dependence \"of mine\".\n\n\n"}
{"id": "21010600", "url": "https://en.wikipedia.org/wiki?curid=21010600", "title": "Doctrine of repair and reconstruction", "text": "Doctrine of repair and reconstruction\n\nThe doctrine of repair and reconstruction in United States patent law distinguishes between permissible repair of a patented article, which the right of an owner of property to preserve its utility and operability guarantees, and impermissible reconstruction of a patented article, which is patent infringement. The doctrine is explained in \"Aro Mfg. Co. v. Convertible Top Replacement Co.\" The \"Aro\" case states the rule in these terms:\nThe decisions of this Court require the conclusion that reconstruction of a patented entity, unpatented elements, is limited to such a true reconstruction of the entity as to \"in fact make a new article,\" after the entity, viewed as a whole, has become spent. In order to call the monopoly, conferred by the patent grant, into play for a second time, it must, indeed, be a second creation of the patented entity. …Mere replacement of individual unpatented parts, one at a time, whether of the same part repeatedly or different parts successively, is no more than the lawful right of the owner to repair his property.\nAn extension of the doctrine is a right to modify the product to enhance its functionality, such as to make it operate faster or with a different size of product. The Supreme Court said in \"Wilbur-Ellis Co. v. Kuther\" that such a right was \"kin to repair for it bore on the useful capacity of the old combination, on which the royalty had been paid.\"\n\nThe House of Lords declared a similar principle—the doctrine of non-derogation from grants—concerning car owners' repair and replacement of automobile parts, in \"British Leyland Motor Corp. v. Armstrong Patents Co.\"\n"}
{"id": "33375094", "url": "https://en.wikipedia.org/wiki?curid=33375094", "title": "Effects of advertising on teen body image", "text": "Effects of advertising on teen body image\n\nThe effects of advertising on body image have been studied by researchers, ranging from psychologists to marketing professionals. \"These days we know that the media and body image are closely related. Particularly, the body image advertising portrays affects our own body image. Of course, there are many other things that influence our body image: parenting, education, intimate relationships, and so on. The popular media does have a big impact, though\"\nThis is because thousands of advertisements contain messages about physical attractiveness and beauty, examples of which include commercials for clothes, cosmetics, weight reduction, and physical fitness. Researchers have conducted studies in an attempt to see if such advertisements have effects on teenage body image, and what those effects might be.\n\nResearchers, such as Mary Martin and James Gentry, have found that teen advertising reduces teenagers' self-esteem by setting unrealistic expectations for them about their physical appearances through the use of idealized models. Other researchers, such as Heidi Posavac, acknowledge this, but believe that this only applies to teenagers who already possess low self-esteem or a poor self-images.\n\nIn contrast, researchers, including Terry Bristol, have found teenagers to be generally unaffected by these advertisements due to the idea that repeat exposure can create an immunity to images and messages in advertisements. Moreover, some researchers, such as Paul Humphreys, have concluded that exposure to such advertisements can actually create higher self-esteem in teenagers.\n\nAccording to Medimark Research Inc., a marketing research company, teenagers are important to marketers because they \"have significant discretionary income; spend family money, as well as influence their parents' spending on both large and small household purchases; establish and affect fashion, lifestyle, and overall trends; and provide a 'window' into our society – a view of how it is now and what it is likely to become.\"\n\nAlmost half of the space of the most popular magazines for adolescent girls is made up of advertisements. In an effort to further reach young men with advertisements, branded content is now being included in video games as well. Researches are trying to determine whether or not these advertisements shape the body image and self-esteem of the teenagers that view them.\n\nThe way beauty is portrayed in the media tends to cause dissatisfaction and negative thoughts about oneself when those results are not achieved. Sociocultural standards of feminine beauty are presented in almost all forms of popular media are bombarding women with these unrealistic images that portray what is considered to be the \"ideal body\" within this society. Such standards of beauty are unattainable for most women; The majority of the models displayed on television and in advertisements are well below what is considered healthy body weight. Mass media's use of such unrealistic models sends an implicit message that in order for a woman to be considered beautiful, she must be unhealthy. The mindset that a person can never be \"too rich or too thin\" is prevalent in society, and this makes it difficult for females to achieve any level of contentment with their physical appearance. There has been a plethora of research to indicate that women are negatively affected by constant exposure to models that fulfill the unrealistic media ideal of beauty.\n\nNaomi Wolf's \"The Beauty Myth\" noted the beginning of feminist critiques of societal standards regarding female beauty. This \"feminine ideal\" is the goal of most women in society, although feminists have been working for decades on eradicating this idea (Brownmiller, 1984). The first feminist mass meeting in 1914 included demands such as the 'right to ignore fashion' and the 'right not to have to wear make up'. (Bordo, 1993). unfortunately these demands have not yet been fulfilled as women in today's society still feel the need to dress in a particular way and to wear makeup to feel beautiful and attractive to the opposite gender and within today's society.\n\nHowever, these efforts to erase the 'ideal body image' are opposed by modern reality TV shows that encourage such behaviour. \"Extreme Makeover\" puts individuals through extreme physical changes to change the way they look, which is then viewed by women of all ages. This tends to encourage people to think about their image, and change what they do not like in an unsafe manner. \"The Swan\" (2004) went one step further, and had the contestants compete in a beauty contest following their various reconstructive surgeries. These types of TV shows tend to teach women that it is okay to change their image to fit the \"feminine ideal\", instead of encouraging them to accept the body that they already have.\n\nRice (1994) states that 'a woman's essential value is based on her ability to attain a thin body size'. Therefore while women continue to diet, they still dislike their bodies. Another statistic, stated by the Media Awareness Network, is that the average model weighed 8 percent less than the average women twenty years ago, compared to models weighing 23 percent less today.\n\nA study by A. Chris Downs and Sheila Harrison from \"Sex Roles\" found that one out of every 3.8 television commercials has a message about attractiveness in it. They determined that viewers receive roughly 5,260 advertisements related to attractiveness per year (or at least 14 per day). Of these messages, 1,850 of them are specifically about beauty.\n\nIn a study published in the \"Journal of Advertising\", Marketing professors Mary Martin and James Gentry noted that images of blonde, thin women are predominant in mass media, and that these characteristics are often portrayed as being ideal. Martin and Gentry also found that advertising can \"impose a sense of inadequacy on young women's self-concepts\". This is because girls and young women tend to compare their own physical attractiveness to the physical attractiveness of models in advertisements. They then experience lowered self-esteem if they do not feel that they look like the models in advertisements.\n\nToday's models weigh 23 percent less than the average woman, while the average model two decades ago weighed eight percent less than the average woman. This currently prevalent media ideal of thinness is met by only about five percent of the population.\n\nAdditionally, a study of \"Seventeen magazine\" concluded that the models featured in this popular teen magazine were far less curvy than those portrayed in women's magazines. It was also noted that the hip-to-waist ratio had decreased in these models from 1970 to 1990.\n\nIn a study published in \"Sex Roles\", psychologists Heidi Posavac, Steven Posavac, and Emil Posavac found that many young women will express dissatisfaction with their bodies, particularly with their body weight, when they are exposed to images of thin models who are slimmer than the average woman. Early researchers in the area of sex roles in the mass media examined a large number of ads at a time in order to classify and count particular types of representation (Rakow 1986).\n\nExpressing similar sentiments, an aspiring young model was quoted as saying, \"Deep down I still want to be a supermodel... As long as they're there, screaming at me from the television, glaring at me from the magazines, I'm stuck in the model trap. Hate them first. Then grow to like them. Love them. Emulate them. Die to be them. All the while praying the cycle will come to an end.\"\n\nAcademic researchers Philip Myers Jr. and Frank Biocca concluded, in their study published in the \"Journal of Communication\", that a woman's self-perceived body image can change after watching a half-an-hour of television programming and advertising. Researchers Yoku Yamamiya and Thomas F. Cash concluded through their study that \"Even a 5 minute exposure to thin-and-beautiful media images results in a more negative body image state than does exposure to images of neutral object.\"\n\nLikewise, a study by Stice et al. in the \"Journal of Abnormal Psychology\" concluded that there is a direct relationship between the amount of media exposure that a young woman has and the likelihood that she will develop eating disorder symptoms.\n\nMartin and Gentry also found that the mass media \"creates and reinforces a preoccupation with physical attractiveness in young women\", which can lead to bulimia, anorexia, and opting for cosmetic surgery. She also concluded that, \"exposure to ultra-thin models in advertisements and magazine pictures produced depression, stress, guilt, shame, insecurity, and body dissatisfaction in female college students\".\n\nIn a study published in the \"Journal of Youth and Adolescence\", Paxton et al. found body dissatisfaction to be more prevalent in young women than in young men.\n\nLow self-esteem that stems from teenage advertising can have detrimental effects on teenagers. Seventy-five percent of young women with low self-esteem report engaging in negative activities such as \"cutting, bullying, smoking, or drinking when feeling badly about themselves\".\n\nTeen promiscuity is another possible effect of low self-esteem.\n\nPeople fail to recognize that photo-shop is widely used on models in magazines and in advertisements which gives an unrealistic expectation. An online survey in 2010 consisting of 100 girls aged 13–17 was conducted by Girl Scouts. What they found was that 9 out of 10 girls felt pressure by fashion and media industries to be skinny. More than 60% compared themselves to fashion models, and 46% believed that the ideal body image is portrayed in fashion magazines and refer to the girls in the magazines as who they strive to look like.\n\nUnfortunately thin-idealized bodies are attributed with self control, success and discipline, and therefore proclaimed as being desirable and socially valued. “Being slim means resisting the temptations that surround consumers in countries of overabundance and wealth” (Thompson et al 1995: Halliwell et al 2004).\n\nIt is more prevalent that young men are more self-conscious and are showing great concern to their bodies. This indicates a huge awareness of both self-appearance and importance to the body itself. In other words, young men tend to be worried about their figure just like young women are. This is present due to the media and the messages it commonly portrays; these messages are mostly targeted toward a younger age group which shows how media has influenced these age groups. \nAccording to an online article, it states that \"The male body in the media has an impact on how males, especially developing males, perceive their own bodies,\" said Brennan. \"Males are being exposed to the same extreme ideals of body perfection as females.\"\n\nA study published in \"JAMA Pediatrics\" in January shows concerns about physique and muscularity in particular, among young males are \"relatively common\". The researchers said approximately 18 percent of participants in their study (which included 5,527 males) were \"extremely concerned for their weight and researchers found 7.6 percent of young males were \"very concerned about muscularity\" and were using techniques that could be harmful to obtain an ideal body.\n\nA study by insurer Blue Cross Blue shield found that in 1999 to 2000, use of steroids and similar drugs amongst boys ages 12 to 17 jumped 25 percent, with 20 percent saying they use the drug for looks rather than sports.\n\nMoreover, men in advertisements are more muscular today than they were 25 to 30 years ago.\n\nA 2002 study found that male college students who are exposed to advertisements featuring muscular men show a significant \"discrepancy between their own perceived muscularity and the level of muscularity that they ideally wanted to have\".\n\nAdditionally, a study from the \"Journal of Social and Clinical Psychology\" by Daniel Agliata and Stacey Tantleff-Dunn found that exposure to media images of lean and muscular men increases muscle dissatisfaction and depression in young men.\n\nSome researchers believe that men are usually more satisfied than women with their physical appearance. Other researchers, however, state that men still struggle with body image. Men believe that they are either too thin or too heavy and therefore do not meet the male ideal body type of lean and muscular.\n\nSince boys are much less likely to discuss their issues about their body image, the statistics pertaining to the number of boys of whom this affects varies because so many instances are unreported. Therefore, it is difficult to precisely determine which gender is more affected by body portrayal in the media. One very thorough study, however, conducted by Alison Field, a professor of pediatrics at Harvard Medical School and a researcher at Boston Children's Hospital, revealed that approximately 18% of adolescent boys, aged 10–17, are concerned about their body and how much they weigh. Furthermore, Frederick and Jamal Essayli from the University of Hawaii at Manoa conducted national online surveys and gathered information from 116,000 men. They concluded that approximately 29% of men were dissatisfied with their bodies specifically because of the media.\n\nHeidi Posavac, Steven Posavac, and Emil Posavac found that young women who are already content with their bodies are generally unaffected by media images of models and other attractive women. They concluded that only those who are dissatisfied with their bodies prior to viewing advertisements will then feel poorly after seeing advertisements featuring thin, attractive women.\n\nFurthermore, Myers and Biocca found that some young women actually feel thinner after viewing advertisements featuring thin, idealized women.\n\nLikewise, a study by psychology professors Paul Humphreys and Susan Paxton suggests that young men who view images of idealized men either feel no different or feel more positive about themselves after viewing such images.\n\nTamara Mangleburg and Terry Bristol's studies featured in the \"Journal of Advertising\" found that teens are not typically swayed by images in advertisements. They suggest the more teens view advertisements, the less they are affected by them and the more they become skeptical of the messages that are in advertisements. This is because repeat exposure to ads can give them a better understanding of the motives behind such ads.\n\nSimilarly, Marsha Richins, former president of the Association for Consumer Research, theorized that, \"by late adolescence... the sight of extremely attractive models is 'old news' and unlikely to provide new information that might influence self-perception\". \"[Yamamiya and Cash] used 20 model slides as stimuli, presented for a total duration of 5 minutes found that as the number of stimuli exceeded 10, viewers were somewhat less influenced, probably due to habituation.\"\n\nPsychological researchers Christopher Ferguson, Benjamin Winegard, and Bo Winegard feel that the media's effects on body dissatisfaction have been over-exaggerated. They believe that media does not heavily influence body dissatisfaction. Instead, they have found peers to have a much greater influence than the media in terms of body dissatisfaction in teenagers.\n"}
{"id": "878327", "url": "https://en.wikipedia.org/wiki?curid=878327", "title": "Engineering notation", "text": "Engineering notation\n\nEngineering notation or engineering form is a version of scientific notation in which the exponent of ten must be divisible by three (i.e., they are powers of a thousand, but written as, for example, 10 instead of 1000). As an alternative to writing powers of 10, SI prefixes can be used, which also usually provide steps of a factor of a thousand.\n\nOn most calculators, engineering notation is called \"ENG\" mode.\n\nAn early implementation of engineering notation in form of range selection and number display with SI prefixes was introduced in the computerized HP 5360A frequency counter by Hewlett-Packard in 1969.\n\nBased on an idea by Peter D. Dickinson the first calculator to support engineering notation displaying the power-of-ten exponent values was the HP-25 in 1975. It was implemented as a dedicated display mode in addition to scientific notation.\n\nIn 1975 Commodore introduced a number of scientific calculators (like the SR4148/SR4148R and SR4190R) providing a \"variable scientific notation\", where pressing the and keys shifted the exponent and decimal point by ±1 in \"scientific\" notation. Between 1976 and 1980 the same \"exponent shift\" facility was also available on some Texas Instruments calculators of the pre-LCD era such as early SR-40, TI-30 and TI-45 model variants utilizing () instead. This can be seen as a precursor to a feature implemented on many Casio calculators since about 1978/1979 (f.e. in the FX-501P/FX-502P), where number display in \"engineering\" notation is available on demand by the single press of a () button (instead of having to activate a dedicated display mode as on most other calculators), and subsequent button presses would shift the exponent and decimal point of the number displayed by ±3 in order to easily let results match a desired prefix. Some graphical calculators (for example the fx-9860G) in the 2000s also support the display of some SI prefixes (f, p, n, µ, m, k, M, G, T, P, E) as suffixes in engineering mode.\n\nCompared to normalized scientific notation, one disadvantage of using SI prefixes and engineering notation is that significant figures are not always readily apparent. For example, 500 µm and 500 × 10 m cannot express the uncertainty distinctions between 5 × 10 m, 5.0 × 10 m, and 5.00 × 10 m. This can be solved by changing the range of the coefficient in front of the power from the common 1–1000 to 0.001–1.0. In some cases this may be suitable; in others it may be impractical. In the previous example, 0.5 mm, 0.50 mm, or 0.500 mm would have been used to show uncertainty and significant figures. It is also common to state the precision explicitly, such as \"47 kΩ ±5%\"\n\nAnother example: when the speed of light (exactly by the definition of the meter and second) is expressed as 3.00 × 10 m/s or 3.00 × 10 km/s then it is clear that it is between 299 500 km/s and 300 500 km/s, but when using 300 × 10 m/s, or 300 × 10 km/s, 300 000 km/s, or the unusual but short 300 Mm/s, this is not clear. A possibility is using 0.300 Gm/s, convenient to write, but somewhat impractical in understanding (writing something large as a fraction of something even larger; in a context of larger numbers expressed in the same unit this could be convenient, but that is not applicable here).\n\nOn the other hand, engineering notation allows the numbers to explicitly match their corresponding SI prefixes, which facilitates reading and oral communication. For example, 12.5 × 10 m can be read as \"twelve-point-five nanometers\" and written as 12.5 nm, while its scientific notation equivalent 1.25 × 10 m would likely be read out as \"one-point-two-five times ten-to-the-negative-eight meters\".\n\nEngineering notation, like scientific notation generally, can use the E-notation, such that\n\ncan be written as\n\nThe \"E\" (or \"e\") should not be confused with the exponential \"e\" which holds a completely different significance. In the latter case, it would be shown that 3e ≈ 0.000 370 23.\n\nJust like decimal engineering notation can be viewed as a base-1000 scientific notation (10 = 1000), binary engineering notation relates to a base-1024 scientific notation (2 = 1024), where the exponent of two must be divisible by ten. This is closely related to the base-2 floating-point representation commonly used in computer arithmetic, and the usage of IEC binary prefixes (e.g. 1B10 for 1 × 2, 1B20 for 1 × 2, 1B30 for 1 × 2, 1B40 for 1 × 2 etc.).\n\n\n"}
{"id": "9891", "url": "https://en.wikipedia.org/wiki?curid=9891", "title": "Entropy", "text": "Entropy\n\nIn statistical mechanics, entropy is an extensive property of a thermodynamic system. It is closely related to the number of microscopic configurations (known as microstates) that are consistent with the macroscopic quantities that characterize the system (such as its volume, pressure and temperature). Under the assumption that each microstate is equally probable, the entropy formula_1 is the natural logarithm of the number of microstates, multiplied by the Boltzmann constant . Formally,\n\nMacroscopic systems typically have a very large number of possible microscopic configurations. For example, the entropy of an ideal gas is proportional to the number of gas molecules . Roughly twenty liters of gas at room temperature and atmospheric pressure has (Avogadro's number). At equilibrium, each of the configurations can be regarded as random and equally likely. \n\nThe second law of thermodynamics states that the entropy of an isolated system never decreases. Such systems spontaneously evolve towards thermodynamic equilibrium, the state with maximum entropy. Non-isolated systems may lose entropy, provided their environment's entropy increases by at least that amount so that the total entropy increases. Entropy is a function of the state of the system, so the change in entropy of a system is determined by its initial and final states. In the idealization that a process is reversible, the entropy does not change, while irreversible processes always increase the total entropy.\n\nBecause it is determined by the number of random microstates, entropy is related to the amount of additional information needed to specify the exact physical state of a system, given its macroscopic specification. For this reason, it is often said that entropy is an expression of the disorder, or randomness of a system, or of the lack of information about it. The concept of entropy plays a central role in information theory.\n\nBoltzmann's constant, and therefore entropy, have dimensions of energy divided by temperature, which has a unit of joules per kelvin (J K) in the International System of Units (or kg m s K in terms of base units). The entropy of a substance is usually given as an intensive property—either entropy per unit mass (SI unit: J K kg) or entropy per unit amount of substance (SI unit: J K mol).\n\nThe French mathematician Lazare Carnot proposed in his 1803 paper \"Fundamental Principles of Equilibrium and Movement\" that in any machine the accelerations and shocks of the moving parts represent losses of \"moment of activity\". In other words, in any natural process there exists an inherent tendency towards the dissipation of useful energy. Building on this work, in 1824 Lazare's son Sadi Carnot published \"Reflections on the Motive Power of Fire\" which posited that in all heat-engines, whenever \"caloric\" (what is now known as heat) falls through a temperature difference, work or motive power can be produced from the actions of its fall from a hot to cold body. He made the analogy with that of how water falls in a water wheel. This was an early insight into the second law of thermodynamics. Carnot based his views of heat partially on the early 18th century \"Newtonian hypothesis\" that both heat and light were types of indestructible forms of matter, which are attracted and repelled by other matter, and partially on the contemporary views of Count Rumford who showed (1789) that heat could be created by friction as when cannon bores are machined. Carnot reasoned that if the body of the working substance, such as a body of steam, is returned to its original state at the end of a complete engine cycle, that \"no change occurs in the condition of the working body\".\n\nThe first law of thermodynamics, deduced from the heat-friction experiments of James Joule in 1843, expresses the concept of energy, and its conservation in all processes; the first law, however, is unable to quantify the effects of friction and dissipation.\n\nIn the 1850s and 1860s, German physicist Rudolf Clausius objected to the supposition that no change occurs in the working body, and gave this \"change\" a mathematical interpretation by questioning the nature of the inherent loss of usable heat when work is done, e.g. heat produced by friction. Clausius described entropy as the \"transformation-content\", i.e. dissipative energy use, of a thermodynamic system or working body of chemical species during a change of state. This was in contrast to earlier views, based on the theories of Isaac Newton, that heat was an indestructible particle that had mass.\n\nLater, scientists such as Ludwig Boltzmann, Josiah Willard Gibbs, and James Clerk Maxwell gave entropy a statistical basis. In 1877 Boltzmann visualized a probabilistic way to measure the entropy of an ensemble of ideal gas particles, in which he defined entropy to be proportional to the natural logarithm of the number of microstates such a gas could occupy. Henceforth, the essential problem in statistical thermodynamics, i.e. according to Erwin Schrödinger, has been to determine the distribution of a given amount of energy E over N identical systems.\nCarathéodory linked entropy with a mathematical definition of irreversibility, in terms of trajectories and integrability.\n\nThere are two related definitions of entropy: the thermodynamic definition and the statistical mechanics definition. Historically, the classical thermodynamics definition developed first. In the classical thermodynamics viewpoint, the system is composed of very large numbers of constituents (atoms, molecules) and the state of the system is described by the average thermodynamic properties of those constituents; the details of the system's constituents are not directly considered, but their behavior is described by macroscopically averaged properties, e.g. temperature, pressure, entropy, heat capacity. The early classical definition of the properties of the system assumed equilibrium. The classical thermodynamic definition of entropy has more recently been extended into the area of non-equilibrium thermodynamics. Later, the thermodynamic properties, including entropy, were given an alternative definition in terms of the statistics of the motions of the microscopic constituents of a system — modeled at first classically, e.g. Newtonian particles constituting a gas, and later quantum-mechanically (photons, phonons, spins, etc.). The statistical mechanics description of the behavior of a system is necessary as the definition of the properties of a system using classical thermodynamics becomes an increasingly unreliable method of predicting the final state of a system that is subject to some process.\n\nThere are many thermodynamic properties that are functions of state. This means that at a particular thermodynamic state (which should not be confused with the microscopic state of a system), these properties have a certain value. Often, if two properties of the system are determined, then the state is determined and the other properties' values can also be determined. For instance, a quantity of gas at a particular temperature and pressure has its state fixed by those values and thus has a specific volume that is determined by those values. As another instance, a system composed of a pure substance of a single phase at a particular uniform temperature and pressure is determined (and is thus a particular state) and is at not only a particular volume but also at a particular entropy. The fact that entropy is a function of state is one reason it is useful. In the Carnot cycle, the working fluid returns to the same state it had at the start of the cycle, hence the line integral of any state function, such as entropy, over this reversible cycle is zero.\n\nEntropy is conserved for a reversible process. A reversible process is one that does not deviate from thermodynamic equilibrium, while producing the maximum work. Any process which happens quickly enough to deviate from thermal equilibrium cannot be reversible. In these cases energy is lost to heat, total entropy increases, and the potential for maximum work to be done in the transition is also lost. More specifically, total entropy is conserved in a reversible process and not conserved in an irreversible process. For example, in the Carnot cycle, while the heat flow from the hot reservoir to the cold reservoir represents an increase in entropy, the work output, if reversibly and perfectly stored in some energy storage mechanism, represents a decrease in entropy that could be used to operate the heat engine in reverse and return to the previous state, thus the \"total\" entropy change is still zero at all times if the entire process is reversible. An irreversible process increases entropy.\n\nThe concept of entropy arose from Rudolf Clausius's study of the Carnot cycle. In a Carnot cycle, heat is absorbed isothermally at temperature from a 'hot' reservoir and given up isothermally as heat to a 'cold' reservoir at . According to Carnot's principle, work can only be produced by the system when there is a temperature difference, and the work should be some function of the difference in temperature and the heat absorbed (). Carnot did not distinguish between and , since he was using the incorrect hypothesis that caloric theory was valid, and hence heat was conserved (the incorrect assumption that and were equal) when, in fact, is greater than . Through the efforts of Clausius and Kelvin, it is now known that the maximum work that a heat engine can produce is the product of the Carnot efficiency and the heat absorbed from the hot reservoir:\n\nTo derive the Carnot efficiency, which is (a number less than one), Kelvin had to evaluate the ratio of the work output to the heat absorbed during the isothermal expansion with the help of the Carnot-Clapeyron equation which contained an unknown function, known as the Carnot function. The possibility that the Carnot function could be the temperature as measured from a zero temperature, was suggested by Joule in a letter to Kelvin. This allowed Kelvin to establish his absolute temperature scale. It is also known that the work produced by the system is the difference between the heat absorbed from the hot reservoir and the heat given up to the cold reservoir:\n\nSince the latter is valid over the entire cycle, this gave Clausius the hint that at each stage of the cycle, work and heat would not be equal, but rather their difference would be a state function that would vanish upon completion of the cycle. The state function was called the internal energy and it became the first law of thermodynamics.\n\nNow equating () and () gives\n\nor\n\nThis implies that there is a function of state which is conserved over a complete cycle of the Carnot cycle. Clausius called this state function \"entropy\". One can see that entropy was discovered through mathematics rather than through laboratory results. It is a mathematical construct and has no easy physical analogy. This makes the concept somewhat obscure or abstract, akin to how the concept of energy arose.\n\nClausius then asked what would happen if there should be less work produced by the system than that predicted by Carnot's principle. The right-hand side of the first equation would be the upper bound of the work output by the system, which would now be converted into an inequality\n\nWhen the second equation is used to express the work as a difference in heats, we get\n\nSo more heat is given up to the cold reservoir than in the Carnot cycle. If we denote the entropies by for the two states, then the above inequality can be written as a decrease in the entropy\n\nThe entropy that leaves the system is greater than the entropy that enters the system, implying that some irreversible process prevents the cycle from producing the maximum amount of work predicted by the Carnot equation.\n\nThe Carnot cycle and efficiency are useful because they define the upper bound of the possible work output and the efficiency of any classical thermodynamic system. Other cycles, such as the Otto cycle, Diesel cycle and Brayton cycle, can be analyzed from the standpoint of the Carnot cycle. Any machine or process that converts heat to work and is claimed to produce an efficiency greater than the Carnot efficiency is not viable because it violates the second law of thermodynamics. For very small numbers of particles in the system, statistical thermodynamics must be used. The efficiency of devices such as photovoltaic cells requires an analysis from the standpoint of quantum mechanics.\n\nThe thermodynamic definition of entropy was developed in the early 1850s by Rudolf Clausius and essentially describes how to measure the entropy of an isolated system in thermodynamic equilibrium with its parts. Clausius created the term entropy as an extensive thermodynamic variable that was shown to be useful in characterizing the Carnot cycle. Heat transfer along the isotherm steps of the Carnot cycle was found to be proportional to the temperature of a system (known as its absolute temperature). This relationship was expressed in increments of entropy equal to the ratio of incremental heat transfer divided by temperature, which was found to vary in the thermodynamic cycle but eventually return to the same value at the end of every cycle. Thus it was found to be a function of state, specifically a thermodynamic state of the system. \n\nWhile Clausius based his definition on a reversible process, there are also irreversible processes that change entropy. Following the second law of thermodynamics, entropy of an isolated system always increases for irreversible processes. The difference between an isolated system and closed system is that heat may \"not\" flow to and from an isolated system, but heat flow to and from a closed system is possible. Nevertheless, for both closed and isolated systems, and indeed, also in open systems, irreversible thermodynamics processes may occur.\n\nAccording to the Clausius equality, for a reversible cyclic process:\nformula_10\nThis means the line integral formula_11 is path-independent.\n\nSo we can define a state function called entropy, which satisfies\nformula_12\n\nClausius coined the name \"entropy\" () for in 1865. He gives \"transformational content\" () as a synonym, paralleling his \"thermal and ergonal content\" () as the name of , but preferring the term \"entropy\" as a close parallel of \"energy\", formed by replacing the root of \"work\" by that of \"transformation\". \n\nTo find the entropy difference between any two states of a system, the integral must be evaluated for some reversible path between the initial and final states. Since entropy is a state function, the entropy change of the system for an irreversible path is the same as for a reversible path between the same two states. However, the entropy change of the surroundings will be different.\n\nWe can only obtain the change of entropy by integrating the above formula. To obtain the absolute value of the entropy, we need the third law of thermodynamics, which states that \"S\" = 0 at absolute zero for perfect crystals.\n\nFrom a macroscopic perspective, in classical thermodynamics the entropy is interpreted as a state function of a thermodynamic system: that is, a property depending only on the current state of the system, independent of how that state came to be achieved. In any process where the system gives up energy Δ\"E\", and its entropy falls by Δ\"S\", a quantity at least \"T\" Δ\"S\" of that energy must be given up to the system's surroundings as unusable heat (\"T\" is the temperature of the system's external surroundings). Otherwise the process cannot go forward. In classical thermodynamics, the entropy of a system is defined only if it is in thermodynamic equilibrium.\n\nThe statistical definition was developed by Ludwig Boltzmann in the 1870s by analyzing the statistical behavior of the microscopic components of the system. Boltzmann showed that this definition of entropy was equivalent to the thermodynamic entropy to within a constant number which has since been known as Boltzmann's constant. In summary, the thermodynamic definition of entropy provides the experimental definition of entropy, while the statistical definition of entropy extends the concept, providing an explanation and a deeper understanding of its nature.\n\nThe interpretation of entropy in statistical mechanics is the measure of uncertainty, or \"mixedupness\" in the phrase of Gibbs, which remains about a system after its observable macroscopic properties, such as temperature, pressure and volume, have been taken into account. For a given set of macroscopic variables, the entropy measures the degree to which the probability of the system is spread out over different possible microstates. In contrast to the macrostate, which characterizes plainly observable average quantities, a microstate specifies all molecular details about the system including the position and velocity of every molecule. The more such states available to the system with appreciable probability, the greater the entropy. In statistical mechanics, entropy is a measure of the number of ways in which a system may be arranged, often taken to be a measure of \"disorder\" (the higher the entropy, the higher the disorder). This definition describes the entropy as being proportional to the natural logarithm of the number of possible microscopic configurations of the individual atoms and molecules of the system (microstates) which could give rise to the observed macroscopic state (macrostate) of the system. The constant of proportionality is the Boltzmann constant.\n\nSpecifically, entropy is a logarithmic measure of the number of states with significant probability of being occupied:\n\nor, equivalently, the expected value of the logarithm of the probability that a microstate will be occupied\n\nwhere \"k\" is the Boltzmann constant, equal to .\nThe summation is over all the possible microstates of the system, and \"p\" is the probability that the system is in the \"i\"-th microstate. This definition assumes that the basis set of states has been picked so that there is no information on their relative phases. In a different basis set, the more general expression is\n\nwhere formula_16 is the density matrix, formula_17 is trace and formula_18 is the matrix logarithm. This density matrix formulation is not needed in cases of thermal equilibrium so long as the basis states are chosen to be energy eigenstates. For most practical purposes, this can be taken as the fundamental definition of entropy since all other formulas for \"S\" can be mathematically derived from it, but not vice versa.\n\nIn what has been called \"the fundamental assumption of statistical thermodynamics\" or \"the fundamental postulate in statistical mechanics\", the occupation of any microstate is assumed to be equally probable (i.e. \"p\" = 1/Ω, where Ω is the number of microstates); this assumption is usually justified for an isolated system in equilibrium. Then the previous equation reduces to\n\nIn thermodynamics, such a system is one in which the volume, number of molecules, and internal energy are fixed (the microcanonical ensemble).\n\nThe most general interpretation of entropy is as a measure of our uncertainty about a system. The equilibrium state of a system maximizes the entropy because we have lost all information about the initial conditions except for the conserved variables; maximizing the entropy maximizes our ignorance about the details of the system. This uncertainty is not of the everyday subjective kind, but rather the uncertainty inherent to the experimental method and interpretative model.\n\nThe interpretative model has a central role in determining entropy. The qualifier \"for a given set of macroscopic variables\" above has deep implications: if two observers use different sets of macroscopic variables, they see different entropies. For example, if observer A uses the variables \"U\", \"V\" and \"W\", and observer B uses \"U\", \"V\", \"W\", \"X\", then, by changing \"X\", observer B can cause an effect that looks like a violation of the second law of thermodynamics to observer A. In other words: the set of macroscopic variables one chooses must include everything that may change in the experiment, otherwise one might see decreasing entropy!\n\nEntropy can be defined for any Markov processes with reversible dynamics and the detailed balance property.\n\nIn Boltzmann's 1896 \"Lectures on Gas Theory\", he showed that this expression gives a measure of entropy for systems of atoms and molecules in the gas phase, thus providing a measure for the entropy of classical thermodynamics.\n\nEntropy arises directly from the Carnot cycle. It can also be described as the reversible heat divided by temperature. Entropy is a fundamental function of state.\n\nIn a thermodynamic system, pressure, density, and temperature tend to become uniform over time because the equilibrium state has higher probability (more possible combinations of microstates) than any other state.\n\nAs an example, for a glass of ice water in air at room temperature, the difference in temperature between a warm room (the surroundings) and cold glass of ice and water (the system and not part of the room), begins to equalize as portions of the thermal energy from the warm surroundings spread to the cooler system of ice and water. Over time the temperature of the glass and its contents and the temperature of the room become equal. In other words, the entropy of the room has decreased as some of its energy has been dispersed to the ice and water.\n\nHowever, as calculated in the example, the entropy of the system of ice and water has increased more than the entropy of the surrounding room has decreased. In an isolated system such as the room and ice water taken together, the dispersal of energy from warmer to cooler always results in a net increase in entropy. Thus, when the \"universe\" of the room and ice water system has reached a temperature equilibrium, the entropy change from the initial state is at a maximum. The entropy of the thermodynamic system is a measure of how far the equalization has progressed.\n\nThermodynamic entropy is a non-conserved state function that is of great importance in the sciences of physics and chemistry. Historically, the concept of entropy evolved to explain why some processes (permitted by conservation laws) occur spontaneously while their time reversals (also permitted by conservation laws) do not; systems tend to progress in the direction of increasing entropy. For isolated systems, entropy never decreases. This fact has several important consequences in science: first, it prohibits \"perpetual motion\" machines; and second, it implies the arrow of entropy has the same direction as the arrow of time. Increases in entropy correspond to irreversible changes in a system, because some energy is expended as waste heat, limiting the amount of work a system can do.\n\nUnlike many other functions of state, entropy cannot be directly observed but must be calculated. Entropy can be calculated for a substance as the standard molar entropy from absolute zero (also known as absolute entropy) or as a difference in entropy from some other reference state which is defined as zero entropy. Entropy has the dimension of energy divided by temperature, which has a unit of joules per kelvin (J/K) in the International System of Units. While these are the same units as heat capacity, the two concepts are distinct. Entropy is not a conserved quantity: for example, in an isolated system with non-uniform temperature, heat might irreversibly flow and the temperature become more uniform such that entropy increases. The second law of thermodynamics states that a closed system has entropy which may increase or otherwise remain constant. Chemical reactions cause changes in entropy and entropy plays an important role in determining in which direction a chemical reaction spontaneously proceeds.\n\nOne dictionary definition of entropy is that it is \"a measure of thermal energy per unit temperature that is not available for useful work\". For instance, a substance at uniform temperature is at maximum entropy and cannot drive a heat engine. A substance at non-uniform temperature is at a lower entropy (than if the heat distribution is allowed to even out) and some of the thermal energy can drive a heat engine.\n\nA special case of entropy increase, the entropy of mixing, occurs when two or more different substances are mixed. If the substances are at the same temperature and pressure, there is no net exchange of heat or work – the entropy change is entirely due to the mixing of the different substances. At a statistical mechanical level, this results due to the change in available volume per particle with mixing.\n\nThe second law of thermodynamics requires that, in general, the total entropy of any system can't decrease other than by increasing the entropy of some other system. Hence, in a system isolated from its environment, the entropy of that system tends not to decrease. It follows that heat can't flow from a colder body to a hotter body without the application of work (the imposition of order) to the colder body. Secondly, it is impossible for any device operating on a cycle to produce net work from a single temperature reservoir; the production of net work requires flow of heat from a hotter reservoir to a colder reservoir, or a single expanding reservoir undergoing adiabatic cooling, which performs adiabatic work. As a result, there is no possibility of a perpetual motion system. It follows that a reduction in the increase of entropy in a specified process, such as a chemical reaction, means that it is energetically more efficient.\n\nIt follows from the second law of thermodynamics that the entropy of a system that is not isolated may decrease. An air conditioner, for example, may cool the air in a room, thus reducing the entropy of the air of that system. The heat expelled from the room (the system), which the air conditioner transports and discharges to the outside air, always makes a bigger contribution to the entropy of the environment than the decrease of the entropy of the air of that system. Thus, the total of entropy of the room plus the entropy of the environment increases, in agreement with the second law of thermodynamics.\n\nIn mechanics, the second law in conjunction with the fundamental thermodynamic relation places limits on a system's ability to do useful work. The entropy change of a system at temperature \"T\" absorbing an infinitesimal amount of heat \"δq\"\nin a reversible way, is given by \"δq\"/\"T\". More explicitly, an energy is not available to do useful work, where \"T\" is the temperature of the coldest accessible reservoir or heat sink external to the system. For further discussion, see \"Exergy\".\n\nStatistical mechanics demonstrates that entropy is governed by probability, thus allowing for a decrease in disorder even in an isolated system. Although this is possible, such an event has a small probability of occurring, making it unlikely.\n\nThe applicability of a second law of thermodynamics is limited to systems which are near or in equilibrium state. At the same time, laws governing systems which are far from equilibrium are still debatable. One of the guiding principles for such systems is the maximum entropy production principle. It claims that non-equilibrium systems evolve such as to maximize its entropy production.\n\nThe entropy of a system depends on its internal energy and its external parameters, such as its volume. In the thermodynamic limit, this fact leads to an equation relating the change in the internal energy \"U\" to changes in the entropy and the external parameters. This relation is known as the \"fundamental thermodynamic relation\". If external pressure \"P\" bears on the volume \"V\" as the only external parameter, this relation is:\n\nSince both internal energy and entropy are monotonic functions of temperature \"T\", implying that the internal energy is fixed when one specifies the entropy and the volume, this relation is valid even if the change from one state of thermal equilibrium to another with infinitesimally larger entropy and volume happens in a non-quasistatic way (so during this change the system may be very far out of thermal equilibrium and then the entropy, pressure and temperature may not exist).\n\nThe fundamental thermodynamic relation implies many thermodynamic identities that are valid in general, independent of the microscopic details of the system. Important examples are the Maxwell relations and the relations between heat capacities.\n\nThermodynamic entropy is central in chemical thermodynamics, enabling changes to be quantified and the outcome of reactions predicted. The second law of thermodynamics states that entropy in an isolated system – the combination of a subsystem under study and its surroundings – increases during all spontaneous chemical and physical processes. The Clausius equation of δ\"q\"/\"T\" = Δ\"S\" introduces the measurement of entropy change, Δ\"S\". Entropy change describes the direction and quantifies the magnitude of simple changes such as heat transfer between systems – always from hotter to cooler spontaneously.\n\nThe thermodynamic entropy therefore has the dimension of energy divided by temperature, and the unit joule per kelvin (J/K) in the International System of Units (SI).\n\nThermodynamic entropy is an extensive property, meaning that it scales with the size or extent of a system. In many processes it is useful to specify the entropy as an intensive property independent of the size, as a specific entropy characteristic of the type of system studied. Specific entropy may be expressed relative to a unit of mass, typically the kilogram (unit: ). Alternatively, in chemistry, it is also referred to one mole of substance, in which case it is called the \"molar entropy\" with a unit of .\n\nThus, when one mole of substance at about is warmed by its surroundings to , the sum of the incremental values of \"q\"/\"T\" constitute each element's or compound's standard molar entropy, an indicator of the amount of energy stored by a substance at . Entropy change also measures the mixing of substances as a summation of their relative quantities in the final mixture.\n\nEntropy is equally essential in predicting the extent and direction of complex chemical reactions. For such applications, Δ\"S\" must be incorporated in an expression that includes both the system and its surroundings, Δ\"S\" = Δ\"S\" + Δ\"S\" . This expression becomes, via some steps, the Gibbs free energy equation for reactants and products in the system: Δ\"G\" [the Gibbs free energy change of the system] = Δ\"H\" [the enthalpy change] −\"T\" Δ\"S\" [the entropy change].\n\nIn chemical engineering, the principles of thermodynamics are commonly applied to \"open systems\", i.e. those in which heat, work, and mass flow across the system boundary. Flows of both heat (formula_21) and work, i.e. formula_22 (shaft work) and \"P\"(\"dV\"/\"dt\") (pressure-volume work), across the system boundaries, in general cause changes in the entropy of the system. Transfer as heat entails entropy transfer formula_23 where \"T\" is the absolute thermodynamic temperature of the system at the point of the heat flow. If there are mass flows across the system boundaries, they also influence the total entropy of the system. This account, in terms of heat and work, is valid only for cases in which the work and heat transfers are by paths physically distinct from the paths of entry and exit of matter from the system.\n\nTo derive a generalized entropy balanced equation, we start with the general balance equation for the change in any extensive quantity Θ in a thermodynamic system, a quantity that may be either conserved, such as energy, or non-conserved, such as entropy. The basic generic balance expression states that dΘ/dt, i.e. the rate of change of Θ in the system, equals the rate at which Θ enters the system at the boundaries, minus the rate at which Θ leaves the system across the system boundaries, plus the rate at which Θ is generated within the system. For an open thermodynamic system in which heat and work are transferred by paths separate from the paths for transfer of matter, using this generic balance equation, with respect to the rate of change with time \"t\" of the extensive quantity entropy \"S\", the entropy balance equation is:\n\nwhere\n\nNote, also, that if there are multiple heat flows, the term formula_29 is replaced by formula_30 where formula_31 is the heat flow and formula_32 is the temperature at the \"j\"th heat flow port into the system.\n\nFor certain simple transformations in systems of constant composition, the entropy changes are given by simple formulas.\n\nFor the expansion (or compression) of an ideal gas from an initial volume formula_33 and pressure formula_34 to a final volume formula_35 and pressure formula_36 at any constant temperature, the change in entropy is given by:\n\nHere formula_38 is the number of moles of gas and formula_39 is the ideal gas constant. These equations also apply for expansion into a finite vacuum or a throttling process, where the temperature, internal energy and enthalpy for an ideal gas remain constant.\n\nFor heating or cooling of any system (gas, liquid or solid) at constant pressure from an initial temperature formula_40 to a final temperature formula_41, the entropy change is\nprovided that the constant-pressure molar heat capacity (or specific heat) C is constant and that no phase transition occurs in this temperature interval.\n\nSimilarly at constant volume, the entropy change is\nwhere the constant-volume heat capacity C is constant and there is no phase change.\n\nAt low temperatures near absolute zero, heat capacities of solids quickly drop off to near zero, so the assumption of constant heat capacity does not apply.\n\nSince entropy is a state function, the entropy change of any process in which temperature and volume both vary is the same as for a path divided into two steps – heating at constant volume and expansion at constant temperature. For an ideal gas, the total entropy change is\n\nSimilarly if the temperature and pressure of an ideal gas both vary,\n\nReversible phase transitions occur at constant temperature and pressure. The reversible heat is the enthalpy change for the transition, and the entropy change is the enthalpy change divided by the thermodynamic temperature. For fusion (melting) of a solid to a liquid at the melting point \"T\", the entropy of fusion is\nSimilarly, for vaporization of a liquid to a gas at the boiling point \"T\", the entropy of vaporization is\n\nAs a fundamental aspect of thermodynamics and physics, several different approaches to entropy beyond that of Clausius and Boltzmann are valid.\n\nThe following is a list of additional definitions of entropy from a collection of textbooks:\n\nIn Boltzmann's definition, entropy is a measure of the number of possible microscopic states (or microstates) of a system in thermodynamic equilibrium. Consistent with the Boltzmann definition, the second law of thermodynamics needs to be re-worded as such that entropy increases over time, though the underlying principle remains the same.\n\nEntropy has often been loosely associated with the amount of order or disorder, or of chaos, in a thermodynamic system. The traditional qualitative description of entropy is that it refers to changes in the status quo of the system and is a measure of \"molecular disorder\" and the amount of wasted energy in a dynamical energy transformation from one state or form to another. In this direction, several recent authors have derived exact entropy formulas to account for and measure disorder and order in atomic and molecular assemblies. One of the simpler entropy order/disorder formulas is that derived in 1984 by thermodynamic physicist Peter Landsberg, based on a combination of thermodynamics and information theory arguments. He argues that when constraints operate on a system, such that it is prevented from entering one or more of its possible or permitted states, as contrasted with its forbidden states, the measure of the total amount of \"disorder\" in the system is given by:\n\nSimilarly, the total amount of \"order\" in the system is given by:\n\nIn which \"C\" is the \"disorder\" capacity of the system, which is the entropy of the parts contained in the permitted ensemble, \"C\" is the \"information\" capacity of the system, an expression similar to Shannon's channel capacity, and \"C\" is the \"order\" capacity of the system.\n\nThe concept of entropy can be described qualitatively as a measure of energy dispersal at a specific temperature. Similar terms have been in use from early in the history of classical thermodynamics, and with the development of statistical thermodynamics and quantum theory, entropy changes have been described in terms of the mixing or \"spreading\" of the total energy of each constituent of a system over its particular quantized energy levels.\n\nAmbiguities in the terms \"disorder\" and \"chaos\", which usually have meanings directly opposed to equilibrium, contribute to widespread confusion and hamper comprehension of entropy for most students. As the second law of thermodynamics shows, in an isolated system internal portions at different temperatures tend to adjust to a single uniform temperature and thus produce equilibrium. A recently developed educational approach avoids ambiguous terms and describes such spreading out of energy as dispersal, which leads to loss of the differentials required for work even though the total energy remains constant in accordance with the first law of thermodynamics (compare discussion in next section). Physical chemist Peter Atkins, for example, who previously wrote of dispersal leading to a disordered state, now writes that \"spontaneous changes are always accompanied by a dispersal of energy\".\n\nFollowing on from the above, it is possible (in a thermal context) to regard entropy as an indicator or measure of the \"effectiveness\" or \"usefulness\" of a particular quantity of energy. This is because energy supplied at a high temperature (i.e. with low entropy) tends to be more useful than the same amount of energy available at room temperature. Mixing a hot parcel of a fluid with a cold one produces a parcel of intermediate temperature, in which the overall increase in entropy represents a \"loss\" which can never be replaced.\n\nThus, the fact that the entropy of the universe is steadily increasing, means that its total energy is becoming less useful: eventually, this will lead to the \"heat death of the Universe\".\n\nA definition of entropy based entirely on the relation of adiabatic accessibility between equilibrium states was given by E.H.Lieb and J. Yngvason in 1999. This approach has several predecessors, including the pioneering work of Constantin Carathéodory from 1909 and the monograph by R. Giles. In the setting of Lieb and Yngvason one starts by picking, for a unit amount of the substance under consideration, two reference states formula_50 and formula_51 such that the latter is adiabatically accessible from the former but not vice versa. Defining the entropies of the reference states to be 0 and 1 respectively the entropy of a state formula_52 is defined as the largest number formula_53 such that formula_52 is adiabatically accessible from a composite state consisting of an amount formula_53 in the state formula_51 and a complementary amount, formula_57, in the state formula_50. A simple but important result within this setting is that entropy is uniquely determined, apart from a choice of unit and an additive constant for each chemical element, by the following properties: It is monotonic with respect to the relation of adiabatic accessibility, additive on composite systems, and extensive under scaling.\n\nIn quantum statistical mechanics, the concept of entropy was developed by John von Neumann and is generally referred to as \"von Neumann entropy\",\n\nwhere ρ is the density matrix and Tr is the trace operator.\n\nThis upholds the correspondence principle, because in the classical limit, when the phases between the basis states used for the classical probabilities are purely random, this expression is equivalent to the familiar classical definition of entropy,\n\ni.e. in such a basis the density matrix is diagonal.\n\nVon Neumann established a rigorous mathematical framework for quantum mechanics with his work \"Mathematische Grundlagen der Quantenmechanik\". He provided in this work a theory of measurement, where the usual notion of wave function collapse is described as an irreversible process (the so-called von Neumann or projective measurement). Using this concept, in conjunction with the density matrix he extended the classical concept of entropy into the quantum domain.\n\nWhen viewed in terms of information theory, the entropy state function is simply the amount of information (in the Shannon sense) that would be needed to specify the full microstate of the system. This is left unspecified by the macroscopic description.\n\nIn information theory, \"entropy\" is the measure of the amount of information that is missing before reception and is sometimes referred to as \"Shannon entropy\". Shannon entropy is a broad and general concept which finds applications in information theory as well as thermodynamics. It was originally devised by Claude Shannon in 1948 to study the amount of information in a transmitted message. The definition of the information entropy is, however, quite general, and is expressed in terms of a discrete set of probabilities \"p so that\n\nIn the case of transmitted messages, these probabilities were the probabilities that a particular message was actually transmitted, and the entropy of the message system was a measure of the average amount of information in a message. For the case of equal probabilities (i.e. each message is equally probable), the Shannon entropy (in bits) is just the number of yes/no questions needed to determine the content of the message.\n\nThe question of the link between information entropy and thermodynamic entropy is a debated topic. While most authors argue that there is a link between the two, a few argue that they have nothing to do with each other.\nThe expressions for the two entropies are similar. If \"W\" is the number of microstates that can yield a given macrostate, and each microstate has the same \"a priori\" probability, then that probability is . The Shannon entropy (in nats) is:\n\nand if entropy is measured in units of \"k\" per nat, then the entropy is given by:\n\nwhich is the famous Boltzmann entropy formula when \"k\" is Boltzmann's constant, which may be interpreted as the thermodynamic entropy per nat. There are many ways of demonstrating the equivalence of \"information entropy\" and \"physics entropy\", that is, the equivalence of \"Shannon entropy\" and \"Boltzmann entropy\". Nevertheless, some authors argue for dropping the word entropy for the \"H\" function of information theory and using Shannon's other term \"uncertainty\" instead.\n\nEntropy of a substance can be measured, although in an indirect way. The measurement uses the \"definition of temperature\" in terms of entropy, while limiting energy exchange to heat (formula_64).\n\nThe resulting relation describes how entropy changes formula_66 when a small amount of energy formula_67 is introduced into the system at a certain temperature formula_41.\n\nThe process of measurement goes as follows. First, a sample of the substance is cooled as close to absolute zero as possible. At such temperatures, the entropy approaches zero—due to the definition of temperature. Then, small amounts of heat are introduced into the sample and the change in temperature is recorded, until the temperature reaches a desired value (usually 25°C). The obtained data allows the user to integrate the equation above, yielding the absolute value of entropy of the substance at the final temperature. This value of entropy is called calorimetric entropy.\n\nAlthough the concept of entropy was originally a thermodynamic construct, it has been adapted in other fields of study, including information theory, psychodynamics, thermoeconomics/ecological economics, and evolution.\nFor instance, an entropic argument has been recently proposed for explaining the preference of cave spiders in choosing a suitable area for laying their eggs.\n\n\nEntropy is the only quantity in the physical sciences that seems to imply a particular direction of progress, sometimes called an arrow of time. As time progresses, the second law of thermodynamics states that the entropy of an isolated system never decreases in large systems over significant periods of time. Hence, from this perspective, entropy measurement is thought of as a clock in these conditions.\n\nSince a finite universe is an isolated system, the second law of thermodynamics states that its total entropy is continually increasing. It has been speculated, since the 19th century, that the universe is fated to a heat death in which all the energy ends up as a homogeneous distribution of thermal energy so that no more work can be extracted from any source.\n\nIf the universe can be considered to have generally increasing entropy, then – as Roger Penrose has pointed out – gravity plays an important role in the increase because gravity causes dispersed matter to accumulate into stars, which collapse eventually into black holes. The entropy of a black hole is proportional to the surface area of the black hole's event horizon. Jacob Bekenstein and Stephen Hawking have shown that black holes have the maximum possible entropy of any object of equal size. This makes them likely end points of all entropy-increasing processes, if they are totally effective matter and energy traps. However, the escape of energy from black holes might be possible due to quantum activity (see Hawking radiation).\n\nThe role of entropy in cosmology remains a controversial subject since the time of Ludwig Boltzmann. Recent work has cast some doubt on the heat death hypothesis and the applicability of any simple thermodynamic model to the universe in general. Although entropy does increase in the model of an expanding universe, the maximum possible entropy rises much more rapidly, moving the universe further from the heat death with time, not closer. This results in an \"entropy gap\" pushing the system further away from the posited heat death equilibrium. Other complicating factors, such as the energy density of the vacuum and macroscopic quantum effects, are difficult to reconcile with thermodynamical models, making any predictions of large-scale thermodynamics extremely difficult.\n\nCurrent theories suggest the entropy gap to have been originally opened up by the early rapid exponential expansion of the universe.\n\nRomanian American economist Nicholas Georgescu-Roegen, a progenitor in economics and a paradigm founder of ecological economics, made extensive use of the entropy concept in his magnum opus on \"The Entropy Law and the Economic Process\". Due to Georgescu-Roegen's work, the laws of thermodynamics now form an integral part of the ecological economics school. Although his work was blemished somewhat by mistakes, a full chapter on the economics of Georgescu-Roegen has approvingly been included in one elementary physics textbook on the historical development of thermodynamics. Economic value, the most fundamental concept in economic theory, can be defined by entropy function. \n\nIn economics, Georgescu-Roegen's work has generated the term 'entropy pessimism'. Since the 1990s, leading ecological economist and steady-state theorist Herman Daly — a student of Georgescu-Roegen — has been the economics profession's most influential proponent of the entropy pessimism position. \n\n\n"}
{"id": "47665171", "url": "https://en.wikipedia.org/wiki?curid=47665171", "title": "Feminist language reform", "text": "Feminist language reform\n\nFeminist language reform or feminist language planning refers to the effort, often of political and grassroots movements, to change how language is used to gender people, activities and ideas on an individual and societal level. This initiative has been adopted in countries such as Sweden, Switzerland and Australia, and has been tentatively linked to higher gender equality.\n\nLinguistic activism and feminist authorship stemming from second wave feminism in the 1960s and 70s began to draw attention to gender bias in language, including \"the uncovering of the gendered nature of many linguistic rules and norms\". Scholarship such as Dennis Baron's \"Grammar and Gender\" and Anne Bodine's \"Androcentrism in Prescriptive Grammar\" uncovered historical male regulation to promote male-centric language such as the use of \"he\" as a generic pronoun.\n\nExposition and analysis of sexism in language through a grassroots feminist linguistics movement continued throughout the 80's and 90's, including study across languages and speech communities such as Germany and France. Study and documentation of gendered language has since spread to cover over 30 languages.\n\nFeminist language planning has more recently been instituted centrally in countries such as Sweden, Switzerland and Australia, with mixed results.\n\nSweden have made strides towards shifting their language to fit a less misogynistic society. In the Swedish language, there has never been a word for the female genitalia or even a translation of the word “vagina”, even though the word \"snopp\" translates to “penis” and has been used as such since the 1960s. Through history, there have been many slang terms used for the woman’s genitalia, including words such as \"fitta\" translated to “cunt”, \"där nere\" translated to “down-there”, and even \"mus\" translated to “mouse”. In the 1990s, Swedish media started to bring the absence of such a word to light. It wasn’t until the early 2000s did the feminists and activists start using the word \"snippa\" to be identified with the female genitalia. \"Snippa\"’s origins can be traced back to many different Swedish dialects. It’s popular definition “refers to something small and/or narrow, for example a small pike or a narrow boat”. In regards to genitalia, “it might have been used to refer to female genitalia of cows and pigs in the early twentieth century”. Since the popularization of using the word \"Snippa,\" the Swedish Academy added the word to the 2006 Swedish Language Dictionary.\n\nSome language reformers directly work with identifying and changing sexist undertones and patriarchal vocabulary through a method called “linguistic disruption”. An example: In the United States, the word “herstory” became popularized “to refer to history which is not only about men”. Sweden has also showed efforts in language planning regarding changing misogynistic undertones in their vocabulary. The Swedish Association for Sexuality Education has promoted the word \"slidkrans\" to replace the word for “hymen”, \"mödomshinna.\" “The new word, \"slidkrans\", is made up of the two parts \"slid\", translating to “vaginal” and \"krans\", translating to “garland”. It lacks the connotations of the ideology of virginity and honour attached to mödomshinna.”\n\nAdditionally, Sweden has also shown efforts in accepting more of a non-gender binary identity by creating the gender-neutral pronoun \"hen,\" which has been used by feminists and the LGBT community. Feminist language reform regarding gender is not of recent efforts. Early feminist language reformists have been fighting the male-dominant approach to language and raising awareness to the public about the gendered structure of the society’s language.\n\nAustralia has been identified as a nation that officially promotes the feminist influence to its public bureaucracy by implementing feminist language reform across many institutions. Since this planned social shift, Australia has seen changes in political and government leadership that aim to interfere with this reform, such as a shift towards a conservative-leaning government. There are shifts that come from such movements that support them as well, such as the gender-neutral pronoun “they” being more widely accepted.\n\nThe ongoing feminist movement acknowledges language as a “powerful instrument of patriarchy”. The goals set for linguistic reform aim to achieve linguistic equality of the sexes. A study of Australian newspapers from 1992 and 1996 found that the word “chairman” was used to describe all people holding the position, including women. This is an example of a linguistic issue that feminist’s seek to reform. Occupational nomenclature reflects gender bias when “professional nomenclature used in employment-related contexts displays bias in favour of men leading to women’s invisibility in this area.” The invisibility of women is a linguistic feminist issue because when encountering sentences predominantly using male pronouns, listeners are more likely to think of men before women and therefore women get overlooked. Positions are gendered to be male and the “continuing, frequent use reflects the fact that far more men than women continue to occupy this position.” This study further investigated and found instances of female professionals being specified as women while men would just be titled with the profession itself, for example “female judge,” “woman engineer,” and “woman politician.”\n\nSwitzerland has attempted to implement feminist language reform both formally and informally. However, changes in Switzerland have proven to be complicated due to the fact that Switzerland is a multilingual country (with the major languages being German, French, and Italian). The Bulletin Suisse de Linguistique Appliquée (Swiss Bulletin of Applied Linguistics) addressed this issue in 2000 when it created a special issue dedicated to the feminization of language in Switzerland. The bulletin attempted to critique language in Switzerland by creating a composite image of all the languages in Switzerland and how they interact with gender.\n\nThe most commonly spoken language in Switzerland is German. German is a gendered language. This has concerned some language activists due to the fact that many important societal position such as judge and professor possess the gender of male and are often referred to as he/him. Activists worry that the gendering of those words discourage women from entering those fields. This facet of the German language is particularly important in Switzerland because it was historically used as a justification to restrict women’s right to vote and pass the bar.\n\nVarious attempts to implement feminist language reform have been undertaken in German speaking Switzerland. The government and other organizations have attempted to implement language feminization in the realms of policy making, teaching, advertising, etc. Language feminization refers to when in writing or talking traditional male words are feminized by either using the feminine variant of the word or adding a feminine suffix. However, these attempts have had only limited success. For example, private Swiss radio and television broadcasts still generally use the generic-masculine form of words.\n\nThe second most commonly spoken language in Switzerland is French which is also a gendered language. The French language raises similar concerns to that of the German language. This is because many nouns (especially those of professions) are gendered. To address these concerns, the Swiss government has created a guide on the non-sexist use of the French language. However, these attempts at change have been met with little success. This is due to the fact that Switzerland has limited influence over the French language. Meanwhile, France and specifically the government backed Académie Française (French Academy) (the French council for matters relating to the French language) has resisted feminist language reform.\n\nThe main focus of Feminist Language Reform is to acknowledge the often unconscious ways that language both silences and emphasizes gender in negative ways. In some languages it is clear with gendered nouns how some words are gendered to associate those words with maleness of femaleness. Feminist Philosophers argue that English, a non gendered language, still has the need for Language Reform.\n\nPrevious language reform attempts to avoid sexist words or phrases were addressed in a symptomatic manner. Often in the workplace, employees were given pamphlets with lists of words to avoid or preferred words to use. Many modern day feminists argue that this is ineffective because it does not address the root of the problem or make the large scale changes to the language that they feel are necessary.\n\nA major part of the theory focuses on when words or phrases make one gender, typically women, subjugated or invisible compared to the other. The most popular examples are the pronoun “he” or the word “man”. Feminist Language Philosophers argue that these words participate in making women invisible by having them being used to refer to men and also women. The fact that the pronouns or words for the male gender can be also used to refer to the female gender shows how maleness is dominant and femaleness is subjugated.\n\nFeminist Language Theory also focuses on when words or phrases emphasize a break in gender norms. Clear examples of this are words like Lady Doctor or Manageress. These are positions of power that are typically held by men. Therefore, when a woman holds them, they need a new title to emphasize their break of social norm. It also goes both ways, with terms like male nurse referring to a man in a typically feminine role. Feminist Language Reform seeks to remove words like this because they help to sustain unhealthy gender norms.\n\nSome modern feminists, like Sergio Bolaños Cuellar, argue that feminist language reforms needs to reverse the generic masculine forms and create a generic feminine form with words like he or man being replaced with she or woman.\n\nCases of feminist language planning have taken a largely sociolinguistic approach in which the goal is to enact social change through the reform of language and language use. This approach to language planning is divided into four stages:\n\n\n\n"}
{"id": "192628", "url": "https://en.wikipedia.org/wiki?curid=192628", "title": "Financial Crimes Enforcement Network", "text": "Financial Crimes Enforcement Network\n\nThe Financial Crimes Enforcement Network (FinCEN) is a bureau of the United States Department of the Treasury that collects and analyzes information about financial transactions in order to combat domestic and international money laundering, terrorist financing, and other financial crimes.\n\nFinCEN's director expressed its mission in November 2013 as \"to safeguard the financial system from illicit use, combat money laundering and promote national security.\" FinCEN serves as the U.S. Financial Intelligence Unit (FIU) and is one of 147 FIUs making up the Egmont Group of Financial Intelligence Units. FinCEN's self-described motto is \"follow the money.\" The website states: \"The primary motive of criminals is financial gain, and they leave financial trails as they try to launder the proceeds of crimes or attempt to spend their ill-gotten profits.\" It is a network bringing people and information together, by coordinating information sharing with law enforcement agencies, regulators and other partners in the financial industry.\n\nFinCEN was established by order of the Secretary of the Treasury (Treasury Order Numbered 105-08) on April 25, 1990. In May 1994, its mission was broadened to include regulatory responsibilities, and in October 1994 the Treasury Department's precursor of FinCEN, the Office of Financial Enforcement was merged with FinCEN. On September 26, 2002, after Title III of the PATRIOT Act was passed, Treasury Order 180-01 made it an official bureau in the Department of the Treasury. In September 2012, FinCEN's information technology called FinCEN Portal and Query System migrated with 11 years of data into FinCEN Query, a search engine similar to Google. It is a \"one stop shop\" accessible via the FinCEN Portal allowing broad searches across more fields than before and returning more results. Since September 2012 FinCEN generates 4 new reports: Suspicious Activity Report (FinCEN SAR), Currency Transaction Report (FinCEN CTR), the Designation of Exempt Person (DOEP) and Registered Money Service Business (RMSB).\n\nAs of November 2013, FinCEN employed approximately 340 people mostly intelligence professionals with expertise in the financial industry, illicit finance, financial intelligence, the AML/CFT (money laundering/terrorist financing) regulatory regime, computer technology, and enforcement\". The majority of the staff are permanent FinCEN personnel, with about 20 long-term detailees assigned from 13 different regulatory and law enforcement agencies. FinCEN shares information with dozens of intelligence agencies, including the Bureau of Alcohol, Tobacco, and Firearms; the Drug Enforcement Administration; the Federal Bureau of Investigation; the U.S. Secret Service; the Internal Revenue Service; the Customs Service; and the U.S. Postal Inspection Service.\n\n\nThe 2001 USA PATRIOT Act required the Secretary of the Treasury to create a secure network for the transmission of information to enforce the relevant regulations. FinCEN's regulations under Section 314(a) enable federal law enforcement agencies, through FinCEN, to reach out to more than 45,000 points of contact at more than 27,000 financial institutions to locate accounts and transactions of persons that may be involved in terrorist financing and/or money laundering. A web interface allows the person(s) designated in §314(a)(3)(A) to register and transmit information to FinCEN. The partnership between the financial community and law enforcement allows disparate bits of information to be identified, centralized, and rapidly evaluated.\n\nAs early as 2003 FinCEN disseminated information on \"informal value transfer systems\" (IVTS), including hawala, a network of people receiving money for the purpose of making the funds payable to a third party in another geographic location... generally tak[ing] place outside of the conventional banking system through non-bank financial institutions or other business entities whose primary business activity may not be the transmission of money. On September 1, 2010, FinCEN issued a guidance on IVTS referencing \"United States v. Banki\" and hawala.\n\nIn July 2011, FinCEN added \"other value that substitutes for currency\" to its definition of money services businesses in preparation to adapt the respective rule to virtual currencies. On March 18, 2013 FinCEN issued a guidance regarding virtual currencies, according to which, exchangers and administrators, but not users of convertible virtual currency are considered money transmitters, and must comply with rules to prevent money laundering/terrorist financing (\"AML/CFT\") and other forms of financial crime, by record-keeping, reporting and registering with FinCEN. Jennifer Shasky Calvery, director of FinCEN said, \"Virtual currencies are subject to the same rules as other currencies. … Basic money services business rules apply here.\"\n\nAt a November 2013 Senate hearing, Calvery stated, \"It is in the best interest of virtual currency providers to comply with these regulations for a number of reasons. First is the idea of corporate responsibility,\" contrasting Bitcoin's understanding of a peer to peer system bypassing corporate financial institutions. She stated that FinCEN collaborates with the Federal Financial Institutions Examination Council, a congressionally-chartered forum called the \"Bank Secrecy Act (BSA) Advisory Group\" and BSA Working Group to review and discuss new regulations and guidance, with the FBI-led \"Virtual Currency Emerging Threats Working Group\" (VCET) formed in early 2012, the FDIC-led \"Cyber Fraud Working Group\", the Terrorist Financing & Financial Crimes-led \"Treasury Cyber Working Group\", and with a community of other financial intelligence units. According to the Department of Justice, VCET members represent the FBI, the Drug Enforcement Administration, multiple U.S. Attorney's Offices, and the Criminal Division's Asset Forfeiture and Money Laundering Section and Computer Crime and Intellectual Property Section.\n\nIn 2009, the GAO found \"opportunities\" to improve \"interagency and state examination coordination\", noting that the federal banking regulators issued an interagency examination manual, that SEC, CFTC, and their respective self-regulatory organizations developed Bank Secrecy Act (BSA) examination modules, and that FinCEN and IRS examining nonbank financial institutions issued an examination manual for money services businesses. Therefore multiple regulators examine compliance of the BSA across industries and for some larger holding companies even within the same institution. Regulators need to promote greater consistency, coordination and information-sharing, reduce unnecessary regulatory burden, and find concerns across industries. FinCEN estimated that it would have data access agreements with 80 percent of state agencies that conduct BSA examinations after 2012.\n\nSince FinCEN's inception in 1990 the Electronic Frontier Foundation in San Francisco has debated its benefits compared to its threat to privacy. FinCEN´s value is hard to gauge without publication of evidence. It does not disclose how many 'Suspicious Activity Reports' result in investigations, indictments or convictions, and no studies exist to tally how many reports are filed on innocent people. FinCEN and money laundering laws have been criticized for being expensive and relatively ineffective, while violating Fourth Amendment rights as an investigator may use FinCEN's government database system to investigate people instead of crimes.\n\nIt has also been alleged, that FinCEN's regulations against structuring are enforced unfairly and arbitrarily; for example, it was reported in 2012 that small businesses selling at farmers' markets have been targeted, while politically connected people like Eliot Spitzer were not prosecuted. Spitzers reasons for structuring were described as \"innocent\".\n\nThe 2016 film \"The Accountant\" features a FinCEN investigation into the title character.\n\n\n"}
{"id": "13715936", "url": "https://en.wikipedia.org/wiki?curid=13715936", "title": "Fogging (censorship)", "text": "Fogging (censorship)\n\nFogging is a type of visual censorship. An area for a picture or movie is blurred to obscure it from sight. This form of censorship is used for sexually related images/scenes, hiding genitals, pubic hair, or sexual penetration of any sort. Pixelization is a form of fogging. In Japan, where it is called \"bokashi\", fogging is employed on most films that show pubic hair or genitals, including hardcore pornography.\n\nThis form of editing also appears in television programs where an individual's face may not be shown due to legal or privacy concerns. As it does not contrast with the surrounding image very much, it is preferable over most other forms of censorship. Fogging is also used if the scenes which are too bloody and gruesome to be rendered even in black and white, over vehicle license plates, mainly to protect the identities of the vehicles' owners, and over branded items and specific company names to obscure their background.\n\n"}
{"id": "32105383", "url": "https://en.wikipedia.org/wiki?curid=32105383", "title": "Gender and development", "text": "Gender and development\n\nThe pre-World War II period saw flourishing movements of various forms of feminism; however, the nexus between (economic) development and women was not clearly articulated until the second half of the 20th century. Women first came into focus in development as objects of welfare policies, including those focused on birth control, nutrition, and pregnancy. \"In 1962 the UN General Assembly asked the Commission on the Status of Women to prepare a report on the role of women in development. Ester Boserup's path breaking study on \"Women's Role in Economic Development\" was published in 1970. These events marked monumental moments in developing the liberal paradigm of women in development, and the welfarist approach still remains dominant in development practice today. This article reviews the dominant liberal approaches, including women in development (WID), women and development (WAD), gender and development (GAD) and neoliberal frameworks (Singh, 2007). There is significant overlap among these approaches (for example, WID can be seen as an early version of the neoliberal framework). (GAD) is most concerned with equity and empowerment.\n\nTheoretical approach\n\nThe term “women in development” was originally coined by a Washington-based network of female development professionals in the early 1970s who sought to question trickle down existing theories of development by contesting that economic development had identical impacts on men and women. The Women in Development movement (WID) gained momentum in the 1970s, driven by the resurgence of women's movements in developed countries, and particularly through liberal feminists striving for equal rights and labour opportunities in the United States. Liberal feminism, postulating that women's disadvantages in society may be eliminated by breaking down customary expectations of women by offering better education to women and introducing equal opportunity programmes, had a notable influence on the formulation of the WID approaches.\n\nThe focus of the 1970s feminist movements and their repeated calls for employment opportunities in the development agenda meant that particular attention was given to the productive labour of women, leaving aside reproductive concerns and social welfare. This approach was pushed forward by WID advocates, reacting to the general policy environment maintained by early colonial authorities and post-war development authorities, wherein inadequate reference to the work undertook by women as producers was made, as they were almost solely identified as their roles as wives and mothers. The WID's opposition to this “welfare approach” was in part motivated by the work of Danish economist Ester Boserup in the early 1970s, who challenged the assumptions of the said approach and highlighted the role women by women in the agricultural production and economy.\nA dominant strand of thinking within WID sought to link women's issues with development, highlighting how such issues acted as impediments to economic growth; this “relevance” approach stemmed from the experience of WID advocates which illustrated that it was more effective if demands of equity and social justice for women were strategically linked to mainstream development concerns, in an attempt to have WID policy goals taken up by development agencies. The Women in Development approach was the first contemporary movement to specifically integrate women in the broader development agenda and acted as the precursor to later movements such as the Women and Development (WAD), and ultimately, the Gender and Development approach, departing from some of the criticized aspects imputed to the WID.\n\nCriticism\n\nThe WID movement faced a number of criticisms; such an approach had in some cases the unwanted consequence of depicting women as a unit whose claims are conditional on its productive value, associating increased female status with the value of cash income in women's lives. The WID view and similar classifications based on Western feminism, applied a general definition to the status, experiences and contributions of women and the solutions for women in Third World countries. Furthermore, the WID, although it advocated for greater gender equality, did not tackle the unequal gender relations and roles at the basis of women's exclusion and gender subordination rather than addressing the stereotyped expectations entertained by men. Moreover, the underlying assumption behind the call for the integration of the Third World women with their national economy was that women were not already participating in development, thus downplaying women's roles in household production and informal economic and political activities. The WID was also criticized for its views on the fact that women's status will improve by moving into “productive employment”, implying that the move to the “modern sector” need to be made from the “traditional” sector to achieve self-advancement, further implying that “traditional” work roles often occupied by women in the developing world were inhibiting to self-development.\n\nWomen and development (WAD) is a theoretical and practical approach to development. It was introduced into gender studies scholarship in the second half of the 1970s, following its origins, which can be traced to the First World Conference on Women in Mexico City in 1975, organized by the UN. It is a departure from the previously predominant theory, WID (Women in Development) and is often mistaken for WID, but has many distinct characteristics.\n\nTheoretical approach\n\nWAD arose out of a shift in thinking about women's role in development, and concerns about the explanatory limitations of modernization theory. While previous thinking held that development was a vehicle to advance women, new ideas suggested that development was only made possible by the involvement of women, and rather than being simply passive recipients of development aid, they should be actively involved in development projects. WAD took this thinking a step further and suggested that women have always been an integral part of development, and did not suddenly appear in the 1970s as a result of exogenous development efforts. The WAD approach suggests that there be women-only development projects that were theorized to remove women from the patriarchal hegemony that would exist if women participated in development alongside men in a patriarchal culture, though this concept has been heavily debated by theorists in the field. In this sense, WAD is differentiated from WID by way of the theoretical framework upon which it was built. Rather than focus specifically on women's relationship to development, WAD focuses on the relationship between patriarchy and capitalism. This theory seeks to understand women's issues from the perspectives of neo-Marxism and dependency theory, though much of the theorizing about WAD remains undocumented due to the persistent and pressing nature of development work in which many WAD theorists engage.\n\nPractical approach\n\nThe WAD paradigm stresses the relationship between women, and the work that they perform in their societies as economic agents in both the public and domestic spheres. It also emphasizes the distinctive nature of the roles women play in the maintenance and development of their societies, with the understanding that purely the integration of women into development efforts would serve to reinforce the existing structures of inequality present in societies overrun by patriarchal interests. In general, WAD is thought to offer a more critical conceptualization of women's position that does WID.\n\nThe WAD approach emphasizes the distinctive nature of women's knowledge, work, goals, and responsibilities, as well as advocating for the recognition of their distinctiveness. This fact, combined with a recognized tendency for development agencies to be dominated by patriarchal interests, is at the root of the women-only initiatives introduced by WAD subscribers.\n\nCriticism\n\nSome of the common critiques of the WAD approach include concerns that the women-only development projects would struggle, or ultimately fail, due to their scale, and the marginalized status of these women. Furthermore, the WAD perspective suffers from a tendency to view women as a class, and pay little attention to the differences among women (such as feminist concept of intersectionality), including race and ethnicity, and prescribe development endeavors that may only serve to address the needs of a particular group. While an improvement on WID, WAD fails to fully consider the relationships between patriarchy, modes of production, and the marginalization of women. It also presumes that the position of women around the world will improve when international conditions become more equitable. Additionally, WAD has been criticized for its singular preoccupation with the productive side of women's work, while it ignores the reproductive aspect of women's work and lives. Therefore, WID/WAD intervention strategies have tended to concentrate on the development of income-generating activities without taking into account the time burdens that such strategies place on women. Value is placed on income-generating activities, and none is ascribed to social and cultural reproduction.\n\nTheoretical approach\n\nThe Gender and Development (GAD) approach focuses on the socially constructed differences between men and women, the need to challenge existing gender roles and relations, and the creation and effects of class differences on development. This approach was majorly influenced by the writings of academic scholars such as Oakley (1972) and Rubin (1975), who argue the social relationship between men and women have systematically subordinated women, along with economist scholars Lourdes Benería and Amartya Sen (1981), who assess the impact of colonialism on development and gender inequality. They state that colonialism imposed more than a 'value system' upon developing nations, it introduced a system of economics 'designed to promote capital accumulation which caused class differentiation'.\n\nGAD departs from WID, which discussed women's subordination and lack of inclusion in discussions of international development without examining broader systems of gender relations. Influenced by this work, by the late 1970s, some practitioners working in the development field questioned focusing on women in isolation. GAD challenged the WID focus on women as an important ‘target group’ and ‘untapped resources’ for development. GAD marked a shift in thinking about the need to understand how women and men are socially constructed and how ‘those constructions are powerfully reinforced by the social activities that both define and are defined by them.’ GAD focuses primarily on the gendered division of labor and gender as a relation of power embedded in institutions. Consequently, two major frameworks ‘Gender roles’ and ‘social relations analysis’ are used in this approach. 'Gender roles' focuses on the social construction of identities within the household; it also reveals the expectations from ‘maleness and femaleness’ in their relative access to resources. 'Social relations analysis' exposes the social dimensions of hierarchical power relations embedded in social institutions, as well as its determining influence on ‘the relative position of men and women in society.’ This relative positioning tends to discriminate against women.\n\nUnlike WID, the GAD approach is not concerned specifically with women, but with the way in which a society assigns roles, responsibilities and expectations to both women and men. GAD applies gender analysis to uncover the ways in which men and women work together, presenting results in neutral terms of economics and efficiency.In an attempt to create gender equality, (denoting women having same opportunities as men, including ability to participate in the public sphere; GAD policies aims to redefine traditional gender role expectations. Women are expected to fulfill household management tasks, home based production as well as bearing and raising children and caring for family members. The role of a wife is largely interpreted as 'the responsibilities of motherhood' Men however, are expected to be breadwinners whom are associated with paid work, and market production. In the labor market, women tend to earn less than men. For instance, 'a study by the Equality and Human Rights Commission found massive pay inequities in some United Kingdom's top finance companies, women received around 80 percent less performance-related pay than their male colleagues.' In response to pervasive gender inequalities, Beijing Platform for Action established gender mainstreaming in 1995 as a strategy across all policy areas at all levels of governance for achieving gender equality.\n\nCaroline Moser developed the Moser Gender Planning Framework for GAD-oriented development planning in the 1980s while working at the Development Planning Unit of the University of London. Working with Caren Levy, she expanded it into a methodology for gender policy and planning.\nThe Moser framework follows the Gender and Development approach in emphasizing the importance of gender relations.\nAs with the WID-based Harvard Analytical Framework, it includes a collection of quantitative empirical facts. Going further, it investigates the reasons and processes that lead to conventions of access and control. \nThe Moser Framework includes gender roles identification, gender needs assessment, disaggregating control of resources and decision making within the household, planning for balancing work and household responsibilities, distinguishing between different aims in interventions and involving women and gender-aware organizations in planning.\n\nCriticisms\n\nGAD has been criticized for emphasizing the social differences between men and women while neglecting the bonds between them and also the potential for changes in roles. Another criticism is that GAD does not dig deeply enough into social relations and so may not explain how these relations can undermine programs directed at women. It also does not uncover the types of trade-offs that women are prepared to make for the sake of achieving their ideals of marriage or motherhood. Another criticism is that the GAD perspective is theoretically distinct from WID, but in practice, a program seem to have the element of the two. Whilst many development agencies are now committed to a gender approach, in practice, the primary institutional perspective remain focused on a WID approach. There is a slippage in reality where gender mainstreaming is often based in a single normative perspective as synonymous to women. Development agencies still advance gender transformation to mean economic betterment for women.\n\nNeoliberalism consist of policies that will privatize public industry, deregulate any laws or policies that interfere with the free flow of the market and cut back on all social services. This policies were often introduced to many low-income countries through structural adjustment programs (SAPs) by the World Bank and the International Monetary Fund (IMF). Neoliberalism was cemented as the dominant global policy framework in the 1980s and 1990s. Among development institutions, gender issues have increasingly become part of economic development agendas, as the examples of the World Bank shows. Awareness by international organizations of the need to address gender issues evolved over the past decades. The World Bank, and regional development banks, donor agencies, and government ministries have provided many examples of instrumental arguments for gender equality, for instance by emphasizing the importance of women's education as a way of increasing productivity in the household and the market. Their concerns have often focused on women's contributions to economic growth rather than the importance of women's education as a means for empowering women and enhancing their capabilities. The World Bank, for example, started focusing on gender in 1977 with the appointment of a first Women in Development Adviser. In 1984 the bank mandated that its programs consider women's issues. In 1994 the bank issued a policy paper on Gender and Development, reflecting current thinking on the subject. This policy aims to address policy and institutional constraints that maintain disparities between the genders and thus limit the effectiveness of development programs.Thirty years after the appointment of a first Women in Development Adviser, a so-called Gender Action Plan was launched to underline the importance of the topic within development strategies and to introduce the new Smart Economics strategy. In 2012, the World Development Report was the first report of the series examining Gender Equality and Development.\n\nWomen have been identified by some development institutions as a key to successful development, for example through financial inclusion. Microcredit is giving small loans to people in poverty without collateral. This was first started by Muhammad Yunus, who formed the Grameen Bank in Bangladesh. Studies have showed that women are more likely to repay their debt than men, and the Grameen Bank focuses on aiding women. This financial opportunity allows women to start their own businesses for a steady income.\n\nThere were numerous case studies done in Tanzania about the correlation of the role of SACCoS and the economic development of the country. The research showed that the microfinance policies were not being carried out in the most efficient ways due to exploitation. However, there was evidence that reform could possibly enrich the overall economy. One case study went a step further to claim that this financial service could provide a more equal society for women in Tanzania.\n\nWhile there are such cases in which women were able to lift themselves out of poverty, there are also cases in which women fell into a poverty trap as they were unable to repay their loans. It is even said that microcredit is actually an \"anti-developmental\" approach. There is little evidence of significant development for these women within the 30 years that the microfinance has been around. In South Africa, unemployment is high due to the introduction of microfinance, more so than it was under apartheid. Microcredit intensified poverty in Johannesburg, South Africa as poor communities, mostly women, who needed to repay debt were forced to work in the informal sector.\n\nAlthough there is debate on how effective microcredit is in alleviating poverty in general, there is an argument that microcredit enables women to participate and fulfill their capabilities in society. For example, a study conducted in Malayasia showed that their version of microcredit, AIM, had a positive effect on Muslim women's empowerment in terms of allowing them to have more control over family planning and over decisions that were made in the home.\n\nAnother example is the Women's Development Business (WDB) in South Africa, a Grameen Bank microfinance replicator. According to WDB, the goal is to ensure “[…] that rural women are given the tools to free themselves from the chains of poverty […]” through allocation of financial resources directly to women including enterprise development programs. The idea is to use microfinance as a market-oriented tool to ensure access to financial services for disadvantaged and low-income people and therefore fostering economic development through financial inclusion.\n\nAs a reaction, a current topic in the feminist literature on economic development is the ‘gendering’ of microfinance, as women have increasingly become the target borrowers for rural microcredit lending. This, in turn, creates the assumption of a “rational economic woman” which can exacerbate existing social hierarchies). \nTherefore, the critique is that the assumption of economic development through microfinance does not take into account all possible outcomes, especially the ones affecting women.\n\nThe impact of programs of the Bretton Woods Institutions and other similar organizations on gender are being monitored by Gender Action, a watchdog group founded in 2002 by Elaine Zuckerman who is a former World Bank economist.\n\nThe global financial crisis and the following politics of austerity have opened up a wide range of gender and feminist debates on neoliberalism and the impact of the crisis on women. One view is that the crisis has affected women disproportionately and that there is a need for alternative economic structures in which investment in social reproduction needs to be given more weight. The International Labour Organization (ILO) assessed the impact of the global financial crisis on workers and concluded that while the crisis initially affected industries that were dominated by male workers (such as finance, construction and manufacturing) it then spread over to sectors in which female workers are predominantly active. Examples for these sectors are the service sector or wholesale retail trade.\n\nThere are different views among feminists on whether neoliberal economic policies have more positive or negative impacts on women. In the post-war era, feminist scholars such as Elizabeth Wilson criticized state capitalism and the welfare state as a tool to oppress women. Therefore, neoliberal economic policies featuring privatization and deregulation, hence a reduction of the influence of the state and more individual freedom was argued to improve conditions for women. This anti-welfare state thinking arguably led to feminist support for neoliberal ideas embarking on a macroeconomic policy level deregulation and a reduced role of the state.\n\nTherefore, some scholars in the field argue that feminism, especially during its second wave, has contributed key ideas to Neoliberalism that, according to these authors, creates new forms of inequality and exploitation.\n\nAs a reaction to the phenomenon that some forms of feminism are increasingly interwoven with capitalism, many suggestions on how to name these movements have emerged in the feminist literature. Examples are ‘free market feminism’ or even ‘faux-feminism’.\n\nTheoretical approaches\nAdvocated chiefly by the World Bank, smart economics is an approach to define gender equality as an integral part of economic development and it aims to spur development through investing more efficiently in women and girls. It stresses that the gap between men and women in human capital, economic opportunities, and voice/agency is a chief obstacle in achieving more efficient development. As an approach, it is a direct descendant of the efficiency approach taken by WID which “rationalizes ‘investing’ in women and girls for more effective development outcomes.” As articulated in the section of WID, the efficiency approach to women in development was chiefly articulated by Caroline Moser in the late 1980s. Continuing the stream of WID, smart economics’ key unit of analysis is women as individual and it particularly focuses on measures that promote to narrow down the gender gap. Its approach identifies women are relatively underinvested source of development and it defines gender equality an opportunity of higher return investment. “Gender equality itself is here depicted as smart economics, in that it enables women to contribute their utmost skills and energies to the project of world economic development.” In this term, smart economics champions neoliberal perspective in seeing business as a vital vehicle for change and it takes a stance of liberal feminism.\n\nThe thinking behind smart economics dates back, at least, to the lost decade of the Structural Adjustment Policies (SAPs) in the 1980s. In 1995, World Bank issued its flagship publication on gender matters of the year Enhancing Women's Participation in Economic Development (World Bank 1995). This report marked a critical foundation to the naissance of Smart Economics; in a chapter entitled ‘The Pay-offs to Investing in Women,’ the Bank proclaimed that investing in women “speeds economic development by raising productivity and promoting the more efficient use of resources; it produces significant social returns, improving child survival and reducing fertility, and it has considerable intergenerational pay-offs.” The Bank also emphasized its associated social benefits generated by investing in women. For example, the Bank turned to researches of Whitehead that evidenced a greater female-control of household income is associated with better outcomes for children's welfare and Jeffery and Jeffery who analyzed the positive correlation between female education and lower fertility rates. In the 2000s, the approach of smart economics came to be further crystallized through various frameworks and initiatives. A first step was World Bank's Gender Action Plan (GAP) 2007-/2010, followed by the “Three Year Road Map for Gender Mainstreaming 2010-13.” The 2010-13 framework responded to criticisms for its precursor and incorporated some shifts in thematic priorities. Lastly but not least, the decisive turning point was 2012 marked by its publication of “World Development Report 2012: Gender Equality and Development.” This Bank's first comprehensive focus on the gender issues was welcomed by various scholars and practitioners, as an indicator of its seriousness. For example, Shahra Razavi appraised the report as ‘a welcome opportunity for widening the intellectual space’.\n\nOther international organizations, particular UN families, have so far endorsed the approach of smart economics. Examining the relationship between child well-being and gender equality, for example, UNICEF also referred to the “Double Dividend of Gender Equality.” Its explicit link to a wider framework of the Millennium Development Goals (where the Goal 3 is Promoting Gender Equality and Women's Empowerment) claimed a wider legitimacy beyond economic efficiency. In 2007, the Bank proclaimed that “The business case for investing in MDG 3 is strong; it is nothing more than smart economics.” In addition, “Development organisations and governments have been joined in this focus on the ‘business case’ for gender equality and the empowerment of women, by businesses and enterprises which are interested in contributing to social good.” A good example is “Girl Effect initiative” taken by Nike Foundation. Its claim for economic imperative and a broader socio-economic impact also met a strategic need of NGOs and community organizations that seeks justification for their program funding. Thus, some NGOs, for example Plan International, captured this trend to further their program. The then-president of the World Bank Robert B. Zoellick was quoted by Plan International in stating “Investing in adolescent girls is precisely the catalyst poor countries need to break intergenerational poverty and to create a better distribution of income. Investing in them is not only fair, it is a smart economic move.” The global financial meltdown and austerity measures taken by major donor counties further supported this approach, since international financial institutions (IFIs) s and international NGOs received a greater pressure from donors and from global public to design and implement maximally cost-effective programs.\n\nCriticisms\nFrom the mid-2000s, the approach of smart economics and its chief proponent –World Bank– met a wide range of criticisms and denouncements. These discontents can be broadly categorized into three major claims; Subordination of Intrinsic Value; Ignorance for the need of systemic transformation; Feminisation of responsibility; Overemphasized efficiency; and Opportunistic pragmatism.This is not exhaustive list of criticisms, but the list aims to highlight different emphasis among existing criticisms.\n\nSmart economics’ subordination of women under the justification of development invited fierce criticisms. Chant expresses her grave concern that “Smart economics is concerned with building women’s capacities in the interests of development rather than promoting women’s rights for their own sake.” She disagrees that investment in women should be promoted by its instrumental utility: “it is imperative to ask whether the goal of female investment is primarily to promote gender equality and women’s ‘empowerment’, or to facilitate development ‘on the cheap’, and/or to promote further economic liberalization.” Although smart economics outlines that gender equality has intrinsic value (realizing gender equality is an end itself) and instrumental value (realizing gender equality is a means to a more efficient development), many points out that the Bank pays almost exclusive attentions to the latter in defining its framework and strategy. Zuckerman also echoed this point by stating “business case [which] ignores the moral imperative of empowering women to achieve women’s human rights and full equal rights with men.” In short, Chant casts a doubt that if it is not “possible to promote rights through utilitarianism.” \n\nA wide range of scholars and practitioners has criticized that smart economics rather endorse the current status-quo of gender inequality and keep silence for the demand of institutional reform. Its approach “[d]oes not involves public action to transform the laws, policies, and practices which constrain personal and group agency.” Naila Kabeer also posits that “attention to collective action to enable women to challenge structural discrimination has been downplayed.” Simply, smart economics assumes that women are entirely capable of increasingly contributing for economic growth amid the ongoing structural barriers to realize their capabilities.\n\nSylvia Chant (2008) discredited its approach as ‘feminisation of responsibility and/or obligation’ where the smart economics intends to spur growth simply by demanding more from women in terms of time, labour, energy, and other resources. She also agrees that “Smart economics seeks to use women and girls to fix the world.” She further goes by clarifying that “It is less welcome to women who are already contributing vast amounts to both production and unpaid reproduction to be romanticised and depicted as the salvation of the world.”\n\nChant is concerned that “An efficiency-driven focus on young women and girls as smart economics leaves this critical part of the global population out.” Smart economics assumes that all women are at their productive stage and fallaciously neglects lives of the elderly women, or women with handicaps. Thus she calls for recognition of “equal rights of all women and girls -regardless of age, or the extent of nature of their economic contribution.” Also, its approach does not talk about cooperation and collaboration between males and females thus leaving men and boys completely out of picture.\n\nChant emphasize that “The smart economics approach represents, at best, pragmatism in a time of economic restructuring and austerity.” Smart economics can have a wider acceptance and legitimacy because now is the time when efficiency is most demanded, not because its utilitarianism has universal appeal. She further warns that feminists should be very cautious about “supporting, and working in coalition with, individuals and institutions who approach gender equality through the lens of smart economics. This may have attractions in strategic terms, enabling us to access resources for work focusing on supporting the individual agency of women and girls, but risks aggravating many of the complex problems that gender and development seeks to transform.”\n\nOther approaches with different paradigms have also played a historically important role in advancing theories and practices in gender and development.\n\nThe structuralist debate was first triggered by Marxist and socialist feminists. Marxism, particularly through alternative models of state socialist development practiced in China and Cuba, challenged the dominant liberal approach over time. Neo-Marxist proponents focused on the role of the post-colonial state in development in general and also on localized class struggles. Marxist feminists advanced these criticisms towards liberal approaches and made significant contribution to the contemporary debate.\n\nDependency theorists opposed that liberal development models, including the attempt to incorporate women into the existing global capitalism, was in fact nothing more than the \"development of underdevelopment.\" This view led them to propose that delinking from the structural oppression of global capitalism is the only way to achieve balanced human development. \nIn the 1980s, there also emerged \"a sustained questioning by post-structuralist critics of the development paradigm as a narrative of progress and as an achievable enterprise.\"\n\nWithin the liberal paradigm of women and development, various criticism have emerged. The Basic Needs (BN) approach began to pose questions to the focus on growth and income as indicators of development. It was heavily influenced by Sen and Nussabaum's capability approach, which was more gender sensitive than BN and focused on expanding human freedom. The BN particularly proposed a participatory approach to development and challenged the dominant discourse of trickle down effects. These approaches focused on the human freedom led to development of other important concepts such as human development and human security. From a perspective of sustainable development, ecofeminists articulated the direct link between colonialism and environmental degradation, which resulted in degradation of women's lives themselves.\n\n\n"}
{"id": "6766624", "url": "https://en.wikipedia.org/wiki?curid=6766624", "title": "Generalized algebraic data type", "text": "Generalized algebraic data type\n\nIn functional programming, a generalized algebraic data type (GADT, also first-class phantom type, guarded recursive datatype, or equality-qualified type) is a generalization of parametric algebraic data types.\n\nIn a GADT, the product constructors (called data constructors in Haskell) can provide an explicit instantiation of the ADT as the type instantiation of their return value. This allows one to define functions with a more advanced type behaviour. For a data constructor of Haskell 98, the return value has the type instantiation implied by the instantiation of the ADT parameters at the constructor's application.\n-- A parametric ADT that is not a GADT\ndata List a = Nil | Cons a (List a)\n\nintegers = Cons 12 (Cons 107 Nil) -- the type of integers is List Int\nstrings = Cons \"boat\" (Cons \"dock\" Nil) -- the type of strings is List String\n\n-- A GADT\ndata Expr a where\n\neval :: Expr a -> a\n\neval e = case e of\n\nexpr1 = EEqual (EInt 2) (EInt 3) -- the type of expr1 is Expr Bool\nret = eval expr1 -- ret is False\nThey are currently implemented in the GHC compiler as a non-standard extension, used by, among others, Pugs and Darcs. OCaml supports GADT natively since version 4.00.\n\nThe GHC implementation provides support for existentially quantified type parameters and for local constraints.\n\nAn early version of generalized algebraic data types were described by and based on pattern matching in ALF.\n\nGeneralized algebraic data types were introduced independently by and prior by as extensions to ML's and Haskell's algebraic data types. Both are essentially equivalent to each other. They are similar to the \"inductive families of data types\" (or \"inductive datatypes\") found in Coq's Calculus of Inductive Constructions and other dependently typed languages, modulo the dependent types and except that the latter have an additional positivity restriction which is not enforced in GADTs.\n\nType inference in the absence of any programmer supplied type annotations is undecidable and functions defined over GADTs do not admit principal types in general. Type reconstruction requires several design trade-offs and is an area of active research (; ; ; ; ; ; ; ; ; ).\n\nApplications of GADTs include generic programming, modelling programming languages (higher-order abstract syntax), maintaining invariants in data structures, expressing constraints in embedded domain-specific languages, and modelling objects.\n\nAn important application of GADTs is to embed higher-order abstract syntax in a type safe fashion. Here is an embedding of the simply typed lambda calculus with an arbitrary collection of base types, tuples and a fixed point combinator:\nAnd a type safe evaluation function:\n\nThe factorial function can now be written as:\n\nWe would have run into problems using regular algebraic data types. Dropping the type parameter would have made the lifted base types existentially quantified, making it impossible to write the evaluator. With a type parameter we would still be restricted to a single base type. Furthermore, ill-formed expressions such as codice_1 would have been possible to construct, while they are type incorrect using the GADT. A well-formed analogue is codice_2. This is because the type of codice_3 is codice_4, inferred from the type of the codice_5 data constructor.\n\n\n"}
{"id": "32140938", "url": "https://en.wikipedia.org/wiki?curid=32140938", "title": "Glitter bombing", "text": "Glitter bombing\n\nGlitter bombing is an act of protest in which activists throw glitter on people at public events. Glitter bombers have frequently been motivated by, though not limited to, their targets' rape apologism or opposition to same-sex marriage.\n\nSome legal officials argue glitter bombing is technically assault and battery. It is possible for glitter to enter the eyes or nose and cause damage to the cornea or other soft tissues potentially irritating them or leading to infection, depending on the size of the glitter. Whether a prosecutor would pursue the charges depends on a number of factors.\n\nGlitter bombs can be sent through the post, so that glitter falls from an envelope or is forcefully ejected from a larger, spring-loaded package when opened. In 2015, RuinDays.com began offering a service where an envelope containing loose glitter or spring-loaded glitter bombs could be sent anonymously to a victim.\n\nIn the Season 3 premiere of \"Glee\", William McKinley High School teacher and Glee Club director Will Schuester glitter bombs cheerleading coach and candidate for the United States House of Representatives Sue Sylvester as a protest against her support for cutting federal funding for the arts in public schools. The tactic backfires, as Sue sees a boost in her poll numbers after the event is posted to YouTube.\n\n"}
{"id": "161653", "url": "https://en.wikipedia.org/wiki?curid=161653", "title": "Hard power", "text": "Hard power\n\nHard power is the use of military and economic means to influence the behavior or interests of other political bodies. This form of political power is often aggressive (coercion), and is most immediately effective when imposed by one political body upon another of lesser military and/or economic power. Hard power contrasts with soft power, which comes from diplomacy, culture and history.\n\nAccording to Joseph Nye, hard power involves \"the ability to use the carrots and sticks of economic and military might to make others follow your will\". Here, \"carrots\" stand for inducements such as the reduction of trade barriers, the offer of an alliance or the promise of military protection. On the other hand, \"sticks\" represent threats - including the use of coercive diplomacy, the threat of military intervention, or the implementation of economic sanctions. Ernest Wilson describes hard power as the capacity to coerce \"another to act in ways in which that entity would not have acted otherwise\".\n\nWhile the existence of hard power has a long history, the term itself arose when Joseph Nye coined \"soft power\" as a new and different form of power in a sovereign state's foreign policy. According to the realist school in international relations theory, power is linked with the possession of certain tangible resources, including population, territory, natural resources, economic and military strength, among others. Hard power describes a nation or political body’s ability to use economic incentives or military strength to influence other actors’ behaviors. \n\nHard power encompasses a wide range of coercive policies, such as coercive diplomacy, economic sanctions, military action, and the forming of military alliances for deterrence and mutual defense. Hard power can be used to establish or change a state of political hegemony or balance of power. Although the term \"hard power\" generally refers to diplomacy, it can also be used to describe forms of negotiation which involve pressure or threats as leverage. \n\nThe use of hard power is often tedious. Insurgencies against the external force can be prominent. The United States has demonstrated a 'hard power' policy in regard to the Iraq War, the Afghanistan War and its continued war on the Taliban. To be more specific, the United States’ attack on Iraq in 2003 was based on the concerns about Iraq’s possession of weapons of mass destruction (WMD). In part by referring to “War on Terrorism,” George W. Bush administration used hard power measures to uproot Iraqi dictator Saddam Hussein and to handle subsequent crisis in Iraq. However, many critics mention that the war in Iraq had the United States lose its reputation as an icon for democracy and justice.\n\nJoseph Nye has used the term to define some policy measures in regard to Iran as well. For instance, there are many sanctions against Iran passed by UN Security Council and numerous nations such as the United States and those of the European Union also impose bilateral sanctions against Iran. They impose restrictions on exports of nuclear and missile to Iran, banking and insurance transactions, investment in oil, exports of refined petroleum products, and so on. Such measures are taken by many nations to deter Iran’s possible nuclear weapon program.\n\n\n"}
{"id": "7561058", "url": "https://en.wikipedia.org/wiki?curid=7561058", "title": "Holocentric", "text": "Holocentric\n\nHolocentric is a philosophical position which focuses on solutions as the outcome of human agency and on critical thinking.\n\nOne of the four fundamental worldview types proposed by Richard Bawden in 1997, the other three being Technocentric, Ecocentric, and Egocentric.\n\nDrawing on ideas introduced by Burrell and Morgan and Miller, Bawden developed the notion of a worldview matrix in which the four viewpoints represent the basic philosophical positions of members in a community of interest considering an ontological dimension (with holism and reductionism along the x axis) and an epistemological dimension (with objectivism and relativism/contextualism along the y axis).\n\nThe so-called, Miller / Bawden Quadrants can be utilized as a framework to assist in the collaborative dialog of any cooperative endeavor and the positioning of the holocentric quadrant at the intersection of holism and relativism distinguishes it uniquely as a view which accommodates both the complex and often non-specific interactions that lie at the heart of any social group.\n\nIn a community’s response to threats and opportunities, the formulation of strategy will typically evolve through a dialog between stakeholder members holding different viewpoints. In a holocentric approach, the resulting strategy will include holistic characteristics in that the solution will reflect the constituent positions within the community with the addition of the creative tension that is contributed through the negotiation process. Through the dialog process, emergent properties arise in the strategy due to the interplay between the various stakeholder viewpoints.\n\nIn order to improve the effectiveness of a community’s responses, consideration must be given to techniques which can deal with complex systems and the advancement of critical thinking skills. Such techniques often employ aspects of systems thinking to help community members better appreciate and deal with the complex interdependencies and conflicts that arise between stakeholder views.\n\nAs the community becomes more effective in the process of dialog, it may become more self-aware, and this ‘systemic’ heightening of awareness may lead to additional emergent properties which in turn may further increase the overall level of understanding and quality of the community response.\n\nWithin a cooperative community, the catalysts for the emergent understanding are the insights gained through inspirational learning and the abstract concepts learned through experiential learning.\n\nEducational approaches aimed at managing the critical learning process through the application of the Miller / Bawden Quadrants have been used in a number of different domains, most commonly those in which a wide variety of stakeholders are forced to formulate strategies dealing with limited natural resources. In this environment, agreement amongst sufficiently powerful stakeholders in any community will inevitably involve negotiated trade-offs, for example between productivity, equity, sustainability and stability.\n\n\n"}
{"id": "563299", "url": "https://en.wikipedia.org/wiki?curid=563299", "title": "Human behavior", "text": "Human behavior\n\nHuman behavior is the responses of individuals or groups of humans to internal and external stimuli. It refers to the array of every physical action and observable emotion associated with individuals, as well as the human race. While specific traits of one's personality and temperament may be more consistent, other behaviors will change as one moves from birth through adulthood. In addition to being dictated by age and genetics, behavior, driven in part by thoughts and feelings, is an insight into individual psyche, revealing among other things attitudes and values. Social behavior, a subset of human behavior, study the considerable influence of social interaction and culture. Additional influences include ethics, encircling, authority, rapport, hypnosis, persuasion and coercion.\n\nThe behavior of humans (and other organisms or even mechanisms) falls within a range with some behavior being common, some unusual, some acceptable, and some beyond acceptable limits. In sociology, behavior in general includes actions having no meaning, being not directed at other people, and thus all basic human actions. Behavior in this general sense should not be mistaken with social behavior, which is a more advanced social action, specifically directed at other people. The acceptability of behavior depends heavily upon social norms and is regulated by various means of social control. Human behavior is studied by the specialized academic disciplines of psychiatry, psychology, social work, sociology, economics, and anthropology.\n\nHuman behavior is experienced throughout an individual’s entire lifetime. It includes the way they act based on different factors such as genetics, social norms, core faith, and attitude. Behavior is impacted by certain traits each individual has. The traits vary from person to person and can produce different actions or behavior from each person. Social norms also impact behavior. Due to the inherently conformist nature of human society in general, humans are pressured into following certain rules and displaying certain behaviors in society, which conditions the way people behave. Different behaviors are deemed to be either acceptable or unacceptable in different societies and cultures. Core faith can be perceived through the religion and philosophy of that individual. It shapes the way a person thinks and this in turn results in different human behaviors. Attitude can be defined as \"the degree to which the person has a favorable or unfavorable evaluation of the behavior in question.\" One's attitude is essentially a reflection of the behavior he or she will portray in specific situations. Thus, human behavior is greatly influenced by the attitudes we use on a daily basis.\n\nLong before Charles Darwin published his book \"On the Origin of Species\" in 1858, animal breeders knew that patterns of behavior are somehow influenced by inheritance from parents. Studies of identical twins as compared to less closely related human beings, and of children brought up in adoptive homes, have helped scientists understand the influence of genetics on human behavior. The study of human behavioral genetics is still developing steadily with new methods such as genome-wide association studies.\n\nSocial norms, the often-unspoken rules of a group, shape not just our behaviors but also our attitudes.\nAn individual’s behavior varies depending on the group(s) they are a part of, a characteristic of society that allows their norms to heavily impact society. Without social norms, human society would not function as it currently does; humans would have to be more abstract in their behavior, as there would not be a pre-tested 'normal' standardized lifestyle, and individuals would have to make many more choices for themselves. The institutionalization of norms is, however, inherent in human society perhaps as a direct result of the desire to be accepted by others, which leads humans to manipulate their own behavior in order to 'fit in' with others. Depending on their nature and upon one's perspective, norms can impact different sections of society both positively (e.g. eating, dressing warm in the winter) and negatively (e.g. racism, drug use).\n\nCreativity is assumed to be present within every individual. Creativity pushes people past their comfort zone. For example, the Wright Brothers' invention of the first practical fixed-wing aircraft. The aircraft first took flight in 1903, and fifty years later the first passenger jet airliner was introduced. Creativity has kept people alive during harsh conditions, and it has also made certain individuals wealthy. We use creativity in our daily lives as well, such as finding a shortcut to a destination.\n\nAnother important aspect of human behavior is people's \"core faith\". Such faith can manifest in religion, philosophy, culture, and/or personal belief and often affects the way a person can behave. , some 80% of the United States public identified with a religion, and religion can play a large role in society. It is only natural for something that plays a large role in society to have an effect on human behavior. Morals are another factor of core faith that affects the way a person behaves. Emotions connected to morals include shame, pride, and discomfort - and these can change the way a person acts. Most importantly, shame and guilt have a large impact on behavior.\n\nLastly, culture highly affects human behavior. Children absorb the beliefs of certain cultures from such a young age that they are greatly affected as they grow up. These beliefs are taken into consideration throughout daily life, which leads to people from different cultures acting differently. These differences affect the way different cultures and areas of the world interact and act.\n\nAn attitude is an expression of favor or disfavor toward a person, place, thing, or event; it alters between each individual. Everyone has a different attitude towards different things. A main factor that determines attitude is likes and dislikes. The more one likes something or someone the more one is willing to open up and accept what they have to offer. When one doesn’t like something, one is more likely to get defensive and shut down. An example of how one's attitude affects one's human behavior could be as simple as taking a child to the park or to the doctor. Children know they have fun at the park so their attitude becomes willing and positive, but when a doctor is mentioned, they shut down and become upset with the thought of pain. Attitudes can sculpt personalities and the way people view who we are. People with similar attitudes tend to stick together as interests and hobbies are common. This does not mean that people with different attitudes do not interact, the fact is they do. What it means is that specific attitudes can bring people together (e.g., religious groups). Attitudes have a lot to do with the mind which highly relates to human behavior. The way a human behaves depends a lot on how they look at the situation and what they expect to gain from it.\n\n\n"}
{"id": "14570", "url": "https://en.wikipedia.org/wiki?curid=14570", "title": "Intension", "text": "Intension\n\nIn linguistics, logic, philosophy, and other fields, an intension is any property or quality connoted by a word, phrase, or another symbol. In the case of a word, the word's definition often implies an intension. For instance, the intensions of the word \"plant\" include properties including \"being composed of cellulose\", \"alive\", and \"organism\", among others. A \"comprehension\" is the collection of all such intensions.\n\nThe meaning of a word can be thought of as the bond between the \"idea the word means\" and the \"physical form of the word\". Swiss linguist Ferdinand de Saussure (1857–1913) contrasts three concepts:\n\n\nWithout intension of some sort, a word has no meaning. For instance, the terms \"rantans\" or \"brillig\" have no intension and hence no meaning. Such terms may be suggestive, but a term can be \"suggestive\" without being meaningful. For instance, \"ran tan\" is an archaic onomatopoeia for chaotic noise or din and may suggest to English speakers a din or meaningless noise, and \"brillig\" though made up by Lewis Caroll may be suggestive of 'brilliant' or 'frigid'. Such terms, it may be argued, are always intensional since they connote the property 'meaningless term', but this is only an apparent paradox and does not constitute a counterexample to the claim that without intension a word has no meaning. Part of its intension is that it has no extension. Intension is analogous to the signified in the Saussurean system, extension to the referent.\n\nIn philosophical arguments about dualism versus monism, it is noted that thoughts have intensionality and physical objects do not (S. E. Palmer, 1999), but rather have extension in space and time.\n\nA statement-form is simply a form obtained by putting blanks into a sentence where one or more expressions with extensions occur—for instance, \"The quick brown ___ jumped over the lazy ___'s back.\" An instance of the form is a statement obtained by filling the blanks in.\n\nAn \"intensional statement-form\" is a statement-form with at least one instance such that substituting co-extensive expressions into it does not always preserve logical value. An \"intensional statement\" is a statement that is an instance of an intensional statement-form. Here co-extensive expressions are expressions with the same extension.\n\nThat is, a statement-form is intensional if it has, as one of its instances, a statement for which there are two co-extensive expressions (in the relevant language) such that one of them occurs in the statement, and if the other one is put in its place (uniformly, so that it replaces the former expression wherever it occurs in the statement), the result is a (different) statement with a different logical value. An intensional statement, then, is an instance of such a form; it has the same form as a statement in which substitution of co-extensive terms fails to preserve logical value.\n\n\nTo see that these are intensional, make the following substitutions: (1) \"Mark Twain\" → \"The author of 'Corn-pone Opinions'\"; (2) \"Aristotle\" → \"the tutor of Alexander the Great\"; (3) can be seen to be intensional given \"had a sister\" → \"had a female sibling.\"\n\nIt will be noted that the intensional statements above feature expressions like \"knows\", \"possible\", and \"pleased\". Such expressions always, or nearly always, produce intensional statements when added (in some intelligible manner) to an extensional statement, and thus they (or more complex expressions like \"It is possible that\") are sometimes called \"intensional operators\". A large class of intensional statements, but by no means all, can be spotted from the fact that they contain intensional operators.\n\nAn \"extensional\" statement is a non-intensional statement. Substitution of co-extensive expressions into it always preserves logical value. A language is intensional if it contains intensional statements, and extensional otherwise. All natural languages are intensional. The only extensional languages are artificially constructed languages used in mathematical logic or for other special purposes and small fragments of natural languages.\n\n\nNote that if \"Samuel Clemens\" is put into (1) in place of \"Mark Twain\", the result is as true as the original statement. It should be clear that no matter what is put for \"Mark Twain\", so long as it is a singular term picking out the same man, the statement remains true. Likewise, we can put in place of the predicate any other predicate belonging to Mark Twain and only to Mark Twain, without changing the logical value. For (2), likewise, consider the following substitutions: \"Aristotle\" → \"The tutor of Alexander the Great\"; \"Aristotle\" → \"The author of the 'Prior Analytics'\"; \"had a sister\" → \"had a sibling with two X-chromosomes\"; \"had a sister\" → \"had a parent who had a non-male child\".\n\nIntensional languages cannot be given an adequate semantics in terms of the extensions of expressions in them, since the extensions themselves do not suffice to determine a logical value. (If they did, then one could not change the logical value by substituting co-extensive expressions.) On the other hand, for the first half of the 20th century the only known systems of formal semantics worked by assigning extensions to expressions and used a Tarski-style truth-definition of statements constructed from the primitive expressions of the language under analysis. Hence, these semantical methods were pathetically inadequate for understanding the semantics of any but a few small artificial languages or mutilated fragments of natural languages.\n\nThis situation changed in the 1960s with the invention of possible-world or \"intensional\" semantics, the main form of which is due to Saul Kripke. Though this has enabled improvements in the semantic modelling of natural languages, much work remains to be done.\n\n\n\n"}
{"id": "16006895", "url": "https://en.wikipedia.org/wiki?curid=16006895", "title": "Jackson Katz", "text": "Jackson Katz\n\nJackson T. Katz (born May 7, 1960) is an American educator, filmmaker, and author. He has created a gender violence prevention and education program entitled Mentors in Violence Prevention, which is used by U.S. military and various sporting organizations.\n\nKatz's work centers on violence, media, and masculinities, with an added focus on media literacy. He has made several documentaries on the representation of men and women in media.\n\nKatz is a former high school football player from Swampscott, Massachusetts. The first man to minor in women's studies at the University of Massachusetts-Amherst, Katz holds a master's degree from the Harvard Graduate School of Education, and a Ph.D. in cultural studies and education from UCLA, where he studied with Douglas Kellner. He has collaborated with Jean Kilbourne, Sut Jhally, and Byron Hurt.\n\nFrom 1988 to 1998, Katz oversaw Real Men, a grass-roots organization against sexism in Boston.\n\nKatz co-founded Mentors in Violence Prevention (MVP) in 1993 at Northeastern University's Center for the Study of Sport in Society. MVP has been implemented by college athletic programs, professional teams (including the New England Patriots and Boston Red Sox), NASCAR, and the United States Marine Corps. The related MVP Strategies 1997, distributes gender violence prevention training materials to U.S. school districts, municipalities, human service programs, corporations, law enforcement agencies, and military services. Katz has personally lectured at many such organizations as well, and has appeared on \"Good Morning America,\" \"The Oprah Winfrey Show\" and \"ABC News 20/20.\" His consultative role ranges has ranged from the World Health Organization to The Liz Claiborne Company. In March 2000, Secretary of Defense William S. Cohen appointed him to the U.S. Secretary of Defense's Task Force on Domestic Violence in the Military, where he served from 2000-2003.\n\nKatz currently is a paid consultant to the U.S. Air Force bystander intervention training and also acts as Director of the first global gender violence prevention program in the U.S. Marine Corps. Katz and his colleagues have also conducted trainings for the U.S. Army in Iraq, and MVP has been piloted around the world by the U.S. Navy.\n\nKatz advocates the bystander approach to gender violence and bullying prevention. Instead of focusing on women as victims and men as perpetrators of harassment, abuse or violence, the bystander approach concentrates on the role of peers in schools, groups, teams, workplaces and other social units.\n\nIn 2009, after an alleged gang rape in Richmond, California where two dozen teenagers watched and did nothing, Newsweek online reported that, \"a small but growing group of educators is trying to bring what's called 'bystander education' to American schools. While sexual violence prevention programs have typically focused on the victim (discouraging women from walking alone at night, for example) or the perpetrator (reiterating the fact that no means no), the bystander approach emphasizes the role witnesses can play in either supporting or challenging violence.\"\n\nKatz and his colleagues developed one of the first bystander initiatives, the mixed-gender Mentors in Violence Prevention (MVP) program, in 1993 at Northeastern University’s Center for the Study of Sport in Society. “Most people think they only have two choices for intervention,” says Katz. “One is to intervene physically right at the point of attack, and the other is to do nothing. And that’s a false set of choices.” As part of the MVP program, students sit in a classroom and talk about the menu of options—from getting a group of friends together to calling 911—available to them. At the heart of the program is a set of scenarios that allow students to imagine what they might do in a variety of situations. Each scenario comes with a list of viable interventions for bystanders.\n\nAccording to Newsweek, research is still needed to determine the effectiveness of bystander-awareness programs in schools, but the initial results are promising. One study found that after the Sioux City School District in Iowa implemented the MVP program, the number of freshman boys who said they could help prevent violence against women and girls increased by 50 percent.\n\nThe bystander programs that have proliferated in recent years on college and high school campuses and in the U.S. military involve both sexes and draw from various violence prevention theories and educational practices. The MVP model was influenced by basic tenets of social justice education. This approach is partly based on the premise that men’s silence in the face of other men’s abusive or violent behavior gives \"implicit consent\" to such behavior.\n\nThe MVP bystander approach frames men’s abuse of women as a societal problem whose roots lie in the institutional structures and cultural practices of a male-dominated society. [24] Thus, the MVP approach emphasizes changing social norms as the key to prevention. By challenging men to speak up and “[change] group dynamics in male peer culture,”this bystander model empowers men to step outside of the victim/perpetrator binary and gives men an opportunity to talk about some of the “dynamics of their interpersonal and group interaction in a safe space.”\n\nJackson Katz presented the Mentors in Violence Prevention (MVP) model hoping to put the focus on men to discontinue trends of violent masculinity through creating a model that would invite men into the critical dialogue, instead of painting them as perpetrators or potential perpetrators. Katz realized that there was a frustrating lack of inclusion of men and boys in the gender violence discussion, prompting him to create an education model that was inclusive to men and boys.\n\nThe original MVP model was created as workshops for all-male student athletes; Katz hoped that by working with male student athletes, they could help to stop the spread of ‘rape-supportive’ and ‘battering-supportive’ attitudes by speaking out against the masculine binary that supports gender violence. (Recon, 166) Katz says his initial focus on working with student-athletes stems from the “apathy, defensiveness—and sometimes outright hostility—of male athletic directors, coaches, and student-athletes...men and young men in the…athletic subculture…typically occupy a privileged position in school culture, and particularly in male peer culture.” This is a step towards the bystander approach. By working with boys who typically represented the popular part of school culture, Katz was hoping that these boys would then influence the people around them and in their schools in similar manners. It was important for Katz to ensure that MVP considers male student-athletes as potential mentors for younger kids, able of providing male leadership necessary to stop gender abuse.\n\nKatz’s model generally revolves around simulation and role-playing, as well as large discussion-based group meetings both consisting same-sex and different-sex students. As a part of his college initiative, his MVP model involves “holding three 90-minute sessions each year with each participating college team. A fourth session is scheduled for those student-athletes who wish to be trained further for work with younger students in middle and high school.” These workshops are designed to provide spaces for boys to discuss with each other the concept of masculinity and its definition, as well as its relation to gender abuse and violence. Additionally, Katz recognizes the role of those in positions of authority in schools and athletic teams. As his program has grown and evolved, he has included training of selected male and professional staff working in all sectors of schools and colleges.) In this, he is hoping that the top-down approach will provide role models for young and impressionable students and athletes who are looking for good representation. If these school leaders are able to use their positions of authority as positions of good influence, it will perhaps encourage a change in paradigm that will affect all of those in the school or community.\n\nThe MVP model originally focused on just male student-athletes. Since, the MVP model has expanded its target audience and educational group to “boys and girls, men and women, working together and in single-sex formats…by the mid-1990’s MVP had moved from a near-exclusive focus on the athletic world to general populations of high school and college students, and other institutional settings.” This expansion means that the dialogue around gender abuse and gender binaries is spreading throughout schools across the nation. More frank and honest talk about gender abuse will not only remove many of the stigmas from those who are abused, but will also encourage students to act out and speak out in defense of themselves and each other.\n\nIn his writings, public lectures, and films, Katz argues that gendered understandings and behavior in every arena from interpersonal relationships to the workplace and even politics are influenced by media and popular culture. Focusing on normative portrayals of men in advertising, television, Hollywood films, the entertainment industries, sports, and politics, Katz calls for an examination of \"the poses we strike and the images of masculinity that proliferate in media culture\" as a way to \"illuminate... what's going on in individual men's lives, and in our culture as a whole.\"\n\nKatz further maintains that in spite of variability due to such categories as class, race and ethnicity, \"violence in America is overwhelmingly a gendered phenomenon,\" shaped by \"cultural codes and ideals of masculinity and manhood.\" He argues that \"masculinity\" and \"femininity\" are socially constructed categories, and thus the \"disturbing equation of masculinity with pathological control and violence\" that currently exists in America is not genetically predetermined and can be changed. In the \"Tough Guise\" study guide, co-written with the video producer Jeremy Earp of the Media Education Foundation, Katz underscores his motivation for promoting media literacy: \"By looking critically at how institutions – from media outlets to political institutions to our schools – often play a role in reinforcing constricted, regressive notions of manhood that maintain an unacceptably violent status quo, we might begin to clear some space for individuals, male and female, to live freer lives.\"\n\nKatz's work on images of masculinity in media extends to his examination of \"a crucial but barely explored topic of cultural studies analysis: the role of media culture in the construction of presidential masculinity.\" Katz posits that \"media have become the single most important source of political information and persuasion,\" and that \"education for democracy in this era requires citizens to be media literate.\"\n\nAccording to Katz, part of being politically media literate means understanding how gender functions as a sub-textual force in presidential politics. He asks questions such as \"how does the perceived 'manliness' or 'toughness' of political candidates affect their electoral success? To what degree is the gender gap in presidential politics affected by men's gendered identities and sense of themselves as men, which itself is reinforced by media discourses and portrayals? How does paid political advertising on television – by far the biggest expenditure of funds in presidential campaigns – shape voters' perceptions of the relative 'manliness' of candidates? What are the similarities and differences between how women and men ascertain whether male political figures measure up to the 'masculine ideal' that is circulating in media culture at a given historical moment? Which mediated (white) masculine styles or archetypes have been politically successful over the past fifty years, and why?\"\n\nIn an article about the Barack Obama-Hillary Clinton race for the Democratic presidential nomination in 2008, Katz responded to pundits and other political observers who decried the media focus on race and gender when other crucial issues loomed. \"Presidential elections are always about race and gender. The reason people are talking about them now is that a black man and a (white) woman are serious contenders for a major party nomination. Their success is making visible what historically has been hidden in plain sight.\"\n\n\"Campaigns for the U.S. presidency in the era of mass media,\" he wrote, \"always turn on the personality and style of candidates, their skills at televisual performance, their race and gender, and how all of these interact with questions of national identity at a given historical moment. The biggest difference this time is that the Democratic nominee will not embody and hence reinforce the dominant position of white masculinity in the race/gender system.\"\n\nKatz further maintained that, \"Presidential contests until now have been contests between men. Men were the gender that mattered. No matter how qualified by intelligence, leadership ability or experience, women were not seriously considered for the top job in government, and everyone knew it. Their gender prevented people from seeing them as 'presidential.' If there is one thing that truly represents 'change' in this historic election season it is the change in what it means to appear 'presidential.' In the past, whether a candidate was a Republican or Democrat, conservative, centrist or liberal, their race and gender were predetermined. They were inevitably – and invariably – white and a man.”\n\nFor Katz, violence also plays an important role in shaping political discourse and in the voters' choice of whom to support for president. \"How much of the white male vote is determined by impressions about the relative 'manliness' or 'toughness' of candidates or political parties hasn’t been quantified,\" Katz writes. \"But there is no doubt that for several decades violence—both our individual and collective vulnerability to it, and questions about when and how to use the violent power of the state to protect the 'national interest' — has been an ominous and omnipresent factor in numerous foreign policy and domestic political issues (e.g. the Cold War, Vietnam, the 'War on Terror,' and the invasion of Iraq, as well as gun control, and executive, legislative and judicial responses to violent crime).\"\n\nIn several articles, Katz analyzes and comments on \"the pervasive use of sports metaphors in presidential discourse and how the language of sport functions to construct a masculine ideal for leadership at the heights of political power.\" He points out that \"the two most 'metaphorically influential' sports in presidential campaign rhetoric are boxing and football... not coincidentally, both are violent sports that attract a disproportionate percentage of male participants and fans.\"\n\n\"The frequent use of boxing and football metaphors in political discourse did not cause violence to become an important force in our politics, but this usage is one measure of how presidential campaigns in the mass media era are less about policy differences and complex political agendas than they are about the selling of a certain kind of executive masculinity, embodied until the historic 2008 election in a particular white man whom the public comes to know largely through television and other technologies of mass communication.\"\n\nKatz also comments on implications for female candidates. He writes, \"One of 2008 Republican vice-presidential nominee Sarah Palin's most-quoted lines on the campaign trail in the fall of 2008 was 'The heels are on, the gloves are off,' which she typically delivered to wild cheers of approval. In coming years, when this historic campaign and those yet to come are analyzed, it will be particularly interesting to see how female and male voters respond to language where a woman throws the 'knockout punch.' Does this masculinize and thus help to make them more credible as potential commanders-in-chief? Or do women who are seen as 'too-aggressive' – even if only in a metaphorical sense – turn voters off? What are the differences between how the sexes view a woman 'throwing punches' if she's a conservative (like Palin) or a liberal feminist (like Hillary Clinton?).\"\n\nKatz is the creator of educational videos for high school and college students produced and distributed through the Media Education Foundation:\n\n\nHe is also featured in such documentaries as Byron Hurt's \"Hip Hop: Beyond Beats and Rhymes\" (2007), Thomas Keith's \"\" (2008), and Jennifer Siebel Newsom's \"Miss Representation\" (2011).\n\nKatz publishes articles in academic journals, anthologies, and text readers on topics such as the intersections of race and gender in the representation of masculinity, advertising, secondary educational leadership, right-wing talk radio, Mel Gibson, athletes and gender violence, media discourse about violence, masculinities and violence, presidential masculinities, and Jewish masculinity.\n\nHis book, \"The Macho Paradox: Why Some Men Hurt Women and How All Men Can Help\", (2006),\n\nMan Enough?: Donald Trump, Hillary Clinton, and the Politics of Presidential Masculinity Paperback – Mar 15 2016\n\nKatz currently blogs for the Huffington Post.\n\n\n"}
{"id": "5730634", "url": "https://en.wikipedia.org/wiki?curid=5730634", "title": "Junkyard tornado", "text": "Junkyard tornado\n\nThe junkyard tornado is an argument used to deride the probability of abiogenesis as comparable to \"the chance that a tornado sweeping through a junkyard might assemble a Boeing 747.\" It was used originally by Fred Hoyle, in which he applied statistical analysis to the origin of life, but similar observations predate Hoyle and have been found all the way back to Darwin's time, and indeed to Cicero in classical times. While Hoyle himself was an atheist, the argument has since become a mainstay of creationist and intelligent design criticisms of evolution.\n\nThis argument is rejected by the vast majority of biologists. From the modern evolutionary standpoint, while the odds of the sudden construction of higher lifeforms are indeed improbably remote, evolution proceeds in many smaller stages, each driven by natural selection rather than by chance, over a long period of time. The transition as a whole is plausible, as each step improves survivability; the Boeing 747 was not designed in a single unlikely burst of creativity, and modern lifeforms were not constructed in one single unlikely event, as the junkyard tornado posits.\n\nAccording to Fred Hoyle's analysis, the probability of cellular life's arising from non-living matter (abiogenesis) was about one-in-10. He commented:\n\nThis echoes his stance, reported elsewhere:\n\nHoyle used this to argue in favor of panspermia, that the origin of life on earth was from preexisting life in space.\n\nThe junkyard tornado derives from arguments most popular in the 1920s, prior to the modern evolutionary synthesis, which are rejected by evolutionary biologists. A preliminary step is to establish that the phase space containing some biological entity (such as humans, working cells, or the eye) is enormous, something not contentious. The argument is then to infer from the huge size of the phase space that the probability that the entity could appear by chance is exceedingly low, ignoring the key process involved, natural selection.\n\nSometimes, arguments invoking the junkyard tornado analogy also invoke Borel's Law, which claims that highly improbable events do not occur. The usual argument against Borel's \"Law\" is that if \"all\" possible outcomes of a natural process are highly improbable when taken individually, then a highly improbable outcome is certain. The true law being referenced is actually the Strong Law of large numbers, but creationists have taken a simple statement made by Borel in books written late in his life concerning probability theory and called this statement Borel's Law.\n\nThis \"Borel's Law\" is actually the universal probability bound, which when applied to evolution is axiomatically incorrect. The universal probability bound assumes that the event one is trying to measure is completely random, and some use this argument to prove that evolution could not possibly occur, since its probability would be much less than that of the universal probability bound. This, however, is fallacious, given that evolution is not a completely random effect (genetic drift), but rather proceeds with the aid of natural selection.\n\nThe junkyard tornado is also applied to cellular biochemistry. This is comparable to the older infinite monkey theorem but instead of the works of William Shakespeare, the claim is that the probability that a protein molecule could achieve a functional sequence of amino acids is too low to be realised by chance alone. The argument conflates the difference between the complexity that arises from living organisms that are able to reproduce themselves (and as such may evolve under natural selection to become better adapted and perhaps more complex over time) with the complexity of inanimate objects, unable to pass on any reproductive changes (such as the multitude of parts manufactured in Boeing 747). The comparison breaks down because of this important distinction.\n\nAccording to Ian Musgrave in \"Lies, Damned Lies, Statistics, and Probability of Abiogenesis Calculations\":\nThe junkyard tornado argument is rejected by evolutionary biologists, since, as the late John Maynard Smith pointed out, \"no biologist imagines that complex structures arise in a single step.\" Evolutionary biology explains how complex cellular structures evolved by analysing the intermediate steps required for precellular life. It is these intermediate steps that are omitted in creationist arguments, which is the cause of their overestimating of the improbability of the entire process.\n\nHoyle's argument is a mainstay of creationist, intelligent design, orthogenetic and other criticisms of evolution. It has been labeled a fallacy by Richard Dawkins in his two books \"The Blind Watchmaker\" and \"Climbing Mount Improbable\". Dawkins argues that the existence of God, who under theistic uses of Hoyle's argument is implicitly responsible for the origin of life, defies probability far more than does the spontaneous origin of life even given Hoyle's assumptions, with Dawkins detailing his counter-argument in \"The God Delusion\", describing God as the Ultimate Boeing 747 gambit.\n\n\n"}
{"id": "26915", "url": "https://en.wikipedia.org/wiki?curid=26915", "title": "Linguistic relativity", "text": "Linguistic relativity\n\nThe hypothesis of linguistic relativity holds that the structure of a language affects its speakers' world view or cognition. Also known as the Sapir–Whorf hypothesis, or Whorfianism, the principle is often defined to include two versions: the \"strong hypothesis\" and the \"weak hypothesis\":\n\nThe term \"Sapir–Whorf hypothesis\" is considered a misnomer by linguists for several reasons: Edward Sapir and Benjamin Lee Whorf never co-authored any works, and never stated their ideas in terms of a hypothesis. The distinction between a weak and a strong version of this hypothesis is also a later invention; Sapir and Whorf never set up such a dichotomy, although often in their writings their views of this relativity principle are phrased in stronger or weaker terms.\n\nThe idea was first clearly expressed by 19th-century thinkers, such as Wilhelm von Humboldt, who saw language as the expression of the spirit of a nation. Members of the early 20th-century school of American anthropology headed by Franz Boas and Edward Sapir also embraced forms of the idea to one degree or another, including in a 1928 meeting of the Linguistic Society of America, but Sapir in particular wrote more often against than in favor of anything like linguistic determinism. Sapir's student, Benjamin Lee Whorf, came to be seen as the primary proponent as a result of his published observations of how he perceived linguistic differences to have consequences in human cognition and behavior. Harry Hoijer, another of Sapir's students, introduced the term \"Sapir–Whorf hypothesis\", even though the two scholars never formally advanced any such hypothesis. A strong version of relativist theory was developed from the late 1920s by the German linguist Leo Weisgerber. Whorf's principle of linguistic relativity was reformulated as a testable hypothesis by Roger Brown and Eric Lenneberg who conducted experiments designed to find out whether color perception varies between speakers of languages that classified colors differently. As the study of the universal nature of human language and cognition came into focus in the 1960s the idea of linguistic relativity fell out of favor among linguists. A 1969 study by Brent Berlin and Paul Kay demonstrated the existence of universal semantic constraints in the field of colour terminology which were widely seen to discredit the existence of linguistic relativity in this domain, although this conclusion has been disputed by relativist researchers.\n\nFrom the late 1980s, a new school of linguistic relativity scholars has examined the effects of differences in linguistic categorization on cognition, finding broad support for non-deterministic versions of the hypothesis in experimental contexts. Some effects of linguistic relativity have been shown in several semantic domains, although they are generally weak. Currently, a balanced view of linguistic relativity is espoused by most linguists holding that language influences certain kinds of cognitive processes in non-trivial ways, but that other processes are better seen as arising from connectionist factors. Research is focused on exploring the ways and extent to which language influences thought. The principle of linguistic relativity and the relation between language and thought has also received attention in varying academic fields from philosophy to psychology and anthropology, and it has also inspired and coloured works of fiction and the invention of constructed languages.\n\nThe strongest form of the theory is linguistic determinism, which holds that language entirely determines the range of cognitive processes. The hypothesis of linguistic determinism is now generally agreed to be false.\n\nThis is the weaker form, proposing that language provides constraints in some areas of cognition, but that it is by no means determinative. Research on weaker forms has produced positive empirical evidence for a relationship.\n\nThe idea that language and thought are intertwined is ancient. Plato argued against sophist thinkers such as Gorgias of Leontini, who held that the physical world cannot be experienced except through language; this made the question of truth dependent on aesthetic preferences or functional consequences. Plato held instead that the world consisted of eternal ideas and that language should reflect these ideas as accurately as possible. Following Plato, St. Augustine, for example, held the view that language was merely labels applied to already existing concepts. This view remained prevalent throughout the Middle Ages. Roger Bacon held the opinion that language was but a veil covering up eternal truths, hiding them from human experience. For Immanuel Kant, language was but one of several tools used by humans to experience the world.\n\nIn the late 18th and early 19th centuries, the idea of the existence of different national characters, or \"Volksgeister\", of different ethnic groups was the moving force behind the German romantics school and the beginning ideologies of ethnic nationalism.\n\nAlthough himself a Swede, Emanuel Swedenborg inspired several of the German Romantics. As early as 1749, he alludes to something along the lines of linguistic relativity in commenting on a passage in the table of nations in the book of Genesis: In 1771 he spelled this out more explicitly: \n\nJohann Georg Hamann is often suggested to be the first among the actual German Romantics to speak of the concept of \"the genius of a language.\" In his \"Essay Concerning an Academic Question,\" Hamann suggests that a people's language affects their worldview:\n\nIn 1820, Wilhelm von Humboldt connected the study of language to the national romanticist program by proposing the view that language is the fabric of thought. Thoughts are produced as a kind of internal dialog using the same grammar as the thinker's native language. This view was part of a larger picture in which the world view of an ethnic nation, their \"Weltanschauung\", was seen as being faithfully reflected in the grammar of their language. Von Humboldt argued that languages with an inflectional morphological type, such as German, English and the other Indo-European languages, were the most perfect languages and that accordingly this explained the dominance of their speakers over the speakers of less perfect languages. Wilhelm von Humboldt declared in 1820:\n\nThe idea that some languages are superior to others and that lesser languages maintained their speakers in intellectual poverty was widespread in the early 20th century. American linguist William Dwight Whitney, for example, actively strove to eradicate Native American languages, arguing that their speakers were savages and would be better off learning English and adopting a \"civilized\" way of life. The first anthropologist and linguist to challenge this view was Franz Boas. While undertaking geographical research in northern Canada he became fascinated with the Inuit people and decided to become an ethnographer. Boas stressed the equal worth of all cultures and languages, that there was no such thing as a primitive language and that all languages were capable of expressing the same content, albeit by widely differing means. Boas saw language as an inseparable part of culture and he was among the first to require of ethnographers to learn the native language of the culture under study and to document verbal culture such as myths and legends in the original language.\n\nBoas:\n\nBoas' student Edward Sapir reached back to the Humboldtian idea that languages contained the key to understanding the world views of peoples. He espoused the viewpoint that because of the differences in the grammatical systems of languages no two languages were similar enough to allow for perfect cross-translation. Sapir also thought because language represented reality differently, it followed that the speakers of different languages would perceive reality differently.\n\nSapir:\n\nOn the other hand, Sapir explicitly rejected strong linguistic determinism by stating, \"It would be naïve to imagine that any analysis of experience is dependent on pattern expressed in language.\"\n\nSapir was explicit that the connections between language and culture were neither thoroughgoing nor particularly deep, if they existed at all:\n\nSapir offered similar observations about speakers of so-called \"world\" or \"modern\" languages, noting, \"possession of a common language is still and will continue to be a smoother of the way to a mutual understanding between England and America, but it is very clear that other factors, some of them rapidly cumulative, are working powerfully to counteract this leveling influence. A common language cannot indefinitely set the seal on a common culture when the geographical, physical, and economics determinants of the culture are no longer the same throughout the area.\"\n\nWhile Sapir never made a point of studying directly how languages affected thought, some notion of (probably \"weak\") linguistic relativity underlay his basic understanding of language, and would be taken up by Whorf.\n\nDrawing on influences such as Humboldt and Friedrich Nietzsche, some European thinkers developed ideas similar to those of Sapir and Whorf, generally working in isolation from each other. Prominent in Germany from the late 1920s through into the 1960s were the strongly relativist theories of Leo Weisgerber and his key concept of a 'linguistic inter-world', mediating between external reality and the forms of a given language, in ways peculiar to that language. Russian psychologist Lev Vygotsky read Sapir's work and experimentally studied the ways in which the development of concepts in children was influenced by structures given in language. His 1934 work \"Thought and Language\" has been compared to Whorf's and taken as mutually supportive evidence of language's influence on cognition. Drawing on Nietzsche's ideas of perspectivism Alfred Korzybski developed the theory of general semantics that has been compared to Whorf's notions of linguistic relativity. Though influential in their own right, this work has not been influential in the debate on linguistic relativity, which has tended to center on the American paradigm exemplified by Sapir and Whorf.\n\nMore than any linguist, Benjamin Lee Whorf has become associated with what he called the \"linguistic relativity principle\". Studying Native American languages, he attempted to account for the ways in which grammatical systems and language use differences affected perception. Whorf also examined how a scientific account of the world differed from a religious account, which led him to study the original languages of religious scripture and to write several anti-evolutionist pamphlets. Whorf's opinions regarding the nature of the relation between language and thought remain under contention. Critics such as Lenneberg, Black and Pinker attribute to Whorf a strong linguistic determinism, while Lucy, Silverstein and Levinson point to Whorf's explicit rejections of determinism, and where he contends that translation and commensuration is possible.\n\nAlthough Whorf lacked an advanced degree in linguistics, his reputation reflects his acquired competence. His peers at Yale University considered the 'amateur' Whorf to be the best man available to take over Sapir's graduate seminar in Native American linguistics while Sapir was on sabbatical in 1937–38. He was highly regarded by authorities such as Boas, Sapir, Bloomfield and Tozzer. Indeed, Lucy wrote, \"despite his 'amateur' status, Whorf's work in linguistics was and still is recognized as being of superb professional quality by linguists\".\n\nDetractors such as Lenneberg, Chomsky and Pinker criticized him for insufficient clarity in his description of how language influences thought, and for not proving his conjectures. Most of his arguments were in the form of anecdotes and speculations that served as attempts to show how 'exotic' grammatical traits were connected to what were apparently equally exotic worlds of thought. In Whorf's words:\n\nAmong Whorf's best-known examples of linguistic relativity are instances where an indigenous language has several terms for a concept that is only described with one word in European languages (Whorf used the acronym SAE \"Standard Average European\" to allude to the rather similar grammatical structures of the well-studied European languages in contrast to the greater diversity of less-studied languages).\n\nOne of Whorf's examples was the supposedly large number of words for 'snow' in the Inuit language, an example which later was contested as a misrepresentation.\n\nAnother is the Hopi language's words for water, one indicating drinking water in a container and another indicating a natural body of water. These examples of polysemy served the double purpose of showing that indigenous languages sometimes made more fine grained semantic distinctions than European languages and that direct translation between two languages, even of seemingly basic concepts such as snow or water, is not always possible.\n\nAnother example is from Whorf's experience as a chemical engineer working for an insurance company as a fire inspector. While inspecting a chemical plant he observed that the plant had two storage rooms for gasoline barrels, one for the full barrels and one for the empty ones. He further noticed that while no employees smoked cigarettes in the room for full barrels, no-one minded smoking in the room with empty barrels, although this was potentially much more dangerous because of the highly flammable vapors still in the barrels. He concluded that the use of the word \"empty\" in connection to the barrels had led the workers to unconsciously regard them as harmless, although consciously they were probably aware of the risk of explosion. This example was later criticized by Lenneberg as not actually demonstrating causality between the use of the word \"empty\" and the action of smoking, but instead was an example of circular reasoning. Pinker in \"The Language Instinct\" ridiculed this example, claiming that this was a failing of human insight rather than language.\n\nWhorf's most elaborate argument for linguistic relativity regarded what he believed to be a fundamental difference in the understanding of time as a conceptual category among the Hopi. He argued that in contrast to English and other SAE languages, Hopi does not treat the flow of time as a sequence of distinct, countable instances, like \"three days\" or \"five years,\" but rather as a single process and that consequently it has no nouns referring to units of time as SAE speakers understand them. He proposed that this view of time was fundamental to Hopi culture and explained certain Hopi behavioral patterns. Malotki later claimed that he had found no evidence of Whorf's claims in 1980's era speakers, nor in historical documents dating back to the arrival of Europeans. Malotki used evidence from archaeological data, calendars, historical documents, modern speech and concluded that there was no evidence that Hopi conceptualize time in the way Whorf suggested. Universalist scholars such as Pinker often see Malotki's study as a final refutation of Whorf's claim about Hopi, whereas relativist scholars such as Lucy and Penny Lee criticized Malotki's study for mischaracterizing Whorf's claims and for forcing Hopi grammar into a model of analysis that doesn't fit the data.\n\nWhorf died in 1941 at age 44, leaving multiple unpublished papers. His line of thought was continued by linguists and anthropologists such as Hoijer and Lee who both continued investigations into the effect of language on habitual thought, and Trager, who prepared a number of Whorf's papers for posthumous publishing. The most important event for the dissemination of Whorf's ideas to a larger public was the publication in 1956 of his major writings on the topic of linguistic relativity in a single volume titled \"Language, Thought and Reality\".\n\nIn 1953, Eric Lenneberg criticised Whorf's examples from an objectivist view of language holding that languages are principally meant to represent events in the real world and that even though languages express these ideas in various ways, the meanings of such expressions and therefore the thoughts of the speaker are equivalent. He argued that Whorf's English descriptions of a Hopi speaker's view of time were in fact translations of the Hopi concept into English, therefore disproving linguistic relativity. However Whorf was concerned with how the habitual \"use\" of language influences habitual behavior, rather than translatability. Whorf's point was that while English speakers may be able to \"understand\" how a Hopi speaker thinks, they do not \"think\" in that way.\n\nLenneberg's main criticism of Whorf's works was that he never showed the connection between a linguistic phenomenon and a mental phenomenon. With Brown, Lenneberg proposed that proving such a connection required directly matching linguistic phenomena with behavior. They assessed linguistic relativity experimentally and published their findings in 1954.\n\nSince neither Sapir nor Whorf had ever stated a formal hypothesis, Brown and Lenneberg formulated their own. Their two tenets were (i) \"the world is differently experienced and conceived in different linguistic communities\" and (ii) \"language causes a particular cognitive structure\". Brown later developed them into the so-called \"weak\" and \"strong\" formulation:\n\nBrown's formulations became widely known and were retrospectively attributed to Whorf and Sapir although the second formulation, verging on linguistic determinism, was never advanced by either of them.\n\nSince Brown and Lenneberg believed that the objective reality denoted by language was the same for speakers of all languages, they decided to test how different languages codified the same message differently and whether differences in codification could be proven to affect behavior.\n\nThey designed experiments involving the codification of colors. In their first experiment, they investigated whether it was easier for speakers of English to remember color shades for which they had a specific name than to remember colors that were not as easily definable by words. This allowed them to compare the linguistic categorization directly to a non-linguistic task. In a later experiment, speakers of two languages that categorize colors differently (English and Zuni) were asked to recognize colors. In this way, it could be determined whether the differing color categories of the two speakers would determine their ability to recognize nuances within color categories. Brown and Lenneberg found that Zuñi speakers who classify green and blue together as a single color did have trouble recognizing and remembering nuances within the green/blue category. Brown and Lenneberg's study began a tradition of investigation of linguistic relativity through color terminology.\n\nLenneberg was also one of the first cognitive scientists to begin development of the Universalist theory of language that was formulated by Chomsky in the form of Universal Grammar, effectively arguing that all languages share the same underlying structure. The Chomskyan school also holds the belief that linguistic structures are largely innate and that what are perceived as differences between specific languages are surface phenomena that do not affect the brain's universal cognitive processes. This theory became the dominant paradigm in American linguistics from the 1960s through the 1980s, while linguistic relativity became the object of ridicule.\n\nExamples of universalist influence in the 1960s are the studies by Berlin and Kay who continued Lenneberg's color research. They studied color terminology formation and showed clear universal trends in color naming. For example, they found that even though languages have different color terminologies, they generally recognize certain hues as more focal than others. They showed that in languages with few color terms, it is predictable from the number of terms which hues are chosen as focal colors, for example, languages with only three color terms always have the focal colors black, white and red. The fact that what had been believed to be random differences between color naming in different languages could be shown to follow universal patterns was seen as a powerful argument against linguistic relativity. Berlin and Kay's research has since been criticized by relativists such as Lucy, who argued that Berlin and Kay's conclusions were skewed by their insistence that color terms encode only color information. This, Lucy argues, made them blind to the instances in which color terms provided other information that might be considered examples of linguistic relativity.\n\nOther universalist researchers dedicated themselves to dispelling other aspects of linguistic relativity, often attacking Whorf's specific points and examples. For example, Malotki's monumental study of time expressions in Hopi presented many examples that challenged Whorf's \"timeless\" interpretation of Hopi language and culture.\n\nToday many followers of the universalist school of thought still oppose linguistic relativity. For example, Pinker argues in \"The Language Instinct\" that thought is independent of language, that language is itself meaningless in any fundamental way to human thought, and that human beings do not even think in \"natural\" language, i.e. any language that we actually communicate in; rather, we think in a meta-language, preceding any natural language, called \"mentalese.\" Pinker attacks what he calls \"Whorf's radical position,\" declaring, \"the more you examine Whorf's arguments, the less sense they make.\"\n\nPinker and other universalists have been accused by relativists of misrepresenting Whorf's views and arguing against strawmen.\n\nJoshua Fishman argued that Whorf's true position was largely overlooked. In 1978, he suggested that Whorf was a \"neo-Herderian champion\" and in 1982, he proposed \"Whorfianism of the third kind\" in an attempt to refocus linguists' attention on what he claimed was Whorf's real interest, namely the intrinsic value of \"little peoples\" and \"little languages\". Whorf had criticized Ogden's Basic English thus:\n\nWhere Brown's weak version of the linguistic relativity hypothesis proposes that language \"influences\" thought and the strong version that language \"determines\" thought, Fishman's 'Whorfianism of the third kind' proposes that language \"is a key to culture\".\n\nIn the late 1980s and early 1990s, advances in cognitive psychology and cognitive linguistics renewed interest in the Sapir–Whorf hypothesis. One of those who adopted a more Whorfian approach was George Lakoff. He argued that language is often used metaphorically and that languages use different cultural metaphors that reveal something about how speakers of that language think. For example, English employs conceptual metaphors likening time with money, so that time can be saved and spent and invested, whereas other languages do not talk about time in that way. Other such metaphors are common to many languages because they are based on general human experience, for example, metaphors likening \"up\" with \"good\" and \"bad\" with \"down\". Lakoff also argued that metaphor plays an important part in political debates such as the \"right to life\" or the \"right to choose\"; or \"illegal aliens\" or \"undocumented workers\".\n\nIn his book \"Women, Fire and Dangerous things: What categories reveal about the mind,\" Lakoff reappraised linguistic relativity and especially Whorf's views about how linguistic categorization reflects and/or influences mental categories. He concluded that the debate had been confused. He described four parameters on which researchers differed in their opinions about what constitutes linguistic relativity:\nLakoff concluded that many of Whorf's critics had criticized him using novel definitions of linguistic relativity, rendering their criticisms moot.\n\nThe publication of the 1996 anthology \"Rethinking Linguistic Relativity\" edited by Gumperz and Levinson began a new period of linguistic relativity studies that focused on cognitive and social aspects. The book included studies on the linguistic relativity and universalist traditions. Levinson documented significant linguistic relativity effects in the linguistic conceptualization of spatial categories between languages. Separate studies by Bowerman and Slobin treated the role of language in cognitive processes. Bowerman showed that certain cognitive processes did not use language to any significant extent and therefore could not be subject to linguistic relativity. Slobin described another kind of cognitive process that he named \"thinking for speaking\" – the kind of process in which perceptional data and other kinds of prelinguistic cognition are translated into linguistic terms for communication. These, Slobin argues, are the kinds of cognitive process that are at the root of linguistic relativity.\n\nResearchers such as Boroditsky, Lucy and Levinson believe that language influences thought in more limited ways than the broadest early claims. Researchers examine the interface between thought (or cognition), language and culture and describe the relevant influences. They use experimental data to back up their conclusions. Kay ultimately concluded that \"[the] Whorf hypothesis is supported in the right visual field but not the left\". His findings show that accounting for brain lateralization offers another perspective.\n\nPsycholinguistic studies explored motion perception, emotion perception, object representation and memory. The gold standard of psycholinguistic studies on linguistic relativity is now finding non-linguistic cognitive differences in speakers of different languages (thus rendering inapplicable Pinker's criticism that linguistic relativity is \"circular\").\n\nRecent work with bilingual speakers attempts to distinguish the effects of language from those of culture on bilingual cognition including perceptions of time, space, motion, colors and emotion. Researchers described differences between bilinguals and monolinguals in perception of color, representations of time and other elements of cognition.\n\nLucy identified three main strands of research into linguistic relativity.\n\nThe \"structure-centered\" approach starts with a language's structural peculiarity and examines its possible ramifications for thought and behavior. The defining example is Whorf's observation of discrepancies between the grammar of time expressions in Hopi and English. More recent research in this vein is Lucy's research describing how usage of the categories of grammatical number and of numeral classifiers in the Mayan language Yucatec result in Mayan speakers classifying objects according to material rather than to shape as preferred by English speakers.\n\nThe \"domain-centered\" approach selects a semantic domain and compares it across linguistic and cultural groups. It centered on color terminology, although this domain is acknowledged to be sub-optimal, because color perception, unlike other semantic domains, is hardwired into the neural system and as such is subject to more universal restrictions than other semantic domains.\n\nSpace is another semantic domain that has proven fruitful for linguistic relativity studies. Spatial categories vary greatly across languages. Speakers rely on the linguistic conceptualization of space in performing many ordinary tasks. Levinson and others reported three basic spatial categorizations. While many languages use combinations of them, some languages exhibit only one type and related behaviors. For example, Yimithirr only uses absolute directions when describing spatial relations — the position of everything is described by using the cardinal directions. Speakers define a location as \"north of the house\", while an English speaker may use relative positions, saying \"in front of the house\" or \"to the left of the house\".\n\nThe \"behavior centered\" approach starts by comparing behavior across linguistic groups and then searches for causes for that behavior in the linguistic system. Whorf attributed the occurrence of fires at a chemical plant to the workers' use of the word 'empty' to describe the barrels containing only explosive vapors. Bloom noticed that speakers of Chinese had unexpected difficulties answering counter-factual questions posed to them in a questionnaire. He concluded that this was related to the way in which counter-factuality is marked grammatically in Chinese. Other researchers attributed this result to Bloom's flawed translations. Strømnes examined why Finnish factories had a higher occurrence of work related accidents than similar Swedish ones. He concluded that cognitive differences between the grammatical usage of Swedish prepositions and Finnish cases could have caused Swedish factories to pay more attention to the work process while Finnish factory organizers paid more attention to the individual worker.\n\nEverett's work on the Pirahã language of the Brazilian Amazon found several peculiarities that he interpreted as corresponding to linguistically rare features, such as a lack of numbers and color terms in the way those are otherwise defined and the absence of certain types of clauses. Everett's conclusions were met with skepticism from universalists who claimed that the linguistic deficit is explained by the lack of need for such concepts.\n\nRecent research with non-linguistic experiments in languages with different grammatical properties (e.g., languages with and without numeral classifiers or with different gender grammar systems) showed that language differences in human categorization are due to such differences. Experimental research suggests that this linguistic influence on thought diminishes over time, as when speakers of one language are exposed to another.\n\nA study published by the American Psychological Association’s Journal of Experimental Psychology claimed that language can influence how you estimate time. The study focused on three groups, those who spoke only Swedish, those who spoke only Spanish and bilingual speakers who spoke both of those languages. Swedish speakers describe time using distance terms like \"long\" or \"short\" while Spanish speakers do it using volume related terms like \"big\" or \"small\". The researchers asked the participants to estimate how much time had passed while watching a line growing across a screen, or a container being filled, or both. The researches stated that \"When reproducing duration, Swedish speakers were misled by stimulus length, and Spanish speakers were misled by stimulus size/quantity.\" When the bilinguals where prompted with the word “duración” (the Spanish word for duration) they based their time estimates of how full the containers were, ignoring the growing lines. When prompted with the word “tid” (the Swedish word for duration) they estimated the time elapsed solely by the distance the lines had traveled.\n\nResearch continued after Lenneberg/Roberts and Brown/Lenneberg. The studies showed a correlation between color term numbers and ease of recall in both Zuni and English speakers. Researchers attributed this to focal colors having higher codability than less focal colors, and not with linguistic relativity effects. Berlin/Kay found universal typological color principles that are determined by biological rather than linguistic factors. This study sparked studies into typological universals of color terminology. Researchers such as Lucy, Saunders and Levinson argued that Berlin and Kay's study does not refute linguistic relativity in color naming, because of unsupported assumptions in their study (such as whether all cultures in fact have a clearly-defined category of \"color\") and because of related data problems. Researchers such as Maclaury continued investigation into color naming. Like Berlin and Kay, Maclaury concluded that the domain is governed mostly by physical-biological universals.\n\nLinguistic relativity inspired others to consider whether thought could be influenced by manipulating language.\n\nThe question bears on philosophical, psychological, linguistic and anthropological questions.\n\nA major question is whether human psychological faculties are mostly innate or whether they are mostly a result of learning, and hence subject to cultural and social processes such as language. The innate view holds that humans share the same set of basic faculties, and that variability due to cultural differences is less important and that the human mind is a mostly biological construction, so that all humans sharing the same neurological configuration can be expected to have similar cognitive patterns.\n\nMultiple alternatives have advocates. The contrary constructivist position holds that human faculties and concepts are largely influenced by socially constructed and learned categories, without many biological restrictions. Another variant is idealist, which holds that human mental capacities are generally unrestricted by biological-material strictures. Another is essentialist, which holds that essential differences may influence the ways individuals or groups experience and conceptualize the world. Yet another is relativist (Cultural relativism), which sees different cultural groups as employing different conceptual schemes that are not necessarily compatible or commensurable, nor more or less in accord with external reality.\n\nAnother debate considers whether thought is a form of internal speech or is independent of and prior to language.\n\nIn the philosophy of language the question addresses the relations between language, knowledge and the external world, and the concept of truth. Philosophers such as Putnam, Fodor, Davidson, and Dennett see language as representing directly entities from the objective world and that categorization reflect that world. Other philosophers (e.g. Wittgenstein, Quine, Searle, Foucault) argue that categorization and conceptualization is subjective and arbitrary.\n\nAnother question is whether language is a tool for representing and referring to objects in the world, or whether it is a system used to construct mental representations that can be communicated.\n\nSapir/Whorf contemporary Alfred Korzybski was independently developing his theory of general semantics, which was aimed at using language's influence on thinking to maximize human cognitive abilities. Korzybski's thinking was influenced by logical philosophy such as Russell and Whitehead's \"Principia Mathematica\" and Wittgenstein's \"Tractatus Logico-Philosophicus\". Although Korzybski was not aware of Sapir and Whorf's writings, the movement was followed by Whorf-admirer Stuart Chase, who fused Whorf's interest in cultural-linguistic variation with Korzybski's programme in his popular work \"The Tyranny of Words\". S. I. Hayakawa was a follower and popularizer of Korzybski's work, writing \"Language in Thought and Action\". The general semantics movement influenced the development of neurolinguistic programming, another therapeutic technique that seeks to use awareness of language use to influence cognitive patterns.\n\nKorzybski independently described a \"strong\" version of the hypothesis of linguistic relativity.\n\nIn their fiction, authors such as Ayn Rand and George Orwell explored how linguistic relativity might be exploited for political purposes. In Rand's \"Anthem\", a fictive communist society removed the possibility of individualism by removing the word \"I\" from the language. In Orwell's \"1984\" the authoritarian state created the language Newspeak to make it impossible for people to think critically about the government, or even to contemplate that they might be impoverished or oppressed, by reducing the number of words to reduce the thought of the locutor.\n\nOthers have been fascinated by the possibilities of creating new languages that could enable new, and perhaps better, ways of thinking. Examples of such languages designed to explore the human mind include Loglan, explicitly designed by James Cooke Brown to test the linguistic relativity hypothesis, by experimenting whether it would make its speakers think more logically. Speakers of Lojban, an evolution of Loglan, report that they feel speaking the language enhances their ability for logical thinking. Suzette Haden Elgin, who was involved in the early development of neurolinguistic programming, invented the language Láadan to explore linguistic relativity by making it easier to express what Elgin considered the female worldview, as opposed to Standard Average European languages which she considered to convey a \"male centered\" world view. John Quijada's language Ithkuil was designed to explore the limits of the number of cognitive categories a language can keep its speakers aware of at once. Similarly, Sonja Lang's Toki Pona was developed according to a Taoist point of view for exploring how (or if) such a language would direct human thought.\n\nAPL programming language originator Kenneth E. Iverson believed that the Sapir–Whorf hypothesis applied to computer languages (without actually mentioning it by name). His Turing award lecture, \"Notation as a tool of thought\", was devoted to this theme, arguing that more powerful notations aided thinking about computer algorithms.\n\nThe essays of Paul Graham explore similar themes, such as a conceptual hierarchy of computer languages, with more expressive and succinct languages at the top. Thus, the so-called \"blub\" paradox (after a hypothetical programming language of average complexity called \"Blub\") says that anyone preferentially using some particular programming language will \"know\" that it is more powerful than some, but not that it is less powerful than others. The reason is that \"writing\" in some language means \"thinking\" in that language. Hence the paradox, because typically programmers are \"satisfied with whatever language they happen to use, because it dictates the way they think about programs\".\n\nIn a 2003 presentation at an open source convention, Yukihiro Matsumoto, creator of the programming language Ruby, said that one of his inspirations for developing the language was the science fiction novel \"Babel-17\", based on the Sapir–Whorf Hypothesis.\n\nTed Chiang's short story \"Story of Your Life\" developed the concept of the Sapir-Whorf hypothesis as applied to an alien species which visits Earth. The aliens' biology contributes to their spoken and written languages, which are distinct. In the 2016 American film \"Arrival\", based on Chiang's short story, the Sapir-Whorf hypothesis is the premise. The protagonist explains that \"the Sapir-Whorf hypothesis is the theory that the language you speak determines how you think\".\n\nIn his science fiction novel \"The Languages of Pao\" the author Jack Vance describes how specialized languages are a major part of a strategy to create specific classes in a society, to enable the population to withstand occupation and develop itself.\n\n\n"}
{"id": "25001382", "url": "https://en.wikipedia.org/wiki?curid=25001382", "title": "Market share liability", "text": "Market share liability\n\nMarket share liability is a legal doctrine that allows a plaintiff to establish a prima facie case against a group of product manufacturers for an injury caused by a product, even when the plaintiff does not know from which defendant the product originated. The doctrine is unique to the law of the United States and apportions liability among the manufacturers according to their share of the market for the product giving rise to the plaintiff's injury.\n\nMarket share liability was introduced in the California case \"Sindell v. Abbott Laboratories\". In \"Sindell\", the plaintiffs were injured by DES, a drug prescribed to prevent miscarriage. The mothers of the plaintiffs had taken DES while pregnant, and expert testimony showed this to be a proximate cause of reproductive tract cancers in the plaintiffs years later. The plaintiffs, however, could not ascertain which drug company distributed the DES taken by their mothers. The court responded by allowing the plaintiffs to apportion liability among the defendant drug companies according to their respective shares in the DES market.\n\n\"Sindell\" laid out the requirements for applying the doctrine of market share liability:\n\nFirst, the defendants in court must constitute substantially all of the market. This is a distinguishing factor from alternative liability that requires that all of the defendants be in court (See Summers v. Tice). Having \"substantially all\" of the market makes it more likely that the actual wrongdoer will be in court. A main reason for not requiring all of the relevant market is that as time passes, some manufacturers drop out of the market, and it would raise the bar for the plaintiff too high. Also if all defendants were present, then market share liability would be unnecessary, because the plaintiff would be able to apply the doctrine of alternative liability to put the burden of proving causation onto the defendants.\n\nSecond, the products must be fungible (i.e. interchangeable—they must be of the same composition). For example, in \"Skipworth v. Lead Industries Association\", 690 A.2d 169 (Pa. 1997), the Pennsylvania Supreme Court held that the lead paint the defendants sold to not be fungible because the paints had lead pigments containing different chemical formulations, different amounts of lead, and differed in potential toxicity.\n\nThird, the defendants (potential tortfeasors) must all have been in the market within the specific timeframe surrounding the incident.\n\nFourth, the inability to point to a specific tortfeasor must not be the plaintiff's fault. This is particularly relevant in the pharmaceuticals context, as most plaintiffs are prescribed generic drugs and thus have no knowledge of who manufactured the product.\n\nJurisdictions and courts differ on the possibilities open to defendants to absolve themselves of market share liability. In \"Sindell\" (California), the court allowed defendants to bring forth exculpatory evidence and thus free themselves of liability. However, in \"Hymowitz v. Eli Lilly & Co.\" (New York), the court refused to allow exculpatory evidence because it felt that doing so would undermine the theory underpinning market share liability—because liability is based on relevant market share, providing exculpatory evidence will not reduce a defendant's overall share of the market.\n\n\"Sindell\" required plaintiffs to join defendant drug companies in a single action. A Wisconsin court took a different approach on this issue in \"Collins v. Eli Lilly Co.\" In \"Collins\", the court found that the plaintiff could bring a cause of action against a single defendant, and the burden of proof would be shifted to the defendant to show that they did not produce the DES taken by the plaintiff's mother.\n\nEfforts to expand the market share approach beyond DES cases have been mostly rejected because the strict requirements of applying market share liability. Courts have declined to expand the market-share approach to asbestos (\"Becker v. Baron Bros.\"), handguns (\"Hamilton v. Beretta\"), and lead paint (\"Santiago v. Sherwin Williams Co.\"). The market-share approach has been expanded to cases involving MTBE in the New York case \"In re Methyl Tertiary Butyl Ether\".\n"}
{"id": "331195", "url": "https://en.wikipedia.org/wiki?curid=331195", "title": "Mass surveillance", "text": "Mass surveillance\n\nMass surveillance is the intricate surveillance of an entire or a substantial fraction of a population in order to monitor that group of citizens. The surveillance is often carried out by local and federal governments or governmental organisations, such as organizations like the NSA and the FBI, but it may also be carried out by corporations (either on behalf of governments or at their own initiative). Depending on each nation's laws and judicial systems, the legality of and the permission required to engage in mass surveillance varies. It is the single most indicative distinguishing trait of totalitarian regimes. It is also often distinguished from targeted surveillance.\n\nMass surveillance has often been cited as necessary to fight terrorism, prevent crime and social unrest, protect national security, and control the population. Conversely, mass surveillance has equally often been criticized for violating privacy rights, limiting civil and political rights and freedoms, and being illegal under some legal or constitutional systems. Another criticism is that increasing mass surveillance could lead to the development of a surveillance state or an electronic police state where civil liberties are infringed or political dissent is undermined by COINTELPRO-like programs. Such a state could be referred to as a totalitarian state.\n\nIn 2013, the practice of mass surveillance by world governments was called into question after Edward Snowden‘s 2013 global surveillance disclosure. Reporting based on documents Snowden leaked to various media outlets triggered a debate about civil liberties and the right to privacy in the Digital Age. Mass surveillance is considered a global issue.\n\nPrivacy International's 2007 survey, covering 47 countries, indicated that there had been an increase in surveillance and a decline in the performance of privacy safeguards, compared to the previous year. Balancing these factors, eight countries were rated as being 'endemic surveillance societies'. Of these eight, China, Malaysia and Russia scored lowest, followed jointly by Singapore and the United Kingdom, then jointly by Taiwan, Thailand and the United States. The best ranking was given to Greece, which was judged to have 'adequate safeguards against abuse'.\n\nMany countries throughout the world have already been adding thousands of surveillance cameras to their urban, suburban and even rural areas. For example, in September 2007 the American Civil Liberties Union (ACLU) stated that we are \"in danger of tipping into a genuine surveillance society completely alien to American values\" with \"the potential for a dark future where our every move, our every transaction, our every communication is recorded, compiled, and stored away, ready to be examined and used against us by the authorities whenever they want.\"\n\nOn 12 March 2013, Reporters Without Borders published a \"Special report on Internet Surveillance\". The report included a list of \"State Enemies of the Internet\", countries whose governments are involved in active, intrusive surveillance of news providers, resulting in grave violations of freedom of information and human rights. Five countries were placed on the initial list: Bahrain, China, Iran, Syria, and Vietnam.\n\nBahrain is one of the five countries on Reporters Without Borders' March 2013 list of \"State Enemies of the Internet\", countries whose governments are involved in active, intrusive surveillance of news providers, resulting in grave violations of freedom of information and human rights. The level of Internet filtering and surveillance in Bahrain is one of the highest in the world. The royal family is represented in all areas of Internet management and has sophisticated tools at its disposal for spying on its subjects. The online activities of dissidents and news providers are closely monitored and the surveillance is increasing.\n\nChina is one of the five countries on Reporters Without Borders' March 2013 list of \"State Enemies of the Internet\", countries whose governments are involved in active, intrusive surveillance of news providers, resulting in grave violations of freedom of information and human rights. All Internet access in China is owned or controlled by the state or the Communist Party. Many foreign journalists in China have said that they take for granted that their telephones are tapped and their email is monitored.\n\nThe tools put in place to filter and monitor the Internet are collectively known as the Great Firewall of China. Besides the usual routing regulations that allow access to an IP address or a particular domain name to be blocked, the Great Firewall makes large-scale use of Deep Packet Inspection (DPI) technology to monitor and block access based on keyword detection. The Great Firewall has the ability to dynamically block encrypted connections. One of the country's main ISPs, China Unicom, automatically cuts a connection as soon as it is used to transmit encrypted content.\n\nThe monitoring system developed by China is not confined to the Great Firewall, monitoring is also built into social networks, chat services and VoIP. Private companies are directly responsible to the Chinese authorities for surveillance of their networks to ensure banned messages are not circulated. The QQ application, owned by the firm Tencent, allows the authorities to monitor in detail exchanges between Internet users by seeking certain keywords and expressions. The author of each message can be identified by his or her user number. The QQ application is effectively a giant Trojan horse. And since March 2012, new legislation requires all new users of micro-blogging sites to register using their own name and telephone number.\n\nSkype, one of the world's most popular Internet telephone platforms, is closely monitored. Skype services in China are available through a local partner, the TOM media group. The Chinese-language version of Skype, known as TOM-Skype, is slightly different from the downloadable versions in other countries. A report by OpenNet Initiative Asia says everyday conversations are captured on servers. Interception and storage of a conversation may be triggered by a sender's or recipient's name or by keywords that occur in the conversation.\n\nOn 30 January, the \"New York Times\" reported that it had been the target of attacks by the Chinese government. The first breach took place on 13 September 2012 when the newspaper was preparing to publish an article about the fortune amassed by the family of outgoing Prime Minister Wen Jiabao. The newspaper said the purpose of attacks was to identify the sources that supplied the newspaper with information about corruption among the prime minister's entourage. The \"Wall Street Journal\" and \"CNN\" also said they had been the targets of cyber attacks from China. In February, Twitter disclosed that the accounts of some 250,000 subscribers had been the victims of attacks from China similar to those carried out on the \"New York Times\". Mandiant, the company engaged by the NYT to secure its network, identified the source of the attacks as a group of hackers it called Advanced Persistent Threat 1, a unit of the People's Liberation Army operating from a 12-story building in the suburbs of Shanghai that had hundreds, possibly thousands, of staff and the direct support of the Chinese government.\n\nBefore the Digital Revolution, one of the world's biggest mass surveillance operations was carried out by the Stasi, the secret police of the former East Germany. By the time the state collapsed in 1989, the Stasi had built up an estimated civilian network of 300,000 informants (approximately one in fifty of the population), who monitored even minute hints of political dissent among other citizens. Many West Germans visiting friends and family in East Germany were also subject to Stasi spying, as well as many high-ranking West German politicians and persons in the public eye.\n\nMost East German citizens were well aware that their government was spying on them, which led to a culture of mistrust: touchy political issues were only discussed in the comfort of their own four walls and only with the closest of friends and family members, while widely maintaining a façade of unquestioning followership in public.\n\nThe right to privacy is a highly developed area of law in Europe. The Data Protection Directive regulates the processing of personal data within the European Union. For comparison, the US has no data protection law that is comparable to this; instead, the US regulates data protection on a sectoral basis.\n\nSince early 2012, the European Union has been working on a General Data Protection Regulation to replace the Data Protection Directive and harmonise data protection and privacy law. On 20 October 2013, a committee at the European Parliament backed the measure, which, if it is enacted, could require American companies to seek clearance from European officials before complying with United States warrants seeking private data. The vote is part of efforts in Europe to shield citizens from online surveillance in the wake of revelations about a far-reaching spying program by the U.S. National Security Agency. European Union justice and rights commissioner Viviane Reding said \"The question has arisen whether the large-scale collection and processing of personal information under US surveillance programmes is necessary and proportionate to meet the interests of national security.\" The EU is also asking the US for changes to US legislation to match the legal redress offered in Europe; American citizens in Europe can go to the courts if they feel their rights are infringed but Europeans without right of residence in America cannot. When the EU / US arrangement to implement International Safe Harbor Privacy Principles were struck down by the European Court of Justice, a new framework for transatlantic data flows, called the \"EU-US Privacy Shield\", was adopted in July 2016.\n\nIn April 2014, the European Court of Justice declared invalid the EU Data Retention Directive. The Court said it violates two basic rights - respect for private life and protection of personal data. The legislative body of the European Union passed the Data Retention Directive on 15 December 2005. It requires that telecommunication operators retain metadata for telephone, Internet, and other telecommunication services for periods of not less than six months and not more than two years from the date of the communication as determined by each EU member state and, upon request, to make the data available to various governmental bodies. Access to this information is not limited to investigation of serious crimes, nor is a warrant required for access.\n\nUndertaken under the \"Seventh Framework Programme\" \"for research and technological development\" (FP7 - Science in Society) some multidisciplinary and mission oriented mass surveillance activities (for example INDECT and HIDE) were funded by the European Commission in association with industrial partners.\n\nThe INDECT Project (\"Intelligent information system supporting observation, searching and detection for security of citizens in urban environment\") develops an intelligent urban environment observation system to register and exchange operational data for the automatic detection, recognition and intelligent processing of all information of abnormal behaviour or violence.\n\nThe main expected results of the INDECT project are:\n\nHIDE (\"Homeland Security, Biometric Identification & Personal Detection Ethics\") was a research project funded by the European Commission within the scope of the Seventh RTD Framework Programme (FP7). The consortium, coordinated by Emilio Mordini, explored the ethical and privacy implications of biometrics and personal detection technologies, focusing on the continuum between personal detection, authentication, identification and mass surveillance.\n\nIn 2002 German citizens were tipped off about wiretapping when a software error led to a phone number allocated to the German Secret Service being listed on mobile telephone bills.\n\nThe Indian parliament passed the Information Technology Act of 2008 with no debate, giving the government fiat power to tap all communications without a court order or a warrant. Section 69 of the act states \"Section 69 empowers the Central Government/State Government/ its authorized agency to intercept, monitor or decrypt any information generated, transmitted, received or stored in any computer resource if it is necessary or expedient so to do in the interest of the sovereignty or integrity of India, defence of India, security of the State, friendly relations with foreign States or public order or for preventing incitement to the commission of any cognizable offence or for investigation of any offence.\"\n\nIndia is setting up a national intelligence grid called NATGRID, which would be fully set up by May 2011 where each individual's data ranging from land records, Internet logs, air and rail PNR, phone records, gun records, driving license, property records, insurance, and income tax records would be available in real time and with no oversight. With a UID from the Unique Identification Authority of India being given to every Indian from February 2011, the government would be able track people in real time. A national population registry of all citizens will be established by the 2011 census, during which fingerprints and iris scans would be taken along with GPS records of each household.\n\nAs per the initial plan, access to the combined data will be given to 11 agencies, including the Research and Analysis Wing, the Intelligence Bureau, the Enforcement Directorate, the National Investigation Agency, the Central Bureau of Investigation, the Directorate of Revenue Intelligence and the Narcotics Control Bureau.\n\nSeveral states within India have already installed CCTV surveillance systems with face matching capabilities using biometrics in Aadhaar. Andhra Pradesh and Telangana are using information linked with Aadhaar across different agencies to create a 360-degree profile of a person, calling it the Integration Information Hub. Other states are now planning to follow this model.\n\nIran is one of the five countries on Reporters Without Borders' March 2013 list of \"State Enemies of the Internet\", countries whose governments are involved in naturally active efforts to news providers . The government runs or controls almost all of the country's institutions for regulating, managing or legislating on telecommunications. The Supreme Council for Cyberspace, which was headed by President Ahmadinejad, was established in March 2012 and now determines digital policy. The construction of a parallel \"Iranian Internet\", with a high connection speed but fully monitored and censored, is almost complete.\n\nThe tools used by the Iranian authorities to monitor and control the Internet include data interception tools capable of Deep Packet Inspection. Interception products from leading Chinese companies such as ZTE and Huawei are in use. The products provided by Huawei to Mobin Net, the leading national provider of mobile broadband, can be used to analyze email content, track browsing history and block access to sites. The products that ZTA sold to the Telecommunication Company of Iran (TCI) offer similar services plus the possibility of monitoring the mobile network. European companies are the source of other spying and data analysis tools. Products designed by Ericsson and Nokia Siemens Networks (later Trovicor) are in use. These companies sold SMS interception and user location products to Mobile Communication Company of Iran and Irancell, Iran's two biggest mobile phone companies, in 2009 and they were used to identify Iranian citizens during the post-election uprising in 2009. The use of Israeli surveillance devices has also been detected in Iran. The network traffic management and surveillance device NetEnforcer was provided by Israel to Denmark and then resold to Iran. Similarly, US equipment has found its way to Iran via the Chinese company ZTE.\n\nIn July 2018, the Malaysian police announced the creation of the Malaysian Internet Crime Against Children Investigation Unit (Micac) that is equipped with real-time mass internet surveillance software developed in the United States and is tasked with the monitoring of all Malaysian internet users, with a focus on pornography and child pornography. The system creates a \"data library\" of users which includes details such as IP addresses, websites, locations, duration and frequency of use and files uploaded and downloaded.\n\nAfter struggling with drug trafficking and criminal groups for decades Mexico has been strengthening their military mass surveillance. Approximately half of the population in Mexico does not support democracy as a form of government, and believe an authoritarian system is better if social matters are solved through it. The relevance of these political beliefs may make it easier for mass surveillance to take spread within the country. \"This does not necessarily mean the end of democratic institutions as a whole—such as free elections or the permanence of critical mass media—but it means strengthening the mechanisms for exercising power that exclude dialogue, transparency and social agreement.\" Developing intelligence agencies has been on Mexico's radar for a while for means of security. \n\nAccording to a 2004 report, the government of the Netherlands carries out more clandestine wire-taps and intercepts than any country, per capita, in the world. The Dutch military intelligence service MIVD operates a satellite ground station to intercept foreign satellite links and also a facility to eavesdrop on foreign high-frequency radio traffic.\n\nHaving attained the nickname ‘surveillance state’, North Korea's government has complete control over all forms of telecommunications and Internet. It is routine to be sent to a prison camp for communicating with the outside world. The government enforces restrictions around the types of appliances North Koreans may own in their home, in case radio or TV sets pick up signals from nearby South Korea, China and Russia. There is no attempt to mask the way this government actively spies on their citizens. In North Korea, an increasing number of citizens do have smartphones. However, these devices are heavily controlled and are being used to censor and observe everything North Koreans do on their phones. Reuters reported in 2015 that Koryolink, North Korea's official mobile phone network, has around 3 million subscribers in a country of 24 million. Obviously, in order to have digital data to draw from, the citizens must have access to phones and other things online.\n\nThe SORM (and SORM-2) laws enable complete monitoring of any communication, electronic or traditional, by eight state agencies, without warrant. These laws seem to be in conflict with Article 23 of the Constitution of Russia which states:\n\nIn 2015, the European Court for Human Rights ruled that the legislation violated Article 8 of the European Convention on Human Rights (\"Zakharov v. Russia\").\n\nYarovaya Law required storage and unconditional access to private communication data for law enforcement.\n\nSingapore is known as a city of sensors. Singapore's surveillance structure spreads widely from Closed-circuit television in public areas even around the neighbourhood, internet monitoring/ traffic monitoring and to the use of surveillance metadata for government initiatives. In Singapore, SIM card registration is mandatory even for prepaid card. Singapore's government have the rights to access communication data. Singapore's largest telecompany, Singtel, has close relations to the government and Singapore's laws are broadly phrased to allow the government to obtain sensitive data such as text-messages, email, call logs and web surfing history from its people without the need for court permission.\n\nThe installation of mass surveillance cameras in Singapore is an effort to act as a deterrence not only for terror attacks but also for public security such as loan sharks, illegal parking and more. As part of Singapore's Smart Nation initiative to build a network of sensors to collect and connect data from city life (including the citizen's movement), the Singapore government rolled out 1000 sensors ranging from computer chips to surveillance cameras, to track almost everything in Singapore from air quality to public safety in 2014.\n\nIn 2016, in a bid to increase security, the Singapore Police Force installed 62,000 police cameras in 10,000 Housing and Development Board (HDB) blocks covering the lifts and multi-storey car parks. With rising security concerns, the number of CCTV cameras in public areas such as monitoring of the public transport system and commercial/ government buildings in Singapore is set to increase.\n\nIn 2018, the Singapore government would be rolling out new and more advanced surveillance systems. Starting with Singapore's maritime borders, new panoramic electro-optic sensors will be put in place on the north and south coasts, monitoring a 360-degree view of the area. A tethered unmanned aerial vehicle (UAV) will also be operational, which can be used during search and rescue operations including hostage situations and public order incidents.\n\nAccording to a 2017 report by Privacy International, Spain may be part of a group of 21 European countries that is withholding information, also known as data retention. In 2014, many defense lawyers tried to overturn multiple cases that used mass storage as their evidence to convict, according to the European Agency for Fundamental Rights.\n\nPrior to 2009, the National Defence Radio Establishment (FRA) was limited to wireless signals intelligence (SIGINT), although it was left largely unregulated. In December 2009, new legislation went into effect, allowing the FRA to monitor cable bound signals passing the Swedish border. Communications service providers are legally required, under confidentiality, to transfer cable communications crossing Swedish borders to specific \"interaction points\", where data may be accessed after a court order.\n\nThe FRA has been contested since the change in its legislation, mainly because of the public perception the change would enable mass surveillance. The FRA categorically deny this allegation, as they are not allowed to initialize any surveillance on their own, and has no direct access to communication lines. All SIGINT has to be authorized by a special court and meet a set of narrow requirements, something Minister for Defence Sten Tolgfors have been quoted as saying, \"should render the debate on mass surveillance invalid.\" Due to the architecture of Internet backbones in the Nordic area, a large portion of Norwegian and Finnish traffic will also be affected by the Swedish wiretapping.\n\nSyria is one of the five countries on Reporters Without Borders' March 2013 list of \"State Enemies of the Internet\", countries whose governments are involved in active, intrusive surveillance of news providers, resulting in grave violations of freedom of information and human rights. Syria has stepped up its web censorship and cyber-monitoring as the country's civil war has intensified. At least 13 Blue Coat proxy servers are in use, Skype calls are intercepted, and social engineering techniques, phishing, and malware attacks are all in use.\n\nThe failed coup attempt June 15, 2016 led to an authoritarian shift that uses mass surveillance to suppress opposite views. Digital surveillance is part of everyday life due to the box the government puts the Turkish citizens in. It is increasingly difficult to release any academic knowledge beyond what the Turkish government wants to be released. They have a digital and physical strong hold over any knowledge that goes against their regime. Today, the surveillance of academicians goes along with the state's oppression in Turkey. It is hard to say what will happen in the next few years in Turkey as they become increasingly more authoritarian. The centralization of state power along with digitalization expands the scope of the state surveillance. The digitalization and the centralization of state power are closely related to the regime of power that becomes prominent in this conjuncture. National security and terrorism are Turkey's main explanations to the world on this topic, although there is clearly more happening there. According to the report of Human Rights Joint Platform published on February 23, 2017, during the nine months period of the state of emergency, the number of dismissed academicians reached 4,811, increasing to 7,619 with the addition of academicians who were working in the universities closed after the failed coup attempt. The extended surveillance in Turkey helped them to control the population at a massive scale.\n\nState surveillance in the United Kingdom has formed part of the public consciousness since the 19th century. The postal espionage crisis of 1844 sparked the first panic over the privacy of citizens. However, in the 20th century, electronic surveillance capabilities grew out of wartime signal intelligence and pioneering code breaking. In 1946, the Government Communications Headquarters (GCHQ) was formed. The United Kingdom and the United States signed the bilateral UKUSA Agreement in 1948. It was later broadened to include Canada, Australia and New Zealand, as well as cooperation with several \"third-party\" nations. This became the cornerstone of Western intelligence gathering and the \"Special Relationship\" between the UK and the USA.\n\nAfter the growth of the Internet and development of the World Wide Web, a series of media reports in 2013 revealed more recent programs and techniques involving GCHQ, such as Tempora.\n\nThe use of these capabilities is controlled by laws made in the UK Parliament. In particular, access to the content of private messages (that is, interception of a communication) must be authorized by a warrant signed by a Secretary of State. In addition European Union data privacy law applies in UK law. The UK exhibits governance and safeguards as well as use of electronic surveillance.\n\nThe Investigatory Powers Tribunal, a judicial oversight body for the intelligence agencies, ruled in December 2014 that the legislative framework in the United Kingdom does not breach the European Convention on Human Rights. However, the Tribunal stated in February 2015 that one particular aspect, the data-sharing arrangement that allowed UK Intelligence services to request data from the US surveillance programs Prism and Upstream, had been in contravention of human rights law prior to this until two paragraphs of additional information, providing details about the procedures and safeguards, were disclosed to the public in December 2014.\n\nIn its December 2014 ruling, the Investigatory Powers Tribunal found that the legislative framework in the United Kingdom does not permit mass surveillance and that while GCHQ collects and analyses data in bulk, it does not practice mass surveillance. A report on Privacy and Security published by the Intelligence and Security Committee of Parliament also came to this view, although it found past shortcomings in oversight and said the legal framework should be simplified to improve transparency. This view is supported by independent reports from the Interception of Communications Commissioner. However, notable civil liberties groups continue to express strong views to the contrary and plan to appeal the ruling to the European Court of Human Rights, while others have criticised these viewpoints in turn.\n\nThe Regulation of Investigatory Powers Act 2000 (RIP or RIPA) is a significant piece of legislation that granted and regulated the powers of public bodies to carry out surveillance and investigation. In 2002 the UK government announced plans to extend the Regulation of Investigatory Powers Act so that at least 28 government departments would be given powers to access metadata about citizens' web, e-mail, telephone and fax records, without a warrant and without a subject's knowledge.\n\nThe Protection of Freedoms Act 2012 includes several provisions related to controlling and restricting the collection, storage, retention, and use of information in government databases.\n\nSupported by all three major political parties, the UK Parliament passed the Data Retention and Investigatory Powers Act in July 2014 to ensure police and security services retain existing powers to access phone and Internet records. \n\nThis was superseded by the Investigatory Powers Act 2016, a comprehensive statute which made public a number of previously secret powers (equipment interference, bulk retention of metadata, intelligence agency use of bulk personal datasets), and enables the Government to require internet service providers and mobile phone companies to maintain records of (but not the content of) customers' Internet connections for 12 months. In addition, it created new safeguards, including a requirement for judges to approve the warrants authorised by a Secretary of State before they come into force. The Act was informed by two reports by David Anderson QC, the UK's Independent Reviewer of Terrorism Legislation: A Question of Trust (2015) and the report of his Bulk Powers Review (2016), which contains a detailed appraisal (with 60 case studies) of the operational case for the powers often characterised as mass surveillance. It may yet require amendment as a consequence of legal cases brought before the Court of Justice of the European Union and the European Court of Human Rights.\n\nMany advanced nation-states have implemented laws that partially protect citizens from unwarranted intrusion, such as the Human Rights Act 1998 and Data Protection Act 1998 in the United Kingdom, and laws that require a formal warrant before private data may be gathered by a government.\n\nThe UK is a member of the European Union, participates in its programs, and is subject to EU policies and directives on surveillance.\n\nThe vast majority of video surveillance cameras in the UK are not operated by government bodies, but by private individuals or companies, especially to monitor the interiors of shops and businesses. According to 2011 Freedom of Information Act requests, the total number of local government operated CCTV cameras was around 52,000 over the entirety of the UK. The prevalence of video surveillance in the UK is often overstated due to unreliable estimates being requoted; for example one report in 2002 extrapolated from a very small sample to estimate the number of cameras in the UK at 4.2 million (of which 500,000 in London). More reliable estimates put the number of private and local government operated cameras in the United Kingdom at around 1.85 million in 2011.\n\nHistorically, mass surveillance was used as part of wartime censorship to control communications that could damage the war effort and aid the enemy. For example, during the world wars, every international telegram from or to the United States sent through companies such as Western Union was reviewed by the US military. After the wars were over, surveillance continued in programs such as the Black Chamber following World War I and project Shamrock following World War II. COINTELPRO projects conducted by the U.S. Federal Bureau of Investigation (FBI) between 1956 and 1971 targeted various \"subversive\" organizations, including peaceful anti-war and racial equality activists such as Albert Einstein and Martin Luther King Jr.\n\nBillions of dollars per year are spent, by agencies such as the National Security Agency (NSA) and the Federal Bureau of Investigation (FBI), to develop, purchase, implement, and operate systems such as Carnivore, ECHELON, and NarusInsight to intercept and analyze the immense amount of data that traverses the Internet and telephone system every day.\n\nSince the September 11, 2001, terrorist attacks, a vast domestic intelligence apparatus has been built to collect information using the NSA, FBI, local police, state homeland security offices and military criminal investigators. The intelligence apparatus collects, analyzes and stores information about millions of (if not all) American citizens, many of whom have not been accused of any wrongdoing.\n\nUnder the Mail Isolation Control and Tracking program, the U.S. Postal Service photographs the exterior of every piece of paper mail that is processed in the United States — about 160 billion pieces in 2012. The U.S. Postmaster General stated that the system is primarily used for mail sorting, but the images are available for possible use by law enforcement agencies. Created in 2001 following the anthrax attacks that killed five people, it is a sweeping expansion of a 100-year-old program called \"mail cover\" which targets people suspected of crimes.\n\nThe FBI developed the computer programs \"Magic Lantern\" and CIPAV, which they can remotely install on a computer system, in order to monitor a person's computer activity.\n\nThe NSA has been gathering information on financial records, Internet surfing habits, and monitoring e-mails. They have also performed extensive analysis of social networks such as Myspace.\n\nThe PRISM special source operation system legally immunized private companies that cooperate voluntarily with U.S. intelligence collection. According to \"The Register\", the FISA Amendments Act of 2008 \"specifically authorizes intelligence agencies to monitor the phone, email, and other communications of U.S. citizens for up to a week without obtaining a warrant\" when one of the parties is outside the U.S. PRISM was first publicly revealed on 6 June 2013, after classified documents about the program were leaked to \"The Washington Post\" and \"The Guardian\" by American Edward Snowden.\n\nThe Communications Assistance for Law Enforcement Act (CALEA) requires that all U.S. telecommunications and Internet service providers modify their networks to allow easy wiretapping of telephone, VoIP, and broadband Internet traffic.\n\nIn early 2006, \"USA Today\" reported that several major telephone companies were providing the telephone call records of U.S. citizens to the National Security Agency (NSA), which is storing them in a large database known as the NSA call database. This report came on the heels of allegations that the U.S. government had been conducting electronic surveillance of domestic telephone calls without warrants. In 2013, the existence of the Hemisphere Project, through which AT&T provides telephone call data to federal agencies, became publicly known.\n\nTraffic cameras, which were meant to help enforce traffic laws at intersections, may be used by law enforcement agencies for purposes unrelated to traffic violations. Some cameras allow for the identification of individuals inside a vehicle and license plate data to be collected and time stamped for cross reference with other data used by police. The Department of Homeland Security is funding networks of surveillance cameras in cities and towns as part of its efforts to combat terrorism.\n\nThe New York City Police Department infiltrated and compiled dossiers on protest groups before the 2004 Republican National Convention, leading to over 1,800 arrests.\n\nModern surveillance in the United States was thought of more of a wartime effort before Snowden disclosed in depth information about the National Security Agency in June 2013. The constant development and improvements of the Internet and technology has made it easier for mass surveillance to take hold. Such revelations allow critical commentators to raise questions and scrutinize the implementation, use, and abuse of networking technologies, devices, and software systems that partake in a “global surveillant assemblage” (Bogard 2006; Collier and Ong 2004; Haggerty and Ericson 2000; Murakami Wood 2013). The NSA collected millions of Verizon user's telephone records in between 2013-2014. The NSA also collected data through Google and Facebook with a program called 'Prism'. Journalists through Snowden published nearly 7,000 top-secret documents since then, yet the information disclosed seems to be less than 1% of the entire information. Having access to every individual's private records seems to directly contradict the fourth amendment. \n\nVietnam is one of the five countries on Reporters Without Borders' March 2013 list of \"State Enemies of the Internet\", countries whose governments are involved in active, intrusive surveillance of news providers, resulting in grave violations of freedom of information and human rights. Most of the country's 16 service providers are directly or indirectly controlled by the Vietnamese Communist Party. The industry leader, Vietnam Posts and Telecommunications Group, which controls 74 per cent of the market, is state-owned. So is Viettel, an enterprise of the Vietnamese armed forces. FPT Telecom is a private firm, but is accountable to the Party and depends on the market leaders for bandwidth.\n\nService providers are the major instruments of control and surveillance. Bloggers monitored by the government frequently undergo man-in-the-middle attacks. These are designed to intercept data meant to be sent to secure (https) sites, allowing passwords and other communication to be intercepted. According to a July 2012 Freedom House report, 91 percent of survey respondents connected to the Internet on their mobile devices and the government monitors conversations and tracks the calls of \"activists\" or \"reactionaries.\"\n\nAs a result of the digital revolution, many aspects of life are now captured and stored in digital form. Concern has been expressed that governments may use this information to conduct mass surveillance on their populations. Commercial mass surveillance often makes use of copyright laws and \"user agreements\" to obtain (typically uninformed) 'consent' to surveillance from consumers who use their software or other related materials. This allows gathering of information which would be technically illegal if performed by government agencies. This data is then often shared with government agencies - thereby - in practice - defeating the purpose of such privacy protections.\n\nOne of the most common forms of mass surveillance is carried out by commercial organizations. Many people are willing to join supermarket and grocery loyalty card programs, trading their personal information and surveillance of their shopping habits in exchange for a discount on their groceries, although base prices might be increased to encourage participation in the program.\n\nThrough programs like Google's AdSense, OpenSocial and their increasing pool of so-called \"web gadgets\", \"social gadgets\" and other Google-hosted services many web sites on the Internet are effectively feeding user information about sites visited by the users, and now also their social connections, to Google. Facebook also keep this information, although its acquisition is limited to page views within Facebook. This data is valuable for authorities, advertisers and others interested in profiling users, trends and web site marketing performance. Google, Facebook and others are increasingly becoming more guarded about this data as their reach increases and the data becomes more all inclusive, making it more valuable.\n\nNew features like geolocation give an even increased admission of monitoring capabilities to large service providers like Google, where they also are enabled to track one's physical movements while users are using mobile devices, especially those which are syncing without any user interaction. Google's Gmail service is increasingly employing features to work as a stand-alone application which also might activate while a web browser is not even active for synchronizing; a feature mentioned on the Google I/O 2009 developer conference while showing the upcoming HTML5 features which Google and others are actively defining and promoting.\n\nIn 2008 at the World Economic Forum in Davos, Google CEO Eric Schmidt, said: \"The arrival of a truly mobile Web, offering a new generation of location-based advertising, is set to unleash a 'huge revolution'\".\nAt the Mobile World Congress in Barcelona on 16 February 2010, Google presented their vision of a new business model for mobile operators and trying to convince mobile operators to embrace location-based services and advertising. With Google as the advertising provider, it would mean that every mobile operator using their location-based advertising service would be revealing the location of their mobile customers to Google.\n\nOrganizations like the Electronic Frontier Foundation are constantly informing users on the importance of privacy, and considerations about technologies like geolocation.\n\nComputer company Microsoft patented in 2011 a product distribution system with a camera or capture device that monitors the viewers that consume the product, allowing the provider to take \"remedial action\" if the actual viewers do not match the distribution license.\n\nReporters Without Borders' March 2013 \"Special report on Internet Surveillance\" contained a list of \"Corporate Enemies of the Internet\", companies that sell products that are liable to be used by governments to violate human rights and freedom of information. The five companies on the initial list were: Amesys (France), Blue Coat Systems (U.S.), Gamma (UK and Germany), Hacking Team (Italy), and Trovicor (Germany), but the list was not exhaustive and is likely to be expanded in the future.\n\nA surveillance state is a country where the government engages in pervasive surveillance of large numbers of its citizens and visitors. Such widespread surveillance is usually justified as being necessary for national security, such as to prevent crime or acts of terrorism, but may also be used to stifle criticism of and opposition to the government.\nExamples of early surveillance states include the former Soviet Union and the former East Germany, which had a large network of informers and an advanced technology base in computing and spy-camera technology. But these states did not have today's technologies for mass surveillance, such as the use of databases and pattern recognition software to cross-correlate information obtained by wire tapping, including speech recognition and telecommunications traffic analysis, monitoring of financial transactions, automatic number plate recognition, the tracking of the position of mobile telephones, and facial recognition systems and the like which recognize people by their appearance, gait, DNA profiling, etc.\n\nThe development of smart cities has seen the increased adoption of surveillance technologies by governments, although the primary purpose of surveillance in such cities is to use information and communication technologies to improve the urban environment. The implementation of such technology by a number of cities has resulted in increased efficiencies in urban infrastructure as well as improved community participation. Sensors and systems monitor a smart city's infrastructure, operations and activities and aim to help it run more efficiently. For example, the city could use less electricity; its traffic run more smoothly with fewer delays; its citizens use the city with more safety; hazards can be dealt with faster; citizen infractions of rules can be prevented, and the city's infrastructure; power distribution and roads with traffic lights for example, dynamically adjusted to respond to differing circumstances.\n\nThe development of smart city technology has also led to an increase in potential unwarranted intrusions into privacy and restrictions upon autonomy. The widespread incorporation of information and communication technologies within the daily life of urban residents results in increases in the surveillance capacity of states - to the extent that individuals may be unaware of what information is being accessed, when the access occurs and for what purpose. It is possible that such conditions could give rise to the development of an electronic police state. Shanghai, Amsterdam, San Jose, Dubai, Barcelona, Madrid, Stockholm, and New York are all cities that use various techniques from smart city technology. \n\nAn electronic police state is a state in which the government aggressively uses electronic technologies to record, collect, store, organize, analyze, search, and distribute information about its citizens. Electronic police states also engage in mass government surveillance of landline and cellular telephone traffic, mail, email, web surfing, Internet searches, radio, and other forms of electronic communication as well as widespread use of video surveillance. The information is usually collected in secret.\n\nThe crucial elements are not politically based, so long as the government can afford the technology and the populace will permit it to be used, an electronic police state can form. The continual use of electronic mass surveillance can result in constant low-level fear within the population, which can lead to self-censorship and exerts a powerful coercive force upon the populace.\n\nSeventeen factors for judging the development of an electronic police state were suggested in \"The Electronic Police State: 2008 National Rankings\":\n\nThe list includes factors that apply to other forms of police states, such as the use of identity documents and police enforcement, but go considerably beyond them and emphasize the use of technology to gather and process the information collected.\n\nThe concept of being monitored by our government collects a large audience of curious citizens. Mass surveillance has been prominently featured in a wide array of books, films, and other media. Advances in technology over the last century have led to possible social control through the Internet and the conditions of late capitalism. Many directors and writers have been enthralled with the potential stories that could come from mass surveillance. Perhaps the most iconic example of fictional mass surveillance is George Orwell's 1949 novel \"Nineteen Eighty-Four\", which depicts a dystopian surveillance state. \n\nHere are a few other works that focus on mass surveillance:\n\n"}
{"id": "1928636", "url": "https://en.wikipedia.org/wiki?curid=1928636", "title": "Mental body", "text": "Mental body\n\nThe mental body (the mind) is one of the subtle bodies in esoteric philosophies, in some religious teachings and in New Age thought. It is understood as a sort of body made up of thoughts, just as the emotional body consists of emotions and the physical body is made up of matter. In occult understanding, thoughts are not just subjective qualia, but have an existence apart from the associated physical organ, the brain.\n\nAccording to Theosophists C.W. Leadbeater and Annie Besant (Adyar School of Theosophy), and later Alice Bailey, the mental body is equivalent to the \"Lower Manas\" of Blavatsky's original seven principles of man. But the New Age writer Barbara Brennan describes the Mental body as intermediate between the Emotional and the Astral body in terms of the layers in the \"Human Energy Field\" or Aura.\n\nThe mental body is usually considered in terms of an aura that includes thoughtforms. In Theosophical and Alice Bailey's teachings, it corresponds to the Mental plane.\n\nAccording to Max Heindel's Rosicrucian writings, the mind is the latest acquisition of the human spirit and is related to the \"Region of Concrete Thought\", which is the lower region of the World of Thought. It is not yet an organized body and in most people it is still a mere inchoate cloud disposed particularly in the region of the head. It works as the link or focus between the \"threefold\" Spirit and the \"threefold\" body , in a reversed reflexion manner : the mind is like the projecting lens of a stereopticon, it projects the image in one of three directions, according to the will of the thinker, which ensouls the thought-form.\n\nHis writings, called Western Wisdom Teachings, give a clear description on how the man's inner Spirit perceives, from the world of thought, the lower worlds through the mind: \" We ourselves, as Egos, function directly in the subtle substance of the Region of Abstract Thought, which we have specialized within the periphery of our individual aura. Thence we view the impressions made by the outer world upon the vital body through the senses, together with the feelings and emotions generated by them in the desire body, and mirrored in the mind. From these mental images we form our conclusions, in the substance of the Region of Abstract Thought, concerning the subjects with which they deal. Those conclusions are ideas. By the power of will we project an idea through the mind, where it takes concrete shape as a thought-form by drawing mind-stuff around itself from the Region of Concrete Thought. \".\n\nHe also states that to the trained clairvoyant there appears to be an empty space in the center of the forehead just above and between the eyebrows and it looks like the blue part of a gas flame, but not even the most gifted seer can penetrate that veil, also known as \"THE VEIL OF ISIS\".\n\nSamael Aun Weor stated that only those who have worked consciously to do so have created a mental body. A \"solar mind\" or \"solar mental body\" is the quality of mind of a true human, yet, it is stated that this humanity is not composed of true humans, but rather intellectual animals: beings with a mind of an animal, but reasoning superior to that of other animals. According to Samael Aun Weor, the qualifications to being a real human being is identical to the lowest requirements of being a Buddha. The process of acquiring the mind of a human in this sense involves the psychological death of the \"I\" (desire) and the work of practical sexual alchemy. More explicitly stated, the title of Buddha is achieved through the Fourth Initiation of Major Mysteries, when the fourth serpent of fire or kundalini has risen.\n\nWhether the lunar or solar aspect, the mental body is stated to exist within the 5th dimension and is represented by Netzach. With the mental body one can travel through the mental world, the world of thoughts and ideas.\n\nIn Esoteric Christianity, the mental body is represented by the stubborn yet useful donkey that the Savior (Christ) subdues in order to be used as a vehicle to enter into heavenly Jerusalem (the superior worlds).\n\n"}
{"id": "2922219", "url": "https://en.wikipedia.org/wiki?curid=2922219", "title": "Michael X", "text": "Michael X\n\nMichael X (1933 – 16 May 1975), born Michael de Freitas in Trinidad and Tobago, was a self-styled black revolutionary and civil rights activist in 1960s London. He was also known as Michael Abdul Malik and Abdul Malik. Convicted of murder in 1972, Michael X was executed by hanging in 1975 in Port of Spain's Royal Jail.\n\nMichael de Freitas was born in Trinidad to an \"Obeah-practising black woman from Barbados and an absent Portuguese father from St Kitts\". Encouraged by his mother to pass for white, \"Red Mike\" was a headstrong youth and was expelled from school at the age of 14. In 1957, he immigrated to the United Kingdom, where he settled in London and worked as an enforcer and frontman for the slum landlord Peter Rachman.\n\nBy the mid-1960s he had renamed himself \"Michael X\" and became a well-known exponent of Black Power in London. Writing in \"The Observer\" in 1965, Colin McGlashan called him the \"authentic voice of black bitterness.\"\n\nIn 1965, under the name Abdul Malik, he founded the Racial Adjustment Action Society (RAAS).\n\nIn 1967 he was involved with the counterculture/hippie organisation the London Free School (LFS) through his contact with John \"Hoppy\" Hopkins, which both helped widen the reach of the group, at least in the Notting Hill area, and create problems with local police who disliked his involvement. Michael and the LFS were instrumental in organising the first outdoor Notting Hill Carnival later that year.\n\nLater that year, he became the first non-white person to be charged and imprisoned under the UK's Race Relations Act, which was designed to protect Britain's Black and Asian populations from discrimination. He was sentenced to 12 months in jail for advocating the immediate killing of any white man seen \"laying hands\" on a black woman. He also said \"white men have no soul\".\n\nIn 1969, he became the self-appointed leader of a Black Power commune on Holloway Road, North London, called the \"Black House\". The commune was financed by a young millionaire benefactor, Nigel Samuel. Michael X said, \"They've made me the archbishop of violence in this country. But that 'get a gun' rhetoric is over. We're talking of really building things in the community needed by people in the community. We're keeping a sane approach.\" John Lennon and Yoko Ono donated a bag of their hair to be auctioned for the benefit of the Black House.\n\nIn what the media called \"the slave collar affair\", businessman Marvin Brown was enticed to The Black House, viciously attacked, and made to wear a spiked \"slave\" collar around his neck as Michael X and others threatened him in order to extort money. The Black House closed in the autumn of 1970. The two men found guilty of assaulting Marvin Brown were imprisoned for 18 months.\n\nThe Black House burned down in mysterious circumstances, and soon Michael X and four colleagues were arrested for extortion. His bail was paid by John Lennon in January 1971.\n\nIn February 1971, he fled to his native Trinidad, where he started an agricultural commune devoted to Black empowerment east of the capital, Port of Spain. \"The only politics I ever understand is the politics of revolution,\" he told the \"Trinidad Express\". \"The politics of change, the politics of a completely new system.\" He began another commune, also called the Black House, which, in February 1972, also burned down.\n\nPolice who had come to the commune to investigate the fire discovered the bodies of Joseph Skerritt and Gale Benson, members of the commune. They had been hacked to death and separately buried in shallow graves. Benson, who had been going under the name Hale Kimga, was the daughter of Conservative MP Leonard F. Plugge. She had met Michael X through her relationship with Malcolm X's cousin Hakim Jamal.\n\nMichael X fled to Guyana a few days later and was captured there. He was charged with the murder of Skerritt and Benson, but was never tried for the latter crime. A witness at his trial claimed that Skerritt was a member of Malik's \"Black Liberation Army\" and had been killed by him because he refused to obey orders to attack a local police station. Malik was found guilty and sentenced to death. The Save Malik Committee, whose members included Angela Davis, Dick Gregory, Kate Millet and others, including the well known \"radical lawyer\" William Kunstler, who was paid by John Lennon, pleaded for clemency, but Malik was hanged in 1975.\n\nOther members of the group were tried for Benson's murder. It was asserted that Benson had been shown an open grave and was then pushed in it and hacked at by Michael X with a machete on her neck.\n\nUnder the name Michael Abdul Malik, Michael X was the author of \"From Michael Freitas to Michael X\" (André Deutsch, 1968). It was ghost written by John Stevenson. Michael X also left behind fragments of a novel about a romantic black hero who wins the abject admiration of the narrator, a young English woman named Lena Boyd-Richardson. Inspecting the hero's bookshelf, Lena Boyd-Richardson is impressed at finding \"Salammbô\": \"I discover that he not only have (sic) the books but actually reads and understands them I was absolutely bowld (sic), litterally. I took a seat, and gazed upon this marvel, Mike.\"\n\nMichael X is the subject of the essay \"Michael X and the Black Power Killings in Trinidad\" by V. S. Naipaul, collected in \"The Return of Eva Perón and the Killings in Trinidad\" (1980), and is also believed to be the model for the fictional character Jimmy Ahmed in Naipaul's 1975 novel \"Guerrillas\".\n\nMichael X is a character in \"The Bank Job\" (2008), a dramatisation of a real-life bank robbery in 1971. The film claims that Michael X was in possession of indecent photographs of Princess Margaret and used them to avoid criminal prosecution by threatening to publish them. He was played by Peter de Jersey.\n\nMichael X and his trial are the subject of a chapter in Geoffrey Robertson's legal memoir \"The Justice Game\" (1998).\n\nMichael X plays a part in \"Make Believe: A True Story\" (1993), a memoir by Diana Athill.\n\n\"Michael X\" is the eponymous title of a play, by the writer Vanessa Walters, that takes the form of a 1960s Black Power rally and was performed at The Tabernacle Theatre, Powis Square, London W11 (Notting Hill), in November 2008.\n\nMichael X (played by Adrian Lester) is portrayed in a scene opposite Jimi Hendrix in the film \"All Is By My Side\" based on Jimi's early years in the music industry.\n\nMuhammad Ali gave his bloody boxing shorts that he wore when he fought Henry Cooper to Michael Abdul Malik, and is referred to as a black militant from Trinidad in \"The Greatest - My Own Story\" by Muhammad Ali and Richard Durham\n\n"}
{"id": "24574814", "url": "https://en.wikipedia.org/wiki?curid=24574814", "title": "Models of collaborative tagging", "text": "Models of collaborative tagging\n\nIt has been argued that social tagging or collaborative tagging systems can provide navigational cues or \"way-finders\" for other users to explore information. The notion is that, given that social tags are labels that users create to represent topics extracted from Web documents, interpretation of these tags should allow other users to predict contents of different documents efficiently. Social tags are arguably more important in exploratory search, in which the users may engage in iterative cycles of goal refinement and exploration of new information (as opposed to simple fact-retrievals), and interpretation of information contents by others will provide useful cues for people to discover topics that are relevant. \nOne significant challenge that arises in social tagging systems is the rapid increase in the number and diversity of the tags. As opposed to structured annotation systems, tags provide users an unstructured, open-ended mechanism to annotate and organize web-content. As users are free to create any tag to describe any resource, it leads to what is referred to as the vocabulary problem. Because users may use different words to describe the same document or extract different topics from the same document based on their own background knowledge, the lack of a top-down mediation may lead to an increase in the use of incoherent tags to represent the information resources in the system. In other words, the inherent \"unstructuredness\" of social tags may hinder their potential as navigational cues for searchers because the diversities of users and motivation may lead to diminishing tag-topic relations as the system grows. However, a number of studies have shown that structures do emerge at the semantic level – indicating that there are cohesive forces that are driving the emergent structures in a social tagging system.\n\nJust like any social phenomena, behavioral patterns in social tagging systems can be characterized by either a descriptive or predictive model. While descriptive models ask the question of \"what\", predictive models go deeper to also ask the question of \"why\" by attempting to provide explanations to the aggregate behavioral patterns. While there may be no general agreement on what an acceptable explanation should be like, many believe that a good explanation should have certain level of predictive accuracy. Descriptive models of social tagging typically are not concerned with explaining the actions of single individuals but describing the patterns that emerge as individual behavior is aggregated in a large social information system. Predictive models, however, attempt to explain aggregate patterns by analyzing how individuals interact and link to each other in ways that bring about similar or different emergent patterns of social behavior. In particular, a mechanism-based predictive model assumes a certain set of rule that individuals interact with each other, and understand how these interactions could produce aggregate patterns as observed and characterized by descriptive models. Predictive models can therefore provide explanations to why different system characteristics may lead to different aggregate patterns, and can therefore potentially provide information on how systems should be designed to achieve different social purposes.\n\nFor most tagging systems the total number of tags in the collective vocabulary is much less than the total number of objects being tagged. Given this multiplicity of tags to documents, a question remains: how effective are the tags at isolating any single document? Naively, if we specify a single tag in this system we would uniquely identify lots of documents – thus the answer to our question is \"not very well!\". However this method carries a faulty assumption; not every document is equal. Some documents are more popular and important than others, and this importance is conveyed by the number bookmarks per document. Thus, we can reformulate the above question to be: how well does the mapping of tags to documents retain about the distribution of the documents? Information theory provides a natural framework to understand the amount of shared information between two random variables. The conditional entropy measures the amount of entropy remaining in one random variable when we know the value of a second random variable. Work done by Chi and Mytkowicz show that the entropy of documents conditional on tags, H(D|T), is increasing rapidly. What this means is that, even after knowing completely the value of a tag, the entropy of the set of documents is increasing over time. Conditional Entropy asks the question: \"Given that I know a set of tags, how much uncertainty regarding the document set that I was referencing with those tags remains?\" The fact that this curve is strictly increasing suggests that the specificity of any given tag is decreasing. That is to say, as a navigation aid, tags are becoming harder and harder to use. We are moving closer and closer to the proverbial \"needle in a haystack\" where any single tag references too many documents to be considered useful. \n\nAnother way to look at the data is to think about mutual information, which is a measure of independence between the two variables. Full independence is reached when I(D;T) = 0. Chi and Mytkowicz research on delicious social tagging data show that as a measure of usefulness of the tags and their encoding, there is a worsening trend in the ability of users to specify and find tags and documents when they are engaged in simple fact retrieval. This suggests that we need to build search and recommendation systems that help users sift through resources in social tagging systems, especially when we are engaged in more than simple fact retrieval as characterized by the information theory. In fact, although the number of documents associated with any given tag is increasing, there are many ways contextual information can help users to look for relevant information. This is in fact one of the major weakness of the simple information theory in explaining usefulness of tags – it ignores the fact that humans can extract meanings from a set of tags assigned to a document, and this semantic extraction process is exactly the reason why humans are able to communicate efficiently even though the size of our vocabulary is increasing ever since language was developed. For example, the work by Cattuto et al. (2007), published in PNAS, show that while the number of tags are increasing, the general growth pattern is scale-free – the general distribution of tag-tag co-occurrences follows a power-law. Cattuto also finds that the characteristics of this scale-free distribution are dependent on the semantics of the tag – tags that are semantically general (e.g., blogs) tend to co-occur with many tags, while semantically narrow tags (e.g., Ajax) tend to co-occur with few number of tags across a wide set of documents in a social tagging system. What this means is that the assumption of the information theory approach is too simple – when the semantics of the set of tags assigned to documents are taken into account, the predictive value of tags on contents of documents are relatively stable. This finding is important for development of recommender systems – discovering these higher level semantic patterns is important in helping people to find relevant information (also see semantic imitation model below).\n\nDespite this potential vocabulary problem, recent research has found that at the aggregate level, tagging behavior seemed relatively stable and that the tag choice proportions seemed to be converging rather than diverging. While these observations provided evidence against the proposed vocabulary problem, they also triggered a series of research investigating how and why tag proportions tended to converge over time. \n\nOne explanation for the stability was that there was an inherent propensity for users to \"imitate\" word use of others as they create tags. This propensity may act as a form of social cohesion that fosters the coherence of tag-topic relations in the system, and leads to stability in the system. Golder and Huberman showed that the stochastic urn model by Eggenberger and Pólya was useful in explaining how simple imitation behavior at the individual level could explain the converging usage patterns of tags. Specifically, convergence of tag choices was simulated by a process in which a colored ball was randomly selected from an urn and was replaced in the urn along with an additional ball of the same color, simulating the probabilistic nature of tag reuse. The simple model, however, does not explain why certain tags would to be \"imitated\" more often than others, and therefore cannot provide a realistic mechanism for tag choices and how social tags could be utilized as navigational cues during exploratory search, not to mention the obviously over-simplified representation of individual users by balls in an urn.\n\nOther research, using data from the social bookmarking website Del.icio.us, has shown that collaborative tagging systems exhibit a form of complex systems (or self-organizing) dynamics. Furthermore, although there is no central controlled vocabulary to constrain the actions of individual users, the distributions of tags that describe different resources has been shown to converge over time to a stable power law distributions. Once such stable distributions form, examining the correlations between different tags can be used to construct simple folksonomy graphs, which can be efficiently partitioned to obtain a form of community or shared vocabularies. Such vocabularies can be seen as emerging from the decentralised actions of many users, as a form of crowdsourcing.\n\nThe memory-based Yule-Simon (MBYS) model of Cattuto attempted to explain tag choices by a stochastic process. They found that the temporal order of tag assignment influences users' tag choices. Similar to the stochastic urn model, the MBYS model assumed that at each time step a tag would be randomly sampled: with probability p the sampled tag was new, and with probability 1-p the sampled tag was copied from existing tags. When copying, the probability of selecting a tag was assumed to decay with time, and this decay function was found to follow a power law distribution. Thus, tags that were recently used had a higher probability of being reused than those used in the past. One major finding by Cattuto et al. was that semantically general tags (e.g., \"blog\") tended to co-occur more frequently with other tags than semantically narrower tags (e.g., \"ajax\"), and this difference could be captured by the decay function of tag reuse in their model. Specifically, they found that a slower decay parameter (when the tag is reused more often) could explain the phenomenon that semantically general tags tended to co-occur with a larger set of tags. In other words, they argued that the \"semantic breadth\" of a tag could be modeled by a memory decay function, which could lead to different emergent behavioral patterns in a tagging system.\n\nDescriptive models mentioned above were based on analyses of word-word relations as revealed by the various statistical structures in the organization of tags (e.g., how likely one tag would co-occur with other tags or how likely each tag was reused over time). These models are therefore descriptive models at the aggregate level, and have little to offer about predictions at the level of interface interactions and cognitive processes of individual. \nRather than imitating other users at the word level, one possible explanation for this kind of social cohesion could be grounded on the natural tendency for people to process tags at the semantic level, and it was at this level of processing that most imitation occurred. This explanation was supported by research in the area of reading comprehension, which showed that people tended to be influenced by meanings of words, rather than the words themselves during comprehension. Assuming that background knowledge of people in the same culture tend to have shared structures (e.g., using similar vocabularies and their corresponding meanings in order to conform and communicate with each), users of the same social tagging system may also share similar semantic representations of words and concepts, even when the use of tags may vary across individuals at the word level. In other words, we argued that part of the reason for the stability of social tagging systems can be attributed to the shared semantic representations among the users, such that users may have relatively stable and coherent interpretation of information contents and tags as they interact with the system. Based on this assumption, the semantic imitation model predicts how different semantic representations may lead to differences in individual tag choices and eventually different emergent properties at the aggregate behavioral level. The model also predicts that the folksonomies (i.e., knowledge structures) in the system reflect the shared semantic representations of the users.\n\nSemantic imitation has important implication to the general vocabulary problem (see work by, e.g., Susan Dumais) in information retrieval and human-computer interaction – the creation of large number of diverse tags to describe the same set of information resource. The finding that semantic imitation occurs implies that the unit of communication among users is more likely at the semantic level, not at the word level. Thus, although there may not be strong coherence in the choice of words in describing a resource, at the semantic level there seems to be a stronger coherence force that guides the convergence of descriptive indices. This is in sharp contrast to conclusions derived based on a purely information-theoretical approach, which assumes that humans search and evaluation information at the word level. Instead, the process of semantic imitation in social tagging implies that the information-theoretic approach is at most incomplete, as it does not take into account the basic unit of human information processing. Similar to the fact that human communication occurs at the semantic level, the fact that people may use different words or syntax does not affect the effectiveness of communication, so long as the underlying \"common ground\" between the two persons is the same. In the social tagging case, so long as users share similar understanding of the contents of the information resources, the fact that the information value of tag-document decreases (that humans have more words in their languages) do not imply that it will always be harder to find relevant information (similarly, the fact that there are more words in our languages does not mean that our communication becomes less effective). However, it does point to the notion that one needs to effectively present these semantic structures in the information system so that people can effectively interpret the semantics of the tagged documents. Intelligent techniques based on statistical models of language such as latent semantic analysis, probabilistic topics model, etc. are promising aspects that will overcome this vocabulary problem.\n\n"}
{"id": "1041023", "url": "https://en.wikipedia.org/wiki?curid=1041023", "title": "Money illusion", "text": "Money illusion\n\nIn economics, money illusion, or price illusion, is the tendency of people to think of currency in nominal, rather than real, terms. In other words, the numerical/face value (nominal value) of money is mistaken for its purchasing power (real value) at a previous point in the general price level (in the past). This is false, as modern fiat currencies have no intrinsic value and their real value is derived from all the underlying value systems in an economy, e.g., sound government, sound economics, sound education, sound legal system, sound defence, etc. The change in this real value over time is indicated by the change in the Consumer Price Index over time.\n\nThe term was coined by Irving Fisher in \"Stabilizing the Dollar\". It was popularized by John Maynard Keynes in the early twentieth century, and Irving Fisher wrote an important book on the subject, \"The Money Illusion\", in 1928. The existence of money illusion is disputed by monetary economists who contend that people act rationally (i.e. think in real prices) with regard to their wealth. Eldar Shafir, Peter A. Diamond, and Amos Tversky (1997) have provided empirical evidence for the existence of the effect and it has been shown to affect behaviour in a variety of experimental and real-world situations.\n\nShafir et al. also state that money illusion influences economic behaviour in three main ways:\n\n\nMoney illusion can also influence people's perceptions of outcomes. Experiments have shown that people generally perceive an approximate 2% cut in nominal income with no change in monetary value as unfair, but see a 2% rise in nominal income where there is 4% inflation as fair, despite them being almost rational equivalents. This result is consistent with the 'Myopic Loss Aversion theory'. Furthermore, the money illusion means nominal changes in price can influence demand even if real prices have remained constant.\n\nExplanations of money illusion generally describe the phenomenon in terms of heuristics. Nominal prices provide a convenient rule of thumb for determining value and real prices are only calculated if they seem highly salient (e.g. in periods of hyperinflation or in long term contracts).\n\nSome have suggested that money illusion implies that the negative relationship between inflation and unemployment described by the Phillips curve might hold, contrary to more recent macroeconomic theories such as the \"expectations-augmented Phillips curve\". If workers use their nominal wage as a reference point when evaluating wage offers, firms can keep real wages relatively lower in a period of high inflation as workers accept the seemingly high nominal wage increase. These lower real wages would allow firms to hire more workers in periods of high inflation.\n\nMoney illusion is believed to be instrumental in the Friedmanian version of the Phillips curve. Actually, money illusion is not enough to explain the mechanism underlying this Phillips curve. It requires two additional assumptions. First, prices respond differently to modified demand conditions: an increased aggregate demand exerts its influence on commodity prices sooner than it does on labour market prices. Therefore, the drop in unemployment is, after all, the result of decreasing real wages and an accurate judgement of the situation by employees is the only reason for the return to an initial (natural) rate of unemployment (i.e. the end of the money illusion, when they finally recognize the actual dynamics of prices and wages). The other (arbitrary) assumption refers to a special informational asymmetry: whatever employees are unaware of in connection with the changes in (real and nominal) wages and prices can be clearly observed by employers. The new classical version of the Phillips curve was aimed at removing the puzzling additional presumptions, but its mechanism still requires money illusion.\n\n\n"}
{"id": "9445847", "url": "https://en.wikipedia.org/wiki?curid=9445847", "title": "Negativity bias", "text": "Negativity bias\n\nThe negativity bias, also known as the negativity effect, is the notion that, even when of equal intensity, things of a more negative nature (e.g. unpleasant thoughts, emotions, or social interactions; harmful/traumatic events) have a greater effect on one's psychological state and processes than neutral or positive things. In other words, something very positive will generally have less of an impact on a person's behavior and cognition than something equally emotional but negative. The negativity bias has been investigated within many different domains, including the formation of impressions and general evaluations; attention, learning, and memory; and decision-making and risk considerations.\n\nPaul Rozin and Edward Royzman proposed four elements of the negativity bias in order to explain its manifestation: negative potency, steeper negative gradients, negativity dominance, and negative differentiation.\n\nNegative potency refers to the notion that, while possibly of equal magnitude or emotionality, negative and positive items/events/etc. are not equally salient. Rozin and Royzman note that this characteristic of the negativity bias is only empirically demonstrable in situations with inherent measurability, such as comparing how positively or negatively a change in temperature is interpreted.\n\nWith respect to positive and negative gradients, it appears to be the case that negative events are thought to be perceived as increasingly more negative than positive events are increasingly positive the closer one gets (spatially or temporally) to the affective event itself. In other words, there is a steeper negative gradient than positive gradient. For example, the negative experience of an impending dental surgery is perceived as increasingly more negative the closer one gets to the date of surgery than the positive experience of an impending party is perceived as increasingly more positive the closer one gets to the date of celebration (assuming for the sake of this example that these events are equally positive and negative). Rozin and Royzman argue that this characteristic is distinct from that of negative potency because there appears to be evidence of steeper negative slopes relative to positive slopes even when potency itself is low.\n\nNegativity dominance describes the tendency for the combination of positive and negative items/events/etc. to skew towards an overall more negative interpretation than would be suggested by the summation of the individual positive and negative components. Phrasing in more Gestalt-friendly terms, the whole is more negative than the sum of its parts.\n\nNegative differentiation is consistent with evidence suggesting that the conceptualization of negativity is more elaborate and complex than that of positivity. For instance, research indicates that negative vocabulary is more richly descriptive of the affective experience than that of positive vocabulary. Furthermore, there appear to be more terms employed to indicate negative emotions than positive emotions. The notion of negative differentiation is consistent with the mobilization-minimization hypothesis, which posits that negative events, as a consequence of this complexity, require a greater mobilization of cognitive resources to deal with the affective experience and a greater effort to minimize the consequences.\n\nMost of the early evidence suggesting a negativity bias stems from research on social judgments and impression formation, in which it became clear that negative information was typically more heavily weighted when participants were tasked with forming comprehensive evaluations and impressions of other target individuals. Generally speaking, when people are presented with a range of trait information about a target individual, the traits are neither \"averaged\" nor \"summed\" to reach a final impression. When these traits differ in terms of their positivity and negativity, negative traits disproportionately impact the final impression. This is specifically in line with the notion of negativity dominance (see \"Explanations\" above).\n\nAs an example, a famous study by Leon Festinger and colleagues investigated critical factors in predicting friendship formation; the researchers concluded that whether or not people became friends was most strongly predicted by their proximity to one another. Ebbesen, Kjos, and Konecni, however, demonstrated that proximity itself does not predict friendship formation; rather, proximity serves to amplify the information that is relevant to the decision of either forming or not forming a friendship. Negative information is just as amplified as positive information by proximity. As negative information tends to outweigh positive information, proximity may predict a failure to form friendships even more so than successful friendship formation.\n\nOne explanation that has been put forth as to why such a negativity bias is demonstrated in social judgments is that people may generally consider negative information to be more diagnostic of an individual's character than positive information, that it is more useful than positive information in forming an overall impression. This is supported by indications of higher confidence in the accuracy of one's formed impression when it was formed more on the basis of negative traits than positive traits. People consider negative information to be more important to impression formation and, when it is available to them, they are subsequently more confident.\n\nAn oft-cited paradox, a dishonest person can sometimes act honestly while still being considered to be predominantly dishonest; on the other hand, an honest person who sometimes does dishonest things will likely be reclassified as a dishonest person. It is expected that a dishonest person will occasionally be honest, but this honesty will not counteract the prior demonstrations of dishonesty. Honesty is considered more easily tarnished by acts of dishonesty. Honesty itself would then be not diagnostic of an honest nature, only the absence of dishonesty.\n\nThe presumption that negative information has greater diagnostic accuracy is also evident in voting patterns. Voting behaviors have been shown to be more affected or motivated by negative information than positive: people tend to be more motivated to vote against a candidate because of negative information than they are to vote for a candidate because of positive information. As noted by researcher Jill Klein, \"character weaknesses were more important than strengths in determining...the ultimate vote\".\n\nThis diagnostic preference for negative traits over positive traits is thought to be a consequence of behavioral expectations: there is a general expectation that, owing to social requirements and regulations, people will generally behave positively and exhibit positive traits. Contrastingly, negative behaviors/traits are more unexpected and, thus, more salient when they are exhibited. The relatively greater salience of negative events or information means they ultimately play a greater role in the judgment process.\n\nStudies reported in a paper in the \"Journal of Experimental Psychology: General\" by Carey Morewedge (2009) found that people exhibit a negativity bias in attribution of external agency, such that they are more likely to attribute negative outcomes to the intentions of another person than similar neutral and positive outcomes. In laboratory experiments, Morewedge found that participants were more likely to believe that a partner had influenced the outcome of a gamble in when the participants lost money than won money, even when the probability of winning and losing money was held even. This bias is not limited to adults. Children also appear to be more likely to attribute negative events to intentional causes than similarly positive events.\n\nAs addressed by negative differentiation, negative information seems to require greater information processing resources and activity than does positive information; people tend to think and reason more about negative events than positive events. Neurological differences also point to greater processing of negative information: participants exhibit greater event-related potentials when reading about, or viewing photographs of, people performing negative acts that were incongruent with their traits than when reading about incongruent positive acts. This additional processing leads to differences between positive and negative information in attention, learning, and memory.\n\nA number of studies have suggested that negativity is essentially an attention magnet. For example, when tasked with forming an impression of presented target individuals, participants spent longer looking at negative photographs than they did looking at positive photographs. Similarly, participants registered more eye blinks when studying negative words than positive words (blinking rate has been positively linked to cognitive activity).\n\nImportantly, this preferential attendance to negative information is evident even when the affective nature of the stimuli is irrelevant to the task itself. Drs. Felicia Pratto and Oliver P. John administered a modified Stroop task to participants in an effort to investigate the automatic vigilance hypothesis. Participants were presented with a series of positive and negative personality traits in several different colors; as each trait appeared on the screen, participants were to name the color as quickly as possible. Even though the positive and negative elements of the words were immaterial to the color-naming task, participants were slower to name the color of negative traits than they were positive traits. This difference in response latencies indicates that greater attention was devoted to processing the trait itself when it was negative.\n\nAside from studies of eye blinks and color naming, Baumeister and colleagues noted in their review of \"bad events\" versus \"good events\" that there is also easily accessible, real-world evidence for this attentional bias: bad news sells more papers and the bulk of successful novels are full of negative events and turmoil. When taken in conjunction with the laboratory-based experiments, there is strong support for the notion that negative information generally has a stronger pull on attention than does positive information.\n\nLearning and memory are direct consequences of attentional processing: the more attention is directed or devoted toward something, the more likely it is that it will be later learned and remembered. Research concerning the effects of punishment and reward on learning suggests that punishment for incorrect responses is more effective in enhancing learning than are rewards for correct responses—learning occurs more quickly following bad events than good events.\n\nDrs. Pratto and John addressed the effects of affective information on incidental memory as well as attention using their modified Stroop paradigm (see section concerning \"Attention\"). Not only were participants slower to name the colors of negative traits, they also exhibited better incidental memory for the presented negative traits than they did for the positive traits, regardless of the proportion of negative to positive traits in the stimuli set.\n\nIntentional memory is also impacted by the stimuli's negative or positive quality. When studying both positive and negative behaviors, participants tend to recall more negative behaviors during a later memory test than they do positive behaviors, even after controlling for serial position effects. There is also evidence that people exhibit better recognition memory and source memory for negative information.\n\nWhen asked to recall a recent emotional event, people tend to report negative events more often than they report positive events, and this is thought to be because these negative memories are more salient than are the positive memories. People also tend to underestimate how frequently they experience positive affect, in that they more often forget the positively emotional experiences than they forget negatively emotional experiences.\n\nStudies of the negativity bias have also been related to research within the domain of decision-making, specifically as it relates to risk aversion or loss aversion. When presented with a situation in which a person stands to either gain something or lose something depending on the outcome, potential costs are more heavily considered than potential gains. The greater consideration of losses (i.e. negative outcomes) is in line with the principle of negative potency as proposed by Rozin and Royzman. This issue of negativity and loss aversion as it relates to decision-making is most notable addressed by Drs. Daniel Kahneman's and Amos Tversky's prospect theory.\n\nResearch points to a correlation between political affiliation and negativity bias , where conservatives are more sensitive to negative stimuli and therefore tend to lean towards right-leaning ideology which considers threat reduction and social-order to be its main focus. \nIndividuals with lower negativity bias tend to lean towards liberal political policies such as pluralism and are accepting of diverse social groups which by proxy could threaten social structure and cause greater risk of unrest. \n\nAlthough most of the research concerning the negativity bias has been conducted with adults (particularly undergraduate students), there have been a small number of infant studies also suggesting negativity biases.\n\nInfants are thought to interpret ambiguous situations on the basis of how others around them react. When an adult (e.g. experimenter, mother) displays reactions of happiness, fear, or neutrality towards target toys, infants tend to approach the toy associated with the negative reaction significantly less than the neutral and positive toys. Furthermore, there was greater evidence of neural activity when the infants were shown pictures of the \"negative\" toy than when shown the \"positive\" and \"neutral\" toys. Although recent work with 3-month-olds suggests a negativity bias in social evaluations, as well, there is also work suggesting a potential positivity bias in attention to emotional expressions in infants younger than 7 months. A review of the literature conducted by Drs. Amrisha Vaish, Tobias Grossman, and Amanda Woodward suggests the negativity bias may emerge during the second half of an infant's first year, although the authors also note that research on the negativity bias and affective information has been woefully neglected within the developmental literature.\n\nSome research indicates that older adults may display, at least in certain situations, a positivity bias or positivity effect. Proposed by Dr. Laura Carstensen and colleagues, the socioemotional selectivity theory outlines a shift in goals and emotion regulation tendencies with advancing age, resulting in a preference for positive information over negative information. Aside from the evidence in favor of a positivity bias, though, there have still been many documented cases of older adults displaying a negativity bias.\n\n\n\n"}
{"id": "25451307", "url": "https://en.wikipedia.org/wiki?curid=25451307", "title": "Order (virtue)", "text": "Order (virtue)\n\nOrder is the planning of time and organizing of resources, as well as of society.\n\nAlthough order is rarely discussed as a virtue in contemporary society, order is in fact central to improving efficiency, and is at the heart of time management strategies such as David Allen's \"Getting Things Done\".\n\nThe valorisation of order in the early stages of commercialization and industrialisation was linked by R. H. Tawney to Puritan concerns for system and method in 17th-century England. The same period saw English prose developing the qualities Matthew Arnold described as \"regularity, uniformity, precision, balance\".\n\n\"Let all your things have their places; let each part of your business have its time\" is a saying attributed to Benjamin Franklin in 1730, while he was 20 years old. It was part of his 13 virtues.\n\nA darker view of the early modern internalisation of order and discipline was taken by Michel Foucault in \"The Order of Things\" and \"Discipline and Punish\"; but for Rousseau love of order both in nature and in the harmonious psyche of the natural man was one of the tap-roots of moral conscience.\n\nThe Romantic reaction against reason, industry and the sober virtues, led to a downgrading of order as well. In art, spontaneity took precedence over method and craft; in life, the Bohemian call of wildness and disorder eclipsed the appeal of ordered sobriety – as with the cultivated disorganization of the sixties hippie.\n\n\"Latter-day attempts such as those of Deidre McCloskey to reclaim the bourgeois virtues like order may be met in some quarters only by laughter.\"\n\nSociologists, while noting that praise of order is generally associated with a conservative stance – one that can be traced back through Edmund Burke and Richard Hooker to Aristotle - point out that many taken-for-granted aspects of social order (such as which side of the road to drive on) produce substantial and equitable advantages for individuals at very little personal cost. Conversely, breakdowns in public order reveal everyone's daily dependence upon the smooth functioning of the wider society.\n\nDurkheim saw anomie as the existential reaction to the ordered disorder of modern society.\n\nJungians considered orderliness (along with restraint and responsibility) as one of the virtues attributable to the senex or old man - as opposed to the spontaneous openness of the puer or eternal youth.\n\nFreud saw the positive traits of orderliness and conscientiousness as rooted in anal eroticism.\n\nFreud himself was a highly organised personality, ordering his life – at work and play – with the regularity of a timetable.\n\nWilliam Osler was another highly successful physician who built his life on a highly organised basis.\n\nWallace Stevens wrote of the \"blessed rage for order\" in \"Ideas of Order\" (1936).\n\n\nWilliam Osler, \"Aequanimitas\" (New York 1963)\n"}
{"id": "36749982", "url": "https://en.wikipedia.org/wiki?curid=36749982", "title": "Pacific Northwest Labor and Civil Rights History Projects", "text": "Pacific Northwest Labor and Civil Rights History Projects\n\nThe Pacific Northwest Labor and Civil Rights History Projects are a series of multimedia public history initiatives. The projects cover a range of themes and subjects in the Northwest and Seattle, with a particular focus on working people and their movements. The effort, particularly the Seattle Civil Rights and Labor History Project, has garnered praise for the breadth of primary and secondary resources made available and its joint creation by academics, community members and hundreds of students. It has been recognized as a model of digital and publicly engaged scholarship.\n\nThe primary projects in the series are the Seattle Civil Rights and Labor History Project, the Great Depression in Washington State Project, the Waterfront Workers History Project, the Labor Press Project, the Seattle General Strike Project, the Communism in Washington State Project and the Antiwar and Radical History Project. The Strikes! Labor History Encyclopedia for the Pacific Northwest draws together the resources available on the other sites and adds additional information on workers from the many industries and communities of the region. Many of these resources are only digitized and available through the projects, having been culled from archival material and personal collections and materials including the only known film of the 1919 Seattle General Strike and the 1934 West Coast Waterfront Strike are exceedingly rare.\n\nThe Projects have gained attention as a trailblazing initiative in public scholarship and engagement between the University of Washington and the Seattle community to record histories like Filipino Cannery Unionism and the Chicano Movement in Washington State that are largely unavailable elsewhere. A unique, collaborative process has also given community members greater control over content than traditional academic research and created more investment by students in their work The impact of the Projects beyond the academic realm was demonstrated when Washington State law on neighborhood association covenants changed as a result of information brought to light on racially exclusive housing covenants that remained in neighborhood charters. In other cases, the projects have brought light to rarely studied stories, like the Seattle Black Panther Party. The local Chapter was one of the first founded outside Oakland and one of the longest lived. The Civil Rights and Labor History Project unearthed material and conducted oral histories that form the largest body of material on any Party chapter in the nation, including the founding chapter in Oakland. \nAll of the projects have been notable for the quantity of material made available online. The Labor Press Project hosts thousands of digitized articles from more than thirty different union and radical newspapers, and the Strikes! Labor History Encyclopedia contains a day-by-day database of articles from the Northwest related to labor covering the crucial periods of 1915-1919 and 1930-1939. Video oral histories are key part of the projects, showing first-hand perspectives that are placed alongside original academic essays and digitized historical materials. The Projects have also focused on outreach to Washington Public Schools, working with educators to design curriculum using the materials to teach students about the sometimes forgotten history of labor and civil rights in the Northwest and fulfill State requirements.\n\n"}
{"id": "684628", "url": "https://en.wikipedia.org/wiki?curid=684628", "title": "Parental alienation", "text": "Parental alienation\n\nParental alienation is the process, and the result, of psychological manipulation of a child into showing unwarranted fear, disrespect or hostility towards a parent and/or other family members. It is a distinctive form of psychological abuse, towards both the child and the rejected family members, that occurs almost exclusively in association with family separation or divorce, particularly where legal action is involved. It undermines core principles of both the Universal Declaration of Human Rights and the United Nations Convention on the Rights of the Child. Most commonly, the primary cause is a parent wishing to exclude another parent from the life of their child, but other family members or friends, as well as professionals involved with the family (including psychologists, lawyers and judges), may contribute significantly to the process. It often leads to the long-term, or even permanent, estrangement of a child from one parent and other family members and, as a particularly adverse childhood experience, results in significantly increased lifetime risks of both mental and physical illness.\n\nFirst described in 1976 as \"pathological alignment\", parental alienation refers to a situation in which a child unreasonably rejects a non-custodial parent. Richard A. Gardner proposed parental alienation syndrome in the 1980s based on his clinical experience with the children of divorcing parents. Parental alienation lacks a single definition and its existence, cause and characteristics have been the subject of debate. Gardner's concept of a syndrome has failed to gain acceptance. Some empirical research has been performed, though the quality of the studies vary widely and research in the area is still developing.\n\nA survey of literature suggests that alienating behaviors by both parents are common in high-conflict divorces. Rejected parents tend to lose a sense of warmth and empathy with the child. As a result, the rejected parent may become passive, depressed, anxious, and withdrawn – characteristics that may encourage further rejection. The parent that the child aligns with (the aligned parent) may engage in alienating behaviors, including undermining the other parent. These behaviors may be conscious and deliberate or may reflect a lack of awareness on the effect of the actions on the children. Direct alienating behaviors occur when one parent actively undermines the other parent, such as making derogatory remarks about the other parent, telling the child that the other parent is responsible for the separation, or telling the child that the other parent is the cause of financial difficulties. Indirect alienation behaviors occur when one parent fails to support access or contact with the other parent or tacitly accepts the child's negative behaviour and comments towards the other parent.\n\nThe causes of alienation can be divided into two broad categories,\nRealistic estrangement is a different phenomenon from \"pathological alienation\". The former is an understandable refusal by a child to see an abusive parent, while the latter is emotionally harmful and unjustified.\n\nSymptoms associated with parental alienation include:\n\nSome researchers emphasized the role of an alienating parent, termed variously the \"programming\" parent or \"embittered-chaotic parent\", while other researchers have focused on the \"alienated child\", and the relationship dynamics that contribute to the alienation.\n\nWithin the context of relationship dynamics, alienation is seen as a breakdown of attachment between parent and child that may be caused by a variety factors. These researchers have proposed a more complex analysis, in which all family members may play a role in the alienation. This \"systems-based\" view acknowledges that a child may be alienated from one parent with no alienation programming from the other parent. The behaviors of all family members, including those of the alienated parent, may lead to family dysfunction and the rejection of a parent. Under this approach, when a child is estranged from a parent it is necessary to evaluate all contributing factors and all possible remedies to the estrangement.\n\nIn one conception of parental alienation, driven by a specific parent, a parent who experienced feelings of inadequacy or abandonment in their childhood can have those feelings re-triggered by a divorce or breakup. In response, that parent can reenact a false narrative related to their own childhood, where the child's other parent symbolizes an inadequate or abusive parent, the child symbolizes a victim of the other parent, and the parent using harmful parenting practices symbolizes a good parent ostensibly trying to protect their child. The role of the bystander such as friends, therapists, and judges is to confirm the delusion for the parent, which was already partially confirmed for them by the child acting like a victim However, in reality, the other parent is neither inadequate nor abusive; rather, the parent using the harmful parenting practices is abusive. In effect, the parent who fears inadequacy or abandonment is able to project their fears onto the other parent because \"all can plainly see\" that it is the other parent who is rejected and abandoned by the child and who is \"inadequate\".\n\nA parent who uses harmful parenting practices may suffer from borderline personality disorder or narcissistic personality disorder,\nrelated to an experience of feeling inadequate or abandoned while growing up. This feeling can be re-triggered by a divorce or breakup, causing them to decompensate into persecutory delusions.\nThese parents may believe that they do not need to follow social norms of fairness, and they may\n\"parentify their own children\", \"excessively bind their children to themselves\",\n\"demand absolute, unlimited control over their children while threatening rejection\",\nproject their own fears onto the other parent, abandon their spouse in favor of their children, and revive their own childhood attachment trauma after a difficult experience.\n\nThe techniques of harmful parenting may be subtle and \"genuine\". A parent can triangulate the child into the marital conflict\nby encouraging the child to make even minor complaints about the other parent and then \"enthusiastically validating\" them. This signals to the child that the other parent is dangerous\nand insensitive. This encouragement to complain manipulates the child into the role of victim without the child's awareness, allowing the parent to move into the protector role, forcing the other parent into the \"inadequate\" parent role, and leaving no trace of what happened for bystanders who only see the child acting as a \"victim\". Over time, the combined effects of growing closer to the alienating parent through this complaining process and growing further from the rejected parent as the result of focusing on negative things about the other parent cause the child to reject their other parent as being inadequate.\n\nA parent may also mix in lies, partial lies, and exaggerations, particularly ones that the child may not be able to verify or where only the true part of the partial lie is easy to verify. As the result of being encouraged to act as judge of their rejected parent, the child then feels superior to their rejected parent, leading to the symptoms of grandiosity, entitlement, and haughty arrogance. This feeds the delusion of the parent, that they are protecting the child from an inadequate parent. The child then begins to adopt this delusion also.\n\nBecause the child and parent are from different generations, this qualifies as a perverse triangle,\nfurther complicated by enmeshment, and made even worse because a member of the perverse triangle has a personality disorder, climaxed by the splitting dynamic of the parent with the personality disorder that requires the ex-spouse to also become the ex-parent of the child. Finally, the child may be led to misinterpret the grief they experience from the loss of a parent as pain that means the rejected parent is abusive, since they mainly experience it in the presence of the rejected parent.\n\nThe success of restoring the child's attachment to their parent hinges on first protecting the child from harmful parenting. A study suggests that the child does not experience this protection as being traumatic.\n\nAccording to one theory, when symptoms of alienation are present, structured intervention is likely to be more effective than traditional counseling. Structured intervention involves:\n\nAdvocates of structured intervention argue that traditional counseling, based on the therapeutic alliance, is susceptible to:\n\nSome have discussed a different approach for severe cases that defines a set of psychological symptoms in a child and proposes a psychological explanation for how those symptoms were caused by harmful parenting practices and why a parent would employ those parenting practices. In this approach, the phenomenon is seen simply as a combination of psychological problems, each of which psychologists understand and recognize.\nAccording to this theoretical formulation, \"the pathology traditionally called ‘parental alienation' are manifestations of well-established forms of existing pathologies.”\n\nThe history of parental alienation reflects an evolution of its acceptance by professionals involved in custody cases. A 2009 survey of mental health and legal professionals found broad skepticism of the concept of parental alienation syndrome, and caution in relation to the concept of parental alienation.\n\nMental health professionals are reluctant to recognize so-called parental alienation syndrome. In the past, the American Psychiatric Association and American Psychological Association have held a neutral view of parental alienation as a distinct syndrome.\n\nIn anticipation of the fifth version of the Diagnostic and Statistical Manual of Mental Disorders, which was released in 2013, William Bernet argued for the inclusion of \"parental alienation disorder\", a diagnosis related to parental alienation. His conception makes reference to parental alienation and a variety of other descriptions of behaviors he believes represent the underlying concept of parental alienation disorder. Despite lobbying by proponents, in December 2012, the proposal was rejected.\n\nSome argue that elements of parental alienation are covered in the DSM-5 under the diagnosis: \"Parent-Child Relational Problem\". For example, the child's perception of an alienated parent \"may include negative attributions of the other's intentions, hostility toward or scapegoating of the other (parent), and unwarranted feelings of estrangement\".\n\nIn a survey at the Association of Family and Conciliation Courts in 2010, 98% of the 300 respondents agreed with the question, \"Do you think that some children are manipulated by one parent to irrationally and unjustifiably reject the other parent?\". However, parental alienation refers not to the acts of manipulation, but rather to the child's rejection of a parent that results from alienating behavior.\n\nSome courts recognize parental alienation as a form of child abuse with long-term effects and serious outcomes for the child. Some jurisdictions, including Brazil and Mexico, have enacted parental alienation as a criminal offense. Other jurisdictions may suspend child support in cases where parental alienation occurs. For example, in New York, in \"Matter of Robert Coull v. Pamela Rottman\", No. 2014-01516, 2015 N.Y. App. Div. LEXIS 6611 (September 2, 2015), where the father was prevented from seeing his son by the child's mother through a \"pattern of alienation\", child support was suspended. Some United States courts have also tried to address the issue through mandated reunification therapy; but no federal or state laws regulating parental alienation currently exist in the United States Due to the nature of allegations of parental alienation, many courts require that a qualified expert witness testify in support of allegations of parental alienation or in association with any allegation that a parent has a mental health disorder.\n\nWhile states have broadly rejected parental alienation syndrome as a concept that may be presented in a child custody case, it remains possible to argue that parental alienation has occurred, and to demonstrate how a parent's alienating behaviors should be considered by a court when evaluating a custody case. Behaviors that result in parental alienation may reflect other mental health disorders, both on the part of the alienating parent and the alienated parent, that may be relevant to a custody determination. The behavior of the alienated child may also be a relevant factor.\n\n\n"}
{"id": "40600057", "url": "https://en.wikipedia.org/wiki?curid=40600057", "title": "Planck's principle", "text": "Planck's principle\n\nIn sociology of scientific knowledge, Planck's principle is the view that scientific change does not occur because individual scientists change their mind, but rather that successive generations of scientists have different views.\n\nThe reason for the name is the statements by Max Planck:\n\nPlanck's quote has been used by Thomas Kuhn, Paul Feyerabend and others to argue that scientific revolutions are arational, rather than spreading through \"mere force of truth and fact\". It has been described as Darwinian rather than Lamarckian conceptual evolution.\n\nWhether age influences the readiness to accept new ideas has been empirically criticised. In the case of acceptance of evolution in the years after Darwin's \"On the Origin of Species\" age was a minor factor. Similarly, it was a weak factor in accepting cliometrics.\n"}
{"id": "33102920", "url": "https://en.wikipedia.org/wiki?curid=33102920", "title": "Precariat", "text": "Precariat\n\nIn sociology and economics, the precariat () is a social class formed by people suffering from precarity, which is a condition of existence without predictability or security, affecting material or psychological welfare. The term is a portmanteau obtained by merging \"precarious\" with \"proletariat\". Unlike the proletariat class of industrial workers in the 20th century who lacked their own means of production and hence sold their labour to live, members of the precariat are only partially involved in labour and must undertake extensive \"unremunerated activities that are essential if they are to retain access to jobs and to decent earnings\". Specifically, it is the condition of lack of job security, including intermittent employment or underemployment and the resultant precarious existence. The emergence of this class has been ascribed to the entrenchment of neoliberal capitalism.\n\nThe young precariat class in Europe has become a serious issue in the early part of the 21st century, and has been linked with major populist political developments including the Brexit referendum and the presidency of Donald Trump.\n\nThe British economist Guy Standing has analysed the precariat as a new emerging social class in work done for the think tank Policy Network and the World Economic Forum. In 2014, he wrote another book titled \"A Precariat Charter\" where he argued that all citizens have a right to socially inherited wealth. The latest in the series is titled \"\" where he proposed basic income as a solution for addressing the problem.\n\nThe analysis of the results of the Great British Class Survey of 2013, a collaboration between the BBC and researchers from several UK universities, contended there is a new model of class structure consisting of seven classes, ranging from the Elite at the top to the Precariat at the bottom. The Precariat class was envisaged as \"the most deprived British class of all with low levels of economic, cultural and social capital\" and the opposite of \"the Technical Middle Class\" in Great Britain in that instead of having money but no interests, people of the new Precariat Class have all sorts of potential activities they like to engage in but cannot do any of them because they have no money, insecure lives, and are usually trapped in old industrial parts of the country.\n\nThe precariat class has been emerging in societies such as Japan, where it includes over 20 million so-called \"freeters\".\n\n\n"}
{"id": "3569067", "url": "https://en.wikipedia.org/wiki?curid=3569067", "title": "Private currency", "text": "Private currency\n\nA private currency is a currency issued by a private entity, be it an individual, a commercial business, a nonprofit or decentralized common enterprise. It is often contrasted with fiat currency issued by governments or central banks. In many countries, the issuance of private paper currencies and new cryptocurrency is severely restricted by law, while the minting of metal coins intended to be used as currency may even be a criminal act such as in the USA (18 U.S. Code § 486).\n\nToday, there are over four thousand privately issued currencies in more than 35 countries. These include commercial trade exchanges that use barter credits as units of exchange, private gold and silver exchanges, local paper money, computerized systems of credits and debits, and digital currencies in circulation, such as digital gold currency.\n\nIn the United States, the lasted between 1837 and 1866, when almost anyone could issue paper money. States, municipalities, private banks, railroad and construction companies, stores, restaurants, churches and individuals printed an estimated 8,000 different types of money by 1860. If an issuer went bankrupt, closed, left town, or otherwise went out of business, the note would be worthless. Such organizations earned the nickname of \"wildcat banks\" for a reputation of unreliability; they were often situated in remote, unpopulated locales said to be inhabited more by wildcats than by people. The National Bank Act of 1863 ended the \"wildcat bank\" period. See also: History of free banking.\nIn Australia, the Bank Notes Tax Act 1910 effectively shut down the circulation of private currencies by imposing a prohibitive tax on the practice. The Act was repealed by the \"Commonwealth Bank Act\" 1945, which imposed a fine for private currencies.\n\nNow, s. 44(1) of the Australian \"Reserve Bank Act 1959\", prohibits this practice. In 1976, Wickrema Weerasooria published an article which suggested that the issuing of bank cheques violated this section, though some banks responded that since bank cheques were printed with the words \"not negotiable\" on them, the cheques were not intended for circulation and thus did not violate the statute.\n\nIn Hong Kong, although the government issues currency, bank-issued private currency is the dominant medium of exchange. Most automated teller machines dispense private Hong Kong bank notes.\n\nIn Scotland, the Bank of Scotland, Clydesdale Bank, and the Royal Bank of Scotland, and in Northern Ireland, the Bank of Ireland, Danske Bank, First Trust Bank, and Ulster Bank, are authorised by Parliament to issue Pound sterling bank notes. They are subject to central bank (the Bank of England) regulations concerning \"ring-fenced backing assets\" and are backed in part by deposits at the Bank of England. They are exchangeable with other pound notes on a one-to-one basis, and circulate freely within the United Kingdom, though not legal tender, not even in Scotland and Northern Ireland. In fact, technically, no banknote (including Bank of England notes) qualifies as legal tender in Scotland or Northern Ireland.\n\nEngland has had the Totnes pound since it was launched by Transition Towns Totnes Economics and Livelihoods Group in March 2007; A Totnes Pound is equal to one pound sterling and is backed by sterling held in a bank account. As at September 2008, about 70 businesses in Totnes were accepting the Totnes Pound. Other local currencies launched since then include the Lewes Pound (2008), the Brixton Pound (2009), the Stroud Pound (2009) and the Bristol Pound, which also allows for electronic payments.\n\nAustria had the Wörgl Experiment from July 1932 to September 1933.\n\nBavaria, Germany, has had the Chiemgauer since 2003. As of 2011 there were over 550,000 in circulation.\n\nSince starting in 2006, the \"City Initiative Karlsruhe\" has issued the \"Karlsruher\" which has no nominal value. Every coin has the value of 50 Eurocents and is primarily used in parking garages.\nAs of 2009, 120 companies in Karlsruhe accept the \"Karlsruher\" and usually grant a discount when paid with it.\n\nIn Canada, numerous complementary currencies are in use, such as the Calgary Dollar and Toronto dollar. However private currencies in Canada cannot be referred to as being legal tender and many private currencies (as well as loyalty programs) avoid the word \"dollar\", using names like \"coupons\" or \"bucks\", to avoid confusion. Examples include: Canadian Tire money and Pioneer Energy's Bonus Bucks.\n\nCustomer reward and loyalty programs operated by businesses are sometimes counted as private currencies. However, though \"points\" or \"miles\" may be exchangeable for merchandise or travel from the program sponsor, most of them lack the key element for currency of being a medium of exchange transferable to other individuals and usable as payment for items from other vendors. A few programs do have \"partnerships\" allowing this to some extent, and permit the transfer of points or miles. Some startups, such as the Canadian website Points.com, have sought to make loyalty \"points\" more currency-like by creating an exchange where points from one loyalty program can be traded for points in other such programs.\n\nA cryptocurrency is a form of digital or virtual currency where cryptography secures the transactions and controls the creation of additional units of the currency. A cryptocurrency wallet can be used to store the public and private keys which can be used to receive or spend the cryptocurrency. The cryptographic systems used allow for decentralisation; a decentralised cryptocurrency is fiat money but one without a central banking system. In terms of total market value, Bitcoin is the largest cryptocurrency, but there are over 700 digital currencies in existence.\n\nOn 6 August 2013, Federal Judge Amos Mazzant of the Eastern District of Texas of the Fifth Circuit ruled that bitcoins are \"a currency or a form of money\" (specifically securities as defined by Federal Securities Laws), and as such were subject to the court's jurisdiction. In August 2013, the German Finance Ministry characterized Bitcoin as a unit of account, usable in multilateral clearing circles and subject to capital gains tax if held less than one year.\n\nIn Thailand, lack of existing law leads many to believe Bitcoin is banned.\n\nAs national currencies can be counterfeited, so too can private currencies, and private currencies are subject to other criminal issues, including fraud.\n\nThe Liberty Dollar was a commodity-backed private currency created by Bernard von NotHaus and issued between 1998 and 2009. In 2011, von NotHaus was arrested and subsequently convicted on charges of money laundering, mail fraud, wire fraud, counterfeiting, and conspiracy. The charges stemmed from the government view that the Liberty silver coins too closely resembled official coinage.\n\nIn 2007, Angel Cruz, founder of The United Cities Corporation (TUC), announced he was establishing an alternative \"asset based\" currency named \"United States Private Dollars\". Cruz claimed United States Private Dollars were \"backed by the total net worth of the assets of its members\" and had printed six billion dollars' worth of the private currency, The backing assets were claimed to be valued at 357 billion dollars. The currency featured the slogan \"In Jehovah We Trust\". The Comptroller of the Currency issued an alert warning banks that checks issued by TUC were \"valueless instruments\" and should not be cashed. In 2008, Cruz was indicted by a Federal grand jury in Florida on one count of conspiracy to defraud the United States under and and six counts of bank fraud under and in connection with his dealings with Bank of America, while attempting to get United Cities bank drafts cashed. As of late October 2010, Cruz was still a fugitive, though an associate was convicted on related charges and sentenced to prison for eight years.\n\n\n"}
{"id": "5665228", "url": "https://en.wikipedia.org/wiki?curid=5665228", "title": "Quasi-open map", "text": "Quasi-open map\n\nIn topology a branch of mathematics, a quasi-open map or quasi-interior map is a function which has similar properties to continuous maps. However, continuous maps and quasi-open maps are not related.\n\nA function formula_1 between topological spaces formula_2 and formula_3 is quasi-open if, for any non-empty open set formula_4, the interior of formula_5 in formula_3 is non-empty.\n\nLet formula_7 be a function such that \"X\" and \"Y\" are topological spaces.\n"}
{"id": "21685018", "url": "https://en.wikipedia.org/wiki?curid=21685018", "title": "Rate gyro", "text": "Rate gyro\n\nA rate gyro is a type of gyroscope, which rather than indicating direction, indicates the rate of change of angle with time. If a gyro has only one gimbal ring, with consequently only one plane of freedom, it can be adapted for use as a rate gyro to measure a rate of angular movement.\n\nRate gyros are used in rate integrating gyroscopes, and in attitude control systems for vehicles, and in combination with other sensors to make inertial navigation systems.\n\nThe advantage of rate gyros over other types of gyros is the fast response rate and their relatively low cost.\n\nThe traditional type of rate gyro employs relatively conventional gyroscopes with viscous couplings to transfer the spin rate to allow it to be read.\n\nMEMS gyros are cheap and have no moving parts. They often work by sonic resonance effects driven by piezoelectric transducers, that provide a signal when a rotation occurs.\n\n"}
{"id": "34546616", "url": "https://en.wikipedia.org/wiki?curid=34546616", "title": "Reversal test", "text": "Reversal test\n\nThe reversal test is a heuristic designed to spot and eliminate the status quo bias.\n\nThe reversal test was introduced in the context of the bioethics of human enhancement by Nick Bostrom and Toby Ord. Given that humans might suffer from irrational status quo bias, how can one distinguish between valid criticisms of proposed increase in some human trait and criticisms merely motivated by resistance to change? The reversal test attempts to do this by asking whether it would be a good thing if the trait was \"decreased\": An example given is that if someone objects that an increase in intelligence would be a bad thing due to more dangerous weapons being made etc., the objector to that position would then ask \"Shouldn't we decrease intelligence then?\"\n\n\"\"Reversal Test\": When a proposal to change a certain parameter is thought to have bad overall consequences, consider a change to the same parameter in the opposite direction. If this is also thought to have bad overall consequences, then the onus is on those who reach these conclusions to explain why our position cannot be improved through changes to this parameter. If they are unable to do so, then we have reason to suspect that they suffer from status quo bias.\" (p. 664)\n\nIdeally the test will help reveal whether status quo bias is an important causal factor in the initial judgement.\n\nA similar thought experiment in regards to dampening traumatic memories was described by Adam J. Kolber, imagining whether aliens naturally resistant to traumatic memories should adopt traumatic \"memory enhancement\". The \"trip to reality\" rebuttal to Nozick's experience machine thought experiment (where one's entire current life is shown to be a simulation and one is offered to return to reality) can also be seen as a form of reversal test.\n\nA further elaboration on the reversal test is suggested as the double reversal test:\n\"\"Double Reversal Test\": Suppose it is thought that increasing a certain parameter and decreasing it would both have bad overall consequences. Consider a scenario in which a natural factor threatens to move the parameter in one direction and ask whether it would be good to counterbalance this change by an intervention to preserve the status quo. If so, consider a later time when the naturally occurring factor is about to vanish and ask whether it would be a good idea to intervene to reverse the first intervention. If not, then there is a strong prima facie case for thinking that it would be good to make the first intervention even in the absence of the natural countervailing factor.\" (p. 673)\n\nIn this case the status quo bias is turned against itself, hopefully reducing its impact on the reasoning. It also handles possible arguments from evolutionary adaptation, transition costs, risk, and person-affecting morality that might otherwise complicate the simple reversal test.\n\nAlfred Nordmann argues that the simple reversal test merely erects a straw-man argument in favour of enhancement. He also claims that both tests ignore approaches that are neither consequentialist nor deontological, plus that one cannot view humans as collections of parameters that can be optimized separately or without regard to their history.\n\nChristian Weidemann similarly argues that the double reversal test can muddy the water; weighing transition costs versus benefits might be the relevant practical ethical question in much future enhancement analysis.\n"}
{"id": "130526", "url": "https://en.wikipedia.org/wiki?curid=130526", "title": "Riemann curvature tensor", "text": "Riemann curvature tensor\n\nIn the mathematical field of differential geometry, the Riemann curvature tensor or Riemann–Christoffel tensor (after Bernhard Riemann and Elwin Bruno Christoffel) is the most common method used to express the curvature of Riemannian manifolds. It assigns a tensor to each point of a Riemannian manifold (i.e., it is a tensor field), that measures the extent to which the metric tensor is not locally isometric to that of Euclidean space. The curvature tensor can also be defined for any pseudo-Riemannian manifold, or indeed any manifold equipped with an affine connection.\n\nIt is a central mathematical tool in the theory of general relativity, the modern theory of gravity, and the curvature of spacetime is in principle observable via the geodesic deviation equation. The curvature tensor represents the tidal force experienced by a rigid body moving along a geodesic in a sense made precise by the Jacobi equation.\n\nThe curvature tensor is given in terms of the Levi-Civita connection formula_1 by the following formula:\n\nwhere [\"u\",\"v\"] is the Lie bracket of vector fields. For each pair of tangent vectors \"u\", \"v\", \"R\"(\"u\",\"v\") is a linear transformation of the tangent space of the manifold. It is linear in \"u\" and \"v\", and so defines a tensor. Occasionally, the curvature tensor is defined with the opposite sign.\n\nIf formula_3 and formula_4 are coordinate vector fields then formula_5 and therefore the formula simplifies to \nThe curvature tensor measures \"noncommutativity of the covariant derivative\", and as such is the integrability obstruction for the existence of an isometry with Euclidean space (called, in this context, \"flat\" space). The linear transformation formula_7 is also called the curvature transformation or endomorphism.\n\nThe curvature formula can also be expressed in terms of the second covariant derivative defined as:\n\nwhich is linear in \"u\" and \"v\". Then:\n\nThus in the general case of non-coordinate vectors \"u\" and \"v\", the curvature tensor measures the noncommutativity of the second covariant derivative.\n\nOne can see the effects of curved space by comparing a tennis court and the Earth. Start at the lower right corner of the tennis court, with a racket held out towards north. Then while walking around the outline of the court, at each step make sure the tennis racket is maintained in the same orientation, parallel to its previous positions. Once the loop is complete the tennis racket will be parallel to its initial starting position. This is because tennis courts are built so the surface is flat. On the other hand, the surface of the Earth is curved: we can complete a loop on the surface of the Earth. Starting at the equator, point a tennis racket north along the surface of the Earth. Once again the tennis racket should always remain parallel to its previous position, using the local plane of the horizon as a reference. For this path, first walk to the north pole, then turn 90 degrees and walk down to the equator, and finally turn 90 degrees and walk back to the start. \nHowever now the tennis racket will be pointing backwards (towards the east). This process is akin to parallel transporting a vector along the path and the difference identifies how lines which appear \"straight\" are only \"straight\" locally. Each time a loop is completed the tennis racket will be deflected further from its initial position by an amount depending on the distance and the curvature of the surface. It is possible to identify paths along a curved surface where parallel transport works as it does on flat space. These are the geodesic of the space, for example any segment of a great circle of a sphere.\n\nThe concept of a curved space in mathematics differs from conversational usage. For example, if the above process was completed on a cylinder one would find that it is not curved overall as the curvature around the cylinder cancels with the flatness along the cylinder, this is a consequence of Gaussian curvature and the Gauss–Bonnet theorem. A familiar example of this is a floppy pizza slice which will remain rigid along its length if it is curved along its width.\n\nThe Riemann curvature tensor is a way to capture a measure of the intrinsic curvature. When you write it down in terms of its components (like writing down the components of a vector), it consists of a multi-dimensional array of sums and products of partial derivatives (some of those partial derivatives can be thought of as akin to capturing the curvature imposed upon someone walking in straight lines on a curved surface).\n\nWhen a vector in a Euclidean space is parallel transported around a loop, it will again point in the initial direction after returning to its original position. However, this property does not hold in the general case. The Riemann curvature tensor directly measures the failure of this in a general Riemannian manifold. This failure is known as the non-holonomy of the manifold.\n\nLet \"x\" be a curve in a Riemannian manifold \"M\". Denote by τ : T\"M\" → T\"M\" the parallel transport map along \"x\". The parallel transport maps are related to the covariant derivative by\nfor each vector field \"Y\" defined along the curve.\n\nSuppose that \"X\" and \"Y\" are a pair of commuting vector fields. Each of these fields generates a one-parameter group of diffeomorphisms in a neighborhood of \"x\". Denote by τ and τ, respectively, the parallel transports along the flows of \"X\" and \"Y\" for time \"t\". Parallel transport of a vector \"Z\" ∈ T\"M\" around the quadrilateral with sides \"tY\", \"sX\", −\"tY\", −\"sX\" is given by\nThis measures the failure of parallel transport to return \"Z\" to its original position in the tangent space T\"M\". Shrinking the loop by sending \"s\", \"t\" → 0 gives the infinitesimal description of this deviation:\nwhere \"R\" is the Riemann curvature tensor.\n\nConverting to the tensor index notation, the Riemann curvature tensor is given by\nwhere formula_14 are the coordinate vector fields. The above expression can be written using Christoffel symbols:\n\n(see also the list of formulas in Riemannian geometry).\n\nThe Riemann curvature tensor is also the commutator of the covariant derivative of an arbitrary covector formula_16\nwith itself:\nsince the connection formula_18 is torsionless, which means that the torsion tensor formula_19 vanishes.\n\nThis formula is often called the \"Ricci identity\". This is the classical method used by Ricci and Levi-Civita to obtain an expression for the Riemann curvature tensor. In this way, the tensor character of the set of quantities formula_20 is proved.\n\nThis identity can be generalized to get the commutators for two covariant derivatives of arbitrary tensors as follows \nThis formula also applies to tensor densities without alteration, because for the Levi-Civita (\"not generic\") connection one gets:\n\nIt is sometimes convenient to also define the purely covariant version by\n\nThe Riemann curvature tensor has the following symmetries:\n\nHere the bracket formula_27 refers to the inner product on the tangent space induced by the metric tensor. The last identity was discovered by Ricci, but is often called the first Bianchi identity or algebraic Bianchi identity, because it looks similar to the Bianchi identity below. (Also, if there is nonzero torsion, the first Bianchi identity becomes a differential identity of the torsion tensor.)\nThese three identities form a complete list of symmetries of the curvature tensor, i.e. given any tensor which satisfies the identities above, one can find a Riemannian manifold with such a curvature tensor at some point. Simple calculations show that such a tensor has formula_28 independent components.\n\nYet another useful identity follows from these three:\n\nOn a Riemannian manifold one has the covariant derivative formula_30 and the Bianchi identity (often called the second Bianchi identity or differential Bianchi identity) takes the form: \n\nGiven any coordinate chart about some point on the manifold, the above identities may be written in terms of the components of the Riemann tensor at this point as:\n\n\n\n\n\nThe algebraic symmetries are also equivalent to saying that \"R\" belongs to the image of the Young symmetrizer corresponding to the partition 2+2.\n\nThe Ricci curvature tensor is the contraction of the first and third indices of the Riemann tensor.\n\nFor a two-dimensional surface, the Bianchi identities imply that the Riemann tensor has only one independent component which means the Ricci scalar completely determines the Riemann tensor. There is only one valid expression for the Riemann tensor which fits the required symmetries:\n\nand by contracting with the metric twice we find the explicit form:\n\nwhere formula_41 is the metric tensor and formula_42 is a function called the Gaussian curvature and \"a\", \"b\", \"c\" and \"d\" take values either 1 or 2. The Riemann tensor has only one functionally independent component. The Gaussian curvature coincides with the sectional curvature of the surface. It is also exactly half the scalar curvature of the 2-manifold, while the Ricci curvature tensor of the surface is simply given by\n\nA Riemannian manifold is a space form if its sectional curvature is equal to a constant \"K\". The Riemann tensor of a space form is given by\n\nConversely, except in dimension 2, if the curvature of a Riemannian manifold has this form for some function \"K\", then the Bianchi identities imply that \"K\" is constant and thus that the manifold is (locally) a space form.\n\n\n"}
{"id": "435437", "url": "https://en.wikipedia.org/wiki?curid=435437", "title": "Snow White and The Madness of Truth", "text": "Snow White and The Madness of Truth\n\nSnow White and The Madness of Truth () was a 2004 item of installation art by Swedish, Israeli-born composer and musician Dror Feiler and his Swedish wife, artist Gunilla Sköld-Feiler. Feiler and Sköld-Feiler created the visuals and the music for the artwork together, which was installed in the Swedish History Museum in Stockholm, Sweden.\n\nThe installation consisted of a long pool of water coloured blood red, upon which floated a small white boat named \"Snövit\" (\"Snow White\") carrying a portrait of Hanadi Jaradat, a Palestinian suicide bomber, which were accompanied by text written on the nearby walls, and the sound of Bach's \"Mein Herze schwimmt im Blut\" (Cantata 199). This piece begins with the words, \"My heart swims in blood / because the brood of my sins / in God's holy eyes / makes me into a monster\". According to the artists, the installation was made to \"call attention to how weak people left alone can be capable of horrible things\".\n\nThe artwork became the centre of some controversy when the Israeli ambassador to Sweden, Zvi Mazel, vandalized it after he claimed it was antisemitic in nature. Some argued that critics failed to understand the artists' central message about tolerance, freedom of thought, and diversity. Reactions to the piece have been compared to reactions to Steve Earle's song \"John Walker's Blues\", which appeared on his 2002 album \"Jerusalem\".\n\nAs scheduled, the artwork was removed from display on February 8, 2004. In 2011 the Feilers created a new installation called \"Once upon a time in the middle of winter\" based on the events.\n\nIn early 2004 the artwork briefly came to the attention of the international media after it was vandalized on January 16 by Zvi Mazel, the Israeli ambassador to Sweden. Mazel disconnected the electricity powering the installation and tipped one of its lights into the water, causing a short circuit. When Mazel was asked to leave he refused and had to be escorted out by museum security. The entire event was filmed by the museum's security cameras.\n\nMazel later gave contradicting statements about the event. To the Swedish media, he said it was done in the heat of the moment, but to Israeli media he said it was premeditated and that he had planned it even before he saw the artwork. On January 20, Feiler appeared in Nyhetsmorgon on Swedish TV4 and explained that the white boat symbolized truth; and if an individual believed that their views were the absolute embodiment of truth, the end result could well be the pool of blood depicted in the installation.\n\nAccording to Sköld-Feiler, the name Snow White was chosen simply because in her portrait, Hanadi Jaradat resembled Snow White with her black hair, pale skin and red lips.\n\nThe installation was a part of the Making Differences exhibition at the Swedish History Museum. On January 18, 2004, Thomas Nordanstad, who is responsible for the exhibition, was attacked by an unidentified man who tried to push Nordanstad down a staircase. Nordanstad had also recently received over 400 e-mails containing various threats. Both Kristian Berg, head of the museum, and the artists also received many threats. The following Sunday, a museum guard had to remove a group of people who were throwing various objects into the water.\n\nAfter the attack on Nordanstad the number of visitors to the museum increased to approximately 1,400 per day, up from roughly the same number per week.\n\nAccording to Swedish Dagens Nyheter journalist Henrik Brors there may have been hidden motives behind Zvi Mazel's act. He speculated that it may have been done in an effort to discredit Sweden and the European Union by depicting them as antisemites, and to have the EU back down from its peace efforts in the Middle East. In the analysis in Dagens Nyheter Brors further speculated that Mazel may have done it to give Israel an excuse for not attending the international anti-genocide conference Stockholm International Forum that was to be held in Stockholm January 26–28.\n\nThe situation escalated further when Israel Army Radio incorrectly reported that a \"pro Israeli\" film was removed from the exhibition at the request of Syria. Both Thomas Nordanstad and Kristian Berg demonstrated that this allegation was false, as the documentary in question, \"Map\" by award-winning Israeli film maker Amit Goren, remained as part of the exhibition. It is believed that the erroneous rumour probably started when the display was moved from Tensta Konsthall due to some internal problems. During the whole time, another work by Goren, the film \"119 Bullets + Three\" was also on display. The display of Goren's works is sponsored by the Israeli embassy, and the cultural attache, Lizzie Oved Scheja, stated that the exhibit had their absolute support.\n\nThe Young Christian Democrats, the youth organisation of the Swedish Christian Democratic party, reported the artwork to the police in hope that action could be taken pursuant to Sweden's strict laws against hate speech. Mazel himself asked in an interview \"If we Jews say that this offends us, why can't a government remove it?\".\n\nStockholms Lokaltrafik decided to remove advertising of the Making Differences exhibit that used a picture of Hanadi Jaradat; those posters were a part of C. M. V. Hausswolff's artwork \"God made me do it\" and had nothing to do with Feiler/Sköld installation \"Snow White and the Madness of Truth.\"\n\nAn e-mail protest organized by the Simon Wiesenthal Center has been directed at Prime Minister Göran Persson's office. By the morning of January 27, 2004, 13,603 emails had been received.\n\nKristian Berg stated that \"I did not hear anyone who saw the work say that it was an anti-Semitic installation, against the Jewish people or against the Israeli people, I therefore think that this work was politically hijacked – the interpretation that Ambassador Mazel gave it was very narrow and very political.\" \n\n\n"}
{"id": "4551565", "url": "https://en.wikipedia.org/wiki?curid=4551565", "title": "Telexistence", "text": "Telexistence\n\nTelexistence is fundamentally a concept named for the general technology that enables a human being to have a real-time sensation of being at a place other than where he or she actually exists, and being able to interact with the remote environment, which may be real, virtual, or a combination of both. It also refers to an advanced type of teleoperation system that enables an operator at the control to perform remote tasks dexterously with the feeling of existing in a surrogate robot working in a remote environment. Telexistence in the real environment through a virtual environment is also possible. This concept was first proposed by Susumu Tachi in Japan in 1980 and 1981 as patents and the first report was published in Japanese in 1982 and in English in 1984.\n\n"}
{"id": "51667259", "url": "https://en.wikipedia.org/wiki?curid=51667259", "title": "Theodore Doughty Miller", "text": "Theodore Doughty Miller\n\nTheodore Doughty Miller (September 19, 1835 – March 1, 1897) was a Baptist preacher from Philadelphia, Pennsylvania in the late 19th century. Before the US Civil War (1861-1865), he was a part of abolitionist society in Philadelphia, and after the war he played a leading role in the Baptist Church. In 1881 he was called \"the best colored preacher ever located in Philadelphia\".\n\nTheodore Doughty Miller was born September 19, 1835 in New York City. His parents were Henry and Sarah Miller. Henry died when Theodore was an infant and Sarah died when he was about sixteen. He had an older brother who went to California during the gold rush and died in the 1862 sinking of the SS Golden Gate. As a boy, he went to colored school no. 1 headed by John Patterson. In July, 1849 he passed the teacher's examination and became first assistant in the Public High School. As a youth he attended St. Phillips Episcopal Church. He left this church and joined the Church of the Messiah led by Alexander Crummell.\n\nFrom 1849 to 1851 he studied during the evenings and Saturdays at the St. Augustine Institute and began to study all religious creeds and compare them with the bible. He was baptized into the Baptist church, but did not agree with that church's doctrine of Baptism. In 1851 he moved to Trenton, New Jersey to become principal of a public school there. Around that time he married Elizabeth P. Wood. He also helped form a young men's association and organized a choir and Sunday school of the local Mt. Zion A. M. E. church. In 1856 he left Trenton to take charge of a public school at Newburgh, New York, where he finally joined the Baptist church along with his wife, both being baptized February 22, 1857 in the Hudson River. He joined the Shiloh Baptist Church where his position as a church leader was opposed by the white pastor. In spite of this, he was chosen as teacher and then superintendent of the Sunday school and made a trustee and deacon of the church. When his further advancement was opposed by the pastor, he opened his own church where he preached on Sunday afternoons and nights - although he was not licensed to preach by the Church. He attended the American Baptist Missionary Society Convention at Philadelphia in 1858 where he along with Leonard Grimes, William Spellman, and Sampson White pushed the organization to oppose slavery. They voted to have no fellowship with slave-holding ministries. He preached at the convention and he was given a recommendation that he be licensed, either at Shiloh or at the First Baptist Church, a white church which had promised to give him license. Under this pressure, Shiloh granted him a license and he began to preach.\n\nIn 1858, he was called by the Zion Baptist Church of New Haven, Connecticut and was ordained on January 19, 1859 at the Concord Street Church in Brooklyn. That same year, he moved to Albany, New York where he preached for five years at the Hamilton Street Baptist Church. In Albany, Miller supported anti-slavery efforts and served as secretary of the Irrepressible Conflict Society for Human Rights organized immediately following the execution of John Brown in December 1859. During this time he studied under Elias Lyman Magoon, a noted preacher in Albany. In 1864, he preached at Oak Street Baptist Church and the Pearl Street Church, both in West Philadelphia, and became pastor at the Pearl Street Branch on August 1, where he finally settled. The church was also known as the First Baptist Church and moved to Cherry Street when it overran capacity at the previous location.\n\nHe held many leadership positions in the church, including corresponding secretary of the American Baptist Missionary Convention and recording secretary of the New England Baptist Missionary Convention. He gave the opening sermon at the Philadelphia Baptist Association in 1879. He led the Sunday School at his church. He organized a church in Princeton, New Jersey and a branch of his church in Germantown, Philadelphia. He also received a Doctor of Divinity. In 1894, Miller was elected moderator of the Philadelphia Baptist Association convention, the first black man ever elected to that position He also submitted articles to newspapers, including a pre-Emancipation Proclamation poem, \"God Never Made a Sin\", which was in the \"Louisville Newspaper\" February 10, 1849 and included the refrain, \"but [God] never, never made a slave.\"\n\nMiller died on March 1, 1897.\n"}
{"id": "31586", "url": "https://en.wikipedia.org/wiki?curid=31586", "title": "Ty Cobb", "text": "Ty Cobb\n\nTyrus Raymond Cobb (December 18, 1886 – July 17, 1961), nicknamed The Georgia Peach, was an American Major League Baseball (MLB) outfielder. He was born in rural Narrows, Georgia. Cobb spent 22 seasons with the Detroit Tigers, the last six as the team's player-manager, and finished his career with the Philadelphia Athletics. In 1936 Cobb received the most votes of any player on the inaugural Baseball Hall of Fame ballot, receiving 222 out of a possible 226 votes (98.2%); no other player received a higher percentage of votes until Tom Seaver in 1992. In 1999, editors at the \"Sporting News\" ranked Ty Cobb third on their list of \"Baseball's 100 Greatest Players\".\n\nCobb is widely credited with setting 90 MLB records during his career. His combined total of 4,065 runs scored and runs batted in (after adjusting for home runs) is still the highest ever produced by any major league player. He still holds several records as of the end of the 2018 season, including the highest career batting average (.366 or .367, depending on source) and most career batting titles with 11 (or 12, depending on source). He retained many other records for almost a half century or more, including most career hits until 1985 (4,189 or 4,191, depending on source), most career runs (2,245 or 2,246 depending on source) until 2001, most career games played (3,035) and at bats (11,429 or 11,434 depending on source) until 1974, and the modern record for most career stolen bases (892) until 1977. He still holds the career record for stealing home (54 times) and for stealing second base, third base, and home in succession (5 times), and as the youngest player ever to compile 4,000 hits and score 2,000 runs. Cobb ranks fifth all-time in number of games played and committed 271 errors, the most by any American League (AL) outfielder.\n\nCobb's legacy, which includes a large college scholarship fund for Georgia residents financed by his early investments in Coca-Cola and General Motors, has been somewhat tarnished by allegations of racism and violence, largely stemming from a couple of largely-discredited biographies that were released following his death. Cobb's reputation as an extremely violent man was fanned by his first biographer, sportswriter Al Stump, whose stories about Cobb have been discredited as sensationalized, and in some part proven to be entirely fictional. Cobb, who was raised in a family of abolitionists, often spoke positively about the need for baseball's integration and was a well-known philanthropist who founded a hospital and educational foundation.\n\nCobb was born in 1886 in Narrows, Georgia, a small rural community of farmers that was unincorporated. He was the first of three children born to William Herschel Cobb (1863–1905) and Amanda Chitwood Cobb (1871–1936). Cobb's father was a state senator.\n\nWhen he was still an infant, his parents moved to nearby Royston, where he was raised. By most accounts, he became fascinated with baseball as a child, and decided he wanted to play professional ball one day; his father was vehemently opposed to this idea, but by his teen years, he was trying out for area teams. He played his first years in organized baseball for the Royston Rompers, the semi-pro Royston Reds, and the Augusta Tourists of the South Atlantic League who released him after only two days. He then tried out for the Anniston Steelers of the semipro Tennessee–Alabama League, with his father's stern admonition ringing in his ears: \"Don't come home a failure!\" After joining the Steelers for a monthly salary of $50, Cobb promoted himself by sending several postcards written about his talents under different aliases to Grantland Rice, the sports editor of the \"Atlanta Journal\". Eventually, Rice wrote a small note in the \"Journal\" that a \"young fellow named Cobb seems to be showing an unusual lot of talent\". After about three months, Cobb returned to the Tourists and finished the season hitting .237 in 35 games. In August 1905, the management of the Tourists sold Cobb to the American League's Detroit Tigers for US$750 (equivalent to approximately $ in today's funds).\n\nOn August 8, 1905, Cobb's mother fatally shot his father with a pistol that his father had purchased for her. Court records indicate that Mr. Cobb had suspected his wife of infidelity and was sneaking past his own bedroom window to catch her in the act. She saw the silhouette of what she presumed to be an intruder and, acting in self-defense, shot and killed her husband. Mrs. Cobb was charged with murder and then released on a $7,000 recognizance bond. She was acquitted on March 31, 1906. Cobb later attributed his ferocious play to his late father, saying, \"I did it for my father. He never got to see me play... but I knew he was watching me, and I never let him down.\"\n\nIn 1911, Cobb moved to Detroit's architecturally significant and now historically protected Woodbridge neighborhood, from which he would walk with his dogs to the ballpark prior to games. The Victorian duplex in which Cobb lived still stands.\n\nThree weeks after his mother killed his father, Cobb debuted in center field for the Detroit Tigers. On August 30, 1905, in his first major league at bat, he doubled off of Jack Chesbro of the New York Highlanders. Chesbro had won a record 41 games the previous season. Cobb was 18 years old at the time, the youngest player in the league by almost a year. Although he hit only .240 in 41 games, he signed a $1,500 contract to play for the Tigers in 1906.\n\nAlthough rookie hazing was customary, Cobb could not endure it in good humor and soon became alienated from his teammates. He later attributed his hostile temperament to this experience: \"These old-timers turned me into a snarling wildcat.\" Tigers manager Hughie Jennings later acknowledged that Cobb was targeted for abuse by veteran players, some of whom sought to force him off the team. \"I let this go for a while because I wanted to satisfy myself that Cobb has as much guts as I thought in the very beginning\", Jennings recalled. \"Well, he proved it to me, and I told the other players to let him alone. He is going to be a great baseball player and I won't allow him to be driven off this club.\"\n\nThe following year, 1906, Cobb became the Tigers' full-time center fielder and hit .316 in 98 games, setting a record for the highest batting average (minimum 310 plate appearances) for a 19-year-old (later bested by Mel Ott's .322 average in 124 games for the 1928 New York Giants). He never hit below that mark again. After being moved to right field, he led the Tigers to three consecutive American League pennants in 1907, 1908 & 1909. Detroit would lose each World Series (to the Cubs twice and then the Pirates), however, with Cobb's postseason numbers far below his career standard. Cobb did not get another opportunity to play on a pennant-winning team.\n\nIn 1907, Cobb reached first and then stole second, third and home. He accomplished the feat four more times during his career. He finished the 1907 season with a league-leading .350 batting average, 212 hits, 49 steals and 119 runs batted in (RBI). At age 20, he was the youngest player to win a batting championship and held this record until 1955, when fellow Detroit Tiger Al Kaline won the batting title twelve days younger than Cobb when he did it. Reflecting on his career in 1930, two years after retiring, he told Grantland Rice, \"The biggest thrill I ever got came in a game against the Athletics in 1907 [on September 30]... The Athletics had us beaten, with Rube Waddell pitching. They were two runs ahead in the 9th inning, when I happened to hit a home run that tied the score. This game went 17 innings to a tie, and a few days later, we clinched our first pennant. You can understand what it meant for a 20-year-old country boy to hit a home run off the great Rube, in a pennant-winning game with two outs in the ninth.\"\nDespite great success on the field, Cobb was no stranger to controversy off it. As described in Smithsonian Magazine, \"In 1907 during spring training in Augusta, Georgia, a black groundskeeper named Bungy Cummings, whom Cobb had known for years, attempted to shake Cobb's hand or pat him on the shoulder.\" The \"overly familiar greeting infuriated\" Cobb, who attacked Cummings. When Cummings' wife tried to defend him, Cobb allegedly choked her. The assault was only stopped when catcher Charles \"Boss\" Schmidt knocked Cobb out. However, aside from Schmidt's statement to the press, no other corroborating witnesses to the assault on Cummings ever came forward and Cummings himself never made a public comment about it. Author Charles Leerhsen speculates that the assault on Cummings and his wife never occurred and that Schmidt likely made it up completely. Cobb had spent the previous year defending himself on several occasions from assaults by Schmidt, with Schmidt often coming out of nowhere to blindside Cobb. On that day, several reporters did see Cummings, who appeared to be \"partially under the influence of liquor\", approach Cobb and shout \"Hello, Carrie!\" (the meaning of which is unknown) and go in for a hug. Cobb then pushed him away, which was the last interaction that anyone saw between Cobb and Cummings. Shortly thereafter, hearing a fight, several reporters came running and found Cobb and Schmidt wrestling on the ground. When the fight was broken up and Cobb had walked away, Schmidt remained behind and told the reporters that he saw Cobb assaulting Cummings and his wife and had intervened. Leerhsen speculates that this was just another one of Schmidt's assaults on Cobb and that once discovered, Schmidt made up a story that made him sound like he had assaulted Cobb for a noble purpose. In 1908, Cobb attacked a black laborer in Detroit who complained when Cobb stepped into freshly poured asphalt; Cobb was found guilty of battery but the sentence was suspended.\n\nIn September 1907, Cobb began a relationship with The Coca-Cola Company that lasted the remainder of his life. By the time he died, he held over 20,000 shares of stock and owned bottling plants in Santa Maria, California, Twin Falls, Idaho, and Bend, Oregon. He was also a celebrity spokesman for the product. In the offseason between 1907 and 1908, Cobb negotiated with Clemson Agricultural College of South Carolina, offering to coach baseball there \"for $250 a month, provided that he did not sign with Detroit that season\". This did not come to pass, however.\n\nThe following season, the Tigers finished ahead of the Chicago White Sox for the pennant. Cobb again won the batting title with a .324 average, but Detroit suffered another loss in the World Series. In August 1908, Cobb married Charlotte (\"Charlie\") Marion Lombard, the daughter of prominent Augustan Roswell Lombard. In the offseason, the couple lived on her father's Augusta estate, \"The Oaks\", until they moved into their own house on Williams Street in November 1913.\n\nThe Tigers won the AL pennant again in 1909. During that World Series, Cobb's last, he stole home in the second game, igniting a three-run rally, but that was the high point for him, finishing with a lowly .231, as the Tigers lost to Honus Wagner and the powerful Pirates in seven games. Although he performed poorly in the postseason, he won the Triple Crown by hitting .377 with 107 RBI and nine home runs, all inside the park, thus becoming the only player of the modern era to lead his league in home runs in a season without hitting a ball over the fence.\nIn the same season, Charles M. Conlon snapped the famous photograph of a grimacing Cobb sliding into third base amid a cloud of dirt, which visually captured the grit and ferocity of his playing style.\n\nGoing into the final days of the 1910 season, Cobb had a .004 lead on Nap Lajoie for the American League batting title. The prize for the winner of the title was a Chalmers automobile. Cobb sat out the final games to preserve his average. Lajoie hit safely eight times in a doubleheader, but six of those hits were bunt singles. Later it was rumored that the opposing manager had instructed his third baseman to play extra deep to allow Lajoie to win the batting race over the generally disliked Cobb. Although Cobb was credited with a higher batting average, it was later discovered that one game had been counted twice so that Cobb actually lost to Lajoie.\n\nAs a result of the incident, AL president Ban Johnson was forced to arbitrate the situation. He declared Cobb the rightful owner of the title, but car company president Hugh Chalmers chose to award one to both Cobb and Lajoie.\n\nCobb regarded baseball as \"something like a war\", future Tiger second baseman Charlie Gehringer said. \"Every time at bat for him was a crusade.\" Baseball historian John Thorn said in the book \"Legends of the Fall\", \"He is testament to how far you can get simply through will... Cobb was pursued by demons.\"\n\nCobb was having a tremendous year in 1911, which included a 40-game hitting streak. Still, \"Shoeless\" Joe Jackson led him by .009 points in the batting race late in the season. Near the end of the season, Cobb's Tigers had a long series against Jackson's Cleveland Naps. Fellow Southerners Cobb and Jackson were personally friendly both on and off the field. Cobb used that friendship to his advantage. Cobb ignored Jackson when Jackson tried to say anything to him. When Jackson persisted, Cobb snapped angrily back at him, making him wonder what he could have done to enrage Cobb. Cobb felt that it was these mind games that caused Jackson to \"fall off\" to a final average of .408, twelve points lower than Cobb's .420, a twentieth-century record which stood until George Sisler tied it and Rogers Hornsby surpassed it with .424, the record since then except for Hugh Duffy's .438 in the nineteenth century.\n\nCobb led the AL that year in numerous other categories, including 248 hits, 147 runs scored, 127 RBI, 83 stolen bases, 47 doubles, 24 triples and a .621 slugging percentage. Cobb hit eight home runs but finished second in that category to Frank Baker, who hit eleven. He was awarded another Chalmers car, this time for being voted the AL MVP by the Baseball Writers' Association of America.\nOn May 12, 1911, Cobb's play illustrated his combination of skill and cunning. Playing against the New York Highlanders, he scored from first base on a single to right field, then scored another run from second base on a wild pitch. In the seventh inning, he tied the game with a two-run double. The Highlanders catcher vehemently argued the safe call at second base with the umpire in question, going on at such length that the other Highlanders infielders gathered nearby to watch. Realizing that no one on the Highlanders had called time, Cobb strolled unobserved to third base, and then casually walked towards home plate as if to get a better view of the argument. He then suddenly broke into a run and slid into home plate for the eventual winning run. It was performances like this that led Branch Rickey to say later that Cobb \"had brains in his feet\".\n\nDescribing his gameplay strategy in 1930, he said, \"My system was all offense. I believed in putting up a mental hazard for the other fellow. If we were five or six runs ahead, I'd try some wild play, such as going from first to home on a single. This helped to make the other side hurry the play in a close game later on. I worked out all the angles I could think of, to keep them guessing and hurrying.\" In the same interview, Cobb talked about having noticed a throwing tendency of first baseman Hal Chase, but having to wait two full years until the opportunity came to exploit it. By unexpectedly altering his own baserunning tendencies, he was able to surprise Chase and score the winning run of the game in question.\n\nOn May 15, 1912, Cobb assaulted a heckler, Claude Lucker (often misspelled as Lueker), in the stands in New York's Hilltop Park where his Tigers were playing the Highlanders. Lucker and Cobb had traded insults with each other through the first couple of innings. Cobb at one point went to the Highlander dugout to look for the Highlander's owner to try to have Lucker ejected from the game, but his search was in vain. The situation finally climaxed when Lucker allegedly called Cobb a \"half-nigger\". Cobb, in his discussion of the incident in the Holmes biography, avoided such explicit words but alluded to Lucker's epithet by saying he was \"reflecting on my mother's color and morals\". He went on to state that he warned Highlander manager Harry Wolverton that if something wasn't done about that man, there would be trouble. No action was taken. At the end of the sixth inning, after being challenged by teammates Sam Crawford and Jim Delahanty to do something about it, Cobb climbed into the stands and attacked Lucker, who it turned out was handicapped (he had lost all of one hand and three fingers on his other hand in an industrial accident). When onlookers shouted at him to stop because the man had no hands, he reportedly retorted, \"I don't care if he got no feet!\" Though extremely rare in the 21st century, attacking fans was not so unusual an activity in the early years of baseball. Other notable baseball stars who assaulted heckling fans include Babe Ruth, Cy Young, Rube Waddell, Kid Gleason, Sherry Magee, and Fred Clarke.\nThe league suspended him, and his teammates, though not fond of Cobb, went on strike to protest the suspension, and the lack of protection of players from abusive fans, before the May 18 game in Philadelphia. For that one game, Detroit fielded a replacement team made up of hastily recruited college and sandlot players plus two Tiger coaches and lost 24–2, thereby setting some of Major League Baseball's modern-era (post-1900) negative records, notably the 26 hits in a nine-inning game allowed by Allan Travers, who pitched one of the sport's most unlikely complete games. The pre-1901 record for the most hits and runs given up in a game is held by the Cleveland Blues' Dave Rowe. Primarily an outfielder, Rowe pitched a complete game on July 24, 1882, giving up 35 runs on 29 hits. The current post-1900 record for most hits in a nine-inning game is 31, set in 1992 by the Milwaukee Brewers against Toronto; however, the Blue Jays used six pitchers.\n\nThe strike ended when Cobb urged his teammates to return to the field. According to him, this incident led to the formation of a players' union, the \"Ballplayers' Fraternity\" (formally, the Fraternity of Professional Baseball Players of America), an early version of what is now called the Major League Baseball Players Association, which garnered some concessions from the owners.\n\nCobb, during his career, was involved in numerous other fights, both on and off the field, and several profanity-laced shouting matches. For example, Cobb and umpire Billy Evans arranged to settle their in-game differences through fisticuffs under the grandstand after the game. Members of both teams were spectators, and broke up the scuffle after Cobb had knocked Evans down, pinned him and began choking him. In 1909, Cobb was arrested for assault for an incident that occurred in a Cleveland hotel. Cobb got into an argument with the elevator operator around 2:15 a.m. when the man refused to take him to the floor where some of his teammates were having a card game. The elevator operator stated that he could only take Cobb to the floor where his room was. As the argument escalated, a night watchman approached and he and Cobb eventually got into a physical confrontation. During the fight, Cobb produced a pen knife and slashed the watchman across the hand. Cobb later claimed that the watchman, who had the upper hand in the fight, had his finger in Cobb's left eye and that Cobb was worried he was going to have his sight ruined. The fight finally ended when the watchman produced a gun and struck Cobb several times in the head, knocking him out. Cobb would later plead guilty to simple assault and pay a $100 fine. This incident has often been retold with the elevator operator and the watchman both being black. However, recent scholarship has shown that all parties involved were white.\n\nIn 1915, Cobb set the single-season record for stolen bases with 96, which stood until Dodger Maury Wills broke it in 1962.\nIn 1917, Cobb hit in 35 consecutive games, still the only player with two 35-game hitting streaks (including his 40-game streak in 1911). He had six hitting streaks of at least 20 games in his career, second only to Pete Rose's seven. \n\nAlso in 1917, Cobb starred in the motion picture \"Somewhere in Georgia\" for a sum of $25,000 plus expenses (equivalent to approximately $ today ). Based on a story by sports columnist Grantland Rice, the film casts Cobb as \"himself\", a small-town Georgian bank clerk with a talent for baseball. Broadway critic Ward Morehouse called the movie \"absolutely the worst flicker I ever saw, pure hokum\".\n\nIn October 1918, Cobb enlisted in the Chemical Corps branch of the United States Army and was sent to the Allied Expeditionary Forces headquarters in Chaumont, France. He served approximately 67 days overseas before receiving an honorable discharge and returning to the United States. He was given the rank of captain underneath the command of Major Branch Rickey, the president of the St. Louis Cardinals. Other baseball players serving in this unit included Captain Christy Mathewson and Lieutenant George Sisler. All of these men were assigned to the Gas and Flame Division, where they trained soldiers in preparation for chemical attacks by exposing them to gas chambers in a controlled environment, which was eventually responsible for Mathewson's contracting tuberculosis which led to his premature death on the eve of the 1925 World Series.\n\nOn August 19, 1921, in the second game of a doubleheader against Elmer Myers of the Boston Red Sox, Cobb collected his 3,000th hit. Aged 34 at the time, he is still the youngest ballplayer to reach that milestone, and in the fewest at-bats (8,093).\n\nBy 1920, Babe Ruth, newly sold to the newly named New York Yankees from the Boston Red Sox, had established himself as a power hitter, something Cobb was not considered to be. When his Tigers showed up in New York to play the Yankees for the first time that season, writers billed it as a showdown between two stars of competing styles of play. Ruth hit two homers and a triple during the series, compared to Cobb's one single.\n\nAs Ruth's popularity grew, Cobb became increasingly hostile toward him. He saw the Babe not only as a threat to his style of play, but also to his style of life. While Cobb preached ascetic self-denial, Ruth gorged on hot dogs, beer and women. Perhaps what angered him the most about Ruth was that despite Babe's total disregard for his physical condition and traditional baseball, he was still an overwhelming success and brought fans to the ballparks in record numbers to see him challenge his own slugging records.\n\nAfter enduring several years of seeing his fame and notoriety usurped by Ruth, Cobb decided that he was going to show that swinging for the fences was no challenge for a top hitter. On May 5, 1925, he began a two-game hitting spree better than any even Ruth had unleashed. Sitting in the Tiger dugout, he told a reporter that, for the first time in his career, he was going to swing for the fences. That day, he went 6 for 6, with two singles, a double and three home runs. The 16 total bases set a new AL record, which stood until May 8, 2012 when Josh Hamilton of the Texas Rangers hit four home runs and a double for a total of 18 bases. The next day he had three more hits, two of which were home runs. The single his first time up gave him nine consecutive hits over three games. His five homers in two games tied the record set by Cap Anson of the old Chicago NL team in 1884. Cobb wanted to show that he could hit home runs when he wanted, but simply chose not to do so. At the end of the series, the 38-year-old veteran superstar had gone 12 for 19 with 29 total bases and then went happily back to his usual bunting and hitting-and-running. For his part, Ruth's attitude was that \"I could have had a lifetime .600 average, but I would have had to hit them singles. The people were paying to see me hit home runs.\" Even so, when asked in 1930 by Grantland Rice to name the best hitter he'd ever seen, Cobb answered, \"You can't beat the Babe. Ruth is one of the few who can take a terrific swing and still meet the ball solidly. His timing is perfect. [No one has] the combined power and eye of Ruth.\"\n\nTiger owner Frank Navin tapped Cobb to take over for Hughie Jennings as manager for the 1921 season, a deal he signed on his 34th birthday for $32,500 (equivalent to approximately $ in today's funds). The signing surprised the baseball world. Although Cobb was a legendary player, he was disliked throughout the baseball community, even by his own teammates; and he expected as much from his players since he set a standard most players couldn't meet.\n\nThe closest Cobb came to winning another pennant was in 1924, when the Tigers finished in third place, six games behind the pennant-winning Washington Senators. The Tigers had also finished third in 1922, but 16 games behind the Yankees. Cobb blamed his lackluster managerial record (479 wins against 444 losses) on Navin, who was arguably even more frugal than he was, passing up a number of quality players Cobb wanted to add to the team. In fact, he had saved money by hiring Cobb to both play and manage.\n\nIn 1922, Cobb tied a batting record set by Wee Willie Keeler, with four five-hit games in a season. This has since been matched by Stan Musial, Tony Gwynn and Ichiro Suzuki. On May 10, 1924, Cobb was honored at ceremonies before a game in Washington, D.C., by more than 100 dignitaries and legislators. He received 21 books, one for each year in professional baseball.\n\nAt the end of 1925 Cobb was once again embroiled in a batting title race, this time with one of his teammates and players, Harry Heilmann. In a doubleheader against the St. Louis Browns on October 4, 1925, Heilmann got six hits to lead the Tigers to a sweep of the doubleheader and beat Cobb for the batting crown, .393 to .389. Cobb and Brownie player-manager George Sisler each pitched in the final game, Cobb pitching a perfect inning.\n\nCobb announced his retirement after a 22-year career as a Tiger in November 1926, and headed home to Augusta, Georgia. Shortly thereafter, Tris Speaker also retired as player-manager of the Cleveland Indians. The retirement of two great players at the same time sparked some interest, and it turned out that the two were coerced into retirement because of allegations of game-fixing brought about by Dutch Leonard, a former pitcher managed by Cobb.\nLeonard accused former pitcher and outfielder Smoky Joe Wood and Cobb of betting on a Tiger-Indian game played in Detroit on September 25, 1919, in which they allegedly orchestrated a Tiger victory to win the bet. Leonard claimed proof existed in letters written to him by Cobb and Wood. Commissioner Kenesaw Mountain Landis held a secret hearing with Cobb, Speaker and Wood. A second secret meeting among the AL directors led to the unpublicized resignations of Cobb and Speaker; however, rumors of the scandal led Judge Landis to hold additional hearings in which Leonard subsequently refused to participate. Cobb and Wood admitted to writing the letters, but claimed that a horse-racing bet was involved and that Leonard's accusations were in retaliation for Cobb's having released him from the Tigers, thereby demoting him to the minor leagues. Speaker denied any wrongdoing.\n\nOn January 27, 1927, Judge Landis cleared Cobb and Speaker of any wrongdoing because of Leonard's refusal to appear at the hearings. Landis allowed both Cobb and Speaker to return to their original teams, but each team let them know that they were free agents and could sign with any club they wanted. Speaker signed with the Washington Senators for 1927, and Cobb with the Philadelphia Athletics. Speaker then joined Cobb in Philadelphia for the 1928 season. Cobb said he had come back only to seek vindication and say he left baseball on his own terms.\n\nCobb played regularly in 1927 for a young and talented team that finished second to one of the greatest teams of all time, the 110–44 1927 Yankees, returning to Detroit to a tumultuous welcome on May 11 and doubling his first time up to the cheers of Tiger fans. On July 18, Cobb became the first member of the 4000 hit club when he doubled off former teammate Sam Gibson, still pitching for the Tigers, at Navin Field.\n\n1927 was also the final season of Washington Senators pitcher Walter Johnson's career. With their careers largely overlapping, Cobb faced Johnson more times than any other batter-pitcher matchup in baseball history. Cobb also got the first hit ever allowed by Johnson. After Johnson hit Detroit's Ossie Vitt with a pitch in August 1915, seriously injuring him, Cobb realized that Johnson was fearful of hitting opponents. He used this knowledge to his advantage by standing closer to the plate.\n\nCobb returned for the 1928 season, but played less frequently due to his age and the blossoming abilities of the young A's, who were again in a pennant race with the Yankees. On September 3, Ty Cobb pinch-hit in the ninth inning of the first game of a doubleheader against the Senators and doubled off Bump Hadley for his last career hit although his last at-bat wasn't until September 11 against the Yankees, popping out off Hank Johnson and grounding out to shortstop Mark Koenig. He then announced his retirement, effective the end of the season, after batting .300 or higher in 23 consecutive seasons (the only season under .300 being his rookie season), a major league record not likely to be broken.\n\nHe also ended his career with a rather dubious record. When Cobb retired, he led AL outfielders for most errors all-time with 271, which still stands today. Nineteenth-century player Tom Brown holds the major league record with 490 errors committed as an outfielder, while the National League record is held by nineteenth-century player George Gore with 346 errors. Cobb ranks 14th on the all-time list for errors committed by an outfielder.\n\nCobb retired a very rich and successful man. He toured Europe with his family, went to Scotland for some time and then returned to his farm in Georgia. He spent his retirement pursuing his off-season avocations of hunting, golfing, polo and fishing. His other pastime was trading stocks and bonds, increasing his immense personal wealth. He was a major stockholder in the Coca-Cola Corporation, which by itself would have made him wealthy.\n\nIn the winter of 1930, Cobb moved into a Spanish ranch estate on Spencer Lane in the affluent town of Atherton located south of San Francisco, California on the San Francisco Peninsula. At the same time, his wife Charlie filed the first of several divorce suits; but withdrew the suit shortly thereafter. The couple eventually divorced in 1947 after 39 years of marriage; the last few years of which Mrs. Cobb lived in nearby Menlo Park. The couple had three sons and two daughters: Tyrus Raymond Jr, Shirley Marion, Herschel Roswell, James Howell and Beverly.\n\nCobb never had an easy time as husband and father. His children found him to be demanding, yet also capable of kindness and extreme warmth. He expected his sons to be exceptional athletes in general and baseball players in particular. Tyrus Raymond, Jr. flunked out of Princeton (where he had played on the varsity tennis team), much to his father's dismay. The elder Cobb subsequently traveled to the Princeton campus and beat his son with a whip to ensure against future academic failure. Tyrus Raymond, Jr. then entered Yale University and became captain of the tennis team while improving his academics, but was then arrested twice in 1930 for drunkenness and left Yale without graduating. Cobb helped his son deal with his pending legal problems, but then permanently broke off with him. Even though Tyrus Raymond, Jr. finally reformed and eventually earned an M.D. from the Medical College of South Carolina and practiced obstetrics and gynecology in Dublin, Georgia, until his premature death at 42 on September 9, 1952, from a brain tumor, his father remained distant.\n\nIn February 1936, when the first Hall of Fame election results were announced, Cobb had been named on 222 of 226 ballots, outdistancing Babe Ruth, Honus Wagner, Christy Mathewson and Walter Johnson, the only others to earn the necessary 75% of votes to be elected that first year. His 98.2 percentage stood as the record until Tom Seaver received 98.8% of the vote in 1992. Those incredible results show that although many people disliked him personally, they respected the way he had played and what he had accomplished. In 1998, \"Sporting News\" ranked him as third on the list of 100 Greatest Baseball Players.\n\nOf major league stars of the 1940s and 1950s, he had positive things to say about Stan Musial, Phil Rizzuto and Jackie Robinson, but few others. Even so, he was known to help out young players. He was instrumental in helping Joe DiMaggio negotiate his rookie contract with the New York Yankees.\n\nAccording to sportswriter Grantland Rice, he and Cobb were returning from the Masters golf tournament in the late 1940s and stopped at a Greenville, South Carolina, liquor store. Cobb noticed that the man behind the counter was \"Shoeless\" Joe Jackson, who had been banned from baseball almost 30 years earlier following the Black Sox scandal. Jackson did not appear to recognize him, and after making his purchase an incredulous Cobb asked, \"Don't you know me, Joe?\" \"I know you\", replied Jackson, \"but I wasn't sure you wanted to speak to me. A lot of them don't.\"\n\nCobb was mentioned in the poem \"Line-Up for Yesterday\" by Ogden Nash:\n\nAt the age of 62, Cobb married a second time in 1949. His new wife was 40-year-old Frances Fairbairn Cass, a divorcee from Buffalo, New York. Their childless marriage also failed, ending with a divorce in 1956. At this time, Cobb became generous with his wealth, donating $100,000 in his parents' name for his hometown to build a modern 24-bed hospital, Cobb Memorial Hospital, which is now part of the Ty Cobb Healthcare System. He also established the Cobb Educational Fund, which awarded scholarships to needy Georgia students bound for college, by endowing it with a $100,000 donation in 1953 (equivalent to approximately $ in current year dollars ).\n\nHe knew that another way he could share his wealth was by having biographies written that would both set the record straight on him and teach young players how to play. John McCallum spent some time with Cobb to write a combination how-to and biography titled \"The Tiger Wore Spikes: An Informal Biography of Ty Cobb\" that was published in 1956. In December 1959, he was diagnosed with prostate cancer, diabetes, high blood pressure, and Bright's disease.\n\nIt was also during his final years that Cobb began work on his autobiography, \"My Life in Baseball: The True Record\", with writer Al Stump. Later Stump would claim the collaboration was contentious, and after Cobb's death Stump published two more books and a short story giving what he claimed was the \"true story\". One of these later books was used as the basis for the 1994 film \"Cobb\" (a box office flop starring Tommy Lee Jones as Cobb and directed by Ron Shelton). In 2010, an article by William R. \"Ron\" Cobb (no relation to Ty) in the peer-reviewed \"The National Pastime\" (the official publication of the Society for American Baseball Research) accused Stump of extensive forgeries of Cobb-related documents and diaries. The article further accused Stump of numerous false statements about Cobb in his last years, most of which were sensationalistic in nature and intended to cast Cobb in an unflattering light.\n\nIn his last days, Cobb spent some time with the old movie comedian Joe E. Brown, talking about the choices he had made in his life. He told Brown that he felt that he had made mistakes and that he would do things differently if he could. He had played hard and lived hard all his life, had no friends to show for it at the end, and regretted it. Publicly, however, he claimed to have no regrets: \"I've been lucky. I have no right to be regretful of what I did.\"\n\nHe checked into Emory Hospital for the last time in June 1961. His first wife, Charlie, his son Jimmy and other family members came to be with him for his final days. He died a month later, on July 17, 1961, at Emory University Hospital.\n\nApproximately 150 friends and relatives attended a brief service in Cornelia, Georgia, and drove to the Cobb family mausoleum in Royston for the burial. Baseball's only representatives at his funeral were three old-time players, Ray Schalk, Mickey Cochrane and Nap Rucker, along with Sid Keener, the director of the Baseball Hall of Fame, but messages of condolences numbered in the hundreds. Family in attendance included Cobb's former wife Charlie, his two daughters, his surviving son Jimmy, his two sons-in-law, his daughter-in-law Mary Dunn Cobb and her two children.\n\nAt the time of his death, Cobb's estate was reported to be worth at least $11.78 million (equivalent to $ today), including $10 million worth of General Motors stock and $1.78 million in The Coca-Cola Company stock. His will left a quarter of his estate to the Cobb Educational Fund, and distributed the rest among his children and grandchildren. Cobb is interred in the Rose Hill Cemetery in Royston, Georgia. As of July 2015, the Ty Cobb Educational Foundation has distributed $15.8 million in college scholarships to needy Georgians.\n\nHistorian Steven Elliott Tripp has explored the reaction of fans—he was “a player fans loved to hate,” so much so that he became the pioneer sports celebrity. It was the male fans who responded enthusiastically to how Cobb demonstrated in action a new level of modern masculinity. Cobb did that by his performance as a specialist in his art, a man with iron nerve, undaunted, fighting to advance his team and his career by crushing his weaker, less-masculine opponents. Cobb demonstrated raw emotion and encouraged his audience to participate in the manly struggle underway in the stadium by shouting their taunts and jeers at the opposing team.\n\nCobb has been judged by some historians and journalists as the best player of the dead-ball era, and is generally seen as one of the greatest players of all time.\n\nEfforts to create a Ty Cobb Memorial in Royston initially failed, primarily because most of the artifacts from his life were sent to the Baseball Hall of Fame in Cooperstown, New York and the Georgia town was viewed as too remote to make a memorial worthwhile. But ultimately, on July 17, 1998, the 37th anniversary of Cobb's death, the Ty Cobb Museum and the Franklin County Sports Hall of Fame opened its doors in Royston. On that day, Cobb was one of the first members to be inducted into the Franklin County Sports Hall of Fame.\n\nOn August 30, 2005, his hometown hosted a 1905 baseball game to commemorate the 100th anniversary of Cobb's first major league game. Players in the game included many of Cobb's descendants as well as many citizens from his hometown of Royston. Another early-20th-century baseball game was played in his hometown at Cobb Field on September 30, 2006, with Cobb's descendants and Roystonians again playing. Cobb's personal batboy from his major league years was also in attendance, and threw out the first pitch.\n\nIn addition to the aforementioned film, Ty Cobb's legacy also includes legions of collectors of his early tobacco card issues, as well as game used memorabilia and autographs. Perhaps the most curious item is a 1909 Ty Cobb Cigarettes pack, leaving some to believe Cobb either had, or attempted to have, his own brand of cigarettes. Very little about the card is known other than its similarity to the 1909 T206 Red Portrait card published by the American Tobacco Company, and until 2005 only a handful were known to exist. That year, a sizable cache of the cards was brought to auction by the family of a Royston, Georgia, man who had stored them in a book for almost 100 years..\n\nThe new baseball stadium at Hampden–Sydney College is named Ty Cobb Ballpark.\n\nThe band Soundgarden recorded a song \"Ty Cobb\" in the album \"Down on the Upside\" in 1996. However, the song wasn't actually written about Ty Cobb, it was given the name because the lyrics reminded their bassist Ben Shepherd of him.\n\nCeltic-Punk band Flatfoot 56 composed and recorded a song about Ty Cobb as a part of their album \"Odd Boat\" released in March 2017.\n\nSam Crawford and Ty Cobb were teammates for parts of thirteen seasons. They played beside each other in right and center field, and Crawford followed Cobb in the batting order year after year. Despite the physical closeness, the two had a complicated relationship.\n\nInitially, they had a student-teacher relationship. Crawford was an established star when Cobb arrived, and Cobb eagerly sought his advice. In interviews with Al Stump, Cobb told of studying Crawford's base stealing technique and of how Crawford would teach him about pursuing fly balls and throwing out base runners. Cobb told Stump he would always remember Crawford's kindness.\nThe student-teacher relationship gradually changed to one of jealous rivals. Cobb was not popular with his teammates, and as Cobb became the biggest star in baseball, Crawford was unhappy with the preferential treatment given to Cobb. Cobb was allowed to show up late for spring training and was given private quarters on the road – perks not offered to Crawford. The competition between the two was intense. Crawford recalled that, if he went three for four on a day when Cobb went hitless, Cobb would turn red and sometimes walk out of the park with the game still on. When it was reported that Nap Lajoie had won the batting title, Crawford was alleged to have been one of several Tigers who sent a telegram to Lajoie congratulating him on beating Cobb.\n\nIn retirement, Cobb wrote a letter to a writer for \"The Sporting News\" accusing Crawford of not helping in the outfield and of intentionally fouling off balls when Cobb was stealing a base. Crawford learned about the letter in 1946 and accused Cobb of being a \"cheapskate\" who never helped his teammates. He said that Cobb had not been a very good fielder, \"so he blamed me.\" Crawford denied intentionally trying to deprive Cobb of stolen bases, insisting that Cobb had \"dreamed that up\".\n\nWhen asked about the feud, Cobb attributed it to envy. He felt that Crawford was \"a hell of a good player\", but he was \"second best\" on the Tigers and \"hated to be an also ran\". Cobb biographer Richard Bak noted that the two \"only barely tolerated each other\" and agreed with Cobb that Crawford's attitude was driven by Cobb's having stolen Crawford's thunder.\n\nAlthough they may not have spoken to each other, Cobb and Crawford developed an uncanny ability to communicate non-verbally with looks and nods on the base paths. They became one of the most successful double steal pairings in baseball history.\n\nFive years after Jackie Robinson broke the color barrier, Cobb publicly supported blacks and whites playing baseball together, adding, \"Certainly it is okay for them to play. I see no reason in the world why we shouldn't compete with colored athletes as long as they conduct themselves with politeness and gentility. Let me say also that no white man has the right to be less of a gentleman than a colored man; in my book that goes not only for baseball but in all walks of life.\" Using even stronger language, Cobb told the \"Sporting News\" in 1952 that \"the Negro should be accepted and not grudgingly but wholeheartedly.\" In 1953, black newspapers cited his praise for Brooklyn Dodgers' catcher Roy Campanella, who Cobb said was \"among the all-time best catchers\" in baseball. Following Campanella's accident that left him paralyzed, the Dodgers staged a tribute game where tens of thousands of spectators silently held lit matches above their heads. Cobb wrote the Dodgers owner to show appreciation \"for what you did for this fine man\". Cobb also stated that Willie Mays was the \"only player I'd pay money to see\". In the obituaries that ran in the black press following Cobb's death, he was praised for \"[speaking] in favor of racial freedom in baseball\".\n\nSome historians, including Wesley Fricks, Dan Holmes, and Charles Leerhsen have defended Cobb against unfair portrayals of him in popular culture since his death. A noted case is the book written by sportswriter Al Stump in the months after Cobb died in 1961. Stump was later discredited when it became known that he had stolen items belonging to Cobb and also betrayed the access Cobb gave him in his final months. As a result of the movie \"Cobb\" which starred Tommy Lee Jones, there are many myths surrounding Cobb's life, including one that he sharpened his spikes to inflict wounds to opposing players. Leerhsen's book \"Ty Cobb: A Terrible Beauty\" presents primary evidence in contradiction to some of the more negative charges against Cobb.\n\nIn 2013, Cobb's grandson, Herschel Cobb, published a book about his grandfather titled \"Heart of a Tiger, Growing Up With My Grandfather, Ty Cobb\". In this book, Herschel Cobb provides an inside view of his grandfather's kindness and generosity. It also includes an account of teenaged Herschel Cobb confronting Stump leading to a first-hand account of Stump's dishonesty.\n\nBoth official sources, such as Total Baseball, and a number of independent researchers, including John Thorn, have raised questions about Cobb's exact career totals. Hits have been re-estimated at between 4,189 and 4,191, due to a possible double-counted game in 1910. At-bats estimates have ranged as high as 11,437. The numbers shown below are the figures officially recognized on MLB.com.\n\nThe figures on Baseball-Reference.com are as follows. Other private research sites may have different figures. Caught Stealing is not shown comprehensively for Cobb's MLB.com totals, because the stat was not regularly recorded until 1920.\n\n\n\n"}
{"id": "59541", "url": "https://en.wikipedia.org/wiki?curid=59541", "title": "Vajrayana", "text": "Vajrayana\n\nVajrayāna, Mantrayāna, Tantrayāna, Tantric Buddhism and Esoteric Buddhism are the various Buddhist traditions of Tantra and \"Secret Mantra\", which developed in medieval India and spread to Tibet, Bhutan, and East Asia. In Tibet, Buddhist Tantra is termed \"Vajrayāna\", while in China it is generally known as Tángmì (唐密, \"Chinese Tantrayāna\") or \"Mìzōng \"(密宗, \"church of Tantrayāna\"), in Pali it is known as \"Pyitsayãna \" (ပစ္စယာန) , and in Japan it is known as Mikkyō (密教, \"secret teachings\").\n\nVajrayāna is usually translated as Diamond Vehicle or Thunderbolt Vehicle, referring to the Vajra, a mythical weapon which is also used as a ritual implement.\n\nFounded by medieval Indian Mahāsiddhas, Vajrayāna subscribes to the literature known as the Buddhist Tantras. It includes practices that make use of mantras, dharanis, mudras, mandalas and the visualization of deities and Buddhas. According to Vajrayāna scriptures, the term \"Vajrayāna\" refers to one of three vehicles or routes to enlightenment, the other two being the Śrāvakayāna (also known as the Hīnayāna) and Mahāyāna.\n\nTantric Buddhism can be traced back to groups of wandering yogis called Mahasiddhas (great adepts). According to Reynolds (2007), the mahasiddhas date to the medieval period in the Northern Indian Subcontinent (3–13 cen. CE), and used methods that were radically different than those used in Buddhist monasteries including living in forests and caves and practiced meditation in charnel grounds similar to those practiced by Shaiva Kapalika ascetics. These yogic circles came together in tantric feasts (ganachakra) often in sacred sites (\"pitha\") and places (\"ksetra\") which included dancing, singing, sex rites and the ingestion of taboo substances like alcohol, urine, meat, etc. At least two of the Mahasiddhas given in the Buddhist literature are actually names for Shaiva Nath saints (Gorakshanath and Matsyendranath) who practiced Hatha Yoga.\n\nAccording to Schumann, a movement called \"Sahaja-siddhi\" developed in the 8th century in Bengal. It was dominated by long-haired, wandering Mahasiddhas who openly challenged and ridiculed the Buddhist establishment. The Mahasiddhas pursued siddhis, magical powers such as flight and extrasensory perception as well as liberation.\n\nRonald M. Davidson states that,\n\n\"Buddhist siddhas demonstrated the appropriation of an older sociological form—the independent sage/magician, who lived in a liminal zone on the borders between fields and forests. Their rites involved the conjunction of sexual practices and Buddhist mandala visualization with ritual accouterments made from parts of the human body, so that control may be exercised over the forces hindering the natural abilities of the siddha to manipulate the cosmos at will. At their most extreme, siddhas also represented a defensive position within the Buddhist tradition, adopted and sustained for the purpose of aggressive engagement with the medieval culture of public violence. They reinforced their reputations for personal sanctity with rumors of the magical manipulation of various flavors of demonic females (dakini, yaksi, yogini), cemetery ghouls (vetala), and other things that go bump in the night. Operating on the margins of both monasteries and polite society, some adopted the behaviors associated with ghosts (preta, pisaca), not only as a religious praxis but also as an extension of their implied threats.\"\n\nEarlier Mahayana sutras already contained some elements which are emphasized in the Tantras, such as mantras and dharani. The use of mantras and protective verses actually dates back to the Vedic period and the early Buddhist texts like the Pali canon. The practice of visualization of Buddhas such as Amitābha is also seen in pre-tantra texts like the Longer Sukhāvatīvyūha Sūtra. There are other Mahayana sutras which contain \"proto-tantric\" material such as the Gandavyuha sutra and the Dasabhumika which might have served as a central source of visual imagery for Tantric texts.\n\nVajrayana developed a large corpus of texts called the Buddhist Tantras, some of which can be traced to at least the 7th century CE but might be older. The dating of the tantras is \"a difficult, indeed an impossible task\" according to David Snellgrove. Some of the earliest of these texts, kriya tantras such as the Mañjuśrī-mūla-kalpa (6th century), focus on the use of mantras and dharanis for mostly worldly ends including curing illness, controlling the weather and generating wealth.\n\nThe Tattvasaṃgraha Tantra, classed as a \"Yoga tantra\", is one of the first Buddhist tantras which focuses on liberation as opposed to worldly goals and in the Vajrasekhara Tantra the concept of the five Buddha families is developed. Other early tantras include the Mahavairocana Tantra and the Guhyasamāja Tantra. The Guhyasamāja is a Mahayoga class of Tantra, which features new forms of ritual practice considered \"left-hand\" (vamachara) such as the use of taboo substances like alcohol, sexual yoga, and charnel ground practices which evoke wrathful deities. Indeed, Ryujun Tajima divides the tantras into those which were \"a development of Mahayanist thought\" and those \"formed in a rather popular mould toward the end of the eighth century and declining into the esoterism of the left\", mainly, the Yogini tantras and later works associated with wandering antinomian yogis. Later monastic Vajrayana Buddhists reinterpreted and internalized these radically transgressive and taboo practices as metaphors and visualization exercises.\n\nLater tantras such as the Hevajra Tantra and the Chakrasamvara are classed as \"Yogini tantras\" and represent the final form of development of Indian Buddhist tantras in the ninth and tenth centuries. The Kalachakra tantra developed in the 10th century. It is farthest removed from the earlier Buddhist traditions, and incorporates concepts of messianism and astrology not present elsewhere in Buddhist literature.\n\nAccording to Ronald M. Davidson, the rise of Tantric Buddhism was a response to the feudal structure of Indian society in the early medieval period (ca. 500-1200 CE) which saw kings being divinized as manifestations of gods. Likewise, tantric yogis reconfigured their practice through the metaphor of being consecrated (\"abhiśeka\") as the overlord (\"rājādhirāja\") of a mandala palace of divine vassals, an imperial metaphor symbolizing kingly fortresses and their political power.\n\nThe question of the origins of early Vajrayana has been taken up by various scholars. David Seyfort Ruegg has suggested by Buddhist tantra employed various elements of a “pan-Indian religious substrate” which is not specifically Buddhist, Shaiva or Vaishnava.\n\nAccording to Alexis Sanderson, various classes of Vajrayana literature developed as a result of royal courts sponsoring both Buddhism and Saivism. The relationship between the two systems can be seen in texts like the Mañjusrimulakalpa, which later came to be classified under Kriyatantra, and states that mantras taught in the Shaiva, Garuda and Vaishnava tantras will be effective if applied by Buddhists since they were all taught originally by Manjushri.\n\nAlexis Sanderson notes that the Vajrayana \"yogini tantras\" draw extensively from Shaiva Bhairava tantras classified as \"Vidyapitha\". Sanderson's comparison of them shows similarity in \"ritual procedures, style of observance, deities, mantras, mandalas, ritual dress, Kapalika accoutrements, specialized terminology, secret gestures, and secret jargons. There is even direct borrowing of passages from Saiva texts.\" Sanderson gives numerous examples such as the \"Guhyasiddhi\" of Padmavajra, a work associated with the Guhyasamaja tradition, which prescribes acting as a Shaiva guru and initiating members into Saiva Siddhanta scriptures and mandalas. The Samvara tantra texts adopted the pitha list from the Shaiva text \"Tantrasadbhava\", introducing a copying error where a deity was mistaken for a place.\n\nRonald M. Davidson meanwhile, argues that Sanderson's claims for direct influence from Shaiva \"Vidyapitha\" texts are problematic because \"the chronology of the \"Vidyapitha\" tantras is by no means so well established\" and that \"the available evidence suggests that received Saiva tantras come into evidence sometime in the ninth to tenth centuries with their affirmation by scholars like Abhinavagupta (c. 1000 c.e.)\" Davidson also notes that the list of pithas or sacred places \"are certainly not particularly Buddhist, nor are they uniquely Kapalika venues, despite their presence in lists employed by both traditions.\" Davidson further adds that like the Buddhists, the Shaiva tradition was also involved in the appropriation of Hindu and non-Hindu deities, texts and traditions, an example being \"village or tribal divinities like Tumburu\". Davidson adds that Buddhists and Kapalikas as well as other ascetics (possibly Pasupatas) mingled and discussed their paths at various pilgrimage places and that there were conversions between the different groups. Thus he concludes:The Buddhist-Kapalika connection is more complex than a simple process of religious imitation and textual appropriation. There can be no question that the Buddhist tantras were heavily influenced by Kapalika and other Saiva movements, but the influence was apparently mutual. Perhaps a more nuanced model would be that the various lines of transmission were locally flourishing and that in some areas they interacted, while in others they maintained concerted hostility. Thus the influence was both sustained and reciprocal, even in those places where Buddhist and Kapalika siddhas were in extreme antagonism.Davidson also argues for the influence of non-brahmanical and outcaste tribal religions and their feminine deities (Parnasabari and Janguli).\n\nAccording to Louis de La Vallée-Poussin and Alex Wayman, the view of the Vajrayana is based on Mahayana Buddhist philosophy, mainly the Madhyamaka and Yogacara schools. The major difference seen by Vajrayana thinkers is Tantra's superiority due to being a faster vehicle to liberation containing many skillful methods (upaya) of tantric ritual.\n\nThe importance of the theory of emptiness is central to the Tantric view and practice. Buddhist emptiness sees the world as being fluid, without an ontological foundation or inherent existence but ultimately a fabric of constructions. Because of this, tantric practice such as self-visualization as the deity is seen as being no less real than everyday reality, but a process of transforming reality itself, including the practitioner's identity as the deity. As Stephan Beyer notes, \"In a universe where all events dissolve ontologically into Emptiness, the touching of Emptiness in the ritual is the re-creation of the world in actuality\".\n\nThe doctrine of Buddha-nature, as outlined in the Ratnagotravibhāga of Asanga, was also an important theory which became the basis for Tantric views. As explained by the Tantric commentator Lilavajra, this \"intrinsic secret (behind) diverse manifestation\" is the utmost secret and aim of Tantra. According to Alex Wayman this \"Buddha embryo\" (\"tathāgatagarbha\") is a \"non-dual, self-originated Wisdom (jnana), an effortless fount of good qualities\" that resides in the mindstream but is \"obscured by discursive thought.\" This doctrine is often associated with the idea of the inherent or natural luminosity (Skt: \"prakṛti-prabhāsvara-citta\", T. \"’od gsal gyi sems\") or purity of the mind (\"prakrti-parisuddha\"). \n\nAnother fundamental theory of Tantric practice is that of transformation. Negative mental factors such as desire, hatred, greed, pride are not rejected as in non Tantric Buddhism, but are used as part of the path. As noted by French Indologist Madeleine Biardeau, tantric doctrine is \"an attempt to place kama, desire, in every meaning of the word, in the service of liberation.\" This view is outlined in the following quote from the Hevajra tantra:\n\nThose things by which evil men are bound, others turn into means and gain thereby release from the bonds of existence. By passion the world is bound, by passion too it is released, but by heretical Buddhists this practice of reversals is not known.\n\nThe Hevajra further states that \"One knowing the nature of poison may dispel poison with poison.\" As Snellgrove notes, this idea is already present in Asanga's Mahayana-sutra-alamkara-karika and therefore it is possible that he was aware of Tantric techniques, including sexual yoga.\n\nAccording to Buddhist Tantra there is no strict separation of the profane or samsara and the sacred or nirvana, rather they exist in a continuum. All individuals are seen as containing the seed of enlightenment within, which is covered over by defilements. Douglas Duckworth notes that Vajrayana sees Buddhahood not as something outside or an event in the future, but as immanently present.\n\nIndian Tantric Buddhist philosophers such as Buddhaguhya, Vimalamitra,\nRatnākaraśānti and Abhayakaragupta continued the tradition of Buddhist philosophy and adapted it to their commentaries on the major Tantras. Abhayakaragupta’s \"Vajravali\" is a key source in the theory and practice of tantric rituals. After monks such as Vajrabodhi and Śubhakarasiṃha brought Tantra to Tang China (716 to 720), tantric philosophy continued to be developed in Chinese and Japanese by thinkers such as Yi Xing and Kūkai.\n\nLikewise in Tibet, Sakya Pandita (1182-28 - 1251), as well as later thinkers like Longchenpa (1308–1364) expanded on these philosophies in their Tantric commentaries and treatises. The status of the tantric view continued to be debated in medieval Tibet. Tibetan Buddhist Rongzom Chokyi Zangpo (1012–1088) held that the views of sutra such as Madhyamaka were inferior to that of tantra, as Koppl notes:\n\nTsongkhapa (1357–1419) on the other hand, held that there is no difference between Vajrayana and other forms of Mahayana in terms of prajnaparamita (perfection of insight) itself, only that Vajrayana is a method which works faster.\n\nVarious classifications are possible when distinguishing Vajrayana from the other Buddhist traditions. Vajrayana can be seen as a third \"yana\", next to Hinayana and Mahayana. Vajrayana can be distinguished from the Sutrayana. The \"Sutrayana\" is the method of perfecting good qualities, where the \"Vajrayāna\" is the method of taking the intended outcome of Buddhahood as the path. Vajrayana, belonging to the mantrayana, can also be distinguished from the paramitayana. According to this schema, Indian Mahayana revealed two vehicles (\"yana\") or methods for attaining enlightenment: the method\nof the perfections (\"Paramitayana\") and the method of mantra (\"Mantrayana\"). The \"Paramitayana\" consists of the six or ten \"paramitas\", of which the scriptures say that it takes three incalculable aeons to lead one to Buddhahood. The tantra literature, however, claims that the \"Mantrayana\" leads one to Buddhahood in a single lifetime. According to the literature, the mantra is an easy path without the difficulties innate to the \"Paramitayana\". \"Mantrayana\" is sometimes portrayed as a method for those of inferior abilities. However the practitioner of the mantra still has to adhere to the vows of the Bodhisattva.\n\nThe goal of spiritual practice within the Mahayana and Vajrayana traditions is to become a \"Sammāsambuddha\" (fully awakened Buddha), those on this path are termed Bodhisattvas. As with the Mahayana, motivation is a vital component of Vajrayana practice. The Bodhisattva-path is an integral part of the Vajrayana, which teaches that all practices are to be undertaken with the motivation to achieve Buddhahood for the benefit of all sentient beings.\n\nIn the Sutrayana practice, a path of Mahayana, the \"path of the cause\" is taken, whereby a practitioner starts with his or her potential Buddha-nature and nurtures it to produce the fruit of Buddhahood. In the Vajrayana the \"path of the fruit\" is taken whereby the practitioner takes his or her innate Buddha-nature as the means of practice. The premise is that since we innately have an enlightened mind, practicing seeing the world in terms of ultimate truth can help us to attain our full Buddha-nature. Experiencing ultimate truth is said to be the purpose of all the various tantric techniques practiced in the Vajrayana.\n\nVajrayana Buddhism is esoteric in the sense that the transmission of certain teachings only occurs directly from teacher to student during an empowerment (\"abhiṣeka\") and their practice requires initiation in a ritual space containing the mandala of the deity. Many techniques are also commonly said to be secret, but some Vajrayana teachers have responded that secrecy itself is not important and only a side-effect of the reality that the techniques have no validity outside the teacher-student lineage. In order to engage in Vajrayana practice, a student should have received such an initiation or permission:\nThe secrecy of teachings was often protected through the use of allusive, indirect, symbolic and metaphorical language (twilight language) which required interpretation and guidance from a teacher. The teachings may also be considered \"self-secret\", meaning that even if they were to be told directly to a person, that person would not necessarily understand the teachings without proper context. In this way the teachings are \"secret\" to the minds of those who are not following the path with more than a simple sense of curiosity.\n\nBecause of their role in giving access to the practices and guiding the student through them, the role of the Guru, Lama or Vajracharya is indispensable in Vajrayana.\n\nSome Vajrayana rituals include use of certain taboo substances, such as blood, semen, alcohol and urine, as ritual offerings and sacraments, though these are often replaced with less taboo substances in their place such as yogurt. Tantric feasts and initiations sometimes employed substances like human flesh as noted by Kahha’s \"Yogaratnamala\". The use of these substances is related to the non-dual (\"advaya\") nature of Buddhahood. Since the ultimate state is in some sense non-dual, a practitioner can approach that state by \"transcending attachment to dual categories such as pure and impure, permitted and forbidden\". As the Guhyasamaja Tantra states \"the wise man who does not discriminate achieves buddhahood\".\n\nVajrayana rituals also include sexual yoga, union with a physical consort as part of advanced practices. Some tantras go further, the\nHevajra Tantra states ‘You should kill living beings, speak lying words, take what is not given, consort with the women of others’. While some of these statements were taken literally as part of ritual practice, others such as killing was interpreted in a metaphorical sense. In the Hevajra, \"killing\" is defined as developing concentration by killing the life-breath of discursive thoughts. Likewise, while actual sexual union with a physical consort is practiced, it is also common to use a visualized mental consort.\n\nAlex Wayman points out that the symbolic meaning of tantric sexuality is ultimately rooted in bodhicitta and the bodhisattva's quest for enlightenment is likened to a lover seeking union with the mind of the Buddha. Judith Simmer-Brown notes the importance of the psycho-physical experiences arising in sexual yoga, termed \"great bliss\" (Mahasukha): \"Bliss melts the conceptual mind, heightens sensory awareness, and opens the practitioner to the naked experience of the nature of mind.\" This tantric experience is not the same as ordinary self gratifying sexual passion since it relies on tantric meditative methods using the subtle body and visualizations as well as the motivation for enlightenment. As the Hevajra tantra says:\n\n\"This practice [of sexual union with a consort] is not taught for the sake of enjoyment, but for the examination of one's own thought, whether the mind is steady or waving.\"\n\nFeminine deities and forces are also increasingly prominent in Vajrayana. In the Yogini tantras in particular, women and female figures are given high status as the embodiment of female deities such as the wild and nude Vajrayogini. The \"Candamaharosana Tantra\" states:\n\nIn India, there is evidence to show that women participated in tantric practice alongside men and were also teachers, adepts and authors of tantric texts.\n\nPractitioners of the Vajrayana need to abide by various tantric vows or \"samaya\" of behaviour. These are extensions of the rules of the Prātimokṣa and Bodhisattva vows for the lower levels of tantra, and are taken during initiations into the empowerment for a particular Anuttarayoga Tantra. The special tantric vows vary depending on the specific mandala practice for which the initiation is received, and also depending on the level of initiation. Ngagpas of the Nyingma school keep a special non-celibate ordination.\n\nA tantric guru, or teacher, is expected to keep his or her \"samaya\" vows in the same way as his students. Proper conduct is considered especially necessary for a qualified Vajrayana guru. For example, the \"Ornament for the Essence\" of Manjushrikirti states:\n\nWhile Vajrayana includes all of the traditional practices used in Mahayana Buddhism such as samatha and vipassana meditation and the paramitas, it also includes a number of unique practices or \"skillful means\" (Sanskrit: \"upaya\") which are seen as more advanced and effective. Vajrayana is a system of lineages, whereby those who successfully receive an empowerment or sometimes called initiation (permission to practice) are seen to share in the mindstream of the realisation of a particular skillful means of the \"vajra\" Master. Vajrayana teaches that the Vajrayana techniques provide an accelerated path to enlightenment which is faster than other paths.\n\nA central feature of tantric practice is the use of mantras, syllables, words or a collection of syllables understood to have special powers and hence is a 'performative utterance' used for a variety of ritual ends. In tantric meditation, mantric seed syllables are used during the ritual evocation of deities which are said to arise out of the uttered and visualized mantric syllables. After the deity has been established, heart mantras are visualized as part of the contemplation in different points of the deity's body.\n\nAccording to Alex Wayman, Buddhist esotericism is centered on what is known as \"the three mysteries\" or \"secrets\": the tantric adept affiliates his body, speech, and mind with the body, speech, and mind of the Buddha through mudra, mantras and samadhi respectively. Padmavajra (c 7th century) explains in his \"Tantrarthavatara\" Commentary, the secret Body, Speech, and Mind of the Tathagatas are:\n\nThe fundamental, defining practice of Buddhist Tantra is “deity yoga” (\"devatayoga\"), meditation on a yidam, or personal deity, which involves the recitation of mantras, prayers and visualization of the deity along with the associated mandala of the deity's Pure Land, with consorts and attendants. According to Tsongkhapa, deity yoga is what separates Tantra from sutra practice.\n\nA key element of this practice involves the dissolution of the profane world and identification with a sacred reality. Because Tantra makes use of a \"similitude\" of the resultant state of Buddhahood as the path, it is known as the effect vehicle or result vehicle (\"phalayana\") which \"brings the effect to the path\".\n\nIn the Highest Yoga Tantras and in the Inner Tantras this is usually done in two stages, the generation stage (\"utpattikrama\") and the completion stage (\"nispannakrama\"). In the generation stage, one dissolves oneself in emptiness and meditates on the yidam, resulting in identification with this yidam. In the completion stage, the visualization of and identification with the yidam is dissolved in the realization of luminous emptiness. Ratnakarasanti describes the generation stage cultivation practice thus:\n\n[A]ll phenomenal appearance having arisen as mind, this very mind is [understood to be] produced by a mistake (\"bhrāntyā\"), i.e. the appearance of an object where there is no object to be grasped; ascertaining that this is like a dream, in order to abandon this mistake, all appearances of objects that are blue and yellow and so on are abandoned or destroyed (\"parihṛ-\"); then, the appearance of the world (\"viśvapratibhāsa\") that is ascertained to be oneself (\"ātmaniścitta\") is seen to be like the stainless sky on an autumn day at noon: appearanceless, unending sheer luminosity.\n\nThis dissolution into emptiness is then followed by the visualization of the deity and re-emergence of the yogi as the deity. During the process of deity visualization, the deity is to be imaged as not solid or tangible, as \"empty yet apparent\", with the character of a mirage or a rainbow. This visualization is to be combined with \"divine pride\", which is \"the thought that one is oneself the deity being visualized.\" Divine pride is different from common pride because it is based on compassion for others and on an understanding of emptiness.\n\nSome practices associated with the completion stage make use of an energetic system of human psycho-physiology composed of what is termed as energy channels (rtsa), winds or currents (rlung), and drops or charged particles (thig le). These subtle body energies as seen as \"mounts\" for consciousness, the physical component of awareness. They are said to converge at certain points along the spinal column called chakras. Some practices which make use of this system include Trul khor and Tummo.\n\nAnother form of Vajrayana practice are certain meditative techniques associated with Mahamudra and Dzogchen often termed \"formless practices\". These techniques do not rely on yidam visualization but on direct Pointing-out instruction from a master and are seen as the most advanced forms.\n\nIn Tibetan Buddhism, advanced practices like deity yoga and the formless practices are usually preceded by or coupled with \"preliminary practices\" called ngondro which includes prostrations and recitations of the 100 syllable mantra.\n\nAnother distinctive feature of Tantric Buddhism is its unique rituals, which are used as a substitute or alternative for the earlier abstract meditations. They include death rituals (see \"phowa\"), tantric feasts (ganachakra) and Homa fire ritual, common in East Asian Tantric Buddhism.\n\nOther unique practices in Tantric Buddhism include Dream yoga, the yoga of the intermediate state (at death) or Bardo and Chöd, in which the yogi ceremonially offers their body to be eaten by tantric deities.\n\nThe Vajrayana uses a rich variety of symbols, terms and images which have multiple meanings according to a complex system of analogical thinking. In Vajrayana, symbols and terms are multi-valent, reflecting the microcosm and the macrocosm as in the phrase \"As without, so within\" (\"yatha bahyam tatha ’dhyatmam iti\") from Abhayakaragupta’s \"Nispannayogavali\".\n\nThe Sanskrit term \"vajra\" denoted the thunderbolt, a legendary weapon and divine attribute that was made from an adamantine, or indestructible, substance and which could therefore pierce and penetrate any obstacle or obfuscation. It is the weapon of choice of Indra, the King of the Devas. As a secondary meaning, \"vajra\" symbolizes the ultimate nature of things which is described in the tantras as translucent, pure and radiant, but also indestructible and indivisible. It is also symbolic of the power of tantric methods to achieve its goals.\n\nA vajra is also a scepter-like ritual object ( \"dorje\"), which has a sphere (and sometimes a gankyil) at its centre, and a variable number of spokes, 3, 5 or 9 at each end (depending on the sadhana), enfolding either end of the rod. The vajra is often traditionally employed in tantric rituals in combination with the bell or ghanta; symbolically, the vajra may represent method as well as great bliss and the bell stands for wisdom, specifically the wisdom realizing emptiness. The union of the two sets of spokes at the center of the wheel is said to symbolize the unity of wisdom (prajña) and\ncompassion (karuna) as well as the sexual union of male and female deities.\n\nRepresentations of the deity, such as statues (\"murti\"), paintings (\"thangka\"), or mandala, are often employed as an aid to visualization, in Deity yoga. The use of visual aids, particularly microcosmic/macrocosmic diagrams, known as \"mandalas\", is another unique feature of Buddhist Tantra. Mandalas are symbolic depictions of the sacred space of the awakened Buddhas and Bodhisattvas as well as of the inner workings of the human person. The macrocosmic symbolism of the mandala then, also represents the forces of the human body. The explanatory tantra of the Guhyasamaja tantra, the \"Vajramala\", states: \"The body becomes a palace, the hallowed basis of all the Buddhas.\"\n\nMandalas are also sacred enclosures, sacred architecture that house and contain the uncontainable essence of a central deity or \"yidam\" and their retinue. In the book \"The World of Tibetan Buddhism\", the Dalai Lama describes mandalas thus: \"This is the celestial mansion, the pure residence of the deity.\" The Five Tathagatas or 'Five Buddhas', along with the figure of the Adi-Buddha, are central to many Vajrayana mandalas as they represent the \"five wisdoms\", which are the five primary aspects of primordial wisdom or Buddha-nature.\n\nAll ritual in Vajrayana practice can be seen as aiding in this process of visualization and identification. The practitioner can use various hand implements such as a \"vajra\", bell, hand-drum (\"damaru\") or a ritual dagger (\"phurba\"), but also ritual hand gestures (\"mudras\") can be made, special chanting techniques can be used, and in elaborate offering rituals or initiations, many more ritual implements and tools are used, each with an elaborate symbolic meaning to create a special environment for practice. Vajrayana has thus become a major inspiration in traditional Tibetan art.\n\nThe Vajrayana tradition has developed an extended body of texts:\nVajrayana texts exhibit a wide range of literary characteristics—usually a mix of verse and prose, almost always in a Sanskrit that \"transgresses frequently against classical norms of grammar and usage,\" although also occasionally in various Middle Indic dialects or elegant classical Sanskrit.\n\nThe Dunhuang manuscripts also contain Tibetan Tantric manuscripts. Dalton and Schaik (2007, revised) provide an excellent online catalogue listing 350 Tibetan Tantric Manuscripts] from Dunhuang in the Stein Collection of the British Library which is currently fully accessible online in discrete digitized manuscripts. With the Wylie transcription of the manuscripts they are to be made discoverable online in the future. These 350 texts are just a small portion of the vast cache of the Dunhuang manuscripts.\n\nAlthough there is historical evidence for Vajrayana Buddhism in Southeast Asia and elsewhere (see History of Vajrayana above), today the Vajrayana exists primarily in the form of the two major traditions of Tibetan Buddhism and Japanese Esoteric Buddhism in Japan known as \"Shingon\" (literally \"True Speech\", i.e. \"mantra\"), with a handful of minor subschools utilising lesser amounts of esoteric or tantric materials.\n\nThe distinction between traditions is not always rigid. For example, the tantra sections of the Tibetan Buddhist canon of texts sometimes include material not usually thought of as tantric outside the Tibetan Buddhist tradition, such as the \"Heart Sutra\" and even versions of some material found in the \"Pali Canon\".\n\nVajrayana Buddhism was established in Tibet in the 8th century when Śāntarakṣita was brought to Tibet from India at the instigation of the Dharma King Trisong Detsen, some time before 767. Tibetan Buddhism reflects the later stages of Indian tantric Buddhist developments, including the Yogini tantras, translated into the Tibetan language. It also includes native Tibetan developments, such as the tulku system, new sadhana texts, Tibetan scholastic works, Dzogchen literature and Terma literature.\n\nThe Tibetan Buddhist schools, based on the lineages and textual traditions of the Kangyur and Tengyur of Tibet, are found in Tibet, Bhutan, northern India, Nepal, southwestern and northern China, Mongolia and various constituent republics of Russia that are adjacent to the area, such as Amur Oblast, Buryatia, Chita Oblast, the Tuva Republic and Khabarovsk Krai. Tibetan Buddhism is also the main religion in Kalmykia.\n\nNewar Buddhism is practiced by Newars in Nepal. It is the only form of Vajrayana Buddhism in which the scriptures are written in Sanskrit and this tradition has preserved many Vajrayana texts in this language. Its priests do not follow celibacy and are called \"vajracharya\" (literally \"diamond-thunderbolt carriers\").\n\nTantric Theravada or \"Esoteric Southern Buddhism\" is a term for esoteric forms of Buddhism from Southeast Asia, where Theravada Buddhism is dominant. The monks of the Sri Lankan, Abhayagiri vihara once practiced forms of tantra which were popular in the island. Another tradition of this type was Ari Buddhism, which was common in Burma. The Tantric Buddhist 'Yogāvacara' tradition was a major Buddhist tradition in Cambodia, Laos and Thailand well into the modern era. This form of Buddhism declined after the rise of Southeast Asian Buddhist modernism.\n\nIndonesian Esoteric Buddhism refers to the traditions of Esoteric Buddhism found in the Indonesian islands of Java and Sumatra before the rise and dominance of Islam in the region (13-16th centuries). The Buddhist empire of Srivijaya (650 CE–1377 CE) was a major center of Esoteric Buddhist learning which drew Chinese monks such as Yijing and Indian scholars like Atiśa. The temple complex at Borobudur in central Java, built by the Shailendra dynasty also reflects strong Tantric or at least proto-tantric influences, particularly of the cult of Vairocana.\n\nAlthough no written record exists about early Buddhism in the Philippines, the recent archaeological discoveries and the few scant references in the other nations historical records can tell, however, about the existence of Buddhism from the 9th century onward in the islands. The Philippines’s archaeological finds include a few of Buddhist artifacts, most of them dated to the 9th century. The artifacts reflect the iconography of the Srivijaya’s Vajrayana Buddhism and its influences on the Philippines’s early states. The artifacts distinct features point to their production in the islands and hint at the artisans or goldsmiths knowledge of Buddhist culture and Buddhist literature because the artisans have made these unique works of Buddhist art. The artifacts imply also the presence of Buddhist believers in the places where these artifacts turned up. These places extended from the Agusan-Surigao area in Mindanao island to Cebu, Palawan, and Luzon islands.\n\nHence, Vajrayana Buddhism must have spread far and wide throughout the archipelago. And Vajrayana Buddhism must have become the religion of the majority of the inhabitants in the islands. The early states trade contacts with the neighboring empires and polities like in Sumatra, Srivijaya and Majapahit empire in Java long before or in the 9th century must have served as the conduit for introducing Vajrayana Buddhism to the islands.\n\nEsoteric and Tantric teachings followed the same route into northern China as Buddhism itself, arriving via the Silk Road and Southeast Asian Maritime trade routes sometime during the first half of the 7th century, during the Tang dynasty and received sanction from the emperors of the Tang dynasty. During this time, three great masters came from India to China: Śubhakarasiṃha, Vajrabodhi, and Amoghavajra who translated key texts and founded the \"Zhenyan\" (真言, \"true word\", \"mantra\") tradition. \"Zhenyan\" was also brought to Japan as Shingon during this period. This tradition focused on tantras like the Mahavairocana tantra, and unlike Tibetan Buddhism, does not employ the antinomian and radical tantrism of the Anuttarayoga Tantras.\n\nThe prestige of this tradition influenced other schools of Chinese Buddhism such as Chan and Tiantai to adopt esoteric practices.\n\nDuring the Yuan dynasty, the Mongol emperors made Tibetan Buddhism the official religion of China, and Tibetan lamas were given patronage at the court. Imperial support of Tibetan Vajrayana continued into the Ming and Qing dynasties.\n\nAnother form of esoteric Buddhism in China is Azhaliism, which is practiced among the Bai people of China.\n\nEsoteric Buddhist practices (known as \"milgyo\", 密教) and texts arrived in Korea during the initial introduction of Buddhism to the region in 372 CE. Esoteric Buddhism was supported by the royalty of both Unified Silla (668-935) and Goryeo Dynasty (918-1392). During the Goryeo Dynasty esoteric practices were common within large sects like the Seon school, and the Hwaeom school as well as smaller esoteric sects like the Sinin (\"mudra\") and Ch'ongji (\"Dharani\") schools. During the era of the Mongol occupation (1251-1350s), Tibetan Buddhism also existed in Korea though it never gained a foothold there.\n\nDuring the Joseon dynasty, Esoteric Buddhist schools were forced to merge with the Son and Kyo schools, becoming the ritual specialists. With the decline of Buddhism in Korea, Esoteric Buddhism mostly died out, save for a few traces in the rituals of the Jogye Order and Taego Order.\n\nThere are two Esoteric Buddhist schools in modern Korea: the Chinŏn (眞言) and the Jingak Order (眞\n覺). According to Henrik H. Sørensen, \"they have absolutely no historical link with the Korean Buddhist tradition per se but are late constructs based in large measures on Japanese Shingon Buddhism.\"\n\nThe Shingon school is found in Japan and includes practices, known in Japan as \"Mikkyō\" (\"Esoteric (or Mystery) Teaching\"), which are similar in concept to those in Vajrayana Buddhism. The lineage for Shingon Buddhism differs from that of Tibetan Vajrayana, having emerged from India during the 9th-11th centuries in the Pala Dynasty and Central Asia (via China) and is based on earlier versions of the Indian texts than the Tibetan lineage. Shingon shares material with Tibetan Buddhism–-such as the esoteric sutras (called Tantras in Tibetan Buddhism) and mandalas – but the actual practices are not related. The primary texts of Shingon Buddhism are the \"Mahavairocana Sutra\" and \"Vajrasekhara Sutra\". The founder of Shingon Buddhism was Kukai, a Japanese monk who studied in China in the 9th century during the Tang dynasty and brought back Vajrayana scriptures, techniques and mandalas then popular in China. The school mostly died out or was merged into other schools in China towards the end of the Tang dynasty but flourished in Japan. Shingon is one of the few remaining branches of Buddhism in the world that continues to use the \"siddham\" script of the Sanskrit language.\n\nAlthough the Tendai school in China and Japan does employ some esoteric practices, these rituals came to be considered of equal importance with the exoteric teachings of the \"Lotus Sutra\". By chanting mantras, maintaining mudras, or practicing certain forms of meditation, Tendai maintains that one is able to understand sense experiences as taught by the Buddha, have faith that one is innately an enlightened being, and that one can attain enlightenment within the current lifetime.\n\nShugendō was founded in 7th-century Japan by the ascetic En no Gyōja, based on the \"Queen's Peacocks Sutra\". With its origins in the solitary \"hijiri\" back in the 7th century, Shugendō evolved as a sort of amalgamation between Esoteric Buddhism, Shinto and several other religious influences including Taoism. Buddhism and Shinto were amalgamated in the \"shinbutsu shūgō\", and Kūkai's syncretic religion held wide sway up until the end of the Edo period, coexisting with Shinto elements within Shugendō\n\nIn 1613 during the Edo period, the Tokugawa Shogunate issued a regulation obliging Shugendō temples to belong to either Shingon or Tendai temples. During the Meiji Restoration, when Shinto was declared an independent state religion separate from Buddhism, Shugendō was banned as a superstition not fit for a new, enlightened Japan. Some Shugendō temples converted themselves into various officially approved Shintō denominations. In modern times, Shugendō is practiced mainly by Tendai and Shingon sects, retaining an influence on modern Japanese religion and culture.\n\nSerious Vajrayana academic study in the Western world is in early stages due to the following obstacles:\n\nBuddhist tantric practice are categorized as secret practice; this is to avoid misinformed people from harmfully misusing the practices. A method to keep this secrecy is that tantric initiation is required from a master before any instructions can be received about the actual practice. During the initiation procedure in the highest class of tantra (such as the Kalachakra), students must take the tantric vows which commit them to such secrecy. \"Explaining general tantra theory in a scholarly manner, not sufficient for practice, is likewise not a root downfall. Nevertheless, it weakens the effectiveness of our tantric practice.\" \n\nThe terminology associated with Vajrayana Buddhism can be confusing. Most of the terms originated in the Sanskrit language of tantric Indian Buddhism and may have passed through other cultures, notably those of Japan and Tibet, before translation for the modern reader. Further complications arise as seemingly equivalent terms can have subtle variations in use and meaning according to context, the time and place of use. A third problem is that the Vajrayana texts employ the tantric tradition of twilight language, a means of instruction that is deliberately coded. These obscure teaching methods relying on symbolism as well as synonym, metaphor and word association add to the difficulties faced by those attempting to understand Vajrayana Buddhism:\nThe term Tantric Buddhism was not one originally used by those who practiced it. As scholar Isabelle Onians explains:\n\n\n \n"}
{"id": "13416479", "url": "https://en.wikipedia.org/wiki?curid=13416479", "title": "Visiting friends and relatives", "text": "Visiting friends and relatives\n\n\"Visiting Friends and Relatives\" (VFR tourism / VFR travel) is a substantial form of travel worldwide. Scholarly interest into VFR travel developed in the mid 1990s after Jackson’s (1990) seminal article suggested that this type of tourism was much larger than official estimates suggested. Most official data collections differentiate travel as being for either leisure, business, or VFR purposes. In many destinations, VFR is the largest or second-largest form of travel by size. Definitions have been traditionally lacking due to the complexities involved in understanding VFR travel. VFR travellers can state a VFR purpose of visit but that does not necessarily mean that they are staying with those friends / relatives. Similarly, they may be accommodated by friends / relatives although have a different purpose of visit. \n\nOne definition put forward has been \"VFR travel is a form of travel involving a visit whereby either (or both) the purpose of the trip or the type of accommodation involves visiting friends and / or relatives\" This has subsequently been developed into a VFR definitional model to describe it visually.\n\nVFR expenditures tend to be quite broad; spread widely throughout the community rather than confined to the narrow tourism sector (McKercher, 1995). In some expenditure categories, VFR travellers have been shown to outspend non-VFR travellers (Seaton & Palmer, 1997; Morrison, Verginis et al., 2000) \n"}
{"id": "51709007", "url": "https://en.wikipedia.org/wiki?curid=51709007", "title": "Wiley Jones", "text": "Wiley Jones\n\nWalter \"Wiley\" Jones (July 14, 1841 – December 7, 1904) was a businessman in Pine Bluff, Arkansas, who was one of the wealthiest African-Americans in his state. He owned the first streetcar company in Pine Bluff and a park in the city which housed the fairgrounds. A devotee of horse racing, he owned stables and a race track on the park grounds. He also owned a saloon. He was active in civic affairs and was an advocate for civil rights.\n\nWalter \"Wiley\" Jones was born in Madison County in northeastern Georgia, on July 14, 1848. His parents were George Jones, a white planter, and Jones' slave, Anne, who had six children by George Jones: Matthew (who superintended the construction of the Wiley Jones Street Car Line), Thomas, Julia (wife of Ben Reed), Wiley, Taylor, and James (who managed many of Wiley's businesses). Wiley received his nickname because of his mischievous nature. At the age of five, he moved to Arkansas with his master and more than forty fellow slaves. They settled on the Governor Byrd plantation. George Jones died in 1858. Anne was called his wife in an 1889 biography of Jones, and she believed that George had promised to free herself and her children upon his death, but no manumission papers were found, and the family was kept as slaves and sold by the estate administer, Peter Finerty, to James Yell, a lawyer and planter in Pine Bluff. Jones worked as a houseboy and carriage driver for his new master. When Jones was ten, he was given to Yell's only son, Fountain Pitts Yell, on the occasion of Pitts Yell's marriage. Pitts was a state representative from 1860 to 1861. During the American Civil War, James Yell became a Major General of the Arkansas State Militia, and Pitts became a colonel in Company S of the 26th Arkansas Infantry Regiment in the Confederate Army. James Yell's was transferred to the Confederate States Army in the summer of 1861, and James left the service and moved to Texas. Jones served for Pitts during the war until Pitts' death in 1864 at the Battle of Pleasant Hill in Louisiana. Jones then joined James Yell and his family in Waco, Texas. There, he served as a porter in a mercantile house for one year. He was then hired to drive a wagon carrying cotton on a route along the Brazos River to San Antonio.\n\nAfter the war, Jones returned to Monticello, Arkansas, with the Yell family. From there, he moved to Pine Bluff to work first as a mule driver and then as the business manager of the Yell plantation. In 1868, he began to work as a barber in the shop of Ben Reed, his brother-in-law, and continued in that pursuit until 1881. He then began dealing tobacco, cigars, and other goods. His brother, James, worked as his plantation business manager. In 1884, Jones got the better of state legislator and pastor William Young in a fist fight in front of Jones's saloon as a result of Young giving a speech which Jones did not like.\n\nIn August 1886, Jones secured the charter for the first streetcar line in Pine Bluff, Arkansas. He had one and one-fourth mile completed and the first car running byn October 19, 1886, coinciding with the first day of the annual fair of the Colored Industrial and Fair Association, an organization of which he was treasurer. He owned the fair grounds located on a 55-acre park he owned near main street and which was called Wiley Jones Park. His stables included one stallion, \"Executor\" that was of particular note, and later his colt, \"Trickster\". He also owned a number of mares and a herd of Durham and Holstein cattle. In 1901, his thoroughbred pace, \"Billy H\", broke a track record at a race in Windsor, Canada. In 1890, he purchased the second line in Pine Bluff, known as the Citizen's line, from H. P. Bradford for $125,000. In 1894, Jones sold his streetcar company to another streetcar syndicate. In 1901, Jones founded the Southern Mercantile Company, making his longtime friend Fred Havis president and his brother, James, manager.\n\nJones was an active Republican and was a delegate to the 1880 Republican National Convention in Chicago, which nominated the James Garfield-Chester Arthur ticket. He opened a manual training school, the Colored Industrial Institute of Pine Bluff in about 1888. He played an important role in promoting blacks to office in Pine Bluff and in Jefferson County. He was an organizer of the Arkansas Colored Men's Association. In 1893, he was a delegate to the annual convention of the Colored Men's National Protective Association in Chicago. He was an active Mason and along with professor J. C. Corbin played an important role in the building of a Masonic Temple in Pine Bluff. Jones sold land at 12th Avenue and Main to the Masons to be used to build the temple, but the building was instead built at 4th and State.\n\nHe did not learn to read and write until he was an adult. He was a Christian but not a part of any denomination or church. He did not marry. He died in Pine Bluff on December 7, 1904 of Bright's disease. The funeral was held at the new black Masonic Temple. He is interred at the black cemetery which he had founded.\n"}
