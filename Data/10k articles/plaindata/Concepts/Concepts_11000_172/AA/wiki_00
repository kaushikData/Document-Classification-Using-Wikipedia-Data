{"id": "21350938", "url": "https://en.wikipedia.org/wiki?curid=21350938", "title": "Absolute (philosophy)", "text": "Absolute (philosophy)\n\nIn philosophy, the concept of The Absolute, also known as The (Unconditioned) Ultimate, The Wholly Other, The Supreme Being, The Absolute/Ultimate Reality, and other names, is the thing, being, entity, power, force, reality, presence, law, principle, etc. that possesses maximal ontological status, existential ranking, existential greatness, or existentiality. In layman's terms, this is the one that is, in one way or another, the greatest, truest, or most real being.\n\nThere are many conceptions of The Absolute in various fields and subjects, such as philosophy, religion, spiritual traditions, mathematics, and even natural science. The nature of these conceptions can range from \"merely\" encompassing all physical existence, nature, or reality, to being completely unconditioned existentially, transcending all concepts, notions, and types, kinds, and categories of being.\n\nThe Absolute is often thought of as causing to come into being manifestations that interact with lower or lesser forms of being. This is either done passively, through emanations, or actively, through avatars and incarnations. These existential manifestations, which themselves can possess transcendent attributes, only contain minuscule or infinitesimal portions of the true essence of The Absolute.\n\nThe term itself was not in use in ancient or medieval philosophy, but closely related to the description of God as \"Actus purus\" (Pure Actuality) in scholasticism. It was introduced in modern philosophy, notably by Hegel, for \"the sum of all being, actual and potential\".\nThe term has since also been adopted in perennial philosophy.\n\nThere are three general ways of conceiving the Absolute. The Absolute might be (1) the first and greatest being, (2) not a being at all but the \"ground\" of being, or (3) both the ground of being and a being.\n\nIn conception one the Absolute is the most true and intelligible reality. It can be spoken of and known. For example, Georg Wilhelm Friedrich Hegel's Absolute Spirit is the most true reality. It is thinkable, speakable, and exists in the objective world by comprehending everything, including people, states, and world history.\n\nIn conception two the Absolute might be conceived of as utterly outside of all other reality and hence unintelligible. It cannot be known or spoken about. Plato's Socrates says that \"The Form of the Good\" is \"beyond being\", implying that it is even beyond thought, language, and normal categories of existence.\n\nSt. John of the Cross says:\nIn conception three the Absolute is seen as transcending duality and distinction. This concept of a fundamental reality that transcends or includes all other reality is usually (but not always) associated with divinity. While this conception initially seems contradictory, it has been highly influential. One way to understand this third conception is to consider the \"Tao Te Ching\".\n\nThese opening lines distinguish between two Taos. One is the \"eternal Tao\" (which cannot be named or explained) and the other \"Tao\" seems to exist in space and time (and can be named and explained). The eternal Tao is beyond existence and cannot be named or fully understood, while the other Tao exists and can be known. The eternal Tao is infinite; the other is finite. The eternal Tao is formless; the other is formed. The eternal Tao is transcendent; the other is immanent. The other \"Tao\" is an attempt to describe the \"eternal Tao\" in human terms; but such effort can never express the eternal Tao fully. He continues:\nIn these lines, he further discusses the difference between the two Taos. The eternal Tao is \"nameless\" and is the origin of Heaven and Earth; this origin can be understood as an underlying metaphysics that cannot be described fully. The \"named\" Tao, on the other hand, is able to describe specific phenomenons that exist in space and time, hence it is the mother of myriad of things; it also can be treated as the humanly conceived concepts in the effort to describe our physical world. Later, he points out that both the \"named\" and the \"nameless\" emerge together from the same eternal Tao. This seemingly self-contradictory unity, of course, is said to be the mystery to be understood.\n\nOne or more of these three conceptions of the Absolute can be found in various other religions or philosophies. The following is a list of concepts of divine or absolute reality:\n\nWhile these conceptions are superficially similar, they admit of multiple interpretations. Some philosophers, especially perennialists and pantheist philosophers, find great significance in the similarities between these different words and argue that various/all cultures past and present have an identical concept of the 'Absolute'.\n\nOther philosophers, however, argue that these concepts are not the same, since the Logos is rational and formal whereas Brahman is formless and irrational; and since Plato's Form of the Good is impersonal where the Christian God is personal; since Bradley's Absolute is a conscious experience whereas Brand Blanshard's Absolute is an unconscious, intelligible system.\n\nPerennialist philosophers such as John Hick argue that even if the concepts vary slightly, the reality of the Absolute reality behind the varying concepts is the same.\n\nPhilosophers such as Adi Shankara denied the Absolute any personal sense, whereas philosophers such as Ramanuja and Madhva, tended to identify the Absolute with a personal God. The Traditionalist School, via Frithjof Schuon, admits:It is true that God as creator, revealer, and savior is not to be identified with the Absolute as such; it is likewise true that God in Himself, in the full depth of His reality, is not to be reduced to the creative Function.Early Hinduism identified Brahman with Brahma, Vishnu, and Shiva. The same immortal spirit was conceived of as functional in the world in three ways: creation, preservation, and destruction. There was therefore no real contradiction between love of a personal God and an impersonal Absolute, although the latter was sometimes conceived of as \"purer.\"\n\nShaivism, and most monotheistic Indian religions, gave God five functions: creation, preservation, destruction, concealment, and revelation. Shiva, as Brahman, would therefore act in the world as a personal God. Yet this distinction between the Absolute and Infinite, or Transcendent and Immanent is not entirely, in itself, absolute. Philosophers like Shankara believe that upon doing away with maya the entire universe disappears, including the notion of a personal God. Philosophers such as Madhva and Ramanuja, tend to propound an identification of the Absolute with God, whereas later philosophers such as Nimbarka and Caitanya, tended to identify the Absolute with a personal form of God (Krishna). Either way, all these claims, taken in context, tend to prove non-contradictory.\n\nThe quote above, via Schuon, is actually fully represented within the Hindu tradition. Brahma, the creator god, is not worshiped within Hinduism. The only deities that are worshiped, are Shiva, and Vishnu. Both Shiva and Vishnu, by their respective devotees, are represented as having power over the following five functions: creation, preservation, destruction, concealment, and revelation. However, a further distinction is made by Shankara: God is not Brahman (the Absolute). Rather the appearance of God is still via the power of Maya. So there are in effect, three levels, which Schuon himself observes: Brahman (the Absolute), God as creator, revealer, and savior (AKA, Shiva or Vishnu), and finally God as creator (AKA, Brahma). Incidental reasons are given for Brahma's lack of worship, a Hindu myth attributes this situation to a curse by Bhrigu. Devdutt Pattanaik, an Indian author, gives some philosophical reasons. Ultimately the reason is actually inherent (\"inherent\" in the Absolute) and theological.\n\nLaozi taught that the Tao was not only the ultimate reality but the ideal of human life. Another conceptual similarity between various conceptions is that the ultimate reality also somehow reveals to humans the way to live. For example, Plato taught that the Good was both the source of reality, the highest object of knowledge, and the ultimate end of desire.\n\nC. S. Lewis explains the connection between the highest reality and human action in this way:\nI. K. Taimni says:\nAldous Huxley says:\nSimilarly, the Hindu Taimni describes the Parabrahman as unknowable by the human mind and unthinkable but the highest object of realization and the most profound object of philosophical enquiry.\n\nPlotinus likewise taught that the goal of philosophy was to \"contemplate the One\".\n\nPhilosophers and religious adherents who aim to pattern their life after the Absolute reality sometimes claim to have experienced the Absolute. They report mystical experiences, feelings of oneness, transcendence of their everyday personality or of personhood altogether.\n\nThe Absolute is conceptually defined as something inexpressible and perhaps unthinkable. This concept creates special problems for expression in words, poetry, mythology, and art. Writers, painters, storytellers, filmmakers often use paradox or contradiction because of the \"contradictory aspect of the ultimate reality\".\n\nAccording to Mircea Eliade, the Absolute can be mediated or revealed through symbols. For Eliade the \"archaic\" mind is constantly aware of the presence of the Sacred, and for this mind all symbols are religious (relinking to the Origin). Through symbols human beings can get an immediate \"intuition\" of certain features of the inexhaustible Sacred. The mind makes use of images to grasp the ultimate reality of things because reality manifests itself in contradictory ways and therefore can't be described in concepts. It is therefore the image as such, as a whole bundle of meaning, that is \"true\" (faithful, trustworthy). Eliade says :\n\n...the \"sacred\" is equivalent to a \"power\", and, in the last analysis, to \"reality\". The sacred is saturated with \"being\". Sacred power means reality and at the same time enduringness and efficacy. The polarity sacred-profane is often expressed as opposition between real and \"unreal\" or pseudoreal. \"[...]\" Thus it is easy to understand that religious man deeply desires \"to be\", to participate in \"reality\", to be saturated with power.Common symbols of the Absolute include world trees, the tree of life, microcosm, fire, children, circles, mandalas, and the human body.\n\n"}
{"id": "35297376", "url": "https://en.wikipedia.org/wiki?curid=35297376", "title": "Alaveteli", "text": "Alaveteli\n\nAlaveteli is free and open source software by mySociety to help citizens write Freedom of Information requests and automatically publish any responses.\n\nAlaveteli is described as \"a project to create a free, standard, internationalised platform for making Freedom of Information (FOI) requests\". Alaveteli is funded by the Open Society Institute and the Hivos Foundation.\n\nIt started life as the software running WhatDoTheyKnow, a UK site that publishes responses to FOI requests. The original WhatDoTheyKnow code was written primarily by Francis Irving while working for mySociety. Alaveteli is named after Alaveteli in Finland where Anders Chydenius who was an early campaigner for Freedom of Information worked as a curate. Alaveteli is the name for the software rather than a public facing website or brand.\n\nPeople who run sites on the Alaveteli platform are also invited to become part of a community, with support and tips shared via a message board, and regular conferences\n\nAlternative free and open source software that are used to operate FOI-request portals include Froide, which FragDenStaat.de in Germany and FragDenStaat.at in Austria are based on, and MuckRock, which is used for MuckRock and FOIA Machine in the United States.\n\n"}
{"id": "15498298", "url": "https://en.wikipedia.org/wiki?curid=15498298", "title": "Allowable Strength Design", "text": "Allowable Strength Design\n\nAllowable Strength Design (ASD) is a term used by the American Institute of Steel Construction (AISC) in the 14th Edition of the Manual of Steel Construction.\n\nAllowable Stress Design philosophy was left unsupported by AISC after the 9th edition of the manual which remained an acceptable reference design standard in evolving building codes (e.g. International Building Code by the International Code Council). This presented problems since new research, engineering concepts and design philosophy were ignored in the minimum requirements and references in the aging 9th edition. As a result, structures that were code compliant based on design using the Allowable Stress Design methods may not have been code compliant if reviewed with the Load and Resistance Factor Design (LRFD) requirements - particularly where the LRFD procedures explicitly defined additional analysis which was not explicitly defined in the Allowable Stress Design procedures.\n\nAISC's Allowable Strength Design applies a quasi-safety factor approach to evaluating allowable strength. Ultimate strength of an element or member is determined in the same manner regardless of the load combination method considered (e.g. ASD or LRFD). Design load combination effects are determined in a manner appropriate to the intended form of the analysis results. ASD load combinations are compared to the ultimate strength reduced by a factor (omega) which provides a mathematical form similar to Allowable Stress Design resolved with a safety factor.\n\nThis AISC Allowable Strength Design does not attempt to relate capacity to elastic stress levels. Therefore, it is inappropriate to refer to the procedure or philosophy as either Allowable Stress or Permissible Stress Design.\n"}
{"id": "39350338", "url": "https://en.wikipedia.org/wiki?curid=39350338", "title": "Appraisal (discourse analysis)", "text": "Appraisal (discourse analysis)\n\nIn discourse analysis, applied linguistics and related fields appraisal refers to the ways that writers or speakers express approval or disapproval for things or ideas. Language users build relationships with their interlocutors by expressing such positions. This notion is closely related to the idea of stance in linguistics and anthropology.\n\nJ.R. Martin and P.R.R. White's approach to appraisal in systemic functional linguistics regionalised the concept into three interacting domains: 'attitude', 'engagement' and 'graduation'.\n"}
{"id": "1456626", "url": "https://en.wikipedia.org/wiki?curid=1456626", "title": "Autonomous agent", "text": "Autonomous agent\n\nAn autonomous agent is an \"intelligent agent\" operating on an owner's behalf but without any interference of that ownership entity. An Intelligent agent, however appears according to a multiply cited statement in a no longer accessible IBM white paper as follows:\n\nIntelligent agents are software entities that carry out some set of operations on behalf of a user or another program with some degree of independence or autonomy, and in so doing, employ some knowledge or representation of the user's goals or desires.\n\nSuch an agent is a system situated in, and part of, a technical or natural environment, which senses any or some status of that environment, and acts on it in pursuit of its own agenda. Such an agenda evolves from drives (or programmed goals). The agent acts to change part of the environment or of its status and influences what it sensed.\n\nNon-biological examples include intelligent agents, autonomous robots, and various software agents, including artificial life agents, and many computer viruses. Biological examples are not yet defined.\n\nLee et al. (2015) post safety issue from how the combination of external appearance and internal autonomous agent have impact on human reaction about autonomous vehicles. Their study explores the humanlike appearance agent and high level of autonomy are strongly correlated with social presence, intelligence, safety and trustworthy. In specific, appearance impact most on affective trust while autonomy impact most on both affective and cognitive domain of trust where cognitive trust is characterized by knowledge-based factors and affective trust ls largely emotion driven \n\n\n\n"}
{"id": "10156846", "url": "https://en.wikipedia.org/wiki?curid=10156846", "title": "Avatar (spacecraft)", "text": "Avatar (spacecraft)\n\nAvatar () (from \"Aerobic Vehicle for Transatmospheric Hypersonic Aerospace TrAnspoRtation\") is a concept study for a robotic single-stage reusable spaceplane capable of horizontal takeoff and landing, by India's Defence Research and Development Organisation. The mission concept is for low cost military and commercial satellite space launches.\n\nThis spaceplane concept is unrelated to India's RLV Technology Demonstration Programme (RLV-TD).\n\nIn Sanskrit, the word avatar (अवतार ') is derived from ' (lit. to move/cross below, i.e. descend) and literally means \"that which descends\". In Hinduism, an avatar refers to deliberate descent of a deity to Earth, or a descent of the Supreme Being.\n\nThe idea is to develop a spaceplane vehicle that can take off from conventional airfields. Its liquid air cycle engine would collect air in the atmosphere on the way up, liquefy it, separate oxygen and store it on board for subsequent flight beyond the atmosphere. The Avatar, a reusable launch vehicle, was first announced in May 1998 at the Aero India 98 exhibition held at Bangalore.\n\nAvatar is projected to weigh 25 tons, of which 60% of that mass would be liquid hydrogen fuel. The oxygen required by the vehicle for combustion in outer space would be collected from the atmosphere during takeoff, thus reducing the need to carry oxygen during launch. The notional specification is for a payload weighing up to to low Earth orbit and to withstand up to 100 launches and reentries.\n\nIf built, Avatar would take off horizontally like a conventional airplane from a conventional airstrip using turbo-ramjet engines that burn hydrogen and atmospheric oxygen. During this cruising phase, an on-board system would collect air from the atmosphere, from which liquid oxygen would be separated and stored and used to burn the stored hydrogen in the final flight phase to attain orbit. The vehicle would be designed to permit at least one hundred launches and atmospheric reentries.\n\nThe Avatar concept study was commissioned by India's Defence Research and Development Organisation in 2001. India's Space Agency ISRO has no connection with the project. Air Commodore Raghavan Gopalaswami, who headed the study, made a presentation on the spaceplane at the global conference on propulsion at Salt Lake City, United States on July 10, 2001. Gopalaswami said the idea for Avatar originated from the work published by the RAND Corporation of the United States in 1987.\nSpaceplanes of comparable role, configuration and era\n\n"}
{"id": "559865", "url": "https://en.wikipedia.org/wiki?curid=559865", "title": "Bīja", "text": "Bīja\n\nIn Hinduism and Buddhism, the Sanskrit term Bīja () (Jp. 種子 shuji) (Chinese 种子 zhǒng zǐ), literally seed, is used as a metaphor for the origin or cause of things and cognate with bindu. \nVarious schools of Buddhist thought held that karmic effects arose out of seeds that were latent in an individual's mindstream or psycho-physical continuum. Rupert Gethin describes the theory thus:\n\nWhen I perform an action motivated by greed, it plants a 'seed' in the series of dharmas [phenomena] that is my mind. Such a seed is not a thing in itself - a dharma but merely the modification or 'perfuming' of the subsequent flow of dharmas consequent upon the action. In the course of time this modification matures and issues in a particular result, in the same way as a seed does not produce its fruit immediately, but only after the 'modifications' of the shoot, stem, leaf, and flower. \n\nThe Sautrantika school held such a theory as did the Mahasamghikas and the early Mahasisakas. The Sautrantika Sthavira Srilata held a conception of \"subsidiary element\" (\"anudhatu\" or *\"purvanudhatu\") which also corresponds to this theory of seeds. The seed theory was defended by the Buddhist philosopher Vasubandhu in his Abhidharmakosha who mentions that is the view of the “old teachers” (\"purvacarya\"). It is also present in the \"Viniscayasamgrahani\" of the Yogacarabhumi. In the Bashyam Vasubandhu connects the Sautrantika theory of seeds with the notion of the latent defilements or anusaya:\n\nThe Sautrantikas define anusayas as kleshas in the state of seeds and say that they are not separate dravyas (substances). Anusayas are dormant, i.e., not actualized, while paryavasthanas (active defilements) are awakened.\n\nLikewise, the \"Nyayanusara\" of Sanghabhadra states that the theory had different terms to refer to \"seeds\":\n\nThere are certain masters who give different names to these seeds, each according to his own understanding. Some call them subsidiary elements (\"anudhatu\"), others call them impressions (\"vasana\"); still others call them capability (\"samarthya\"), non-disappearance (\"avipranasa\"), or accumulation (\"upacaya\").\n\nThe theory is considerably extended in the Consciousness-only teachings of the Yogacara school of Buddhism. According to this theory, all experiences and actions produce \"bīja\" as impressions, stored in the alaya (storehouse) consciousness. The external world is produced when the seeds \"perfume\" this consciousness.\n\nIn Vajrayana Buddhism and Hinduism, the term \"bīja\" is used for mystical \"seed syllables\" contained within mantras. These seeds do not have precise meanings, but are thought to carry connections to spiritual principles. The best-known \"bīja\" syllable is Om, first found in the Hindu scriptures the Upanishads.\n\nKhanna (2003: p. 21) links mantras and yantras to thoughtforms:\n\nIn some tantric traditions, the Bija of the 'Varnamala' (Sanskrit; English: \"garland of letters\"; which may be rendered as alphabet) are understood as aniconic representations and sound embodiments of the matrikas (a group of goddesses).\n\nIn Tibetan Buddhism the seed syllables corresponding to the Three Vajras are: a white \"oṃ\" (enlightened body), a red \"āḥ\" (enlightened speech) and a blue \"hūṃ\" (enlightened mind).\n\nIn the Bön tradition of Tibet, it's a little different: a white \"āḥ\", a red \"oṃ\" and a blue \"hūṃ\".\n\nBijas are often the vehicle of esoteric transmission of terma to a 'tertön' (Tibetan; English: \"revealer of terma\"), such as that experienced by Dudjom Lingpa.\n\nGuruwari of the Indigenous Australian peoples is an interesting cross cultural correlate and may be cognate. See also gankyil of the Vajrayana tradition which is cognate with bindu. In the respected fieldwork published in \"Aboriginal Men of High Degree\", A.P. Elkin cites what he in his professional opinion is evidence that traders from Indonesia brought fleeting contact of Buddhism and Hinduism to areas near modern-day Dampier. Traditions of Mantrayana were also evident in Indonesia, e.g. Candi Sukuh. And it is in the Vajrayana and Mantrayana traditions of esoteric transmission where bija take precedence. Indeed, bija defines Mantrayana. Elkin interpreted a link between Indigenous Australian culture and Buddhist ideas such as reincarnation. He argued this link could have been brought through contact with Macassan traders. There was also speculation due to reports of Chinese relics appearing in northern Australia dating to the 15th century, although it may have been brought much later through trade rather than earlier exploration. Elkin cited linguistic commonalities of certain far northern Australian indigenous words and lexical items and ancient southern Indian Dravidian languages. There are also documented analogues and marked similarities in their kinship systems.\n\n"}
{"id": "24331066", "url": "https://en.wikipedia.org/wiki?curid=24331066", "title": "Centre for Investigative Journalism", "text": "Centre for Investigative Journalism\n\nThe Centre for Investigative Journalism (CIJ) is a British Charity providing training to journalists, researchers, producers and students in the practice and methodology of investigative journalism. Incorporated as a Company Limited by Guarantee in June 2005 and registered as a Charity in March 2007. Using grants from the Lorana Sullivan Foundation, the CIJ organises annual three-day summer schools, an annual investigative film week and courses in data journalism and investigative techniques. It has provided training to thousands of journalists, researchers and students from over 35 countries. The CIJ is based at the School of Journalism at Goldsmiths, University of London. Since 2014, has held the CIJ summer school each year.\nThe Centre supports and encourages Freedom of Information, Computer Assisted Reporting, and the protection of whistleblowers. The CIJ offers particular assistance to those working in difficult environments where free speech and freedom of the press are under threat and where truthful reporting can be a dangerous occupation.<ref>\n"}
{"id": "2072569", "url": "https://en.wikipedia.org/wiki?curid=2072569", "title": "Cinderella complex", "text": "Cinderella complex\n\nThe Cinderella complex was first described by Colette Dowling, who wrote a book on women's fear of independence – an unconscious desire to be taken care of by others. The complex is said to become more apparent as a person grows older. \n\nThe complex is named after the fairy tale character Cinderella. It is based on the idea of femininity portrayed in that story, where a woman is beautiful, graceful, polite, supportive, hardworking, independent, and maligned by the females of her society, but she is not capable of changing her situations with her own actions and must be helped by an outside force, usually a male (i.e., the Prince).\n\nThis phenomenon or syndrome becomes particularly significant with regard to the question of why women may choose to stay in dysfunctional relationships.\n\nOthers point to Ronald Fairbairn's concept of mature dependency, to challenge cultural disparagement of dependency in favor of an ideal of isolated independence. Carol Gilligan's championship of a web of connections as a feminist goal, rather than the solitary male hero, is also invoked to defend the Cinderella complex's tendency to define the self in terms of a mate/settled relationship.\n\nIn the movie \"Tootsie\", Teri Garr tells Dustin Hoffman during their break-up at the end of the movie, \"I read the Cinderella Complex, I know I'm responsible for my own orgasm! I don't care, I just don't like being lied to!\" \n\nIn the TV series \"Police Squad!\" episode 4 \"Revenge and Remorse\", Joyce Brothers gets advice from the shoe shine man Johnny about how to treat the Cinderella Complex: \"Tell them to get in touch with their unconscious feelings and to share in the growth process with their partner\"\n\n"}
{"id": "15398838", "url": "https://en.wikipedia.org/wiki?curid=15398838", "title": "Contour set", "text": "Contour set\n\nIn mathematics, contour sets generalize and formalize the everyday notions of\n\nGiven a relation on pairs of elements of set formula_1\nand an element formula_3 of formula_1\n\nThe upper contour set of formula_3 is the set of all formula_7 that are related to formula_3:\n\nThe lower contour set of formula_3 is the set of all formula_7 such that formula_3 is related to them:\n\nThe strict upper contour set of formula_3 is the set of all formula_7 that are related to formula_3 without formula_3 being \"in this way\" related to any of them:\n\nThe strict lower contour set of formula_3 is the set of all formula_7 such that formula_3 is related to them without any of them being \"in this way\" related to formula_3:\n\nThe formal expressions of the last two may be simplified if we have defined\nso that formula_25 is related to formula_26 but formula_26 is \"not\" related to formula_25, in which case the strict upper contour set of formula_3 is\n\nand the strict lower contour set of formula_3 is\n\nIn the case of a function formula_33 considered in terms of relation formula_34, reference to the contour sets of the function is implicitly to the contour sets of the implied relation\n\nConsider a real number formula_3, and the relation formula_37. Then\n\nConsider, more generally, the relation\nThen\n\nIt would be \"technically\" possible to define contour sets in terms of the relation\nthough such definitions would tend to confound ready understanding.\n\nIn the case of a real-valued function formula_33 (whose arguments might or might not be themselves real numbers), reference to the contour sets of the function is implicitly to the contour sets of the relation\nNote that the arguments to formula_33 might be vectors, and that the notation used might instead be\n\nIn economics, the set formula_1 could be interpreted as a set of goods and services or of possible outcomes, the relation formula_65 as \"strict preference\", and the relationship formula_66 as \"weak preference\". Then\n\nSuch preferences might be captured by a utility function formula_75, in which case\n\nOn the assumption that formula_66 is a total ordering of formula_1, the complement of the upper contour set is the strict lower contour set.\n\nand the complement of the strict upper contour set is the lower contour set.\n\n\n"}
{"id": "3584524", "url": "https://en.wikipedia.org/wiki?curid=3584524", "title": "Design load", "text": "Design load\n\nIn a general sense, the design load is the maximum amount of something a system is designed to handle or the maximum amount of something that the system can produce, which are very different meanings. For example, a crane with a design load of 20 tons is designed to be able to lift loads that weigh 20 tons or less. However, when a failure could be catastrophic, such as a crane dropping its load or collapsing entirely, a factor of safety is necessary. As a result, the crane should lift about 2 to 5 tons at the most. \n\nIn structural design, a design load is greater than the load which the system is expected to support. This is because engineers incorporate a safety factor in their design, in order to ensure that the system will be able to support at least the expected loads (called specified loads, despite any problems with construction, materials, etc. that go unnoticed during construction.\n\nA heater would have a general design load, meaning the maximum amount of heat it can produce. A bridge would have a specified load, with the design load being determined by engineers and applied as a theoretical load intended to ensure the actual real-world capacity of the specified load.\n\n"}
{"id": "19254708", "url": "https://en.wikipedia.org/wiki?curid=19254708", "title": "Double tangent bundle", "text": "Double tangent bundle\n\nIn mathematics, particularly differential topology, the double tangent bundle or the second tangent bundle refers to the tangent bundle of the total space \"TM\" of the tangent bundle of a smooth manifold \"M\"\n. A note on notation: in this article, we denote projection maps by their domains, e.g., \"π\" : \"TTM\" → \"TM\". Some authors index these maps by their ranges instead, so for them, that map would be written \"π\".\n\nThe second tangent bundle arises in the study of connections and second order ordinary differential equations, i.e., (semi)spray structures on smooth manifolds, and it is not to be confused with the second order jet bundle.\n\nSince is a vector bundle on its own right, its tangent bundle has the secondary vector bundle structure where is the push-forward of the canonical projection \nIn the following we denote\n\nand apply the associated coordinate system\n\non \"TM\". Then the fibre of the secondary vector bundle structure at \"X\"∈\"T\"\"M\" takes the form\n\nThe double tangent bundle is a double vector bundle.\n\nThe canonical flip is a smooth involution \"j\":\"TTM\"→\"TTM\" that exchanges these vector space structures\nin the sense that it is a vector bundle isomorphism between and In the associated coordinates on \"TM\" it reads as\n\nThe canonical flip has the property that for any \"f\": R → \"M\", \nwhere \"s\" and \"t\" are coordinates of the standard basis of R . Note that both partial derivatives are functions from R to \"TTM\".\n\nThis property can, in fact, be used to give an intrinsic definition of the canonical flip. Indeed, there is a submersion\n\"p\": J (R,M) → \"TTM\" given by \nwhere \"p\" can be defined in the space of two-jets at zero because only depends on \"f\" up to order two at zero. We consider the application:\nwhere α(\"s\",\"t\")= (\"t\",\"s\"). Then \"J\" is compatible with the projection \"p\" and induces the canonical flip on the quotient \"TTM\".\n\nAs for any vector bundle, the tangent spaces of the fibres \"T\"\"M\" of the tangent bundle can be identified with the fibres \"T\"\"M\" themselves. Formally this is achieved though the vertical lift, which is a natural vector space isomorphism\n\nThe vertical lift can also be seen as a natural vector bundle isomorphism\n\nfrom the pullback bundle of over onto the vertical tangent bundle\n\nThe vertical lift lets us define the canonical vector field\n\nwhich is smooth in the slit tangent bundle \"TM\"\\0. The canonical vector field can be also defined as the infinitesimal generator of the Lie-group action\n\nUnlike the canonical vector field, which can be defined for any vector bundle, the canonical endomorphism\n\nis special to the tangent bundle. The canonical endomorphism \"J\" satisfies\n\nand it is also known as the tangent structure for the following reason. If (\"E\",\"p\",\"M\") is any vector bundle\nwith the canonical vector field \"V\" and a (1,1)-tensor field \"J\" that satisfies the properties listed above, with \"VE\" in place of \"VTM\", then the vector bundle (\"E\",\"p\",\"M\") is isomorphic to the tangent bundle of the base manifold, and \"J\" corresponds to the tangent structure of \"TM\" in this isomorphism.\n\nThere is also a stronger result of this kind which states that if \"N\" is a 2\"n\"-dimensional manifold and if there exists a (1,1)-tensor field \"J\" on \"N\" that satisfies\n\nthen \"N\" is diffeomorphic to an open set of the total space of a tangent bundle of some \"n\"-dimensional manifold \"M\", and \"J\" corresponds to the tangent structure of \"TM\" in this diffeomorphism.\n\nIn any associated coordinate system on \"TM\" the canonical vector field and the canonical endomorphism have the coordinate representations\n\nA Semispray structure on a smooth manifold \"M\" is by definition a smooth vector field \"H\" on \"TM\" \\0 such that \"JH\"=\"V\". An equivalent definition is that \"j\"(\"H\")=\"H\", where \"j\":\"TTM\"→\"TTM\" is the canonical flip. A semispray \"H\" is a spray, if in addition, [\"V\",\"H\"]=\"H\".\n\nSpray and semispray structures are invariant versions of second order ordinary differential equations on \"M\". The difference between spray and semispray structures is that the solution curves of sprays are invariant in positive reparametrizations as point sets on \"M\", whereas solution curves of semisprays typically are not.\n\nThe canonical flip makes it possible to define nonlinear covariant derivatives on smooth manifolds as follows. Let\nbe an Ehresmann connection on the slit tangent bundle \"TM\"/0 and consider the mapping\nwhere \"Y\":\"TM\"→\"TTM\" is the push-forward, \"j\":\"TTM\"→\"TTM\" is the canonical flip and κ:\"T\"(\"TM\"/0)→\"TM\"/0 is the connector map. The mapping \"D\" is a derivation in the module Γ (\"TM\") of smooth vector fields on \"M\" in the sense that\n\n\nAny mapping \"D\" with these properties is called a (nonlinear) covariant derivative\nThe term \"nonlinear\" refers to the fact that this kind of covariant derivative \"D\" on is not necessarily linear with respect to the direction \"X\"∈\"TM\"/0 of the differentiation.\n\nLooking at the local representations one can confirm that the Ehresmann connections on (\"TM\"/0,π,\"M\") and nonlinear covariant derivatives on \"M\" are in one-to-one correspondence. Furthermore, if \"D\" is linear in \"X\", then the Ehresmann connection is linear in the secondary vector bundle structure, and \"D\" coincides with its linear covariant derivative.\n\n"}
{"id": "6546863", "url": "https://en.wikipedia.org/wiki?curid=6546863", "title": "Drop Art", "text": "Drop Art\n\nIn 1961, filmmaker Gene Bernofsky and artist Clark Richert, art students from the University of Kansas, developed an art concept they called Drop Art or droppings. Informed by the \"happenings\" of Allan Kaprow and the impromptu performances a few years earlier of John Cage, Robert Rauschenberg and Buckminster Fuller at Black Mountain College, Drop Art began when Richert and Bernofsky started painting rocks and dropping them from a loft roof onto the sidewalk of Lawrence Kansas's main drag — watching the reactions of passersby. Early Drop Art included such pieces as \"Egg Drop\" and \"Pendulum\" (pictured) .\n\nDrop Art eventually led to the creation of Drop City, an experimental artist's community founded in 1965 near Trinidad, Colorado. The intention was to create a live-in work of Drop Art.\n\n\n"}
{"id": "19268056", "url": "https://en.wikipedia.org/wiki?curid=19268056", "title": "Drumming out", "text": "Drumming out\n\nDrumming out is the historical act of being dishonorably dismissed from military service to the sound of a drum. In modern figurative usage, in which the term is sometimes altered to \"drub[bing/bed/etc.] out,\" it may refer to any act of expulsion or dismissal in disgrace.\n\nOne of the earliest recorded references to drumming out occurs in Alexander Pope's \"Moral Essays\", 3rd epistle, 1731–1733: \"Chartres was a man infamous for all manner of vices. When he was an ensign in the army, he was drummed out of the regiment for a cheat; he was next banished Brussels, and drummed out of Ghent, on the same account.\"\n\nIt also occurs in a figurative sense in Thomas Amory's 1766 \"Life of John Buncle\": \"They ought to be drummed out of society.\"\n\nThe earliest known discharge of an American soldier involved the drumming out of Lieutenant Frederick Gotthold Enslin for attempted sodomy in March of 1778 during the Revolutionary War. The diary of Lieutenant James McMichael contains a record of the sentence being carried out: \nThe sentencing order, approved by George Washington, called for Enslin to be drummed out, never to return.\n\nAmerican Civil War officers drummed out of service might have their heads shaved and their uniforms stripped of insignia and be paraded in front of their comrades. Fellow officers were forbidden to touch the person being dishonorably discharged, but in more than one case after the war had ended, a drummed-out man was found dead after receiving a beating from his former comrades. When someone was being drummed out, the tune \"Rogue's March\" would be played.\n\nThe opening to the 1965 NBC series \"Branded\" used the ceremony in its opening credits.\n\nIn the 1983 film \"The Lords of Discipline\", one of the main characters is dismissed from the fictional Carolina Military Institute in such a ceremony.\n\nIn the \"Married... With Children\" episode \"All-Nite Security Dude,\" Al is drummed out of his position as school security guard.\n\nIn season 4 episode 2 of AMC series \"\" a soldier's wife is drummed out of camp and loses her privileges as a camp follower for refusing to wash clothes for the army.\n\n"}
{"id": "54108343", "url": "https://en.wikipedia.org/wiki?curid=54108343", "title": "Dyuloka", "text": "Dyuloka\n\nDyuloka is a Sanskrit term for \"heavenly world\". It appears in the Vedic text \"Shatapatha Brahmana\", in verses 16.6.1.8–9 as well later texts. Its root is \"Dyu\" (द्यु) which in the \"Rigveda\" means \"heaven, shining, sky\".\n\nThe term appears in the \"Upanishads\", where it connotes \"sky or heaven\", as in sun lighting it up. For example, in the commentary to the Yajnavalkya-Gargi dialogue of section 6.2 in the \"Brihadaranyaka Upanishad\", Radhakrishnan translates \"Dyuloka\" as heaven.\n\nIn another context, \"Dyuloka\" is the realm of existence (samsara) where souls are reborn as gods and goddesses, to live out a life based on one's karma before they die again, according to the \"Devi-Bhagavata Purana\".\n\n\n"}
{"id": "511043", "url": "https://en.wikipedia.org/wiki?curid=511043", "title": "Egocentric bias", "text": "Egocentric bias\n\nEgocentric bias is the tendency to rely too heavily on one's own perspective and/or have a higher opinion of oneself than reality. It appears to be the result of the psychological need to satisfy one's ego and to be advantageous for memory consolidation. Research has shown that experiences, ideas, and beliefs are more easily recalled when they match one's own, causing an egocentric outlook. Michael Ross and Fiore Sicoly first identified this cognitive bias in their 1979 paper, \"Egocentric biases in availability and attribution\". Egocentric bias is referred to by most psychologists as a general umbrella term under which other related phenomena fall.\n\nThe effects of egocentric bias can differ based on personal characteristics, such as age and the number of languages one speaks. Thus far, there have been many studies focusing on specific implications of egocentric bias in different contexts. Research on collaborative group tasks have emphasized that people view their own contributions differently than they view that of others. Other areas of research have been aimed at studying how mental health patients display egocentric bias, and at the relationship between egocentric bias and voter distribution. These types of studies surrounding egocentric bias usually involve written or verbal questionnaires, based on the subject's personal life or their decision in various hypothetical scenarios.\n\nThe term \"egocentric bias\" was first coined in 1980 by Anthony Greenwald, a psychologist at Ohio State University. He described it as a phenomenon in which people skew their beliefs so that what they recall from their memory or what they initially understood is different than what actually occurred. He cites research by Rogers, Kuiper, and Kirker, who explain that the self-reference effect is the ability of people to recall information better if they think about how the information will affect them during the encoding process (recording memories in their brain). Greenwald argues that the self-reference effect causes people to exaggerate their role in a situation. Furthermore, information is better encoded, and thus people are more likely to suffer from egocentric bias, if they produce information actively rather than passively, such as by having a direct role in the outcome of a situation.\n\nEgocentric bias occurs when people fail to consider situations from other people's perspectives. Egocentric bias has influenced ethical judgements to the point where people not only believe that self-interested outcomes are preferential but are also the morally sound way to proceed. People are more inclined to be aware of their own behaviors since they can use their thoughts and emotions to gain more information about themselves. These thoughts and emotions can affect how people view themselves in relation to others in specific situations. A common example arises when people are asked to explain how much credit should be given to each person in a collaborative project. Daniel Schacter, a psychology professor at Harvard University, considers egocentric bias as one of the \"seven sins\" of memory and essentially reflects the prominent role played by the self when encoding and retrieving episodic memories. As such, people often feel that their contributions to a collaborative project are greater than those of other members, since people tend to focus more on how much they have done.\n\nIn social context, egocentric bias influences people to choose a social circle that is capable of maintaining one's positive traits. Studies show that one's choice of friend or social circle is likely to be dependent on the amount of positive feedback received.\n\nIn a 1993 study conducted in Japan, subjects were asked to write down fair or unfair behaviors that they themselves or others did. When writing about fair behavior, they tended to start with the word \"I\" rather than \"others\". Likewise, they began unfair behaviors with \"others\" rather than \"I\". This demonstrates that people tend to attribute successes and positive behaviors to themselves, while placing the burden of failures and negative behaviors on others. Furthermore, in this study there were gender differences detected; Japanese women, compared to men, remembered the behaviors of others more than their own, and were also more probable to characterize fair or unfair behavior to others compared to themselves.\n\nAnother study found that egocentric bias influences perceived fairness. Subjects felt that overpayment to themselves were more fair than overpayment to others; by contrast, they felt the underpayment to themselves were less fair than underpayment to others. Greenberg's studies showed that this egocentrism was eliminated when the subjects were put in a self-aware state, which was applied in his study with a mirror being placed in front of the subjects. When a person is not self-aware, they perceive that something can be fair to them but not necessarily fair to others. Therefore, fairness was something biased and subjective. When a person is self-aware, there is a uniform standard of fairness and there is no bias. When made self-aware, subjects rated overpayment and underpayment to both themselves and to others as equally unfair. It is believed that these results were obtained because self-awareness elevated subjects' concerns about perceived fairness in payment, thereby overriding egocentric tendencies.\n\nThe egocentric bias can also be clearly observed in young children, especially those who have not yet developed theory of mind, or the ability to understand concrete situations from the perspective of others. In one study by Wimmer and Perner, a child and a stuffed animal were presented with two differently colored boxes and both are shown that one contains an object of interest. The experimenter then removed the stuffed animal from the room and moved the object into the other box. When asked where the stuffed animal should search for the object, the children overwhelmingly tended to point to the box that they knew the object was in. Rather than thinking about the animal's perspective, the children displayed an egocentric bias in assuming that the animal would share their point of view, even though the animal had no way of knowing the same information as them.\n\nThe causes and motivations for egocentric bias were investigated in a 1983 journal entry by Brian Mullen of Murray State University. Inspired by the study by Ross et al. demonstrating the false consensus effect, Mullen's paper focused on the overestimation of consensus. Mullen analyzed the NBC television show \"Play the Percentages\" to determine whether egocentric bias was rooted in a perceptual and unintentional distortion of reality versus a conscious, intentional motivation to appear normalized. Subjects in this analysis were contestants from the show, 20–30 year old middle class married couple with equal gender distribution. At the start of each show, studio audiences were asked several trivia questions, and the percentage of correct answers was recorded for later use in the game. During each round of the game, opposing contestants estimated the percentage of correct answers. The contestant who had a closer estimate wins the percentage of correct answer as a score, and then if they answer said trivia question correctly, wins the remaining percentage for a maximum possible 100 points. The first couple to win 300 points received a cash prize, with the opportunity to win more prizes in bonus rounds. Thus, the show provided incentive for unbiased estimates of consensus. Statistical analysis of the collected data showed that the \"egocentric bias of false consensus was observed in spite of the potent incentive for unbiased estimates of consensus.\" This analysis ultimately supports the hypothesis that egocentric bias is a result of unintentional perceptual distortion of reality rather than a conscious, intentional motivation to appear normalized.\n\nFrom a psychological standpoint, memories appear to be stored in the brain in an egocentric manner: the role of oneself is magnified in one's experiences to make them more personally relevant and thereby easier to recall. Early childhood memories, therefore, may be more difficult to recall since one's sense of self is less developed, so old memories do not connect as strongly to oneself as newer ones. Moreover, egocentric bias may have evolved from hunter-gatherer times, in which communities were small and interdependent enough that individuals could assume that others around them had very similar outlooks. An egocentric view would have reduced cognitive load and increased communication efficiency.\n\nA 2016 study published by Riva, Triscoli, Lamm, Carnaghi, and Silani found that egocentric bias tends to be experienced in a much greater degree by adolescents and older adults than by young and middle aged adults. They examined the emotional effect of visuo-tactile stimulation on pairs of participants from a population of 114 female of varying ages. The varying degree of egocentric bias with age was attributed to the developmental cycle of the right supramarginal gyrus (rSMG) of the parietal lobe, which finishes developing at the end of adolescence and decays early.\n\nRecent studies of egocentric bias have been done in many different subgroups of people, such as bilingual people. A study done by Paula Rubio-Fernández and Sam Glucksberg found that bilingual people are less prone to egocentric bias because they have grown to pay more attention to others' thoughts. Thus, it is less difficult for them to differentiate between their own opinions and those of others.\n\nConsidered to be a facet of egocentric bias, the false-consensus effect states that people believe their thoughts, actions, and opinions are much more common than they are in reality. When people are asked to make an estimate of a population's statistic, they often only have data from themselves and tend to assume that others in the population are similar to them due to egocentric bias. In turn, people tend to overestimate the extent to which their opinion is shared by the rest of the population. Moreover, people tend to believe that those who differ in opinion must be part of a minority and that the majority actually agrees with them. Therefore, the false-consensus effect, or the tendency to deduce judgements from own's own opinions, is a direct result of egocentric bias.\n\nA well known example of false-consensus effect is a study published by Ross, Greene and House in 1977. Students are asked to walk around a campus with a sandwich board that bearing the word \"repent\". People who agreed to do so (50%) estimated that most of their peers would also agree to do so (average estimation 63.5%). Conversely, those who refused to do the experiment reported that most of their peers would refuse as well.\n\nPeople who exhibit the false consensus effect take egocentric bias a step further: they not only forgo thinking of other perspectives, but they believe that their viewpoints are those accepted by the majority of people. Nevertheless, some psychologists do not distinguish between egocentric bias and the false consensus effect. For example, in the paper published by Ross, Greene, and House, the terms \"false consensus\" and \"egocentric attribution bias\" are used interchangeably. In the second part of their study, they gave out a questionnaire which asked participants which option (out of two choices) they would choose in specified situations, and what percentage of the population would choose which option. In all four scenarios that were given, subjects rated the option that they chose as the most probable. Ross, Greene, and House conclude that their results support the false consensus hypothesis, and that \"intuitive estimates of deviance and normalcy, and the host of social inferences and interpersonal responses that accompany such estimates, are systematically and egocentrically biased in accord with his own behavioral choices.\"\n\nA related concept to egocentric bias is self-serving bias, in which one takes undue credit for achievements and blames failures on external forces. However, egocentric bias differs from self-serving bias in that egocentric bias is rooted in an erroneous assumption of other's perception of reality, while self-serving bias is an erroneous perception of one's own reality. For example, consider a student who earns a low grade in a class. Self-serving bias would result in the assumption that the student's low grade is a result of poor teaching, which would direct the fault of one's reality away from one's own actions.\n\nEgocentric bias might also result in an overestimation of the number of students that received low grades in the class for the purpose to normalize these students' performance. However, similar to the false-consensus effect, the self-serving bias and the egocentric bias have also been used as interchangeable terms.\n\nBoth concepts may be the product of individualistic cultures that usually stress independence and personal achievement over group-oriented success. Cross-cultural studies have found a strong presence of the egocentric bias in the primarily individualistic American, South African, and Yugoslavian communities, but noted the opposite effect in the collectivistic Japanese, Nepali, and Indian societies. People from these cultures tend to demonstrate a bias toward modesty, in which success is attributed to external or group-related factors and failures are seen as the result of personal shortcomings.\n\nBayesian reasoning is a form of statistical inference that relies on Bayes' rule to make probability prediction based on given information. In Bayesian updating, people use prior probabilities to make estimates, and then gradually change these probabilities as they gain more information. Bayesian inference is often used by psychologists to determine whether subjects who exhibit the false-consensus effect have a rational thought process. To understand Bayes' rule, consider an example from an experiment by Kreuger and Clement: there is an urn with 100 chips, some blue and some red, and then subjects are told that the first chip drawn from the urn is blue. Subjects are asked to estimate the probability that the urn contains predominantly blue chips. Using Bayes' rule, the probability that a blue chip is drawn given that the urn contains predominantly blue chips is equal to the probability of the urn being predominantly blue multiplied by the probability of the urn being predominantly blue given that a blue chip was drawn, all divided by the probability that the urn is predominantly blue. Most participants overestimated the requested probability. Data shows that subjects tend not to pay attention to sample size when making probability predictions. For example, although it has statistically been proven by the law of large numbers that larger samples have less variability, people tend to claim that large and small samples have the same amount of variability. Studies like the urn experiment above provide evidence that the false-consensus effect is not entirely rational, and that egocentric viewpoints tend to be predominant.\n\nEgocentric bias can lead to the devaluation of peer contributions and the amplification of one's own work when in a collaborative setting. For example, when group members have been asked to report what percentage of the output they created, the total summed to greater than 100%. Usually, individuals are more easily able to recall their personal contributions and thus believe them to greater or more important. This applies to both positive and negative inputs: in a study of married couples, each spouse rated themselves as more responsible for helpful (cleaning) and detractive activities (causing arguments). Research has shown that feelings of sibling caregivers and their siblings depend on the contact between siblings and their feelings of closeness. Each of these two groups believed that their siblings contributed less to the needs of their family than themselves, and were more resistant to increasing these types of contributions. The closer that siblings were to each other, measured through observation and self reports, the smaller the extent of egocentric bias they felt in reporting each sibling's contribution.\n\nAn overly exaggerated or extremely low demonstration of egocentric bias could be an indicator of mental illness. Those with anxiety tend to view themselves as the center of all events around them, regardless of their nature or how unrelated they are to oneself. On the other hand, people suffering from depression may have a lower tendency towards egocentricity, as evidenced by the fact that they tend to more realistically rate their contributions to group work, while non-depressed participants often overreport their additions.\n\nThe egocentric bias has also been shown to contribute to a citizen's decision to vote in elections. Firstly, people tend to view their personal choice between voting and abstinence as a reflection of those who support the same candidates and issues. Secondly, although each individual vote has very little power in large-scale elections, those who vote overestimate the significance their ballot. Moreover, citizens demonstrate egocentric bias, in conjunction with the false-consensus effect, in their predictions of election outcomes. A study examining the 2008 American presidential election found that the more strongly people favor a certain candidate, the higher they estimate that candidate's likelihood of winning the election. For instance, those who strongly preferred Barack Obama predicted that he had a 65% chance of becoming the president, while those who preferred another candidate approximated that he only had a 40% chance of victory.\n\n"}
{"id": "7149012", "url": "https://en.wikipedia.org/wiki?curid=7149012", "title": "Factorization system", "text": "Factorization system\n\nIn mathematics, it can be shown that every function can be written as the composite of a surjective function followed by an injective function. Factorization systems are a generalization of this situation in category theory.\n\nA factorization system (\"E\", \"M\") for a category C consists of two classes of morphisms \"E\" and \"M\" of C such that:\n\n\"Remark:\" formula_10 is a morphism from formula_11 to formula_12 in the arrow category.\n\nTwo morphisms formula_13 and formula_14 are said to be \"orthogonal\", denoted formula_15, if for every pair of morphisms formula_4 and formula_5 such that formula_18 there is a unique morphism formula_9 such that the diagram\n\ncommutes. This notion can be extended to define the orthogonals of sets of morphisms by\n\nSince in a factorization system formula_22 contains all the isomorphisms, the condition (3) of the definition is equivalent to\n\"Proof:\" In the previous diagram (3), take formula_25 (identity on the appropriate object) and formula_26.\n\nThe pair formula_27 of classes of morphisms of C is a factorization system if and only if it satisfies the following conditions:\n\n\nSuppose \"e\" and \"m\" are two morphisms in a category C. Then \"e\" has the \"left lifting property\" with respect to \"m\" (resp. \"m\" has the \"right lifting property\" with respect to \"e\") when for every pair of morphisms \"u\" and \"v\" such that \"ve\"=\"mu\" there is a morphism \"w\" such that the following diagram commutes. The difference with orthogonality is that \"w\" is not necessarily unique.\n\nA weak factorization system (\"E\", \"M\") for a category C consists of two classes of morphisms \"E\" and \"M\" of C such that :\n\n"}
{"id": "6603892", "url": "https://en.wikipedia.org/wiki?curid=6603892", "title": "Fiber (mathematics)", "text": "Fiber (mathematics)\n\nIn mathematics, the term fiber (or fibre in British English) can have two meanings, depending on the context:\n\n\nLet be a map. The fiber of an element formula_2 commonly denoted by formula_3 is defined as formula_4 That is, the fiber of \"y\" under \"f\" is the set of elements in the domain of \"f\" that are mapped to \"y\".\n\nThe inverse image or preimage formula_5 generalizes the concept of the fiber to subsets formula_6 of the codomain. The notation formula_7 is still used to refer to the fiber, as the fiber of an element \"y\" is the preimage of the singleton set formula_1, as in formula_9. That is, the fiber can be treated as a function from the codomain to the powerset of the domain: formula_10 while the preimage generalizes this to a function between powersets: formula_11\n\nIf \"f\" maps into the real numbers, so formula_12 is simply a number, then the fiber formula_7 is also called the level set of \"y\" under \"f\": formula_14 If \"f\" is a continuous function and \"y\" is in the image of \"f\", then the level set of \"y\" under \"f\" is a curve in 2D, a surface in 3D, and, more generally, a hypersurface of dimension \n\nIn algebraic geometry, if \"f\" : \"X\" → \"Y\" is a morphism of schemes, the fiber of a point \"p\" in \"Y\" is the fiber product of schemes \nwhere \"k\"(\"p\") is the residue field at \"p\".\n\n"}
{"id": "11344", "url": "https://en.wikipedia.org/wiki?curid=11344", "title": "First-order predicate", "text": "First-order predicate\n\nIn mathematical logic, a first-order predicate is a predicate that takes only individual(s) constants or variables as argument(s). Compare second-order predicate and higher-order predicate.\n\nThis is not to be confused with a one-place predicate or monad, which is a predicate that takes only one argument. For example the expression \"is a planet\" is a one-place predicate, while the expression \"is father of\" is a two-place predicate.\n\n"}
{"id": "3876658", "url": "https://en.wikipedia.org/wiki?curid=3876658", "title": "Fleeing felon rule", "text": "Fleeing felon rule\n\nAt common law, the fleeing felon rule permits the use of force, including deadly force, against an individual who is suspected of a felony and is in clear flight. According to David Caplan \"Immediate stopping of the fleeing felon, whether actually or presumably dangerous, was deemed absolutely necessary for the security of the people in a free state, and for maintaining the \"public security.\" ... \" Indeed, it has been said that the social policy of the common law in this matter was not only to threaten dangerous felons and hence deter them, but was also to induce them to \"surrender peaceably\" if they dared commit inherently dangerous felonies, rather than allow them to \"escape trial for their crimes.\" \n\nUnder U.S. law the fleeing felon rule was limited in 1985 to non-lethal force in most cases by \"Tennessee v. Garner,\" . The justices held that deadly force \"may not be used unless necessary to prevent the escape and the officer has probable cause to believe that the suspect poses a significant threat of death or serious bodily harm to the officer or others.\"\n\nFleeing felons may be followed into places not open to the public without a warrant if the officer is in \"hot pursuit.\" Deadly force that is executed by a co-defendant against an accomplice is not justified by the fleeing felon rule.\n\n\n"}
{"id": "8365879", "url": "https://en.wikipedia.org/wiki?curid=8365879", "title": "Guy Coburn Robson", "text": "Guy Coburn Robson\n\nGuy Coburn Robson (1888 - 1945) was a British zoologist, specializing in Mollusca, who first named and described \"Mesonychoteuthis hamiltoni\", the colossal squid.\n\nRobson studied at the marine biological station in Naples, and joined the staff of the Natural History Museum in 1911, becoming Deputy Keeper of the Zoology Department from 1931 to 1936.\n\nRobson is best known for his major book \"The Variations of Animals in Nature\" (co-authored with O. W. Richards, 1936) which argued that although the fact of evolution is well established, the mechanisms are largely hypothetical and undemonstrated. The book claims that most differences among animal populations and related species are non-adaptive. It was published before major developments in the modern synthesis and contains critical evaluation of natural selection. It was positively reviewed in science journals in the 1930s. Zoologist Mark Ridley has noted that \"Robson and Richards suggested that the differences between species are non-adaptive and have nothing to do with natural selection.\"\n\nHistorian Will Provine has commented that the book \"has been in disrepute since the late 1940s because of its antagonism to natural selection\" but notes that it was the \"best known general work on animal taxonomy\" before the work of Julian Huxley and Ernst Mayr. Huxley in \"\" (1942), described the book as \"an undue belittling of the role of selection in evolution.\"\n\n\n"}
{"id": "13755584", "url": "https://en.wikipedia.org/wiki?curid=13755584", "title": "Ideological criticism", "text": "Ideological criticism\n\nIdeological criticism is a method in rhetorical criticism concerned with critiquing texts for the dominant ideology they express while silencing opposing or contrary ideologies. It was started by a group of scholars roughly in the late-1970s through the mid-1980s at universities in the United States. Leading scholars of ideological criticism were Michael Calvin McGee at the University of Iowa and Phillip Wander at San Jose State University. Wander's 1983 article, \"The Ideological Turn in Modern Criticism,\" and his 1984 article, \"The Third Persona: An Ideological Turn in Rhetorical Theory,\" remain two of the most important articles in the field. According to Sonja Foss, “the primary goal of the ideological critic is to discover and make visible the dominant ideology or ideologies embedded in an artifact and the ideologies that are being muted in it.” Foss has also mentioned the contribution to ideological criticism of several theoretical schools, including Marxism, structuralism, cultural studies, and postmodernism.\n\nA unit of analysis in ideological criticism, or what Foss calls \"traces of ideology in an artifact,\" is the ideograph. It is a symbol representing an ideological concept and is more than what the symbol itself depicts. Michael McGee, a renowned ideological critic, postulated that an “ideograph is an ordinary term found in political discourse” that “is a high-order abstraction representing collective commitment to a particular but equivocal and ill-defined normative goal”. Thus, McGee restricted ideographs to words, words that “constitute a vocabulary of public motives, which authorize and warrant public actions”. McGee encourages the study of ideographs (such as “liberty” and “freedom”) to help identify the ideological position of a society. He argues such terms are used in discourse as a means of justifying problematic issues within a society. The meaning of an ideograph is defined by a society and its culture and can change over time. Ideographs need not be only positive in nature, but can be negative as well. For example, tyranny and slavery, can “guide behavior and belief negatively by branding unacceptable behavior.\" McGee notes that to fully understand ideographs, they must be examined both “diachronically” as well as “synchronically.” That is, ideographs need to be examined across time to determine how their meanings may have changed and all ideographs that are used in a given situation must be considered.\n\nWho in democracy would be opposed to actions taken under the auspices of liberty and freedom? To do so would, ideographically speaking, be undemocratic. Citizens of a democratic state are “conditioned” to believe that liberty and freedom are so fundamentally important that society expects those citizens to simply unquestioningly accept actions claiming to be in defense of liberty and freedom. For example, even within the United States, the ideograph of freedom has changed. At the time of the American War of Independence (1775–1783), freedom meant breaking away from the tyrannical rule of the Kingdom of Great Britain. Today, freedom means many things including the freedom to pursue one's dreams and the freedom to be left alone. People disagree about the freedoms that are most important: freedom to possess guns, freedom to make decisions that affect one's body, freedom from fear or violence, and freedom of movement. Depending on one's ideological orientation, the ideograph of freedom represents many things, which is why it can be so powerfully used by politicians. Ideographs succeed in political discourse because of their inability to be concretely understood. \n\nIdeographs need not be verbal only; they can be visual too. In 1997, Janis Edwards and Carol Winkler expanded the idea of the ideograph to include visual images as well as written words. They argue images can act as “a Visual reference point that forms the basis of arguments about a variety of themes and subjects” that are used by both “elites and non-elites” alike. Like McGee’s textual ideographs, visual ideographs depict common values and goals in a given culture, recur in different contexts over time, and are used to validate arguments and social practices. Edwards and Winkler mention images of people can act as ideographs too. “In their construct, a person (character) is abstracted and elevated to the status of a cultural figure, and becomes a surface for the articulation of the political character, employing cultural ideals”. Foss identifies the following steps in a piece of ideological criticism: 1) “formulate a research question and select an artifact”; 2) “select a unit of analysis” (which she calls “traces of ideology in an artifact”); 3) “analyze the artifact” (which, according to Foss, involves identifying the ideology in the artifact, analyzing the interests the ideology serves, and uncovering the strategies used in the artifact to promote the ideology); and 4) “write the critical essay”.\n\n"}
{"id": "19541290", "url": "https://en.wikipedia.org/wiki?curid=19541290", "title": "Ignorantia juris non excusat", "text": "Ignorantia juris non excusat\n\nIgnorantia juris non excusat or ignorantia legis neminem excusat (Latin for \"ignorance of the law excuses not\" and \"ignorance of law excuses no one\" respectively) is a legal principle holding that a person who is unaware of a law may not escape liability for violating that law merely because one was unaware of its content. \n\nEuropean-law countries with a tradition of Roman law may also use an expression from Aristotle translated into Latin: nemo censetur ignorare legem (nobody is thought to be ignorant of the law) or ignorantia iuris nocet (not knowing the law is harmful).\n\nThe rationale of the doctrine is that if ignorance were an excuse, a person charged with criminal offenses or a subject of a civil lawsuit would merely claim that one was unaware of the law in question to avoid liability, even if that person really does know what the law in question is. Thus, the law imputes knowledge of all laws to all persons within the jurisdiction no matter how transiently. Even though it would be impossible, even for someone with substantial legal training, to be aware of every law in operation in every aspect of a state's activities, this is the price paid to ensure that willful blindness cannot become the basis of exculpation. Thus, it is well settled that persons engaged in any undertakings outside what is common for a normal person, such as running a nuclear power plant, will make themselves aware of the laws necessary to engage in that undertaking. If they do not, they cannot complain if they incur liability.\n\nThe doctrine assumes that the law in question has been properly promulgated—published and distributed, for example, by being printed in a government gazette, made available over the internet, or printed in volumes available for sale to the public at affordable prices. In the ancient phrase of Gratian, \"Leges instituuntur cum promulgantur\" (\"Laws are instituted when they are promulgated\"). In order that a law obtain the binding force which is proper to a law, it must be applied to the men who have to be ruled by it. Such application is made by their being given notice by promulgation. A law can bind only when it is reasonably possible for those to whom it applies to acquire knowledge of it in order to observe it, even if actual knowledge of the law is absent for a particular individual. A secret law is no law at all.\n\nIn criminal law, although ignorance may not clear a defendant of guilt, it can be a consideration in sentencing, particularly where the law is unclear or the defendant sought advice from law enforcement or regulatory officials. For example, in one Canadian case, a person was charged with being in possession of gambling devices after they had been advised by customs officials that it was legal to import such devices into Canada. Although the defendant was convicted, the sentence was an absolute discharge.\n\nIn addition, there were, particularly in the days before satellite communication and cellular phones, persons who could genuinely be ignorant of the law due to distance or isolation. For example, in a case in British Columbia, a pair of hunters were acquitted of game offenses where the law was changed during the period they were in the wilderness hunting. In reaching this decision, the court refused to follow an early English law case in which a seaman on a clipper before the invention of radio was convicted even though the law had been changed while he was at sea (Bailey (1800) Russ & Ry 1).\n\nThe doctrine,\"Ignorance of the law is no excuse,\" first shows up in the Bible in Leviticus 5:17: \"If a person sins and does what is forbidden in any of the LORD's commands, even though he does not know it, he is guilty and will be held responsible.\" An alternate explanation of the origin of the maxim, though not particularly relevant to the modern context, can be found in the philosophy of the Greeks and Romans. Such were cultures heavily influenced by customary legal systems. Within such a system, law is learned as a person participates in the culture and customs of the community. Thus it is unreasonable to believe a person could have avoided learning them. These rules and customs were also interwoven with ethical and religious dialogue so that laws expressed what is right and that which is not. We find that Cicero wrote the following in \"De re publica\" (On the Republic):\n\n\"There is a true law, right reason, agreeable to nature, known to all men, constant and eternal, which calls to duty by its precepts, deters from evil by its prohibition. This law cannot be departed from without guilt. Nor is there one law at Rome and another at Athens, one thing now and another afterward; but the same law, unchanging and eternal, binds all races of man and all times.\"\n\nMinos (attributed to Plato) states the following conversation between Socrates and his companion:\n\n\n\n\n.\n\n\n\n\n\n\nPresumed knowledge of the law is the principle in jurisprudence that one is bound by a law even if one does not know of it. It has also been defined as the \"prohibition of ignorance of the law\".\n\nThe concept comes from Roman law, and is expressed in the brocard \"ignorantia legis non excusat\".\n\nThe essential public character of a law requires that the law, once properly promulgated, must apply to anyone in the jurisdiction where the law applies. Thus, no one can justify his conduct on the grounds that he was not aware of the law.\n\nGenerally, a convention exists by which the laws are issued and rendered accessible by methods, authors and means that are simple and well known: the law is readable in certain places (some systems prescribe that a collection of the laws is copied in every local city council), is made by certain authorities (usually sovereign, government, parliament, and derivative bodies), and enters into effect in certain ways (many systems for instance prescribe a certain number of days - often 15 - after issue). This is commonly intended as a constitutional regulation, and in fact many constitutions or statutes exactly describe the correct procedures.\n\nHowever, some recent interpretations weaken this concept. Particularly in civil law, regard can be had to the difficulty of being informed of the existence of a law considering the lifestyle of the average citizen. On the penal side, the quality of the knowledge of the law can affect the evaluation of the animus nocendi or the mens rea, in that certain subjective conditions can weaken personal responsibility.\n\nThe theme was widely discussed, also for political reasons, at the time of the Enlightenment and in the 18th century, given the heavy proportion of illiterate citizens in European countries (who would have some difficulties being aware of all the laws in a country). It was then argued that both the presumed knowledge and the heavily increasing corpus of national legislation were working in favour of lawyers rather than citizens.\n\nIn recent times, some authors have considered this concept as an extension of (or at least as analogous to) the other ancient concept (typical of criminal law) that no one can be punished under a law that was issued after the action was committed (non-retroactivity of the law. See ex post facto). This interpretation is however disputed, given that the matter would hierarchically more properly refer to a constitutional doctrine rather than to a civil or penal one.\n\nSome modern criminal statutes contain language such as stipulating that the act must be done \"knowingly and wittingly\" or \"with unlawful intent,\" or some similar language. However, this does not refer to ignorance of laws, but having criminal intent.\n\nThis principle is also stated in statutes:\n\n\nIn some jurisdictions, there are exceptions to the general rule that ignorance of the law is not a valid defense. For example, under U.S. Federal criminal tax law, the element of \"willfulness\" required by the provisions of the Internal Revenue Code has been ruled by the courts to correspond to a \"voluntary, intentional violation of a known legal duty\" under which an \"actual good faith belief based on a misunderstanding caused by the complexity of the tax law\" is a valid legal defense. See Cheek v. United States.\n\n"}
{"id": "3370779", "url": "https://en.wikipedia.org/wiki?curid=3370779", "title": "Incrementalism", "text": "Incrementalism\n\nIncrementalism is a method of working by adding to a project using many small incremental changes instead of a few (extensively planned) large jumps. Logical incrementalism implies that the steps in the process are sensible. Logical incrementalism focuses on \"the Power-Behavioral Approach to planning rather than to the Formal Systems Planning Approach\". In public policy, incrementalism is the method of change by which many small policy changes are enacted over time in order to create a larger broad based policy change. This was the theoretical policy of rationality developed by Lindblom to be seen as a middle way between the rational actor model and bounded rationality, as both long term goal driven policy rationality and satisficing were not seen as adequate.\n\nMost people use incrementalism without ever needing a name for it because it is the natural and intuitive way to tackle everyday problems, such as making coffee or getting dressed. These actions normally don't require extensive planning and problems can be dealt with one at a time as they arise.\n\nEven in processes that involve more extensive planning, incrementalism is often an important tactic for dealing reactively with small details. For example, one might plan a route for a driving trip on a map, but one would not typically plan in advance where to change lanes or how long to stop at each streetlight.\n\nThe political scientist Charles E. Lindblom developed Incrementalism in the mid 1950s. “The Science of Muddling Through” (1959), was an essay Lindblom wrote to help policymakers understand why they needed to consider a different approach when making policy changes. The goal for the new perspective of Incrementalism was for policy makers to avoid making changes before they really engaged and rationally thought through the issue.\n\nIn large projects following some type of strategic planning, there is normally a need to allocate time to plan the project in order to avoid \"fire fighting\", in other words the avoidance of time delaying issues. In contrast to other systems of planning such as top down, bottom up, and so on, incrementalism involves concentrating on dealing with the immediate problems as they arrive and avoiding trying to create an overall strategic plan. This means muddling through the issues at hand based on importance.\n\nStrategic implementation is a very well thought out plan of implementation that is the opposite to incrementalism. Although the plan involved with the strategic implementation might work incrementally it has set objectives at set times with little to no intention of muddling through the process. In other words, every part of the implementation would be expected and planned for ahead of time.\n\nThe antithesis of incrementalism is that work must be accomplished in one single push rather than through a process of continuous improvement. All work must be planned, only presented when complete and work in progress must be hidden. \n\nIn political science, research on incrementalism has largely been incorporated into the study of Punctuated equilibrium in social theory, which views policy change as periods of incremental improvement punctuated by major policy shifts.\n\nThe advantages of incrementalism over other formal systems is that no time is wasted planning for outcomes which may not occur.\n\nDisadvantages are that time may be wasted dealing with the immediate problems and no overall strategy is developed. Incrementalism in the study of rationality can be seen as a stealthy way to bring about radical changes that were not initially intended, a slippery slope.\n\nIncrementalism is commonly employed in politics, engineering, software design, planning and industry. Whereas it is often criticized as \"fire fighting\", the progressive improvement of product designs characteristic, e.g., of Japanese engineering can create steadily improving product performance, which in certain circumstances outperforms more orthodox planning systems.\n\nAnother example would be in small changes that make way for a bigger overall change to get past unnoticed. A series of small steps toward an agenda would be less likely to be questioned than a large and swift change. An example could be the rise of gas prices, the company would only raise the price by a few cents every day, instead of a large change to a target price overnight. More people would notice and dispute a dramatic, 100% increase overnight, while a 100% increase over a span of a week would less likely be even noticed, let alone argued. This can be applied in many different ways, such as, economics, politics, a person's appearance, or laws.\n\nIn the 1970s, many countries decided to invest in wind energy. Denmark, a small country of around 5 million people, became a world leader in this technology using an incremental approach. While more formal design processes in the US, Germany and the United Kingdom failed to develop competitive machines. The reason for the difference of approach was that the Danish wind industry developed from an agricultural base whilst the American and UK wind industries were based on hi-tech aerospace companies with significant university involvement. While the Danes built better and better windmills using an incremental approach, those using formal planning techniques believed that they could easily design a superior windmill straight away.\n\nIn practice, however, windmill design is not very complicated and the biggest problem is the tradeoff between cost and reliability. Although the UK and the U.S.A. designs were technically superior, the lack of experience in the field meant that their machines were less reliable in the field. In contrast, the heavy agricultural windmills produced by the Danes just kept turning, and by 2000 the top three windmill manufacturers in the world were Danish.\n\nThe Central Arizona Project and the Salt River Project display the use of Innovation and incrementalism. There was a Plan 6 cost-sharing program that was a component in both of these projects and displayed innovations of the external enforcers and internal entrepreneurs and how they muddled through as well as collaborated incrementally to work on these projects with many different players in the mix.\n\nThe resource allocation in local authorities is riddled by politics and provides the underlying methods of incrementalism in the negotiations process of putting local authorities priorities together. Looking the United States Federal Budget is a back and forth negotiation between politicians and provides great insight of incremental change. Every year a new budget must be formed to allocate funds to the agencies such as the DoD and government programs such as Social Security and Medicare. The amounts with which are decided gradually change based on the importance as well as efficiencies and inefficiencies of agencies or priorities.\n\nIn the case of climate change the opinions changed gradually over the years as more and more scientific evidence became clear to policy makers that it should be a prevalent policy issue. Political economy of climate change and Politics of global warming are worth noting on the international scale of climate change policy and how there has been an incremental leaning towards the belief and action against climate change over the years.\n\nIncrementalism is a planning methodology normally found where a large strategic plan is either unnecessary or has failed to develop and for that reason it is often just called \"muddling through\". Incrementalism is the antithesis of intrusive central planning, which can create rigid work systems unable to deal with the actual problems faced at the grassroots level. However, without a central planning framework incremental working is difficult to support within structured systems and therefore requires a degree of self-reliance, skills and experience of those dealing with the problems such as is found in autonomous work groups. \n\n\n"}
{"id": "7808413", "url": "https://en.wikipedia.org/wiki?curid=7808413", "title": "Inkjet refill kit", "text": "Inkjet refill kit\n\nAn inkjet refill kit is a set of tools and a certain amount of ink used to refill ink cartridges. The specific tools and the amount or type of ink depends on which cartridge the kit is designed for. The purpose of an inkjet refill kit for consumers is that it offers a low-cost alternative to buying new cartridges.\n\nTypically, a refill kit comes with a cartridge holder, bottles of ink and needles. The exact tools that come with the kit can vary by manufacturer or by which cartridge the kit is for. Some tools are found in all kits because they are necessary to refill, but others, like the cartridge holder or a needle to withdraw air from the cartridge, are optional.\n\nThe most common refill kits come with either: bottles of black ink for black refill kits; or one bottle each of cyan, magenta and yellow for color refill kits; or one bottle each of photo cyan, photo magenta and photo black for photo-color refill kits; or combination of all colors for combo refill kits.\n\nThe refill process typically involves the following steps:\n\n\n\nMany printer manufactures provide their cartridges with chips and/or sensors to prevent refilling. These chips can also serve as a \"copy protection,\" so that the printer does not work with cartridges made by other manufacturers. In such cases, the refilling process must include the bypassing of those anti-refilling protections. (Refill instructions, chip resetters or autoreset chips [the latter are reset each time the printer is switched on] for different cartridge models, and other tools are available on the Internet.)\n\nTime-coding of ink cartridges\n\nTo make more money, some manufacturers provide their ink cartridges with a time chip, so that after a certain period of time or after a certain number of printed pages the ink cartridges no longer work and/or a message appears that they are empty even if they are still almost full. So the user cannot buy several ink cartridges to store them for a longer time, but must regularly buy new ones.\n\nRegion-coding of printers and ink cartridges\n\nFor price discrimination, some printer manufacturers (e.g. Canon, Epson, HP, Lexmark, Xerox) give their printers and ink cartridges region codes - similar to DVD region codes -, so that the users can only use printers and ink cartridges from their region and cannot import cheaper ones from another region. The region can be changed several times; then, the printer is \"region-locked\" like an RPC-2 DVD drive and accepts only cartridges from one certain region. Sometimes the region change must be done by the manufacturer's customer service and cannot be done by the user.\n\nXerox printers are shipped with neutral \"factory\" ink sticks with no region coding. Upon the installation of the first new ink stick after these factory sticks, the machine will set a region code based on the installed ink stick and will only accept ink sticks for that region from that point forward. \"Officially, \" only three starter ink sticks per color can be used; then, the printer will no longer accept them and will want region-coded ink sticks to be inserted, but there are workarounds for that problem.\n\nWhen moving to a new region, it seems a good idea to store empty cartridges from the old region (or to re-use the region-free Xerox factory ink sticks) and to refill them with ink from the new region. However, they usually also have chips and sensors to prevent refilling (such as the \"time chips\" mentioned above).\nSome manufacturers of region-coded printers also offer region-free printers specially designed for travelers, but, generally, \"the best solution seems to be to avoid region-coded printers.\"\n\nIntegration of the print-head in the cartridge\n\nSome manufacturers install the print-head not in the printer, but integrate it in the cartridge. This makes it more difficult or even illegal (because of patent laws) for other manufacturers to rebuild cartridges, and just refilling the cartridge (including cleaning the print-head and resetting or disabling chips/sensors, if necessary) is sometimes not sufficient, because one cannot print anymore once the print-head no longer works.\n\nThe main benefit of using a refill kit is the claimed cost savings. Environmental benefit is also claimed, as the process reuses a cartridge that would have otherwise been thrown away after one use.\n\nThe downside to refill is the time associated with it and the unpredictability. Refilling a cartridge can take 10–15 minutes for those unfamiliar with the process, and some may prefer buying a new cartridge to the effort it takes to refill. Also, ink cartridges usually last for 4-5 refills, but there are those that can only be refilled one time before they are worn out.\n\nThe biggest perceived downside to refilling is the mess associated with it. Many consumers shy away from refilling either based on past experiences or stories they have heard. Many of the unsuccessful refill kits of the past were so-called \"universal\" kits, meaning they were designed for use with multiple cartridges. Because all manufacturers use different types of ink, and because different cartridge designs require different refilling processes, these universal kits had a high failure rate. Today these kits are harder to find, as refill kits made for specific cartridges have become more the norm, but perception that all refill kits are messy still remains.\n\nThe main reason for the decline in refill kits is the emergence of large chains of ink stores that offer a refill process. This is similar to the evolution of the automobile oil change. Just as cars became too complex for the average driver to change oil, the new cartridges have also become too complex for the average consumer to do it by themselves.\n\nInkjet refill kits are available in different sizes and with different grades of ink.\n\n"}
{"id": "26274196", "url": "https://en.wikipedia.org/wiki?curid=26274196", "title": "International Modern Media Institute", "text": "International Modern Media Institute\n\nThe International Modern Media Institute (IMMI) is an international institution with the aim of promoting debate about laws good for freedom of information, speech, and expression. The institute does this by offering advice and guidance in relation to legislation.\n\nOn 18 February 2010, the institute entered a parliamentary resolution proposal, commonly known as the Icelandic Modern Media Initiative, into the Icelandic Parliament Alþingi, proposing that Iceland \"strongly position itself legally with regard to the protection of freedoms of expression and information\". The proposal was adopted unanimously by parliament on 16 June 2010. Birgitta Jónsdóttir from The Movement was the chief sponsor of the proposal, 19 other MPs (out of 63) from all parties in the parliament supported the proposal by co-sponsoring it.\n\nThe proposal passed on 16 June was not a piece of final legislation. Instead, it began a process of editing 13 separate laws according to the proposal's specifications. This process was expected to be completed by mid-2012.\n\nAfter WikiLeaks exposed the loan book of Kaupthing Bank, one of the largest news channels, RUV, was injuncted from displaying the news story. Instead they were forced to simply put a message up of the WikiLeaks website. This led to WikiLeaks being invited by the Digital Freedoms Society to attend an annual conference in Iceland.\n\nThe IMMI board has released a report of the legislation on April 16, 2012. It details the status of various proposals that make up IMMI and their progress.\n\nThe IMMI project was cooperatively organised by numerous organisations and members of the Icelandic parliament. Its principal endorsers were Eva Joly, Index on Censorship, the Icelandic Digital Freedom Society, WikiLeaks, and Icelandic MPs such as Birgitta Jónsdóttir and Róbert Marshall. The project has also had public endorsements from various organisations such as Global Voices, La Quadrature du Net and the Free Knowledge Institute.\n\n"}
{"id": "30864383", "url": "https://en.wikipedia.org/wiki?curid=30864383", "title": "Intrinsic and extrinsic properties", "text": "Intrinsic and extrinsic properties\n\nAn intrinsic property is a property of a system or of a material itself or within. It is independent of how much of the material is present and is independent of the form of the material, e.g., one large piece or a collection of small particles. Intrinsic properties are dependent mainly on the chemical composition or structure of the material.\n\nA property that is not essential or inherent is called an extrinsic property. For example, density is an intrinsic property of any physical object, whereas belonging to something is an extrinsic property that depends on another object.\n\nIn biology, intrinsic effects originate from inside an organism or cell, such as an autoimmune disease or intrinsic immunity.\n\n"}
{"id": "42182310", "url": "https://en.wikipedia.org/wiki?curid=42182310", "title": "Kurt Walter Bachstitz", "text": "Kurt Walter Bachstitz\n\nKurt Walter Bachstitz (4 October 1882 – 1949 in The Hague) was a German-Austrian art dealer. He died shortly before his naturalization to the Netherlands.\n\nBachstitz was born as the child of the Jewish couple Liber Jacob Bachstitz and Mathilde Markowitz. His place of birth is arguable. All contemporary sources mention the formerly German Breslau (the present-day Polish Wrocław) as his place of birth. But Bachstitz requested for himself the Austrian village Raipoltenbach as his place of birth when he claimed at the U.S. Department of Labor for an extension of his temporary stay in 1931. He studied architecture in Paris, London and Vienna where he finished his studies with a diploma. On the outbreak of the First World War he was called up for military service and served between 1914 and 1918 as an officer, lastly in the rank of a troop captain. He served actively in the field until 1916, when he was severely wounded. He married Elfriede Pesé (died in 1918) with whom he had two children – a son Walter Werner Michael who died in 1943 by tuberculosis in Switzerland and a daughter, Margit Martha who died in South Africa in 1982. On 19 December 1918 he married his second wife Elisa (\"Lilly\") Emma Hofer. Lilly was a Protestant. Because of her Bachstitz converted to the evangelic faith. In 1919 he apparently lived and traded in Munich. In his diary Thomas Mann wrote about a meeting in Bachstitz' Munich apartment, where Mann bought a work from Bachstitz. He described him quite prerogatively as a \"blond-Jewish\" example of an \"international culture-capitalistic profiteer\". In 1920 he established an art dealership in the Hague named Kunsthandel K.W. Bachstitz (Bachstitz Gallery N.V.). Surinamestraat 11, He lived in Vienna and in Berlin and he created an internationally known company with art galleries in The Hague, New York City and Berlin. Lilly was the sister of art dealer Walter Andreas Hofer who had managed the Gallery in The Hague for a while and subsequently became an art buyer for Hermann Göring.\n\nIn 1937 Bachstitz waived his Austrian citizenship. In 1938 the couple moved to The Hague.\n\nBetween the beginning of the German occupation in 1940 and 1941 Bachstitz sold a number of paintings to the \"\" that was run by Hitler's Special Representative of the planned 'Führermuseum' in Linz, Hans Posse until his death in 1942.\n\nAmong the works sold to the Sonderauftrag were the following:\n\nThe correspondence between Bachstitz and Posse concerning these works is preserved. Posse achieved high price reductions.\n\n\nIn February 1941 Bachstitz officially resigned as supervisory director of the Bachstitz Gallery and his wife became the managing director. Together with his wife, he continued to provide a clandestine management role. In this way, they avoided having the Gallery placed under the forced administration for the duration of the war. According to the documents in the file concerning his successful application to become a Dutchman after the war the couple provided undercover protection for Jews trying to escape the authorities.\n\nIn 1942 Bachstitz was summoned by the occupation authority (the \"Wirtschaftsamt\") as he had failed to register the gallery as \"non-Aryan property\". Proceedings were commenced against him and he was arrested by the Sicherheitsdienst (SD) in July 1943 and imprisoned in the Scheveningen prison in The Hague. Due to an intervention of Göring initiated by Bachstitz' brother-in-law Hofer, he was released from prison. He was then also exempted from wearing the Star of David. Furthermore, the couple had their marriage dissolved in September 1943 to prevent the confiscation of the gallery by the occupying authority.\n\nBetween 1942 und 1944 Bachstitz sold a number of works to the museums that were run by Kurt Martin, the head of the Museums of the Upper Rhine (Alsace and Baden) under Robert Heinrich Wagner.\n\nIn 1944 Bachstitz managed to obtain permission to leave the Netherlands and he emigrated to Switzerland, again with the help of Andreas Hofer.\n\nAs a bribe for the exit visa Bachstitz had to hand over art to Hermann Göring, namely a painting with the Samson and Delilah motive by Jan Steen, as well two antique necklaces.\n\nAfter the war the Allies returned most of the art that the gallery had sold to German authorities to the Netherlands. The Netherlands restituted the painting by Jan Steen but rejected an application for the restitution of the other works. They became part of the Collection of the Stichting Nederlands Kunstbezit (SNK). Kurt Walter Bachsitz and Lilly Bachstitz-Hofer were again registered as officially married. Kurt Walter Bachstitz died in 1949. In 1951 his widow liquidated the Bachstitz Gallery N.V. with a high deficit. The gallery's art library was auctioned off.\n\nIn 2009 the Dutch government restituted the painting \"Roman Capriccio\" by Pietro Capelli from the stock of the SNK to Kurt Walter Bachstitz' grandchildren. The Restitution Committee of the Netherlands denied though a restitution claim concerning a number of other works, among them the works sold to Hitler (Sonderauftrag Linz). In view of most of these works the Committee argued that these sales had not been made under duress because Kurt Walter Bachstitz had been left \"undisturbed\" in 1940 and 1941. The grandchildren applied in 2013 for the re-opening of the case in this regard.\n\nIn July 2013 the Prussian Heritage Foundation restituted a Tyrolean gothic wall-mounted writing slate (c. 1500) and a large 16th-century Italian bronze mortar.\nKurt Walter Bachstitz' grandchildren are still searching for many works of art that were lost due to National-Socialist persecution\n\n\n"}
{"id": "6328159", "url": "https://en.wikipedia.org/wiki?curid=6328159", "title": "Landfill diversion", "text": "Landfill diversion\n\nWaste diversion or landfill diversion is the process of diverting waste from landfills. The success of landfill diversion can be measured by comparison of the size of the landfill from one year to the next. If the landfill grows minimally or remains the same, then policies covering landfill diversion are successful. For example, currently in the United States there are 3000 landfills. A measure of the success of landfill diversion would be if that number remains the same or is reduced. In 2009, it was recorded that the national average of landfill diversion in the United States was 33.8%, while San Francisco had implemented the most effective policies and had recorded a landfill diversion rate of 77%. By diverting landfills we can preserve our natural resources.\n\nWaste diversion is the process of diverting waste from landfills through recycling and source reduction activities. This can be calculated in different ways. As a global community, we can measure the size and number of landfills from one year to the next. If the landfills have shrunk or decreased in number, then it can be gathered that we are successfully implementing a waste diversion plan. If landfills have increased in number, then we are not doing enough to combat the growing population and growing waste we produce. On a smaller scale, we can track our week to week, or even day to day, waste diversion rate.\n\nReduction of waste is another way to divert waste from landfills; not creating waste in the first place will reduce the amount of waste going to landfills. There are numerous ways to reduce waste, for example, consumers can avoid single use products and instead invest in re-usable items such as canvas bags instead of plastic bags; consuming less in general is also an effective way to reduce waste. In addition, maintaining vehicles' tires will also help reduce waste tires in landfills since they are undesirable and take up too much space along with many other negative effects.\n\nLandfill diversion can occur through recycling. Recycling refers to taking used materials and creating new products in order to prevent the disposal of these products in landfills. Recycling material can include glass, paper, metal, plastic, textiles, and electronics. \n\nAnother method of landfill diversion is thermal treatment (such as Incineration). Approximately sixteen percent (16%) of waste is incinerated yearly in the United States. Incineration, however, can lead to other environmental issues that may have positive or negative results.\n\nIn addition to reusing materials waste products can go through biological treatment. There are two types of biological treatments anaerobic digestion or composting. Simply stated, biological treatment is the breaking down of material through the action of micro-organisms. Materials are broken down to carbon dioxide, water and biomass. Biomass consists of wood, crops, yard and animal waste. Biomass is considered a renewable energy because more can be grown in a short amount of time. Biomass contributes to roughly four percent of our energy. Biomass energy although its burned, does not pollute the air as much as fossil fuels. Some materials easily break down, others do not. The environment in which the material is placed determines the speed of breakdown.\n\nIt is possible in many production facilities to return waste product to the supplier of the original raw material. Some examples include the reuse of beer kegs by returning to the distributor to be refilled, reuse of propane tanks, and recycling batteries to be used again. These products are large contributors to the overgrowth of landfills. Many companies will offer incentives or credits for the returned product towards the next purchase.\n\nThe development of more closed loop systems aides in diverting waste from landfills. Manufacturing and most production facilities will create waste to varying degrees. A closed loop system will recycle the waste back into the production process to maintain minimal levels of waste that is left to be disposed of. This is environmentally and economically friendly. \n\nMore unfamiliar than other types, it is possible for a company to sell its waste to a third party. This third party will purchase the waste for reuse in their own production process. In addition to the sale of waste, there are also third parties which will retrieve your waste for you if they are capable of disposing of it more efficiently and/or affordably.\n\nOther options for diversion are composting and waste-to-energy: converting primary waste into various types of energy such as heat or electricity.\n\nAn open dump is an area where unwanted waste is disposed of with no regulations or restrictions; they often produce adverse effects on the environment. The Resources Conservation and Recovery Act of 1976 prohibited open dumping, therefore making it illegal in many states.\n\nA sanitary landfill is where waste is disposed of in thin layers little by little; each layer is covered and compacted with soil to prevent foul odors and wind blown litter. This method prevents the creation of safety and public health hazards; this landfill has four requirements before it is built. The first requirement is that it must have absolute leachate security; the bottom of the landfill can be lined, synthetically or with soil, to prevent water contamination. Secondly, there must be formal engineering preparations and plannings in order to ensure the success of the landfill. Thirdly, permanent supervision must be present in all stages of the landfill also to ensure success and sustainability. Lastly, the placement and compacting of waste must be planned to prevent pest and vermin infestations.\n\nA secure landfill is where hazardous waste is deposited since it requires a much more stringent regulation than municipal waste. The landfill must have at least two impermeable liners as well as a system for leachate collection to prevent any water contamination. In addition to this, the landfill must also have a groundwater monitoring system in case there is a leak; the wells can be pumped to remove the contaminated water for treatment.\n\nDeep-well injection is a form of disposing of liquid hazardous waste. The liquid waste is pumped into porous limestone or sandstone through a steel casing, and high pressure is applied in order to permanently store the waste within the pores and fissures of the rocks. The limestone or sandstone used for injection must be located beneath an impermeable layer of clay or rock at least 0.5 mile below the surface. This option generally does not require pre-treatment of the waste and is one of the more inexpensive options, however it poses a risk of hazardous waste leakage.\n\nThe California Integrated Waste Management Act mandated all Californian cities and counties to divert 25% of their solid waste by 1990 and 50% by 2000 through planning and programs; this is managed by the California Department of Resources Recycling and Recovery (CalRecycle), and they also provide assistance in creating plans and programs. The percentage of solid waste required to be diverted has remained at 50% each year.\n\nThe Maryland Department of the Environment (MDE) promotes the idea of waste diversion by partnering with Maryland's jurisdictions as well as the public and private sectors. All counties and Baltimore City are required to recycle 15% of waste generated (populations under 150,000) or 20% (populations over 150,000) due to The Maryland Recycling Act (MRA); the state government is also required to recycle at least 20% of their solid waste.\n\nThe Municipal Waste Planning Recycling and Waste Reduction Act (Act 101) was passed in 1988 which first initiated a statewide recycling program in Pennsylvania. As of 2016, at least 94% of Pennsylvania residents had access to recycling while 79% of the same population have direct access through curb side pick up programs. This act also required that individual counties develop efficient plans to combat the waste which will need disposed of in the next 10+ years.\nSuccess of Pennsylvania's recycling programs can be seen in the numbers. Over 6.12 million tons of waste were recycled into resources in 2013. This amount of recycling constitutes to 7.5 million tons of carbon dioxide emissions that were diverted from entering the air. The amount of carbon dioxide that this single state reduced in one year is equivalent to taking 1.58 million vehicles off of the road for one full year.\n\nEuropean waste legislation focuses upon the diversion of biodegradable waste from landfill, due to its potential to add to the effects of climate change.\n\nCalculating waste diversion rates is an important tool for households and especially businesses to use. It is a KPI in indicating a successful recycling program. By tracking progress weekly, changes can be made to improve week to week. A simple formula is used to calculate the waste diversion rate, as follows:\n\n(Weight of Recycling / (Weight of Recycling + Weight of Garbage)) X 100\n\nWaste should be labeled with the name of the area in which they were received. For businesses, this will be helpful in implementing programs; what may work for one part of the company may not work for another. The goal is to calculate a number as close to one hundred as possible. This would imply that one hundred percent of your waste is recycled. If a lower number is calculated, changes are required to improve the score. When a need to change the recycling plan is recognized, you must effectively communicate the plan to all members involved to make sure it is implemented in full. After the plan is implemented, try measuring the waste diversion rate again. Measure the changes to see if the new plan has produced clear benefits.\n\nThe UL is a global independent safety science company which is working to find and improve current technologies and the public use of these things. They work to innovate the usage to promote a world where these luxuries and a healthy environment can co-inhabit the planet. They are three different levels of validations which the UL uses to honor the companies who manage their waste in environmentally healthy ways. Facilities are recognized as \"Zero Waste\" if they can consistently measure at a waste diversion rate of 100 percent. Facilities which are granted \"Virtually Zero,\" maintain a waste diversion rate of 98 percent or higher. If facilities can manage to keep a waste diversion rate of 80 percent or higher, they are recognized as operating with landfill waste diversion.\n\nA zero waste system is one which redesigns the traditional production system. Rather than using natural resources which are scarce, it promotes the reuse of waste to create new products. This process continues endlessly, constantly making product from the waste created by the last production process.\n\nA zero waste society will be led by motivated citizens. Responsible policies must be enacted which will provide regulations to follow to achieve zero waste. Regulations and closed loop manufacturing systems will create a clean and efficient manufacturing process. Programs will be enacted locally to promote education and awareness over the importance of operating at zero waste and ways to effectively do so. Even after a zero waste production process is created, there is still remaining waste that must be properly disposed of. This requires recovery infrastructure. This infrastructure would look to replace landfills. It has a potential to recover upwards of 90% of waste that has entered and is present in landfills to date.\n\n"}
{"id": "2677220", "url": "https://en.wikipedia.org/wiki?curid=2677220", "title": "Lie algebra-valued differential form", "text": "Lie algebra-valued differential form\n\nIn differential geometry, a Lie algebra-valued form is a differential form with values in a Lie algebra. Such forms have important applications in the theory of connections on a principal bundle as well as in the theory of Cartan connections.\n\nA Lie algebra-valued differential \"k\"-form on a manifold, formula_1, is a smooth section of the bundle formula_2, where formula_3 is a Lie algebra, formula_4 is the cotangent bundle of formula_1 and Λ denotes the \"k\" exterior power.\n\nSince every Lie algebra has a bilinear Lie bracket operation, the wedge product of two Lie algebra-valued forms can be composed with the bracket operation to obtain another Lie algebra-valued form. This operation, denoted by formula_6, is given by: for formula_3-valued \"p\"-form formula_8 and formula_3-valued \"q\"-form formula_10\nwhere \"v\"'s are tangent vectors. The notation is meant to indicate both operations involved. For example, if formula_8 and formula_10 are Lie algebra-valued one forms, then one has\nThe operation formula_6 can also be defined as the bilinear operation on formula_16 satisfying\nfor all formula_18 and formula_19.\n\nSome authors have used the notation formula_20 instead of formula_6. The notation formula_20, which resembles a commutator, is justified by the fact that if the Lie algebra formula_23 is a matrix algebra then formula_6 is nothing but the graded commutator of formula_8 and formula_10, i. e. if formula_27 and formula_28 then\nwhere formula_30 are wedge products formed using the matrix multiplication on formula_23.\n\nLet formula_32 be a Lie algebra homomorphism. If φ is a formula_3-valued form on a manifold, then \"f\"(φ) is an formula_34-valued form on the same manifold obtained by applying \"f\" to the values of φ: formula_35.\n\nSimilarly, if \"f\" is a multilinear functional on formula_36, then one puts\nwhere \"q\" = \"q\" + … + \"q\" and φ are formula_3-valued \"q\"-forms. Moreover, given a vector space \"V\", the same formula can be used to define the \"V\"-valued form formula_39 when\nis a multilinear map, φ is a formula_3-valued form and η is a \"V\"-valued form. Note that, when\ngiving \"f\" amounts to giving an action of formula_3 on \"V\"; i.e., \"f\" determines the representation\nand, conversely, any representation ρ determines \"f\" with the condition (*). For example, if formula_44 (the bracket of formula_3), then we recover the definition of formula_46 given above, with ρ = ad, the adjoint representation. (Note the relation between \"f\" and ρ above is thus like the relation between a bracket and ad.) \n\nIn general, if \"α\" is a formula_47-valued \"p\"-form and φ is a \"V\"-valued \"q\"-form, then one more commonly writes α⋅φ = \"f\"(α, φ) when Explicitly,\nWith this notation, one has for example:\n\nExample: If ω is a formula_3-valued one-form (for example, a connection form), ρ a representation of formula_3 on a vector space \"V\" and φ a \"V\"-valued zero-form, then\n\nLet \"P\" be a smooth principal bundle with structure group \"G\" and formula_53. \"G\" acts on formula_3 via adjoint representation and so one can form the associated bundle:\nAny formula_56-valued forms on the base space of \"P\" are in a natural one-to-one correspondence with any tensorial forms on \"P\" of adjoint type.\n\n\n"}
{"id": "2451238", "url": "https://en.wikipedia.org/wiki?curid=2451238", "title": "Logic Spectacles", "text": "Logic Spectacles\n\nLogic Spectacles, Thomas Carlyle's name for eyes that can discern only the external relations of things, but not the inner nature of them.\n"}
{"id": "54604090", "url": "https://en.wikipedia.org/wiki?curid=54604090", "title": "Martha Gruening", "text": "Martha Gruening\n\nMartha Gruening (1889–1937) was an American writer and civil rights activist.\n\nShe was born in Philadelphia, where her father was a well-known doctor, into a Jewish family who spoke German at home. She graduated from Smith College in 1909. After college, Gruening went to Greenwich Village in New York, where she became a relentless political agitator. She wrote and edited \"The Dawn\", a pacifist magazine, and was arrested for \"disorderly conduct\" after distributing pacifist literature in New York. She served as the assistant secretary to the National Association for the Advancement of Colored People and wrote reports on national events for the association. She eventually moved to France and continued to advocate for the rights of black men and women until her death.\n\n"}
{"id": "4823199", "url": "https://en.wikipedia.org/wiki?curid=4823199", "title": "Metatheory", "text": "Metatheory\n\nA metatheory or meta-theory is a theory whose subject matter is some theory. All fields of research share some meta-theory, regardless whether this is explicit or correct. In a more restricted and specific sense, in mathematics and mathematical logic, \"metatheory\" means a \"mathematical theory about another mathematical theory\".\n\nThe following is an example of a meta-theoretical statement:\nMeta-theoretical investigations are generally part of the philosophy of science. Also a metatheory is an object of concern to the area in which the individual theory is conceived.\n\nExamining groups of related theories, a first finding may be to identify classes of theories, thus specifying a taxonomy of theories.\n\nThe concept burst upon the scene of 20th-century philosophy as a result of the work of the German mathematician David Hilbert, who in 1905 published a proposal for proof of the consistency and completeness of mathematics, creating the field of metamathematics. His hopes for the success of this proof were dashed by the work of Kurt Gödel, who in 1931, used his incompleteness theorems to prove this goal of consistency and completeness to be unattainable. Nevertheless, his program of unsolved mathematical problems, out of which grew this metamathematical proposal, continued to influence the direction of mathematics for the rest of the 20th century.\n\nThe study of metatheory became widespread during the rest of that century by its application in other fields, notably scientific linguistics and its concept of metalanguage.\n\n\n"}
{"id": "20018", "url": "https://en.wikipedia.org/wiki?curid=20018", "title": "Metric space", "text": "Metric space\n\nIn mathematics, a metric space is a set for which distances between all members of the set are defined. Those distances, taken together, are called a metric on the set. A metric on a space induces topological properties like open and closed sets, which lead to the study of more abstract topological spaces.\n\nThe most familiar metric space is 3-dimensional Euclidean space. In fact, a \"metric\" is the generalization of the Euclidean metric arising from the four long-known properties of the Euclidean distance. The Euclidean metric defines the distance between two points as the length of the straight line segment connecting them. Other metric spaces occur for example in elliptic geometry and hyperbolic geometry, where distance on a sphere measured by angle is a metric, and the hyperboloid model of hyperbolic geometry is used by special relativity as a metric space of velocities.\n\nIn 1906 Maurice Fréchet introduced metric spaces in his work \"Sur quelques points du calcul fonctionnel\". However the name is due to Felix Hausdorff.\n\nA metric space is an ordered pair formula_1 where formula_2 is a set and formula_3 is a metric on formula_2, i.e., a function\n\nsuch that for any formula_6, the following holds:\n\nThe first condition follows from the other three. Since for any formula_7:\n\nThe function formula_3 is also called \"distance function\" or simply \"distance\". Often, formula_3 is omitted and one just writes formula_2 for a metric space if it is clear from the context what metric is used.\n\nIgnoring mathematical details, for any system of roads and terrains the distance between two locations can be defined as the length of the shortest route connecting those locations. To be a metric there shouldn't be any one-way roads. The triangle inequality expresses the fact that detours aren't shortcuts. If the distance between two points is zero, the two points are indistinguishable from one-another. Many of the examples below can be seen as concrete versions of this general idea.\n\n\nEvery metric space is a topological space in a natural manner, and therefore all definitions and theorems about general topological spaces also apply to all metric spaces.\n\nAbout any point formula_14 in a metric space formula_2 we define the open ball of radius formula_77 (where formula_78 is a real number) about formula_14 as the set\nThese open balls form the base for a topology on \"M\", making it a topological space.\n\nExplicitly, a subset formula_81 of formula_2 is called open if for every formula_14 in formula_81 there exists an formula_77 such that formula_86 is contained in formula_81. The complement of an open set is called closed. A neighborhood of the point formula_14 is any subset of formula_2 that contains an open ball about formula_14 as a subset.\n\nA topological space which can arise in this way from a metric space is called a metrizable space; see the article on metrization theorems for further details.\n\nA sequence (formula_91) in a metric space formula_2 is said to converge to the limit formula_93 iff for every formula_94, there exists a natural number \"N\" such that formula_95 for all formula_96. Equivalently, one can use the general definition of convergence available in all topological spaces.\n\nA subset formula_68 of the metric space formula_2 is closed iff every sequence in formula_68 that converges to a limit in formula_2 has its limit in formula_68.\n\nA metric space formula_2 is said to be complete if every Cauchy sequence converges in formula_2. That is to say: if formula_104 as both formula_73 and formula_72 independently go to infinity, then there is some formula_107 with formula_108.\n\nEvery Euclidean space is complete, as is every closed subset of a complete space. The rational numbers, using the absolute value metric formula_109, are not complete.\n\nEvery metric space has a unique (up to isometry) completion, which is a complete space that contains the given space as a dense subset. For example, the real numbers are the completion of the rationals.\n\nIf formula_30 is a complete subset of the metric space formula_2, then formula_30 is closed in formula_2. Indeed, a space is complete iff it is closed in any containing metric space.\n\nEvery complete metric space is a Baire space.\n\nA metric space \"M\" is called bounded if there exists some number \"r\", such that \"d\"(\"x\",\"y\") ≤ \"r\" for all \"x\" and \"y\" in \"M\". The smallest possible such \"r\" is called the diameter of \"M\". The space \"M\" is called precompact or totally bounded if for every \"r\" > 0 there exist finitely many open balls of radius \"r\" whose union covers \"M\". Since the set of the centres of these balls is finite, it has finite diameter, from which it follows (using the triangle inequality) that every totally bounded space is bounded. The converse does not hold, since any infinite set can be given the discrete metric (one of the examples above) under which it is bounded and yet not totally bounded.\n\nNote that in the context of intervals in the space of real numbers and occasionally regions in a Euclidean space formula_114 a bounded set is referred to as \"a finite interval\" or \"finite region\". However boundedness should not in general be confused with \"finite\", which refers to the number of elements, not to how far the set extends; finiteness implies boundedness, but not conversely. Also note that an unbounded subset of formula_114 may have a finite volume.\n\nA metric space \"M\" is compact if every sequence in \"M\" has a subsequence that converges to a point in \"M\". This is known as sequential compactness and, in metric spaces (but not in general topological spaces), is equivalent to the topological notions of countable compactness and compactness defined via open covers.\n\nExamples of compact metric spaces include the closed interval [0,1] with the absolute value metric, all metric spaces with finitely many points, and the Cantor set. Every closed subset of a compact space is itself compact.\n\nA metric space is compact iff it is complete and totally bounded. This is known as the Heine–Borel theorem. Note that compactness depends only on the topology, while boundedness depends on the metric.\n\nLebesgue's number lemma states that for every open cover of a compact metric space \"M\", there exists a \"Lebesgue number\" δ such that every subset of \"M\" of diameter < δ is contained in some member of the cover.\n\nEvery compact metric space is second countable, and is a continuous image of the Cantor set. (The latter result is due to Pavel Alexandrov and Urysohn.)\n\nA metric space is said to be locally compact if every point has a compact neighborhood. Euclidean spaces are locally compact, but infinite-dimensional Banach spaces are not.\n\nA space is proper if every closed ball {\"y\" : \"d\"(\"x\",\"y\") ≤ \"r\"} is compact. Proper spaces are locally compact, but the converse is not true in general.\n\nA metric space formula_2 is connected if the only subsets that are both open and closed are the empty set and formula_2 itself.\n\nA metric space formula_2 is path connected if for any two points formula_7 there exists a continuous map formula_120 with formula_121 and formula_122.\nEvery path connected space is connected, but the converse is not true in general.\n\nThere are also local versions of these definitions: locally connected spaces and locally path connected spaces.\n\nSimply connected spaces are those that, in a certain sense, do not have \"holes\".\n\nA metric space is separable space if it has a countable dense subset. Typical examples are the real numbers or any Euclidean space. For metric spaces (but not for general topological spaces) separability is equivalent to second-countability and also to the Lindelöf property.\n\nIf formula_30 is a nonempty metric space and formula_124 then formula_125 is called a \"pointed metric space\", and formula_126 is called a \"distinguished point\". Note that a pointed metric space is just a nonempty metric space with attention drawn to its distinguished point, and that any nonempty metric space can be viewed as a pointed metric space. The distinguished point is sometimes denoted formula_23 due to its similar behavior to zero in certain contexts.\n\nSuppose (\"M\",\"d\") and (\"M\",\"d\") are two metric spaces.\n\nThe map \"f\":\"M\"→\"M\" is continuous\nif it has one (and therefore all) of the following equivalent properties:\n\nMoreover, \"f\" is continuous if and only if it is continuous on every compact subset of \"M\".\n\nThe image of every compact set under a continuous function is compact, and the image of every connected set under a continuous function is connected.\n\nThe map \"ƒ\" : \"M\" → \"M\" is uniformly continuous if for every \"ε\" > 0 there exists \"δ\" > 0 such that\n\nEvery uniformly continuous map \"ƒ\" : \"M\" → \"M\" is continuous. The converse is true if \"M\" is compact (Heine–Cantor theorem).\n\nUniformly continuous maps turn Cauchy sequences in \"M\" into Cauchy sequences in \"M\". For continuous maps this is generally wrong; for example, a continuous map\nfrom the open interval (0,1) \"onto\" the real line turns some Cauchy sequences into unbounded sequences.\n\nGiven a real number \"K\" > 0, the map \"ƒ\" : \"M\" → \"M\" is \"K\"-Lipschitz continuous if\n\nEvery Lipschitz-continuous map is uniformly continuous, but the converse is not true in general.\n\nIf \"K\" < 1, then \"ƒ\" is called a contraction. Suppose \"M\" = \"M\" and \"M\" is complete. If \"ƒ\" is a contraction, then \"ƒ\" admits a unique fixed point (Banach fixed point theorem). If \"M\" is compact, the condition can be weakened a bit: \"ƒ\" admits a unique fixed point if\n\nThe map \"f\":\"M\"→\"M\" is an isometry if\nIsometries are always injective; the image of a compact or complete set under an isometry is compact or complete, respectively. However, if the isometry is not surjective, then the image of a closed (or open) set need not be closed (or open).\n\nThe map \"f\" : \"M\" → \"M\" is a quasi-isometry if there exist constants \"A\" ≥ 1 and \"B\" ≥ 0 such that\n\nand a constant \"C\" ≥ 0 such that every point in \"M\" has a distance at most \"C\" from some point in the image \"f\"(\"M\").\n\nNote that a quasi-isometry is not required to be continuous. Quasi-isometries compare the \"large-scale structure\" of metric spaces; they find use in geometric group theory in relation to the word metric.\n\nGiven two metric spaces (\"M\", \"d\") and (\"M\", \"d\"):\n\n\nMetric spaces are paracompact Hausdorff spaces and hence normal (indeed they are perfectly normal). An important consequence is that every metric space admits partitions of unity and that every continuous real-valued function defined on a closed subset of a metric space can be extended to a continuous map on the whole space (Tietze extension theorem). It is also true that every real-valued Lipschitz-continuous map defined on a subset of a metric space can be extended to a Lipschitz-continuous map on the whole space.\n\nMetric spaces are first countable since one can use balls with rational radius as a neighborhood base.\n\nThe metric topology on a metric space \"M\" is the coarsest topology on \"M\" relative to which the metric \"d\" is a continuous map from the product of \"M\" with itself to the non-negative real numbers.\n\nA simple way to construct a function separating a point from a closed set (as required for a completely regular space) is to consider the distance between the point and the set. If (\"M\",\"d\") is a metric space, \"S\" is a subset of \"M\" and \"x\" is a point of \"M\", we define the distance from \"x\" to \"S\" as\n\nThen \"d\"(\"x\", \"S\") = 0 if and only if \"x\" belongs to the closure of \"S\". Furthermore, we have the following generalization of the triangle inequality:\nwhich in particular shows that the map formula_137 is continuous.\n\nGiven two subsets \"S\" and \"T\" of \"M\", we define their Hausdorff distance to be\n\nIn general, the Hausdorff distance \"d\"(\"S\",\"T\") can be infinite. Two sets are close to each other in the Hausdorff distance if every element of either set is close to some element of the other set.\n\nThe Hausdorff distance \"d\" turns the set \"K\"(\"M\") of all non-empty compact subsets of \"M\" into a metric space. One can show that \"K\"(\"M\") is complete if \"M\" is complete.\n\nOne can then define the Gromov–Hausdorff distance between any two metric spaces by considering the minimal Hausdorff distance of isometrically embedded versions of the two spaces. Using this distance, the class of all (isometry classes of) compact metric spaces becomes a metric space in its own right.\n\nIf formula_140 are metric spaces, and \"N\" is the Euclidean norm on \"R\", then formula_141 is a metric space, where the product metric is defined by\n\nand the induced topology agrees with the product topology. By the equivalence of norms in finite dimensions, an equivalent metric is obtained if \"N\" is the taxicab norm, a p-norm, the max norm, or any other norm which is non-decreasing as the coordinates of a positive \"n\"-tuple increase (yielding the triangle inequality).\n\nSimilarly, a countable product of metric spaces can be obtained using the following metric\n\nAn uncountable product of metric spaces need not be metrizable. For example, formula_144 is not first-countable and thus isn't metrizable.\n\nIn the case of a single space formula_1, the distance map formula_146 (from the definition) is uniformly continuous with respect to any of the above product metrics formula_147, and in particular is continuous with respect to the product topology of formula_148.\n\nIf \"M\" is a metric space with metric \"d\", and \"~\" is an equivalence relation on \"M\", then we can endow the quotient set \"M/~\" with the following (pseudo)metric. Given two equivalence classes [\"x\"] and [\"y\"], we define\n\nwhere the infimum is taken over all finite sequences formula_150 and formula_151 with formula_152, formula_153, formula_154. In general this will only define a pseudometric, i.e. formula_155 does not necessarily imply that formula_156. However, for nice equivalence relations (e.g., those given by gluing together polyhedra along faces), it is a metric.\n\nThe quotient metric \"d\" is characterized by the following universal property. If formula_157 is a metric map between metric spaces (that is, formula_158 for all \"x\", \"y\") satisfying \"f\"(\"x\")=\"f\"(\"y\") whenever formula_159 then the induced function formula_160, given by formula_161, is a metric map formula_162\n\nA topological space is sequential if and only if it is a quotient of a metric space.\n\n\nThe ordered set formula_164 can be seen as a category by requesting exactly one morphism formula_165 if formula_166 and none otherwise. By using formula_167 as the tensor product and formula_23 as the identity, it becomes a monoidal category formula_169.\nEvery metric space formula_1 can now be viewed as a category formula_171 enriched over formula_169:\n\nSee the paper by F.W. Lawvere listed below.\n\n\nThis is reprinted (with author commentary) at Reprints in Theory and Applications of Categories\nAlso (with an author commentary) in Enriched categories in the logic of geometry and analysis. Repr. Theory Appl. Categ. No. 1 (2002), 1–37.\n\n"}
{"id": "1190101", "url": "https://en.wikipedia.org/wiki?curid=1190101", "title": "Metta World Peace", "text": "Metta World Peace\n\nMetta World Peace (born Ronald William Artest Jr.; November 13, 1979) is an American professional basketball coach and former player. He is currently the player development coach for the South Bay Lakers of the NBA G League. He was known as Ron Artest before legally changing his name in September 2011.\n\nWorld Peace gained a reputation as one of the league's premier defenders as he won the NBA Defensive Player of the Year Award in 2004, when he was also named an NBA All-Star and earned All-NBA honors. He was a participant in several controversial on-court incidents, most notably the Malice at the Palace, and is known for his sometimes eccentric and outspoken behavior. He won an NBA championship in 2010 as a member of the Los Angeles Lakers.\n\nArtest played high school basketball at La Salle Academy and college basketball at St. John's University. He has played for six teams in the NBA.\n\nMetta World Peace was born Ronald William Artest Jr. on November 13, 1979, and raised in the Queensbridge projects in Queens, New York. He has two younger brothers, Isaiah and Daniel. He played high school basketball at La Salle Academy. He also teamed with future NBA players Elton Brand and Lamar Odom on the same Amateur Athletic Union (AAU) team.\n\nGrowing up, Artest witnessed the murder of a fellow player on a basketball court in Niagara Falls, New York. \"It was so competitive, they broke a leg from a table and they threw it, it went right through his heart and he died right on the court. So I'm accustomed to playing basketball really rough.\" The player to whom Artest was referring was 19-year-old Lloyd Newton, who was stabbed in the back with a broken-off table leg during an altercation at a 1991 YMCA-sanctioned basketball tournament.\n\nArtest played college basketball at St. John's University from 1997 to 1999. At St. John's, he majored in mathematics. In 1999, he led the Red Storm to a 14-4 record in the Big East Conference and 28-9 overall and the Elite Eight of the NCAA Division I Tournament, losing to Ohio State.\n\nArtest gained fame playing in some of New York City's high-profile summer basketball tournaments at Nike Pro City, Hoops in the Sun at Orchard Beach, Bronx, New York and Dyckman Park at Washington Heights, earning himself nicknames such as Tru Warier and The New World Order, a name he received from Randy Cruz (one of the co-founders of the Hoops In The Sun basketball league at Orchard Beach).\n\nArtest was selected by the Chicago Bulls with the 16th pick of the 1999 NBA draft.\n\nArtest played a total of 175 games for the Bulls over 2-1/2 years, the bulk as a starter, during which time he averaged about 12.5 points and just over 4 rebounds per game. He was named to the NBA All-Rookie Second Team in the 1999–2000 season.\n\nMidway through the 2001–02 season, Artest was traded by Chicago to the Indiana Pacers along with Ron Mercer, Brad Miller, and Kevin Ollie, in exchange for Jalen Rose, Travis Best, Norman Richardson, and a 2nd round draft pick.\n\nDuring the 2003–04 season with the Pacers, he averaged 18.3 points per game, 5.7 rebounds per game, and 3.7 assists per game. Artest made the 2004 NBA All-Star Game as a reserve and was named the Defensive Player of the Year. He wore three jersey numbers for the Pacers: 15, 23, and 91.\n\nOn November 19, 2004, Artest was at the center of an altercation among players and fans during a game in Auburn Hills, Michigan, between Artest's Pacers and the home team Detroit Pistons. The brawl involved Artest, Pistons center Ben Wallace, Artest's teammates Jermaine O'Neal and Stephen Jackson, several other players, and spectators including Pistons fans John Green and A.J. Shackleford.\n\nThe fight resulted in the game being stopped with less than a minute remaining. O'Neal, Jackson and Wallace were suspended indefinitely the day after the game. A day later, the NBA suspended Artest for the rest of the regular season, plus any playoff games. Artest missed 86 games, the longest suspension for an on-court incident in NBA history.\n\nEarly in the 2005–06 season, Artest requested a trade from the Indiana Pacers and was put on the team's inactive roster. Artest's call for a trade created a rift between him and his teammates. \"We felt betrayed, a little disrespected\", teammate Jermaine O'Neal said. As for their basketball relationship, O'Neal said: \"The business relationship is over. That's fact.\" Pacers president Larry Bird said he also felt \"betrayed\" and \"disappointed\".\n\nOn January 24, 2006, reports from NBA sources confirmed that the Sacramento Kings had agreed to trade Peja Stojaković to the Pacers for Artest. However, before the trade could be completed, many press outlets reported that Artest had informed team management that he did not want to go to Sacramento. According to Artest's agent, his original trade request was only made because he was upset when he heard rumors that the Pacers were going to trade him to Sacramento for Stojaković early in the season. While not denying his agent's story, Artest did deny that he had rejected the trade to Sacramento, saying that he would play anywhere; hence, contradicting earlier press accounts stating Artest was holding up the trade. Given conflicting accounts, it is unclear why the trade was delayed, but it was nevertheless completed on January 25 and Artest was officially sent to the Kings for Stojaković.\n\nThough traded midseason to the Kings franchise, Artest quickly found his place on the team by providing some much needed defense. Though many feared his abrasive personality would be a problem, he worked well with his teammates and then-coach Rick Adelman. Artest wore #93 for his jersey number with the Kings. After acquiring Artest in late January 2006, the team immediately went on a 14–5 run, the team's best run of the season. The Kings broke .500 and landed the eighth spot in the Western Conference. This prompted ESPN to declare that \"Ron Artest has breathed new life in the Sacramento Kings and enhanced their chances of reaching the playoffs for the ninth straight year.\" Fox Sports proclaimed, \"Artest has Kings back in playoff hunt.\"\n\nHe was suspended for Game 2 of the team's first-round series against the San Antonio Spurs following a flagrant foul (elbow to the head) on Manu Ginóbili. The Kings eventually were eliminated from the playoffs in six games.\n\nAfter the playoffs, Artest offered to donate his entire salary to keep teammate Bonzi Wells with the team, who became a free agent after the 2005–06 NBA season. He even jokingly threatened to kill Wells if he did not re-sign with the Kings. Wells was later picked up by the Houston Rockets and then traded to the New Orleans Hornets for former Sacramento Kings player Bobby Jackson. Artest also offered to donate his salary to retain the services of head coach Rick Adelman, whose contract expired after the same season. Adelman and the Kings did not agree on a contract extension so the two parted ways.\n\nOn July 29, 2008, it was reported that Artest was to be traded to the Houston Rockets along with Patrick Ewing, Jr. and Sean Singletary for Bobby Jackson, recently drafted forward Donté Greene, a 2009 first-round draft pick, and cash considerations. The deal was made official on August 14, due to Greene's rookie contract signing on July 14. In response to the trade, Yao Ming was generally positive, but jokingly said that \"hopefully he's not fighting anymore and going after a guy in the stands.\" In response, Artest said, \"This is Tracy (McGrady) and Yao's team, you know. I'm not going to take it personal. I understand what Yao said, but I'm still ghetto. That's not going to change. I'm never going to change my culture. Yao has played with a lot of black players, but I don't think he's ever played with a black player that really represents his culture as much as I represent my culture.\"\n\nArtest and Yao later exchanged extensive phone calls. Artest also said, \"Whatever Adelman needs me to do, whether that's come off the bench, sixth, seventh man, start, I don't even care. Whatever he needs me to do, I'm 100 percent sure it's going to work out.\"\n\nOn October 30, 2008, Artest received his first technical as a Houston Rocket, as he raced towards a group of Dallas Mavericks players and then quickly went to Yao Ming who bumped Josh Howard after play stopped. Artest was trying to pull Yao away from the play and to the foul line, but contact was made with Maverick players. The TNT broadcast crew felt this technical was not warranted, and was based upon Artest's prior reputation as a feisty player in the league. In the playoffs, Artest helped the Rockets advance past the first round for the first time in 12 seasons. In Game 2 of the second round against the Los Angeles Lakers, Artest, who was battling for rebounding position with Kobe Bryant, was elbowed in the neck by Bryant, which was later ruled to be a Type 1 flagrant foul. After being called for an offensive foul, Artest was indignant and proceeded to antagonize Bryant after the play, which eventually led to an ejection by Joe Crawford. In Game 3, Artest was again ejected in the fourth quarter after a hard foul on Pau Gasol, who was attempting to dunk on a fast-break. It was determined the next day that the foul was not serious enough to warrant an ejection, and the flagrant foul was downgraded.\n\nIn July 2009, the Los Angeles Lakers signed Artest to a five-year deal worth about $33 million. Artest chose the number 37 jersey, which he said was in honor of Michael Jackson. Jackson's \"Thriller\" album was at No. 1 on the charts for 37 straight weeks.\n\nIn Game 5 of the 2010 Western Conference Finals, Artest hit a game-winning shot at the buzzer after grabbing a last second offensive rebound. He scored 25 points against the Phoenix Suns in Game 6 and went to the NBA Finals for the first time in his career. In the finals, the Lakers defeated the Boston Celtics, four games to three. Artest scored 20 points in the clincher and sank the team's last field goal – a three-pointer late in the fourth quarter – to virtually seal the victory. Afterwards, Lakers head coach Phil Jackson called Artest the most valuable player of Game 7 against the Celtics. He won his first championship ring with the Lakers.\n\nFor the 2010–2011 season, Artest switched back to number 15, his college number at St. John's and the first number he wore in his NBA career.\n\nOn April 26, 2011, Artest won the NBA's J. Walter Kennedy Citizenship Award.\n\nArtest changed his name to \"Metta World Peace\" during the offseason. He came into training camp for the out of shape. Consequently, new Lakers coach Mike Brown moved World Peace to a reserve role with reduced playing time. World Peace lamented that Brown's coaching style placed too much emphasis on statistics.\nOn April 22, 2012, in a game against the Oklahoma City Thunder, World Peace elbowed James Harden in the head as he was celebrating a dunk. He received a flagrant foul 2 and was immediately ejected. Harden stayed on the floor for several minutes and left the game for evaluation. Harden was later found to have suffered a concussion. After the game, World Peace apologized in front of reporters, stating that the elbow was \"unintentional.\" On April 24, 2012, World Peace was suspended for seven games, meaning he would miss the Lakers' season finale game against the Sacramento Kings as well as the first few games of the playoffs.\n\nAfter a 1–4 start to the 2012–13 season, the Lakers fired Brown as head coach and hired Mike D'Antoni. On December 18, 2012, in a win against the Philadelphia 76ers, he grabbed a career high 16 rebounds to add to his 19 points. On January 11, 2013, he suffered a right leg injury against the Thunder that would hamper him for two months. Around the same time, he also had an injury to his right arm that made it difficult to bend. His health worsened to the point where D'Antoni moved him off the perimeter on defense and had him guard power forwards instead. By mid-March, he was able to guard the perimeter again. On March 25, against the Golden State Warriors, World Peace tore the lateral meniscus in his left knee. He underwent surgery that was originally estimated to sideline him for six weeks. Despite the estimates, he returned 12 days after his surgery. In his absence, D'Antoni was using a reduced seven-man rotation with Kobe Bryant playing close to all 48 minutes each game. World Peace wanted to reduce his teammates' workload, if even for a few minutes, as the Lakers fought to qualify for the playoffs. The Lakers qualified for the playoffs as the seventh seed, but were swept 4–0 by San Antonio in the first round. Due to the Lakers' other injuries, World Peace played in Game 3 in spite of running with discomfort after having fluid drained from a cyst behind his surgically repaired left knee. He missed the final game of the series, and later admitted he came back too soon. For the season, he averaged his most points (12.4) since 2008–09, and shot his highest percentage (.404) since 2009–10. Still, ESPN wrote those numbers indicated that \"the 33-year-old is clearly on the decline\".\n\nOn July 11, 2013, after four seasons with the Lakers, the team waived World Peace via the amnesty clause to gain relief from the salary cap.\n\nOn July 16, 2013, World Peace signed a two-year deal with the New York Knicks. On February 24, 2014, he was waived by the Knicks after they bought out his contract.\n\nOn August 4, 2014, World Peace signed with the Sichuan Blue Whales of the Chinese Basketball Association. Due to a recurrent knee injury, he was replaced on the roster in December 2014 with Daniel Orton. In 15 games, World Peace averaged 19 points, 6 rebounds and 2.3 steals per game.\n\nOn March 24, 2015, World Peace signed with Pallacanestro Cantù of Italy for the rest of the 2014–15 Lega Basket Serie A season. On May 27, 2015, in Cantù's Game 5 quarter-final loss to Reyer Venezia Mestre which ended their season, World Peace was ejected from the game and charged with five fouls after getting involved in a skirmish during the fourth quarter. In July 2015, he parted ways with the club after the two parties could not come to a new contract agreement.\n\nOn September 24, 2015, World Peace signed with the Los Angeles Lakers, returning to the franchise for a second stint. On November 6, 2015, he made his season debut in a 104–98 win over the Brooklyn Nets, playing 17 minutes with a plus-minus of 12. Teammate Kobe Bryant praised him for his impact on \"everybody on the floor defensively\".\n\nOn September 21, 2016, World Peace re-signed with the Lakers. On April 11, 2017, World Peace scored a team-leading 18 points in the second half to help the Lakers extend its longest winning streak in four years to five games with a 108–96 victory over the New Orleans Pelicans. He had the ball in his hands with the crowd on its feet for the Lakers' final possession in what was potentially his final game at Staples Center. During the game, he got his 1,716th and 1,717th career steals to move past Ron Harper for 22nd place in NBA history. During the offseason, World Peace played with the New Orleans Gators of the Global Mixed Gender Basketball (GMGB) League.\n\nOn October 23, 2017, World Peace was hired as a player development coach by the South Bay Lakers, the Los Angeles Lakers' development-league team in the NBA G League. During the offseason in 2018, he played 3x3 basketball with the BIG3. He played under the name Ron Artest at the request of league co-founder Ice Cube, who wanted to \"turn back the clock a little bit\".\n\nIn April 2010, it was announced that Artest would help develop and produce his own reality show, \"They Call Me Crazy\", in conjunction with E1 Entertainment and Tijuana Entertainment.\n\nOn December 18, 2010, an art show honoring Artest was held in Toronto, Canada. Entitled Lovable Badass, the show featured work by 30 Canadian and American artists, illustrators, painters and sculptors inspired by the athlete. Artest made a surprise appearance at the exhibition's opening night, commenting that \"(the show) was definitely special. It was unexpected. Overwhelming.\"\n\nArtest was part of the line-up for the thirteenth season of the reality show \"Dancing with the Stars\", though he finished in last place, being eliminated in the show's first week.\n\nIn October 2012, he guest starred as a special panelist on Nickelodeon's game show \"Figure It Out\".\n\nIn September 2013, he made the first in a recurring series of skits on the Comedy Central sketch show \"Key and Peele\" called \"Metta World News\", in which he plays a newscaster.\n\nIn January 2018, it was announced that World Peace was a contestant in the first U.S. edition of Celebrity Big Brother. Metta became the fourth celebrity to be evicted from the house on Day 20.\n\nWorld Peace is the founder of the Artest Media Group. Established in 2010, the brand management company's clients include himself and music artists Vinita, Deacon, Sade Artest, Rugby, and Emmaline Cleary. Music producers Wip, Q, and Lucky are also associated with the group. On February 19, 2013, World Peace was awoken by a squad of police who received a tip there had been gun play within his property. Authorities were quick to recognize their mistake after World Peace explained that the armed individuals were actors shooting a \"life on the streets\"-styled movie for his group.\n\nOn October 31, 2006, Artest released a rap album entitled \"My World\". He published the album on the Lightyear Records label under his own imprint, Tru Warier Records. The album features guest artists P. Diddy, Juvenile, Mike Jones, Big Kap, Nature and Capone.\n\nHe has become involved in advocacy relating to mental health issues. In December 2010, he announced that he would donate some or all of his salary for the 2011–12 NBA season toward mental health awareness charities. Artest also auctioned off his 2009–10 championship ring and donated the proceeds to various mental health charities nationwide. In 2016, he told \"Sports Illustrated\", \"Some people don’t understand mental health is broad. You have to ask questions. Are you depressed? Are you schizophrenic? Do you have anxiety? Are you bipolar? Those are the different things that come under the banner of mental health.\"\n\nHe has posed for PETA ad campaigns encouraging people to report animal abuse and to have their pets fixed.\n\nDuring his rookie season in Chicago, he was criticized for applying for a job at Circuit City in order to get an employee discount. In a December 2009 \"Sporting News\" interview, Artest admitted that he had led a \"wild\" lifestyle as a young player, and that he drank Hennessy cognac in the locker room at halftime while with the Bulls. In February 2004, he wore a bathrobe over his practice uniform to a Pacers practice as \"a symbolic reminder to take it easy\".\n\nArtest was suspended for three games in 2003 for destroying a TV camera at Madison Square Garden, and for four games the same year for a confrontation with Miami Heat coach Pat Riley. He was also suspended for two games early in the 2004–05 season by Pacers head coach Rick Carlisle after he allegedly asked for a month off because he was tired from promoting an R&B album for the group Allure on his Tru Warier production label, on which he released his own album, a rap recording titled \"My World\", in October 2006.\n\nOn November 19, 2004, Artest was at the center of an altercation among players and fans during a game in Auburn Hills, Michigan between Artest's Pacers and the home team Detroit Pistons.\n\nThe brawl began when Artest fouled Pistons center Ben Wallace as Wallace was putting up a shot. Wallace, upset at being fouled hard when the game was effectively over (the Pacers led 97–82 with less than 50 seconds to go), responded by shoving Artest, leading to an altercation near the scorer's table. Artest walked to the sideline and lay down on the scorer's table. Reacting to Wallace throwing something at Artest, Pistons fan John Green threw a cup of Diet Coke at Artest, hitting him. Artest jumped into the front-row seats and confronted a man he incorrectly believed to be responsible, which in turn erupted into a brawl between Pistons fans and several of the Pacers. Artest returned to the basketball court, and punched Pistons fan A.J. Shackleford, who was apparently taunting Artest verbally. This fight resulted in the game being stopped with less than a minute remaining. Artest's teammates Jermaine O'Neal and Stephen Jackson were suspended indefinitely the day after the game, along with Wallace.\n\nOn November 21, the NBA suspended Artest for the rest of the regular season, plus any playoff games. All told, Artest missed 86 games (73 regular season games plus 13 playoff games), the longest suspension for an on-court incident in NBA history. Eight other players (four Pacers and four Pistons) received suspensions, without pay, which ranged from one to thirty games in length. Each of the players involved were levied fines and ordered to do community service. Several fans were also charged and were banned from attending Pistons games for life. Artest lost approximately $5 million in salary due to the suspension.\n\nOn March 5, 2007, Artest was arrested for domestic violence, and excused from the Sacramento Kings indefinitely by GM Geoff Petrie. On March 10, Kings announced that Artest would return to the team, while his case was being reviewed by the Placer County District Attorney. On May 3, he was sentenced to 20 days in jail and community service. Artest spent only 10 days in the jail, as the judge stayed 10 days of the sentence, and served the remainder in a work release program. On July 14, 2007, the NBA suspended Artest for seven games at the beginning of the 2007–08 NBA season for his legal problems.\n\nOn September 16, 2011, Artest's name was officially changed to Metta World Peace. \"Metta\" is his first name, and \"World Peace\" is his surname. \"Changing my name was meant to inspire and bring youth together all around the world\", World Peace said in a statement released after the name change court hearing. His publicist, Courtney Barnes, said that World Peace chose Metta as his first name because it is a traditional Buddhist word that means loving kindness and friendliness towards all.\n\nWorld Peace and Kimsha Artest (née Hatfield) were married for 6 years. Kimsha was a cast member on VH1's reality TV show \"\". The two have three children together: Sadie, Ron III, and Diamond. Kimsha and World Peace, who was still named Ron Artest at the time, married in June 2003 and divorced in 2009. World Peace has another son, Jeron, with his former high school girlfriend Jennifer Palma.\n\nIn the late 1990s, World Peace became a close friend of American-born Irish basketball legend, Jermaine Turner. The pair met on the playgrounds of New York and played together in tournaments at Rucker Park.\n\n\n"}
{"id": "48735002", "url": "https://en.wikipedia.org/wiki?curid=48735002", "title": "Mãe Menininha do Gantois", "text": "Mãe Menininha do Gantois\n\nMãe Menininha do Gantois (10 February 1894 – 13 August 1986) also known as Mother Menininha do Gantois, was a Brazilian spiritual leader \"(iyalorixá)\" and spiritual daughter of orixá Oxum, who officiated for 64 years as the head of one of the most noted Candomblé temples, the Ilê Axé Iyá Omin Iyamassê, or Terreiro do Gantois, of Brazil, located in Alto do Gantois in Salvador, Bahia. She was instrumental in gaining legal recognition of Candomblé and its rituals, bringing an end to centuries of prejudice against Afro-Brazilians, who practiced their faith. When she died on 13 August 1986, the State of Bahia declared a three-day state mourning in her honour, and the City Council of Salvador held a special session to pay tributes to her. The Terreiro do Gantois temple has been declared a protected national monument.\n\nMaria Escolástica da Conceição Nazaré Assunção was born on 10 February 1894 in Salvador, Bahia. Her grand mother, who had baptized her, gave her the nickname as Menininha meaning \"Little girl\" She was born into a matriarchal society to Maria da Glória and Joaquim Assunção, who were Afro-Brazilian with Yoruba Nigerian royal ancestry from Egba-Alakê in Abeokutá, a kingdom in the southwestern part of Nigeria. \nHer great grandparents, Maria Júlia da Conceição do Nazaré and Francisco Nazaré Eta, were the first blacks to be freed from slavery. Maria Júlia's daughter Damiana was the mother of . Menininha was initiated into the worship of deities at the Terreiro do Gantois when she was 8 years old by her grandmother Maria Julia da Conceição Nazaré who had built the temple \"Ile Iyá Omi Axé Iyamassê\". She was married to Alvaro MacDowell de Oliveira and they had two daughters. The elder daughter was Mãe Cleusa da Conceição Nazaré de Oliveira, born in 1923, who was a doctor and who became the inherited Candomblé priestess of the temple after her mother's death. She died in 1998 and was succeeded by Menininha's other daughter, Mãe Carmem. As spiritual heads of their temple, all of the Candomblé priestesses receive the honorific 'mãe', which in the Portuguese language means \"mother\".\n\nThe temple, which she headed was established by her grandmother Mãe Pulquéria following a dispute over leadership from Engenho Velho, an older temple said to be one of the oldest Candomblé temple (1830 or even 100 years older) in Bahia which had been built by three freed African women. Two temples were built, one was the Terreiro do Gantois built in 1900 by Mãe Pulquéria and the other was Ile Axe Opo Afonja credited to Mãe Aninha. Mãe Pulquéria, who was the functional head of the Terreiro do Gantois, died suddenly in 1918. As she had no children, her niece Maria da Glória Nazaré was designated as her successor, but Maria died in 1920 before assuming office. Then according to hierarchical rights the temple was given to Mother Menininha. This process was confirmed by deities Oxóssi, Shango, Oshun and Babalú-Ayé. Once chosen and confirmed in 1922 Menininha became the head of the Candomblé do Gantois. She dedicated her life to the temple and for the cause of the African religion of Candomblé which represented to her the \"last stronghold of the black dignity\". She faced persecution at the hands of the Brazilian government and even incarceration, as well as being subjected to harassment. She defended the African-Brazilian traditions of worship at the Terreiro do Gantois and other Terreiros at Engenho Velho and Casa Branca. Her struggle, in association with other well known candomblé priesteses like Stella de Oxossi, asserted the Africanness of Candombé, stressing the fact that their religion was not the same as Roman Catholicism.\n\nOne of the reasons she became prominent was that she initiated hundreds of \"daughters\" into the faith, as well as artists, and invited the academic community to study the roots of the religion. One of those academics, Ruth Landes compiled her findings and published a book, \"City of Women\" (1947) discussing how the racial policies of the government were intertwined with the Candomblé religious rites. Antônio Carlos Magalhães, a powerful senator from Bahia; Carybé, the illustrator; and and Pierre Verger, two other anthropologists who studied Afro-Brazilian communities, were also prominent connections used by Menininha to further study and promote the validity of Candomblé. These studies were influential in furthering research on the Nigerian roots of the religion, but at the same time brought criticism from other temples in the faith that Menininha was exploiting the religion. However, her success in obtaining legalization of the religion in the 1970s facilitated the first freedom to practice their faith in hundreds of years and began the process of eliminating prejudice against other Afro-Brazilian faiths.\n\nMenininha died at the age of 92 on 13 August 1986. At the special session held in the City Council of Salvador to commemorate her death, Edvaldo Britto, Deputy Mayor; Pedro Godinho, President of the House; her friends; and attended. Veloso paid a tribute to the mother by highlighting her role as the priestess in leading the resistance and fighting against discrimination and religious faith. Her successor to the temple was her daughter Cleusa who was chosen as priestess in 1989. Upon Cleusa's death, the deities chose her younger sister, to succeed her. Menininha became a symbol of motherhood and spiritual daughter of the Orixa Oxum. Her ritual chair, which appears like a throne, is placed at the entry to the city museum in Salvador.\n\nMany songs have been written paryear songs seeking her blessings and spiritual guidance. Beth Carvalho, a famous singer paid tribute to her in his composition titled \"'O Encanto do Gantois\", in 1985. One of these poems reads:\nPrayer to Mother Menininha<br>Oh my mother<br>My Mother Menininha<br>Oh my mother<br>The little girl Gantois<br>The most beautiful star, <br> huh? It's in the Gantois <br>And the brightest sun, <br>huh? It's in the Gantois<br>The beauty of the world,<br> huh? It's in the Gantois<br> And the hand of sweetness,<br> huh? It's in the Gantois<br>The comfort us, eh? It's in the Gantois<br>And Oshun more beautiful, huh? It's in the Gantois <br>Olorun who sent <br>This daughter of Oshun <br>Take care of us <br> And all that is <br>Olorun who sent ô ô <br>Now yeh yeh ô ...<br>Now yeh yeh ô\n\n"}
{"id": "8499571", "url": "https://en.wikipedia.org/wiki?curid=8499571", "title": "Negative probability", "text": "Negative probability\n\nThe probability of the outcome of an experiment is never negative, although a quasiprobability distribution allows a negative probability, or quasiprobability for some events. These distributions may apply to unobservable events or conditional probabilities.\n\nIn 1942, Paul Dirac wrote a paper \"The Physical Interpretation of Quantum Mechanics\" where he introduced the concept of negative energies and negative probabilities:\n\nThe idea of negative probabilities later received increased attention in physics and particularly in quantum mechanics. Richard Feynman argued that no one objects to using negative numbers in calculations: although \"minus three apples\" is not a valid concept in real life, negative money is valid. Similarly he argued how negative probabilities as well as probabilities above unity possibly could be useful in probability calculations.\n\nMark Burgin gives another example:\nNegative probabilities have later been suggested to solve several problems and paradoxes. \"Half-coins\" provide simple examples for negative probabilities. These strange coins were introduced in 2005 by Gábor J. Székely. Half-coins have infinitely many sides numbered with 0,1,2... and the positive even numbers are taken with negative probabilities. Two half-coins make a complete coin in the sense that if we flip two half-coins then the sum of the outcomes is 0 or 1 with probability 1/2 as if we simply flipped a fair coin.\n\nIn \"Convolution quotients of nonnegative definite functions\" and \"Algebraic Probability Theory\" Imre Z. Ruzsa and Gábor J. Székely proved that if a random variable X has a signed or quasi distribution where some of the probabilities are negative then one can always find two random variables, Y and Z, with ordinary (not signed / not quasi) distributions such that X, Y are independent and X + Y = Z in distribution. Thus X can always be interpreted as the \"difference\" of two ordinary random variables, Z and Y. If Y is interpreted as a measurement error of X and the observed value is Z then the negative regions of the distribution of X are masked / shielded by the error Y.\n\nAnother example known as the Wigner distribution in phase space, introduced by Eugene Wigner in 1932 to study quantum corrections, often leads to negative probabilities. For this reason, it has later been better known as the Wigner quasiprobability distribution. In 1945, M. S. Bartlett worked out the mathematical and logical consistency of such negative valuedness. The Wigner distribution function is routinely used in physics nowadays, and provides the cornerstone of phase-space quantization. Its negative features are an asset to the formalism, and often indicate quantum interference. The negative regions of the distribution are shielded from direct observation by the quantum uncertainty principle: typically, the moments of such a non-positive-semidefinite quasiprobability distribution are highly constrained, and prevent \"direct measurability\" of the negative regions of the distribution. But these regions contribute negatively and crucially to the expected values of observable quantities computed through such distributions, nevertheless.\n\nConsider a double slit experiment with photons. The two waves exiting each slit can be written as:\n\nformula_1\n\nand\n\nformula_2\n\nwhere \"d\" is the distance to the detection screen, \"a\" is the separation between the two slits, \"x\" the distance to the center of the screen, \"λ\" the wavelength and \"dN/dt\" is the number of photons emitted per unit time at the source. The amplitude of measuring a photon at distance \"x\" from the center of the screen is the sum of these two amplitudes coming out of each hole, and therefore the probability that a photon is detected at position \"x\" will be given by the square of this sum:\n\nformula_3,\n\nThis should strike you as the well-known probability rule:\n\nformula_4\n\nwhatever the last term means. Indeed, if one closes either one of the holes forcing the photon to go through the other slit, the two corresponding intensities are\n\nformula_5 and formula_6.\n\nBut now, if one does interpret each of these terms in this way, the joint probability takes negative values roughly every formula_7 !formula_8\n\nHowever, these negative probabilities are never observed as one can't isolate the cases in which the photon \"goes through both slits\", but can hint at the existence of anti-particles.\n\nNegative probabilities have more recently been applied to mathematical finance. In quantitative finance most probabilities are not real probabilities but pseudo probabilities, often what is known as risk neutral probabilities. These are not real probabilities, but theoretical \"probabilities\" under a series of assumptions that helps simplify calculations by allowing such pseudo probabilities to be negative in certain cases as first pointed out by Espen Gaarder Haug in 2004.\n\nA rigorous mathematical definition of negative probabilities and their properties was recently derived by Mark Burgin and Gunter Meissner (2011). The authors also show how negative probabilities can be applied to financial option pricing.\n\nThe concept of negative probabilities have also been proposed for reliable facility location models where facilities are subject to negatively correlated disruption risks when facility locations, customer allocation, and backup service plans are determined simultaneously. Li et al. proposed a virtual station structure that transforms a facility network with positively correlated disruptions into an equivalent one with added virtual supporting stations, and these virtual stations were subject to independent disruptions. This approach reduces a problem from one with correlated disruptions to one without. Xie et al. later showed how negatively correlated disruptions can also be addressed by the same modeling framework, except that a supporting station now may be disrupted with a “failure propensity” which\n\n“... inherits all mathematical characteristics and properties of a failure probability except that we allow it to be larger than 1...”\n\nThis finding paves ways for using compact mixed-integer mathematical programs to optimally design reliable location of service facilities under site-dependent and positive/negative/mixed disruption correlations.\n\nThe proposed “propensity” concept in Xie et al. turns out to be what Feynman and others referred to as “quasi-probability.” Note that when a quasi-probability is larger than 1, then 1 minus this value gives a negative probability. The truly physically verifiable observation is the facility disruption states, and there is no direct information on the station states or their corresponding probabilities. Hence the failure probability of the stations, interpreted as “probabilities of imagined intermediary states,” could exceed unity.\n\n"}
{"id": "3341704", "url": "https://en.wikipedia.org/wiki?curid=3341704", "title": "Neo-futurism", "text": "Neo-futurism\n\nNeo-futurism is a late 20th to early 21st century movement in the arts, design, and architecture. It could be seen as a departure from the attitude of post-modernism and represents an idealistic belief in a better future and \"a need to periodize the modern rapport with the technological\".\n\nThis avant-garde movement is a futuristic rethinking of the aesthetic and functionality of rapidly growing cities. The industrialization that began worldwide following the end of the Second World War gave wind to new streams of thought in life, art and architecture, leading to post-modernism, neo-modernism and then neo-futurism.\n\nIn the Western countries, futurist architecture evolved into Art Deco, the Googie movement and high-tech architecture, and most recently into neo-futurism.\n\nPioneered in the late 1960s and early 70s by American architects Buckminster Fuller and John C. Portman, Jr.; Finnish-American architect and industrial designer Eero Saarinen, Archigram, a British avant-garde architectural group (Peter Cook, Warren Chalk, Ron Herron, Dennis Crompton, Michael Webb and David Greene) based at the Architectural Association, London; American avant-garde architectural group ArchiGO, centered around the Illinois Institute of Technology; Danish architect Henning Larsen; Czech architect Jan Kaplický; Italian light sculptor Marco Lodola; American concept artist Syd Mead; American theatre screenwriter Greg Allen and Russian poets Andrei Voznesensky, Serge Segay and Rea Nikonova.\n\nAlthough it was never built, the Fun Palace (1961) interpreted by architect Cedric Price as a \"giant neo-futurist machine\" influenced other architects, notably Richard Rogers and Renzo Piano, whose Pompidou Centre extended many of Price's ideas.\n\nNeo-futurism was relaunched in 2007 after the dissemination of \"The Neo-Futuristic City Manifesto\" included in the candidature presented to the Bureau International des Expositions (BIE) and written by innovation designer Vito Di Bari, a former executive director at UNESCO), to outline his vision for the city of Milan at the time of the Universal Expo 2015. Di Bari defined his neo-futuristic vision as the \"cross-pollination of art, cutting edge technologies and ethical values\ncombined to create a pervasively higher quality of life\"; he referenced the Fourth Pillar of Sustainable Development Theory and reported that the name had been inspired by the United Nations report \"Our Common Future\".\n\nJean-Louis Cohen has defined neo-futurism as \"a corollary to technology, being the structures built today byproducts of new materials to create previously impossible forms.\" Etan J. Ilfeld wrote that in the contemporary neo-futurist aesthetics \"the machine becomes an integral element of the creative process itself, and generates the emergence of artistic modes that would have been impossible prior to computer technology.\" Reyner Banham's definition of \"une architecture autre\" is a call for an architecture that technologically overcomes all previous architectures but possessing an expressive form, as Banham stated about neo-futuristic \"Archigram’s Plug-in Computerized City, form does not have to follow function into oblivion.\"\n\nInspired by Futurist architect Antonio Sant'Elia and pioneered from early 1960s and late 1970s by thought leader Hal Foster, French architect Denis Laming, American architects William Pereira and Charles Luckman and Danish architects Henning Larsen and Jørn Utzon. The neo-futurist avant-garde movement has been relaunched in 2007 by Expo 2015 Innovation Designer Vito Di Bari. Neo-Futurist architecture and art have been creatively inspired by Iraqi-British Pritzker Prize architect Zaha Hadid, and Spanish architect Santiago Calatrava; Indian sculptor Anish Kapoor and Dutch kinetic sculptor Theo Jansen. Italian Innovation Designer Vito Di Bari is considered the thought leader of the movement, his vision of the “cross-pollination of art and technology for a better world” has been defined by Steve Jobs as the \"post-PC DNA\" and it is shared by acclaimed architects, designers and artists such as the youngest recipient ever of the Pritzker Prize Japanese architect Ryue Nishizawa, architect of Ecoville in Curitiba and of the first rotating residential buildings Bruno de Franco, Design for Asia Award 2004-7-9 recipient Hong Kong Architect Gary Chang, Brazilian architect Rodrigo Ohtake, Lubetkin Prize Winner British designer Thomas Heatherwick, Design for Asia 2008 Award recipient Japanese artist Tokujin Yoshioka, Italian artist Mario Arlati, Polish artist Karina Smigla-Bobinski.\n\nThe relaunch of neo-futurism in the 21st century has been creatively inspired by the Iraqi-British Pritzker Architecture Prize-winning architect Zaha Hadid, Spanish architect Santiago Calatrava \n\nNeo-futurist architects, designers and artists are French architect ; American artists Josh Hadar, Erin Sparler, Marlow Rodale, Panayiotis Terzis, and Miguel Ovalle; urban-noise artist Joseph Young; French designer Patrick Jouin British artist Olivia Peake; Japanese designer Yuima Nakazato, Swedish artist Simon Stålenhag, and Greek artist Charis Tsevis. Neo-futurism has absorbed some of the high-tech architecture’s themes and ideas, incorporating elements of high-tech industry and technology іnto building design: technology and context is the focus of some architects of this movement such as Buckminster Fuller, Norman Foster, Kenzo Tange, Renzo Piano, Richard Rogers, Frei Otto, and Santiago Calatrava.\n\n"}
{"id": "25111839", "url": "https://en.wikipedia.org/wiki?curid=25111839", "title": "Overexploitation", "text": "Overexploitation\n\nOverexploitation, also called overharvesting, refers to harvesting a renewable resource to the point of diminishing returns. Continued overexploitation can lead to the destruction of the resource. The term applies to natural resources such as: wild medicinal plants, grazing pastures, game animals, fish stocks, forests, and water aquifers.\n\nIn ecology, overexploitation describes one of the five main activities threatening global biodiversity. Ecologists use the term to describe populations that are harvested at a rate that is unsustainable, given their natural rates of mortality and capacities for reproduction. This can result in extinction at the population level and even extinction of whole species. In conservation biology the term is usually used in the context of human economic activity that involves the taking of biological resources, or organisms, in larger numbers than their populations can withstand. The term is also used and defined somewhat differently in fisheries, hydrology and natural resource management.\n\nOverexploitation can lead to resource destruction, including extinctions. However it is also possible for overexploitation to be sustainable, as discussed below in the section on fisheries. In the context of fishing, the term overfishing can be used instead of overexploitation, as can overgrazing in stock management, overlogging in forest management, overdrafting in aquifer management, and endangered species in species monitoring. Overexploitation is not an activity limited to humans. Introduced predators and herbivores, for example, can overexploit native flora and fauna.\n\nConcern about overexploitation is relatively recent, though overexploitation itself is not a new phenomenon. It has been observed for millennia. For example, ceremonial cloaks worn by the Hawaiian kings were made from the mamo bird; a single cloak used the feathers of 70,000 birds of this now-extinct species. The dodo, a flightless bird from Mauritius, is another well-known example of overexploitation. As with many island species, it was naive about certain predators, allowing humans to approach and kill it with ease.\n\nFrom the earliest of times, hunting has been an important human activity as a means of survival. There is a whole history of overexploitation in the form of overhunting. The overkill hypothesis (Quaternary extinction events) explains why the megafaunal extinctions occurred within a relatively short period of time. This can be traced with human migration. The most convincing evidence of this theory is that 80% of the North American large mammal species disappeared within 1000 years of the arrival of humans on the western hemisphere continents. The fastest ever recorded extinction of megafauna occurred in New Zealand, where by 1500 AD, just 200 years after settling the islands, ten species of the giant moa birds were hunted to extinction by the Māori. A second wave of extinctions occurred later with European settlement.\n\nIn more recent times, overexploitation has resulted in the gradual emergence of the concepts of sustainability and sustainable development, which has built on other concepts, such as sustainable yield, eco-development and deep ecology.\n\nOverexploitation doesn't necessarily lead to the destruction of the resource, nor is it necessarily unsustainable. However, depleting the numbers or amount of the resource can change its quality. For example, footstool palm is a wild palm tree found in Southeast Asia. Its leaves are used for thatching and food wrapping, and overharvesting has resulted in its leaf size becoming smaller.\n\nThe tragedy of the commons refers to a dilemma described in an article by that name written by Garrett Hardin and first published in the journal \"Science\" in 1968.\n\nCentral to Hardin's essay is an example which is a useful parable for understanding how overexploitation can occur. This example was first sketched in an 1833 pamphlet by William Forster Lloyd, as a hypothetical and simplified situation based on medieval land tenure in Europe, of herders sharing a common on which they are each entitled to let their cows graze. In Hardin's example, it is in each herder's interest to put each succeeding cow he acquires onto the land, even if the carrying capacity of the common is exceeded and it is temporarily or permanently damaged for all as a result. The herder receives all of the benefits from an additional cow, while the damage to the common is shared by the entire group. If all herders make this individually rational economic decision, the common will be overexploited or even destroyed to the detriment of all. However, since all herders reach the same rational conclusion, overexploitation in the form of overgrazing occurs, with immediate losses, and the pasture may be degraded to the point where it gives very little return.\n\"Therein is the tragedy. Each man is locked into a system that compels him to increase his herd without limit—in a world that is limited. Ruin is the destination toward which all men rush, each pursuing his own interest in a society that believes in the freedom of the commons.\" (Hardin, 1968)\nIn the course of his essay, Hardin develops the theme, drawing in many examples of latter day commons, such as national parks, the atmosphere, oceans, rivers and fish stocks. The example of fish stocks had led some to call this the \"tragedy of the fishers\". A major theme running through the essay is the growth of human populations, with the Earth's finite resources being the general common.\n\nThe tragedy of the commons has intellectual roots tracing back to Aristotle, who noted that \"what is common to the greatest number has the least care bestowed upon it\", as well as to Hobbes and his \"Leviathan\". The opposite situation to a tragedy of the commons is sometimes referred to as a tragedy of the anticommons: a situation in which rational individuals, acting separately, collectively waste a given resource by underutilizing it.\n\nThe tragedy of the commons can be avoided if it is appropriately regulated. Hardin's use of \"commons\" has frequently been misunderstood, leading Hardin to later remark that he should have titled his work \"The tragedy of the unregulated commons\".\n\nIn wild fisheries, overexploitation or overfishing occurs when a fish stock has been fished down \"below the size that, on average, would support the long-term maximum sustainable yield of the fishery\". However, overexploitation can be sustainable.\n\nWhen a fishery starts harvesting fish from a previously unexploited stock, the biomass of the fish stock will decrease, since harvesting means fish are being removed. For sustainability, the rate at which the fish replenish biomass through reproduction must balance the rate at which the fish are being harvested. If the harvest rate is increased, then the stock biomass will further decrease. At a certain point, the maximum harvest yield that can be sustained will be reached, and further attempts to increase the harvest rate will result in the collapse of the fishery. This point is called the maximum sustainable yield, and in practice, usually occurs when the fishery has been fished down to about 30% of the biomass it had before harvesting started.\n\nIt is possible to fish the stock down further to, say, 15% of the pre-harvest biomass, and then adjust the harvest rate so the biomass remains at that level. In this case, the fishery is sustainable, but is now overexploited, because the stock has been run down to the point where the sustainable yield is less than it could be.\n\nFish stocks are said to \"collapse\" if their biomass declines by more than 95 percent of their maximum historical biomass. Atlantic cod stocks were severely overexploited in the 1970s and 1980s, leading to their abrupt collapse in 1992. Even though fishing has ceased, the cod stocks have failed to recover. The absence of cod as the apex predator in many areas has led to trophic cascades.\n\nAbout 25% of world fisheries are now overexploited to the point where their current biomass is less than the level that maximizes their sustainable yield. These depleted fisheries can often recover if fishing pressure is reduced until the stock biomass returns to the optimal biomass. At this point, harvesting can be resumed near the maximum sustainable yield.\n\nThe tragedy of the commons can be avoided within the context of fisheries if fishing effort and practices are regulated appropriately by fisheries management. One effective approach may be assigning some measure of ownership in the form of individual transferable quotas (ITQs) to fishermen. In 2008, a large scale study of fisheries that used ITQs, and ones that didn't, provided strong evidence that ITQs help prevent collapses and restore fisheries that appear to be in decline.\n\nWater resources, such as lakes and aquifers, are usually renewable resources which naturally recharge (the term fossil water is sometimes used to describe aquifers which don't recharge). Overexploitation occurs if a water resource, such as the Ogallala Aquifer, is mined or extracted at a rate that exceeds the recharge rate, that is, at a rate that exceeds the practical sustained yield. Recharge usually comes from area streams, rivers and lakes. An aquifer which has been overexploited is said to be overdrafted or depleted. Forests enhance the recharge of aquifers in some locales, although generally forests are a major source of aquifer depletion. Depleted aquifers can become polluted with contaminants such as nitrates, or permanently damaged through subsidence or through saline intrusion from the ocean.\n\nThis turns much of the world's underground water and lakes into finite resources with peak usage debates similar to oil. These debates usually centre around agriculture and suburban water usage but generation of electricity from nuclear energy or coal and tar sands mining is also water resource intensive. A modified Hubbert curve applies to any resource that can be harvested faster than it can be replaced. Though Hubbert's original analysis did not apply to renewable resources, their overexploitation can result in a Hubbert-like peak. This has led to the concept of peak water.\n\nForests are overexploited when they are logged at a rate faster than reforestation takes place. Reforestation competes with other land uses such as food production, livestock grazing, and living space for further economic growth. Historically utilization of forest products, including timber and fuel wood, have played a key role in human societies, comparable to the roles of water and cultivable land. Today, developed countries continue to utilize timber for building houses, and wood pulp for paper. In developing countries almost three billion people rely on wood for heating and cooking. Short-term economic gains made by conversion of forest to agriculture, or overexploitation of wood products, typically leads to loss of long-term income and long term biological productivity. West Africa, Madagascar, Southeast Asia and many other regions have experienced lower revenue because of overexploitation and the consequent declining timber harvests.\n\nOverexploitation is one of the main threats to global biodiversity. Other threats include pollution, introduced and invasive species, habitat fragmentation, habitat destruction, uncontrolled hybridization, global warming, ocean acidification and the driver behind many of these, human overpopulation.\n\nOne of the key health issues associated with biodiversity is drug discovery and the availability of medicinal resources. A significant proportion of drugs are natural products derived, directly or indirectly, from biological sources. Marine ecosystems are of particular interest in this regard. However unregulated and inappropriate bioprospecting could potentially lead to overexploitation, ecosystem degradation and loss of biodiversity.\n\nOverexploitation threatens one-third of endangered vertebrates, as well as other groups. Excluding edible fish, the illegal trade in wildlife is valued at $10 billion per year. Industries responsible for this include the trade in bushmeat, the trade in Chinese medicine, and the fur trade. The Convention for International Trade in Endangered Species of Wild Fauna and Flora, or CITES was set up in order to control and regulate the trade in endangered animals. It currently protects, to a varying degree, some 33,000 species of animals and plants. It is estimated that a quarter of the endangered vertebrates in the United States of America and half of the endangered mammals is attributed to overexploitation.\n\nAll living organisms require resources to survive. Overexploitation of these resources for protracted periods can deplete natural stocks to the point where they are unable to recover within a short time frame. Humans have always harvested food and other resources they have needed to survive. Human populations, historically, were small, and methods of collection limited to small quantities. With an exponential increase in human population, expanding markets and increasing demand, combined with improved access and techniques for capture, are causing the exploitation of many species beyond sustainable levels. In practical terms, if continued, it reduces valuable resources to such low levels that their exploitation is no longer sustainable and can lead to the extinction of a species, in addition to having dramatic, unforeseen effects, on the ecosystem. Overexploitation often occurs rapidly as markets open, utilising previously untapped resources, or locally used species.\n\nToday, overexploitation and misuse of natural resources is an ever-present threat for species richness. This is more prevalent when looking at island ecology and the species that inhabit them, as islands can be viewed as the world in miniature. Island endemic populations are more prone to extinction from overexploitation, as they often exist at low densities with reduced reproductive rates. A good example of this are island snails, such as the Hawaiian \"Achatinella\" and the French Polynesian \"Partula\". Achatinelline snails have 15 species listed as extinct and 24 critically endangered while 60 species of partulidae are considered extinct with 14 listed as critically endangered. The WCMC have attributed over-collecting and very low lifetime fecundity for the extreme vulnerability exhibited among these species.\n\nAs another example, when the humble hedgehog was introduced to the Scottish island of Uist, the population greatly expanded and took to consuming and overexploiting shorebird eggs, with drastic consequences for their breeding success. Twelve species of avifauna are affected, with some species numbers being reduced by 39%.\n\nWhere there is substantial human migration, civil unrest, or war, controls may no longer exist. With civil unrest, for example in the Congo and Rwanda, firearms have become common and the breakdown of food distribution networks in such countries leaves the resources of the natural environment vulnerable. Animals are even killed as target practice, or simply to spite the government. Populations of large primates, such as gorillas and chimpanzees, ungulates and other mammals, may be reduced by 80% or more by hunting, and certain species may be eliminated altogether. This decline has been called the bushmeat crisis.\n\nOverall, 50 bird species that have become extinct since 1500 (approximately 40% of the total) have been subject to overexploitation, including:\n\n\nOther species affected by overexploitation include: \n\n\nOverexploitation of species can result in knock-on or cascade effects. This can particularly apply if, through overexploitation, a habitat loses its apex predator. Because of the loss of the top predator, a dramatic increase in their prey species can occur. In turn, the unchecked prey can then overexploit their own food resources until population numbers dwindle, possibly to the point of extinction.\n\nA classic example of cascade effects occurred with sea otters. Starting before the 17th century and not phased out until 1911, sea otters were hunted aggressively for their exceptionally warm and valuable pelts, which could fetch up to $2500 US. This caused cascade effects through the kelp forest ecosystems along the Pacific Coast of North America.\n\nOne of the sea otters’ primary food sources is the sea urchin. When hunters caused sea otter populations to decline, an ecological release of sea urchin populations occurred. The sea urchins then overexploited their main food source, kelp, creating urchin barrens, areas of seabed denuded of kelp, but carpeted with urchins. No longer having food to eat, the sea urchin became locally extinct as well. Also, since kelp forest ecosystems are homes to many other species, the loss of the kelp caused other cascade effects of secondary extinctions.\n\nIn 1911, when only one small group of 32 sea otters survived in a remote cove, an international treaty was signed to prevent further exploitation of the sea otters. Under heavy protection, the otters multiplied and repopulated the depleted areas, which slowly recovered. More recently, with declining numbers of fish stocks, again due to overexploitation, killer whales have experienced a food shortage and have been observed feeding on sea otters, again reducing their numbers.\n\n"}
{"id": "17597112", "url": "https://en.wikipedia.org/wiki?curid=17597112", "title": "Pace J. McConkie", "text": "Pace J. McConkie\n\nPace Jefferson McConkie (born September 1, 1962) is a civil rights lawyer in Annapolis, Maryland and a professor at Morgan State University in Baltimore, Maryland. He is the founder and director of Morgan State University's Robert M. Bell Center for Civil Rights in Education.\n\nA native of Utah, McConkie is the son of attorney Oscar W. McConkie Jr. As a young man, McConkie served as a Mormon missionary for The Church of Jesus Christ of Latter-day Saints in New Zealand.\n\nMcConkie received his bachelor's degree from the University of Utah in Salt Lake City and his law degree from the William H. Bowen School of Law in Little Rock, Arkansas in 1987. After law school, he completed a two-year clerkship with Associate Chief Justice Richard C. Howe of the Utah Supreme Court.\n\nMcConkie was assistant general counsel for the National Association for the Advancement of Colored People (NAACP) in Maryland.\n\nMcConkie has served as assistant attorney general of Maryland As assistant attorney general, McConkie opposed the starting of an MBA program at Towson University that would compete against Morgan State University.\n\nMcConkie is president of the Annapolis Stake of The Church of Jesus Christ of Latter-day Saints.\n\nMcConkie, who is white, is a recipient of the National Association for the Advancement of Colored People Attorney of the Year award.\n\n"}
{"id": "30556018", "url": "https://en.wikipedia.org/wiki?curid=30556018", "title": "Parabolic geometry (differential geometry)", "text": "Parabolic geometry (differential geometry)\n\nIn differential geometry and the study of Lie groups, a parabolic geometry is a homogeneous space \"G\"/\"P\" which is the quotient of a semisimple Lie group \"G\" by a parabolic subgroup \"P\". More generally, the curved analogs of a parabolic geometry in this sense is also called a parabolic geometry: any geometry that is modeled on such a space by means of a Cartan connection.\n\nThe projective space \"P\" is an example. It is the homogeneous space PGL(\"n\"+1)/\"H\" where \"H\" is the isotropy group of a line. In this geometrical space, the notion of a straight line is meaningful, but there is no preferred (\"affine\") parameter along the lines. The curved analog of projective space is a manifold in which the notion of a geodesic makes sense, but for which there are no preferred parametrizations on those geodesics. A projective connection is the relevant Cartan connection that gives a means for describing a projective geometry by gluing copies of the projective space to the tangent spaces of the base manifold. Broadly speaking, projective geometry refers to the study of manifolds with this kind of connection.\n\nAnother example is the conformal sphere. Topologically, it is the \"n\"-sphere, but there is no notion of length defined on it, just of angle between curves. Equivalently, this geometry is described as an equivalence class of Riemannian metrics on the sphere (called a conformal class). The group of transformations that preserve angles on the sphere is the Lorentz group O(\"n\"+1,1), and so \"S\" = O(\"n\"+1,1)/\"P\". Conformal geometry is, more broadly, the study of manifolds with a conformal equivalence class of Riemannian metrics, i.e., manifolds modeled on the conformal sphere. Here the associated Cartan connection is the conformal connection.\n\nOther examples include:\n\n"}
{"id": "46661027", "url": "https://en.wikipedia.org/wiki?curid=46661027", "title": "Phagomimicry", "text": "Phagomimicry\n\nPhagomimicry is a defensive behaviour of sea hares, in which the animal ejects a mixture of chemicals, which mimic food, and overwhelm the senses of their predator, giving the sea hare a chance to escape. The typical defence response of the sea hare to a predator is to release two chemicals - ink from the ink gland and opaline from the opaline gland. While ink creates a dark, diffuse cloud in the water which disrupts the sensory perception of the predator by acting as a smokescreen and as a decoy, the opaline, which affects the senses dealing with feeding, causes the predator to instinctively attack the cloud of chemicals as if it were indeed food. This ink is able to mimic food by having a high concentration of amino acids and other compounds that are normally found in food, and the attack behaviour of the predator allows the sea-hares the opportunity to escape.\n\nThe inking behaviour exhibited in phagomimicry is in response to predator threat. Sea hares have many natural predators such as starfish, lobsters, and other crustaceans. When threatened by a predator, phagomimicry behaviour begins. An ink solution is released from both the opaline and ink glands individually, then the compounds mix in the mantle of the sea hare to form the ink mixture. When ink is released it creates a smoke-screen like defense mechanism allowing the sea hares time to escape while also affecting the olfactory and gustation senses of their predator. Predators are tricked into thinking that they have captured their prey due to the specific chemical composition of the ink released. This induces feeding behaviours in the predator, and again gives the sea hares a better chance of escaping predation.\n\nThe opaline gland is a structure resembling a bundle of grapes attached to a central canal which is composed of epithelial cells. Synthesis of the opaline substance happens in the opaline vesicles themselves, as there are only opaline vesicles and muscle cells in the opaline gland. The gland is innervated by three separate motor neurons, and is composed of single large cells and vesicle cells, all of which have enlarged nucleus. These cells are inclosed in an external layer of muscle. When a sensory neuron detects a predator threat, dopamine is released onto one of the three motor neurons. The dopamine release causes a gland contraction, which then causes the expulsion of the opaline substance.\n\nThe ink gland is smaller in size than the opaline gland, and is composed of two cell types: Rough endoplasmic recticlum (RER) and granulate cells. The cells are surrounded by a layer of muscle, to contraction and expelling their contents. The RER is the formation site of the anti-predator protein, the granulate cells are for extra pigment storage. Pigment is dependent on the amount of red algae available to the sea hares, the higher the red algal consumption, the darker the colour of their ink. This mixing can cause another chain of reactions between the compounds that have further implications on the effect that the ink secretion has on predators.\n\nBoth the opaline and ink gland secrete different substances that when mixed together form the ink released during phagomimicry. The secretion is very acidic (ink having a pH of 4.9 and opaline having a pH of 5.8) and contains high levels of bioactive molecules that can serve as feeding stimulants, feeding deterrents, and aversive compounds. Feeding stimulants can be found in both the ink and opaline secretions in the form of amino acids (such as lysine and arginine), and serve to trick predators into thinking that the ink secretion is a food source. To induce the aversive feeding effects on predators the ink contains a compound from the opaline gland produced from the oxidation of -lysine, which is then mixed in the mantle with the -amino acid oxidase from the ink gland. Together this compound, called escapin is secreted in the ink, and is a feeding deterrent. The ink secretion can have a long-lasting effect on predators as chemical phagomimics can cause chemo-mechanosensory stimulation which overwhelms the sensory system and leads to confusion and eventually the cession of the attack.\n\nThe ink released from the ink gland is dark purple in colour, the colour depends on the type of algae consumed by the sea-hare. The opaline ink is white in colour, and when it mixes with the ink gland ink they form a compound that suspends itself in the water (polidisperse suspension), creating a smoke-screen defence mechanism. The particle density of the ink is similar to that of species such as cuttlefish, the particles range in size from 80–150 nm, with a density of 1.27 cm which allows for the inks suspension in water \n\n"}
{"id": "26667808", "url": "https://en.wikipedia.org/wiki?curid=26667808", "title": "Principle of least astonishment", "text": "Principle of least astonishment\n\nThe principle of least astonishment (POLA) (and variations of \"\"principle\"/\"law\"/\"rule\" of least \"astonishment\"/\"surprise\"\") applies to user interface and software design. A typical formulation of the principle, from 1984, is: \"If a necessary feature has a high astonishment factor, it may be necessary to redesign the feature.\"\n\nMore generally, the principle means that a component of a system should behave in a way that most users will expect it to behave; the behavior should not astonish or surprise users.\n\nA textbook formulation is: \"People are part of the system. The design should match the user's experience, expectations, and mental models.\"\n\nThe choice of \"least surprising\" behavior can depend on the expected audience (for example, end users, programmers, or system administrators).\n\nIn more practical terms, the principle aims to leverage the pre-existing knowledge of users to minimize the learning curve, for instance by designing interfaces that borrow heavily from \"functionally similar or analogous programs with which your users are likely to be familiar\". User expectations in this respect may be closely related to a particular computing platform or tradition. For example, Unix command line programs are expected to follow certain conventions with respect to switches, and widgets of Microsoft Windows programs are expected to follow certain conventions with respect to keyboard shortcuts. In more abstract settings like an API, the expectation that function or method names intuitively match their behavior is another example. This practice also involves the application of sensible defaults.\n\nWhen two elements of an interface conflict, or are ambiguous, the behavior should be that which will least surprise the user; in particular a programmer should try to think of the behavior that will least surprise someone who uses the program, rather than that behavior that is natural from knowing the inner workings of the program.\n\nA web site could declare an input that should autofocus when the page is loaded, such as a search field (e.g., Google.com), or the \"username\" field of a login form. Sites offering keyboard shortcuts often allow pressing to see the available shortcuts. Examples include Gmail and Jira.\n\nThe Function key in Windows operating systems is almost always for opening a help program associated with an application, and similarly for some of the Linux desktop environments. The corresponding key combination in Mac OS X is . Users expect a help screen or similar help services popup when they press this key. Software binding this key to some other feature is likely to cause astonishment if no help appears. Malicious programs are known to exploit users' familiarity with regular shortcut keys.\n\nIn programming, a good example of this principle is the common codice_1 function which exists in most languages and is used to convert a string to an integer value. The radix is usually an optional argument and assumed to be 10 (representing base 10). Other bases are usually supported (like binary or octal) but only when specified explicitly; when the radix argument is not specified, base 10 is assumed. Notably JavaScript did not originally adopt this behavior, which resulted in developer confusion and software bugs.\n\n\n"}
{"id": "42595150", "url": "https://en.wikipedia.org/wiki?curid=42595150", "title": "Self-tiling tile set", "text": "Self-tiling tile set\n\nA self-tiling tile set, or \"setiset\", of order \"n\" is a set of \"n\" shapes or pieces, usually planar, each of which can be tiled with smaller replicas of the complete set of \"n\" shapes. That is, the \"n\" shapes can be assembled in \"n\" different ways so as to create larger copies of themselves, where the increase in scale is the same in each case. Figure 1 shows an example for \"n\" = 4 using distinctly shaped decominoes. The concept can be extended to include pieces of higher dimension. The name setisets was coined by Lee Sallows in 2012, but the problem of finding such sets for \"n\" = 4 was asked decades previously by C. Dudley Langford, and examples for polyaboloes (discovered by Martin Gardner, Wade E. Philpott and others) and polyominoes (discovered by Maurice J. Povah) were previously published by Gardner.\n\nFrom the above definition it follows that a setiset composed of \"n\" identical pieces is the same thing as a 'self-replicating tile' or rep-tile, of which setisets are therefore a generalization. Setisets using \"n\" distinct shapes, such as Figure 1, are called \"perfect\". Figure 2 shows an example for \"n\" = 4 which is \"imperfect\" because two of the component shapes are the same.\nThe shapes employed in a setiset need not be \"connected\" regions. Disjoint pieces composed of two or more separated islands are also permitted. Such pieces are described as \"disconnected\", or \"weakly-connected\" (when islands join only at a point), as seen in the setiset shown in Figure 3.\n\nThe fewest number of pieces in a setiset is two. Figure 4 encapsulates an infinite family of order 2 setisets each composed of two triangles, \"P\" and \"Q\". As shown, the latter can be hinged together to produce a compound triangle that has the same shape as \"P\" or \"Q\", depending upon whether the hinge is fully open or fully closed. This unusual specimen thus provides an example of a hinged dissection.\n\nThe properties of setisets mean that their pieces form substitution tilings, or tessellations in which the prototiles can be dissected or combined so as to yield smaller or larger duplicates of themselves. Clearly, the twin actions of forming still larger and larger copies (known as inflation), or still smaller and smaller dissections (deflation), can be repeated indefinitely. In this way, setisets can produce non-periodic tilings. However, none of the non-periodic tilings thus far discovered qualify as aperiodic, because the prototiles can always be rearranged so as to yield a periodic tiling. Figure 5 shows the first two stages of inflation of an order 4 set leading to a non-periodic tiling.\n\nBesides self-tiling tile sets, which can be interpreted as loops of length 1, there exist longer loops, or closed chains of sets, in which every set tiles its successor. Figure 6 shows a pair of mutually tiling sets of decominoes, in other words, a loop of length 2. Sallows and Schotel did an exhaustive search of order 4 sets that are composed of octominoes. In addition to seven ordinary setisets (i.e., loops of length 1) they found a bewildering variety of loops of every length up to a maximum of 14. The total number of loops identified was nearly one and a half million. More research in this area remains to be done, but it seems safe to suppose that other shapes may also entail loops.\nTo date, two methods have been used for producing setisets. In the case of sets composed of shapes such as polyominoes, which entail integral piece sizes, a brute force search by computer is possible, so long as \"n\", the number of pieces involved, is not prohibitive. It is easily shown that \"n\" must then be a perfect square. Figures 1,2,3,5 and 6 are all examples found by this method.\n\nAlternatively, there exists a method whereby multiple copies of a rep-tile can be dissected in certain ways so as to yield shapes that create setisets. Figures 7 and 8 show setisets produced by this means, in which each piece is the union of 2 and 3 rep-tiles, respectively. In Figure 8 can be seen how the 9 pieces above together tile the 3 rep-tile shapes below, while each of the 9 pieces is itself formed by the union of 3 such rep-tile shapes. Hence each shape can be tiled with smaller duplicates of the entire set of 9.\n\n"}
{"id": "1091100", "url": "https://en.wikipedia.org/wiki?curid=1091100", "title": "Similitude (model)", "text": "Similitude (model)\n\nSimilitude is a concept applicable to the testing of engineering models. A model is said to have similitude with the real application if the two share geometric similarity, kinematic similarity and dynamic similarity. \"Similarity\" and \"similitude\" are interchangeable in this context.\n\nThe term dynamic similitude is often used as a catch-all because it implies that geometric and kinematic similitude have already been met.\n\nSimilitude's main application is in hydraulic and aerospace engineering to test fluid flow conditions with scaled models. It is also the primary theory behind many textbook formulas in fluid mechanics.\n\nThe concept of similitude is strongly tied to dimensional analysis.\n\nEngineering models are used to study complex fluid dynamics problems where calculations and computer simulations aren't reliable. Models are usually smaller than the final design, but not always. Scale models allow testing of a design prior to building, and in many cases are a critical step in the development process.\n\nConstruction of a scale model, however, must be accompanied by an analysis to determine what conditions it is tested under. While the geometry may be simply scaled, other parameters, such as pressure, temperature or the velocity and type of fluid may need to be altered. Similitude is achieved when testing conditions are created such that the test results are applicable to the real design.\n\nThe following criteria are required to achieve similitude;\n\nTo satisfy the above conditions the application is analyzed; \n\nIt is often impossible to achieve strict similitude during a model test. The greater the departure from the application's operating conditions, the more difficult achieving similitude is. In these cases some aspects of similitude may be neglected, focusing on only the most important parameters.\n\nThe design of marine vessels remains more of an art than a science in\nlarge part because dynamic similitude is especially difficult to attain\nfor a vessel that is partially submerged: a ship is affected by wind\nforces in the air above it, by hydrodynamic forces within the water\nunder it, and especially by wave motions at the interface between the\nwater and the air. The scaling requirements for each of these\nphenomena differ, so models cannot replicate what happens to a full\nsized vessel nearly so well as can be done for an aircraft or\nsubmarine—each of which operates entirely within one medium.\n\nSimilitude is a term used widely in fracture mechanics relating to the strain life approach. Under given loading conditions the fatigue damage in an un-notched specimen is comparable to that of a notched specimen. Similitude suggests that the component fatigue life of the two objects will also be similar.\n\nConsider a submarine modeled at 1/40th scale. The application operates in sea water at 0.5 °C, moving at 5 m/s. The model will be tested in fresh water at 20 °C. Find the power required for the submarine to operate at the stated speed.\n\nA free body diagram is constructed and the relevant relationships of force and velocity are formulated using techniques from continuum mechanics. The variables which describe the system are:\n\nThis example has five independent variables and three fundamental units. The fundamental units are: metre, kilogram, second.\n\nInvoking the Buckingham π theorem shows that the system can be described with two dimensionless numbers and one independent variable.\n\nDimensional analysis is used to re-arrange the units to form the Reynolds number (formula_1) and pressure coefficient (formula_2). These dimensionless numbers account for all the variables listed above except \"F\", which will be the test measurement. Since the dimensionless parameters will stay constant for both the test and the real application, they will be used to formulate scaling laws for the test.\n\nScaling laws:\n\nThe pressure (formula_4) is not one of the five variables, but the force (formula_5) is. The pressure difference (Δformula_4) has thus been replaced with (formula_7) in the pressure coefficient. This gives a required test velocity of:\n\nA model test is then conducted at that velocity and the force that is measured in the model (formula_9) is then scaled to find the force that can be expected for the real application (formula_10):\n\nThe power formula_12 in watts required by the submarine is then:\n\nNote that even though the model is scaled smaller, the water velocity needs to be increased for testing. This remarkable result shows how similitude in nature is often counterintuitive.\n\nSimilitude has been well documented for a large number of engineering problems and is the basis of many textbook formulas and dimensionless quantities. These formulas and quantities are easy to use without having to repeat the laborious task of dimensional analysis and formula derivation. Simplification of the formulas (by neglecting some aspects of similitude) is common, and needs to be reviewed by the engineer for each application.\n\nSimilitude can be used to predict the performance of a new design based on data from an existing, similar design. In this case, the model is the existing design. Another use of similitude and models is in validation of computer simulations with the ultimate goal of eliminating the need for physical models altogether.\n\nAnother application of similitude is to replace the operating fluid with a different test fluid. Wind tunnels, for example, have trouble with air liquefying in certain conditions so helium is sometimes used. Other applications may operate in dangerous or expensive fluids so the testing is carried out in a more convenient substitute.\n\nSome common applications of similitude and associated dimensionless numbers;\n\nSimilitude analysis is a powerful engineering tool to design the scaled-down structures. Although both dimensional analysis and direct use of the governing equations may be used to derive the scaling laws, the latter results in more specific scaling laws. The design of the scaled-down composite structures can be successfully carried out using the complete and partial similarities. In the design of the scaled structures under complete similarity condition, all the derived scaling laws must be satisfied between the model and prototype which yields the perfect similarity between the two scales. However, the design of a scaled-down structure which is perfectly similar to its prototype has the practical limitation, especially for laminated structures. Relaxing some of the scaling laws may eliminate the limitation of the design under complete similarity condition and yields the scaled models that are partially similar to their prototype. However, the design of the scaled structures under the partial similarity condition must follow a deliberate methodology to ensure the accuracy of the scaled structure in predicting the structural response of the prototype. Scaled models can be designed to replicate the dynamic characteristic (e.g. frequencies, mode shapes and damping ratios) of their full-scale counterparts. However, appropriate response scaling laws need to be derived to predict the dynamic response of the full-scale prototype from the experimental data of the scaled model.\n\n\n\n"}
{"id": "697354", "url": "https://en.wikipedia.org/wiki?curid=697354", "title": "Social proof", "text": "Social proof\n\nSocial proof, a term coined by Dr. Robert Cialdini in his 1984 book, \"Influence\", is also known as informational social influence. It describes a psychological and social phenomenon wherein people copy the actions of others in an attempt to undertake behavior in a given situation. \n\nSocial proof is considered prominent in ambiguous social situations where people are unable to determine the appropriate \"mode of behavior\", and is driven by the assumption that the surrounding people possess more knowledge about the current situation.\n\nThe effects of social influence can be seen in the tendency of large groups to conform to choices which are either correct or mistaken. This is referred to in some publications as the \"herd behavior\". Although social proof reflects a rational motive to take into account the information possessed by others, formal analysis shows that it can cause people to converge too quickly upon a single distinct choice, so that decisions of even larger groups of individuals may be grounded in very little information (see information cascades).\n\nSocial proof is one type of conformity. When a person is in a situation where they are unsure of the correct way to behave, they will often look to others for clues concerning the correct behavior. When \"we conform because we believe that others' interpretation of an ambiguous situation is more accurate than ours and will help us choose an appropriate course of action\", it is informational social influence. This is contrasted with normative social influence wherein a person conforms to be liked or accepted by others.\n\nSocial proof often leads not only to public compliance (conforming to the behavior of others publicly without necessarily believing it is correct) but also private acceptance (conforming out of a genuine belief that others are correct). \nSocial proof is more powerful when being accurate is more important and when others are perceived as especially knowledgeable.\n\nThe multiple source effect occurs when people give more credence to ideas that are stated by multiple sources. This effect can be clearly seen when social proof occurs. For instance, one study observed that people who hear five positive reviews on a book as read by five different synthesized voices perceive that book more favourably than if they hear the same five reviews as read by one synthesized voice.\n\nUncertainty is a major factor that encourages the use of social proof. One study found that when evaluating a product, consumers were more likely to incorporate the opinions of others through the use of social proof when their own experiences with the product were ambiguous, leaving uncertainty as to the correct conclusion that they should make.\n\nSimilarity also motivates the use of social proof; when a person perceives themselves as similar to the people around them, they are more likely to adopt and perceive as correct the observed behavior of these people. This has been noted in areas such as the use of laugh tracks, where participants will laugh longer and harder when they perceive the people laughing to be similar to themselves.\n\nSocial proof is also one of Robert Cialdini's six principles of persuasion, (along with reciprocity, commitment/consistency, authority, liking, and scarcity) which maintains that people are especially likely to perform certain actions if they can relate to the people who performed the same actions before them. One experiment which exemplifies this claim was conducted by researchers who joined a door-to-door charity campaign, who found that if a list of prior donators was longer, the next person solicited was more likely to donate as well. This trend was even more pronounced when the names on the donor list were people that the prospective donor knew, such as friends and neighbors. Cialdini's principle also asserts that peer power is effective because people are more likely respond to influence tactics applied horizontally rather than vertically, so people are more likely to be persuaded by a colleague than a superior.\n\nThe most famous study of social proof is Muzafer Sherif's 1935 experiment. In this experiment subjects were placed in a dark room and asked to look at a dot of light about 15 feet away. They were then asked how much, in inches, the dot of light was moving. In reality it was not moving at all, but due to the autokinetic effect it appeared to move. How much the light appears to move varies from person to person but is generally consistent over time for each individual. A few days later a second part of the experiment was conducted. Each subject was paired with two other subjects and asked to give their estimate of how much the light was moving out loud. Even though the subjects had previously given different estimates, the groups would come to a common estimate. To rule out the possibility that the subjects were simply giving the group answer to avoid looking foolish while still believing their original estimate was correct, Sherif had the subjects judge the lights again by themselves after doing so in the group. They maintained the group's judgment. Because the movement of the light is ambiguous the participants were relying on each other to define reality.\n\nAnother study looked at informational social influence in eyewitness identification. Subjects were shown a slide of the \"perpetrator\". They were then shown a slide of a line-up of four men, one of whom was the perpetrator they had seen, and were asked to pick him out. The task was made difficult to the point of ambiguity by presenting the slides very quickly. The task was done in a group that consisted of one actual subject and three confederates (a person acting as a subject but actually working for the experimenter). The confederates answered first and all three gave the same wrong answer. In a high-importance condition of the experiment subjects were told that they were participating in a real test of eyewitness identification ability that would be used by police departments and courts, and their scores would establish the norm for performance. In a low-importance condition subjects were told that the slide task was still being developed and that the experimenters had no idea what the norm for performance was—they were just looking for useful hints to improve the task. It was found that when subjects thought the task was of high importance they were more likely to conform, giving the confederate's wrong answer 51% of the time as opposed to 35% of the time in the low-importance condition.\n\nThe strength of social proof also varies across different cultures. For instance, studies have shown that subjects in collectivist cultures conform to others' social proof more often than those in individualist cultures. Although this trend seems reoccurring, there is evidence which suggests that these results are a simplification, and that an independent subject's personal individualistic-collectivist tendency also makes an impact upon their decisions. Additional variables, such as the subject's sense of social responsibility, need to be taken into account to better understand the mechanisms of social proof across cultures; for example, more collectivist individuals will often have an increased compulsion to help others because of their prominent awareness of social responsibility, and this in turn will increase the likelihood they will comply to requests, regardless of their peers' previous decisions.\n\nSocial proof has been proposed as an explanation for copycat suicide, where suicide rates increase following media publication about suicides. One study using agent-based modeling showed that copycat suicides are more likely when there are similarities between the person involved in the publicized suicide and the potential copycats. In addition, research performed by David Phillips between 1947 and 1968 further supports the existence of copycat suicides.\n\nA person who has been unemployed for a long time may have a hard time finding a new job—even if they are highly skilled and qualified. Potential employers attribute wrongly the person's lack of employment to the person rather than the situation. This causes the potential employers to search more intensively for flaws or other negative characteristics that are \"congruent\" with or explain the person's failure and to discount the applicant's virtues.\n\nSimilarly, a person who is in high demand—for example a CEO—may continue to get many attractive job offers and can, as a result, extract a considerable wage premium—even if his/her objective performance has been poor. When people appear successful, potential employers and others who evaluate them tend to search more intensively for virtues or positive characteristics that are \"congruent\" with or explain the person's success, and\nto ignore or underestimate the person's faults. People who experience positive social proof may also benefit from a halo effect. Other attributes are deemed to be more positive than they actually are. Additionally, the person's attributes may be viewed with a positive framing bias. For example, a person might be viewed as arrogant if they have negative social proof, and bold if they have positive social proof. For these reasons, social proof is important in determining a potential employer's consideration set.\n\nSocial proof naturally also applies to products and is used extensively in marketing and sales.\n\nSituations that violate social proof can cause cognitive dissonance, and can cause people to have a sense of loss of control or failure of the \"just world hypothesis\".\n\nTheaters sometimes use specially planted audience members who are instructed to give ovations at pre-arranged times. Usually, these people are the ones who clap initially, and the rest of the audience follows. Such ovations may be perceived by non-expert audience members as signals of the performance's quality.\n\nContrary to common annoyance of canned laughter in television shows, television studios have discovered that they can increase the perceived \"funniness\" of a show by merely playing canned laughter at key \"funny\" moments. They have found that even though viewers find canned laughter highly annoying, they perceive shows that happen to use canned laughter more funny than the shows that do not use canned laughter.\n\nSocial proof is also prominent on social networks such as Twitter, Facebook, Instagram and YouTube. The number of followers, fans, views, likes, favorites and even comments that a user has made, positively affects how other users perceive them. A user on Twitter with a million followers is perceived as more trustworthy and reputable than a similar user with a thousand followers, resulting in faster growth of followers and higher engagement and click-through-rates.. Although, these fake followers will never help meet business objectives or generate sales directly.\n\nAn entire multimillion-dollar industry, known as ghost followers, exist for the sole purpose of increasing social proof on social media.\n\nSocial norms are often not clearly articulated for sustainable or pro-environmental conduct.\n\nIf one perceives that s/he is better advised about a situation than the surrounding group, then s/he is less likely to follow the group's behavior.\n\nIf one perceives themselves as a relevant authority figure in the situation, they are less likely to follow the surrounding group's behavior. This is a combination of \"Identification of the surrounding group with self\" and \"Possession of special knowledge\". People in authority positions tend to place themselves in different categories than other people and usually they have special training or knowledge that allows them to conclude that they are better informed than the surrounding group.\n\nOne might perceive particular groups of others, identified by their behavior or other characteristics, to be more reliable guides to the situation than the average person. One might think truck drivers to be more frequent, and therefore more experienced drivers than others, and therefore weigh more heavily the number of trucks than the number of cars parked when judging the quality of a restaurant. One might identify the movement of betting odds or securities prices at certain times as revealing the preferences of \"smart money\"—those more likely to be in the know.\n"}
{"id": "45546786", "url": "https://en.wikipedia.org/wiki?curid=45546786", "title": "The International Resource Privilege", "text": "The International Resource Privilege\n\nThe International Resource Privilege is the power to transfer ownership or freely dispose of the natural resources of a country by the authority that countries give to the current leadership or government of that country. The resource privilege exists regardless of how the rulers came to power. While bribery is often illegal, the purchase of these resources by payment to the current government in control is legal. Corrupt leaders sell these resources to generate revenue which entrenches the corrupt government and incentivizing the seizure of power itself. This further handicaps the ability to achieve democracy along with hindering economic growth and the eradication of poverty.\n\nSome academics argue that International Resource Privilege remains because arrangements between global institutions tend to be struck without adequate concern for their thoroughgoing effects on the global poor. One example is that it provides additional incentive to overthrowing governments, which in turn contributes to a cycle of political instability where a promising government might just as soon be toppled as a brutal military regime. There is little incentive for foreign governments to challenge the situation because they benefit from it. The Washington Post quotes Thomas Pogge as saying “most of us do not merely let people starve, but also participate in starving them.” We elect officials that let the corporations buy the natural resources that should belong to the people is the argument for why we are involved. For example oil wealth and dictatorship go together as seen in Malaysia, Saudi Arabia, and the United Arab Emirates. This international economic and political system perpetuates and reproduces poverty in such that western nations have a negative duty not to do harm to the people of these nations.\n\nExxon Mobile is the largest exporter from Equatorial Guinea, Exxon pays Teodoro Obiang and his family for the oil rights. Simon Taylor, director of Global Witness said he is \"A dictator who has impoverished his citizens and enriched himself and his family by plundering the country's oil wealth\" Which leads us to the thought of \"What are our moral obligations to these people?\", are we responsible for their poverty and human rights violations? Thomas Pogge argues that we are.\n\nMathias Risse calls the resource and borrowing privilege \"The Cosmopolitan Complaint\". He does acknowledge that the global order provides incentives for it but attributes oppression to the sheer desire to rule. Risse rejects the belief that the global order Pogge is referring to is shaped by the \"sheer existence of states\" but Pogge rejects this idea also.\n\n"}
{"id": "6020487", "url": "https://en.wikipedia.org/wiki?curid=6020487", "title": "White-winged junco", "text": "White-winged junco\n\nThe white-winged junco (\"Junco hyemalis aikeni\") is a subspecies of the dark-eyed junco. It is superficially similar to the slate-colored junco. It was formerly classified as a distinct species.\n\nIt is a common endemic breeder in the Black Hills area of South Dakota, Wyoming, Nebraska, and Montana, and winters south along the Front Range to northeastern New Mexico.\n\n\"J. h. aikeni\" resembles the slate-colored junco but is larger, lighter gray (the head plumage contrasting with the dark lores), has much more white in the tail, and has a larger, longer bill that often has a bluish cast. Females are paler and washed brownish. Most fresh (fall/winter) individuals have the white wingbars that give this taxon its common name, but this feature is not always present, especially in spring and summer on females as the white tips to the wing coverts easily wear off. About one slate-colored junco in 200 has wing bars as bold as those of a fresh white-winged junco. Therefore, using wingbars alone to identify a bird as a white-winged junco outside the breeding range is ill-advised; identifications must be based on all the relevant characteristics.\n\n"}
{"id": "165487", "url": "https://en.wikipedia.org/wiki?curid=165487", "title": "World line", "text": "World line\n\nThe world line (or worldline) of an object is the path that object traces in 4-dimensional spacetime. It is an important concept in modern physics, and particularly theoretical physics.\n\nThe concept of a \"world line\" is distinguished from concepts such as an \"orbit\" or a \"trajectory\" (e.g., a planet's \"orbit in space\" or the \"trajectory\" of a car on a road) by the \"time\" dimension, and typically encompasses a large area of spacetime wherein perceptually straight paths are recalculated to show their (relatively) more absolute position states—to reveal the nature of special relativity or gravitational interactions. \n\nThe idea of world lines originates in physics and was pioneered by Hermann Minkowski. The term is now most often used in relativity theories (i.e., special relativity and general relativity).\n\nIn physics, a world line of an object (approximated as a point in space, e.g., a particle or observer) is the sequence of spacetime events corresponding to the history of the object. A world line is a special type of curve in spacetime. Below an equivalent definition will be explained: A world line is a time-like curve in spacetime. Each point of a world line is an event that can be labeled with the time and the spatial position of the object at that time.\n\nFor example, the \"orbit\" of the Earth in space is approximately a circle, a three-dimensional (closed) curve in space: the Earth returns every year to the same point in space. However, it arrives there at a different (later) time. The \"world line\" of the Earth is helical in spacetime (a curve in a four-dimensional space) and does not return to the same point.\n\nSpacetime is the collection of points called events, together with a continuous and smooth coordinate system identifying the events. Each event can be labeled by four numbers: a time coordinate and three space coordinates; thus spacetime is a four-dimensional space. The mathematical term for spacetime is a four-dimensional manifold. The concept may be applied as well to a higher-dimensional space. For easy visualizations of four dimensions, two space coordinates are often suppressed. The event is then represented by a point in a Minkowski diagram, which is a plane usually plotted with the time coordinate, say formula_1, upwards and the space coordinate, say formula_2 horizontally.\nAs expressed by F.R. Harvey\n\nA world line traces out the path of a single point in spacetime. A world sheet is the analogous two-dimensional surface traced out by a one-dimensional line (like a string) traveling through spacetime. The world sheet of an open string (with loose ends) is a strip; that of a closed string (a loop) is a volume.\n\nOnce the object is not approximated as a mere point but has extended volume, it traces out not a \"world line\" but rather a world tube.\n\nA one-dimensional \"line\" or \"curve\" can be represented by the coordinates as a function of one parameter. Each value of the parameter corresponds to a point in spacetime and varying the parameter traces out a line. So in mathematical terms a curve is defined by four coordinate functions formula_3 (where formula_4 usually denotes the time coordinate) depending on one parameter formula_5. A coordinate grid in spacetime is the set of curves one obtains if three out of four coordinate functions are set to a constant.\n\nSometimes, the term world line is loosely used for \"any\" curve in spacetime. This terminology causes confusions. More properly, a world line is a curve in spacetime which traces out the \"(time) history\" of a particle, observer or small object. One usually takes the proper time of an object or an observer as the curve parameter formula_5 along the world line.\n\nA curve that consists of a horizontal line segment (a line at constant coordinate time), may represent a rod in spacetime and would not be a world line in the proper sense. The parameter traces the length of the rod.\n\nA line at constant space coordinate (a vertical line in the convention adopted above) may represent a particle at rest (or a stationary observer). A tilted line represents a particle with a constant coordinate speed (constant change in space coordinate with increasing time coordinate). The more the line is tilted from the vertical, the larger the speed.\n\nTwo world lines that start out separately and then intersect, signify a \"collision\" or \"encounter\". Two world lines starting at the same event in spacetime, each following its own path afterwards, may represent the decay of a particle into two others or the emission of one particle by another.\n\nWorld lines of a particle and an observer may be interconnected with the world line of a photon (the path of light) and form a diagram which depicts the emission of a photon by a particle which is subsequently observed by the observer (or absorbed by another particle).\n\nThe four coordinate functions formula_3\ndefining a world line, are real functions of a real variable formula_5 and can simply be differentiated in the usual calculus. Without the existence of a metric (this is important to realize) one can speak of the difference between a point formula_9 on the curve at the parameter value formula_10 and a point on the curve a little (parameter formula_11) farther away. In the limit formula_12, this difference divided by formula_13 defines a vector, the tangent vector of the world line at the point formula_9. It is a four-dimensional vector, defined in the point formula_9. It is associated with the normal 3-dimensional velocity of the object (but it is not the same) and therefore called four-velocity formula_16, or in components:\n\nwhere the derivatives are taken at the point formula_9, so at formula_19.\n\nAll curves through point p have a tangent vector, not only world lines. The sum of two vectors is again a tangent vector to some other curve and the same holds for multiplying by a scalar. Therefore, all tangent vectors in a point p span a linear space, called the tangent space at point p. For example, taking a 2-dimensional space, like the (curved) surface of the Earth, its tangent space at a specific point would be the flat approximation of the curved space.\n\nSo far a world line (and the concept of tangent vectors) has been described without a means of quantifying the interval between events. The basic mathematics is as follows: The theory of special relativity puts some constraints on possible world lines. In special relativity the description of spacetime is limited to \"special\" coordinate systems that do not accelerate (and so do not rotate either), called inertial coordinate systems. In such coordinate systems, the speed of light is a constant. The structure of spacetime is determined by a bilinear form η which gives a real number for each pair of events. The bilinear form is sometimes called a \"spacetime metric\", but since distinct events sometimes result in a zero value, unlike metrics in metric spaces of mathematics, the bilinear form is \"not\" a mathematical metric on spacetime.\n\nWorld lines of freely falling particles/objects are called geodesics. In special relativity these are straight lines in Minkowski space.\n\nOften the time units are chosen such that the speed of light is represented by lines at a fixed angle, usually at 45 degrees, forming a cone with the vertical (time) axis. In general, useful curves in spacetime can be of three types (the other types would be partly one, partly another type):\n\n\n\nAt a given event on a world line, spacetime (Minkowski space) is divided into three parts.\n\n\nSince a world line formula_20 determines a velocity 4-vector formula_21 that is time-like, the Minkowski form formula_22 determines a linear function formula_23 by formula_24 Let \"N\" be the null space of this linear functional. Then \"N\" is called the simultaneous hyperplane with respect to \"v\". The relativity of simultaneity is a statement that \"N\" depends on \"v\". Indeed, \"N\" is the orthogonal complement of \"v\" with respect to η. \nWhen two world lines \"u\" and \"w\" are related by formula_25 then they share the same simultaneous hyperplane. This hyperplane exists mathematically, but physical relations in relativity involve the movement of information by light. For instance, the traditional electro-static force described by Coulomb's law may be pictured in a simultaneous hyperplane, but relativistic relations of charge and force involve retarded potentials.\n\nThe use of world lines in general relativity is basically the same as in special relativity, with the difference that spacetime can be curved. A metric exists and its dynamics are determined by the Einstein field equations and are dependent on the mass-energy distribution in spacetime. Again the metric defines lightlike (null), spacelike and timelike curves. Also, in general relativity, world lines are timelike curves in spacetime, where timelike curves fall within the lightcone. However, a lightcone is not necessarily inclined at 45 degrees to the time axis. However, this is an artifact of the chosen coordinate system, and reflects the coordinate freedom (diffeomorphism invariance) of general relativity. Any timelike curve admits a comoving observer whose \"time axis\" corresponds to that curve, and, since no observer is privileged, we can always find a local coordinate system in which lightcones are inclined at 45 degrees to the time axis. See also for example Eddington-Finkelstein coordinates.\n\nWorld lines of free-falling particles or objects (such as planets around the Sun or an astronaut in space) are called geodesics.\n\nIn 1884 C. H. Hinton wrote an essay \"What is the fourth dimension ?\" which he published as a scientific romance. He wrote\n\nA popular description of human world lines was given by J. C. Fields at the University of Toronto in the early days of relativity. As described by Toronto lawyer Norman Robertson:\n\nBecause they oversimplify world lines, which traverse four-dimensional spacetime, into one-dimensional timelines, almost all purported science-fiction stories about time travel are actually wishful fantasy stories. Some device or superpowered person is generally portrayed as departing from one point in time, and with little or no subjective lag, arriving at some other point in time—but at the same literally geographic point in space, typically inside a workshop or near some historic site. However, in reality the planet, its solar system, and its galaxy would all be at vastly different spatial positions on arrival. Thus, the time travel mechanism would also have to provide instantaneous teleportation, with infinitely accurate and simultaneous adjustment of final 3D location, linear momentum, and angular momentum.\n\nAuthor Oliver Franklin published a science fiction work in 2008 entitled \"World Lines\" in which he related a simplified explanation of the hypothesis for laymen.\n\nIn the short story \"Life-Line\", author Robert A. Heinlein describes the world line of a person:\n\nHeinlein's \"Methuselah's Children\" uses the term, as does James Blish's \"The Quincunx of Time\" (expanded from \"Beep\").\n\nA visual novel named Steins;Gate, produced by 5pb., tells a story based on the shifting of world lines. The \"Science Adventure\" series by the same company also utilized the concept.\n\nNeal Stephenson's novel Anathem involves a long discussion of worldlines over dinner in the midst of a philosophical debate between Platonic realism and nominalism.\n\nAbsolute Choice depicts different world lines as a sub-plot and setting device.\n\n\n\n\n"}
{"id": "9465910", "url": "https://en.wikipedia.org/wiki?curid=9465910", "title": "Zero one infinity rule", "text": "Zero one infinity rule\n\nThe Zero one or infinity (ZOI) rule is a rule of thumb in software design proposed by early computing pioneer Willem van der Poel. It argues that arbitrary limits on the number of instances of a particular entity should not be allowed. Specifically, an entity should either be forbidden entirely, only one should be allowed, or any number of them should be allowed. Although various factors outside that particular software could limit this number in practice, it should not be the software itself that puts a hard limit on the number of instances of the entity.\n\n\"\"Allow none of foo, one of foo, or any number of foo.\"\n\nExamples of this rule may be found in the structure of many file systems' directories (also known as folders): \nNote that violations of this rule of thumb do exist: for example, some file systems impose a limit of 65,536 (i.e. 2) files to a directory.\n"}
