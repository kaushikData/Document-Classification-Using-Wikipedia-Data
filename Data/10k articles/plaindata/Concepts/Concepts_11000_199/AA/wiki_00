{"id": "38603941", "url": "https://en.wikipedia.org/wiki?curid=38603941", "title": "Abhava", "text": "Abhava\n\nAbhava means non-existence, negation, nothing or absence. It is the negative of Bhava which means being, becoming, existing or appearance.\n\nUddayana divides \"Padārtha\" (Categories) into \"Bhava\" (existence) which is real, and \"Abhava\" (non-existence) which is not real. \"Dravya\" (substance), \"Guṇa\" (quality), \"Karma\" (action), \"Samanya\" (community or generality), \"Visesa\" (particularity or partimerity) and \"Samavaya\" (inherence) are the marks of existence. \"Abhava\" has not been categorically defined by the Vaisheshika School of Hindu philosophy but is of four kinds viz – 1) \"Pragabhava\" i.e. Prior non-existence, 2) \"Pradhvamsabhava\" i.e. Posterior non-existence, 3) \"Atyantabhava\" i.e. Absolute non-existence, and 4) \"Anyonyabhava\" i.e. Mutual non-existence.\n\n\nThe process with which the sound value collapses into the point value of the gap existing between the first and the next syllable of the first letter of the Rigveda, \"Agnim\", is \"Pradhvamsabhava\", the silent point of all possibilities within the gap is \"Atyantabhava\", the structuring dynamics of what happens within the gap \"Anyonyabhava\", and the mechanics by which the sound emerges from the point value of the gap i.e. emergence of the following syllable, is \"Pragabhava\"; this mechanism is inherent in both syllables.\n\nThe Vaisheshika, the Nyaya, the Bhatta Mimamsa and Dvaita schools hold \"Abhava\" as a distinct category. Recognised as a reality by the Nyaya school, \"Abhava\" is often stated to be the reality of the greatest moment in the pluralistic universe and is connected with Mukti. It is a relative word, for there can be \"abhava\" only when previously there is \"bhava\"; moreover it is an event occurring in time. The Nyaya and the Siddhantin maintain that the cognition of \"abhava\" is due to perception involving special kind of contact or sense contact. \n\n\"Abhava\" is that unmanifest level from where the concrete \"Bhava\" arises or emerges. Vasubandhu has referred to \"Sunyata\" having the characteristic of the own-being of \"abhava\", rather than a characteristic consisting of \"bhava\" which Sthiramati observes is in fact not redundant, which means \"abhava\" does not negate \"bhava\". \"Abhava\" refers to particular entities and not to Being ; it is a theoretical or logical denial of the existence of some particular impossibility.\nThe acceptance of abhava as an independent padartha having ontological reality of its own is a peculiar feature of Indian philosophical tradition. Dharmakirti considered \"abhava\" as an \"anumana\". He had brought in the idea of imaginary presence of that whose absence was apprehended in order to explain the specificity of the absence.\n"}
{"id": "2218843", "url": "https://en.wikipedia.org/wiki?curid=2218843", "title": "Antitheism", "text": "Antitheism\n\nAntitheism (sometimes anti-theism) is the opposition to theism. The term has had a range of applications. In secular contexts, it typically refers to direct opposition to the belief in any deity.\n\nThe \"Oxford English Dictionary\" defines \"antitheist\" as \"One opposed to belief in the existence of a god\". The earliest citation given for this meaning dates from 1833. \n\"Antitheism\" has been adopted as a label by those who regard theism as dangerous, destructive, or encouraging of harmful behavior. Christopher Hitchens offers an example of this approach in \"Letters to a Young Contrarian\" (2001), in which he writes: \"I'm not even an atheist so much as I am an antitheist; I not only maintain that all religions are versions of the same untruth, but I hold that the influence of churches, and the effect of religious belief, is positively harmful.\"\n\nOther definitions of antitheism include that of the French Catholic philosopher Jacques Maritain (1953) for whom it is \"an active struggle against everything that reminds us of God\" (p. 104), and that of Robert Flint (1877), Professor of Divinity at the University of Edinburgh. Flint's Baird Lecture for 1877 was entitled \"Anti-Theistic Theories\". He used it as a very general umbrella term for all opposition to his own form of theism, which he defined as the \"belief that the heavens and the earth and all that they contain owe their existence and continuance to the wisdom and will of a supreme, self-existent, omnipotent, omniscient, righteous, and benevolent Being, who is distinct from, and independent of, what He has created.\" He wrote:\n\nIn dealing with theories which have nothing in common except that they are antagonistic to theism, it is necessary to have a general term to designate them. Anti-theism appears to be the appropriate word. It is, of course, much more comprehensive in meaning than the term atheism. It applies to all systems which are opposed to theism. It includes, therefore, atheism, but short of atheism there are anti-theistic theories. Polytheism is not atheism, for it does not deny that there is a deity; but it is anti-theistic since it denies that there is only one. Pantheism is not atheism, for it asserts that there is a god; but it is anti-theism, for it denies that god is a being distinct from creation and possessed of such attributes as wisdom, and holiness, and love. Every theory which refuses to ascribe to a god an attribute which is essential to a worthy conception of its character is anti-theistic. Only those theories which refuse to acknowledge that there is evidence even for the existence of a god are atheistic.\n\nHowever, Flint also acknowledges that antitheism is typically understood differently from how he defines it. In particular, he notes that it has been used as a subdivision of atheism, descriptive of the view that theism has been disproven, rather than as the more general term that Flint prefers. He rejects \"non-theistic\" as an alternative, \"not merely because of its hybrid origin and character, but also because it is far too comprehensive. Theories of physical and mental science are non-theistic, even when in no degree, directly or indirectly, antagonistic to theism.\"\n\nOpposition to the existence of a god or gods is frequently referred to as dystheism (which means \"belief in a deity that is not benevolent\") or misotheism (strictly speaking, this means \"hatred of God\"). Examples of belief systems founded on the principle of opposition to the existence of a god or gods include some forms of Atheistic Satanism and maltheism.\n\nAnother use of the term \"antitheism\" was coined by Christopher New in a thought experiment published in 1993. In his article, he imagines what arguments for the existence of an evil god would look like: \"Antitheists, like theists, would have believed in an omnipotent, omniscient, eternal creator; but whereas theists in fact believe that the supreme being is also perfectly good, antitheists would have believed that he was perfectly evil.\" New's usage has reappeared in the work of Wallace A. Murphree.\n\nThe word \"antitheism\" (or the hyphenated \"anti-theism\") has been recorded in English since 1788. The etymological roots of the word are the Greek \"anti\" and \"theos.\"\n\n"}
{"id": "11731170", "url": "https://en.wikipedia.org/wiki?curid=11731170", "title": "Area chart", "text": "Area chart\n\nAn area chart or area graph displays graphically quantitative data. It is based on the line chart. The area between axis and line are commonly emphasized with colors, textures and hatchings. Commonly one compares two or more quantities with an area chart.\n\nWilliam Playfair is usually credited with inventing the area charts as well as the line, bar, and pie charts. His book \"The Commercial and Political Atlas\", published in 1786, contained a number of time-series graphs, including \"Interest of the National Debt from the Revolution\" and \"Chart of all the Imports and Exports to and from England from the Year 1700 to 1782\" that are often described as the first area charts in history.\n\nArea charts are used to represent cumulated totals using numbers or percentages (stacked area charts in this case) over time.\nUse the area chart for showing trends over time among related attributes. The area chart is like the plot chart except that the area below the plotted line is filled in with color to indicate volume.\n\nWhen multiple attributes are included, the first attribute is plotted as a line with color fill followed by the second attribute, and so on.\n\nArea charts which use vertical and horizontal lines to connect the data points in a series forming a step-like progression are called \"step-area charts\".\n\nArea charts in which data points are connected by smooth curves instead of straight lines are called \"spline-area charts\".\n\n"}
{"id": "2987765", "url": "https://en.wikipedia.org/wiki?curid=2987765", "title": "Assault occasioning actual bodily harm", "text": "Assault occasioning actual bodily harm\n\nAssault occasioning actual bodily harm (often abbreviated to Assault O.A.B.H. or simply ABH) is a statutory offence of aggravated assault in England and Wales, Northern Ireland, the Australian Capital Territory, New South Wales, Hong Kong and the Solomon Islands. It has been abolished in the Republic of Ireland and in South Australia, but replaced with a similar offence.\n\nAnything interfering with the health or comfort of victim which is more than merely transient or trifling has been held by Australian courts to be \"actual bodily harm\".\n\nThe offence is created by section 24(1) of the Crimes Act 1900.\n\nThe offence is created by section 59(1) of the Crimes Act 1900 (a different statute of the same name).\n\nAssault occasioning actual bodily harm was formerly an offence under section 40 of the Criminal Law Consolidation Act 1935, but has been abolished and replaced with a similar offence (see below).\n\nThe offence is created by section 39 of the Offences against the Person Ordinance. It is triable on indictment and a person guilty of it is liable to imprisonment for three years.\n\nThe common law offence of assault occasioning actual bodily harm was abolished, and section 47 of the Offences against the Person Act 1861 was repealed, on a date three months after 19 May 1997.\n\nThe offence is created by section 245 of the Penal Code (Ch.26).\n\nIn England and Wales, and in Northern Ireland, the offence is created by section 47 of the Offences against the Person Act 1861:\n\nThe words \"at the discretion of the court\" omitted in the first place, and the words \"for the term of three years, or to be imprisoned for any term not exceeding two years, with or without hard labour\" omitted in the second place, were repealed by the Statute Law Revision Act 1892.\n\nThe words from \"and\" to the end, omitted in the third place, were repealed for England and Wales by section 170(2) of, and Schedule 16 to, the Criminal Justice Act 1988 (subject to section 123(6) of, and paragraph 16 of Schedule 8 to, that Act).\n\nThe words \"with or without hard labour\" at the end were repealed for England and Wales by section 1(2) of the Criminal Justice Act 1948.\n\nThe text of this section is slightly different in Northern Ireland.\n\nThe expression assault includes \"battery\".\n\n\"Fagan v Metropolitan Police Commissioner\" was decided under section 51 of the Police Act 1964, which also used the word \"assault\" without further explanation and without any explicit reference to battery. James J. said:\n\nIn \"R v Williams (Gladstone)\", the defendant was prosecuted for this offence. Lord Lane said:\n\nIn \"R v Burstow, R v Ireland\", one of the defendants was prosecuted for this offence. Lord Steyn said:\n\nThe second form of assault referred to is the offence described as common assault in section 39 of the Criminal Justice Act 1988, which is also known as psychic assault or simply assault.\n\nBlackstone's Criminal Practice, 2001, says that \"occasioning\" is equivalent to causing (para B2.21 at p. 172) and has a specimen form of indictment that uses the word \"caused\" (para B2.18 at p. 171).\n\nIn \"R v Roberts\", the defendant gave a lift in his car, late at night, to a girl.\n\nThe girl said that while travelling in the defendant's car he sought to make advances towards her and then tried to take her coat off. She said that this was the last straw, and although the car was travelling at some speed, she jumped out and sustained injuries. The defendant said that he had not touched the girl. He said that he had had an argument with her and that in the course of that argument she suddenly opened the door and jumped out.\n\nStephenson LJ said that the test for determining whether the defendant had \"occasioned\" the injuries that the girl had suffered as a result of jumping out of the car was this:\n\nThis passage was set out in \"R v Savage, DPP v Parmenter\" at page 14.\n\nThe book \"Archbold\" says that this test applies to any case where the injury was not the direct result of the defendant's act.\n\nIn \"R v Savage\", \"DPP v Parmenter\", Savage threw beer over the victim and, in the struggle, the glass broke and cut the victim. It was held that section 47 did not require proof of recklessness in relation to the \"occasioning\". The throwing of the beer was an assault, and that \"assault\" had occasioned the actual bodily harm which occurred in the continuing struggle. Parmenter injured his baby by tossing him about too roughly. Even though the baby was too young to apprehend the physical contact, there was voluntary contact that caused injury, so Parmenter was liable under section 47 because the injury resulted from his intention to play with his son.\n\nIn \"Rex v. Donovan\", Swift J., in delivering the Judgement of the Court of Criminal Appeal, said:\n\nThis passage was cited and approved in \"R v Brown (Anthony)\", by Lord Templeman (at p. 230) and Lord Jauncey (at p. 242).\n\nIn \"R v. Miller\" [1954] 2 All ER 529, [1954] 2 QB 282, Lynskey J. said:\n\n<poem>According to \"Archbold's Criminal Pleading, Evidence and Practice\", 32nd ed, p 959:\n\n\"Actual bodily harm includes any hurt or injury calculated to interfere with the health or comfort of the prosecutor...\"</poem>\n\nHowever the House of Lords rejected this definition in \"DPP v. Smith\", a case of grievous bodily harm in which the trial judge had described grievous bodily harm as \"some harm which will seriously interfere for a time with health or comfort.\" The Lord Chancellor, Viscount Kilmuir QC, held:\n\n\"DPP v. Smith\" was followed in \"R v. Chan-Fook\". Hobhouse LJ. said of the expression \"actual bodily harm\", in contending that it should be given its ordinary meaning:\n\nHe went on to say:\n\n\"R v Chan-Fook\" also followed the case of \"R v Metharam\", in which Ashworth J had said:\n\nIn \"R v. Morris (Clarence Barrington)\", Potter LJ., in delivering the judgement of the Court of Appeal said (the citations that he quotes from the textbook are omitted):\n\n<poem>What constitutes \"actual bodily harm\" for the purposes of section 47 of the 1861 Act is succinctly and accurately set out in \"Archbold\" (1997 ed.) at para 19-197:\n\n\"Bodily harm has it ordinary meaning and includes any \"hurt\" (our emphasis) or injury calculated to interfere with the health or comfort of the victim: such hurt or injury need not be permanent, but must be more than merely transient or trifling ...\n\nActual bodily harm is capable of including psychiatric injury but it does not include mere emotion, such as fear, distress or panic ...\"</poem>\n\nIn \"DPP v. Smith (Michael Ross)\", Judge P. said:\n\nGlanville Williams said that actual bodily harm is a silly expression because it suggests that there is some form of bodily harm that is not actual.\n\nIn \"DPP v Smith (Michael Ross)\", the defendant held down his former girlfriend and cut off her ponytail with kitchen scissors a few weeks before her 21st birthday. The Magistrates acquitted him on the ground that, although there was undoubtedly an assault, it had not caused actual bodily harm, since there was no bruising or bleeding, and no evidence of any psychological or psychiatric harm. The victim’s distress did not amount to bodily harm. The Divisional Court allowed an appeal by the Director of Public Prosecutions, rejecting the argument for the defendant that the hair was dead tissue above the scalp and so no harm was done. Judge P said:\n\nIt has been accepted that actual bodily harm includes any hurt or injury that interferes with the health or comfort of the victim, and which is more than transient or trifling. To damage an important physical aspect of a person’s bodily integrity must amount to actual bodily harm, even if the element damaged is dead skin or tissue. As Creswell J. commented in his short concurring judgment:\n\nThe Crown Prosecution Service has revised the guidance in its publication \"Offences Against the Person, Incorporating the Charging Standard\" due to the enactment of section 58 of the Children Act 2004 which provides that reasonable chastisement is not a defence to the offence of assault occasioning actual bodily harm. Assertions at that time that minor injuries to children could be charged as actual bodily harm were withdrawn in 2011.\n\nThe CPS previously advised that an assault which resulted in nothing more than grazes, scratches, abrasions, minor bruising, swellings, reddening of the skin, superficial cuts or a black eye should be prosecuted as a common assault in the absence of aggravating factors other than injury.\n\nThe charging standard states: \"The offence of Common Assault carries a maximum penalty of six months’ imprisonment. This will provide the court with adequate sentencing powers in most cases. ABH should generally be charged where the injuries and overall circumstances indicate that the offence merits clearly more than six months; imprisonment and where the prosecution intend to represent that the case is not suitable for summary trial.\"\n\nAnd in reference to vulnerable victims such as children:\n\nThere may be exceptional cases where the injuries suffered by a victim are not serious and would usually amount to Common Assault but due to the presence of significant aggravating features (alone or in combination), they could more appropriately be charged as ABH contrary to section 47 of the Offences Against the Person Act 1861. This would only be where a sentence clearly in excess of six months' imprisonment ought to be available, having regard to the significant aggravating features.\n\nThe CPS also previously said that, by way of example, it considered the following injuries to be actual bodily harm and to be sufficiently serious that they could not be adequately reflected by a charge of common assault and ought normally to be prosecuted under section 47:\n\n\nCausing any of these injuries (by assault or battery) would constitute the actus reus of assault occasioning actual bodily harm.\n\nThe mens rea of this offence is identical to that of assault or battery (depending on the mode by which the offence is committed). Accordingly, it does not correspond with the actus reus. Academic writers have termed this feature of the offence \"half mens rea\" and \"constructive liability\".\n\nThe mens rea for this crime may be one of recklessness rather than intention as to the commission of an assault or battery, and it is considered to be a crime of basic intent.\n\nThe court in \"DPP v Parmenter\" ruled that, for this offence,\n\nIn England and Wales, assault occasioning actual bodily harm is triable either way.\n\nIn England and Wales, a person guilty of assault occasioning actual bodily harm is liable, on conviction on indictment, to imprisonment for a term not exceeding five years, or on summary conviction to imprisonment for a term not exceeding six months, or to a fine not exceeding the prescribed sum, or to both.\n\nWhere a person is convicted on indictment of assault occasioning actual bodily harm, other than an offence for which the sentence falls to be imposed under section 227 or 228 of the Criminal Justice Act 2003, the court, if not precluded from sentencing an offender by its exercise of some other power, may impose a fine instead of or in addition to dealing with him in any other way in which the court has power to deal with him, subject however to any enactment requiring the offender to be dealt with in a particular way.\n\nAssault occasioning actual bodily harm is a specified offence for the purposes of chapter 5 of the Criminal Justice Act 2003 because it is a specified violent offence. It is not a serious offence for the purposes of that Chapter because it is not, apart from section 225, punishable in the case of a person aged 18 or over by imprisonment for life, or by imprisonment for a determinate period of ten years or more. This means that sections 227 and 228 of the Criminal Justice Act 2003 (which relate to extended sentences) apply where a person is convicted of assault occasioning actual bodily harm, committed after the commencement of section 227 or 228 (as the case may be) and the court considers that there is a significant risk to members of the public of serious harm occasioned by the commission by the offender of further specified offences.\n\nSee \"Crown Prosecution Service Sentencing Manual\" for case law on sentencing. Relevant cases are:\n\nIt is inappropriate for the court to sentence an offender on the basis of racial aggravation where he has been convicted of this offence, but not the racially aggravated offence: \"R v. McGilliviray\"; \"R v. Kentsch\".\n\nIn Northern Ireland, a person guilty of assault occasioning actual bodily harm is liable, on conviction on indictment, to imprisonment for a term not exceeding seven years, or on summary conviction to imprisonment for a term not exceeding twelve months, or to a fine not exceeding the prescribed sum, or to both.\n\nIn England and Wales, section 29(1)(b) of the Crime and Disorder Act 1998 (c.37) creates the distinct offence of racially or religiously aggravated assault occasioning actual bodily harm.\n\nIn England and Wales and Northern Ireland, assault occasioning actual bodily harm is an offence against the person for the purposes of section 3 of the Visiting Forces Act 1952.\n\nIn a number of jurisdictions this offence has been replaced by an offence which is very similar.\n\nSouth Australia's section 20(4) of the Criminal Law Consolidation Act 1935 creates the offence of assault causing harm.\n\nSection 267(b) of the Canadian \"Criminal Code\" creates the offence of assault causing bodily harm.\n\nSection 3 of the Non-Fatal Offences against the Person Act 1997 (No.26) creates the offence of assault causing harm.\n\n"}
{"id": "1683043", "url": "https://en.wikipedia.org/wiki?curid=1683043", "title": "Behavior-shaping constraint", "text": "Behavior-shaping constraint\n\nA behavior-shaping constraint, also sometimes referred to as a forcing function or poka-yoke, is a technique used in error-tolerant design to prevent the user from making common errors or mistakes. One example is the reverse lockout on the transmission of a moving automobile.\n\nThe microwave oven provides another example of a forcing function. In all modern microwave ovens, it is impossible to start the microwave while the door is still open. Likewise, the microwave will shut off automatically if the door is opened by the user. By forcing the user to close the microwave door while it is in use, it becomes impossible for the user to err by leaving the door open. Forcing functions are very effective in safety critical situations such as this, but can cause confusion in more complex systems that do not inform the user of the error that has been made.\n\nWhen automobiles first started shipping with on-board GPS systems, it was not uncommon to use a forcing function which prevented the user from interacting with the GPS (such as entering in a destination) while the car was in motion. This ensures that the driver's attention is not distracted by the GPS. However, many drivers found this feature irksome, and the forcing function has largely been abandoned. This reinforces the idea that forcing functions are not always the best approach to shaping behavior.\n\nThese forcing functions are being used in the service industry as well. Call centers concerned with credit card fraud and friendly fraud are using agent-assisted automation to prevent the agent from seeing or hearing the credit card information so that it cannot be stolen. The customer punches the information into their phone keypad, the tones are masked to the agent and are not visible in the customer relationship management software.\n\n"}
{"id": "2894295", "url": "https://en.wikipedia.org/wiki?curid=2894295", "title": "Bibeltemplet", "text": "Bibeltemplet\n\nBibeltemplet (the Bible temple) is a Christian website in Sweden, whose administrator Leif Liljeström was sentenced in April 2005 to two months in prison for holding and expressing critical views on homosexuality. The case was appealed twice, and the Supreme Court of Sweden acquitted Liljeström in November 2007.\n\nAccording to the lower court in 2005, the administrator was guilty of \"incitement against a group of people\" for statements he himself had written, and for crime against \"the law on electronic bulletin boards\", for guest-messages which he neglected to delete. Liljeström told the court that his purpose is to preach the gospel and win people for Jesus, and that the truth is needed to awake people. Among the statements that led to the verdict were the following: \"The modern homophilia is the source and engine behind the AIDS-epidemic\", and \"AIDS is a punishment from God against sodomy\". The view that there should be a \"death penalty for homosexual acts\" was also uttered on the website by a guest, but that was repudiated by Leif Liljeström directly in the forum. Still, he was convicted to prison also for the guest's statements.\n\nIn April 2006, an appeals court in Gothenburg acquitted Liljestrom of the hate-speech and website content charges, but found him guilty of being an accomplice to hate-speech for allowing third parties to post offensive material on his website. The appeals court sentenced Liljestrom to one month's imprisonment.\n\nLiljestrom then filed an appeal to the Gothenburg court decision. The Supreme Court in Stockholm decided to accept the case, and on November 7, 2007, after more than four years of struggle (counting from the day he was reported to the police in October, 2003), he was finally acquitted of all charges.\n\nThe case has many similarities with the case of Åke Green, and is expected to be seen as a guideline for coming justice in Sweden.\n\n\n"}
{"id": "56121172", "url": "https://en.wikipedia.org/wiki?curid=56121172", "title": "Case Solvers", "text": "Case Solvers\n\nCase Solvers is a company founded in September 2012 and run by young Hungarian professionals. Case Solvers' mission is to train young problem solvers, and to create a platform between graduates and the actors of the labor market. The organization was called Hungarian Business Case Society until 2013, then it gradually took up the name 'Case Solvers'. The team of 35 young Hungarians held more than 250 trainings to talented university students in 27 countries by 2017.\n\nCase Solvers was founded as Hungarian Business Case Society in September 2012 by Zsolt Ábrahám, Gergely Balázs and István Juhász. Initially, the organization functioned as a blog where professional articles about case solving were published continually. The page, case-study.hu aimed to spread case solving as a teaching method among Hungarian and international business students as well.\n\nCase Solvers (then known as HBCS) held its first training at the College of Management (Hungary) in March 2013, which was soon followed by several case interview trainings. The team organized its first case study camp, the Case Camp in August 2013. Within a year, Case Solvers held training courses in its home country's most prestigious business universities and prepared top teams for national and international case study competitions.\n\nHBCS held its first training course as Case Solvers in November 2013, in India. The first training was soon followed by another in Romania, then in the Netherlands. By 2017, Case Solvers held more than 250 trainings in 27 countries.\n\nCase Solvers trainings in Hungary:\n\n● Corvinus University of Budapest, Budapest, Hungary\n\n● Budapest Business School, Budapest, Hungary\n\n● University of Miskolc, Miskolc, Hungary\n\n● University of Pécs, Pécs, Hungary\n\nInternational Case Solvers trainings:\n\n● Aalto University, Helsinki, Finland\n\n● Babes-Bolyai University, Cluj-Napoca, Romania\n\n● Caucasus University, Tbilisi, Georgia\n\n● Charles University, Prague, Czech Republic\n\n● Delhi University, New Delhi, India\n\n● FGV São Paulo, São Paulo, Brazil\n\n● University of Glasgow, Glasgow, United Kingdom\n\n● Graduate Institute, Geneva, Switzerland\n\n● HEC Paris, Paris, France\n\n● Imperial College London, London, United Kingdom\n\n● Indian Institute of Management Calcutta, Calcutta, India\n\n● Koc University, Istanbul, Turkey\n\n● London School of Economics and Political Sciences, London, UK\n\n● NOVA School of Management, Lisbon, Portugal\n\n● Partium Christian University, Oradea, Romania\n\n● Rotterdam School of Management, Rotterdam, The Netherlands\n\n● Sapientia University, Miercurea Ciuc, Romania\n\n● Solvay Business School, Brussels, Belgium\n\n● University of Cologne, Cologne, Germany\n\n● University of Ljubljana, Ljubljana, Slovenia\n\n● University of Oslo, Oslo, Norway\n\n● University of Pretoria, Pretoria, South Africa\n\n● University of Sao Paulo, Sao Paolo, Brazil\n\n● University of St. Gallen, St. Gallen, Switzerland\n\n● Warsaw School of Economics, Warsaw, Poland\n\n● Buenos Aires, Argentina\n\nOne of the main activities of Case Solvers is training business students in case solving. There are two main groups of trainings: Case Solving Training and Case Interview Training.\n\nConventional case solving training, where problem solving, structured thinking and logical deduction are the obtainable skills. The case solver's task is to give a solution for an ill-structured, complex business problem, that they also need to present in front of a professional jury. Case Solvers hold trainings in several formats: from one afternoon they can even last a whole weekend. The amount and complexity of the material taught on trainings depend on the length of the training. Case Solvers often prepares teams for specific case competitions, both national and international ones.\n\nCorporations, multinationals and consulting firms are likely to choose between candidates based on case interviews. The point is that job candidates must find a solution to a problem during the interview. This is usually a real problem that the interviewer has already faced in the company. The case interviews are perfect for assessing the candidate's abilities. At certain companies, this is a key point in the recruitment process, therefore careful preparation is required from the applicant.\n\nCase interview trainings by Case Solvers prepare for situations like this: students can learn the methods of case interviewing by professionals, who have already undergone similar situations and who are currently working in the most prestigious consulting firms or multinational companies themselves. Case Interview Training – similar to Case Solving – could last from just a half-day up to an entire weekend as well. The amount and complexity of the material taught depends on the length of the training.\n\nIB Day is about revealing the mystery of investment banks by showing training participants what they actually do, and how their recruitment and hiring processes work.\n\nIn addition to preparing teams for national and international case competitions, Case Solvers also organizes its own competitions.\n\nThe Case Solver of The Year Ranking (founded in 2013) aims to differentiate the case study competitions in Hungary and to make the competitor's performance measurable. The ranking is proposed to present the most successful competitors of the given year to the public, who are among Hungary's best case solvers based on their performance in case study competitions. The most prestigious case competitions of the academic year are the ones that matter in the Ranking.\n\nCase Solver of the Year, the final competition organized by Case Solvers and Vialto Consulting is an invitational competition. The event aims to create a platform for the country's top case solvers where they can challenge themselves against the other outstanding students from the Case Solver of The Year Ranking. The contestant with the highest score gets a trophy for being the Case Solver of The Year.\n\nFormer case studies of the Case Solver of The Year Competition:\n\n2014: Gránit Bank\n\n2015: Budapesti Közlekedési Központ (Centre for Budapest Transport)\n\n2016: Hungarian Telekom\n\n2017: ENKSZ\n\nSolvers' Cup is Hungary's unique international case competition both as an invitational and online competition, which was first organized in 2016. The invitational part of Solvers' Cup, which included teams from Europe's top universities was held in Budapest, at the Corvinus University. Competitors were representatives of Consulting Clubs from for example Oxford and St. Gallen, as well as Czech, Austrian and Hungarian teams, among others. During the three-day event, participants had to provide a solution to a complex business problem followed by two rounds of presentations in front of the professional jury. Among the jury members we could find the dean of the Corvinus University and representatives of Loxon Solutions, DHL Consulting, Roland Berger, PwC, Philip Morris and Ringier Axel Springer.\n\nCase Solvers created an online surface to give an opportunity for case solvers all over the world to join the contest. The 130 registered students had the same task as the invited competitors, but the case solving time was only 10 hours long for them. The online competition gave a chance to participate and to experience dynamic thinking and quick decision-making given the short deadline to all those who did not have the opportunity to compete personally in Budapest. Considering the first year's success, Case Solvers intents to organize Solvers' Cup every year from now on.\n\nCase Solvers continuously publishes international research related to case solving and the expectations of the young generation at work. The research is aimed to inform the key actors of the labor market and to transfer their accumulated international knowledge.\n\nCase Solvers' team first published an English report – Career Ambitions Report – on career expectations of the young entrants of the labor market in March 2016. The survey is made up of three modules:\n\n1. How students collect information\n\n2. How students evaluate information\n\n3. The key aspects of the students’ decision-making process\n\nThe 2015 survey reflects the opinion of the youth interested in management consulting from six countries (Hungary, Romania, Switzerland, the Netherlands, India and Ukraine), while the report of 2016 was enlarged by university students of three other countries: Brazil, Argentina and the South African Republic.\n\nCase competitions play every year more important role in the life of business students. The good results achieved in these competitions become an advantage when it comes to finding a job, especially in the consulting area. Case Solvers' research covers the current situation of the Hungarian case competitions, as well as the motivations and opinion of the participants.\n\nThe survey was based on interviews and questionnaires, overall it summarizes the opinion of more than a hundred university students. The main conclusions are the following: every year there are a significant increase in the number of case competitions in Hungary, and the main motivation of the competitors is to gain professional experience.\n\nCase Solvers placed great emphasis on the development of the Hungarian youth from the beginning. In December 2013, they co-founded the National Secondary School Problem Solving Contest (Országos Középiskolai Problémamegoldó Verseny) with Mathias Corvinus Collegium, and they launched the “Where to continue my studies?” (Hol tanuljak tovább?, HTT) initiative in November 2014. To support these projects, Problema Solvenda Foundation was established in January 2016 with the purpose of educating Hungarian high school students.\n\nHTT is a non-profit project of Case Solvers that helps secondary school students make thoughtful decisions about their further studies. On the program's website, people with different fields of education and profession talk about their every day working lives, bringing it closer to graduating students.\n\nOKPV is a program for high school students that gives them an insight into the world of the future academic case competitions. The task is problem solving of course, but the participants have to take on a historical figure’s character and make decisions with their minds. OKPV in 2017 is now the fourth competition in a row – in cooperation with Mathias Corvinus Collegium. Thanks to the Problema Solvenda Foundation, the competition is now held in Slovenia, Romania and Ukraine as well.\n"}
{"id": "14069912", "url": "https://en.wikipedia.org/wiki?curid=14069912", "title": "Caterina Davinio", "text": "Caterina Davinio\n\nCaterina Davinio (born Maria Caterina Invidia; November 25, 1957, Foggia) is an Italian poet, novelist and new media artist. Author of digital art, net.art, video art. She was the creator of Italian Net-poetry in 1998.\n\nBorn in Foggia, she grew up in Rome since 1961. She studied literature and art history (student of Giulio Carlo Argan) at Rome University La Sapienza, where, in 1981, she received a MA degree in Italian Literature. Caterina began to write poetry when she was fourteen years old. In Rome she came in contact with the international circuit of experimental poetry and art, resulting in an intense curatorial activity in collaboration with renowned artists, critics and poets of the avant-garde. Since 1997 she has been living in Monza and Lecco, working at international level.\n\nFrom the early 1990s Davinio was a pioneer of Italian electronic poetry, in the experimental field among writing, visual art, and new media, using computer, video, digital photography, Internet. She was the first woman artist who utilized the computer and Internet in literature and poetry in Italy. Author of visual and sound poetry, she created also works with traditional techniques, such as painting and photography. She is author of novels, books of poetry, essays, and for many of them she received literary awards and recognition in Italy and abroad.\nIn 1997 she collaborated to \"netOper@\", the first Italian interactive work for the web, by the composer Sergio Maltagliati. She also initiated Net-poetry in Italy, in 1998, with the website and network \"Karenina.it\". The participants included Julien Blaine, Clemente Padin, Philadelpho Menezes, Mirella Bentivoglio, Lamberto Pignotti, Eugenio Miccini, and many other new media artists, critics, and experimental poets.\n\nHer art has been featured in more than three hundred international exhibitions and festivals in many countries, among them the Biennale de Lyon (two editions), the Biennale of Sydney (on-line events), the Athens Biennial, E-Poetry (University SUNY Buffalo, NY, and Barcelona), Polyphonix Festival (Barcelona and Paris), seven times in the Venice Biennale and collateral events, where she collaborated also as a curator.\n\nShe exhibited animated digital poetry works - called \"Terminal Videopoems\" - in the 1997 Venice Biennale, in \"VeneziaPoesia\", a project directed by the poet and writer Nanni Balestrini.\nIn 1999 she participated, as a poet and a video artist, in \"Progetto Oreste\" at the Italian Pavilion of the 48th Venice Biennale, where she also curated a video poetry exhibition.\n\nDavinio's net-poetry participated in the Venice Biennale also in 2001 - Harald Szeemann curator - in the context of \"Bunker Poetico\", which was a collaborative installation - involving 1000 international poets and artists - created by the architect Marco Nereo Rotelli in cooperation with Istituto Italiano per gli Studi Filosofici of Venice, Massimo Donà, I Quaderni del Battello Ebbro publisher, Caterina Davinio, Milanocosa cultural association, and others. Davinio engaged in this project renown avant-garde poets and organized a virtual happening on-line called \"Parallel Action-Bunker\", simultaneous with real readings and performances at Orsogrill delle Artiglierie, a venue of the Venice Biennial.\n\nIn 2005 she created the net-poetry work \"Virtual Island\", a web site and poetry network, in the context of the 51st Venice Biennale.\"Virtual Island\" involved 500 international poets, among them: Adunis, Lawrence Ferlinghetti, Alda Merini, Fernanda Pivano, and many other established writers.\n\nIn 2009 she created the virtual installation \"The First Poetry Space Shuttle Landing on Second Life\" and other on-line happenings in the 53rd Venice Biennale Collateral Events, engaging more than 200 poets from around the world, to celebrate the centenary of Italian Futurism. In the same project she curated also the event \"Network Poetico Net-Poetry Reading in Webcam\", a poetry reading in Skype videocall with poets from various continents and countries. In the context of the 2009 Venice Biennale Davinio participated also in the exhibition \"Détournement Venise 2009\".\n\nIn 2014 she exhibited her net-poetry installation \"Big Splash\" in the \"Master Section\" of the international festival OLE.01, dedicated to electronic literature, in the Doric Room of the Royal Palace of Naples; The festival took place in many institutional spaces of Naples in October 2014 and involved some of the main international pioneers of electronic literature and experts and scholars in that field.\n\nAmong the literary critics who have written about Davinio's works of fiction and poetry: Francesco Muzzioli, Dante Maffia, Ivano Mugnaini, David W. Seaman; some of the critics who have been interested in her work of digital poetry and electronic arts are: Eugenio Miccini, Lamberto Pignotti, Jorge Luiz Antonio, Christopher Thompson Funkhouser, Marco Maria Gazzano, and others.\n\nNet-poetry project \"Karenina it\" (1998) was the first art-poetry-communication project presented on the web in an Italian context; the website was not a simple cultural on-line journal, but a \"space of aggregation\", which hosted an ongoing discourse, involving emerging and established experimental artists, critics, and visual poets. The communication aspect was treated as an artistic medium that goes beyond the contents or the quality of the words: borders among art, critic, and communication, in Davinio's own concept, were cancelled. The flow of words and information became art in itself, transcending the necessity to view art in traditional terms of form.\nThe suffix \".it\" present in Karenina.it title is a geographic locator for the origin of the website. The value of the site resides within the conceptual framework of the Fluxus art movement.\"\nKarenina.it won MAD03 Award (section Net-Zin) in 2003, Madrid.\n\nOther Davinio’s net-poetry and net.art performances and events are based on the evolution of the multi-located structure experimented with \"Parallel Action-Bunker\", mentioned before: beyond the simple presence of the performer on stage, performance is considered a \"collaborative\", \"decentralized\", \"multi-located\" action; poetry is conceived as \"social structure, e-communication, real/virtual interaction\", and \"e-communication\" is assumed as a new material for the artist.\nAmong them:\n\n\n\nCaterina Davinio participated in more than three hundred international art exhibitions in the world, among them: \"Biennale de Lyon\" (two editions), \"The Venice Biennale\" and collateral events (seven editions since 1997, where she collaborated also as a curator), \"Athens Biennial\", \"Poliphonyx\" (in Barcelona and in Paris), \"Biennale of Sydney\" (Online Venue), Liverpool Biennial (\"Independents\", Online Venue), \"ParmaPoesia\", \"VeneziaPoesia\" (Nanni Balestrini curator), \"RomaPoesia\", \"Biennale di arti elettroniche, cinema e televisione\" of Rome (Marco Maria Gazzano curator), \"Le tribù dell'Arte\", \"Tribù del video e della performance\" (Rome, Galleria Comunale d'Arte Moderna e Contemporanea, Achille Bonito Oliva curator), \"Artmedia VII\" (University of Salerno, Mario Costa curator), \"E-Poetry Festival\" (University of Barcelona, University SUNY Buffalo, NY), \"Interactiva, New Media Art Biennial, Merida\", Mexico, Hong Kong Artists' Biennial, and many others.\n\nNovels:\nPoetry books:\nEssays:\nOther publications:\n\nStudent at the Faculty of Humanities, University La Sapienza of Rome, in 1977, she participated in the Movement of 1977 and in the occupation of the faculty.\nDavinio lived a turbulent young life marked by heroin addiction and abuse of drugs and alcohol; this experience emerges in many of her literary works, particularly in \"Il libro dell'oppio 1975 – 1990\" (The Book of Opium 1975 – 1990).\nIn 1980 she married the Turkish entrepreneur Levent Muharrem Sergün in Rome, moving to Munich and Istanbul; in 1982 their son Leonardo was born in Rome. After the divorce in 1984, Caterina married Claudio Preziosi in Rome in 1986, giving birth, in the same year, to her son Riccardo Amedeo.\nLover of travels, Davinio dedicated to India, Africa, and many other places, poetry and photography works.\nShe has nine tattoos made in her travels, including some Sak Yant, traditional South East Asia tattoos, realized in Cambodia.\n\n\n\nBooks\nInterviews\nReviews\n"}
{"id": "8255831", "url": "https://en.wikipedia.org/wiki?curid=8255831", "title": "Charles Dixon (ornithologist)", "text": "Charles Dixon (ornithologist)\n\nCharles Dixon (1858-17 June 1926) was an English ornithologist, born in London. He discovered the St Kilda wren and a new species in North Africa. He collaborated with Henry Seebohm on his great work on \"British Birds\", in the second volume of which he summarized and modified A. R. Wallace's theory of the relation between nests and coloration of birds. Elliott Coues wrote in the preface to the American edition of Dixon's book \"Rural bird life\" pointing out the originality of the observations made from the field and Julian Huxley noted Dixon for recognizing the value of prismatic binoculars for bird study. In his later years, he wrote in the newspapers on agricultural fairs and horse shows. \n\nLittle is known of Dixon's early life. Dixon's early studies on ornithology were followed by numerous books. He did not believe in the role of natural selection in evolution and in his \"Evolution without Natural Selection\" (1885) he used examples of adaptations that were apparently of little survival value to illustrate his position. Reviewers were quick to point out that natural selection essentially works on adaptations that do have a survival value. He also argued that Darwin was mistaken to conclude that ornate male plumages evolved due to female selection. \n\nDixon made a special study of bird migration — especially in his 1892 book \"The Migration of Birds\" (new edition, 1897), an ingenious theoretical work — and of geographical distribution of birds. Dixon changed his ideas drastically between the two editions of his book on migration. In the 1892 edition he supported the idea that birds moved out of unfavourable environmental conditions but in the 1897 edition he suggested that migration is essentially derived from dispersal and range extension of birds. He believed that glaciation in former times could not have induced migration on its own and that southward migration was because of a former mass of tropical land that stretched around the equator. Reviewers did not think of his theories as being well-founded. Julian Huxley recognized him for noting the potential of prismatic binoculars to unravel the life of living birds. He also published behavioural observations on birds and often incorporated these in his books. He recognized the threats to birds posed by human activity and was an early conservationist. He was quite opposed to the ideas of acclimatisation and recognized the problem of introduction of species into Australia and New Zealand and their effects, especially on flightless birds. He expressed his conservation ethic thus:\n\nOf his many books, the following may be mentioned: \n\nIn later life he took an interest in agricultural and horse shows, especially the Richmond horse show. He died of a heart attack at his home in Harlesden in 1926. Seebohm named the long-tailed thrush \"Zoothera dixoni\" (originally in the genus \"Geocichla\").\n"}
{"id": "42012063", "url": "https://en.wikipedia.org/wiki?curid=42012063", "title": "Charles McDew", "text": "Charles McDew\n\nCharles \"Chuck\" McDew (June 23, 1938 – April 3, 2018) was an American lifelong activist for racial equality and a former activist of the Civil Rights Movement. After attending South Carolina State University, he became the chairman of the Student Nonviolent Coordinating Committee (SNCC) from 1960 to 1963. His involvement in the movement earned McDew the title, “black by birth, a Jew by choice and a revolutionary by necessity” stated by fellow SNCC activist Bob Moses.\n\nCharles Frederick McDew was born in Massillon, Ohio in 1938, to Eva (née Stephens) and James McDew. He was one of four children. Mcdew's mother worked as a nurse and his father, who had been a chemistry teacher in South Carolina, had become a steel worker after Ohio schools refused to hire him. According to McDew's autobiography, he believed that his birth date was notable because he was born on the day that boxer Joe Louis defeated Max Schmeling for the heavyweight championship of the world. Even though the fight was a rematch, McDew was convinced by his elders that he was destined to do something great or good for the \"Negro\" race. McDew also referred to himself as a \"race baby\", an ideal that had never been defined to him by family members, but one that he believed he was expected to define for himself as his future unfolded. \"I had a charge to do something for the race. It was never specified what I would do for the race, but it was expected that I would do something to help the colored race to move ahead.\"\n\nMcDew grew up in a family who talked little about the advancement of civil rights. Though there was little talk on that topic, McDew displayed his first example of general protesting when he was only in the eighth grade. Protesting the rights of religious freedom, McDew is seen standing up for his peers by representing Amish religion at a very young age.\n\nAs he got older, McDew expected to grow up to work in the steel mills, as many men in that area did. Before he did so, his father requested that McDew go to the South to experience his \"own culture\" to expand his ideas of what work he could do. Upon arrival at his university of choice, South Carolina State University, Charles thought that his father was \"the most brilliant man alive.\" Never having seen so many \"pretty black girls,\" McDew instantly knew he chose the right college.\n\nDuring his first Thanksgiving on campus, McDew decided to travel with his roommate, Charles Gatson, back to the area where Gatson had family because it would be cheaper than going back to Ohio and the schools closed during these holidays. During their vacation, the two of them, and some others, went to a party. McDew responsibly decided to be the designated driver, but on their way home, they were pulled over by a police officer. This was presumably for the reason of McDew and Gatson being black. Not knowing how to address an officer in the South different than in the North, McDew answered the officer's questions with a bit too much sass.(I) This is what led to the beating and first arrest of Charles McDew.\n\nA couple days later, McDew was on his way to the train station to head home. The general cart for white people and the end cart for the black people were both filled, so McDew was told to go sit in the luggage cart. Refusing is what led to the second arrest of Charles McDew.\n\nThe day he finally got back to South Carolina, McDew was walking to his dorm. In pain because of his previous beating, he decided to walk home though a park. Being unfamiliar with segregation, the park McDew walked through happened to only be open to white people on this particular day, which led to his third arrest in two days.\n\nThese events were said to be the beginning of McDew's inspiration towards the Movement and McDew's general distaste for the Southern way of life.\n\nIn April 1960, McDew received a letter from Martin Luther King Jr. stating that they were going to have a SCLC meeting at Shaw University in Raleigh, North Carolina to discuss the student sit ins, and as a representative for South Carolina State University, Charles attended. This meeting talked about student involvement all over the South, along with King trying to persuade everyone to join the SCLC. McDew did not want to join because he did not completely agree with the route of nonviolence. Thinking of Mahatma Gandhi, McDew's reasoning was that if Gandhi tried the nonviolence method in Africa and was beaten, jailed, and ultimately run out of the country, how would this method work in the \"most violent country in the world?\"\n\nDue to this disagreement, McDew and a few other students went down the hall and talked about creating a new group. This group would compliment the already established SCLC, along with enforcing a few other beliefs. After much talking, the students thought to call their new group the Student Coordinating Committee, but with a couple students completely focused on nonviolence, they ultimately chose to include \"Nonviolent\" in the name. The students then proceeded to nominate Marion Barry as their first chairman. Performing the last touches to establish their organization, McDew even had a hand in developing the dress code and other rules.\n\nAs the Student Nonviolent Coordinating Committee received more publicity and presence in the media, reporters gave them nicknames. This is how SNCC (pronounced \"snick\") came to be. One reporter referred to them as this in his article, and from then on, the organization was SNCC.\n\nDuring this time, SNCC and McDew wanted to focus on black voter registration. Feeling that the real \"threat\" in the movement would ultimately be the black voters, McDew and the organization went on to promote registration in the \"blackest\" parts of the country. Thinking that if they could get people in, for example, Baker's County and Mississippi to register, then they could get anyone to register. Knowing that \"violence was a part of the game,\" they could not let these areas of the country intimidate them because once these areas were registered, anywhere could get registered.\n\nAs the movement developed and grew, SNCC kept getting into trouble and people kept getting arrested. This is how the \"Jail No Bail\" tactic began. This was where activists would get arrested, refuse to pay their fines for 39 days, (they only had 40 days to post bail) and then on the 39th day post their bail. This was a way of protesting the illegal arrests they were suffering.\n\nAs time went on and the need for a second chairman came around, and Charles McDew was elected because of his obvious drive for the movement. He remained SNCC's second chairman until 1963. Since these years, he has participated in many sit ins, arrests, protests and more to stand up for what he believes is right and fair for everybody.\n\nHe, and eleven others, were once arrested for \"disrupting racial harmony\" and were placed into a cold Mississippi cell described as an \"iceberg.\" Little food, no eating or drinking utensils, and some having to huddle for warmth. This arrest included, McDew has been arrested 43 times.\n\nHe was also active in organizations for social and political change, working as a teacher and as a labor organizer, managing anti-poverty programs in Washington, D.C., \"serving as community organizer and catalyst for change in Boston and San Francisco, as well as other communities.\"\n\nAfter moving to the South for college, McDew attempted to attend various churches. All the churches he tried were white churches, so he was rejected from every one. This led him into the arms of a rabbi, who was the first to welcome him religiously in the South. This, along with the quote \"If I am not for myself, who will be for me? If I am for myself only, what am I? If not now, when?\" from the Talmud, is what led McDew to Judaism and McDew's moral \"obligation\" to fight for justice.\n\nMcDew had one daughter, Eva (Dion) Goodman. He lived in St. Paul, Minnesota. He was retired from Metropolitan State University in Minneapolis, Minnesota, where he had taught classes in the history of the civil rights movement, African-American history and classes in social and cultural awareness. \n\nMcDew died on April 3, 2018 of a heart attack while visiting his close longtime friend in Massachusetts. He was 79.\n\n"}
{"id": "375416", "url": "https://en.wikipedia.org/wiki?curid=375416", "title": "Computer simulation", "text": "Computer simulation\n\nComputer simulation is the reproduction of the behavior of a system using a computer to simulate the outcomes of a mathematical model associated with said system. Since they allow to check the reliability of chosen mathematical models, computer simulations have become a useful tool for the mathematical modeling of many natural systems in physics (computational physics), astrophysics, climatology, chemistry, biology and manufacturing, human systems in economics, psychology, social science, health care and engineering. Simulation of a system is represented as the running of the system's model. It can be used to explore and gain new insights into new technology and to estimate the performance of systems too complex for analytical solutions.\n\nComputer simulations are realized by running computer programs that can be either small, running almost instantly on small devices, or large-scale programs that run for hours or days on network-based groups of computers. The scale of events being simulated by computer simulations has far exceeded anything possible (or perhaps even imaginable) using traditional paper-and-pencil mathematical modeling. Over 10 years ago, a desert-battle simulation of one force invading another involved the modeling of 66,239 tanks, trucks and other vehicles on simulated terrain around Kuwait, using multiple supercomputers in the DoD High Performance Computer Modernization Program.\nOther examples include a 1-billion-atom model of material deformation; a 2.64-million-atom model of the complex protein-producing organelle of all living organisms, the ribosome, in 2005;\na complete simulation of the life cycle of Mycoplasma genitalium in 2012; and the Blue Brain project at EPFL (Switzerland), begun in May 2005 to create the first computer simulation of the entire human brain, right down to the molecular level.\n\nBecause of the computational cost of simulation, computer experiments are used to perform inference such as uncertainty quantification.\n\nA computer model is the algorithms and equations used to capture the behavior of the system being modeled. By contrast, computer simulation is the actual running of the program that contains these equations or algorithms. Simulation, therefore, is the process of running a model. Thus one would not \"build a simulation\"; instead, one would \"build a model\", and then either \"run the model\" or equivalently \"run a simulation\".\n\nComputer simulation developed hand-in-hand with the rapid growth of the computer, following its first large-scale deployment during the Manhattan Project in World War II to model the process of nuclear detonation. It was a simulation of 12 hard spheres using a Monte Carlo algorithm. Computer simulation is often used as an adjunct to, or substitute for, modeling systems for which simple closed form analytic solutions are not possible. There are many types of computer simulations; their common feature is the attempt to generate a sample of representative scenarios for a model in which a complete enumeration of all possible states of the model would be prohibitive or impossible.\n\nThe external data requirements of simulations and models vary widely. For some, the input might be just a few numbers (for example, simulation of a waveform of AC electricity on a wire), while others might require terabytes of information (such as weather and climate models).\n\nInput sources also vary widely:\n\nLastly, the time at which data is available varies:\n\nBecause of this variety, and because diverse simulation systems have many common elements, there are a large number of specialized simulation languages. The best-known may be Simula (sometimes called Simula-67, after the year 1967 when it was proposed). There are now many others.\n\nSystems that accept data from external sources must be very careful in knowing what they are receiving. While it is easy for computers to read in values from text or binary files, what is much harder is knowing what the accuracy (compared to measurement resolution and precision) of the values are. Often they are expressed as \"error bars\", a minimum and maximum deviation from the value range within which the true value (is expected to) lie. Because digital computer mathematics is not perfect, rounding and truncation errors multiply this error, so it is useful to perform an \"error analysis\" to confirm that values output by the simulation will still be usefully accurate.\n\nEven small errors in the original data can accumulate into substantial error later in the simulation. While all computer analysis is subject to the \"GIGO\" (garbage in, garbage out) restriction, this is especially true of digital simulation. Indeed, observation of this inherent, cumulative error in digital systems was the main catalyst for the development of chaos theory.\n\nComputer models can be classified according to several independent pairs of attributes, including:\n\nAnother way of categorizing models is to look at the underlying data structures. For time-stepped simulations, there are two main classes:\n\nEquations define the relationships between elements of the modeled system and attempt to find a state in which the system is in equilibrium. Such models are often used in simulating physical systems, as a simpler modeling case before dynamic simulation is attempted.\n\nFormerly, the output data from a computer simulation was sometimes presented in a table or a matrix showing how data were affected by numerous changes in the simulation parameters. The use of the matrix format was related to traditional use of the matrix concept in mathematical models. However, psychologists and others noted that humans could quickly perceive trends by looking at graphs or even moving-images or motion-pictures generated from the data, as displayed by computer-generated-imagery (CGI) animation. Although observers could not necessarily read out numbers or quote math formulas, from observing a moving weather chart they might be able to predict events (and \"see that rain was headed their way\") much faster than by scanning tables of rain-cloud coordinates. Such intense graphical displays, which transcended the world of numbers and formulae, sometimes also led to output that lacked a coordinate grid or omitted timestamps, as if straying too far from numeric data displays. Today, weather forecasting models tend to balance the view of moving rain/snow clouds against a map that uses numeric coordinates and numeric timestamps of events.\n\nSimilarly, CGI computer simulations of CAT scans can simulate how a tumor might shrink or change during an extended period of medical treatment, presenting the passage of time as a spinning view of the visible human head, as the tumor changes.\n\nOther applications of CGI computer simulations are being developed to graphically display large amounts of data, in motion, as changes occur during a simulation run.\n\nGeneric examples of types of computer simulations in science, which are derived from an underlying mathematical description:\n\nSpecific examples of computer simulations follow:\n\nNotable, and sometimes controversial, computer simulations used in science include: Donella Meadows' World3 used in the \"Limits to Growth\", James Lovelock's Daisyworld and Thomas Ray's Tierra.\n\nIn social sciences, computer simulation is an integral component of the five angles of analysis fostered by the data percolation methodology, which also includes qualitative and quantitative methods, reviews of the literature (including scholarly), and interviews with experts, and which forms an extension of data triangulation.\n\nGraphical environments to design simulations have been developed. Special care was taken to handle events (situations in which the simulation equations are not valid and have to be changed). The open project Open Source Physics was started to develop reusable libraries for simulations in Java, together with Easy Java Simulations, a complete graphical environment that generates code based on these libraries.\n\nTaiwanese Tone Group Parser is a simulator of Taiwanese tone sandhi acquisition.\nIn practical, the method using linguistic theory to implement the Taiwanese tone group parser is a way to apply knowledge engineering technique to build the experiment environment of computer simulation for language acquisition. A work-in-process version of artificial tone group parser that includes a knowledge base and an executable program file for Microsoft Windows system (XP/Win7) can be download for evaluation.\n\nComputer simulations are used in a wide variety of practical contexts, such as:\n\nThe reliability and the trust people put in computer simulations depends on the validity of the simulation model, therefore verification and validation are of crucial importance in the development of computer simulations. Another important aspect of computer simulations is that of reproducibility of the results, meaning that a simulation model should not provide a different answer for each execution. Although this might seem obvious, this is a special point of attention in stochastic simulations, where random numbers should actually be semi-random numbers. An exception to reproducibility are human-in-the-loop simulations such as flight simulations and computer games. Here a human is part of the simulation and thus influences the outcome in a way that is hard, if not impossible, to reproduce exactly.\n\nVehicle manufacturers make use of computer simulation to test safety features in new designs. By building a copy of the car in a physics simulation environment, they can save the hundreds of thousands of dollars that would otherwise be required to build and test a unique prototype. Engineers can step through the simulation milliseconds at a time to determine the exact stresses being put upon each section of the prototype.\n\nComputer graphics can be used to display the results of a computer simulation. Animations can be used to experience a simulation in real-time, e.g., in training simulations. In some cases animations may also be useful in faster than real-time or even slower than real-time modes. For example, faster than real-time animations can be useful in visualizing the buildup of queues in the simulation of humans evacuating a building. Furthermore, simulation results are often aggregated into static images using various ways of scientific visualization.\n\nIn debugging, simulating a program execution under test (rather than executing natively) can detect far more errors than the hardware itself can detect and, at the same time, log useful debugging information such as instruction trace, memory alterations and instruction counts. This technique can also detect buffer overflow and similar \"hard to detect\" errors as well as produce performance information and tuning data.\n\nAlthough sometimes ignored in computer simulations, it is very important to perform a sensitivity analysis to ensure that the accuracy of the results is properly understood. For example, the probabilistic risk analysis of factors determining the success of an oilfield exploration program involves combining samples from a variety of statistical distributions using the Monte Carlo method. If, for instance, one of the key parameters (e.g., the net ratio of oil-bearing strata) is known to only one significant figure, then the result of the simulation might not be more precise than one significant figure, although it might (misleadingly) be presented as having four significant figures.\n\nThe following three steps should be used to produce accurate simulation models: calibration, verification, and validation. Computer simulations are good at portraying and comparing theoretical scenarios, but in order to accurately model actual case studies they have to match what is actually happening today. A base model should be created and calibrated so that it matches the area being studied. The calibrated model should then be verified to ensure that the model is operating as expected based on the inputs. Once the model has been verified, the final step is to validate the model by comparing the outputs to historical data from the study area. This can be done by using statistical techniques and ensuring an adequate R-squared value. Unless these techniques are employed, the simulation model created will produce inaccurate results and not be a useful prediction tool.\n\nModel calibration is achieved by adjusting any available parameters in order to adjust how the model operates and simulates the process. For example, in traffic simulation, typical parameters include look-ahead distance, car-following sensitivity, discharge headway, and start-up lost time. These parameters influence driver behavior such as when and how long it takes a driver to change lanes, how much distance a driver leaves between his car and the car in front of it, and how quickly a driver starts to accelerate through an intersection. Adjusting these parameters has a direct effect on the amount of traffic volume that can traverse through the modeled roadway network by making the drivers more or less aggressive. These are examples of calibration parameters that can be fine-tuned to match characteristics observed in the field at the study location. Most traffic models have typical default values but they may need to be adjusted to better match the driver behavior at the specific location being studied.\n\nModel verification is achieved by obtaining output data from the model and comparing them to what is expected from the input data. For example, in traffic simulation, traffic volume can be verified to ensure that actual volume throughput in the model is reasonably close to traffic volumes input into the model. Ten percent is a typical threshold used in traffic simulation to determine if output volumes are reasonably close to input volumes. Simulation models handle model inputs in different ways so traffic that enters the network, for example, may or may not reach its desired destination. Additionally, traffic that wants to enter the network may not be able to, if congestion exists. This is why model verification is a very important part of the modeling process.\n\nThe final step is to validate the model by comparing the results with what is expected based on historical data from the study area. Ideally, the model should produce similar results to what has happened historically. This is typically verified by nothing more than quoting the R-squared statistic from the fit. This statistic measures the fraction of variability that is accounted for by the model. A high R-squared value does not necessarily mean the model fits the data well. Another tool used to validate models is graphical residual analysis. If model output values drastically differ from historical values, it probably means there is an error in the model. Before using the model as a base to produce additional models, it is important to verify it for different scenarios to ensure that each one is accurate. If the outputs do not reasonably match historic values during the validation process, the model should be reviewed and updated to produce results more in line with expectations. It is an iterative process that helps to produce more realistic models.\n\nValidating traffic simulation models requires comparing traffic estimated by the model to observed traffic on the roadway and transit systems. Initial comparisons are for trip interchanges between quadrants, sectors, or other large areas of interest. The next step is to compare traffic estimated by the models to traffic counts, including transit ridership, crossing contrived barriers in the study area. These are typically called screenlines, cutlines, and cordon lines and may be imaginary or actual physical barriers. Cordon lines surround particular areas such as a city's central business district or other major activity centers. Transit ridership estimates are commonly validated by comparing them to actual patronage crossing cordon lines around the central business district.\n\nThree sources of error can cause weak correlation during calibration: input error, model error, and parameter error. In general, input error and parameter error can be adjusted easily by the user. Model error however is caused by the methodology used in the model and may not be as easy to fix. Simulation models are typically built using several different modeling theories that can produce conflicting results. Some models are more generalized while others are more detailed. If model error occurs as a result, in may be necessary to adjust the model methodology to make results more consistent.\n\nIn order to produce good models that can be used to produce realistic results, these are the necessary steps that need to be taken in order to ensure that simulation models are functioning properly. Simulation models can be used as a tool to verify engineering theories, but they are only valid if calibrated properly. Once satisfactory estimates of the parameters for all models have been obtained, the models must be checked to assure that they adequately perform the intended functions. The validation process establishes the credibility of the model by demonstrating its ability to replicate actual traffic patterns. The importance of model validation underscores the need for careful planning, thoroughness and accuracy of the input data collection program that has this purpose. Efforts should be made to ensure collected data is consistent with expected values. For example, in traffic analysis it is typical for a traffic engineer to perform a site visit to verify traffic counts and become familiar with traffic patterns in the area. The resulting models and forecasts will be no better than the data used for model estimation and validation.\n\n\n"}
{"id": "54390139", "url": "https://en.wikipedia.org/wiki?curid=54390139", "title": "Cotton ceiling", "text": "Cotton ceiling\n\nThe term cotton ceiling refers to the difficulty trans people experience when seeking lesbian and gay relationships, and in lesbian and gay social spaces more generally. A play on the similar term \"glass ceiling\", the term was coined by Canadian trans woman and activist Drew DeVeaux.\n\nSome trans rights activists have described this as transphobic exclusion. In 2014, Julia Serano wrote that \"when the overwhelming majority of cis dykes date and fuck cis women, but are not open to, or are even turned off by, the idea of dating or fucking trans women, how is that not transphobic?\" Cisgender lesbian Andrea Zanin wrote in 2013 that \"a lot of cis and otherwise non-trans gals need to ... take the opportunity to really examine how much of our desire rests on cissexism, and how much of the sexual culture we create and consume excludes trans women\".\n\nHowever, other trans activists consider the concept problematic. Journalist Paris Lees wrote in 2015 that \"there's a huge difference between denying someone a job versus not desiring someone sexually. Sexual attraction may be the one area that it's OK to 'discriminate' in—after all, it's up to you who you want to fuck—but you don't need to be a dick about your preference.\" Meanwhile, a 2013 Everyday Feminism article, written by an anonymous trans woman, stated that \"the 'cotton ceiling' should be considered an unhelpful concept for this type of discussion and should be set aside by trans activists moving forward.\"\n\nThe concept is almost universally condemned by anti-trans activists. Academic Sheila Jeffreys wrote in her 2014 book \"Gender Hurts: A Feminist Analysis of the Politics of Transgenderism\" that '[t]he campaign relies on guilt-tripping, in which women who resist are accused of transphobia or transmisogyny, in an attempt to induce them to admit unwanted penises to their bodies.\", while in the same year blogger Julian Vigo wrote on CounterPunch that \"[w]hile many are sympathetic to the fact that trans women wish to be accepted within social circles as women, they find it preposterous that lesbians are now being asked to deny their sexuality as proof of their solidarity with trans women, least (sic) they be labelled a bigot.\"\n"}
{"id": "41577021", "url": "https://en.wikipedia.org/wiki?curid=41577021", "title": "Developmental Eclecticism", "text": "Developmental Eclecticism\n\nDevelopmental Eclecticism or Systematic Eclecticism was founded by Gerard Egan in the 1970s.\n"}
{"id": "16796643", "url": "https://en.wikipedia.org/wiki?curid=16796643", "title": "Domain (mathematical analysis)", "text": "Domain (mathematical analysis)\n\nIn mathematical analysis, a domain is any connected open subset of a finite-dimensional vector space. This is a different concept than the domain of a function, though it is often used for that purpose, for example in partial differential equations and Sobolev spaces.\n\nVarious degrees of smoothness of the boundary of the domain are required for various properties of functions defined on the domain to hold, such as integral theorems (Green's theorem, Stokes theorem), properties of Sobolev spaces, and to define measures on the boundary and spaces of traces (generalized functions defined on the boundary). Commonly considered types of domains are domains with continuous boundary, Lipschitz boundary, \"C\" boundary, and so forth.\n\nA Bounded domain is a domain which is a bounded set, while an Exterior or external domain is the interior of the complement of a bounded domain.\n\nIn complex analysis, a complex domain (or simply domain) is any connected open subset of the complex plane ℂ. For example, the entire complex plane is a domain, as is the open unit disk, the open upper half-plane, and so forth. Often, a complex domain serves as the domain of definition for a holomorphic function.\n\nIn the study of several complex variables, the definition of a domain is extended to include any connected open subset of ℂ\"\".\n\nAccording to Hans Hahn, the concept of a domain as an open connected set was introduced by Constantin Carathéodory in his famous book . Hahn also remarks that the word \"\"Gebiet\" (\"Domain\"\") was occasionally previously used as a synonym of open set.\n\nHowever, the term \"domain\" was occasionally used to identify closely related but slightly different concepts. For example, in his influential monographs on elliptic partial differential equations, Carlo Miranda uses the term \"region\" to identify an open connected set, and reserves the term \"domain\" to identify an internally connected, perfect set, each point of which is an accumulation point of interior points, following his former master Mauro Picone: according to this convention, if a set is a region then its closure is a domain.\n\n\n"}
{"id": "335910", "url": "https://en.wikipedia.org/wiki?curid=335910", "title": "Eight-circuit model of consciousness", "text": "Eight-circuit model of consciousness\n\nThe Eight-Circuit Model of Consciousness is a hypothesis by Timothy Leary, and later expanded on by Robert Anton Wilson and Antero Alli, that \"suggested eight periods [circuits] and twenty-four stages of neurological evolution\". The eight circuits, or eight \"brains\" as referred by other authors, operate within the human nervous system, each corresponding to its own imprint and direct experience of reality. Leary and Alli include three stages for each circuit that details developmental points for each level of consciousness.\nThe first four circuits deal with life on earth, and survival of the species. The last four circuits are post-terrestrial, and deal with the evolution of the species, altered states of consciousness, enlightenment, mystical experiences, psychedelic states of mind, and psychic abilities. The proposal suggests that these altered states of consciousness are recently realized, but not widely utilized. Leary describes the first four as \"larval circuits\", necessary for surviving and functioning in a terrestrial human society, and proposed that the post terrestrial circuits will be useful for future humans who, through a predetermined script, continue to act on their urge to migrate to outer space and live extra-terrestrially. Leary, Wilson, and Alli have written about the idea in depth, and have explored and attempted to define how each circuit operates, both in the lives of individual people and in societies and civilization.\n\nThe term \"circuit\" is equated to a metaphor of the brain being computer hardware, and that the wiring of the brain as circuitry.\n\nLeary uses the eight circuits along with recapitulation theory to explain the evolution of the human species, the personal development of an individual, and the biological evolution of all life.\n\nEach circuit listed has each name from Leary's book \"Exo-Psychology\" after the preface, and Wilson's book \"Quantum Psychology\" pgs.196-201. \"Note:In other books from Leary, Wilson, and Alli, the eight circuits have different names due to different interpretations and findings of each author. Please reference bibliography section for other works on labeling of each circuit.\"\n\nThis circuit is concerned with nourishment, physical safety, comfort and survival, suckling, cuddling, etc. It begins with one spatial dimension, forward/back.\n\nThis circuit is imprinted early in infancy. The imprint will normally last for life unless it is re-imprinted by a powerful experience. Depending on the nature of the imprint, the organism will tend towards one of two basic attitudes:\n\nThis circuit is said to have appeared in the earliest evolution of the invertebrate brain and corresponds to the reptilian brain of triune brain theory. This circuit operates in essentially the same way across mammals, reptiles, fish, primates and humans. \n\nRobert Anton Wilson equated this circuit with the oral stage in the Freudian theory of psychosexual development, and proposed that this circuit is activated in adults by strong opioids.\n\nThe emotional-territorial circuit is imprinted in the toddler stage. It is concerned with domination and submission, territoriality, etc.\n\nThe imprint on this circuit will trigger one of two states:\n\nThis circuit is activated by depressant drugs such as alcohol, barbiturates, and benzodiazepines. This circuit appeared first in territorial vertebrate animals and is preserved across all mammals. It corresponds to the mammalian brain of triune brain theory. Robert Anton Wilson equated this circuit with the anal stage in the Freudian theory of psycho-sexual development. This circuit introduces a 2nd spatial dimension; up/down.\n\nThe first and second circuits both imprint in a binary fashion: trust/suspicion and dominance/submission. Thus there are four possible ways of imprinting the first two circuits:\n\n\nThis circuit is imprinted by human symbol systems. It is concerned with language, handling the environment, invention, calculation, prediction, building a mental \"map\" of the universe, physical dexterity, etc.\n\nThis circuit is activated by stimulant drugs such as amphetamines, cathinones, cocaine, and caffeine. This circuit supposedly appeared first when hominids started differentiating from the rest of the primates.\n\nRobert Anton Wilson, being heavily influenced by General Semantics, writes of this circuit as the 'time-binding circuit'. This means that this circuit's contents – including human know-how, technology, science etc. - are preserved memetically and passed on from generation to generation, constantly mutating and increasing in sophistication.\n\nThis fourth circuit is imprinted by the first orgasm-mating experiences and tribal \"morals\". It is concerned with sexual pleasure (instead of sexual reproduction), local definitions of \"moral\" and \"immoral\", reproduction, rearing of the young, etc. The fourth circuit concerns itself with cultural values and operating within social networks. This circuit is said to have first appeared with the development of tribes. Some have pointed out that entactogens such as MDMA seem to meet some of the requirements needed to activate this circuit.\n\nThis is concerned with neurological-somatic feedbacks, feeling high and blissful, somatic reprogramming, etc. It may be called the rapture circuit.\n\nWhen this circuit is activated, a non-conceptual feeling of well-being arises. This has a beneficial effect on the health of the physical body.\n\nThe fifth circuit is consciousness of the body. There is a marked shift from linear visual space to an all-encompassing aesthetic sensory space. Perceptions are judged not so much for their meaning and utility, but for their aesthetic qualities. Experience of this circuit often accompanies an hedonistic turn-on, a rapturous amusement, a detachment from the previously compulsive mechanism of the first four circuits.\n\nThis circuit is activated by ecstatic experiences via physiological effects of cannabis, Hatha Yoga, tantra and Zen meditation. Robert Anton Wilson writes, \"Tantra yoga is concerned with shifting consciousness entirely into this circuit\" and that \"Prolonged sexual play without orgasm always triggers some Circuit V consciousness\".\n\nLeary describes that this circuit first appeared in the upper classes, with the development of leisure-class civilizations around 2000 BC.\n\n\"Note: Timothy Leary lists this circuit as the sixth, and the neurogenetic circuit as the seventh. In \"Prometheus Rising\", Robert Anton Wilson reversed the order of these two circuits, describing the neurogenetic circuit as the sixth circuit, and the metaprogramming circuit as the seventh. In the subsequently published \"Quantum Psychology\", he reverted this back to the order proposed by Leary.\"\n\nThis circuit is concerned with re-imprinting and re-programming all earlier circuits and the relativity of \"realities\" perceived. The sixth circuit consists of the nervous system becoming aware of itself. Leary says this circuit enables telepathic communication and is activated by low-to-moderate doses of LSD (50-150 µg), moderate doses of peyote, psilocybin mushrooms and meditation/chanting especially when used in a group or ritual setting. This circuit is traced by Leary back to 500 BC.\n\nThis circuit is the connection of the individual's mind to the whole sweep of evolution and life as a whole. It is the part of consciousness that echoes the experiences of the previous generations that have brought the individual's brain-mind to its present level.\n\nIt deals with ancestral, societal and scientific DNA-RNA-brain feedbacks. Those who achieve this mutation may speak of past lives, reincarnation, immortality etc. It corresponds to the collective unconscious in the models of Carl Jung where archetypes reside.\n\nActivation of this circuit may be equated with consciousness of the Great God Pan in his aspect as Life as a whole, or with consciousness of Gaia, the biosphere considered as a single organism.\n\nThis circuit is activated by higher doses of LSD (200-500 µg), higher doses of peyote, higher doses of psilocybin mushrooms, yoga and meditation.\n\nThe circuit first appeared among the Hindus in the early first millennium and later reappeared among the Sufi sects.\n\nThe eighth circuit is concerned with quantum consciousness, non-local awareness (information from beyond ordinary space-time awareness which is limited by the speed of light), illumination. Some of the ways this circuit can get activated are: the awakening of kundalini, shock, a near-death experience, DMT, high doses of LSD and according to Robert Anton Wilson almost any dose of ketamine. This circuit has even been compared to the Buddhist concept of Indra's net from the Avatamsaka Sutra.\n\nLeary stated \"They[The theories presented in \"Info-Psychology\"] are scientific in that they are based on empirical findings from physics, physiology, pharmacology, genetics, astronomy, behavioral psychology, information science, and most importantly, neurology.\" \n\nLeary called his book \"science faction\" or \"psi-phy\" and noted he had written it \"in various prisons to which the author had been sentenced for dangerous ideology and violations of Newtonian and religious laws\".\n\nAlthough Leary propounded the basic premise of eight \"brains\" or brain circuits, he was inspired by sources such as the Hindu \"chakra\" system.\n\nLeary claimed that among other things this model explained the social conflict in the 1960s, where the mainstream was said to be those with four circuits active and characterized by Leary as tribal moralists and clashed with the counter-culturists, who were then said to be those with the fifth circuit active and characterized as individualists and hedonists. \n\nLeary's first book on the subject, \"Neurologic\", only included seven circuits when it was published in 1973. \"Exo-Psychology\", published in 1977, expanded the number of circuits to eight and clarified the subject. In it, he puts forward the theory that the later four circuits are \"post terrestrial;\" intended to develop as we migrate off this planet and colonize others. Once we begin space migration, according to Leary, we will have more ready access to these higher circuits. \"Exo-Psychology\" was re-published as revised by Timothy Leary with additional material in 1989 under the title \"Info-Psychology\" (New Falcon Publishing).\n\nLeary's ideas heavily influenced the work of Robert Anton Wilson. Wilson's book \"Prometheus Rising\" is an in-depth work documenting Leary's eight-circuit model of consciousness. Wilson's published screenplay \"Reality Is What You Can Get Away With\" uses and explains the model. Wilson, like Leary, wrote about the distinction between terrestrial and post-terrestrial life.\n\n\"Angel Tech\" by Antero Alli, is structured around the Eight-circuit model of consciousness. Alli defines the word angel as \"a being of light\" and tech from the word \"techne\" meaning \"art\". The title is defined as \"the art of being light\". It includes suggested activities such as meditations and construction of tarot-card collages associated with each circuit and imprint.\n\nThe model is fairly prominent in chaos magic. This concept has been detailed in \"Chaotopia!\" by Dave Lee, a leading member of the magic society Illuminates of Thanateros. Leary and Wilson were also members of the society. \n\nRolf Von Eckartsberg also appears to have been influenced by the model.\n\n\n\n"}
{"id": "27687935", "url": "https://en.wikipedia.org/wiki?curid=27687935", "title": "Environmental issues with coral reefs", "text": "Environmental issues with coral reefs\n\nHuman impact on coral reefs is significant. Coral reefs are dying around the world. Damaging activities include coral mining, pollution (organic and non-organic), overfishing, blast fishing, the digging of canals and access into islands and bays. Other dangers include disease, destructive fishing practices and warming oceans. Factors that affect coral reefs include the ocean's role as a carbon dioxide sink, atmospheric changes, ultraviolet light, ocean acidification, viruses, impacts of dust storms carrying agents to far-flung reefs, pollutants, algal blooms and others. Reefs are threatened well beyond coastal areas. Warming causes coral bleaching, which if severe kills the coral.\n\nIn 2008, a worldwide study estimated that 19% of the existing area of coral reefs has already been lost, and that a further 17% is likely to be lost over the subsequent 10–20 years. Only 46% of the world's reefs could be currently regarded as in good health. About 60% of the world's reefs may be at risk due to destructive, human-related activities. The threat to the health of reefs is particularly strong in Southeast Asia, where 80% of reefs are endangered. By the 2030s, 90% of reefs are expected to be at risk from both human activities and climate change; by 2050, it is predicted that all coral reefs will be in danger.\n\nIn the Caribbean Sea and tropical Pacific ocean, direct contact between coral and 40–70% of common seaweeds cause bleaching and death of coral tissue via allelopathic competition. The lipid-soluble extracts of seaweeds that harmed coral tissues also produced rapid bleaching. At these sites bleaching and mortality was limited to areas of direct contact with seaweed or their extracts. The seaweed then expanded to occupy the dead coral's habitat. However, as of 2009, only 4% of coral reefs worldwide had more than 50% algal coverage. Further, there is no recent global trend towards algal dominance.\n\nCompetitive seaweed and other algae thrive in nutrient-rich waters in the absence of sufficient herbivorous predators. Herbivores include fish such as parrotfishs, surgeonfishes, tangs and unicornfishes.\n\nOverfishing, particularly selective overfishing, can unbalance coral ecosystems by encouraging the excessive growth of coral predators. Predators that eat living coral, such as the crown-of-thorns starfish, are called \"corallivores\". Coral reefs are built from stony coral, which evolved with large amounts of the wax cetyl palmitate in their tissues. Most predators find this wax indigestible. The crown-of-thorns starfish is a large (up to one meter) starfish protected by long, venomous spines. Its enzyme system dissolves the wax in stony corals, and allows the starfish to feed on the living animal. Starfish face predators of their own, such as the giant triton sea snail. However, the giant triton is valued for its shell and has been over fished. As a result, crown-of-thorns starfish populations can periodically grow unchecked, devastating reefs.\n\nAlthough some marine aquarium fish species can reproduce in aquaria (such as Pomacentridae), most (95%) are collected from coral reefs. Intense harvesting, especially in maritime Southeast Asia (including Indonesia and the Philippines), damages the reefs. This is aggravated by destructive fishing practices, such as cyanide and blast fishing. Most (80–90%) aquarium fish from the Philippines are captured with sodium cyanide. This toxic chemical is dissolved in sea water and released into areas where fish shelter. It narcotizes the fish, which are then easily captured. However, most fish collected with cyanide die a few months later from liver damage. Moreover, many non-marketable specimens die in the process. It is estimated that 4,000 or more Filipino fish collectors have used over of cyanide on Philippine reefs alone, about 150,000 kg per year. A major catalyst of cyanide fishing is poverty within fishing communities. In countries like the Philippines that regularly employ cyanide, more than thirty percent of the population lives below the poverty line.\n\nDynamite fishing is another destructive method for gathering fish. Sticks of dynamite, grenades, or home-made explosives are detonated in the water. This method of fishing kills the fish within the main blast area, along with many unwanted reef animals. The blast also kills the corals in the area, eliminating the reef's structure, destroying habitat for the remaining fish and other animals important for reef health. Muroami is the destructive practice of covering reefs with nets and dropping large stones onto the reef to produce a flight response among the fish. The stones break and kill the coral. Muroami was generally outlawed in the 1980s.\n\nFishing gear damages reefs via direct physical contact with the reef structure and substrate. Gill nets, fish traps, and anchors break branching coral and cause coral death through entanglement. When fishermen drop lines by coral reefs, the lines entangle the coral. The fisher cuts the line and abandons it, leaving it attached to the reef. The discarded lines abrade coral polyps and upper tissue layers. Corals are able to recover from small lesions, but larger and recurrent damage complicates recovery.\n\nBottom dragging gear such as beach seines can damage corals by abrasion and fracturing. A beach seine is a long net about with a mesh size of and a weighted line to hold the net down while it is dragged across the substrate and is one of the most destructive types of fishing gear on Kenya’s reefs.\n\nBottom trawling in deep oceans destroys cold–water and deep–sea corals. Historically, industrial fishers avoided coral because their nets would get caught on the reefs. In the 1980s, \"rock–hopper\" trawls attached large tires and rollers to allow the nets to roll over rough surfaces. Fifty-five percent of Alaskan cold–water coral that was damaged by one pass from a bottom trawl had not recovered a year later. Northeast Atlantic reefs bear scars up to long. In Southern Australia, 90 percent of the surfaces on coral seamounts are now bare rock. Even in the Great Barrier Reef World Heritage Area, seafloor trawling for prawns and scallops is causing localized extinction of some coral species.\n\nReefs in close proximity to human populations are subject to poor water quality from land- and marine-based sources. In 2006 studies suggested that approximately 80 percent of ocean pollution originates from activities on land. Pollution arrives from land via runoff, the wind and \"injection\" (deliberate introduction, e.g., drainpipes).\nRunoff brings with it sediment from erosion and land-clearing, nutrients and pesticides from agriculture, wastewater, industrial effluent and miscellaneous material such as petroleum residue and trash that storms wash away. Some pollutants consume oxygen and lead to eutrophication, killing coral and other reef inhabitants.\n\nAn increasing fraction of the global population lives in coastal areas. Without appropriate precautions, development (e.g., buildings and paved roads) increases the fraction of rainfall and other water sources that enter the ocean as runoff by decreasing the land's ability to absorb it.\n\nPollution can introduce pathogens. For example, Aspergillus sydowii has been associated with a disease in sea fans, and Serratia marcescens, has been linked to the coral disease white pox.\n\nReefs in close proximity to human populations can be faced with local stresses, including poor water quality from land-based sources of pollution. Copper, a common industrial pollutant has been shown to interfere with the life history and development of coral polyps.\n\nIn addition to runoff, wind blows material into the ocean. This material may be local or from other regions. For example, dust from the Sahara moves to the Caribbean and Florida. Dust also blows from the Gobi and Taklamakan deserts across Korea, Japan, and the Northern Pacific to the Hawaiian Islands. Since 1970, dust deposits have grown due to drought periods in Africa. Dust transport to the Caribbean and Florida varies from year to year with greater flux during positive phases of the North Atlantic Oscillation. The USGS links dust events to reduced health of coral reefs across the Caribbean and Florida, primarily since the 1970s. Dust from the 1883 eruption of Krakatoa in Indonesia appeared in the annular bands of the reef-building coral \"Montastraea annularis\" from the Florida Reeftract.\n\nSediment smothers corals and interferes with their ability to feed and reproduce. Pesticides can interfere with coral reproduction and growth. There is evidence that chemicals in sunscreens contribute to coral bleaching by lowering the resistance of zooxanthellae to viruses.\n\nNutrient pollution, particularly nitrogen and phosphorus can cause eutrophication, upsetting the balance of the reef by enhancing algal growth and crowding out corals. This nutrient–rich water can enable blooms of fleshy algae and phytoplankton to thrive off coasts. These blooms can create hypoxic conditions by using all available oxygen. Biologically available nitrogen (nitrate plus ammonia) needs to be below 1.0 micromole per liter (less than 0.014 parts per million of nitrogen), and biologically available phosphorus (orthophosphate plus dissolved organic phosphorus) needs to be below 0.1 micromole per liter (less than 0.003 parts per million of phosphorus). In addition concentrations of chlorophyll (in the microscopic plants called phytoplankton) needs to be below 0.5 parts per billion. Both plants also obscure sunlight, killing both fish and coral. High nitrate levels are specifically toxic to corals, while phosphates slow down skeletal growth.\n\nExcess nutrients can intensify existing disease, including potentially doubling the spread of Aspergillosis, a fungal infection that kills soft corals such as sea fans, and increasing yellow band disease, a bacterial infection that kills reef-building hard corals by fifty percent.\n\nA study released in April 2013 has shown that air pollution can also stunt the growth of coral reefs; researchers from Australia, Panama and the UK used coral records (between 1880 and 2000) from the western Caribbean to show the threat of factors such as coal-burning coal and volcanic eruptions. The researchers state that the study signifies the first time that the relationship between air pollution and coral reefs has been elucidated, while former chair of the Great Barrier Reef Marine Park Authority Ian McPhail referred to the report as \"fascinating\" upon the public release of its findings.\n\nMarine debris is any solid object that enters coastal and ocean waters. Debris may arrive directly from a ship or indirectly when washed out to sea via rivers, streams, and storm drains. Human-made items tend to be the most harmful such as plastics (from bags to balloons, hard hats to fishing line), glass, metal, rubber (millions of waste tires), and even entire vessels.\n\nPlastic debris kills several reef species. Derelict (abandoned) fishing nets and other gear—often called \"ghost nets\" because they still catch fish and other marine life despite being abandoned—can entangle and kill reef organisms and break or damage reefs. Even remote reef systems suffer the effects of marine debris. Reefs in the Northwestern Hawaiian Islands are particularly prone to the accumulation of marine debris because of their central location in the North Pacific Gyre. From 2000 to 2006, NOAA and partners removed over 500 tons of marine debris there.\n\nDredging operations are sometimes completed by cutting a path through a coral reef, directly destroying the reef structure and killing any organisms that live on it. Operations that directly destroy coral are often intended to deepen or otherwise enlarge shipping channels or canals, due to the fact that in many areas, removal of coral requires a permit, making it more cost-effective and simple to avoid coral reefs if possible.\n\nDredging also releases plumes of suspended sediment, which can settle on coral reefs, damaging them by starving them of food and sunlight. Continued exposure to dredging spoil has been shown to increase rates of diseases such as white syndrome, bleaching and sediment necrosis among others. A study conducted in the Montebello and Barrow Islands showed that the number of coral colonies with signs of poor health more than doubled in transects with high exposure to dredging sediment plumes.\n\nSunscreen enters the wastewater system when it is washed off and eventually reaches the ocean. Some 14,000 tons of sunscreen ends up in the ocean each year. Certain formulations of sunscreen are a serious danger to coral health. The common sunscreen ingredient oxybenzone causes coral bleaching and has an impact on other marine fauna.\n\nIn Akumal, Mexico, visitors are warned not to use sunscreen and are kept out of some areas to prevent damage to the coral. In several other tourist destinations, authorities recommend the use of sunscreens prepared with the naturally occurring chemicals titanium dioxide or zinc oxide, or suggest the use of clothing rather than chemicals to screen the skin from the sun.\n\nRising sea levels due to climate change requires coral to grow to stay close enough to the surface to continue photosynthesis. Also, water temperature changes or disease of the coral can induce coral bleaching, as happened during the 1998 and 2004 El Niño years, in which sea surface temperatures rose well above normal, bleaching and killing many reefs. Bleaching may be caused by different triggers, including High sea surface temperature (SST), pollution, or other diseases. SST coupled with high irradiance (light intensity), triggers the loss of zooxanthellae, a symbiotic single cell algae that gives the coral its color and the coral's dinoflagellate pigmentation, which turns the coral white when it is expelled, which can kill the coral. Zooxanthellae provide up to 90% of their hosts' energy supply. Healthy reefs can often recover from bleaching if water temperatures cool. However, recovery may not be possible if levels rise to 500 ppm because concentrations of carbonate ions may then be too low.\n\nWarming seawater may also encourage an emerging problem: coral disease. Weakened by warm water, coral is much more prone to diseases including black band disease, white band disease and skeletal eroding band. If global temperatures increase by 2 °C during the twenty-first century, coral may not be able to adapt quickly enough.\n\nWarming seawater is also expected to cause migrations in fish populations to compensate for the change. This puts coral reefs and their associated species at risk of invasion and may cause their extinction if they are unable to compete with the invading populations.\n\nA 2010 report by the Institute of Physics predicts that unless the national targets set by the Copenhagen Accord are amended to eliminate loopholes, then by 2100 global temperatures could rise by 4.2 °C and result in an end to coral reefs.\n\nOcean acidification results from increases in atmospheric carbon dioxide. Oceans absorb around one–third of the increase. The dissolved gas reacts with the water to form carbonic acid, and thus acidifies the ocean. This decreasing pH is another issue for coral reefs.\n\nOcean surface pH is estimated to have decreased from about 8.25 to 8.14 since the beginning of the industrial era, and a further drop of 0.3–0.4 units is expected. This drop has made it so the amount of hydrogen ions have increased by 30%. Before the industrial age the conditions for calcium carbonate production were typically stable in surface waters since the carbonate ion is at supersaturated concentrations. However, as the ionic concentration falls, carbonate becomes under-saturated, making calcium carbonate structures vulnerable to dissolution. Corals experience reduced calcification or enhanced dissolution when exposed to elevated . This causes the skeletons of the corals to weaken, or even not be made at all.\n\nBamboo coral is a deep water coral which produces growth rings similar to trees. The growth rings illustrate growth rate changes as deep sea conditions change, including changes due to ocean acidification. Specimens as old as 4,000 years have given scientists \"4,000 years worth of information about what has been going on in the deep ocean interior\".\n\nRising carbon dioxide levels could confuse brain signaling in fish. In 2012, researchers reported on their results after studying the behaviour of baby clown and damselfishes for several years in water with elevated levels of dissolved carbon dioxide, in line with what may exist by the end of the century. They found that the higher carbon dioxide disrupted a key brain receptor in the fish, interfering with neurotransmitter functions. The damaged central nervous systems affected fish behaviour and diminishing their sensory capacity to a point \"likely to impair their chances of survival\". The fishes were less able to locate reefs by smell or \"detect the warning smell of a predator fish\". Nor could they hear the sounds made by other reef fish, compromising their ability to locate safe reefs and avoid dangerous ones. They also lost their usual tendencies to turn to the left or right, damaging their ability to school with other fish.\n\nDisease is a serious threat to many coral species. The diseases of coral may consist of bacterial, viral, fungal, or parasitic infections. Due to many of the dramatic changes in climate and stress caused by pollution, coral become more vulnerable to diseases. Some examples of coral disease are vibrio, white syndrome, white band, rapid wasting disease, and many more. These diseases have different effects on the corals, ranging from damaging individual corals, killing individual coral, or even wiping out entire reefs. In the Caribbean, white band disease is one of the primary causes for the death of over eighty percent of Staghorn and Elkhorn coral (Reef Resilience). It is a disease that can destroy miles of coral reef fast. \nA disease such as white plague can spread over a coral colony by a half an inch a day. By the time the disease has fully taken over the colony, it leaves behind a dead skeleton. Dead standing coral structures are what most people see after disease has taken over a reef.\n\nWithin the last 20 years, once-prolific seagrass meadows and mangrove forests, which absorb massive amounts of nutrients and sediment, have been destroyed. Both the loss of wetlands, mangrove habitats and seagrass meadows affect the water quality of inshore reefs.\n\nCoral mining is another threat. Both small scale harvesting by villagers and industrial scale mining by companies are serious threats. Mining is usually done to produce construction material which is valued as much as 50% cheaper than other rocks, such as from quarries. The rocks are ground and mixed with other materials, like cement to make concrete. Ancient coral used for construction is known as coral rag. Building directly on the reef also takes its toll, altering water circulation and the tides which bring the nutrients to the reef. The pressing reason for building on reefs is simply lack of space.\n\nBoats and ships require access points into bays and islands to load and unload cargo and people. For this, parts of reefs are often chopped away to clear a path. Negative consequences can include altered water circulation and altered tidal patterns which can disrupt the reef's nutrient supply; sometimes destroying a great part of the reef. Fishing vessels and other large boats occasionally run aground on a reef. Two types of damage can result. Collision damage occurs when a coral reef is crushed and split by a vessel's hull into multiple fragments. Scarring occurs when boat propellers tear off the live coral and expose the skeleton. The physical damage can be noticed as striations. Mooring causes damage which can be reduced by using mooring buoys. Buoys can attach to the seafloor using concrete blocks as weights or by penetrating the seafloor, which further reduces damage. Also, reef docks can be used to move over goods from large, seagoing vessels to small, flat-bottomed vessels. \n\nCoral in Taiwan is being threatened by the influx of human population growth. Since 2007, several local environmental groups conducted research and found that much of the coral populations are being affected by untreated sewage, an influx of tourists taking corals for souvenirs, without fully understanding the destructive impact on the coral's ecological system. Researchers reported to the Taiwanese government that many coral populations have turned black in the southeast coast of Taiwan. Potentially, this could lead to loss of food supply, medicinal sources and tourism due to the breakdown of the food chain.\n\nThe global standard for recording threatened marine species is the IUCN Red List of Threatened Species. This list is the foundation for marine conservation priorities worldwide. A species is listed in the threatened category if it is considered to be critically endangered, endangered, or vulnerable. Other categories are near threatened and data deficient. By 2008, the IUCN had assessed all 845 known reef-building corals species, marking 27% as Threatened 20% as near threatened and 17% as data deficient.\n\nThe coral triangle (Indo-Malay-Philippine archipelago) region has the highest number of reef-building coral species in threatened category as well as the highest coral species diversity. The loss of coral reef ecosystems will have devastating effects on many marine species, as well as on people that depend on reef resources for their livelihoods.\n\nThe Great Barrier Reef is the world's largest coral reef system. The reef is located in the Coral Sea and a large part of the reef is protected by the Great Barrier Reef Marine Park. Particular environmental pressures include surface runoff, salinity fluctuations, climate change, cyclic crown-of-thorns outbreaks, overfishing, and spills or improper ballast discharge. According to the 2014 report of the Government of Australia's Great Barrier Reef Marine Park Authority (GBRMPA), climate change is the most significant environmental threat to the Great Barrier Reef.\n\nSoutheast Asian coral reefs are at risk from damaging fishing practices (such as cyanide and blast fishing), overfishing, sedimentation, pollution and bleaching. Activities including education, regulation and the establishment of marine protected areas help protect these reefs.\n\nIndonesia is home to one-third of the world's coral reefs, with coral that covers nearly and is home to one-quarter of its fish species. Indonesia's coral reefs are located in the heart of the Coral Triangle and have fallen victim to destructive fishing, tourism and bleaching. Data from LIPI in 1998 found that only 7 percent is in excellent condition, 24 percent is in good condition and approximately 69 percent is in poor-to-fair condition. According to one source, Indonesia will lose 70 percent of its coral reef by 2050 if restoration action does not occur.\n\nIn 2007, Reef Check, the world's largest reef conservation organization, stated that only 5% of Philippines of coral reef are in \"excellent condition\": Tubbataha Reef, Marine Park in Palawan, Apo Island in Negros Oriental, Apo Reef in Puerto Galera, Mindoro, and Verde Island Passage off Batangas. Philippine coral reefs is Asia's second largest.\n\nCoral reefs in Taiwan are being threatened by human population growth. Many corals are affected by untreated sewage and souvenir-hunting tourists, not knowing that this practice destroys habitat and causes disease. Many corals have turned black from disease off Taiwan's southeast coast.\n\nIt has been estimated that 50% of the Caribbean sea coral cover has disappeared since the 1960s. According to a United Nations Environment Program report, the Caribbean coral reefs might face extirpation in next 20 years due to population expansion along the coast lines, overfishing, the pollution of coastal areas, global warming, and invasive species.\n\nJamaica is the third largest Caribbean island. The Caribbean's coral reefs will cease to exist in 20 years if a conservation effort is not made. In 2005, 34 percent of Jamaica's coral reefs were bleached due to rising sea temperatures. Jamaica's coral reefs are also threatened by overfishing, pollution, natural disasters, and reef mining. In 2009, researchers concluded that many of the corals are recovering very slowly.\n\n“Reef Resilience.” livingoceansfoundation.org. Khaled bin Sultan Living Oceans Foundation. 2016. Web. 16 Nov. 2016. <https://www.livingoceansfoundation.org/science/reef-resilience/>.\n\n\n"}
{"id": "31626113", "url": "https://en.wikipedia.org/wiki?curid=31626113", "title": "Esra'a Al Shafei", "text": "Esra'a Al Shafei\n\nEsra'a Al Shafei is a Bahraini civil rights activist, blogger, and the founder and executive director of Majal (Mideast Youth) and its related projects, including CrowdVoice.org. Al Shafei is a senior TED Fellow, an Echoing Green fellow, and has been referred to by \"CNN\" reporter George Webster as \"An outspoken defender of free speech\". She has been featured in \"Fast Company\" magazine as one of the \"100 Most Creative People in Business.\" In 2011, \"The Daily Beast\" listed Al Shafei as one of the 17 bravest bloggers worldwide. She is also a promoter of music as a means of social change, and founded \"Mideast Tunes\", which is currently the largest platform for underground musicians in the Middle East and North Africa.\n\nAl Shafei is a recipient of the Berkman Award for Internet Innovation from Berkman Klein Center for Internet & Society at Harvard Law School in 2008 for \"outstanding contributions to the internet and its impact on society.\" In 2012, she received a Shuttleworth Foundation Fellowship for her work on the open source platform CrowdVoice.org. She is also the recipient of the Monaco Media Prize, which acknowledges innovative uses of media for the betterment of humanity. In 2014, she was featured in \"Forbes\" magazine's \"30 Under 30\" list of social entrepreneurs making an impact in the world. The World Economic Forum listed her as one of \"15 Women Changing the World in 2015.\"\nThat same year, she won the \"Most Courageous Media\" Prize from \"Free Press Unlimited\". Al Shafei was selected as a 2017 Director’s Fellow at the MIT Media Lab. In 2018 she was listed as one of BBC's 100 Women.\n\nAl Shafei was a keynote speaker at Wikimania 2017. In December of the same year, she was appointed to the Wikimedia Foundation Board of Trustees.\n\nEsra'a Al Shafei, according to her own account, recalls witnessing inhumane treatment of migrant workers as a child. This, along with stereotypical media portrayals of middle eastern youth, prompted her to found the Mideast Youth network. Over time, the network expanded to include other civil rights issues within the Middle East, and branched out to create a diverse range of platforms with a global reach.\n\nIn 2006, she started blogging with WordPress. She uses Twitter to communicate, but deletes her Tweets if they go viral.\n\nHer music streaming site is a way for underground music to penetrate isolated markets, such as MENA. Her sites can push information out to the masses that is not found in mainstream outlets. Her blogs become a source for world information. Al Shafei has blogged for \"CNN\" and the \"Huffington Post\".\n\n\n"}
{"id": "262553", "url": "https://en.wikipedia.org/wiki?curid=262553", "title": "Factor of safety", "text": "Factor of safety\n\nIn engineering, a factor of safety (FoS), also known as (and used interchangeably with) safety factor (SF), expresses how much stronger a system is than it needs to be for an intended load. Safety factors are often calculated using detailed analysis because comprehensive testing is impractical on many projects, such as bridges and buildings, but the structure's ability to carry a load must be determined to a reasonable accuracy.\n\nMany systems are intentionally built much stronger than needed for normal usage to allow for emergency situations, unexpected loads, misuse, or degradation (reliability).\n\nThere are two definitions for the factor of safety: \n\n\nThe realized factor of safety must be greater than the required \"design factor of safety\". However, between various industries and engineering groups usage is inconsistent and confusing; it is important to be aware of which definition(s) are being used. The cause of much confusion is that various reference books and standards agencies use the factor of safety definitions and terms differently. Design codes and structural and mechanical engineering textbooks often use \"Factor of Safety\" to mean the fraction of total structural capability over that needed and are \"realized factor of safety\" (first use). Many undergraduate Strength of Materials books use \"Factor of Safety\" as a constant value intended as a minimum target for design (second use).\n\nThere are several ways to compare the factor of safety for structures. All the different calculations fundamentally measure the same thing: how much extra load beyond what is intended a structure will actually take (or be required to withstand). The difference between the methods is the way in which the values are calculated and compared. Safety factor values can be thought of as a standardized way for comparing strength and reliability between systems.\n\nThe use of a factor of safety does not imply that an item, structure, or design is \"safe\". Many quality assurance, engineering design, manufacturing, installation, and end-use factors may influence whether or not something is safe in any particular situation.\n\nThe difference\nbetween the safety factor and design factor (design safety factor) is as follows: The safety factor, or yield stress, is how much the designed part actually will be able to withstand (first \"use\" from above). The design factor, or working stress, is what the item is required to be able to withstand (second \"use\"). The design factor is defined for an application (generally provided in advance and often set by regulatory code or policy) and is not an actual calculation, the safety factor is a ratio of maximum strength to intended load for the actual item that was designed.\nBy this definition, a structure with a FOS of exactly 1 will support only the design load and no more. Any additional load will cause the structure to fail. A structure with a FOS of 2 will fail at twice the design load.\n\nMany government agencies and industries (such as aerospace) require the use of a margin of safety (MoS or M.S.) to describe the ratio of the strength of the structure to the requirements. There are two separate definitions for the margin of safety so care is needed to determine which is being used for a given application. One usage of M.S. is as a measure of capability like FoS. The other usage of M.S. is as a measure of satisfying design requirements (requirement verification). Margin of safety can be conceptualized (along with the reserve factor explained below) to represent how much of the structure's total capability is held \"in reserve\" during loading.\n\nM.S. as a measure of structural capability: This definition of margin of safety commonly seen in textbooks basically says that if the part is loaded to the maximum load it should ever see in service, how many more loads of the same force can it withstand before failing. In effect, this is a measure of excess capability. If the margin is 0, the part will not take any additional load before it fails, if it is negative the part will fail before reaching its design load in service. If the margin is 1, it can withstand one additional load of equal force to the maximum load it was designed to support (i.e. twice the design load).\nM.S. as a measure of requirement verification: Many agencies and organizations such as NASA and AIAA define the margin of safety including the design factor, in other words, the margin of safety is calculated after applying the design factor. In the case of a margin of 0, the part is at exactly the required strength (the safety factor would equal the design factor). If there is a part with a required design factor of 3 and a margin of 1, the part would have a safety factor of 6 (capable of supporting two loads equal to its design factor of 3, supporting six times the design load before failure). A margin of 0 would mean the part would pass with a safety factor of 3. If the margin is less than 0 in this definition, although the part will not necessarily fail, the design requirement has not been met. A convenience of this usage is that for all applications, a margin of 0 or higher is passing, one does not need to know application details or compare against requirements, just glancing at the margin calculation tells whether the design passes or not. This is helpful for oversight and reviewing on projects with various integrated components, as different components may have various design factors involved and the margin calculation helps prevent confusion.\n\nDesign Safety Factor = [Provided as requirement]\n\nFor a successful design, the Realized Safety Factor must always equal or exceed the Design Safety Factor so the Margin of Safety is greater than or equal to zero. The Margin of Safety is sometimes, but infrequently, used as a percentage, i.e., a 0.50 M.S is equivalent to a 50% M.S. When a design satisfies this test it is said to have a \"positive margin,\" and, conversely, a “negative margin” when it does not.\n\nIn the field of Nuclear Safety (as implemented at U.S. government owned facilities) the Margin of Safety has been defined as a quantity that may not be reduced without review by the controlling government office. The U.S. Department of Energy publishes DOE G 424.1-1, \"Implementation Guide for Use in Addressing Unreviewed Safety Question Requirements\" as a guide for determining how to identify and determine whether a margin of safety will be reduced by a proposed change. The guide develops and applies the concept of a qualitative margin of safety that may not be explicit or quantifiable, yet can be evaluated conceptually to determine whether an increase or decrease will occur with a proposed change. This approach becomes important when examining designs with large or undefined (historical) margins and those that depend on 'soft' controls such as programmatic limits or requirements. The commercial U.S. nuclear industry utilized a similar concept in evaluating planned changes until 2001, when 10 CFR 50.59 was revised to capture and apply the information available in facility-specific risk analyses and other quantitative risk management tools.\n\nA measure of strength frequently used in Europe is the Reserve Factor (RF). With the strength and applied loads expressed in the same units, the Reserve Factor is defined as:\nRF = Proof Strength / Proof Load\n\nRF = Ultimate Strength / Ultimate Load\nThe applied loads have any factors, including factors of safety applied.\n\nFor ductile materials (e.g. most metals), it is often required that the factor of safety be checked against both yield and ultimate strengths. The yield calculation will determine the safety factor until the part starts to plastically deform. The ultimate calculation will determine the safety factor until failure. On brittle materials these values are often so close as to be indistinguishable, so is it usually acceptable to only calculate the ultimate safety factor.\n\nAppropriate design factors are based on several considerations, such as the accuracy of predictions on the imposed loads, strength, wear estimates, and the environmental effects to which the product will be exposed in service; the consequences of engineering failure; and the cost of over-engineering the component to achieve that factor of safety. For example, components whose failure could result in substantial financial loss, serious injury, or death may use a safety factor of four or higher (often ten). Non-critical components generally might have a design factor of two. Risk analysis, failure mode and effects analysis, and other tools are commonly used. Design factors for specific applications are often mandated by law, policy, or industry standards.\n\nBuildings commonly use a factor of safety of 2.0 for each structural member. The value for buildings is relatively low because the loads are well understood and most structures are redundant. Pressure vessels use 3.5 to 4.0, automobiles use 3.0, and aircraft and spacecraft use 1.2 to 3.0 depending on the application and materials. Ductile, metallic materials tend to use the lower value while brittle materials use the higher values. The field of aerospace engineering uses generally lower design factors because the costs associated with structural weight are high (i.e. an aircraft with an overall safety factor of 5 would probably be too heavy to get off the ground). This low design factor is why aerospace parts and materials are subject to very stringent quality control and strict preventative maintenance schedules to help ensure reliability. A usually applied Safety Factor is 1.5, but for pressurized fuselage it is 2.0, and for main landing gear structures it is often 1.25.\n\nIn some cases it is impractical or impossible for a part to meet the \"standard\" design factor. The penalties (mass or otherwise) for meeting the requirement would prevent the system from being viable (such as in the case of aircraft or spacecraft). In these cases, it is sometimes determined to allow a component to meet a lower than normal safety factor, often referred to as \"waiving\" the requirement. Doing this often brings with it extra detailed analysis or quality control verifications to assure the part will perform as desired, as it will be loaded closer to its limits.\n\nFor loading that is cyclical, repetitive, or fluctuating, it is important to consider the possibility of metal fatigue when choosing factor of safety. A cyclic load well below a material's yield strength can cause failure if it is repeated through enough cycles.\n\n\n"}
{"id": "35862718", "url": "https://en.wikipedia.org/wiki?curid=35862718", "title": "Fotoform", "text": "Fotoform\n\nFotoform was a group founded in 1949 by the photographer Otto Steinert. Until 1958 it was the preeminent group of avant-garde West German photographers. Other collaborators were Peter Keetman, Ludwig Windstoßer, Toni Schneiders, Wolfgang Reisewitz, Siegfried Lauterwasser, Heinz Hajek-Halke and Christer Christian (the pseudonym of the Swedish photographer Christer Strömholm).\n\nIt made photographic experiments and sought to draw attention to the creative possibilities of photography which had been extingished by Nazi cultural policy.\n"}
{"id": "2135548", "url": "https://en.wikipedia.org/wiki?curid=2135548", "title": "Generosity", "text": "Generosity\n\nGenerosity (also called largess) is the virtue of being unattached to material possessions, often symbolized by the giving of gifts. Generosity is regarded as a virtue by various world religions, and is often celebrated in cultural and religious ceremonies. Scientific investigation into generosity has examined the effect of a number of scenarios and games on individuals' generosity, and potential links with neurochemicals such as oxytocin, and relationship with similar feelings, such as that of empathy.\n\nGenerosity is sometimes used to denote charity, (the virtue of giving without expecting anything in return). It can involve offering time, assets or talents to aid someone in need. In times of natural disaster, relief efforts are frequently provided, voluntarily, by individuals or groups acting unilaterally in making gifts of time, resources, goods, money, etc. Generosity is a guiding principle for many registered charities, foundations, and non-profit organizations.\n\nAlthough the term generosity often goes hand-in-hand with charity, many people in the public's eye want recognition for their good deeds. Donations are needed to support organizations and committees, however, generosity should not be limited to times of great need such as natural disasters and extreme situations.\nThe modern English word \"generosity\" derives from the Latin word \"generōsus\", which means \"of noble birth\", which itself was passed down to English through the Old French word \"généreux\". The Latin stem \"gener–\" is the declensional stem of \"genus\", meaning \"kin\", \"clan\", \"race\", or \"stock\", with the root Indo-European meaning of \"gen\" being \"to beget\". The same root gives the words \"genesis\", \"gentry\", \"gender\", \"genital\", \"gentile\", \"genealogy\", and \"genius\", among others.\nMost recorded English uses of the word \"generous\" up to and during the sixteenth century reflect an aristocratic sense of being of noble lineage or high birth. To be generous was literally a way of complying with nobility.\n\nDuring the 17th century, however, the meaning and use of the word began to change. \"Generosity\" came increasingly to identify not literal family heritage but a nobility of spirit thought to be associated with high birth—that is, with various admirable qualities that could now vary from person to person, depending not on family history but on whether a person actually possessed the qualities. In this way \"generosity\" increasingly came in the 17th century to signify a variety of traits of character and action historically associated (whether accurately or not) with the ideals of actual nobility: gallantry, courage, strength, richness, gentleness, and fairness. In addition to describing these diverse human qualities, \"generous\" became a word during this period used to describe fertile land, the strength of animal breeds, abundant provisions of food, vibrancy of colors, the strength of liquor, and the potency of medicine.\n\nThen, during the 18th century, the meaning of \"generosity\" continued to evolve in directions denoting the more specific, contemporary meaning of munificence, open–handedness, and liberality in the giving of money and possessions to others. This more specific meaning came to dominate English usage by the 19th century. Over the last five centuries in the English speaking world, \"generosity\" developed from being primarily the description of an ascribed status pertaining to the elite nobility to being an achieved mark of admirable personal quality and action capable of being exercised in theory by any person who had learned virtue and noble character (Smith 2009).\n\nIn Buddhism, generosity is one of the Ten Perfections and is the antidote to the self-chosen poison called \"greed\". Generosity is known as charity in the Bible, and daan in the Eastern religious scriptures.\n\nIn Islam Quran states that whatever one gives away generously, with the intention of pleasing God, He will replace it. God knows what is in the hearts of men. Say: “Truly, my Lord enlarges the provision for whom He wills of His slaves, and also restricts it) for him, and whatsoever you spend of anything (in God’s Cause), He will replace it. And He is the Best of providers.” (Quran 34:39)\n\nIn Christianity, the Book of Acts states that Jesus said that giving is better than receiving (Acts 20:35). \n\n\nअपूर्व: कोपि कोशोयं विद्यते तव भारति |व्ययतो वॄद्धिम् आयाति क्षयम् आयाति संचयात् ||\n\nResearch has shown that generosity is associated with empathy. In this research, by Paul J. Zak and colleagues and published in Public Library of Science ONE, the peptide oxytocin or placebo was given to about 100 men and then they made several decisions regarding money. One, the Dictator Game, was used to measure altruism by asking people to make a unilateral transfer of $10 they were given by the experimenters to a stranger in the lab; oxytocin had no effect on altruism.\n\nAnother task, the Ultimatum Game, was used to measure generosity. In this game, one person was endowed with $10 and was asked to offer some split of it to another person in the lab, all done by computer. If the second person did not like the split, he could reject it (for example, if it was stingy) and both people would get zero. In a clever twist, the researchers told participants they would be randomly chosen to be \"either\" the person making the offer or the person responding to it. This required the person making the offer to take the other's perspective explicitly. Generosity was defined as an offer greater than the minimum amount needed for acceptance. Oxytocin increased generosity 80% compared to those on placebo. In addition, oxytocin was quantitatively twice as important in predicting generosity as was altruism.\n\nThe science of generosity initiative at the University of Notre Dame is investigating the sources, origins, and causes of generosity; manifestations and expressions of generosity; and consequences of generosity for both the givers and receivers involved. Generosity for the purposes of this project is defined as the virtue of giving good things to others freely and abundantly.\n\n"}
{"id": "56062096", "url": "https://en.wikipedia.org/wiki?curid=56062096", "title": "Globular set", "text": "Globular set\n\nIn category theory, a branch of mathematics, a globular set is a higher-dimensional generalization of a directed graph. Precisely, it is a sequence of sets formula_1 equipped with pairs of functions formula_2 such that\n(Equivalently, it is a presheaf on the category of “globes”.) The letters \"\"s\", \"t\"\" stand for \"source\" and \"target\" and one imagines formula_5 consists of directed edges at level \"n\".\n\nA variant of the notion was used by Grothendieck to introduce the notion of an ∞-groupoid. Extending Grothendieck's work, gave a definition of a weak ∞-category in terms of globular sets.\n\n\n"}
{"id": "28370193", "url": "https://en.wikipedia.org/wiki?curid=28370193", "title": "Greek minuscule", "text": "Greek minuscule\n\nThe minuscule script was a Greek writing style which was developed as a book hand in Byzantine manuscripts during the 9th and 10th centuries. It replaced the earlier style of uncial writing, from which it differed in using smaller, more rounded and more connected letter forms, and in using a large number of ligatures. Many of these forms had previously developed as parts of more informal cursive writing. The basic letter shapes used in the minuscule script are the ancestors of modern lower case Greek letters.\n\nFrom the 10th century onwards, most Byzantine manuscripts of classical and early Christian Greek works were gradually rewritten in the new minuscule style, and few of the older uncial manuscripts were preserved. For this reason, uncial manuscripts are today extremely rare, while early minuscule manuscripts are often the oldest preserved sources attesting an ancient work and may therefore be of central importance for its philological study. Manuscripts from the oldest phase of minuscule writing (mid-9th to mid-10th century) are known in scholarship today as \"codices vetustissimi\" (\"oldest codices\"). Those from the mid-10th to the mid-12th centuries are known as \"codices vetusti\" (\"old codices\"), and later ones as \"codices recentiores\" (\"newer codices\").\n\nMinuscule writing remained in use for handwriting throughout the Byzantine and into the post-Byzantine era. In the modern era, western printers used minuscule book hands as a model for developing early Greek print fonts. Like with Latin, it became common to mix minuscule writing with some uncial or capital letters, with the latter used for emphasis, in titles and initials. From this practice, the modern orthographic system of letter case for Greek arose. In modern Greek writing, the upper case letters are generally modeled on the letter shapes of ancient inscriptions, while the lower case letters are based on the tradition of minuscule handwriting.\n\n\n"}
{"id": "13149599", "url": "https://en.wikipedia.org/wiki?curid=13149599", "title": "Habit", "text": "Habit\n\nA habit (or wont) is a routine of behavior that is repeated regularly and tends to occur subconsciously.\n\nThe \"American Journal of Psychology\" (1903) defines a \"habit, from the standpoint of psychology, [as] a more or less fixed way of thinking, willing, or feeling acquired through previous repetition of a mental experience.\" Habitual behavior often goes unnoticed in persons exhibiting it, because a person does not need to engage in self-analysis when undertaking routine tasks. Habits are sometimes compulsory. New behaviours can become automatic through the process of habit formation. Old habits are hard to break and new habits are hard to form because the behavioural patterns which humans repeat become imprinted in neural pathways, but it is possible to form new habits through repetition.\n\nWhen behaviors are repeated in a consistent context, there is an incremental increase in the link between the context and the action. This increases the automaticity of the behavior in that context. Features of an automatic behavior are all or some of:\n\n\nHabit formation is the process by which a behavior, through regular repetition, becomes automatic or habitual. This is modelled as an increase in automaticity with number of repetitions up to an asymptote. This process of habit formation can be slow. Lally \"et al.\" (2010) found the average time for participants to reach the asymptote of automaticity was 66 days with a range of 18–254 days.\n\nAs the habit is forming, it can be analysed in three parts: the cue, the behavior, and the reward. The cue is the thing that causes the habit to come about, the trigger of the habitual behavior. This could be anything that one's mind associates with that habit and one will automatically let a habit come to the surface. The behavior is the actual habit that one exhibits, and the reward, a positive feeling, therefore continues the \"habit loop\". A habit may initially be triggered by a goal, but over time that goal becomes less necessary and the habit becomes more automatic.\n\nA variety of digital tools, online or mobile apps, have been introduced that are designed to support habit formation. For example, Habitica is a system that uses gamification, implementing strategies found in video games to real life tasks by adding rewards such as experience and gold. A review of such tools, however, suggests most are poorly designed with respect to theory and fail to support the development of automaticity.\n\nShopping habits are particularly vulnerable to change at \"major life moments\" like graduation, marriage, birth of first child, moving to a new home, and divorce. Some stores use purchase data to try to detect these events and take advantage of the marketing opportunity.\n\nSome habits are known as \"keystone habits\", and these influence the formation of other habits. For example, identifying as the type of person who takes care of their body and is in the habit of exercising regularly, can also influence eating better and using credit cards less. In business, safety can be a keystone habit that influences other habits that result in greater productivity.\n\nA recent study by Adriaanse et al. (2014) found that habits mediate the relationship between self-control and unhealthy snack consumption. The results of the study empirically demonstrate that high-self control may influence the formation of habits and in turn affect behavior. \n\nThe habit–goal interface or interaction is constrained by the particular manner in which habits are learned and represented in memory. Specifically, the associative learning underlying habits is characterized by the slow, incremental accrual of information over time in procedural memory. Habits can either benefit or hurt the goals a person sets for themselves.\n\nGoals guide habits by providing the initial outcome-oriented motivation for response repetition. In this sense, habits are often a trace of past goal pursuit. Although, when a habit forces one action, but a conscious goal pushes for another action, an oppositional context occurs. When the habit prevails over the conscious goal, a capture error has taken place.\n\nBehavior prediction is also derived from goals. Behavior prediction is to acknowledge the likelihood that a habit will form, but in order to form that habit, a goal must have been initially present. The influence of goals on habits is what makes a habit different from other automatic processes in the mind.\n\nThe following is a description of a classic goal devaluation experiment (from a Scientific American MIND guest blog post called Should Habits or Goals Direct Your Life? It Depends) which demonstrates the difference between goal-directed and habitual behavior: A series of elegant experiments conducted by Anthony Dickinson and colleagues in the early 1980s at the University of Cambridge in England clearly exposes the behavioral differences between goal-directed and habitual processes. Basically, in the training phase, a rat was trained to press a lever in order to receive some food. Then, in a second phase, the rat was placed in a different cage without a lever and was given the food, but it was made ill whenever it ate the food. This caused the rat to \"devalue\" the food, because it associated the food with being ill, without directly associating the action of pressing the lever with being ill. Finally, in the test phase, the rat was placed in the original cage with the lever. (To prevent additional learning, no food was delivered in the test phase.) Rats that had undergone an extensive training phase continued to press the lever in the test phase even though the food was devalued; their behavior was called habitual. Rats that had undergone a moderate training phase did not, and their behavior was called goal-directed. … [G]oal-directed behavior is explained by the rat using an explicit prediction of the consequence, or outcome, of an action to select that action. If the rat wants the food, it presses the lever, because it predicts that pressing the lever will deliver the food. If the food has been devalued, the rat will not press the lever. Habitual behavior is explained by a strong association between an action and the situation from which the action was executed. The rat presses the lever when it sees the lever, not because of the predicted outcome.\n\nThere are a number of habits possessed by individuals that can be classified as nervous habits. These include nail-biting, stammering, sniffling, and banging the head. They are known as symptoms of an emotional state and are generally based upon conditions of anxiety, insecurity, inferiority and tension. These habits are often formed at a young age and may be because of a need for attention. When trying to overcome a nervous habit it is important to resolve the cause of the nervous feeling rather than the symptom which is a habit itself or as a result one could experience anxiety. Anxiety is a disorder known for excessive and unexpected worry that negatively impacts an individuals daily life, and routines.\n\nA bad habit is an undesirable behavior pattern. Common examples include: procrastination, fidgeting, overspending, and nail-biting. The sooner one recognizes these bad habits, the easier it is to fix them. Rather than merely attempting to eliminate a bad habit, it may be more productive to seek to replace it with a healthier coping mechanism. \n\nA key factor in distinguishing a bad habit from an addiction or mental disease is willpower. If a person can easily control over the behavior, then it is a habit. Good intentions can override the negative effect of bad habits, but their effect seems to be independent and additive—the bad habits remain, but are subdued rather than cancelled.\n\nMany techniques exist for removing established bad habits, e.g., \"withdrawal of reinforcers\"—identifying and removing factors that trigger and reinforce the habit. The basal ganglia appears to remember the context that triggers a habit, so habits can be revived if triggers reappear. Recognizing and eliminating bad habits as soon as possible is advised. Habit elimination becomes more difficult with age because repetitions reinforce habits cumulatively over the lifespan. According to Charles Duhigg, there is a loop that includes a cue, routine and reward for every habit. An example of a habit loop is TV program ends (cue), go to the fridge (routine), eat a snack (reward). The key to changing habits is to identify your cue and modify your routine and reward.\n\n\n\n\n\n\n"}
{"id": "28477064", "url": "https://en.wikipedia.org/wiki?curid=28477064", "title": "Haraç", "text": "Haraç\n\nHaraç (, , , ) was a land tax levied on non-Muslims in the Ottoman Empire.\n\n\"Haraç\" was developed from an earlier form of land taxation, \"kharaj\" (\"harac\"), and was, in principle, only payable by non-Muslims; it was seen as a counterpart to zakat paid by Muslims. The \"haraç\" system later merged into the cizye taxation system.\n\nHaraç collection was reformed by a firman of 1834, which abolished the old levying system, and required that \"haraç\" be raised by a commission composed of the kadı and the \"ayans\", or municipal chiefs of \"rayas\" in each district. The firman made several other changes to taxation.\n\n"}
{"id": "1311139", "url": "https://en.wikipedia.org/wiki?curid=1311139", "title": "Harry Frankfurt", "text": "Harry Frankfurt\n\nHarry Gordon Frankfurt (born May 29, 1929) is an American philosopher. He is professor emeritus of philosophy at Princeton University, where he taught from 1990 until 2002, and previously taught at Yale University, Rockefeller University, and Ohio State University.\n\nFrankfurt was born on May 29, 1929, in Pennsylvania. He obtained his B.A. in 1949 and Ph.D. in 1954 from Johns Hopkins University.\n\nHe is professor emeritus of philosophy at Princeton University and has previously taught at Yale University, Rockefeller University, and Ohio State University.\n\nHis major areas of interest include moral philosophy, philosophy of mind and action, and 17th-century rationalism. His 1986 paper \"On Bullshit\", a philosophical investigation of the concept of \"bullshit\", was republished as a book in 2005 and became a surprise bestseller, leading to media appearances such as Jon Stewart's \"The Daily Show\". In 2006 he released a companion book, \"On Truth\", which explores society's loss of appreciation for truth.\n\nAmong philosophers, he was for a time best known for his interpretation of Descartes's rationalism. His most influential work, however, has been on freedom of the will (on which he has written numerous important papers) based on his concept of higher-order volitions and for developing what are known as \"Frankfurt cases\" or \"Frankfurt counterexamples\" (i.e., thought experiments designed to show the possibility of situations in which a person could not have done other than he/she did, but in which our intuition is to say nonetheless that this feature of the situation does not prevent that person from being morally responsible). Frankfurt is probably the leading living Humean compatibilist, developing Hume's view that to be free is to do what one wants to do. (Others who develop this view are David Velleman, Gary Watson and John Martin Fischer.) Frankfurt's version of compatibilism is the subject of a substantial literature by other philosophy professors. More recently, he has written on love and caring.\n\nHe is a Fellow of the American Academy of Arts and Sciences. He has been a Visiting Fellow of All Souls College, Oxford University; he served as President, Eastern Division, American Philosophical Association; and he has received fellowships and grants from the Guggenheim Foundation, the National Endowment for the Humanities, and the Andrew Mellon Foundation.\n\n\n\n\n\n"}
{"id": "40581191", "url": "https://en.wikipedia.org/wiki?curid=40581191", "title": "Infinity mirror", "text": "Infinity mirror\n\nAn infinity mirror is a pair of parallel mirrors, which create a series of smaller and smaller reflections that appear to recede to infinity. They are used as room accents and in artwork.\n\nIn a classic self-contained infinity mirror, a set of light bulbs, LEDs, or other point-source lights are placed around the periphery of a fully reflective mirror, and a second, partially reflective \"one-way mirror\" is placed a short distance in front of it, in a parallel alignment. When an outside observer looks into the surface of the partially reflective mirror, the lights appear to recede into infinity, creating the appearance of a tunnel of lights of great depth.\n\nAlternatively, this effect can also be seen when an observer stands \"between\" two parallel fully reflective mirrors, as in some dressing rooms, some elevators, or a house of mirrors. A weaker version of this effect can be seen by standing between any two parallel reflective surfaces, such as the glass walls of a small entry lobby into some buildings. The partially reflective glass produces this sensation, diluted by the visual noise of the views through the glass into the surrounding environment.\n\nThe 3D illusion mirror effect is produced whenever there are two parallel reflective surfaces which can bounce a beam of light back and forth an indefinite (theoretically infinite) number of times. The reflections appear to recede into the distance because the light actually is traversing the distance it appears to be traveling. \n\nFor example, in a two-centimeter-thick infinity mirror, with the light sources halfway between, light from the source initially travels one centimeter. The first reflection travels one centimeter to the rear mirror and then two centimeters to, and through the front mirror, a total of three centimeters. The second reflection travels two centimeters from front mirror to back mirror, and again two centimeters from the back mirror to, and through the front mirror, totaling four centimeters, plus the first reflection (three centimeters) making the second reflection seven centimeters away from the front mirror. Each successive reflection adds four more centimeters to the total (the third reflection appears 11 centimeters deep, fourth 15 centimeters deep, and so on).\n\nEach additional reflection adds length to the path the light must travel before exiting the mirror. If the mirrors are not precisely parallel, but instead are canted at a slight angle, the \"visual tunnel\" will be perceived to be curved (off to one side) as it recedes into infinity.\n\nWhen studied using the principles of geometrical optics, the series of repeating images forms the infinite mathematical surface known as Gabriel's Horn, or Torricelli's Trumpet, named in honor of Italian mathematician Evangelista Torricelli, who first studied it. In theory, such a surface is infinite in area, but encloses a finite volume.\n\nVisual artists, especially contemporary sculptors, have made use of infinity mirrors. Yayoi Kusama, Josiah McElheny, Ivan Navarro, and Taylor Davis have all produced works that use the infinity mirror to expand the sensation of unlimited space in their artworks.\n\nSome amusement park dark rides, such as Disney's \"Space Mountain\" roller coaster attraction, use infinity mirrors to create the impression of flying through space.\n\n"}
{"id": "1410429", "url": "https://en.wikipedia.org/wiki?curid=1410429", "title": "International POPs Elimination Network", "text": "International POPs Elimination Network\n\nThe International POPs Elimination Network (IPEN) is a global network of NGOs dedicated to the common aim of eliminating persistent organic pollutants.\n\nIPEN is composed of public interest non-governmental organizations who support a common platform for the global elimination of POPs. The Participating Organizations (POs) of IPEN are those NGOs which have endorsed the POPs Elimination Platform and/or the Stockholm Declaration. Because the network is primarily engaged in facilitating information exchange and in supporting activities of its constituents, and because the purpose of the network does not include developing network-wide-policy statements, strategies, or action plans, a formal decision-making process for the network can be simple, flexible, and largely administrative in nature. (IPEN 2005)\n\nThe International POPs Elimination Network (IPEN) is a global network of more than 600 public interest non-governmental organizations working together for the elimination of persistent organic pollutants, on an expedited yet socially equitable basis. This mission includes achieving a world in which all chemicals are produced and used in ways that eliminate significant adverse effects on human health and the environment, and where persistent organic pollutants (POPs) and chemicals of equivalent concern no longer pollute our local and global environments, and no longer contaminate our communities, our food, our bodies, or the bodies of our children and future generations.\n\n\n"}
{"id": "418697", "url": "https://en.wikipedia.org/wiki?curid=418697", "title": "Intrinsic parity", "text": "Intrinsic parity\n\nIn quantum mechanics, the intrinsic parity is a phase factor that arises as an eigenvalue of the parity operation formula_1 (a reflection about the origin). To see that the parity's eigenvalues are phase factors, we assume an eigenstate of the parity operation (this is realized because the intrinsic parity is a property of a particle species) and use the fact that two parity transformations leave the particle in the same state, thus the new wave function can differ by only a phase factor, i.e.: formula_2 thus formula_3, since these are the only eigenstates satisfying the above equation. \n\nThe intrinsic parity's phase is conserved for non-weak interactions (the product of the intrinsic parities is the same before and after the reaction). As formula_4 the Hamiltonian is invariant under a parity transformation. The intrinsic parity of a system is the product of the intrinsic parities of the particles, for instance for noninteracting particles we have formula_5. Since the parity commutes with the Hamiltonian and formula_6 its eigenvalue does not change with time, therefore the intrinsic parities phase is a conserved quantity.\n\nA consequence of the Dirac equation is that the intrinsic parity of fermions and antifermions obey the relation formula_7, so particles and their antiparticles have the opposite parity. Single leptons can never be created or destroyed in experiments, as lepton number is a conserved quantity. This means experiments are unable to distinguish the sign of a leptons parity, so by convention it is chosen that leptons have intrinsic parity +1, antileptons have formula_8. Similarly the parity of the quarks is chosen to be +1, and antiquarks is -1.\n"}
{"id": "2326687", "url": "https://en.wikipedia.org/wiki?curid=2326687", "title": "Legal observer", "text": "Legal observer\n\nLegal observers are individuals, usually representatives of civilian human rights agencies, who attend public demonstrations, protests and other activities where there is a potential for conflict between the public or activists and the police, security guards, or other law enforcement personnel. The purpose of legal observers is to monitor, record, and report on any unlawful or improper behaviour. Legal or human rights observers act as an independent third party within a conflictual civil protest context, observing police behaviour in order to keep police accountable for their actions. Legal observers can write incident reports describing police violence and misbehaviour and compile reports after the event. The use of video and still cameras, incident reports and audio recorders is common.\n\nIt is thought that the concept of using legal observers first emerged during protests in the 1930s in the East End of London, where police agents provocateur were used during protests by the British Union of Fascists (BUF). There were large counter-protests and it was alleged that the police sided with the BUF. Another case of legal observing was that carried out by the Black Panthers in the United States.\n\nLegal observers were used by Liberty (then known as the National Council for Civil Liberties) in Wapping, London, during the mid-1980s. The Wapping demonstration was in response to large protests by labour unions against the industrial relations policies of media magnate Rupert Murdoch.\n\nIn the United States, the National Lawyers Guild (NLG) holds registered trademarks for the words \"legal observer\" alone, as well as the words \"legal observer\" on a green background. The National Lawyers Guild Legal Observer certification program was established in 1968 in New York City in response to protests at Columbia University and citywide antiwar and civil rights demonstrations. That same year, guild students organized for the defense of people swept up in mass arrests at the Democratic National Convention in Chicago. The NLG Legal Observer certification program requires legal observers to take a training course and is part of a comprehensive system of legal support designed to enable people to express their political views as fully as possible without unconstitutional disruption or interference by the police and with the fewest possible consequences from the criminal justice system. Legal observers are trained and directed by National Lawyer Guild attorneys. The presence of legal observers may serve as a deterrent to unconstitutional behavior by law enforcement during a demonstration. \n\nNLG worked with the Bureau des Avocats Internationaux, the Institute for Justice & Democracy in Haiti, and the International Association of Democratic Lawyers to debut legal observers in Haiti during May Day protests of 2018.\n\nIn other countries, legal observers are associated with such groups as Liberty (UK), Green and Black Cross (UK), the G8 Legal Collective (Scotland), and others. In Australia in the 1970s, priests acted as legal observers during the large Moratorium Marches against the Vietnam War. In September 2000, Pt'chang Nonviolent Community Safety Group organised a large legal observer team for the S11 protest against the World Economic Forum in Melbourne. In Sydney, the Legal Observers Project, formally based at the Community Law Centre at the University of Technology, Sydney, and renamed Human Rights Monitors, was established in April 2001. This group reformed as Sydney Copwatch in 2009. Human rights organizations such as Amnesty International sometimes dispatch human rights observers who serve similar roles to legal observers.\n\n"}
{"id": "58903975", "url": "https://en.wikipedia.org/wiki?curid=58903975", "title": "List of most-played mobile games by player count", "text": "List of most-played mobile games by player count\n\nThis is a list of the most-played mobile games ordered by their player count, including by registered accounts and monthly active users. For console/PC/arcade games, see the list of most-played video games by player count.\n"}
{"id": "18456", "url": "https://en.wikipedia.org/wiki?curid=18456", "title": "Literacy", "text": "Literacy\n\nLiteracy is traditionally defined as the ability to read and write. In the modern world, this is one way of interpreting literacy. A more broad interpretation is literacy as knowledge and competence in a specific area. The concept of literacy has evolved in meaning. The modern term's meaning has been expanded to include the ability to use language, numbers, images, computers, and other basic means to understand, communicate, gain useful knowledge, solve mathematical problems and use the dominant symbol systems of a culture. The concept of literacy is expanding across OECD countries to include skills to access knowledge through technology and ability to assess complex contexts. A person who travels and resides in a foreign country but is unable to read or write in the language of the host country would also be regarded by the locals as illiterate.\n\nThe key to literacy is reading development, a progression of skills that begins with the ability to understand spoken words and decode written words, and culminates in the deep understanding of text. Reading development involves a range of complex language underpinnings including awareness of speech sounds (phonology), spelling patterns (orthography), word meaning (semantics), grammar (syntax) and patterns of word formation (morphology), all of which provide a necessary platform for reading fluency and comprehension.\n\nOnce these skills are acquired, the reader can attain full language literacy, which includes the abilities to apply to printed material critical analysis, inference and synthesis; to write with accuracy and coherence; and to use information and insights from text as the basis for informed decisions and creative thought. The inability to do so is called illiteracy or analphabetism.\n\nThe United Nations Educational, Scientific and Cultural Organization (UNESCO) defines literacy as the \"ability to identify, understand, interpret, create, communicate and compute, using printed and written materials associated with varying contexts. Literacy involves a continuum of learning in enabling individuals to achieve their goals, to develop their knowledge and potential, and to participate fully in their community and wider society\".\n\nLiteracy is emerged with the development of numeracy and computational devices as early as 8,000 BCE. Script developed independently at least five times in human history Mesopotamia, Egypt, the Indus civilization, lowland Mesoamerica, and China. \nThe earliest forms of written communication originated in Serbia (Vinča culture), followed by Sumer, located in southern Mesopotamia about 3500-3000 BCE. During this era, literacy was \"a largely functional matter, propelled by the need to manage the new quantities of information and the new type of governance created by trade and large scale production\". Writing systems in Mesopotamia first emerged from a recording system in which people used impressed token markings to manage trade and agricultural production. The token system served as a precursor to early cuneiform writing once people began recording information on clay tablets. Proto-cuneiform texts exhibit not only numerical signs, but also ideograms depicting objects being counted.\n\nEgyptian hieroglyphs emerged from 3300-3100 BCE and depicted royal iconography that emphasized power amongst other elites. The Egyptian hieroglyphic writing system was the first notation system to have phonetic values.\n\nWriting in lowland Mesoamerica was first put into practice by the Olmec and Zapotec civilizations in 900-400 BCE. These civilizations used glyphic writing and bar-and-dot numerical notation systems for purposes related to royal iconography and calendar systems.\n\nThe earliest written notations in China date back to the Shang Dynasty in 1200 BCE. These systematic notations were found inscribed on bones and recorded sacrifices made, tributes received, and animals hunted, which were activities of the elite. These oracle-bone inscriptions were the early ancestors of modern Chinese script and contained logosyllabic script and numerals.\n\nIndus script is largely pictorial and has not been deciphered yet. It may or may not include abstract signs. It is thought that they wrote from right to left and that the script is thought to be logographic. Because it has not been deciphered, linguists disagree on whether it is a complete and independent writing system; however, it is genuinely thought to be an independent writing system that emerged in the Harappa culture.\n\nThese examples indicate that early acts of literacy were closely tied to power and chiefly used for management practices, and probably less than 1% of the population was literate, as it was confined to a very small ruling elite.\n\nAccording to social anthropologist Jack Goody, there are two interpretations that regard the origin of the alphabet. Many classical scholars, such as historian Ignace Gelb, credit the Ancient Greeks for creating the first alphabetic system (c. 750 BCE) that used distinctive signs for consonants and vowels. But Goody contests, \"The importance of Greek culture of the subsequent history of Western Europe has led to an over-emphasis, by classicists and others, on the addition of specific vowel signs to the set of consonantal ones that had been developed earlier in Western Asia\".\n\nThus, many scholars argue that the ancient Semitic-speaking peoples of northern Canaan (modern-day Syria) invented the consonantal alphabet as early as 1500 BCE. Much of this theory's development is credited to English archeologist Flinders Petrie, who, in 1905, came across a series of Canaanite inscriptions located in the turquoise mines of Serabit el-Khadem. Ten years later, English Egyptologist Alan Gardiner reasoned that these letters contain an alphabet, as well as references to the Canaanite goddess Asherah. In 1948, William F. Albright deciphered the text using additional evidence that had been discovered subsequent to Goody's findings. This included a series of inscriptions from Ugarit, discovered in 1929 by French archaeologist Claude F. A. Schaeffer. Some of these inscriptions were mythological texts (written in an early Canaanite dialect) that consisted of a 32-letter cuneiform consonantal alphabet.\n\nAnother significant discovery was made in 1953 when three arrowheads were uncovered, each containing identical Canaanite inscriptions from twelfth century BCE. According to Frank Moore Cross, these inscriptions consisted of alphabetic signs that originated during the transitional development from pictographic script to a linear alphabet. Moreover, he asserts, \"These inscriptions also provided clues to extend the decipherment of earlier and later alphabetic texts\".\n\nThe consonantal system of the Canaanite script inspired alphabetical developments in subsequent systems. During the Late Bronze Age, successor alphabets appeared throughout the Mediterranean region and were employed for Phoenician, Hebrew and Aramaic.\n\nAccording to Goody, these cuneiform scripts may have influenced the development of the Greek alphabet several centuries later. Historically, the Greeks contended that their writing system was modeled after the Phoenicians. However, many Semitic scholars now believe that Ancient Greek is more consistent with an early form Canaanite that was used c. 1100 BCE. While the earliest Greek inscriptions are dated c. eighth century BCE, epigraphical comparisons to Proto-Canaanite suggest that the Greeks may have adopted the consonantal alphabet as early as 1100 BCE, and later \"added in five characters to represent vowels\".\n\nPhoenician, which is considered to contain the first \"linear alphabet\", rapidly spread to the Mediterranean port cities in northern Canaan. Some archeologists believe that Phoenician scripture had some influence on the developments of the Hebrew and Aramaic alphabets based on the fact that these languages evolved during the same time period, share similar features, and are commonly categorized into the same language group.\n\nWhen the Israelites migrated to Canaan between 1200 and 1001 BCE, they also adopted a variation of the Canaanite alphabet. Baruch ben Neriah, Jeremiah's scribe, used this alphabet to create the later scripts of the Old Testament. The Early Hebrew alphabet was prominent in the Mediterranean region until Chaldean Babylonian rulers exiled the Jews to Babylon in the sixth century BCE. It was then that the new script (\"Square Hebrew\") emerged and the older one rapidly died out.\n\nThe Aramaic alphabet also emerged sometime between 1200 and 1001 BCE. As the Bronze Age collapsed, the Aramaeans moved into Canaan and Phoenician territories and adopted their scripts. Although early evidence of this writing is scarce, archeologists have uncovered a wide range of later Aramaic texts, written as early as the seventh century BCE. Due to its longevity and prevalence in the region, Achaemenid rulers would come to adopt it as a \"diplomatic language\". The modern Aramaic alphabet rapidly spread east to the Kingdom of Nabataea, then to Sinai and the Arabian Peninsula, eventually making its way to Africa. Aramaic merchants carried older variations of the language as far as India, where it later influenced the development of Brahmi scripture. It also led to the developments of Arabic, Pahlavi (an Iranian adaptation), \"as well as for a range of alphabets used by early Turkish and Mongol tribes in Siberia, Mongolia and Turkestan\". Literacy at this period spread with the merchant classes and may have grown to number 15-20% of the total population.\n\nThe Aramaic language would die out with the spread of Islam and with it, its influence of Arabic.\n\nUntil recently it was thought that the majority of people were illiterate in ancient times. However, recent work challenges this perception. Anthony DiRenzo asserts that Roman society was \"a civilization based on the book and the register\", and \"no one, either free or slave, could afford to be illiterate\". Similarly Dupont points out, \"The written word was all around them, in both public and private life: laws, calendars, regulations at shrines, and funeral epitaphs were engraved in stone or bronze. The Republic amassed huge archives of reports on every aspect of public life\". The imperial civilian administration produced masses of documentation used in judicial, fiscal and administrative matters as did the municipalities. The army kept extensive records relating to supply and duty rosters and submitted reports. Merchants, shippers, and landowners (and their personal staffs) especially of the larger enterprises must have been literate. \n\nIn the late fourth century the Desert Father Pachomius would expect literacy of a candidate for admission to his monasteries:\nthey shall give him twenty Psalms or two of the Apostles' epistles or some other part of Scripture. And if he is illiterate he shall go at the first, third and sixth hours to someone who can teach and has been appointed for him. He shall stand before him and learn very studiously and with all gratitude. The fundamentals of a syllable, the verbs and nouns shall all be written for him and even if he does not want to he shall be compelled to read.\n\nIn the course of the 4th and 5th century the Churches made efforts to ensure a better clergy in particular among the bishops who were expected to have a classical education, which was the hallmark of an socially acceptable person in higher society (and possession of which allayed the fears of the pagan elite that their cultural inheritance would be destroyed). Even after the remnants of the Western Roman Empire fell in the 470s literacy continued to be a distinguishing mark of the elite as communications skills were still important in political and Church life (bishops were largely drawn from the senatorial class) in a new cultural synthesis that made \"Christianity the Roman religion,\" . However, these skills were less in needed than previously in the absence of the large imperial administrative apparatus whose middle and top echelons the elite had dominated as if by right. Even so, in pre-modern times it is unlikely that literacy was found in more than about 30-40% of the population. The highest percentage of literacy during the Dark Ages was among the clergy and monks who supplied much of the staff needed to administer the states of western Europe. \n\nPost-Antiquity illiteracy was made much worse due to a lack of suitable writing medium. When the Western Roman Empire collapsed, the import of papyrus to Europe ceased. Since papyrus perishes easily and does not last well in the wetter or damper European climate, the alternative was parchment which was expensive and accessible only by the Church and upper layers of the society. Once paper was introduced into Europe in the 11th century in Spain. Its use spread north slowly over the next four centuries. Increased literacy saw a resurgence because of its use. By the 15th century paper had largely replaced parchment except for many luxury manuscripts (some of which used paper). \n\nThe Reformation stressed the importance of literacy and being able to read the Bible. The Protestant countries were the first to attain full literacy; Scandinavian countries were fully literate in the early 17th century. The Church demanded literacy as the pre-requisite for marriage in Sweden, this further propagating full literacy.\n\nLiteracy data published by UNESCO displays that since 1950, the adult literacy rate at the world level has increased by 5 percentage points every decade on average, from 55.7 per cent in 1950 to 86.2 per cent in 2015. However, for four decades, the population growth was so rapid that the number of illiterate adults kept increasing, rising from 700 million in 1950 to 878 million in 1990. Since then, the number has fallen markedly to 745 million in 2015, although it remains higher than in 1950 despite decades of universal education policies, literacy interventions and the spread of print material and information and communications technology (ICT). However, these trends have been far from uniform across regions.\n\nAvailable global data indicates significant variations in literacy rates between world regions. North America, Europe, West Asia, and Central Asia have achieved almost full adult literacy (individuals at or over the age of 15) for both men and women. Most countries in East Asia and the Pacific, as well as Latin America and the Caribbean, are above a 90% literacy rate for adults. Illiteracy persists to a greater extent in other regions: 2013 UNESCO Institute for Statistics (UIS) data indicates adult literacy rates of only, 67.55% in South Asia and North Africa, 59.76% in Sub-Saharan Africa.\n\nIn much of the world, high youth literacy rates suggest that illiteracy will become less and less common as younger generations with higher educational attainment levels replace older ones. However, in sub-Saharan Africa and South Asia, where the vast majority of the world's illiterate youth live, lower school enrollment implies that illiteracy will persist to a greater degree. According to 2013 UIS data, the youth literacy rate (individuals ages 15 to 24) is 84.03% in South Asia and North Africa, and 70.06% in Sub-Saharan Africa.\n\nThat being said, literacy has rapidly spread in several regions in the last twenty-five years (see image).\n\nOn a worldwide scale, illiteracy disproportionately impacts women. According to 2015 UIS data collected by the UNESCO Institute for Statistics, about two-thirds (63%) of the world's illiterate adults are women. This disparity was even starker in previous decades: from 1970 to 2000, the global gender gap in literacy would decrease by roughly 50%. In recent years, however, this progress has stagnated, with the remaining gender gap holding almost constant over the last two decades. In general, the gender gap in literacy is not as pronounced as the regional gap; that is, differences between countries in overall literacy are often larger than gender differences within countries. However, the gap between men and women would narrow from 1990 onwards, after the increase of male adult literacy rates at 80 per cent (see image).\n\nSub-Saharan Africa, the region with the lowest overall literacy rates, also features the widest gender gap: just 52% of adult females are literate, and 68% among adult men. Similar gender disparity persists in two other regions, North Africa (86% adult male literacy, 70% adult female literacy) and South Asia (77% adult male literacy, 58% adult female literacy).\n\nThe 1990 World Conference on Education for All, held in Jomtien, Thailand, would bring attention to the literacy gender gap and prompt many developing countries to prioritize women's literacy. In the past decade, global development agendas would increasingly address the issue of female literacy. For example, UN Secretary-General Ban Ki-moon would center his 2010 International Literacy Day speech around the theme \"Empowering Women Through Literacy Empowers Us All,\" emphasizing the broad societal progress that higher female literacy rates could promote.\n\nIn many contexts, female illiteracy co-exists with other aspects of gender inequality. Martha Nussbaum, for example, make illiterate women more vulnerable to becoming trapped in an abusive marriage, given that illiteracy limits their employment opportunities and worsens their intra-household bargaining position. Moreover, Nussbaum links literacy to the potential for women to effectively communicate and collaborate with one another in order \"to participate in a larger movement for political change.\"\n\nSocial barriers prevent expanding literacy skills among women and girls. Making literacy classes available can be ineffective when it conflicts with the use of the valuable limited time of women and girls. School age girls, in many contexts, face stronger expectations than their male counterparts to perform household work and care after younger siblings. Generational dynamics can also perpetuate these disparities: illiterate parents may not readily appreciate the value of literacy for their daughters, particularly in traditional, rural societies with expectations that girls will remain at home.\n\nA 2015 World Bank and the International Center for Research on Women review of academic literature would conclude that child marriage, which predominantly impacts girls, tends to reduce literacy levels. A 2008 analysis of the issue in Bangladesh found that for every additional year of delay in a girl's marriage, her likelihood of literacy would increase by 5.6 percent. Similarly, a 2014 study found that in sub-Saharan Africa, marrying early would significantly decrease a girl's probability of literacy, holding other variables constant. A 2015 review of the child marriage literature therefore would recommend marriage postponement as part of a strategy to increase educational attainment levels, including female literacy in particular.\n\nWhile women and girls comprise the majority of the global illiterate population, in many developed countries a literacy gender gap exists in the opposite direction. Data from the Programme for International Student Assessment (PISA) has consistently indicated the literacy underachievement of boys within member countries of the Organisation for Economic Co-operation and Development (OECD). In view of such findings, many education specialists have recommended changes in classroom practices to better accommodate boys' learning styles, and to remove any gender stereotypes that may create a perception of reading and writing as feminine activities.\n\nMany policy analysts consider literacy rates as a crucial measure of the value of a region's human capital. For example, literate people can be more easily trained than illiterate people, and generally have a higher socioeconomic status; thus they enjoy better health and employment prospects. The international community has come to consider literacy as a key facilitator and goal of development. In regard to the Sustainable Development Goals adopted by the UN in 2015, the UNESCO Institute for Lifelong Learning has declared the \"central role of literacy in responding to sustainable development challenges such as health, social equality, economic empowerment and environmental sustainability.\"\n\nIlliterate people are generally less knowledgeable about hygiene and nutritional practices, an unawareness which can exacerbate a wide range of health issues. Within developing countries in particular, literacy rates also have implications for child mortality; in these contexts, children of literate mothers are 50% more likely to live past age 5 than children of illiterate mothers. Public health research has thus increasingly concerned itself with the potential for literacy skills to allow women to more successfully access health care systems, and thereby facilitate gains in child health.\n\nFor example, a 2014 descriptive research survey project correlates literacy levels with the socioeconomic status of women in Oyo State, Nigeria. The study claims that developing literacy in this area will bring \"economic empowerment and will encourage rural women to practice hygiene, which will in turn lead to the reduction of birth and death rates.\"\n\nLiteracy can increase job opportunities and access to higher education. In 2009, the National Adult Literacy agency (NALA) in Ireland commissioned a cost benefit analysis of adult literacy training. This concluded that there were economic gains for the individuals, the companies they worked for, and the Exchequer, as well as the economy and the country as a whole—for example, increased GDP. Korotayev and coauthors have revealed a rather significant correlation between the level of literacy in the early 19th century and successful modernization and economic breakthroughs in the late 20th century, as \"literate people could be characterized by a greater innovative-activity level, which provides opportunities for modernization, development, and economic growth\".\n\nWhile informal learning within the home can play an important role in literacy development, gains in childhood literacy often occur in primary school settings. Continuing the global expansion of public education is thus a frequent focus of literacy advocates. These kinds of broad improvements in education often require centralized efforts undertaken by national governments; alternatively, local literacy projects implemented by NGOs can play an important role, particularly in rural contexts.\n\nFunding for both youth and adult literacy programs often comes from large international development organizations. USAID, for example, steered donors like the Bill and Melinda Gates Foundation and the Global Partnership for Education toward the issue of childhood literacy by developing the Early Grade Reading Assessment. Advocacy groups like the National Institute of Adult Continuing Education have frequently called upon international organizations such as UNESCO, the International Labour Organization, the World Health Organization, and the World Bank to prioritize support for adult women's literacy. Efforts to increase adult literacy often encompass other development priorities as well; for example, initiatives in Ethiopia, Morocco, and India have combined adult literacy programs with vocational skills trainings in order to encourage enrollment and address the complex needs of women and other marginalized groups who lack economic opportunity.\n\nIn 2013, the UNESCO Institute for Lifelong Learning published a set of case studies on programs that successfully improved female literacy rates. The report features countries from a variety of regions and of differing income levels, reflecting the general global consensus on \"the need to empower women through the acquisition of literacy skills.\" Part of the impetus for UNESCO's focus on literacy is a broader effort to respond to globalization and \"the shift towards knowledge-based societies\" that it has produced. While globalization presents emerging challenges, it also provides new opportunities: many education and development specialists are hopeful that new information and communications technologies (ICTs) will have the potential to expand literacy learning opportunities for children and adults, even those in countries that have historically struggled to improve literacy rates through more conventional means.\n\nThe Human Development Index, produced by the United Nations Development Programme (UNDP), uses education as one of its three indicators; originally, adult literacy represented two-thirds of this education index weight. In 2010, however, the UNDP replaced the adult literacy measure with mean years of schooling. A 2011 UNDP research paper framed this change as a way to \"ensure current relevance,\" arguing that gains in global literacy already achieved between 1970 and 2010 meant that literacy would be \"unlikely to be as informative of the future.\" Other scholars, however, have since warned against overlooking the importance of literacy as an indicator and a goal for development, particularly for marginalized groups such as women and rural populations.\n\nUnlike medieval times, when reading and writing skills were restricted to a few elites and the clergy, these literacy skills are now expected from every member of a society. Literacy is a human right essential for lifelong learning and social change. As supported by the 1996 Report of the International Commission on Education for the Twenty-First Century, and the 1997 Hamburg Declaration: ‘Literacy, broadly conceived as the basic knowledge and skills needed by all in a rapidly changing world, is a fundamental human right. (...) There are millions, the majority of whom are women, who lack opportunities to learn or who have insufficient skills to be able to assert this right. The challenge is to enable them to do so. This will often imply the creation of preconditions for learning through awareness raising and empowerment. Literacy is also a catalyst for participation in social, cultural, political and economic activities, and for learning throughout life’.\n\nThe public library has long been a force promoting literacy in many countries. In the U.S. context, the American Library Association promotes literacy through the work of the Office for Literacy and Outreach Services. This committee's charge includes ensuring equitable access to information and advocating for adult new and non-readers. The Public Library Association recognizes the importance of early childhood in the role of literacy development and created, in collaboration with the Association for Library Service to Children, Every Child Ready to Read @your library in order to inform and support parents and caregivers in their efforts to raise children who become literate adults. The release of the National Assessment of Adult Literacy (NAAL) report in 2005 revealed that approximately 14% of U.S. adults function at the lowest level of literacy; 29% of adults function at the basic functional literacy level and cannot help their children with homework beyond the first few grades. The lack of reading skills hinders adults from reaching their full potential. They might have difficulty getting and maintaining a job, providing for their families, or even reading a story to their children. For adults, the library might be the only source of a literacy program.\n\nDia! Which stand for Diversity in Action and is also known as \"El Dia de los Ninos/El dia de los libros (Children's Day/Book Day)\" is a program which celebrates the importance of reading to children from all cultural and linguistic backgrounds. Dia! is celebrated every year on 30 April in schools, libraries, and homes and this website provides tools and programs to encourage reading in children. Parents, caregivers, and educators can even start a book club.\n\nThis community literacy program was initiated in 1992 by the Orange County Public Library in California. The mission of READ/Orange County is to \"create a more literate community by providing diversified services of the highest quality to all who seek them.\" Potential tutors train during an extensive 23-hour tutor training workshop in which they learn the philosophy, techniques and tools they will need to work with adult learns. After the training, the tutors invest at least 50 hours a year to tutoring their student.The organization builds on people's experience as well as education rather than trying to make up for what has not been learned. The program seeks to equip students with skills to continue learning in the future. The guiding philosophy is that an adult who learns to read creates a ripple effect in the community. The person becomes an example to children and grandchildren and can better serve the community.\n\nLocated in Boulder, Colorado, the program recognized the difficulty that students had in obtaining child care while attending tutoring sessions, and joined with the University of Colorado to provide reading buddies to the children of students. Reading Buddies matches children of adult literacy students with college students who meet with them once a week throughout the semester for an hour and a half. The college students receive course credit to try to enhance the quality and reliability of their time. Each Reading Buddies session focuses primarily on the college student reading aloud with the child. The goal is to help the child gain interest in books and feel comfortable reading aloud. Time is also spent on word games, writing letters, or searching for books in the library. Throughout the semester the pair work on writing and illustrating a book together. The college student's grade is partly dependent on the completion of the book. Although Reading Buddies began primarily as an answer to the lack of child care for literacy students, it has evolved into another aspect of the program. Participating children show marked improvement in their reading and writing skills throughout the semester.\n\nApproximately 120,000 adults in Hillsborough County are illiterate or read below the fourth-grade level. Working since 1986, the HLC is \"committed to improving literacy by empowering adults through education\". Sponsored by the statewide Florida Literacy Coalition, HLC strives to improve the literacy ability of adults in Hillsborough County, Florida. The HLC provides tutoring for English for speakers of other languages (ESOL). Through one-on-one tutoring, the organization works to help adult students reach at least the fifth-grade level.\n\nTraditionally, literacy is the ability to use written language actively and passively; one definition of literacy is the ability to \"read, write, spell, listen, and speak\". Since the 1980s, some have argued that literacy is ideological, which means that literacy always exists in a context, in tandem with the values associated with that context. Prior work viewed literacy as existing autonomously.\n\nSome have argued that the definition of literacy should be expanded. For example, in the United States, the National Council of Teachers of English and the International Reading Association have added \"visually representing\" to the traditional list of competencies. Similarly, in Scotland, literacy has been defined as: \"The ability to read, write and use numeracy, to handle information, to express ideas and opinions, to make decisions and solve problems, as family members, workers, citizens and lifelong learners\". It is argued that literacy includes the cultural, political, and historical contexts of the community in which communication takes place.\n\nA basic literacy standard in many places is the ability to read the newspaper. Increasingly, communication in commerce and in general requires the ability to use computers and other digital technologies. Since the 1990s, when the Internet came into wide use in the United States, some have asserted that the definition of literacy should include the ability to use tools such as web browsers, word processing programs, and text messages. Similar expanded skill sets have been called multimedia literacy, computer literacy, information literacy, and technological literacy. Some scholars propose the idea multiliteracies which includes Functional Literacy, Critical Literacy, and Rhetorical Literacy.\n\n\"Arts literacy\" programs exist in some places in the United States. Visual literacy also includes the ability to understand visual forms of communication such as body language, pictures, maps, and video. Evolving definitions of literacy often include all the symbol systems relevant to a particular community.\n\nOther genres under study by academia include critical literacy, media literacy, ecological literacy and health literacy With the increasing emphasis on evidence-based decision making, and the use of statistical graphics and information, statistical literacy is becoming a very important aspect of literacy in general. The International Statistical Literacy Project is dedicated to the promotion of statistical literacy among all members of society.\n\nGiven that a large part of the benefits of literacy can be obtained by having access to a literate person in the household, some recent literature in economics, starting with the work of Kaushik Basu and James Foster, distinguishes between a \"proximate illiterate\" and an \"isolated illiterate\". The former refers to an illiterate person who lives in a household with literates and the latter to an illiterate who lives in a household of all illiterates. What is of concern is that many people in poor nations are not just illiterates but isolated illiterates.\n\nTeaching English literacy in the United States is dominated by a focus on a set of discrete decoding skills. From this perspective, literacy—or, rather, reading—comprises a number of subskills that can be taught to students. These skill sets include phonological awareness, phonics (decoding), fluency, comprehension, and vocabulary. Mastering each of these subskills is necessary for students to become proficient readers.\n\nFrom this same perspective, readers of alphabetic languages must understand the alphabetic principle to master basic reading skills. For this purpose a writing system is \"alphabetic\" if it uses symbols to represent individual language sounds, though the degree of correspondence between letters and sounds varies between alphabetic languages. Syllabic writing systems (such as Japanese kana) use a symbol to represent a single syllable, and logographic writing systems (such as Chinese) use a symbol to represent a morpheme.\n\nThere are any number of approaches to teaching literacy; each is shaped by its informing assumptions about what literacy is and how it is best learned by students. Phonics instruction, for example, focuses on reading at the level of the word. It teaches readers to observe and interpret the letters or groups of letters that make up words. A common method of teaching phonics is synthetic phonics, in which a novice reader pronounces each individual sound and \"blends\" them to pronounce the whole word. Another approach is embedded phonics instruction, used more often in whole language reading instruction, in which novice readers learn about the individual letters in words on a just-in-time, just-in-place basis that is tailored to meet each student's reading and writing learning needs. That is, teachers provide phonics instruction opportunistically, within the context of stories or student writing that feature many instances of a particular letter or group of letters. Embedded instruction combines letter-sound knowledge with the use of meaningful context to read new and difficult words. Techniques such as directed listening and thinking activities can be used to aid children in learning how to read and reading comprehension.\n\nIn a 2012 proposal, it has been claimed that reading can be acquired naturally if print is constantly available at an early age in the same manner as spoken language. If an appropriate form of written text is made available before formal schooling begins, reading should be learned inductively, emerge naturally, and with no significant negative consequences. This proposal challenges the commonly held belief that written language requires formal instruction and schooling. Its success would change current views of literacy and schooling. Using developments in behavioral science and technology, an interactive system (Technology Assisted Reading Acquisition, TARA) would enable young pre-literate children to accurately perceive and learn properties of written language by simple exposure to the written form.\n\nIn Australia a number of State governments have introduced Reading Challenges to improve literacy. The Premier's Reading Challenge in South Australia, launched by Premier Mike Rann has one of the highest participation rates in the world for reading challenges. It has been embraced by more than 95% of public, private and religious schools.\n\nPrograms have been implemented in regions that have an ongoing conflict or in a post-conflict stage. The Norwegian Refugee Council Pack program has been used in 13 post-conflict countries since 2003. The program organizers believe that daily routines and other wise predictable activities help the transition from war to peace. Learners can select one area in vocational training for a year-long period. They complete required courses in agriculture, life skills, literacy and numeracy. Results have shown that active participation and management of the members of the program are important to the success of the program. These programs share the use of integrated basic education, e.g. literacy, numeracy, scientific knowledge, local history and culture, native and mainstream language skills, and apprenticeships.\n\nAlthough there is considerable awareness that language deficiencies (lacking proficiency) are disadvantageous to immigrants settling in a new country, there appears to be a lack of pedagogical approaches that address the instruction of literacy to migrant English language learners (ELLs). Harvard scholar Catherine Snow (2001) called for a gap to be addresses: \"The TESOL field needs a concerted research effort to inform literacy instruction for such children ... to determine when to start literacy instruction and how to adapt it to the LS reader's needs\". The scenario becomes more complex when there is no choice in such decisions as in the case of the current migration trends with citizens from the Middle East and Africa being relocated to English majority nations due to various political or social reasons. Recent developments to address the gap in teaching literacy to second or foreign language learners has been ongoing and promising results have been shown by Pearson and Pellerine (2010) which integrates Teaching for Understanding, a curricular framework from the Harvard Graduate School of Education. A series of pilot projects had been carried out in the Middle East and Africa (see Patil, 2016). In this work significant interest from the learners perspective have been noticed through the integration of visual arts as springboards for literacy oriented instruction. In one case migrant women had been provided with cameras and a walking tour of their local village was provided to the instructor as the women photographed their tour focusing on places and activities that would later be used for writings about their daily life. In essence a narrative of life. Other primers for writing activities include: painting, sketching, and other craft projects (e.g. gluing activities).\n\nA series of pilot studies were carried out to investigate alternatives to instructing literacy to migrant ELLs, starting from simple trials aiming to test the teaching of photography to participants with no prior photography background, to isolating painting and sketching activities that could later be integrated into a larger pedagogical initiative. In efforts to develop alternative approaches for literacy instruction utilising visual arts, work was carried out with Afghan labourers, Bangladeshi tailors, Emirati media students, internal Ethiopian migrants (both labourers and university students), and a street child.\nIt should be pointed out that in such challenging contexts sometimes the teaching of literacy may have unforeseen barriers. The \"EL Gazette\" reported that in the trials carried out in Ethiopia, for example, it was found that all ten of the participants had problems with vision. In order to overcome this, or to avoid such challenges, preliminary health checks can help inform pre-teaching in order to better assist in the teaching/learning of literacy.\n\nIn a visual arts approach to literacy instruction a benefit can be the inclusion of both a traditional literacy approach (reading and writing) while at the same time addressing 21st Century digital literacy instruction through the inclusion of digital cameras and posting images onto the web. Many scholars feel that the inclusion of digital literacy is necessary to include under the traditional umbrella of literacy instruction specifically when engaging second language learners. (Also see: Digital literacy.) \n\nOther ways in which visual arts have been integrated into literacy instruction for migrant populations include integrating aspects of visual art with the blending of core curricular goals.\n\nA more pressing challenge in education is the instruction of literacy to Migrant English Language Learners (MELLs), a term coined by Pellerine. It is not just limited to English. “Due to the growing share of immigrants in many Western societies, there has been increasing concern for the degree to which immigrants acquire language that is spoken in the destination country” (Tubergen 2006). Remembering that teaching literacy to a native in their L1 can be challenging, and the challenge becomes more cognitively demanding when in a second language (L2), the task can become considerably more difficult when confronted with a migrant who has made a sudden change (migrated) and requires the second language upon arrival in the country of destination. In many instances a migrant will not have the opportunity, for many obvious reasons, to start school again at grade one and acquire the language naturally. In these situations alternative interventions need to take place.\n\nIn working with illiterate people (and individuals with low-proficiency in an L2) following the composition of some artifact like in taking a photo, sketching an event, or painting an image, a stage of orality has been seen as an effective way to understand the intention of the learner.\n\nIn the accompanying image from left to right a) an image taken during a phototour of the participant's village. This image is of the individual at her shop, and this is one of her products that she sells, dung for cooking fuel. The image helps the interlocutor understand the realities of the participants daily life and most importantly it allows the participant the opportunity to select what they feel is important to them. b) This is an image of a student explaining and elaborating the series of milestones in her life to a group. In this image the student had a very basic ability and with some help was able to write brief captions under the images. While she speaks a recording of her story takes place to understand her story and to help develop it in the L2. The third image is of a painting that had been used with a composite in Photoshop. With further training participants can learn how to blend images they would like to therefore introducing elements of digital literacies, beneficial in many spheres of life in the 21st century.\n\nIn the following image (see right) you can see two samples 1) One in Ethiopia from stencil to more developed composition based on a village tour, photography, and paintings. 2) In the Middle East at a tailor's shop focusing English for Specific Purposes (ESP) and in this example the writing has evolved from photography, sketching, and in situ exposure for the instructor (much like the village tour in sample one).\n\nFrom the work based in Ethiopia, participants were asked to rate preference of activity, on a scale of 1-10. The survey prompt was: On a scale of 1 - 10 how would you rate photography as an activity that helped you get inspiration for your writing activities (think of enjoyment and usefulness). The following activities were rated, in order of preference - activities used as primers for writing:\n\n\nMore research would need to be conducted to confirm such trends.\n\nIn bringing work together from students in culminating projects, authorship programs have been successful in bringing student work together in book format. Such artifacts can be used to both document learning, but more importantly reinforce language and content goals.\n\nThe culmination of such writings, into books can evoke both intrinsic and extrinsic motivation. Form feedback by students involved in such initiatives the responses have indicated that the healthy pressures of collective and collaborative work was beneficial.\n\nTeaching people to read and write, in a traditional sense of the meaning (literacy) is a very complex task in a native language. To do this in a second language becomes increasingly more complex, and in the case of migrants relocating to another country there can be legal and policy driven boundaries that prohibit the naturalization and acquisition of citizen ship based on language proficiency. In Canada for example despite a debate, language tests are required years after settling into Canada. Similar exists globally, see:, and for example.\n\nThe \"EL Gazette\" reviewed Pellerine's work with migrant English language learners and commented: \"Handing English language learners a sponge and some paint and asking them to ‘paint what comes’ might not appear like a promising teaching method for a foreign language. But Canadian EL instructor and photographer Steve Pellerine has found that the technique, along with others based around the visual arts, has helped some of his most challenging groups to learn\". Visual arts have been viewed as an effective way to approach literacy instruction - the art being primers for subsequent literacy tasks within a scaffolded curricular design, such at Teaching for Understanding (TfU) or Understanding by Design (UbD).\n\nNearly one in ten young adult women has poor reading and writing skills in the UK in the 21st century. This seriously damages their employent prospects and many are trapped in poverty. Lack of reading skill is a social stigma and women tend to hide their difficulty rather than seeking help. Girls on average do better than boys at English in school. A quarter of British adults would struggle to read a bus timetable. \n\nLiteracy is first documented in the area of modern England on 24 September 54 BCE, on which day Julius Caesar and Quintus Cicero wrote to Cicero \"from the nearest shores of Britain\". Literacy was widespread under Roman rule, but became very rare, limited almost entirely to churchmen, after the fall of the Western Roman Empire. In 12th and 13th century England, the ability to recite a particular passage from the Bible in Latin entitled a common law defendant to the so-called benefit of clergy—i.e., trial before an ecclesiastical court, where sentences were more lenient, instead of a secular one, where hanging was a likely sentence. Thus literate lay defendants often claimed the right to benefit of clergy, while an illiterate person who had memorized the psalm used as the literacy test, Psalm 51 (\"O God, have mercy upon me...\"), could also claim benefit of clergy. Despite lacking a system of free and compulsory primary schooling, England managed to reach near universal literacy in the nineteenth century as a result of shared, informal learning systems such as family members, fellow workers, and/or benevolent employers, to name a few. Even with near universal literacy rates, the gap between male and female literacy rates continued to persist until the early twentieth century. Many female readers in the West during the nineteenth century were able to read, but unable to write.\n\nFormal higher education in the arts and sciences in Wales, from the Dark Ages to the 18th century, was the preserve of the wealthy and the clergy. As in England, Welsh history and archaeological finds dating back to the Bronze Age reveal not only reading and writing, but also alchemy, botany, advanced maths and science. Following the Roman occupation and the conquest by the English, education in Wales was at a very low ebb in the early modern period; in particular, formal education was only available in English while the majority of the population spoke only Welsh. The first modern grammar schools were established in Welsh towns such as Ruthin, Brecon, and Cowbridge. One of the first modern national education methods to use the native Welsh language was started by Griffith Jones in 1731. Jones was the rector of Llanddowror from 1716 and remained there for the rest of his life. He organized and introduced a Welsh medium circulating school system, which was attractive and effective for Welsh speakers, while also teaching them English, which gave them access to broader educational sources. The circulating schools may have taught half the country's population to read. Literacy rates in Wales by the mid-18th century were one of the highest.\nThe ability to read did not necessarily imply the ability to write. The 1686 church law (\"kyrkolagen\") of the Kingdom of Sweden (which at the time included all of modern Sweden, Finland, Latvia and Estonia) enforced literacy on the people, and by 1800 the ability to read was close to 100%. This was directly dependent on the need to read religious texts in the Lutheran faith in Sweden and Finland. As a result, literacy in these countries was inclined towards reading, specifically. But as late as the 19th century, many Swedes, especially women, could not write. The exception to this rule were the men and women of Iceland who achieved widespread literacy without formal schooling, libraries, or printed books via informal tuition by religious leaders and peasant teachers. That said, the situation in England was far worse than in Scandinavia, France, and Prussia: as late as 1841, 33% of all Englishmen and 44% of Englishwomen signed marriage certificates with their mark as they were unable to write (government-financed public education was not available in England until 1870 and, even then, on a limited basis).\n\nHistorian Ernest Gellner argues that Continental European countries were far more successful in implementing educational reform precisely because their governments were more willing to invest in the population as a whole. Government oversight allowed countries to standardize curriculum and secure funding through legislation thus enabling educational programs to have a broader reach.\n\nAlthough the present-day concepts of literacy have much to do with the 15th-century invention of the movable type printing press, it was not until the Industrial Revolution of the mid-19th century that paper and books became affordable to all classes of industrialized society. Until then, only a small percentage of the population were literate as only wealthy individuals and institutions could afford the materials. Even , the cost of paper and books is a barrier to universal literacy in some less-industrialized nations.\n\nOn the other hand, historian Harvey Graff argues that the introduction of mass schooling was in part an effort to control the type of literacy that the working class had access to. According to Graff, literacy learning was increasing outside of formal settings (such as schools) and this uncontrolled, potentially critical reading could lead to increased radicalization of the populace. In his view, mass schooling was meant to temper and control literacy, not spread it. Graff also points out, using the example of Sweden, that mass literacy can be achieved without formal schooling or instruction in writing.\n\nResearch on the literacy rates of Canadians in the colonial days rested largely on examinations of the proportion of signatures to marks on parish acts (birth, baptismal, and marriage registrations). Although some researchers have concluded that signature counts drawn from marriage registers in nineteenth century France corresponded closely with literacy tests given to military conscripts, others regard this methodology as a \"relatively unimaginative treatment of the complex practices and events that might be described as literacy\" (Curtis, 2007, p. 1-2). But censuses (dating back to 1666) and official records of New France offer few clues of their own on the population's levels of literacy, therefore leaving few options in terms of materials from which to draw literary rate estimates.\n\nIn his research of literacy rates of males and females in New France, Trudel found that in 1663, of 1,224 persons in New France who were of marriageable age, 59% of grooms and 46% of brides wrote their name; however, of the 3,000-plus colony inhabitants, less than 40% were native born. Signature rates were therefore likely more reflective of rates of literacy among French immigrants. Magnuson's (1985) research revealed a trend: signature rates for the period of 1680–1699 were 42% for males, 30% for females; in 1657-1715, they were 45% for males and 43% for females; in 1745-1754, they were higher for females than for males. He believed that this upward trend in rates of females’ ability to sign documents was largely attributed to the larger number of female religious orders, and to the proportionately more active role of women in health and education, while the roles of male religious orders were largely to serve as parish priests, missionaries, military chaplains and explorers. 1752 marked the date that Canada's first newspaper—the \"Halifax Gazette\"—began publication.\n\nThe end of the Seven Years' War in 1763 allowed two Philadelphia printers to come to Québec City and to begin printing a bilingual \"Quebec Gazette\" in 1764, while in 1785 Fleury Mesplet started publication of the \"Montreal Gazette\", which is now the oldest continuing newspaper in the country.\n\nIn the 19th century, everything about print changed, and literature in its many forms became much more available. But educating the Canadian population in reading and writing was nevertheless a huge challenge. Concerned about the strong French Canadian presence in the colony, the British authorities repeatedly tried to help establish schools that were outside the control of religious authorities, but these efforts were largely undermined by the Catholic Church and later the Anglican clergy.\n\nFrom the early 1820s in Lower Canada, classical college curriculum, which was monopolized by the Church, was also subject to growing liberal and lay criticism, arguing it was fit first and foremost to produce priests, when Lower Canadians needed to be able to compete effectively with foreign industry and commerce and with the immigrants who were monopolizing trade (Curtis, 1985). Liberal and lay attempts to promote parish schools generated a reaction from the Catholic and later the Anglican clergy in which the dangers of popular literacy figured centrally. Both churches shared an opposition to any educational plan that encouraged lay reading of the Bible, and spokesmen for both warned of the evil and demoralizing tendencies of unregulated reading in general. Granted the power to organize parish schooling through the Vestry School Act of 1824, the Catholic clergy did nothing effective.\n\nDespite this, the invention of the printing press had laid the foundation for the modern era and universal social literacy, and so it is that with time, \"technologically, literacy had passed from the hands of an elite to the populace at large. Historical factors and sociopolitical conditions, however, have determined the extent to which universal social literacy has come to pass\".\n\nIn 1871 only about half of French Canadian men in Canada self-reported that they were literate, whereas 90 percent of other Canadian men said they could read and write, but information from the Canadian Families Project sample of the 1901 Census of Canada indicated that literacy rates for French Canadians and other Canadians increased, as measured by the ability of men between the ages of 16 and 65 to answer literacy questions. Compulsory attendance in schools was legislated in the late 19th century in all provinces but Quebec, but by then, a change in parental attitudes towards educating the new generation meant that many children were already attending regularly. Unlike the emphasis of school promoters on character formation, the shaping of values, the inculcation of political and social attitudes, and proper behaviour, many parents supported schooling because they wanted their children to learn to read, write, and do arithmetic. Efforts were made to exert power and religious, moral, economic/professional, and social/cultural influence over children who were learning to read by dictating the contents of their school readers accordingly. But educators broke from these spheres of influence and also taught literature from a more child-centred perspective: for the pleasure of it.\n\nEducational change in Québec began as a result of a major commission of inquiry at the start of what came to be called the \"Quiet Revolution\" in the early 1960s. In response to the resulting recommendations, the Québec government revamped the school system in an attempt to enhance the francophone population's general educational level and to produce a better-qualified labour force. Catholic Church leadership was rejected in favour of government administration and vastly increased budgets were given to school boards across the province.\n\nWith time, and with continuing inquiry into the literacy achievement levels of Canadians, the definition of literacy moved from a dichotomous one (either a person could, or couldn’t write his or her name, or was literate or illiterate), to ones that considered its multidimensionality, along with the qualitative and quantitative aspects of literacy. In the 1970s, organizations like the Canadian Association for Adult Education (CAAE) believed that one had to complete the 8th grade to achieve functional literacy. Examination of 1976 census data, for example, found that 4,376,655, or 28.4% of Canadians 15 years of age and over reported a level of schooling of less than grade 9 and were thus deemed not functionally literate. But in 1991, UNESCO formally acknowledged Canada's findings that assessment of educational attainment as proxy measure of literacy was not as reliable as was direct assessment. This dissatisfaction manifested itself in the development of actual proficiency tests that measure reading literacy more directly.\n\nCanada conducted its first literacy survey in 1987 which discovered that there were more than five million functionally illiterate adults in Canada, or 24 per cent of the adult population. Statistics Canada then conducted three national and international literacy surveys of the adult population — the first one in 1989 commissioned by the Human Resources and Skills Development Canada (HRSDC) department.\n\nThis first survey was called the \"Literacy Skills Used in Daily Activities\" (LSUDA) survey, and was modeled on the 1985 U.S. survey of young adults (YALS). It represented a first attempt in Canada to produce skill measures deemed comparable across languages. Literacy, for the first time, was measured on a continuum of skills. The survey found that 16% of Canadians had literacy skills too limited to deal with most of the printed material encountered in daily life whereas 22% were considered \"narrow\" readers.\n\nIn 1994-95, Canada participated in the first multi-country, multi-language assessment of adult literacy, the International Adult Literacy Survey (IALS). A stratified multi-stage probability sample design was used to select the sample from the Census Frame. The sample was designed to yield separate samples for the two Canadian official languages, English and French, and participants were measured on the dimensions of prose literacy, document literacy and quantitative literacy. The survey found that 42.2%, 43% and 42.2% of Canadians between the ages of 16 and 65 scored at the lowest two levels of Prose Literacy, Document Literacy and Quantitative Literacy, respectively. The survey presented many important correlations, among which was a strong plausible link between literacy and a country's economic potential.\n\nIn 2003, Canada participated in the Adult Literacy and Life Skills Survey (ALL). This survey contained identical measures for assessing the prose and document literacy proficiencies, allowing for comparisons between survey results on these two measures and found that 41.9% and 42.6% of Canadians between the ages of 16 and 65 scored at the lowest two levels of Prose Literacy and document literacy respectively. Further, Canadians’ mean scores also improved on both the prose and the document literacy scales. Energy production:36%, transportation: 24%, homes and businesses: 12%, industry: 11%, agriculture: 10%, and waste: 7%.\n\nThe OECD's Programme for the International Assessment of Adult Competencies (PIAAC) is expected to produce new comparative skill profiles in late 2013.\n\nIn the last 40 years, the rate of illiteracy in Mexico has been steadily decreasing. In the 1960s, because the majority of the residents of the federal capital were illiterate, the planners of the Mexico City Metro designed a system of unique icons to identify each station in the system in addition to its formal name. However, The INEGI´s census data of 1970 showed a national average illiteracy rate of 25.8%; the last census data puts the national average at 6.9%. Mexico still has a gender educational bias. The illiteracy rate for women in the last census was 8.1% compared with 5.6% for men. Rates differ across regions and states. Chiapas, Guerrero and Oaxaca, the states with the highest poverty rate, had greater than 15% illiteracy in 2010(17.8%, 16.7% and 16.3 respectively). In contrast, the illiteracy rates in the Federal District (D.F. / Mexico City) and in some northern states like Nuevo León, Baja California, and Coahuila were below 3% in the 2010 census (2.1%, 2.2%, 2.6% and 2.6% respectively).\n\nBefore the 20th century white illiteracy was not uncommon and many of the slave states made it illegal to teach slaves to read. By 1900 the situation had improved somewhat, but 44% of black people remained illiterate. There were significant improvements for African American and other races in the early 20th century as the descendants of former slaves, who had had no educational opportunities, grew up in the post Civil War period and often had some chance to obtain a basic education. The gap in illiteracy between white and black adults continued to narrow through the 20th century, and in 1979 the rates were about the same.\n\nFull prose proficiency, as measured by the ability to process complex and challenging material such as would be encountered in everyday life, is achieved by about 13% of the general, 17% of the white, and 2% of the African American population. However 86% of the general population had basic or higher prose proficiency as of 2003, with a decrease distributed across all groups in the full proficiency group vs. 1992 of more than 10% consistent with trends, observed results in the SAT reading score to the present (2015).\n\nBefore colonization, oral storytelling and communication composed most if not all Native American literacy. Native people communicated and retained their histories verbally—it was not until the beginning of American Indian boarding schools that reading and writing forms of literacy were forced onto Native Americans. While literacy rates of English increased, forced assimilation exposed Native children to physical and sexual abuse, unsanitary living conditions, and even death. Many students ran away in an attempt to hold on to their cultural identity and literary traditions that were relevant to their community. While these formalized forms of literacy prepared Native youth to exist in the changing society, they destroyed all traces of their cultural literacy. Native children would return to their families unable to communicate with them due to the loss of their indigenous language. In the 20th and 21st century, there is still a struggle to learn and maintain cultural language. But education initiatives and programs have increased overall—according to the 2010 census, 86 percent of the overall population of Native Americans and Alaska Natives have high school diplomas, and 28 percent have a bachelor's degree or higher.\n\nIn 1964 in Brazil, Paulo Freire was arrested and exiled for teaching peasants to read. Since democracy returned to Brazil, however, there has been a steady increase in the percentage of literate people. Educators with the Axé project within the city of Salvador, Bahía attempt to improve literacy rates among urban youth, especially youth living on the streets, through the use of music and dances of the local culture. They are encouraged to continue their education and become professionals.\n\nThe literacy rates in Africa vary significantly between countries. The highest registered literacy rate in the region is in Equatorial Guinea and Libya (both 94.2%), while the lowest literacy rate is in South Sudan (27%). Poorer youth in sub-Saharan Africa have fewer educational opportunities to become literate compared with wealthier families. They often must leave school because of being needed at home to farm or care for siblings.\nIn sub-Saharan Africa, the rate of literacy has not improved enough to compensate for the effects of demographic growth. As a result, the number of illiterate adults has risen by 27% over the last 20 years, reaching 169 million in 2010. Thus, out of the 775 million illiterate adults in the world in 2010, more than one fifth were in sub- Saharan Africa – in other words, 20% of the adult population. The countries with the lowest levels of literacy in the world are also concentrated in this region. These include Niger (28.7%), Burkina Faso (28.7%), Mali (33.4%), Chad (35.4%) and Ethiopia (39%), where adult literacy rates are well below 50%. There are, however, certain exceptions, like Equatorial Guinea, with a literacy rate of 94%.\n\nThe literacy rate of Algeria is around 70%: education is compulsory and free in Algeria up to age of 17.\n\nBotswana has among the highest literacy rates in the developing world with around 85% of its population being literate.\n\nBurkina Faso has a very low literacy rate of 28.7%. The government defines literacy as anyone at least 15 years of age and up who can read and write. To improve the literacy rate, the government has received at least 80 volunteer teachers. A severe lack of primary school teachers causes problems for any attempt to improve the literacy rate and school enrollment.\n\nEgypt has a relatively high literacy rate. The adult literacy rate in 2010 was estimated at 72%.\nEducation is compulsory from ages 6 to 15 and free for all children to attend. 93% of children enter primary school today, compared with 87% in 1994.\n\nDjibouti has an estimated literacy rate of 70%.\n\nAccording to the Ministry of Information of Eritrea, the nation has an estimated literacy rate of 80%.\n\nThe Ethiopians are among the first literate people in the world, having written, read, and created manuscripts in their ancient language of Ge'ez (Amharic) since the second century CE. All boys learned to read the Psalms around the age of 7. National literacy campaign introduced in 1978 increased literacy rates to between 37% (unofficial) and 63% (official) by 1984.\n\nGuinea has a literacy rate of 41%. The Guinea government defines literacy as anyone who can read or write who is at least 15 years old. Guinea was the first to use the Literacy, Conflict Resolution, and Peacebuilding project. This project was developed to increase agriculture production, develop key skills, resolve conflict, improve literacy, and numeracy skills. The LCRP worked within refugee camps near the border of Sierra Leone, however this project only lasted from 1999 to 2001. There are several other international projects working within the country that have similar goals.\n\nThe literacy rate in Kenya among people below 20 years of age is over 70%, as the first 8 years of primary school are provided tuition-free by the government. In January 2008, the government began offering a restricted program of free secondary education. Literacy is much higher among the young than the old population, with the total being about 53% for the country. Most of this literacy, however, is elementary—not secondary or advanced.\n\nMali has one of the lowest literacy rates in the world, at 33.4%, with males having a 43.1% literacy rate and females having a 24.6% literacy rate. The government defines literacy as anyone who is at least 15 and over who can read or write. The government of Mali and international organizations in recent years has taken steps to improve the literacy rate. The government recognized the slow progress in literacy rates and began created ministries for basic education and literacy for their national languages in 2007. To also improve literacy the government planned to increase its education budget by 3%, when this was purposed it was at 35% in 2007. The lack of literate adults causes the programs to be slowed. The programs need qualified female trainers is a major problem because most men refuse to send female family members to be trained under male teachers.\n\nFree education in Mauritius didn't proceed beyond the primary level until 1976, so many women now in their 50s or older left school at age 12. The younger generation (below 50) are however extremely well educated with very high educational expectations placed upon pupils. Education is today free from pre-primary to tertiary (only admission fees remain at University level). Most professional people have at least a bachelor's degree. Mauritian students consistently rank top in the world each year for the Cambridge International O Level, International A and AS level examinations. Most Mauritian children, even at primary level, attend tuition after school and at weekends to cope with the highly competitive public school system where admission to prestigious public colleges (secondary) and most sought after university courses depend on merit based academic performance.\n\nThe adult literacy rate was estimated at 89.8% in 2011. Male literacy was 92.3% and Female literacy 87.3%.\n\nNiger has an extremely low literacy rate at 28.7%. However, the gender gap between males and females is a major problem for the country, men have a literacy rate of 42.9% and women a literacy rate of 15.1%. The Nigerien government defines literacy as anyone who can read or write over the age of 15. The Niass Tijaniyya, a predominate group of the Sufi brotherhoods, has started anti-poverty, empowerment, and literacy campaigns. The women in Kiota had not attempted to improve their education, or economic standing. Saida Oumul Khadiri Niass, known as Maman, through talking to men and women throughout the community changed the community's beliefs on appropriate behavior for women because the community recognized she was married to a leader of the Niass Tijaniyya. Maman's efforts has allowed women in Kiota to own small businesses, sell in the market place, attend literacy classes, and organize small associations that can give micro loans. Maman personally teaches children in and around Kiota, with special attention to girls. Maman has her students require instructor permission to allow the girls' parents to marry their daughters early. This increases the amount of education these girls receive, as well as delaying marriage, pregnancy, and having children.\n\nSenegal has a literacy rate of 49.7%; the government defines literacy as anyone who is at least 15 years of age and over who can read and write. However, many students do not attend school long enough to be considered literate. The government did not begin actively attempting to improve the literacy rate until 1971 when it gave the responsibility to Department for Vocational Training at the Secretariat for Youth and Sports. This department and subsequent following departments had no clear policy on literacy until the Department of Literacy and Basic Education was formed in 1986. The government of Senegal relies heavily on funding from the World Bank to fund its school system.\n\nThere is no reliable data on the nationwide literacy rate in Somalia. A 2013 FSNAU survey indicates considerable differences per region, with the autonomous northeastern Puntland region having the highest registered literacy rate at 72%.\n\nThe Sierra Leone government defines literacy as anyone over the age of 15 who can read and write in English, Mende, Temne, or Arabic. Official statics put the literacy rate at 43.3%. Sierra Leone was the second country to use the Literacy, Conflict Resolution and Peacebuilding project. However, due to fighting near the city where the project was centered causing the project to be delayed until an arms amnesty was in place.\n\nUganda has a literacy rate of 66.8%.\n\nZimbabwe has a high literacy rate of 86.5% (2016 est.).\n\n Afghanistan has one of the lowest literacy rates in the world at 28.1% with males having a literacy rate of 43.1% and females with a literacy rate of 12.6%. The Afghan government considers someone literate if they are 15 years of age or older, and if they can read and write. To improve the literacy rate U.S. military trainers have been teaching Afghan Army recruits how to read before teaching to fire a weapon. U.S. commanders in the region estimate that as many as 65% of recruits may be illiterate.\n\nThe PRC conducts standardized testing to assess proficiency in Standard Chinese, known as \"putonghua,\" but it is primarily for foreigners or those needing to demonstrate professional proficiency in the Beijing dialect. Literacy in languages like Chinese can be assessed by reading comprehension tests, just as in other languages, but historically has often been graded on the number of Chinese characters introduced during the speaker's schooling, with a few thousand considered the minimum for practical literacy. Social science surveys in China have repeatedly found that just more than half the population of China is conversant in spoken putonghua.\n\nLiteracy is defined by the Registrar General and Census Commissioner of India, as \"[the ability of] a person aged 7 years and above [to]... both write and read with understanding in any language.\" According to the 2011 census, 74.04 percent.\n\nLaos has the lowest level of adult literacy in all of Southeast Asia other than East Timor.\n\nObstacles to literacy vary by country and culture as writing systems, quality of education, availability of written material, competition from other sources (television, video games, cell phones, and family work obligations), and culture all influence literacy levels. In Laos, which has a phonetic alphabet, reading is relatively easy to learn—especially compared to English, where spelling and pronunciation rules are filled with exceptions, and Chinese, with thousands of symbols to be memorized. But a lack of books and other written materials has hindered functional literacy in Laos, where many children and adults read so haltingly that the skill is hardly beneficial.\n\nA literacy project in Laos addresses this by using what it calls \"books that make literacy fun!\" The project, Big Brother Mouse, publishes colorful, easy-to-read books, then delivers them by holding book parties at rural schools. Some of the books are modeled on successful western books by authors such as Dr. Seuss; the most popular, however, are traditional Lao fairy tales. Two popular collections of folktales were written by Siphone Vouthisakdee, who comes from a village where only five children finished primary school.\n\nBig Brother Mouse has also created village reading rooms, and published books for adult readers about subjects such as Buddhism, health, and baby care.\n\nIn Pakistan, the National Commission for Human Development (NCHD) aims to bring literacy to adults, especially women.\nISLAMABAD - UNESCO Islamabad Director Kozue Kay Nagata has said, \"Illiteracy in Pakistan has fallen over two decades, thanks to the government and people of Pakistan for their efforts working toward meeting the Millennium Development Goals\". \"Today, 70 percent of Pakistani youths can read and write. In 20 years, illiterate population has been reduced significantly\", she said while speaking at a function held in connection with International Literacy Day.\n\nHowever, she also emphasised on the need to do more to improve literacy in the country and said, \"The proportion of population in Pakistan lacking basic reading and writing is too high. This is a serious obstacle for individual fulfillment, to the development of societies, and to mutual understanding between peoples.\" Referring to the recent national survey carried out by the Ministry of Education, Trainings and Standards in Higher Education with support of UNESCO, UNICEF, and provincial and areas departments of education, Nagata pointed out that, in Pakistan, although primary school survival rate is 70 percent, gender gap still exists with only 68 percent of girls’ survival rate compared to 71 percent for boys. Specifically in the case of Punjab, she said, primary school survival rate today is better with 76 percent, but not without a gender gap of 8 percent points with 72 percent girls’ survival rate compared to 80 percent for boys. She also pointed out that average per student spending in primary level (age 5-9) was better in Punjab: Rs 6,998, compared to the national average. In Balochistan, although almost the same amount (Rs 6,985) as in Punjab is spent per child, the primary school survival rate is only 53 percent. Girls’ survival rate is slightly better with 54 percent than that of boys which is 52 percent. Literate Pakistan Foundation, a non-profit organization, which was established in 2003, is a case study, which brings to light the solutions for removing this menace from its roots. It works to improve rate of literacy in Pakistan.\n\nThe data of the survey shows that in Khyber Pakhtunkhwa, primary school survival rate is 67 percent which is lower than the national average of 70 percent. Furthermore, gender gap also exists with only 65 percent of girls’ survival rate compared to that of boys which is 68 percent. Per-student education expenditure in primary level (age 5-9) in Khyber Pakhtunkhwa is Rs 8,638. In Sindh, primary school survival rate is 63percent, with a gender gap of only 67 percent of girls’ survival rate compared to 60 percent for boys. Per student education expenditure in primary level (age 5-9) in Sindh is Rs 5,019. Nagata made reference to the survey report and mentioned that the most common reason in Pakistan for children (both boys and girls) of age 10 to 18 years leaving school before completing primary grade is \"the child not willing to go to school\", which may be related to quality and learning outcome. She said, however, and sadly, for the girls living in rural communities the second highest reason for dropout is \"parents did not allow\" which might be related to prejudice and cultural norm against girls.\n\nEarly Filipinos devised and used their own system of writings from 300 BC, which derived from the Brahmic family of scripts of Ancient India. Baybayin became the most widespread of these derived scripts by the 11th century.\n\nEarly chroniclers, who came during the first Spanish expeditions to the islands, noted the proficiency of some of the natives, especially the chieftain and local kings, in Sanskrit, Old Javanese, Old Malay, and several other languages.\n\nDuring the Spanish colonization of the islands, reading materials were destroyed to a far much less extent compared to the Spanish colonization of the Americas. Education and literacy was introduced only to the Peninsulares and remained a privilege until the Americans came.\n\nThe Americans introduced the public schools system to the country which drove literacy rates up. English became the lingua franca in the Philippines. It was only during a brief period in the Japanese occupation of the Philippines that the Japanese were able to teach their language in the Philippines and teach the children their written language.\n\nAfter World War II, the Philippines had the highest literacy rates in Asia. It nearly achieved universal literacy once again in the 1980s and 1990s. Ever since then, the literacy rate has plummeted only to start regaining a few percentage years back.\n\nThe DepEd, CHED, and other academic institutions encourage children to improve literacy skills and knowledge. The government has a program of literacy teaching starting in kindergarten. New reforms are being brought in shifting to a K-12 system which will teach children their regional languages before English, as opposed to the ten-year basic education program which teaches English and Filipino, the country's two official languages, from Grade 1.\n\nWith a literacy rate of 92.5%, Sri Lanka has one of the most literate populations amongst developing nations. Its youth literacy rate stands at 98%, computer literacy rate at 35%, and primary school enrollment rate at over 99%. An education system which dictates 9 years of compulsory schooling for every child is in place. The free education system established in 1945, is a result of the initiative of C. W. W. Kannangara and A. Ratnayake. It is one of the few countries in the world that provide universal free education from primary to tertiary stage.\n\nApproximately 56% of Australians aged 15 to 74 achieve Level 3 literacy or above Australian Bureau of Statistics 2011-2012 and 83% of five-year-olds are on track to develop good language and cognitive skills Australian Early Development Census 2012 summary report. In 2012-2013, Australia had 1515 public library service points, lending almost 174 million items to 10 million members of Australian public library services, at an average per capita cost of just under AU$45 Australian Public Library Statistics 2012-2013.\n\n\n\n"}
{"id": "34934339", "url": "https://en.wikipedia.org/wiki?curid=34934339", "title": "Lukas Pusch", "text": "Lukas Pusch\n\nLukas Pusch (born 1970) is an Austrian artist based in Vienna and Siberia.\nHe studied painting at the University of Applied Arts Vienna, Surikov Institut in Moscow and the Dresden Academy of Fine Arts.\n\nPusch artworks includes paintings, objects, films and performances. 2007 he founded SLUM-TV together with Sam Hopkins and Alexander Nikolic in Mathare. 2008 he opened the White Cube Gallery Novosibirsk. It was the first and in that time only center of contemporary art in Siberia in form of an iron garage.\n\n\n\n\n\n"}
{"id": "990809", "url": "https://en.wikipedia.org/wiki?curid=990809", "title": "Moving average", "text": "Moving average\n\nIn statistics, a moving average (rolling average or running average) is a calculation to analyze data points by creating a series of averages of different subsets of the full data set. It is also called a moving mean (MM) or rolling mean and is a type of finite impulse response filter. Variations include: simple, and cumulative, or weighted forms (described below).\n\nGiven a series of numbers and a fixed subset size, the first element of the moving average is obtained by taking the average of the initial fixed subset of the number series. Then the subset is modified by \"shifting forward\"; that is, excluding the first number of the series and including the next value in the subset.\n\nA moving average is commonly used with time series data to smooth out short-term fluctuations and highlight longer-term trends or cycles. The threshold between short-term and long-term depends on the application, and the parameters of the moving average will be set accordingly. For example, it is often used in technical analysis of financial data, like stock prices, returns or trading volumes. It is also used in economics to examine gross domestic product, employment or other macroeconomic time series. Mathematically, a moving average is a type of convolution and so it can be viewed as an example of a low-pass filter used in signal processing. When used with non-time series data, a moving average filters higher frequency components without any specific connection to time, although typically some kind of ordering is implied. Viewed simplistically it can be regarded as smoothing the data.\n\nIn financial applications a simple moving average (SMA) is the unweighted mean of the previous \"n\" data. However, in science and engineering, the mean is normally taken from an equal number of data on either side of a central value. This ensures that variations in the mean are aligned with the variations in the data rather than being shifted in time.\n\nAn example of a simple equally weighted running mean for a n-day sample of closing price is the mean of the previous \"n\" days' closing prices. If those prices are formula_1 then the formula is\n\nWhen calculating successive values, a new value comes into the sum and the oldest value drops out, meaning a full summation each time is unnecessary for this simple case,\n\nThe period selected depends on the type of movement of interest, such as short, intermediate, or long-term. In financial terms moving-average levels can be interpreted as support in a falling market, or resistance in a rising market.\n\nIf the data used are not centered around the mean, a simple moving average lags behind the latest datum point by half the sample width. An SMA can also be disproportionately influenced by old datum points dropping out or new data coming in. One characteristic of the SMA is that if the data have a periodic fluctuation, then applying an SMA of that period will eliminate that variation (the average always containing one complete cycle). But a perfectly regular cycle is rarely encountered.\n\nFor a number of applications, it is advantageous to avoid the shifting induced by using only 'past' data. Hence a central moving average can be computed, using data equally spaced on either side of the point in the series where the mean is calculated. This requires using an odd number of datum points in the sample window.\n\nA major drawback of the SMA is that it lets through a significant amount of the signal shorter than the window length. Worse, it \"actually inverts it\". This can lead to unexpected artifacts, such as peaks in the smoothed result appearing where there were troughs in the data. It also leads to the result being less smooth than expected since some of the higher frequencies are not properly removed.\n\nIn a cumulative moving average, the data arrive in an ordered datum stream, and the user would like to get the average of all of the data up until the current datum point. For example, an investor may want the average price of all of the stock transactions for a particular stock up until the current time. As each new transaction occurs, the average price at the time of the transaction can be calculated for all of the transactions up to that point using the cumulative average, typically an equally weighted average of the sequence of \"n\" values formula_4 up to the current time:\n\nA weighted average is an average that has multiplying factors to give different weights to data at different positions in the sample window. Mathematically, the moving average is the convolution of the datum points with a fixed weighting function. One application is removing pixelisation from a digital graphical image.\n\nIn technical analysis of financial data, a weighted moving average (WMA) has the specific meaning of weights that decrease in arithmetical progression. In an \"n\"-day WMA the latest day has weight \"n\", the second latest \"n\" − 1, etc., down to one.\n\nThe denominator is a triangle number equal to formula_7 In the more general case the denominator will always be the sum of the individual weights.\n\nWhen calculating the WMA across successive values, the difference between the numerators of WMA and WMA is \"np\" − \"p\" − ⋅⋅⋅ − \"p\". If we denote the sum \"p\" + ⋅⋅⋅ + \"p\" by Total, then\n\nThe graph at the right shows how the weights decrease, from highest weight for the most recent datum points, down to zero. It can be compared to the weights in the exponential moving average which follows.\n\nAn exponential moving average (EMA), also known as an exponentially weighted moving average (EWMA), is a first-order infinite impulse response filter that applies weighting factors which decrease exponentially. The weighting for each older datum decreases exponentially, never reaching zero. The graph at right shows an example of the weight decrease.\n\nThe EMA for a series \"Y\" may be calculated recursively:\n\nWhere:\n\n\"S\" may be initialized in a number of different ways, most commonly by setting \"S\" to \"Y\" as shown above, though other techniques exist, such as setting \"S\" to an average of the first 4 or 5 observations. The importance of the \"S\" initialisations effect on the resultant moving average depends on \"α\"; smaller \"α\" values make the choice of \"S\" relatively more important than larger \"α\" values, since a higher \"α\" discounts older observations faster.\n\nWhatever is done for \"S\" it assumes something about values prior to the available data and is necessarily in error. In view of this, the early results should be regarded as unreliable until the iterations have had time to converge. This is sometimes called a 'spin-up' interval. One way to assess when it can be regarded as reliable is to consider the required accuracy of the result. For example, if 3% accuracy is required, initialising with \"Y\" and taking data after five time constants (defined above) will ensure that the calculation has converged to within 3% (only <3% of \"Y\" will remain in the result ). Sometimes with very small alpha, this can mean little of the result is useful. This is analogous to the problem of using a convolution filter (such as a weighted average) with a very long window.\n\nThis formulation is according to Hunter (1986). By repeated application of this formula for different times, we can eventually write \"S\" as a weighted sum of the datum points \"Y\", as:\n\nfor any suitable \"k\" ∈ {0, 1, 2, …} The weight of the general datum point formula_11 is formula_12.\n\nAn alternate approach by Roberts (1959) uses \"Y\" in lieu of \"Y\":\n\nThis formula can also be expressed in technical analysis terms as follows, showing how the EMA steps towards the latest datum point, but only by a proportion of the difference (each time):\n\nExpanding out formula_15 each time results in the following power series, showing how the weighting factor on each datum point \"p\", \"p\", etc., decreases exponentially:\n\nwhere\n\nsince formula_22.\n\nIt can also be calculated recursively without introducing the error when initializing the first estimate (n starts from 1):\n\nThis is an infinite sum with decreasing terms.\n\nThe question of how far back to go for an initial value depends, in the worst case, on the data. Large price values in old data will affect the total even if their weighting is very small. If prices have small variations then just the weighting can be considered.\nThe power formula above gives a starting value for a particular day, after which the successive days formula shown first can be applied. The weight omitted by stopping after \"k\" terms is\n\nwhich is\n\ni.e. a fraction\n\nout of the total weight.\n\nFor example, to have 99.9% of the weight, set above ratio equal to 0.1% and solve for \"k\":\n\nto determine how many terms should be used. Since formula_31 as formula_32, we know formula_33 approaches formula_34 as N increases\n. This gives:\n\nWhen formula_36 is related to N via to formula_37,\nthis simplifies to approximately,\n\nfor this example (99.9% weight).\n\nNote that there is no \"accepted\" value that should be chosen for formula_39 although there are some recommended values based on the application. A commonly used value for formula_36 is formula_41. This is because the weights of an SMA and EMA have the same \"center of mass\" when formula_42.\nThe weights of an formula_43-day SMA have a \"center of mass\" on the formula_44 day, where\n\nFor the remainder of this proof we will use one-based indexing.\nNow meanwhile, the weights of an EMA have center of mass\nThat is,\nWe also know the Maclaurin Series\nTaking derivatives of both sides with respect to formula_50 gives: \nor \nSubstituting formula_53, we get\nor \nSo the value of formula_36 that sets formula_57 is, in fact: \nor \n\nAnd so formula_60 is the value of formula_36 that creates an EMA whose weights have the same center of gravity as would the equivalent N-day SMA\n\nThis is also why sometimes an EMA is referred to as an \"N\"-day EMA. Despite the name suggesting there are \"N\" periods, the terminology only specifies the \"α\" factor. \"N\" is not a stopping point for the calculation in the way it is in an SMA or WMA. For sufficiently large \"N\", the first \"N\" datum points in an EMA represent about 86% of the total weight in the calculation when formula_41:\n\nThe sum of the weights of all the terms (i.e., infinite number of terms) in an exponential moving average is 1. The sum of the weights of formula_63 terms is formula_64. Both of these sums can be derived by using the formula for the sum of a geometric series. The weight omitted after formula_63 terms is given by subtracting this from 1, and you get formula_66 (this is essentially the formula given previously for the weight omitted). \n\nWe now substitute the commonly used value for formula_41 in the formula for the weight of formula_63 terms. If you make this substitution, and you make use of formula_69, then you get\n\nthe 0.8647 approximation. Intuitively, what this is telling us is that the weight after formula_63 terms of an ``formula_63-period\" exponential moving average converges to 0.8647.\nThe designation of formula_75 it not a requirement. It is a common convention to form an intuitive understanding of the relationship between EMAs and SMAs, when both are used together on datasets. An EMA with any value of formula_36 can be used, and can either be named by stating the value of formula_36, or used with the more familiar \"N\"-day EMA terminology and let formula_78.\n\nIn addition to the mean, we may also be interested in the variance and in the standard deviation to evaluate the statistical significance of a deviation from the mean.\n\nEWMVar can be computed easily along with the moving average.\nThe starting values are formula_79 and formula_80,\nand we then compute the subsequent values using:\n\nformula_81\n\nFrom this, the exponentially weighted moving standard deviation can be computed as formula_82.\nWe can then use the standard score to normalize data with respect to the moving average and variance.\nThis algorithm is based on Welford's algorithm for computing the variance.\n\nA modified moving average (MMA), running moving average (RMA), or smoothed moving average (SMMA) is defined as:\n\nIn short, this is an exponential moving average, with formula_84.\n\nSome computer performance metrics, e.g. the average process queue length, or the average CPU utilization, use a form of exponential moving average.\n\nHere is defined as a function of time between two readings. An example of a coefficient giving bigger weight to the current reading, and smaller weight to the older readings is\n\nwhere is the exponential function, time for readings \"t\" is expressed in seconds, and is the period of time in minutes over which the reading is said to be averaged (the mean lifetime of each reading in the average). Given the above definition of , the moving average can be expressed as\n\nFor example, a 15-minute average \"L\" of a process queue length \"Q\", measured every 5 seconds (time difference is 5 seconds), is computed as\n\nOther weighting systems are used occasionally – for example, in share trading a volume weighting will weight each time period in proportion to its trading volume.\n\nA further weighting, used by actuaries, is Spencer's 15-Point Moving Average (a central moving average). The symmetric weight coefficients are −3, −6, −5, 3, 21, 46, 67, 74, 67, 46, 21, 3, −5, −6, −3.\n\nOutside the world of finance, weighted running means have many forms and applications. Each weighting function or \"kernel\" has its own characteristics. In engineering and science the frequency and phase response of the filter is often of primary importance in understanding the desired and undesired distortions that a particular filter will apply to the data.\n\nA mean does not just \"smooth\" the data. A mean is a form of low-pass filter. The effects of the particular filter used should be understood in order to make an appropriate choice. On this point,\nthe French version of this article discusses the spectral effects of 3 kinds of means (cumulative, exponential, Gaussian).\n\nFrom a statistical point of view, the moving average, when used to estimate the underlying trend in a time series, is susceptible to rare events such as rapid shocks or other anomalies. A more robust estimate of the trend is the simple moving median over \"n\" time points:\n\nwhere the median is found by, for example, sorting the values inside the brackets and finding the value in the middle. For larger values of \"n\", the median can be efficiently computed by updating an indexable skiplist.\n\nStatistically, the moving average is optimal for recovering the underlying trend of the time series when the fluctuations about the trend are normally distributed. However, the normal distribution does not place high probability on very large deviations from the trend which explains why such deviations will have a disproportionately large effect on the trend estimate. It can be shown that if the fluctuations are instead assumed to be Laplace distributed, then the moving median is statistically optimal. For a given variance, the Laplace distribution places higher probability on rare events than does the normal, which explains why the moving median tolerates shocks better than the moving mean.\n\nWhen the simple moving median above is central, the smoothing is identical to the median filter which has applications in, for example, image signal processing.\n\nIn a moving average regression model, a variable of interest is assumed to be a weighted moving average of unobserved independent error terms; the weights in the moving average are parameters to be estimated.\n\nThose two concepts are often confused due to their name, but while they share many similarities, they represent distinct methods and are used in very different contexts.\n"}
{"id": "2910814", "url": "https://en.wikipedia.org/wiki?curid=2910814", "title": "National Physical Laboratory of India", "text": "National Physical Laboratory of India\n\nThe National Physical Laboratory of India, situated in New Delhi, is the measurement standards laboratory of India. It maintains standards of SI units in India and calibrates the national standards of weights and measures.\n\nOne of the most ancient texts of India, \"Manusmriti\", describes among the duties of the king: \"The king should examine the weights and balances every six months to ensure true measurements and to mark them with the royal stamp.\" -- \"Manusmriti\", 8th Chapter, Shloka 403. In the Harappan era, which is nearly 5000 years old, one finds excellent examples of town planning and architecture. The sizes of the bricks were the same all over the region. In the time of Chandragupta Maurya, some 2400 years ago, there was a well - defined system of weights and measures. The government of that time ensured that everybody used the same system. In the Indian medical system, Ayurveda, the units of mass and volume were well defined.\n\nThe measurement system during the time of the Mughal emperor, Akbar, the \"guz\" was the measure of length. The \"guz\" was widely used till the introduction of the metric system in India in 1956. During the British period, efforts were made to achieve uniformity in weights and measures. A compromise was reached in the system of measurements which continued till India's independence in 1947. After independence in 1947, it was realized that for fast industrial growth of the country, it would be necessary to establish a modern measurement system in the country. The Lok Sabha in April 1955 resolved : \"This house is of the opinion that the Government of India should take necessary steps to introduce uniform weights and measures throughout the country based on metric system\".\n\nThe National Physical Laboratory, India was set up in 1900) is one of the earliest national laboratories set up under the Council of Scientific & Industrial Research. Jawaharlal Nehru laid the foundation stone of NPL on 4 January 1947. Dr. K. S. Krishnan was the first Director of the laboratory. The main building of the laboratory was formally opened by Former Deputy Prime Minister Sardar Vallabhbhai Patel on 21 January 1950. Former Prime Minister Indira Gandhi, inaugurated the Silver Jubilee Celebration of the Laboratory on 23 December 1975.\n\nNPL Charter:-\n\nThe main aim of the laboratory is to strengthen and advance physics-based research and development for the overall development of science and technology in the country. In particular its objectives are:\n\nTo establish, maintain and improve continuously by research, for the benefit of the nation, National Standards of Measurements and to realize the Units based on International System (Under the subordinate Legislations of Weights and Measures Act 1956, reissued in 1988 under the 1976 Act). \nTo identify and conduct after due consideration, research in areas of physics which are most appropriate to the needsof the nation and for advancement of field\n\nTo assist industries, national and other agencies in their developmental tasks by precision measurements, calibration, development of devices, processes, and other allied problems related to physics.\n\nTo keep itself informed of and study critically the status of physics.\n\nEach modernized country, including India has a National Metrological Institute (NMI), which maintains the standards of measurements. This responsibility has been given to the National Physical Laboratory, New Delhi.\n\nThe standard unit of length, metre, is realized by employing a stabilized Helium - Neon laser as a source of light. Its frequency is measured experimentally. From this value of frequency and the internationally accepted value of the speed of light (299,792,458 metres/second), the wavelength is determined using the relation:\n\nWavelength = Velocity of light / frequency\n\nThe nominal value of wavelength, employed at NPL is 633 nanometer. By a sophisticated instrument, known as an optical interferometer, any length can be measured in terms of the wavelength of laser light.\n\nThe present level of uncertainty attained at NPL in length measurements is ± 3 × 10. However in most measurements, an uncertainty of ± 1 × 10 is adequate.\n\nThe Indian national standard of mass, kilogramme, is copy number 57 of the international prototype kilogram supplied by the International Bureau of Weights and Measures (BIPM : French - Bureau International des Poids et Mesures), Paris. This is a Platinum Iridium cylinder whose mass is measured against the international prototype at BIPM. The NPL also maintains a group of transfer standard kilograms made of non - magnetic stainless steel and nickel - chromium alloy.\n\nThe uncertainty in mass measurements at NPL is ± 4.6 × 10.\n\nThe national standard of time interval, second as well as frequency, is maintained through four parameters, which can be measured most accurately. Therefore, attempts are made to link other physical quantities to time and frequency. The standard maintained at NPL has to be linked to different users. This process, known as dissemination, is carried out in a number of ways. For applications requiring low levels of uncertainty, there is satellite based dissemination service, which utilizes the Indian national satellite, INSAT. Time is also disseminated through TV, radio, and special telephone services. The caesium atomic clocks maintained at NPL are linked to other such instituted all over the world through a set of global positioning satellites.\n\nThe unit of electric current, ampere, is realized at NPL by measuring volt and Ohm separately.\n\nThe uncertainty in measurement of ampere is ± 1 × 10.\n\nThe standard of temperature is based on the International Temperature Scale of 1990 (ITS-90). This is based on the assigned temperatures to several fixed points. One of the most fundamental temperatures of these is the triple point of water. At this temperature, ice, water and steam are at equilibrium with each other. This temperature has been assigned the value of 273.16 kelvins. This temperature can be realized, maintained and measured in the laboratory. At present temperature standards maintained at NPL cover a range of 54 to 2,473 kelvins.\n\nThe uncertainty in its measure is ± 2.5 × 10.\n\nThe unit of luminous intensity, candela, is realized by using an absolute radiometer. For practical work, a group of tungsten incandescent lamps are used.\n\nThe level of uncertainty is ± 1.3 × 10.\n\nExperimental work has been initiated to realize mole, the SI unit for amount of substance\n\nThe NPL does not maintain standards of measurements for ionizing radiations. This is the responsibility of the Homi Bhabha Atomic Research Centre, Mumbai.\n\nThe standards maintained at NPL are periodically compared with standards maintained at other National Metrological Institutes in the world as well as the BIPM in Paris. This exercise ensures that Indian national standards are equivalent to those of the rest of the world.\n\nAny measurement made in a country should be directly or indirectly linked to the national standards of the country, For this purpose, a chain of laboratories are set up in different states of the country. The weights and measures used in daily life are tested in the laboratories and certified. It is the responsibility of the NPL to calibrate the measurement standards in these laboratories at different levels. In this manner, the measurements made in any part of the country are linked to the national standards and through them to the international standards.\n\nThe weights and balances used in local markets and other areas are expected to be certified by the Department of Weights and Measures of the local government. Working standards of these local departments should, in turn, be calibrated against the state level standards or any other laboratory which is entitled to do so. The state level laboratories are required to get their standards calibrated from the NPL at the national level which is equivalent to the international standards.\n\nBharatiya Nirdeshak Dravya (BND) or Indian reference materials are reference materials developed by NPL which derive their traceability from National Standards.\n\nNPL is also involved in research. One of the important research activities undertaken by NPL is to devise the chemical formula for the indelible ink which is being used in the Indian elections to prevent fraudulent voting. This ink, manufactured by the Mysore Paints and Varnish Limited is applied on the finger nail of the voter as an indicator that the voter has already cast his vote.\n\nNPL also have section working on development of biosensors. Currently the Biomedical Instrumentation section is headed by Dr. R. K. Kotnala and section is primarily focusing on development of sensor for cholesterol, measurement and microfluidic based biosensors. Section is also developing biosensors for Uric acid detection.\n\nNPL has developed Hydroelectric Cell, which is form of galvanic cell. The novelty of this work lies in the generation of electrical energy by water molecule dissociation using lithium substituted magnesium ferrite at room temperature. Porous magnesium ferrite has been explored extensively for its water molecule sensing properties via chemidissociation of water molecule. More about this can be checked from NPL website.\n\nDuring general election, nearly 40 million people wear a CSIR mark on their fingers. The Indelible ink used to mark the fingernail of a Voter during general elections is a time-tested gift of CSIR to the spirit of democracy. Developed in 1952, it was first produced in-campus. Subsequently industry has been manufacturing the Ink. It is also exported to Sri Lanka, Indonesia, Turkey and other democracies.\n\nNational Physical Laboratory (NPL) has established an atmospheric monitoring station in the campus of Institute of Himalayan Bioresource Technology (IHBT) at Palampur (H.P.) at an altitude of 1391 m for generating the base data for atmospheric trace species & properties to serve as reference for comparison of polluted atmosphere in India. At this station, NPL has installed state of art air monitoring system, greenhouse gas measurement system and Raman Lidar. A number of parameters like CO, NO, NO2, NH3, SO2, O3, PM, HC & BC besides CO2 & CH4 are being currently monitored at this station which is also equipped with weather station (AWS) for measurement of weather parameters.\n\nThe BND-4201 is first Indian reference material for gold of ‘9999’ fineness (gold that is 99.99% pure with impurities of only 100 parts-per-million).\n\n"}
{"id": "401506", "url": "https://en.wikipedia.org/wiki?curid=401506", "title": "National Urban League", "text": "National Urban League\n\nThe National Urban League (NUL), formerly known as the National League on Urban Conditions Among Negroes, is a nonpartisan civil rights organization based in New York City that advocates on behalf of African Americans and against racial discrimination in the United States. It is the oldest and largest community-based organization of its kind in the nation. Its current President is Marc Morial.\n\nThe Committee on Urban Conditions Among Negroes was founded in New York City on September 29, 1910 by Ruth Standish Baldwin and Dr. George Edmund Haynes, among others. It merged with the Committee for the Improvement of Industrial Conditions Among Negroes in New York (founded in New York in 1906) and the National League for the Protection of Colored Women (founded in 1905), and was renamed the National League on Urban Conditions Among Negroes.\n\nIn 1918, Eugene K. Jones took the leadership of the organization. Under his direction, the League significantly expanded its multifaceted campaign to crack the barriers to black employment, spurred first by the boom years of the 1920s, and then by the desperate years of the Great Depression.\n\nIn 1920, the organization took the present name, the National Urban League. The mission of the Urban League movement, as stated by the National Urban League, is \"to enable African Americans to secure economic self-reliance, parity, power and civil rights.\"\n\nIn 1941, Lester Granger was appointed Executive Secretary and led the NUL's effort to support the March on Washington proposed by A. Philip Randolph, Bayard Rustin and A. J. Muste to protest racial discrimination in defense work and the military. During the Civil Rights Movement, Granger prevailed in his insistence that the NUL continue its strategy of \"education and persuasion\".\n\nIn 1961, Whitney Young became executive director amidst the expansion of activism in the civil rights movement, which provoked a change for the League. Young substantially expanded the League's fund-raising ability- and made the League a full partner in the civil rights movement. In 1963, the NUL hosted the planning meetings of A. Philip Randolph, Martin Luther King, Jr., and other civil rights leaders for the March on Washington. During Young's ten-year tenure at the League, he initiated programs such as \"Street Academy,\" an alternative education system to prepare high school dropouts for college; and \"New Thrust,\" an effort to help local black leaders identify and solve community problems. Young also pushed for federal aid to cities.\n\nClarence M. Pendleton, Jr., was from 1975 to 1981, the head of the Urban League in San Diego, California. In 1981, U.S. President Ronald W. Reagan tapped Pendleton as the chairman of the United States Commission on Civil Rights, a position which he held until his sudden death in 1988. Pendleton sought to steer the commission into the conservative direction in line with Reagan's views on social and civil rights policies.\n\nIn 1994, Hugh Price was appointed as president of the Urban League.\n\nIn 2003, Marc Morial, former mayor of New Orleans, Louisiana, was appointed the league's eighth President and Chief Executive Officer. He worked to reenergize the movement's diverse constituencies by building on the legacy of the organization and increasing the profile of the organization.\n\nToday, the National Urban League has 90 affiliates serving 300 communities, in 36 states and the District of Columbia. The National Urban League provides direct services in the areas of education, health care, housing, jobs, and justice -- improving the lives of more than 2 million people nationwide. The organization also has a Washington Bureau that serves as its research, policy and advocacy arm on issues relating to Congress and the Administration.\n\nThe National Urban League is an organizational member of the Coalition to Stop Gun Violence, which advocates gun control. In 1989, it was the beneficiary of all proceeds from the Stop the Violence Movement and their hip hop single, \"Self Destruction\".\n\nIn May 2017, the National Urban League began producing its now annual State of Black America TV Town Hall, which airs on TV One. The TV Town Hall elevates social issues related to African Americans through an interview style format with celebrity guests. The show is executive produced by Rhonda Spears Bell.\n\nIn February 2018, the National Urban League launched a weekly podcast named, For The Movement, which discusses persistent policy, social and civil rights issues affecting communities of color. The co-hosts for the podcast are Marc Morial, Donald Cravins, Jr., Kezmiché \"Kim\" Atterbury, and Jordun Lawrence. The podcast was created and is executive produced by Kezmiché \"Kim\" Atterbury.\n\nThe Presidents (or Executive Directors) of the National Urban League have been:\n\n\n\n\n\n"}
{"id": "21911", "url": "https://en.wikipedia.org/wiki?curid=21911", "title": "Naturism", "text": "Naturism\n\nNaturism, or nudism, is a cultural and political movement practicing, advocating, and defending personal and social nudity, most but not all of which takes place on private property. The term may also refer to a lifestyle based on personal, family, or social nudism. Naturism may take a number of forms. It may be practiced individually, within a family, socially, or in public. Additionally, there is also militant naturism, including campaigning, and extreme naturism is sometimes considered a separate category.\n\nThe XIV Congress of the International Naturist Federation (Agde, France, 1974) defined naturism as:\n\nSeveral other terms (\"social nudity\", \"public nudity\", \"skinny dipping\", \"sunning\", and \"clothes-free\") have been proposed as alternative terms for naturism, but none has found the same widespread public acceptance as the older terms \"naturism\" and (in much of the United States) \"nudism\".\n\nPeople interested in social nudity can attend clothes-free beaches and other types of ad-hoc nudist events. At these venues, participants generally need not belong to a nudist club.\n\nMany contemporary naturists and naturist organisations feel that the practice of social nudity should be asexual. For various social, cultural, and historical reasons the lay public, the media, and many contemporary naturists and their organisations often oversimplify the relationship between naturism and sexuality. Current research has begun to explore this complex relationship.\n\nThe International Naturist Federation explains:\n\nThe usage and definition of these terms varies geographically and historically. Though in the United States, naturism and nudism have the same meaning, in Britain there is a clear distinction.\n\nNudism is the \"act of being naked\", while naturism is a \"lifestyle\" which at various times embraced nature, environment, respect for others, self-respect, crafts, healthy eating, vegetarianism, teetotalism, non-smoking, yoga, physical exercise and pacifism as well as nudity.\n\nIn naturist parlance, \"textile\" or \"textilist\" is a non-naturist person, non-naturist behaviour or non-naturist facilities. e.g. \"the textile beach starts at the flag\", \"they are a mixed couple – he is naturist, she is textile\". \"Textile\" is the predominant term used in the UK ('textilist' is unknown in British naturist magazines including \"H&E naturist\"), although some naturists avoid it due to perceived negative or derogatory connotations. \"Textilist\" is said to be used interchangeably, but no dictionary definition to this effect exists, nor are there any equivalent examples of use in mainstream literature such as those for \"textile\". \"Clothing optional\" and \"nude optional\" (US specific) describe a policy or a venue that allows or encourages nudity but tolerates the wearing of clothes. The opposite is \"clothing compulsory\"; that is, prohibiting nudity. Adjectival phrases \"clothes free\" and \"clothing free\" prescribe where naturism is permitted in an otherwise textile environment, or define the preferred state of a naturist.\n\nThe social nudity movement includes a large range of variants including \"naturism\", \"nudism\", \"Freikörperkultur (FKK)\", the \"free beach movement\" as well as generalized \"public lands/public nudity\" advocacy. There is a large amount of shared history and common themes, issues and philosophy, but differences between these separate movements remain contentious.\n\nMany people are often nude in the privacy of their home or garden, either alone or with members of the family; naturists normally refer to them as at-home-nudists or closet-nudists. This may be occasional nudity or as a naturist lifestyle. There are differences of opinion as to whether, and if so to what extent, parents should appear naked in front of their children, and whether children should be nude within the home in the view of their family as well as visitors. This has attracted a great deal of academic study.\n\nA United States study by Alfred Kinsey (1948–1953) found that 75% of the participants stated that there was never nudity in the home when they were growing up, 5% of the participants said that there was \"seldom\" nudity in the home, 3% said \"often\", and 17% said that it was \"usual\". The study found that there was no significant difference between what was reported by men and by women with respect to frequency of nudity in the home.\nGordon and Schroeder in 1995 reported that parental nudity varies considerably from family to family. They say that \"there is nothing inherently wrong with bathing with children or otherwise appearing naked in front of them\", noting that doing so may provide an opportunity for parents to provide important information. They note that by ages 5 to 6 children begin to develop a sense of modesty, and recommend to parents who wish to be sensitive to their children's wishes that they limit such activities from that age onwards.\n\nBarbara Bonner in 1999 cautioned against nudity in the home if children exhibit sexual play of a type that is considered problematic.\n\nIn a 1995 review of the literature, Paul Okami concluded that there was no reliable evidence linking exposure to parental nudity to any negative effect. Three years later, his team finished an 18-year longitudinal study that showed that, if anything, such exposure was associated with slight beneficial effects, particularly for boys.\n\nSmith and Sparks in their study on the effects of social nudity on children conclude that \"the viewing of the unclothed body, far from being destructive to the psyche, seems to be either benign and totally harmless or to actually provide positive benefits to the individuals involved.\n\nThe rhetoric of the nudism and anti-nudism movements emphasizes freedom from many of the normal constraints which regulate human interaction in nudist settings, although for different reasons. Using data from French and German beaches, this hypothesis was tested using five different indicators. Little significant variation between nudists and non-nudists within French and German settings is found in their patterns of interactional spacing, while more significant main effects for differences of cultures are found regardless of nudity status. As a subculture, nudists would appear to differ from nonnudists only in their propensity to like to sunbathe in the nude. Their nude status would appear to have none of the de-inhibiting effects often attributed to nudism. By contrast, clear cultural differences between German and French cultures are shown consistent with Hall's high-low context distinction and the Francoeur's hot-cool sexuality continuum.\n\nAt naturist organised events or venues clothing is usually optional, except by swimming pools or sunbathing lawns where complete nudity is expected, weather permitting. This rule is sometimes a source of controversy among some naturists. Staff at a naturist facility are usually required to be clothed due to health and safety regulations.\n\nFacilities for naturists are classified in various ways. A landed or members' naturist club is one that owns its own facilities, while non-landed (or travel) clubs meet at various locations, such as private residences, swimming pools, hot springs, landed clubs and resorts, and rented facilities. Landed clubs can be run by members on democratic lines or by one or more owners who make the rules. In either case, they can determine membership criteria and the obligations of members. This usually involves sharing work necessary to maintain or develop the site.\n\nSome clubs have stricter entrance requirements than some traditional 'country clubs', including the requirement to supply references, a sponsoring member, a trial membership, committee approval or, criminal background checks. UK clubs are now required to have child-protection policies in place, and designated child-protection officers. Many clubs promote frequent social activities.\n\nThe international naturist organizations were mainly composed of representatives of landed clubs. Nudist colony is no longer a favored term, but it is used by naturists as a term of derision for landed clubs that have rigid non-inclusive membership criteria, and in meta-data on naturist websites.\n\nA holiday centre is a facility that specializes in providing apartments, chalets and camping pitches for visiting holidaymakers. The center is run commercially, and visitors are not members and have no say in the management. Most holiday centers expect visitors to hold an INF card, that is, be a member of their national organization, but some have relaxed this restriction, relying on the carrying of a trade card. Holiday centers can be quite small, just a couple of hectares or large occupying over 300 hectares. In a large holiday centre there will be swimming pools, sports pitches, an entertainment program, kids' clubs, restaurants and supermarkets. Some holiday centres allow regular visitors to purchase their own chalets, and generations of the same families will visit each year. Holiday centres are more tolerant of clothing than members-only clubs; total nudity is usually compulsory in the swimming pools and may be expected on the beaches, while on the football pitches, or in the restaurants in the evening, it is rare.\n\nA naturist resort is, to a European, an essentially urban development where naturism is the norm. Cap d'Agde in France, naturist village Charco del Palo on Lanzarote, Canary Islands, Vera Playa in Spain and Vritomartis in Greece are examples. Some residents use these resorts as a year-round home.\n\nIn US usage, a naturist resort can mean a holiday centre.\n\nFreikörperkultur (FKK) literally translated as 'free body culture' is the name for the general movement in Germany. The abbreviation is widely recognised all over Europe and often found on informal signs indicating the direction to a remote naturist beach.\n\nClothing is optional at nude beaches (or \"free beaches\"). A feature of bathing on a nude beach is the anonymity it offers, with membership of a club not being required, nor detailed application processes, nor pre-booking of visits.\n\nIn some European countries, such as Denmark, all beaches are clothing optional, while in others like Germany and experimentally in France, there are naturist sunbathing areas in public parks, e.g., in Munich and Berlin. Beaches in some holiday destinations, such as Crete, are also clothing-optional, except some central urban beaches. There are two centrally located clothes-optional beaches in Barcelona.\n\nNaturism encourages a healthy life style, and many naturist clubs at times organize and encourage members to take part in local and international sport events and competitions. The German Association for Free Body Culture (DFK) promotes recreational sports and is a member of the German Olympic Sport Federation (DOSB).\n\nFrom Woodstock to Edinburgh, and Nambassa in the southern hemisphere communal nudity is commonly recorded at music and counterculture festivals.\n\nThe series of 1970s Nambassa hippie festivals held in New Zealand is a further example of non-sexualized naturism. Of the 75,000 patrons who attended the 1979 Nambassa 3 day counterculture Festival an estimated 35% of festival attendees spontaneously chose to remove their clothing, preferring complete or partial nudity.'\n\nRoskilde festival in Denmark hosts a naked run, that has become one of the most popular events there.\n\nPerhaps nowadays the biggest and most famous festival where participants spontaneously decide to go naked or take part in nude events is Burning Man: it's got its own naked bike ride aka 'Naked Pub Crawl', and a few camps organize activities in the nude, including the famous oil wrestling by camp Gymnasium.\nFlorida Young Naturists has organized seasonal \"Bashes\" hosted by several Florida nudist/naturist clubs and resorts since 2008.\n\nOrganized by the Federación Nudista de México (Mexican Nudist Federation) since 2016 when Zipolite beach nudity was legalized, FESTIVAL NUDISTA ZIPOLITE occurs annually on the first weekend of February.\n\nNudist festivals are also held to celebrate particular days of the year, and in many such events nude bodypainting is also common, such as Neptune Day Festival held in Koktebel, Crimea to depict mythological events; the Solstice Cyclists nudist events celebrating the summer solstice held in Fremont, Seattle, United States; the Naked Pumpkin Run held in US to celebrate Halloween; and the World Naked Gardening Day held to celebrate gardening.\nThe prevalence of naturism tends to increase during the summer months especially when the temperature is higher with some regions experiencing first-time naturists and people who have transitioned to becoming a naturist. Some studies have observed that among some of these naturists, they are clothed during other seasons, thus making them seasonal naturists. This quiddity has caught the public perception and comprehension of public nudity, and thus it is frequently equated with summer destinations such as beaches.\n\nNudity in social contexts has been practised in various forms by many cultures at all time periods. In Western society nowadays, social nudity is most frequently encountered in the contexts of bathing, swimming and in saunas, whether in single-sex groups, within the family or with mixed-sex friends, but throughout history and in many tropical cultures until now, nudity is a norm at many sports events and competitions.\n\nIt is difficult to nominate exactly when naturism started as a movement. The word 'naturism' was used for the first time in 1778 by a French-speaking Belgian, Jean Baptiste Luc Planchon (1734–1781), and was advocated as a means of improving the \"hygiène de vie\" or healthy living.\n\nThe earliest known naturist club in the \"western\" sense of the word was established in British India in 1891. The 'Fellowship of the Naked Trust' was founded by Charles Edward Gordon Crawford, a widower, who was a District and Sessions Judge for the Bombay Civil Service. The commune was based in Matheran and had just three members at the beginning; Crawford and two sons of an Anglican missionary, Andrew and Kellogg Calderwood.\nThe commune fell apart when Crawford was transferred to Ratnagiri; he died soon after in 1894.\n\nIn 1902, a series of philosophical papers was published in Germany by Dr. Heinrich Pudor, under the pseudonym Heinrich Scham, who coined the term \"Nacktkultur\". In 1906 he went on to write a three volume treatise with his new term as its title, which discussed the benefits of nudity in co-education and advocated participating in sports while being free of cumbersome clothing. Richard Ungewitter (\"Nacktheit\", 1906, \"Nackt\", 1908, etc.) proposed that combining physical fitness, sunlight, and fresh air bathing, and then adding the nudist philosophy, contributed to mental and psychological fitness, good health, and an improved moral-life view. Major promoters of these ideas included Adolf Koch and Hans Suren. Germany published the first journal of nudism between 1902 and 1932.\n\nThe wide publication of those papers and others, contributed to an explosive worldwide growth of nudism, in which nudists participated in various social, recreational, and physical fitness activities in the nude. The first organized club for nudists on a large scale, \"Freilichtpark\" (Free-Light Park), was opened near Hamburg in 1903 by Paul Zimmerman.\nIn 1919, German doctor Kurt Huldschinsky discovered that exposure to sunlight helped to cure rickets in many children, causing sunlight to be associated with improved health.\n\nIn France in the early 20th century, the brothers Gaston and André Durville, both of them physicians, studied the effects of psychology, nutrition, and environment on health and healing. They became convinced of the importance of natural foods and the natural environment on human well-being and health. They named this concept . The profound effect of clean air and sunlight on human bodies became evident to them and so nudity became a part of their naturism.\n\nNaturism became a more widespread phenomenon in the 1920s, in Germany, the United Kingdom, France and other European countries and spread to the United States where it became established in the 1930s.\n\nBy 1951, the national federations united to form the International Naturist Federation or INF. Some naturists preferred not to join clubs, and after 1945, pressure was put to designate beaches for naturist use.\nFrom the middle of the 20th century, with changing leisure patterns, commercial organisations began opening holiday resorts to attract naturists who expected the same – or better – standards of comfort and amenity offered to non-naturists. More recently, naturist holiday options have expanded to include cruises.\n\nNaturism had many different philosophical sources and means many things to different people. There is no one definition. In 1974, the INF defined naturism as:\n\nAt one end of the spectrum are the nudists who just enjoy a nude life style, and at the other are the naturists, who have deeply held beliefs and see communal nudity as just one of many important principles.\n\nThe naturist philosophy has several sources, many of which can be traced back to early 20th century health and fitness philosophies in Germany and England, although the concepts of returning to nature and creating equality have much deeper roots.\n\nIn the 4th century BC, Alexander the Great encountered, in India, wandering groups of naked holy men whom he dubbed the \"naked philosophers\". (\"Gr \"gymnos\": naked; \"sophist\": knowledge\"). The philosopher Onesicritus investigated their beliefs and lifestyle. Pyrrho the Sceptic was impressed and incorporated nudity into his philosophy. The Gymnosophists were Hindus, but Jain and Ajivika monks practiced nudity as a statement that they had given up all worldly goods. Nudity was not a new concept to the Greeks as the Olympic Games (founded in 776 BC) were exclusively male and nude events. \n\nHistorically, the Adamites, a Gnostic sect, practiced religious nudism.\nA religious sect in Canada that immigrated from Russia, the Sons of Freedom, went so far in the 1900s (1903-1950s) as to publicly strip in mass public demonstrations to protest against government policies which were meant to assimilate them. Today, Christian naturism contains various members associated with most denominations. Although beliefs vary, a common theme is that much of Christianity has misinterpreted the events regarding the Garden of Eden, and God was displeased with Adam and Eve for covering their bodies with fig leaves.\n\nThe first English naturists adopted the name Gymnosophy as a thinly disguised euphemism for their pastime. The English Gymnosophical Society was formed in 1922 and became the New Gymnosophy Society in 1926; they purchased land at 'Bricketts Wood' to become Britain's first nudist colony. One of the first members was Gerald Gardner, who in 1945 established the 'Five Acres Club' nearby, ostensibly as a nudist club, but as a front for Wiccans, as witchcraft was illegal in England until 1951.\n\nThe Digambar, one of the two main divisions of the Jain religion of India, remain skyclad, or naked, though generally it is practiced by males. Digambar means 'clothed with the sky'. Wiccans have adopted this wording and some practice their rituals skyclad.\n\n\nIndividuals have formed naturist groups for a variety of specific purposes. It is generally agreed by naturist organisations that eroticism and blatant sexuality have no place in naturism and are, in fact, antithetical to its ideals. Reasons that have at times been given:\n\n\nWalt Whitman American writer, A Sun-bathed Nakedness:\n\nHenry David Thoreau, \"In wildness is the preservation of the world.\", Walking:\n\nNaturism was part of a literary movement in the late 1800s (see the writings of André Gide) which also influenced the art movements of the time specifically Henri Matisse and other Fauve painters. This movement was based on the French concept of \"joie de vivre\", the idea of reveling freely in physical sensations and direct experiences and a spontaneous approach to life.\n\nSunlight has been shown to be beneficial in some skin conditions and enables the body to make vitamin D, but with the increased awareness of skin cancer, wearing of sunscreen is now part of the culture. Sun exposure prompts the body to produce nitric oxide that helps support the cardiovascular system and the feelgood brain-chemical serotonin.\n\nThere are also documented psychological benefits of naturist activities including greater life satisfaction, more positive body image, and higher self-esteem.\n\nThe World Naked Bike Ride (WNBR) is an international clothing-optional bike ride and exercise in public nudity, that has developed outside the organised naturism movement. Participants plan, meet and ride together \"en masse\" on human-powered transport (the vast majority on bicycles, but some on skateboards and inline skates), to \"deliver a vision of a cleaner, safer, body-positive world.\" The WNBR shares some aspects of the philosophy of naturism in that it promotes a return to healthy exercise in unpolluted air at the same time promoting positive body image.\n\n\n\nIn Finnish culture, nudism is considered to be a relatively normal way to live. It is not uncommon to see entire families spending time together naked. Families may be naked while bathing in a sauna, swimming in a pool, or playing on a beach, and it's not unusual to see children playing naked in a kindergarten or family yard for example. Nudity as a whole is considered less taboo than many other countries.\n\nIn 1903 la \"Revue des deux mondes\" published a report on German naturism and S. Gay created a naturist community at Bois-Fourgon. In 1907, supported by his superiors, Abbé Legrée encouraged the students at his Catholic college to bathe nude on the rocky beaches near Marseille.\n\nMarcel Kienné de Mongeot is credited with starting naturism in France in 1920. His family had suffered from tuberculosis, and he saw naturism as a cure and a continuation of the traditions of the ancient Greeks. In 1926, he started the magazine \"Vivre intégralement\" (later called \"Vivre\") and the first French naturist club, \"Sparta Club\" at Garambouville, near Evreux. The court action that he initiated, established that nudism was legal on private property that was fenced and screened.\n\nDrs. André and Gaston Durville bought a 70 hectare site on the Île du Levant where they established the village of Héliopolis. The village was open to the public. In 1925 Dr François Fougerat de David de Lastours wrote a thesis on heliotherapy. and in that year opened the \"Club gymnique de France\". In 1936, the naturist movement was officially recognised.\n\nAlbert and Christine Lecocq were active members of many of these clubs, but after disagreements left and In 1944 Albert and Christine Lecocq founded the \"Club du Soleil\" with members in 84 cities. In 1948 they founded the , in 1949 they started the magazine, \"Vie au Soleil\" and in 1950 opened the CHM Montalivet, the world's first naturist holiday centre where the INF was formed.\n\nThe naturist village Leucate and Cap d'Agde offers a different form of social nudity. Euronat is the largest holiday centre (335ha) situated 10 km north of Montalivet. Naturism employs more than 3000 people, and is estimated to be worth 250 million Euro to the French economy. France is represented on the INF by the .\n\nGerman naturism was part of the Lebensreform movement and the Wandervogel youth movement of 1896, from Steglitz, Berlin which promoted ideas of fitness and vigour. At the same time doctors of the were using heliotherapy, treating diseases such as TB, rheumatism and scrofula with exposure to sunlight.\n\nNacktkultur, a term coined in 1903 by Heinrich Pudor, flourished. Nacktkultur connected nudity, vegetarianism and social reform. It was practised in a network of 200 members clubs. The movement gained prominence in the 1920s as offering a health giving life-style with Utopian ideals. Germany published the first naturist journal between 1902 and 1932.\nIt became politicised by radical socialists who believed it would lead to classlessness and a breaking down of society. It became associated with pacificism.\n\nIn 1926, Adolf Koch established a school of naturism in Berlin; encouraging a mixing of the sexes, open air exercises, and a programme of \"sexual hygiene\". In 1929, the Berlin school hosted the first International Congress on Nudity.\n\nDuring the National Socialist \"Gleichschaltung\" era, all naturist clubs had to register with the \"Reichsbund für Leibesübungen\", which meant excluding Jews and Communists. Also, they had to keep all activities hidden in the countryside where there was little chance of being seen by others. The status as a West German \"sports federation\" member gave the clubs rights and privileges (e.g. tax exemptions) so the naturist clubs remained in the federation after the war had ended.\n\nAfter the war, East Germans were free to practice naturism, chiefly at beaches rather than clubs (private organizations being regarded as potentially subversive). Naturism became a large element in DDR politics. The \"Proletarische Freikörperkulturbewegung\" subsection of the Workers Sports Organisation had 60,000 members.\nToday, following reunification there are many clubs, parks and beaches open to naturists.\nthough nudity has become less common in the former eastern zone. Germans are typically the most commonly seen foreigners at nude beaches in France and around Europe.\n\nPublic nudity is prohibited in Greece and there are no official nude beaches. There are, however, numerous unofficial nude beaches especially on the islands frequented by tourists, like Crete, Mykonos or Karpathos but also on smaller islands like Skopelos or Skiathos where nudity is tolerated, usually at the more remote ends or secluded areas of beaches.\n\nPublic nudity is prohibited in Italy and can be punished with high fines, but in the recent decade, a few regions have created naturism laws to help the tourism industry. There are only a few permitted nude beaches in those regions, where nudity is allowed without risking legal consequences. On all other public beaches in Italy as well as normally tolerated nude beaches, police can potentially impose substantial fines.\n\nFirst reported naturist society was established in 1897 in Grudziądz. In pre-war and post-war Poland, naturism was practised in closed and secluded areas. Reported places for naturism were Zaleszczyki (in today's Ukraine) and Otwock. Under the communism regime, Poland's naturism became unofficial and was practiced mostly by the artistic boheme near Krynica Morska, Misdroy and Dębki.\n\nIn the early 1980s naturism became popular mostly due to increased interest in media. As the pop song \"Chałupy Welcome To\" (about the naturist beach in Chałupy, featuring beach nudity in the clip) became the 1985 summer hit in Poland, the nude seaside locations like Chałupy or Rowy became known to an average Polish sunbather. Polish Naturist Society was formed and after the number of lawsuits, naturism became tolerated in selected \"unofficial\" beaches and distant spots.\n\nIn today's Poland naturism is practiced in number of the seaside and inland beaches. Most Polish beaches are actually clothes-optional rather than naturist. Among the most popular locations are Misdroy-Lubiewo, Grzybowo, Rowy, Dębki, Gdańsk-Stogi and Piaski. The most popular inland locations include Warsaw (Wał Miedzeszyński), Kazimierz Dolny and Kryspinów near Kraków. In the winter season, naturism is practiced by organized groups in Warsaw and Tri-City. Public naturist events are held bi-monthly in Poznań-Koziegłowy and Łódź waterpark.\n\nNaturism in Portugal had its first historical record around 1920, linked to the Portuguese Naturist Society, of which the anarcho-syndicalist José Peralta was a prominent member. Nudity was already being practiced on Costa da Caparica beaches. With the beginning of the New State authoritarian regime in the 1930s, the naturist movement was limited to vegetarian and alternative medicines, since nudity was banned and associated to the crime of \"indecency\". Only after the end of the New State regime in 1974 (April, 25th) the activities linked to the practice of nudity were resumed.\n\nThe \"Federação Portuguesa de Naturismo\" (Portuguese Naturist Federation) or FPN was founded on the March 1st, 1977, at a meeting in Lisbon.\n\nAt the present, there are seven official naturist beaches in Portugal. Besides these, there are several dozens of beaches were the practice of naturism is common. There are also several naturist campings and resorts.\n\nBeginnings of naturism in Slovenia started in the year 1852, when a 29 year old Swiss physician Arnold Rikli visited Bled for the first time. In the following years he started to promote healthy way of living, because he considered water, air and light to be the source for his healing therapy. He continued to build spa centers which included light therapy and hydrotherapy treatment. His first visitors were most likely pilgrims from Slovenia and Friuli-Venezia Giulia region who visited the church on Bled island. When the word has spread across Europe, other visitors started visiting Bled known for Rikli's healing therapy. A method used in the healing therapy process included sunbathing and visitors were often seen walking nude in public. Rikli continued to promote his healing tourism for the next 52 years, when he lived in Bled.\n\nPublic nudity in Spain is not illegal since there is no law banning its practice. Spanish legislation foresees felony for exhibitionism but restricts its scope to obscene exposure in front of children or mentally impaired individuals, i.e. with sexual connotation. However, people do not normally use this right to be naked to do it anywhere, and most usually perform this activity in places where nudism is a tradition.\n\nThere are however some municipalities (like San Pedro del Pinatar) where public nudity has been regulated (banned) by means of by-laws. Other municipalities (like Barcelona, Salou, Platja de Palma and Sant Antoni de Portmany) have also used these provisions to regulate the practice of semi-nudism, forcing people to cover their torso on the streets. Some naturist associations have appealed these by-laws on the grounds that a fundamental right (freedom of expression, as they understand that nudism is a way of self-expression) cannot be regulated with this mechanism. Some judicial instances have ruled in favour of nudist associations.\n\nNudism in Spain is normally practised by the seaside, on beaches or small coves with a tradition on naturism. In Vera (Andalusia), there is a wide residential area formed by nudist urbanisations that constitute some kind of nudist town. Nudist organisations may organise some activities elsewhere in inner territory (like hiking on the mountains close to Madrid), but these kind of activities are negligible. Madrid municipality enables nudist use of some of their public swimming pools one day during summer.\n\nTextile use of traditionally nudist public spaces (like beaches or streets nearby) is allowed, mainly due to lack of regulation. Mixed groups of nudist and textile individuals are frequent in these kind of spaces. In order to chase voyeuristic persons away, nudist people will normally clap their hands.\n\nLegal aspects regarding topless are analogue to those regarding nudism, but social tolerance towards topless is higher. This let people not cover their breasts in public swimming pools and on any beach in Spain.\n\nIn the United Kingdom, the first official nudist club was established in Wickford, Essex in 1924. According to Michael Farrar, writing for British Naturism the club adopted the name \"Moonella Group\" from the name of the owner of the ground, \"Moonella\", and called its site The Camp. Moonella, who was still living in 1965 but whose identity remains to be discovered, had inherited a house with land in 1923 and made it available to certain members of the New Gymnosophy Society. This society had been founded a few years before by H.C. Booth, M.H. Sorensen and Rex Wellbye under the name of the English Gymnosophical Society. It met for discussions at the Minerva Cafe at 144 High Holborn in London, the headquarters of the Women's Freedom League. Those who were permitted to join the Moonella Group were carefully selected, and the club was run by an \"aristocracy\" of the original members, all of whom had \"club names\" to preserve their anonymity. The club closed in 1926 because of building on adjacent land.\nBy 1943 there were a number of these so-called \"sun clubs\" and together they formed the British Sun Bathers Association or BSBA. In 1954 a group of clubs unhappy with the way the BSBA was being run split off to form the Federation of British Sun Clubs or FBSC. In 1961, the BSBA Annual Conference agreed that the term nudist was inappropriate and should be discarded in favour of naturist. The two organisations rivalled each other before eventually coming together again in 1964 as the Central Council for British Naturism or CCBN. This organisation structure has remained much the same but it is now called British Naturism which is often abbreviated to BN. BN is currently a company limited by guarantee.\n\nThe first official nude beach was opened at Fairlight Glen in Covehurst Bay near Hastings in 1978 (not to be confused with Fairlight Cove, which is 2 km to the east) followed later by the beaches at Brighton and Fraisthorpe. Bridlington opened in April 1980.\n\nIn Canada, individuals around the country became interested in nudism, skinny-dipping, and physical culture in the early part of the 20th century. After 1940 they had their own Canadian magazine, \"Sunbathing & Health\", which occasionally carried local news. Canadians had scattered groups in several cities during the 1930s and 1940s, and some of these groups attracted enough interest to form clubs on private land. The most significant clubs were the Van Tan Club, formed in 1939, and continues today in North Vancouver, BC., and, in Ontario, the Sun Air Club.\n\nCanadians who served in the military during the Second World War met like-minded souls from across the country, and often visited clubs while in Europe. They were a ready pool of recruits for post-war organizers. A few years later, the wave of post-war immigration brought many Europeans with their own extensive experience, and they not only swelled the ranks of membership, but often formed their own clubs, helping to expand nudism from coast to coast.\n\nMost of those clubs united in the Canadian Sunbathing Association, which affiliated with the American Sunbathing Association in 1954. Several disagreements between eastern and western members of the CSA resulted in the breakup of CSA into the Western Canadian Sunbathing Association (WCSA) and the Eastern Canadian Sunbathing Association (ECSA) in 1960. The ECSA endured much in-fighting over the next decade and a half, leading to its official demise in 1978. The WCSA continues today as the American Association for Nude Recreation – Western Canadian Region (www.aanr-wc.com), a region of the American Association for Nude Recreation (AANR) which itself was formerly known as the ASA.\n\nIn 1977 the Fédération québécoise de naturisme (FQN) was founded in Quebec, by Michel Vaïs, who had experienced European naturism at Montalivet. In 1985 the Federation of Canadian Naturists (FCN) was formed with the support of the FQN. In 1988 the FQN and FCN formed the FQN-FCN Union as the official Canadian representative in the International Naturist Federation (INF).\n\nIn 1925, Katherine and Herman Shoshinki were familiar with nudism from Germany from 1918 to 1923. Kurt Barthel founded the American League for Physical Culture in 1929 and organized the first nudist event. In about 1930 they organized the American Gymnosophical Association. Barthel founded America's first official nudist camp, Sky Farm in New Jersey, in May, 1932. Around 1932, AGA established the Rock Lodge Club as a nudist facility in Stockholm, New Jersey and Ilsley Boone, a Dutch Reformed minister, formed the Christian naturism movement. Naturism began expanding nationwide. Nudism venues were teetotal until 1970,\n\nThe American Association for Nude Recreation (AANR) is the national naturist organization. Arnd Krüger compared nudists in Germany and the United States and came to the conclusion that in Germany the racial aspects (\"Zuchtwahl\") were important for the breakthrough (e.g. the Commanding General of the Army served as patron for nudists events), while in the U.S. nudism was far more commercial and had thus more difficulties. The AANR withdrew from the INF in 2010.\n\nIn 2008, a young adults group organized as Florida Young Naturists held their first Naked Bash which has since been repeated 3-4 times a year, growing into one of the largest young naturist gatherings in the world.\n\nIn 2009, a campaign to promote Nudism in the United States occurred with an effort by AANR to record the largest simultaneous Skinny Dip at several U.S. Clubs and beaches, occurring on July 11 of that year.\n\nIn 2010, A new organization formed called Young Naturists and Nudists America which was mostly focused around the younger generation as well as social issues, such as body image. Young Naturists and Nudists America closed in 2017.\n\nIn 2014, an organization called Unconstitutional Arkansas was created to highlight the unconstitutionality of laws that prohibit or impede nudism. The organization uses Arkansas law § 5-68-204 as a case study, but claims all anti-nudism laws infringe the constitutional right to assemble.\n\nBeach nudity in Playa Zipolite is legal. Elsewhere, Mexican law condemns only \"immorality\" and thus the issue ends up being a matter of the judge's discretion. Private libertine or lifestyle type resorts exist in Mexico that might not be characterized as naturist (see List of social nudity places in North America#Mexico).\n\nAs of 2016, Playa Zipolite is Mexico's first and only legal public nude beach. A \"free beach\" and unofficially nudist for more than 30 years, this beach is reputed to be the best place for nudism in the country. The numerous nudists, and the long tradition, make it safe for nudism and naturism. Annually since 2016, on the first weekend of February, Zipolite has hosted Festival Nudista Zipolite organized by the Federación Nudista de México.\n\nHotel Nude is Zipolite's first nude-optional resort/hotel. Intima Resort is another clothing optional resort in Tulum, Mexico.\n\nGenerally, public nudity in Asia is not tolerated. However, some traditional, religious or cultural nudity has survived the introduction of Western moral values against nudity, such as the Jain Digambara monks in India, hot springs in Taiwan and Japan, and some traditional tribes in Papua. Nudism and naked recreation is slowly developing in some countries, mainly Indonesia (Bali) and Thailand. Nudists meet on the internet (e.g. Bareskinasia.com) and organize activities in remote or private locations. Several nudists also have their own blogs.\n\nIn the seventies, nudity on Bali's remote and deserted beaches was common but with the massive growth of tourism, this practice has disappeared. In 2002, nudity was declared illegal on Petitenget Beach, the last beach in Seminyak that tolerated discreet nudity. Individuals began to practice nudity in private villas and resorts. Laki Uma Villa, the first naturist facility to open, was for gay men only. Bali au Naturel, the first adult-only nudist resort for both genders, opened its doors in 2004. It subsequently expanded from 3 to 15 rooms and added from two more swimming pools.\n\nNudism is considered taboo in Nepal. Although there are no laws governing nudism, people may be detained, arrested and fined for public nudity. Nevertheless, many Hindu male sages practice nudism and they are not legally detained. Nudist sages can be seen in Pashupatinath.\n\nNudism was successfully introduced 10 years ago in Pattaya (Chan Resort), and six more nudist resorts have been created all over Thailand. Barefeet Resort in Bangkok, Lemon Tree in Phuket, Oriental Village in Chiangmai, Phuan Naturist Village in Huay Yai, and Family Naturist Camp in Petchaburi all belong to the Naturist Association of Thailand as well as other international naturist organizations. A gay hotel and sauna (Sansuk Hotel) located in Pattaya now also authorizes nudity in and around the swimming pool.\n\nNaturism addresses, challenges and explores a myriad of sometimes taboo subjects: stereotypes and mores relating to the nude appearance of the human body, mixed sex nudity, personal space, human sexuality, gymnophobia, modesty, physical attractiveness, vanity, objectification, exploitation and consent. It can thus be controversial. Descamps assembled a list of criticisms of naturism: it is too cold; normal bodies look ugly—it is only for the physically beautiful; it is too embarrassing; it is against the laws of nature, against the law, or against religion; \"nudism makes me think of sex\"; it is for primitive people or animals.\n\nNaturism can sometimes contain aspects of eroticism, although the debate about this is often simplified and seen negatively in the media and the public mind and by many modern naturists and naturist organisations. Historically the experience and discussion of erotic feelings during naturist activities such as dance and gymnastics played an important part in early Germanic naturism and formed part of its 'positive' connection with nature. However, it was when naturism arrived in the more sexually conservative cultures of the UK and the United States that the expression and discussion of eroticism within naturism became frowned upon.\n\nSmith states This statement is in response to the quote \"The world of naturism is in trouble. Membership is falling, and fewer young people than ever are getting involved. Has the great nude adventure run its course? \"\n\nSmith and King pose the further points in their 2009 peer reviewed paper \"Naturism and Sexuality:broadening our approach to sexual wellbeing \"\n\nMany countries and states have laws which adversely affect naturists. Oftentimes, these laws are intended to address \"indecent exposure\", but are so broadly written that they criminalize ordinary, non-sexual nudity. Some laws, however, specifically target naturism. For example, in Arkansas in the United States, not only is nudism illegal (even on private property), it is a crime to \"promote\" or \"advocate\" (i.e. express a favourable opinion about) nudism.\n\nAny social group is said to go through four phases:\nforming, storming, norming, performing, wrote Bruce Tuckman in 1965. In this context one can understand some of the current pressures on various aspects of naturism:\n\n\nMagazines published by, for or purportedly about naturists can be grouped:\n\n\nMagazines in the second and, occasionally, third grouping feature naturist editorial and advertising, while some naturists argue over which magazines belonged in which of these categories – these views may change as publishers and editors change. Many clubs and groups have benefitted from magazines which, while not exclusively or even predominantly naturist in character, made naturist information available to many who would not otherwise have been aware of it. (These days, the information and advertising provided online, and the wide availability of free online porn, has meant the disappearance of old-style 'skin' magazines presenting significant glamour content masquerading as or alongside naturist content. Naturist magazines have to appeal strongly to naturists to succeed – they cannot sit on the fence between naturism and glamour.)\nSome naturists still feel that the worthwhile editorial content in some magazines is not a fair balance for the disapproved-of photographic content.\n\nSome naturist clubs have been willing to allow filming by the media on their grounds, though content that proved not to be of genuine naturism can end up being parodied by the media as the norm.\n\nSome commercial 'naturist' DVDs are dominated by imagery of naked children. Such material can be marketed in ways that appear to appeal directly to paedophile inclinations, and ownership of these DVDs (and their earlier video cassette incarnations) has resulted in successful British prosecutions for possession of indecent images of children. One case was appealed, unsuccessfully, to the European Court of Human Rights. The precedents set by the court cases mean that possession in Britain of any naturist image of a child is, potentially, grounds for prosecution.\n\nPhoto shoots, including major high-profile works by Spencer Tunick, are done on public places including beaches.\n\n\n\n\n\n\n"}
{"id": "5481226", "url": "https://en.wikipedia.org/wiki?curid=5481226", "title": "Onion diagram", "text": "Onion diagram\n\nAn onion diagram is a kind of chart that shows the dependencies among parts of an organization or process. The chart displays items in concentric circles, where the items in each ring depend on the items in the smaller rings.\n\nThe onion diagram is able to show layers of a complete system in a few circles. Each of the circles is able to represent a component that is dependent upon the component on the inside of it shown by the circle inside of it. The main concept of the diagram is shown by the center circle of the diagram. This chart is used due to the fact that it has a clear visual representation that is easy to read, and it has a strong visual impact.\n\nThere is also the cultural onion which has seven layers to it including artifacts, behaviors, feelings, values, beliefs, worldview and ultimate allegiance. These layers organize a person's reality and life. The outer most layers are the most accessible while the in-depth ones are only accessible with connections to the person. The seven layers are integrated into three structural levels, which are the foundational, the evaluating, and the actualizing level.\n\n\nMicrosoft Visio has built-in support for onion diagrams.\n"}
{"id": "2304753", "url": "https://en.wikipedia.org/wiki?curid=2304753", "title": "Psychological punishment", "text": "Psychological punishment\n\nA psychological punishment is a type of punishment that relies not or only in secondary order on the actual harm inflicted (such as corporal punishments or fines) but on psychological effects, mainly emotions, such as fear, shame and guilt. This can occasionally cause severe cardiac harm, even death, but those are not strictly intended, and in the case of torture accidental death would even defeat the purpose. Psychological punishments that are particularly cruel or severe may be considered psychological torture.\n\nVery common is the use of shame through private or, especially, public humiliation.\n\nFor example, publicly shaving a woman’s head may not only humiliate her in front of those who witness her shearing, it may also deprive her of her hair for as long as it takes to grow back, thus serving as a continual reminder of her punishment and her humiliation. \n\n"}
{"id": "15583578", "url": "https://en.wikipedia.org/wiki?curid=15583578", "title": "Pyrolite", "text": "Pyrolite\n\nPyrolite is a theoretical rock considered to be the best approximation of the composition of Earth's upper mantle. The definition varies, but it is generally considered as being 1 part tholeiitic basalt and 3 parts dunite. If fused experimentally, this mix yields high pressure tholeiitic basaltic melts, and intermediate pressure alkaline basalts. The hypothetical pyrolite compositions are not compatible with trace element, isotopic and chondritic abundances data as well as evidence for mantle heterogeneity.\n"}
{"id": "34480174", "url": "https://en.wikipedia.org/wiki?curid=34480174", "title": "Robert Zimmer (philosopher)", "text": "Robert Zimmer (philosopher)\n\nRobert Zimmer (born October 25, 1953 in Trier, Germany) is a German philosopher and essayist who writes biographies and popular introductions to philosophy and to the history of philosophy.\n\nRobert Zimmer was educated at the German universities of Saarbrücken and Düsseldorf and wrote his doctoral dissertation on Edmund Burke. From 1986 - 2013 he lived as a freelance writer and publicist in Berlin. In 2013 he moved to Stuttgart. His most popular book so far has been “Das Philosophenportal”, a collection of 16 essays on 16 different classical works of philosophy, which has been translated into more than a dozen languages (not yet in English). In 2010 he published a biography of Arthur Schopenhauer. He also translated a selection of essays by the 19th Century French critic and writer Charles Augustin Sainte-Beuve.\n\nZimmer is a follower of Critical rationalism. Together with Martin Morgenstern he wrote a short and popular biography of Karl Popper and edited the correspondence between Karl Popper and Hans Albert.\n\n\n"}
{"id": "637475", "url": "https://en.wikipedia.org/wiki?curid=637475", "title": "Rogneda of Polotsk", "text": "Rogneda of Polotsk\n\nRogneda of Polotsk (962–1002) is the Slavic name for Ragnhild, was a Princess consort of Rus. She was the daughter of Ragnvald (Slavic: Rogvolod) came from Scandinavia and established himself at Polatsk in the mid-10th century. \n\nIt has been speculated that Rogneda belonged to the Ynglings royal family of Norway. In or about 980, Vladimir, on learning that she was betrothed to his half-brother Yaropolk I of Kiev, took Polotsk and forced Rogneda to marry him. Having raped Rogneda in the presence of her parents, he ordered them to be killed, along with two of Rogneda's brothers.\n\nRogneda gave him several children. The four sons were Yaroslav the Wise, Vsevolod, Mstislav of Chernigov, and Izyaslav of Polotsk. She also bore two daughters, one of whom is named by Nestor the Chronicler as Predslava (taken as a concubine of Boleslaus I of Poland, according to Gallus). A later chronicle tells a story, most likely taken from a Norse saga, of Rogneda plotting against Vladimir and asking her elder son, Izyaslav, to kill him. As was the Norse royal custom, she was sent with her elder son to govern the land of her parents, i.e. Polotsk. Izyaslav's line continued to rule Polotsk and the newly found town of Izyaslavl until the Mongol invasion.\n\nAfter Vladimir converted to Christianity and took Anna Porphyrogeneta as his wife, he had to divorce all his previous wives, including Rogneda. After that, she entered the convent and took the name Anastasia.\n\nAround 1825 Kondraty Ryleev wrote a narrative poem entitled \"Rogneda\". This poem became a literary source for her portrayal in the nationalist Russian opera \"Rogneda\" by Alexander Serov, which premiered in 1865.\n\n"}
{"id": "1826989", "url": "https://en.wikipedia.org/wiki?curid=1826989", "title": "Self-healing", "text": "Self-healing\n\nSelf-healing refers to the process of recovery (generally from psychological disturbances, trauma, etc.), motivated by and directed by the patient, guided often only by instinct. Such a process encounters mixed fortunes due to its amateur nature, although self-motivation is a major asset. The value of self-healing lies in its ability to be tailored to the unique experience and requirements of the individual. The process can be helped and accelerated with introspection techniques such as Meditation. \n\nHistorically, communities of Color in the United States and around the World have attempted to use different modes (i.e. scholarship, art, and community gathering) to create self-healing as a way to combat the daily trauma of living in a racialized society.\n\nFrantz Fanon wrote about the subjectivity and objectivity paradox inherent in Blackness in his book Black Skin, White Masks. He describes feeling \"infinite\" but being subjected to the standards reserved for someone who is crippled. At the end of the fifth chapter, he writes that he weeps at the \"crossroads between Nothingness and Infinity.\" His scholarship is meant to provide a lesson to White readers: Black people are also human beings. However, his intention in writing the fifth chapter was no doubt a hope to heal himself in offering up his struggle so that those who mistreated him and his people could reach a place of understanding. In sharing his personal trauma, he offered a way for Black people to connect over shared struggle and commiserate, but also brought his plight to the attentions of a White audience, who, if they could empathize, could lighten the racial load of the Black people around them and could hopefully, someday, ease Fanon's own mental load.\n\nLangston Hughes is an example of how Black people have used art to self-heal from racial trauma. His poem, \"Theme for English B\" details his struggle with completing a writing assignment about truth for a class. He is only able to complete the assignment when he acknowledges the stratified differences between him, his other classmates, and his professor. As he writes, \"I am the only colored student in my class.\" His poem is a way to package his trauma so that he can use it for something constructive in the hopes that it will ultimately heal some of his pain.\n\nHarriet's Apothecary is a NYC-based organization that seeks to create self-healing for communities of color through different healing based events. Their work takes place across the US. They host vendors, and offer reiki-healing, massages, food, and yoga among many other different \"stations\" as a way to combat racial trauma. They do community building work to address poverty (because racism in the United States has left communities of color in disproportionate levels of poverty compared to their White counterparts). To gain entrance to most, if not all of their events, their policy is pay-what-you-can.\n\nSelf-healing is the ultimate phase of Gestalt Therapy.\n\nSelf-healing may refer to automatic, homeostatic processes of the body that are controlled by physiological mechanisms inherent in the organism. Disorders of the spirit and the absence of faith can be self-healed.\n\nIn a figurative sense, self-healing properties can be ascribed to systems or processes, which by nature or design tend to correct any disturbances brought into them. Such as the regeneration of the skin after a cut or scrape, or of an entire limb. The injured party (the living body) repairs the damaged part by itself.\n\nBeyond the innate restorative capacities of the physical body, there are many factors of psychological nature that can influence self-healing. Hippocrates, considered by many to be the father of medical treatment, observed: \"The physician must be ready, not only to do his duty himself, but also to secure the co-operation of the patient, of the attendants and of externals.\"\n— Hippocrates.\n\nSelf-healing may also be achieved through deliberately applied psychological mechanisms. These approaches may improve the psychological and physical conditions of a person. Research confirms that this can be achieved through numerous mechanisms, including relaxation, breathing exercises, fitness exercises, imagery, Meditation, Yoga, qigong, t'ai chi, biofeedback, and various forms of psychotherapy, among other approaches.\n\nVarieties of mechanisms for self-healing have been proposed, including:\n\n\nAnother phrase that often includes self-healing is self-help. In 2013 Kathryn Schulz examined it as \"an $11 billion industry\".\n\nTwelve-step programs support individuals recovering from dysfunctional families and addictive/compulsive behaviors.\n\n"}
{"id": "41207422", "url": "https://en.wikipedia.org/wiki?curid=41207422", "title": "Social equality", "text": "Social equality\n\nSocial equality is a state of affairs in which all people within a specific society or isolated group have the same status in certain respects, including civil rights, freedom of speech, property rights and equal access to certain social goods and services. However, it also includes concepts of health equality, economic equality and other social securities. It also includes equal opportunities and obligations, and so involves the whole of society. Social equality requires the absence of legally enforced social class or caste boundaries and the absence of discrimination motivated by an inalienable part of a person's identity. For example, sex, gender, race, age, sexual orientation, origin, caste or class, income or property, language, religion, convictions, opinions, health or disability must absolutely not result in unequal treatment under the law and should not reduce opportunities unjustifiably.\n\n\"Equal opportunities\" is interpreted as being judged by ability, which is compatible with a free-market economy. Relevant problems are horizontal inequality − the inequality of two persons of \"same\" origin and ability and differing opportunities given to individuals − such as in (education) or by inherited capital.\n\nConceivements of social equality may vary per philosophy and individual and other than egalitarianism it does not necessarily require all social inequalities to be eliminated by artificial means but instead often recognizes and respects natural differences between people.\n\nThe standard of equality that states everyone is created equal at birth is called ontological equality. This type of equality can be seen in many different places like the Declaration of Independence. This early document, which states many of the values of the United States of America, has this idea of equality embedded in it. It clearly states that \"all men are created equal, that they are endowed by their Creator with certain unalienable Rights\". The statement reflects the philosophy of John Locke and his idea that we are all equal in certain natural rights. Although this standard of equality is seen in documents as important as the Declaration of Independence, it is \"one not often invoked in policy debates these days\". However this notion of equality is often used to justify inequalities such as material inequality. Dalton Conley claims that ontological equality is used to justify material inequality by putting a spotlight on the fact, legitimated by theology, that \"the distribution of power and resources here on earth does not matter, because all of us are equally children of God and will have to face our maker upon dying\". Dalton Conley, the author of \"You May Ask Yourself\", claims that ontological equality can also be used to put forth the notion that poverty is virtue. Luciano Floridi, author of a book about information, wrote about what he calls the ontological equality principle. His work on information ethics raises the importance of equality when presenting information. Here is a short sample of his work:\nFloridi goes onto claim that this \"ontological equality principle means that any form of reality (any instance of information/being), simply for the fact of being what it is, enjoys a minimal, initial, overridable, equal right to exist and develop in a way which is appropriate to its nature.\"\nValues in his claims correlate to those shown in the sociological textbook \"You May Ask Yourself\" by Dalton Conley. The notion of \"ontological equality\" describes equality by saying everything is equal by nature. Everyone is created equal at birth. Everything has equal right to exist and develop by its nature.\n\nAnother standard of equality is equality of opportunity, \"the idea that everyone has an equal chance to achieve wealth, social prestige, and power because the rules of the game, so to speak, are the same for everyone\". This concept can be applied to society by saying that no one has a head start. This means that, for any social equality issue dealing with wealth, social prestige, power, or any of that sort, the equality of opportunity standard can defend the idea that everyone had the same start. This views society almost as a game and any of the differences in equality are due to luck and playing the \"game\" to one's best ability. Conley gives an example of this standard of equality by using a game of Monopoly to describe society. He claims that \"Monopoly follows the rules of equality of opportunity\" by explaining that everyone had an equal chance when starting the game and any differences were a result of the luck of the dice roll and the skill of the player to make choices to benefit their wealth. Comparing this example to society, the standard of equality of opportunity eliminates inequality because the rules of the games in society are still fair and the same for all; therefore making any existing inequalities in society fair. Lesley A. Jacobs, the author of \"Pursuing Equal Opportunities: The Theory and Practice of Egalitarian Justice\", talks about equality of opportunity and its importance relating to egalitarian justice. Jacobs states that \nThis concept points out factors like race, gender, class etc. that should not be considered when talking about equality through this notion. Conley also mentions that this standard of equality is at the heart of a bourgeois society, such as a modern capitalist society, or \"a society of commerce in which the maximization of profit is the primary business incentive\". It was the equal opportunity ideology that civil rights activists adopted in the era of the Civil Rights Movement in the 1960s. This ideology was used by them to argue that Jim Crow laws were incompatible with the standard of equality of opportunity.\n\nAnother notion of equality introduced by Conley is equality of condition. Through this framework is the idea that everyone should have an equal starting point. Conley goes back to his example of a game of Monopoly to explain this standard. If the game of four started off with two players both having an advantage of $5,000 dollars to start off with and both already owning hotels and other property while the other two players both did not own any property and both started off with a $5,000 dollar deficit, then from a perspective of the standard of equality of condition, one can argue that the rules of the game \"need to be altered in order to compensate for inequalities in the relative starting positions\". From this we form policies in order to even equality which in result bring an efficient way to create fairer competition in society. Here is where social engineering comes into play where we change society in order to give an equality of condition to everyone based on race, gender, class, religion etc. when it is made justifiable that the proponents of the society makes it unfair for them.\n\nSharon E. Kahn, author of \"Academic Freedom and the Inclusive University\", talks about equality of condition in their work as well and how it correlates to freedom of individuals. They claim that in order to have individual freedom there needs to be equality of condition \"which requires much more than the elimination of legal barriers: it requires the creation of a level playing field that eliminates structural barriers to opportunity\". Her work talks about the academic structure and its problem with equalities and claims that to \"ensure equity...we need to recognize that the university structure and its organizational culture have traditionally privileged some and marginalized other; we need to go beyond theoretical concepts of equality by eliminating systemic barriers that hinder the equal participation of members of all groups; we need to create and equality of condition, not merely an equality of opportunity\". \"Notions of equity, diversity, and inclusiveness begin with a set of premises about individualism, freedom and rights that take as given the existence of deeply rooted inequalities in social structure,\" therefore in order to have a culture of the inclusive university, it would have to \"be based on values of equity; that is, equality of condition\" eliminating all systemic barriers that go against equality.\n\nA fourth standard of equality is equality of outcome, which is \"a position that argues each player must end up with the same amount regardless of the fairness\". This ideology is predominately a Marxist philosophy that is concerned with equal distribution of power and resources rather than the rules of society. In this standard of equality, the idea is that \"everyone contributes to society and to the economy according to what they do best.\". Under this notion of equality, Conley states that \"nobody will earn more power, prestige, and wealth by working harder\".\n\nWhen defining equality of outcome in education, \"the goals should not be the liberal one of equality of access but equality of outcome for the median number of each identifiable non-educationally defined group, i.e. the average women, negro, or proletarian or rural dweller should have the same level of educational attainment as the average male, white, suburbanite\". The outcome and the benefits from equality from education from this notion of equality promotes that all should have the same outcomes and benefits regardless of race, gender, religion etc. The equality of outcome in Hewitt's point of view is supposed to result in \"a comparable range of achievements between a specific disadvantaged group – such as an ethnic minority, women, lone parents and the disabled – and society as a whole\".\n\n"}
{"id": "962906", "url": "https://en.wikipedia.org/wiki?curid=962906", "title": "Sound unit", "text": "Sound unit\n\nA sound unit is any acoustic unit of sound measurement.\n\n"}
{"id": "147860", "url": "https://en.wikipedia.org/wiki?curid=147860", "title": "Style (visual arts)", "text": "Style (visual arts)\n\nIn the visual arts, style is a \"...distinctive manner which permits the grouping of works into related categories\" or \"...any distinctive, and therefore recognizable, way in which an act is performed or an artifact made or ought to be performed and made\". It refers to the visual appearance of a work of art that relates it to other works by the same artist or one from the same period, training, location, \"school\", art movement or archaeological culture: \"The notion of style has long been the art historian's principal mode of classifying works of art. By style he selects and shapes the history of art\".\nStyle is often divided into the general style of a period, country or cultural group, group of artists or art movement, and the individual style of the artist within that group style. Divisions within both types of styles are often made, such as between \"early\", \"middle\" or \"late\". In some artists, such as Picasso for example, these divisions may be marked and easy to see, in others they are more subtle. Style is seen as usually dynamic, in most periods always changing by a gradual process, though the speed of this varies greatly, between the very slow development in style typical of prehistoric art or Ancient Egyptian art to the rapid changes in Modern art styles. Style often develops in a series of jumps, with relatively sudden changes followed by periods of slower development.\n\nAfter dominating academic discussion in art history in the 19th and early 20th centuries, so-called \"style art history\" has come under increasing attack in recent decades, and many art historians now prefer to avoid stylistic classifications where they can.\n\nAny piece of art is in theory capable of being analysed in terms of style; neither periods nor artists can avoid having a style, except by complete incompetence, and conversely natural objects or sights cannot be said to have a style, as style only results from choices made by a maker. Whether the artist makes a conscious choice of style, or can identify his own style, hardly matters. Artists in recent developed societies tend to be highly conscious of their own style, arguably over-conscious, whereas for earlier artists stylistic choices were probably \"largely unselfconscious\".\n\nMost stylistic periods are identified and defined later by art historians, but artists may choose to define and name their own style. The names of most older styles are the invention of art historians and would not have been understood by the practitioners of those styles. Some originated as terms of derision, including Gothic, Baroque, and Rococo. Cubism on the other hand was a conscious identification made by a few artists; the word itself seems to have originated with critics rather than painters, but was rapidly accepted by the artists.\n\nWestern art, like that of some other cultures, most notably Chinese art, has a marked tendency to revive at intervals \"classic\" styles from the past. In critical analysis of the visual arts, the style of a work of art is typically treated as distinct from its iconography, which covers the subject and the \"content\" of the work, though for Jas Elsner this distinction is \"not, of course, true in any actual example; but it has proved rhetorically extremely useful\".\n\nClassical art criticism and the relatively few medieval writings on aesthetics did not greatly develop a concept of style in art, or analysis of it, and though Renaissance and Baroque writers on art are greatly concerned with what we would call style, they did not develop a coherent theory of it, at least outside architecture. Giorgio Vasari set out a hugely influential but much-questioned account of the development of style in Italian painting (mainly) from Giotto to his own Mannerist period. He stressed the development of a Florentine style based on \"disegno\" or line-based drawing, rather than Venetian colour. With other Renaissance theorists like Leon Battista Alberti he continued classical debates over the best balance in art between the realistic depiction of nature and idealization of it; this debate was to continue until the 19th century and the advent of Modernism.\n\nThe theorist of Neoclassicism, Johann Joachim Winckelmann, analysed the stylistic changes in Greek classical art in 1764, comparing them closely to the changes in Renaissance art, and \"Georg Hegel codified the notion that each historical period will have a typical style\", casting a very long shadow over the study of style. Hegel is often attributed with the invention of the German word \"Zeitgeist\", but he never actually used the word, although in \"Lectures on the Philosophy of History\", he uses the phrase \"der Geist seiner Zeit\" (the spirit of his time), writing \"no man can surpass his own time, for the spirit of his time is also his own spirit.\"\n\nConstructing schemes of the period styles of historic art and architecture was a major concern of 19th-century scholars in the new and initially mostly German-speaking field of art history, with important writers on the broad theory of style including Carl Friedrich von Rumohr, Gottfried Semper, and Alois Riegl in his \"Stilfragen\" of 1893, with Heinrich Wölfflin and Paul Frankl continuing the debate in the 20th century. Paul Jacobsthal and Josef Strzygowski are among the art historians who followed Riegl in proposing grand schemes tracing the transmission of elements of styles across great ranges in time and space. This type of art history is also known as formalism, or the study of forms or shapes in art.\n\nSemper, Wölfflin, and Frankl, and later Ackerman, had backgrounds in the history of architecture, and like many other terms for period styles, \"Romanesque\" and \"Gothic\" were initially coined to describe architectural styles, where major changes between styles can be clearer and more easy to define, not least because style in architecture is easier to replicate by following a set of rules than style in figurative art such as painting. Terms originated to describe architectural periods were often subsequently applied to other areas of the visual arts, and then more widely still to music, literature and the general culture.\n\nIn architecture stylistic change often follows, and is made possible by, the discovery of new techniques or materials, from the Gothic rib vault to modern metal and reinforced concrete construction. A major area of debate in both art history and archaeology has been the extent to which stylistic change in other fields like painting or pottery is also a response to new technical possibilities, or has its own impetus to develop (the \"kunstwollen\" of Riegl), or changes in response to social and economic factors affecting patronage and the conditions of the artist, as current thinking tends to emphasize, using less rigid versions of Marxist art history.\n\nAlthough style was well-established as a central component of art historical analysis, seeing it as the over-riding factor in art history had fallen out of fashion by World War II, as other ways of looking at art were developing, as well as a reaction against the emphasis on style; for Svetlana Alpers, \"the normal invocation of style in art history is a depressing affair indeed\". According to James Elkins \"In the later 20th century criticisms of style were aimed at further reducing the Hegelian elements of the concept while retaining it in a form that could be more easily controlled\". Meyer Schapiro, James Ackerman, Ernst Gombrich and George Kubler (\"\", 1962) have made notable contributions to the debate, which has also drawn on wider developments in critical theory. In 2010 Jas Elsner put it more strongly: \"For nearly the whole of the 20th century, style art history has been the indisputable king of the discipline, but since the revolutions of the seventies and eighties the king has been dead\", though his article explores ways in which \"style art history\" remains alive, and his comment would hardly be applicable to archaeology.\n\nThe use of terms such as Counter-\"Maniera\" appears to be in decline, as impatience with such \"style labels\" grows among art historians. In 2000 Marcia B. Hall, a leading art historian of 16th-century Italian painting and mentee of Sydney Joseph Freedberg (1914–1997), who invented the term, was criticised by a reviewer of her \"After Raphael: Painting in Central Italy in the Sixteenth Century\" for her \"fundamental flaw\" in continuing to use this and other terms, despite an apologetic \"Note on style labels\" at the beginning of the book and a promise to keep their use to a minimum. \nA rare recent attempt to create a theory to explain the process driving changes in artistic style, rather than just theories of how to describe and categorize them, is by the behavioural psychologist Colin Martindale, who has proposed an evolutionary theory based on Darwinian principles. However this cannot be said to have gained much support among art historians.\n\nTraditional art history has also placed great emphasis on the individual style of an artist: \"the notion of personal style—that individuality can be uniquely expressed not only in the way an artist draws, but also in the stylistic quirks of an author's writing (for instance)— is perhaps an axiom of Western notions of identity\". The identification of individual styles is especially important in the attribution of works to artists, which is a dominant factor in their valuation for the art market, above all for works in the Western tradition since the Renaissance. The identification of individual style in works is \"essentially assigned to a group of specialists in the field known as connoisseurs\", a group who centre in the art trade and museums, often with tensions between them and the community of academic art historians.\n\nThe exercise of conoisseurship is largely a matter of subjective impressions that are hard to analyse, but also a matter of knowing details of technique and the \"hand\" of different artists. Giovanni Morelli (1816 – 1891) pioneered the systematic study of the scrutiny of diagnostic minor details that revealed artists' scarcely conscious shorthand and conventions for portraying, for example, ears or hands, in Western old master paintings. His techniques were adopted by Bernard Berenson and others, and have been applied to sculpture and many other types of art, for example by Sir John Beazley to Attic vase painting. Personal techniques can be important in analysing individual style. Though artists' training was before Modernism essentially imitative, relying on taught technical methods, whether learnt as an apprentice in a workshop or later as a student in an academy, there was always room for personal variation. The idea of technical \"secrets\" closely guarded by the master who developed them, is a long-standing \"topos\" in art history from Vasari's probably mythical account of Jan van Eyck to the secretive habits of Georges Seurat. \nHowever the idea of personal style is certainly not limited to the Western tradition. In Chinese art it is just as deeply held, but traditionally regarded as a factor in the appreciation of some types of art, above all calligraphy and literati painting, but not others, such as Chinese porcelain; a distinction also often seen in the so-called decorative arts in the West. Chinese painting also allowed for the expression of political and social views by the artist a good deal earlier than is normally detected in the West. Calligraphy, also regarded as a fine art in the Islamic world and East Asia, brings a new area within the ambit of personal style; the ideal of Western calligraphy tends to be to suppress individual style, while graphology, which relies upon it, regards itself as a science.\n\n\"Manner\" is a related term, often used for what is in effect a sub-division of a style, perhaps focused on particular points of style or technique. While many elements of period style can be reduced to characteristic forms or shapes, that can adequately be represented in simple line-drawn diagrams, \"manner\" is more often used to mean the overall style and atmosphere of a work, especially complex works such as paintings, that cannot so easily be subject to precise analysis. It is a somewhat outdated term in academic art history, avoided because it is imprecise. When used it is often in the context of imitations of the individual style of an artist, and it is one of the hierarchy of discreet or diplomatic terms used in the art trade for the relationship between a work for sale and that of a well-known artist, with \"Manner of Rembrandt\" suggesting a distanced relationship between the style of the work and Rembrandt's own style. The \"Explanation of Cataloguing Practice\" of the auctioneers Christie's' explains that \"Manner of ...\" in their auction catalogues means \"In our opinion a work executed in the artist's style but of a later date\". Mannerism, derived from the Italian \"maniera\" (\"manner\") is a specific phase of the general Renaissance style, but \"manner\" can be used very widely.\n\nIn archaeology, despite modern techniques like radiocarbon dating, period or cultural style remains a crucial tool in the identification and dating not only of works of art but all classes of archaeological artefact, including purely functional ones (ignoring the question of whether purely functional artefacts exist). The identification of individual styles of artists or artisans has also been proposed in some cases even for remote periods such as the Ice Age art of the European Upper Paleolithic.\n\nAs in art history, formal analysis of the morphology (shape) of individual artefacts is the starting point. This is used to construct typologies for different types of artefacts, and by the technique of seriation a relative dating based on style for a site or group of sites is achieved where scientific absolute dating techniques cannot be used, in particular where only stone, ceramic or metal artefacts or remains are available, which is often the case. Sherds of pottery are often very numerous in sites from many cultures and periods, and even small pieces may be confidently dated by their style. In contrast to recent trends in academic art history, the succession of schools of archaeological theory in the last century, from culture-historical archaeology to processual archaeology and finally the rise of post-processual archaeology in recent decades has not significantly reduced the importance of the study of style in archaeology, as a basis for classifying objects before further interpretation.\n\nStylization and stylized (or \"stylisation\" and \"stylised\" in (non-Oxford) British English, respectively) have a more specific meaning, referring to visual depictions that use simplified ways of representing objects or scenes that do not attempt a full, precise and accurate representation of their visual appearance (\"mimesis\" or \"realistic\"), preferring an attractive or expressive overall depiction. More technically, it has been defined as \"the decorative generalization of figures and objects by means of various conventional techniques, including the simplification of line, form, and relationships of space and color\", and observed that \"[s]tylized art reduces visual perception to constructs of pattern in line, surface elaboration and flattened space\".\n\nAncient, traditional, and modern art, as well as popular forms such as cartoons or animation very often use stylized representations, so for example \"The Simpsons\" use highly stylized depictions, as does traditional African art. The two Picasso paintings illustrated at the top of this page show a movement to a more stylized representation of the human figure within the painter's style, and the Uffington White Horse is an example of a highly stylized prehistoric depiction of a horse. Motifs in the decorative arts such as the palmette or arabesque are often highly stylized versions of the parts of plants.\n\nEven in art that is in general attempting mimesis or \"realism\", a degree of stylization is very often found in details, and especially figures or other features at a small scale, such as people or trees etc. in the distant background even of a large work. But this is not stylization intended to be noticed by the viewer, except on close examination. Drawings, \"modelli\", and other sketches not intended as finished works for sale will also very often stylize.\n\n\"Stylized\" may mean the adoption of any style in any context, and in American English is often used for the typographic style of names, as in \"AT&T is also stylized as ATT and at&t\": this is a specific usage that seems to have escaped dictionaries, although it is a small extension of existing other senses of the word.\n\nIn a 2012 experiment at Lawrence Technological University in Michigan, a computer analysed approximately 1,000 paintings from 34 well-known artists using a specially developed algorithm and placed them in similar style categories to human art historians. The analysis involved the sampling of more than 4000 visual features per work of art.\n\n\n\n"}
{"id": "28966352", "url": "https://en.wikipedia.org/wiki?curid=28966352", "title": "Sustainability and environmental management", "text": "Sustainability and environmental management\n\nAt the global scale sustainability and environmental management involves managing the oceans, freshwater systems, land and atmosphere, according to sustainability principles.\n\nLand use change is fundamental to the operations of the biosphere because alterations in the relative proportions of land dedicated to urbanisation, agriculture, forest, woodland, grassland and pasture have a marked effect on the global water, carbon and nitrogen biogeochemical cycles. Management of the Earth's atmosphere involves assessment of all aspects of the carbon cycle to identify opportunities to address human-induced climate change and this has become a major focus of scientific research because of the potential catastrophic effects on biodiversity and human communities. Ocean circulation patterns have a strong influence on climate and weather and, in turn, the food supply of both humans and other organisms.\n\nIn March 2009 at a meeting of the Copenhagen Climate Council 2,500 climate experts from 80 countries issued a keynote statement that there is now \"no excuse\" for failing to act on global warming and that without strong carbon reduction targets \"abrupt or irreversible\" shifts in climate may occur that \"will be very difficult for contemporary societies to cope with\". Management of the global atmosphere now involves assessment of all aspects of the carbon cycle to identify opportunities to address human-induced climate change and this has become a major focus of scientific research because of the potential catastrophic effects on biodiversity and human communities.\n\nOther human impacts on the atmosphere include the air pollution in cities, the pollutants including toxic chemicals like nitrogen oxides, sulphur oxides, volatile organic compounds and airborne particulate matter that produce photochemical smog and acid rain, and the chlorofluorocarbons that degrade the ozone layer. Anthropogenic particulates such as sulfate aerosols in the atmosphere reduce the direct irradiance and reflectance (albedo) of the Earth's surface. Known as global dimming the decrease is estimated to have been about 4% between 1960 and 1990 although the trend has subsequently reversed. Global dimming may have disturbed the global water cycle by reducing evaporation and rainfall in some areas. It also creates a cooling effect and this may have partially masked the effect of greenhouse gases on global warming.\n\n Ocean circulation patterns have a strong influence on climate and weather and, in turn, the food supply of both humans and other organisms. Scientists have warned of the possibility, under the influence of climate change, of a sudden alteration in circulation patterns of ocean currents that could drastically alter the climate in some regions of the globe. Major human environmental impacts occur in the more habitable regions of the ocean fringes – the estuaries, coastline and bays. Ten per cent of the world's population – about 600 million people – live in low-lying areas vulnerable to sea level rise. Trends of concern that require management include: over-fishing (beyond sustainable levels); coral bleaching due to ocean warming and ocean acidification due to increasing levels of dissolved carbon dioxide; and sea level rise due to climate change. Because of their vastness oceans also act as a convenient dumping ground for human waste. Remedial strategies include: more careful waste management, statutory control of overfishing by adoption of sustainable fishing practices and the use of environmentally sensitive and sustainable aquaculture and fish farming, reduction of fossil fuel emissions and restoration of coastal and other marine habitat.\n\nWater covers 71% of the Earth's surface. Of this, 97.5% is the salty water of the oceans and only 2.5% freshwater, most of which is locked up in the Antarctic ice sheet. The remaining freshwater is found in lakes, rivers, wetlands, the soil, aquifers and atmosphere. All life depends on the solar-powered global water cycle, the evaporation from oceans and land to form water vapour that later condenses from clouds as rain, which then becomes the renewable part of the freshwater supply. Awareness of the global importance of preserving water for ecosystem services has only recently emerged as, during the 20th century, more than half the world’s wetlands have been lost along with their valuable environmental services. Biodiversity-rich freshwater ecosystems are currently declining faster than marine or land ecosystems making them the world's most vulnerable habitats. Increasing urbanization pollutes clean water supplies and much of the world still does not have access to clean, safe water. In the industrial world demand management has slowed absolute usage rates but increasingly water is being transported over vast distances from water-rich natural areas to population-dense urban areas and energy-hungry desalination is becoming more widely used. Greater emphasis is now being placed on the improved management of blue (harvestable) and green (soil water available for plant use) water, and this applies at all scales of water management.\n\nLoss of biodiversity stems largely from the habitat loss and fragmentation produced by the human appropriation of land for development, forestry and agriculture as natural capital is progressively converted to man-made capital. Land use change is fundamental to the operations of the biosphere because alterations in the relative proportions of land dedicated to urbanisation, agriculture, forest, woodland, grassland and pasture have a marked effect on the global water, carbon and nitrogen biogeochemical cycles and this can impact negatively on both natural and human systems. At the local human scale major sustainability benefits accrue from the pursuit of green cities and sustainable parks and gardens.\n\nSince the Neolithic Revolution, human use has reduced the world’s forest cover by about 47%. Present-day forests occupy about a quarter of the world’s ice-free land with about half of these occurring in the tropics In temperate and boreal regions forest area is gradually increasing (with the exception of Siberia), but deforestation in the tropics is of major concern.\n\nForests moderate the local climate and the global water cycle through their light reflectance (albedo) and evapotranspiration. They also conserve biodiversity, protect water quality, preserve soil and soil quality, provide fuel and pharmaceuticals, and purify the air. These free ecosystem services are not given a market value under most current economic systems, and so forest conservation has little appeal when compared with the economic benefits of logging and clearance which, through soil degradation and organic decomposition returns carbon dioxide to the atmosphere. The United Nations Food and Agriculture Organization (FAO) estimates that about 90% of the carbon stored in land vegetation is locked up in trees and that they sequester about 50% more carbon than is present in the atmosphere. Changes in land use currently contribute about 20% of total global carbon emissions (heavily logged Indonesia and Brazil are a major source of emissions). Climate change can be mitigated by sequestering carbon in reafforestation schemes, plantations and timber products. Also wood biomass can be utilized as a renewable carbon-neutral fuel. The FAO has suggested that, over the period 2005–2050, effective use of tree planting could absorb about 10–20% of man-made emissions – so monitoring the condition of the world's forests must be part of a global strategy to mitigate emissions and protect ecosystem services. However, climate change may pre-empt this FAO scenario as a study by the International Union of Forest Research Organizations in 2009 concluded that the stress of a 2.5C (4.5F) temperature rise above pre-industrial levels could result in the release of vast amounts of carbon so the potential of forests to act as carbon \"sinks\" is \"at risk of being lost entirely\".\n\nFeeding more than six billion human bodies takes a heavy toll on the Earth’s resources. This begins with the appropriation of about 38% of the Earth’s land surface and about 20% of its net primary productivity. Added to this are the resource-hungry activities of industrial agribusiness – everything from the crop need for irrigation water, synthetic fertilizers and pesticides to the resource costs of food packaging, transport (now a major part of global trade) and retail. Food is essential to life. But the list of environmental costs of food production is a long one: topsoil depletion, erosion and conversion to desert from constant tillage of annual crops; overgrazing; salinization; sodification; waterlogging; high levels of fossil fuel use; reliance on inorganic fertilisers and synthetic organic pesticides; reductions in genetic diversity by the mass use of monocultures; water resource depletion; pollution of waterbodies by run-off and groundwater contamination; social problems including the decline of family farms and weakening of rural communities.\n\nAll of these environmental problems associated with industrial agriculture and agribusiness are now being addressed through such movements as sustainable agriculture, organic farming and more sustainable business practices.\n\nAlthough biodiversity loss can be monitored simply as loss of species, effective conservation demands the protection of species within their natural habitats and ecosystems. Following human migration and population growth, species extinctions have progressively increased to a rate unprecedented since the Cretaceous–Paleogene extinction event. Known as the Holocene extinction event this current human-induced extinction of species ranks as one of the worlds six mass extinction events. Some scientific estimates indicate that up to half of presently existing species may become extinct by 2100. Current extinction rates are 100 to 1000 times their prehuman levels with more than 10% birds and mammals threatened, about 8% of plants, 5% of fish and more than 20% of freshwater species.\n\nThe 2008 IUCN Red List warns that long-term droughts and extreme weather put additional stress on key habitats and, for example, lists 1,226 bird species as threatened with extinction, which is one-in-eight of all bird species. The Red List Index also identifies 44 tree species in Central Asia as under threat of extinction due to over-exploitation and human development and threatening the region's forests which are home to more than 300 wild ancestors of modern domesticated fruit and nut cultivars.\n\nIn many parts of the industrial world land clearing for agriculture has diminished and here the greatest threat to biodiversity, after climate change, has become the destructive effect of invasive species. Increasingly efficient global transport has facilitated the spread of organisms across the planet. The potential danger of this aspect of globalization is starkly illustrated through the spread of human diseases like HIV AIDS, mad cow disease, bird flu and swine flu, but invasive plants and animals are also having a devastating impact on native biodiversity. Non-indigenous organisms can quickly occupy disturbed land and natural areas where, in the absence of their natural predators, they are able to thrive. At the global scale this issue is being addressed through the Global Invasive Species Information Network but there is improved international biosecurity legislation to minimise the transmission of pathogens and invasive organisms. Also, through CITES legislation there is control the trade in rare and threatened species. Increasingly at the local level public awareness programs are alerting communities, gardeners, the nursery industry, collectors, and the pet and aquarium industries, to the harmful effects of potentially invasive species.\n\nThe environmental sustainability problem has proven difficult to solve. The modern environmental movement has attempted to solve the problem in a large variety of ways. But little progress has been made, as shown by severe ecological footprint overshoot and lack of sufficient progress on the climate change problem. Something within the human system in preventing change to a sustainable mode of behavior. That system trait is systemic change resistance. Change resistance is also known as organizational resistance, barriers to change, or policy resistance.\n\n\n\n"}
{"id": "29965", "url": "https://en.wikipedia.org/wiki?curid=29965", "title": "Tensor", "text": "Tensor\n\nIn mathematics, a tensor is an arbitrarily complex geometric object that maps in a (multi-)linear manner geometric vectors, scalars, and other tensors to a resulting tensor. Thereby, vectors and scalars themselves, often used already in elementary physics and engineering applications, are considered as the simplest tensors. Additionally, vectors from the dual space of the vector space, which supplies the geometric vectors, are also included as tensors. \"Geometric\" in this context is chiefly meant to emphasize independence of any selection of a coordinate system.\n\nElementary examples of such relations include the dot product, mapping two vectors to a tensor, which is a simple scalar. A more complex example is the Cauchy stress tensor T, which takes a directional unit vector v as input and maps it to the stress vector T, which is the force (per unit area) exerted by material on the negative side of the plane orthogonal to v against the material on the positive side of the plane, thus expressing a relationship between these two vectors, shown in the figure (right). The cross product, where two vectors are mapped to a third one, is strictly speaking not a tensor, because it changes its sign under those transformations that change the orientation of the coordinate system. The totally anti-symmetric symbol formula_1 allows nevertheless a convenient handling of the cross product in equally oriented three dimensional coordinate systems.\n\nAssuming a basis of a real vector space, e.g., a coordinate frame in the ambient space, a tensor can be represented as an organized multidimensional array of numerical values with respect to this specific basis. Changing the basis transforms the values in the array in a characteristic way that allows to \"define\" tensors as objects adhering to this transformational behavior. For example, there are invariants of tensors that must be preserved under any change of the basis, thereby making only certain multidimensional arrays of numbers a tensor. Compare this to the array representing formula_2 not being a tensor, for the sign change under transformations changing the orientation.\n\nBecause the components of vectors and their duals transform differently under the change of their dual bases, there is a covariant and/or contravariant transformation law that relates the arrays, which represent the tensor with respect to one basis and that with respect to the other one. The numbers of, respectively, (contravariant indices) and dual (covariant indices) in the input and output of a tensor determine the \"type\" (or \"valence\") of the tensor, a pair of natural numbers , which determine the precise form of the transformation law. The \"\" of a tensor is the sum of these two numbers.\n\nThe order (also \"degree\" or \"\") of a tensor is thus the sum of the orders of its arguments plus the order of the resulting tensor. This is also the dimensionality of the array of numbers needed to represent the tensor with respect to a specific basis, or equivalently, the number of indices needed to label each component in that array. For example in a fixed basis, a standard linear map that maps a vector to a vector, is represented by a matrix (a 2-dimensional array), and therefore is a 2nd-order tensor. A simple vector can be represented as a 1-dimensional array, and is therefore a 1st-order tensor. Scalars are simple numbers and are thus 0th-order tensors. This way the tensor representing the scalar product, taking two vectors and resulting in a scalar has order , equal to the stress tensor, taking one vector and returning another . The mapping two vectors to one vector, would have order \n\nThe collection of tensors on a vector space and its dual forms a tensor algebra, which allows products of arbitrary tensors. Simple applications of tensors of order , which can be represented as a square matrix, can be solved by clever arrangement of transposed vectors and by applying the rules of matrix multiplication, but the tensor product should not be confused with this.\n\nTensors are important in physics because they provide a concise mathematical framework for formulating and solving physics problems in areas such as mechanics (stress, elasticity, fluid mechanics, moment of inertia, ...), electrodynamics (electromagnetic tensor, Maxwell tensor, permittivity, magnetic susceptibility, ...), or general relativity (stress–energy tensor, curvature tensor, ... ) and others. In applications, it is common to study situations in which a different tensor can occur at each point of an object; for example the stress within an object may vary from one location to another. This leads to the concept of a tensor field. In some areas, tensor fields are so ubiquitous that they are simply called \"tensors\". \n\nTensors were conceived in 1900 by Tullio Levi-Civita and Gregorio Ricci-Curbastro, who continued the earlier work of Bernhard Riemann and Elwin Bruno Christoffel and others, as part of the \"absolute differential calculus\". The concept enabled an alternative formulation of the intrinsic differential geometry of a manifold in the form of the Riemann curvature tensor.\n\nAlthough seemingly different, the various approaches to defining tensors describe the same geometric concept using different language and at different levels of abstraction.\n\nA tensor may be represented as a (potentially multidimensional) array (although a multidimensional array is not necessarily a representation of a tensor, as discussed below with regard to holors). Just as a vector in an -dimensional space is represented by a one-dimensional array of length with respect to a given basis, any tensor with respect to a basis is represented by a multidimensional array. For example, a linear operator is represented in a basis as a two-dimensional square array. The numbers in the multidimensional array are known as the \"scalar components\" of the tensor or simply its \"components\". They are denoted by indices giving their position in the array, as subscripts and superscripts, following the symbolic name of the tensor. For example, the components of an order tensor could be denoted  , where and are indices running from to , or also by . Whether an index is displayed as a superscript or subscript depends on the transformation properties of the tensor, described below. Thus while and can both be expressed as \"n\" by \"n\" matrices, and are numerically related via index juggling, the difference in their transformation laws indicates it would be improper to add them together. The total number of indices required to identify each component uniquely is equal to the dimension of the array, and is called the \"order\", \"degree\" or \"rank\" of the tensor. However, the term \"rank\" generally has another meaning in the context of matrices and tensors.\n\nJust as the components of a vector change when we change the basis of the vector space, the components of a tensor also change under such a transformation. Each type of tensor comes equipped with a \"transformation law\" that details how the components of the tensor respond to a change of basis. The components of a vector can respond in two distinct ways to a change of basis (see covariance and contravariance of vectors), where the new basis vectors formula_3 are expressed in terms of the old basis vectors formula_4 as,\n\nHere \"R\" are the entries of the change of basis matrix, and in the rightmost expression the summation sign was suppressed: this is the Einstein summation convention, which will be used throughout this article. The components \"v\" of a column vector v transform with the inverse of the matrix \"R\",\nwhere the hat denotes the components in the new basis. This is called a \"contravariant\" transformation law, because the vector transforms by the \"inverse\" of the change of basis. In contrast, the components, \"w\", of a covector (or row vector), w transform with the matrix \"R\" itself,\n\nThis is called a \"covariant\" transformation law, because the covector transforms by the \"same matrix\" as the change of basis matrix. The components of a more general tensor transform by some combination of covariant and contravariant transformations, with one transformation law for each index. If the transformation matrix of an index is the inverse matrix of the basis transformation, then the index is called \"contravariant\" and is conventionally denoted with an upper index (superscript). If the transformation matrix of an index is the basis transformation itself, then the index is called \"covariant\" and is denoted with a lower index (subscript). \n\nAs a simple example, the matrix of a linear operator with respect to a basis is a rectangular array formula_8 that transforms under a change of basis matrix formula_9 by formula_10. For the individual matrix entries, this transformation law has the form formula_11 so the tensor corresponding to the matrix of a linear operator has one covariant and one contravariant index: it is of type (1,1). \n\nCombinations of covariant and contravariant components with the same index allow us to express geometric invariants. For example, the fact that a vector is the same object in different coordinate systems can be captured by the following equations, using the formulas defined above:\n\nwhere formula_13 is the Kronecker delta, which functions similarly to the identity matrix, and has the effect of renaming indices (\"j\" into \"k\" in this example). This shows several features of the component notation- the ability to re-arrange terms at will (commutativity), the need to use different indices when working with multiple objects in the same expression, the ability to rename indices, and the manner in which contravariant and covariant tensors combine so that all instances of the transformation matrix and its inverse cancel, so that expressions like formula_14 can immediately be seen to be geometrically identical in all coordinate systems.\n\nSimilarly, a linear operator, viewed as a geometric object, does not actually depend on a basis: it is just a linear map that accepts a vector as an argument and produces another vector. The transformation law for how the matrix of components of a linear operator changes with the basis is consistent with the transformation law for a contravariant vector, so that the action of a linear operator on a contravariant vector is represented in coordinates as the matrix product of their respective coordinate representations. That is, the components formula_15 are given by formula_16. These components transform contravariantly, since\n\nThe transformation law for an order tensor with \"p\" contravariant indices and \"q\" covariant indices is thus given as,\n\nHere the primed indices denote components in the new coordinates, and the unprimed indices denote the components in the old coordinates. Such a tensor is said to be of order or \"type\" . The terms \"order\", \"type\", \"rank\", \"valence\", and \"degree\" are all sometimes used for the same concept. Here, the term \"order\" or \"total order\" will be used for the total dimension of the array (or its generalisation in other definitions), in the preceding example, and the term \"type\" for the pair giving the number of contravariant and covariant indices. A tensor of type is also called a -tensor for short.\n\nThis discussion motivates the following formal definition:\n\n[\\mathbf{f}]</math>\nto each basis of an \"n\"-dimensional vector space such that, if we apply the change of basis\nthen the multidimensional array obeys the transformation law\n\nThe definition of a tensor as a multidimensional array satisfying a transformation law traces back to the work of Ricci.\n\nAn equivalent definition of a tensor uses the representations of the general linear group. There is an action of the general linear group on the set of all ordered bases of an \"n\"-dimensional vector space. If formula_25 is an ordered basis, and formula_26 is an invertible formula_27 matrix, then the action is given by\nLet \"F\" be the set of all ordered bases. Then \"F\" is a principal homogeneous space for GL(\"n\"). Let \"W\" be a vector space and let formula_29 be a representation of GL(\"n\") on \"W\" (that is, a group homomorphism formula_30). Then a tensor of type formula_29 is an equivariant map formula_32. Equivariance here means that\n\nWhen formula_29 is a tensor representation of the general linear group, this gives the usual definition of tensors as multidimensional arrays. This definition is often used to describe tensors on manifolds, and readily generalizes to other groups.\n\nA downside to the definition of a tensor using the multidimensional array approach is that it is not apparent from the definition that the defined object is indeed basis independent, as is expected from an intrinsically geometric object. Although it is possible to show that transformation laws indeed ensure independence from the basis, sometimes a more intrinsic definition is preferred. One approach that is common in differential geometry is to define tensors relative to a fixed (finite-dimensional) vector space \"V\", which is usually taken to be a particular vector space of some geometrical significance like the tangent space to a manifold. In this approach, a type tensor \"T\" is defined as a multilinear map,\nwhere \"V\" is the corresponding dual space of covectors, which is linear in each of its arguments. The above assumes \"V\" is a vector space over the real numbers, R. More generally, \"V\" can be taken over an arbitrary field of numbers, \"F\" (e.g. the complex numbers) with a one-dimensional vector space over \"F\" replacing R as the codomain of the multilinear maps.\n\nBy applying a multilinear map \"T\" of type to a basis {e} for \"V\" and a canonical cobasis {ε} for \"V\",\na -dimensional array of components can be obtained. A different choice of basis will yield different components. But, because \"T\" is linear in all of its arguments, the components satisfy the tensor transformation law used in the multilinear array definition. The multidimensional array of components of \"T\" thus form a tensor according to that definition. Moreover, such an array can be realized as the components of some multilinear map \"T\". This motivates viewing multilinear maps as the intrinsic objects underlying tensors.\n\nIn viewing a tensor as a multilinear map, it is conventional to identify the double dual \"V\" of the vector space \"V\", i.e., the space of linear functionals on the dual vector space \"V\", with the vector space \"V\". There is always a natural linear map from \"V\" to its double dual, given by evaluating a linear form in \"V\" against a vector in \"V\". This linear mapping is an isomorphism in finite dimensions, and it is often then expedient to identify \"V\" with its double dual.\n\nFor some mathematical applications, a more abstract approach is sometimes useful. This can be achieved by defining tensors in terms of elements of tensor products of vector spaces, which in turn are defined through a universal property. A type tensor is defined in this context as an element of the tensor product of vector spaces,\n\nA basis of and basis of naturally induce a basis of the tensor product . The components of a tensor are the coefficients of the tensor with respect to the basis obtained from a basis for and its dual basis , i.e.\nUsing the properties of the tensor product, it can be shown that these components satisfy the transformation law for a type tensor. Moreover, the universal property of the tensor product gives a -to- correspondence between tensors defined in this way and tensors defined as multilinear maps.\n\nTensor products can be defined in great generality – for example, involving arbitrary modules over a ring. In principle, one could define a \"tensor\" simply to be an element of any tensor product. However, the mathematics literature usually reserves the term \"tensor\" for an element of a tensor product of any number of copies of a single vector space and its dual, as above.\n\nThis discussion of tensors so far assumes finite dimensionality of the spaces involved, where the spaces of tensors obtained by each of these constructions are naturally isomorphic. Constructions of spaces of tensors based on the tensor product and multilinear mappings can be generalized, essentially without modification, to vector bundles or coherent sheaves. For infinite-dimensional vector spaces, inequivalent topologies lead to inequivalent notions of tensor, and these various isomorphisms may or may not hold depending on what exactly is meant by a tensor (see topological tensor product). In some applications, it is the tensor product of Hilbert spaces that is intended, whose properties are the most similar to the finite-dimensional case. A more modern view is that it is the tensors' structure as a symmetric monoidal category that encodes their most important properties, rather than the specific models of those categories.\n\nIn many applications, especially in differential geometry and physics, it is natural to consider a tensor with components that are functions of the point in a space. This was the setting of Ricci's original work. In modern mathematical terminology such an object is called a tensor field, often referred to simply as a tensor.\n\nIn this context, a coordinate basis is often chosen for the tangent vector space. The transformation law may then be expressed in terms of partial derivatives of the coordinate functions,\ndefining a coordinate transformation,\n\nThis table shows important examples of tensors on vector spaces and tensor fields on manifolds. The tensors are classified according to their type , where \"n\" is the number of contravariant indices, \"m\" is the number of covariant indices, and gives the total order of the tensor. For example, a bilinear form is the same thing as a -tensor; an inner product is an example of a -tensor, but not all -tensors are inner products. In the -entry of the table, \"M\" denotes the dimensionality of the underlying vector space or manifold because for each dimension of the space, a separate index is needed to select that dimension to get a maximally covariant antisymmetric tensor.\n\nRaising an index on an -tensor produces an -tensor; this corresponds to moving diagonally down and to the left on the table. Symmetrically, lowering an index corresponds to moving diagonally up and to the right on the table. Contraction of an upper with a lower index of an -tensor produces an -tensor; this corresponds to moving diagonally up and to the left on the table.\n\nThere are several notational systems that are used to describe tensors and perform calculations involving them. \n\nRicci calculus is the modern formalism and notation for tensor indices: indicating inner and outer products, covariance and contravariance, summations of tensor components, symmetry and antisymmetry, and partial and covariant derivatives.\n\nThe Einstein summation convention dispenses with writing summation signs, leaving the summation implicit. Any repeated index symbol is summed over: if the index is used twice in a given term of a tensor expression, it means that the term is to be summed for all . Several distinct pairs of indices may be summed this way.\n\nPenrose graphical notation is a diagrammatic notation which replaces the symbols for tensors with shapes, and their indices by lines and curves. It is independent of basis elements, and requires no symbols for the indices.\n\nThe abstract index notation is a way to write tensors such that the indices are no longer thought of as numerical, but rather are indeterminates. This notation captures the expressiveness of indices and the basis-independence of index-free notation.\n\nA component-free treatment of tensors uses notation that emphasises that tensors do not rely on any basis, and is defined in terms of the tensor product of vector spaces.\n\nThere are several operations on tensors that again produce a tensor. The linear nature of tensor implies that two tensors of the same type may be added together, and that tensors may be multiplied by a scalar with results analogous to the scaling of a vector. On components, these operations are simply performed component-wise. These operations do not change the type of the tensor; but there are also operations that produce a tensor of different type.\n\nThe tensor product takes two tensors, \"S\" and \"T\", and produces a new tensor, , whose order is the sum of the orders of the original tensors. When described as multilinear maps, the tensor product simply multiplies the two tensors, i.e.\n\nwhich again produces a map that is linear in all its arguments. On components, the effect is to multiply the components of the two input tensors pairwise, i.e.\n\nIf is of type and is of type , then the tensor product has type .\n\nTensor contraction is an operation that reduces a type tensor to a type tensor, of which the trace is a special case. It thereby reduces the total order of a tensor by two. The operation is achieved by summing components for which one specified contravariant index is the same as one specified covariant index to produce a new component. Components for which those two indices are different are discarded. For example, a -tensor formula_43 can be contracted to a scalar through\nWhere the summation is again implied. When the -tensor is interpreted as a linear map, this operation is known as the trace.\n\nThe contraction is often used in conjunction with the tensor product to contract an index from each tensor.\n\nThe contraction can also be understood using the definition of a tensor as an element of a tensor product of copies of the space \"V\" with the space \"V\" by first decomposing the tensor into a linear combination of simple tensors, and then applying a factor from \"V\" to a factor from \"V\". For example, a tensor\ncan be written as a linear combination\nThe contraction of \"T\" on the first and last slots is then the vector\n\nIn a vector space with an inner product (also known as a metric) \"g\", the term contraction is used for removing two contravariant or two covariant indices by forming a trace with the metric tensor or its inverse. For example, a -tensor formula_48 can be contracted to a scalar through\n(yet again assuming the summation convention).\n\nWhen a vector space is equipped with a nondegenerate bilinear form (or \"metric tensor\" as it is often called in this context), operations can be defined that convert a contravariant (upper) index into a covariant (lower) index and vice versa. A metric tensor is a (symmetric) (-tensor; it is thus possible to contract an upper index of a tensor with one of the lower indices of the metric tensor in the product. This produces a new tensor with the same index structure as the previous tensor, but with lower index generally shown in the same position of the contracted upper index. This operation is quite graphically known as \"lowering an index\".\n\nConversely, the inverse operation can be defined, and is called \"raising an index\". This is equivalent to a similar contraction on the product with a -tensor. This \"inverse metric tensor\" has components that are the matrix inverse of those of the metric tensor.\n\nImportant examples are provided by continuum mechanics. The stresses inside a solid body or fluid are described by a tensor field. The stress tensor and strain tensor are both second-order tensor fields, and are related in a general linear elastic material by a fourth-order elasticity tensor field. In detail, the tensor quantifying stress in a 3-dimensional solid object has components that can be conveniently represented as a 3 × 3 array. The three faces of a cube-shaped infinitesimal volume segment of the solid are each subject to some given force. The force's vector components are also three in number. Thus, 3 × 3, or 9 components are required to describe the stress at this cube-shaped infinitesimal segment. Within the bounds of this solid is a whole mass of varying stress quantities, each requiring 9 quantities to describe. Thus, a second-order tensor is needed.\n\nIf a particular surface element inside the material is singled out, the material on one side of the surface will apply a force on the other side. In general, this force will not be orthogonal to the surface, but it will depend on the orientation of the surface in a linear manner. This is described by a tensor of type, in linear elasticity, or more precisely by a tensor field of type , since the stresses may vary from point to point.\n\nCommon applications include\n\n\nThe concept of a tensor of order two is often conflated with that of a matrix. Tensors of higher order do however capture ideas important in science and engineering, as has been shown successively in numerous areas as they develop. This happens, for instance, in the field of computer vision, with the trifocal tensor generalizing the fundamental matrix.\n\nThe field of nonlinear optics studies the changes to material polarization density under extreme electric fields. The polarization waves generated are related to the generating electric fields through the nonlinear susceptibility tensor. If the polarization P is not linearly proportional to the electric field E, the medium is termed \"nonlinear\". To a good approximation (for sufficiently weak fields, assuming no permanent dipole moments are present), P is given by a Taylor series in E whose coefficients are the nonlinear susceptibilities:\n\nHere formula_51 is the linear susceptibility, formula_52 gives the Pockels effect and second harmonic generation, and formula_53 gives the Kerr effect. This expansion shows the way higher-order tensors arise naturally in the subject matter.\n\nAs discussed above, a tensor can be represented as a (potentially multidimensional, multi-indexed) array of quantities. To distinguish tensors (when denoted as tensorial arrays of quantities with respect to a fixed basis) from arbitrary arrays of quantities the term \"holor\" was coined for the latter.\n\nSo tensors can be analyzed as a particular type of holor, alongside other not strictly tensorial holors, such as neural network (node and/or link) values, indexed inventory tables, and so on. Another group of holors that transform like tensors up to a so called \"weight\", derived from the transformation equations, are the tensor densities, e.g. the Levi-Civita Symbol. The Christoffel symbols also belong to the holors.\n\nThe term \"holor\" is not in widespread use, and unfortunately the word \"tensor\" is often misused when referring to the multidimensional array representation of a holor, causing confusion regarding the strict meaning of \"tensor\". \n\nThe concept of holors and the associated terminology provide an algebra and calculus for holors in a more general setting than what is seen for tensorial arrays.\n\nThe vector spaces of a tensor product need not be the same, and sometimes the elements of such a more general tensor product are called \"tensors\". For example, an element of the tensor product space is a second-order \"tensor\" in this more general sense, and an order- tensor may likewise be defined as an element of a tensor product of different vector spaces. A type tensor, in the sense defined previously, is also a tensor of order in this more general sense. The concept of tensor product can be extended to arbitrary modules over a ring.\n\nThe notion of a tensor can be generalized in a variety of ways to infinite dimensions. One, for instance, is via the tensor product of Hilbert spaces. Another way of generalizing the idea of tensor, common in nonlinear analysis, is via the multilinear maps definition where instead of using finite-dimensional vector spaces and their algebraic duals, one uses infinite-dimensional Banach spaces and their continuous dual. Tensors thus live naturally on Banach manifolds and Fréchet manifolds.\n\nSuppose that a homogeneous medium fills , so that the density of the medium is described by a single scalar value in . The mass, in kg, of a region is obtained by multiplying by the volume of the region , or equivalently integrating the constant over the region:\nwhere the Cartesian coordinates are measured in m. If the units of length are changed into cm, then the numerical values of the coordinate functions must be rescaled by a factor of 100:\nThe numerical value of the density must then also transform by formula_56 to compensate, so that the numerical value of the mass in kg is still given by integral of formula_57. Thus formula_58 (in units of ).\n\nMore generally, if the Cartesian coordinates undergo a linear transformation, then the numerical value of the density must change by a factor of the reciprocal of the absolute value of the determinant of the coordinate transformation, so that the integral remains invariant, by the change of variables formula for integration. Such a quantity that scales by the reciprocal of the absolute value of the determinant of the coordinate transition map is called a scalar density. To model a non-constant density, is a function of the variables (a scalar field), and under a curvilinear change of coordinates, it transforms by the reciprocal of the Jacobian of the coordinate change. For more on the intrinsic meaning, see Density on a manifold.\n\nA tensor density transforms like a tensor under a coordinate change, except that it in addition picks up a factor of the absolute value of the determinant of the coordinate transition:\nHere \"w\" is called the weight. In general, any tensor multiplied by a power of this function or its absolute value is called a tensor density, or a weighted tensor. An example of a tensor density is the current density of electromagnetism.\n\nUnder an affine transformation of the coordinates, a tensor transforms by the linear part of the transformation itself (or its inverse) on each index. These come from the rational representations of the general linear group. But this is not quite the most general linear transformation law that such an object may have: tensor densities are non-rational, but are still semisimple representations. A further class of transformations come from the logarithmic representation of the general linear group, a reducible but not semisimple representation, consisting of an with the transformation law\n\nThe transformation law for a tensor behaves as a functor on the category of admissible coordinate systems, under general linear transformations (or, other transformations within some class, such as local diffeomorphisms.) This makes a tensor a special case of a geometrical object, in the technical sense that it is a function of the coordinate system transforming functorially under coordinate changes. Examples of objects obeying more general kinds of transformation laws are jets and, more generally still, natural bundles.\n\nWhen changing from one orthonormal basis (called a \"frame\") to another by a rotation, the components of a tensor transform by that same rotation. This transformation does not depend on the path taken through the space of frames. However, the space of frames is not simply connected (see orientation entanglement and plate trick): there are continuous paths in the space of frames with the same beginning and ending configurations that are not deformable one into the other. It is possible to attach an additional discrete invariant to each frame that incorporates this path dependence, and which turns out (locally) to have values of ±1. A spinor is an object that transforms like a tensor under rotations in the frame, apart from a possible sign that is determined by the value of this discrete invariant. \n\nSuccinctly, spinors are elements of the spin representation of the rotation group, while tensors are elements of its tensor representations. Other classical groups have tensor representations, and so also tensors that are compatible with the group, but all non-compact classical groups have infinite-dimensional unitary representations as well.\n\nThe concepts of later tensor analysis arose from the work of Carl Friedrich Gauss in differential geometry, and the formulation was much influenced by the theory of algebraic forms and invariants developed during the middle of the nineteenth century. The word \"tensor\" itself was introduced in 1846 by William Rowan Hamilton to describe something different from what is now meant by a tensor. The contemporary usage was introduced by Woldemar Voigt in 1898.\n\nTensor calculus was developed around 1890 by Gregorio Ricci-Curbastro under the title \"absolute differential calculus\", and originally presented by Ricci in 1892. It was made accessible to many mathematicians by the publication of Ricci and Tullio Levi-Civita's 1900 classic text \"Méthodes de calcul différentiel absolu et leurs applications\" (Methods of absolute differential calculus and their applications).\n\nIn the 20th century, the subject came to be known as \"tensor analysis\", and achieved broader acceptance with the introduction of Einstein's theory of general relativity, around 1915. General relativity is formulated completely in the language of tensors. Einstein had learned about them, with great difficulty, from the geometer Marcel Grossmann. Levi-Civita then initiated a correspondence with Einstein to correct mistakes Einstein had made in his use of tensor analysis. The correspondence lasted 1915–17, and was characterized by mutual respect:\n\nTensors were also found to be useful in other fields such as continuum mechanics. Some well-known examples of tensors in differential geometry are quadratic forms such as metric tensors, and the Riemann curvature tensor. The exterior algebra of Hermann Grassmann, from the middle of the nineteenth century, is itself a tensor theory, and highly geometric, but it was some time before it was seen, with the theory of differential forms, as naturally unified with tensor calculus. The work of Élie Cartan made differential forms one of the basic kinds of tensors used in mathematics.\n\nFrom about the 1920s onwards, it was realised that tensors play a basic role in algebraic topology (for example in the Künneth theorem). Correspondingly there are types of tensors at work in many branches of abstract algebra, particularly in homological algebra and representation theory. Multilinear algebra can be developed in greater generality than for scalars coming from a field. For example, scalars can come from a ring. But the theory is then less geometric and computations more technical and less algorithmic. Tensors are generalized within category theory by means of the concept of monoidal category, from the 1960s.\n\n\n\n\n"}
{"id": "1185505", "url": "https://en.wikipedia.org/wiki?curid=1185505", "title": "Trans bashing", "text": "Trans bashing\n\nTrans bashing is the act of victimizing a person emotionally, physically, sexually, or verbally because they are transgender or transsexual. The term has also been applied to hate speech directed at transgender people and at depictions of transgender people in the media that reinforce negative stereotypes about them.\n\nDiscrimination, including physical or sexual violence against trans people due to transphobia or homophobia, is a common occurrence for trans people. Hate crimes against trans people are common even recently, and \"in some instances, inaction by police or other government officials leads to the untimely deaths of transgender victims.\"\n\nOne of the most infamous incidents was the December 1993 rape and murder of Brandon Teena, a young trans man, by two male friends after they found out that he had been assigned female at birth. The events became internationally known when told in the feature film \"Boys Don't Cry\", which earned Hilary Swank an Academy Award for Best Actress.\n\nUnlike gay bashing, trans bashing is committed because of the target's actual or perceived gender identity, not sexual orientation. However, a trans person may be gay bashed if the person perceives them as gay rather than transgender.\n\nAt least since the Stonewall riots in 1969, people from the greater trans communities have often been politically aligned with the lesbian, gay, and bisexual communities. However, researchers and some activists from the greater trans communities argue trans bashing should be categorized separately from violence committed on the basis of sexual orientation (\"gay-bashing\"). Anti-trans bias crimes have been conceptually and characteristically distinguished from homophobic crimes in the scholarly research. One argument is that conflating violence against trans peoples with violence against gay people erases the identities of people in the greater trans communities and the truth of what happens to them. However, campaigns against gay bashing and trans bashing are often seen as a common cause.\n\nIn one case, perpetrators accused of hate crimes against trans people have tried to use a trans panic defense, an extension of gay panic defense. The jury deadlocked, but there is evidence they rejected the trans-panic defense. One law journal provided an analysis of the trans-panic defense, arguing in part that the emotional premise of a trans panic defense (shock at discovering unexpected genitals) is different from the emotional premise of a gay panic defense (shock at being propositioned by a member of the same sex, perhaps because of one's repressed homosexuality).\n\nThe United Nations adopted their Universal Declaration of Human Rights in 1948 as the first global declaration of human rights. There are a number of articles in the declaration that have been suggested to specifically pertain to transgender people and violence (including, but not limited to, physical, psychological, legal, systemic, emotional, and political violence), although LGBT rights are not explicitly outlined in the document.\n\n\nIn the United States, currently seventeen states plus the District of Columbia have hate crime laws protecting people victimized on the basis of their gender identity (they are California, Colorado, Connecticut, Delaware, Hawaii, Illinois, Maryland, Massachusetts, Minnesota, Missouri, Nevada, New Jersey, New Mexico, Oregon, Rhode Island, Vermont, Washington, and Washington, D.C.).\n\nIn the late 2000s in Seattle's gay village of Capitol Hill, there was evidence of an increase in incidents of trans bashing.\n\nThe Matthew Shepard Act expanded the federal hate crime laws to include gender, gender identity, and sexual orientation. In order to qualify as a federal hate crime in the United States, the crime must include successful or attempted bodily injury due to the use of firearm, explosives, weapons, fire, or incendiary devices. Hate crimes are covered by state, rather than federal laws unless the victim or defendant travel across state lines or national borders; using an interstate commuting route; the weapon has been brought across state lines; or if the conduct interferes with or otherwise affects commerce across state lines. This means that, unless hate crimes under the federal definition occur in a way that does not just affect one state, states have the freedom to implement their own hate crime laws. The protections of these laws range widely. Pennsylvania, for example, has not included gender identity in their hate crime protections since it was rescinded from the law in 2008.\n\nBathroom bills are bills proposed with relation to bathroom access and gender identity. There have been a number of bills proposed in the United States intended to limit access to restrooms for those who do not identify with the sex on their birth certificate. Some of these bills are justified with the rationale of protecting cisgender women from violent acts committed by cisgender men entering their facilities under the pretense of identifying as transgender women, although there is no evidence thus far of any incidences of this.\n\nSome transgender people are content, and may even prefer, using gender-neutral bathrooms, but others expect the right to use the bathroom of the gender with which they identify. The Gay, Lesbian, and Straight Education Network found that singling out trans students by offering them alternative facility options may backfire by increasing their chances of disengaging from school or dropping out entirely.\n\nIt is transgender people who are likely to be harassed in bathrooms by cisgender people, not the other way around. In one survey, 70 percent of the transgender respondents had faced discrimination when attempting to use a restroom of their gender identity, including \"denial of access to facilities, verbal harassment, and physical assault.\" An example of such harassment occurred in 2018, when California Republican Congressional candidate Jazmina Saavedra said she heard the \"voice of a man\" from a locked stall in the women's restroom of a fast-food restaurant in Los Angeles and filmed herself chasing the person out of the restaurant with assistance from the restaurant manager. In the video, Saavedra said she was prepared to use pepper spray and a stungun against the transgender woman. This kind of tactic can result in public outing of a transgender person's current or former gender identity.\n\nMalta passed the 'Gender Identity, Gender Expression, and Sex Characteristics Act in 2015. This bill states that all citizens of Malta have the right to\n\nThis act protects the gender identity of a person at all times. It also states that \"person shall not be required to provide proof of a surgical procedure for total or partial genital reassignment, hormonal therapies or any other psychiatric, psychological or medical treatment to make use of the right to gender identity.\" The act allows parents to postpone listing gender on a child's birth certificate and prohibits “non-medically necessary treatments on the sex characteristics of a person.”\n\nMedia can contribute to trans bashing through misinformation and scare tactics. Transgender individuals are oftentimes misrepresented negatively in media, or not represented in media at all.Transgender individuals may be portrayed in the media as curiosities or oddities, as mentally unstable persons, and/ or as predators. A public example of this is the attention paid to the transition of Chelsea Manning, a transgender U.S. Army soldier imprisoned for releasing classified documents to WikiLeaks. A Fox News story on Manning's transition was introduced with the Aerosmith song \"Dude (Looks Like a Lady)\", while host Gretchen Carlson referred to Chelsea by her birth name, Bradley, mocking \"The New York Times\" for \"helping him\" by using Manning's preferred gender pronoun. The Army refused to let her grow her hair as long as female prisoners, and continued referring to her as Bradley \"to avoid confusion\" until a court mandated her preferred gender pronouns.\n\nAccording to the 2011 National Transgender Discrimination Survey Report on Health and Health Care (NTDSR), which surveyed 6,450 transgender and gender non-conforming people, people who do not identify with their birth sex face obstacles to getting healthcare and have a greater likelihood of facing health issues related to their gender identity.\n\nTransgender people experience greater mental health problems, such as depression, anxiety, suicide attempts, and post traumatic stress disorder (PTSD), as well as physical health disparities (e.g., cardiovascular disease). Trans people also have a higher rate of suicide attempts than the population as a whole. In 2013, the 2.2% of U.S. adults had attempted suicide while 41% of trans people had attempted suicide in 2011. The rate of attempted suicide in transgender individuals increased to 51% for those bullied or harassed in school, 55% for those who recently lost a job due to bias, and 61% and 64% for those who were victims of physical and sexual assault, respectively.\nLow self-esteem in transgender people has been linked to being at high-risk for HIV transmission. In 2008, the rate of HIV in transgender women in North America was 27.7%.\n\nIn the 2010 and 2011 NTDSRs, 19% of the people surveyed reported having been refused medical care due to their gender identity and 50% reported lack of provider knowledge of transgender health needs.\nUnder the Affordable Care Act, it is illegal for any health program receiving federal funding to discriminate based on gender identity. Discrimination includes refusal to admit, treat or provide any services that are available for other patients; subjection of patients to intrusive examination; harass or refuse to respond to harassment by other staff or patients; refusal to provide support services; obligation to participate in conversion therapy; and any sort of interference in the pursuit of health care rights.\n\nRace has been shown to compound manifestations of existing discrimination on the basis of gender identity.\nBlack trans women have the highest suicide rate of any other group in the United States, at almost half attempting in their lives, while cisgender black women attempt suicide at a rate of 1.7% on average. \nTrans students of color face higher rates of harassment and violence in schools. American Indian transgender students face the highest rates of sexual assault in school at 24%, followed by multiracial (18%), Asian (17%), and black (15%) students. White transgender students face a 9% rate of sexual assault in K–12.\nBlack trans women have a higher rate of HIV infection than other groups, with a 30.8–56.3% rate, versus 27.7% of MTF transgender people on average.\n\nIn the 2011 National Transgender Discrimination Survey, 22% of respondents who had interacted with the police reported harassment due to bias. 20% reported denial of equal services. 48% reported being uncomfortable asking for police assistance. Respondents who had served time in jail reported a higher rate of harassment by officers than by others in jail. For all respondents, 7% reported being held in a jail cell solely due to gender identity expression, while this number was 41% for black and 21% for Latino trans respondents. \nTransgender people have reported being refused medical care, particularly hormone therapy, in prison, with black trans people and American Indian trans people with the highest reporting rates.\n\n\n"}
{"id": "49288430", "url": "https://en.wikipedia.org/wiki?curid=49288430", "title": "Women Power Line 1090", "text": "Women Power Line 1090\n\nThe Women Power Line 1090 is a IVRS based dedicated service in Uttar Pradesh, India, to empower women from all forms of harassment and ensure their safety in society. 1090 is a toll-free number that provides immediate help to the harassed women suffering from an antisocial behaviour or any other format of assistance which is sought. This helpline handles the cases of offense against women and ensures speedy protection to women and girls.\n\n\"Women Power Line\" was initiated by the Uttar Pradesh Government under the leadership of Akhilesh Yadav, the Chief Minister of Uttar Pradesh, on November 15, 2012 which is being operated by the Uttar Pradesh Police department headed by Navniet Sekera. The service was started to deal with the crime against women and to control the antisocial activities against women happening in the state of Uttar Pradesh. The idea came to light when the cases of ragging started to increase in universities. In the past three years (till 25 March 2015), about 3,230 cases have been registered of which around 3,170 cases have been successfully solved.\n\nThe helpline has been launched with the purpose of providing effective help to girls/women who become victims of any antisocial behaviour like eve-teasing, harassment, disrespect, or any other form of violence. The WPL personnel first goes for a counselling and then takes due legal action against the offender. \nThe mission of Women Powerline is to bring a revolutionary change in controlling crimes against women and creating a society where women can protest against harassment and molestation with courage.\n\nTo resolve the cases of harassment, the state police have set up an ultra-modern powerline and trained women police personnel to redress the cases of social harassment. The victim women can dial 1090 which is accessible from any telephone or mobile number to lodge complaints against harassment. A special team of women constables attend the calls and provide timely help to victims. The women constables, have received sensitivity and physiological training to ensure a safe and secure environment for all the callers. The identity of the caller is kept secret at all times.\n\nThe entire process is divided into stars which acts as a measure at each stage:\n\n\n"}
