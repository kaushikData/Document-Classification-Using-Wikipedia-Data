{"id": "54796126", "url": "https://en.wikipedia.org/wiki?curid=54796126", "title": "AS Long As Possible (ASLAP)", "text": "AS Long As Possible (ASLAP)\n\nAS Long As Possible (ASLAP) (2015-2017) is a visual art work by Finnish artist Juha van Ingen, consisting of a 1000-year long GIF animation loop. It premiered at Kiasma National Museum of Contemporary Art in Helsinki on 28 March 2017. The animation is created in collaboration with developer and sound artist Janne Särkelä.\n\nASLAP belongs to a group of art works where extreme duration is an essential part of the concept, like for instance Canadian artist Rodney Graham's Parsifal (1882—38,969,364,735) based on a musical score by Richard Wagner's assistant Engelbert Humperdinck, a work that was initiated in 1990 and in theory is playing for another 39 billion years – three times longer than the estimated age of the Universe. Other well known examples are Longplayer by Jem Finer (of the Pogues) sounding from the Trinity Buoy lighthouse near Canary Wharf in London and the yet to be realised 10,000-year Clock of the Long Now by the Long Now Foundation in USA.\n\nThe work is developed as a GIF animation, with each frame lasting 655090 milliseconds, which is approximately 10,5 minutes. The total number of frames is 48 140 288 making the duration of the animation 1000 years. The GIF file contains a loop function which will automatically, after the last frame has played, start the animation all over. ASLAP is intended to continue to play for ever.\n\nThe animation was developed in 2015, and premiered at Kiasma Museum of Contemporary Art in Helsinki in 2017, coinciding with the 30 year anniversary of the GIF format. ASLAP was presented in the context of ARS 17: ”Hello World”, a major exhibition of international contemporary art on the theme of postinternet art.\n\nThe name of ASLAP is homage to the musical composition ORGAN²/ASLSP (1987) by John Cage which is currently played on the church organ of St. Burchardi church in Halberstadt in Germany since its premiere in 2001, and will continue to play for the next 639 years. The abbreviation of Cage's composition includes an instruction to the performer of the piece on how to perform the work: As SLow aS Possible.\n\nThe ASLAP file is cloned and it will simultaneously run on six physical playback units at different geographical locations. When one unit is destroyed for any reason, or when it needs to be technically upgraded, a new physical unit is built and the animation file is cloned and synchronised with the remaining units. If all of the playback units are destroyed the file is to be reconstructed from special time capsules that contain the description of the artwork, the specifications of the GIF format, the original GIF file and necessary documents including a printed copy of the code for generating a new file.\n\nThe first ASLAP play back unit is included in the collection of The Finnish National Gallery and is playing and stored in Helsinki. The Finnish National Gallery has agreed to keep the animation playing until 3017. \n\nThe first time capsule was deposited 18 March 2017 into the Kumu Art Museum of Estonia collection and is permanently stored in Tallinn, Estonia.\n\nApart from the projected image of the ASLAP animation, the art work as presented by Kiasma included a player programmed by Jani Lindqvist, a computer, and a stainless steel box to protect the file and equipment through its life time. The installation also contained three digital prints of ASLAP frames and the printed binary code of the ASLAP GIF-file, frames 1 - 40100.\n\n"}
{"id": "56528952", "url": "https://en.wikipedia.org/wiki?curid=56528952", "title": "Akeed", "text": "Akeed\n\nThe Jordanian Media Credibility Monitor \"Akeed\" is a tool that tracks the content of media outlets in Jordan. It tracks the credibility of news material that is published and broadcast by Jordanian media outlets. It is one of the projects of the Jordan Media Institute. \n\nAkeed was founded in 2014 with support from the King Abdullah Fund for Development as part of the Democratic Empowerment Programme. It is intended to holds Jordanian media outlets accountable, and to examine the credibility of news material that is published and broadcast. It also publishes periodic reports on the news.\n"}
{"id": "471476", "url": "https://en.wikipedia.org/wiki?curid=471476", "title": "Astronomical system of units", "text": "Astronomical system of units\n\nThe astronomical system of units, formally called the IAU (1976) System of Astronomical Constants, is a system of measurement developed for use in astronomy. It was adopted by the International Astronomical Union (IAU) in 1976, and has been significantly updated in 1994 and 2009 (see astronomical constant).\n\nThe system was developed because of the difficulties in measuring and expressing astronomical data in International System of Units (SI units). In particular, there is a huge quantity of very precise data relating to the positions of objects within the Solar System which cannot conveniently be expressed or processed in SI units. Through a number of modifications, the astronomical system of units now explicitly recognizes the consequences of general relativity, which is a necessary addition to the International System of Units in order to accurately treat astronomical data.\n\nThe astronomical system of units is a tridimensional system, in that it defines units of length, mass and time. The associated astronomical constants also fix the different frames of reference that are needed to report observations. The system is a conventional system, in that neither the unit of length nor the unit of mass are true physical constants, and there are at least three different measures of time.\n\nThe astronomical unit of time is the Day, defined as seconds. 365.25 days make up one Julian year. The symbol \"D\" is used in astronomy to refer to this unit.\n\nThe astronomical unit of mass is the solar mass. The symbol is often used to refer to this unit.\nThe solar mass (), , is a standard way to express mass in astronomy, used to describe the masses of other stars and galaxies. It is equal to the mass of the Sun, about times the mass of the Earth or 1 048 times the mass of Jupiter.\n\nIn practice, the masses of celestial bodies appear in the dynamics of the Solar System only through the products \"GM\", where \"G\" is the constant of gravitation. In the past, \"GM\" of the Sun could be determined experimentally with only limited accuracy. Its present accepted value is \n\nJupiter mass ( or \"M\"), is the unit of mass equal to the total mass of the planet Jupiter, . Jupiter mass is used to describe masses of the gas giants, such as the outer planets and extrasolar planets. It is also used in describing brown dwarfs and Neptune-mass planets.\n\nEarth mass () is the unit of mass equal to that of the Earth. 1 = . Earth mass is often used to describe masses of rocky terrestrial planets. It is also used to describe Neptune-mass planets. One Earth mass is times a Jupiter mass.\n\nThe astronomical unit of length is now defined as exactly 149 597 870 700 meters. It is approximately equal to the mean Earth–Sun distance. It was formerly defined as that length for which the Gaussian gravitational constant (\"k\") takes the value when the units of measurement are the astronomical units of length, mass and time. The dimensions of \"k\" are those of the constant of gravitation (\"G\"), i.e., LMT. The term “unit distance” is also used for the length \"A\" while, in general usage, it is usually referred to simply as the “astronomical unit”, symbol au.\n\nAn equivalent formulation of the old definition of the astronomical unit is the radius of an unperturbed circular Newtonian orbit about the Sun of a particle having infinitesimal mass, moving with a mean motion of radians per day. \nThe speed of light in IAU is the defined value \"c\" =  of the SI units. In terms of this speed, the old definition of the astronomical unit of length had the accepted value: 1 ua = \"c\"τ =  ± 3 m, where τ is the transit time of light across the astronomical unit. The astronomical unit of length was determined by the condition that the measured data in the ephemeris match observations, and that in turn decides the transit time τ.\n\nThe distances to distant galaxies are typically not quoted in distance units at all, but rather in terms of redshift. The reasons for this are that converting redshift to distance requires knowledge of the Hubble constant which was not accurately measured until the early 21st century, and that at cosmological distances, the curvature of space-time allows one to come up with multiple definitions for distance. For example, the distance as defined by the amount of time it takes for a light beam to travel to an observer is different from the distance as defined by the apparent size of an object.\n\n\n"}
{"id": "4868", "url": "https://en.wikipedia.org/wiki?curid=4868", "title": "B. F. Skinner", "text": "B. F. Skinner\n\nBurrhus Frederic Skinner (March 20, 1904 – August 18, 1990), commonly known as B. F. Skinner, was an American psychologist, behaviorist, author, inventor, and social philosopher. He was the Edgar Pierce Professor of Psychology at Harvard University from 1958 until his retirement in 1974.\n\nSkinner considered free will an illusion and human action dependent on consequences of previous actions. If the consequences are bad, there is a high chance the action will not be repeated; if the consequences are good, the probability of the action being repeated becomes stronger. Skinner called this the principle of reinforcement.\n\nTo strengthen behavior, Skinner used operant conditioning, and he considered the rate of response to be the most effective measure of response strength. To study operant conditioning, he invented the operant conditioning chamber, also known as the Skinner Box, and to measure rate he invented the \"cumulative recorder\". Using these tools, he and C. B. Ferster produced his most influential experimental work, which appeared in their book \"Schedules of Reinforcement\" (1957).\n\nSkinner developed behavior analysis, the philosophy of that science he called radical behaviorism, and founded a school of experimental research psychology—the experimental analysis of behavior. He imagined the application of his ideas to the design of a human community in his utopian novel, \"Walden Two\", and his analysis of human behavior culminated in his work, \"Verbal Behavior\".\nSkinner was a prolific author who published 21 books and 180 articles. Contemporary academia considers Skinner a pioneer of modern behaviorism, along with John B. Watson and Ivan Pavlov. A June 2002 survey listed Skinner as the most influential psychologist of the 20th century.\n\nSkinner was born in Susquehanna, Pennsylvania, to Grace and William Skinner. His father was a lawyer. He became an atheist after a Christian teacher tried to assuage his fear of the hell that his grandmother described. His brother Edward, two and a half years younger, died at age sixteen of a cerebral hemorrhage.\n\nSkinner's closest friend as a young boy was Raphael Miller, whom he called Doc because his father was a doctor. Doc and Skinner became friends due to their parents’ religiousness and both had an interest in contraptions and gadgets. They had set up a telegraph line between their houses to send messages to each other, although they had to call each other on the telephone due to the confusing messages sent back and forth. During one summer, Doc and Skinner started an elderberry business to gather berries and sell them door to door. They had found out that when they picked the ripe berries, the unripe ones came off the branches too, so they built a device that was able to separate them. The device was a bent piece of metal to form a trough. They would pour water down the trough into a bucket, and the ripe berries would sink into the bucket and the unripe ones would be pushed over the edge to be thrown away.\n\nHe attended Hamilton College in New York with the intention of becoming a writer. He found himself at a social disadvantage at Hamilton College because of his intellectual attitude. While attending, he joined Lambda Chi Alpha fraternity. Hamilton was known for being a strong fraternity college. Skinner had thought that his fraternity brothers were respectful and did not haze or mistreat the newcomers, instead, they helped out the other boys with courses or other activities. Freshmen were called “‘slimers’” who had to wear small green knit hats and greet everyone that they passed for punishment. The year before Skinner entered Hamilton, there was a hazing accident that caused the death of a student. The freshman was asleep in his bed when he was pushed onto the floor, where he smashed his head, resulting in his death. Skinner had a similar incident where two freshmen captured him and tied him to a pole, where he should have stayed all night, but he had a razor blade in his shoe for emergency and managed to cut himself free. He wrote for the school paper, but, as an atheist, he was critical of the traditional mores of his college. After receiving his Bachelor of Arts in English literature in 1926, he attended Harvard University, where he would later research, teach, and eventually become a prestigious board member. While he was at Harvard, a fellow student, Fred Keller, convinced Skinner that he could make an experimental science from the study of behavior. This led Skinner to invent his prototype for the Skinner Box and to join Keller in the creation of other tools for small experiments. After graduation, he unsuccessfully tried to write a great novel while he lived with his parents, a period that he later called the Dark Years. He became disillusioned with his literary skills despite encouragement from the renowned poet Robert Frost, concluding that he had little world experience and no strong personal perspective from which to write. His encounter with John B. Watson's \"Behaviorism\" led him into graduate study in psychology and to the development of his own version of behaviorism.\n\nSkinner received a PhD from Harvard in 1931, and remained there as a researcher until 1936. He then taught at the University of Minnesota at Minneapolis and later at Indiana University, where he was chair of the psychology department from 1946–1947, before returning to Harvard as a tenured professor in 1948. He remained at Harvard for the rest of his life. In 1973, Skinner was one of the signers of the Humanist Manifesto II.\n\nIn 1936, Skinner married Yvonne (Eve) Blue. The couple had two daughters, Julie (m. Vargas) and Deborah (m. Buzan). Yvonne Skinner died in 1997, and is buried in Mount Auburn Cemetery, Cambridge, Massachusetts.\n\nSkinner's public exposure had increased in the 1970s, he remained active even after his retirement in 1974, until his death. In 1989, Skinner was diagnosed with leukemia and died on August 18, 1990 in Cambridge, Massachusetts. Ten days before his death, he was given the lifetime achievement award by the American Psychological Association and gave a talk in an auditorium concerning his work.\n\nA controversial figure, Skinner has been depicted in many different ways. He has been widely revered for bringing a much-needed scientific approach to the study of human behavior; he has also been vilified for attempting to apply findings based largely on animal experiments to human behavior in real-life settings.\n\nSkinner called his approach to the study of behavior radical behaviorism. This philosophy of behavioral science assumes that behavior is a consequence of environmental histories of reinforcement (see Applied behavior analysis). In contrast to the approach of cognitive science, behaviorism does not accept private events such as thinking, perceptions, and unobservable emotions as causes of an organism's behavior. However, in contrast to methodological behaviorism, Skinner's radical behaviorism did accept thoughts, emotions, and other \"private events\" as responses subject to the same rules as overt behavior. In his words: \n\nIn this way we repair the major damage wrought by mentalism. When what a person does [is] attributed to what is going on inside him, investigation is brought to an end. Why explain the explanation? For twenty five hundred years people have been preoccupied with feelings and mental life, but only recently has any interest been shown in a more precise analysis of the role of the environment. Ignorance of that role led in the first place to mental fictions, and it has been perpetuated by the explanatory practices to which they gave rise.\n\nSkinner's behavioral theory was largely set forth in his first book, \"Behavior of Organisms\". Here he gave a systematic description of the manner in which environmental variables control behavior. He distinguished two sorts of behavior—respondent and operant—which are controlled in different ways. \"Respondent\" behaviors are elicited by stimuli, and may be modified through respondent conditioning, which is often called \"Pavlovian conditioning\" or \"classical conditioning\", in which a neutral stimulus is paired with an eliciting stimulus. \"Operant\" behaviors, in contrast, are \"emitted\", meaning that initially they are not induced by any particular stimulus. They are strengthened through operant conditioning, sometimes called \"instrumental conditioning\", in which the occurrence of a response yields a reinforcer. Respondent behaviors might be measured by their latency or strength, operant behaviors by their rate. Both of these sorts of behavior had already been studied experimentally, for example, respondents by Pavlov, and operants by Thorndike. Skinner's account differed in some ways from earlier ones, and was one of the first accounts to bring them under one roof.\n\nThe idea that behavior is strengthened or weakened by its consequences raises several questions. Among the most important are these: (1) Operant responses are strengthened by reinforcement, but where do they come from in the first place? (2) Once it is in the organism's repertoire, how is a response directed or controlled? (3) How can very complex and seemingly novel behaviors be explained?\n\nSkinner's answer to the first question was very much like Darwin's answer to the question of the origin of a \"new\" bodily structure, namely, variation and selection. Similarly, the behavior of an individual varies from moment to moment; a variation that is followed by reinforcement is strengthened and becomes prominent in that individual's behavioral repertoire. \"Shaping\" was Skinner's term for the gradual modification of behavior by the reinforcement of desired variations. As discussed later in this article, Skinner believed that \"superstitious\" behavior can arise when a response happens to be followed by reinforcement to which it is actually unrelated.\n\nThe second question, \"how is operant behavior controlled?\" arises because, to begin with, the behavior is \"emitted\" without reference to any particular stimulus. Skinner answered this question by saying that a stimulus comes to control an operant if it is present when the response is reinforced and absent when it is not. For example, if lever-pressing only brings food when a light is on, a rat, or a child, will learn to press the lever only when the light is on. Skinner summarized this relationship by saying that a discriminative stimulus (e.g. light) sets the occasion for the reinforcement (food) of the operant (lever-press). This three-term contingency (stimulus-response-reinforcer) is one of Skinner's most important concepts, and sets his theory apart from theories that use only pair-wise associations.\n\nMost behavior of humans cannot easily be described in terms of individual responses reinforced one by one, and Skinner devoted a great deal of effort to the problem of behavioral complexity. Some complex behavior can be seen as a sequence of relatively simple responses, and here Skinner invoked the idea of \"chaining.\" Chaining is based on the fact, experimentally demonstrated, that a discriminative stimulus not only sets the occasion for subsequent behavior, but it can also reinforce a behavior that precedes it. That is, a discriminative stimulus is also a \"conditioned reinforcer.\" For example, the light that sets the occasion for lever pressing may also be used to reinforce \"turning around\" in the presence of a noise. This results in the sequence \"noise - turn-around - light - press lever - food.\" Much longer chains can be built by adding more stimuli and responses.\n\nHowever, Skinner recognized that a great deal of behavior, especially human behavior, cannot be accounted for by gradual shaping or the construction of response sequences. Complex behavior often appears suddenly in its final form, as when a person first finds his way to the elevator by following instructions given at the front desk. To account for such behavior, Skinner introduced the concept of rule-governed behavior. First, relatively simple behaviors come under the control of verbal stimuli: the child learns to \"jump\", \"open the book\", and so on. After a large number of responses come under such verbal control, a sequence of verbal stimuli can evoke an almost unlimited variety of complex responses.\n\nReinforcement, a key concept of behaviorism, is the primary process that shapes and controls behavior, and occurs in two ways, \"positive\" and \"negative.\" In \"The Behavior of Organisms\" (1938), Skinner defined \"negative reinforcement\" to be synonymous with punishment, that is, the presentation of an aversive stimulus. Subsequently, in \"Science and Human Behavior\" (1953), Skinner redefined negative reinforcement. In what has now become the standard set of definitions, positive reinforcement is the strengthening of behavior by the occurrence of some event (e.g., praise after some behavior is performed), whereas negative reinforcement is the strengthening of behavior by the removal or avoidance of some aversive event (e.g., opening and raising an umbrella over your head on a rainy day is reinforced by the cessation of rain falling on you).\n\nBoth types of reinforcement strengthen behavior, or increase the probability of a behavior reoccurring; the difference is in whether the reinforcing event is something applied (positive reinforcement) or something removed or avoided (negative reinforcement). Punishment is the application of an aversive stimulus/event (positive punishment or punishment by contingent stimulation) or the removal of a desirable stimulus (negative punishment or punishment by contingent withdrawal). Though punishment is often used to suppress behavior, Skinner argued that this suppression is temporary and has a number of other, often unwanted, consequences. Extinction is the absence of a rewarding stimulus, which weakens behavior.\n\nWriting in 1981, Skinner pointed out that Darwinian natural selection is, like reinforced behavior, \"selection by consequences.\" Though, as he said, natural selection has now \"made its case\", he regretted that essentially the same process, \"reinforcement\", was less widely accepted as underlying human behavior.\n\nSkinner recognized that behavior is typically reinforced more than once, and, together with C. B. Ferster, he did an extensive analysis of the various ways in which reinforcements could be arranged over time, which he called \"schedules of reinforcement.\"\n\nThe most notable schedules of reinforcement studied by Skinner were continuous, interval (fixed or variable), and ratio (fixed or variable). All are methods used in operant conditioning.\n\n\nAn operant conditioning chamber (also known as a \"Skinner Box\") is a laboratory apparatus used in the experimental analysis of animal behavior. It was invented by Skinner while he was a graduate student at Harvard University. As used by Skinner, the box had a lever (for rats), or a disk in one wall (for pigeons). A press on this \"manipulandum\" could deliver food to the animal through an opening in the wall, and responses reinforced in this way increased in frequency. By controlling this reinforcement together with discriminative stimuli such as lights and tones, or punishments such as electric shocks, experimenters have used the operant box to study a wide variety of topics, including schedules of reinforcement, discriminative control, delayed response (\"memory\"), punishment, and so on. By channeling research in these directions, the operant conditioning chamber has had a huge influence on course of research in animal learning and its applications. It enabled great progress on problems that could be studied by measuring the rate, probability, or force of a simple, repeatable response. However, it discouraged the study of behavioral processes not easily conceptualized in such terms—spatial learning, in particular, which is now studied in quite different ways, for example, by the use of the water maze.\n\nThe cumulative recorder makes a pen-and-ink record of simple repeated responses. Skinner designed it for use with the Operant chamber as a convenient way to record and view the rate of responses such as a lever press or a key peck. In this device, a sheet of paper gradually unrolls over a cylinder. Each response steps a small pen across the paper, starting at one edge; when the pen reaches the other edge, it quickly resets to the initial side. The slope of the resulting ink line graphically displays the rate of the response; for example, rapid responses yield a steeply sloping line on the paper, slow responding yields a line of low slope. The cumulative recorder was a key tool used by Skinner in his analysis of behavior, and it was very widely adopted by other experimenters, gradually falling out of use with the advent of the laboratory computer. Skinner's major experimental exploration of response rates, presented in his book with C. B. Ferster, \"Schedules of Reinforcement\", is full of cumulative records produced by this device.\n\nThe air crib is an easily cleaned, temperature- and humidity-controlled enclosure intended to replace the standard infant crib. \nSkinner invented the device to help his wife cope with the day-to-day tasks of child rearing. It was designed to make early childcare simpler (by reducing laundry, diaper rash, cradle cap, etc.), while allowing the baby to be more mobile and comfortable, and less prone to cry. Reportedly it had some success in these goals.\n\nThe air crib was a controversial invention. It was popularly mischaracterized as a cruel pen, and it was often compared to Skinner's operant conditioning chamber, commonly called the \"Skinner Box.\" This association with laboratory animal experimentation discouraged its commercial success, though several companies attempted production.\n\nA 2004 book by Lauren Slater, entitled \"\" caused a stir by mentioning the rumors that Skinner had used his baby daughter, Deborah, in some of his experiments, and that she had subsequently committed suicide. Although Slater's book stated that the rumors were false, a reviewer in \"The Observer\" in March 2004 misquoted Slater's book as supporting the rumors. This review was read by Deborah Skinner (now Deborah Buzan, an artist and writer living in London) who wrote a vehement riposte in \"The Guardian\".\n\nThe teaching machine was a mechanical device whose purpose was to administer a curriculum of programmed learning. The machine embodies key elements of Skinner's theory of learning and had important implications for education in general and classroom instruction in particular.\n\nIn one incarnation, the machine was a box that housed a list of questions that could be viewed one at a time through a small window. (See picture). There was also a mechanism through which the learner could respond to each question. Upon delivering a correct answer, the learner would be rewarded.\n\nSkinner advocated the use of teaching machines for a broad range of students (e.g., preschool aged to adult) and instructional purposes (e.g., reading and music). For example, one machine that he envisioned could teach rhythm. He wrote:A relatively simple device supplies the necessary contingencies. The student taps a rhythmic pattern in unison with the device. \"Unison\" is specified very loosely at first (the student can be a little early or late at each tap) but the specifications are slowly sharpened. The process is repeated for various speeds and patterns. In another arrangement, the student echoes rhythmic patterns sounded by the machine, though not in unison, and again the specifications for an accurate reproduction are progressively sharpened. Rhythmic patterns can also be brought under the control of a printed score.The instructional potential of the teaching machine stemmed from several factors: it provided automatic, immediate and regular reinforcement without the use of aversive control; the material presented was coherent, yet varied and novel; the pace of learning could be adjusted to suit the individual. As a result, students were interested, attentive, and learned efficiently by producing the desired behavior, \"learning by doing.\"\n\nTeaching machines, though perhaps rudimentary, were not rigid instruments of instruction. They could be adjusted and improved based upon the students' performance. For example, if a student made many incorrect responses, the machine could be reprogrammed to provide less advanced prompts or questions—the idea being that students acquire behaviors most efficiently if they make few errors. Multiple-choice formats were not well-suited for teaching machines because they tended to increase student mistakes, and the contingencies of reinforcement were relatively uncontrolled.\n\nNot only useful in teaching explicit skills, machines could also promote the development of a repertoire of behaviors that Skinner called self-management. Effective self-management means attending to stimuli appropriate to a task, avoiding distractions, reducing the opportunity of reward for competing behaviors, and so on. For example, machines encourage students to pay attention before receiving a reward. Skinner contrasted this with the common classroom practice of initially capturing students’ attention (e.g., with a lively video) and delivering a reward (e.g., entertainment) before the students have actually performed any relevant behavior. This practice fails to reinforce correct behavior and actually counters the development of self-management.\n\nSkinner pioneered the use of teaching machines in the classroom, especially at the primary level. Today computers run software that performs similar teaching tasks, and there has been a resurgence of interest in the topic related to the development of adaptive learning systems.\n\nDuring World War II, the US Navy required a weapon effective against surface ships, such as the German \"Bismarck\" class battleships. Although missile and TV technology existed, the size of the primitive guidance systems available rendered automatic guidance impractical. To solve this problem, Skinner initiated Project Pigeon, which was intended to provide a simple and effective guidance system. This system divided the nose cone of a missile into three compartments, with a pigeon placed in each. Lenses projected an image of distant objects onto a screen in front of each bird. Thus, when the missile was launched from an aircraft within sight of an enemy ship, an image of the ship would appear on the screen. The screen was hinged, such that pecks at the image of the ship would guide the missile toward the ship.\n\nDespite an effective demonstration, the project was abandoned, and eventually more conventional solutions, such as those based on radar, became available. Skinner complained that \"our problem was no one would take us seriously.\" It seemed that few people would trust pigeons to guide a missile, no matter how reliable the system appeared to be.\n\nEarly in his career Skinner became interested in \"latent speech\" and experimented with a device he called the \"verbal summator.\" This device can be thought of as an auditory version of the Rorschach inkblots. When using the device, human participants listened to incomprehensible auditory \"garbage\" but often read meaning into what they heard. Thus, as with the Rorschach blots, the device was intended to yield overt behavior that projected subconscious thoughts. Skinner's interest in projective testing was brief, but he later used observations with the summator in creating his theory of verbal behavior. The device also led other researchers to invent new tests such as the tautophone test, the auditory apperception test, and the Azzageddi test.\n\nChallenged by Alfred North Whitehead during a casual discussion while at Harvard to provide an account of a randomly provided piece of verbal behavior, Skinner set about attempting to extend his then-new functional, inductive approach to the complexity of human verbal behavior. Developed over two decades, his work appeared in the book \"Verbal Behavior\". Although Noam Chomsky was highly critical of \"Verbal Behavior\", he conceded that Skinner's \"S-R psychology\" was worth a review. (Behavior analysts reject the \"S-R\" characterization: operant conditioning involves the emission of a response which then becomes more or less likely depending upon its consequence–see above.).\n\n\"Verbal Behavior\" had an uncharacteristically cool reception, partly as a result of Chomsky's review, partly because of Skinner's failure to address or rebut any of Chomsky's criticisms. Skinner's peers may have been slow to adopt the ideas presented in \"Verbal Behavior\" because of the absence of experimental evidence—unlike the empirical density that marked Skinner's experimental work. However, in applied settings there has been a resurgence of interest in Skinner's functional analysis of verbal behavior.\n\nSkinner's views influenced education as well as psychology. Skinner argued that education has two major purposes: (1) to teach repertoires of both verbal and nonverbal behavior; and (2) to interest students in learning. He recommended bringing students’ behavior under appropriate control by providing reinforcement only in the presence of stimuli relevant to the learning task. Because he believed that human behavior can be affected by small consequences, something as simple as \"the opportunity to move forward after completing one stage of an activity\" can be an effective reinforcer . Skinner was convinced that, to learn, a student must engage in behavior, and not just passively receive information. (Skinner, 1961, p. 389).\n\nSkinner believed that effective teaching must be based on positive reinforcement which is, he argued, more effective at changing and establishing behavior than punishment. He suggested that the main thing people learn from being punished is how to avoid punishment. For example, if a child is forced to practice playing an instrument, the child comes to associate practicing with punishment and thus learns to hate and avoid practicing the instrument. This view had obvious implications for the then widespread practice of rote learning and punitive discipline in education. The use of educational activities as punishment may induce rebellious behavior such as vandalism or absence.\n\nBecause teachers are primarily responsible for modifying student behavior, Skinner argued that teachers must learn effective ways of teaching. In \"The Technology of Teaching\", Skinner has a chapter on why teachers fail (pages 93–113): He says that teachers have not been given an in-depth understanding of teaching and learning. Without knowing the science underpinning teaching, teachers fall back on procedures that work poorly or not at all, such as:\n\nSkinner suggests that any age-appropriate skill can be taught. The steps are\nSkinner's views on education are extensively presented in his book \"The Technology of Teaching\". They are also reflected in Fred S. Keller's \"Personalized System of Instruction\" and Ogden R. Lindsley's \"Precision Teaching\".\n\nSkinner is popularly known mainly for his books \"Walden Two\" and \"Beyond Freedom and Dignity,\" (for which he made the cover of \"TIME\" Magazine). The former describes a fictional \"experimental community\" in 1940s United States. The productivity and happiness of citizens in this community is far greater than in the outside world because the residents practice scientific social planning and use operant conditioning in raising their children.\n\n\"Walden Two\", like Thoreau's \"Walden\", champions a lifestyle that does not support war, or foster competition and social strife. It encourages a lifestyle of minimal consumption, rich social relationships, personal happiness, satisfying work, and leisure. In 1967, Kat Kinkade and others founded the Twin Oaks Community, using Walden Two as a blueprint. The community still exists and continues to use the Planner-Manager system and other aspects of the community described in Skinner's book, though behavior modification is not a community practice.\n\nIn \"Beyond Freedom and Dignity\", Skinner suggests that a technology of behavior could help to make a better society. We would, however, have to accept that an autonomous agent is not the driving force of our actions. Skinner offers alternatives to punishment, and challenges his readers to use science and modern technology to construct a better society.\n\nSkinner's political writings emphasized his hopes that an effective and human science of behavioral control – a technology of human behavior – could help with problems as yet unsolved and often aggravated by advances in technology such as the atomic bomb. Indeed, one of Skinner's goals was to prevent humanity from destroying itself. He saw political activity as the use of aversive or non-aversive means to control a population. Skinner favored the use of positive reinforcement as a means of control, citing Jean-Jacques Rousseau's novel \"\" as an example of literature that \"did not fear the power of positive reinforcement.\"\n\nSkinner's book, \"Walden Two\", presents a vision of a decentralized, localized society, which applies a practical, scientific approach and behavioral expertise to deal peacefully with social problems. (For example, his views led him to oppose corporal punishment in schools, and he wrote a letter to the California Senate that helped lead it to a ban on spanking.) Skinner's utopia is both a thought experiment and a rhetorical piece. In \"Walden Two\", Skinner answers the problem that exists in many utopian novels – \"What is the Good Life?\" The book's answer is a life of friendship, health, art, a healthy balance between work and leisure, a minimum of unpleasantness, and a feeling that one has made worthwhile contributions to a society in which resources are ensured, in part, by minimizing consumption. \n\nSkinner described his novel as \"my New Atlantis\", in reference to Bacon's utopia. \n\nOne of Skinner's experiments examined the formation of superstition in one of his favorite experimental animals, the pigeon. Skinner placed a series of hungry pigeons in a cage attached to an automatic mechanism that delivered food to the pigeon \"at regular intervals with no reference whatsoever to the bird's behavior.\" He discovered that the pigeons associated the delivery of the food with whatever chance actions they had been performing as it was delivered, and that they subsequently continued to perform these same actions.\n\nSkinner suggested that the pigeons behaved as if they were influencing the automatic mechanism with their \"rituals\", and that this experiment shed light on human behavior:\n\nModern behavioral psychologists have disputed Skinner's \"superstition\" explanation for the behaviors he recorded. Subsequent research (e.g. Staddon and Simmelhag, 1971), while finding similar behavior, failed to find support for Skinner's \"adventitious reinforcement\" explanation for it. By looking at the timing of different behaviors within the interval, Staddon and Simmelhag were able to distinguish two classes of behavior: the \"terminal response\", which occurred in anticipation of food, and \"interim responses\", that occurred earlier in the interfood interval and were rarely contiguous with food. Terminal responses seem to reflect classical (as opposed to operant) conditioning, rather than adventitious reinforcement, guided by a process like that observed in 1968 by Brown and Jenkins in their \"autoshaping\" procedures. The causation of interim activities (such as the schedule-induced polydipsia seen in a similar situation with rats) also cannot be traced to adventitious reinforcement and its details are still obscure (Staddon, 1977).\n\nAs understood by Skinner, ascribing \"dignity\" to individuals involves giving them credit for their actions. To say \"Skinner is brilliant\" means that Skinner is an originating force. If Skinner's determinist theory is right, he is merely the focus of his environment. He is not an originating force and he had no choice in saying the things he said or doing the things he did. Skinner's environment and genetics both allowed and compelled him to write his book. Similarly, the environment and genetic potentials of the advocates of freedom and dignity cause them to resist the reality that their own activities are deterministically grounded. J. E. R. Staddon (\"The New Behaviorism, 2nd Edition\", 2014) has argued the compatibilist position; Skinner's determinism is not in any way contradictory to traditional notions of reward and punishment, as he believed.\n\nNoam Chomsky, a prominent critic of Skinner, published a review of Skinner's \"Verbal Behavior\" two years after it was published. Chomsky argued that Skinner's attempt to use behaviorism to explain human language amounted to little more than word games. Conditioned responses could not account for a child's ability to create or understand an infinite variety of novel sentences. Chomsky's review has been credited with launching the cognitive revolution in psychology and other disciplines. Skinner, who rarely responded directly to critics, never formally replied to Chomsky's critique. Many years later, Kenneth MacCorquodale's reply was endorsed by Skinner.\n\nChomsky also reviewed Skinner's \"Beyond Freedom and Dignity\", using the same basic motives as his \"Verbal Behavior\" review. Among Chomsky's criticisms were that Skinner's laboratory work could not be extended to humans, that when it was extended to humans it represented 'scientistic' behavior attempting to emulate science but which was not scientific, that Skinner was not a scientist because he rejected the hypothetico-deductive model of theory testing, and that Skinner had no science of behavior.\n\nSkinner has been repeatedly criticized for his supposed animosity towards Sigmund Freud, psychoanalysis, and psychodynamic psychology. Some have argued, however, that Skinner shared several of Freud's assumptions, and that he was influenced by Freudian points of view in more than one field, among them the analysis of defense mechanisms, such as repression. To study such phenomena, Skinner even designed his own projective test, the \"verbal summator\" described above.\n\n\nSkinner received honorary degrees from:\n\nWriter of \"The Simpsons\" Jon Vitti named the Principal Skinner character after behavioral psychologist B. F. Skinner.\n\n\n\n\n"}
{"id": "26778610", "url": "https://en.wikipedia.org/wiki?curid=26778610", "title": "Cartoon violence", "text": "Cartoon violence\n\nCartoon violence is the representation of violent actions involving animated characters and situations. This may include violence where a character is unharmed after the action has been inflicted.\n\nPeople have different views about cartoons and the violence within them. Some researchers believe that high level of violence in cartoons can make children more aggressive. Their studies also found that young children tend to mimic the negative behavior they see on television. Output aimed at children as young as seven, which include a number of cartoons, had the highest levels of violence.\n\nSome researches on the other hand believe that people need to consider the ways in which children process information, the amount of mental effort they invest, and their own life experience to gain an understanding of how television violence affects children. For instance recent research has indicated that children do not appear to mimic acts of violence in the media, whether television or cartoons.\nBlumberg, Bierwirth and Schwartz argue that children possess the ability to differentiate real life from animation, as well as the ability to understand right from wrong. They know that violent acts qualify as immoral and infringe on the welfare of others, therefore the violence witnessed in cartoons will register as \"make believe\" to children and will not be applied into their real lives.\n\nThere are a number of ways parents can control their children’s exposure to violence. One of the most effective and common ways of prevention is restricting the amount and types of programs children watch. With older children, parents might want to discuss, and explain television. This can help children to understand television material and overcome the effect TV violence has on their outlook and behaviors.\n\nThree initiatives have been put in place to combat violence in cartoons (). The first is The Children's Television Act which requires broadcasters to air shows which are educational and provide information for the children. The second initiative is the V-chip legislation that gives parents the opportunity to block out violent shows from their television. The third legislation against violent cartoons is the National Cable Television Association’s TV Parental Guidelines, which is a system that rates the Television shows based on their contents\n\nIn action-adventure oriented cartoons, the most consistent avenue of addressing violence is the use of a form of fantasy violence in which no one is injured or killed onscreen. In science fiction cartoons, for example, enemy forces are typically said to be robots so that they may be destroyed in bulk by the heroes without concern over killing living beings. In cases where vehicles are known to be piloted by living beings, tanks, aircraft, and other war vehicles that are destroyed in combat always allow time for the pilot to escape or bail out. Realistic firearms are often replaced with futuristic beam weapons which still seldom hit anyone. Swords and other bladed weapons may be prohibited from being used as offensive weapons but may be used defensively or be depicted as magical weapons. Direct violence is frequently limited to hand to hand combat where directly kicking or punching another character may or may not be allowed. The majority of action adventure cartoons over the past decades have used these methods of depicting dynamic action scenes although their use has been heavily criticized as \"sanitized violence\". Cartoons based on the Voltron, Transformers, G.I. Joe, and Masters of the Universe franchises (especially the versions produced during the 1980s) are notable examples using variations on fantasy violence.\n\nAdditionally, parents should limit the total screen time for children older than two years of age to no more than one to two hours per day. Children under two years of age should avoid watching television altogether. Televisions should be kept out of children’s bedrooms and parents should watch television with their children and discuss the content.\n\nHealth practitioners can also play their part by taking the time to ask their young patients how much time per day they spend with entertainment media and if there is a television or computer with Internet access in their bedroom.\n\nEffects of cartoon violence on youth remain controversial. Research has generally been divided on this issue with no consensus reached regarding the effects of violence on behavior. That being said, the impact of exposure to violence may remain regardless of whether children choose to imitate it.\n"}
{"id": "16408009", "url": "https://en.wikipedia.org/wiki?curid=16408009", "title": "Cauchy momentum equation", "text": "Cauchy momentum equation\n\nThe Cauchy momentum equation is a vector partial differential equation put forth by Cauchy that describes the non-relativistic momentum transport in any continuum. In convective (or Lagrangian) form it is written: \n\nwhere is the density at the point considered in the continuum (for which the continuity equation holds), is the stress tensor, and contains all of the body forces per unit mass (often simply gravitational acceleration). is the flow velocity vector field, which depends on time and space.\n\nAfter an appropriate change of variables, it can also be written in conservation (or Eulerian) form:\n\nwhere is the momentum density at a given space-time point, is the flux associated to the momentum density, and contains all of the body forces per unit volume.\n\nApplying Newton's second law (th component) to a control volume in the continuum being modeled gives:\n\nand basing on the Reynolds transport theorem and on the material derivative notation:\n\nwhere represents the control volume. Since this equation must hold for any control volume, it must be true that the integrand is zero, from this the Cauchy momentum equation follows. The main step (not done above) in deriving this equation is establishing that the derivative of the stress tensor is one of the forces that constitutes .\n\nCauchy equations can also be put in the following form:\n\nsimply by defining:\n\nwhere is the momentum density at the point considered in the continuum (for which the continuity equation holds), is the flux associated to the momentum density, and contains all of the body forces per unit volume. is the dyad of the velocity.\n\nHere and have same number of dimensions as the flow speed and the body acceleration, while , being a tensor, has .\n\nIn the Eulerian forms it is apparent that the assumption of no deviatoric stress brings Cauchy equations to the Euler equations.\n\nA significant feature of the Navier–Stokes equations is the presence of convective acceleration: the effect of time-independent acceleration of a flow with respect to space. While individual continuum particles indeed experience time dependent acceleration, the convective acceleration of the flow field is a spatial effect, one example being fluid speeding up in a nozzle.\n\nRegardless of what kind of continuum is being dealt with, convective acceleration is a nonlinear effect. Convective acceleration is present in most flows (exceptions include one-dimensional incompressible flow), but its dynamic effect is disregarded in creeping flow (also called Stokes flow). Convective acceleration is represented by the nonlinear quantity , which may be interpreted either as or as , with the tensor derivative of the velocity vector . Both interpretations give the same result.\n\nThe convection term formula_6 can be written as , where is the advection operator. This representation can be contrasted to the one in terms of the tensor derivative. \nThe tensor derivative is the component-by-component derivative of the velocity vector, defined by , so that\n\nThe vector calculus identity of the cross product of a curl holds:\n\nwhere the Feynman subscript notation is used, which means the subscripted gradient operates only on the factor .\n\nLamb in his famous classical book Hydrodynamics (1895), still in print, used this identity to change the convective term of the flow velocity in rotational form, i.e. without a tensor derivative:\n\nwhere the vector formula_10 is called the Lamb vector. The Cauchy momentum equation becomes:\n\nUsing the identity:\n\nthe Cauchy equation becomes:\n\nIn fact, in case of an external conservative field, by defining its potential :\n\nIn case of a steady flow the time derivative of the flow velocity disappears, so the momentum equation becomes:\n\nAnd by projecting the momentum equation on the flow direction, i.e. along a \"streamline\", the cross product disappears due to a vector calculus identity of the triple scalar product:\n\nIf the stress tensor is isotropic, then only the pressure enters, and the Euler momentum equation in the steady incompressible case becomes:\n\nIn the steady incompressible case the mass equation is simply:\n\nthat is, \"the mass conservation for a steady incompressible flow states that the density along a streamline is constant\". This leads to a considerable simplification of the Euler momentum equation:\n\nThe convenience of defining the total head for an inviscid liquid flow is now apparent:\n\nin fact, the above equation can be simply written as:\n\nThat is, \"the momentum balance for a steady inviscid and incompressible flow in an external conservative field states that the total head along a streamline is constant\".\n\nThe Lamb form is also useful in irrotational flow, where the curl of the velocity (called vorticity) is equal to zero. In that case, the convection term formula_6 reduces to\n\nThe effect of stress in the continuum flow is represented by the and terms; these are gradients of surface forces, analogous to stresses in a solid. Here is the pressure gradient and arises from the isotropic part of the Cauchy stress tensor. This part is given by the normal stresses that occur in almost all situations. The anisotropic part of the stress tensor gives rise to , which usually describes viscous forces; for incompressible flow, this is only a shear effect. Thus, is the deviatoric stress tensor, and the stress tensor is equal to:\n\nwhere is the identity matrix in the space considered and the shear tensor.\n\nAll non-relativistic momentum conservation equations, such as the Navier–Stokes equation, can be derived by beginning with the Cauchy momentum equation and specifying the stress tensor through a constitutive relation. By expressing the shear tensor in terms of viscosity and fluid velocity, and assuming constant density and viscosity, the Cauchy momentum equation will lead to the Navier–Stokes equations. By assuming inviscid flow, the Navier–Stokes equations can further simplify to the Euler equations.\n\nThe divergence of the stress tensor can be written as\n\nThe effect of the pressure gradient on the flow is to accelerate the flow in the direction from high pressure to low pressure.\n\nAs written in the Cauchy momentum equation, the stress terms and are yet unknown, so this equation alone cannot be used to solve problems. Besides the equations of motion—Newton's second law—a force model is needed relating the stresses to the flow motion. For this reason, assumptions based on natural observations are often applied to specify the stresses in terms of the other flow variables, such as velocity and density.\n\nThe vector field represents body forces per unit mass. Typically, these consist of only gravity acceleration, but may include others, such as electromagnetic forces. In non-inertial coordinate frames, other \"inertial accelerations\" associated with rotating coordinates may arise.\n\nOften, these forces may be represented as the gradient of some scalar quantity , with in which case they are called conservative forces. Gravity in the direction, for example, is the gradient of . Because pressure from such gravitation arises only as a gradient, we may include it in the pressure term as a body force . The pressure and force terms on the right-hand side of the Navier–Stokes equation become\n\nIn order to make the equations dimensionless, a characteristic length and a characteristic velocity need to be defined. These should be chosen such that the dimensionless variables are all of order one. The following dimensionless variables are thus obtained:\n\nSubstitution of these inverted relations in the Euler momentum equations yields:\n\nand by dividing for the first coefficient:\n\nNow defining the Froude number:\n\nthe Euler number:\n\nand the coefficient of skin-friction or the one usually referred as 'drag' co-efficient in the field of aerodynamics:\n\nby passing respectively to the conservative variables, i.e. the momentum density and the force density:\n\nthe equations are finally expressed (now omitting the indexes):\n</math>\n\nCauchy equations in the Froude limit (corresponding to negligible external field) are named free Cauchy equations:\n\n</math>\n\nand can be eventually conservation equations. The limit of high Froude numbers (low external field) is thus notable for such equations and is studied with perturbation theory.\n\nFinally in convective form the equations are:\n\n</math>\n\n"}
{"id": "2815048", "url": "https://en.wikipedia.org/wiki?curid=2815048", "title": "Computational model", "text": "Computational model\n\nA computational model is a mathematical model in computational science that requires extensive computational resources to study the behavior of a complex system by computer simulation.\n\nThe system under study is often a complex nonlinear system for which simple, intuitive analytical solutions are not readily available. Rather than deriving a mathematical analytical solution to the problem, experimentation with the model is done by adjusting the parameters of the system in the computer, and studying the differences in the outcome of the experiments. Operation theories of the model can be derived/deduced from these computational experiments.\n\nExamples of common computational models are weather forecasting models, earth simulator models, flight simulator models, molecular protein folding models, and neural network models.\n\n"}
{"id": "773298", "url": "https://en.wikipedia.org/wiki?curid=773298", "title": "Conceptual system", "text": "Conceptual system\n\nA conceptual system is a system that is composed of non-physical objects, i.e. ideas or concepts. In this context a system is taken to mean \"an interrelated, interworking set of objects\".\n\nA conceptual system is a conceptual model. Such systems may be related to any topic from formal science to individual imagination. Conceptual systems may be found within the human mind, as works of art and fiction, and within the academic world. Indeed, this article may be understood as a conceptual system because it includes a set of interrelated concepts.\n\nBroadly, when a conceptual system includes a range of values, ideas, and beliefs the conceptual system is said be a view of the world. In psychology and social work, a conceptual system may refer to an individual's mental model of the world. In humans, a conceptual system may be understood as kind of a metaphor for the world. In science, there are many forms of conceptual systems including laws, theories, and models. Those conceptual systems may be developed through inductive reasoning, deductive reasoning, and empirical analysis.\n\nThe idea that the human mind might contain conceptual systems goes back at least as far as Kelly's personal construct theory in 1955. More recently, many scholars discuss conceptual systems and the importance of understanding them (c.f. Bateson, Luhmann, Senge, Quine, Eco, Umpleby, and Wallis). On the personal level, the human mind is generally held to contain a wide range of conceptual systems although they are not well organized. Indeed, our minds are full of conflicting mental models which makes decision making unreliable - particularly in large-scale, complex situations.\n\nWithin the academic literature, each theory may be understood as a conceptual system. Conceptual systems are generally held to have greater value when they are more useful, based on more research, and are more systemically interrelated.\n\nGenerally, that validity may also be described in terms of its internal coherence and the correspondence between the conceptual system and other systems (e.g. social systems or physical systems). Coherence may be tested by Integrative complexity (for individuals) and by Integrative Propositional Analysis (for academic theories). Correspondence is generally tested by empirical analysis and conditions of falsifiability. The conceptual system may then be said to model the physical or social system and serve as a guide for individual behavior or academic research.\n\nExamples of conceptual systems include:\n\nA concept is an abstract idea or a mental symbol, typically associated with a corresponding representation in language or symbology, that denotes all of the objects in a given category or class of entities, interactions, phenomena, or relationships between them. Concepts are abstract in that they omit the differences of the things in extension, treating them as if they were identical. They are universal in that they apply equally to everything in their extension. Concepts are also the basic elements of propositions, much the same way a word is the basic semantic element of a sentence. Unlike perceptions, which are particular images of individual objects, concepts cannot be visualized. Because they are not, themselves, individual perceptions, concepts are discursive and result from reason. They can only be thought about, or designated, by means of a name. Words are not concepts. Words are signs for concepts.\n\nA conceptual model is a representation of some phenomenon, data or theory by logical and mathematical objects such as functions, relations, tables, stochastic processes, formulas, axiom systems, rules of inference etc. A conceptual model has an ontology, that is the set of expressions in the model which are \"intended\" to denote some aspect of the modeled object. Here we are deliberately vague as to how expressions are constructed in a model and particularly what the logical structure of formulas in a model actually is. In fact, we have made no assumption that models are encoded in any formal logical system at all, although we briefly address this issue below. Moreover, the definition given here is oblivious to whether two expressions really should denote the same thing. Note that this notion of ontology is different from (and weaker than) ontology as is sometimes understood in philosophy; in our sense there is no claim that the expressions actually denote anything which exists \"physically\" or \"spatio-temporally\" (to use W. Quine's formulation).\n\nFor example, a stochastic model of stock prices includes in its ontology a sample space, random variables, the mean and variance of stock prices, various regression coefficients etc. Models of quantum mechanics in which pure states are represented as unit vectors in a Hilbert space include in their ontologies observables, dynamics, measurement operators etc. It is possible that observables and states of quantum mechanics are as physically real as the electrons they model, but by adopting this purely formal notion of ontology we avoid altogether this question.\n\nA conceptual framework is used in research to outline possible courses of action or to present a preferred approach to a system analysis project. It has also been defined as the organization of ideas to achieve a purpose The framework is built from a set of concepts linked to a planned or existing system of methods, behaviors, functions, relationships, and objects. A conceptual framework might, in computing terms, be thought of as a relational model.\n\nFor example, a conceptual framework of accounting \"seeks to identify the nature, subject, purpose and broad content of general-purpose financial reporting and the qualitative characteristics that financial information should possess\".\n\n\n"}
{"id": "49122599", "url": "https://en.wikipedia.org/wiki?curid=49122599", "title": "Consumption map", "text": "Consumption map\n\nA consumption map or efficiency map shows the brake-specific fuel consumption in g per kWh over mean effective pressure per rotational speed of an internal combustion engine.\n\nThe x-axis shows the rotational speed range. The y-axis represents the load on the engine. The contour lines show the specific fuel consumption, indicating the areas of the speed/load regime where the engine is more or less efficient.\n\nThe map contains each possible condition, combining rotational speed and mean effective pressure. It shows the result of specific fuel consumption. A typical rotation power output P (linear to formula_1 ) is reached on several locations on the map but differing in the amount of fuel consumption. Automatic transmissions, are designed to keep the engine at the speed with the lowest possible fuel consumption, given the power demand.\n\nThe map also shows the efficiency of the engine. Depending on the fuel type, diesel and gasoline engines reach up to 210 g/kWh and about 40% efficiency. Using natural gas this efficiency is reached at 200 g/kWh.\n\nAverage values are 160–180 g/kWh for slow moving two stroke diesel boat engines using fuel oil, reaching up to 55% efficiency at 300 rpm. 195–210 g/kWh at cooled and pre-charged diesel engines for passenger cars, trucks 195–225 g/kWh. Non-charged Otto cycle gasoline engines for passenger cars 250–350 g/kWh.\n\n"}
{"id": "3795229", "url": "https://en.wikipedia.org/wiki?curid=3795229", "title": "Correspondence rule", "text": "Correspondence rule\n\nIn quantum mechanics, correspondence rules govern the principle of replacing physical quantities with operators.\n\nSuch replacements include energy and momentum, which can be derived informally from taking the time and space derivities of the plane wave function. These show a similarity to the heisenberg uncertainty principle.\n\nExamples of correspondence rules include:\n\n"}
{"id": "465009", "url": "https://en.wikipedia.org/wiki?curid=465009", "title": "Defence mechanisms", "text": "Defence mechanisms\n\nA defence mechanism is an unconscious psychological mechanism that reduces anxiety arising from unacceptable or potentially harmful stimuli.\n\nDefence mechanisms may result in healthy or unhealthy consequences depending on the circumstances and frequency with which the mechanism is used. In psychoanalytic theory, defence mechanisms () are psychological strategies brought into play by the unconscious mind to manipulate, deny, or distort reality in order to defend against feelings of anxiety and unacceptable impulses and to maintain one's self-schema or other schemas. These processes that manipulate, deny, or distort reality may include the following: repression, or the burying of a painful feeling or thought from one's awareness even though it may resurface in a symbolic form; identification, incorporating an object or thought into oneself; and rationalization, the justification of one's behaviour and motivations by substituting \"good\" acceptable reasons for the actual motivations. In psychoanalytic theory, repression is considered as the basis for other defence mechanisms.\n\nHealthy persons normally use different defences throughout life. An ego defence mechanism becomes pathological only when its persistent use leads to maladaptive behaviour such that the physical or mental health of the individual is adversely affected. Among the purposes of ego defence mechanisms is to protect the mind/self/ego from anxiety or social sanctions or to provide a refuge from a situation with which one cannot currently cope.\n\nOne resource used to evaluate these mechanisms is the \"Defense Style Questionnaire\" (DSQ-40).\n\nThe concept of id impulses comes from Sigmund Freud's structural model. According to this theory, id impulses are based on the pleasure principle: instant gratification of one's own desires and needs. Sigmund Freud believed that the id represents biological instinctual impulses in humans, such as aggression (Thanatos or the Death instinct) and sexuality (Eros or the Life instinct).\n\nFor example, when the id impulses (e.g., desire to have sexual relations with a stranger) conflict with the superego (e.g., belief in societal conventions of not having sex with unknown persons), unsatisfied feelings of anxiousness or feelings of anxiety come to the surface. To reduce these unpleasant feelings, the ego might use defence mechanisms (conscious or unconscious blockage of the id impulses).\n\nFreud believed that conflicts between these two structures resulted in conflicts associated with psychosexual stages.\n\nFreud proposed three structures of the psyche or personality:\n\nIn the ego, there are two ongoing processes. First, there is the unconscious primary process, where the thoughts are not organised in a coherent way; the feelings can shift, contradictions are not in conflict or are just not perceived that way, and condensations arise. There is no logic and no time line. Lust is important for this process. By contrast, there is the conscious secondary process, where strong boundaries are set and thoughts must be organised in a coherent way. Most conscious thoughts originate here.\n\nId impulses are not appropriate in a civilised society, so there is societal pressure to modify the pleasure principle in favour of the reality principle; that is, the requirements of the external world.\n\nThe superego forms as the child grows and learns parental and social standards. The superego consists of two structures: the conscience, which stores information about what is \"bad\" and what has been punished, and the ego ideal, which stores information about what is \"good\" and what one \"should\" do or be.\n\nWhen anxiety becomes overwhelming, it is the ego's place to protect the person by employing defence mechanisms. Guilt, embarrassment, and shame often accompany anxiety. In the first definitive book on defence mechanisms, \"The Ego and the Mechanisms of Defence\" (1936), Anna Freud introduced the concept of signal anxiety; she stated that it was \"not directly a conflicted instinctual tension but a signal occurring in the ego of an anticipated instinctual tension\".\n\nThe signalling function of anxiety is thus seen as crucial, and biologically adapted to warn the organism of danger or a threat to its equilibrium. The anxiety is felt as an increase in bodily or mental tension, and the signal that the organism receives in this way allows for the possibility of taking defensive action regarding the perceived danger. Defence mechanisms work by distorting the id impulses into acceptable forms, or by unconscious or conscious blockage of these impulses.\n\nThe list of defence mechanisms, with no theoretical consensus on the exact number. Classifying defence mechanisms according to some of their properties (like underlying mechanisms, similarities or connections with personality) has been attempted. Different theorists have different categorizations and conceptualizations of defence mechanisms. Large reviews of theories of defence mechanisms are available from Paulhus, Fridhandler and Hayes (1997) and Cramer (1991). The \"Journal of Personality\" published a special issue on defence mechanisms (1998).\n\nIn 1936, Anna Freud enumerated the ten defence mechanisms that appear in the works of her father, Sigmund Freud: 1. Repression, 2. Regression, 3. Reaction formation, 4. Isolation, 5. Undoing, 6. Projection, 7. Introjection, 8. Turning against one's own person, 9. Reversal into the opposite, 10. Sublimation or displacement.\n\nBoth Freuds studied defence mechanisms, but Anna spent more of her time and research on five main mechanisms: repression, regression, projection, reaction formation, and sublimation. All defence mechanisms are responses to anxiety and how the consciousness and unconscious handle the stress of a social situation.\n\n\nOtto F. Kernberg (1967) developed a theory of borderline personality organization of which one consequence may be borderline personality disorder. His theory is based on ego psychological object relations theory. Borderline personality organization develops when the child cannot integrate helpful and harmful mental objects together. Kernberg views the use of primitive defence mechanisms as central to this personality organization. Primitive psychological defences are projection, denial, dissociation or splitting and they are called borderline defence mechanisms. Also, devaluation and projective identification are seen as borderline defences.\n\nIn George Eman Vaillant's (1977) categorization, defences form a continuum related to their psychoanalytical developmental level. They are classified into pathological, immature, neurotic and \"mature\" defences.\n\nRobert Plutchik's (1979) theory views defences as derivatives of basic emotions, which in turn relate to particular diagnostic structures. According to his theory, reaction formation relates to joy (and manic features), denial relates to acceptance (and histrionic features), repression to fear (and passivity), regression to surprise (and borderline traits), compensation to sadness (and depression), projection to disgust (and paranoia), displacement to anger (and hostility) and intellectualization to anticipation (and obsessionality).\n\nThe \"Diagnostic and Statistical Manual of Mental Disorders (DSM-IV)\" published by the American Psychiatric Association (1994) includes a tentative diagnostic axis for defence mechanisms. This classification is largely based on Vaillant's hierarchical view of defences, but has some modifications. Examples include: denial, fantasy, rationalization, regression, isolation, projection, and displacement.\n\nPsychiatrist George Eman Vaillant introduced a four-level classification of defence mechanisms:\n\nWhen predominant, the mechanisms on this level are almost always severely pathological. These six defences, in conjunction, permit one effectively to rearrange external experiences to eliminate the need to cope with reality. Pathological users of these mechanisms frequently appear irrational or insane to others. These are the \"psychotic\" defences, common in overt psychosis. However, they are normally found in dreams and throughout childhood as well.\nThey include:\n\nThese mechanisms are often present in adults. These mechanisms lessen distress and anxiety produced by threatening people or by an uncomfortable reality. Excessive use of such defences is seen as socially undesirable, in that they are immature, difficult to deal with and seriously out of touch with reality. These are the so-called \"immature\" defences and overuse almost always leads to serious problems in a person's ability to cope effectively. These defences are often seen in major depression and personality disorders.\nThey include:\n\nThese mechanisms are considered neurotic, but fairly common in adults. Such defences have short-term advantages in coping, but can often cause long-term problems in relationships, work and in enjoying life when used as one's primary style of coping with the world.\nThey include:\n\nThese are commonly found among emotionally healthy adults and are considered mature, even though many have their origins in an immature stage of development. They have been adapted through the years in order to optimise success in human society and relationships. The use of these defences enhances pleasure and feelings of control. These defences help to integrate conflicting emotions and thoughts, whilst still remaining effective. Those who use these mechanisms are usually considered virtuous.\nMature defences include:\n\n\n\n\n\nThere are many different perspectives on how the construct of \"defence\" relates to the construct of \"coping\"; some writers differentiate the constructs in various ways, but \"an important literature exists that does not make any difference between the two concepts\". In at least one of his books, George Eman Vaillant stated that he \"will use the terms \"adaptation\", \"resilience\", \"coping\", and \"defense\" interchangeably\".\n"}
{"id": "3158597", "url": "https://en.wikipedia.org/wiki?curid=3158597", "title": "Dependency inversion principle", "text": "Dependency inversion principle\n\nIn object-oriented design, the dependency inversion principle is a specific form of decoupling software modules. When following this principle, the conventional dependency relationships established from high-level, policy-setting modules to low-level, dependency modules are reversed, thus rendering high-level modules independent of the low-level module implementation details. The principle states:\n\nBy dictating that high-level and low-level objects must depend on the same abstraction this design principle the way some people may think about object-oriented programming.\n\nThe idea behind points A and B of this principle is that when designing the interaction between a high-level module and a low-level one, the interaction should be thought of as an abstract interaction between them. This not only has implications on the design of the high-level module, but also on the low-level one: the low-level one should be designed with the interaction in mind and it may be necessary to change its usage interface.\n\nIn many cases, thinking about the interaction in itself as an abstract concept allows the coupling of the components to be reduced without introducing additional coding patterns, allowing only a lighter and less implementation dependent interaction schema.\n\nWhen the discovered abstract interaction schema(s) between two modules is/are generic and generalization makes sense, this design principle also leads to the following dependency inversion coding pattern.\n\nIn conventional application architecture, lower-level components (e.g. Utility Layer) are designed to be consumed by higher-level components (e.g. Policy Layer) which enable increasingly complex systems to be built. In this composition, higher-level components depend directly upon lower-level components to achieve some task. This dependency upon lower-level components limits the reuse opportunities of the higher-level components.\n\nThe goal of the dependency inversion pattern is to avoid this highly coupled distribution with the mediation of an abstract layer, and to increase the re-usability of higher/policy layers.\n\nWith the addition of an abstract layer, both high- and lower-level layers reduce the traditional dependencies from top to bottom. Nevertheless, the \"inversion\" concept does not mean that lower-level layers depend on higher-level layers. Both layers should depend on abstractions that draw the behavior needed by higher-level layers.\n\nIn a direct application of dependency inversion, the abstracts are owned by the upper/policy layers. This architecture groups the higher/policy components and the abstractions that define lower services together in the same package. The lower-level layers are created by inheritance/implementation of these abstract classes or interfaces.\n\nThe inversion of the dependencies and ownership encourages the re-usability of the higher/policy layers. Upper layers could use other implementations of the lower services. When the lower-level layer components are closed or when the application requires the reuse of existing services, it is common that an Adapter mediates between the services and the abstractions.\n\nIn many projects the dependency inversion principle and pattern are considered as a single concept that should be generalized. There are at least two reasons for that:\nIf the mocking tool used relies only on inheritance, generalizing the dependency inversion pattern may become a necessity. This has major drawbacks:\n\nThe presence of interfaces to accomplish the Dependency Inversion Pattern (DIP) have other design implications in an object-oriented program:\n\n\nUsing inheritance-based mocking tools also introduce restrictions:\n\nPrinciples are ways of thinking, patterns are common ways to solve problems. Coding patterns may be seen as missing programming language features.\n\nTwo common implementations of DIP use similar logical architecture, with different implications.\n\nA direct implementation packages the policy classes with service abstracts classes in one library. In this implementation high-level components and low-level components are distributed into separate packages/libraries, where the interfaces defining the behavior/services required by the high-level component are owned by, and exist within the high-level component's library. The implementation of the high-level component's interface by the low level component requires that the low-level component package depend upon the high-level component for compilation, thus inverting the conventional dependency relationship.\n\nFigures 1 and 2 illustrate code with the same functionality, however in Figure 2, an interface has been used to invert the dependency. The direction of dependency can be chosen to maximize policy code reuse, and eliminate cyclic dependencies.\n\nIn this version of DIP, the lower layer component's dependency on the interfaces/abstracts in the higher-level layers makes re-utilization of the lower layer components difficult. This implementation instead ″inverts″ the traditional dependency from top-to-bottom to the opposite, from bottom-to-top.\n\nA more flexible solution extracts the abstract components into an independent set of packages/libraries:\n\nThe separation of all layers into their own package encourages re-utilization of any layer, providing robustness and mobility.\n\nA genealogical system may represent relationship between people as a graph of first level relationships between them (father/son, father/daughter, mother/son, mother/daughter, husband/wife, wife/husband...). This is very efficient (and extensible: ex-husband/ex-wife, legal guardian...)\n\nBut the high level modules may require a simpler way to browse the system: a person may have children, a father, a mother, brothers and sisters (including or not half brothers and sisters), grandfathers, grandmothers, uncles, aunts, cousins ...\n\nDepending on the usage of the genealogical module, presenting common relationships as distinct direct properties (hiding the graph) will make the coupling between the high-level module and the genealogical module by far lighter and allow one to change the internal representation completely without any effect on the using modules. It also allows one to embed in the genealogical module the exact definition of brother and sisters (including or not half ones), uncles ... allowing one to enforce the single responsibility principle.\n\nFinally, if the first extensible generalized graph approach seems the most extensible, the usage of the genealogical module may show that a more specialized and simpler relationship implementation is sufficient for the application(s) and helps you to make a more efficient system.\n\nIn this example abstracting the interaction between the modules leads to a simplified interface of the low-level module and may lead to a simpler implementation of it.\n\nImagine you have to implement a client to a remote file server (FTP, cloud storage ...). You may think of it as a set of abstract interfaces:\n\nIf both local files and remote files offers the same abstract interfaces, any high-level module using local files and fully implementing the dependency inversion pattern will be able to access local and remote files indiscriminately.\n\nLocal disk will generally use folder, remote storage may use folder and/or tags. You have to decide how to unify them if possible.\n\nOn remote file we may have to use only create or replace: remote files update do not necessarily make sense because random update is too slow comparing local file random update and may be very complicated to implement). On remote file we may need partial read and write (at least inside the remote file module to allow download or upload to resume after a communication interruption), but random read isn't adapted (except if a local cache is used).\n\nFile searching may be pluggable : file searching can rely on the OS or in particular for tag or full text search, be implemented with distinct systems (OS embedded, or available separately).\n\nConcurrent replacement or delete resolution detection may impact the other abstract interfaces.\n\nWhen designing the remote file server client for each conceptual interface you have to ask yourself the level of service your high level modules require (not necessary all of them) and not only how to implement the remote file server functionalities but maybe how to make the file services in your application compatible between already implemented file services (local files, existing cloud clients) and your new remote file server client.\n\nOnce you have designed the abstract interfaces required, your remote file server client should implement these interfaces. And because you probably restricted some local functionalities existing on local file (for example file update), you may have to write adapters for local or other existing used remote file access modules each offering the same abstract interfaces. You also have to write your own file access enumerator allowing to retrieve all file compatible systems available and configured on your computer.\n\nOnce you do that, your application will be able to save its documents locally or remotely transparently. Or simpler, the high level module using the new file access interfaces can be used indistinctly in local or remote file access scenarios making it reusable.\n\nRemark : many OSes have started to implement these kind of functionalities and your work may be limited to adapt your new client to this already abstracted models.\n\nIn this example, thinking of the module as a set of abstract interfaces, and adapting other modules to this set of interfaces, allows you to provide a common interface for many file storage systems.\n\nUI and ApplicationLayer packages contains mainly concrete classes. Controllers contains abstracts/interface types. UI has an instance of ICustomerHandler. All packages are physically separated. In the ApplicationLayer there is a concrete implementation that Page class will use. Instances of this interface are created dynamically by a Factory (possibly in the same Controllers package). The concrete types, Page and CustomerHandler, don't depend on each other; both depend on ICustomerHandler.\n\nThe direct effect is that the UI doesn't need to reference the ApplicationLayer or any concrete package that implements the ICustomerHandler. The concrete class will be loaded using reflection. At any moment the concrete implementation could be replaced by another concrete implementation without changing the UI class. Another interesting possibility is that the Page class implements an interface IPageViewer that could be passed as an argument to ICustomerHandler methods. Then the concrete implementation could communicate with UI without a concrete dependency. Again, both are linked by interfaces.\n\nApplying the dependency inversion principle can also be seen as an example of the adapter pattern, i.e. the high-level class defines its own adapter interface which is the abstraction that the other high-level classes depend on. The adaptee implementation also depends on the adapter interface abstraction (of course, since it implements its interface) while it can be implemented by using code from within its own low-level module. The high-level has no dependency on the low-level module since it only uses the low-level indirectly through the adapter interface by invoking polymorphic methods to the interface which are implemented by the adaptee and its low-level module.\n\nVarious patterns such as Plugin, Service Locator, or Dependency Injection are employed to facilitate the run-time provisioning of the chosen low-level component implementation to the high-level component.\n\nThe dependency inversion principle was postulated by Robert C. Martin and described in several publications including the paper \"Object Oriented Design Quality Metrics: an analysis of dependencies\", an article appearing in the C++ Report in May 1996 entitled \"The Dependency Inversion Principle\", and the books \"Agile Software Development, Principles, Patterns, and Practices\", and \"Agile Principles, Patterns, and Practices in C#\".\n\n\n"}
{"id": "1970381", "url": "https://en.wikipedia.org/wiki?curid=1970381", "title": "Edward S. Miller", "text": "Edward S. Miller\n\nEdward S. Miller was the Deputy Assistant Director of the Inspections Division under Mark Felt with the United States Federal Bureau of Investigation.\n\nIn November 1980, Miller, then head of the FBI's Domestic Intelligence Division, and Mark Felt were convicted after a seven-week federal jury trial of having \"conspired to injure and oppress the citizens of the United States\" and Miller was fined $3,500. While the convictions were being appealed in April 1981, President Ronald Reagan pardoned both men. At the time of trial, Felt and Miller were the highest-ranking bureau employees to have been tried for a criminal offense.\n\n"}
{"id": "25262819", "url": "https://en.wikipedia.org/wiki?curid=25262819", "title": "Exceptional isomorphism", "text": "Exceptional isomorphism\n\nIn mathematics, an exceptional isomorphism, also called an accidental isomorphism, is an isomorphism between members \"a\" and \"b\" of two families, usually infinite, of mathematical objects, that is not an example of a pattern of such isomorphisms. These coincidences are at times considered a matter of trivia, but in other respects they can give rise to other phenomena, notably exceptional objects. In the following, coincidences are listed wherever they occur.\n\nThe exceptional isomorphisms between the series of finite simple groups mostly involve projective special linear groups and alternating groups, and are:\n\nIn addition to the aforementioned, there are some isomorphisms involving SL, PSL, GL, PGL, and the natural maps between these. For example, the groups over formula_6 have a number of exceptional isomorphisms:\n\nThere are coincidences between alternating groups and small groups of Lie type:\nThese can all be explained in a systematic way by using linear algebra (and the action of formula_15 on affine formula_16-space)\nto define the isomorphism going from the right side to the left side. (The above isomorphisms for formula_17 and formula_18 are linked via the exceptional isomorphism formula_19.)\nThere are also some coincidences with symmetries of regular polyhedra: the alternating group A agrees with the icosahedral group (itself an exceptional object), and the double cover of the alternating group A is the binary icosahedral group.\n\nCyclic groups of small order especially arise in various ways, for instance:\n\nThe spheres \"S\", \"S\", and \"S\" admit group structures, which can be described in many ways:\n\nThere are some exceptional isomorphisms of Coxeter diagrams, yielding isomorphisms of the corresponding Coxeter groups and of polytopes realizing the symmetries. These are:\n\nClosely related ones occur in Lie theory for Dynkin diagrams.\n\nIn low dimensions, there are isomorphisms among the classical Lie algebras and among the classical Lie groups called \"accidental isomorphisms\". For instance, there are isomorphisms between low-dimensional spin groups and certain classical Lie groups, due to low-dimensional isomorphisms between the root systems of the different families of simple Lie algebras, visible as isomorphisms of the corresponding Dynkin diagrams:\n\n"}
{"id": "524632", "url": "https://en.wikipedia.org/wiki?curid=524632", "title": "Forced confession", "text": "Forced confession\n\nA forced confession is a confession obtained from a suspect or a prisoner by means of torture (including enhanced interrogation techniques) or other forms of duress. Depending on the level of coercion used, a forced confession is not valid in revealing the truth. The person being interrogated may agree to the story presented to him or even make up falsehoods himself in order to satisfy the interrogator and discontinue his suffering.\n\nFor centuries the Latin phrase \"Confessio est regina probationum\" (In English: Confession is the Queen of evidence) justified the use of forced confession in the European legal system. When especially during the Middle Ages acquiring a confession was the most important thing during preparations before a trial, than the method used to get the confession seemed irrelevant, de facto sanctioning the use of torture to extract forced confession. \n\nBy the late 18th century, most scholars and lawyers thought of the forced confession not only as a relic of past times and morally wrong but also ineffective as the victim of torture may confess to anything just to ease their suffering.\n\nDevelopments in the 20th century, notably the Universal Declaration of Human Rights, greatly reduced the legal acceptance of forced confessions. However, for most of legal history they have been accepted in most of the world, and are still accepted in some jurisdictions.\n\nSince 2001, as part of its War on Terror the United States using the CIA operates a network of off shore prisons, called black sites, probably the most famous of which is Guantánamo Bay detention camp.\nState officials have admitted to the press and in court to be using various torture techniques (authorised by the District attorney) to interrogate suspects of terrorism, sometimes after forced disappearance or extraordinary rendition by the United States. \n\nWhen these systematic acts were made public by the international media, the European Union, United Nations, the international press and various human rights movements condemned their practice.\nThe US Supreme Court did not discontinue their usage and repeatedly ruled against hearing citizens that underwent forced confessions, even after they were found innocent, claiming that a trial would constitute a breach of national security.\n\nA famous case is that of Khalid El-Masri. He appealed several times aided by different international human rights movements and lawyers, yet the US Supreme Court retained its usage of forced confession techniques, and denied a hearing of the evidence.\n\nThe People's Republic of China systematically employed forced televised confession against Chinese dissidents and workers of various human rights group in an attempt to discredit, smear and suppress dissident voices and activism, as well as part of the state propaganda. These scripted confessions, obtained via systematic duress and torture, are broadcast on the state television. Notable victims includes Wang Yu, a female human rights lawyer, and Swedish citizen Peter Dahlin, an NGO worker and human rights activist.\n\n"}
{"id": "17104172", "url": "https://en.wikipedia.org/wiki?curid=17104172", "title": "Friedrich Nietzsche and free will", "text": "Friedrich Nietzsche and free will\n\nThe 19th-century philosopher Friedrich Nietzsche is known as a critic of Judeo-Christian morality and religions in general. One of the arguments he raised against the truthfulness of these doctrines is that they are based upon the concept of free will, which, in his opinion, does not exist.\n\nIn \"The Gay Science\", Nietzsche praises Arthur Schopenhauer's \"immortal doctrines of the intellectuality of intuition, the apriority of the law of causality, (...) and the non-freedom of the will,\" which have not been assimilated enough by the disciples. Following is, then, the short description of those views of the latter philosopher.\n\nIn \"Fourfold Root of the Principle of Sufficient Reason\" Schopenhauer claimed to prove – in accordance with Kant and against Hume – that causality is present in the perceivable reality as its principle, i.e. it precedes and enables human perception (so called apriority of the principle of causality), and thus it is not just an observation of something likely, statistically frequent, which however does not happen \"on principle\" (empiricism of the principle of causality). More on this dispute in philosophy can be found in the article on free will.\n\nIn his treatise \"On the Freedom of the Will\", Schopenhauer calls the fact that we can do whatever we will a physical freedom, i.e. lack of physically present obstacles, which is not identical with moral freedom. Physically \"free\" means: one acting according only to one's will; if attempts are made to use this term to the will itself, the question arises: \"is will itself willed?,\" \"do you will the will to become so-and-so?\". It is therefore a specific aspect of the claim of freedom, in which it is stressed whether the course of consciousness follows indeed in a willed way. The problem of willing the will appears in \"Thus spake Zarathustra\", for instance in the chapter \"Backworldsmen.\"\n\nIn \"On the Freedom of the Will\", Schopenhauer demonstrates the (well known in philosophy) distinction between necessity and contingency. He calls \"necessary\" what follows from a given sufficient basis (i.e. that what is already certain – if one knows that the sufficient cause is present). On the other hand, one calls \"contingent\" or \"incidental\" (with regard to a sufficient basis) that what does not follow from the latter (so e.g. two unconnected events can be contingent to each other: like when a black cat crosses the street and one's job is lost on the same day). As \"moral\" freedom means lack of necessity, it would mean a lack of \"any\" basis: it \"would have to be defined as \"absolutely contingent\"\", i.e. an absolute fortuity, or chance.\n\nThe question about the freedom of will is thus the question whether something depends on another thing (a state, an event), i.e. is in some way determined by it, or does not depend on anything (then we call it a chance). Or, in other words, whether something can be predicted: whether it is certain (given the presence or absence of the sufficient cause) or not. Cf. Luther's argument: for him everything is a necessity because the Creator knows it already.\n\nIn \"Beyond Good and Evil\" Nietzsche criticizes the concept of free will both negatively and positively. He calls it a folly resulting from extravagant pride of man; and calls the idea a \"crass stupidity\". The latter probably relates to ordinary-man's visions about a god who (after the ellapse of eternal waiting) creates the world and then waits and observes (being, however, still \"beyond time\"): and then he is surprised and subdued by what one does. (This vision is brought up by Nietzsche in \"The Antichrist\".)\n\nNext, he argues that free will generally represents an error of \"causa sui\":\n\nFinally, he suggests that the only \"real\" thing about will is whether it is strong (i.e. hard to break) or weak:\n\nNothing is (or can be) fully resistant to stimula, for that would mean it is immutable: whereas nothing in this world is or can be immutable. He therefore continues here the Schopenhauer's issue of physical freedom: \"whether you will, what you willed to will\".\n\nWill is generally considered a mental power. \"Freedom\" of will could then be interpreted as: power of will (cf. the appropriate passus from \"The Antichrist\", where Nietzsche generally opposes will-based psychology). Will has power over actions, over many things; therefore, things are \"determined\" by will. But is this power unlimited? Does will rule without itself being ruled? (And further: does a Christian want to sin?) – Nietzsche disagrees. A godless man becomes pious out of \"grace\", he did not want it; and likewise a pious man becomes godless with no merit or guilt. Nietzsche suggests in many places that if a pious man loses faith, it is because of the power of his \"values\" over him, of the will for truthfulness...\n\nWill is something that determines human acts, thoughts etc. It is will what makes man reluctant to toss a coin for something (cf. \"The Antichrist\" about Christians: \"in point of fact, they simply do what they cannot help doing\"). The problem is, whether it is itself ruled? And here two terms which complicate the picture appear: the term \"me\" and \"chance\" (i.e. something independent from anything, beyond control).\n\nThe term \"me\" (as in the statements \"it's up to me\", \"it is \"you\" who willed that\") had already been recognized as empty in the preface of \"Beyond Good and Evil\" (or as connected with the \"superstition about the soul\"). Later Nietzsche stated more clearly that it was a tautology (\"what will I do? what will my decision be?\" – \"it's up to \"you\"\" – that actually means: your decision depends on your decision, something happens in your mind and not somewhere else...). See e.g. \"On the Genealogy of Morals\":\n\nThe same however can be applied to the \"moral\" weakness of a Christian (his lack of resistance), who would certainly prefer not to sin and would construct himself otherwise if he could. \"And many a one can command himself, but still sorely lacketh self-obedience!\" – Nietzsche criticizes the idea of \"free choice\", and even of \"choice\" in general (cf. the end of above quotation): man does not want to \"choose\", man wants to affirm himself (\"will to power\").\n\nAnother problem is the role of chance. Unless the change brought to man is too big, a chance is generally responded by will, \"wherever there is will\". He calls it \"the redemption (of chance)\". This topic dawns as early as in \"Human, All Too Human\", and it returns in many places of \"Zarathustra\". For instance in part 3 it is discussed as follows:\n\nEarlier in this part:\n\nTo cut it short, if it was always that \"\"we\" choose a chance\", then there would be determinism (for \"we\", \"we ourselves\" means: our will and its filtering and determining capabilities). And since it happens otherwise (\"a chance chooses us\"), then there is indeterminism. But the latter case means we have no will in a topic, i.e. it is at that time morally indifferent to us, \"adiaphora\", not opposed to anything (and therefore even more there is no guilt).\n\nSince free will is discussed, it must obviously be some restricted reality (if \"freedom\" meant \"everything,\" there would be no need for a separate word). What follows? That there must be events \"external\" to one's freedom: therefore, besides \"free will\" there should also consequently be \"unfree will.\" Although Nietzsche considers both terms entirely fictional, he gives some clues about the \"psychological\" reality behind them:\n\nIn short, an unexpected change. Now, going back to the mentioned definition, chance means: that what cannot be predicted. If randomness affects a man (unsubjugated, reaching even the surface of his consciousness), then \"unfree will\" occurs. Thus, whenever we call something free, we \"feel\" something free, in short: wherever we feel our power, it is deterministic, it is a necessity. And indeed Nietzsche says it with the mouth of Zarathustra:\n\nThe same in \"Beyond Good and Evil\":\n\nYet in another part of \"Zarathustra\" Nietzsche claims that when we look long-term enough and from the bird's-eye perspective of supreme powers big enough, a chance is unimportant, because it is subject to and step-by-step softened and arranged by natural laws and necessities which constitute the order of the world and evolution:\n\nTo Nietzsche everything in this world is an expression of will to power. To exist is to represent will to power, to \"cause influence\" (compare similar views of Protagoras' disciples in Plato's \"Theaetetus\"). One can cause influence only on something that exists. Therefore, (through induction) an act changes everything from that moment onwards. If one thing was otherwise, everything would have to be otherwise (and generally also backwards). Contrary to Chesterton's views, this general rule is not precluded even by absolute chances: they of course change the course of the world too, but still: if one thing was set otherwise, everything would have to be otherwise.\n\nSeveral scholars have argued that Nietzsche was not a determinist in his views of the universe. In \"Zarathustra\", absolute randomness (maybe not as the essence of reality, but as a part thereof) can be thought of, yes, perhaps it even exists:\n\nBecause \"causa sui\" is according to Nietzsche a nonsense, even to a chance could get a basis attributed (only \"the whole\" has no basis), and it would be \"divine dice\" (or \"Divine Plan\"):\n\nTo Nietzsche no one is responsible either for the necessities (laws and powers) he represents, or for chances he encounters (which conquer him unwillingly – and which, as things totally independent from anything, only the \"supreme being\" could change); after all, no one is absolutely and completely resistant, there can always happen something which changes one deeply enough.\n\nFrom \"The Dawn of Day\":\n\nIn \"Twilight of the Idols\" Nietzsche discusses fatalism and responsibility in these words:\n\nNietzsche's critique of free will has essentially two aspects: one is philosophical (fatalistic), and the other is psychological. Fatalism lets Nietzsche theoretically prove the error of moral doctrines, which – most generally speaking – would require that a sinner changed his destiny (for instance by changing the laws of nature, influencing chances which lie completely beyond the extent of his influence), which is by definition impossible. But such theory would not be convincing enough if at the same time the impression of control was not removed, as well as the ever renewed attempts at associating it with the \"freedom of will\" and building a philosophy out of that. Thus a psychological critique is needed.\n\nIf one agrees that the \"freedom of will\" denotes the power of will which rules but is not itself ruled, then it would at bottom be enough to prove that it is not will what governs human behaviour in order to abolish the very term, to prove that \"it is not there\". And Nietzsche went on to this. For Nietzsche the term \"will\" is psychologically strictly connected with the term \"aim\" (he often combines the two), maybe even they are identical to him. Aim could then be interpreted, according to a common definition, as planning and intellectual foreseeing (of especially effects); according to Nietzsche first and foremost the anticipation of acts which in fact do not need to follow by its virtue from aiming (which is here foreseeing).\n\nIn \"Twilight of the Idols\" Nietzsche demonstrates the \"error of false causality\" just before the \"error of free will\":\n\nand then, in the section directly regarding free will, he observes:\n\nSimilarly in \"The Antichrist\": \"the will no longer «acts,» or «moves»...\", \"the term no longer denotes any power\". This non-deriving of acts straight way out of aims, which are just foreseeing (the accompanying self-consciousness of that what is to come), but searching for their sources elsewhere (for example in reflexes, habits, urges) is to Nietzsche even one of major differences between medieval (Thomist) and modern psychology.\n\nNietzsche's words turned out to be prophetic, for modern neuroscience, especially the famous Libet's (or Kornhuber's) experiment and other of this type, has not once confirmed that the decision for an act is made beyond the (self)consciousness (in popular words, the will), which comes up to even half a second later.\n\nIn \"The Antichrist\" Nietzsche argues that man should be considered no otherwise than as a machine. Even if some generic chaos (randomness) is added to the picture, it does not affect this. A chance is innocent.\n\nNietzsche points out the weakness of human as well as of God. Man wills the good, \"God\" wills the good, and yet evil happens. So where is this \"freedom\" (i.e. power) of will? And where is this good God?\n\nThese two human valuations refer to things essentially mixed with each other and interdependent. Good causes the evil, and evil causes the good. The dichotomy between a good God and an evil satan is a \"dualistic fiction.\"\n\nIn \"Twilight of the Idols\" (see the quote above) and later in \"The Antichrist\" all concepts which explain life as a test or raise an (externally reasonable) moral \"task,\" \"purpose\" or the \"will of God\" are considered false. They are a part of the \"error of free will\" consisting in incomprehension of fatalism of life, i.e. the fact that it is shaped by higher forces.\n\nReligion is a form of controlling people: one man-machine wants to achieve power over another. Even the term \"freedom,\" very often used by theologians, in its positive sense actually means \"power.\" Religion is by no means more \"fulfilling the will of God\" than anything else. As God is primary and almighty, his will is by definition always fulfilled (it is impossible that he wills something and it is not fulfilled).\n\nA priest, a moralist does in fact nothing for man's \"salvation,\" but just rules, and even when doing so he acts in a way that would (apart from that) be considered immoral.\n\nNietzsche goes on to analysing the Bible philologically and to guesses about the person of Jesus. He claims that it was not the aim of the latter to have anybody serve him, for God rules everything anyway; to the contrary, in Nietzsche's opinion Jesus fought with churchedness and the notion of sin rooted in the Old Testament. And thus in \"The Antichrist\" Christianity was portrayed as the corruption of the original doctrine taught by Jesus about equal rights of all to be children of God, the doctrine of no guilt and of no gulf between God and man.\n\nThe very \"freedom of will\" was invented by the priests in order to master the process of human thinking – and nothing more. And in order to master it, they had first to denaturize it.\n\nThe downfall of Christian values is not an effect – as it has been presented hitherto – of human free will. The supreme values (especially formerly common in European culture) overthrow each other themselves due to inner contradictions and non-matching the nature.\n\n\n"}
{"id": "37816431", "url": "https://en.wikipedia.org/wiki?curid=37816431", "title": "Functional approach", "text": "Functional approach\n\nThe Functional Approach is considered to be the second paradigm of psychology. This idea focuses on the function of the mental processes which involves consciousnesses. (Gordon, 1995) This approach was developed by William James in 1890. James was the first American Psychologist and wrote the first general textbook regarding psychology. In this approach he reasoned that the mental act of consciousness must be an important biological function (Schacter et al., 2011) He also noted that it was a psychologist's job to understand these functions so they can discover how the mental process operates. This idea was an alternative approach to the structuralism, which was the first paradigm(Gordon, 1995). \n\nIn second language acquisition (SLA) functional approaches are of similarities with Chomsky's Universal Grammar (UG). Focus is on the use of language in real situations (performance), as well as underlying knowledge (competence).\n\n"}
{"id": "13512823", "url": "https://en.wikipedia.org/wiki?curid=13512823", "title": "Functional psychology", "text": "Functional psychology\n\nFunctional psychology or functionalism refers to a psychological philosophy that considers mental life and behaviour in terms of active adaptation to the person's environment. As such, it provides the general basis for developing psychological theories not readily testable by controlled experiments or applied psychology.\n\nFunctionalism arose in the U.S. in the late 19th century as an alternative to structuralism. While functionalism never became a formal school, it built on structuralism's concern for the anatomy of the mind and led to greater concern over the functions of the mind, and later to behaviourism.\n\nFunctionalism was a philosophy opposing the prevailing structuralism of psychology of the late 19th century. Edward Titchener, the main structuralist, gave psychology its first definition as a science of the study of mental experience, of consciousness, to be studied by trained introspection.\n\nWilliam James is considered to be the founder of functional psychology. But he would not consider himself as a functionalist, nor did he truly like the way science divided itself into schools. John Dewey, George Herbert Mead, Harvey A. Carr, and especially James Rowland Angell were the main proponents of functionalism at the University of Chicago. Another group at Columbia, including notably James McKeen Cattell, Edward L. Thorndike, and Robert S. Woodworth, were also considered functionalists and shared some of the opinions of Chicago's professors. Egon Brunswik represents a more recent, but Continental, version. The functionalists retained an emphasis on conscious experience.\n\nBehaviourists also rejected the method of introspection but criticized functionalism because it was not based on controlled experiments and its theories provided little predictive ability. B.F. Skinner was a developer of behaviourism. He did not think that considering how the mind affects behaviour was worthwhile, for he considered behaviour simply as a learned response to an external stimulus. Yet, such behaviourist concepts tend to deny the human capacity for random, unpredictable, sentient decision-making, further blocking the functionalist concept that human behaviour is an active process driven by the individual. Perhaps, \"a combination\" of both the functionalist and behaviourist perspectives provides scientists with the most empirical value, but, even so, it remains philosophically (and physiologically) difficult to integrate the two concepts without raising further questions about human behaviour. For instance, consider the interrelationship between three elements: the human environment, the human autonomic nervous system (our fight or flight muscle responses), and the human somatic nervous system (our voluntary muscle control). The behaviourist perspective explains a mixture of both types of muscle behaviour, whereas the functionalist perspective resides mostly in the somatic nervous system. It can be argued that all behavioural origins begin within the nervous system, prompting all scientists of human behaviour to possess basic physiological understandings, something very well understood by the functionalist founder William James.\n\nEvolutionary psychology is based on the idea that knowledge concerning the function of the psychological phenomena affecting human evolution is necessary for a complete understanding of the human psyche. Even the project of studying the evolutionary functions of consciousness is now an active topic of study. Like evolutionary psychology, James's functionalism was inspired by Charles Darwin's theory of natural selection.\n\n\n"}
{"id": "25452614", "url": "https://en.wikipedia.org/wiki?curid=25452614", "title": "Hail and Farewell", "text": "Hail and Farewell\n\nHail and Farewell (a translation of \"ave atque vale\", last words of the poem Catullus 101) is a traditional military event whereby those coming to and departing from an organization are celebrated. This may coincide with a change in command, be scheduled on an annual basis, or be prompted by any momentous organizational change. It is a time to honor those who have departed the unit and thank them for their service. At the same time it is a welcome to those who are joining and introduces them to the special history and traditions of their new organization. This celebration builds organizational camaraderie and esprit de corps. It supports a sense of continuity through change.\n\nFor the United States Army, a Hail and Farewell is most often celebrated at a formal dining in when there is a change in command. This provides the unit with a formal setting in which to welcome the new commander and honor the old commander. Some units may elect a less formal Dining Out in which family member and other non-military guests are encouraged to take place in the unit change. There are no official requirements outlined by the United States Army to have a Hail and Farewell celebration. It is up to each unit to carry out this tradition as they see fit.\n\nThe United States Navy, on the other hand, has specified that by custom the ship's officers must give a formal dinner when their new captain arrives. There may also be a formal dinner for the departing captain and these may be combined into one formal Hail and Farewell dinner.\n\n"}
{"id": "38810478", "url": "https://en.wikipedia.org/wiki?curid=38810478", "title": "Heterogram (linguistics)", "text": "Heterogram (linguistics)\n\nHeterogram (classical compound: \"different\" + \"written\") is a term used mostly in the study of ancient texts for a special kind of a logogram consisting of the embedded written representation of a word in a foreign language, which does not have a spoken counterpart in the main (matrix) language of the text. In most cases, the matrix and embedded languages share the same script. While from the perspective of the embedded language the word may be written either phonetically (representing the sounds of the embedded language) or logographically, it is never a phonetic spelling from the point of view of the matrix language of the text, since there is no relationship between the symbols used and the underlying pronunciation of the word in the matrix language.\n\nIn English, the written abbreviations \"e.g.\", \"i.e.\", and \"viz.\" are often read respectively as \"for example\", \"that is\", and \"namely\". When read this way, the abbreviations for the Latin words \"exempli gratia\", \"id est\", and \"videlicet\" are being used logographically to indicate unrelated English phrases. Similarly, the ampersand ⟨&⟩, originally a ligature for the Latin word \"et\", in many European languages stands logographically for the local word for \"and\" regardless of pronunciation. This can be contrasted with the older way of abbreviating \"et cetera\"—\"&c.\"—where ⟨&⟩ is used to represent \"et\" as a full loanword, not a heterogram.\n\nHeterograms are frequent in cuneiform scripts, such as the Akkadian cuneiform, which uses Sumerian heterograms, or the Anatolian cuneiform, which uses both Sumerian and Akkadian heterograms. In Middle Iranian scripts derived from the Aramaic scripts (such as the Pahlavi scripts), all logograms are heterograms coming from Aramaic. Sometimes such heterograms are referred to by terms identifying the source language such as \"Sumerograms\" or \"Aramaeograms\".\n\n"}
{"id": "5584696", "url": "https://en.wikipedia.org/wiki?curid=5584696", "title": "Higher-order volition", "text": "Higher-order volition\n\nHigher-order volitions (or higher-order desire), as opposed to action-determining volitions, are volitions about volitions. Higher-order volitions are potentially more often guided by long-term convictions and reasoning.\n\nA first-order volition is a desire about anything else, such as to own a new car, to meet the pope, or to drink alcohol. Second-order volition are desires about desires, or to desire to change the process, the how, of desiring. Examples would be a new car; meeting the pope; or to desire to quit drinking alcohol permanently. A higher-order volition can go unfulfilled due to uncontrolled lower-order volitions.\n\nAn example for a failure to follow higher-order volitions is the drug addict who takes drugs even though he would like to quit taking drugs. According to Harry Frankfurt the drug addict has established free will, in respect to that single aspect, when his higher-order volition to stop wanting drugs determines the precedence of his changing, action determining desires either to take drugs or not to take drugs.\n\n"}
{"id": "41608207", "url": "https://en.wikipedia.org/wiki?curid=41608207", "title": "Human Rights between the Sexes", "text": "Human Rights between the Sexes\n\nHuman Rights between the Sexes is an analysis of the human rights of intersex people in 12 countries. It was written by Dan Christian Ghattas of the \"Internationalen Vereinigung Intergeschlechtlicher Menschen\" (the Organisation Intersex International (OII) in Germany) and published in October 2013 by the Heinrich Böll Foundation. The countries studied were Australia, Belgium, France, Germany, New Zealand, Serbia, South Africa, Taiwan, Turkey, Uganda, Ukraine and Uruguay.\n\nThe report is believed to be the first comparative international analysis of the human rights of intersex people. It found that intersex people are discriminated against worldwide.\n\nGhattas states:\nGhattas found that:\n\nGhattas makes five conclusions for human rights organisations:\n\nThe book is published in German as \"Menschenrechte zwischen den Geschlechtern\".\n\nThe book can be downloaded for free in either English or German.\n\n\n"}
{"id": "612100", "url": "https://en.wikipedia.org/wiki?curid=612100", "title": "Ideosphere", "text": "Ideosphere\n\nThe ideosphere, much like the noosphere, is the realm of memetic evolution, just like the biosphere is the realm of biological evolution. It is the \"place\" where thoughts, theories and ideas are thought to be created, evaluated and evolved. The health of an ideosphere can be measured by its memetic diversity.\n\nThe ideosphere is not considered to be a physical place by most people. It is instead \"inside the minds\" of all the humans in the world. It is also, sometimes, believed that the Internet, books and other media could be considered to be part of the ideosphere. Alas, as such media are not aware, it cannot process the thoughts it contains.\n\nAaron Lynch claims to have co-invented this word with Douglas Hofstadter in the mid-1980s.\n\nAccording to philosopher Yasuhiko Kimura, the ideosphere is in the form of a \"concentric ideosphere\" where ideas are generated by a few people with others merely perceiving and accepting these ideas from these \"external authorities.\" He advocates an \"omnicentric ideosphere\" where all individuals create new ideas and interact as self-authorities. \n\n\n"}
{"id": "860010", "url": "https://en.wikipedia.org/wiki?curid=860010", "title": "In-group favoritism", "text": "In-group favoritism\n\nIn-group favoritism, sometimes known as in-group–out-group bias, in-group bias, or intergroup bias, is a pattern of favoring members of one's in-group over out-group members. This can be expressed in evaluation of others, in allocation of resources, and in many other ways.\n\nThis interaction has been researched by many psychologists and linked to many theories related to group conflict and prejudice. The phenomenon is primarily viewed from a social psychology standpoint. Studies have shown that in-group favoritism arises as a result of the formation of cultural groups. These cultural groups can be divided based on seemingly trivial observable traits, but with time, populations grow to associate certain traits with certain behaviour, increasing covariation. This then incentivises in-group bias.\n\nTwo prominent theoretical approaches to the phenomenon of in-group favoritism are realistic conflict theory and social identity theory. Realistic conflict theory proposes that intergroup competition, and sometimes intergroup conflict, arises when two groups have opposing claims to scarce resources. In contrast, social identity theory posits a psychological drive for positively distinct social identities as the general root cause of in-group favoring behavior.\n\nIn 1906, the sociologist William Sumner posited that humans are a species that join together in groups by their very nature. However, he also maintained that humans had an innate tendency to favor their own group over others, proclaiming how \"each group nourishes its own pride and vanity, boasts itself superior, exists in its own divinities, and looks with contempt on outsiders\" (p. 13). This is seen on the group level with ingroup–outgroup bias. When experienced in larger groups such as tribes, ethnic groups, or nations, it is referred to as ethnocentrism.\n\nRealistic conflict theory (or realistic group conflict) posits that competition between groups for resources is the cause of in-group bias and the corresponding negative treatment of members of the out-group. Muzafer Sherif's Robbers Cave Experiment is the most widely known demonstration of realistic conflict theory. In the experiment, 22 eleven-year-old boys with similar backgrounds were studied in a mock summer camp situation, with researchers posing as camp personnel.\n\nThe boys were divided into two equal groups and encouraged to bond, with the aim of fostering an in-group mentality. The researchers then introduced a series of competitive activities which pitted groups against each other for a valuable prize. Hostility and out-group negativity ensued. Lastly, researchers attempted to reverse the hostility by engaging the boys in situations of mutual interdependence, an effort which eventually resulted in relative harmony between the two groups.\n\nSherif concluded from this experiment that negative attitudes toward out-groups arises when groups compete for limited resources. However, he also theorised that inter-group frictions could be reduced and positive relations created, but only in the presence of an all-encompassing goal which could only be achieved with the two groups cooperation.\n\nAccording to social identity theory, one of the key determinants of group biases is the need to improve self-esteem. The desire to view one's self positively is transferred onto the group, creating a tendency to view one's own group in a positive light, and by comparison, outside groups in a negative light. That is, individuals will find a reason, no matter how insignificant, to prove to themselves why their own group is superior. This phenomenon was pioneered and studied most extensively by Henri Tajfel, a British social psychologist who looked at the psychological root of in-group/out-group bias. To study this in the lab, Tajfel and colleagues created what are now known as minimal groups (see minimal group paradigm), which occur when \"complete strangers are formed into groups using the most trivial criteria imaginable\". In Tajfel's studies, participants were split into groups by flipping a coin, and each group then was told to appreciate a certain style of painting none of the participants were familiar with when the experiment began. What Tajfel and his colleagues discovered was that—regardless of the facts that a) participants did not know each other, b) their groups were completely meaningless, and c) none of the participants had any inclination as to which \"style\" they like better—participants almost always \"liked the members of their own group better and they rated the members of their in-group as more likely to have pleasant personalities\". By having a more positive impression of individuals in the in-group, individuals are able to boost their own self-esteem as members of that group.\n\nRobert Cialdini and his research team looked at the number of university T-shirts being worn on college campuses following either a win or loss at the football game. They found that the Monday after a win, there were more T-shirts being worn, on average, than following a loss.\n\nIn another set of studies, done in the 1980s by Jennifer Crocker and colleagues, self-esteem was studied using minimal group processes in which it was shown that individuals with high self-esteem who suffer a threat to the self-concept exhibit greater ingroup biases than people with low self-esteem who suffer a threat to the self-concept. While some studies have supported this notion of a negative correlation between self-esteem and in-group bias, other researchers have found that individuals with low self-esteem have a higher prejudice to both in-group and out-group members. Some studies have even shown that high-self-esteem groups showed a greater prejudice than did lower self-esteem groups. This research may suggest that there is an alternative explanation and additional reasoning as to the relationship between self-esteem and in-group/out-group biases. Alternatively, it is possible that researchers have used the wrong sort of self-esteem measures to test the link between self-esteem and in-group bias (global personal self-esteem rather than specific social self-esteem).\n\nIn a meta-analysis and review of the effect of oxytocin on social behavior done by Carsten De Dreu, the research reviewed shows that oxytocin enables the development of trust, specifically towards individuals with similar characteristics - categorised as 'in-group' members - promoting cooperation with and favoritism towards such individuals. This bias of oxytocin-induced goodwill towards those with features and characteristics perceived to be similar may have evolved as a biological basis for sustaining in-group cooperation and protection, fitting with the Darwinian insight that acts of self-sacrifice and cooperation contribute to the functioning of the group and hence improve the odd of survival for members of said group.\n\nRace can be used as an example of in-group and out-group tendencies because society often categorizes individuals into groups based on race (Caucasian, African American, Latino, etc.). One study that examined race and empathy found that participants receiving nasally administered oxytocin had stronger reactions to pictures of in-group members making pained faces than to pictures of out-group members with the same expression. This shows that oxytocin may be implicated in our ability to empathize with individuals of different races, with individuals of one race potentially biased towards helping individuals of the same race than individuals of another race when they are experiencing pain.\n\nOxytocin has also been implicated in lying when lying would prove beneficial to other in-group members. In a study where such a relationship was examined, it was found that when individuals were administered oxytocin, rates of dishonesty in the participants' responses increased for their in-group members when a beneficial outcome for their group was expected. Both of these examples show the tendency to act in ways that benefit people with which one feels is part of their social group, or in-group.\n\nAs noted in two recent theoretical reviews, the theoretical basis for the inclusion of self-identity in the theories of reasoned action and planned behavior has many similarities to social identity theory and its extension, self-categorization theory. According to social identity theory, an important component of the self-concept is derived from memberships in social groups and categories. When people define and evaluate themselves in terms of a self-inclusive social category (e.g. a sex, class, team) two processes come into play : (1) categorization, which perceptually accentuates differences between in-group and out-group, and similarities among in-group members (including self) on stereotypical dimensions; and (2) self-enhancement which, because the self-concept is defined in terms of group membership, seeks behaviorally and perceptually to favor the in-group over the out-group. Social identities are cognitively represented as group prototypes that describe and prescribe beliefs, attitudes, feelings and behaviors that optimize a balance between minimization of in-group differences and maximization of intergroup differences.\n\nMore specifically, according to social identity theory, there is a continuum between personal and social identity shifts along this continuum that determine the extent to which group-related or personal characteristics influence a person's feelings and actions. If a particular social identity is a salient basis for self-conception, then the self is assimilated to the perceived in-group prototype which can be thought of as a set of perceived in-group norms such that self-perception, beliefs, attitudes, feelings and behaviours are defined in terms of the group prototype. Thus, social identities should influence behaviour through the mediating role of group norms. People will be more likely to engage in a particular behaviour if it is in accord with the norms of a behaviourally relevant group membership, particularly if the identity is a salient basis for self-definition. If the group membership is not salient, then people's behaviour and feelings should be in accord with their own personal and idiosyncratic characteristics rather than group norms.\n\nOn the other hand, the self-identity theory poses that the self is often a reflection of expected norms and practices in the role that the person places him/herself in. At the center of it is the proposition that the self is made up of multi-faceted and differentiated components that exist in an organized manner for the sake of filling in roles in society. People are able to create an identity for themselves only through talking to others, and often what roles they are taking on differ from one group to another. These differing roles and positions people fill are a result of their interactions with others and are called role identities. Role identities may be self-realized or facts like being a mother, a social worker, or a blood donor. Role identities lead people to act in certain ways due to assumed expectations for the roles. Because there is satisfaction in complying with expectations of the role, there is often distress behind an inability to appear congruent to one's identity as defined by societal norms. There is also an existing hierarchy of importance for roles that individuals take on, and according to the hierarchical standing of roles, people become more representative of roles that stand higher hierarchically, according to them.\n\nIdentity salience, the likelihood of role identities being invoked in different situations, is the result of role identities being placed hierarchically in different orders from person to person. People who hold the same roles may act differently because some roles are valued over others. For example, a working mother may have less time to spend with her child as opposed to a mother that doesn't work. Behaviors are reflective of the identities that are held higher hierarchically by people, so people act out in self-worth and self-meaning according to these hierarchies. Someone who holds the identity of being a psychologist higher than the identity of being a linguist will find that while he/she may become competitive when meeting another person that is better at psychology than he/she, he/she won't care when in contact with someone who is much better at being a linguist than he/she. In a similar way, social relationships are influenced by this salience. Self-identity often places individuals in social contexts and a commitment to the role within that context becomes a big part of perpetrating the idea of self. It also finds people relating more to others that hold similar role identities at the top of their hierarchies.\n\nBecause people have self-concepts that are derived from a role they define for themselves within the context of a group, when staying within their roles, intergroup similarities are accentuated while intergroup differences are diminished. In an attempt to assimilate oneself according to the tendencies of a group, often people reconfigure their intragroup representations or identities. Certain prototypes form about these groups that reaffirm rules that members of the group are encouraged to follow. Shared information and views are discussed more often than novel and unshared information within a group, therefore a norm is established where the majority views are perpetuated and others silenced. This norm is fluid and changing according to different contexts, but those within the group who want to keep up with the majority views in all matters have to keep an active role in affirming the views of the in-group in contest to out-groups.\n\nStudies have shown that in-group favoritism arises endogenously, through the formation of cultural groups. Symbolic markers in certain conditions can result in trivial groupings developing into cultural groups. The formation of such cultural groups then results in a higher degree of in-group favoritism.\n\nEfferson, Lalive and Fehr published such a study in 2008, utilising a series of coordination games to mimic cooperation between individuals. The study found that cultural groups were able to form endogenously through creation of a linkage between a payoff-relevant behaviour and a payoff-irrelevant marker. Subsequently, in-group favouritism occurred in ensuing social interactions.\n\nParticipants were first divided into one of several populations of 10 people, and then further divided into subpopulations of 5. Each group had different payoff for coordinating on one of 2 choices, behaviour A or behaviour B. In group 1, participants were awarded 41 points for coordinating (choosing A themselves and choosing another participant who also chose A) on A and 21 for coordinating on B. The payoffs were switched in the 2nd group. In both groups participants were awarded just 1 point for mis-coordinating. During each turn participants were also allowed to choose a payoff-irrelevant marker (circle or triangle). Players from both subpopulations were mixed to create a coordination problem, and every turn, an unidentified player from each subpopulation would be randomly switched.\n\nThe experiment created a situation in which participants were strongly incentivised to develop a sense of expected behaviours in his or her subpopulation, but occasionally would find themselves in a totally new situation in which their behaviours were not in-line with social norms.\n\nThe results showed that players generally developed an inclination to pair behaviour with a marker, especially if it had resulted in a positive payoff. As linkages at an individual level increase, covariation (of marker and behaviour) at an aggregate level also increases. In the experiment, there was a significant increase in participants requesting for partners with the same-shape choice as it progressed, although the initial choice of shape had no effect on payoffs. Toward the end of the experiment, this number stood at a substantial 87%, indicating the presence of in-group favouritism.\n\nTheir study supported the thesis that the formation of cultural groups alters selective pressure facing individuals, and thus leads to certain behavioural traits being advantageous. Thus, if such selective pressures were present in past civilisations, where membership in a certain group is correlated with a certain behavioural norm, the emergence of in-group biases where it is beneficial to act in differing manners to members of the same group is certainly plausible.\n\n conducted research on gender bias that measured gender preferences without directly asking the participants. Subjects at Purdue and Rutgers participated in computerized tasks that measured automatic attitudes based on how quickly a person categorizes pleasant and unpleasant attributes with each gender. Such a task was done to discover whether people associate pleasant words (good, happy, and sunshine) with women, and unpleasant words (bad, trouble, and pain) with men.\n\nThis research found that while both women and men have more favorable views of women, women's in-group biases were 4.5 times stronger than those of men and only women (not men) showed cognitive balance among in-group bias, identity, and self-esteem, revealing that men lack a mechanism that bolsters automatic preference for their own gender.\n\nUsing a publics-goods game, Van Gugt, De Cremer, and P. Janssen (2016) found that men contributed more to their group in the face of outside competition from another group; there was no distinct difference amongst women's contributions.\n\nFershtman and Gneezy (2001) found that men showed in-group biases in a \"trust\" game based on ethnicity whereas this tendency was not present in women. The study aim to identify ethnic discrimination in Israeli Jewish society, and was conducted on 996 Israeli undergraduates. Groups were separated based on whether the participants name was typically ethnically Eastern or Ashkenazic. Similar to a dictator game, subjects were instructed to divide a sum of money (20 NIS) between themselves and another player. Player A was told that any money sent over to Player B would be tripled, and Player B would receive details of the experiment, including the name of Player A and the transferred sum. Subsequently, Player B would have a choice of whether to send any money back.\n\nThe experiment found that despite sharing similar average transfer values (10.63 for women and 11.42 for men), women did not display significant in-group biases when it came to recipients with either Ashkenazic or Eastern sounding names. However, a bias against Eastern sounding names was present amongst men.\n\nFurthermore, men showed more bias for Ashkenazic men compared to women, but the opposite was true for Eastern names. This result may seem counter-intuitive as participants appear to share more in common if they were both male, thus we would expect Eastern females to be more marginalised, but is actually consistent with other studies which studied discrimination against Afro-American women.\n\nFehr, Bernhard, and Rockenbach (2008), in a study conducted on children, found that boys displayed in-group favouritism from ages 3–8 whereas girls did not display such tendencies. The experiment involved usage of an \"envy game\", a modified version of the dictator game. A possible explanation posited by researchers relied on an evolutionary basis.\n\nThey theorised that parochialism and favouring members of the same group may have been particularly advantageous as it strengthened the individuals group position in intergroup conflicts. As males were the ones who were frequently at the forefront of such conflicts in the past, and thus bore the majority of the costs of conflicts in terms of injury or death, evolution may have favoured a greater sensitivity in males in situations which resulted in an advantageous payoff for their in-group. Thus males tended to show in-group biases from a younger age than females, as was evident in the experiment.\n\nA study conducted during the 2008 Presidential elections showcased how group identities were dynamic. The study carried out on 395 Democrats from Cambridge, MA, using an Economics dictator game. Subjects were given $6 to divide between themselves and another person. The recipients remained anonymous apart from which candidate they supported in the Democratic Primaries.\n\nData was collected in three separate periods. June 10 to 18th (after Hillary Clinton's concession speech on June 7); August 9 to 14th, before the Democratic National Convention on the 25th; and September 2 to 5th, in the buildup to the Presidential elections. The results showed that men displayed significant in-group favouritism from June all the way to the DNC in August. This in-group bias however was not present in September. Women displayed no significant in-group favouritism throughout.\n\nThe experiment showed how group identities were flexible and could change over time. Researchers theorised that in-group bias was strong in June as the competition to be the Democratic representative in the elections was still recent and thus salient. A lack of actual electoral conflict (against the Republicans) caused perception of salient groupings to remain throughout August. Only in September did the in-group favouritism subside as a superordinate goal shared between groups was now present.\n\nSocial psychologists have long made the distinction between ingroup favouritism and outgroup negativity, where outgroup negativity is the act of punishing or placing burdens upon the outgroup. Indeed, a significant body of research exists that attempts to identify the relationship between ingroup favouritism and outgroup negativity, as well as conditions that will lead to outgroup negativity. For example, Struch and Schwartz found support for the predictions of belief congruence theory. The belief congruence theory concerns itself with the degree of similarity in beliefs, attitudes, and values \"perceived\" to exist between individuals. This theory also states that dissimilarity increases negative orientations towards others. When applied to racial discrimination, the belief congruence theory argues that the perceived dissimilarity of beliefs has more of an impact on racial discrimination than does race itself.\n\nResearch finds evidence of in-group bias in police investigations and judicial decisions.\n\nOxytocin is not only correlated with the preferences of individuals to associate with members of their own group, but it is also evident during conflicts between members of different groups. During conflict, individuals receiving nasally administered oxytocin demonstrate more frequent defense-motivated responses toward in-group members than out-group members. Further, oxytocin was correlated with participant desire to protect vulnerable in-group members, despite that individual's attachment to the conflict. Similarly, it has been demonstrated that when oxytocin is administered, individuals alter their subjective preferences in order to align with in-group ideals over out-group ideals. These studies demonstrate that oxytocin is associated with intergroup dynamics.\n\nFurther, oxytocin influences the responses of individuals in a particular group to those of another group. The in-group bias is evident in smaller groups; however, it can also be extended to groups as large as one's entire country leading toward a tendency of strong national zeal. A study done in the Netherlands showed that oxytocin increased the in-group favoritism of their nation while decreasing acceptance of members of other ethnicities and foreigners. People also show more affection for their country's flag while remaining indifferent to other cultural objects when exposed to oxytocin. It has thus been hypothesized that this hormone may be a factor in xenophobic tendencies secondary to this effect. Thus, oxytocin appears to affect individuals at an international level where the in-group becomes a specific \"home\" country and the out-group grows to include all other countries.\n\nCross-cultural studies have found that in-group derogation, the tendency to criticize members of one's own group or culture more harshly than members of outside groups, is more common among members of disadvantaged and minority groups than among members of the majority or dominant group. According to psychology professor Christine Ma-Kellams et al. (2011), system justification theory seeks to explain why \"minorities sometimes endorse system-justifying views of their group\". They said their research into in-group favoritism and derogation partially supported this theory, but that the theory failed to address all of the nuances.\n\nMa-Kellams et al. also found that, compared to individualist cultures, people from collectivist cultures, such as East Asian cultures, tended to judge their own group members less favorably than they judged outsiders, whereas people from individualist cultures were inclined to judge members of their own group more favorably than they judged outsiders. Social identity theory and Freudian theorists explain in-group derogation as the result of a negative self-image, which they believe is then extended to the group. Ma-Kellams et al. theorized that \"ingroup derogation may be more culturally normative and less troubling for East Asians\" as evidenced by the fact that East Asians were also likely to report high levels of positive affect (emotion) towards members of their in-group, demonstrating ambivalence towards the unfavorable characteristics they had acknowledged about their in-group. According to Ma-Kellam et al., culturally-ingrained attitudes and beliefs, rather than low self-esteem, may play a role in collectivist cultures' in-group derogation due to their ability to tolerate holding seemingly contradictory views.\n"}
{"id": "3232486", "url": "https://en.wikipedia.org/wiki?curid=3232486", "title": "Inhibition theory", "text": "Inhibition theory\n\nInhibition theory is based on the basic assumption that during the performance of any mental task requiring a minimum of mental effort, the subject actually goes through a series of alternating latent states of distraction (non-work 0) and attention (work 1) which cannot be observed and are completely imperceptible to the subject. \n\nAdditionally, the concept of inhibition or reactive inhibition which is also latent, is introduced. The assumption is made that during states of attention inhibition linearly increases with a slope \"a\" and during states of distraction inhibition linearly decreases with a slope \"a\".According to this view the distraction states can be considered a sort of recovery state.\n\nIt is further assumed, that when the inhibition increases during a state of attention, depending on the amount of increase, the inclination to switch to a distraction state also increases. When inhibition decreases during a state of distraction, depending on the amount of decrease, the inclination to switch to an attention state increases. The inclination to switch from one state to the other is mathematically described as a transition rate or hazard rate, making the whole process of alternating distraction times and attention times a stochastic process.\n\nA non-negative continuous random variable \"T\" represents the time until an event will take place. The hazard rate \"λ\"(\"t\") for that random variable is defined to be the limiting value of the probability that the event will occur in a small interval [\"t\",\"t\" + Δ\"t\"]; given the event has not occurred before time \"t\", divided by Δ\"t\". Formally, the hazard rate is defined by the following limit: \n\nThe hazard rate \"λ\"(\"t\") can also be written in terms of the density function or probability density function \"f\"(\"t\") and the distribution function or cumulative distribution function \"F\"(\"t\"): \n\nThe transition rates \"λ\"(\"t\"), from state 1 to state 0, and \"λ\"(\"t\"), from state 0 to state 1, depend on inhibition Y(\"t\"): \"λ\"(\"t\") = \"ℓ\"(Y(\"t\")) and \"λ\"(\"t\") = \"ℓ\"(Y(\"t\")), where \"ℓ\" is a non-decreasing function and \"ℓ\" is a non-increasing function. Note, that \"ℓ\" and \"l\" are dependent on \"Y\", whereas \"Y\" is dependent on \"T\". Specification of the functions \"l\" and \"l\" leads to the various inhibition models. \n\nWhat can be observed in the test are the actual reaction times. A reaction time is the sum of a series of alternating distraction times and attention times, which cannot be observed. It is, nevertheless, possible to estimate from the observable reaction times some properties of the latent process of distraction times and attention times, i.e., the average distraction time, the average attention time, and the ratio a/a. In order to be able to simulate the consecutive reaction times, inhibition theory has been specified into various inhibition models. \n\nOne is the so-called beta inhibition model. In the beta-inhibition model, it is assumed that the inhibition Y(\"t\") oscillates between two boundaries which are 0 and \"M\" (\"M\" for Maximum), where \"M\" is positive. In this model \"ℓ\" and \"ℓ\" are as follows: \n\nand \n\nboth with \"c\" > 0 and \"c\" > 0. Note that, according to the first assumption, as \"y\" goes to \"M\" (during an interval), \"ℓ\"(\"y\") goes to infinity and this forces a transition to a state of rest before the inhibition can reach \"M\". According to the second assumption, as y goes to zero (during a distraction), \"ℓ\"(\"y\") goes to infinity and this forces a transition to a state of work before the inhibition can reach zero. For a work interval starting at \"t\" with inhibition level \"y\" = \"Y\"(\"t\") the transition rate at time \"t\" + \"t\" is given by \"λ\"(\"t\") = \"l\"(\"y\" + \"a\"t). For a non-work interval starting at \"t\" with inhibition level \"y\" = \"Y\"(\"t\") the transition rate is given by \"λ\"(\"t\") = \"ℓ\"(\"y\" − \"a\"\"t\"). Therefore \n\nand \n\nThe model has \"Y\" fluctuating in the interval between 0 and \"M\". The stationary distribution of \"Y\"/\"M\" in this model is a beta distribution (the beta inhibition model). \n\nThe total real working time until the conclusion of the task (or the task unit in case of a repetition of equivalent unit tasks), for example, in the Attention Concentration Test, is referred to as \"A\". The average stationary response time \"E\"(\"T\") may be written as\n\nFor \"M\" goes to infinity \"λ\"(\"t\") = \"c\". This model is known as the gamma − or Poisson inhibition − model (see Smit and van der Ven, 1995).\n\nInhibition theory has especially been developed to account for short-term oscillation as well as the long-term trend in the reaction time curves obtained in continuous response tasks such as the Attention Concentration Test (ACT). The ACT typically consists of an overlearned prolonged work task in which each response elicits the next. Several authors, among them Binet (1900), stressed the importance of the fluctuation in the reaction times suggesting the mean deviation as a measure of performance. \n\nIn this connection it is also worthwhile to mention a study by Hylan (1898). In his experiment B, he used, a 27 single digits addition task indicating the importance of the fluctuation of reaction times and was the first to report gradually increasing (marginally decreasing) reaction time curves (Hylan, 1898, page 15, figure 5).\n\nRecently, the inhibition model has been also used to explain the phase durations in binocular rivalry experiments (van der Ven, Gremmen & Smit, 2005). The model is able to account for the statistical properties of alternating phase durations\n\"T\", \"T\", \"T\", \"T\", \"T\", \"T\", ..., \nrepresenting the amount of time a person perceives the stimulus in one eye \"T\" and in the other eye \"T\".\n\n"}
{"id": "46536057", "url": "https://en.wikipedia.org/wiki?curid=46536057", "title": "Intelligence and personality", "text": "Intelligence and personality\n\nIntelligence and personality have some common features; for example, they both follow a relatively stable pattern throughout the whole of an individual’s life, which is genetically determined in different degrees. In addition, they are both significant predictors of various outcomes, such as educational achievement, occupational performance, and health. However, the traditional view in psychology is that there is no meaningful relationship between personality and intelligence and they should be studied as separate entities.\n\nFirstly, intelligence is considered to be a cognitive process, while personality is recognised as being non-cognitive, and this implies that there is a great distinction between personality and intelligence. However, other psychologists argue that the distinction between cognitive and non-cognitive is vague because almost all personality traits have cognitive attributes, although they are more obvious in some traits than in others. For example, neuroticism is a personality trait, but is also related to rumination and compulsive thinking about possible threats, while agreeableness is associated with understanding and considering the mental state of others.\n\nIn addition, different methods are generally used to assess intelligence and personality. Intelligence is normally measured by means of ability tests, whereas personality is usually assessed by means of questionnaires. Furthermore, different typical measurements lead to another conceptual distinction, which is that intelligence is considered to indicate individuals’ \"maximal performance\", while personality is believed to reflect their \"typical behaviour\". However, others argue that multiple methods can be used to assess intelligence and personality; for example, questionnaires that require to be rated by self, peers or observers can also be used to measure individuals’ mental ability, although these kinds of measurement may lack accuracy. Therefore, different typical methods cannot prove that the relationship between intelligence and personality is a meaningless one. In addition, since individuals’ ability can also affect their typical behaviour, IQ can predict outcomes related to aspects such as performance at work, academic achievement, and health. Therefore, ability tests can provide indices of both maximal performance and typical behaviour.\n\nAn increasing number of studies have recently explored the relationship between intelligence and the Big Five personality traits.\n\nOpenness shows the strongest positive relationship with \"g\" among the Big Five personality traits, ranging from r=.06 to r=.42. Individuals with a high level of openness enjoy the experience of learning and prefer an intellectually stimulating environment. Therefore, openness shows a significant moderate association with crystallized intelligence (r=.30), but a non-significant low association with fluid intelligence (r=.08), and these results are consistent with those of other studies.\n\nSome psychologists have recently pointed out that previous instruments used to measure openness actually assessed two distinctive aspects. The first is intellect, which reflects intellectual engagement and perceived intelligence and is marked by ideas, while the second is emotion, which reflects the artistic and contemplative qualities related to being engaged in sensation and perception and is marked by fantasy, aesthetics, feelings and actions. On this basis, intellect was found to be associated with the neural system of the working memory, which is related to \"g\", whereas openness was not. In addition, according to a study of genetic behaviour, intellect is genetically closer to intelligence than openness.\n\nThe association between conscientiousness and intelligence is complex and uncertain. Individuals with a lower level of intelligence are always assumed to tend to behave in an orderly fashion and do extra work, which is related to being conscientious, in order to compensate for their lower level of cognitive ability. However, although intelligence has been observed to be negatively correlated with conscientiousness in some studies, others have not found this correlation to be significant and have even found a positive relationship.\n\nFurthermore, some interaction has been found between conscientiousness and intelligence. Conscientiousness has been found to be a stronger predictor of safety behaviour in individuals with a low level of intelligence than in those with a high level. This interaction may also be found in educational and occupational settings in future studies. Therefore, relatively speaking, an increase in either conscientiousness or intelligence may compensate for a deficiency in the other.\n\nThe results of a meta-analysis research conducted in 1997, which consisted of 35 studies, indicated that there is a very small, but statistically significant positive correlation between Extraversion and \"g\" (r=.08). Another recent meta-analysis of extraversion, which comprised 50 new studies, reported a similar correlation (r=.05).\n\nThere are some moderating variables in the relationship between extraversion and \"g\" including differences in the assessment instruments and samples’ age and sensory stimulation; for example, no meaningful correlation was found between extraversion and intelligence in the samples of children. Furthermore, Bates and Rock (2004) used Raven’s matrices and found that extraverts performed better than introverts with increasing auditory stimulation, whereas introverts performed best in silence. This result is consistent with that of Revelle et al. (1976). In addition, different measures and different sub-traits of extraversion have been found to cause significantly different correlations.\n\nNeuroticism has been found to have a reliable negative association with \"g\"(r=-.33). However, other researchers have recently reported a lower coefficient of .09 for general mental ability and emotional stability. Although these studies have some differences, they all indicate that intelligence increases with a decrease in negative emotion.\n\nOne of the reasons for this negative correlation is Test anxiety, which refers to the psychological distress experienced by individuals prior to, or during, an evaluative situation. This is closely associated with neuroticism and has a negative influence on individuals’performance in an intelligence test (r=-.23).\n\nSome argue that all the aforementioned evidence indicates that neuroticism is related to test performance rather than true intelligence. However, according to the results of a longitudinal study recently conducted by Gow et al., (2005), neuroticism influences an age-related decline in intelligence and there is a small negative correlation between neuroticism and a change in the level of IQ (r=-.18). Although it is still debatable if neuroticism reduces general intelligence, this study provided some valuable evidence and a direction for research. \nIn addition, some interaction between intelligence and neuroticism has been found. Individuals with a high level of neuroticism demonstrated a poor performance, health, and adjustment only if they had a low level of intelligence. Therefore, intelligence may act as a buffer and compensate neuroticism in individuals.\n\nNo significant association between agreeableness and \"g\" has been found in previous research. However, some components of agreeableness have been found to be related to intelligence. For example, aggression is negatively associated with intelligence (r is around -.20) because unintelligent people may experience more frustration, which may lead to aggression and aggression and intelligence may share some biological factors. In addition, emotional perception and emotional facilitation, which are also components of agreeableness, have been found to be significantly correlated with intelligence. This may be because emotional perception and emotional facilitation are components of emotional intelligence and some researchers have found that emotional intelligence is a Second-Stratum Factor of \"g\".\n"}
{"id": "52216453", "url": "https://en.wikipedia.org/wiki?curid=52216453", "title": "Invisible support", "text": "Invisible support\n\nInvisible support is a psychological term used to describe a type of social support in which supportive exchanges are not visible to recipients. There are two possible situations that can describe acts of invisible support. The first possibility entails a situation where \"recipients are completely unaware of the supportive transaction between themselves and support-givers\". For example, a spouse may choose to spontaneously take care of housework without mentioning it to the other couple-member. Invisible support also occurs when \"recipients are aware of an act that takes place but do not interpret the act as a supportive exchange\". In this case, a friend or family member may subtly provide advice in an indirect manner as a means to preserve the recipient's self-esteem or to defer his or her attention from a stressful situation. Invisible support can be viewed on both ends of an exchange, in which the recipient is unaware of the support received and the provider enacts support in a skillful, subtle way.\n\nIt is well known that perceptions of social support availability predict better adjustment to stressful life events. It has been found that the perception of support availability is inherently comforting, and can serve as a psychological safety-net that motivates self-reliant coping efforts in the face of stress. Although the perception of support availability is associated with better adjustment, the knowledge that one has been the recipient of specific supportive acts has often been unhelpful to effectively reduce stress. The knowledge of receiving help may come at a cost with decreased feelings of self-esteem and self-efficacy, because it increases recipients' awareness towards their personal difficulties to manage stressors. People's well-intentioned support attempts may also be miscarried, and their efforts could either fail or even worsen the situation for a person under stress. Since supportive acts benefit recipients but their actual knowledge of receiving support is sometimes harmful, it has been theorized that the most effective support exchange would involve one in which the provider reports giving support but the recipient does not notice that support has occurred. From a cost-benefit point of view, invisible support would be optimal for the recipient because the benefits of provision are accrued while the costs of receipt are avoided. Using the same idea, it also implies that the least effective type of support would be one in which the provider does not report providing support but the recipient reports receiving it. The first investigation of invisible support involved a couples study in which one member was preparing for the New York State Bar Exam. Support receipt and provision were measured by having both couple members complete daily diary entries. Over the course of one month, stressed individuals who reported low frequency of received support (but whose partner ranked his or her own actions as highly supportive) rated themselves low on anxiety and depression compared to other individuals who reported high frequency of received support.\n\nA substantial body of work has evidence to suggest that support is most effective when it is invisible or goes unnoticed by recipients. While invisible support has been shown to benefit recipients over visibly supportive acts in some cases, there have also been instances where recipients have benefitted from visible support as well. For example, greater observed support enacted by intimate partners during couples’ support-relevant exchanges have been shown to build feelings of closeness and support, boost positive mood and self-esteem, and foster greater goal achievement and relationship quality across time. It has been recently suggested that acts of invisible support and visible support may be beneficial or costly depending on different circumstances. To investigate this idea, a recent study in 2013 compared the short-term and long-term effects of visible and invisible support reception during romantic couples’ discussions of each partner’s personal goal. It was found that either type of support was more beneficial depending on the emotional distress that recipients felt at the time. Visible emotional support (support through reassurance, encouragement, and understanding) was associated with perceptions of greater support and discussion success for recipients who felt greater distress during the discussion. In contrast, invisible emotional support was not associated with recipients’ post-discussion perceptions of support or discussion success. For long-term support effects, it was found that only invisible emotional support predicted greater goal achievement across the following year. When put together, these findings suggest that visible support and invisible support have unique functions for well-being. When people are under distress, visible support appears to be a short-term remedy to reassure recipients that they are cared for and supported. These benefits are only present when recipients are actually distressed during the time that the supportive act takes place. On the other hand, while invisible support tends to go unnoticed by recipients, it seems to play an integral role in the long-term success of goal-maintenance.\n\nThe effects of invisible support on recipients have been extensively investigated, but the consequences of invisible support on providers are less known. One study in 2016 investigated the benefits and costs of invisible support on couple-members who enacted supportive behaviors by differentiating the processes of invisible emotional support (support through reassurance, encouragement, and understanding) from processes of invisible instrumental support (providing tangible aid such as sending money or childcare). No costs of support-giving were found for providers when they demonstrated acts of invisible emotional support. The effects for invisible instrumental support told a different story, where providers who reported high relationship satisfaction were unaffected, but providers who reported low relationship satisfaction were negatively affected by their acts of invisible instrumental support with an increase in negative mood. These findings suggest that emotional comfort may be a more central function to maintain close relationships than instrumental support. Therefore, providing invisible emotional support may lead to less perceptions of a costly inequity than providing invisible instrumental support on average. However, since invisible instrumental support did not incur costs for providers who reported high relationship satisfaction, it implies that high relationship satisfaction may buffer potential costs that would otherwise be felt by support-providers. The differential results between invisible instrumental and emotional support indicate that a solid distinction between instrumental and emotional social support may be useful to take into account when investigating effects of invisible support as a whole.\n"}
{"id": "555336", "url": "https://en.wikipedia.org/wiki?curid=555336", "title": "Karuṇā", "text": "Karuṇā\n\nKaruā (in both Sanskrit and Pali) is generally translated as compassion. It is part of the spiritual path of both Buddhism and Jainism.\n\nKaruā is important in all schools of Buddhism. For Theravāda Buddhists, dwelling in karuā is a means for attaining a happy present life and heavenly rebirth. For Mahāyāna Buddhists, karuā is a co-requisite for becoming a Bodhisattva.\n\nIn Theravāda Buddhism, karuā is one of the four \"divine abodes\" (\"brahmavihāra\"), along with loving kindness (Pāli: \"mettā\"), sympathetic joy (\"mudita\") and equanimity (\"upekkha\"). In the Pali canon, the Buddha recommends cultivating these four virtuous mental states to both householders and monastics. When one develops these four states, the Buddha counsels radiating them in all directions, as in the following stock canonical phrase regarding karuā:\n\nSuch a practice purifies one's mind, avoids evil-induced consequences, leads to happiness in one's present life and, if there is a future karmic rebirth, it will be in a heavenly realm.\n\nThe Pali commentaries distinguish between karuā and mettā in the following complementary manner: Karuna is the desire to remove harm and suffering (\"ahita-dukkha-apanaya-kāmatā\") from others; while mettā is the desire to bring about the well-being and happiness (\"hita-sukha-upanaya-kāmatā\") of others.\nThe \"far enemy\" of karuā is cruelty, a mind-state in obvious opposition. The \"near enemy\" (quality which superficially resembles karuā but is in fact more subtly in opposition to it), is (sentimental) pity: here too one wants to remove suffering, but for a partly selfish (attached) reason hence not the pure motivation. \nIn the Pali Canon, buddhas are also described as choosing to teach \"out of compassion for beings.\"\n\nIn Mahāyāna Buddhism, karuā is one of the two qualities, along with enlightened wisdom (Sanskrit: \"prajña\"), to be cultivated on the bodhisattva path. According to scholar Rupert Gethin, this elevation of karuā to the status of prajña is one of the distinguishing factors between the Theravāda arahant ideal and the Mahāyāna bodhisattva ideal:\nThroughout the Mahāyāna world, Avalokiteśvara (Sanskrit; Chinese: Guan Yin; Japanese: Kannon; Tibetan: Chenrezig) is a bodhisattva who embodies karuā.\n\nIn the Intermediate section of the \"Stages of Meditation\" by Kamalaśīla, he writes:\nIn Tibetan Buddhism, one of the foremost authoritative texts on the Bodhisattva path is the \"Bodhisattvacaryāvatāra\" by Shantideva. In the eighth section entitled \"Meditative Concentration\", Shantideva describes meditation on Karunā as thus:\n\nKaruā is associated with the Jain practice of compassion. For instance, karuā is one of the four reflections of universal friendship — along with amity (Sanskrit: \"maitri\"), appreciation (\"pramoda\") and equanimity (\"madhyastha\")—used to stop (\"samvara\") the influx of karma.\n\nKaruā is a common first name throughout India, used for both genders.\n\nLithuanian \"karūna\" means \"crown\", possible relation of meaning of qualities of crown owners.\n\n\n\n"}
{"id": "2444954", "url": "https://en.wikipedia.org/wiki?curid=2444954", "title": "Kees Boeke", "text": "Kees Boeke\n\nCornelis Boeke (25 September 1884, Alkmaar – 3 July 1966, Abcoude), usually known as Kees Boeke, was a Dutch reformist educator, Quaker missionary and pacifist. He is best known for his popular essay/book \"Cosmic View\" (1957) which presents a seminal view of the universe, from the galactic to the microscopic scale, and which inspired several films.\n\nBoeke tried to reform education by allowing the children to contribute their ideas. He called this process sociocracy and regarded schools as workshops, with pupils as workers, and teachers as co-workers. Based on Quaker ideas, he wanted the children to respect democracy. In 1926, he founded a school in Bilthoven, which he led until 1954. As a child, the later Dutch Queen Beatrix attended the school.\n\nKees Boeke grew up in a Mennonite family in Alkmaar. He studied architecture at the Delft University of Technology. As a student, he spent a year in England, where he met the Quakers. He became a Quaker and attended Woodbrooke Quaker Study Centre, a college in Selly Oak, Birmingham. There, he found inspiration in Bournville, the garden village which the Cadbury family (owners of the chocolate factory) had built for their workers. He met and married Beatrice (Betty) Cadbury. The couple went to Syria in 1912 as Quaker missionaries. In 1914, after the outbreak of World War I, they returned to England. They became active in peace work, the Fellowship of Reconciliation having come into being in 1914 through Henry Hodgkin. In 1915 Boeke traveled to Berlin, where he met Friedrich Siegmund-Schultze, with whom Hodgkin had been working at the outbreak of war. Boeke began to speak publicly in England: \"The Germans are our brothers; God did not create man that he might kill; the war will find its quickest end when all soldiers lay down their weapons.\" He was deported from Britain and returned to the Netherlands. His family followed; there they lived in Bilthoven, near Utrecht. Their home soon became a pacifist centre. Later in the Second World War Boeke took part in the underground Dutch resistance movement against the same Germans, he called brothers before. This was, however, in line with his ideas of anti-authority and his disapproval of war and prosecution.\n\nAfter the First World War, Boeke erected a large conference centre in Bilthoven, which he called \"Brotherhood House.\" The first international peace conference took place there between 4 and 11 October 1919. Present at the conference were Leon Revoyne, Mathilda Wrede, Leonard Ragaz, Pierre Ceresole, as well as Hodgkin and Schultze. Boeke and Ceresole became the secretaries of this movement, which initially called itself \"Christian International\", later the International Fellowship of Reconciliation. Together with Helene Stöcker, and Wilfred Wellock, they founded the Service Civil International and in 1921 \"Paco\" (the Esperanto word for peace), which in 1923 became War Resisters' International (WRI).\n\nKees and Betty Boeke considered war to be rooted in the entanglement of the state and capitalism. As Betty was a Cadbury, she inherited large shares in her family's firm. She transferred this money to various charitable organizations such as the Quaker-Help Organisation in Russia in 1920. Later, she gave the shares to a trust for the workers of the Cadbury factory. For a while, the Boekes abstained from using money, so as to avoid contributing to the state — since public funds are also spent on weapons. They never used public transport, nor did they pay postage, tolls, or taxes. As a result, they were imprisoned several times. On one occasion the Dutch tax authorities auctioned off the estate in order to recover taxes. Queen Wilhelmina was in attendance at the auction, and purchased Kees' favorite violin, only to return it to him on the spot. Boeke supported his family by working in Utrecht in a building association which he had founded; he did not work as an architect (which was his training), but as a simple worker.\nIn the late 1920s Boeke increasingly withdrew from international peace movements. Believing he could build a better society through educating children, he started a school called \"De werkplaats\" (the workshop). He founded his school in 1926 when all private schools, including the Montessori school his children attended, started receiving an equal amount of money per child from the state, to which he objected.\n\nHis school, which uses Maria Montessori's methods, extended by Boeke's own educational ideas, became nationally known; even the Dutch queen Juliana sent her daughters there. The school has been hugely influential for its creative way of making the students co-responsible for their own curriculum, together with the teachers; many students who failed in regular schools have blossomed at \"De werkplaats\", but on the other hand many talented children could not reach a high level in this school.\n\nCo-responsibility in school did not mean a freewheeling life at \"the Werkplaats\". Children had to perform tasks such as cleaning the school, growing vegetables and fruits, and helping with lunch cooking. Boeke's notion of sociocracy was, in effect, a secular implementation of the Quaker ideals applied to education in such a way that children were treated as adults, and were on first-name terms with their teachers.\n\nBoeke wrote a major book on education[what is its title, etc.?!]. One of his last works was Cosmic View (New York 1957). He died in 1966 in the company of his family.\n\nBoeke's system of sociocracy survives today and was expanded upon in the work of a well-known student of the school, Dr. Gerard Endenburg, who in the 1960s and '70s developed a governance and decision-making methodology by the same name while directing the Endenburg Electrotechniek company.\n\nBoeke's essay/book Cosmic View (1957) presents a seminal view of the universe, from the galactic to the microscopic scale. It inspired several films:\n\n\"Cosmic View\" is mentioned as an inspiration by Will Wright, creator of a video game, \"Spore\" (2008).\n\n"}
{"id": "51494663", "url": "https://en.wikipedia.org/wiki?curid=51494663", "title": "Kjell Olav A. Maldum", "text": "Kjell Olav A. Maldum\n\nKjell Olav A. Maldum (born 12 December 1962) is a Norwegian entrepreneur and business leader. He is a public figure in the Norwegian movement for bottle recycling, an equivalent to bottle bill in the US and cash for container in Australia. Since 2007, he has been serving as the CEO and Chairman of Infinitum AS, the operator of the national paid recycling scheme for bottles and cans marked with the official \"recyclable\" or \"deposit\" logo in Norway.\n\nBeing a graduated from NTNU in Trondheim, Maldum has served in different technical and leadership positions before being appointed as CEO of Infinitum in 2007. He has been a Department Manager at National Institute of Technology (Norway) Teknologisk Institutt 1990-2000, and CEO of Groceries' Environmental Forum or DMF (DAGLIGVAREHANDELENS MILJØFORUM in Norwegian) 2001–2007\n\nThrough his career and especially in deposit-return system for bottles, he became a known figure for advocating for environment in Norway, lecturing at academic gatherings and national TV programs to promote the idea of where he has promoted sustainable production with low impact on environment and recycling of one-way containers and avoid wasting food. \nIn 2006 he won the Optimization Award of the year in Norway. It has been the first time that a person won the award instead of an entity for \"his extensive efforts to ensure that the retail sector have optimal logistics and thus be the most environmentally friendly \nMaldum has been behind the deposit-return TV commercials and \"Infinitum movement\" in Norway where a number of celebrities, artists and athletes advertise and encourage for recycling of the materials in the society. The movememnt encourages people to infinitely recycle instead the containers instead of just rhewoing them away. Prime Minister Erna Solberg also took part in the TV action for the bottle recycling.\n\nUntil 2014 Coca-Cola has been using non-deposit bottle for its beverages in Norway. Kjell Olav Maldum played a central role in negotiations for Coca-Cola Norway switching from non-deposit refillable bottles to non-refillable deposit bottles. The move was considered as an environmentally friendly one to introduce deposit on bottles and decrease littering, but it also led to downsizing of Coca-Cola in Norway due to less labor needed for one-way bottles and made headline in Norwegian market about the job losses and also counter-arguments Coca-Cola Norway also promised to invest in recycling facilities inside Norway. \nMaldum was also behind the efforts that finally led to the recycling of aluminum cans performed in Norway. The aluminum cans that have been collected in Norway were used to be sent to France for recycling but it has been recycled by Norsk Hydro in Holmestrand since 2014. The move was considered as environmentally friendly step vowing for recycling 60,000 mt of aluminium annually in Holmestrand.\n\nInfinitum AS\n"}
{"id": "46818882", "url": "https://en.wikipedia.org/wiki?curid=46818882", "title": "Mani Jewel", "text": "Mani Jewel\n\nA Mani Jewel () refers to any of various jewels mentioned in Buddhist literature as either metaphors for several concepts in Buddhist philosophy or as mythical relics. The word \"mani\" is simply Sanskrit and Pali for \"jewel\", so the phrase \"Mani Jewel\" is in one sense redundant. However, the Mani Jewel metaphors were significantly expanded in Chinese language texts in which it was also called by essentially the same redundant name \"móní zhū\", where the first two characters (摩尼, móní) are the transcription of \"mani\" and the third character (珠) is its Chinese translation, \"jewel\". The English phrase \"Mani Jewel\" is thus in essence a translation of the Chinese term. The use of the Mani Jewel in Buddhist literature includes various magical relics such as the wish-fulfilling cintamani as well as metaphorical devices to illustrate several ideas such as Buddha-nature and Śūnyatā.\n\nThe Mani Jewel makes its first appearance in the Pali Nikāyas where it is mentioned as one of the seven treasures owned by a \"wheel-turning king\". The Mahasudhassana Sutta in the Digha Nikaya describes the Mani Jewel as follows:\n\n“It was a beryl, pure, excellent, well-cut \ninto eight facets, clear, bright, unflawed, \nperfect in every respect. The luster of this \nJewel-Treasure radiated for an entire yojana \nround about.\nThe Mani Jewel in this text serves as the source of virtue and good governance for the king. Without it he would lose his throne.\n\nLater texts describe the Mani Jewel differently. One version is the Cintamani or wish-fulfilling jewel. It was said to be originally owned by the God Indra, but it fell to the earth during a war with the Asuras, allowing whoever possess it to have their wishes granted. Depictions of the Bodhisattvas Ksitigarbha and Avalokiteshvara sometimes show them holding this Cintamani, indicating their ability to fulfill the wishes of sentient beings.\n\nThe Mani Jewel also appears as a water purifying jewel (清水摩尼) where it could be placed in muddy water by traveling monks, causing any cloudiness to settle out leaving the water clear and pure. This version of the jewel is mentioned in the Abhidharma-kosa where it is used as a metaphor for faith as an agent capable of dispelling uncertainty.\n\nYet another depiction of the jewel is in the metaphor of Indra's net which appears in the Avatamsaka Sutra. It describes a net of infinite size with infinite knots, with each knot containing a Mani Jewel with infinite facets. Each individual Mani Jewel reflects every other Mani Jewel in the same way that any individual being or phenomenon is indistinguishable from the whole or noumenon due to their fundamental interconnectedness.\n\nThe Lankavatara Sutra, the Sutra of Perfect Enlightenment, and the Surangama Sutra all used the Mani Jewel as metaphors for Buddha-nature. In these sutras, a transparent Mani Jewel within us changes colors depending on the conditions around us, representing the five skandhas. The Mani Jewel itself represents each being's Buddha-nature, but because of the three poisons of ignorance, attachment, and aversion, a being sees only the various colors emitted by the jewel. These are mistakenly perceived as the defilements rather than the purity of the jewel itself, which is merely reflecting conditions around it. Thus Buddha-nature is not perceived and only the five skandhas are seen, which are then conflated with a sense of self in opposition to the Buddhist idea of anātman or no-self.\n\nLater, the Mani Jewel began to appear in texts produced by Zen Buddhists. An early example is found in Guifeng Zongmi's work \"Chart of the Master-Disciple Succession of the Chan Gate That Transmits the Mind Ground in China\" in which he compares the four contemporary Zen schools: the Northern School, the Ox Head School, the Hongzhou school and the Heze school. He accomplishes this by comparing how each school would interpret the Mani Jewel metaphor used in the Sutra of Perfect Enlightenment discussed above. According to Guifeng, the Northern School would believe in a fundamentally pure Mani Jewel that must be cleaned to reveal its purity; the Ox Head school would perceive both the color reflections and the Mani Jewel itself as empty; the Hongzhou school would say that the blackness covering the Mani Jewel is the Jewel itself, and that its purity can never be seen; the Heze School (to which Guifeng belonged) would interpret the black color covering the jewel as an illusion that is in fact just a manifestation of its brightness such that the surface defilements and the purity of the Jewel interpenetrate one another.\n\nEihei Dōgen, a 13th-century Zen monk and founder of the Sōtō school of Zen Buddhism in Japan, wrote extensively on the Mani Jewel in an essay of his large work the Shōbōgenzō entitled \"Ikka myōju\", or \"One Bright Jewel\". The essay primarily comments on the phrase of the Tang Dynasty Chinese monk Xuansha Shibei, who wrote that \"the ten-direction world is one bright jewel\". His phrase is in turn an adaptation of the earlier writings of Guifeng Zongmi mentioned above.\n"}
{"id": "2530829", "url": "https://en.wikipedia.org/wiki?curid=2530829", "title": "Maxim (philosophy)", "text": "Maxim (philosophy)\n\nA maxim is a concise expression of a fundamental moral rule or principle, whether considered as objective or subjective contingent on one's philosophy. A maxim is often pedagogical and motivates specific actions. The \"Oxford Dictionary of Philosophy\" defines it as:\n\nIn deontological ethics, mainly in Kantian ethics, maxims are understood as subjective principles of action. A maxim is thought to be part of an agent's thought process for every rational action, indicating in its standard form: (1) the action, or type of action; (2) the conditions under which it is to be done; and (3) the end or purpose to be achieved by the action, or the motive. The maxim of an action is often referred to as the agent's intention. In Kantian ethics, the categorical imperative provides a test on maxims for determining whether the actions they refer to are right, wrong, or permissible.\n\nThe categorical imperative is stated canonically as: \"Act only according to that maxim whereby you can, at the same time, will that it should become a universal law.\"\n\nIn his \"Critique of Practical Reason\", Immanuel Kant provided the following example of a maxim and of how to apply the test of the categorical imperative:\nI have, for example, made it my maxim to increase my wealth by any safe means. Now I have a deposit in my hands, the owner of which has died and left no record of it. . . . I therefore apply the maxim to the present case and ask whether it could indeed take the form of a law, and consequently whether I could through my maxim at the same time give such a law as this: that everyone may deny a deposit which no one can prove has been made. I at once become aware that such a principle, as a law, would annihilate itself since it would bring it about that there would be no deposits at all.\n\nAlso, an action is said to have \"moral worth\" if the maxim upon which the agent acts cites the purpose of conforming to a moral requirement. That is, a person's action has moral worth when he does his duty purely for the sake of duty, or does the right thing for the right reason. Kant himself believed that it is impossible to know whether anyone's action has ever had moral worth. It might appear to someone that he has acted entirely \"from duty\", but this could always be an illusion of self-interest: of wanting to see oneself in the best, most noble light. This indicates that agents are not always the best judges of their own maxims or motives.\n\nMichael Polanyi in his account of tacit knowledge stressed the importance of the maxim in focusing both explicit and implicit modes of understanding. “Maxims are rules, the correct application of which is part of the art they govern...Maxims can only function within a framework of personal (i.e., experiential) knowledge”.\n\n\n"}
{"id": "2267869", "url": "https://en.wikipedia.org/wiki?curid=2267869", "title": "Multilineal evolution", "text": "Multilineal evolution\n\nMultilineal evolution is a 20th-century social theory about the evolution of societies and cultures. It is composed of many competing theories by various sociologists and anthropologists. This theory has replaced the older 19th century set of theories of unilineal evolution.\n\nWhen critique of classical social evolutionism became widely accepted, modern anthropological and sociological approaches have changed to reflect their responses to the critique of their predecessor. Modern theories are careful to avoid unsourced, ethnocentric speculation, comparisons, or value judgements; more or less regarding individual societies as existing within their own historical contexts. These conditions provided the context for new theories such as cultural relativism and multilineal evolution.\n\nBy the 1940s cultural anthropologists such as Leslie White and Julian Steward sought to revive an evolutionary model on a more scientific basis, and succeeded in establishing an approach known as the neoevolutionism. White rejected the opposition between \"primitive\" and \"modern\" societies but did argue that societies could be distinguished based on the amount of energy they harnessed, and that increased energy allowed for greater social differentiation. Steward on the other hand rejected the 19th century notion of progress, and instead called attention to the Darwinian notion of \"adaptation\", arguing that all societies had to adapt to their environment in some way.\n\nThe anthropologists Marshall Sahlins and Elman Service wrote a book, \"Evolution and Culture\", in which they attempted to synthesize White's and Steward's approaches. Other anthropologists, building on or responding to work by White and Steward, developed theories of cultural ecology and ecological anthropology. The most prominent examples are Peter Vayda and Roy Rappaport. By the late 1950s, students of Steward such as Eric Wolf and Sidney Mintz turned away from cultural ecology to Marxism, World Systems Theory, Dependency theory and Marvin Harris's cultural materialism.\n\nToday most anthropologists continue to reject 19th century notions of progress and the three original assumptions of unilineal evolution. Following Steward, they take seriously the relationship between a culture and its environment in attempts to explain different aspects of a culture. But most modern cultural anthropologists have adopted a general systems approach, examining cultures as emergent systems and argue that one must consider the whole social environment, which includes political and economic relations among cultures. There are still others who continue to reject the entirety of the evolutionary thinking and look instead at historical contingencies, contacts with other cultures, and the operation of cultural symbol systems. As a result, the simplistic notion of 'cultural evolution' has grown less useful and given way to an entire series of more nuanced approaches to the relationship of culture and environment. In the area of development studies, authors such as Amartya Sen have developed an understanding of 'development' and 'human flourishing' that also question more simplistic notions of progress, while retaining much of their original inspiration.\n\n"}
{"id": "39667721", "url": "https://en.wikipedia.org/wiki?curid=39667721", "title": "Naree", "text": "Naree\n\nNaree () is a 1992 Bangladeshi book about feminism and women’s rights written by Humayun Azad. The book was considered incendiary, and was banned on 19 November 1995, by the government of Bangladesh. Five years later, though, in 2000, the ban was lifted, following a legal battle that Azad won. The High Court of Bangladesh decided that the prohibition was invalid.\n\nThe book in Bengali is a feminist analysis of women's status and condition in civilizations created by men. This is the first comprehensive discussion in Bengali about feminism and the difficulties Bengali women face in daily life. The radicalism inherent in the work was enough for many to think back on \"The Second Sex\" written by French feminist Simone de Beauvoir and \"Sexual Politics\" by American feminist Kate Millett. In the work, Azad takes readers on a journey through the broad swathes of experience feminist writers in South Asia have gone through in their writings. Azad is critical of acclaimed figures, notably Rabindranath Tagore and Kazi Nazrul Islam, for what he considers their anti-feminist perceptions of life.\n\nAzad analytically compiles the feminist ideas of the west, which underlie the feminist contributions of the subcontinent's socio-political reformers.\n\n"}
{"id": "48860259", "url": "https://en.wikipedia.org/wiki?curid=48860259", "title": "Parallel individuation system", "text": "Parallel individuation system\n\nThe parallel individuation system, also called object tracking system is a non-symbolic cognitive system that supports the representation of numerical values from zero to three (in infants) or four (in adults and non-human animals). It is one of the two cognitive systems responsible for the representation of number, the other one being the approximate number system. Unlike the approximate number system, which is not precise and provides only an estimation of the number, the parallel individuation system is an exact system and encodes the exact numerical identity of the individual items. The parallel individuation system has been attested in human adults, non-human animals, such as fish and human infants, although performance of infants is dependent on their age and task.\n\nThe evidence for parallel individuation system comes from a number of experiments on adults, infants and non-human animals. For example, adults perform error-free when they enumerate elements for numerosities from one to four, after which their error rate rises. Similarly, infants of 10 to 12 months represented the values for \"exactly one\", \"exactly two\" and \"exactly three\", but not for higher numbers, in a task based on hidden object retrieval.\n\nParallel individuation system in animals was demonstrated in an experiment in which guppies were tested on their preference of social groups of different size, under the assumption that they have a preference for bigger size groups. In this experiment, fish successfully discriminated between numbers from 1 to 4 but after this number their performance decreased. However, not all studies find confirmation of this system and for example New Zealand robins showed no difference in their understanding of small (1 to 4) and larger (above 4) amounts.\n"}
{"id": "22495421", "url": "https://en.wikipedia.org/wiki?curid=22495421", "title": "Peer critique", "text": "Peer critique\n\nPeer critique, a specialized form of critique, is the common practice of writers reviewing and providing constructive criticism of each other's work. Most fiction writers use some form of peer critique as part of their process of writing.\n\nPeer critique has long been used as part of the process of teaching writing. In traditional classrooms power and authority can often be teacher-centric, with teachers correcting work to their own vision of ideal writing. Many researchers have found that peer critique offers a complementary style of feedback Whereas teachers' feedback often focuses on general comments and error correction, peers tend to give specific, deep comments on the work before them rather than correcting to an ideal.\n\nIn his groundbreaking 1973 book \"Writing without Teachers\", Peter Elbow stated a powerful argument for peer-only writing classes, eliminating the teacher from the process entirely. Many informal writing groups still use Elbow's methods for peer critique.\n\nPeer critique has also been found to be useful to those who provide critiques, helping students to develop analytical and critical thinking abilities and become better able to judge their own writing.\n\nHowever, it can also in today’s era be harmful to a students psyche, as these critiques can cause emotional distress on the one being critiqued. Many of today’s youths can take the critique in a negative manor which can cause them to self doubt or ultimately become depressed. It has been said that this method maybe outdated and harmful in our age of information.\n\nPeer writing groups have existed probably as long as writing has. Anne Ruggles Gere has written several useful articles and books about the history of writing groups, and how they have evolved over time from social \"clubs\" and chautauquas to the many types of groups we have today, including online peer critique sites.\n\nThe most traditional form of peer critique, both inside and outside the classroom, is face-to-face. In this method, writers gather together in person and discuss each other's work in detail. Face-to-face writing groups (also known as writing circles, writing groups, or workshops) can be a source of great support and encouragement for writers in what is sometimes a lonely endeavor. The greatest challenge for informal groups is keeping a face-to-face critique group together; many fall apart quickly due to lack of commitment, personality conflicts, or hurt feelings.\n\nIn recent years with the advent of the Blackboard Learning System and similar online teaching tools, it has become possible to take writing courses entirely online. In online courses students generally give each other feedback on writing in message-board style posts. Comments are usually brief. Teachers must beware of the \"pile-on effect\" of students merely echoing what teachers and previous commenters have mentioned; it will be useful for teachers to apply lessons from peer critique websites, which have functioned online for many years.\n\nSince at least 1985, with the Compuserve Books & Writer's Forum, writers have formed writing spaces online where they can discuss writing, share resources, and critique work. There are many active critique sites now, catering to all levels and genres of writers; the popular website Reddit has a sub-reddit dedicated to writing critique, titled critique my writing., while another popular forum, www.writingforums.com, is dedicated to writing and online critique. Other peer critique sites include Authonomy and Youwriteon.\n\nOnline peer critique sites tend to vary by:\n"}
{"id": "225192", "url": "https://en.wikipedia.org/wiki?curid=225192", "title": "Petri net", "text": "Petri net\n\nA Petri net, also known as a place/transition (PT) net, is one of several mathematical modeling languages for the description of distributed systems. It is a class of discrete event dynamic system. A Petri net is a directed bipartite graph, in which the nodes represent transitions (i.e. events that may occur, represented by bars) and places (i.e. conditions, represented by circles). The directed arcs describe which places are pre- and/or postconditions for which transitions (signified by arrows). Some sources state that Petri nets were invented in August 1939 by Carl Adam Petri—at the age of 13—for the purpose of describing chemical processes.\n\nLike industry standards such as UML activity diagrams, Business Process Model and Notation and EPCs, Petri nets offer a graphical notation for stepwise processes that include choice, iteration, and concurrent execution. Unlike these standards, Petri nets have an exact mathematical definition of their execution semantics, with a well-developed mathematical theory for process analysis.\n\nA Petri net consists of \"places\", \"transitions\", and \"arcs\". Arcs run from a place to a transition or vice versa, never between places or between transitions. The places from which an arc runs to a transition are called the \"input places\" of the transition; the places to which arcs run from a transition are called the \"output places\" of the transition.\n\nGraphically, places in a Petri net may contain a discrete number of marks called \"tokens\". Any distribution of tokens over the places will represent a configuration of the net called a \"marking\". In an abstract sense relating to a Petri net diagram, a transition of a Petri net may \"fire\" if it is \"enabled\", i.e. there are sufficient tokens in all of its input places; when the transition fires, it consumes the required input tokens, and creates tokens in its output places. A firing is atomic, i.e. a single non-interruptible step.\n\nUnless an \"execution policy\" is defined, the execution of Petri nets is nondeterministic: when multiple transitions are enabled at the same time, they will fire in any order.\n\nSince firing is nondeterministic, and multiple tokens may be present anywhere in the net (even in the same place), Petri nets are well suited for modeling the concurrent behavior of distributed systems.\n\nPetri nets are state-transition systems that extend a class of nets called elementary nets.\n\nDefinition 1. A \"net\" is a triple formula_1 where:\n\nDefinition 2. Given a net \"N\" = (\"P\", \"T\", \"F\"), a \"configuration\" is a set \"C\" so that \"C\" ⊆ \"P\".\nDefinition 3. An \"elementary net\" is a net of the form \"EN\" = (\"N\", \"C\") where:\n\nDefinition 4. A \"Petri net\" is a net of the form \"PN\" = (\"N\", \"M\", \"W\"), which extends the elementary net so that:\n\nIf a Petri net is equivalent to an elementary net, then \"Z\" can be the countable set {0,1} and those elements in \"P\" that map to 1 under \"M\" form a configuration. Similarly, if a Petri net is not an elementary net, then the multiset \"M\" can be interpreted as representing a non-singleton set of configurations. In this respect, \"M\" extends the concept of configuration for elementary nets to Petri nets.\n\nIn the diagram of a Petri net (see top figure right), places are conventionally depicted with circles, transitions with long narrow rectangles and arcs as one-way arrows that show connections of places to transitions or transitions to places. If the diagram were of an elementary net, then those places in a configuration would be conventionally depicted as circles, where each circle encompasses a single dot called a \"token\". In the given diagram of a Petri net (see right), the place circles may encompass more than one token to show the number of times a place appears in a configuration. The configuration of tokens distributed over an entire Petri net diagram is called a \"marking\".\n\nIn the top figure (see right), the place \"p\" is an input place of transition \"t\"; whereas, the place \"p\" is an output place to the same transition. Let \"PN\" (Fig. top) be a Petri net with a marking configured \"M\" and \"PN\" (Fig. bottom) be a Petri net with a marking configured \"M\". The configuration of \"PN\" \"enable\" transition \"t\" through the property that all input places have sufficient number of tokens (shown in the figures as dots) \"equal to or greater\" than the multiplicities on their respective arcs to \"t\". Once and only once a transition is enabled will the transition fire. In this example, the \"firing\" of transition \"t\" generates a map that has the marking configured \"M\" in the image of \"M\" and results in Petri net \"PN\", seen in the bottom figure. In the diagram, the firing rule for a transition can be characterised by subtracting a number of tokens from its input places equal to the multiplicity of the respective input arcs and accumulating a new number of tokens at the output places equal to the multiplicity of the respective output arcs.\n\nRemark 1. The precise meaning of \"equal to or greater\" will depend on the precise algebraic properties of addition being applied on \"Z\" in the firing rule, where subtle variations on the algebraic properties can lead to other classes of Petri nets; for example, Algebraic Petri nets.\n\nThe following formal definition is loosely based on . Many alternative definitions exist.\n\nA Petri net graph (called \"Petri net\" by some, but see below) is a 3-tuple formula_5, where\n\nThe \"flow relation\" is the set of arcs: formula_7. In many textbooks, arcs can only have multiplicity 1. These texts often define Petri nets using \"F\" instead of \"W\". When using this convention, a Petri net graph is a bipartite multigraph formula_8 with node partitions \"S\" and \"T\".\n\nThe \"preset\" of a transition \"t\" is the set of its \"input places\": formula_9;\nits \"postset\" is the set of its \"output places\": formula_10. Definitions of pre- and postsets of places are analogous.\n\nA \"marking\" of a Petri net (graph) is a multiset of its places, i.e., a mapping formula_11. We say the marking assigns to each place a number of \"tokens\".\n\nA Petri net (called \"marked Petri net\" by some, see above) is a 4-tuple formula_12, where\n\nIn words:\n\nWe are generally interested in what may happen when transitions may continually fire in arbitrary order.\n\nWe say that a marking \"is reachable from\" a marking \"in one step\" if formula_18; we say that it \"is reachable from \" if formula_19, where formula_20 is the reflexive transitive closure of formula_21; that is, if it is reachable in 0 or more steps.\n\nFor a (marked) Petri net formula_22, we are interested in the firings that can be performed starting with the initial marking formula_14. Its set of \"reachable markings\" is the set\nformula_24\n\nThe \"reachability graph\" of is the transition relation formula_21 restricted to its reachable markings formula_26. It is the state space of the net.\n\nA \"firing sequence\" for a Petri net with graph and initial marking formula_14 is a sequence of transitions formula_28 such that formula_29. The set of firing sequences is denoted as formula_30.\n\nAs already remarked, a common variation is to disallow arc multiplicities and replace the bag of arcs \"W\" with a simple set, called the \"flow relation\", formula_31.\nThis doesn't limit expressive power as both can represent each other.\n\nAnother common variation, e.g. in, Desel and Juhás (2001), is to allow \"capacities\" to be defined on places. This is discussed under \"extensions\" below.\n\nThe markings of a Petri net formula_12 can be regarded as vectors of nonnegative integers of length formula_33.\n\nIts transition relation can be described as a pair of formula_33 by formula_35 matrices:\nThen their difference\ncan be used to describe the reachable markings in terms of matrix multiplication, as follows.\nFor any sequence of transitions , write formula_41 for the vector that maps every transition to its number of occurrences in . Then, we have\n\nNote that it must be required that is a firing sequence; allowing arbitrary sequences of transitions will generally produce a larger set.\n\nOne thing that makes Petri nets interesting is that they provide a balance between modeling power and analyzability: many things one would like to know about concurrent systems can be automatically determined for Petri nets, although some of those things are very expensive to determine in the general case. Several subclasses of Petri nets have been studied that can still model interesting classes of concurrent systems, while these problems become easier.\n\nAn overview of such decision problems, with decidability and complexity results for Petri nets and some subclasses, can be found in\nEsparza and Nielsen (1995).\n\nThe reachability problem for Petri nets is to decide, given a Petri net \"N\" and a marking \"M\", whether formula_45.\n\nClearly, this is a matter of walking the reachability graph defined above, until either we reach the requested marking or we know it can no longer be found. This is harder than it may seem at first: the reachability graph is generally infinite, and it is not easy to determine when it is safe to stop.\n\nIn fact, this problem was shown to be EXPSPACE-hard years before it was shown to be decidable at all (Mayr, 1981). Papers continue to be published on how to do it efficiently. Recently (2018) Czerwinski et al improved the lower bound and showed that the problem is not ELEMENTARY.\n\nWhile reachability seems to be a good tool to find erroneous states, for practical problems the constructed graph usually has far too many states to calculate. To alleviate this problem, linear temporal logic is usually used in conjunction with the tableau method to prove that such states cannot be reached. LTL uses the semi-decision technique to find if indeed a state can be reached, by finding a set of necessary conditions for the state to be reached then proving that those conditions cannot be satisfied.\n\nPetri nets can be described as having different degrees of liveness formula_46. A Petri net formula_47 is called formula_48-live iff all of its transitions are formula_48-live, where a transition is\n\nNote that these are increasingly stringent requirements: formula_60-liveness implies formula_61-liveness, for formula_62.\n\nThese definitions are in accordance with Murata's overview, which additionally uses formula_63\"-live\" as a term for \"dead\".\n\nA place in a Petri net is called \"k-bounded\" if it does not contain more than \"k\" tokens in all reachable markings, including the initial marking; it is said to be \"safe\" if it is 1-bounded; it is \"bounded\" if it is \"k-bounded\" for some \"k\".\n\nA (marked) Petri net is called \"k\"-bounded, \"safe\", or \"bounded\" when all of its places are.\nA Petri net (graph) is called \"(structurally) bounded\" if it is bounded for every possible initial marking.\n\nNote that a Petri net is bounded if and only if its reachability graph is finite.\n\nBoundedness is decidable by looking at covering, by constructing the Karp–Miller Tree.\n\nIt can be useful to explicitly impose a bound on places in a given net.\nThis can be used to model limited system resources.\n\nSome definitions of Petri nets explicitly allow this as a syntactic feature.\nFormally, \"Petri nets with place capacities\" can be defined as tuples formula_64, where formula_12 is a Petri net, formula_66 an assignment of capacities to (some or all) places, and the transition relation is the usual one restricted to the markings in which each place with a capacity has at most that many tokens.\n\nFor example, if in the net \"N\", both places are assigned capacity 2, we obtain a Petri net with place capacities, say \"N2\"; its reachability graph is displayed on the right.\n\nAlternatively, places can be made bounded by extending the net. To be exact,\na place can be made \"k\"-bounded by adding a \"counter-place\" with flow opposite to that of the place, and adding tokens to make the total in both places \"k\".\n\nAs well as for discrete events, there are Petri nets for continuous and hybrid discrete-continuous processes that are useful in discrete, continuous and hybrid control theory, and related to discrete, continuous and hybrid automata.\n\nThere are many extensions to Petri nets. Some of them are completely backwards-compatible (e.g. coloured Petri nets) with the original Petri net, some add properties that cannot be modelled in the original Petri net formalism (e.g. timed Petri nets). Although backwards-compatible models do not extend the computational power of Petri nets, they may have more succinct representations and may be more convenient for modeling. Extensions that cannot be transformed into Petri nets are sometimes very powerful, but usually lack the full range of mathematical tools available to analyse ordinary Petri nets.\n\nThe term high-level Petri net is used for many Petri net formalisms that extend the basic P/T net formalism; this includes coloured Petri nets, hierarchical Petri nets such as Nets within Nets, and all other extensions sketched in this section. The term is also used specifically for the type of coloured nets supported by CPN Tools.\n\nA short list of possible extensions:\n\n\nThere are many more extensions to Petri nets, however, it is important to keep in mind, that as the complexity of the net increases in terms of extended properties, the harder it is to use standard tools to evaluate certain properties of the net. For this reason, it is a good idea to use the most simple net type possible for a given modelling task.\n\nInstead of extending the Petri net formalism, we can also look at restricting it, and look at particular types of Petri nets, obtained by restricting the syntax in a particular way. Ordinary Petri nets are the nets where all arc weights are 1. Restricting further, the following types of ordinary Petri nets are commonly used and studied:\n\nWorkflow nets (WF-nets) are a subclass of Petri nets intending to model the workflow of process activities. \nThe WF-net transitions are assigned to tasks or activities, and places are assigned to the pre/post conditions.\nThe WF-nets have additional structural and operational requirements, mainly the addition of a single input (source) place with no previous transitions, and output place (sink) with no following transitions. Accordingly, start and termination markings can be defined that represent the process status.\n\nWF-nets have the soundness property, indicating that a process with a start marking of k tokens in its source place, can reach the termination state marking with k tokens in its sink place (defined as K-sound WF-net). Additionally, all the transitions in the process could fire (i.e., for each transition there is a reachable state in which the transition is enabled). \nA general sound (G-sound) WF-net is defined as being K-sound for every k>0.\n\nA directed path in the Petri net is defined as the sequence of nodes (places and transitions) linked by the directed arcs. An elementary path includes every node in the sequence only once.\n\nA Well-handled Petri net is a net in which there are no fully distinct elementary paths between a place and a transition (or transition and a place), i.e., if there are two paths between the pair of node then these paths share a node.\nAn acyclic well-handled WF-net is sound (G-sound).\n\nExtended WF-net is a Petri net that is composed of a WF-net with additional transition t (feedback transition). The sink place is connected as the input place of transition t and the source place as its output place. Firing of the transition causes iteration of the process (Note: the extended WF-net is not a WF-net). \nWRI (Well-handled with Regular Iteration) WF-net, is an extended acyclic well-handled WF-net. \nWRI-WF-net can be built as composition of nets, i.e., replacing a transition within a WRI-WF-net with a subnet which is a WRI-WF-net. The result is also WRI-WF-net. WRI-WF-nets are G-sound, therefore by using only WRI-WF-net building blocks, one can get WF-nets that are G-sound by construction.\n\nThe Design structure matrix (DSM) can model process relations, and be utilized for process planning. The DSM-nets are realization of DSM-based plans into workflow processes by Petri nets, and are equivalent to WRI-WF-nets. The DSM-net construction process ensures the soundness property of the resulting net.\n\nOther ways of modelling concurrent computation have been proposed, including process algebra, the actor model, and trace theory. Different models provide tradeoffs of concepts such as compositionality, modularity, and locality.\n\nAn approach to relating some of these models of concurrency is proposed in the chapter by Winskel and Nielsen.\n\n\n\n\n"}
{"id": "56398", "url": "https://en.wikipedia.org/wiki?curid=56398", "title": "Phase diagram", "text": "Phase diagram\n\nA phase diagram in physical chemistry, engineering, mineralogy, and materials science is a type of chart used to show conditions (pressure, temperature, volume, etc.) at which thermodynamically distinct phases (such as solid, liquid or gaseous states) occur and coexist at equilibrium.\n\nCommon components of a phase diagram are \"lines of equilibrium\" or \"phase boundaries\", which refer to lines that mark conditions under which multiple phases can coexist at equilibrium. Phase transitions occur along lines of equilibrium.\n\nTriple points are points on phase diagrams where lines of equilibrium intersect. Triple points mark conditions at which three different phases can coexist. For example, the water phase diagram has a triple point corresponding to the single temperature and pressure at which solid, liquid, and gaseous water can coexist in a stable equilibrium ( and a partial vapor pressure of ).\n\nThe solidus is the temperature below which the substance is stable in the solid state. The liquidus is the temperature above which the substance is stable in a liquid state. There may be a gap between the solidus and liquidus; within the gap, the substance consists of a mixture of crystals and liquid (like a \"slurry\").\n\nWorking fluids are often categorized by on the basis of the shape of their phase diagram.\n\nThe simplest phase diagrams are pressure–temperature diagrams of a single simple substance, such as water. The axes correspond to the pressure and temperature. The phase diagram shows, in pressure–temperature space, the lines of equilibrium or phase boundaries between the three phases of solid, liquid, and gas.\n\nThe curves on the phase diagram show the points where the free energy (and other derived properties) becomes non-analytic: their derivatives with respect to the coordinates (temperature and pressure in this example) change discontinuously (abruptly). For example, the heat capacity of a container filled with ice will change abruptly as the container is heated past the melting point. The open spaces, where the free energy is analytic, correspond to single phase regions. Single phase regions are separated by lines of non-analytical behavior, where phase transitions occur, which are called phase boundaries.\n\nIn the diagram on the right, the phase boundary between liquid and gas does not continue indefinitely. Instead, it terminates at a point on the phase diagram called the critical point. This reflects the fact that, at extremely high temperatures and pressures, the liquid and gaseous phases become indistinguishable, in what is known as a supercritical fluid. In water, the critical point occurs at around \"T\" = , \"p\" = and \"ρ\" = 356 kg/m³.\n\nThe existence of the liquid–gas critical point reveals a slight ambiguity in labelling the single phase regions. When going from the liquid to the gaseous phase, one usually crosses the phase boundary, but it is possible to choose a path that never crosses the boundary by going to the right of the critical point. Thus, the liquid and gaseous phases can blend continuously into each other. The solid–liquid phase boundary can only end in a critical point if the solid and liquid phases have the same symmetry group.\n\nFor most substances, the solid–liquid phase boundary (or fusion curve) in the phase diagram has a positive slope so that the melting point increases with pressure. This is true whenever the solid phase is denser than the liquid phase. The greater the pressure on a given substance, the closer together the molecules of the substance are brought to each other, which increases the effect of the substance's intermolecular forces. Thus, the substance requires a higher temperature for its molecules to have enough energy to break out of the fixed pattern of the solid phase and enter the liquid phase. A similar concept applies to liquid–gas phase changes. \n\nWater is an exception which has a solid-liquid boundary with negative slope so that the melting point decreases with pressure. This occurs because ice (solid water) is less dense than liquid water, as shown by the fact that ice floats on water. At a molecular level, ice is less dense because it has a more extensive network of hydrogen bonding which requires a greater separation of water molecules. Other exceptions are antimony and bismuth.\n\nThe value of the slope dP/dT is given by the Clapeyron equation for fusion (melting)\nwhere ΔH is the heat of fusion which is always positive, and ΔV is the volume change for fusion. For most substances ΔV is positive so that the slope is positive. However for water and other exceptions, ΔV is negative so that the slope is negative.\n\nIn addition to temperature and pressure, other thermodynamic properties may be graphed in phase diagrams. Examples of such thermodynamic properties include specific volume, specific enthalpy, or specific entropy. For example, single-component graphs of temperature vs. specific entropy (\"T\" vs. \"s\") for water/steam or for a refrigerant are commonly used to illustrate thermodynamic cycles such as a Carnot cycle, Rankine cycle, or vapor-compression refrigeration cycle.\n\nIn a two-dimensional graph, two of the thermodynamic quantities may be shown on the horizontal and vertical axes. Additional thermodynamic quantities may each be illustrated in increments as a series of lines - curved, straight, or a combination of curved and straight. Each of these iso-lines represents the thermodynamic quantity at a certain constant value.\n\nIt is possible to envision three-dimensional (3D) graphs showing three thermodynamic quantities. For example, for a single component, a 3D Cartesian coordinate type graph can show temperature (\"T\") on one axis, pressure (\"p\") on a second axis, and specific volume (\"v\") on a third. Such a 3D graph is sometimes called a \"p\"–\"v\"–\"T\" diagram. The equilibrium conditions are shown as curves on a curved surface in 3D with areas for solid, liquid, and vapor phases and areas where solid and liquid, solid and vapor, or liquid and vapor coexist in equilibrium. A line on the surface called a triple line is where solid, liquid and vapor can all coexist in equilibrium. The critical point remains a point on the surface even on a 3D phase diagram.\n\nFor water, the 3D \"p\"–\"v\"–\"T\" diagram is seen here:\nAn orthographic projection of the 3D \"p\"–\"v\"–\"T\" graph showing pressure and temperature as the vertical and horizontal axes collapses the 3D plot into the standard 2D pressure–temperature diagram. When this is done, the solid–vapor, solid–liquid, and liquid–vapor surfaces collapse into three corresponding curved lines meeting at the triple point, which is the collapsed orthographic projection of the triple line.\n\nOther much more complex types of phase diagrams can be constructed, particularly when more than one pure component is present. In that case, concentration becomes an important variable. Phase diagrams with more than two dimensions can be constructed that show the effect of more than two variables on the phase of a substance. Phase diagrams can use other variables in addition to or in place of temperature, pressure and composition, for example the strength of an applied electrical or magnetic field, and they can also involve substances that take on more than just three states of matter.\n\nOne type of phase diagram plots temperature against the relative concentrations of two substances in a mixture called a \"binary phase diagram\", as shown at right. Such a mixture can be either a solid solution, eutectic or peritectic, among others. These two types of mixtures result in very different graphs. Another type of binary phase diagram is a \"boiling-point diagram\" for a mixture of two components, i. e. chemical compounds. For two particular volatile components at a certain pressure such as atmospheric pressure, a boiling-point diagram shows what vapor (gas) compositions are in equilibrium with given liquid compositions depending on temperature. In a typical binary boiling-point diagram, temperature is plotted on a vertical axis and mixture composition on a horizontal axis.\nA simple example diagram with hypothetical components 1 and 2 in a non-azeotropic mixture is shown at right. The fact that there are two separate curved lines joining the boiling points of the pure components means that the vapor composition is usually not the same as the liquid composition the vapor is in equilibrium with. See Vapor–liquid equilibrium for more information.\n\nIn addition to the above-mentioned types of phase diagrams, there are thousands of other possible combinations. Some of the major features of phase diagrams include congruent points, where a solid phase transforms directly into a liquid. There is also the peritectoid, a point where two solid phases combine into one solid phase during cooling. The inverse of this, when one solid phase transforms into two solid phases during cooling, is called the eutectoid.\n\nA complex phase diagram of great technological importance is that of the iron–carbon system for less than 7% carbon (see steel).\n\nThe x-axis of such a diagram represents the concentration variable of the mixture. As the mixtures are typically far from dilute and their density as a function of temperature is usually unknown, the preferred concentration measure is mole fraction. A volume-based measure like molarity would be inadvisable.\n\nPolymorphic and polyamorphic substances have multiple crystal or amorphous phases, which can be graphed in a similar fashion to solid, liquid, and gas phases.\n\nSome organic materials pass through intermediate states between solid and liquid; these states are called mesophases. Attention has been directed to mesophases because they enable display devices and have become commercially important through the so-called liquid-crystal technology. Phase diagrams are used to describe the occurrence of mesophases.\n\n\n"}
{"id": "23944162", "url": "https://en.wikipedia.org/wiki?curid=23944162", "title": "Press–Schechter formalism", "text": "Press–Schechter formalism\n\nThe Press–Schechter formalism is a mathematical model for predicting the number of objects (such as galaxies or galaxy clusters) of a certain mass within a given volume of the Universe. It was described in a famous paper by William H. Press and Paul Schechter in 1974.\n\nIn the context of cold dark matter cosmological models,\nperturbations on all scales are imprinted on the universe at very early times,\nfor example by quantum fluctuations during an inflationary era.\nLater, as radiation redshifts away, these become mass perturbations, and they\nstart to grow linearly. Only long after that, starting with small mass scales\nand advancing over time to larger mass scales, do the perturbations actually\ncollapse to form (for example) galaxies or clusters of galaxies, in so-called\nhierarchical structure formation (see Physical cosmology).\n\nPress and Schechter observed that the fraction of mass in collapsed objects\nmore massive than some mass M is related to the fraction of volume samples\nin which the smoothed initial density fluctuations are above some\ndensity threshold. This yields a formula for the mass function (distribution\nof masses) of objects at any given time.\n\nThe Press–Schechter formalism predicts that the number of objects with mass between formula_1 and formula_2 is:\n\nwhere formula_4 is the mean (baryonic and dark) matter density of the universe, formula_5 is the index of the power spectrum of the fluctuations in the early universe formula_6, and formula_7 is a critical mass above which structures will form.\n\nQualitatively, the prediction is that the mass distribution is a power law for\nsmall masses, with an exponential cutoff above some characteristic mass that\nincreases with time. Such functions had previously been noted by Schechter\nas observed luminosity functions,\nand are now known as Schechter luminosity functions. The Press-Schechter\nformalism provided the first quantitative model for how such functions might\narise.\n"}
{"id": "48897477", "url": "https://en.wikipedia.org/wiki?curid=48897477", "title": "Quotient of an abelian category", "text": "Quotient of an abelian category\n\nIn mathematics, the quotient (also called Serre quotient or Gabriel quotient) of an abelian category formula_1 by a Serre subcategory \"formula_2\" is the abelian category \"formula_3\" which, intuitively, is obtained from \"formula_1\" by ignoring (i.e. treating as zero) all objects from \"formula_2.\" There is a canonical exact functor formula_6 whose kernel is \"formula_2\".\n\nFormally, \"formula_3\" is the category whose objects are those of \"formula_1\" and whose morphisms from \"X\" to \"Y\" are given by the direct limit (of abelian groups) formula_10 over subobjects formula_11 and formula_12 such that formula_13 and formula_14. (Here, formula_15 and formula_16 denote quotient objects computed in \"formula_1\".) Composition of morphisms in \"formula_3\" is induced by the universal property of the direct limit. \n\nThe canonical functor formula_6 sends an object \"X\" to itself and a morphism formula_20 to the corresponding element of the direct limit with X'=X and Y'=0.\n\nLet formula_21 be a field and consider the abelian category formula_22 of all vector spaces over formula_21. Then the full subcategory formula_24of finite-dimensional vector spaces is a Serre-subcategory of formula_22. The quotient formula_26 has as objects the formula_21-vector spaces, and the set of morphisms from formula_28 to formula_29 in formula_30 is formula_31(which is a quotient of vector spaces). This has the effect of identifying all finite-dimensional vector spaces with 0, and of identifying two linear maps whenever their difference has finite-dimensional image.\n\nThe quotient \"formula_3\" is an abelian category, and the canonical functor formula_6 is exact. The kernel of formula_34 is \"formula_2\", i.e., formula_36is a zero object of \"formula_3\" if and only if formula_28 belongs to \"formula_2\". \n\nThe quotient and canonical functor are characterized by the following universal property: if \"formula_40\" is any abelian category and formula_41 is an exact functor such that formula_42 is a zero object of \"formula_40\" for each object formula_44, then there is a unique exact functor formula_45 such that formula_46.\n\nThe Gabriel–Popescu theorem states that any Grothendieck category formula_47 is equivalent to a quotient category formula_48, where formula_49denotes the abelian category of right modules over some unital ring formula_50, and formula_51 is some localizing subcategory of formula_49.\n"}
{"id": "147089", "url": "https://en.wikipedia.org/wiki?curid=147089", "title": "Red envelope", "text": "Red envelope\n\nIn Chinese and other East Asian and Southeast Asian societies, a red envelope, red packet, lì xì (Vietnamese), lai see (Cantonese), âng-pau (Hokkien) or hóngbāo (Mandarin) is a monetary gift which is given during holidays or special occasions such as weddings, graduation or the birth of a baby.\n\nOutside of China, similar customs have been adopted across parts of Southeast Asia and many other countries with a sizable ethnic Chinese population. \n\nIn China, the Chinese mobile app WeChat popularized the distribution of red envelopes in 2014 via mobile payments over the internet. This method of distributing red envelopes is now quite popular in the country.\n\nRed envelopes are gifts presented at social and family gatherings such as weddings or holidays such as Chinese New Year. The red color of the envelope symbolizes good luck and is a symbol to ward off evil spirits. The act of requesting red packets is normally called \"tao hongbao\" () or \"yao lishi\" (), and in the south of China, \"dou li shi\" (). Red envelopes are usually given out by married couples to single people, regardless of age, or by older to younger ones during holidays and festivals.\n\nThe amount of money contained in the envelope usually ends with an even digit, in accordance with Chinese beliefs; odd-numbered money gifts are traditionally associated with funerals. The exception being the number 9 as it pronunciation of \"nine\" is homophonus to the word \"long\" and is the largest digit. Still in some regions of China and in its diaspora community, odd numbers are favored for weddings because they are difficult to divide. There is also a widespread tradition that money should not be given in fours, or the number four should not appear in the amount, such as in 40, 400 and 444, as the pronunciation of the word \"four\" is homophonous to the word \"death\".\n\nAt wedding banquets, the amount offered is usually intended to cover the cost of the attendees as well as signify goodwill to the newlyweds. Amounts given are often recorded in ceremonial ledgers for the new couple to keep.\n\nDuring the Chinese New Year, in Southern China, red envelopes are typically given by the married to the unmarried, most of whom are children. In northern and southern China, red envelopes are typically given by the elders to the younger under 25 (30 in most of the three northeastern provinces), regardless of marital status, while in some regions red envelopes are only given to the young people without jobs. The amount of money is usually notes to avoid heavy coins and to make it difficult to judge the amount inside before opening. It is traditional to put brand new notes inside red envelopes and also to avoid opening the envelopes in front of the relatives out of courtesy.\n\nIt is also given during the Chinese New Year in workplace from a person of authority (supervisors or owner of the business) out of his own fund to employees as a token of good fortune for the upcoming year.\n\nIn acting, it is also conventional to give an actor a red packet when he or she is to play a dead character, or pose for a picture for an obituary or a grave stone. \n\nRed packets are also used to deliver payment for favorable service to lion dance performers, religious practitioners, teachers, and doctors.\n\nDuring the Chinese New Year holiday in 2014, the mobile instant messaging service WeChat introduced the ability to distribute virtual red envelopes of money to contacts and groups via its mobile payment platform. The feature became considerably popular, owing to its contemporary interpretation of the traditional practice, and a promotional giveaway held during the CCTV New Year's Gala, China's most-watched television special, where viewers could win red envelopes as prizes. Adoption of WeChat Pay saw a major increase following the launch, and two years later, over 32 billion virtual envelopes were sent over the Chinese New Year holiday in 600bc (itself a tenfold increase over 2015). The popularity spawned a \"red envelope war\" between WeChat owner Tencent and its historic rival, Alibaba Group, which added a similar function to its competing messaging service and has held similar giveaway promotions, and imitations of the feature from other vendors. Analysts estimated that over 100 billion digital red envelopes would be sent over the New Year holiday in 2017.\n\nIn China, during the Qin Dynasty, the elderly would thread coins with a red string. The money was referred to as \"money warding off evil spirits\" () and was believed to protect the person of younger generation from sickness and death. The \"yasui qian\" was replaced by red envelopes when printing presses became more common and is now found written using the homophone for \"\" that means \"old age\" instead of \"evil spirits\" thus, \"money warding off old age\" (). Red envelopes continue to be referred to by such names today.\n\nOther similar traditions also exist in other countries in Asia. In Thailand, Myanmar (Burma) and Cambodia, the Chinese diaspora and immigrants have introduced the culture of red envelopes.\n\nIn Cambodia, red envelopes are called Ang Pav or Tae Ea(give Ang Pav). Ang Pav is delivered with best wishes from elder to younger generations. The money amount in Ang Pav makes young children happy and is a most important gift which traditionally reflects the best wishes as a symbol of good luck for the elders. Ang Pav can be presented in the day of Chinese New Year or \"Saen Chen\", when relatives gather together. The gift is kept as a worship item in or under the pillowcase, or somewhere else, especially near the bed of young while they are sleeping in New Year time. Gift in Ang Pav can be either money or a cheque, and more or less according to the charity of the donors.\nThe tradition of the delivery of Ang Pav traditionally descended from one generation to another a long time ago. Ang Pav will not be given to some one in family who has got a career, but this person has to, in return, deliver it to their parents and/or their younger children or siblings.\nAt weddings, the amount offered is usually intended to cover the cost of the attendees as well as help the newly married couple.\n\nIn Vietnam, red envelopes are considered to be lucky money and are typically given to children. They are generally given by the elders and adults, where a greeting or offering health and longevity is exchanged by the younger generation. Common greetings include \"Sống lâu trăm tuổi\", \"An khang thịnh vượng\" (安康興旺), \"Vạn sự như ý\" (萬事如意) and Sức khỏe dồi dào, which all relate back to the idea of wishing health and prosperity as age besets everyone in Vietnam on the Lunar New Year. The typical name for lucky money is lì xì or, less commonly, mừng tuổi.\n\nIn South Korea and Japan, a monetary gift is given to children by their relatives during the New Year period. In both countries, however, white envelopes are used instead of red, with the name of the receiver written on the back. A similar practice, Shūgi-bukuro, is observed for Japanese weddings, but the envelope is folded rather than sealed, and decorated with an elaborate bow.\n\nIn the Philippines, Chinese Filipinos exchange red envelopes (termed \"ang pao\") during the Lunar New Year, which is an easily recognisable symbol. The red envelope has gained wider acceptance among non-Chinese Filipinos, who have appropriated the custom for other occasions such as birthdays, and in giving monetary \"aguinaldo\" during Christmas.\n\nRed packets as a form of bribery in China's film industry were revealed in 2014's Sony hack.\n\nMalay Muslims in Malaysia, Brunei, Indonesia, and Singapore have adopted the Chinese custom of handing out monetary gifts in envelopes as part of their Eid al-Fitr (Malay: \"Hari Raya Aidilfitri\") celebrations, but instead of red packets, green envelopes are used. Customarily a family will have (usually small) amounts of money in green envelopes ready for visitors, and may send them to friends and family unable to visit. Green is used for its traditional association with Islam, and the adaptation of the red envelope is based on the Muslim custom of \"sadaqah\", or voluntary charity. While present in the Qur'an, \"sadaqah\" is much less formally established than the sometimes similar practice of \"zakat\", and in many cultures this takes a form closer to gift-giving and generosity among friends than charity in the strict sense, i.e. no attempt is made to give more to guests \"in need\", nor is it as a religious obligation as Islamic charity is often viewed.\n\nThe tradition of \"ang pao\" has also been adopted by the local Indian Hindu populations of Singapore and Malaysia for Deepavali. They are known as \"Deepavali ang pow\" (in Malaysia), \"purple ang pow\" or simply \"ang pow\" (in Singapore). Yellow coloured envelopes for Deepavali have also been available at times in the past.\n\n\n\n"}
{"id": "17618723", "url": "https://en.wikipedia.org/wiki?curid=17618723", "title": "Renewable energy in developing countries", "text": "Renewable energy in developing countries\n\nRenewable energy technology has sometimes been seen as a costly luxury item by critics, and affordable only in the affluent developed world. This erroneous view has persisted for many years, but 2015 was the first year when investment in non-hydro renewables, was higher in developing countries, with $156 billion invested, mainly in China, India, and Brazil.\n\nMost developing countries have abundant renewable energy resources, including solar energy, wind power, geothermal energy, and biomass, as well as the ability to manufacture the relatively labor-intensive systems that harness these. By developing such energy sources developing countries can reduce their dependence on oil and natural gas, creating energy portfolios that are less vulnerable to price rises. In many circumstances, these investments can be less expensive than fossil fuel energy systems.\n\nIn isolated rural areas, electricity grid extensions are often not economical. Off‐grid renewable technologies provide a sustainable and cost‐effective alternative to the diesel generators that would be otherwise be deployed in such areas. Renewable technologies can also help to displace other unsustainable energy sources such as kerosene lamps and traditional biomass.\n\nKenya is the world leader in the number of solar power systems installed per capita (but not the number of watts added). More than 30,000 small solar panels, each producing 12 to 30 watts, are sold in Kenya annually. Kenya was the first African country to use geothermal power, and still has the largest installed capacity of geothermal power in Africa at 200 MW, with a potential of up to 10 GW.\n\nIn 2009, about 1.4 billion of people in the world lived without electricity, and 2.7 billion relied on wood, charcoal, and dung for home energy requirements. This lack of access to modern energy technology limits income generation, blunts efforts to escape poverty, affects people's health, and contributes to global deforestation and climate change. Small-scale renewable energy technologies and distributed energy options, such as onsite solar power and improved cookstoves, offer rural households\nmodern energy services.\n\nRenewable energy can be particularly suitable for developing countries. In rural and remote areas, transmission and distribution of energy generated from fossil fuels can be difficult and expensive. Producing renewable energy locally can offer a viable alternative.\n\nRenewable energy doesn't always have to come from a developing country. The Developing Areas Study Group session is a group of speakers from all over the energy businesses discusses the potential ideas to get developing countries the renewable energy that they need. Papers written by W. Morgan, R. Moss and P. Richard discuss the opportunities of renewable resources that lie within the developing country as well. Morgan and Richard claim firewood and agriculture could play a great role in an alternative energy solution in developing countries, while Richards claims that efficient use of agriculture could lead to renewable energy. Morgan also points out that green plants could play a great role in producing synthetic fuel alcohol, which would not only impact the developing country but the world as a whole in providing an alternative fuel source.\n\nInterest in renewable energies has increased in recent years due to environmental concern about global warming and air pollution, reduced costs of the technologies themselves, and improved efficiency and reliability. In recent years, supportive programs from governments, businesses, nonprofit organizations, and community cooperatives have expanded access to these off-grid technologies and the energy services they provide. Program planners should select “low-hanging fruit” first, aiming for maximum access to modern energy services with the least effort.\n\nCollectively, developing countries have more than half of global renewable power capacity. China and India are rapidly expanding markets for renewable energy. Brazil produces most of the world’s sugar-derived ethanol and has been adding new biomass and wind power plants. Many renewable markets are growing at rapid rates in countries such as Argentina, Costa Rica, Egypt, Indonesia, Kenya, Tanzania, Thailand, Tunisia, and Uruguay.\n\nIn isolated rural areas, electricity grid extensions are often not economical. Off‐grid renewable technologies provide a sustainable and cost‐effective alternative to the diesel generators that would be otherwise be deployed in such areas. Renewable technologies can also help to displace other unsustainable energy sources such as kerosene lamps and traditional biomass.\n\nTechnology advances are opening up a huge new market for solar power: the approximately 1.3 billion people around the world who don't have access to grid electricity. Even though they are typically very poor, these people have to pay far more for lighting than people in rich countries because they use inefficient kerosene lamps. Solar power costs half as much as lighting with kerosene. An estimated 3 million households get power from small solar PV systems. Kenya is the world leader in the number of solar power systems installed per capita. More than 30,000 very small solar panels, each producing 12 to 30 watts, are sold in Kenya annually.\n\nMicro-hydro systems configured into village-scale or county-scale mini-grids serve many areas. More than 30 million rural households get lighting and cooking from biogas made in household-scale systems. These stoves are being manufactured in factories and workshops worldwide, and more than 160 million households now use them.\n\nRenewable energy projects in many developing countries have demonstrated that renewable energy can directly contribute to poverty alleviation by providing the energy needed for creating businesses and employment. Renewable energy technologies can also make indirect contributions to alleviating poverty by providing energy for cooking, space heating, and lighting.\n\nRenewable energy can also contribute to education, by providing electricity to schools. Renewable energy for cooking and heating can reduce the time that children spend out of school collecting fuel.\n\n2.4 billion people use only traditional biomass, such as wood, residues and dung, for cooking and heating. The constant use of these types of energy sources exposes them to indoor particulate and carbon monoxide concentrations many times higher than World Health Organization (WHO) standards. \"Traditional stoves using dung and charcoal emit large amounts of carbon monoxide and other noxious gases. Women and children suffer most, because they are exposed for the longest periods of time. Acute respiratory illnesses affect as much as 6% of the world population. The WHO estimates that 2.5 million women and young children in developing countries die prematurely each year from breathing the fumes from indoor biomass stoves\".\nRenewable energy can improve this situation by reducing exposure to indoor pollutants.\n\nFurthermore, renewable can also provide energy to refrigerate medicine and sterilize medical equipment in rural areas where the access to electricity is difficult. It can also provide power to supply the fresh water and sewerage services needed to reduce the spread of infectious diseases.\n\nMore developing countries are implementing the public policies needed for the widespread development of renewable energy technologies and markets, which have traditionally been dominated by Europe, Japan, and North America. The exceptions include countries like Brazil, which has built the world’s leading biofuels industry, China, India, which are leaders in developing decentralized renewable sources such as small hydro, small wind, biogas, and solar water heating.\nHowever, policies like feed-in tariff are applied. Besides, with the Kyoto Protocol, the program called the Clean Development Mechanism (CDM) that allows for industrialized nations to invest in projects that reduce emissions in developing countries as an alternative to more expensive emission reductions in their own countries.\n\nDeveloping-country Governments need to steer resources mobilized for large-scale investments into new production sectors and new technologies. Some argue that policies should base on active industrial policies, combining large scale investments and active policy interventions. There is a need of subsidizing these type of energy services to make them affordable to the major part of the population.\n\n The Philippine government sees the growth of the renewable energy sector essential for national energy security. The Philippines' fossil fuel sector is unsustainable, being dependent on the import of nonrenewable fuel, including petroleum, but has significant potential in the renewable energy sector. Based on a report of an Australian consulting firm, International Energy Consultants, the Philippines has the highest electricity rate in Asia, followed by Japan. Transmitting power and transporting fuel throughout the Philippine archipelago is problematic due to very high cost.\n\nThe Philippines could be considered a world leader in renewable energy, with its 30 percent of its power generation being powered by the renewable energy sector. the Philippines is the world's second largest generator of geothermal energy and was the first Southeast Asian nation to invest in large-scale solar and wind technologies.\n\nPromotion and support of renewable energy in the country was intensified with the passing of the Renewable Energy Act of 2008 which made a feed-in-tariff and a renewable portfolio standard. The Philippines aims to triple renewable energy supply by 2030.\n\nRecently the government has concluded agreements with private developers for extensive projects in Oriental Mindoro with an eventual output of 48 MW, with plans for even larger development in the future.\n\nDespite government efforts, some investors have criticized the government's lack of firmness in its feed-in-tariff policy, and the solar industry accused the government for hampering its progress in the country.\n\nOn February 3, 2011, Algeria launched the National Development Programme for new and renewable energy and energy efficiency. The program, which spans the period from 2011 to 2013, aims to produce 22,000 MW of electricity from solar and wind power which 10,000 MW for export.\n\nIn Kenya, the Ministry of Energy and Petroleum is in charge of renewable energy policies. In March 2008, the country adopted the feed-in tariff policy. In January 2010, the policy was revised to urge private sectors to invest in electricity generation from renewable sources.\n\nKenya was the first African country to use geothermal power, and still has the largest installed capacity of geothermal power in Africa at 200 MW, with a potential of up to 10 GW. The only other country in Africa utilising geothermal power is Ethiopia.\n\nKenya is the world leader in the number of solar power systems installed per capita (but not the number of watts added). More than 30,000 small solar panels, each producing 12 to 30 watts, are sold in Kenya annually. For an investment of as little as $100 for the panel and wiring, the PV system can be used to charge a car battery, which can then provide power to run a fluorescent lamp or a small television for a few hours a day. More Kenyans are turning to solar power every year rather than making connections to the country’s electric grid. This is due to the high connectivity costs and the fact that there is an abundance of solar power in Kenya.\n\nRenewable energy accounted for more than 85.4% of the domestically produced electricity used in Brazil, according to preliminary data from the 2009 National Energy Balance, conducted by the Energy Research Corporation (EPE). After the oil shocks of the 1970s, Brazil started focusing on developing alternative sources of energy, mainly sugarcane ethanol. Its large sugarcane farms helped. In 1985, 91% of cars produced that year ran on sugarcane ethanol. The success of flexible-fuel vehicles, introduced in 2003, together with the mandatory E25 blend throughout the country, have allowed ethanol fuel consumption in the country to achieve a 50% market share of the gasoline-powered fleet by February 2008.\n\nRenewable Energy in Costa Rica accounts for over 90% of the total output of the nation's energy. The country is the world leader in renewable use with massive investment in windmill technologies. The government aim is to make the country the world's first carbon neutral country.\nIn March 2015 the whole country was running over 75 straight days on 100% renewable energy.\n\n"}
{"id": "290437", "url": "https://en.wikipedia.org/wiki?curid=290437", "title": "Righteousness", "text": "Righteousness\n\nRighteousness is defined as \"the quality of being morally correct and justifiable.\" It can also be considered synonymous with \"rightness\". It is a concept that can be found in Dharmic traditions and Abrahamic traditions as a theological concept. For example, from various perspectives in Hinduism, Christianity, and Judaism it is considered an attribute that implies that a person's actions are justified, and can have the connotation that the person has been \"judged\" or \"reckoned\" as leading a life that is pleasing to God.. It is also found in tamil literature in the name of அறம்(aram).Tamil Custom known for it's righteousness.In Tamil literature there is separate section called அற நூல்கள் righteous books for example thirukkural nalatiyar and many more books.tirukkural dedicated 1-38 chapters Book of aram for righteousness.A poem in purananuru written by kaniyanpoongundranar it showcases the practice of righteousness leads to worldpeace and harmony in society.\n\nWilliam Tyndale (Bible translator into English in 1526) remodelled the word after an earlier word \"rihtwis\", which would have yielded modern English *\"rightwise\" or *\"rightways\". He used it to translate the Hebrew root צדקים (\"TzDYQ\"), \"tzedek\", which appears over five hundred times in the Hebrew Bible, and the Greek word (\"dikaios\"), which appears more than two hundred times in the New Testament.\n\nIn the word \"righteousness,\" the suffix \"-ness\" modifies the adjective \"righteous,\" which is \"right\" modified by \"-ous.\" Righteousness is a phenomenon or state or condition of: resembling or displaying the nature of moral, good, correct, true, factual, excellent, just, virtuous, natural, morally upright, correct for situations, balanced, and honorable being or being in such a state. \n\nOrigin\nOld English rihtwīs, from riht ‘right’ + wīs ‘manner, state, condition’ (as opposed to \"wrangwise\", \"wrongful\"). The change in the ending in the 16th century was due to association with words such as bounteous.\n\nEthics is a major branch of philosophy, encompasses right conduct and good living.\n\" Rushworth Kidder states that \"standard definitions of ethics have typically included such phrases as 'the science of the ideal human character' or 'the science of moral duty'\".[3] Richard William Paul and Linda Elder define ethics as \"a set of concepts and principles that guide us in determining what behavior helps or harms sentient creatures\".[4] The Cambridge Dictionary of Philosophy states that the word ethics is \"commonly used interchangeably with 'morality' ... and sometimes it is used more narrowly to mean the moral principles of a particular tradition, group or individual.\"\n\nRighteousness is one of the chief Attributes of God as portrayed in the Hebrew Bible.\n\"Eusebeia\" enters the New Testament in later writings, where it is typically translated as \"godliness,\" a vague translation that reflects uncertainty about its relevant meaning in the New Testament. In mid 20th century, an inscription of the Indian Emperor Asoka from the year 258 BC was discovered. This rock inscription contained Sanskrit, Aramaic and Greek text. According to Paul Hacker,[34] on the rock appears a Greek rendering for the Sanskrit word dharma: the word eusebeia. In common parlance, dharma means ‘\"right\" way of living’, 'laws of nature' and ‘path of \"rightness\"’.\n\n\"The word εὐσέβεια as it is used in the Greek New Testament carries the meaning of \"godliness\", and is distinct from θρησκεία (thrēskeia), \"religion\". Eusebeia relates to real, true, vital, and spiritual relation with God, while thrēskeia relates to the outward acts of religious observances or ceremonies, which can be performed by the flesh. The English word \"religion\" was never used in the sense of true godliness. It always meant the outward forms of worship. In 1Ti 3:16, the Mystery, or secret connected with true Christianity as distinct from religion, it is the Genitive of relation. (This specific meaning occurs only in Act 3:12.)] This word arises in the Greek New Testament in 1 Tim 2:2, 1 Tim 3:16, 1 Tim 4:7, 1 Tim 4:8, 1 Tim 6:3, 1 Tim 6:5, 1 Tim 6:6, 1 Tim 6:11, 2 Tim 3:5, Tit 1:1, 2 Pt 1:3, 2 Pt 1:6, 2 Pt 1:7, 2 Pt 3:11.[7]\"\n\nYi, (Chinese: 義; simplified Chinese: 义; traditional Chinese: 義; pinyin: yì; Jyutping: Ji6; Zhuyin Fuhao: ㄧˋ), literally \"justice, righteousness; meaning,\" is an important concept in Confucianism. It involves a moral disposition to do good, and also the intuition and sensibility to do so competently. Yi resonates with Confucian philosophy's orientation towards the cultivation of benevolence (ren) and skillful practice (li). Yi represents moral acumen which goes beyond simple rule following, and involves a balanced understanding of a situation, and the \"creative insights\" necessary to apply virtues \"with no loss of sight of the total good. Yi represents this ideal of totality as well as a decision-generating ability to apply a virtue properly and appropriately in a situation.\" \n\nDharma is a key concept with multiple meanings. There might not be a single-word translation for dharma in Western languages. \"Dharma\" धर्म can be translated as righteousness, religion, faith, duty, law, and virtue. Connotations of dharma include rightness, good, natural, morality, righteousness, and virtue. It means moral, right, just, balanced, or natural etc. In common parlance, dharma means ‘\"right\" way of living’ and ‘path of \"rightness\"’. Dharma encompasses ideas such as duty, rights, character, vocation, religion, customs and all behaviour considered appropriate, correct or \"morally upright\". It is explained as law of righteousness and equated to satya (truth, Sanskrit: satya सत्यं). \"...when a man speaks the Truth, they say, \"He speaks the Dharma\"; and if he speaks Dharma, they say, \"He speaks the Truth!\" For both are one.\" — Brihadaranyaka Upanishad, 1.4.xiv\n\nBhagavad Gita Chapter 4: TEXT 7\n\n\"Whenever there is decay of righteousness, O Bharata, \nAnd there is exaltation of unrighteousness, then I Myself come forth\"\nWhenever and wherever there is a decline in righteousness/religious practice, Oh descendant of Bharata, and a rise of evil/irreligion— Then at that time I manifest Myself.\n\nIn Hindu philosophy and/or religion, major emphasis is placed on individual practical morality. In the Sanskrit epics, this concern is omnipresent.. Including duties, rights, laws, conduct, virtues and ‘‘right way of living’. The Sanskrit epics contain themes and examples where right prevails over wrong, the good over evil. \n\nIn mid 20th century, an inscription of the Indian Emperor Asoka from the year 258 BC was discovered. This rock inscription contained Sanskrit, Aramaic and Greek text. According to Paul Hacker, on the rock appears a Greek rendering for the Sanskrit word dharma: the word eusebeia. In his 250 BCE Edicts used the word \"eusebeia\" as a Greek translation for the central Buddhist and Hindu concept of \"dharma\". This rock inscription, concludes Paul Hacker,[34] suggests dharma in India, about 2300 years ago, was a central concept and meant not only religious ideas, but ideas of \"right,\" of \"good\", of one’s duty.\n\nFor Sikhs, the word Dharm means the path of \"righteousness\" and proper religious practice.\n\nThe major Jain text, Tattvartha Sutra mentions Das-dharma with the meaning of \"ten righteous virtues\".\nRighteousness is one of the chief attributes of God as portrayed in the Hebrew Bible. Its chief meaning concerns ethical conduct (for example, Leviticus 19:36; Deuteronomy 25:1; Psalm 1:6; Proverbs 8:20). In the Book of Job the title character is introduced to us as a person who is perfect in righteousness.\n\nThe New Testament continues the Hebrew Bible's tradition of the ethical () and legal () aspects of righteousness. William Lane Craig argues that we should think of God as the paradigm, the locus, the source of all righteousness. Matthew's gospel contains the most utterances of the word. In Matthew's account of the baptism encounter Jesus tells the prophet \"it is fitting for us to fulfill all righteousness\" as Jesus requests that John perform the rite for him. The Sermon of the Mount contains the memorable commandment \"Seek ye first the kingdom of God and His righteousness\". The Greek word \"dikaiosune\" also means justice and the sole translation using this rendering for is the New English Bible.\n\nJesus asserts the importance of righteousness by saying in Matthew 5:20, \"For I tell you that unless your righteousness surpasses that of the Pharisees and the teachers of the law, you will certainly not enter the kingdom of heaven.\" Jesus also re-affirms the Laws of Moses by saying in Matthew 5:19, \"Anyone who breaks one of the least of these commandments and teaches others to do the same will be called least in the kingdom of heaven, but whoever practices and teaches these commands will be called great in the kingdom of heaven.\"\n\nHowever, Paul the Apostle speaks of two ways, at least in theory, to achieve righteousness: through the Law of Moses (or Torah); and through faith in the atonement made possible through the death and resurrection of Jesus Christ (). Some interpret that he repeatedly emphasizes that faith is the only effective way. Reference (). (). For example, just a few verses earlier, he states the Jews did not attain the law of righteousness because they sought it not by faith, but by works (). The New Testament speaks of a salvation founded on God's righteousness, as exemplified throughout the history of salvation narrated in the Old Testament ().\nPaul writes to the Romans that righteousness comes by faith: \"...a righteousness that is by faith from first to last, just as it is written: 'The righteous will live by faith.'\" ()\n\nIn II Cor. 9:9 the New Revised Standard Version has a footnote that the original word has the meaning of 'benevolence' and the Messianic Jewish commentary of David Stern affirms the Jewish practice of 'doing \"tzedakah\"' as charity in referring to the Matt. 6 and II Cor. 9 passages. \n\nIn the Eastern Orthodox Church, \"Righteous\" is a type of saint who is regarded as a holy person under the Old Covenant (Old Testament Israel) but also sometimes used for married saints of the New Covenant (the Church). According to Orthodox theology, the Righteous saints of the Old Covenant were not able to enter into heaven until after the death of Jesus on the cross (), but had to await salvation in the Bosom of Abraham (see: Harrowing of Hell).\n\nRighteousness is mentioned several times in the Qur'an. The Qur'an says that a life of righteousness is the only way to go to Heaven.\n\n"}
{"id": "3775601", "url": "https://en.wikipedia.org/wiki?curid=3775601", "title": "Salva veritate", "text": "Salva veritate\n\nThe literal translation of the Latin \"salva veritate\" is \"with (or by) unharmed truth\", using ablative of manner: \"salva\" meaning \"rescue,\" \"salvation,\" or \"welfare,\" and \"veritate\" meaning \"reality\" or \"truth\". Thus, \"Salva veritate\" (or intersubstitutivity) is the logical condition by which two expressions may be interchanged without altering the truth-value of statements in which the expressions occur. Substitution \"salva veritate\" is not possible in opaque contexts.\n\nThe phrase occurs in two fragments from Gottfried Leibniz's \"General Science. Characteristics\":\n\n\nW.V.O. Quine takes substitutivity \"salva veritate\" to be the same as the \"indiscernibility of identicals\". Given a true statement, one of its two terms may be substituted for the other in any true statement and the result will be true. He continues to show that depending on context, the statement may change in value, In fact, the whole quantified modal logic of necessity is dependent on context and empty otherwise; for it collapses if essence is withdrawn.\n\nFor example, the statements:\n\nare true; however, replacement of the name 'Giorgione' by the name 'Barbarelli' turns (2) into the falsehood:\n\nQuine's example here refers to Giorgio Barbarelli's sobriquet \"Giorgione\", an Italian name roughly glossed as \"Big George.\"\n\n\n\n"}
{"id": "60426", "url": "https://en.wikipedia.org/wiki?curid=60426", "title": "Symbiogenesis", "text": "Symbiogenesis\n\nSymbiogenesis, or endosymbiotic theory, is an evolutionary theory of the origin of eukaryotic cells from prokaryotic organisms, first articulated in 1905 and 1910 by the Russian botanist Konstantin Mereschkowski, and advanced and substantiated with microbiological evidence by Lynn Margulis in 1967. It holds that the organelles distinguishing eukaryote cells evolved through symbiosis of individual single-celled prokaryotes (bacteria and archaea).\n\nThe theory holds that mitochondria, plastids such as chloroplasts, and possibly other organelles of eukaryotic cells represent formerly free-living prokaryotes taken one inside the other in endosymbiosis. In more detail, mitochondria appear to be related to Rickettsiales proteobacteria, and chloroplasts to nitrogen-fixing filamentous cyanobacteria.\n\nAmong the many lines of evidence supporting symbiogenesis are that new mitochondria and plastids are formed only through binary fission, and that cells cannot create new ones otherwise; that the transport proteins called porins are found in the outer membranes of mitochondria, chloroplasts and bacterial cell membranes; that cardiolipin is found only in the inner mitochondrial membrane and bacterial cell membranes; and that some mitochondria and plastids contain single circular DNA molecules similar to the chromosomes of bacteria.\n\nThe theory of symbiogenesis (from Greek: σύν \"syn\" \"together\", βίος \"bios\" \"life\", and γένεσις \"genesis\" \"origin, birth\") was first outlined by the Russian botanist Konstantin Mereschkowski in his 1905 work, \"The nature and origins of chromatophores in the plant kingdom\", and then elaborated in his 1910 \"The Theory of Two Plasms as the Basis of Symbiogenesis, a New Study of the Origins of Organisms\". Mereschkowski was familiar with work by botanist Andreas Schimper, who had observed in 1883 that the division of chloroplasts in green plants closely resembled that of free-living cyanobacteria, and who had himself tentatively proposed (in a footnote) that green plants had arisen from a symbiotic union of two organisms. In 1918 the French scientist published \"Les Symbiotes\" in which he claimed that the mitochondria originated from a symbiosis process. Ivan Wallin advocated the idea of an endosymbiotic origin of mitochondria in the 1920s.\n\nThe Russian botanist Boris Kozo-Polyansky was the first to explain the theory in terms of Darwinian evolution. In his 1924 book \"Novyi printzip biologii. Ocherk teorii simbiogeneza\" (\"The new principle of biology. Essay on the theory of symbiogenesis\"; translated to English as \"Symbiogenesis: A New Principle of Evolution\" in 2010), he wrote, \"The theory of symbiogenesis is a theory of selection relying on the phenomenon of symbiosis.\" These theories were initially dismissed or ignored. More detailed electron microscopic comparisons between cyanobacteria and chloroplasts (for example studies by Hans Ris published in 1961 and 1962), combined with the discovery that plastids and mitochondria contain their own DNA (which by that stage was recognized to be the hereditary material of organisms) led to a resurrection of the idea in the 1960s.\n\nThe theory was advanced and substantiated with microbiological evidence by Lynn Margulis in a 1967 paper, \"On the origin of mitosing cells.\" In her 1981 work \"Symbiosis in Cell Evolution\" she argued that eukaryotic cells originated as communities of interacting entities, including endosymbiotic spirochaetes that developed into eukaryotic flagella and cilia. This last idea has not received much acceptance, because flagella lack DNA and do not show ultrastructural similarities to bacteria or archaea (see also: Evolution of flagella and Prokaryotic cytoskeleton). According to Margulis and Dorion Sagan, \"Life did not take over the globe by combat, but by networking\" (i.e., by cooperation). The possibility that peroxisomes may have an endosymbiotic origin has also been considered, although they lack DNA. Christian de Duve proposed that they may have been the first endosymbionts, allowing cells to withstand growing amounts of free molecular oxygen in the Earth's atmosphere. However, it now appears that peroxisomes may be formed \"de novo\", contradicting the idea that they have a symbiotic origin.\n\nAccording to Keeling and Archibald, the usual way to distinguish organelles from endosymbionts is by their reduced genome sizes. As an endosymbiont evolves into an organelle, most of their genes are transferred to the host cell genome. The host cell and organelle need to develop a transport mechanism that enables the return of the protein products needed by the organelle but now manufactured by the cell. Cyanobacteria and α-proteobacteria are the most closely related free-living organisms to plastids and mitochondria respectively. Both cyanobacteria and α-proteobacteria maintain a large (>6Mb) genome encoding thousands of proteins. Plastids and mitochondria exhibit a dramatic reduction in genome size when compared to their bacterial relatives. Chloroplast genomes in photosynthetic organisms are normally 120-200kb encoding 20-200 proteins and mitochondrial genomes in humans are approximately 16kb and encode 37 genes, 13 of which are proteins. Using the example of the freshwater amoeboid, however, \"Paulinella chromatophora\", which contains chromatophores found to be evolved from cyanobacteria, Keeling and Archibald argue that this is not the only possible criterion; another is that the host cell has assumed control of the regulation of the former endosymbiont's division, thereby synchronizing it with the cell's own division. Nowack and her colleagues performed gene sequencing on the chromatophore (1.02 Mb) and found that only 867 proteins were encoded by these photosynthetic cells. Comparisons with their closest free living cyanobacteria of the genus \"Synechococcus\" (having a genome size 3 Mb, with 3300 genes) revealed that chromatophores underwent a drastic genome shrinkage. Chromatophores contained genes that were accountable for photosynthesis but were deficient in genes that could carry out other biosynthetic functions; this observation suggests that these endosymbiotic cells are highly dependent on their hosts for their survival and growth mechanisms. Thus, these chromatophores were found to be non-functional for organelle-specific purposes when compared to mitochondria and plastids. This distinction could have promoted the early evolution of photosynthetic organelles.\n\nThe loss of genetic autonomy, that is, the loss of many genes from endosymbionts, occurred very early in evolutionary time. Taking into account the entire original endosymbiont genome, there are three main possible fates for genes over evolutionary time. The first fate involves the loss of functionally redundant genes, in which genes that are already represented in the nucleus are eventually lost. The second fate involves the transfer of genes to the nucleus. The loss of autonomy and integration of the endosymbiont with its host can be primarily attributed to nuclear gene transfer. As organelle genomes have been greatly reduced over evolutionary time, nuclear genes have expanded and become more complex. As a result, many plastid and mitochondrial processes are driven by nuclear encoded gene products. In addition, many nuclear genes originating from endosymbionts have acquired novel functions unrelated to their organelles.\n\nThe mechanisms of gene transfer are not fully known; however, multiple hypotheses exist to explain this phenomenon. The cDNA hypothesis involves the use of messenger RNA (mRNAs) to transport genes from organelles to the nucleus where they are converted to cDNA and incorporated into the genome. The cDNA hypothesis is based on studies of the genomes of flowering plants. Protein coding RNAs in mitochondria are spliced and edited using organelle-specific splice and editing sites. Nuclear copies of some mitochondrial genes, however, do not contain organelle-specific splice sites, suggesting a processed mRNA intermediate. The cDNA hypothesis has since been revised as edited mitochondrial cDNAs are unlikely to recombine with the nuclear genome and are more likely to recombine with their native mitochondrial genome. If the edited mitochondrial sequence recombines with the mitochondrial genome, mitochondrial splice sites would no longer exist in the mitochondrial genome. Any subsequent nuclear gene transfer would therefore also lack mitochondrial splice sites.\n\nThe bulk flow hypothesis is the alternative to the cDNA hypothesis, stating that escaped DNA, rather than mRNA, is the mechanism of gene transfer. According to this hypothesis, disturbances to organelles, including autophagy (normal cell destruction), gametogenesis (the formation of gametes), and cell stress, release DNA which is imported into the nucleus and incorporated into the nuclear DNA using non-homologous end joining (repair of double stranded breaks). For example, in the initial stages of endosymbiosis, due to a lack of major gene transfer, the host cell had little to no control over the endosymbiont. The endosymbiont underwent cell division independently of the host cell, resulting in many \"copies\" of the endosymbiont within the host cell. Some of the endosymbionts lysed (burst), and high levels of DNA were incorporated into the nucleus. A similar mechanism is thought to occur in tobacco plants, which show a high rate of gene transfer and whose cells contain multiple chloroplasts. In addition, the bulk flow hypothesis is also supported by the presence of non-random clusters of organelle genes, suggesting the simultaneous movement of multiple genes.\nIn 2015, the biologist Roberto Cazzolla Gatti provided evidence for a variant theory, endogenosymbiosis, in which not only are organelles endosymbiotic, but that pieces of genetic material from symbiotic parasites (\"gene carriers\" such as viruses, retroviruses and bacteriophages), are included in the host's nuclear DNA, changing the host's gene expression and contributing to the process of speciation.\n\nMolecular and biochemical evidence suggests that mitochondria are related to Rickettsiales proteobacteria (in particular, the SAR11 clade, or close relatives), and that chloroplasts are related to nitrogen-fixing filamentous cyanobacteria.\n\nThe third and final possible fate of endosymbiont genes is that they remain in the organelles. Plastids and mitochondria, although they have lost much of their genomes, retain genes encoding rRNAs, tRNAs, proteins involved in redox reactions, and proteins required for transcription, translation, and replication. There are many hypotheses to explain why organelles retain a small portion of their genome; however no one hypothesis will apply to all organisms and the topic is still quite controversial. The hydrophobicity hypothesis states that highly hydrophobic (water hating) proteins (such as the membrane bound proteins involved in redox reactions) are not easily transported through the cytosol and therefore these proteins must be encoded in their respective organelles. The code disparity hypothesis states that the limit on transfer is due to differing genetic codes and RNA editing between the organelle and the nucleus. The redox control hypothesis states that genes encoding redox reaction proteins are retained in order to effectively couple the need for repair and the synthesis of these proteins. For example, if one of the photosystems is lost from the plastid, the intermediate electron carriers may lose or gain too many electrons, signalling the need for repair of a photosystem. The time delay involved in signalling the nucleus and transporting a cytosolic protein to the organelle results in the production of damaging reactive oxygen species. The final hypothesis states that the assembly of membrane proteins, particularly those involved in redox reactions, requires coordinated synthesis and assembly of subunits; however, translation and protein transport coordination is more difficult to control in the cytoplasm.\n\nThe majority of the genes in the mitochondria and plastids are related to the expression (transcription, translation and replication) of genes encoding proteins involved in either photosynthesis (in plastids) or cellular respiration (in mitochondria). One might predict that the loss of photosynthesis or cellular respiration would allow for the complete loss of the plastid genome or the mitochondrial genome respectively. While there are numerous examples of mitochondrial descendants (mitosomes and hydrogenosomes) that have lost their entire organellar genome, non-photosynthetic plastids tend to retain a small genome. There are two main hypotheses to explain this occurrence:\n\nThe essential tRNA hypothesis notes that there have been no documented functional plastid-to-nucleus gene transfers of genes encoding RNA products (tRNAs and rRNAs). As a result, plastids must make their own functional RNAs or import nuclear counterparts. The genes encoding tRNA-Glu and tRNA-fmet, however, appear to be indispensable. The plastid is responsible for haem biosynthesis, which requires plastid encoded tRNA-Glu (from the gene trnE) as a precursor molecule. Like other genes encoding RNAs, trnE cannot be transferred to the nucleus. In addition, it is unlikely trnE could be replaced by a cytosolic tRNA-Glu as trnE is highly conserved; single base changes in trnE have resulted in the loss of haem synthesis. The gene for tRNA-formylmethionine (tRNA-fmet) is also encoded in the plastid genome and is required for translation initiation in both plastids and mitochondria. A plastid is required to continue expressing the gene for tRNA-fmet so long as the mitochondrion is translating proteins.\n\nThe limited window hypothesis offers a more general explanation for the retention of genes in non-photosynthetic plastids. According to the bulk flow hypothesis, genes are transferred to the nucleus following the disturbance of organelles. Disturbance was common in the early stages of endosymbiosis, however, once the host cell gained control of organelle division, eukaryotes could evolve to have only one plastid per cell. Having only one plastid severely limits gene transfer as the lysis of the single plastid would likely result in cell death. Consistent with this hypothesis, organisms with multiple plastids show an 80-fold increase in plastid-to-nucleus gene transfer compared to organisms with single plastids.\n\nThere are many lines of evidence that mitochondria and plastids including chloroplasts arose from bacteria.\n\nPrimary endosymbiosis involves the engulfment of a cell by another free living organism. Secondary endosymbiosis occurs when the product of primary endosymbiosis is itself engulfed and retained by another free living eukaryote. Secondary endosymbiosis has occurred several times and has given rise to extremely diverse groups of algae and other eukaryotes. Some organisms can take opportunistic advantage of a similar process, where they engulf an alga and use the products of its photosynthesis, but once the prey item dies (or is lost) the host returns to a free living state. Obligate secondary endosymbionts become dependent on their organelles and are unable to survive in their absence (for a review see McFadden 2001). RedToL, the Red Algal Tree of Life Initiative funded by the National Science Foundation highlights the role red algae or Rhodophyta played in the evolution of our planet through secondary endosymbiosis.\n\nOne possible secondary endosymbiosis in process has been observed by Okamoto & Inouye (2005). The heterotrophic protist \"Hatena\" behaves like a predator until it ingests a green alga, which loses its flagella and cytoskeleton, while \"Hatena\", now a host, switches to photosynthetic nutrition, gains the ability to move towards light and loses its feeding apparatus.\n\nThe process of secondary endosymbiosis left its evolutionary signature within the unique topography of plastid membranes. Secondary plastids are surrounded by three (in euglenophytes and some dinoflagellates) or four membranes (in haptophytes, heterokonts, cryptophytes, and chlorarachniophytes). The two additional membranes are thought to correspond to the plasma membrane of the engulfed alga and the phagosomal membrane of the host cell. The endosymbiotic acquisition of a eukaryote cell is represented in the cryptophytes; where the remnant nucleus of the red algal symbiont (the nucleomorph) is present between the two inner and two outer plastid membranes.\n\nDespite the diversity of organisms containing plastids, the morphology, biochemistry, genomic organisation, and molecular phylogeny of plastid RNAs and proteins suggest a single origin of all extant plastids – although this theory is still debated.\n\nSome species including \"Pediculus humanus\" (lice) have multiple chromosomes in the mitochondrion. This and the phylogenetics of the genes encoded within the mitochondrion suggest that mitochondria have multiple ancestors, that these were acquired by endosymbiosis on several occasions rather than just once, and that there have been extensive mergers and rearrangements of genes on the several original mitochondrial chromosomes.\n\nThe question of when the transition from prokaryotic to eukaryotic form occurred and when the first crown-group eukaryotes appeared on earth is still unresolved. The oldest known body fossils that can be positively assigned to the Eukaryota are acanthomorphic acritarchs from the 1631±1 Ma Deonar Formation of India (lower Vindhyan Supergroup) of India. These fossils can still be identiﬁed as derived post-nuclear eukaryotes with a sophisticated, morphology-generating cytoskeleton sustained by mitochondria. This fossil evidence indicates that endosymbiotic acquisition of alphaproteobacteria must have occurred before 1.6 Ga. Molecular clocks have also been used to estimate the last eukaryotic common ancestor (LECA, however these methods have large inherent uncertainty and give a wide range of dates. Reasonable results for LECA include the estimate of c. 1800 Mya. A 2300 Mya estimate also seems reasonable and has the added attraction of coinciding with one of the most pronounced biogeochemical perturbations in Earth history (the Great Oxygenation Event). The marked increase in atmospheric oxygen concentrations during the early Palaeoproterozoic Great Oxidation Event has been invoked as a contributing cause of eukaryogenesis – by inducing the evolution of oxygen-detoxifying mitochondria. Alternatively, the Great Oxidation Event might be a consequence of eukaryogenesis and its impact on the export and burial of organic carbon.\n\n\n\n"}
{"id": "18442482", "url": "https://en.wikipedia.org/wiki?curid=18442482", "title": "Symmetric inverse semigroup", "text": "Symmetric inverse semigroup\n\nIn abstract algebra, the set of all partial bijections on a set \"X\" ( one-to-one partial transformations) forms an inverse semigroup, called the symmetric inverse semigroup (actually a monoid) on \"X\". The conventional notation for the symmetric inverse semigroup on a set \"X\" is formula_1 or formula_2 In general formula_1 is not commutative.\n\nDetails about the origin of the symmetric inverse semigroup are available in the discussion on the origins of the inverse semigroup.\n\nWhen \"X\" is a finite set {1, ..., \"n\"}, the inverse semigroup of one-one partial transformations is denoted by \"C\" and its elements are called charts or partial symmetries. The notion of chart generalizes the notion of permutation. A (famous) example of (sets of) charts are the hypomorphic mapping sets from the reconstruction conjecture in graph theory.\n\nThe cycle notation of classical, group-based permutations generalizes to symmetric inverse semigroups by the addition of a notion called a \"path\", which (unlike a cycle) ends when it reaches the \"undefined\" element; the notation thus extended is called \"path notation\".\n\n\n"}
{"id": "50821960", "url": "https://en.wikipedia.org/wiki?curid=50821960", "title": "Unicity (philosophy)", "text": "Unicity (philosophy)\n\nThe principle of unicity explains that each event, each living being, each object, each person or each circumstance has the characteristic of its uniqueness, of its particularity. Other similar events, living beings, objects, persons or circumstances may exist, but never the same entity.\n"}
{"id": "3772116", "url": "https://en.wikipedia.org/wiki?curid=3772116", "title": "Vector-valued differential form", "text": "Vector-valued differential form\n\nIn mathematics, a vector-valued differential form on a manifold \"M\" is a differential form on \"M\" with values in a vector space \"V\". More generally, it is a differential form with values in some vector bundle \"E\" over \"M\". Ordinary differential forms can be viewed as R-valued differential forms.\n\nAn important case of vector-valued differential forms are Lie algebra-valued forms. (A connection form is an example of such a form.)\n\nLet \"M\" be a smooth manifold and \"E\" → \"M\" be a smooth vector bundle over \"M\". We denote the space of smooth sections of a bundle \"E\" by Γ(\"E\"). An \"E\"-valued differential form of degree \"p\" is a smooth section of the tensor product bundle of \"E\" with Λ(\"T\"\"M\"), the \"p\"-th exterior power of the cotangent bundle of \"M\". The space of such forms is denoted by\nBecause Γ is a strong monoidal functor, this can also be interpreted as\nwhere the latter two tensor products are the tensor product of modules over the ring Ω(\"M\") of smooth R-valued functions on \"M\" (see the seventh example here). By convention, an \"E\"-valued 0-form is just a section of the bundle \"E\". That is,\nEquivalently, an \"E\"-valued differential form can be defined as a bundle morphism\nwhich is totally skew-symmetric.\n\nLet \"V\" be a fixed vector space. A \"V\"-valued differential form of degree \"p\" is a differential form of degree \"p\" with values in the trivial bundle \"M\" × \"V\". The space of such forms is denoted Ω(\"M\", \"V\"). When \"V\" = R one recovers the definition of an ordinary differential form. If \"V\" is finite-dimensional, then one can show that the natural homomorphism\nwhere the first tensor product is of vector spaces over R, is an isomorphism.\n\nOne can define the pullback of vector-valued forms by smooth maps just as for ordinary forms. The pullback of an \"E\"-valued form on \"N\" by a smooth map φ : \"M\" → \"N\" is an (φ*\"E\")-valued form on \"M\", where φ*\"E\" is the pullback bundle of \"E\" by φ.\n\nThe formula is given just as in the ordinary case. For any \"E\"-valued \"p\"-form ω on \"N\" the pullback φ*ω is given by\n\nJust as for ordinary differential forms, one can define a wedge product of vector-valued forms. The wedge product of an \"E\"-valued \"p\"-form with an \"E\"-valued \"q\"-form is naturally an (\"E\"⊗\"E\")-valued (\"p\"+\"q\")-form:\nThe definition is just as for ordinary forms with the exception that real multiplication is replaced with the tensor product:\nIn particular, the wedge product of an ordinary (R-valued) \"p\"-form with an \"E\"-valued \"q\"-form is naturally an \"E\"-valued (\"p\"+\"q\")-form (since the tensor product of \"E\" with the trivial bundle \"M\" × R is naturally isomorphic to \"E\"). For ω ∈ Ω(\"M\") and η ∈ Ω(\"M\", \"E\") one has the usual commutativity relation:\n\nIn general, the wedge product of two \"E\"-valued forms is \"not\" another \"E\"-valued form, but rather an (\"E\"⊗\"E\")-valued form. However, if \"E\" is an algebra bundle (i.e. a bundle of algebras rather than just vector spaces) one can compose with multiplication in \"E\" to obtain an \"E\"-valued form. If \"E\" is a bundle of commutative, associative algebras then, with this modified wedge product, the set of all \"E\"-valued differential forms\nbecomes a graded-commutative associative algebra. If the fibers of \"E\" are not commutative then Ω(\"M\",\"E\") will not be graded-commutative.\n\nFor any vector space \"V\" there is a natural exterior derivative on the space of \"V\"-valued forms. This is just the ordinary exterior derivative acting component-wise relative to any basis of \"V\". Explicitly, if {\"e\"} is a basis for \"V\" then the differential of a \"V\"-valued \"p\"-form ω = ω\"e\" is given by\nThe exterior derivative on \"V\"-valued forms is completely characterized by the usual relations:\nMore generally, the above remarks apply to \"E\"-valued forms where \"E\" is any flat vector bundle over \"M\" (i.e. a vector bundle whose transition functions are constant). The exterior derivative is defined as above on any local trivialization of \"E\".\n\nIf \"E\" is not flat then there is no natural notion of an exterior derivative acting on \"E\"-valued forms. What is needed is a choice of connection on \"E\". A connection on \"E\" is a linear differential operator taking sections of \"E\" to \"E\"-valued one forms:\nIf \"E\" is equipped with a connection ∇ then there is a unique covariant exterior derivative\nextending ∇. The covariant exterior derivative is characterized by linearity and the equation\nwhere ω is a \"E\"-valued \"p\"-form and η is an ordinary \"q\"-form. In general, one need not have \"d\" = 0. In fact, this happens if and only if the connection ∇ is flat (i.e. has vanishing curvature).\n\nLet \"E\" → \"M\" be a smooth vector bundle of rank \"k\" over \"M\" and let \"π\" : F(\"E\") → \"M\" be the (associated) frame bundle of \"E\", which is a principal GL(R) bundle over \"M\". The pullback of \"E\" by \"π\" is canonically isomorphic to F(\"E\") × R via the inverse of [\"u\", \"v\"] →\"u\"(\"v\"), where ρ is the standard representation. Therefore, the pullback by \"π\" of an \"E\"-valued form on \"M\" determines an R-valued form on F(\"E\"). It is not hard to check that this pulled back form is right-equivariant with respect to the natural action of GL(R) on F(\"E\") × R and vanishes on vertical vectors (tangent vectors to F(\"E\") which lie in the kernel of d\"π\"). Such vector-valued forms on F(\"E\") are important enough to warrant special terminology: they are called \"basic\" or \"tensorial forms\" on F(\"E\").\n\nLet \"π\" : \"P\" → \"M\" be a (smooth) principal \"G\"-bundle and let \"V\" be a fixed vector space together with a representation \"ρ\" : \"G\" → GL(\"V\"). A basic or tensorial form on \"P\" of type ρ is a \"V\"-valued form ω on \"P\" which is equivariant and horizontal in the sense that\nHere \"R\" denotes the right action of \"G\" on \"P\" for some \"g\" ∈ \"G\". Note that for 0-forms the second condition is vacuously true.\n\n\nGiven \"P\" and \"ρ\" as above one can construct the associated vector bundle \"E\" = \"P\" × \"V\". Tensorial \"q\"-forms on \"P\" are in a natural one-to-one correspondence with \"E\"-valued \"q\"-forms on \"M\". As in the case of the principal bundle F(\"E\") above, given a \"q\"-form formula_18 on \"M\" with values in \"E\", define φ on \"P\" fiberwise by, say at \"u\",\nwhere \"u\" is viewed as a linear isomorphism formula_20. φ is then a tensorial form of type ρ. Conversely, given a tensorial form φ of type ρ, the same formula defines an \"E\"-valued form formula_18 on \"M\" (cf. the Chern–Weil homomorphism.) In particular, there is a natural isomorphism of vector spaces\n\n\nNow, suppose there is a connection on \"P\" so that there is an exterior covariant differentiation \"D\" on (various) vector-valued forms on \"P\". Through the above correspondence, \"D\" also acts on \"E\"-valued forms: define ∇ by\nIn particular for zero-forms,\nThis is exactly the covariant derivative for the connection on the vector bundle \"E\".\n\n"}
{"id": "8252674", "url": "https://en.wikipedia.org/wiki?curid=8252674", "title": "Work–family conflict", "text": "Work–family conflict\n\nWork-family conflict occurs when an individual experiences incompatible demands between work and family roles, causing participation in both roles to become more difficult. This imbalance creates conflict at the work-life interface. It is important for organizations and individuals to understand the implications linked to work-family conflict. In certain cases, work-family conflict has been associated with increased occupational burnout, job stress, decreased health, and issues pertaining to organizational commitment and job performance. \n\nWork-family conflict was first studied in the late 19 century. During this time period, work and income moved from inside the home (agricultural work) to outside the home (factories). Industrialization challenged the current relationship between working and family.\n\nBoundary theory and border theory are the foundations used to study work-family conflict. Boundary theory divides social life into two interdependent sections, work and family. Individuals have different roles and responsibilities in each section. Since the sections are interdependent, two roles cannot take place at the same time. Individuals have to participate in role transformation between expectations of the workplace and expected roles within the family structure.\n\nBorder theory expands this by considering the influences each section has on the other. Border theory attempts to pin down ways to manage conflict and achieve balance between conflicting identities. Individuals may choose to treat these segments separately, moving back and forth between work and family roles (displaying boundary theory) or can decide to integrate the segments with hopes of finding balance.\n\nConflict between work and family is bi-directional. There is a distinction between what is termed work-to-family conflict and what is termed family-to-work conflict.\n\nWork-to-family conflict occurs when experiences and commitments at work interfere with family life, such as extensive, irregular, or inflexible work hours, work overload and other forms of job stress, interpersonal conflict at work, extensive travel, career transitions, or an unsupportive supervisor or organization. For example, an unexpected meeting late in the day may prevent a parent from picking up his or her child from school.\n\nFamily-to-work conflict occurs when experiences and commitments in the family interfere with work life, such as the presence of young children, primary responsibility for children, elder care responsibilities, interpersonal conflict within the family unit, or unsupportive family members.For example, a parent may need to take time off from work in order to take care of a sick child, or to witness a tournament or performance of a child. Family-to-work conflict is perceived to result in lower work productivity of employees.\n\nWithin work-to-family conflict and family-to-work conflict, three subtypes of conflict have been identified: time-based, strain-based, and behavior-based. \"Time-based\" conflict entails competing time requirements across work and family roles, \"strain-based\" conflict entails pressures in one role impairing performance in the second role, and \"behavior-based\" conflict entails an incompatibility of behaviors necessary for the two roles. \n\nAlthough work interface with family (WIF) and family interface with work (FIW) are strongly correlated, more attention has been directed toward WIF. Research, largely attributed to the idea Ariel Russel Hochschild termed the \"ideal worker\", depicts the inelastic nature of work roles and responsibilities. The expectations employers hold of an \"ideal worker\" already rest on unrealistic assumptions about how the family should operate. Many employers expect that employees with families have someone tending to everything at home, leaving the worker unencumbered. Despite the fact that a majority of families in the U.S are dual earning, the image of the \"ideal worker\" persists, presenting work-family conflict.\n\nWorkaholism correlates with experiences of work-to-family conflict, since one's priority of work may interfere with family commitments. In its simplest form, workaholism is said to be a substantial investment in one’s work. One who is said to be involved in the act of workaholism can be labeled as a workaholic. Workaholism is said to be multifaceted and multi-directional.The flexibility and satisfaction within one’s job has an impact on an employee’s happiness and satisfaction in the home and vice versa. An overabundance of work has been said to take priority over everyone and everything else in the lives of those infatuated with work. Excessive work prevents one from forming and maintaining intimate relationships and close friendships. Workaholics are known to spend a vast amount of time in work related activities, which then results in the sacrifice of crucial family, social, and recreational activities. Marital problems, trouble with maintaining close relationships, and isolation from friends and family are the common issues related to workaholism and those involved.\n\nIn most recent years, employers have become more aware of the strain and stress that work can place on an employee. Companies have since started seeing their employees not only as workers, but also as people with personal and home lives.Implementation of family-responsive human resource practices and policies that promote work-family balance have become a reality as a way to reduce stress in both environments.\n\nWith the struggles of work-family conflict, options are necessary to provide a solution for these problems. Loehr and Schwartz compare the extreme demands experienced by an individual in the workplace to that of a professional athlete. In both scenarios energy expenditure (stress) is experienced. Without recovery (oscillation) both cannot perform to their greatest ability, eventually leading to chronic stress, burnout, and fatigue. Persist stress without oscillation and the result will be permanent damage.\n\nCreating an environment that values oscillation, for instance encouraging 15-minute walk breaks throughout the workday or offering corporate gym memberships, can improve employee cognition, energy, focus, and emotional intelligence. Companies, along with their bottom line and employees, win when mental and physical health are treated as equally important to cognitive capabilities. In order to gain competitive advantage, organizations are attempting to be portrayed as work-life balance supportive employers. Companies that value employee work-life balance are able to attract and retain satisfied employees, improve worker performance, and boost employee morale and organization identification.\n\nWork-family conflict can be diminished by establishing family-friendly policies in the workplace. Some of these policies include maternity, paternity, parental, sick leaves, and health care insurance. Organizations may provide child care options either as an on-site child care center at the business, references to close child care centers, or supplemented child care incomes for the families placing their children in a child care center.\n\nWith advances in technology, individuals who work outside the home and have intense schedules are finding ways to keep in touch with their families when they cannot physically be with them. \"Technology has provided a bit of an upper hand, allowing them unprecedented control and creativity in maneuvering the tenuous balance between work and family\" (Temple, 2009). Organizations are now able to implement telecommuting policies which allow employees to work from home and provide more flexibility and control over their schedules.\n\nThe role of gender is a large factor in work-family conflict because one's gender may determine their role in the home or work place. Female representation in the workplace is a direct result of power operating covertly through ideological controls. This is illustrated by the basic assumption of an \"ideal worker.\" Many organizations view the ideal worker as one who is \"committed to their work above all else\". Ideal workers are those that complete tasks beyond their formal and assigned behaviors, seen as a positive and valuable attribute to the organization. Individuals having to divide their time (and their commitments) between family and work are perceived as less dedicated to the organization. A manager's perception of a subordinate's role and commitment to the organization is positively associated with the individual's promotability.\n\nManager expectations of an ideal worker are often placed on female workers. Since female workers are both part of the workforce and have significant responsibilities at home, they experience a greater bearing of work-life conflict. Female employees, who managers perceive to be juggling work and family commitments, were presumed to be less committed to the organization, therefore not worthy of advancement. Women in the workforce may be \"inaccurately perceived to have less commitment to their organizations than their counterparts. Their advancement in organizations may be unfairly obstructed\". Males are perceived to be extremely dedicated to their organization because they experience lower levels of work-family conflict.\n\nA male individual may be unmarried and have no thought as to what \"typical\" family responsibilities entail because they simply have not had the experience. The male may be married, but his wife, due to the demands of the husband's position, has remained at home, tending solely to the house and children and experiencing the \"typical\" family responsibilities. Since the wife is the one who stays home and tends to the children, the husband is more present in the workforce, representing the higher percentage of males at the top of the organization hierarchy. Ironically, these are the individuals creating and reforming workplace policies.\n\nThe motherhood penalty is a term sociologists use when arguing that in the workplace working mothers encounter systematic disadvantages in pay, perceived competence, and benefits relative to childless women. In their place of work, women may suffer a per-child wage penalty, leading to a pay gap between mothers and non-mothers that is larger than the gap between men and women. Not only do working mothers have the burden of balancing work and home life, but they also have to prove they are as dedicated as other employees. Mothers tend to suffer less favorable job-site evaluations compared to non-mothers, stating that mothers are much less committed to their jobs, less authoritative, and less dependable than non-mothers. Hence, mothers may experience discrimination is terms of pay, hiring, and day-to-day job experience.\n\nThe way in which companies have shaped the \"ideal worker\" does not compliment the family lifestyle, nor does it accommodate it. Long hours and near complete devotion to the profession make it difficult for working mothers to participate in, or get ahead in the workplace while maintaining a home and family .\n"}
{"id": "2767017", "url": "https://en.wikipedia.org/wiki?curid=2767017", "title": "Yellowfin cutthroat trout", "text": "Yellowfin cutthroat trout\n\nThe yellowfin cutthroat trout (\"Oncorhynchus clarkii macdonaldi\") is an extinct subspecies or variety of the cutthroat trout, a North American freshwater fish.\n\nAt the end of the last ice-age boulders and clay moraine blocked off a tributary of the headwaters of the Arkansas River in what is now the state of Colorado. The two lakes which formed were named the \"Twin Lakes\" by the area's settlers. Both lakes held small greenback cutthroat trout from the early days of the Wild West, but in the mid-1880s reports circulated of much larger trout, up to in weight, with bright yellow fins.\n\nIn July 1889, Professor David Starr Jordan and G. R. Fisher visited Twin Lakes and published their discoveries in the 1891 Bulletin of the United States Fish Commission. They found both the greenback and what they proclaimed to be a new species the \"yellowfin cutthroat\". In the species description, published in the 1890 edition of the Proceedings of the United States National Museum, Jordan and Evermann described the fish as follows: Color, silvery olive; a broad lemon yellow shade along the sides, lower fins bright golden yellow in life, no red anywhere except the deep red dash on each side of the throat. The subspecies was scientifically named \"macdonaldi\" after the US Fish Commissioner, Marshall McDonald.\n\nJordan's specimens were recently re-examined by the fisheries biologist Robert J. Behnke, who commented, \"I have no doubt that Jordan was correct; the yellowfin trout and the greenback trout from Twin Lakes were two distinct groups of cutthroat trout\".\n\nUntil about 1903, greenback and yellowfin cutthroats survived together in Twin Lakes, the populations remaining isolated as both breeders and feeders. The end for the yellowfin cutthroat came soon after the introduction of the rainbow trout to Twin Lakes. The greenback population interbred with the rainbows, resulting in cutbows, but the yellowfin disappeared completely. The yellowfin is now extinct.\n"}
