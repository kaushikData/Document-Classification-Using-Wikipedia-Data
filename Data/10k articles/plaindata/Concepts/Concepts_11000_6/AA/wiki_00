{"id": "37768888", "url": "https://en.wikipedia.org/wiki?curid=37768888", "title": "Böckenförde dilemma", "text": "Böckenförde dilemma\n\nThe Böckenförde Dilemma () is a problem (dilemma), which claims that in secular states there are obstacles to creation of social capital.\n\nThe dilemma is named after German constitutional judge Ernst-Wolfgang Böckenförde.\n\nBöckenförde wrote that:\n\nIn a feudal state the king represents the ultimate power based on the divine right doctrine, the legitimacy of king's rule is transcendentally justified. In a republic there is no generally valid notion of sovereign, although in theory the people have sovereignty (popular sovereignty). But according to constitution the people hand over to some extent their sovereignty or government authority to state leaders and parliaments. In election coverage formulations like \"the sovereign has decided\" are used. The Böckenförde Dilemma alludes to the fact that in a democracy the legitimacy of the government is justified \"from below\" in contrast to absolutism. While the absolutist state demands loyalty from its citizens and through this loyalty can exercise its rule, the democratic state relies on democratic convictions of its citizens and can not enforce those convictions itself.\n\nThis leads to difficulties in answering the question of how a democratically constituted society can secure its survival and defend itself against threats. Böckenförde draws attention to the paradox that the state in the attempt to defend democracy with \"the means of legal coercion and decrees from authority\" would itself become a dictatorship because it would infringe upon the idea of people as sovereign.\n\nGerhard Czermak writes that Böckenförde is \"fundamentally misunderstood when not instrumentalized\" when it is concluded from his dilemma that \"the state should promote churches and religious communities as sources of virtue in particular... He (Böckenförde) speaks of adventure and points to very different forces acting in society. He means that all groups with their own, also moral, worldview contribute to integration of a part of society.\"“\n\nIn two interviews in 2009 and 2010 Böckenförde answered the critique that he had exaggerated the ethical force of religion: \"This criticism misses the context in which I made this statement in 1964. Back then I was trying to explain to Catholics the origin of the secular, that is worldly, no longer religious state and dissolve their scepticism of it. This had happened before 1965 when at the end of the Second Vatican Council the Roman Catholic Church for the first time completely recognized the concept of religious freedom. In the face of this scepticism I urged Catholics to accept this state and engage in it, among other things with the argument that the state has to rely on their ethical shaping force.\"\n\nIn 2010 Böckenförde clarified it as follows: \"To conceive of such a state the liberal order needs a unifying ethos, a \"sense of community\" among those who live in this state. The question then becomes: what is creating this ethos, which can neither be enforced by the state nor compelled by a sovereign? One can say: first the common culture. But what are the elements and factors of that culture? Then indeed we are dealing with its sources such as Christianity, Enlightenment and humanism. But not automatically any religion.\"\n\nA secular version of this thought one can find already in Aristotle: that the virtue of a state is founded on the virtue of its citizens and that it rests on their disposition, habit and reason - which is also reflected in the famous quote of Joseph de Maistre that every nation gets the government it deserves. Therefore political education becomes a necessary condition for existence and an essential task (however hard it is to ensure institutionally) of the good political order.\n\nIn this context the debate over changing values is worth noting. In the tradition of cultural pessimism Elisabeth Noelle-Neumann believes that since the 60's an uninterrupted decline in values has taken place. The erosion of \"civic virtues\" such as sense of community and pride in work as well as declining attendance in churches and shrinking religious engagement have been noted as symptoms. According to Helmut Klages instead of a decay of values what is happening is a synthesis of old and new values. Ronald Inglehart postulates a change from material to non-material values that will ultimately strengthen democracy: he believes more cooperation and more freedom will result from this change.\n\nGerhard Himmelman points out that the sociologists countered the debate about a decline in values with the argument that \"the modern social regulatory mechanisms and the democratic procedures serve as foundations of social integration\". Instead of appealing, among other things, to the communitarianism, the public discourse, the communication free from domination (Jürgen Habermas) creates out of itself (\"Selbstschöpfungsprozess\") the values and behaviors (democratic virtues), that the liberal state needs to exist and survive. Jürgen Habermas also sees a risk that runaway modernization of society undermines the democratic layer and destroys the kind of solidarity on which the democratic state relies, without being able to enforce it legally,\n\nMichael Haus also rejects the Böckenförde thesis as unfounded. From Böckenförde's premise that the modern democratic state was created under the influence of the Christian religion, it does not necessarily follow that the society of \"today\" is dependent on religion as a foundation. Instead a civic consensus could also rest on binding commonalities such as shared interests, interdependencies, dependencies, opportunities for cooperation, a common history or common historical lessons.\n\nAxel Montenbruck follows Böckenförde's approach. But answering Böckenförde's call for \"binding ethos\" Montenbruck introduces the western secular ideas of civil religion that goes back to Rousseau: \"The solution to this dilemma can only be found on an even higher level, such as that of the preambles. The people needs to create aside from the state also its own \"substitute religion of internalized values and principles\", to which it must then submit. Indeed, the nations possess these \"substitute religions\" as evidenced by preambles to their constitutions etc. But they find an understandable difficulty speaking again of religion, even if only of civil religion.\"\n\nSince the 1990s, this idea has been taken up and modified by Paul Kirchhof and related to demographic developments.\n\nThe Böckenförde dilemma stands at the \"center of liberal conservatism\".\n\n\n\n"}
{"id": "47678733", "url": "https://en.wikipedia.org/wiki?curid=47678733", "title": "Caux Palace Hotel", "text": "Caux Palace Hotel\n\nThe Caux Palace Hotel is a former palace hotel located in Caux, above Montreux in the Vaud canton, in Switzerland.\n\nBuilt on the Caux Mount by the Swiss architect Eugène Jost, it was inaugurated on 7 July 1902. The building rests on a 400-meter long terrace and is decorated with an abundance of towers and turrets with coloured tiles, which make it a remarkable feature of the Montreux landscape, visible from the whole Montreux Riviera region. It soon became an international venue first in the early 20th century as a luxury hotel, then from 1946 on as an international conference centre dedicated to the rebuilding of Europe under the leadership of the Swiss Initiatives of Change team. It is now also the seat of the Swiss Hotel Management School (SHMS) which uses the premises during the school semesters while Initiatives of Change keeps organising summer conferences there each year. The Caux-Palace Hotel is listed as a .\n\nUntil 1875, the area around Caux was only sparsely populated. The \"Caux mountains\" had always been used as a pasture for local farmers while the road to the Jaman pass was the shortest route towards the Sarine and Simmental valleys. In 1875 taking into account the rapid development of tourism on the lakeside where the first hotels had opened in 1837 in Montreux and in 1841 in Territet, Emile Monnier decided to transform his chalet on the Caux Mountain into an inn with a view to welcome the ramblers who started to explore the mountainside. This development had first affected the village of Glion, halfway between Montreux and Caux: a road to Glion was opened in 1850 and a cable-car service was opened between Territet and Glion in 1883.\n\nAbout the same time local entrepreneurs became aware of the potential of Caux, almost 1000 meters above Glion. Philippe Faucherre, born in 1844 and his wife Louise Vauthier, both from hotel management background, were among them. In 1890 Faucherre bought a stone career in the area and built the Caux Grand Hotel in three years, all the needed material being brought to the construction site by mules for lack of other means of transportation.\n\nThe railway from Glion to Caux and to the Rochers-de-Naye summit was built at the same time and inaugurated in 1892 after only 15 months of works, a technical tour-de-force realized under the famous railway engineer Laubi. The extension of this railway between Montreux and Glion would wait 27 more years. The road to Caux was also opened at the same time by public works contractor Pierre Botelli.\n\nThe immediate success of the Grand Hotel, which attracted many prominent people to Caux, led other entrepreneurs to conceive the Caux Palace Hotel.\n\nFive years after the Grand Hotel opening, Ami Chessex, who was the owner of the lakeside Territet Grand Hotel, decided to build a new hotel on a piece of land he owned at Caux, just under the Caux Grand Hotel – although the area was rather sloppy. Early in 1899 a joint venture company was founded by Chessex and Faucherre with a capital of 2.5 million Swiss Francs. At the start of 1900 this company issued 3 million worth of bonds (and issued 500,000 francs more in 1903).\n\nThe first round of works consisted of an additional floor on top of the Grand Hotel, which immediately increased its capacity by 80 beds. Then in 1900 the construction works of the Caux Palace started. The main requirement was to make it the most advanced, most luxurious and biggest hotel ever built in Switzerland. As imagined by chief architect Eugène Jost, the construction started by a 400-meter long supporting wall along the hotel’s site, allowing for the creation of a nice garden at the foot of the future hotel and for a promenade along this belvedere from which future Caux Palace Hotel customers would enjoy a unique sight on the grand landscape of Lake Geneva and of the Alps.\n\nAlfred Daulte, one of Jost’s deputies, was to lead the works on site. It was difficult job given that there were up to 800 workers on site and that the progress of the construction was under close personal scrutiny from Ami Chessex, who used to walk up from Territet twice a week and did not hesitate to issue orders contradicting Daulte’s. Nevertheless, the building and decoration works were completed in a little over two years, and on 7 July 1902, the Caux Palace Hotel was officially inaugurated in presence of the president of the Canton’s executive, Mr Cossy, and of the whole Vaud government. The books of the \"Société immobilière de Caux\" showed a total cost of construction of 2,555,949 Swiss francs.\n\nLike its predecessor, the Caux Grand Hotel, the Caux Palace Hotel was blessed with instant success. Visitors included celebrities such as Sacha Guitry, Paul Morand, Romain Rolland, Edgar Wallace, prince Ibn Saud, future king of Saudi Arabia, John D. Rockefeller and the maharajah of Baroda. The latter stayed frequently in Caux, using most of the fourth floor. His personal room at the south-west angle of the building enjoyed an outstanding view and was furbished in lemon-tree wood furniture, especially designed for the maharajah. This exceptional furniture and the initial decoration of this room have been preserved to this day.\n\nTwo to three weeks of waiting time were sometimes necessary before the privilege of staying at the Caux Palace Hotel could be granted to the customers. Several smaller hotels were therefore built in Caux in the wake of the opening of the Caux Palace Hotel, such as the “Pavillon des Fougères” (later “Hotel Alpina”) or the “Hotel Maria”. A school was opened in Caux in 1905, an Anglican chapel was built in 1906 and a Catholic one in 1907. Many private chalets were also built around the same years. Winter sport facilities included ski and sledge slopes, three ice rinks for skating and a bobsleigh track. The world bobsleigh federation and the world ice hockey federation were be created in Caux.\n\n1 August 1914 spelt the end of the golden years of luxury tourism in Switzerland. In a matter of a few days most of the customers had left the hotels, which would remain empty for the next five years. On 10 August, the few remaining Grand Hotel customers were transferred to the Caux Place Hotel and the Grand Hotel was then closed down. In 1917, Ami Chessex passed away after having struggled for three years to keep the company afloat. The cumulated loss at the end of the war would be of 1 million.\n\nIn 1919, war had at last stopped and everything could have returned to normal, but exchange rates were high for the Swiss Francs and the Caux hotels did not completely correspond with the new expectations of the customers. Therefore, in spite of a financial restructuration of the company in 1919, business remained disappointing. In 1925, the Grand Hotel was renovated and renamed Hotel Regina, in memory of Empress Sissi of Austria-Hungary who had resided there in 1898 just before being assassinated in Geneva.\n\nThe years 1927 and 1928 brought at last sizeable improvement for the Caux hotels. A second financial restructuration took place in 1929 in order to raise 1 million francs to renovate the Caux Palace Hotel. The bobsleigh world cup was organised in Caux in 1930. Unfortunately, the years 1930 to 1935 were most difficult as a result of the worldwide financial crisis. The value of the individual share of the \"Société immobilière de Caux\" had sunk from around 200 francs in 1900 to 1 francs in 1936. A fourth financial restructuration was insufficient to mend the situation and the board put the hotels up for sale as the losses piled up.\n\nIn 1938 the railway was converted from steam to electricity and the ski fashion reignited interest for Caux. The Caux Palace Hotel was renamed Hotel Esplanade and now targeted a less exclusive audience. However, in 1939 it had to stop all activities for good.\n\nAfter the Caux Palace Hotel, most other hotels also had to gradually close down. In 1941, Hotel Regina was declared bankrupt and sold twice in a row. The Caux Palace Hotel reopened in May 1944 as a detention centre for English and American Air Force pilots escaped from Italian prisoner's camps. Then from November 1944 to July 1945 they were replaced by Italian civilian refugees and from December 1944 by Jewish Hungarian refugees. This last group consisted of 1670 people coming from the Bergen-Belsen concentration camp where they had been briefly detained by the SS administration in spite of the payment of a handsome ransom for their freedom. This episode is known as the Kasztner train story, by the name of the main Jewish negotiator for this evacuation. Last minute negotiations on the background of an impending German defeat allowed the train to be finally redirected to Switzerland as initially planned and to save its passengers from an almost certain death. Orthodox Jews were put up at the Regina Hotel and all other in the former Caux Palace Hotel. An oak tree was planted on the Caux terrace in memory of this convoy and a plaque was inaugurated there in 1999. It reads: “In memory of the Jewish refugees accommodated here during WWII, and in memory of those who were driven back by the Swiss borders. We shall not forget them.”\n\nThese various visitors of Caux degraded the buildings a lot. Everything that could have a market value like door knobs, locks, taps, etc. was dismantled and sold. This completed the ruin of the creators of the Caux Palace Hotel. Apart from the ground and of the building’s shell, nothing was left of the 9 to 10 million Swiss Francs which had been invested there since 1890. It later turned out, however, that the caretaker of the Caux Palace Hotel, Robert Auberson, had been able to hide and store a lot of valuable pieces of furniture, as well as crockery and cutlery.\n\nIn 1946, the derelict Caux Palace Hotel as well as the former Grand Hotel and other smaller hotel buildings in Caux looked like near their end. The bankrupt \"Société Immobilière de Caux\" had fallen into the hands of its main banker, \"Banque populaire de Montreux\", who were looking for a quick way out and had put the whole lot on the market at a very low price. The most likely outcome was the demolition of the building in order to reuse its material.\n\nBut in an unexpected move, Geneva-born diplomat Philippe Mottu bid for the building with a small group of Swiss people. A graduate in theology and political science from Geneva university, Philippe Mottu had been associated with Frank Buchman and the Oxford Group since the mid-1930s and in 1943 he had had the recurring thought: \"If Switzerland is spared by war, our task will be to put at the disposal of Frank Buchman a place where Europeans, torn apart by hatred, suffering and resentment, will be able to meet each other. Caux is the place.\"\n\nThe bankers as well as the city of Montreux mayor understood full well the positives of having an international conference centre in the area of Montreux and offered a \"discount\" price of 1.050.000 Swiss francs, giving Moral Rearmament a priority over other bidders. The \"Caux Foundation\", which would administer the Caux Palace Hotel in the coming decades, being not yet in place, the sale contract was signed on 25 May 1946 by Philippe Mottu and Robert Hahnloser in their own name. It would take 95 individual Swiss donors to be able to reach the 450,000 Francs amount requested as first down payment on 1 July 1946. In-kind donations such as furniture, carpets also converged from all over Switzerland to help refurbish the former palace.\n\nDuring six weeks, a team of international volunteers toiled day and night under the guidance of Swiss engineer Robert Hahnloser and his deputy, Dutch architect Jap de Boer, in order to repair the inside of the house. On 9 July 1946 the first meal cooked in the just enabled new kitchen was served to 150 guests. During that 1946 summer, 3000 people visited the new Caux conference centre. Dormitories were installed and some of the participants had to be allocated in nearby hotels. In 1946 and 1947 a series of needed transformations were performed in order to adapt the building to its new destiny: conversation of the ball room into a theater, new, larger entrance hall, etc. Lacking the adequate number of beds, the \"Caux Foundation\" bought the Grand Hotel and the Maria Hotel in 1947 and the Alpina Hotel in 1949, plus various smaller buildings.\n\nIn the course of the next 50 years, the Caux Palace Hotel did not undergo any other significant modifications. Its history is marked by a long string of meetings organised by MRA, which in certain cases had political repercussions.\n\nThe Caux-Palace Hotel building surprises the observer both by its size and by its eclectic style.\n\nThe building’s style is often considered as neo-medieval and has earned the Caux Palace Hotel the nickname of \"Sleeping Beauty Castle\", whereas\n\nStudying the façades of all hotels built by Eugène Jost, Professor Dave Lüthi from the University of Lausanne observed that, in order to avoid the hotel to look like barracks as could result from long rows of aligned hotel rooms windows, Jost contrived to counterbalance the horizontal deployment of the façades by an almost brutal articulation of vertical volumes and by the use of a few ornate bays which create a dynamic in the various sections of the façades (accentuation of dormers and roofs, contrasting with angles left free of any decoration).\n\nIn the case of the Caux Palace Hotel, which can probably be regarded as Jost’s masterpiece, the South façade, which contains 271 windows, is ingeniously split in five parts and patterned by numerous protruding elements such as balconies, bow windows or a corbeling gallery on the last floor. In contrast to this part of the building, the common areas rooms is equipped with very large bay windows which somewhat blur the visitor’s perception of the building from the gardens: these brutal scale changes are typical of eclectic architecture; they indicate the function of each part of the building and by bringing them together, oppose them, so as to warn the visitor about his own subjectivity: big or small are relative values.\n\nSeen close by, the Caux Palace Hotel is an imposing sight because of its monumental size (which may be its main similarity with its so-called medieval models), yet it nevers \"crushes\" the observer; seen from afar only its cornice, roof and turrets can be seen: the Caux Palace Hotel, like a diadem set on top of the Caux Mount, becomes the giant advertisement for the site. The Caux Palace Hotel is therefore quite representative of the new trend launched by Eugène Jost:\n\nIn the case of the Caux Palace Hotel as in his other hotel projects, Eugène Jost foremost concentrated on the general layout and on the façades. He unfolded his monumental buildings beyond the point where dimension became detrimental to usage.\n\nThe Caux Foundation made several renovations in the course of the years, the most spectacular being in the course of the 1980s the complete renovation of the roofs; appropriate coloured glazed tiles could only be found in the region of Dijon (France) and they were bought with the financial assistance of the French Initiatives of Change association. The dining room had been redone in 1959 and a fresco by Finnish painter Lennart Segerstråle was then added.\n\nThe arrival of the Swiss Hotel Management School (SHMS) in 1995 as a tenant outside the conference season has allowed the Caux Foundation to do more to maintain and improve the ageing building and its surroundings. In some cases it was a matter of compliance with more demanding new regulations: there was a revamping of the kitchen in line with the most advanced professional norms, the installation of required fire detector systems and fireproof doors at strategic locations, the installation of separate collection and evacuation systems for wastewater and rainwater, etc. Another key work is the gradual renovation of over 200 bathrooms which had more or less remained early 20th century bathrooms. In other instances, there was a need to adapt to the requirements of the teaching activity of SHMS: creation of classrooms and of a new amphitheater, addition of an internet café. Some structures, such as the ground floor pergola, also received needed renovations.\n\nHowever, from the cultural heritage viewpoint, the most interesting piece of work was the renovation of the great hall and of some historic rooms in 2007 and 2008 with support from Foundation Pro Patria, Loterie Romande and JP Morgan Chase. The challenge was to clean up and to restore the wall and ceiling frescoes of the great hall which had been created by Bernese painter in 1902. The ceiling was particularly important as one of the largest ever painted in Switzerland and as the only one still in its original state. It is also unique by its decoration in Swiss Art deco style and by its cupola shape. The restoration works of the frescoes allowed reducing the visual impact of the various alterations they endured in time, to keep in place as much as possible the initial decorations’ substance and to bring to light two additional frescoes adorning the great Hall’s decorative fireplace mantels.\n\nThese renovation works were led by specialists Olivier Guyot et Julian James and supervised by the “Monuments and Sites” section of the Vaud state, as well as by Swiss architect Eric Jaeger for the Caux Foundation.\n\nAt the end of 2015, the CAUX-Initiatives of Change Foundation had the heating system replaced, moving from oil to (local) wood heating. Fossil fuel's CO2 emissions were lowered by 590 tons per year as a result. The fuel oil boilers and tanks had been installed in the early 1960s to replace the original 1902 six coal firing boilers.\n\nThis page is translated from the French Wikipedia page. Main sources are:\n"}
{"id": "3407787", "url": "https://en.wikipedia.org/wiki?curid=3407787", "title": "Cinderella effect", "text": "Cinderella effect\n\nIn evolutionary psychology, the Cinderella effect is the phenomenon of higher incidence of different forms of child-abuse and mistreatment by stepparents than by biological parents. It takes its name from the fairy tale character Cinderella. Evolutionary psychologists describe the effect as a byproduct of a bias towards kin, and a conflict between reproductive partners of investing in young that are unrelated to one partner. There is both supporting evidence for this theory and criticism against it.\n\nIn the early 1970s, a theory arose on the connection between stepparents and child maltreatment. \"In 1973, forensic psychiatrist P. D. Scott summarized information on a sample of \"fatal battered-baby cases\" perpetrated in anger ... 15 of the 29 killers – 52% – were stepfathers.\" Although initially there was no analysis of this raw data, empirical evidence has since been collected on what is now called the Cinderella effect through official records, reports, and census.\n\nFor over 30 years, data has been collected regarding the validity of the Cinderella effect, with a wealth of evidence indicating a direct relationship between step-relationships and abuse. This evidence of child abuse and homicide comes from a variety of sources including official reports of child abuse, clinical data, victim reports, and official homicide data. Studies have concluded that \"stepchildren in Canada, Great Britain, and the United States indeed incur greatly elevated risk of child maltreatment of various sorts, especially lethal beatings\".\n\nPowerful evidence in support of the Cinderella effect comes from the finding that when abusive parents have both step and genetic children, they generally spare their genetic children. In such families, stepchildren were exclusively targeted 9 out of 10 times in one study and in 19 of 22 in another. In addition to displaying higher rates of negative behaviors (e.g., abuse) toward stepchildren, stepparents display fewer positive behaviors toward stepchildren than do the genetic parents. For example, on average, stepparents invest less in education, play with stepchildren less, take stepchildren to the doctor less, etc. This discrimination against stepchildren is unusual compared with abuse statistics involving the overall population given \"the following additional facts: (1) when child abuse is detected, it is often found that \"all\" the children in the home have been victimized; and (2) stepchildren are almost always the eldest children in the home, whereas the general ... tendency in families of uniform parentage is for the youngest to be most frequent victims.\"\n\nEvolutionary psychologists Martin Daly and Margo Wilson propose that the Cinderella effect is a direct consequence of the modern evolutionary theory of inclusive fitness, especially parental investment theory. They argue that human child rearing is so prolonged and costly that \"a parental psychology shaped by natural selection is unlikely to be indiscriminate\". According to them, \"research concerning animal social behaviour provide a rationale for expecting parents to be discriminative in their care and affection, and more specifically, to discriminate in favour of their own young\". Inclusive fitness theory proposes a selective criterion for the evolution of social traits, where social behavior that is costly to an individual organism can nevertheless emerge when there is a statistical likelihood that significant benefits of that social behavior accrue to (the survival and reproduction of) other organisms whom also carry the social trait (most straightforwardly, accrue to close genetic relatives). Under such conditions, a net overall increase in reproduction of the social trait in future generations can result.\n\nThe initial presentation of inclusive fitness theory (in the mid 1960s) focused on making the mathematical case for the possibility of social evolution, but also speculated about possible mechanisms whereby a social trait could effectively achieve this necessary statistical correlation between its likely bearers. Two possibilities were considered: One that a social trait might reliably operate straightforwardly via social context in species where genetic relatives are usually concentrated in a local home area where they were born ('viscous populations'); The other, that genetic detection mechanisms ('supergenes') might emerge that go beyond statistical correlations, and reliably detect \"actual\" genetic relatedness between the social actors using direct 'kin recognition'. The relative place of these two broad types of social mechanisms has been debated (see Kin selection and Kin recognition), but many biologists consider 'kin recognition' to be an important possible mechanism. Martin Daly and Margo Wilson follow this second mechanism, and expect that parents \"discriminate in favour of their own young\", i.e. their \"actual\" genetic relatives.\n\nThe most abundant data on stepchild mistreatment has been collected and interpreted by psychologists Martin Daly and Margo Wilson, who study with an emphasis in Neuroscience and Behavior at McMaster University. Their first measure of the validity of the Cinderella effect was based on data from the American Humane Association (AHA), an archive of child abuse reports in the United States holding over twenty thousand reports. These records led Wilson and Daly to conclude that \"a child under three years of age who lived with one genetic parent and one stepparent in the United States in 1976 was about seven times more likely to become a validated child-abuse case in the records than one who dwelt with two genetic parents\". Their overall findings demonstrate that children residing with stepparents have a higher risk of abuse even when other factors are considered.\n\nAll organisms face trade-offs as to how to invest their time, energy, risk, and other resources, so investment in one domain (e.g., parental investment) generally takes away from their ability to invest in other domains (e.g. mating effort, growth, or investment in other offspring). Investment in non-genetic children therefore reduces an individual's ability to invest in itself or its genetic children, without directly bringing reproductive benefits. Thus, from an evolutionary biology perspective, one would not expect organisms to regularly and deliberately care for unrelated offspring.\n\nDaly and Wilson point out that infanticide is an extreme form of biasing parental investment that is widely practiced in the animal world. For example, when an immigrant male lion enters a pride, it is not uncommon for him to kill the cubs fathered by other males. Since the pride can only provide support for a limited number of cubs to survive to adulthood, the killing of the cubs in competition with the new male's potential offspring increases the chances of his progeny surviving to maturity. In addition, the act of infanticide speeds the return to sexual receptivity in the females, allowing for the male to father his own offspring in a timelier manner. These observations indicate that in the animal world, males employ certain measures in order to ensure that parental investment is geared specifically toward their own offspring.\n\nUnlike the lion, however, humans in a stepparenting situation face a more complicated tradeoff since they cannot completely disown their partner's offspring from a previous relationship, as they would risk losing sexual access to their partner and any chance of producing potential offspring. Thus, according to Daly and Wilson, stepparental investment can be viewed as mating effort to ensure the possibility of future reproduction with the parent of their stepchild. This mating effort hypothesis suggests that humans will tend to invest more in their genetic offspring and invest just enough in their stepchildren. It is from this theoretical framework that Daly and Wilson argue that instances of child abuse towards non-biological offspring should be more frequent than towards biological offspring.\n\nOne would therefore expect greater parental responsiveness towards one's own offspring than towards unrelated children, and this will result in more positive outcomes and fewer negative outcomes towards one's own children than towards other children in which one is expected to invest (i.e., stepchildren). \"If child abuse is a behavioral response influenced by natural selection, then it is more likely to occur when there are reduced inclusive fitness payoffs owing to uncertain or low relatedness\". Owing to these adaptations from natural selection, child abuse is more likely to be committed by stepparents than genetic parents—both are expected to invest heavily in the children, but genetic parents will have greater child-specific parental love that promotes positive caretaking and inhibits maltreatment.\n\nDaly and Wilson report that this parental love can explain why genetic offspring are more immune to lashing out by parents. They assert that, \"Child-specific parental love is the emotional mechanism that permits people to tolerate—even to rejoice in—those long years of expensive, unreciprocated parental investment\". They point to a study comparing natural father and stepfather families as support for the notion that stepparents do not view their stepchildren the same as their biological children, and likewise, children do not view their stepparents the same as their biological parents. This study, based on a series of questionnaires which were then subjected to statistical analyses, reports that children are less likely to go to their stepfathers for guidance and that stepfathers rate their stepchildren less positively than do natural fathers.\n\nDaly and Wilson's reports on the overrepresentation of stepparents in child homicide and abuse statistics support the evolutionary principle of maximizing one's inclusive fitness, formalized under Hamilton's Rule, which helps to explain why humans will preferentially invest in close kin. Adoption statistics also substantiate this principle, in that non-kin adoptions represent a minority of worldwide adoptions. Research into the high adoption rates of Oceania shows that childlessness is the most common reason for adopting, and that in the eleven populations for which data was available, a large majority of adoptions involved a relative with a coefficient of relatedness greater than or equal to 0.125 (e.g., genetic cousins). It is also observed that parents with both biological and adopted children bias the partitioning of their estates in favor of the biological children, demonstrating again that parental behavior corresponds to the principles of kin selection.\n\nIn their 1985 Canadian sample, Daly and Wilson classify the frequencies of different living arrangements (two natural parents, one natural parent, one natural parent with one stepparent, or other) according to child age. This was accomplished by administering a randomized telephone survey.\n\nRecords of child abuse from children's aid organizations as well as police reports on runaways and juvenile offenders were then used to determine whether children from stepparental living situations were overrepresented as abuse victims when compared to the demographic data gathered from the telephone survey data. The results indicate that the only living situation that has a significant correlation to increased child abuse is one natural parent and one stepparent in the same household. While rates of running away and crime were comparable for children living with stepparents and children of single-parents, abuse rates for children living with stepparents were much higher.\n\nDaly and Wilson examined several potentially confounding variables in their research, including socioeconomic status, family size, and maternal age at childbirth, however only minor differences between natural-parent and stepparent families with respect to these factors were found, indicating that none of these are major contributing factors to the observed Cinderella effect.\n\nEvolutionary psychologists have also suggested that one of the causes of stepchild abuse may be the lack of a parental attachment bond that the mother would normally form with her own child . An attachment bond will, in general, be more secure if formed before the age of two, and adoption can often disrupt the development of this bond. An infant who is fed by the primary parental figure, usually the mother, and has the mother present during severely physically painful events will have form a stronger parental attachment bond, and either a consistent omission of the mother from this process or an alteration between two people (the original mother and the adoptive mother) can cause either an insecure attachment or disorganized attachment from the parent to the child . As a result, it is highly recommended by most psychologists that the adoptive mother be present very early in the infant's life, preferably immediately after its birth, in order to avoid attachment disruptions and attachment disorders. This theory cannot be a whole explanation for the Cinderella effect, as psychological research has shown that secure attachment bonds can be developed between a parent and adopted child, and the quality of the relationship between parent and child will more often depend on the child's pre-adoption experiences, such as length of time in social care and previous trauma, more than characteristics of the parents.\n\nIt is sometimes argued that this evolutionary psychological account does not explain why the majority of stepparents do not abuse their partners' children, or why a significant minority of genetic parents do abuse their own offspring. However, their argument is based on a misunderstanding: the evolutionary psychological account is that (all else equal) parents will love their own children more than other people's children – it does not argue that stepparents will \"want\" to abuse their partner's children, or that genetic parenthood is absolute proof against abuse. Under this account, stepparental care is seen as \"mating effort\" towards the genetic parent, such that most interactions between stepparent and stepchildren will be generally positive or at least neutral, just usually not as positive as interactions between the genetic parent and the child would be.\n\nStrong support for the Cinderella effect as described by Daly and Wilson comes from a study of unintentional childhood fatal injuries in Australia. Tooley et al. follow the argument of Daly and Wilson to extend the Cinderella effect from cases of abuse to incidences of unintentional fatalities. Children are not only vulnerable to abuse by their parents, but they are also dependent on their parents for supervision and protection from a variety of other harms. Given that parental supervision is fundamentally correlated to incidences of unintentional childhood injury as shown by Wadsworth et al. and Peterson & Stern, Tooley et al. posit that selective pressures would favor an inclination towards parental vigilance against threats to offspring well-being. Tooley et al. further argue that parental vigilance is not as highly engaged in stepparents as genetic parents, therefore placing stepchildren at greater risk for unintentional injury.\n\nBased on data gathered from the Australia National Coroners' Information System, stepchildren under five years of age are two to fifteen times more likely to experience an unintentional fatal injury, especially drowning, than genetic children. Additionally, the study finds that the risks of unintentional fatal injury are not significantly higher for genetic children in single parent homes versus two-parent homes. This difference suggests that removing one biological parent from the home does not significantly increase risk to the children, but that adding a nonbiological parent to the home results in a drastic increase in the risk of unintentional fatal injury. Despite the fact that adding a stepparent to the home increases the available resources in terms of supervision in comparison to a single-parent home, risk of unintentional fatal injury still significantly rises. This higher risk of injury for stepchildren can be attributed to the fact that stepparents occupy the same supervisory role as a genetic parent, yet they have a lower intrinsic commitment to protecting the child and therefore are less likely to be adequately vigilant. The authors conclude that the Cinderella effect applies not only to purposeful abuse by stepparents, but is also relevant to explaining increased rates of accidental fatalities among stepchildren.\n\nFurthermore, a study of parental investment behaviors among American men living in Albuquerque, New Mexico, reveals a trend of increasing financial expenditures on genetic offspring in comparison to step-offspring, which also suggests that parents are less inclined to preserve the well-being of stepchildren. The study assesses paternal investment based on four measures: the probability that a child attends college, the probability that the child receives money for college, the total money spent on children, and the amount of time per week spent with children. Four different classifications of father-child relationships are examined and compared, including fathers living with their genetic children and stepfathers living with the stepchildren of their current mates. Though the study finds a clear trend of increasing investment in genetic children, the data also shows that stepfathers do still invest substantially in stepchildren. The authors explain the parental investment exhibited by stepfathers towards stepchildren as possibly motivated by the potential to improve the quality or increase the duration of the man's relationship with the stepchildren's mother. This studied corroborates the findings of Lynn White, that stepparents in general provide less social support to stepchildren than their genetic children.\n\nThough the general trend of the data from this study supports the Cinderella effect, Anderson and colleagues note that the observed differences between investment in children and stepchildren might be slightly reduced by a few confounding factors. For example, the authors point out that stepparenting is a self-selective process, and that when all else is equal, men who bond with unrelated children are more likely to become stepfathers, a factor that is likely to be a confounding variable in efforts to study the Cinderella effect. Anderson and colleagues also conducted a similar study of Xhosa students in South Africa that analyzes the same four classifications of adult-child relationships, and this study offers similar results to those observed among men in Albuquerque.\n\nAdditionally, a study of Hadza foragers in Tanzania by Marlowe also finds evidence of decreased care provided by men to stepchildren when compared with genetic children. The author uses the Mann-Whitney U-tests to evaluate most of the observed differences in care exhibited towards children and stepchildren, and finds that Hadza men spend less time with (U=96), communicate less with (U=94.5), nurture less, and never play with their stepchildren. Marlowe further argues that any care that is provided towards stepchildren is likely attributable to the man's mating efforts and not parental interest in the well-being of the stepchildren.\n\nIn further support of the Cinderella effect as elaborated by Daly and Wilson, a study conducted in a rural village in Trinidad demonstrates that in households containing both genetic children and stepchildren, fathers devote approximately twice as much time to interaction with genetic offspring in comparison to stepchildren. Additionally, this study finds that the duration of the relationship between the stepfather and stepchildren is negatively correlated with the relative proportion of interaction time and positively correlated with the relative proportion of antagonistic interactions between the two. As a proportion of total time spent interacting with genetic and stepchildren, stepfathers are shown to have approximately 75 percent more antagonistic interactions with stepchildren. In this study, antagonistic interactions are defined as involving physical or verbal combat or an expression of injury. This includes, for example, spanking, screaming, crying, and arguing. The duration of the relationship between genetic fathers and children shows a positive correlation with both relative proportion of interaction time and antagonistic interaction. The author argues that these results show that in terms of time invested, men favor their children over stepchildren, and this preference is not attributable to the duration of the adult-child relationship, a factor which is sometimes believed to be a confounding variable in the Cinderella effect. Though this study does claim a significant increase in antagonistic behavior between stepparents and stepchildren and therefore supports the Cinderella effect, it also notes that only six percent of all the observed parent-child interactions were considered antagonistic, and that the researchers never noticed any blatant physical child abuse.\n\nPhilosopher of science David Buller, as a part of his general critique of evolutionary psychology has reviewed Daly and Wilson's data. He argues that evolutionary psychology (EP) mistakenly attempts to discover human psychological adaptations rather than \"the evolutionary causes of psychological traits.\" Buller also argues that Daly and Wilson's 1985 Canadian sample included cases of sexual abuse as well as cases of unintentional omission, such as not buckling a child's seatbelt in the car. Buller asserts that unintentional omission does not fall under the realm of dangerous acts, and rather should be designated \"maltreatment\". He argues that since sexual abuse is not often accompanied by physical abuse, it is unreasonable to assume that it is motivated by the same kind of psychological mechanism as child homicide. Buller also points out that the conclusion that non-biological parents are more likely to abuse children is contradicted by the fact that even if the rate of abuse among stepparents was disproportionate, most child abuse is in fact committed by biological parents, and that the lowest rate of child abuse is found among adoptive parents. Daly and Wilson respond to Buller's criticism by stating that Buller confuses the empirical statistical findings, which define the Cinderella effect, with the proposed theoretical framework, which offers an evolutionary explanation for the data.\n\nBuller also argues that Daly and Wilson's findings are inherently biased since they use data from official documents, and the officials collecting that data are trained to take special notice of stepparents versus biological parents. Furthermore, Buller states that since Daly and Wilson rely on official reports (such as death certificates) for their data, and that this data is inherently biased against stepparents. He cites a Colorado study, in which it was found that maltreatment fatalities were more likely to be correctly reported on death certificates when an unrelated individual was the perpetrator rather than when a parent was the perpetrator, suggesting that the data is empirically skewed to support the Cinderella effect. According to this study, by Crume et al., when the perpetrator of the murder was a parent, maltreatment was correctly noted on the death certificate only 46 percent of the time. Furthermore, they found that when the perpetrator was an \"Other unrelated (including boyfriend)\" individual, maltreatment was reported on the death certificate 86 percent of the time, significantly higher than for parents. Although these statistics seem to provide evidence of bias against stepparents, further review of the data undermines this conclusion. As Crume et al. and Daly and Wilson note, maltreatment was only likely to be reported on the death certificates 47 percent of the time in the case of \"Other relatives (including step-parents),\" which represents a marginal increase from the amount of parental maltreatment. Therefore, as Daly and Wilson respond to Buller's critique, this does not seem to be a significant source of error in studying the Cinderella effect and does not provide evidence for inherent bias in their data.\n\nThe findings of Daly and Wilson have been called into question by one study of child homicides in Sweden between 1975 and 1995, which found that children living in households with a non-genetic parent were not at an increased risk of homicide when compared to children living with both genetic parents. The study, published in 2000 and conducted by Temrin and colleagues argued that when Daly and Wilson classified homicides according to family situation, they did not account for the genetic relatedness of the parent who actually committed the crime. In the Swedish sample, in two out of the seven homicides with a genetic and non-genetic parent, the offender was actually the genetic parent and thus these homicides do not support Daly and Wilson's definition of the Cinderella effect.\n\nDaly and Wilson attribute the contrasting findings of the Swedish study to an analytical oversight. Temrin and colleagues neglect to consider the fact that the proportion of children in living situations with a stepparent is not constant for all child age groups, but rather increases with age. After correcting for age differences, the Swedish data set produces results in accordance with the previous findings of Daly and Wilson. The Swedish sample does show, however, decreased risk to children living with a stepparent compared to the North American samples collected by Daly and Wilson, suggesting that there is some degree of cross-cultural variation in the Cinderella effect.\n\nIt has been noted by multiple researchers that child abuse is an intricate issue and is affected by other factors. Daly and Wilson state, however, that even if evolutionary psychology cannot account for every instance of stepparental abuse, this does not invalidate their empirical findings.\n\nBurgess and Drais propose that child maltreatment is too complex to be explained fully by genetic relatedness alone and cite other reasons for child maltreatment, such as social factors, ecological factors and child traits such as disability and age. However, they also note that these traits are simply indicative, and do not inevitably lead to child maltreatment. Temrin and colleagues also suggest that there may be other factors involved with child homicide, such as prior convictions, drug abuse problems, lost custody battles and mental health problems.\n\nIn 1984, Giles-Sims and David Finkelhor categorized and evaluated five possible hypotheses that could explain the Cinderella effect: \"social-evolutionary theory\", \"normative theory\", \"stress theory\", \"selection factors\", and \"resource theory\". The social-evolutionary theory is based on the proposal that non-genetically related parents will invest less in costly parental duties, due to the fact that their genes are not being passed on by that individual. The normative theory proposes that, due to genetic repercussions, incest among genetically related individuals is a widespread taboo and would thus be less common among biological relatives. They propose that incest among stepfamilies would be less taboo, since there is no risk of genetic degradation. The stress theory proposes that increased stressors, which are inherently more common among stepfamilies, cause an increased risk of abuse. The selection factors theory proposes that individuals who are likely to be stepparents (divorcees) are likely to be inherently more violent due to emotional disturbances, aggressive impulses, and self-esteem issues. Due to this, stepparents as a group would have a higher proportion of individuals with violent-prone characteristics, which would suggest that the abuse is happening due to personality factors, rather than the stepparental relationship directly. Finally, according to resource theory, individuals who contribute resources are granted authority, while individuals that lack resources are denied authority and more likely to resort to violence to obtain authority. It is therefore hypothesized that stepparents who are able to contribute resources to a family and have those resources be accepted by the family are less likely to be abusive. However, this hypothesis had yet to be tested directly on stepfamilies. This paper of Giles-Sims and Finkelhor predates however practically all empirical studies on the Cinderella effect.\n\nDiscussing the implications of this line of research, Australian psychologist Greg Tooley, author of a 2006 study confirming the existence of the effect, confessed that \"it is certainly difficult to talk about because it is such a hot issue\".\n\n\n"}
{"id": "1532957", "url": "https://en.wikipedia.org/wiki?curid=1532957", "title": "Cognitive load", "text": "Cognitive load\n\nIn cognitive psychology, cognitive load refers to the effort being used in the working memory. Cognitive load theory differentiates cognitive load into three types: intrinsic, extraneous, and germane.\n\n\"Intrinsic\" cognitive load is the effort associated with a specific topic, \"extraneous\" cognitive load refers to the way information or tasks are presented to a learner, and \"germane\" cognitive load refers to the work put into creating a permanent store of knowledge, or a schema.\n\nCognitive load theory was developed in the late 1980s out of a study of problem solving by John Sweller. Sweller argued that instructional design can be used to reduce cognitive load in learners.\nMuch later, other researchers developed a way to measure perceived mental effort which is indicative of cognitive load. \nTask-invoked pupillary response is a reliable and sensitive measurement of cognitive load that is directly related to working memory. Heavy cognitive load can have negative effects on task completion, and it is important to note that the experience of cognitive load is not the same in everyone. The elderly, students, and children experience different, and more often higher, amounts of cognitive load.\n\nHigh cognitive load in the elderly has been shown to affect their center of balance. With increased distractions, particularly from cell phone use, students are more prone to experiencing high cognitive load which can reduce academic success.\n\n\"Cognitive load theory has been designed to provide guidelines intended to assist in the presentation of information in a manner that encourages learner activities that optimize intellectual performance\". Sweller's theory employs aspects of information processing theory to emphasize the inherent limitations of concurrent working memory load on learning during instruction. It makes use of the schema as primary unit of analysis for the design of instructional materials.\n\nThe history of cognitive load theory can be traced to the beginning of Cognitive Science in the 1950s and the work of G.A. Miller. In his classic paper, Miller was perhaps the first to suggest our working memory capacity has inherent limits. His experimental results suggested that humans are generally able to hold only seven plus or minus two units of information in short-term memory. And in the early 1970s Simon and Chase were the first to use the term \"chunk\" to describe how people might organize information in short-term memory. This chunking of memory components has also been described as schema construction.\n\nIn the late 1980s John Sweller developed cognitive load theory (CLT) while studying problem solving. Studying learners as they solved problems, he and his associates found that learners often use a problem solving strategy called means-ends analysis. He suggests problem solving by means-ends analysis requires a relatively large amount of cognitive processing capacity, which may not be devoted to schema construction. Sweller suggests that instructional designers should prevent this unnecessary cognitive load by designing instructional materials which do not involve problem solving. Examples of alternative instructional materials include what are known as worked-examples and goal-free problems.\n\nIn the 1990s, cognitive load theory was applied in several contexts. The empirical results from these studies led to the demonstration of several learning effects: the completion-problem effect; modality effect; split-attention effect; worked-example effect; and expertise reversal effect.\n\nCognitive load theory provides a general framework and has broad implications for instructional design, by allowing instructional designers to control the conditions of learning within an environment or, more generally, within most instructional materials. Specifically, it provides empirically-based guidelines that help instructional designers decrease extraneous cognitive load during learning and thus refocus the learner's attention toward germane materials, thereby increasing germane (schema related) cognitive load. This theory differentiates between three types of cognitive load: intrinsic cognitive load, germane cognitive load, and extraneous cognitive load.\n\n\"Intrinsic cognitive load\" is the inherent level of difficulty associated with a specific instructional topic. The term was first used in the early 1990s by Chandler and Sweller. According to them, all instruction has an inherent difficulty associated with it (e.g., the calculation of 2 + 2, versus solving a differential equation). This inherent difficulty may not be altered by an instructor. However, many schemas may be broken into individual \"subschemas\" and taught in isolation, to be later brought back together and described as a combined whole.\n\n\"Extraneous cognitive load\" is generated by the manner in which information is presented to learners and is under the control of instructional designers. This load can be attributed to the design of the instructional materials. Because there is a single limited cognitive resource using resources to process the extraneous load, the amount of resources available to process the intrinsic load and germane load (i.e., learning) is reduced. Thus, especially when intrinsic and/or germane load is high (i.e., when a problem is difficult), materials should be designed so as to reduce the extraneous load.\n\nAn example of extraneous cognitive load occurs when there are two possible ways to describe a square to a student. A square is a figure and should be described using a figural medium. Certainly an instructor can describe a square in a verbal medium, but it takes just a second and far less effort to see what the instructor is talking about when a learner is shown a square, rather than having one described verbally. In this instance, the efficiency of the visual medium is preferred. This is because it does not unduly load the learner with unnecessary information. This unnecessary cognitive load is described as extraneous.\n\nChandler and Sweller introduced the concept of extraneous cognitive load. This article was written to report the results of six experiments that they conducted to investigate this working memory load. Many of these experiments involved materials demonstrating the split attention effect. They found that the format of instructional materials either promoted or limited learning. They proposed that differences in performance were due to higher levels of the cognitive load imposed by the format of instruction. \"Extraneous cognitive load\" is a term for this unnecessary (artificially induced) cognitive load.\n\n\"Germane cognitive load\" is the processing, construction and automation of schemas. It was first described by Sweller, Van Merriënboer and Paas in 1998. While intrinsic cognitive load is generally thought to be immutable (although techniques can be applied to manage complexity by segmenting and sequencing complex material), instructional designers can manipulate extraneous and germane load. It is suggested that they limit extraneous load and promote germane load.\n\nUntil the 1998 article by Sweller, Van Merriënboer & Paas, cognitive load theory primarily concentrated on the reduction of extraneous cognitive load. With this article, cognitive load researchers began to seek ways of redesigning instruction to redirect what would be extraneous load, to now be focused toward schema construction (germane load). Thus it is very important for instructional designers to \"reduce extraneous cognitive load and redirect learners' attention to cognitive processes that are directly relevant to the construction of schemas\".\n\nPaas and Van Merriënboer developed a construct (known as relative condition efficiency) which helps researchers measure perceived mental effort, an index of cognitive load. This construct provides a relatively simple means of comparing instructional conditions. It combines mental effort ratings with performance scores. Group mean z-scores are graphed and may be compared with a one-way Analysis of variance (ANOVA).\n\nPaas and Van Merriënboer used relative condition efficiency to compare three instructional conditions (worked examples, completion problems, and discovery practice). They found learners who studied worked examples were the most efficient, followed by those who used the problem completion strategy. Since this early study many other researchers have used this and other constructs to measure cognitive load as it relates to learning and instruction.\n\nThe ergonomic approach seeks a quantitative neurophysiological expression of cognitive load which can be measured using common instruments, for example using the heart rate-blood pressure product (RPP) as a measure of both cognitive and physical occupational workload. They believe that it may be possible to use RPP measures to set limits on workloads and for establishing work allowance.\n\nTask-invoked pupillary response is a form of measurement that directly reflects the cognitive load on working memory. Greater pupil dilation is found to be associated with high cognitive load. Pupil constriction occurs when there is low cognitive load. Task-invoked pupillary response shows a direct correlation with working memory, making it an effective measurement of cognitive load explicitly unrelated to learning.\n\nSome researchers have compared different measures of cognitive load. For example, Deleeuw and Mayer (2008) compared three commonly used measures of cognitive load and found that they responded in different ways to extraneous, intrinsic, and germane load.\n\nEstablished eye movement and pupillary response indicators of cognitive load are:\n\nEvidence has been found that individuals systematically differ in their processing capacity. For example, there are individual differences in processing capacities between novices and experts. Experts have more knowledge or experience with regard to a specific task which reduces the cognitive load associated with the task. Novices do not have this experience or knowledge and thus have heavier cognitive load.\n\nIt has been theorized that an impoverished environment can contribute to cognitive load. Regardless of the task at hand, or the processes used in solving the task, people who experience poverty also experience higher cognitive load. A number of factors contribute to the cognitive load in people with lower socioeconomic status that are not present in middle and upper-class people.\n\nIdentifying the processing capacity of individuals could be extremely useful in further adapting instruction (or predicting the behavior) of individuals. Accordingly, further research would clearly be desirable. First, it is essential to compute the memory load imposed by detailed analysis of the processes to be used. Second, it is essential to ensure that individual subjects are actually using those processes. The latter requires intensive pre-training.\n\nA heavy cognitive load typically creates error or some kind of interference in the task at hand. A heavy cognitive load can also increase stereotyping. Stereotyping is an extension of the Fundamental Attribution Error which also increases in frequency with heavier cognitive load. The notions of cognitive load and arousal contribute to the \"Overload Hypothesis\" explanation of social facilitation: in the presence of an audience, subjects tend to perform worse in subjectively complex tasks (whereas they tend to excel in subjectively easy tasks).\n\nThe danger of heavy cognitive load is seen in the elderly population. Aging can cause declines in the efficiency of working memory which can contribute to higher cognitive load. The relationship between heavy cognitive load and control of center of mass are heavily correlated in the elderly population. As cognitive load increases, the sway in center of mass in elderly individuals increases. Another study examined the relationship between body sway and cognitive function and their relationship during multitasking and found disturbances in balance led to a decrease in performance on the cognitive task Heavy cognitive load can disturb balance in elderly people. Conversely, an increasing demand for balance can increase cognitive load.\n\nWith the widespread acceptance of laptops in the classroom, an increasing cognitive load while in school is a major concern. With the use of Facebook and other social forms of communication, adding multiple tasks is hurting students performance in the classroom. When many cognitive resources are available, the probability of switching from one task to another is high and does not lead to optimal switching behavior. Both students who were heavy Facebook users and students who sat nearby those who were heavy Facebook users performed poorly and resulted in lower GPA.\n\nThe components of working memory as proposed by British psychologists, Alan Baddeley and Graham Hitch, are in place at 6 years of age. However, there is a clear difference between adult and child knowledge. These differences are due to developmental increases in processing efficiency. Children lack general knowledge, and this is what creates increased cognitive load in children. Children in impoverished families often experience even higher cognitive load in learning environments than those in middle-class families. These children do not hear, talk, or learn about schooling concepts because their parents often do not have formal education. When it comes to learning, their lack of experience with numbers, words, and concepts increases their cognitive load.\n\nAs children grow older they develop superior basic processes and capacities. They also develop metacognition, which helps them to understand their own cognitive activities. Lastly, they gain greater content knowledge through their experiences. These elements help reduce cognitive load in children as they develop.\n\nGesturing is a technique children use to reduce cognitive load while speaking. By gesturing, they can free up working memory for other tasks. Pointing allows a child to use the object they are pointing at as the best representation of it, which means they do not have to hold this representation in their working memory, thereby reducing their cognitive load. Additionally, gesturing about an object that is absent reduces the difficulty of having to picture it in their mind.\n\nBodily activity can both be advantageous and detrimental to learning depending on how this activity is implemented. Cognitive load theorists have asked for updates that makes CLT more compatible with insights from embodied cognition research. As a result, Embodied Cognitive Load Theory has been suggested as a means to predict the usefulness of interactive features in learning environments. In this framework, the benefits of an interactive feature (such as easier cognitive processing) need to exceed its cognitive costs (such as motor coordination) in order for an embodied mode of interaction to increase learning outcomes.\n\n\nFor those wishing to learn more about cognitive load theory, please consider reading these journals and special issues of those journals:\n\nFor ergonomics standards see:\n\n\n"}
{"id": "3272375", "url": "https://en.wikipedia.org/wiki?curid=3272375", "title": "Communication diagram", "text": "Communication diagram\n\nA communication diagram in the Unified Modeling Language (UML) 2.0, is a simplified version of the UML 1.x collaboration diagram.\n\nUML has four types of interaction diagrams:\n\nA Communication diagram models the interactions between objects or parts in terms of sequenced messages. Communication diagrams represent a combination of information taken from Class, Sequence, and Use Case Diagrams describing both the static structure and dynamic behavior of a system.\n\nHowever, communication diagrams use the free-form arrangement of objects and links as used in Object diagrams. In order to maintain the ordering of messages in such a free-form diagram, messages are labeled with a chronological number and placed near the link the message is sent over. Reading a communication diagram involves starting at message 1.0, and following the messages from object to object.\n\nCommunication diagrams show a lot of the same information as sequence diagrams, but because of how the information is presented, some of it is easier to find in one diagram than the other. Communication diagrams show which elements each one interacts with better, but sequence diagrams show the order in which the interactions take place more clearly.\n\n\n"}
{"id": "143151", "url": "https://en.wikipedia.org/wiki?curid=143151", "title": "Counterexample", "text": "Counterexample\n\nIn logic, and especially in its applications to mathematics and philosophy, a counterexample is an exception to a proposed general rule or law. For example, consider the proposition \"all students are lazy\". \nBecause this statement makes the claim that a certain property (laziness) holds for \"all\" students, even a \"single\" example of a diligent student will prove it false.\nThus, any hard-working student is a counterexample to \"all students are lazy\".\nMore precisely, a counterexample is a specific instance of the falsity of a universal quantification (a \"for all\" statement).\n\nIn mathematics, this term is (by a slight abuse) also sometimes used for examples illustrating the necessity of the full hypothesis of a theorem, by considering a case where a part of the hypothesis is not verified, and where one can show that the conclusion does not hold.\n\nIn mathematics, counterexamples are often used to prove the boundaries of possible theorems. By using counterexamples to show that certain conjectures are false, mathematical researchers avoid going down blind alleys and learn how to modify conjectures to produce provable theorems.\n\nSuppose that a mathematician is studying geometry and shapes, and she wishes to prove certain theorems about them. She conjectures that \"All rectangles are squares\". She can either attempt to prove the truth of this statement using deductive reasoning, or if she suspects that her conjecture is false, she might attempt to find a counterexample. In this case, a counterexample would be a rectangle that is not a square, like a rectangle with two sides of length 5 and two sides of length 7. However, despite having found rectangles that were not squares, all the rectangles she did find had four sides. She then makes the new conjecture \"All rectangles have four sides\". This is weaker than her original conjecture, since every square has four sides, even though not every four-sided shape is a square.\n\nThe previous paragraph explained how a mathematician might weaken her conjecture in the face of counterexamples, but counterexamples can also be used to show that the assumptions and hypothesis are needed. Suppose that after a while the mathematician in question settled on the new conjecture \"All shapes that are rectangles and have four sides of equal length are squares\". This conjecture has two parts to the hypothesis: the shape must be 'a rectangle' and 'have four sides of equal length' and the mathematician would like to know if she can remove either assumption and still maintain the truth of her conjecture. So she needs to check the truth of the statements: (1) \"All shapes that are rectangles are squares\" and (2) \"All shapes that have four sides of equal length are squares\". A counterexample to (1) was already given, and a counterexample to (2) is a non-square rhombus. Thus the mathematician sees that both assumptions were necessary.\n\nA counterexample to the statement \"all prime numbers are odd numbers\" is the number 2, as it is a prime number but is not an odd number. Neither of the numbers 7 or 10 is a counterexample, as neither contradicts the statement. In this example, 2 is the only possible counterexample to the statement, but only a single example is needed to contradict \"\"All\" prime numbers are odd numbers\". Similarly the statement \"All natural numbers are either prime or composite\" has the number 1 as a counterexample as 1 is neither prime nor composite.\n\nEuler's sum of powers conjecture was disproved by counterexample. It asserted that at least \"n\" \"n\" powers were necessary to sum to another \"n\" power. The conjecture was disproved in 1966 with a counterexample involving \"n\" = 5; other \"n\" = 5 counterexamples are now known, as are some \"n\" = 4 counterexamples.\n\nWitsenhausen's counterexample shows that it is not always true for control problems that a quadratic loss function and a linear equation of evolution of the state variable imply optimal control laws that are linear.\n\nOther examples include the disproofs of the Seifert conjecture, the Pólya conjecture, the conjecture of Hilbert's fourteenth problem, Tait's conjecture, and the Ganea conjecture.\n\nIn philosophy, counterexamples are usually used to argue that a certain philosophical position is wrong by showing that it does not apply in certain cases. Unlike mathematicians, philosophers cannot prove their claims beyond any doubt, so other philosophers are free to disagree and try to find counterexamples in response. Of course, now the first philosopher can argue that the alleged counterexample does not really apply.\n\nAlternatively, the first philosopher can modify their claim so that the counterexample no longer applies; this is analogous to when a mathematician modifies a conjecture because of a counterexample.\n\nFor example, in Plato's \"Gorgias\", Callicles, trying to define what it means to say that some people are \"better\" than others, claims that those who are stronger are better.\n\nBut Socrates replies that, because of their strength of numbers, the class of common rabble is stronger than the propertied class of nobles, even though the masses are prima facie of worse character. Thus Socrates has proposed a counterexample to Callicles' claim, by looking in an area that Callicles perhaps did not expect — groups of people rather than individual persons.\n\nCallicles might challenge Socrates' counterexample, arguing perhaps that the common rabble really are better than the nobles, or that even in their large numbers, they still are not stronger. But if Callicles accepts the counterexample, then he must either withdraw his claim or modify it so that the counterexample no longer applies. For example, he might modify his claim to refer only to individual persons, requiring him to think of the common people as a collection of individuals rather than as a mob.\n\nAs it happens, he modifies his claim to say \"wiser\" instead of \"stronger\", arguing that no amount of numerical superiority can make people wiser.\n\n\n"}
{"id": "44701366", "url": "https://en.wikipedia.org/wiki?curid=44701366", "title": "Directed evolution (transhumanism)", "text": "Directed evolution (transhumanism)\n\nThe term directed evolution is used within the transhumanist community to refer to the idea of applying the principles of directed evolution and experimental evolution to the control of human evolution. In this sense, it is distinct from the use of the term in biochemistry, which refers only to the evolution of proteins and RNA. Maxwell J. Melhmanh has described directed evolution of humans as the Holy Grail of transhumanism.\nOxford philosopher Julian Savulescu wrote that:\nAccording to UCLA biophysicist Gregory Stock:\nRiccardo Campa, from the Institute for Ethics and Emerging Technologies, wrote that \"self-directed evolution\" can be coupled with many different political, philosophical, and religious views.\n\nAndrew Askland, from the Sandra Day O'Connor College of Law claims that referring to transhumanism as directed evolution is problematic because evolution is ateleological and transhumanism is teleological.\n\nParticipant evolution is an alternative term that refers to the process of deliberately redesigning the human body and brain using technological means, rather than through the natural processes of mutation and natural selection, with the goal of removing \"biological limitations\" and human enhancement. The idea of participant evolution was first put forward by Manfred Clynes and Nathan S. Kline in the 1960s in their article \"Cyborgs and Space\", where they argued that the human species was already on a path of participant evolution. Science fiction writers have speculated what the next stage of such participant evolution will be.\n\nWhilst Clynes and Kline saw participant evolution as the process of creating cyborgs, the idea has been adopted and propounded by transhumanists who argue that individuals should have the choice of using human enhancement technologies on themselves and their children, to progressively become transhuman and ultimately posthuman, as part of a voluntary regimen of participant evolution.\n"}
{"id": "1559185", "url": "https://en.wikipedia.org/wiki?curid=1559185", "title": "Discrete trial training", "text": "Discrete trial training\n\nDiscrete trial training (DTT; also called discrete trial instruction or DTI) is a technique used by practitioners of applied behavior analysis (ABA) that was developed by Ivar Lovaas at the University of California, Los Angeles (UCLA). DTT is a practitioner-led, structured instructional procedure that breaks tasks down into simple subunits to shape new skills. Often employed up to 6–7 hours per day for children with autism, the technique relies on the use of prompts, modeling, and positive reinforcement strategies to facilitate the child's learning. It is also noted for its previous use of aversives to punish unwanted behaviors.\n\nLovaas spent most of his career conducting groundbreaking research on the use of this methodology to teach autistic children. As of 2005, two studies have shown that most children with autism under the age of 5 who received structured early intensive behavioral intervention (EIBI), or 35–40 hours per week of DTT, had gained significant language, intellectual, and adaptive skills. The first, a seminal study by Lovaas (1987) reported that 47% of such children acquired typical language and academic skills, and were placed into mainstream classrooms at age 7. Follow-up measures in 1993 showed that nearly each \"were indistinguishable from average children on tests of [social], intelligence, and adaptive behavior.\" The study, later, received praise in a mental health report by the US Surgeon General in 1999.\n\nSince 2009, the American Academy of Pediatrics identified EIBI and the early start denver model (ESDM)—a comprehensive early intervention that consists of both developmental, play therapy and naturalistic ABA—as the only evidence-based clinical interventions for the population. While EIBI is \"well-established,\" the ESDM is \"emerging.\"\n\nThe Lovaas approach is a highly structured comprehensive program that relies heavily on discrete trial training (DTT) methods. Within Lovaas therapy, DTT is used to reduce stereotypical autistic behaviours through extinction and the provision of socially acceptable alternatives to self-stimulatory behaviors. Intervention can start when a child is as young as three and can last from two to six years. Progression through goals of the program are determined on an individual basis and are not determined by which year the client has been in the program. The first year seeks to reduce self-stimulating (\"stimming\") behavior, teaches imitation, establishes playing with toys in their intended manner, and integration of the family into the treatment protocol. The second year teaches early expressive and abstract linguistic skills, peer interaction, basic socializing skills, and strives to include the individual's community in the treatment to optimize mainstreaming while eliminating any possible sources of stigmatization. The third year focuses on emotional expression and variation in addition to observational learning, and pre-academic skills such as reading writing, and arithmetic. Rarely is the technique implemented for the first time with adults.\n\nThe Lovaas method is ideally performed five to seven days a week with each session lasting from five to seven hours, totaling an average of 35–40 hours per week. Each session is divided into trials with intermittent breaks. The trials do not have a specified time limit to allow for a natural conclusion when the communicator feels the child is losing focus. Each trial is composed of a series of prompts (verbal, gestural, physical, etc.) that are issued by the \"communicator\" who is positioned directly across the table from the individual receiving treatment.\nThese prompts can range from \"put in\",\" put on\",\" show me\",\" give to me\" and so on, in reference to an object, color, simple imitative gesture, etc. The concept is centered on shaping the child to correctly respond to the prompts, increasing the attentive ability of the individual, and mainstreaming the child for academic success. Should the child fail to respond to a prompt, a \"prompter,\" seated behind the child, uses either a partial-, a simple nudge or touch on the hand or arm or a full-, hand over hand assistance until the prompt has been completed, physical guide to correct the individual's mistake or non-compliance. Each correct response is reinforced with verbal praise, an edible, time with a preferred toy, or any combination thereof. DTT is often used in conjunction with the Picture Exchange Communication System (PECS) as it primes the child for an easy transition between treatment types. The PECS program serves as another common intervention technique used to mainstream individuals with autism. As many as 25% of individuals with autism have no functional speech, the remainder typically display pronounced phonological and grammatical deficits in addition to a limited vocabulary. The program teaches spontaneous social communication through symbols and/or pictures by relying on ABA techniques. PECS operates on a similar premise to DTT in that it uses systematic chaining to teach the individual to pair the concept of expressive speech with an object. It is structured in a similar fashion to DTT, in that each session begins with a preferred reinforcer survey to ascertain what would most motivate the child and effectively facilitate learning.\n\nMore than 500 articles have been published showing the effectiveness of the Lovaas technique for children with autism. Questions concerning the effectiveness of the method involve reports of recovery from autism, based on the intervention.\n\nThe Lovaas technique was developed based on research performed by Ivar Lovaas and his assistants. This research reported that 47% of those children who had received the Lovaas treatment protocol of an average of 40 hours of intensive therapy, were mainstreamed into regular classrooms, and were classified as \"indistinguishable\" from their peers in follow-up studies. Although subsequent studies have shown that intensive behavioral therapy clearly benefited children with autism, it has been claimed that Lovaas's original claims of effectiveness were overstated. A 2005 California study found that early intensive behavioral intervention (EIBI), the Lovaas technique used for very young children, was substantially more effective for preschool children with autism than the mixture of methods provided in many programs. However, this study did not use random assignment or a uniform assessment protocol, and provided limited information about the intervention, making it difficult to replicate.\n\nSmith et al. (2002) performed a preliminary study of nine high-functioning children with autism, all of whom were previous recipients of early intensive behavioral intervention (EIBI), of ages five to seven in free play settings. The purpose was to assess the effects of EIBI on solitary activities, ritualistic behaviors, and social activity when exposed to the two experimental groups. Each child participated in four one-hour sessions consisting of 15 minute periods of play with either a typically developing peer or a lower functioning child with autism who had major deficits in pragmatic communication, social interaction and self-care. The children had never met prior to these experimental sessions. The period of play began with 15 minutes of play with either the typically developed (TD) peer or the developmentally disabled (DD) peer, and alternated accordingly in one of two variations: TD-DD-TD-DD or DD-TD-DD-TD. Observers rated play on five criteria: i. interactive toy play, ii. interactive speech, iii. solitary toy play, iv. solitary speech, and v. self-stimulation. Data showed the high-functioning children displayed significantly more instances of interactive play and interactive speech when paired with the typically developed peer.\n\nThe Lovaas technique is best generalized when paired with natural settings, and the implementation is clearly structured. A good sense of direction is needed when planning for intervention. Although this is one approach, many children on the autism spectrum learn differently and this needs to be taken into account to ensure the Lovaas approach is effective for all. It has been shown that, for some children with autism, typical peer interaction can increase the chance of leading a normal life. Lovaas techniques are cost effective for administrators.\n\nWhile the therapy has always relied principally on positive reinforcement of preferred behavior, Lovaas's original technique also included more extensive use of aversives such as striking, shouting, or using electrical shocks. These procedures have been widely abandoned for over a decade. A review of literature by autistic activist Michelle Dawson asserts that the method has become less effective since these stimuli were abandoned. Only one institution, the Judge Rotenberg Center, still employs electric shocks as aversives—a practice that continues to cause them considerable legal and political controversy. This has led some to question whether the use of aversives by those in behavioral institutions should be limited to those who are licensed (see licensed behavior analyst). \n\nA concern that parents have brought up regarding Lovaas is the cost, which in April 2002 amounted to about US$4,200 per month ($50,000 annually per child). In addition, the 20–40 hours per week intensity of the program, often conducted at home, may place additional stress on already challenged families.\n\nAnother study estimated the expenses of a three-year period of DTT to total a conservative cost of $20,000 and the extreme cost of $60,000, with a yearly average of $40,000. These costs were based on a sliding scale model that would be adjusted accordingly to socio-economic status and parental involvement. Yearly expenditures were predicted to drop to an average of $22,500 a year when parents and family became involved in the process. Additional family involvement would subsequently alleviate case manager and paraprofessional hours by assuming their roles in the process. The upfront costs of DTT for the state of Texas would initially amount to $67,500 for three years compared to the currently state budgeted $33,000 for Special Education. The difference is predicted to be recovered within five years of the initial implementation of the program. Texas would experience a 72% reduction in expenses in the 15 year offset following the conclusion of DTT, amounting to a total savings of $84,300 per child.\n\nHowever, in the United States, the Individuals with Disabilities Education Act (IDEA) requires school districts to provide a Free and Appropriate Public Education (FAPE) to \"all\" children over the age of three. Many administrative rulings and court decisions have found 35–40 hours per week of EIBI to be FAPE. Parents may wish to consider hiring an attorney or advocate if their school district denies EIBT.\n\nThomas et al. (2007) conducted a survey study that involved 383 families with children diagnosed with autism spectrum disorder from North Carolina. Three quarters of these families reported using a major treatment plan. Of these, college or graduate degree holding parents were two to four times more likely to use a neurologist and/or PECS. Annual incomes of $50,000 or more had higher rates of using developmental pediatricians and speech/language therapists. Racial and ethnic minorities were half as likely to see a case manager. These families also had a quarter of the odds of seeing a psychologist, developmental pediatrician, or implementing sensory integration. This supports several other national studies that concluded racial and ethnic families, parents with a low degree of education, and those not residing in a metropolitan area were more likely to receive limited care, utilize a less diverse range of services and less likely to follow a major treatment plan. Both the national studies and the North Carolinian study yielded a correlation between high stress levels and amount of services sought.\n\nFamilies that did not identify with a major treatment approach had one fifth to one half the odds of using support of friends and family in providing care. Therapeutic support services (PECS, parent support classes, sensory integration, casein- and gluten-free diets) were also one fifth to one half as likely to be used compared to families identifying with major treatment plans.\n\nInsurance coverage is another major determinant in the amount of support services received. Recipients of Medicaid or other forms of public health insurance have 2-11 times the odds of using services that are considered medically necessary. Utilization of respite, PECS, case managers, speech or language therapists also increases markedly in this bracket compared to families with private insurance.\n\nRising costs in education and the provision of adequate care for developmentally disabled individuals have been a continuing concern for state policy makers and tax payers alike. A study was conducted on cost comparison of 18 years of traditional Special Education on Early Intensive Behavioral Intervention (EIBI) for children with autism. The Texas state budget for the year 2002 allotted $11,000 per child for Special Education. The study suggested the state would save an average of $208,500 per child over an 18-year period by implementing DTT in early childhood, effectively curbing or eliminating future special needs costs by preparing the child academically for mainstreaming. This amounted to a potential total savings of $2.9 billion over an 18-year period for a cohort consisting of 10,000 children with autism.\n\nGresham and MacMillar (1998) specifically cite a lack of a true experimental design in Lovaas' (1987) experiment on early intervention. They charge that he instead implemented a quasi-experimental design of matched pairs regarding the distribution of subjects within the experimental and control groups. Gresham and MacMillar (1998) also state a lack of a true representation of autism in that the subjects were neither randomly sampled from the population of individuals with autism nor were they randomly assigned to treatment groups. The internal validity of the study was also called into question due to the possibility of skewed data resulting from three influential threats. Instrumentation, changes or variations in measurement of procedures over time, was argued to have been altered in both the pre-test and post-test conditions which were confounded by a differentiation in ascertaining cognitive abilities and intelligence of the subjects. The pre-test utilized four measures of cognitive ability and mental development. Five of the subjects' intelligence was determined through a parent-reported measure of adaptive behavior. All of the subjects were post-tested three years later using five other measures of intelligence and cognitive ability. Long-term follow-up was assessed with three measurements of (1) intelligence, (2) nonverbal reasoning, and (3) receptive language. The original three measurements during the testing phase were determined by (1) IQ score, (2) class placement, and (3) promotion/retention. External validity was called into question concerning sample characteristics. Lovaas' (1987) criteria for acceptance into the program required a psychological mental age greater than 11 months and a chronological age less than 46 months in the case of echolalic children. Schopler et al. (1989) purport that if both the intellectual and echolalia criteria were rigidly adhered to at the North Carolina institute, approximately 57% of the referrals would have been excluded from the program.\n\nOther criticisms include a failure to operationally define the use of the term 'reinforcement' for compliance, the use of a Pro-rated Mental Age, and the statistical regression of the child's IQ over time. Boyd (1998) addressed the potential impact of a disproportionate sex ratio of females to males on the control group's mean IQ score. One study showed females with autism displayed slightly lower levels of functioning in comparison to their male counterparts.\n\nIn a rejoinder to Boyd's (1998) article that cited an unequal sex ratio as a source of error, Lovaas (1998) listed three reasons as to why the disproportionate ratio's influence on the data was negligible. The autistic population at the time had a ratio of 4:1. Lovaas (1998) argued that the ratios for the experimental group, control group 1, and control group 2 of 16:3, 11:8, and 16:5, respectively, were in fact near the expected ratio scale of the general population with the exception of control group 1. The second argument lay in the studies Boyd (1998) referenced in regards to low intellectual performance in females diagnosed with autism. One of the studies admitted to having a female subject with Rett disorder, a condition that showed little responsiveness to intensive early behavioral intervention. Lovaas (1998) concluded by proposing that males may more readily meet diagnostic criteria for autism because of certain salient characteristics inherent in the sex while the subtleties in their female counterparts may be overlooked.\n\n\n"}
{"id": "5424970", "url": "https://en.wikipedia.org/wiki?curid=5424970", "title": "Ecological validity (perception)", "text": "Ecological validity (perception)\n\nThe ecological validity of a sensory cue in perception is the correlation between the cue (something an organism might be able to measure from the proximal stimulus) and a property of the world (some aspect of the distal stimulus). For example, the color of a banana is a cue that indicates whether the banana is ripe. This particular cue has an ecological validity close to 1, because a banana's ripeness is highly correlated with its color. By contrast, the presence of a sticker on the banana is a cue with an ecological validity close to 0, if (as seems likely) ripe and unripe bananas (in a fruit bowl, say) are equally likely to have stickers on them.\n\nThe concept of ecological validity is closely related to likelihood in Bayesian statistical inference and to cue validity in statistics.\n\nEgon Brunswik defined the term \"ecological validity\" in the 1940s to describe a cue's informativeness. His students have written that the now-common use of \"ecological validity\" to describe a type of experimental validity was a corruption of his original terminology (see external link to paper by Hammond). Brunswik used the words \"representative design\" to describe what is now usually called the external validity of an experiment; this in turn depends partly on what is now usually called the ecological validity of the experiment. As originally defined by Brunswik, however, ecological validity was a property of a cue, not a property of an experiment.\n\n"}
{"id": "379031", "url": "https://en.wikipedia.org/wiki?curid=379031", "title": "Education in Japan", "text": "Education in Japan\n\nEducation in Japan is compulsory at the elementary and lower secondary levels. Most students attend public schools through the lower secondary level, but private education is popular at the upper secondary and university levels.\n\nEducation prior to elementary school is provided at kindergartens and day-care centers. Public and private day-care centers take children from under age 1 on up to 5 years old. The programmes for those children aged 3–5 resemble those at kindergartens. The educational approach at kindergartens varies greatly from unstructured environments that emphasize play to highly structured environments that are focused on having the child pass the entrance exam at a private elementary school. The academic year starts from April and ends in March, having summer vacation in August and winter vacation in the end of December to the beginning of January. Also, there are few days of holidays between academic years. The period of academic year is the same all through elementary level to higher educations nationwide.\n\nJapanese students consistently rank highly among OECD students in terms of quality and performance in reading literacy, math, and sciences. The average student scored 540 in reading literacy, maths and science in the OECD’s Programme for International Student Assessment (PISA) and the country has one of the world's highest-educated labour forces among OECD countries. Its populace is well educated and its society highly values education as a platform for social mobility and for gaining employment in the country's high-tech economy. The country's large pool of highly educated and skilled individuals is largely responsible for ushering Japan’s post-war economic growth. Tertiary-educated adults in Japan, particularly graduates in sciences and engineering, benefit economically and socially from their education and skills in the country's high tech economy. Spending on education as a proportion of GDP is below the OECD average. Although expenditure per student is comparatively high in Japan, total expenditure relative to GDP remains small. In 2015, Japan’s public spending on education amounted to just 3.5 percent of its GDP, below the OECD average of 4.7%. In 2014, the country ranked fourth for the percentage of 25- to 64-year-olds that have attained tertiary education with 48 percent. In addition, bachelor's degrees are held by 59 percent of Japanese aged 25–34, the second most in the OECD after South Korea. As the Japanese economy is largely scientific and technological based, the labor market demands people who have achieved some form of higher education, particularly related to science and engineering in order to gain a competitive edge when searching for employment opportunities. About 75.9 percent of high school graduates attended a university, junior college, trade school, or other higher education institution.\n\nJapan's education system played a central part in Japan's recovery and rapid economic growth in the decades following the end of World War II. After World War II, the Fundamental Law of Education and the School Education Law were enacted. The latter law defined the school system that would be in effect for many decades: six years of elementary school, three years of junior high school, three years of high school, and two or four years of university.\nAlthough Japan ranks highly on the PISA tests, its educational system has been criticized for its focus on standardized testing and conformity; bullying problems; and its strong academic pressure on students.\n\nFormal education in Japan began with the adoption of Chinese culture, in the 6th century. Buddhist and Confucian teachings as well as sciences, calligraphy, divination and literature were taught at the courts of Asuka, Nara and Heian. Scholar officials were chosen through an Imperial examination system. But contrary to China, the system never fully took hold and titles and posts at the court remained hereditary family possessions. The rise of the \"bushi\", the military class, during the Kamakura period ended the influence of scholar officials, but Buddhist monasteries remained influential centers of learning.\n\nIn the Edo period, the Yushima Seidō in Edo was the chief educational institution of the state; and at its head was the \"Daigaku-no-kami\", a title which identified the leader of the Tokugawa training school for shogunate bureaucrats.\n\nUnder the Tokugawa shogunate, the daimyō vied for power in the largely pacified country. Since their influence could not be raised through war, they competed on the economic field. Their warrior-turned-bureaucrat Samurai elite had to be educated not only in military strategy and the martial arts, but also agriculture and accounting. Likewise, the wealthy merchant class needed education for their daily business, and their wealth allowed them to be patrons of arts and science. But temple schools (terakoya) educated peasants too, and it is estimated that at the end of the Edo period 50% of the male and 20% of the female population possessed some degree of literacy. Even though contact with foreign countries was restricted, books from China and Europe were eagerly imported and Rangaku (\"Dutch studies\") became a popular area of scholarly interest.\n\nThere were facilities that were created to specifically educate samurai and their children to perpetuate morality and mindfulness of their class. These schools, hanko schools, were where scholars would bring together samurai to listen to lectures on Confucianism, military arts, and other subjects. Samurai would then attempt to teach villagers what they had learned, “proper guidance to the common people’s spirit and manners,” by posting flyers and creating handbooks . Some Shogun and Daimyo were also interested in spreading education throughout their protected land with the target audience as adult commoners and children. Elementary education was imparted as well as writing and morality lessons. The Shirakawa Village School’s town bulletin explains the point of education for the commoners, “If not only the important people of the village but also the lesser people have continuous teaching from the appointed village schools, they will gain understanding” . ‘Commoners’ would also form many communal gatherings to attempt and Englishmen themselves with the help of a scholar. To name one, Baigan Ishida, who was a great orator and writer that reached the outcropping of the merchant class. There were wakashu-gumi, or youth groups, that consisted of young men ages fourteen to seventeen, who at these groups learned about ceremonies, cooperative living, language, manners, marriage, straw weaving, and world information, not to mention talking and singing. Japan was thriving with the want for enlightenment. One may say the need for more education is one of the reasons why the Tokugawa Shogunate failed in 1868. \n\nAfter the Meiji Restoration of 1868, the methods and structures of Western learning were adopted as a means to make Japan a strong, modern nation. Students and even high-ranking government officials were sent abroad to study, such as the Iwakura mission. Foreign scholars, the so-called \"o-yatoi gaikokujin\", were invited to teach at newly founded universities and military academies. Compulsory education was introduced, mainly after the Prussian model. In order to aid in the modernization the country, the Meiji government built a public library in 1872 modeled after Western architecture. The Japan Library Association (or the JLA) was founded in 1892 to promote the library. However, public education became the main focus of the Meiji government before they could strengthen the library’s presence in 1899. By 1890, only 20 years after the resumption of full international relations, Japan discontinued employment of the foreign consultants.\n\nA modern concept of childhood emerged in Japan after 1850 as part of its engagement with the West. Meiji period leaders decided the nation-state had the primary role in mobilizing individuals - and children - in service of the state. The Western-style school was introduced as the agent to reach that goal. By the 1890s, schools were generating new sensibilities regarding childhood. After 1890 Japan had numerous reformers, child experts, magazine editors, and well-educated mothers who bought into the new sensibility. They taught the upper middle class a model of childhood that included children having their own space where they read children's books, played with educational toys and, especially, devoted enormous time to school homework. These ideas rapidly disseminated through all social classes.\n\nAfter the defeat in World War II, the Allied occupation government set education reform as one of its primary goals, to eradicate militarist teachings and convert Japan into a pacifist democracy. Nine years of education was made mandatory, with six years in elementary education and three in junior high as an emulation of the American educational system. A number of reforms were carried out in the post-war period that aimed at easing the burden of entrance examinations, promoting internationalization and information technologies, diversifying education and supporting lifelong learning.\n\nIn an effort to ease Japanese postwar sentiments, any nationalistic, militaristic, authoritarian, or anti-American content was blackened from learning materials. This practice was known as \"suminuru\", and was used as the primary method of educational reform until newly fashioned texts, Kuni no ayumi (Footsteps of the Nation), Nihon rekishi (Japanese History), and Minshushugi (Democracy) were written by the Ministry of Education and Civil Information and Education Section. The Ministry of Education is now known as the Ministry of Education, Culture, Sports, Science and Technology (MEXT) and is responsible for educational administration.\n\nIn successive international assessment tests, Japan's fourth- and eighth-grade students have consistently ranked in the top five globally in both mathematics and science (see TIMSS).\n\nDespite concerns that academic skills for Japanese students may have declined since the mid-1990s, Japan's students showed a significant improvement in math and science scores in the 2011 TIMSS survey, compared to the 2007 scores.\n\nThe school year in Japan begins in April and classes are held from Monday to either Friday or Saturday, depending on the school. The school year consists of two or three terms, which are separated by short holidays in spring and winter, and a six-week-long summer break.\n\nThe year structure is summarized below:\n\nLower secondary school covers grades seven through nine, with children typically aged twelve through fifteen. There are 3.5 million primary school students in Japan as of 2012, down from over 5.3 million in 1990. However, the number of junior high schools has remained relatively static, falling from 11,275 in 1990 to 10,699 in 2012. The number of junior high school teachers has also changed little, with 257,605 junior high school teachers in 1990, and 253,753 in 2012). Approximately 8% of junior high students attend a private junior high school (accounting for 7% of all junior high schools). Private schools are considerably more expensive: as of 2012, the average annual cost of private primary school attendance was ¥1,295,156 per student, roughly thrice the ¥450,340 cost for a public school. Japan's compulsory education ends at grade nine, but less than 2% drop out; 60% of students advanced to senior education as of 1960, increasing rapidly to over 90% by 1980, rising further each year until reaching 98.3% as of 2012.\n\nTeachers often major in their respective subjects, and more than 80% graduate from a four-year college. Classes are large, with an average of thirty-eight students per class, and each class is assigned a homeroom teacher, doubling as a counselor. Unlike kindergarten students, primary school students have different teachers for different subjects. However, the teacher changes rooms for each period, rather than the students.\n\nInstruction in primary schools is often in the form of lectures. Teachers also use other media, such as television and radio, and there is some laboratory work. By 1989 about 45% of all public primary schools had computers, including schools that used them only for administrative purposes. All course contents are specified in the Course of Study for Lower-Secondary Schools. Some subjects, such as Japanese language and mathematics, are coordinated with the elementary curriculum. Others, such as foreign-language study, begin at this level, though from April 2011, English became a compulsory part of the elementary school curriculum. The junior school curriculum covers Japanese language, social studies, mathematics, science, music, fine arts, health, and physical education. All students are also exposed to industrial arts and homemaking. Moral education and special activities continue to receive attention. Most students also participate in one of a range of school clubs that occupy them until around 6 p.m. most weekdays (including weekends and often before school as well), as part of an effort to address juvenile delinquency.\n\nA growing number of primary school students also attend \"juku\", private extracurricular study schools, in the evenings and on weekends. A focus by students upon these other studies and the increasingly structured demands upon students' time have been criticized by teachers and in the media for contributing to a decline in classroom standards and student performance in recent years.\n\nThe ministry recognizes a need to improve the teaching of all foreign languages, especially English. To improve instruction in spoken English, the government invites many young native speakers of English to Japan to serve as assistants to school boards and prefectures under its Japan Exchange and Teaching Program (JET). Beginning with 848 participants in 1987, the program grew to a high of 6,273 participants in 2002. The program was in a decline in recent years due to several factors, including shrinking local school budgets funding the program, as well as an increasing number of school boards hiring their foreign native speakers directly or through lower-paying, private agencies. Today, the program is again growing due to English becoming a compulsory part of the elementary school curriculum in 2011.\n\nThough upper-secondary school is not compulsory in Japan, 94% of all junior high school graduates enrolled as of 2005. Private upper-secondary schools account for about 55% of all upper-secondary schools, and neither public nor private schools are free. The Ministry of Education estimated that annual family expenses for the education of a child in a public upper-secondary school were about ¥300,000 in the 1980s and that private upper-secondary schools were about twice as expensive.\n\nThe most common type of upper-secondary school has a full-time, general program that offered academic courses for students preparing for higher education as well as technical and vocational courses for students expecting to find employment after graduation. More than 70% of upper-secondary school students were enrolled in the general academic program in the late 1980s. A small number of schools offer part-time programs, evening courses, or correspondence education.\n\nThe first-year programs for students in both academic and commercial courses are similar. They include basic academic courses, such as Japanese language, English, mathematics, and science. In upper-secondary school, differences in ability are first publicly acknowledged, and course content and course selection are far more individualized in the second year. However, there is a core of academic material throughout all programs.\n\nVocational-technical programs includes several hundred specialized courses, such as information processing, navigation, fish farming, business, English, and ceramics. Business and industrial courses are the most popular, accounting for 72% of all students in full-time vocational programs in 1989.\n\nMost upper-secondary teachers are university graduates. Upper-secondary schools are organized into departments, and teachers specialize in their major fields although they teach a variety of courses within their disciplines. Teaching depends largely on the lecture system, with the main goal of covering the very demanding curriculum in the time allotted. Approach and subject coverage tends to be uniform, at least in the public schools.\n\nTraining of disabled students, particularly at the upper-secondary level, emphasizes vocational education to enable students to be as independent as possible within society. Vocational training varies considerably depending on the student's disability, but the options are limited for some. It is clear that the government is aware of the necessity of broadening the range of possibilities for these students. Advancement to higher education is also a goal of the government, and it struggles to have institutions of higher learning accept more students with disabilities.\n\nHigher education in Japan is provided at universities (daigaku), junior colleges (tanki daigaku), colleges of technology (koto senmon gakko) and special training schools and community colleges (senshu gakko). Of these four types of institutions, only universities and junior colleges are strictly considered postsecondary education providers.\n\nAs of 2010, more than 2.8 million students were enrolled in 778 universities. At the top of the higher education structure, these institutions provide a four-year training leading to a bachelor's degree, and some offer six-year programs leading to a professional degree. There are two types of public four-year colleges: the 86 national universities (including the Open University of Japan) and the 95 local public universities, founded by prefectures and municipalities. The 597 remaining four-year colleges in 2010 were private. With a wealth of opportunities for students wishing to pursue tertiary education, the nation’s prestigious schools are the most appealing for students seeking to gain top employment prospects.\n\nThe overwhelming majority of college students attend full-time day programs. In 1990 the most popular courses, enrolling almost 40 percent of all undergraduate students, were in the social sciences, including business, law, and accounting. Other popular subjects were engineering (19 percent), the humanities (15 percent), and education (7 percent).\n\nThe average costs (tuition, fees, and living expenses) for a year of higher education in 1986 were ¥1.4 million. To help defray expenses, students frequently work part-time or borrow money through the government-supported Japan Scholarship Association. Assistance is also offered by local governments, nonprofit corporations, and other institutions.\n\nAccording to the \"Times Higher Education Supplement\" and École des Mines de Paris, the top-ranking universities in Japan are the University of Tokyo and Kyoto University.\n\nThe QS Asia University Rankings Top 40 included the University of Tokyo at 13th position,Tokyo Institute of Technology at 14th, Osaka University at 15th, Kyoto University at 17th, Tohoku University at 20th, Nagoya University at 27th, Kyushu University at 29th, Keio University at 36th, Waseda University at 39th, and the University of Tsukuba at 40th.\n\nBased on the 2011 Times Higher Education–QS World University Rankings, there are 33 Japanese universities in the top 100 Asian university rankings.\n\nThe Japanese educational system is supplemented by a heavy emphasis on extracurricular activities, also known as shadow education, which are any educational activities that don't take place during formal schooling. This is largely motivated by the extreme weight that is placed upon formal examinations as a prerequisite to attend university, something that is seen as integral to their future career and social status. In order to gain a competitive edge, Japanese families are willing to expend money and have their child put in time and effort into a supplementary education. Forms of shadow education include \"mogi shiken\", which are practice exams given by private companies that determine the child's chances of getting into a university. \"Juku\" are private after school classes that aim to develop abilities for students to excel in formal school curriculum or to prepare for university examinations. \"Ronin\" are students that undergo full-time preparation for university exams following high school due to their inability to get into their school of choice.\n\nOver 86% of students with college plans participate in at least one form of shadow education, with 60% participating in two or more.\n\nJapanese students are faced with immense pressure to succeed academically from their parents, teachers, peers and society. This is largely a result of a society that has long placed a great amount of importance on education, and a system that places all of its weight upon a single examination that has significant life-long consequences. This pressure has led to behaviors such as school violence, cheating, suicide, and significant psychological harm. In some cases, students have experienced nervous breakdowns that have required hospitalization as young as twelve. In 1991, it was reported that 1,333 people in the age group of 15-24 had committed suicide, much of which was due to academic pressure. A survey by the Education Ministry showed that students at public schools were involved in a record number of violent incidents in 2007: 52,756 cases, an increase of some 8,000 on the previous year. In almost 7,000 of these incidents, teachers were the target of assault.\n\nThe Japanese educational system has also been criticized for failure to foster independent thinkers with cultural and artistic sensibility. Japanese students that attend schools overseas often face difficulty adapting and competing in that environment due to lack of international viewpoints.\n\nAs of 2016, Japan has 30-40 international schools. There are many Kindergarten type schools that use the word \"international\" in their names but this is not an indicator that they are Japanese schools in the traditional sense. These types of kindergartens are usually immersion programs for Japanese students and the schools hire mostly foreigners to act as the main class \"teacher\" or as an assistant to the Japanese teacher. United Nations University is located in Japan and Temple University has a branch campus in Japan. International University of Japan is an internationally top-ranked, fully English-taught University in Japan. Akita International University is also an English-taught University. Sophia University's Faculty of Liberal Arts is fully taught in English. Tokyo University of Foreign Studies is a highly selective, specialist institution for International Studies and offers some languages that are rarely taught elsewhere in the world.\n\n\n\n\n"}
{"id": "31847810", "url": "https://en.wikipedia.org/wiki?curid=31847810", "title": "Feminist ethics", "text": "Feminist ethics\n\nFeminist ethics is an approach to ethics that builds on the belief that traditionally ethical theorizing has under-valued and/or under-appreciated women's moral experience, which is largely male dominated, and it therefore chooses to re imagine ethics through a holistic feminist approach to transform it.\n\nFeminist philosophers critique traditional ethics as pre-eminently focusing on men's perspective with little regard for women's viewpoints. Caring and the moral issues of private life and family responsibilities were traditionally regarded as trivial matters. Generally, women are portrayed as ethically immature and shallow in comparison to men. Traditional ethics prizes masculine cultural traits like \"independence, autonomy, intellect, will, wariness, hierarchy, domination, culture, transcendence, product, asceticism, war, and death,\" and gives less weight to culturally feminine traits like \"interdependence, community, connection, sharing, emotion, body, trust, absence of hierarchy, nature, immanence, process, joy, peace, and life.\" Should women embody or use any traditionally masculine cultural traits they are seen as other or as an attempt to be more like men. Traditional ethics has a \"male\" orientated convention in which moral reasoning is viewed through a framework of rules, rights, universality, and impartiality and becomes the standard of a society. The \"female\" approaches to moral reasoning emphasizes relationships, responsibilities, particularity, and partiality.\n\nFeminist ethics developed from Mary Wollstonecraft's 'Vindication of the Rights of Women' published in 1792. With the new ideas from the Enlightenment, individual feminists being able to travel more than ever before, generating more opportunities for the exchange of ideas and advancement of women's rights. With new social movements like Romanticism there developed unprecedented optimistic outlook on human capacity and destiny. This optimism was reflected in John Stuart Mill's essay The Subjection of Women (1869). Feminist approaches to ethics, were further developed around this period by other notable people like Catherine Beecher, Charlotte Perkins Gilman, Lucretia Mott and Elizabeth Cady Stanton with an emphasis on the gendered nature of morality, specifically related to 'women's morality'.\n\nThe American writer and sociologist Charlotte Perkins Gilman imagined a fictional \"Herland\". In this male-free society, women produce their daughters through parthenogenesis and live a superior morality. This women-centered society valued both industriousness and motherhood while discouraged individualistic competitive approaches to life. Gilman thought that in such a scenario women could relate cooperatively as there would be no requirement to dominate each other. Herland cultivates and combines the best \"feminine\" virtues and the best \"masculine\" virtues together as co-extensive with human virtue. If a society wants to be virtuous, according to Gilman, it should exemplify the fictional utopia of Herland. However so long as women are dependent on men for economic support, women will continue to be known for their servility and men for their arrogance. Women need to be men's economic equals before they can develop truly human moral virtue, this is a perfect blend of pride and humility that we call self-respect.\n\nCarol Gilligan and Nel Noddings are exponents of a feminist care ethics which criticize traditional ethics as deficient to the degree they lack, disregard, trivialize or attack women's cultural values and virtues. In the 20th-century feminist ethicists developed a variety of care focused feminist approaches to ethics in comparison to non-feminist care-focused approaches to ethics, feminist ones tend to appreciate the impact of gender issues more fully. Feminist care-focused ethicists note the tendencies of patriarchal societies not to appreciate the value and benefits of women's ways of loving, thinking, working and writing and tend to view females as subordinate. This is why some social studies make a conscious effort to adopt feminist ethics, rather than just the traditional ethics of studies. An example of this was Roffee and Waling's 2016 study into microaggressions against the LGBTIQ community. Even though it was focused on the LGBTIQ community the feminist ethics were better suited, as they are more considerate to the vulnerabilities and needs of the participants. Medical fields also fail to recognize that ethics plays an often negative part in the LGBTIQ community in how they receive treatment and what treatments are given as options to them. As well a how women are also treated within medical fields.\n\nFeminist justice ethics is a feminist view on morality which seeks to engage with, and ultimately transform, traditional universal approaches to ethics. Like most types of feminist ethics, feminist justice ethics looks at how gender is left out of mainstream ethical considerations. Mainstream ethics are argued to be male-oriented. However, feminist justice ethics does differ considerably from other feminist ethics. A universal set of ethics is a significant part of feminist justice ethics but depending on the geographical location, such as the difference between the Global North and Global South, may differ in how justice is applied and may change what is considered justice. Feminist justice ethics is clear in dividing \"thick\" morality from \"thin\" morality. Other ethical approaches that define themselves by differentiating groups from one another through culture or other phenomena are regarded as \"thick\" accounts of morality. Feminist justice ethics claims that \"thick\" accounts of morality, as opposed to \"thin\" accounts of morality, are intrinsically prone to eroding valid feminist critique.\n\nFeminist ethicists believe there is an obligation for women's differing points of view to be heard and then to fashion an inclusive consensus view from them. To attempt to achieve this and to push towards gender equality with men together is the goal of feminist ethics. The fixing of these issues are important in modern times because of the shifting view points as well as what has considered to be 'ethical' in terms of treatment and how women, in particular, women's bodies should be treated.\n\n\"The goal of feminist ethics is the transformation of societies and situations where women are harmed through violence, subordination and exclusion. When such injustices are evident now and in the future, radical feminist activists will continue their work of protest and action following careful appraisal and reflection\" With violence, it once again circles back to masculine behavior and traditional ethics that such behavior and treatment was encourages. In today's society, the twentieth century, it is becoming less socially acceptable to commit violence against women.\n\nFeminist theories and that of ethics broaden the scope of the predominantly masculine sphere of International Relations. This is especially important for issues of the private realm to take stage into the public which includes issues such as children's rights, gender violence and discrimination, gender relations in war torn societies, and other similar issues which remain difficult to appear relevant in the mainstream discussions of ethics in international relations. The feminist dialogues of ethics are almost inescapably present to the private realm and are known to only shadow dominant 'male' paradigms of ethics in the public realm. This is especially a reality in discussion of ethics in International Relations where it is predominantly built on a language of violence, technologies or economics and what are known to be the masculine topics of discussion.\n\nSee Kimberly Hutchings discussion in \"Ethics\" for further detail on the foundations of the theory in International Relations \n\nAlison Watson \n\nWatson discusses the issue of children born of wartime rape and uses feminist theory of ethics in addressing these marginalized issues. The invisibility is emphasized in the traditional construction within much of the existing international discourse of motherhood as a 'private sphere activity' where important focused issues such as children of wartime rape can be lost in translation of international dialogue and minimally touched upon. Feminist theory of ethics is provided in terms of broadening theoretical dialogues of international relations and addressing issues that remain marginalized.\n\nPuechguirbal \n\nThere is evidence that failure to broaden the current scope of ethics in peacekeeping operations and rebuilding strategies, surrounding arms and violence, results in failing to meet the needs of both men and women. Puechguirbal argues that conflict is a 'gendered experience' and discusses the importance of peacekeeping operations keeping in check the differential impacts of war on women, men, boys and girls in post conflict society so as to not further marginalize the most vulnerable groups of the population Currently, peacekeeping operations are heavily masculine in the sense that security revolves around the cessation of hostilities and disarmament. Peacebuilding operations must shift the focus from solely disarming and cessation of hostilities against gang members to social constructions of violence against women, men, and children that is embedded in societies broken apart by conflict. Gender issues have not been part of mandates of peacekeeping missions and urges women to take a more active role in political processes in post-conflict reconstruction. Applying Feminist ethics in peacekeeping and re-building strategies can reach a wider range of issues as well as deemed not of dire importance in dialogues of International Relations. Current strategies are not reaching target goals of generating peace and cessation of gender violence and sexual abuses that continue to reach high levels in incidences. This remains a residue of post-conflict societies that must be addressed. Implementing feminist ethics generates greater peacekeeping and peacebuilding strategies for gendered strategies to meet the needs of both genders so as to be implemented into not only the institutions but society.\n\nWhen applying feminist ethics and care, it is important to consider in what way does that apply to those who are transgender, either Female to Male or Male to Female. As there is a historical with ethics being deeply rooted in religious ethics. For those who are transgender and wish to be identified as their preferred gender have to apply either masculine or feminine ethics in both appearance and thinking to pass. One notable mention is when “Halberstam claims that surgical intervention in the case of “sex-change” serves to “fictionalize” gender (i.e., render or expose as artificial) … a masculine performing butch lesbian, for example…”\n\n"}
{"id": "11742", "url": "https://en.wikipedia.org/wiki?curid=11742", "title": "Finite set", "text": "Finite set\n\nIn mathematics, a finite set is a set that has a finite number of elements. Informally, a finite set is a set which one could in principle count and finish counting. For example,\nis a finite set with five elements. The number of elements of a finite set is a natural number (a non-negative integer) and is called the cardinality of the set. A set that is not finite is called infinite. For example, the set of all positive integers is infinite:\nFinite sets are particularly important in combinatorics, the mathematical study of counting. Many arguments involving finite sets rely on the pigeonhole principle, which states that there cannot exist an injective function from a larger finite set to a smaller finite set.\n\nFormally, a set is called finite if there exists a bijection\nfor some natural number . The number is the set's cardinality, denoted as ||. The empty set {} or Ø is considered finite, with cardinality zero.\n\nIf a set is finite, its elements may be written — in many ways — in a sequence:\nIn combinatorics, a finite set with elements is sometimes called an \"-set\" and a subset with elements is called a \"-subset\". For example, the set {5,6,7} is a 3-set – a finite set with three elements – and {6,7} is a 2-subset of it.\n\nAny proper subset of a finite set \"S\" is finite and has fewer elements than \"S\" itself. As a consequence, there cannot exist a bijection between a finite set \"S\" and a proper subset of \"S\". Any set with this property is called Dedekind-finite. Using the standard ZFC axioms for set theory, every Dedekind-finite set is also finite, but this implication cannot be proved in ZF (Zermelo Fraenkel axioms with the axiom of choice removed) alone. \nThe axiom of countable choice, a weak version of the axiom of choice, is sufficient to prove this equivalence.\n\nAny injective function between two finite sets of the same cardinality is also a surjective function (a surjection). Similarly, any surjection between two finite sets of the same cardinality is also an injection.\n\nThe union of two finite sets is finite, with\nIn fact:\nMore generally, the union of any finite number of finite sets is finite. The Cartesian product of finite sets is also finite, with:\nSimilarly, the Cartesian product of finitely many finite sets is finite. A finite set with \"n\" elements has 2 distinct subsets. That is, the\npower set of a finite set is finite, with cardinality 2.\n\nAny subset of a finite set is finite. The set of values of a function when applied to elements of a finite set is finite.\n\nAll finite sets are countable, but not all countable sets are finite. (Some authors, however, use \"countable\" to mean \"countably infinite\", so do not consider finite sets to be countable.)\n\nThe free semilattice over a finite set is the set of its non-empty subsets, with the join operation being given by set union.\n\nIn Zermelo–Fraenkel set theory without the axiom of choice (ZF), the following conditions are all equivalent:\n\n\nIf the axiom of choice is also assumed (the axiom of countable choice is sufficient), then the following conditions are all equivalent:\n\n\nGeorg Cantor initiated his theory of sets in order to provide a mathematical treatment of infinite sets. Thus the distinction between the finite and the infinite lies at the core of set theory. Certain foundationalists, the strict finitists, reject the existence of infinite sets and thus recommend a mathematics based solely on finite sets. Mainstream mathematicians consider strict finitism too confining, but acknowledge its relative consistency: the universe of hereditarily finite sets constitutes a model of Zermelo–Fraenkel set theory with the axiom of infinity replaced by its negation.\n\nEven for those mathematicians who embrace infinite sets, in certain important contexts, the formal distinction between the finite and the infinite can remain a delicate matter. The difficulty stems from Gödel's incompleteness theorems. One can interpret the theory of hereditarily finite sets within Peano arithmetic (and certainly also vice versa), so the incompleteness of the theory of Peano arithmetic implies that of the theory of hereditarily finite sets. In particular, there exists a plethora of so-called non-standard models of both theories. A seeming paradox, non-standard models of the theory of hereditarily finite sets contain infinite sets --- but these infinite sets look finite from within the model. (This can happen when the model lacks the sets or functions necessary to witness the infinitude of these sets.) On account of the incompleteness theorems, no first-order predicate, nor even any recursive scheme of first-order predicates, can characterize the standard part of all such models. So, at least from the point of view of first-order logic, one can only hope to describe finiteness approximately.\n\nMore generally, informal notions like set, and particularly finite set, may receive interpretations across a range of formal systems varying in their axiomatics and logical apparatus. The best known axiomatic set theories include Zermelo-Fraenkel set theory (ZF), Zermelo-Fraenkel set theory with the Axiom of Choice (ZFC), Von Neumann–Bernays–Gödel set theory (NBG), Non-well-founded set theory, Bertrand Russell's Type theory and all the theories of their various models. One may also choose among classical first-order logic, various higher-order logics and intuitionistic logic.\n\nA formalist might see the meaning of \"set\" varying from system to system. Some kinds of Platonists might view particular formal systems as approximating an underlying reality.\n\nIn contexts where the notion of natural number sits logically prior to any notion of set, one can define a set \"S\" as finite if \"S\" admits a bijection to some set of natural numbers of the form formula_9. Mathematicians more typically choose to ground notions of number in set theory, for example they might model natural numbers by the order types of finite well-ordered sets. Such an approach requires a structural definition of finiteness that does not depend on natural numbers.\n\nVarious properties that single out the finite sets among all sets in the theory ZFC turn out logically inequivalent in weaker systems such as ZF or intuitionistic set theories. Two definitions feature prominently in the literature, one due to Richard Dedekind, the other to Kazimierz Kuratowski. (Kuratowski's is the definition used above.)\n\nA set \"S\" is called Dedekind infinite if there exists an injective, non-surjective function formula_10. Such a function exhibits a bijection between \"S\" and a proper subset of \"S\", namely the image of \"f\". Given a Dedekind infinite set \"S\", a function \"f\", and an element \"x\" that is not in the image of \"f\", we can form an infinite sequence of distinct elements of \"S\", namely formula_11. Conversely, given a sequence in \"S\" consisting of distinct elements formula_12, we can define a function \"f\" such that on elements in the sequence formula_13 and \"f\" behaves like the identity function otherwise. Thus Dedekind infinite sets contain subsets that correspond bijectively with the natural numbers. Dedekind finite naturally means that every injective self-map is also surjective.\n\nReaders unfamiliar with semi-lattices and other notions of abstract algebra may prefer an entirely elementary formulation. Kuratowski finite means \"S\" lies in the set \"K\"(\"S\"), constructed as follows. Write \"M\" for the set of all subsets \"X\" of \"P\"(\"S\") such that:\nThen \"K\"(\"S\") may be defined as the intersection of \"M\".\n\nIn ZF, Kuratowski finite implies Dedekind finite, but not vice versa. In the parlance of a popular pedagogical formulation, when the axiom of choice fails badly, one may have an infinite family of socks with no way to choose one sock from more than finitely many of the pairs. That would make the set of such socks Dedekind finite: there can be no infinite sequence of socks, because such a sequence would allow a choice of one sock for infinitely many pairs by choosing the first sock in the sequence. However, Kuratowski finiteness would fail for the same set of socks.\n\nIn ZF set theory without the axiom of choice, the following concepts of finiteness for a set \"S\" are distinct. They are arranged in strictly decreasing order of strength. In other words, if a set \"S\" meets one of the criteria in this list, it meets all of the criteria which follow that one. In the absence of the axiom of choice, the reverse implications are all unprovable. If the axiom of choice is assumed, then all of these concepts are equivalent. (Note that none of these definitions need the set of finite ordinal numbers to be defined first. They are all pure \"set-theoretic\" definitions in terms of the equality and element-of relations, not involving ω.)\n\n\nThe forward implications (from strong to weak) are theorems within ZF. Counter-examples to the reverse implications (from weak to strong) are found using model theory.\n\nMost of these finiteness definitions and their names are attributed to by . However, definitions I, II, III, IV and V were presented in , together with proofs (or references to proofs) for the forward implications. At that time, model theory was not sufficiently advanced to find the counter-examples.\n\n\n"}
{"id": "3038928", "url": "https://en.wikipedia.org/wiki?curid=3038928", "title": "Four-tensor", "text": "Four-tensor\n\nIn physics, specifically for special relativity and general relativity, a four-tensor is an abbreviation for a tensor in a four-dimensional spacetime.\n\nGeneral four-tensors are usually written in tensor index notation as\n\nwith the indices taking integer values from 0 to 3, with 0 for the timelike components and 1, 2, 3 for spacelike components. There are \"n\" contravariant indices and \"m\" covariant indices.\n\nIn special and general relativity, many four-tensors of interest are first order (four-vectors) or second order, but higher order tensors occur. Examples are listed next.\n\nIn special relativity, the vector basis can be restricted to being orthonormal, in which case all four-tensors transform under Lorentz transformations. In general relativity, more general coordinate transformations are necessary since such a restriction is not in general possible.\n\nIn special relativity, one of the simplest non-trivial examples of a four-tensor is the four-displacement\n\na four-tensor with contravariant rank 1 and covariant rank 0. Four-tensors of this kind are usually known as four-vectors. Here the component \"x\" = \"ct\" gives the displacement of a body in time (coordinate time \"t\" is multiplied by the speed of light \"c\" so that \"x\" has dimensions of length). The remaining components of the four-displacement form the spatial displacement vector x = (\"x\", \"x\", \"x\").\n\nThe four-momentum for massive or massless particles is\n\ncombines its energy (divided by \"c\") \"p\" = \"E\"/\"c\" and 3-momentum p = (\"p\", \"p\", \"p\").\n\nFor a particle with relativistic mass \"m\", four momentum is defined by\n\nwith \"τ\" the proper time of the particle.\n\nThe Minkowski metric tensor with an orthonormal basis for the (−+++) convention is\n\nused for calculating the line element and raising and lowering indices. The above applies to Cartesian coordinates. In general relativity, the metric tensor is given by much more general expressions for curvilinear coordinates.\n\nThe angular momentum of a particle with relativistic mass \"m\" and relativistic momentum p (as measured by an observer in a lab frame) combines with another vector quantity (without a standard name) in the relativistic angular momentum tensor\n\nwith components\n\nThe stress–energy tensor of a continuum or field generally takes the form of a second order tensor, and usually denoted by \"T\". The timelike component corresponds to energy density (energy per unit volume), the mixed spacetime components to momentum density (momentum per unit volume), and the purely spacelike parts to 3d stress tensors.\n\nThe electromagnetic field tensor combines the electric field and E and magnetic field B\n\nformula_8\n\nThe electromagnetic displacement tensor combines the electric displacement field D and magnetic field intensity H as follows\n\nThe magnetization-polarization tensor combines the P and M fields\n\nThe three field tensors are related by\n\nwhich is equivalent to the definitions of the D and H fields.\n\nThe electric dipole moment d and magnetic dipole moment μ of a particle are unified into a single tensor\n\nThe Ricci curvature tensor is another second order tensor.\n\nIn general relativity, there are curvature tensors which tend to be higher order, such as the Riemann curvature tensor and Weyl curvature tensor which are both fourth order tensors.\n\n"}
{"id": "1586291", "url": "https://en.wikipedia.org/wiki?curid=1586291", "title": "Fréchet filter", "text": "Fréchet filter\n\nIn mathematics, the Fréchet filter, also called the cofinite filter, on a set is a special subset of the set's power set. A member of this power set is in the Fréchet filter if and only if its complement in the power set is finite. This is of interest in topology, where filters originated, and relates to order and lattice theory because a set's power set is a partially ordered set (and more specifically, a lattice) under set inclusion.\n\nThe Fréchet filter is named after the French mathematician Maurice Fréchet (1878-1973), who worked in topology. It is alternatively called a \"cofinite filter\" because its members are exactly the cofinite sets in a power set.\n\nThe Fréchet filter \"F\" on \"X\" is the set of all subsets \"A\" of \"X\" such that the complement of \"A\" in \"X\" is finite. That is, \n\nThis makes \"F\" a filter on the lattice (P(\"X\"), ⊆), the power set of \"X\" with set inclusion, since\n\nIf the base set \"X\" is finite, then \"F\" = P(\"X\") since every subset of \"X\", and in particular every complement, is then finite. This case is sometimes excluded by definition or else called the improper filter on \"X\". Allowing \"X\" to be finite creates a single exception to the Fréchet filter's being free and non-principal since a filter on a finite set cannot be free and a non-principal filter cannot contain any singletons as members.\n\nIf \"X\" is infinite, then every member of \"F\" is infinite since it is simply \"X\" minus finitely many of its members. Additionally, \"F\" is infinite since one of its subsets is the set of all {\"x\"}, where \"x\" ∈ \"X\".\n\nThe Fréchet filter is both free and non-principal, excepting the finite case mentioned above, and is included in every free filter. It is also the dual filter of the ideal of all finite subsets of (infinite) \"X\".\n\nThe Fréchet filter is \"not\" necessarily an ultrafilter (or maximal proper filter). Consider P(N). The set of even numbers is the complement of the set of odd numbers. Since neither of these sets is finite, neither set is in the Fréchet filter on N. However, an ultrafilter is free if and only if it includes the Fréchet filter. The existence of free ultrafilters was established by Tarski in 1930, relying on a theorem equivalent to the axiom of choice and is used in the construction of the hyperreals in nonstandard analysis.\n\nOn the set N of natural numbers, the set \"B\" = { (\"n\",∞) : \"n\" ∈ N} is a Fréchet filter base, i.e., the Fréchet filter on N consists of all supersets of elements of \"B\".\n\n\n"}
{"id": "4532553", "url": "https://en.wikipedia.org/wiki?curid=4532553", "title": "Gavin McInnes", "text": "Gavin McInnes\n\nGavin Miles McInnes (; born 17 July 1970) is a Canadian writer, actor, and comedian. He is the co-founder of Vice Media and \"Vice Magazine\" and host of \"Get Off My Lawn\" on Conservative Review. He is a contributor to \"Taki's Magazine\" and a former contributor to The Rebel Media, and was a frequent guest on television programs on Fox News and TheBlaze.\n\nMcInnes was a leading figure in the hipster subculture while at Vice, being labelled as the \"godfather\" of hipsterdom. After leaving the company in 2008, he became increasingly known for his far-right political views. He is the founder of the Proud Boys, a chauvinist men's group considered an extremist organisation by the FBI and the Southern Poverty Law Center.\n\nMcInnes was born in Hitchin in Hertfordshire, England, to Scottish parents, James and Loraine McInnes. His family migrated to Canada when McInnes was four. He attended Ottawa's Earl of March Secondary School. As a teen, McInnes played in the Ottawa punk band \"Anal Chinook\". As an adult, McInnes emigrated to the United States from Canada.\n\nMcInnes co-founded \"Vice\" in 1994 with Shane Smith and Suroosh Alvi. During his tenure there he was described as the \"godfather\" of hipsterdom by WNBC and as \"one of hipsterdom’s primary architects\" by \"AdBusters\". He occasionally contributed articles to \"Vice\", including \"The VICE Guide to Happiness\" and \"The VICE Guide to Picking Up Chicks\", and co-authored two \"Vice\" books: \"The Vice Guide to Sex and Drugs and Rock and Roll\", and \"Vice Dos and Don'ts: 10 Years of VICE Magazine's Street Fashion Critiques\".\n\nIn an interview in the \"New York Press\" in 2002, McInnes said that he was pleased that most Williamsburg hipsters were white. McInnes later wrote in a letter to Gawker that the interview was done as a prank intended to ridicule \"baby boomer media like \"The Times\"\". After he became the focus of a letter-writing campaign by a black reader, \"Vice\" apologized for McInnes's comments. McInnes was featured in a 2003 \"New York Times\" article about \"Vice\" magazine expressing his political views.\n\nIn 2006, he was featured in \"The Vice Guide to Travel\" with actor and comedian David Cross in China. He left \"Vice\" in 2008 due to what he described as \"creative differences\". In a 2013 interview with \"The New Yorker\", McInnes said his split with \"Vice\" was about the increasing influence of corporate advertising on \"Vice's\" content, stating that \"Marketing and editorial being enemies had been the business plan\".\n\nIn 2008, McInnes created the website \"StreetCarnage.com\". He also co-founded an advertising agency called Rooster where he serves as creative director. In 2009, McInnes convinced a journalist at \"The Village Voice\" that he had been knocked out after losing a challenge to an MMA fighter. The footage was actually an outtake from a failed TV pilot. In 2010, McInnes convinced a journalist at Gawker that he had eaten a bowl of urine-soaked corn flakes after not winning their \"Hipster of the Decade\" competition. The footage was actually an outtake from a collection of comedy sketches called \"Gavin McInnes Is a Fucking Asshole\".\n\nMcInnes was featured in Season 3 of the Canadian reality TV show \"Kenny vs. Spenny\", as a judge in the \"Who is Cooler?\" episode. In 2010, McInnes was approached by Adult Swim and asked to play the part of Mick, an anthropomorphic Scottish soccer ball, in the short-lived \"Aqua Teen Hunger Force\" spin-off \"Soul Quest Overdrive\". After losing a 2010 pilot contest to \"Cheyenne Cinnamon and the Fantabulous Unicorn of Sugar Town Candy Fudge\", six episodes of \"Soul Quest Overdrive\" were ordered, with four airing in Adult Swim's 4 AM DVR Theater block on 25 May 2011 before quickly being cancelled. McInnes jokingly blamed the show's cancellation on the other cast members (Kristen Schaal, David Cross, and H. Jon Benjamin) not being \"as funny\" as him.\n\nIn 2012, McInnes wrote a book called \"How to Piss in Public\". In 2013 he directed \"The Brotherhood of the Traveling Rants\", a documentary on his tour as an occasional standup comedian. For the film, he faked a serious car accident. Also that year, McInnes starred in the independent film \"How to Be a Man\", which premiered at Sundance Next Weekend. He has also played supporting roles in other films including \"Soul Quest Overdrive\" (2010), \"Creative Control\" (2015) and \"One More Time\" (2015).\n\nIn August 2014, McInnes was asked to take an indefinite leave of absence as chief creative officer of Rooster, following online publication at Thought Catalog of an essay about transphobia titled \"Transphobia is Perfectly Natural\" that sparked a call to boycott the company. In response, Rooster issued a statement, saying in part: \"We are extremely disappointed with his actions and have asked that he take a leave of absence while we determine the most appropriate course of action.\" McInnes defended the article by saying \"All I was saying was transsexuals have a huge suicide rate\", and calling the reaction \"fake hysteria\".\n\nIn June 2015, broadcaster Anthony Cumia announced that McInnes would be hosting a show on his network, therefore retiring the Free Speech podcast that he had started in March. \"The Gavin McInnes Show\" premiered on Compound Media on 15 June. McInnes is a former contributor to Canadian far-right portal The Rebel Media and a regular on conspiracy theorist media platform Infowars' \"The Alex Jones Show\", and Fox News' \"Red Eye\", \"The Greg Gutfeld Show\", and \"The Sean Hannity Show\". He writes for \"Taki's Magazine\" and previously wrote for TruthRevolt, Death and Taxes, The Federalist, \"American Renaissance\", and VDARE. McInnes tweeted in December 2015 that every case of domestic abuse he knows about \"was the result of some cunt trying to ruin [a man’s] life\". In 2016, McInnes referred to Jada Pinkett Smith as a \"monkey actress\" on his radio show.\n\nOn 2 February 2017, in an episode of his YouTube show \"The Rebel\", McInnes announced his resignation from Fox News.\n\nMcInnes left Rebel Media in August 2017, declaring that he was going to be \"a multi-media Howard Stern–meets–Tucker Carlson\". He later joined CRTV, an online television network launched by Conservative Review. The debut episode of his new show \"Get Off My Lawn\" aired on 22 September 2017. On 10 August 2018, McInnes's Twitter account, as well as the account for the Proud Boys, was permanently suspended by Twitter due to their rules against violent extremist groups. The suspension was ahead of the one-year anniversary of the Unite the Right rally, and the scheduled 2018 Unite the Right rally.\n\nOn 12 October 2018, McInnes participated in a reenactment of the 1960 assassination of Inejiro Asanuma by Otoya Yamaguchi at the Metropolitan Republican Club. After the event, a contingent of Proud Boys were caught on tape beating a protester outside the venue, after members of Antifa threw a plastic bottle filled with urine at them.\n\nOn November 21st, shortly after news broke that, according to an alleged, unconfirmed Police report, the FBI had classified the Proud Boys as an extremist group with ties to white nationalists, McInnes said that his lawyers had advised him that quitting might help the nine members being prosecuted for the incidents in October and he said \"this is 100% a legal gesture, and it is 100% about alleviating sentencing\", and said it was a \"stepping down gesture, in quotation marks\". \n\nLater that month, McInnes was planning on traveling to Australia for a speaking tour with Milo Yiannopolous and Tommy Robinson (Stephen Yaxley-Lennon), but was informed by Australian immigration authorities that \"he was judged to be of bad character\" and would be denied a visa to enter the country. Issuing a visa to McInnes was opposed by an online campaign called \"#BanGavin\", which collected 81,000 signatures.\n\nMcInnes describes himself as libertarian and part of the New Right, a term that he prefers to use rather than alt-light. \"The New York Times\" has described McInnes as a \"far-right provocateur.\"\n\nMcInnes has referred to himself as a \"western chauvinist\" and started a men's organization called Proud Boys who swear their allegiance to this cause.\nThe FBI classifies the Proud Boys \"an extremist group with ties to white nationalism\", according to a document allegedly produced by Washington state law enforcement, and the Southern Poverty Law Center classifies it as a hate group. McInnes says that his group is not white nationalist.\n\nIn 2003 McInnes said, \"I love being white and I think it's something to be very proud of. I don't want our culture diluted. We need to close the borders now and let everyone assimilate to a Western, white, English-speaking way of life.\"\n\nMcInnes has been accused of racism and of promoting white supremacist rhetoric. He has stated alleged racial slurs against Susan Rice and Jada Pinkett Smith personally, and more widely against Palestinians and Asians. McInnes has said that there is a \"mass conformity that black people push on each other\", and in 2018, he said there was significant \"black violence\" in the United States, with 8,000 cases a year of black-on-black murder.\n\nIn March 2017, during a trip to Israel with The Rebel Media, McInnes made controversial comments defending Holocaust deniers, accused the Jews of being responsible for the Holodomor and the Treaty of Versailles, and said he was \"becoming anti-Semitic\". He later said his comments were taken out of context. McInnes also produced a comedic video for Rebel called \"Ten Things I Hate about Jews\", later retitled \"Ten Things I Hate About Israel\". In response to the controversy, McInnes said: “I landed, and I’ve got tons of Nazi friends. David Duke and all the Nazis totally think I rock... No offence, Nazis, I don’t want to hurt your feelings, but I don’t like you. I like Jews.”\n\nMcInnes is anti-Islam. He has said that \"Muslims are stupid ... the only thing they really respect is violence and being tough.\" He also has equated Islam with fascism, stating \"Nazis are not a thing. Islam is a thing.\" In April 2018, Mcinnes labelled a significant section of Muslims as both mentally ill and incestuous, claiming that \"Muslims have a problem with inbreeding. They tend to marry their first cousins... and that is a major problem [in the U.S.] because when you have mentally damaged inbreds – which not all Muslims are, but a disproportionate number are – and you have a hate book called the Koran... you end up with a perfect recipe for mass murder.\"\n\nMcInnes has described himself as \"an Archie Bunker sexist.\"\n\nAs early as 2003, Vanessa Grigoriadis in \"The New York Times\" quoted McInnes saying, \"'No means no' is puritanism. I think Steinem-era feminism did women a lot of injustices, but one of the worst ones was convincing all these indie norts that women don't want to be dominated.\" McInnes has been accused of sexism by various media outlets including \"Chicago Sun-Times\", \"Independent Journal Review\", \"Salon\", \"Jezebel\", \"The Hollywood Reporter\", and \"Slate\". In October 2013, McInnes said during a panel interview that \"people would be happier if women would stop pretending to be men\", and that feminism \"has made women less happy\". He explained that \"We've trivialized childbirth and being domestic so much that women are forced to pretend to be men. They're feigning this toughness, they're miserable.\" A heated argument ensued with University of Miami School of Law professor Mary Anne Franks.\n\nMcInnes has espoused the white genocide conspiracy theory saying that white women having abortions and immigration is \"leading to white genocide in the West\". In 2018, regarding South African farm attacks and land reform proposals, he said that black South Africans were not \"trying to get their land back – they never had that land\", instead claiming there were \"ethnic cleansing\" efforts against white South Africans.\n\nIn 2005, McInnes married Manhattan-based publicist and consultant Emily Jendrisak, the daughter of Native American activist Christine Whiterabbit Jendrisak.\n\n\n"}
{"id": "34810345", "url": "https://en.wikipedia.org/wiki?curid=34810345", "title": "Gestaltzerfall", "text": "Gestaltzerfall\n\nGestaltzerfall (German for \"shape decomposition\") refers to a type of visual agnosia and is a psychological phenomenon where delays in recognition are observed when a complex shape is stared at for a while as the shape seems to decompose into its constituting parts. With regards to kanji, a study has shown that delays are most significant when the characters are of the same size. When characters to recognize are of different sizes, delays are observed only when they are of different patterns.\n\nThe phenomenon was first described and named by C. Faust in 1947 as a symptom of the bilateral region of the parieto-occipital sulcus after a through and through bullet wound of this region. Afterwards, when the subject stared at a truck for a while the truck seemed to decompose into its motor, chassis, driver cab and the person could only focus on one of these parts until he briefly closed his eyes or looked away which reset the shape to the complete truck again.\n\nThe characteristic of orthographic satiation as opposed to semantic satiation is that meaning remains intact. It was suggested that this is different from semantic satiation and from the stimulus familiarization effect because orthographic satiation occurs after the perceivers have access to lexical meaning.\n\n"}
{"id": "38579", "url": "https://en.wikipedia.org/wiki?curid=38579", "title": "Gravity", "text": "Gravity\n\nGravity (), or gravitation, is a natural phenomenon by which all things with mass or energy—including planets, stars, galaxies, and even light—are brought toward (or \"gravitate\" toward) one another. On Earth, gravity gives weight to physical objects, and the Moon's gravity causes the ocean tides. The gravitational attraction of the original gaseous matter present in the Universe caused it to begin coalescing, forming starsand for the stars to group together into galaxiesso gravity is responsible for many of the large-scale structures in the Universe. Gravity has an infinite range, although its effects become increasingly weaker on farther objects.\n\nGravity is most accurately described by the general theory of relativity (proposed by Albert Einstein in 1915) which describes gravity not as a force, but as a consequence of the curvature of spacetime caused by the uneven distribution of mass. The most extreme example of this curvature of spacetime is a black hole, from which nothing—not even light—can escape once past the black hole's event horizon. However, for most applications, gravity is well approximated by Newton's law of universal gravitation, which describes gravity as a force which causes any two bodies to be attracted to each other, with the force proportional to the product of their masses and inversely proportional to the square of the distance between them.\n\nGravity is the weakest of the four fundamental forces of physics, approximately 10 times weaker than the strong force, 10 times weaker than the electromagnetic force and 10 times weaker than the weak force. As a consequence, it has no significant influence at the level of subatomic particles. In contrast, it is the dominant force at the macroscopic scale, and is the cause of the formation, shape and trajectory (orbit) of astronomical bodies. For example, gravity causes the Earth and the other planets to orbit the Sun, it also causes the Moon to orbit the Earth, and causes the formation of tides, the formation and evolution of the Solar System, stars and galaxies.\n\nThe earliest instance of gravity in the Universe, possibly in the form of quantum gravity, supergravity or a gravitational singularity, along with ordinary space and time, developed during the Planck epoch (up to 10 seconds after the birth of the Universe), possibly from a primeval state, such as a false vacuum, quantum vacuum or virtual particle, in a currently unknown manner. Attempts to develop a theory of gravity consistent with quantum mechanics, a quantum gravity theory, which would allow gravity to be united in a common mathematical framework (a theory of everything) with the other three forces of physics, are a current area of research.\n\nAryabhata first identified the force to explain why objects do not fall when the earth rotates, Brahmagupta described gravity as an attractive force and used the term \"gruhtvaakarshan\" for gravity.\n\nModern work on gravitational theory began with the work of Galileo Galilei in the late 16th and early 17th centuries. In his famous (though possibly apocryphal) experiment dropping balls from the Tower of Pisa, and later with careful measurements of balls rolling down inclines, Galileo showed that gravitational acceleration is the same for all objects. This was a major departure from Aristotle's belief that heavier objects have a higher gravitational acceleration. Galileo postulated air resistance as the reason that objects with less mass fall more slowly in an atmosphere. Galileo's work set the stage for the formulation of Newton's theory of gravity.\n\nIn 1687, English mathematician Sir Isaac Newton published \"Principia\", which hypothesizes the inverse-square law of universal gravitation. In his own words, \"I deduced that the forces which keep the planets in their orbs must [be] reciprocally as the squares of their distances from the centers about which they revolve: and thereby compared the force requisite to keep the Moon in her Orb with the force of gravity at the surface of the Earth; and found them answer pretty nearly.\" The equation is the following:\n\nformula_1\n\nWhere \"F\" is the force, \"m\" and \"m\" are the masses of the objects interacting, \"r\" is the distance between the centers of the masses and \"G\" is the gravitational constant.\n\nNewton's theory enjoyed its greatest success when it was used to predict the existence of Neptune based on motions of Uranus that could not be accounted for by the actions of the other planets. Calculations by both John Couch Adams and Urbain Le Verrier predicted the general position of the planet, and Le Verrier's calculations are what led Johann Gottfried Galle to the discovery of Neptune.\n\nA discrepancy in Mercury's orbit pointed out flaws in Newton's theory. By the end of the 19th century, it was known that its orbit showed slight perturbations that could not be accounted for entirely under Newton's theory, but all searches for another perturbing body (such as a planet orbiting the Sun even closer than Mercury) had been fruitless. The issue was resolved in 1915 by Albert Einstein's new theory of general relativity, which accounted for the small discrepancy in Mercury's orbit. This discrepancy was the advance in the perihelion of Mercury of 42.98 arcseconds per century.\n\nAlthough Newton's theory has been superseded by Einstein's general relativity, most modern non-relativistic gravitational calculations are still made using Newton's theory because it is simpler to work with and it gives sufficiently accurate results for most applications involving sufficiently small masses, speeds and energies.\n\nThe equivalence principle, explored by a succession of researchers including Galileo, Loránd Eötvös, and Einstein, expresses the idea that all objects fall in the same way, and that the effects of gravity are indistinguishable from certain aspects of acceleration and deceleration. The simplest way to test the weak equivalence principle is to drop two objects of different masses or compositions in a vacuum and see whether they hit the ground at the same time. Such experiments demonstrate that all objects fall at the same rate when other forces (such as air resistance and electromagnetic effects) are negligible. More sophisticated tests use a torsion balance of a type invented by Eötvös. Satellite experiments, for example STEP, are planned for more accurate experiments in space.\n\nFormulations of the equivalence principle include:\n\nIn general relativity, the effects of gravitation are ascribed to spacetime curvature instead of a force. The starting point for general relativity is the equivalence principle, which equates free fall with inertial motion and describes free-falling inertial objects as being accelerated relative to non-inertial observers on the ground. In Newtonian physics, however, no such acceleration can occur unless at least one of the objects is being operated on by a force.\n\nEinstein proposed that spacetime is curved by matter, and that free-falling objects are moving along locally straight paths in curved spacetime. These straight paths are called geodesics. Like Newton's first law of motion, Einstein's theory states that if a force is applied on an object, it would deviate from a geodesic. For instance, we are no longer following geodesics while standing because the mechanical resistance of the Earth exerts an upward force on us, and we are non-inertial on the ground as a result. This explains why moving along the geodesics in spacetime is considered inertial.\n\nEinstein discovered the field equations of general relativity, which relate the presence of matter and the curvature of spacetime and are named after him. The Einstein field equations are a set of 10 simultaneous, non-linear, differential equations. The solutions of the field equations are the components of the metric tensor of spacetime. A metric tensor describes a geometry of spacetime. The geodesic paths for a spacetime are calculated from the metric tensor.\n\nNotable solutions of the Einstein field equations include:\n\nThe tests of general relativity included the following:\n\nIn the decades after the publication of the theory of general relativity, it was realized that general relativity is incompatible with quantum mechanics. It is possible to describe gravity in the framework of quantum field theory like the other fundamental forces, such that the attractive force of gravity arises due to exchange of virtual gravitons, in the same way as the electromagnetic force arises from exchange of virtual photons. This reproduces general relativity in the classical limit. However, this approach fails at short distances of the order of the Planck length, where a more complete theory of quantum gravity (or a new approach to quantum mechanics) is required.\n\nEvery planetary body (including the Earth) is surrounded by its own gravitational field, which can be conceptualized with Newtonian physics as exerting an attractive force on all objects. Assuming a spherically symmetrical planet, the strength of this field at any given point above the surface is proportional to the planetary body's mass and inversely proportional to the square of the distance from the center of the body.\n\nThe strength of the gravitational field is numerically equal to the acceleration of objects under its influence. The rate of acceleration of falling objects near the Earth's surface varies very slightly depending on latitude, surface features such as mountains and ridges, and perhaps unusually high or low sub-surface densities. For purposes of weights and measures, a standard gravity value is defined by the International Bureau of Weights and Measures, under the International System of Units (SI).\n\nThat value, denoted \"g\", is \"g\" = 9.80665 m/s (32.1740 ft/s).\n\nThe standard value of 9.80665 m/s is the one originally adopted by the International Committee on Weights and Measures in 1901 for 45° latitude, even though it has been shown to be too high by about five parts in ten thousand. This value has persisted in meteorology and in some standard atmospheres as the value for 45° latitude even though it applies more precisely to latitude of 45°32'33\".\n\nAssuming the standardized value for g and ignoring air resistance, this means that an object falling freely near the Earth's surface increases its velocity by 9.80665 m/s (32.1740 ft/s or 22 mph) for each second of its descent. Thus, an object starting from rest will attain a velocity of 9.80665 m/s (32.1740 ft/s) after one second, approximately 19.62 m/s (64.4 ft/s) after two seconds, and so on, adding 9.80665 m/s (32.1740 ft/s) to each resulting velocity. Also, again ignoring air resistance, any and all objects, when dropped from the same height, will hit the ground at the same time.\n\nAccording to Newton's 3rd Law, the Earth itself experiences a force equal in magnitude and opposite in direction to that which it exerts on a falling object. This means that the Earth also accelerates towards the object until they collide. Because the mass of the Earth is huge, however, the acceleration imparted to the Earth by this opposite force is negligible in comparison to the object's. If the object doesn't bounce after it has collided with the Earth, each of them then exerts a repulsive contact force on the other which effectively balances the attractive force of gravity and prevents further acceleration.\n\nThe force of gravity on Earth is the resultant (vector sum) of two forces: (a) The gravitational attraction in accordance with Newton's universal law of gravitation, and (b) the centrifugal force, which results from the choice of an earthbound, rotating frame of reference. The force of gravity is the weakest at the equator because of the centrifugal force caused by the Earth's rotation and because points on the equator are furthest from the center of the Earth. The force of gravity varies with latitude and increases from about 9.780 m/s at the Equator to about 9.832 m/s at the poles.\n\nUnder an assumption of constant gravitational attraction, Newton's law of universal gravitation simplifies to \"F\" = \"mg\", where \"m\" is the mass of the body and \"g\" is a constant vector with an average magnitude of 9.81 m/s on Earth. This resulting force is the object's weight. The acceleration due to gravity is equal to this \"g\". An initially stationary object which is allowed to fall freely under gravity drops a distance which is proportional to the square of the elapsed time. The image on the right, spanning half a second, was captured with a stroboscopic flash at 20 flashes per second. During the first of a second the ball drops one unit of distance (here, a unit is about 12 mm); by it has dropped at total of 4 units; by , 9 units and so on.\n\nUnder the same constant gravity assumptions, the potential energy, \"E\", of a body at height \"h\" is given by \"E\" = \"mgh\" (or \"E\" = \"Wh\", with \"W\" meaning weight). This expression is valid only over small distances \"h\" from the surface of the Earth. Similarly, the expression formula_2 for the maximum height reached by a vertically projected body with initial velocity \"v\" is useful for small heights and small initial velocities only.\n\nThe application of Newton's law of gravity has enabled the acquisition of much of the detailed information we have about the planets in the Solar System, the mass of the Sun, and details of quasars; even the existence of dark matter is inferred using Newton's law of gravity. Although we have not traveled to all the planets nor to the Sun, we know their masses. These masses are obtained by applying the laws of gravity to the measured characteristics of the orbit. In space an object maintains its orbit because of the force of gravity acting upon it. Planets orbit stars, stars orbit galactic centers, galaxies orbit a center of mass in clusters, and clusters orbit in superclusters. The force of gravity exerted on one object by another is directly proportional to the product of those objects' masses and inversely proportional to the square of the distance between them.\n\nThe earliest gravity (possibly in the form of quantum gravity, supergravity or a gravitational singularity), along with ordinary space and time, developed during the Planck epoch (up to 10 seconds after the birth of the Universe), possibly from a primeval state (such as a false vacuum, quantum vacuum or virtual particle), in a currently unknown manner.\n\nAccording to general relativity, gravitational radiation is generated in situations where the curvature of spacetime is oscillating, such as is the case with co-orbiting objects. The gravitational radiation emitted by the Solar System is far too small to measure. However, gravitational radiation has been indirectly observed as an energy loss over time in binary pulsar systems such as PSR B1913+16. It is believed that neutron star mergers and black hole formation may create detectable amounts of gravitational radiation. Gravitational radiation observatories such as the Laser Interferometer Gravitational Wave Observatory (LIGO) have been created to study the problem. In February 2016, the Advanced LIGO team announced that they had detected gravitational waves from a black hole collision. On 14 September 2015, LIGO registered gravitational waves for the first time, as a result of the collision of two black holes 1.3 billion light-years from Earth. This observation confirms the theoretical predictions of Einstein and others that such waves exist. The event confirms that binary black holes exist. It also opens the way for practical observation and understanding of the nature of gravity and events in the Universe including the Big Bang and what happened after it.\n\nIn December 2012, a research team in China announced that it had produced measurements of the phase lag of Earth tides during full and new moons which seem to prove that the speed of gravity is equal to the speed of light. This means that if the Sun suddenly disappeared, the Earth would keep orbiting it normally for 8 minutes, which is the time light takes to travel that distance. The team's findings were released in the Chinese Science Bulletin in February 2013.\n\nIn October 2017, the LIGO and Virgo detectors received gravitational wave signals within 2 seconds of gamma ray satellites and optical telescopes seeing signals from the same direction. This confirmed that the speed of gravitational waves was the same as the speed of light.\n\nThere are some observations that are not adequately accounted for, which may point to the need for better theories of gravity or perhaps be explained in other ways.\n\n\n\n\n\n\n"}
{"id": "2730667", "url": "https://en.wikipedia.org/wiki?curid=2730667", "title": "Integrated chain management", "text": "Integrated chain management\n\nIntegrated Chain Management (ICM), also known as Integral Chain Management, is an approach for the reduction of environmental impact of product chains. Such a product chain exists out of an extraction phase, a production phase, a use phase and a waste phase. The ultimate goal of ICM is a reduction of environmental load over the whole chain. Integrated Chain Management is one of the approaches that can be used to come to sustainable development. Other approaches in this line are the Ecological Footprint and the DTO approach. \n\nWithin the ICM approach all phases within the chain must be considered. Therefore it can be seen as a \"cradle to grave\" approach. \nSeveral inputs and outputs can be taken into account when applying the ICM approach. Such as: Energy flows, mass flows, materials, waste flows and emissions. Within ICM material cycles should be closed where possible and the remainder flows of emissions and waste should be brought within acceptable boundaries. Also the use of resources should be kept to a minimum. \n\nIntegrated chain management should not be mixed up with Supply Chain Management or Integrated Supply Chain Management. These concepts do not have the reduction of environmental load as their main goal. \n\nAn important aspect of ICM is that shifting to other phases in the product chain is avoided. For instance, a producer of chairs can choose to leave off an environment unfriendly material in a new product. The producer can even see this as an extra selling point for the customer, but as a consequence the supplier of raw materials has to use much more energy to produce a material with the same qualities. The result of this is that there may no longer be a net environmental reduction across the whole chain. Within the integrated chain management approach this is avoided. \n\nThe chain can be managed by developing new policies and economical or political incentives. Therefore one must have insight into the inputs and outputs of the production chain. Before these policies can be developed one must engage in several actions. \n\n\nEffective supply chain management can impact virtually all business and production processes\n\nAn example of applying the ICM approach would be to develop policies in a particular product area. The responsibility of problems caused by the waste stage can be assigned to the producers of these products. This leads to improved product design and new insight in how to put these products in the market. For instance the product can be sold with a disposal contribution. On the price tag of a radio nowadays can be printed: \"this radio costs 25 $ not including the 3 $ disposal contribution\" \nThe effects can be seen within the whole chain. The producer will try to choose non-polluting materials, as they increase the costs of the waste-stage. The producer of raw materials will try to improve its production process in order to meet the increased demand for 'clean' primary products. And the consumer will be aware that some products give more pressure on the environment than others when its economical lifespan has run out. \n\n"}
{"id": "38864294", "url": "https://en.wikipedia.org/wiki?curid=38864294", "title": "John K. McNulty", "text": "John K. McNulty\n\nJohn Kent McNulty (born 1934) is an American legal scholar, who was a professor of law at the University of California, Berkeley (Boalt Hall) for 38 years from 1964 to 2002 and who as a legal educator and scholar, was influential in shaping U.S. tax law policy debate during the later quarter of the 20th century.\n\nMcNulty was Boalt Hall’s Robert J. Traynor professor of law for the last decade of his career from 1991 to 2002 and is a professor emeritus at the law school. He was for over 30 years and continued to be even after his academic retirement a noted researcher in the area of structural reform of U.S. tax law. His work is of particular importance in the area of proposals for U.S. federal \"Integration\" of corporate and individual taxation. \"Integration\" of corporate and individual income taxes is plans under which corporate income is only taxed once.\n\nMcNulty has published 26 times in scholarly journals. His articles have been translated into several foreign languages, including Korean, Japanese and German.\n\nNotable among these articles are: \n\nMcNulty has also written 7 textbooks on tax law. \n\nMcNulty received his A.B. with honors and as a member of Phi Beta Kappa from Swarthmore College in 1956 and an LL.B. from Yale University in 1959 (Order of the Coif). He was an editor of the \"Yale Law Journal\". At Yale Law, McNulty studied under Friedrich Kessler. McNulty, was, subsequently, a law clerk to U.S. Supreme Court Justice Hugo Black from 1959 to 1960. McNulty has been a member of the State of Ohio bar since 1961 and of the bar of the United States Supreme Court since 1964.\n\n\n"}
{"id": "2259426", "url": "https://en.wikipedia.org/wiki?curid=2259426", "title": "Juggling notation", "text": "Juggling notation\n\nJuggling notation is the written depiction of concepts and practices in juggling. Toss juggling patterns have a reputation for being \"easier done than said\" – while it might be easy to learn a given maneuver and demonstrate it for others, it is often much harder to communicate the idea accurately using speech or plain text. To circumvent this problem, various numeric or diagram-based notation systems have been developed to facilitate communication of patterns or tricks between jugglers, as well the investigation and discovery of new patterns.\n\nA juggling notation system (based on music notation) was first proposed by Dave Storer in 1978 and while the first juggling diagram (a ladder diagram), by Claude Shannon around 1981, was not printed till 2010, the first printed diagram and second oldest notation system were proposed by Jeff Walker in 1982.\n\nWhile diagrams are the most visual and reader-friendly way to notate many juggling patterns, they rely on images, so are complicated to produce and unwieldy to share via text or speech.\n\n\nThe following notation systems use only numbers and common characters. The patterns can easily be communicated by text. Most numeric systems are designed to be processed by software juggling simulators — for example, to view juggling patterns as computer animations.\n\nDeveloped by mathematically inclined jugglers Bengt Magnusson and Bruce Boppo Tiemann in 1985, siteswap is by far the most common juggling notation.\n\nA given juggling pattern is represented by a sequence of digits, like \"333\", \"97531\", or \"744\". Each digit represents the number of throws that occur by the time that same prop will be caught. For example, \"333\" represents a common three-ball cascade, where three props are thrown before the same prop will be caught and thrown again. Within the \"531531\" pattern, the prop thrown first, the '5' throw, will not be caught until five throws have been made, including itself, where it will be thrown again as a '1'. The prop thrown next, the '3', will be thrown again on the third throw afterwards, the next '3'. And the next prop is thrown with a '1' throw, which is a direct pass to the other hand and will be thrown on the very next throw as a '5'. \n\nBecause the number represents the number of throws that occur before that prop will be caught, it can be also be thought to describe how high one throws the prop, or how long it remains in the air relative to the other throws, where even numbers inevitably come back to the same hand and odd numbers cross over to the other hand.\n\nThe number of props in a given juggling pattern can be determined by the average of one repeating group. \"633633633\", therefore describes a four-prop pattern, while \"414414414\" describes a three-prop juggling pattern.\n\n\"Vanilla\" siteswap is the most basic form of siteswap and uses only a simple string of digits to describe patterns that throw only one prop at a time, alternating between hands. For slightly more complicated patterns, extra rules and syntax are added to create the following two siteswap extensions:\n\n\nVanilla, synch, and multiplex siteswap are the \"standard\" forms of siteswap. Not only are they understood by jugglers, there are also many computer programs capable of animating juggling patterns entered in siteswap notation.\n\nOther extensions to siteswap have been developed for specific purposes. These are far less common than the \"standard\" forms of siteswap, understood by far fewer jugglers and only specialized software.\n\n\n"}
{"id": "344793", "url": "https://en.wikipedia.org/wiki?curid=344793", "title": "Laplace's demon", "text": "Laplace's demon\n\nIn the history of science, \"Laplace's demon\" was the first published articulation of causal or scientific determinism, by Pierre-Simon Laplace in 1814. According to determinism, if someone (the Demon) knows the precise location and momentum of every atom in the universe, their past and future values for any given time are entailed; they can be calculated from the laws of classical mechanics.\n\nA desire to confirm or refute Laplace's demon played a vital motivating role in the subsequent development of statistical thermodynamics, the first of several repudiations developed by later generations of physicists to the assumption of causal determinacy upon which Laplace's demon is erected.\n\nThis intellect is often referred to as \"Laplace's demon\" (and sometimes \"Laplace's Superman\", after Hans Reichenbach). Laplace himself did not use the word \"demon\", which was a later embellishment. As translated into English above, he simply referred to: \"Une intelligence... Rien ne serait incertain pour elle, et l'avenir, comme le passé, serait présent à ses yeux.\" Apparently, Laplace was not the first to evoke one such demon and strikingly similar passages can be found decades before Laplace's \"Essai philosophique\" in the work of scholars such as Nicolas de Condorcet and Baron D'Holbach. However, it seems that the first who offered the image of a super-powerful calculating intelligence was Roger Joseph Boscovich, whose formulation of the principle of determinism in his 1758 \"Theoria philosophiae naturalis\" turns out not only to be temporally prior to Laplace's but also—being founded on fewer metaphysical principles and more rooted in and elaborated by physical assumptions—to be more precise, complete and comprehensive than Laplace's somewhat parenthetical statement of the doctrine.\n\nAccording to chemical engineer Robert Ulanowicz, in his 1986 book \"Growth and Development\", Laplace's demon met its end with early 19th century developments of the concepts of irreversibility, entropy, and the second law of thermodynamics. In other words, Laplace's demon was based on the premise of reversibility and classical mechanics; however, Ulanowicz points out that many thermodynamic processes are irreversible, so that if thermodynamic quantities are taken to be purely physical then no such demon is possible as one could not reconstruct past positions and momenta from the current state. Maximum entropy thermodynamics takes a very different view, considering thermodynamic variables to have a statistical basis which can be kept separate from the microscopic physics. However, this theory has met criticism regarding its ability to make predictions about physics; a number of physicists and mathematicians, including Yvan Velenik of the Department of Mathematics for the University of Geneva, have pointed out that maximum entropy thermodynamics essentially describes our knowledge about a system and not the system itself.\n\nDue to its canonical assumption of determinism, Laplace's demon is incompatible with the Copenhagen interpretation, which stipulates indeterminacy. The interpretation of quantum mechanics is still very much open for debate and there are many who take opposing views (such as the Many Worlds Interpretation and the de Broglie–Bohm interpretation).\n\nChaos theory is sometimes pointed out as a contradiction to Laplace's demon: it describes how a deterministic system can nonetheless exhibit behavior that is impossible to predict: as in the butterfly effect, minor variations between the starting conditions of two systems can result in major differences. While this explains unpredictability in practical cases, applying it to Laplace's case is questionable: under the strict demon hypothesis all details are known—to infinite precision—and therefore variations in starting conditions are non-existent. Put another way: Chaos theory is applicable when knowledge of the system is imperfect whereas Laplace's demon assumes perfect knowledge of the system, therefore chaos theory and Laplace's demon are actually compatible with each other.\n\nIn 2008, David Wolpert used Cantor diagonalization to disprove Laplace's demon. He did this by assuming that the demon is a computational device and showed that no two such devices can completely predict each other.. Wolpert's paper was cited in 2014 in a paper of Josef Rukavicka, where a significantly simpler argument is presented that disproves Laplace's demon using Turing machines. \n\nThere has recently been proposed a limit on the computational power of the universe, i.e. the ability of Laplace's demon to process an infinite amount of information. The limit is based on the maximum entropy of the universe, the speed of light, and the minimum amount of time taken to move information across the Planck length, and the figure was shown to be about 10 bits. Accordingly, anything that requires more than this amount of data cannot be computed in the amount of time that has elapsed so far in the universe.\n\nAnother theory suggests that if Laplace's demon were to occupy a parallel universe or alternate dimension from which it could determine the implied data and do the necessary calculations on an alternate and greater time line, the aforementioned time limitation would not apply. This position is for instance explained in \"The Fabric of Reality\" by David Deutsch, who says that realizing a 300-qubit quantum computer would prove the existence of parallel universes carrying the computation.\n\nCounter arguments to this can be made using string theory. Albeit, the gradients of finite theories are useful, speculative scenarios, such as space-time decompactification occurring on a faster frame, require infinities whose interpretation remains open.\n\nIn the anime series , Laplace's Demon is the basis of a high school student's computer program called Dark Star. Dark Star is a program which allows for a masked vigilante, Twenty Faces, to cause the deaths of people who have escaped justice.\n\nBlast of Tempest Chaos Theory and the Butterfly Effect are incorporated in the main theme, where time travel and breaking out of parallel universes' becomes the main plot.\n\nIn the film Waking Life a discussion of Laplace's Demon takes place, as well as a handling of the retort from Quantum Mechanics.\n\nIn the webcomic Dresden Codak this concept is used in a page melding philosophical notions and a Dungeons and Dragons séance entitled \"Advanced dungeons and discourse\". In this page, Kimiko Ross has to burn the second law of thermodynamics in order to summon the Demon.\n\nThe UK sitcom Spaced featured an episode called Chaos, in which the artist Brian makes an implicit reference to Laplace's Demon in a conversation about Chaos Theory. He states that reality is a mathematically predictable preordained system, even though it would \"utterly defy any possibility of comprehension by even the most brilliant human mind.\"\n\nIn the light novel and anime series Seishun Buta Yarou wa Bunny Girl Senpai no Yume wo Minai, it is mentioned in order to try define the situation in which the main protagonist is repeating a specific day.\n\nRapurasu no Majo (Laplace's witch), a 2015 novel by Japanese author Keigo Higashino. It was adapted to film in 2018, directed by Takashi Miike and starring Shō Sakurai.\n\n"}
{"id": "34764942", "url": "https://en.wikipedia.org/wiki?curid=34764942", "title": "Leon Jordan", "text": "Leon Jordan\n\nLeon Mercer Jordan (May 6, 1905, Kansas City, Missouri - July 15, 1970, Kansas City, Missouri) was an American police officer, politician and civil rights leader who was assassinated. He was \"one of the most influential African Americans in Kansas City's history\" and, at the time of his death, the \"state's most powerful black politician\".\n\nJordan attended Lincoln High School in Kansas City, served in the U.S. Army, and graduated from Wilberforce University in Wilberforce, Ohio in 1932. He married fellow Wilberforce student Orchid Irene Ramsey on August 10, 1932. After graduation, he worked as a school teacher.\n\nJordan joined the Kansas City Police Department in 1938, became a detective, and in 1952, became the first African-American police lieutenant in that department's history. He took a leave of absence in 1947, and spent eight years training the police forces of Liberia. A pilot, he flew his own plane around the country. In 1948, he helped coordinate the rescue of the French High Commissioner of West Africa and 16 other French officials after their plane made a forced landing. He was awarded the Chevalier of the Star of Africa by Liberian President William Tubman in 1948.\n\nIn 1951, Jordan became a life member of the National Association for the Advancement of Colored People. He returned to Kansas City in February, 1952, and was promoted to police lieutenant. However, he discovered that he had little power, so he resigned and went back to Liberia for three years. He returned to Kansas City for good in the mid-1950s, and purchased the Green Duck Tavern.\n\nIn 1958, Jordan became a Democratic Party committeeman for the 14th Ward of Kansas City. In 1962, Jordan co-founded Freedom, Inc. along with Bruce R. Watkins. The organization advocated political awareness among African-Americans in Kansas City, organized a massive voter registration drive, and developed African-American political candidates. In 1963, Jordan and Watkins helped pass an accommodations ordinance, desegregating all public facilities in the city.\n\nIn 1964, Freedom, Inc. put forward eight candidates for office, and seven of them won. Among them was Jordan, who was elected to the first of three terms in the Missouri House of Representatives. He was campaigning for a fourth term at the time he was murdered. Shortly before his death, he described himself as a \"radical\", adding \"I'm not a conformist but there are bounds of reason.\"\n\nAt about 1:00 a.m. on July 15, 1970, he was killed just outside his Green Duck Tavern by three shotgun blasts. Eyewitnesses reported that the three killers were African-American. The shotgun had been stolen, and was abandoned immediately. When it was recovered, it was traced to a burglary five years earlier in Independence, Missouri.\n\nThree men were arrested for the murder, including at least one affiliated with a criminal group called the \"Black Mafia\". One man was acquitted, and charges were dropped against the other two suspects.\n\nJordan was killed using a Remington 12-gauge Wingmaster shotgun which was one of several guns that had been stolen from a hardware store in Independence, Missouri in 1965. A January, 1966, report on the burglary by the Independence Police Department stated that the guns had later been sold through a \"North End Italian fence.\" This report was not discovered in the initial investigation of Jordan's murder, but was uncovered by investigative journalists working for the \"Kansas City Star\" in 2010. When the reporters asked the Kansas City Police Department about the gun, they were told that it had been lost in 1973. The gun may have been sold in a police surplus auction. Some time later, the police purchased the used shotgun from a gun store, and did not check the serial number. The gun was refurbished and placed into police service.\n\nOn November 5, 1997, a police officer used the shotgun to shoot and wound an armed suspect in North Kansas City, Missouri. The gun was analyzed by the crime lab, who failed to identify it as the Jordan murder weapon, and it was returned to police service the following year. Only when the \"Kansas City Star\" asked questions about the missing shotgun in 2010 did a crime lab technician run a computer check that located the gun, which was recovered from the trunk of a police car and then returned to the evidence room.\n\nIn 2010, reporters with the \"Kansas City Star\" began investigating the assassination while preparing for coverage of the 40th anniversary of Jordan's death. This led to discovery of the missing murder weapon and some old fingerprint cards, and that motivated the Kansas City Police Department to re-open the official investigation of the department's oldest cold case. Civil rights leader Alvin Sykes pressed the department for a complete investigation. In trying to determine who was responsible for the assassination, the newspaper reported that Jordan and his Freedom, Inc. political movement had been opposed to the \"North End\" faction in Kansas City politics, a group under the influence of La Cosa Nostra, and which had previously controlled black voting blocs. In 1965, Jordan had punched Frank Mazzuca, a fellow state legislator who was alleged to have supported mob interests in Jefferson City, Missouri, and death threats against Jordan were reported in the aftermath.\n\nThe newspaper reported that police informants associated with the Black Mafia had described the killing as a favor to North End mob interests, and that it was organized by \"Shotgun Joe\" Centimano, owner of a local liquor store. The informants said that Centimano had supplied the murder weapon and recruited the killers. The newspaper reported that one informant said the assassination had elements of both a \"contract killing\" and a \"revenge killing\", and that another said it was \"all about politics.\" News coverage said that a 900-page police report finished in 2011 had concluded that mob boss Nick Civella had given his \"blessing\" to Jordan's assassination. No one was indicted because all of the main players were dead by then.\n\nJordan's widow, Orchid, became a candidate for his legislative seat when her husband was killed. She won the election, and served for 16 years in the Missouri House of Representatives. She died on December 25, 1995 at the age of 85.\n\nThe Leon M. Jordan Memorial Park, located at 31st Street and Benton Boulevard in Kansas City, features a statue of Jordan and the following text on a plaque on the front of its base:\n\nHis papers, including extensive documentation of his service in Liberia, are collected in the library of the University of Missouri-Kansas City.\n\nFarnsworth, Robert M. (2013), Leon Mercer Jordan, The Founder of Freedom, Inc. Following in the Footsteps of His Father and Grandfather, University of Missouri Press\n\n"}
{"id": "1168528", "url": "https://en.wikipedia.org/wiki?curid=1168528", "title": "Marcel Broodthaers", "text": "Marcel Broodthaers\n\nMarcel Broodthaers (28 January 1924 – 28 January 1976) was a Belgian poet, filmmaker and artist with a highly literate and often witty approach to creating art works.\n\nBroodthaers was born in Brussels, Belgium, where he was associated with the Groupe Surréaliste-revolutionnaire from 1945 and dabbled in journalism, film, and poetry. After spending 20 years in poverty as a struggling poet, at the end of 1963 he decided to become an artist and began to make objects. He performed the symbolic act of embedding fifty unsold copies of his book of poems \"Pense-Bête\" in plaster, creating his first art object. That same year, 1964, for his first exhibition, he wrote a famous preface for the exhibition catalogue;\n\n\"I, too, wondered whether I could not sell something and succeed in life. For some time I had been no good at anything. I am forty years old... Finally the idea of inventing something insincere crossed my mind and I set to work straightaway. At the end of three months I showed what I had produced to Philippe Edouard Toussaint, the owner of the Galerie St Laurent. 'But it is art' he said 'and I will willingly exhibit all of it.' 'Agreed' I replied. If I sell something, he takes 30%. It seems these are the usual conditions, some galleries take 75%.\n\nWhat is it? In fact it is objects.\"\nBroodthaers made his first film in 1957, and from 1967 he produced over 50 short films in documentary, narrative, and experimental styles.\n\nBroodthaers later worked principally with assemblies of found objects and collage, often containing written texts. He incorporated written language in his art and used whatever was at hand for his raw materials—most notably the shells of eggs and mussels, but also furniture, clothing, garden tools, household gadgets and reproductions of artworks. In his \"Visual Tower\" (1966), Broodthaers made a seven-story circular tower of wood. He filled each story with uniform glass jars, and in every jar he placed an identical image taken from an illustrated magazine, of the eye of a beautiful young woman. For \"Surface de moules (avec sac) (Surface of mussels (with bag))\" (1966), he glued mussels in resin on a square panel; in 1974 the artist added a discreet metal hook to the centre of the work designed to support a shopping bag filled with mussel shells.\n\nFrom 1968 to 1975 Broodthaers produced large-scale environmental pieces that reworked the very notion of the museum. His most noted work was an installation which began in his Brussels house which he called \"Musée d'Art Moderne, Départment des Aigles\" (1968), containing different representations of eagles in glass cases that were accompanied by signs that asserted \"This is not a work of art\", implying that museums obscure the ideological functioning of images by imposing illegitimate classifications of value. This installation was followed by a further eleven manifestations of the 'museum', including at the Kunsthalle Düsseldorf for an exhibition in 1970 and at documenta 5 in Kassel in 1972. In 1970 Broodthaers conceived of the \"Financial Section\", which encompassed an attempt to sell the museum \"on account of bankruptcy.\" The sale was announced on the cover of the Art Cologne fair catalogue in 1971, but no buyers were found. As part of the \"Financial Section\", the artist also produced an unlimited edition of gold ingots stamped with the museum's emblem, an eagle, a symbol associated with power and victory. The ingots were sold to raise money for the museum, at a price calculated by doubling the market value of gold, the surcharge representing the bar's value as art. In 1974, Broodthaers launched three separate exhibitions in the same week, each consisting of a new type of installation artwork he referred to as “décors.” The venues of these exhibitions were Wide White Space in Antwerp, Catalogue-Catalogus at Palais de Beaux-Arts Brussels, and Eloge du sujet at Kunstmuseum Basel. In 1975 Broodthaers presented the exhibition \"L’Angelus de Daumier\" at the Centre National d’Art Contemporain in Paris, at which each room had the name of a colour. In \"La Salle Blanche (The White Room)\" (1975), a life-size copy of a room and a half in Broodthaers' home in Brussels, the wooden walls of the empty, unfurnished rooms are covered with printed words in French—such as museum, gallery, oil, subject, composition, images, and privilege—all intended to examine \"the influence of language on perceptions of the world and the ways museums affect the production and consumption of art.\" For such works he is associated with the late 20th century global spread of both installation art as well as \"institutional critique,\" in which interrelationships between artworks, the artist, and the museum are a focus. Indeed, Broodthaers' \"Musée d'Art Moderne\", his \"first fictional museum,\" allowed him to simultaneously posture as artist, director, curator and trustee in a self-reflexive examination of the order and prescriptions implicit in the production of museum exhibits.\n\nFrom late 1969, Broodthaers lived mainly in Düsseldorf, Berlin, and finally London. He died of a liver disease in Cologne, Germany on his 52nd birthday. He is buried at Ixelles Cemetery in Brussels under a tombstone of his own design.\n\nIn 1980, the exhibition \"Marcel Broodthaers\" was mounted by the Tate Gallery, London. Other important retrospectives of Broodthaers’ work have been held at the Walker Art Center (1989), Museum of Contemporary Art, Los Angeles (1989); Carnegie Museum of Art, Pittsburgh (1989); Jeu de Paume, Paris (1991); and Palais des Beaux Arts, Brussels (2000). The most recent traveling survey was organized by the Museum of Modern Art, New York and the Museo Nacional Centro de Arte Reina Sofía, Madrid in 2016. The show also traveled to the Kunstsammlung Nordrhein-Westfalen, Düsseldorf in 2017. An important solo exhibition of the film work, \"Marcel Broodthaers: Cinéma\", was shown at Fundacio Antoni Tàpies, Barcelona; Centro Galego de Arte Contemporánea, Santiago de Compostela, and Kunsthalle Düsseldorf (1997). The first Solo Show in Austria was presented 2003 at Kunsthalle Vienna. In 2015 the Fridericianum presented a comprehensive retrospective featuring works from all of the artist's creative periods. \"Marcel Broodthaers: A Retrospective\" at the Museum of Modern Art, New York was the first Broodthaers retrospective organized in New York. This solo exhibition was at the Museum of Modern Art, New York February 14–May 15, 2016 and then traveled to Museo Nacional Centro de Arte Reina Sofía , Madrid, in October 2016, and to the Kunstsammlung Nordrhein-Westfalen, Düsseldorf in the Spring of 2017.\n\nThere have been many notable international group exhibitions, including documenta 10, 7 and 5, Kassel (1997, 1982, and 1972).\n\nAs a poet and political activist, Broodthaers had a life-long interest in the circulatory power of printed matter: posters, graphics, editions, and artist books. In addition to the monetary potential of galleries selling limited editions, artist's books published with nonprofit institutions like Kunstalle Düsseldorf, the Deutsche Academischer Austaudienst (DAAD), Berlin, the Museum of Modern Art, Oxford, and the Centre Georges Pompidou, Paris, merged the artist's commercial ambitions with conceptual and philosophical ideas. For example, Broodthaers' catalogue for \"Der Adler von Oligizän bis heute,\" the seminal culmination of his \"Musee d'Art Moderne, department des Aigles,\" at Kunstalle Düsseldorf in 1972, was published in two volumes. The first volume featured a scholarly index of the items on display and was for sale at the opening of the exhibition, replete with a coupon that could be redeemed for a copy of volume two, which came out at the close of the exhibition and featured views of the installation.\n\nBroodthaers returned to this motif for his artist's book \"Photographieren Verboten/No Photographs Allowed\" but aimed it at the convention of the exhibition catalogue, with version one published by the DAAD, Berlin, and version two by the Museum of Modern Art, Oxford. The Oxford book presents ostensibly the same content as the DAAD book but scrambles the internal logic of the book, changing the context of its standard component parts—title page, checklist, scholarly essay, curriculum vitae—and thus the implications of each. Content normally reserved for the rear of an exhibition catalogue (in this case the artist's cv) appears on the inside front cover as a decorative pattern, and scholarly content such as the catalogue essay appears on the outside back cover like an advertising blurb.\n\n"}
{"id": "83525", "url": "https://en.wikipedia.org/wiki?curid=83525", "title": "Matriarchy", "text": "Matriarchy\n\nMatriarchy is a social system in which females (most notably in mammals) hold the primary power positions in roles of political leadership, moral authority, social privilege and control of property at the specific exclusion of males — at least to a large degree.\n\nWhile those definitions apply in general English, definitions specific to the disciplines of anthropology and feminism differ in some respects. Most anthropologists hold that there are no known anthropological societies \"that are unambiguously matriarchal\", but some authors believe exceptions may exist or may have.\n\nMatriarchies may also be confused with matrilineal, matrilocal, and matrifocal societies. A few people consider any non-patriarchal system to be matriarchal, thus including genderally equalitarian systems (Peggy Reeves Sanday favors redefining and reintroducing the word matriarchy, especially in reference to contemporary matrilineal societies such as the Minangkabau), but most academics exclude them from matriarchies strictly defined.\n\nIn 19th-century Western scholarship, the hypothesis of matriarchy representing an early, mainly prehistoric, stage of human development gained popularity. Possibilities of so-called primitive societies were cited and the hypothesis survived into the 20th century, including in the context of second-wave feminism. This hypothesis was criticized by some authors such as Cynthia Eller in \"The Myth of Matriarchal Prehistory\" and remains as a largely unsolved question to this day. Some older myths describe matriarchies.\n\nSeveral modern feminists have advocated for matriarchy now or in the future and it has appeared in feminist literature. In several theologies, matriarchy has been portrayed as negative.\nAccording to the \"Oxford English Dictionary\" (\"OED\"), matriarchy is a \"form of social organization in which the mother or oldest female is the head of the family, and descent and relationship are reckoned through the female line; government or rule by a woman or women.\" A popular definition, according to James Peoples and Garrick Bailey, is \"female dominance\". Within the academic discipline of cultural anthropology, according to the \"OED\", matriarchy is a \"culture or community in which such a system prevails\" or a \"family, society, organization, etc., dominated by a woman or women.\" In general anthropology, according to William A. Haviland, matriarchy is \"rule by women\". A matriarchy is a society in which females, especially mothers, have the central roles of political leadership, moral authority, and control of property, but does not include a society that occasionally is led by a female for nonmatriarchal reasons or an occupation in which females generally predominate without reference to matriarchy, such as prostitution or women's auxiliaries of organizations run by men. According to Lawrence A. Kuzner in 1997, A. R. Radcliffe-Brown argued in 1924 that the definitions of matriarchy and patriarchy had \"logical and empirical failings ... [and] were too vague to be scientifically useful\".\n\nMost academics exclude egalitarian nonpatriarchal systems from matriarchies more strictly defined. According to Heide Göttner-Abendroth, a reluctance to accept the existence of matriarchies might be based on a specific culturally biased notion of how to define matriarchy: because in a patriarchy men rule over women, a matriarchy has frequently been conceptualized as women ruling over men, while she believed that matriarchies are egalitarian.\nThe word matriarchy, for a society politically led by females, especially mothers, who also control property, is often interpreted to mean the genderal opposite of patriarchy, but it is not an opposite. According to Peoples and Bailey, the view of anthropologist Peggy Reeves Sanday is that matriarchies are not a mirror form of patriarchies but rather that a matriarchy \"emphasizes maternal meanings where 'maternal symbols are linked to social practices influencing the lives of both sexes and where women play a central role in these practices. Journalist Margot Adler wrote, \"literally, ... [\"matriarchy\"] means government by mothers, or more broadly, government and power in the hands of women.\" Barbara Love and Elizabeth Shanklin wrote, \"by 'matriarchy,' we mean a non-alienated society: a society in which women, those who produce the next generation, define motherhood, determine the conditions of motherhood, and determine the environment in which the next generation is reared.\" According to Cynthia Eller, \"'matriarchy' can be thought of ... as a shorthand description for any society in which women's power is equal or superior to men's and in which the culture centers around values and life events described as 'feminine.'\" Eller wrote that the idea of matriarchy mainly rests on two pillars, romanticism and modern social criticism. The notion of matriarchy was meant to describe something like a utopia placed in the past in order to legitimate contemporary social criticism. With respect to a prehistoric matriarchal Golden Age, according to Barbara Epstein, \"matriarchy ... means a social system organized around matriliny and goddess worship in which women have positions of power.\" According to Adler, in the Marxist tradition, it usually refers to a pre-class society \"where women and men share equally in production and power.\"\n\nAccording to Adler, \"a number of feminists note that few definitions of the word [matriarchy], despite its literal meaning, include any concept of power, and they suggest that centuries of oppression have made it impossible for women to conceive of themselves with such power.\"\n\nMatriarchy has often been presented as negative, in contrast to patriarchy as natural and inevitable for society, thus that matriarchy is hopeless. Love and Shanklin wrote:\nWhen we hear the word \"matriarchy\", we are conditioned to a number of responses: that matriarchy refers to the past and that matriarchies have never existed; that matriarchy is a hopeless fantasy of female domination, of mothers dominating children, of women being cruel to men. Conditioning us negatively to matriarchy is, of course, in the interests of patriarchs. We are made to feel that patriarchy is natural; we are less likely to question it, and less likely to direct our energies to ending it.\n\nThe Matriarchal Studies school led by Göttner-Abendroth calls for an even more inclusive redefinition of the term: Göttner-Abendroth defines \"Modern Matriarchal Studies\" as the \"investigation and presentation of non-patriarchal societies\", effectively defining matriarchy as non-patriarchy. She has also defined matriarchy as characterized by the sharing of power equally between the two genders. According to Diane LeBow, \"matriarchal societies are often described as ... egalitarian ...\", although anthropologist Ruby Rohrlich has written of \"the centrality of women in an egalitarian society.\"\n\nMatriarchy is also the public formation in which the woman occupies the ruling position in a family. For this usage, some scholars now prefer the term matrifocal to matriarchal. Some, including Daniel Moynihan, claimed that there is a matriarchy among Black families in the United States, because a quarter of them were headed by single women; thus, families composing a substantial minority of a substantial minority could be enough for the latter to constitute a matriarchy within a larger non-matriarchal society.\n\nEtymologically, it is from Latin \"māter\" (genitive \"mātris\"), \"mother\" and Greek ἄρχειν \"arkhein\", \"to rule\". The notion of matriarchy was defined by Joseph-François Lafitau (1681–1746), who first named it \"ginécocratie\". According to the \"OED\", the earliest known attestation of the word matriarchy is in 1885. By contrast, gynæcocracy, meaning 'rule of women', has been in use since the 17th century, building on the Greek word found in Aristotle and Plutarch.\n\nTerms with similar etymology are also used in various social sciences and humanities to describe matriarchal or \"matriological\" aspects of social, cultural and political processes. Adjective \"matriological\" is derived from the noun \"matriology\" that comes from Latin word \"māter\" (mother) and Greek word λογος (\"logos\", teaching about). The term matriology was used in theology and history of religion as a designation for the study of particular motherly aspects of various female deities. The term was subsequently borrowed by other social sciences and humanities and its meaning was widened in order to describe and define particular female-dominated and female-centered aspects of cultural and social life. The male alternative for matriology is patriology, with patriarchy being the male alternative to matriarchy.\n\nIn their works, Johann Jakob Bachofen and Lewis Morgan used such terms and expressions as \"mother-right\", \"female rule\", \"gyneocracy\", and \"female authority\". All these terms meant the same: the rule by females (mother or wife). Although Bachofen and Lewis Morgan confined the \"mother right\" inside households, it was the basis of female influence upon the whole society. The authors of the classics did not think that \"gyneocracy\" meant 'female government' in politics. They were aware of the fact that the sexual structure of government had no relation to domestic rule and to roles of both sexes.\n\nA matriarchy is also sometimes called a \"gynarchy\", a \"gynocracy\", a \"gynecocracy\", or a \"gynocentric\" society, although these terms do not definitionally emphasize motherhood. Cultural anthropologist Jules de Leeuwe argued that some societies were \"mainly \"gynecocratic\"\" (others being \"mainly \"androcratic\"\").\n\nGynecocracy, gynaecocracy, gynocracy, gyneocracy, and gynarchy generally mean 'government by women over women and men'. All of these words are synonyms in their most important definitions. While these words all share that principal meaning, they differ a little in their additional meanings, so that \"gynecocracy\" also means 'women's social supremacy', \"gynaecocracy\" also means 'government by one woman', 'female dominance', and, derogatorily, 'petticoat government', and \"gynocracy\" also means 'women as the ruling class'. \"Gyneocracy\" is rarely used in modern times. None of these definitions are limited to mothers.\n\nSome question whether a queen ruling without a king is sufficient to constitute female government, given the amount of participation of other men in most such governments. One view is that it is sufficient. \"By the end of [Queen] Elizabeth's reign, gynecocracy was a \"fait accompli\"\", according to historian Paula Louise Scalingi. Gynecocracy is defined by Scalingi as \"government by women\", similar to dictionary definitions (one dictionary adding 'women's social supremacy' to the governing role). Scalingi reported arguments for and against the validity of gynocracy and said, \"the humanists treated the question of female rule as part of the larger controversy over sexual equality.\" Possibly, queenship, because of the power wielded by men in leadership and assisting a queen, leads to queen bee syndrome, contributing to the difficulty of other women in becoming heads of the government.\n\nSome matriarchies have been described by historian Helen Diner as \"a strong gynocracy\" and \"women monopolizing government\" and she described matriarchal Amazons as \"an extreme, feminist wing\" of humanity and that North African women \"ruled the country politically,\" and, according to Adler, Diner \"envision[ed] a dominance matriarchy\".\n\nGynocentrism is the 'dominant or exclusive focus on women', is opposed to androcentrism, and \"invert[s] ... the privilege of the ... [male/female] binary ...[,] [some feminists] arguing for 'the superiority of values embodied in traditionally female experience'\".\n\nSome people who sought evidence for the existence of a matriarchy often mixed matriarchy with anthropological terms and concepts describing specific arrangements in the field of family relationships and the organization of family life, such as matrilineality and matrilocality. These terms refer to intergenerational relationships (as matriarchy may), but do not distinguish between males and females insofar as they apply to specific arrangements for sons as well as daughters from the perspective of their relatives on their mother's side. Accordingly, these concepts do not represent matriarchy as 'power of women over men'.\n\nAnthropologists have begun to use the term matrifocality. There is some debate concerning the terminological delineation between \"matrifocality\" and \"matriarchy\". Matrifocal societies are those in which women, especially mothers, occupy a central position. Anthropologist R. T. Smith refers to \"matrifocality\" as the kinship structure of a social system whereby the mothers assume structural prominence. The term does not necessarily imply domination by women or mothers. In addition, some authors depart from the premise of a mother-child dyad as the core of a human group where the grandmother was the central ancestor with her children and grandchildren clustered around her in an extended family.\n\nThe term matricentric means 'having a mother as head of the family or household'.\nMatristic: Feminist scholars and archeologists such as Marija Gimbutas, Gerda Lerner, and Riane Eisler label their notion of a \"woman-centered\" society surrounding Mother Goddess worship during prehistory (in Paleolithic and Neolithic Europe) and in ancient civilizations by using the term \"matristic\" rather than \"matriarchal.\" Marija Gimbutas states that she uses \"the term matristic simply to avoid the term matriarchy with the understanding that it incorporates matriliny.\"\n\nMatrilineality, in which descent is traced through the female line, is sometimes conflated with historical matriarchy. Sanday favors redefining and reintroducing the word \"matriarchy\", especially in reference to contemporary matrilineal societies such as the Minangkabau. The 19th-century belief that matriarchal societies existed was due to the transmission of \"economic and social power ... through kinship lines\" so that \"in a matrilineal society all power would be channeled through women. Women may not have retained all power and authority in such societies ..., but they would have been in a position to control and dispense power.\"\n\nA matrilocal society defines a society in which a couple resides close to the bride's family rather than the bridegroom's family.\n\nMost anthropologists hold that there are no known societies that are unambiguously matriarchal. According to J. M. Adovasio, Olga Soffer, and Jake Page, no true matriarchy is known actually to have existed. Anthropologist Joan Bamberger argued that the historical record contains no primary sources on any society in which women dominated. Anthropologist Donald Brown's list of human cultural universals (\"viz.\", features shared by nearly all current human societies) includes men being the \"dominant element\" in public political affairs, which he asserts is the contemporary opinion of mainstream anthropology. There are some disagreements and possible exceptions. A belief that women's rule preceded men's rule was, according to Haviland, \"held by many nineteenth-century intellectuals\". The hypothesis survived into the 20th century and was notably advanced in the context of feminism and especially second-wave feminism, but the hypothesis is mostly discredited today, most experts saying that it was never true.\n\nMatriarchs, according to Peoples and Bailey, do exist; there are \"individual matriarchs of families and kin groups.\"\n\n\"The Cambridge Ancient History\" (1975) stated that \"the predominance of a supreme goddess is probably a reflection from the practice of matriarchy which at all times characterized Elamite civilization to a greater or lesser degree\".\n\nTacitus claimed in his book \"Germania\" that in \"the nations of the Sitones a woman is the ruling sex.\"\n\nLegends of Amazon women originated not from South America, but rather Scythia (present day Russia).\n\nPossible matriarchies in Burma are, according to Jorgen Bisch, the Padaungs and, according to Andrew Marshall, the Kayaw.\n\nThe Mosuo culture, which is in China near Tibet, is frequently described as matriarchal. The Mosuo themselves often use this description and they believe it increases interest in their culture and thus attracts tourism. The term matrilineal is sometimes used, and, while more accurate, still doesn't reflect the full complexity of their social organization. In fact, it is not easy to categorize Mosuo culture within traditional Western definitions. They have aspects of a matriarchal culture: Women are often the head of the house, inheritance is through the female line, and women make business decisions. However, unlike in a true matriarchy, political power tends to be in the hands of males.\n\nIn India, of communities recognized in the national Constitution as Scheduled Tribes, \"some ... [are] matriarchal and matrilineal\" \"and thus have been known to be more egalitarian\". According to interviewer Anuj Kumar, Manipur, India, \"has a matriarchal society\", but this may not be a scholarly assessment.\n\nNairs in kerala follow matriarchy system. There were times in the 17th century AD when the Queen was the head of the family. The kingdom passed from the king to his sister's son. The Queen is always the king's sister. The head of the family is the eldest irrespective of gender. Refer kings of Travancore.\n\nAnthropologist Peggy Reeves Sanday said the Minangkabau society may be a matriarchy.\n\nAccording to William S. Turley, \"the role of women in traditional Vietnamese culture was determined [partly] by ... indigenous customs bearing traces of matriarchy\", affecting \"different social classes\" to \"varying degrees\". According to Peter C. Phan, that \"the first three persons leading insurrections against China were women ... that ancient Vietnam was a matriarchal society\" and \"the ancient Vietnamese family system was most likely matriarchal, with women ruling over the clan or tribe\" until the Vietnamese the patriarchal system introduced by the Chinese\", although \"this patriarchal system ... was not able to dislodge the Vietnamese women from their relatively high position in the family and society, especially among the peasants and the lower classes\", with modern \"culture and legal codes ... [promoting more] rights and privileges\" for women than in Chinese culture. According to Chiricosta, the legend of Âu Cơ is said to be evidence of \"the presence of an original 'matriarchy' in North Vietnam and [it] led to the double kinship system, which developed there ... [and which] combined matrilineal and patrilineal patterns of family structure and assigned equal importance to both lines.\" Chiricosta said that other scholars relied on \"this 'matriarchal' aspect of the myth to differentiate Vietnamese society from the pervasive spread of Chinese Confucian patriarchy\" and that \"resistance to China's colonization of Vietnam ... [combined with] the view that Vietnam was originally a matriarchy ... [led to viewing] women's struggles for liberation from (Chinese) patriarchy as a metaphor for the entire nation's struggle for Vietnamese independence.\" According to Keith Weller Taylor, \"the matriarchal flavor of the time is ... attested by the fact that Trung Trac's mother's tomb and spirit temple have survived, although nothing remains of her father\", and the \"society of the Trung sisters\" was \"strongly matrilineal\". According to Donald M. Seekins, an indication of \"the strength of matriarchal values\" was that a woman, Trưng Trắc, with her younger sister Trưng Nhị, raised an army of \"over 80,000 soldiers ... [in which] many of her officers were women\", with which they defeated the Chinese. According to Seekins, \"in [the year] 40, Trung Trac was proclaimed queen, and a capital was built for her\" and modern Vietnam considers the Trung sisters to be heroines. According to Karen G. Turner, in the 3rd century A.D., Lady Triệu to personify the matriarchal culture that mitigated Confucianized patriarchal norms ... [although] she is also painted as something of a freak ... with her ... savage, violent streak.\"\n\nThe Hopi (in what is now the Hopi Reservation in northeastern Arizona), according to Alice Schlegel, had as its \"gender ideology ... one of female superiority, and it operated within a social actuality of sexual equality.\" According to LeBow (based on Schlegel's work), in the Hopi, \"gender roles ... are egalitarian ... [and] [n]either sex is inferior.\" LeBow concluded that Hopi women \"participate fully in ... political decision-making.\" According to Schlegel, \"the Hopi no longer live as they are described here\" and \"the attitude of female superiority is fading\". Schlegel said the Hopi \"were and still are matrilinial\" and \"the household ... was matrilocal\". Schlegel explains why there was female superiority as that the Hopi believed in \"life as the highest good ... [with] the female principle ... activated in women and in Mother Earth ... as its source\" and that the Hopi \"were not in a state of continual war with equally matched neighbors\" and \"had no standing army\" so that \"the Hopi lacked the spur to masculine superiority\" and, within that, as that women were central to institutions of clan and household and predominated \"within the economic and social systems (in contrast to male predominance within the political and ceremonial systems)\", the Clan Mother, for example, being empowered to overturn land distribution by men if she felt it was unfair, since there was no \"countervailing ... strongly centralized, male-centered political structure\".\n\nThe Iroquois Confederacy or League, combining 5–6 Native American Haudenosaunee nations or tribes before the U.S. became a nation, operated by The Great Binding Law of Peace, a constitution by which women participated in the League's political decision-making, including deciding whether to proceed to war, through what may have been a matriarchy or gyneocracy. According to Doug George-Kanentiio, in this society, mothers exercise central moral and political roles. The dates of this constitution's operation are unknown; the League was formed in approximately 1000–1450, but the constitution was oral until written in about 1880. The League still exists.\n\nGeorge-Kanentiio explains:\n\nIn our society, women are the center of all things. Nature, we believe, has given women the ability to create; therefore it is only natural that women be in positions of power to protect this function...We traced our clans through women; a child born into the world assumed the clan membership of its mother. Our young women were expected to be physically strong...The young women received formal instruction in traditional planting...Since the Iroquois were absolutely dependent upon the crops they grew, whoever controlled this vital activity wielded great power within our communities. It was our belief that since women were the givers of life they naturally regulated the feeding of our people...In all countries, real wealth stems from the control of land and its resources. Our Iroquois philosophers knew this as well as we knew natural law. To us it made sense for women to control the land since they were far more sensitive to the rhythms of the Mother Earth. We did not own the land but were custodians of it. Our women decided any and all issues involving territory, including where a community was to be built and how land was to be used...In our political system, we mandated full equality. Our leaders were selected by a caucus of women before the appointments were subject to popular review...Our traditional governments are composed of an equal number of men and women. The men are chiefs and the women clan-mothers...As leaders, the women closely monitor the actions of the men and retain the right to veto any law they deem inappropriate...Our women not only hold the reigns of political and economic power, they also have the right to determine all issues involving the taking of human life. Declarations of war had to be approved by the women, while treaties of peace were subject to their deliberations.\n\nThe controversy surrounding prehistoric or \"primal\" matriarchy began in reaction to the book by Bachofen, \"Mother Right: An Investigation of the Religious and Juridical Character of Matriarchy in the Ancient World\", in 1861. Several generations of ethnologists were inspired by his pseudo-evolutionary theory of archaic matriarchy. Following him and Jane Ellen Harrison, several generations of scholars, usually arguing from known myths or oral traditions and examination of Neolithic female cult-figures, suggested that many ancient societies might have been matriarchal, or even that there existed a wide-ranging matriarchal society prior to the ancient cultures of which we are aware. According to Uwe Wesel, Bachofen's myth interpretations have proved to be untenable. The concept was further investigated by Lewis Morgan. Many researchers studied the phenomenon of matriarchy afterward, but the basis was laid by the classics of sociology. The notion of a \"woman-centered\" society was developed by Bachofen, whose three-volume \"Myth, Religion, and Mother Right\" (1861) impacted the way classicists such as Harrison, Arthur Evans, Walter Burkert, and James Mellaart looked at the evidence of matriarchal religion in pre-Hellenic societies. According to historian Susan Mann, as of 2000, \"few scholars these days find ... [a \"notion of a stage of primal matriarchy\"] persuasive.\"\n\nThe following excerpts from Lewis Morgan's \"Ancient Society\" will explain the use of the terms: \"In a work of vast research, Bachofen has collected and discussed the evidence of female authority, mother-right, and of female rule, gynecocracy.\" \"Common lands and joint tillage would lead to joint-tenant houses and communism in living; so that gyneocracy seems to require for its creation, descent in the female line. Women thus entrenched in large households, supplied from common stores, in which their own gens so largely predominated in numbers, would produce the phenomena of mother right and gyneocracy, which Bachofen has detected and traced with the aid of fragments of history and of tradition.\"\n\nKurt Derungs is a non-academic author advocating an \"anthropology of landscape\" based on allegedly matriarchal traces in toponymy and folklore.\n\nFriedrich Engels, in 1884, claimed that, in the earliest stages of human social development, there was group marriage and that therefore paternity was disputable, whereas maternity was not, so that a family could be traced only through the female line, and claimed that this was connected with the dominance of women over men or a \"Mutterrecht\", which notion Engels took from Bachofen, who claimed, based on his interpretations of myths, that myths reflected a memory of a time when women dominated over men. Engels speculated that the domestication of animals increased wealth claimed by men. Engels said that men wanted control over women for use as laborers and because they wanted to pass on their wealth to their children, requiring monogamy. Engels did not explain how this could happen in a matriarchal society, but said that women's status declined until they became mere objects in the exchange trade between men and patriarchy was established, causing the global defeat of the female sex and the rise of individualism, competition, and dedication to achievement. According to Eller, Engels may have been influenced with respect to women's status by August Bebel, according to whom this matriarchy resulted in communism while patriarchy did not.\n\nAustrian writer Bertha Diener, also known as Helen Diner, wrote \"Mothers and Amazons\" (1930), which was the first work to focus on women's cultural history. Hers is regarded as a classic of feminist matriarchal study. Her view is that in the past all human societies were matriarchal; then, at some point, most shifted to patriarchal and degenerated. The controversy was reinforced further by the publication of \"The White Goddess\" by Robert Graves (1948) and his later analysis of classical Greek mythology and the vestiges of earlier myths that had been rewritten after a profound change in the religion of Greek civilization that occurred within its very early historical times. From the 1950s, Marija Gimbutas developed a theory of an \"Old European culture\" in Neolithic Europe which had matriarchal traits, replaced by the patriarchal system of the Proto-Indo-Europeans with the spread of Indo-European languages beginning in the Bronze Age. According to Epstein, anthropologists in the 20th century said that \"the goddess worship or matrilocality that evidently existed in many paleolithic societies was not necessarily associated with matriarchy in the sense of women's power over men. Many societies can be found that exhibit those qualities along with female subordination.\" From the 1970s, these ideas were taken up by popular writers of second-wave feminism and expanded with the speculations of Margaret Murray on witchcraft, by the Goddess movement, and in feminist Wicca, as well as in works by Eisler, Elizabeth Gould Davis, and Merlin Stone.\n\n\"A Golden Age of matriarchy\" was, according to Epstein, prominently presented by Charlene Spretnak and \"encouraged\" by Stone and Eisler, but, at least for the Neolithic Age, has been denounced as feminist wishful thinking in \"The Inevitability of Patriarchy\", \"Why Men Rule\", \"Goddess Unmasked\", and \"The Myth of Matriarchal Prehistory\" and is not emphasized in third-wave feminism. According to Eller, Gimbutas had a large part in constructing a myth of historical matriarchy by examining Eastern European cultures that she asserts, by and large, never really bore any resemblance in character to the alleged universal matriarchy suggested by Gimbutas and Graves. She asserts that in \"actually documented primitive societies\" of recent (historical) times, paternity is never ignored and that the sacred status of goddesses does not automatically increase female social status, and believes that this affirms that utopian matriarchy is simply an inversion of antifeminism.\n\nJ.F. del Giorgio insists on a matrifocal, matrilocal, matrilineal Paleolithic society.\n\nAccording to Rohrlich, \"many scholars are convinced that Crete was a matriarchy, ruled by a queen-priestess\" and the \"Cretan civilization\" was \"matriarchal\" before \"1500 B.C.,\" when it was overrun and colonized.\n\nAlso according to Rohrlich, \"in the early Sumerian city-states 'matriarchy seems to have left something more than a trace.\n\nOne common misconception among historians of the Bronze Age such as Stone and Eisler is the notion that the Semites were matriarchal while the Indo-Europeans practiced a patriarchal system. An example of this view is found in Stone's \"When God Was a Woman\", wherein she makes the case that the worship of Yahweh was an Indo-European invention superimposed on an ancient matriarchal Semitic nation. Evidence from the Amorites and pre-Islamic Arabs, however, indicates that the primitive Semitic family was in fact patriarchal and patrilineal.\n\nHowever, not all scholars agree. Anthropologist and Biblical scholar Raphael Patai writes in The Hebrew Goddess that the Jewish religion, far from being pure monotheism, contained from earliest times strong polytheistic elements, chief of which was the cult of Asherah, the mother goddess. A story in the Biblical Book of Judges places the worship of Asherah in the 12th century B.C.E. Originally a Canaanite goddess, her worship was adopted by Hebrews who intermarried with Canaanites. She was worshipped in public and was represented by carved wooden poles. Numerous small nude female figurines of clay were found all over ancient Palestine and a 7th C. Hebrew text invokes her aid for a woman giving birth.\n\nShekinah is the name of the feminine holy spirit who embodies both divine radiance and compassion. She comforts the sick and dejected, accompanies the Jews whenever they are exiled, and intercedes with God to exercise mercy rather than to inflict retribution on sinners. While not a creation of the Hebrew Bible, Shekinah appears in a slightly later Aramaic translation of the Bible in the first or second century C.E., according to Patai. Initially portrayed as the presence of God, she later becomes distinct from God, taking on more physical attributes.\n\nMeanwhile, the Indo-Europeans were known to have practiced multiple succession systems, and there is much better evidence of matrilineal customs among the Indo-European Celts and Germans than among any ancient Semitic peoples.\n\nWomen were running Sparta while the men were often away fighting. Gorgo, Queen of Sparta, was asked by a woman in Attica something along the lines of, \"why are Spartan women the only women in the world who could rule men?\" Gorgo replied, \"Because we are the only women who are mothers of men.\"\n\nArising in the period ranging from the Iron Age to the Middle Ages, several early northwestern European mythologies from the Irish (\"e.g.\", Macha and Scáthach), the Brittonic (\"e.g.\", Rhiannon), and the Germanic (\"e.g.\", Grendel's mother and Nerthus) contain ambiguous episodes of primal female power which have been interpreted as folk evidence of a real potential for matriarchal attitudes in pre-Christian European Iron Age societies. Often transcribed from a retrospective, patriarchal, Romanised, and Catholic perspective, they hint at an earlier, culturally disturbing, era when female power could have predominated. The first-century–attested historic British figure of Boudicca indicates that Brittonnic society permitted explicit female autocracy or a form of gender equality in a form which contrasted strongly with the patriarchal structure of Mediterranean civilisation.\n\nIn 1995, in Kenya, according to Emily Wax, Umoja, a village only for women from one tribe with about 36 residents, was established under a matriarch. Men of the same tribe established a village nearby from which to observe the women's village, the men's leader objecting to the matriarch's questioning the culture and men suing to close the women's village. The village was still operational in 2005 when Wax reported on it.\n\nSpokespersons for various indigenous peoples at the United Nations and elsewhere have highlighted the central role of women in their societies, referring to them as matriarchies, or as matriarchal in character.\n\nMatriarchy may also refer to non-human animal species in which females hold higher status and hierarchical positions, such as among lions, elephants, and bonobos.\n\nA legendary matriarchy related by several writers was Amazon society. According to Phyllis Chesler, \"in Amazon societies, women were ... mothers and their society's only political and religious leaders\", as well as the only warriors and hunters; \"queens were elected\" and apparently \"any woman could aspire to and achieve full human expression.\" Herodotus reported that the Sarmatians were descendants of Amazons and Scythians, and that their females observed their ancient maternal customs, \"frequently hunting on horseback with their husbands; in war taking the field; and wearing the very same dress as the men\". Moreover, said Herodotus, \"no girl shall wed till she has killed a man in battle\". Amazons came to play a role in Roman historiography. Julius Caesar spoke of the conquest of large parts of Asia by Semiramis and the Amazons. Although Strabo was sceptical about their historicity, the Amazons were taken as historical throughout late Antiquity. Several Church Fathers spoke of the Amazons as a real people. Medieval authors continued a tradition of locating the Amazons in the North, Adam of Bremen placing them at the Baltic Sea and Paulus Diaconus in the heart of Germania.\n\nRobert Graves suggested that a myth displaced earlier myths that had to change when a major cultural change brought patriarchy to replace a matriarchy. According to this myth, in Greek mythology, Zeus is said to have swallowed his pregnant lover, the titan goddess Metis, who was carrying their daughter, Athena. The mother and child created havoc inside Zeus. Either Hermes or Hephaestus split Zeus's head, allowing Athena, in full battle armor, to burst forth from his forehead. Athena was thus described as being \"born\" from Zeus. The outcome pleased Zeus as it didn't fulfill the prophecy of Themis which (according to Aeschylus) predicted that Zeus will one day bear a son that would overthrow him. \n\nAccording to Adler, \"there \"is\" plenty of evidence of ancient societies where women held greater power than in many societies today. For example, Jean Markale's studies of Celtic societies show that the power of women was reflected not only in myth and legend but in legal codes pertaining to marriage, divorce, property ownership, and the right to rule.\"\n\nBamberger (1974) examines several matriarchal myths from South American cultures and concludes that portraying the women from this matriarchal period as immoral often serves to restrain contemporary women in these societies. \n\nWhile \"matriarchy\" has mostly fallen out of use for the anthropological description of existing societies, it remains current as a concept in feminism.\nIn first-wave feminist discourse, either Elizabeth Cady Stanton or Margaret Fuller (it is unclear who was first) introduced the concept of matriarchy and the discourse was joined in by Matilda Joslyn Gage. Victoria Woodhull, in 1871, called for men to open the U.S. government to women or a new constitution and government would be formed in a year; and, on a basis of equality, she ran to be elected President in 1872. Charlotte Perkins Gilman, in 1911 and 1914, argued for \"a woman-centered, or better mother-centered, world\" and described government by women. She argued that a government led by either sex must be assisted by the other, both genders being \"useful ... and should in our governments be alike used\", because men and women have different qualities.\n\nCultural feminism includes \"matriarchal worship\", according to Prof. James Penner.\n\nIn feminist literature, matriarchy and patriarchy are not conceived as simple mirrors of each other. While \"matriarchy\" sometimes means \"the political rule of women\", that meaning is often rejected, on the ground that matriarchy is not a mirroring of patriarchy. Patriarchy is held to be about power over others while matriarchy is held to be about power from within, Starhawk having written on that distinction and Adler having argued that matriarchal power is not possessive and not controlling, but is harmonious with nature.\n\nFor radical feminists, the importance of matriarchy is that \"veneration for the female principle ... somewhat lightens an oppressive system.\"\n\nFeminist utopias are a form of advocacy. According to Tineke Willemsen, \"a feminist utopia would ... be the description of a place where at least women would like to live.\" Willemsen continues, among \"type[s] of feminist utopias[,] ... [one] stem[s] from feminists who emphasize the differences between women and men. They tend to formulate their ideal world in terms of a society where women's positions are better than men's. There are various forms of matriarchy, or even a utopia that resembles the Greek myth of the Amazons... [V]ery few modern utopias have been developed in which women are absolute autocrats.\"\n\nA minority of feminists, generally radical, have argued that women should govern societies of women and men. In all of these advocacies, the governing women are not limited to mothers:\n\nSome such advocacies are informed by work on past matriarchy:\n\n\nSome fiction caricatured the current gender hierarchy by describing a matriarchal alternative without advocating for it. According to Karin Schönpflug, \"Gerd Brantenberg's \"Egalia's Daughters\" is a caricature of powered gender relations which have been completely reversed, with the female sex on the top and the male sex a degraded, oppressed group\"; \"gender inequality is expressed through power inversion\" and \"all gender roles are reversed and women rule over a class of intimidated, effeminate men\". \"\"Egalia\" is not a typical example of gender inequality in the sense that a vision of a desirable matriarchy is created; \"Egalia\" is more a caricature of male hegemony by twisting gender hierarchy but not really offering a 'better world.\n\nOn egalitarian matriarchy, Heide Göttner-Abendroth's International Academy for Modern Matriarchal Studies and Matriarchal Spirituality (HAGIA) organized conferences in Luxembourg in 2003 and Texas in 2005, with papers published. Göttner-Abendroth argued that \"matriarchies are all egalitarian at least in terms of gender—they have no gender hierarchy ... [, that, f]or many matriarchal societies, the social order is completely egalitarian at both local and regional levels\", that, \"for our own path toward new egalitarian societies, we can gain ... insight from ... [\"tested\"] matriarchal patterns\", and that \"matriarchies are not abstract \"utopias\", constructed according to philosophical concepts that could never be implemented.\"\n\nAccording to Eller, \"a deep distrust of men's ability to adhere to\" future matriarchal requirements may invoke a need \"to retain at least some degree of female hegemony to insure against a return to patriarchal control\", \"feminists ... [having] the understanding that female dominance is better for society—and better for men—than the present world order\", as is equalitarianism. On the other hand, Eller continued, if men can be trusted to accept equality, probably most feminists seeking future matriarchy would accept an equalitarian model.\n\n\"Demographic[ally]\", \"feminist matriarchalists run the gamut\" but primarily are \"in white, well-educated, middle-class circles\"; many of the adherents are \"religiously inclined\" while others are \"quite secular\".\n\nBiology as a ground for holding either males or females superior over the other has been criticized as invalid, such as by Andrea Dworkin and by Robin Morgan. A claim that women have unique characteristics that prevent women's assimilation with men has been apparently rejected by Ti-Grace Atkinson. On the other hand, not all advocates based their arguments on biology or essentialism.\n\nA criticism by Mansfield of choosing who governs according to gender or sex is that the best qualified people should be chosen, regardless of gender or sex. On the other hand, Mansfield considered merit insufficient for office, because a legal right granted by a sovereign (\"e.g.\", a king), was more important than merit.\n\nDiversity within a proposed community can, according to Becki L. Ross, make it especially challenging to complete forming the community. However, some advocacy includes diversity, in the views of Dworkin and Farley.\n\nProf. Christine Stansell, a feminist, wrote that, for feminists to achieve state power, women must democratically cooperate with men. \"Women must take their place with a new generation of brothers in a struggle for the world's fortunes. Herland, whether of virtuous matrons or daring sisters, is not an option... [T]he well-being and liberty of women cannot be separated from democracy's survival.\" (\"Herland\" was feminist utopian fiction by Charlotte Perkins Gilman in 1911, featuring a community entirely of women except for three men who seek it out, strong women in a matriarchal utopia expected to last for generations, although Charlotte Perkins Gilman was herself a feminist advocate of society being gender-integrated and of women's freedom.)\n\nOther criticisms of superiority are that it is reverse sexism or discriminatory against men, it is opposed by most people including most feminists, women do not want such a position, governing takes women away from family responsibilities, women are too likely to be unable to serve politically because of menstruation and pregnancy, public affairs are too sordid for women and would cost women their respect and femininity (apparently including fertility), superiority is not traditional, women lack the political capacity and authority men have, it is impractical because of a shortage of women with the ability to govern at that level of difficulty as well as the desire and ability to wage war, women are less aggressive, or less often so, than are men and politics is aggressive, women legislating would not serve men's interests or would serve only petty interests, it is contradicted by current science on genderal differences, it is unnatural, and, in the views of a playwright and a novelist, \"women cannot govern on their own.\" On the other hand, another view is that \"women have 'empire' over men\" because of nature and \"men ... are actually obeying\" women.\n\nPursuing a future matriarchy would tend to risk sacrificing feminists' position in present social arrangements, and many feminists are not willing to take that chance, according to Eller. \"Political feminists tend to regard discussions of what utopia would look like as a good way of setting themselves up for disappointment\", according to Eller, and argue that immediate political issues must get the highest priority.\n\n\"Matriarchists\", as typified by comic character Wonder Woman were criticized by Kathie Sarachild, Carol Hanisch, and some others.\n\nSome theologies and theocracies limit or forbid women from being in civil government or public leadership or forbid them from voting, effectively criticizing and forbidding matriarchy. Within none of the following religions is the respective view necessarily universally held:\n\n\nFeminist thealogy, according to Eller, conceptualized humanity as beginning with \"female-ruled or equalitarian societies\", until displaced by patriarchies, and that in the millennial future gynocentric,' life-loving values\" will return to prominence. This, according to Eller, produces \"a virtually infinite number of years of female equality or superiority coming both at the beginning and end of historical time\".\n\nAmong criticisms is that a future matriarchy, according to Eller, as a reflection of spirituality, is conceived as ahistorical, and thus may be unrealistic, unreachable, or even meaningless as a goal to secular feminists.\n\n\n\n\n\n\n\n\n\n"}
{"id": "11911464", "url": "https://en.wikipedia.org/wiki?curid=11911464", "title": "Model of hierarchical complexity", "text": "Model of hierarchical complexity\n\nThe model of hierarchical complexity is a framework for scoring how complex a behavior is, such as verbal reasoning or other cognitive tasks. It quantifies the order of hierarchical complexity of a task based on mathematical principles of how the information is organized, in terms of information science. This model has been developed by Michael Commons and others since the 1980s.\n\nThe model of hierarchical complexity (MHC) is a formal theory and a mathematical psychology framework for scoring how complex a behavior is. Developed by Michael Lamport Commons and colleagues, it quantifies the order of hierarchical complexity of a task based on mathematical principles of how the information is organized, in terms of information science. Its forerunner was the general stage model.\n\nBehaviors that may be scored include those of individual humans or their social groupings (e.g., organizations, governments, societies), animals, or machines. It enables scoring the hierarchical complexity of task accomplishment in any domain. It is based on the very simple notions that higher order task actions:\n\nIt is cross-culturally and cross-species valid. The reason it applies cross-culturally is that the scoring is based on the mathematical complexity of the hierarchical organization of information. Scoring does not depend upon the content of the information (e.g., what is done, said, written, or analyzed) but upon how the information is organized.\n\nThe MHC is a non-mentalistic model of developmental stages. It specifies 16 orders of hierarchical complexity and their corresponding stages. It is different from previous proposals about developmental stage applied to humans; instead of attributing behavioral changes across a person's age to the development of mental structures or schema, this model posits that task sequences of task behaviors form hierarchies that become increasingly complex. Because less complex tasks must be completed and practiced before more complex tasks can be acquired, this accounts for the developmental changes seen, for example, in individual persons' performance of complex tasks. (For example, a person cannot perform arithmetic until the numeral representations of numbers are learned. A person cannot operationally multiply the sums of numbers until addition is learned).\n\nThe creators of the MHC claim that previous theories of stage have confounded the stimulus and response in assessing stage by simply scoring responses and ignoring the task or stimulus. The MHC separates the task or stimulus from the performance. The participant's performance on a task of a given complexity represents the stage of developmental complexity.\n\nOne major basis for this developmental theory is task analysis. The study of ideal tasks, including their instantiation in the real world, has been the basis of the branch of stimulus control called psychophysics. Tasks are defined as sequences of contingencies, each presenting stimuli and each requiring a behavior or a sequence of behaviors that must occur in some non-arbitrary fashion. The complexity of behaviors necessary to complete a task can be specified using the horizontal complexity and vertical complexity definitions described below. Behavior is examined with respect to the analytically-known complexity of the task.\n\nTasks are quantal in nature. They are either completed correctly or not completed at all. There is no intermediate state (\"tertium non datur\"). For this reason, the model characterizes all stages as P-hard and functionally distinct. The orders of hierarchical complexity are quantized like the electron atomic orbitals around the nucleus: each task difficulty has an order of hierarchical complexity required to complete it correctly, analogous to the atomic Slater determinant. Since tasks of a given quantified order of hierarchical complexity require actions of a given order of hierarchical complexity to perform them, the stage of the participant's task performance is equivalent to the order of complexity of the successfully completed task. The quantal feature of tasks is thus particularly instrumental in stage assessment because the scores obtained for stages are likewise discrete.\n\nEvery task contains a multitude of subtasks. When the subtasks are carried out by the participant in a required order, the task in question is successfully completed. Therefore, the model asserts that all tasks fit in some configured sequence of tasks, making it possible to precisely determine the hierarchical order of task complexity. Tasks vary in complexity in two ways: either as \"horizontal\" (involving classical information); or as \"vertical\" (involving hierarchical information).\n\nClassical information describes the number of \"yes–no\" questions it takes to do a task. For example, if one asked a person across the room whether a penny came up heads when they flipped it, their saying \"heads\" would transmit 1 bit of \"horizontal\" information. If there were 2 pennies, one would have to ask at least two questions, one about each penny. Hence, each additional 1-bit question would add another bit. Let us say they had a four-faced top with the faces numbered 1, 2, 3, and 4. Instead of spinning it, they tossed it against a backboard as one does with dice in a game of craps. Again, there would be 2 bits. One could ask them whether the face had an even number. If it did, one would then ask if it were a 2. Horizontal complexity, then, is the sum of bits required by just such tasks as these.\n\nHierarchical complexity refers to the number of recursions that the coordinating actions must perform on a set of primary elements. Actions at a higher order of hierarchical complexity: (a) are defined in terms of actions at the next lower order of hierarchical complexity; (b) organize and transform the lower-order actions (see Figure 2); (c) produce organizations of lower-order actions that are qualitatively new and not arbitrary, and cannot be accomplished by those lower-order actions alone. Once these conditions have been met, we say the higher-order action coordinates the actions of the next lower order.\n\nTo illustrate how lower actions get organized into more hierarchically complex actions, let us turn to a simple example. Completing the entire operation 3 × (4 + 1) constitutes a task requiring the distributive act. That act non-arbitrarily orders adding and multiplying to coordinate them. The distributive act is therefore one order more hierarchically complex than the acts of adding and multiplying alone; it indicates the singular proper sequence of the simpler actions. Although simply adding results in the same answer, people who can do both display a greater freedom of mental functioning. Additional layers of abstraction can be applied. Thus, the order of complexity of the task is determined through analyzing the demands of each task by breaking it down into its constituent parts.\n\nThe hierarchical complexity of a task refers to the number of concatenation operations it contains, that is, the number of recursions that the coordinating actions must perform. An order-three task has three concatenation operations. A task of order three operates on one or more tasks of vertical order two and a task of order two operates on one or more tasks of vertical order one (the simplest tasks).\n\nStage theories describe human organismic and/or technological evolution as systems that move through a pattern of distinct stages over time. Here development is described formally in terms of the model of hierarchical complexity (MHC).\n\nSince actions are defined inductively, so is the function \"h\", known as the order of the hierarchical complexity. To each action \"A\", we wish to associate a notion of that action's hierarchical complexity, \"h(A)\". Given a collection of actions A and a participant \"S\" performing A, the \"stage of performance\" of \"S\" on A is the highest order of the actions in A completed successfully at least once, i.e., it is: stage (\"S\", A) = max{\"h(A)\" | \"A\" ∈ A and \"A\" completed successfully by \"S\"}. Thus, the notion of stage is discontinuous, having the same transitional gaps as the orders of hierarchical complexity. This is in accordance with previous definitions.\n\nBecause MHC stages are conceptualized in terms of the hierarchical complexity of tasks rather than in terms of mental representations (as in Piaget's stages), the highest stage represents successful performances on the most hierarchically complex tasks rather than intellectual maturity.\n\nThe following table gives descriptions of each stage in the MHC.\n\nThere are some commonalities between the Piagetian and Commons' notions of stage and many more things that are different. In both, one finds:\nWhat Commons et al. (1998) have added includes:\nThis makes it possible for the model's application to meet real world requirements, including the empirical and analytic. Arbitrary organization of lower order of complexity actions, possible in the Piagetian theory, despite the hierarchical definition structure, leaves the functional correlates of the interrelationships of tasks of differential complexity formulations ill-defined.\n\nMoreover, the model is consistent with the neo-Piagetian theories of cognitive development. According to these theories, progression to higher stages or levels of cognitive development is caused by increases in processing efficiency and working memory capacity. That is, higher-order stages place increasingly higher demands on these functions of information processing, so that their order of appearance reflects the information processing possibilities at successive ages.\n\nThe following dimensions are inherent in the application:\n\nThe MHC specifies 16 orders of hierarchical complexity and their corresponding stages, positing that each of Piaget's substages, in fact, are robustly hard stages. The MHC adds five postformal stages to Piaget's developmental trajectory: systematic stage 12, metasystematic stage 13, paradigmatic stage 14, cross-paradigmatic stage 15, and meta-cross-paradigmatic stage 16. It may be the Piaget's \"consolidate\" formal stage is the same as the \"systematic\" stage. The sequence is as follows: (0) calculatory, (1) automatic, (2) sensory & motor, (3) circular sensory-motor, (4) sensory-motor, (5) nominal, (6) sentential, (7) preoperational, (8) primary, (9) concrete, (10) abstract, (11) formal, and the five postformal: (12) systematic, (13) metasystematic, (14) paradigmatic, (15) cross-paradigmatic, and (16) meta-cross-paradigmatic. The first four stages (0–3) correspond to Piaget's sensorimotor stage at which infants and very young children perform. Adolescents and adults can perform at any of the subsequent stages. MHC stages 4 through 5 correspond to Piaget's pre-operational stage; 6 through 8 correspond to his concrete operational stage; and 9 through 11 correspond to his formal operational stage.\n\nMore complex behaviors characterize multiple system models. The four highest stages in the MHC are not represented in Piaget's model. The higher stages of the MHC have extensively influenced the field of positive adult development. Some adults are said to develop alternatives to, and perspectives on, formal operations; they use formal operations within a \"higher\" system of operations. Some theorists call the more complex orders of cognitive tasks \"postformal thought\", but other theorists argue that these higher orders cannot exactly be labelled as postformal thought.\n\nJordan (2018) argued that unidimensional models such as the MHC, which measure level of complexity of some behavior, refer to only one of many aspects of adult development, and that other variables are needed (in addition to unidimensional measures of complexity) for a fuller description of adult development.\n\nThe MHC has a broad range of applicability. Its mathematical foundation permits it to be used by anyone examining task performance that is organized into stages. It is designed to assess development based on the order of complexity which the actor utilizes to organize information. The model thus allows for a standard quantitative analysis of developmental complexity in any cultural setting. Other advantages of this model include its avoidance of mentalistic explanations, as well as its use of quantitative principles which are universally applicable in any context.\n\nThe following practitioners can use the MHC to quantitatively assess developmental stages:\n\nIn one representative study, Commons, Goodheart, and Dawson (1997) found, using Rasch analysis (Rasch, 1980), that hierarchical complexity of a given task predicts stage of a performance, the correlation being r = 0.92. Correlations of similar magnitude have been found in a number of the studies. The following are examples of tasks studied using the model of hierarchical complexity or Kurt W. Fischer's similar skill theory:\n\nAs of 2014, people and institutes from all the major continents of the world, except Africa, have used the model of hierarchical complexity. Because the model is very simple and is based on analysis of tasks and not just performances, it is dynamic. With the help of the model, it is possible to quantify the occurrence and progression of transition processes in task performances at any order of hierarchical complexity.\n\nThe descriptions of stages 13–15 have been described as insufficiently precise.\n\n"}
{"id": "10870972", "url": "https://en.wikipedia.org/wiki?curid=10870972", "title": "Multilingual Education", "text": "Multilingual Education\n\nMultilingual Education typically refers to \"first-language-first\" education, that is, schooling which begins in the mother tongue and transitions to additional languages. Typically MLE programs are situated in developing countries where speakers of minority languages, i.e. non-dominant languages, tend to be disadvantaged in the mainstream education system. There are increasing calls to provide first-language-first education to immigrant children from immigrant parents who have moved to the developed world.\n\n\nRelated to the emphasis on a child's mother tongue is the implicit validation of her cultural or ethnic identity by taking languages which were previously considered \"non-standard\" and making active use of them in the classroom. Multilingual Education in that sense underscores the importance of the child's worldview in shaping his or her learning.\n\nA widespread understanding of MLE programs (UNESCO, 2003, 2005) suggests that instruction take place in the following stages:\n\n\nMLE proponents stress that the second language acquisition component is seen as a \"two-way\" bridge, such that learners gain the ability to move back and forth between their mother tongue and the other tongue(s), rather than simply a transitional literacy program where reading through the mother tongue is abandoned at some stage in the education.\n\nBased on the theories of Multilingual Education that are spelled out here, Andhra Pradesh and Orissa have adopted a thematic approach to multilingual education. Using a seasonal calendar within a relevant cultural context has provided a space to the tribal children of Orissa and Andhra Pradesh to rediscover their culture through their language. The Multilingual Education in this approach emphasizes first language first in the child taking the socio- cultural curriculum in to classroom culture and then bridge to second language.\nIn addition to the basic theory of Paulo Freire on critical pedagogy, Gramscian theory on education, Lev Vigostky's scaffolding and Piaget's theory of cognition is applied in the Multilingual Education. The unique thing in this approach is to involve the community in creating their own curriculum and minimise the theoretical hegemony, thereby creating a new set of people who believe in the ethics of creating and sharing knowledge for the society than to limit it to the theoreticians.\nOdisha is a multilingual state having more than 40 ethnic language among the 62 scheduled tribes, along with the Modern Indian Languages like Hindi, Bengali and Telugu. To address the language- education of ethnic minorities children in schools, Odisha government started Multilingual Education programme,ten tribal languages. Led by Dr MAhendra Kumar Mishra, as the Director of Multilingual Education and guided by Prof. D P Pattanayak and Prof Khageswar Mahapatra, the eminent multilingual Experts, the state government started MLE programme in te tribal languages in 547 schools. 10 tribal languages were adopted. These are Santali, Saora, Kui, Kuvi, Koya, Kishan, Oroam, Juang, Bonda and Ho. Culturally responsive curriculum and text books were prepared for class i to Class V to maintain mother tongue based multilingual education to educate the tribal children. State government appointed teachers from the same language community in the schools to teach the tribal children.A language policy was also formulated. The programme was also supported by Summer Institute of Linguistics led by Mr Steve Simpson and Vicky Simpson, Pamela Mackenzie. The curriculum and text books were prepared by the tribal teachers guided by the MLE resource groups. It was initiated in 2005 and isnow running in 2250 schools with majority tribal children. This is a sustained MLE programme in Asian countries.About 7 Asian countries have visited the MLE schools. \n\nMultilingual Education in India, The CAse For English Edited by Dr MAhendra Kumar Mishra and Prof Anand Mahanand published by Viva Books, New Delhi 2016.\n\nid21 insights. Available online at \nMultilingual Education in India, The Csse For English Edited by Dr MAhendra Kumar Mishra and Prof Anand Mahanand published by Viva Books, New Delhi 2016.\n\nwww.folklorefoundation.org.in\n"}
{"id": "333154", "url": "https://en.wikipedia.org/wiki?curid=333154", "title": "Murder of Balbir Singh Sodhi", "text": "Murder of Balbir Singh Sodhi\n\nBalbir Singh Sodhi (1949 – September 15, 2001), a Sikh-American gas station owner in Mesa, Arizona, was murdered in a hate crime in the aftermath of the September 11 attacks. This was the first of several cases across the United States that were reported to the police as supposed acts of retaliation for the attacks. Balbir Singh Sodhi, who wore a beard and a turban in accordance with his Sikh faith, was mistaken for an Arab Muslim and murdered by 42-year-old Frank Silva Roque, a Boeing aircraft mechanic at a local repair facility who held a criminal record for an attempted robbery in California. Roque had reportedly told friends that he was \"going to go out and shoot some towel-heads\" the day of the attacks. Roque was sentenced to death (commuted later to life imprisonment) for first degree murder.\n\nBorn in Punjab, India, Balbir Singh Sodhi was a member of the Sikh religion. He immigrated to the United States in 1989 and initially resided in Los Angeles, where he worked as a computer engineer and analyst at HP. He saved enough money to buy a gas station and several affiliated franchises in Phoenix, Arizona and moved there.\n\nOn September 11, 2001, members of al-Qaeda, a militant Islamist group, hijacked four airplanes and perpetrated the 9/11 attacks, killing 2,977 victims. According to family members, Sodhi had become distraught by the attacks.\n\nOn September 15, 2001, Roque took his Chevrolet S-10 from the Wild Hare sports bar in Mesa, where he had reportedly been ranting about immigrants, and drove to the Chevron gas station owned by Sodhi. Roque shot Sodhi five times from his truck with a .380 handgun, killing him. At the time of the shooting, Sodhi was helping landscaper Luis Ledesma plant flowers around the edge of his gas station.\n\nRoque, who apparently wanted revenge for the 9/11 attacks, mistook him for an Arab Muslim because of the clothes he wore, his turban, and his beard. Roque then drove to a Mobil gas station 10 miles away. Twenty minutes after the first shooting, he shot at a Lebanese-American clerk from his truck, but missed. Roque then drove to his former residence, which had been purchased by a local Afghan family, and fired multiple rounds at the outside of the house. After fleeing the scene of the final shooting, Roque was reported to have gone to a local bar and boasted, \"They're investigating the murder of a turban-head down the street.\"\n\nPolice arrested Roque the next day, initially unaware of the later shooting incidents. He reportedly shouted slogans including \"I am a patriot!\" and \"I stand for America all the way!\" during his arrest. His bail was set at $1 million.\n\nRoque's trial by jury began on August 18, 2003. Defense attorneys argued he was not guilty due to insanity, claiming that he had a diminished IQ and heard relentless voices telling him that Arabs were Satanic and must be killed. Two coworkers testified that Roque was \"narrow-minded\" and that he hated both immigrants and Arabs. Roque's defense attorney characterized him as mentally ill, and noted that his mother had twice been hospitalized for schizophrenia, a condition which has been shown to appear in those genetically predisposed to it. On September 30, 2003, he was found guilty of first degree murder, and was sentenced to death nine days later.\n\nOn July 19, 2005, Roque was found guilty of an unspecified conspiracy charge while in prison, specified only as a violent crime. On February 27, 2006, he was found guilty of having manufactured a primitive weapon in prison three days earlier. In August 2006, the Arizona Supreme Court changed Roque's death sentence to a sentence of life in prison without parole, citing his low IQ and mental illness as mitigating factors. The trial was aired by Court TV in a five-part series.\n\nOn August 4, 2002, less than a year after Sodhi's death, his younger brother Sukhpal was shot to death while driving his taxicab in San Francisco, apparently killed by a stray bullet from a nearby gang fight. In response to this second tragedy, Balbir's son Sukhwinder said, \"What are you going to do with anger? We like peace and we are a peaceful people.\"\n\n\n\n\n \n"}
{"id": "31952115", "url": "https://en.wikipedia.org/wiki?curid=31952115", "title": "Nayef Al-Rodhan", "text": "Nayef Al-Rodhan\n\nNayef R. F. Al-Rodhan (; born 1959) is a Saudi philosopher, neuroscientist, geostrategist, and author. He is an Honorary Fellow of St. Antony’s College at Oxford University, Oxford, United Kingdom, Senior Fellow and Centre Director of the Geopolitics and Global Futures Programme at the Geneva Centre for Security Policy, Geneva, Switzerland.\n\nProfessor Nayef Al-Rodhan began his career as a neurosurgeon and neuroscientist. As a medical student at Newcastle University, he was mentored and influenced by the renowned neurologist, Lord John Walton of Detchant. He trained in neurosurgery and conducted neuroscience research at the Mayo Clinic, Rochester, Minnesota in the United States. He became Chief Resident in neurosurgery and was influenced by Thoralf M. Sundt, David Piepgrass, and Patrick J Kelly at the Mayo Clinic. He obtained a Ph.D. in 1988 for his work on the \"Characterization of Opioid and Neurotensin Receptor Subtypes in the Brain with Respect to Antinociception\".\n\nIn 1993, on a fellowship from the Congress of Neurological Surgeons, he joined the department of neurosurgery at the Yale University School of Medicine as a fellow in epilepsy surgery and molecular neuroscience under the direction of Dennis Spencer.\n\nIn 1994, Nayef Al-Rodhan became a fellow at the department of neurosurgery at the Massachusetts General Hospital at Harvard Medical School, where he worked on the study of neuropeptides, molecular genetics, and neuronal regeneration. In 1995, he was appointed to the faculty of the Harvard Medical School and while at Harvard and Massachusetts General Hospital, he founded the neurotechnology program with Nobel Prize winner James E. Muller. Working with Robert Martuza, Al-Rodhan also founded the Laboratories for Cellular Neurosurgery and Neurosurgical Technology at the department of neurosurgery of Massachusetts General Hospital, Harvard Medical School.\n\nNayef Al-Rodhan has received the following research awards: Sir James Spence Prize, the Gibb Prize, the Farquhar-Murray Prize, the American Association of Neurological Surgeon Prize (twice), the Meninger Prize, the Annual Resident Prize of the Congress of Neurological Surgeons, the Young Investigator Prize of the American Association of Neurological Surgeons, and the Annual Fellowship Prize of the Congress of Neurological Surgeons.\n\nSince 2002, Nayef Al-Rodhan has shifted his scholarly focus to the interplay between neuroscience and international relations. Through several publications, he has pioneered the application of neuroscience and the neuro-behavioural consequences of the neurochemical and cellular mechanisms that underpin emotions, amorality, egoisms, fear, greed, and dominance, into the analysis and conceptualization of trends in contemporary geopolitics, global security, national security, transcultural security, and war and peace.\n\nIn 2006, Nayef Al-Rodhan joined the Geneva Center for Security Policy in Geneva, Switzerland, as a Senior Scholar in geostrategy and Director of the Geopolitics and Global Futures Programme.\nIn 2009, Al-Rodhan became a Senior Member of St. Antony’s College, Oxford University, where he analyses, amongst other things, critical turning points in the Arab-Islamic world and their current and future regional and global geopolitical relevance. In 2014, he became an Honorary Fellow of St. Antony's College. His current geostrategy interests include: Geopolitics of the Middle East; sustainable national and global security; geopolitics of outer space and strategic technologies; and global strategic cascading risks.\nHis philosophical interests include:global justice; human dignity and international order; shared history of humanity and transcultural security and synergy; philosophy of sustainable history and the dignity of man; history of ideas; neurophilosophy of human nature and its implications for war, peace and moral and political cooperation between ideologies, states and cultures.\n\n\n"}
{"id": "3901921", "url": "https://en.wikipedia.org/wiki?curid=3901921", "title": "Nominative and structural type systems", "text": "Nominative and structural type systems\n\nNominative and structural type systems are:\n\nThe differences between nominative and structural type systems are discussed in:\n"}
{"id": "627496", "url": "https://en.wikipedia.org/wiki?curid=627496", "title": "Nonviolent Communication", "text": "Nonviolent Communication\n\nNonviolent Communication (abbreviated NVC, also called Compassionate Communication or Collaborative Communication) is an approach to nonviolent living developed by Marshall Rosenberg beginning in the 1960s. It is based on the idea that all human beings have the capacity for compassion and only resort to violence or behavior that harms themselves and others when they do not recognize more effective strategies for meeting needs. Habits of thinking and speaking that lead to the use of violence (social, psychological and physical) are learned through culture. NVC theory supposes all human behavior stems from attempts to meet universal human needs and that these needs are never in conflict. Rather, conflict arises when strategies for meeting needs clash. NVC proposes that people identify shared needs, revealed by the thoughts and feelings that surround these needs, and collaborate to develop strategies that meet them. This creates both harmony and learning for future cooperation.\n\nNVC supports change on three interconnected levels: with self, with others, and with groups and social systems. As such it is particularly present in the areas of personal development, relationships, and social change. NVC is ostensibly taught as a process of interpersonal communication designed to improve compassionate connection to others. However, due to its far-reaching impact it has also been interpreted as a spiritual practice, a set of values, a parenting technique, a method of social change, a mediation tool, an educational orientation, and a worldview.\n\nNVC has been applied in organizational and business settings,\nin parenting,\nin education, in mediation, in psychotherapy, in healthcare, in addressing eating issues, in justice,\nand as a basis for a children's book,\namong other contexts.\n\nRosenberg related ways he used Nonviolent Communication in peace programs in conflict zones including Rwanda, Burundi, Nigeria, Malaysia, Indonesia, Sri Lanka, Colombia, Serbia, Croatia, Ireland, and the Middle East including the Palestinian Territories.\n\nAccording to a biography of Rosenberg on the Center for Nonviolent Communication (CNVC) website, Nonviolent Communication training evolved from his search for a way to rapidly disseminate peacemaking skills. CNVC says that NVC emerged from work he was doing with civil rights activists in the early 1960s, and that during this period he also mediated between rioting students and college administrators, and worked to peacefully desegregate public schools in long-segregated regions.\n\nA master's thesis by Marion Little (2008) says that the roots of the NVC model developed in the late 1960s, when Rosenberg was working on racial integration in schools and organizations in the Southern United States. The earliest version of the model (observations, feelings, and action-oriented wants) was part of a training manual Rosenberg prepared in 1972. The model had evolved to its present form (observations, feelings, needs and requests) by 1992. The dialog between Rosenberg and NVC colleagues and trainers continued to influence the model, which by the late 2000s put more emphasis on \"self-empathy\" as a key to the model's effectiveness. Another shift in emphasis, since 2000, has been the reference to the model as a \"process\". The focus is thus less on the \"steps\" themselves and more on the practitioner's \"intentions\" in speaking (\"Is the intent to get others to do what one wants, or to foster more meaningful relationships and mutual satisfaction?\") in listening (\"Is the intent to prepare for what one has to say, or to extend heartfelt, respectful attentiveness to another?\") and the quality of connection experienced with others.\n\nAlso according to Little's thesis, Rosenberg's work with Carl Rogers on research to investigate the necessary and sufficient conditions of a therapeutic relationship was central to the development of NVC. Rogers emphasized: 1) experiential learning, 2) \"frankness about one's emotional state,\" 3) the satisfaction of hearing others \"in a way that resonates for them,\" 4) the enriching and encouraging experience of \"creative, active, sensitive, accurate, empathic listening,\" 5) the \"deep value of congruence between one's own inner experience, one's conscious awareness, and one's communication,\" and, subsequently, 6) the enlivening experience of unconditionally receiving love or appreciation and extending the same.\n\nLittle says Rosenberg was influenced by Erich Fromm, George Albee, and George Miller to adopt a community focus in his work, moving away from clinical psychological practice. The central ideas influencing this shift by Rosenberg were that: (1) individual mental health depends on the social structure of a community (Fromm), (2) therapists alone are unable to meet the psychological needs of a community (Albee), and (3) knowledge about human behavior will increase if psychology is freely given to the community (Miller).\n\nAccording to Little, Rosenberg's early work with children with learning disabilities shows his interest in psycholinguistics and the power of language, as well as his emphasis on collaboration. In its initial development, the NVC model re-structured the pupil-teacher relationship to give students greater responsibility for, and decision-making related to, their own learning. The model has evolved over the years to incorporate institutional power relationships (i.e., police-citizen, boss-employee) and informal ones (i.e. man-woman, rich-poor, adult-youth, parent-child). The ultimate aim is to develop societal relationships based on a restorative, \"partnership\" paradigm and mutual respect, rather than a retributive, fear-based, \"domination\" paradigm.\n\nLittle also says Rosenberg identified Mahatma Gandhi as an inspiration for the NVC model, and that Rosenberg's goal was to develop a practical process for interaction rooted in the philosophy of Ahimsa, which Little translates as \"the overflowing love that arises when all ill-will, anger, and hate have subsided from the heart.\"\n\nIn order to show the differences between communication styles, Rosenberg started to use two animals. Violent communication was represented by the carnivorous Jackal as a symbol of aggression and especially dominance. The herbivorous Giraffe on the other hand, represented his NVC strategy. The Giraffe was chosen as symbol for NVC as its long neck is supposed to show the clear-sighted speaker, being aware of his fellow speakers' reactions; and because the Giraffe has a large heart, representing the compassionate side of NVC. In his courses he tended to use these animals in order to make the differences in communication clearer to the audience.\n\nNonviolent Communication holds that most conflicts between individuals or groups arise from miscommunication about their human needs, due to coercive or manipulative language that aims to induce fear, guilt, shame, etc. These \"violent\" modes of communication, when used during a conflict, divert the attention of the participants away from clarifying their needs, their feelings, their perceptions, and their requests, thus perpetuating the conflict.\n\nMarshall Rosenberg, the founder of Nonviolent Communication, published numerous training materials to help in efforts to bring about radical social change. He was concerned with transforming the \"gangs and domination structures\" through the method he called \"ask, ask, ask\". He suggested social change activists could focus on gaining access to those in power in order to \"ask, ask, ask\" for changes that will make life better for all including the powerful. He wrote about the need for the protective use of force, distinguishing it from the punitive use of force.\n\nTwo NVC trainers characterize the assumptions underlying NVC as follows:\n\nThe trainers also say that practicing NVC involves having the following intentions:\n\nRosenberg says that certain ways of communicating tend to alienate people from the experience of compassion:\n\nRosenberg invites NVC practitioners to focus attention on four components:\n\nThere are three primary modes of application of NVC:\n\nAs of 2008, NVC was said to lack significant \"longitudinal analytical research,\" and few studies had evaluated the effectiveness of NVC training programs. There had been little discussion of NVC in academic contexts, and most evidence for the effectiveness of NVC was said to be anecdotal or based on theoretical support. Since that time, the number of publications reporting research on NVC has more than doubled.\n\nCarme Juncadella produced a systematic review of research as of 2013 related to the impact of NVC on the development of empathy. She found 13 studies which met her inclusion criteria (three were published in peer reviewed journals; ten were unpublished theses or researcher reports). Eleven of these suggested an increase in empathy subsequent to the application of NVC (five of these with evidence of statistical significance) and two did not. Juncadella notes several shortcomings of her review. None of the studies she included were randomized and only three used validated instruments. As a result she used a narrative synthesis review format, which, \"lacks precision,\" but allows the summarization of studies of different types, sizes, outcome measures and aims. She suggests the primary limitation of her review is that a number of relevant studies exist that could not be included due to lack of availability. She suggests these might have significantly altered her results. Finally, she includes the following caveat: \"I must mention the inevitable subjectivity bias present throughout the whole review. In spite of the efforts made towards 'disciplined subjectivity'... my decisions show a degree of uncertainty and inaccuracy born via the tension between the weak evidence of the studies and my own convictions about the NVC model.\" Her overall assessment of the current research on NVC's efficacy in promoting the development of empathy is that the results are promising, but \"would need to be confirmed with further studies bearing stronger designs and more appropriate measures.\" She notes that a major shortcoming of the existing research is the \"mismatch between the constructs of the model and the validated empathy measures\" and suggests that improved instruments need to be developed to adequately test NVC.\n\nAs of 2017, fifteen master's theses and doctoral dissertations are known to have tested the model on sample sizes of 108 or smaller and generally have found the model to be effective.\n\nAllan Rohlfs, who first met Rosenberg in 1972 and was a founder of the Center for Nonviolent Communication, in 2011 explained a paucity of academic literature as follows:\nVirtually all conflict resolution programs have an academic setting as their foundation and therefore have empirical studies by graduate students assessing their efficacy. NVC is remarkable for its roots. Marshall Rosenberg, Ph.D. (clinical psychology, U of Wisconsin) comes from a full time private practice in clinical psychology and consultation, never an academic post. NVC, his creation, is entirely a grassroots organization and never had until recently any foundation nor grant monies, on the contrary funded 100% from trainings which were offered in public workshops around the world. ... Empirical data is now coming slowly as independent researchers find their own funding to conduct and publish empirical studies with peer review.\n\nRichard Bowers' master's thesis (2012), updated to book form by Bowers and Moffett (2012), asserts that NVC has been absent from academic programs due to a lack of research into the theoretical basis for the model and lack of research on the reliability of positive results. Bowers' thesis meets the first objection through an analysis of existing theories which provide solid support for each element of the NVC (mediation) model. Without this theoretical understanding, it would not be clear what aspects of the NVC model make it work or even if it can be effectively applied by anyone other than Marshall Rosenberg. This theoretical analysis can provide a foundation for further empirical research on the effectiveness and reliability of the model.\n\nConnor and Wentworth examined the impact of 6-months of NVC training and coaching on 23 executives in a Fortune 100 corporation. A variety of benefits were reported, including \"conversations and meetings were notably more efficient, with issues being resolved in 50-80 percent less time.\"\n\nNVC has reportedly been an element of a bundle of interventions that produced dramatic changes in forensic psychiatric nursing settings in which a high level of violence is the norm. NVC was adopted, in combination with other interventions, in an effort to reduce violence. The interventions were said to reduce key violence indicators by 90 percent over a three-year period in a medium security unit, and by around 50 percent in a single year in a maximum security unit.\n\nA 2014 study examined the effects of combined NVC and mindfulness training on 885 male inmates of the Monroe Correctional Complex in Monroe, Washington. The training was found to reduce recidivism from 37% to 21%, and the training was estimated as having saved the state $5 million per year in reduced incarceration costs. The training was found to increase equanimity, decrease anger, and lead to abilities to take responsibility for one's feelings, express empathy, and to make requests without imposing demands.\n\nNVC has also been reported as effective in reducing domestic violence. Male participants who graduated from an NVC-based batterer intervention program in California had zero percent recidivism within 5 years, according to the relevant District Attorneys' offices. The news report contrasted this with a recidivism rate of 40 percent within 5 years as reported by the Domestic Abuse Intervention Project for graduates of their batterer intervention program based on the Duluth Model, said to previously offer the lowest known domestic violence recidivism rate.\n\nBowers and Moffett provide a thoughtful study of the important role of empathy and human needs in mediation through the development of a theoretical model to explain the effectiveness of NVC mediation. The authors present theories of human needs and the basis for a common core of needs. They discuss theories that explain the importance of understanding human needs in the context of conflict resolution. They clearly distinguish core human needs from interests (strategies) and how focusing on needs is a paradigm shift in the field of conflict resolution. Further, Bowers and Moffett present theories of empathy\nfrom the pioneering work of Carl Rogers, Heinz Kohut, and others. Empathy is distinguished from sympathy and active listening, pointing out how the word empathy is often confused in the literature by using it interchangeably with these other two terms. They also examine stage theories of the development of empathy as well as constructive-developmental theories related to empathy.\n\nSome recent research appears to validate the existence of universal human needs.\n\nAs Theresa Latini notes, \"Rosenberg understands NVC to be a fundamentally spiritual practice.\" Marshall Rosenberg describes the influence of his spiritual life on the development and practice of NVC:\n\nI think it is important that people see that spirituality is at the base of Nonviolent Communication, and that they learn the mechanics of the process with that in mind. It's really a spiritual practice that I am trying to show as a way of life. Even though we don't mention this, people get seduced by the practice. Even if they practice this as a mechanical technique, they start to experience things between themselves and other people they weren't able to experience before. So eventually they come to the spirituality of the process. They begin to see that it's more than a communication process and realize it's really an attempt to manifest a certain spirituality.\n\nRosenberg further states that he developed NVC as a way to \"get conscious of\" what he calls the \"Beloved Divine Energy\".\n\nSome Christians have found NVC to be complementary to their Christian faith.\nMany people have found Nonviolent Communication to be very complementary to Buddhism, both in theory and in manifesting Buddhist ideals in practice.\n\nMarion Little examines theoretical frameworks related to NVC. The influential interest-based model for conflict resolution, negotiation, and mediation developed by Fisher, Ury, and Patton at the Harvard Negotiation Project and at the Program on Negotiation in the 1980s appears to have some conceptual overlap with NVC, although neither model references the other. Little suggests The Gordon Model for Effective Relationships (1970) as a likely precursor to both NVC and interest-based negotiation, based on conceptual similarities, if not any direct evidence of a connection. Like Rosenberg, Gordon had worked with Carl Rogers, so the models' similarities may reflect common influences.\n\nSuzanne Jones sees a substantive difference between active listening as originated by Gordon and empathic listening as recommended by Rosenberg, insofar as active listening involves a specific step of reflecting what a speaker said to let them know you are listening, whereas empathic listening involves an ongoing process of listening with both heart and mind and being fully present to the other's experience, with an aim of comprehending and empathizing with the needs of the other, the meaning of the experience for that person.\n\nGert Danielsen and Havva Kök both note an overlap between the premises of NVC and those of Human Needs Theory (HNT), an academic model for understanding the sources of conflict and designing conflict resolution processes, with the idea that \"Violence occurs when certain individuals or groups do not see any other way to meet their need, or when they need understanding, respect and consideration for their needs.\"\n\nChapman Flack sees an overlap between what Rosenberg advocates and critical thinking, especially Bertrand Russell's formulation uniting kindness and clear thinking.\n\nMartha Lasley sees similarities with the Focused Conversation Method developed by the Institute of Cultural Affairs (ICA), with NVC's \"observations\", \"feelings\", \"needs\", and \"requests\" components relating to FCM's \"objective\", \"reflective\", \"interpretive\", and \"decisional\" stages.\n\nAs of 2008, some researchers noted that NVC lacked an evidence base beyond the copious anecdotal claims of effectiveness and similarly lacked discussion in the literature of the theoretical basis of the model.\n\nSeveral researchers have attempted a thorough evaluation of criticisms and weaknesses of NVC and assessed significant challenges in its application. These span a range of potential problems, from the practical to the theoretical, and include concerns gathered from study participants and researchers.\n\nThe difficulty of using NVC as well as the dangers of misuse are common concerns. In addition, Bitschnau and Flack find a paradoxical potential for violence in the use of NVC, occasioned by its unskilled use. Bitschnau further suggests that the use of NVC is unlikely to allow everyone to express their feelings and have their needs met in real life as this would require inordinate time, patience and discipline. Those who are skilled in the use of NVC may become prejudiced against those who are not and prefer to converse only among themselves.\n\nOboth suggests that people might hide their feelings in the process of empathy, subverting the nonviolence of communication.\n\nThe massive investment of time and effort in learning to use NVC has been noted by a number of researchers.\n\nChapman Flack, in reviewing a training video by Rosenberg, finds the presentation of key ideas \"spell-binding\" and the anecdotes \"humbling and inspiring\", notes the \"beauty of his work\", and his \"adroitly doing fine attentive thinking\" when interacting with his audience. Yet Flack wonders what to make of aspects of Rosenberg's presentation, such as his apparent \"dim view of the place for thinking\" and his building on Walter Wink's account of the origins of our way of thinking. To Flack, some elements of what Rosenberg says seem like pat answers at odds with the challenging and complex picture of human nature history, literature and art offer.\n\nFlack notes a distinction between the \"strong sense\" of Nonviolent Communication as a virtue that is possible with care and attention, and the \"weak sense,\" a mimicry of this born of ego and haste. The strong sense offers a language to examine one's thinking and actions, support understanding, bring one's best to the community, and honor one's emotions. In the weak sense, one may take the language as rules and use these to score debating points, label others for political gain, or insist that others express themselves in this way. Though concerned that some of what Rosenberg says could lead to the weak sense, Flack sees evidence confirming that Rosenberg understands the strong sense in practice. Rosenberg's work with workshop attendees demonstrates \"the real thing.\" Yet Flack warns that \"the temptation of the weak sense will not be absent.\" As an antidote, Flack advises, \"Be conservative in what you do, be liberal in what you accept from others,\" (also known as the robustness principle) and guard against the \"metamorphosis of nonviolent communication into subtle violence done in its name.\"\n\nEllen Gorsevski, assessing Rosenberg's book, \"Nonviolent Communication: A Language of Compassion\" (1999) in the context of geopolitical rhetoric, states that \"the relative strength of the individual is vastly overestimated while the key issue of structural violence is almost completely ignored.\"\n\nPuddleDancer Press reports that NVC has been endorsed by a variety of public figures.\n\nSven Hartenstein has created a series of cartoons spoofing NVC.\n\nReportedly, one of the first acts of Satya Nadella when he became CEO of Microsoft in 2014 was to ask top company executives to read Rosenberg's book, \"Nonviolent Communication.\"\n\nThe Center for Nonviolent Communication (CNVC), founded by Marshall Rosenberg, has trademarked the terms \"NVC\", \"Nonviolent Communication\" and \"Compassionate Communication\", among other terms, for clarity and branding purposes.\n\nCNVC certifies trainers who wish to teach NVC in a manner aligned with CNVC's understanding of the NVC process. CNVC also offers trainings by certified trainers.\n\nSome trainings in Nonviolent Communication are offered by trainers sponsored by organizations considered as allied with, but having no formal relationship with, the Center for Nonviolent Communication founded by Marshall Rosenberg. Some of these trainings are announced through CNVC. Numerous NVC organizations have sprung up around the world, many with regional focuses.\n\n\n"}
{"id": "2025840", "url": "https://en.wikipedia.org/wiki?curid=2025840", "title": "On Moral Fiction", "text": "On Moral Fiction\n\nOn Moral Fiction is a collection of essays by the American novelist John Gardner published in 1978. ()\n\nIn this work, Gardner attacks what he sees as contemporary literature's lack of morality, which he calls the highest purpose of art and which he defines in the book. According to Gardner, morality is not an arbitrary construct of society, but an eternal truth, taking on different forms but not essentially changing through the ages. He says that moral fiction \"attempts to test human values, not for the purpose of preaching or peddling a particular ideology, but in a truly honest and open-minded effort to find out which best promotes human fulfillment.\"\n\nLeo Tolstoy, among others, espouses similar views in his essay \"What is Art?\", and Gardner draws upon Tolstoy in his argument.\n"}
{"id": "4595966", "url": "https://en.wikipedia.org/wiki?curid=4595966", "title": "Pollyanna principle", "text": "Pollyanna principle\n\nThe Pollyanna principle (also called Pollyannaism or positivity bias) is the tendency for people to remember pleasant items more accurately than unpleasant ones. Research indicates that at the subconscious level, the mind has a tendency to focus on the optimistic; while at the conscious level, it has a tendency to focus on the negative. This subconscious bias towards the positive is often described as the Pollyanna principle and is similar to the Forer effect.\n\nThe name derives from the 1913 novel \"Pollyanna\" by Eleanor H. Porter describing a girl who plays the \"glad game\"—trying to find something to be glad about in every situation. The novel has been adapted to film several times, most famously in 1920 and 1960. An early use of the name \"Pollyanna\" in psychological literature was in 1969 by Boucher and Osgood who described a \"Pollyanna hypothesis\" as a universal human tendency to use evaluatively positive words more frequently and diversely than evaluatively negative words in communicating. Empirical evidence for this tendency has been provided by computational analyses of large corpora of text.\n\nThe \"Pollyanna principle\" was described by Matlin and Stang in 1978 using the archetype of Pollyanna more specifically as a psychological principle which portrays the positive bias people have when thinking of the past. According to the Pollyanna Principle, the brain processes information that is pleasing and agreeable in a more precise and exact manner as compared to unpleasant information. We actually tend to remember past experiences as more rosy than they actually occurred.\n\nResearchers Margaret Matlin and David Stang provided substantial evidence of the Pollyanna Principle. They found that people expose themselves to positive stimuli and avoid negative stimuli, they take longer to recognize what is unpleasant or threatening than what is pleasant and safe, and they report that they encounter positive stimuli more frequently than they actually do. Matlin and Stang also determined that selective recall was a more likely occurrence when recall was delayed: the longer the delay, the more selective recall that occurred.\n\nThe Pollyanna principle has been observed on online social networks as well. For example, Twitter users preferentially share more, and are emotionally affected more frequently by, positive information.\n\nHowever, the Pollyanna principle does not always apply to individuals suffering from depression or anxiety, who tend to either have more depressive realism or a negative bias.\n\n\n"}
{"id": "34019395", "url": "https://en.wikipedia.org/wiki?curid=34019395", "title": "Prenatal testosterone transfer", "text": "Prenatal testosterone transfer\n\nPrenatal Testosterone Transfer (also known as prenatal androgen transfer or prenatal hormone transfer) refers to the phenomenon in which testosterone synthesized by a developing male fetus transfers to one or more developing fetuses within the womb and influences development. This typically results in the partial masculinization of specific aspects of female behavior, cognition, and morphology, though some studies have found that testosterone transfer can cause an exaggerated masculinization in males. There is strong evidence supporting the occurrence of prenatal testosterone transfer in rodents and other litter-bearing species, such as pigs. When it comes to humans, studies comparing dizygotic opposite-sex and same-sex twins suggest the phenomenon may occur, though the results of these studies are often inconsistent.\n\nTestosterone is a steroid hormone; therefore it has the ability to diffuse through the amniotic fluid between fetuses. In addition, hormones can transfer among fetuses through the mother's bloodstream.\n\nDuring prenatal development, testosterone exposure is directly responsible for masculinizing the genitals and brain structures. This exposure leads to an increase in male-typical behavior. When females are exposed to elevated levels of testosterone via transfer, the masculinization of a variety of traits have been reported to occur, including sexual behavior, sex-typical play, and spatial ability.\n\nMost animal studies are performed on rats or mice. In these studies, the amount of testosterone each individual fetus is exposed to depends on its intrauterine position (IUP). Each gestating fetus not at either end of the uterine horn is surrounded by either two males (2M), two females (0M), or one female and one male (1M). Development of the fetus varies widely according to its IUP.\n\nIn mice, prenatal testosterone transfer causes higher blood concentrations of testosterone in 2M females when compared to 1M or 0M females. This has a variety of consequences on later female behavior, physiology, and morphology.\n\nBelow is a table comparing physiological, morphological, and behavioral differences of 0M and 2M female mice.\n\nStudies involving humans often compare opposite-sex to same-sex dizygotic twins. Females of opposite-sex twin pairs are thought to have partially masculinized traits as a result of gestating along with a male. These studies test for a range of masculinized cognitive, morphological, physiological, and behavioral traits. Studies testing for differences in behavior (i.e. temperament) tend to yield inconsistent results, while those testing perception and cognition are typically more consistent. Though supporting evidence exists, whether or not prenatal testosterone transfer occurs in humans remains debatable.\n\nListed below are different types of opposite-sex versus same-sex twin tests used to determine whether prenatal testosterone transfer occurs in humans.\n\n\n\n"}
{"id": "2118843", "url": "https://en.wikipedia.org/wiki?curid=2118843", "title": "Progress", "text": "Progress\n\nProgress is the idea that advances in technology, science, and social organization can produce an improvement in the human condition, and therefore that entire societies, and humanity in general, can improve in terms of their social, political, and economic structures. This may happen as a result of direct human action, as in social enterprise or through activism, or as a natural part of sociocultural evolution.\n\nThe concept of progress was introduced in the early 19th century social theories, especially social evolution as described by Auguste Comte and Herbert Spencer. It was present in the Enlightenment's philosophies of history. As a goal, social progress has been advocated by varying realms of political ideologies with different theories on how it is to be achieved.\n\nSpecific indicators for measuring progress can range from economic data, technical innovations, change in the political or legal system, and questions bearing on individual life chances, such as life expectancy and risk of disease and disability.\n\nGDP growth has become a key orientation for politics and is often taken as a key figure to evaluate a politician's performance. However, GDP has a number of flaws that make it a bad measure of progress, especially for developed countries. For example, environmental damage is not taken into account nor is the sustainability of economic activity. Wikiprogress has been set up to share information on evaluating societal progress. It aims to facilitate the exchange of ideas, initiatives and knowledge. HumanProgress.org is another online resource that seeks to compile data on different measures of societal progress.\n\nThe Social Progress Index is a tool developed by the International Organization Imperative Social Progress, which measures the extent to which countries cover social and environmental needs of its citizenry. There are fifty-two indicators in three areas or dimensions: Basic Human Needs, and Foundations of Wellbeing and Opportunities which show the relative performance of nations.\n\nIndices that can be used to measure progress include:\n\nScientific progress is the idea that the scientific community learns more over time, which causes a body of scientific knowledge to accumulate. The chemists in the 19th century knew less about chemistry than the chemists in the 20th century, and they in turn knew less than the chemists in the 21st century. Looking forward, today's chemists reasonably expect that chemists in future centuries will know more than they do. \n\nThis process differs from non-science fields, such as human languages or history: the people who spoke a now-extinct language, or who lived through a historical time period, can be said to have known different things from the scholars who studied it later, but they cannot be said to know less about their lives than the modern scholars. Some valid knowledge is lost through the passage of time, and other knowledge is gained, with the result that the non-science fields do not make scientific progress towards understanding their subject areas.\n\nFrom the 18th century through late 20th century, the history of science, especially of the physical and biological sciences, was often presented as a progressive accumulation of knowledge, in which true theories replaced false beliefs. Some more recent historical interpretations, such as those of Thomas Kuhn, tend to portray the history of science in terms of competing paradigms or conceptual systems in a wider matrix of intellectual, cultural, economic and political trends. These interpretations, however, have met with opposition for they also portray the history of science as an incoherent system of incommensurable paradigms, not leading to any scientific progress, but only to the illusion of progress.\n\nAspects of social progress, as described by Condorcet, have included the disappearance of slavery, the rise of literacy, the lessening of inequalities between the sexes, reforms of harsh prisons and the decline of poverty.\n\nHow progress improved the degraded status of women in traditional society was a major theme of historians starting in the Enlightenment and continuing to today. British theorists William Robertson (1721–1793) and Edmund Burke (1729–1797), along with many of their contemporaries, remained committed to Christian- and republican-based conceptions of virtue, while working within a new Enlightenment paradigm. The political agenda related beauty, taste, and morality to the imperatives and needs of modern societies of a high level of sophistication and differentiation. Two themes in the work of Robertson and Burke—the nature of women in 'savage' and 'civilized' societies and 'beauty in distress'—reveals how long-held convictions about the character of women, especially with regard to their capacity and right to appear in the public domain, were modified and adjusted to the idea of progress and became central to an enlightened affirmation of modern European civilization.\n\nClassics experts have examined the status of women in the ancient world, concluding that in the Roman Empire, with its superior social organization, internal peace, and rule of law, allowed women to enjoy a somewhat better standing than in ancient Greece, where women were distinctly inferior. The inferior status of women in traditional China has raised the issue of whether the idea of progress requires a thoroughgoing reject of traditionalism—a belief held by many Chinese reformers in the early 20th century.\n\nHistorians Leo Marx and Bruce Mazlish asking, \"Should we in fact abandon the idea of progress as a view of the past,\" answer that there is no doubt \"that the status of women has improved markedly\" in cultures that have adopted the Enlightenment idea of progress.\n\nModernization was promoted by classical liberals in the 19th and 20th centuries, who called for the rapid modernization of the economy and society to remove the traditional hindrances to free markets and free movements of people. During the Enlightenment in Europe social commentators and philosophers began to realize that people \"themselves\" could change society and change their way of life. Instead of being made completely by gods, there was increasing room for the idea that people themselves \"made their own society\"—and not only that, as Giambattista Vico argued, \"because\" people made their own society, they could also fully comprehend it. This gave rise to new sciences, or proto-sciences, which claimed to provide new scientific knowledge about what society was like, and how one may change it for the better.\n\nIn turn, this gave rise to progressive opinion, in contrast with conservational opinion. The social conservationists were skeptical about panaceas for social ills. According to conservatives, attempts to radically remake society normally make things worse. Edmund Burke was the leading exponent of this, although later-day liberals like Hayek have espoused similar views. They argue that society changes organically and naturally, and that grand plans for the remaking of society, like the French Revolution, National Socialism and Communism hurt society by removing the traditional constraints on the exercise of power.\n\nThe scientific advances of the 16th and 17th centuries provided a basis for Francis Bacon's book the New Atlantis. In the 17th century, Bernard le Bovier de Fontenelle described progress with respect to arts and the sciences, saying that each age has the advantage of not having to rediscover what was accomplished in preceding ages. The epistemology of John Locke provided further support and was popularized by the Encyclopedists Diderot, Holbach, and Condorcet. Locke had a powerful influence on the American Founding Fathers. The first complete statement of progress is that of Turgot, in his \"A Philosophical Review of the Successive Advances of the Human Mind\" (1750). For Turgot, progress covers not only the arts and sciences but, on their base, the whole of culture—manner, mores, institutions, legal codes, economy, and society. Condorcet predicted the disappearance of slavery, the rise of literacy, the lessening of inequalities between the sexes, reforms of harsh prisons and the decline of poverty.\n\nJohn Stuart Mill's (1806–1873) ethical and political thought demonstrated faith in the power of ideas and of intellectual education for improving human nature or behavior. For those who do not share this faith the idea of progress becomes questionable.\n\nAlfred Marshall (1842–1924), a British economist of the early 20th century, was a proponent of classical liberalism. In his highly influential \"Principles of Economics\" (1890), he was deeply interested in human progress and in what is now called \"sustainable development.\" For Marshall, the importance of wealth lay in its ability to promote the physical, mental, and moral health of the general population. After World War II, the modernization and development programs undertaken in the Third World were typically based on the idea of progress.\n\nIn Russia the notion of progress was first imported from the West by Peter the Great (1672–1725). An absolute ruler, he used the concept to modernize Russia and to legitimize his monarchy (unlike its usage in Western Europe, where it was primarily associated with political opposition). By the early 19th century, the notion of progress was being taken up by Russian intellectuals and was no longer accepted as legitimate by the tsars. Four schools of thought on progress emerged in 19th-century Russia: conservative (reactionary), religious, liberal, and socialist—the latter winning out in the form of Bolshevist materialism.\n\nThe intellectual leaders of the American Revolution, such as Benjamin Franklin, Thomas Paine, Thomas Jefferson and John Adams, were immersed in Enlightenment thought and believed the idea of progress meant that they could reorganize the political system to the benefit of the human condition; both for Americans and also, as Jefferson put it, for an \"Empire of Liberty\" that would benefit all mankind.\n\nJuan Bautista Alberdi (1810–1884) was one of the most influential political theorists in Argentina. Economic liberalism was the key to his idea of progress. He promoted faith in progress, while chiding fellow Latin Americans for blind copying of American and European models. He hoped for progress through promotion of immigration, education, and a moderate type of federalism and republicanism that might serve as a transition in Argentina to true democracy.\n\nIn Mexico, Jose Mora (1795–1856) was a leader of classical liberalism in the first generation after independence, leading the battle against the conservative trinity of the army, the church, and the \"hacendados\". He envisioned progress as both a process of human development by the search for philosophical truth and as the introduction of an era of material prosperity by technological advancement. His plan for Mexican reform demanded a republican government bolstered by widespread popular education free of clerical control, confiscation and sale of ecclesiastical lands as a means of redistributing income and clearing government debts, and effective control of a reduced military force by the government. Mora also demanded the establishment of legal equality between native Mexicans and foreign residents. His program, untried in his lifetime, became the key element in the Mexican Constitution of 1857.\n\nIn Italy, the idea that progress in science and technology would lead to solutions for human ills was connected to the nationalism that united the country in 1860. The Piedmontese Prime Minister Camillo Cavour envisaged the railways as a major factor in the modernization and unification of the Italian peninsula. The new Kingdom of Italy, formed in 1861, worked to speed up the processes of modernization and industrialization that had begun in the north, but were slow to arrive in the Papal States and central Italy, and were nowhere in sight in the \"Mezzogiorno\" (that is, Southern Italy, Sicily, and Sardinia). The government sought to combat the backwardness of the poorer regions in the south and work towards augmenting the size and quality of the newly created Italian army so that it could compete on an equal footing with the powerful nations of Europe. In the same period, the government was legislating in favour of public education to fight the great problem of illiteracy, upgrade the teaching classes, improve existing schools, and procure the funds needed for social hygiene and care of the body as factors in the physical and moral regeneration of the race.\n\nIn China, in the 20th century the KMT or Nationalist party, which ruled from the 1920s to the 1940s, advocated progress. The Communists under Mao Zedong adopted western models and their ruinous projects caused mass famines. After Mao's death, however, the new regime led by Deng Xiaoping (1904–1997) and his successors aggressively promoted modernization of the economy using capitalist models and imported western technology.\n\nAmong environmentalists, there is a continuum between two opposing poles. The one pole is optimistic, progressive, and business-oriented, and endorses the classic idea of progress. For example, bright green environmentalism endorses the idea that new designs, social innovations and green technologies can solve critical environmental challenges. The other is pessimistic in respect of technological solutions, warning of impending global crisis (through climate change or peak oil, for example) and tends to reject the very idea of modernity and the myth of progress that is so central to modernization thinking. Similarly, Kirkpatrick Sale, wrote about progress as a myth benefiting the few, and a pending environmental doomsday for everyone. An example is the philosophy of Deep Ecology.\n\nSociologist Robert Nisbet said that \"No single idea has been more important than ... the Idea of Progress in Western civilization for three thousand years\", and defines five \"crucial premises\" of the idea of progress:\n\nSociologist P. A. Sorokin said, \"The ancient Chinese, Babylonian, Hindu, Greek, Roman, and most of the medieval thinkers supporting theories of rhythmical, cyclical or trendless movements of social processes were much nearer to reality than the present proponents of the linear view\". Unlike Confucianism and to a certain extent Taoism, that both search for an ideal past, the Judeo-Christian-Islamic tradition believes in the fulfillment of history, which was translated into the idea of progress in the modern age. Therefore, Chinese proponents of modernization have looked to western models. According to Thompson, the late Qing dynasty reformer, Kang Youwei, believed he had found a model for reform and \"modernisation\" in the Ancient Chinese Classics.\n\nPhilosopher Karl Popper said that progress was not fully adequate as a scientific explanation of social phenomena. More recently, Kirkpatrick Sale, a self-proclaimed neo-luddite author, wrote exclusively about progress as a myth, in an essay entitled \"Five Facets of a Myth\".\n\nIggers (1965) says that proponents of progress underestimated the extent of man's destructiveness and irrationality, while critics misunderstand the role of rationality and morality in human behavior.\n\nIn 1946, psychoanalyst Charles Baudouin claimed modernity has retained the \"corollary\" of the progress myth, the idea that the present is superior to the past, while at the same time insisting that it is free of the myth:\nA cyclical theory of history was adopted by Oswald Spengler (1880–1936), a German historian who wrote \"The Decline of the West\" in 1920. World War I, World War II, and the rise of totalitarianism demonstrated that progress was not automatic and that technological improvement did not necessarily guarantee democracy and moral advancement. British historian Arnold J. Toynbee (1889–1975) felt that Christianity would help modern civilization overcome its challenges.\n\nThe Jeffersonians said that history is not exhausted but that man may begin again in a new world. Besides rejecting the lessons of the past, they Americanized the idea of progress by democratizing and vulgarizing it to include the welfare of the common man as a form of republicanism. As Romantics deeply concerned with the past, collecting source materials and founding historical societies, the Founding Fathers were animated by clear principles. They saw man in control of his destiny, saw virtue as a distinguishing characteristic of a republic, and were concerned with happiness, progress, and prosperity. Thomas Paine, combining the spirit of rationalism and romanticism, pictured a time when America's innocence would sound like a romance, and concluded that the fall of America could mark the end of 'the noblest work of human wisdom.'\n\nHistorian J. B. Bury wrote in 1920:\n\nIn the postmodernist thought steadily gaining ground from the 1980s, the grandiose claims of the modernizers are steadily eroded, and the very concept of social progress is again questioned and scrutinized. In the new vision, radical modernizers like Joseph Stalin and Mao Zedong appear as totalitarian despots, whose vision of social progress is held to be totally deformed. Postmodernists question the validity of 19th century and 20th century notions of progress—both on the capitalist and the Marxist side of the spectrum. They argue that both capitalism and Marxism over-emphasize technological achievements and material prosperity while ignoring the value of inner happiness and . Postmodernism posits that both dystopia and utopia are one and the same, overarching grand narratives with impossible conclusions.\nSome 20th-century authors refer to the \"Myth of Progress\" to refer to the idea that the human condition will inevitably improve. In 1932, English physician Montague David Eder wrote: \"The myth of progress states that civilization has moved, is moving, and will move in a desirable direction. Progress is inevitable... Philosophers, men of science and politicians have accepted the idea of the inevitability of progress.\" Eder argues that the advancement of civilization is leading to greater unhappiness and loss of control in the environment. The strongest critics of the idea of progress complain that it remains a dominant idea in the 21st century, and shows no sign of diminished influence. As one fierce critic, British historian John Gray (b. 1948), concludes:\nRecently the idea of progress has been generalized to psychology, being related with the concept of a goal, that is, progress is understood as \"what counts as a means of advancing towards the end result of a given defined goal.\"\n\nHistorian J. B. Bury said that thought in ancient Greece was dominated by the theory of world-cycles or the doctrine of eternal return, and was steeped in a belief parallel to the Judaic \"fall of man,\" but rather from a preceding \"Golden Age\" of innocence and simplicity. Time was generally regarded as the enemy of humanity which depreciates the value of the world. He credits the Epicureans with having had a potential for leading to the foundation of a theory of progress through their materialistic acceptance of the atomism of Democritus as the explanation for a world without an intervening deity.\nRobert Nisbet and Gertrude Himmelfarb have attributed a notion of progress to other Greeks. Xenophanes said \"The gods did not reveal to men all things in the beginning, but men through their own search find in the course of time that which is better.\" Plato's Book III of \"The Laws\" depicts humanity's progress from a state of nature to the higher levels of culture, economy, and polity. Plato's \"The Statesman\" also outlines a historical account of the progress of mankind.\n\nDuring the Medieval period, science was to a large extent based on Scholastic (a method of thinking and learning from the Middle Ages) interpretations of Aristotle's work. The Renaissance of the 15th, 16th and 17th Centuries changed the mindset in Europe towards an empirical view, based on a pantheistic interpretation of Plato. This induced a revolution in curiosity about nature in general and scientific advance, which opened the gates for technical and economic advance. Furthermore, the individual potential was seen as a never-ending quest for being God-like, paving the way for a view of Man based on unlimited perfection and progress.\n\nIn the Enlightenment, French historian and philosopher Voltaire (1694–1778) was a major proponent. At first Voltaire's thought was informed by the idea of progress coupled with rationalism. His subsequent notion of the historical idea of progress saw science and reason as the driving forces behind societal advancement.\n\nImmanuel Kant (1724–1804) argued that progress is neither automatic nor continuous and does not measure knowledge or wealth, but is a painful and largely inadvertent passage from barbarism through civilization toward enlightened culture and the abolition of war. Kant called for education, with the education of humankind seen as a slow process whereby world history propels mankind toward peace through war, international commerce, and enlightened self-interest.\n\nScottish theorist Adam Ferguson (1723–1816) defined human progress as the working out of a divine plan, though he rejected predestination. The difficulties and dangers of life provided the necessary stimuli for human development, while the uniquely human ability to evaluate led to ambition and the conscious striving for excellence. But he never adequately analyzed the competitive and aggressive consequences stemming from his emphasis on ambition even though he envisioned man's lot as a perpetual striving with no earthly culmination. Man found his happiness only in effort.\n\nSome scholars consider the idea of progress that was affirmed with the Enlightenment, as a secularization of ideas from early Christianity, and a reworking of ideas from ancient Greece.\n\nIn the 19th century, Romantic critics charged that progress did not automatically better the human condition, and in some ways could make it worse. Thomas Malthus (1766–1834) reacted against the concept of progress as set forth by William Godwin and Condorcet because he believed that inequality of conditions is \"the best (state) calculated to develop the energies and faculties of man\". He said, \"Had population and food increased in the same ratio, it is probable that man might never have emerged from the savage state\". He argued that man's capacity for improvement has been demonstrated by the growth of his intellect, a form of progress which offsets the distresses engendered by the law of population.\n\nGerman philosopher Friedrich Nietzsche (1844–1900) criticized the idea of progress as the 'weakling's doctrines of optimism,' and advocated undermining concepts such as faith in progress, to allow the strong individual to stand above the plebeian masses. An important part of his thinking consists of the attempt to use the classical model of 'eternal recurrence of the same' to dislodge the idea of progress.\n\nIggers (1965) argues there was general agreement in the late 19th century that the steady accumulation of knowledge and the progressive replacement of conjectural, that is, theological or metaphysical, notions by scientific ones was what created progress. Most scholars concluded this growth of scientific knowledge and methods led to the growth of industry and the transformation of warlike societies into an industrial and pacific one. They agreed as well that there had been a systematic decline of coercion in government, and an increasing role of liberty and of rule by consent. There was more emphasis on impersonal social and historical forces; progress was increasingly seen as the result of an inner logic of society.\n\nMarx developed a theory of historical materialism. He describes the mid-19th century condition in \"The Communist Manifesto\" as follows:\n\nFurthermore, Marx described the process of social progress, which in his opinion is based on the interaction between the productive forces and the relations of production:\n\nCapitalism is thought by Marx as a process of continual change, in which the growth of markets dissolve all fixities in human life, and Marx admits that capitalism is progressive and non-reactionary. Marxism further states that capitalism, in its quest for higher profits and new markets, will inevitably sow the seeds of its own destruction. Marxists believe that, in the future, capitalism will be replaced by socialism and eventually communism.\n\nMany advocates of capitalism such as Schumpeter agreed with Marx's analysis of capitalism as a process of continual change through creative destruction, but, unlike Marx, believed and hoped that capitalism could essentially go on forever.\n\nThus, by the beginning of the 20th century, two opposing schools of thought—Marxism and liberalism—believed in the possibility and the desirability of continual change and improvement. Marxists strongly opposed capitalism and the liberals strongly supported it, but the one concept they could both agree on was modernism, a trend of thought which affirms the power of human beings to make, improve and reshape their society, with the aid of scientific knowledge, technology and practical experimentation.\n\n"}
{"id": "53849196", "url": "https://en.wikipedia.org/wiki?curid=53849196", "title": "Psychical inertia", "text": "Psychical inertia\n\nPsychical inertia is a term introduced by Carl Jung to describe the psyche's resistance to development and change. He considered it one of the main reason for the neurotic opposing, or shrinking from, his/her age-appropriate tasks in life.\n\nFreud argued that such psychic inertia played a part in the lives of the normal, as well as of the neurotic, and saw its origins in fixation between early instincts and their first impressions of significant objects. As late as \"Civilization and its Discontents\", he considered as a major obstacle to cultural development \"the inertia of the libido, its disinclination to give up an old position for a new one\".\n\nLater Jungians have seen psychic inertia as a force of nature reflecting both internal and outer determinants; while others have seen it as the product of social pressures, especially in relation to ageing.\n\n"}
{"id": "2347312", "url": "https://en.wikipedia.org/wiki?curid=2347312", "title": "Rage (emotion)", "text": "Rage (emotion)\n\nRage (or fury) is intense, uncontrolled anger that is an increased stage of hostile response to a particularly egregious injury or injustice.\n\nOld French raige, rage (French: rage), from Medieval Latin rabia, from Latin rabies (\"anger fury\") akin to Sanskrit rabhas (violence). The Vulgar Latin spelling of the word possesses many cognates when translated into many of the modern Romance languages, such as Spanish, Galician, Catalan, Portuguese, and modern Italian: \"rabia\", \"rabia\", \"ràbia\", \"raiva\", and \"rabbia\" respectively.\n\nRage can sometimes lead to a state of mind where the individuals experiencing it believe they can do, and often are capable of doing, things that may normally seem physically impossible. Those experiencing rage usually feel the effects of high adrenaline levels in the body. This increase in adrenal output raises the physical strength and endurance levels of the person and sharpens their senses, while dulling the sensation of pain. High levels of adrenaline actually impair memory. Temporal perspective is also affected: people in a rage have described experiencing events in slow-motion. Time dilation occurs due to the individual becoming hyper aware of the hind brain (the seat of fight or flight). Rational thought and reasoning would inhibit an individual from acting rapidly upon impulse. An older explanation of this \"time dilation\" effect is that instead of actually slowing our perception of time, high levels of adrenaline increase our ability to recall specific minutiae of an event after it occurs. Since humans gauge time based on the number of things they can remember, high-adrenaline events such as those experienced during periods of rage seem to unfold more slowly.\n\nA person in a state of rage may also lose much of their capacity for rational thought and reasoning, and may act, usually violently, on their impulses to the point that they may attack until they themselves have been incapacitated or the source of their rage has been destroyed. A person in rage may also experience tunnel vision, muffled hearing, increased heart rate, and hyperventilation. Their vision may also become \"rose-tinted\" (hence \"seeing red\"). They often focus only on the source of their anger. The large amounts of adrenaline and oxygen in the bloodstream may cause a person's extremities to shake. Psychiatrists consider rage to be at one end of the spectrum of anger, and annoyance to be at the other side.\n\nIn 1995, rage was hypothesized to occur when oxytocin, vasopressin, and corticotropin-releasing hormone are rapidly released from the hypothalamus. This results in the pituitary gland producing and releasing large amounts of the adrenocorticotropic hormone, which causes the adrenal cortex to release corticosteroids. This chain reaction occurs when faced with a threatening situation. Nearly two decades later, more came to be known about the impacts of high epinephrine. As the focus in neuroscience began to shift towards the roles of white matter tissues, a more full bodied understanding of this complex emotion was able to be extrapolated.\n\nMemory, being the “retention of perceptions”, can be viewed as a giant mosaic (Robertson, 2002). This mosaic would consist of fragmented perceptions (tiles) being held together by astrocytes (glue), creating resistance. A ratio of 3:2 could indicate an increased demand on neurons being held together, or insulated. This also raises the possibility that a more developed memory improved an individual’s fitness.\n\nIn addition, an increase in white matter tissues assisted in an individual's ability to adapt to new cultures and environments. The metaphor of a kaleidoscope is often utilized when expressing the extraordinary ability humans have at adapting to different cultures by engaging in different patterns of thought. Our ability to perceive patterns of behavior assists in our ability to utilize inductive reasoning, a type of reasoning that can assist in an individual's ability to think of how their behaviors may impact their future. Such lines of reasoning are strengthened through the use of deductive reasoning. Together, inductive and deductive reasoning have assisted in developing adaptive conflict management strategies that assist in the cessation of rage caused by cognitive dissonance.\n\nAstrocytes play a pivotal role in regulating blood flow to and from neurons by creating the blood-brain barrier (BBB). More specifically, these astrocytes are found in close proximity to the ‘end feet’ of blood vessels. These astrocytes aid in the tightening and expansion of the blood vessels to regulate which nutrients make their way to the neurons. The BBB protects the brain from toxins and helps transport things such as oxygen and glucose to the brain.\n\nThis system plays a crucial role in the regulation of memory. Studies have suggested that glucose, together with epinephrine from the adrenal medulla have an effect on memory. Although high doses of epinephrine have been proven to impair memory, moderate doses of epinephrine actually enhance memory. This leads to questioning the role that epinephrine has played on the evolution of the genus Homo as well as epinephrine's crucial role during fits of rage. The crucial role that astrocytes play in the formation of muscle memory may also shed light on the beneficial impact of meditation and deep breathing as a method of managing and controlling one's rage.\n\nSome research suggests that an individual is more susceptible to having feelings of depression and anxiety if he or she experiences rage on a frequent basis. Health complications become much worse if an individual represses feelings of rage. John E. Sarno believes that repressed rage in the subconscious leads to physical ailments. Cardiac stress and hypertension are other health complications that will occur when rage is experienced on a regular basis. Psychopathologies such as depression and Posttraumatic stress disorder regularly present comorbidly with rage.\n\nEvidence has shown that behavioral and cognitive therapy techniques have assisted individuals that have difficulties controlling their anger or rage. Role playing and personal study are the two main techniques used to aid individuals with managing rage. Role playing is utilized by angering an individual to the point of rage and then showing them how to control it. Multi-modal cognitive therapy is another treatment used to help individuals cope with anger. This therapy teaches individuals relaxation techniques, problem solving skills, and techniques on response disruption. This type of therapy has proven to be effective for individuals that are highly stressed and are prone to rage.\n\nAn emerging business is the rage room, a place where people relieve their stress by destroying objects within a room.\n\nAccording to psychologists, rage is an in-born behavior that every person exhibits in some form. Rage is often used to denote hostile/affective/reactive aggression. Rage tends to be expressed when a person faces a threat to their pride, position, ability to deceive others, self-deceptive beliefs, or socioeconomic status. This maladaptive conflict management strategy often stems from cognitive dissonance, most simply put, a 'no' where a 'yes' has been.\n\nCases in which rage is exhibited as a direct response to an individual's deeply held religious beliefs, may directly be related to cognitive dissonance in relation to an individual's ability to manage the terror associated with death and dying. Many researchers have questioned whether Buddhist concepts, such as reincarnation and nibbâna, help ease death anxieties. Coleman and Ka-Ying Hui (2012) stated that “according to the Terror Management Theory, a religious concept of an afterlife helps people manage their personal death anxiety” (949). This suggests that rage, in relation to religious ideas, may stem from an inability to manage feelings of terror.\n\nSome psychologists, however, such as Bushman and Anderson, argue that the hostile/predatory dichotomy that is commonly employed in psychology fails to define rage fully, since it is possible for anger to motivate aggression, provoking vengeful behavior, without incorporating the impulsive thinking that is characteristic of rage. They point to individuals or groups such as Seung-Hui Cho in the Virginia Tech massacre or Eric Harris and Dylan Klebold of the Columbine High School massacre, all of whom clearly experienced intense anger and hate, but whose planning (sometimes over periods of years), forethought, and lack of impulsive behavior is readily observable.\n\nFrank, M. G.|year=(2013). Astroglial regulation of sleep homeostasis.Current Opinion in Neurobiology, 23:812-818.\n\nLundgaard I et al. White matter astrocytes in health and disease. Neuroscience. (2013), https://dx.doi.org/10.1016/j.neuroscience.2013.10.050\n\nColeman P. G. and Ka-Ying Hui, V. (2012). Do reincarnation beliefs protect older adult Chinese Buddhists against personal death anxieties? Death Studies. 36:949-958\n"}
{"id": "57072808", "url": "https://en.wikipedia.org/wiki?curid=57072808", "title": "Renata Lucas", "text": "Renata Lucas\n\nRenata Lucas (born 1971) is a Brazilian artist.\n\nShe was born in Ribeirão Preto. Lucas received a BFA and MFA from the University of Campinas and a PhD from the University of São Paulo. In 2001, in partnership with a group of artists, she opened a gallery \"10.20 x 3.60\" where she held her first solo exhibition. She lives and works in São Paulo.\n\nHer work has been exhibited at the Tate Modern in London, at the 2006 São Paulo Art Biennial, at the Institute of Contemporary Art, Boston, at the 2008 Biennale of Sydney and at the Venice Biennale in 2009. \n\nIn 2009, she received the art award from the Ernst Schering Foundation in cooperation with the Kunst-Werke Institute for Contemporary Art. Also in 2009, she received The_Dena_Foundation_Art_Award. Lucas received the PIPA Prize in 2010. In 2011, she was given a residency at the Gasworks Gallery in London.\n\nHer work is included in the collections of the Museu de Arte de Ribeirão Preto, the , the , the Museum of Modern Art, Rio de Janeiro, the Barcelona Museum of Contemporary Art, the Zabludowicz Collection and the .\n"}
{"id": "8582684", "url": "https://en.wikipedia.org/wiki?curid=8582684", "title": "Reward system", "text": "Reward system\n\nThe reward system is a group of neural structures responsible for incentive salience (i.e., motivation and \"wanting\", desire, or craving for a reward), associative learning (primarily positive reinforcement and classical conditioning), and positively-valenced emotions, particularly ones which involve pleasure as a core component (e.g., joy, euphoria and ecstasy). Reward is the attractive and motivational property of a stimulus that induces appetitive behavior, also known as approach behavior, and consummatory behavior. In its description of a rewarding stimulus (i.e., \"a reward\"), a review on reward neuroscience noted, \"any stimulus, object, event, activity, or situation that has the potential to make us approach and consume it is by definition a reward.\" In operant conditioning, rewarding stimuli function as positive reinforcers; however, the converse statement also holds true: positive reinforcers are rewarding.\n\nPrimary rewards are a class of rewarding stimuli which facilitate the survival of one's self and offspring, and include homeostatic (e.g., palatable food) and reproductive (e.g., sexual contact and parental investment) rewards. Intrinsic rewards are unconditioned rewards that are attractive and motivate behavior because they are inherently pleasurable. Extrinsic rewards (e.g., money or seeing one's favorite sports team winning a game) are conditioned rewards that are attractive and motivate behavior, but are not inherently pleasurable. Extrinsic rewards derive their motivational value as a result of a learned association (i.e., conditioning) with intrinsic rewards. Extrinsic rewards may also elicit pleasure (e.g., euphoria from winning a lot of money in a lottery) after being classically conditioned with intrinsic rewards.\n\nSurvival for most animal species depends upon maximizing contact with beneficial stimuli and minimizing contact with harmful stimuli. Reward cognition serves to increase the likelihood of survival and reproduction by causing associative learning, eliciting approach and consummatory behavior, and triggering positively-valenced emotions. Thus, reward is a mechanism that evolved to help increase the adaptive fitness of animals.\n\nIn neuroscience, the reward system is a collection of brain structures and neural pathways that are responsible for reward-related cognition, including associative learning (primarily classical conditioning and operant reinforcement), incentive salience (i.e., motivation and \"wanting\", desire, or craving for a reward), and positively-valenced emotions, particularly emotions that involve pleasure (i.e., hedonic \"liking\").\n\nTerms that are commonly used to describe behavior related to the \"wanting\" or desire component of reward include appetitive behavior, approach behavior, preparatory behavior, instrumental behavior, anticipatory behavior, and seeking. Terms that are commonly used to describe behavior related to the \"liking\" or pleasure component of reward include consummatory behavior and taking behavior.\n\nThe three primary functions of rewards are their capacity to:\n\nThe brain structures that compose the reward system are located primarily within the cortico-basal ganglia-thalamo-cortical loop; the basal ganglia portion of the loop drives activity within the reward system. Most of the pathways that connect structures within the reward system are glutamatergic interneurons, GABAergic medium spiny neurons (MSNs), and dopaminergic projection neurons, although other types of projection neurons contribute (e.g., orexinergic projection neurons). The reward system includes the ventral tegmental area, ventral striatum (i.e., the nucleus accumbens and olfactory tubercle), dorsal striatum (i.e., the caudate nucleus and putamen), substantia nigra (i.e., the pars compacta and pars reticulata), prefrontal cortex, anterior cingulate cortex, insular cortex, hippocampus, hypothalamus (particularly, the orexinergic nucleus in the lateral hypothalamus), thalamus (multiple nuclei), subthalamic nucleus, globus pallidus (both external and internal), ventral pallidum, parabrachial nucleus, amygdala, and the remainder of the extended amygdala. The dorsal raphe nucleus and cerebellum appear to modulate some forms of reward-related cognition (i.e., associative learning, motivational salience, and positive emotions) and behaviors as well. The laterodorsal tegmental nucleus (LTD), pedunculopontine nucleus (PPTg), and lateral habenula (LHb) (both directly and indirectly via the rostromedial tegmental nucleus) are also capable of inducing aversive salience and incentive salience through their projections to the ventral tegmental area (VTA). The LDT and PPTg both send glutaminergic projections to the VTA that synapse on dopaminergic neurons, both of which can produce incentive salience. The LHb sends glutaminergic projections, the majority of which synapse on GABAergic RMTg neurons that in turn drive inhibition of dopaminergic VTA neurons, although some LHb projections terminate on VTA interneurons. These LHb projections are activated both by aversive stimuli and by the absence of an expected reward, and excitation of the LHb can induce aversion.\n\nMost of the dopamine pathways (i.e., neurons that use the neurotransmitter dopamine to communicate with other neurons) that project out of the ventral tegmental area are part of the reward system; in these pathways, dopamine acts on D1-like receptors or D2-like receptors to either stimulate (D1-like) or inhibit (D2-like) the production of cAMP. The GABAergic medium spiny neurons of the striatum are components of the reward system as well. The glutamatergic projection nuclei in the subthalamic nucleus, prefrontal cortex, hippocampus, thalamus, and amygdala connect to other parts of the reward system via glutamate pathways. The medial forebrain bundle, which is a set of many neural pathways that mediate brain stimulation reward (i.e., reward derived from direct electrochemical stimulation of the lateral hypothalamus), is also a component of the reward system.\n\nTwo theories exist with regard to the activity of the nucleus accumbens and the generation liking and wanting. The inhibition (or hyper­polar­ization) hypothesis proposes that the nucleus accumbens exerts tonic inhibitory effects on downstream structures such as the ventral pallidum, hypothalamus or ventral tegmental area, and that in inhibiting in the nucleus accumbens (NAcc), these structures are excited, \"releasing\" reward related behavior. While GABA receptor agonists are capable of eliciting both \"liking\" and \"wanting\" reactions in the nucleus accumbens, glutaminergic inputs from the basolateral amygdala, ventral hippocampus, and medial prefrontal cortex can drive incentive salience. Furthermore, while most studies find that NAcc neurons reduce firing in response to reward, a number of studies find the opposite response. This had led to the proposal of the disinhibition (or depolarization) hypothesis, that proposes that excitation or NAcc neurons, or at least certain subsets, drives reward related behavior.\nAfter nearly 50 years of research on brain-stimulation reward, experts have certified that dozens of sites in the brain will maintain intracranial self-stimulation. Regions include the lateral hypothalamus and medial forebrain bundles, which are especially effective. Stimulation there activates fibers that form the ascending pathways; the ascending pathways include the mesolimbic dopamine pathway, which projects from the ventral tegmental area to the nucleus accumbens. There are several explanations as to why the mesolimbic dopamine pathway is central to circuits mediating reward. First, there is a marked increase in dopamine release from the mesolimbic pathway when animals engage in intracranial self-stimulation. Second, experiments consistently indicate that brain-stimulation reward stimulates the reinforcement of pathways that are normally activated by natural rewards, and drug reward or intracranial self-stimulation can exert more powerful activation of central reward mechanisms because they activate the reward center directly rather than through the peripheral nerves. Third, when animals are administered addictive drugs or engage in naturally rewarding behaviors, such as feeding or sexual activity, there is a marked release of dopamine within the nucleus accumbens. However, dopamine is not the only reward compound in the brain.\n\n<section begin=Pleasure centers/> is a component of reward, but not all rewards are pleasurable (e.g., money does not elicit pleasure unless this response is conditioned). Stimuli that are naturally pleasurable, and therefore attractive, are known as \"intrinsic rewards\", whereas stimuli that are attractive and motivate approach behavior, but are not inherently pleasurable, are termed \"extrinsic rewards\". Extrinsic rewards (e.g., money) are rewarding as a result of a learned association with an intrinsic reward. In other words, extrinsic rewards function as motivational magnets that elicit \"wanting\", but not \"liking\" reactions once they have been acquired.\n\nThe reward system contains – i.e., brain structures that mediate pleasure or \"liking\" reactions from intrinsic rewards. hedonic hotspots have been identified in subcompartments within the nucleus accumbens shell, ventral pallidum, parabrachial nucleus, orbitofrontal cortex (OFC), and insular cortex. The hotspot within the nucleus accumbens shell is located in the rostrodorsal quadrant of the medial shell, while the hedonic coldspot is located in a more posterior region. The posterior ventral pallidum also contains a hedonic hotspot, while the anterior ventral pallidum contains a hedonic coldspot. Microinjections of opioids, endocannabinoids, and orexin are capable of enhancing liking in these hotspots. The hedonic hotspots located in the anterior OFC and posterior insula have been demonstrated to respond to orexin and opioids, as has the overlapping hedonic coldspot in the anterior insula and posterior OFC. On the other hand, the parabrachial nucleus hotspot has only been demonstrated to respond to benzodiazepine receptor agonists.\n\nHedonic hotspots are functionally linked, in that activation of one hotspot results in the recruitment of the others, as indexed by the induced expression of c-Fos, an immediate early gene. Furthermore, inhibition of one hotspot results in the blunting of the effects of activating another hotspot. Therefore, the simultaneous activation of every hedonic hotspot within the reward system is believed to be necessary for generating the sensation of an intense euphoria.<section end=Pleasure centers/>\n\nIncentive salience is the \"wanting\" or \"desire\" attribute, which includes a motivational component, that is assigned to a rewarding stimulus by the nucleus accumbens shell (NAcc shell). The degree of dopamine neurotransmission into the NAcc shell from the mesolimbic pathway is highly correlated with the magnitude of incentive salience for rewarding stimuli.\n\nActivation of the dorsorostral region of the nucleus accumbens correlates with increases in wanting without concurrent increases in liking. However, dopaminergic neurotransmission into the nucleus accumbens shell is responsible not only for appetitive motivational salience (i.e., incentive salience) towards rewarding stimuli, but also for aversive motivational salience, which directs behavior away from undesirable stimuli. In the dorsal striatum, activation of D1 expressing MSNs produces appetitive incentive salience, while activation of D2 expressing MSNs produces aversion. In the NAcc, such a dichotomy is not as clear cut, and activation of both D1 and D2 MSNs is sufficient to enhance motivation, likely via disinhibiting the VTA through inhibiting the ventral pallidum.\nRobinson and Berridge's incentive-sensitization theory (1993) proposed that \"reward\" contains separable psychological components: wanting (incentive) and liking (pleasure). To explain increasing contact with a certain stimulus such as chocolate, there are two independent factors at work – our desire to have the chocolate (wanting) and the pleasure effect of the chocolate (liking). According to Robinson and Berridge, wanting and liking are two aspects of the same process, so rewards are usually wanted and liked to the same degree. However, wanting and liking also change independently under certain circumstances. For example, rats that do not eat after receiving dopamine (experiencing a loss of desire for food) act as though they still like food. In another example, activated self-stimulation electrodes in the lateral hypothalamus of rats increase appetite, but also cause more adverse reactions to tastes such as sugar and salt; apparently, the stimulation increases wanting but not liking. Such results demonstrate that our reward system includes independent processes of wanting and liking. The wanting component is thought to be controlled by dopaminergic pathways, whereas the liking component is thought to be controlled by opiate-benzodiazepine systems.\n\nAnimals quickly learn to press a bar to obtain an injection of opiates directly into the midbrain tegmentum or the nucleus accumbens. The same animals do not work to obtain the opiates if the dopaminergic neurons of the mesolimbic pathway are inactivated. In this perspective, animals, like humans, engage in behaviors that increase dopamine release.\n\nKent Berridge, a researcher in affective neuroscience, found that sweet (\"liked\" ) and bitter (\"disliked\" ) tastes produced distinct orofacial expressions, and these expressions were similarly displayed by human newborns, orangutans, and rats. This was evidence that pleasure (specifically, \"liking\") has objective features and was essentially the same across various animal species. Most neuroscience studies have shown that the more dopamine released by the reward, the more effective the reward is. This is called the hedonic impact, which can be changed by the effort for the reward and the reward itself. Berridge discovered that blocking dopamine systems did not seem to change the positive reaction to something sweet (as measured by facial expression). In other words, the hedonic impact did not change based on the amount of sugar. This discounted the conventional assumption that dopamine mediates pleasure. Even with more-intense dopamine alterations, the data seemed to remain constant.\n\nBerridge developed the \"incentive salience hypothesis\" to address the \"wanting\" aspect of rewards. It explains the compulsive use of drugs by drug addicts even when the drug no longer produces euphoria, and the cravings experienced even after the individual has finished going through withdrawal. Some addicts respond to certain stimuli involving neural changes caused by drugs. This sensitization in the brain is similar to the effect of dopamine because \"wanting\" and \"liking\" reactions occur. Human and animal brains and behaviors experience similar changes regarding reward systems because these systems are so prominent.\n\nRewarding stimuli can drive learning in both the form of classical conditioning (Pavlovian conditioning) and operant conditioning (instrumental conditioning). In classical conditioning, a reward can act as an unconditioned stimulus that, when associated with the conditioned stimulus, causes the conditioned stimulus to elicit both musculoskeletal (in the form of simple approach and avoidance behaviors) and vegetative responses. In operant conditioning, a reward may act as a reinforcer in that it increases or supports actions that lead to itself. Learned behaviors may or may not be sensitive to the value of the outcomes they lead to; behaviors that are sensitive to the contingency of an outcome on the performance of an action as well as the outcome value are goal-directed, while elicited actions that are insensitive to contingency or value are called habits. This distinction is thought to reflected two forms of learning, model free and model based. Model free learning involves the simple caching and updating of values. In contrast, model based learning involves the storage and construction of an internal model of events that allows inference and flexible prediction. Although pavlovian conditioning is generally assumed to be model-free, the incentive salience assigned to a conditioned stimulus is flexible with regard to changes in internal motivational states.\n\nDistinct neural systems are responsible for learning associations between stimuli and outcomes, actions and outcomes, and stimuli and responses. Although classical conditioning is not limited to the reward system, the enhancement of instrumental performance by stimuli (i.e., Pavlovian-instrumental transfer) requires the nucleus accumbens. Habitual and goal directed instrumental learning are dependent upon the lateral striatum and the medial striatum, respectively.\n\nDuring instrumental learning, opposing changes in the ratio of AMPA to NMDA receptors and phosphorylated ERK occurs in the D-type and D-type MSNs that constitute the direct and indirect pathways, respectively. These changes in synaptic plasticity and the accompanying learning is dependent upon activation of striatal D1 and NMDA receptors. The intracellular cascade activated by D1 receptors involves the recruitment of protein kinase A, and through resulting phosphorylation of DARPP-32, the inhibition of phosphatases that deactivate ERK. NMDA receptors activate ERK through a different but interrelated Ras-Raf-MEK-ERK pathway. Alone NMDA mediated activation of ERK is self-limited, as NMDA activation also inhibits PKA mediated inhibition of ERK deactivating phosphatases. However, when D1 and NMDA cascades are co-activated, they work synergistically, and the resultant activation of ERK regulates synaptic plasticity in the form of spine restructuring, transport of AMPA receptors, regulation of CREB, and increasing cellular excitability via inhibiting Kv4.2\n\nThe first clue to the presence of a reward system in the brain came with an accident discovery by James Olds and Peter Milner in 1954. They discovered that rats would perform behaviors such as pressing a bar, to administer a brief burst of electrical stimulation to specific sites in their brains. This phenomenon is called intracranial self-stimulation or brain stimulation reward. Typically, rats will press a lever hundreds or thousands of times per hour to obtain this brain stimulation, stopping only when they are exhausted. While trying to teach rats how to solve problems and run mazes, stimulation of certain regions of the brain where the stimulation was found seemed to give pleasure to the animals. They tried the same thing with humans and the results were similar. The explanation to why animals engage in a behavior that has no value to the survival of either themselves or their species is that the brain stimulation is activating the system underlying reward.\n\nIn a fundamental discovery made in 1954, researchers James Olds and Peter Milner found that low-voltage electrical stimulation of certain regions of the brain of the rat acted as a reward in teaching the animals to run mazes and solve problems. It seemed that stimulation of those parts of the brain gave the animals pleasure, and in later work humans reported pleasurable sensations from such stimulation. When rats were tested in Skinner boxes where they could stimulate the reward system by pressing a lever, the rats pressed for hours. Research in the next two decades established that dopamine is one of the main chemicals aiding neural signaling in these regions, and dopamine was suggested to be the brain's \"pleasure chemical\".\n\nIvan Pavlov was a psychologist who used the reward system to study classical conditioning. Pavlov used the reward system by rewarding dogs with food after they had heard a bell or another stimulus. Pavlov was rewarding the dogs so that the dogs associated food, the reward, with the bell, the stimulus.\nEdward L. Thorndike used the reward system to study operant conditioning. He began by putting cats in a puzzle box and placing food outside of the box so that the cat wanted to escape. The cats worked to get out of the puzzle box to get to the food. Although the cats ate the food after they escaped the box, Thorndike learned that the cats attempted to escape the box without the reward of food. Thorndike used the rewards of food and freedom to stimulate the reward system of the cats. Thorndike used this to see how the cats learned to escape the box.\n\nΔFosB (DeltaFosB) – a gene transcription factor – overexpression in the D1-type medium spiny neurons of the nucleus accumbens is the \"crucial\" common factor among virtually all forms of addiction (i.e., behavioral addictions and drug addictions) that induces addiction-related behavior and neural plasticity. In particular, ΔFosB promotes self-administration, reward sensitization, and reward cross-sensitization effects among specific addictive drugs and behaviors. Certain epigenetic modifications of histone protein tails (i.e., histone modifications) in specific regions of the brain are also known to play a crucial role in the molecular basis of addictions.\n\nAddictive drugs and behaviors are rewarding and reinforcing (i.e., are \"addictive\") due to their effects on the dopamine reward pathway.\nThe lateral hypothalamus and medial forebrain bundle has been the most-frequently-studied brain-stimulation reward site, particularly in studies of the effects of drugs on brain stimulation reward. The neurotransmitter system that has been most-clearly identified with the habit-forming actions of drugs-of-abuse is the mesolimbic dopamine system, with its efferent targets in the nucleus accumbens and its local GABAergic afferents. The reward-relevant actions of amphetamine and cocaine are in the dopaminergic synapses of the nucleus accumbens and perhaps the medial prefrontal cortex. Rats also learn to lever-press for cocaine injections into the medial prefrontal cortex, which works by increasing dopamine turnover in the nucleus accumbens. Nicotine infused directly into the nucleus accumbens also enhances local dopamine release, presumably by a presynaptic action on the dopaminergic terminals of this region. Nicotinic receptors localize to dopaminergic cell bodies and local nicotine injections increase dopaminergic cell firing that is critical for nicotinic reward. Some additional habit-forming drugs are also likely to decrease the output of medium spiny neurons as a consequence, despite activating dopaminergic projections. For opiates, the lowest-threshold site for reward effects involves actions on GABAergic neurons in the ventral tegmental area, a secondary site of opiate-rewarding actions on medium spiny output neurons of the nucleus accumbens. Thus GABAergic afferents to the mesolimbic dopamine neurons (primary substrate of opiate reward), the mesolimbic dopamine neurons themselves (primary substrate of psychomotor stimulant reward), and GABAergic efferents to the mesolimbic dopamine neurons (a secondary site of opiate reward) form the core of currently characterized drug-reward circuitry.\n\nDysfunctional motivational salience appears in a number of psychiatric symptoms and disorders. Anhedonia, traditionally defined as a reduced capacity to feel pleasure, has been reexamined as reflecting blunted incentive salience, as most anhedonic populations exhibit intact “liking”. On the other end of the spectrum, heightened incentive salience that is narrowed for specific stimuli is characteristic of behavioral and drug addictions. In the case of fear or paranoia, dysfunction may lie in elevated aversive salience.\n\nNeuroimaging studies across diagnoses associated with anhedonia have reported reduced activity in the OFC and ventral striatum. One meta analysis reported anhedonia was associated with reduced neural response to reward anticipation in the caudate nucleus, putamen, nucleus accumbens and medial prefrontal cortex (mPFC).\n\nDepression is associated with reduced motivation, as assessed by willingness to expend effort for reward. These abnormalities have been tentatively linked to reduced activity in areas of the striatum, and while dopaminergic abnormalities are hypothesized to play a role, most studies probing dopamine function in depression have reported inconsistent results. Although postmortem and neuroimaging studies have found abnormalities in numerous regions of the reward system, few findings are consistently replicated. Some studies have reported reduced NAcc, hippocampus, medial prefrontal cortex (mPFC), and orbitofrontal cortex (OFC) activity, as well as elevated basolateral amygdala and subgenual cingulate cortex (sgACC) activity during tasks related to reward or positive stimuli. These neuroimaging abnormalities are complimented by little post mortem research, but what little research has been done suggests reduced excitatory synapses in the mPFC. Reduced activity in the mPFC during reward related tasks appears to be localized to more dorsal regions(i.e. the pregenual cingulate cortex), while the more ventral sgACC is hyperactive in depression.\n\nAttempts to investigate underlying neural circuitry in animal models has also yielded conflicting results. Two paradigms are commonly used to simulate depression, chronic social defeat (CSDS), and chronic mild stress (CMS), although many exist. CSDS produces reduced preference for sucrose, reduced social interactions, and increased immobility in the forced swim test. CMS similarly reduces sucrose preference, and behavioral despair as assessed by tail suspension and forced swim tests. Animals susceptible to CSDS exhibit increased phasic VTA firing, and inhibition of VTA-NAcc projections attenuates behavioral deficits induced by CSDS. However, inhibition of VTA- projections exacerbates social withdrawal. On the other hand, CMS associated reductions in sucrose preference and immobility were attenuated and exacerbated by VTA excitation and inhibition, respectively. Although these differences may be attributable to different stimulation protocols or poor translational paradigms, variable results may also lie in the heterogenous functionality of reward related regions.\n\nOptogenetic stimulation of the mPFC as a whole produces antidepressant effects. This effect appears localized to the rodent homologue of the pgACC (the prelimbic cortex), as stimulation of the rodent homologue of the sgACC (the infralimbic cortex) produces no behavioral effects. Furthermore, deep brain stimulation in the infralimbic cortex, which is thought to have an inhibitory effect, also produces an antidepressant effect. This finding is congruent with the observation that pharmacological inhibition of the infralimbic cortex attenuates depressive behaviors.\n\nSchizophrenia is associated with deficits in motivation, commonly grouped under other negative symptoms such as reduced spontaneous speech. The experience of “liking” is frequently reported to be intact, both behaviorally and neurally, although results may be specific to certain stimuli, such as monetary rewards. Furthermore, implicit learning and simple reward related tasks are also intact in schizophrenia. Rather, deficits in the reward system present during reward related tasks that are cognitively complex. These deficits are associated with both abnormal striatal and OFC activity, as well as abnormalities in regions associated with cognitive functions such as the dorsolateral prefrontal cortex (dlPFC).\n\n"}
{"id": "36788348", "url": "https://en.wikipedia.org/wiki?curid=36788348", "title": "SWOQe", "text": "SWOQe\n\nSWOQe is a new method of strategic planning which derived from SWOT. SWOQe contains the same letters S, W and O with their meanings from SWOT Analysis involved in a project or in a business venture. SWOQe can be defined as Strength, Weakness, Opportunity and most importantly Quality evaluation as a part of analysis. SWOQe and SWOT differ in just one element. SWOQe does emphasize on Quality evaluation in end while SWOT on Threats in end. SWOQe method of analysis came into existence recently from an analysis where Threat was not there or not important as Quality evaluation was.\n"}
{"id": "6129873", "url": "https://en.wikipedia.org/wiki?curid=6129873", "title": "Schouten tensor", "text": "Schouten tensor\n\nIn Riemannian geometry, the Schouten tensor is a second-order tensor introduced by Jan Arnoldus Schouten. It is defined for by:\n\nwhere Ric is the Ricci tensor, \"R\" is the scalar curvature, \"g\" is the Riemannian metric, formula_2 is the trace of \"P\" and \"n\" is the dimension of the manifold.\n\nThe Weyl tensor equals the Riemann curvature tensor minus the Kulkarni–Nomizu product of the Schouten tensor with the metric. In an index notation\n\nThe Schouten tensor often appears in conformal geometry because of its relatively simple conformal transformation law\n\nwhere formula_5\n\n\n"}
{"id": "40740793", "url": "https://en.wikipedia.org/wiki?curid=40740793", "title": "Scottish common sense realism", "text": "Scottish common sense realism\n\nScottish Common Sense Realism, also known as the Scottish School of Common Sense, is a realist school of philosophy that originated in the ideas of Scottish philosophers Thomas Reid, Adam Ferguson, James Beattie, and Dugald Stewart during the 18th-century Scottish Enlightenment. Reid emphasized man's innate ability to perceive common ideas and that this process is inherent in and interdependent with judgement. Common sense therefore, is the foundation of philosophical inquiry. Though best remembered for its opposition to the pervasive philosophy of David Hume, Scottish Common Sense philosophy is influential and evident in the works of Thomas Jefferson and late 18th-century American politics.\n\nThe Scottish School of Common Sense was an epistemological philosophy that flourished in Scotland in the late 18th and early 19th centuries. Its roots can be found in responses to the writings of such philosophers as John Locke, George Berkeley and David Hume, and its most prominent members were Dugald Stewart, Thomas Reid and William Hamilton. Philosophically, Scottish Realism served as a rebuttal to scepticism while keeping with the influential teachings of Isaac Newton and Francis Bacon. While largely understated for many years, the influence it had on philosophers elsewhere in Europe, not to mention in the United States, is of a considerable magnitude.\n\nOne central concern of the school was to defend \"common sense\" against philosophical paradox and scepticism. It argued that common-sense beliefs govern the lives and thoughts even of those who avow non-commonsensical beliefs and that matters of common sense are inherent to the acquisition of knowledge. The qualities of its works were not generally consistent; Edward S. Reed writes, e.g., \"[Whereas] Thomas Reid wished to use common sense to develop philosophical wisdom, much of this school simply wanted to use common sense to attack any form of intellectual change.\"\n\nThe Scottish School of Common Sense was founded by Reid in opposition to Descartes's Theory of Ideas. But the epistemology of sense experience led John Locke and David Hume to a skeptical philosophy that realists found absurd and contrary to common experience. Thus Hume and his sceptical argument would serve as the primary foil to the development of Reid's philosophy. Under the tutelage of George Turnbull, Reid embraced the tenets of Providential Naturalism and its four interconnected tenets; using these as the basis for his refutation of the theory of ideas. Reid painstakingly developed his treatise \"An Inquiry into the Human Mind on the Principles of Common Sense\" over the course of 40 years, often seeking the input of his contemporary philosophers within the Scottish Enlightenment including Hume.\n\nReid articulated the basic principle of Common Sense Realism:\n\nScottish Common Sense Realism is rooted in Aristotelian thought and advocates an empirical and scientific philosophy wherein trust of our senses is implicit and necessary. The principles of common sense are fundamental to our accumulation of knowledge of both metaphysical and physical constructs. However, observation alone cannot account for all knowledge and truth can be garnered by reflection. In Reid's own words:\n\nThe school taught that every person had ordinary experiences that provided intuitively certain assurance of a) the existence of the self, b) the existence of real objects that could be seen and felt; and c) certain \"first principles\" upon which sound morality and religious beliefs could be established. These principles laid the foundation for Reid's influential theory of perception.\n\nIn practice, philosophers of the Scottish school offered scientific explanations to historical events and advocated an unprejudiced and inter-disciplinary approach to education, free from religious and patriotic biases.\n\nThomas Reid and Dugald Stewart offered related theories of perception rooted in Scottish Common Sense Realism. According to Nicholas Wolterstorff of Yale University, Reid's philosophy can be non-contentiously reduced to four basic precepts:\nDugald Stewart's theory of perception acknowledges a great influence from Reid whose philosophy he termed \"fundamental laws of belief.\". However, Stewart proffered a more moderate approach to realism and his theory of perception emphasized the utility of the senses.\n\nCommon Sense Realism not only dominated Scottish thought in the 19th century, it had a major influence as well in France, the United States, and other countries. Victor Cousin (1792–1867) was the most important proponent in France. Reidian thought was the \"orthodox philosophy of colleges and universities\" in the early 18th century and provided an intellectual bedrock for the Age of Enlightenment. \n\nCommon Sense Realism swept American intellectual circles in the 18th century. Reid's philosophy was pervasive during the American Revolution and served as a stabilizing philosophical influence. Hailed by some as the \"father of modern psychiatry,\" Benjamin Rush's tutelage at the University of Edinburgh imbued him with strong realist tendencies which influenced much of his scientific and political work including his moral opposition to slavery. Evidence of the influence of Scottish Common Sense realism can readily be found in the philosophy of both Thomas Jefferson and John Adams. Adams compared the contributions of Dugald Stewart favorably to works of Aristotle and René Descartes. Scotsman and signer of the Declaration of Independence, John Witherspoon presided over Princeton University; students under his tutelage included 12 state governors, 55 delegates to the Constitutional Convention and future president James Madison. His education at the University of Edinburgh made him a strong proponent of the Scottish Enlightenment and Realism. James McCosh (1811–94) continued the influence of Scottish Realism at Princeton when he became president of the university in 1868, reviving its influence as a major stronghold of the movement. Noah Porter (1811–92) taught Common Sense realism to generations of students at Yale.\n\nScottish Realism greatly influenced conservative religious thought and was strongest at Princeton Seminary until the Seminary moved in new directions after 1929. The Princeton theologians built their elaborate system on the basis of \"common-sense\" realism, biblicism and confessionalism. James McCosh was brought from Queen's College, Belfast, to Princeton College's Chair of Moral Philosophy and Presidency because of his book \"The Method of Divine Government,\" a Christian philosophy that was precursory to Charles Darwin's \"The Origin of Species\" (1859). The Princeton Theologians followed McCosh to adopt a stance of theistic evolution. They tried to persuade John Gresham Machen (1881–1937), a leader of the Fundamentalists in the 1920s, but he would not stand with McCosh, nor could he stand for the shift the school was making. Therefore, he and a number of other Princeton faculty members left and started Westminster Theological Seminary in Philadelphia. This, however, did not stop McCosh from moving forward. It was his goal to develop Princeton as a Christian university in North America, as well as a forefront intellectual seminary of the Presbyterian Church. The faculty of the College and Seminary included both evolutionary thinkers and non-evolutionary thinkers. Much evangelical theology of the 21st century is based on Princeton theology and thus reflects Common Sense Realism. New Testament scholar Grant Osborne concludes that Scottish Common Sense Realism influenced biblical hermeneutics, that the surface level understanding of Scripture became popular, and individualistic interpretations abounded.\n\n\n\n\n\n"}
{"id": "29359248", "url": "https://en.wikipedia.org/wiki?curid=29359248", "title": "Self-realization", "text": "Self-realization\n\nSelf-realization is an expression used in Western psychology, philosophy, and spirituality; and in Indian religions. In the Western understanding it is the \"fulfillment by oneself of the possibilities of one's character or personality.\" In the Indian understanding, self-realization is liberating knowledge of the true Self, either as the permanent undying Atman, or as the absence (\"sunyata\") of such a permanent Self.\n\nMerriam Webster's dictionary defines self-realization as:\nIn the Western world \"self-realization\" has gained great popularity. Influential in this popularity were psycho-analysis, humanistic psychology, the growing acquaintance with Eastern religions, and the growing popularity of Western esotericism.\n\nThough Sigmund Freud was skeptical of religion and esotericism, his theories have had a lasting influence on Western thought and self-understanding. His notion of repressed memories, though based on false assumptions, has become part of mainstream thought.\n\nFreud's ideas were further developed by his students and neo-psycho-analysts. Carl Jung, Erik Erikson, and Winnicott have been especially important in the Western understanding of the self. But other alternatives have also been developed.\n\nJung developed the notion of individuation, the lifelong process in which the centre of psychological life shifts from the ego to the self.\n\nErikson described human development throughout the life-span in his theory of psychosocial development.\n\nWinnicott developed the notion of the true self.\n\nRoberto Assagioli developed his approach of Psychosynthesis, an original approach to psychology.\n\nWestern esotericism integrates a broad variety of traditions, some of which view self-realization as the ultimate goal of a human being.\n\nJain philosophy is the oldest world philosophy that separates body (matter) from the soul (consciousness) completely. \nIndividual conscience and individual consciousness are central in the Jain philosophy. Self-realisation is one of the major pre-requisites to attain ultimate enlightenment and liberation (moksha). Self-realisation means peeling away fabricated layers of own personality to understand the true self and hence the true nature of reality. In Jainism, karma is portrayed as invisible particles of subtle matter that adhere to a living organism or Jiva. These particles come together to form a film of negativity and darkness around the soul that obscures the true consciousness; making the Jiva lose touch with its original essence as a soul. These karmic particles tend to attract more such particles which cause the inflow of auspicious and evil karmic matter into the soul (Āsrava), leading the organism to fall into the bondage of lust, worldly pleasures, ego, hatred, jealousy, anger, etc. Thus self-realisation paves the way to simply reverse this process and help the seeker to decipher the absolute truth on its own. Jainism firmly rejects the belief of a creator, and one being is solely responsible for his thoughts, actions, and their consequences.\n\nIn Hinduism, self-realization (\"atma-jnana\" or \"atmabodha\" ) is knowledge of the true self beyond both delusion and identification with material phenomena. It refers to self-identification and not mere ego identification.\n\nIn Shaivism, self-realization is the direct knowing of the Self God Parashiva. Self-realization (nirvikalpa samadhi, which means \"ecstasy without form or seed,\" or asamprajñata samādhi) is considered the ultimate spiritual attainment. \n\nSelf-realization is considered the gateway to moksha, liberation/freedom from rebirth. This state is attained when the Kundalini force pierces through the Sahasrara chakra at the crown of the head. The realization of Self, Parashiva, considered to be each soul's destiny, is attainable through renunciation, sustained meditation and preventing the germination of future karma (the phrase \"frying the seeds of karma\" is often used)\n\nĀtman is the first principle in Advaita Vedanta, along with its concept of Brahman, with Atman being the perceptible personal particular and Brahman the inferred unlimited universal, both synonymous and interchangeable. The soteriological goal, in Advaita, is to gain self-knowledge and complete understanding of the identity of Atman and Brahman. Correct knowledge of Atman and Brahman leads dissolution of all dualistic tendencies and to liberation. Moksha is attained by realizing one's true identity as Ātman, and the identity of Atman and Brahman, the complete understanding of one's real nature as Brahman in this life. This is stated by Shankara as follows:\nSince Buddhism denies the existence of a separate self, as explicated in the teachings of anatman and sunyata, self-realization is a \"contradictio in terminis\" for Buddhism. Though the tathagatagarbha-teachings seem to teach the existence of a separate self, they point to the inherent possibility of attaining awakening, not to the existence of a separate self. The dharmadhatu-teachings make this even more clear: reality is an undivided whole; awakening is the realization of this whole.\n\nSikhism propounds the philosophy of Self-realization. This is possible by \"aatam-cheennea\" or \"Aap Pashaanae\", purifying the self from the false ego:\nGuru Nanak says,\n\n"}
{"id": "2917649", "url": "https://en.wikipedia.org/wiki?curid=2917649", "title": "Speech", "text": "Speech\n\nSpeech is human vocal communication using language. Each language uses phonetic combinations of a limited set of perfectly articulated and individualized vowel and consonant sounds that form the sound of its words (that is, all English words sound different from all French words, even if they are the same word, e.g., \"role\" or \"hotel\"), and using those words in their semantic character as words in the lexicon of a language according to the syntactic constraints that govern lexical words' function in a sentence. In speaking, speakers perform many different intentional speech acts, e.g., informing, declaring, asking, persuading, directing, and can use enunciation, intonation, degrees of loudness, tempo, and other non-representational or paralinguistic aspects of vocalization to convey meaning. In their speech speakers also unintentionally communicate many aspects of their social position such as sex, age, place of origin (through accent), physical states (alertness and sleepiness, vigor or weakness, health or illness), psychic states (emotions or moods), physico-psychic states (sobriety or drunkenness, normal consciousness and trance states), education or experience, and the like. \n\nAlthough people ordinarily use speech in dealing with other persons (or animals), when people swear they do not always mean to communicate anything to anyone, and sometimes in expressing urgent emotions or desires they use speech as a quasi-magical cause, as when they encourage a player in a game to do or warn them not to do something. There are also many situations in which people engage in solitary speech. People talk to themselves sometimes in acts that are a development of what some psychologists (e.g., Lev Vygotsky) have maintained is the use in thinking of silent speech in an interior monologue to vivify and organize cognition, sometimes in the momentary adoption of a dual persona as self addressing self as though addressing another person. Solo speech can be used to memorize or to test one's memorization of things, and in prayer or in meditation (e.g., the use of a mantra).\n\nResearchers study many different aspects of speech: speech production and speech perception of the sounds used in a language, speech repetition, speech errors, the ability to map heard spoken words onto the vocalizations needed to recreate them, which plays a key role in children's enlargement of their vocabulary, and what different areas of the human brain, such as Broca's area and Wernicke's area, underlie speech. Speech is the subject of study for linguistics, cognitive science, communication studies, psychology, computer science, speech pathology, otolaryngology, and acoustics. \nSpeech compares with written language\n, which may differ in its vocabulary, syntax, and phonetics from the spoken language, a situation called diglossia. \n\nThe evolutionary origins of speech are unknown and subject to much debate and speculation. While animals also communicate using vocalizations, and trained apes such as Washoe and Kanzi can use simple sign language, no animals' vocalizations are articulated phonemically and syntactically, and do not constitute speech.\n\nSpeech production is a multi-step process by which thoughts are generated into spoken utterances. Production involves the selection of appropriate words and the appropriate form of those words from the lexicon and morphology, and the organization of those words through the syntax. Then, the phonetic properties of the words are retrieved and the sentence is uttered through the articulations associated with those phonetic properties.\n\nIn linguistics (articulatory phonetics), articulation refers to how the tongue, lips, jaw, vocal cords, and other speech organs used to produce sounds are used to make sounds. Speech sounds are categorized by manner of articulation and place of articulation. Place of articulation refers to where the airstream in the mouth is constricted. Manner of articulation refers to the manner in which the speech organs interact, such as how closely the air is restricted, what form of airstream is used (e.g. pulmonic, implosive, ejectives, and clicks), whether or not the vocal cords are vibrating, and whether the nasal cavity is opened to the airstream. The concept is primarily used for the production of consonants, but can be used for vowels in qualities such as voicing and nasalization. For any place of articulation, there may be several manners of articulation, and therefore several homorganic consonants.\n\nNormal human speech is pulmonic, produced with pressure from the lungs, which creates phonation in the glottis in the larynx, which is then modified by the vocal tract and mouth into different vowels and consonants. However humans can pronounce words without the use of the lungs and glottis in alaryngeal speech, of which there are three types: esophageal speech, pharyngeal speech and buccal speech (better known as Donald Duck talk).\n\nSpeech production is a complex activity, and as a consequence errors are common, especially in children. Speech errors come in many forms and are often used to provide evidence to support hypotheses about the nature of speech. As a result, speech errors are often used in the construction of models for language production and child language acquisition. For example, the fact that children often make the error of over-regularizing the -ed past tense suffix in English (e.g. saying 'singed' instead of 'sang') shows that the regular forms are acquired earlier. Speech errors associated with certain kinds of aphasia have been used to map certain components of speech onto the brain and see the relation between different aspects of production: for example, the difficulty of expressive aphasia patients in producing regular past-tense verbs, but not irregulars like 'sing-sang' has been used to demonstrate that regular inflected forms of a word are not individually stored in the lexicon, but produced from affixation of the base form.\n\nSpeech perception refers to the processes by which humans can interpret and understand the sounds used in language. The study of speech perception is closely linked to the fields of phonetics and phonology in linguistics and cognitive psychology and perception in psychology. Research in speech perception seeks to understand how listeners recognize speech sounds and use this information to understand spoken language. Research into speech perception also has applications in building computer systems that can recognize speech, as well as improving speech recognition for hearing- and language-impaired listeners.\n\nSpeech perception is categorical, in that people put the sounds they hear into categories rather than perceiving them as a spectrum. People are more likely to be able to hear differences in sounds across categorical boundaries than within them. A good example of this is voice onset time (VOT). For example, Hebrew speakers, who distinguish voiced /b/ from voiceless /p/, will more easily detect a change in VOT from -10 ( perceived as /b/ ) to 0 ( perceived as /p/ ) than a change in VOT from +10 to +20, or -10 to -20, despite this being an equally large change on the VOT spectrum.\n\nIn speech repetition, speech being heard is quickly turned from sensory input into motor instructions needed for its immediate or delayed vocal imitation (in phonological memory). This type of mapping plays a key role in enabling children to expand their spoken vocabulary. Masur (1995) found that how often children repeat novel words versus those they already have in their lexicon is related to the size of their lexicon later on, with young children who repeat more novel words having a larger lexicon later in development. Speech repetition could help facilitate the acquisition of this larger lexicon.\n\nThere are several organic and psychological factors that can affect speech. Among these are:\n\n\nThe classical or Wernicke-Geschwind model of the language system in the brain focuses on Broca's area in the inferior prefrontal cortex, and Wernicke's area in the posterior superior temporal gyrus on the dominant hemisphere of the brain (typically the left hemisphere for language). In this model, a linguistic auditory signal is first sent from the auditory cortex to Wernicke's area. The lexicon is accessed in Wernicke's area, and these words are sent via the arcuate fasciculus to Broca's area, where morphology, syntax, and instructions for articulation are generated. This is then sent from Broca's area to the motor cortex for articulation.\n\nPaul Broca identified an approximate region of the brain in 1861 which, when damaged in two of his patients, caused severe deficits in speech production, where his patients were unable to speak beyond a few monosyllabic words. This deficit, known as Broca's or expressive aphasia, is characterized by difficulty in speech production where speech is slow and labored, function words are absent, and syntax is severely impaired, as in telegraphic speech. In expressive aphasia, speech comprehension is generally less affected except in the comprehension of grammatically complex sentences. Wernicke's area is named after Carl Wernicke, who in 1874 proposed a connection between damage to the posterior area of the left superior temporal gyrus and aphasia, as he noted that not all aphasic patients had suffered damage to the prefrontal cortex. Damage to Wernicke's area produces Wernicke's or receptive aphasia, which is characterized by relatively normal syntax and prosody but severe impairment in lexical access, resulting in poor comprehension and nonsensical or jargon speech.\n\nModern models of the neurological systems behind linguistic comprehension and production recognize the importance of Broca's and Wernicke's areas, but are not limited to them nor solely to the left hemisphere. Instead, multiple streams are involved in speech production and comprehension. Damage to the left lateral sulcus has been connected with difficulty in processing and producing morphology and syntax, while lexical access and comprehension of irregular forms (e.g. eat-ate) remain unaffected.\nMoreover, the circuits involved in human speech comprehension dynamically adapt with learning, for example, by becoming more efficient in terms of processing time when listening to familiar messages such as learned verses.\n\n\n\n"}
{"id": "2957972", "url": "https://en.wikipedia.org/wiki?curid=2957972", "title": "Tall oil", "text": "Tall oil\n\nTall oil, also called \"liquid rosin\" or tallol, is a viscous yellow-black odorous liquid obtained as a by-product of the Kraft process of wood pulp manufacture when pulping mainly coniferous trees. The name originated as an anglicization of the Swedish \"tallolja\" (\"pine oil\"). Tall oil is the third largest chemical by-product in a Kraft mill after lignin and hemicellulose; the yield of crude tall oil from the process is in the range of 30–50 kg / ton pulp. It may contribute to 1.0–1.5% of the mill's revenue if not used internally.\n\nIn the Kraft Process, high alkalinity and temperature converts the esters and carboxylic acids in rosin into soluble sodium soaps of lignin, rosin, and fatty acids. The spent cooking liquor is called weak black liquor and is about 15% dry content. The black liquor is concentrated in a multiple effect evaporator and after the first stage the black liquor is about 20–30%. At this stage it is called intermediate liquor. Normally the soaps start to float in the storage tank for the weak or intermediate liquors and are skimmed off and collected. A good soap skimming operation reduces the soap content of the black liquor down to 0.2–0.4% w/w of the dry residue. The collected soap is called \"raw rosin soap\" or \"rosinate\". The raw rosin soap is then allowed to settle or is centrifuged to release as much as possible of the entrained black liquor. The soap goes then to the \"acidulator\" where it is heated and acidified with sulfuric acid to produce \"crude tall oil\" (CTO).\n\nThe soap skimming and acidulator operation can be improved by addition of flocculants. A flocculant will shorten the separation time and give a cleaner soap with lower viscosity. This makes the acidulator run smoother as well.\n\nMost pines give a soap yield of 5–25 kg/ton pulp, while Scots pine gives 20–50 kg/ton. Scots pine grown in northern Scandinavia give a yield of even more than 50 kg/ton. Globally about 2 mill ton/year of CTO are refined.\n\nThe composition of crude tall oil varies a great deal, depending on the type of wood used. A common quality measure for tall oil is acid number. With pure pines it is possible to have acid numbers in the range 160–165, while mills using a mix of softwoods and hardwoods might give acid numbers in the range of 125–135.\n\nNormally crude tall oil contains rosins (which contains resin acids (mainly abietic acid and its isomers), fatty acids (mainly palmitic acid, oleic acid and linoleic acid) and fatty alcohols, unsaponifiable sterols (5–10%), some sterols, and other alkyl hydrocarbon derivates.\n\nBy fractional distillation \"tall oil rosin\" is obtained, with rosin content reduced to 10–35%. By further reduction of the rosin content to 1–10%, \"tall oil fatty acid\" (\"TOFA\") can be obtained, which is cheap, consists mostly of oleic acid, and is a source of volatile fatty acids.\n\nThe tall oil rosin finds use as a component of adhesives, rubbers, and inks, and as an emulsifier. The pitch is used as a binder in cement, an adhesive, and an emulsifier for asphalt.\n\nTOFA is a low-cost and vegetarian lifestyle-friendly alternative to tallow fatty acids for production of soaps and lubricants. When esterified with pentaerythritol, it is used as a compound of adhesives and oil-based varnishes. When reacted with amines, polyamidoamines are produced which may be used as epoxy resin curing agents . \n\nTall oil is also used in oil drilling as a component of drilling fluids.\n"}
{"id": "43581204", "url": "https://en.wikipedia.org/wiki?curid=43581204", "title": "Terrafugia TF-X", "text": "Terrafugia TF-X\n\nThe Terrafugia TF-X is the first fully autonomous flying car under development by Boston-based Terrafugia. Its expected release date is listed as eight to twelve years. The TF-X seats four passengers and uses an engine combined with two electric motors for propulsion. Unlike the previously proposed Transition, the TF-X is capable of vertical take-off and landing by extending its retractable wings attached with pusher propellers while aerial thrust is provided by a ducted fan at the rear. It will be able to fit in a single car garage.\n\nPowered by two plug-in hybrid 600-horsepower electric motors and a 300-horsepower fuel engine, the TF-X is planned to have a flight range of 500 miles (805 km) with a cruising flight speed of 200 mph (322 km/h) without the need to refuel or recharge. Road speed is currently unknown.\n\nDue to the success of the Transition vehicle, Terrafugia announced in 2013 that they were developing the TF-X. When in flight, the TF-X is effectively autonomous, with its pilot able to navigate to a pre-specified landing zone—and pre-selected backup landing zones—by itself, although manual controls and overrides exist. Final landing must be approved by the pilot. The TF-X will also provide operators the choice to fly in either manual or automatic during flight with the ability to control the vehicle in a manner similar to steering the wheel of an automobile. Terrafugia claims that learning to drive the TF-X is likely to take five hours and will take substantially less time to learn how to safely operate than a traditional aircraft.\n\nThe TF-X will be capable of avoiding air traffic, bad weather, and restricted and tower-controlled airspace. For additional safety features, the TF-X would automatically land at the nearest airport if the operator becomes unresponsive. Additionally, if a TF-X operator declares an emergency, the authorities will be automatically notified of the situation and the TF-X can be landed in a non-approved landing zone. The TF-X also features a backup full vehicle parachute system that can be activated if the operator believes the vehicle is incapable of auto-landing.\n\nPricing is expected to be upwards of £200,000 (roughly $300,000).\n\n\n"}
{"id": "14155727", "url": "https://en.wikipedia.org/wiki?curid=14155727", "title": "Trusted timestamping", "text": "Trusted timestamping\n\nTrusted timestamping is the process of securely keeping track of the creation and modification time of a document. Security here means that no one—not even the owner of the document—should be able to change it once it has been recorded provided that the timestamper's integrity is never compromised.\n\nThe administrative aspect involves setting up a publicly available, trusted timestamp management infrastructure to collect, process and renew timestamps.\n\nThe idea of timestamping information is centuries old. For example, when Robert Hooke discovered Hooke's law in 1660, he did not want to publish it yet, but wanted to be able to claim priority. So he published the anagram \"ceiiinosssttuv\" and later published the translation \"ut tensio sic vis\" (Latin for \"as is the extension, so is the force\"). Similarly, Galileo first published his discovery of the phases of Venus in the anagram form.\n\nSir Isaac Newton, in responding to questions from Leibniz in a letter in 1677, concealed the details of his \"fluxional technique\" with an anagram:\n\nThere are many timestamping schemes with different security goals:\n\n\nCoverage in standards:\nFor systematic classification and evaluation of timestamping schemes see works by Masashi Une.\n\nAccording to the <nowiki>RFC 3161</nowiki> standard, a trusted timestamp is a timestamp issued by a Trusted Third Party (TTP) acting as a Time Stamping Authority (TSA). It is used to prove the existence of certain data before a certain point (e.g. contracts, research data, medical records, ...) without the possibility that the owner can backdate the timestamps. Multiple TSAs can be used to increase reliability and reduce vulnerability.\n\nThe newer ANSI ASC X9.95 Standard for trusted timestamps augments the <nowiki>RFC 3161</nowiki> standard with data-level security requirements to ensure data integrity against a reliable time source that is provable to any third party. This standard has been applied to authenticating digitally signed data for regulatory compliance, financial transactions, and legal evidence.\n\nThe technique is based on digital signatures and hash functions. First a hash is calculated from the data. A hash is a sort of digital fingerprint of the original data: a string of bits that is practically impossible to duplicate with any other set of data. If the original data is changed then this will result in a completely different hash. This hash is sent to the TSA. The TSA concatenates a timestamp to the hash and calculates the hash of this concatenation. This hash is in turn digitally signed with the private key of the TSA. This signed hash + the timestamp is sent back to the requester of the timestamp who stores these with the original data (see diagram).\n\nSince the original data cannot be calculated from the hash (because the hash function is a one way function), the TSA never gets to see the original data, which allows the use of this method for confidential data.\n\nAnyone trusting the timestamper can then verify that the document was \"not\" created \"after\" the date that the timestamper vouches. It can also no longer be repudiated that the requester of the timestamp was in possession of the original data at the time given by the timestamp. To prove this (see diagram) the hash of the original data is calculated, the timestamp given by the TSA is appended to it and the hash of the result of this concatenation is calculated, call this hash A.\n\nThen the digital signature of the TSA needs to be validated. This can be done by checking that the signed hash provided by the TSA was indeed signed with their private key by digital signature verification. The hash A is compared with the hash B inside the signed TSA message to confirm they are equal, proving that the timestamp and message is unaltered and was issued by the TSA. If not, then either the timestamp was altered or the timestamp was not issued by the TSA.\n\nWith the advent of cryptocurrencies like bitcoin, it has become possible to securely timestamp information in a decentralized and tamper-proof manner. Digital data can be hashed and the hash can be incorporated into a transaction stored in the blockchain, which serves as a secure proof of the exact time at which that data existed. The proof is due to a tremendous amount of computational effort performed after the hash was submitted to the blockchain. Tampering with the timestamp would also lead to breaking the integrity of the entire digital currency, and this would result in the digital currency devaluing to zero.\n\nThe decentralized timestamping approach using the blockchain has also found applications in other areas, such as in dashboard cameras, to secure the integrity of video files at the time of their recording, or to prove priority for creative content and ideas shared on social media platforms.\n\n\n"}
{"id": "2084265", "url": "https://en.wikipedia.org/wiki?curid=2084265", "title": "Unmarked grave", "text": "Unmarked grave\n\nAn unmarked grave is one that lacks a marker, headstone, or nameplate indicating that a body is buried there. However, in cultures that mark burial sites, the phrase unmarked grave has taken on a metaphorical meaning.\n\nAs a figure of speech, a common meaning of the term \"unmarked grave\" is consignment to an ignominious end. A grave monument (or headstone) is a sign of respect or fondness, erected with the intention of commemorating and remembering a person.\n\nConversely, a deliberately unmarked grave may signify disdain and contempt. The underlying intention of some unmarked graves may be to suggest that the person buried is not worthy of commemoration, and should therefore be completely ignored and forgotten, e.g., Seung-Hui Cho, Dylan Klebold, Adam Lanza.\n\nUnmarked graves have long been used to bury executed criminals as an added degree of disgrace. Similarly, many 18th and 19th century prisons and mental asylums historically used numbered (but otherwise featureless) markers in their inmate cemeteries, which allowed for record-keeping and visitations while also minimizing the shame associated with having one's family name on permanent display in such a disreputable context. Plot E at Oise-Aisne American Cemetery (consisting entirely of soldiers executed for rape and/or murder) is a rare example of this policy persisting into the 20th century. More recently, the practice has been to cremate and secretly scatter the ashes of notorious criminals in some anonymous place. This was the fate of Nazi war criminals such as Adolf Eichmann, Hermann Göring, Heinrich Himmler, Fritz Sauckel, and Julius Streicher. The remains of British serial killers Myra Hindley, Dr Harold Shipman, and Fred West were treated in the same way. The headstone of disgraced television presenter and sex offender Jimmy Savile was removed and destroyed three weeks after being erected, when posthumous allegations of sexual abuse over decades came to light. Cremation and secret scattering of the ashes has the additional effect of removing all possibility of there being a grave to visit in the future.\n\nIn Judaism, contact with a corpse confers uncleanness (see Numbers 19:11-22 and Tractate Oholoth in the Mishna). Cohanim, descendants of Aaron, are prohibited from approaching within 4 cubits of a grave, except for when a funeral is of a close relative. Thus, an unmarked grave opens up the possibility that a pious Jew could become defiled without being aware that it happened. The Jews of early times, therefore, sought to avoid unmarked graves by two means: clearly designating cemeteries beyond the limits of their villages and cities, and making graves and tombs obvious by whitewashing them. This is the background for Jesus' comparison of the Pharisees of his time to white-washed tombs (see Matthew 23:27-28) and to \"unmarked graves, which men walk over without knowing it\" (Luke 11:44). Jesus warned that the Pharisees were defiling others by their hypocrisy, misplaced priorities, and selfish ambition.\n\nHowever, disdain and contempt are not the only reasons why graves remain unmarked.\n\nAs Alicia Hoyt reports: \"Historically, financial limitations and social status were factors in whether a person (even a famous one) was awarded a big fancy marker. Mass, unmarked graves were also common in times of widespread disease or war; plus older markers simply deteriorated over time or were stolen. Another reason might be: other gravesites reflect the wishes of the deceased or family members who simply don't want a marker, can't decide on wording, or plan to add one down the line when a loved one passes away and joins them in the plot. [sources: Texas Historical Commission, \"Washington Post\"]\"\n\nAdditionally, \"modern celebrity concerns\" may be related to a desire for privacy or to avoid vandalism. For example, Apple, Inc. founder Steve Jobs (whose grave site lacks a headstone), Academy Award-winning actor George C. Scott, musician Frank Zappa, comedian John Belushi, and writer H. P. Lovecraft (discussed below) are notable people whose burial sites have been left unmarked (or marked deceptively) for reasons that are not financial.\n\nIn cases when a person's remains are lost, a cenotaph may be erected. This is what happened to comedian John Belushi. The gravestone at his grave in a Martha's Vineyard cemetery was removed and relocated, after operators of the cemetery found many signs of vandalism and rowdiness, where his body lies. In response, a cenotaph gravestone was erected at a nearby empty grave, to deter disrespectful visitors, leaving his actual final resting place without a marker. Another John Belushi cenotaph gravestone was erected by his family in a Chicago area cemetery, at the Belushi family plot, where his parents are now buried. Similarly, when H. P. Lovecraft's headstone in Providence, Rhode Island was stolen, a replacement marker was erected in a different location.\n\nDeceased monarchs and princes of Saudi Arabia are buried in unmarked graves in the public Al Oud cemetery in Riyadh. There is also typically no public funeral or national show of mourning. The Wahhabi sect of Sunni Islam practiced in Saudi Arabia considers public shows of grief or memorials to the dead to be un-Islamic, and therefore the royal family typically practices austere, private burials.\n\nNumerous works, such as moving pictures, photographs, and written works, have been titled some variation of \"Unmarked Grave\".\n\n"}
{"id": "827889", "url": "https://en.wikipedia.org/wiki?curid=827889", "title": "White pride", "text": "White pride\n\nWhite pride or White power is an expression primarily used by white separatist, white nationalist, neo-Nazi and white supremacist organizations in order to signal racist or racialist viewpoints. It is also a slogan used by the prominent post-Ku Klux Klan group Stormfront and a term used to make racist/racialist viewpoints more palatable to the general public who may associate historical abuses with the terms \"white nationalist\", \"neo-Nazi\", and \"white supremacist\".\n\nSociologists Betty A. Dobratz and Stephanie L. Shanks-Meile identified \"White Power! White Pride!\" as \"a much-used chant of white separatist movement supporters\", and sociologist Mitch Berbrier has identified the use of this phrase as part of a \"new racist ... frame-transformation and frame-alignment by (a) consciously packaging a 'hate-free' racism, (b) developing strategies of equivalence and reversal–presenting whites as equivalent to ethnic and racial minorities, and (c) deploying ideas about 'love,' 'pride,' and 'heritage-preservation' to evidence both their putative lack of animosity toward others as well as their ethnic credentials.\" In a social psychology experiment that tested how white participants could be influenced to identify with white pride ideology, social psychologists framed white pride as follows:[P]eople who openly express White pride seem invariably to be those alienated from the mainstream culture—KKK members, skin-heads, and White supremacists—people trying to grab onto some basis for feeling good about themselves when conventional avenues such as successful careers and relationships are not working well for them. Consequently, the vast majority of people who avow White pride seem also to explicitly avow racism. Sociologists Monica McDermott and Frank L. Samson documented the rhetorical evolution of white pride movements thus, \"Because white pride has historically been predicated upon a denigration of nonwhites, the articulation of the duties and requirements of whiteness reflects a desire to correlate a conscious white identity with positive attributes.\"\n\nPolitical and social scientists commonly argue that the idea of \"white pride\" is an attempt to provide a clean or more palatable public face for white supremacy or white separatism and that it is an appeal to a larger audience in hopes of inciting more widespread racial violence. According to Joseph T. Roy of the Southern Poverty Law Center, white supremacists often circulate material on the internet and elsewhere that \"portrays the groups not as haters, but as simple white pride civic groups concerned with social ills\". Philosopher David Ingram argues that \"affirming 'black pride' is not equivalent to affirming 'white pride,' since the former—unlike the latter—is a defensive strategy aimed at rectifying a negative stereotype\". By contrast, then, \"affirmations of white pride—however thinly cloaked as affirmations of ethnic pride—serve to mask and perpetuate white privilege\". In the same vein, Professor of Education at University of Illinois at Urbana–Champaign, Cris Mayo, characterizes white pride as \"a politically distasteful goal, given that whiteness is not a personal or community identity, but has been a strategy to maintain inequities of privilege and power.\"\n\nPolitical scientists Carol M. Swain and Russell Nieli, in their text on white nationalism, identify the idea of \"white pride\" as a relatively new phenomenon in the United States. They argue that over the course of the 1990s, \"a new white pride, white protest, and white consciousness movement has developed in America\". They identify three contributing factors: an immigrant influx during the 1980s and 1990s, resentment over affirmative action policies, and the growth of the Internet as a tool for the expression and mobilization of grievances. According to Janet E. Helms, founding director of Boston College's Institute for the Study and Promotion of Race and Culture, a white person \"must become aware of his or her Whiteness, accept it as personally and socially significant ... Not in the sense of Klan members' 'white pride' but in the context of a commitment to a just society.\" Among people who strongly identify as white, research differentiates between a power cognizant group and a prideful group. The prideful group is more likely to devalue diversity and to show prejudice, while the power cognizant group is more likely to value diversity.\n\nThe slogan \"White Pride Worldwide\" appears on the logo of Stormfront, a website owned and operated by Don Black, who was formerly a Grand Wizard of the Ku Klux Klan. The North Georgia White Knights of the Ku Klux Klan describe themselves as \"a patriotic, White Christian revival movement dedicated to preserving the maintenance of White Pride and the rights of the White Race\". A 2002 study identified white pride as a motivation for racial hate crimes on a US college campus, while in a different study on internet racism, the slogan was identified as being part of an emerging transnationalist trend in white supremacist movements. The slogan was also documented to have been used in hate speech incidents at New York University, Vassar College, and Temple University, and it was a slogan used in posters put up by a white supremacist organization at dozens of US colleges. Certain Denver Nuggets jerseys were named \"white pride\" by Adidas and were listed as such on the team's website in 2016, after which internet outcry prompted the team to rename the jerseys. Similarly, a fitness room in River Falls, Wisconsin was renamed to avoid the racist connotations of it being referred to as the \"White Pride Fitness Room\". The slogan was chanted along with \"White Power\" by up to 100 neo-Nazis rallying in Manchester, United Kingdom in March 2015 and was the theme of a March 2016 event in Swansea and a March 2017 event in Edinburgh, all of which were organized by the National Front. In an exposé from \"The Week\", James Poulos warned that \"Europe is on track to rediscover what looks to us like a highly unsettling form of white pride.\"\n\n"}
