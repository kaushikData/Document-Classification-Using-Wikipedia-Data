{"id": "940405", "url": "https://en.wikipedia.org/wiki?curid=940405", "title": "Albert von Kölliker", "text": "Albert von Kölliker\n\nAlbert von Kölliker (born \"Rudolf Albert Kölliker;\" 6 July 18172 November 1905) was a Swiss anatomist, physiologist, and histologist.\n\nAlbert Kölliker was born in Zurich, Switzerland. His early education was carried on in Zurich, and he entered the university there in 1836. After two years, however, he moved to the University of Bonn, and later to that of Berlin, becoming a pupil of noted physiologists Johannes Peter Müller and of Friedrich Gustav Jakob Henle. He graduated in philosophy at Zurich in 1841, and in medicine at Heidelberg in 1842. The first academic post which he held was that of prosector of anatomy under Henle, but his tenure of this office was briefin 1844 he returned to Zurich University to occupy a chair as professor extraordinary of physiology and comparative anatomy. His stay here was also brief; in 1847 the University of Würzburg, attracted by his rising fame, offered him the post of professor of physiology and of microscopical and comparative anatomy. He accepted the appointment, and at Würzburg he remained thenceforth, refusing all offers tempting him to leave the quiet academic life of the Bavarian town, where he died.\n\nAt Zurich, and afterwards at Würzburg, the title of the chair which Kölliker held laid upon him the duty of teaching comparative anatomy. Many of the numerous memoirs which he published, (including the very first paper he wrote) and which appeared in 1841, before he graduated, were on the structure of animals of the most varied kinds. Notable among these were his papers on the \"Medusae\" and allied creatures. His activity in this direction led him to make zoological excursions to the Mediterranean Sea and to the coasts of Scotland, as well as to undertake, conjointly with his friend Carl Theodor Ernst von Siebold, the editorship of the \"Zeitschrift für Wissenschaftliche Zoologie\", which, founded in 1848, continued under his hands to be one of the most important zoological periodicals.\n\nHis hand was one of the first to be x-rayed, by his friend Wilhelm Roentgen.\n\nKölliker made contributions to the study of zoology. His earlier efforts were directed to the invertebrates, and his memoir on the development of cephalopods (which appeared in 1844) is considered a classical work. He soon passed on to the vertebrates, and studied the amphibians and mammalian embryos. He was among the first, if not the very first, to introduce into this branch of biological inquiry the newer microscopic technique – the methods of hardening, sectioning and staining. By doing so, not only was he enabled to make rapid progress himself, but he also placed in the hands of others the means of a similar advancement. The remarkable strides forward which embryology made during the middle and latter half of the 19th century will always be associated with his name. His \"Lectures on Development\", published in 1861, at once became a standard work.\n\nBut neither zoology nor embryology furnished Kölliker's chief claim to fame. If he did much for these branches of science, he did still more for histology, the knowledge of the minute structure of the animal tissues. Among his earlier results was the demonstration in 1847 that smooth or unstriated muscle is made up of distinct units, of nucleated muscle cells. In this work, he followed in the footsteps of his master Henle. A few years before this, there was doubt whether arteries had muscle in their walls – in addition, no solid histological basis as yet existed for those views as to the action of the nervous system on the circulation, which were soon to be put forward, and which had such a great influence on the progress of physiology.\n\nKölliker's contributions to histology were widespread; smooth muscle, striated muscle, skin, bone, teeth, blood vessels and viscera were all investigated by Kölliker, and he touched none of them without discovering new truths. The results at which he arrived were recorded partly in separate memoirs, partly in his great textbook on microscopical anatomy, which first saw the light in 1850, and by which he advanced histology no less than by his own researches.\n\nAlbert L. Lehninger asserted that Kölliker was among the first to notice the arrangement of granules in the sarcoplasm of striated muscle over a period of years beginning around 1850. These granules were later called sarcosomes by Retzius in 1890. These sarcosomes have come to be known as the mitochondria-the power houses of the cell. In the words of Lehninger, \"Kölliker should also be credited with the first separation of mitochondria from cell structure. In 1888 he teased these granules from insect muscle, in which they are very profuse, found them to swell in water, and showed them to possess a membrane.\"\n\nIn the case of almost every tissue, our present knowledge contains information first discovered by Kölliker – it is for his work on the nervous system that his name is most remembered. As early as 1845, while still at Zurich, he supplied the clear proof that nerve fibers are continuous with nerve cells, and so furnished the absolutely necessary basis for all sound speculations as to the actions of the central nervous system.\n\nFrom that time onward he continually laboured at the histology of the nervous system, and more especially at the difficult problems presented by the intricate patterns in which nerve fibers and neurons are woven together in the brain and spinal cord. From his early days a master of method, he saw at a glance the value of the new Golgi staining method for the investigation of the central nervous system, and, to the great benefit of science, took up once more in his old age, with the aid of a new means, the studies for which he had done so much in his youth. Kölliker contributed greatly to knowledge of the inner structure of the brain.\n\nKölliker was ennobled by Prince Regent Luitpold of Bavaria in 1897 and thus permitted to add the predicate \"von\" to his surname. He was made a member of the learned societies of many countries; in England, which he visited more than once, and where he became well known, the Royal Society made him a fellow in 1860, and in 1897 gave him its highest token of esteem, the Copley medal.\n\nA species of lizard, \"Hyalosaurus koellikeri\", is named in his honor.\n\nIn 1864 Kölliker revived Étienne Geoffroy Saint-Hilaire's theory that evolution proceeds by large steps (saltationism), under the name of heterogenesis. Kölliker was a critic of Darwinism and rejected a universal common ancestor, instead he supported a theory of common descent along separate lines. According to Alexander Vucinich the non-Darwinian evolution theory of Kölliker tied \"organic transformism to three general ideas, all contrary to Darwin's view: the multiple origin of living forms, the internal causes of variation, and \"sudden leaps\" (heterogenesis) in the evolutionary process.\"\nKölliker claimed that heterogenesis functioned according to a general law of evolutionary progress, orthogenesis.\n\n"}
{"id": "1986782", "url": "https://en.wikipedia.org/wiki?curid=1986782", "title": "Attractive nuisance doctrine", "text": "Attractive nuisance doctrine\n\nThe attractive nuisance doctrine applies to the law of torts, in the United States. It states that a landowner may be held liable for injuries to children trespassing on the land if the injury is caused by an object on the land that is likely to attract children. The doctrine is designed to protect children who are unable to appreciate the risk posed by the object, by imposing a liability on the landowner. The doctrine has been applied to hold landowners liable for injuries caused by abandoned cars, piles of lumber or sand, trampolines, and swimming pools. However, it can be applied to virtually anything on the property of the landowner.\n\nThere is no set cut off point that defines youth. The courts will evaluate each \"child\" on case by case basis to see if the \"child\" qualifies as a youth.\n\nIf it is determined that the child was able to understand and appreciate the hazard, the doctrine of attractive nuisance will not likely apply.\n\nUnder the old common law, the plaintiff (either the child, or a parent suing on the child's behalf) had to show that it was the hazardous condition itself which lured the child onto the landowner's property. However, most jurisdictions have statutorily altered this condition, and now require only that the injury was foreseeable by the landowner.\n\nAccording to the Restatement of Torts standard, which is followed in many jurisdictions, there are five conditions that must be met for a land owner to be liable for tort damages to a child trespasser as a result of artificial hazards. \n\n\nStates that use the Restatement test include:\n\n"}
{"id": "3793977", "url": "https://en.wikipedia.org/wiki?curid=3793977", "title": "Chöd", "text": "Chöd\n\nChöd ( lit. 'to sever'), is a spiritual practice found primarily in the Nyingma and Kagyu schools of Tibetan Buddhism (where it is classed as Anuttarayoga Tantra). Also known as \"Cutting Through the Ego,\", the practices are based on the Prajñāpāramitā or \"Perfection of Wisdom\" sutras, which expound the \"emptiness\" concept of Buddhist philosophy.\n\nAccording to Mahayana Buddhists, emptiness is the ultimate wisdom of understanding that all things lack inherent existence. Chöd combines prajñāpāramitā philosophy with specific meditation methods and tantric ritual. The chod practitioner seeks to tap the power of fear through activities such as rituals set in graveyards, and visualisation of offering their bodies in a tantric feast in order to put their understanding of emptiness to the ultimate test.\n\n and Sanskrit \"chedasādhanā\" both literally mean \"cutting practice\".\n\nIn Standard Tibetan (the prestige dialect associated with Buddhism that is based on the speech of Lhasa), the pronunciation of \"gcod\" is IPA //.\n\nChöd literally means \"cutting through\". It cuts through hindrances and obscurations, sometimes called 'demons' or 'gods'. Examples of demons are ignorance, anger and, in particular, the dualism of perceiving the self as inherently meaningful, contrary to the Buddhist doctrine of no-self. The practitioner is fully immersed in the ritual: \"With a stunning array of visualizations, song, music, and prayer, it engages every aspect of one’s being and effects a powerful transformation of the interior landscape.\"\n\nDzogchen forms of Chöd enable the practitioner to maintain primordial awareness free from fear. Here, the Chöd ritual essentialises elements of phowa, gaṇacakra, pāramitā and lojong pure illusory body, mandala, brahmavihāra, ösel and tonglen.\n\nChöd usually commences with phowa, in which the practitioner visualises their mindstream as the Five Pure Lights leaving the body through the aperture of the sahasrara at the top of the head. This is said to ensure psychic integrity of, and compassion for the sādhaka or practitioner. In most versions of the sādhanā, the mindstream precipitates into a tulpa simulacrum of Vajrayoginī. In sambhogakāya attained through visualization, the sādhaka offers a gaṇachakra of their own physical body to the \"four\" guests: the Three Jewels, dakinis, dharmapalas and beings of the bhavachakra, the ever-present lokapala and the pretas. The rite may be protracted with separate offerings to each maṇḍala of guests, or significantly abridged. Many versions of the chod sādhana' still exist.\n\nThe chöd sadhana generally includes music, song and also a dance.\n\nChöd, like all tantric systems, has outer, inner and secret aspects. They are described in an evocation sung to Nyama Paldabum by Milarepa:\n\nChöd is now a staple of the advanced \"sādhana\" of Tibetan Buddhism. It is practiced worldwide following dissemination by the Tibetan diaspora.\n\nVajrayogini is a key figure in the advanced practice of Chöd, where she appears in her Kālikā () or Vajravārāhī () forms. The practices of Tröma Nagmo \"Extremely Wrathful Black Mother\" associated with the Dakini Tröma Nagmo (the black form of Vajrayogini) were also propagated by Machig Labdrön. \"The particular transmission which His Holiness will give descends from Dudjom Lingpa, who received it in a direct vision of the Indian Mahasiddha, Saraha. This practice emphasizes cutting through grasping at the dualistic mind to realize complete selfless compassion. One of the forms of this style of Chöd can be found in the Dudjom Tersar lineage.\n\n\"Chöd was never a unique, monolithic tradition. One should really speak of Chöd traditions and lineages since Chöd has never constituted a school.\"\n\nA form of Chöd was practiced in India by Buddhist mahāsiddhas prior to the 10th century. The two practices of Chöd in Buddhism and in Bön are distinct lineages.\n\nThere are two main Chöd traditions within Buddhism, the \"Mother\" and \"Father\" lineages. Dampa Sangye is known as the \"Father of Chöd\" and Machig Labdrön, founder of the Mahamudra Chöd lineages, as the \"Mother of Chöd\".\n\nBön traces the origin of Chöd to the \"Secret Mother Tantra\", the seventh of the Nine Vehicles of Bön practice. There are four distinct styles of Chöd practice.\n\nChöd developed outside the monastic system. It was subsequently adopted by the monastic lineages. As an internalization of an outer ritual, Chöd involves a form of self-sacrifice: the practitioner visualizes their own body as the offering at a ganachakra. The purpose of the practice is to engender a sense of victory and fearlessness. These two qualities are represented iconographically by the victory banner and the ritual knife. The banner symbolizes overcoming obstacles and the knife symbolizes cutting through the ego. The practitioner may cultivate imaginary fearful or painful situations since they help the practitioner's work of cutting through attachment to the self. Machig Labdrön said, \"To consider adversity as a friend is the instruction of Chöd\".\n\nSarat Chandra Das, writing at the turn of the 20th Century, equated the Chöd practitioner () with the Indian \"avadhūta\", or \"mad saint\". \"Avadhūtas\" - called nyönpa in Tibetan Buddhism - are renowned for expressing their spiritual understanding through \"crazy wisdom\" inexplicable to ordinary people. Chöd practitioners are a type of Mad Saint particularly respected, feared or held in awe due to their roles as denizens of the charnel ground. According to tibetologist Jérôme Édou, Chod practitioners were often associated with the role of shaman and exorcist:\nIn Chöd, the adept symbolically offers the flesh of their body in a form of gaṇacakra or tantric feast. Iconographically, the skin of the practitioner's body may represent surface reality or \"maya\". It is cut from bones that represent the true reality of the mindstream. Commentators have pointed out the similarities between the Chöd ritual and the prototypical initiation of a shaman, although one writer identifies an essential difference between the two in that the shaman's initiation is involuntary whilst a Chodpa chooses to undertake the ritual death of a Chod ceremony. Traditionally, Chöd is regarded as challenging, potentially dangerous and inappropriate for some practitioners.\n\nPractitioners of the Chöd ritual, \"Chödpa,\" use a kangling or human thighbone trumpet, and a Chöd drum, a hand drum similar to but larger than the ḍamaru commonly used in Tibetan ritual. In a version of the Chöd sādhanā of Jigme Lingpa from the \"Longchen Nyingthig\", five ritual knives are employed to demarcate the maṇḍala of the offering and to affix the five wisdoms.\n\nKey to the iconography of Chöd is the (), a half-moon blade knife for skinning an animal and for scraping hides. The practitioner symbolically uses a kartika to separate the bodymind from the mindstream in ritual.\n\nKartika imagery in Chöd rituals provides the practitioner with an opportunity to realize Buddhist doctrine:\n\nSome sources have described Machig Labdrön as the founder of the practice of Chöd. This is accurate in that she is the founder of the Tibetan Buddhist Mahamudrā Chöd lineages. Machig Labdrön is credited with providing the name \"Chöd\" and developing unique approaches to the practice. Biographies suggest it was transmitted to her via sources of the mahāsiddha and tantric traditions. She did not found the Dzogchen lineages, although they do recognize her, and she does not appear at all in the Bön Chöd lineages. Among the formative influences on Mahamudrā Chöd was Dampa Sangye's \"Pacification of Suffering\" ().\n\nThere are several hagiographic accounts of how Chöd came to Tibet. One namtar (spiritual biography) asserts that shortly after Kamalaśīla won his famous debate with Moheyan as to whether Tibet should adopt the \"sudden\" route to enlightenment or his \"gradual\" route, Kamalaśīla used the technique of phowa to transfer his mindstream to animate a corpse polluted with contagion in order to safely move the hazard it presented. As the mindstream of Kamalaśīla was otherwise engaged, a mahasiddha by the name of Dampa Sangye came across the vacant \"physical basis\" of Kamalaśīla. Padampa Sangye, was not karmically blessed with an aesthetic corporeal form, and upon finding the very handsome and healthy empty body of Kamalaśīla, which he assumed to be a newly dead fresh corpse, used phowa to transfer his own mindstream into Kamalaśīla's body. Padampa Sangye's mindstream in Kamalaśīla's body continued the ascent to the Himalaya and thereby transmitted the Pacification of Suffering teachings and the Indian form of Chöd which contributed to the Mahamudra Chöd of Machig Labdrön. The mindstream of Kamalaśīla was unable to return to his own body and so was forced to enter the vacant body of Padampa Sangye.\n\nChöd was a marginal and peripheral practice, and the Chödpas who engaged in it were from outside traditional Tibetan Buddhist and Indian monastic institutions, with a contraindication against all but the most advanced practitioners to go to the charnel grounds to practice. Texts concerning Chöd were both exclusive and rare in the early tradition school. Indeed, due to the itinerant and nomadic lifestyles of practitioners, they could carry few texts. Hence they were also known as \"kusulu\" or \"kusulupa\", that is, studying texts rarely whilst focusing on meditation and praxis: \"The nonconventional attitude of living on the fringe of society kept the Chödpas aloof from the wealthy monastic institutions and printing houses. As a result, the original Chöd texts and commentaries, often copied by hand, never enjoyed any wide circulation, and many have been lost forever.\"\n\nRangjung Dorje, 3rd Karmapa Lama, (1284–1339) was an important systematizer of Chöd teachings and significantly assisted in their promulgation within the literary and practice lineages of the Kagyu, Nyingma, and particularly Dzogchen. It is in this transition from the charnel grounds to the monastic institutions of Tibetan Buddhism that the rite of Chöd became an inner practice; the charnel ground became an internal imaginal environment. Schaeffer conveys that the Third Karmapa was a systematizer of the Chöd developed by Machig Labdrön and lists a number of his works in Tibetan on Chöd. Amongst others, the works include redactions, outlines and commentaries.\n\nChöd was mostly practised outside the Tibetan monastery system by chödpas, who were \"yogis\", \"yogiṇīs\" and \"ngagpas\" rather than \"bhikṣus\" and \"bhikṣuṇīs\". Because of this, material on Chöd has been less widely available to Western readers than some other tantric Buddhist practices. The first Western reports of Chöd came from a French adventurer who lived in Tibet, Alexandra David-Néel in her travelogue \"Magic and Mystery in Tibet,\" published in 1932. Walter Evans-Wentz published the first translation of a Chöd liturgy in his 1935 book \"Tibetan Yoga and Secret Doctrines\". Anila Rinchen Palmo translated several essays about Chöd in the 1987 collection \"Cutting Through Ego-Clinging: Commentary on the practice of Tchod\". Since then, Chöd has emerged more into the mainstream of both western scholarly and academic writings.\n\n\n\n"}
{"id": "55248218", "url": "https://en.wikipedia.org/wiki?curid=55248218", "title": "Conservation of resources theory", "text": "Conservation of resources theory\n\nConservation of Resources (COR) Theory is a stress theory that describes the motivation that drives humans to both maintain their current resources and to pursue new resources. This theory was proposed by Dr. Stevan E. Hobfoll in 1989 as a way to expand on the literature of stress as a construct. \n\nHobfoll posited that psychological stress occurred in three instances; when there was a threat of a loss of resources, an actual net loss of resources, and a lack of gained resources following the spending of resources. From this perspective, resources are defined as things that one values, specifically objects, states, and conditions. COR states that loss of these types of resources will drive individuals into certain levels of stress. \n\nCOR was developed from various theories on the cause of stress. COR development branches back to Walter Bradford Cannon (1932) who was one of the first researchers to study the concept of stress as it applies to humans, specifically in how stress can be withstood. Hans Selye (1950) took on Cannon’s research on stress as a response and indicated that stress itself was designed as a way to protect the body from environmental challenges. \n\nOther researchers such as Elliot and Eisdorfer (1982) defined stress as specifically being the stimulus and not the response, which had been accepted by some of the scientific community. However, this theory is largely based on the homeostatic model of stress developed by Joseph McGrath (1970). It is in this theory that stress is defined as an imbalance between the environmental demand and the response capability of an organism. \n\nCOR covers two basic principles involving the protection of resources from being lost. The first principle is called the Primacy of Resource Loss. This principles states that it is more harmful for individuals to lose resources compared to when there is a gain of resources. What this means, is that a loss of pay will be more harmful than the same gain in pay would have been helpful. \n\nThe second principle is known as Resource Investment. This principle of COR states that people will tend to invest resources in order to protect against resource loss, to recover from losses, and to gain resources. Within the context of coping, people will invest resources to prevent future resource losses. \n\nFrom these two principles, COR has suggested a number of corollaries that can be applied to resource changes. They are as follows:\n\n\nCOR has been utilized when studying work/family stress, burnout, and general stress. In work/family stress, COR research has looked at how the distribution of one’s resources have affected their home life, with some articles finding that putting too much of one’s resources into one’s work may lead to family problems at home. Research into COR and burnout has examined how the use of resources has impacted one’s mood, with recent research finding that emotional exhaustion had the strongest relationship with depressive symptoms. \n\nIn regards to general stress, research has explored how the loss of resources impacts the levels of one’s stress. It should be noted that COR has primarily been studied within the burnout and job fields, as the following meta-analyses will demonstrate. There is currently no meta-analyses on COR within other areas of stress research. \n\nMultiple meta-analyses have been conducted with COR, specifically related to burnout. One meta-analyses by Lee and Ashforth (1996) examined the relationship between demand and resource correlates, behavioral and attitudinal correlate, and 3 different dimensions of job burnout. It used COR as the basis for this research and found that the primacy of resource loss principle is supported. It found that, over 58 sources, individuals tend to be sensitive to increased demands rather than resources received. \n\nJob control and COR have been studied through a meta-analyses conducted by Park, Baiden, Jacob, & Wagner (2009). This study tested COR using all constructs involved in job control and burnout which included constructs of autonomy, authority, skill discretion, and decision latitude. Results indicate that the construct of job control, or the ability that one has to choose their actions from multiple options at their job, is related to depersonalization and personal accomplishment. This study stated that COR is related to burnout in this way, but further studies should be conducted that use non-human service occupations. \n"}
{"id": "20646034", "url": "https://en.wikipedia.org/wiki?curid=20646034", "title": "Continuum (measurement)", "text": "Continuum (measurement)\n\nContinuum theories or models explain variation as involving gradual quantitative transitions without abrupt changes or discontinuities. In contrast, categorical theories or models explain variation using qualitatively different states.\n\nIn physics, for example, the space-time continuum model describes space and time as part of the same continuum rather than as separate entities. A spectrum in physics, such as the electromagnetic spectrum, is often termed as either continuous (with energy at all wavelengths) or discrete (energy at only certain wavelengths).\n\nIn contrast, quantum mechanics uses quanta, certain defined amounts (i.e. categorical amounts) which are distinguished from continuous amounts.\n\nA good introduction to the philosophical issues involved is John Lane Bell's essay in the \"Stanford Encyclopedia of Philosophy\". A significant divide is provided by the law of excluded middle. It determines the divide between intuitionistic continua such as Brouwer's and Lawvere's, and classical ones such as Stevin's and Robinson's. \nBell isolates two distinct historical conceptions of infinitesimal, one by Leibniz and one by Nieuwentijdt, and argues that Leibniz's conception was implemented in Robinson's hyperreal continuum, whereas Nieuwentijdt's, in Lawvere's smooth infinitesimal analysis, characterized by the presence of nilsquare infinitesimals: \"It may be said that Leibniz recognized the need for the first, but not the second type of infinitesimal and Nieuwentijdt, vice versa. It is of interest to note that Leibnizian infinitesimals (differentials) are realized in nonstandard analysis, and nilsquare infinitesimals in smooth infinitesimal analysis\".\n\nIn social sciences in general, psychology and psychiatry included, data about differences between individuals, like any data, can be collected and measured using different levels of measurement. Those levels include dichotomous (a person either has a personality trait or not) and non-dichotomous approaches. While the non-dichotomous approach allows for understanding that everyone lies somewhere on a particular personality dimension, the dichotomous (nominal categorical and ordinal) approaches only seek to confirm that a particular person either has or does not have a particular mental disorder.\n\nExpert witnesses particularly are trained to help courts in translating the data into the legal (e.g. 'guilty' vs. 'innocent') dichotomy, which apply to law, sociology and ethics.\n\nIn linguistics, the range of dialects spoken over a geographical area that differ slightly between neighboring areas is known as a dialect continuum. A language continuum is a similar description for the merging of neighboring languages without a clear defined boundary. Examples of dialect or language continuums include the varieties of Italian or German; and the Romance languages, Arabic languages, or Bantu languages.\n\n"}
{"id": "322355", "url": "https://en.wikipedia.org/wiki?curid=322355", "title": "Deep time", "text": "Deep time\n\nDeep time is the concept of geologic time. The modern philosophical concept was developed in the 18th century by Scottish geologist James Hutton (1726–1797). The age of the Earth has been determined to be, after a long and complex history of developments, around 4.55 billion years.\n\nHutton based his view of deep time on a form of geochemistry that had developed in Scotland and Scandinavia from the 1750s onward. As mathematician John Playfair, one of Hutton's friends and colleagues in the Scottish Enlightenment, remarked upon seeing the strata of the angular unconformity at Siccar Point with Hutton and James Hall in June 1788, \"the mind seemed to grow giddy by looking so far into the abyss of time\".\n\nEarly geologists such as Nicolas Steno (1638-1686) and Horace-Bénédict de Saussure (1740-1799) had developed ideas of geological strata forming from water through chemical processes, which Abraham Gottlob Werner (1749–1817) developed into a theory known as Neptunism, envisaging the slow crystallisation of minerals in the ancient oceans of the Earth to form rock. Hutton's innovative 1785 theory, based on Plutonism, visualised an endless cyclical process of rocks forming under the sea, being uplifted and tilted, then eroded to form new strata under the sea. In 1788 the sight of Hutton's Unconformity at Siccar Point convinced Playfair and Hall of this extremely slow cycle, and in that same year Hutton memorably wrote \"we find no vestige of a beginning, no prospect of an end\".\n\nOther scientists such as Georges Cuvier (1769-1832) put forward ideas of past ages, and geologists such as Adam Sedgwick (1785-1873) incorporated Werner's ideas into concepts of catastrophism; Sedgwick inspired his university student Charles Darwin to exclaim \"What a capital hand is Sedgewick [sic] for drawing large cheques upon the Bank of Time!\". In a competing theory, Charles Lyell in his \"Principles of Geology\" (1830–1833) developed Hutton's comprehension of endless deep time as a crucial scientific concept into uniformitarianism. As a young naturalist and geological theorist, Darwin studied the successive volumes of Lyell's book exhaustively during the \"Beagle\" survey voyage in the 1830s, before beginning to theorise about evolution.\n\nPhysicist Gregory Benford addresses the concept in \"Deep Time: How Humanity Communicates Across Millennia\" (1999), as does paleontologist and \"Nature\" editor Henry Gee in \"In Search of Deep Time: Beyond the Fossil Record to a New History of Life\" (2001) Stephen Jay Gould's \"Time's Arrow, Time's Cycle\" (1987) also deals in large part with the evolution of the concept.\n\nJohn McPhee discussed \"deep time\" at length with the layperson in mind in \"Basin and Range\" (1981), parts of which originally appeared in the \"New Yorker\" magazine. In \"Time's Arrow, Time's Cycle\", Gould cited one of the metaphors McPhee used in explaining the concept of deep time:\nConsider the Earth's history as the old measure of the English yard, the distance from the King's nose to the tip of his outstretched hand. One stroke of a nail file on his middle finger erases human history.\nConcepts similar to geologic time were recognized in the 11th century by the Persian geologist and polymath Avicenna (Ibn Sina, 973–1037), and by the Chinese naturalist and polymath Shen Kuo (1031–1095).\n\nThe Roman Catholic theologian Thomas Berry (1914–2009) explored spiritual implications of the concept of deep time. Berry proposes that a deep understanding of the history and functioning of the evolving universe is a necessary inspiration and guide for our own effective functioning as individuals and as a species. This view has greatly influenced the development of deep ecology and ecophilosophy. The experiential nature of the experience of deep time has also greatly influenced the work of Joanna Macy and John Seed.\n\nH.G. Wells and Julian Huxley regarded the difficulties of coping with the concept of deep time as exaggerated:\n\"The use of different scales is simply a matter of practice\", they said in \"The Science of Life\" (1929). \"We very soon get used to maps, though they are constructed on scales down to a hundred-millionth of natural size. . .  to grasp geological time all that is needed is to stick tight to some magnitude which shall be the unit on the new and magnified scale—a million years is probably the most convenient—to grasp its meaning once and for all by an effort of imagination, and then to think of all passage of geological time in terms of this unit.\"\n\n\n"}
{"id": "45521178", "url": "https://en.wikipedia.org/wiki?curid=45521178", "title": "Divya-drishti", "text": "Divya-drishti\n\nIn the Bhagavad Gita, Krishna tells Arjuna:-\n\nKrishna invited Arjuna to observe the Cosmic Body or Viraj) and behold as concentrated within that body (in the person of Krishna) the entire creation and all that is desired to be seen. When Arjuna failed to see that divine form, Krishna bestowed the gift of divine vision – दिव्यं चक्षुः. Thus endowed, Arjuna saw an undisguised reality he could otherwise not see, what he then saw was अद्भुतदर्शनम् (many a wonderful sight) divine in essence, transcendent and all-effulgent, the sight which has never been seen before. Arjuna saw the power of creating diversity in the universe. A similar gift had been bestowed on Sanjaya by Sage Vyasa. \n\nThe Vedic seers have spoken about the wondrous eyes of Lord Vishnu, the ever-open watchful divine eyes whose power of sight is not restricted by space and time. Rishi Medhātithih Kānvah states that:-\n"}
{"id": "1212755", "url": "https://en.wikipedia.org/wiki?curid=1212755", "title": "Edward Goldsmith", "text": "Edward Goldsmith\n\nEdward René David Goldsmith (8 November 1928 – 21 August 2009), widely known as Teddy Goldsmith, was an Anglo-French environmentalist, writer and philosopher.\n\nHe was a member the prominent Goldsmith family. The eldest son of Major Frank Goldsmith, and elder brother of the financier James Goldsmith. Edward Goldsmith was the founding editor and publisher of \"The Ecologist\". Known for his outspoken views opposing industrial society and economic development, he expressed a strong sympathy for the ways and values of traditional peoples.\n\nHe co-authored the influential \"A Blueprint for Survival\" with Robert Allen, becoming a founding member of the political party \"People\" (later renamed the Green Party), itself largely inspired by the\" Blueprint\". Goldsmith's conservative view of environmentalism put him at odds with the socialist currents of thought, which came to dominate the Green Party.\n\nA deep ecologist and systems theorist, Goldsmith was an early proponent of the Gaia hypothesis, having previously developed a similar cybernetic concept of a self-regulating biosphere.\n\nA talented after-dinner speaker and raconteur, Goldsmith was an articulate spokesman and campaigner, receiving a number of awards for his work protecting the natural world and highlighting the importance and plight of indigenous peoples, including an honorary Right Livelihood Award and the Chevalier de la Legion d'Honneur.\n\nGoldsmith (widely known as Teddy) was born in Paris in 1928 to a German Jewish father, Frank Goldsmith, and French mother, Marcelle Mouiller.\n\nHe entered Millfield School, Somerset, as a grammar student, and he later graduated with honours in Philosophy, Politics, and Economics at Magdalen College, Oxford (1947–1950). While studying at Oxford, Goldsmith rejected the reductionist and compartmentalised ideas taught at the time, and he sought a more holistic worldview with which to study societies and the problems facing the world at large.\n\nAfter fulfilling his National Service as a British Intelligence Officer in Hamburg and Berlin, he involved himself unsuccessfully in a number of business ventures and devoted most of his spare time to the study of the subjects that were to preoccupy him for the rest of his life.\n\nThroughout the 1960s, he spent time travelling the world with his close friend, John Aspinall, witnessing at first hand the destruction of traditional societies. He concluded that the spread of economic development and its accompanying industrialisation, far from being progressive as claimed, was actually the root cause of social and environmental destruction.\n\nIn London, at meetings of the Primitive People's Fund (the committee that founded Survival International), Goldsmith teamed up with the fund's treasurer Robert Prescott-Allen, the explorer Jean Liedloff, and a writer from \"World Medicine\", Peter Bunyard, to found \"The Ecologist\" in 1969.\n\nAfter rejecting what he saw as the excessively reductionist and compartmentalised approach of mainstream academia, he spent much of his time researching and developing his own theories for the unification of the sciences. The \"Theory of a Unified Science\" was heavily influenced by cybernetics, as well as the General Systems Theory of Ludwig von Bertalanffy, the holism of the early academic ecologists, and the functionalism employed by many anthropologists. His theory would later be published, in its final form, as \"The Way: an ecological world view.\" (see below)\n\nEarly on, Goldsmith had formulated a concept of the biosphere as an integrated cybernetic entity, the self-regulating parts (of which he included tribal societies) co-operating, largely unconsciously, for the mutual benefit of the whole, a view that anticipated aspects of the Gaia thesis, of which he was to become a leading proponent.\n\nGoldsmith was also a critic of neo-Darwinism. He claimed that it is a reductionist theory and that if you understand evolution, it is necessary to \"abandon the reductionistic and mechanistic paradigm of science\".\n\nHaving established \"The Ecologist\" in 1969 with founding editors Robert Allen, Jean Liedloff, and Peter Bunyard, Goldsmith was to use the journal as a platform for his theoretical concerns with regular articles appearing under the heading \"Towards a Unified Science\". The journal also became an important forum for the early green movement, with articles focusing on the relevance and survival of hunter-gatherer societies, alternative technology and organic farming, together with prescient articles about climate change, resource depletion, and nuclear accidents. They were accompanied by the usual gamut of articles examining pollution, overpopulation, deforestation, soil erosion, corporate power, large dams, and, not least, the World Bank's alleged role in \"financing the destruction of our planet\".\n\nSigned by over thirty of the leading scientists of the day—l, including Sir Julian Huxley, Sir Frank Fraser Darling, Sir Peter Medawar, Sir Peter Scott, and C. H. Waddington, Goldsmith and his fellow editor Robert Allen made headlines in January 1972 with \"A Blueprint for Survival\".\n\nThe \"Blueprint\" was a far reaching proposal for a radical transition to a largely decentralised and deindustrialised society, an attempt to prevent what the authors referred to as \" the breakdown of society and the irreversible disruption of the life-support systems on this planet\". It became a key text for the early Green movement, selling over half a million copies, and it was translated into 16 different languages. In many ways, it anticipated the concerns taken up by today's Transition Movement.\n\nGoldsmith and Allen argued that rather than devise imaginary utopias, as did Marxist and liberal political theorists of the time, they should instead look to the example of existing tribal peoples, who, the authors claimed, were real-life working models of societies perfectly adapted to both their long-term survival needs and the needs of the living world on which they depended. The tribal peoples alone, the authors argued, had demonstrated a viable means by which the most pressing problems facing humanity could be answered successfully.\n\nSuch societies were characterised by their small, human-scale communities, low-impact technologies, successful population controls, sustainable resource management, holistic and ecologically integrated worldviews and a high degree of social cohesion, physical health, psychological well-being and spiritual fulfilment of their members.\n\nThe \"Blueprint\" was a major inspiration for the embryonic political party called \"People\" (later to become the Green Party,) which invited Goldsmith to stand for the Eye constituency in Suffolk as their candidate in the February 1974 general election.\n\nThe campaign focused on the threat of desertification from the intensive farming practised in the area, which Goldsmith emphasised with the help of a Bactrian camel supplied by Aspinall. Goldsmith was in turn accompanied by bearded supporters dressed in the garb of Arab sheiks, the implication being that if modern oil-intensive farming practises were allowed to continue, the camel would be the only viable means of transport left in Suffolk. Goldsmith lost his deposit, but his unorthodox campaign succeeded in attracting the media's attention and highlighted the issues. He again stood for the now-renamed Ecology Party at the European elections in 1979, now winning a more respectable portion of the vote.\n\nIn 1973, buoyed by the success of the \"Blueprint\" and a sudden rise in public awareness of ecological issues, partly brought about by the Stockholm Conference and the publication of the Club of Rome's \"The Limits to Growth\" in the same year. Goldsmith and his editorial team moved from their offices in London to relocate to rural Cornwall, in the far west of England. Goldsmith and his colleagues bought themselves farms, and for the following 17 years, they attempted to form a small-scale, relatively self-sufficient community of their own, and \"The Ecologist\" continued to be produced on-site, in between their other chores.\n\nIn 1977, when the Central Electricity Generating Board (CEGB) threatened to site a nuclear reactor on farmland in Luxulyan, Cornwall, Goldsmith was among those who organised a continuous sit-in of the land, with local people blocking the entrance and staffing round-the-clock garrisons to prevent CEGB contractors from starting their drilling work. An early example of an environmental protest camp, the High Court of England and Wales eventually awarded in favour of CEGB allowing the drilling to go ahead. The CEGB never went on to develop the site, however.\n\nIn 1974, Goldsmith spent four months with the Gandhi Peace Foundation in New Delhi, comparing the Gandhian (\"Sarvodaya\") movement with the Ecology movement in Europe. This led Goldsmith to forge close links with Indian environmental activists, in particular with the Chipko movement, including Sunderlal Bahuguna and Vandana Shiva. That was to have a major influence on Goldsmith's approach to environmental activism and led to a special issue of \"The Ecologist\" on the subject.\n\nIn 1984, together with his colleague Nicholas Hildyard, Goldsmith authored a multi-volume report on the destructive effects of large-scale, hydroelectric dams. It was the beginning of a long attack against the International Monetary Fund and World Bank, which Goldsmith and his colleagues accused of financing the destruction of the planet.\n\nIn one episode, Goldsmith wrote an open letter to the then President of the World Bank, Alden W. Clausen, demanding that the bank \"stop financing the destruction of the tropical world, the devastation of its remaining forests, the extermination of its wildlife and the impoverishment and starvation of its human inhabitants\". At the time, the connection between large-scale development projects and social and environmental destruction had not been widely recognised, even within the environmental movement.\n\nIn 1989, Goldsmith helped to organise an international campaign calling for an immediate end to the destruction of the world's remaining forests with its detrimental effects on indigenous cultures, biodiversity and global climate. The campaign raised over 3 million signatures, which were taken in wheelbarrows to the UN's headquarters in New York City. Goldsmith and a party of activists subsequently occupied the main lobby, refusing to move until the Secretary General, Perez de Cuellar, agreed to see them. The group demanded for him to call an extraordinary general meeting of the Security Council to tackle the global crisis of deforestation. Although failing, the campaign managed to organise a meeting in the US Senate with a group of senators, headed by Al Gore, whom the activists called upon to end their support of the World Bank.\n\nIn 1991, with the financial support of his brother James, Goldsmith established the Goldsmith (JMG) Foundation supporting a diverse range of non-governmental organisations campaigning against environmentally destructive activities, along with organisations providing sustainable alternatives.\n\nIn 1990, urged on by Arne Næss, Goldsmith left the editorship of \"The Ecologist\" to Nicholas Hildyard, while taking time off to write his philosophical magnum opus \"The Way: an ecological worldview\". \"The Way\" (1992) was the culmination and synthesis of more than four decades of theoretical development, embodying a \"coherent worldview\" by which Goldsmith would attempt to explain the self-inflicted problems facing the world and to propose a way out of them. Much of the work was already mature in Goldsmith's mind by the time that he published the first issues of \"The Ecologist\" in 1970.\n\nIn addition to the UK \"Ecologist\", Goldsmith later helped to found and support \"The Ecologist\" as independent enterprises in many parts of the world:\n\nHe continued to attend key meetings around the world and involved himself with a variety of campaign organisations by becoming President of the \"Climate Initiatives Fund\", Richmond, London; a board member of the \"International Forum on Globalization\", San Francisco, USA; a founder member of \"Marunui Conservation Ltd.\", Mangawhai, New Zealand (1987); and a founder member and vice-president of ECOROPA, a European ecological club and think tank (1975).\n\n\nIn 1997, after an acrimonious split with his editorial team, most notably with his former friend and colleague Nicholas Hildyard, Goldsmith was left to run \"The Ecologist\" on his own. Having been absent for some years, he brought in the International Society for Ecology and Culture (ISEC) to act as the editorial team. His nephew Zac, who was then working for ISEC, eventually took over the editorship on their behalf.\n\nThe split with Hildyard led to a period of often-bitter criticism from some members of the political left in the environmental movement, which, compounded with failing health, resulted in a period of isolation from the British scene.\n\nGoldsmith was accused of having affiliated himself with the Nouvelle Droite, an intellectual voice of the European \"New Right\", after addressing a symposium on Green issues organised in Paris by the GRECE (Research and Study Group on European Culture), a school of political thought founded largely on the works of Alain de Benoist. It was the attending of that and another similar event that had led to rising tensions with his colleague Nicholas Hildyard. The title of Goldsmith's contribution in Paris being simply \"Une société écologique: la seule alternative\" (\"An Ecological Society: The Only Alternative\").\n\nLater, in a controversial article for the \"Guardian\" newspaper, entitled \"Black Shirts in Green Trousers\", George Monbiot (a cofounder of the left-wing political party Respect) accused Goldsmith of having \"advocated the enforced separation of Tutsis and Hutus in Rwanda and Protestants and Catholics in Ulster, on the grounds that they constitute 'distinct ethnic groups' and are thus culturally incapable of co-habitation\" (a point rejected by Goldsmith). That, along with other attacks, eventually led Goldsmith to counter his critics with his indepth rebuttal \"My Answer\".\n\nGoldsmith's close association with his brother, Sir James Goldsmith, his lifelong friendship with the controversial casino owner and conservationist John Aspinall, along with his anti-modernist stance and support for indigenous peoples, ensured that Goldsmith had many detractors throughout his life. Still, Goldsmith received affectionate support and respect from across the full spectrum of the environmental movement and from many of the people whose views and preoccupations were the focus of his theoretical and philosophical critique.\n\nGoldsmith's message continued to be sponsored around the world, in particular through his work with the International Forum on Globalization (IFG), and, regardless of their previous acrimony, Hildyard and Goldsmith went on to restore their former friendship.\n\n\nWith his first wife, Gillian Marion Pretty (later wife of \"Comte\" Jean-Baptiste de Monpezat, brother of Prince Consort Henrik of Denmark), he had two daughters and a son:\n\nWith his second wife, Katherine Victoria James, he had two sons.\n\nHe had a brother, James Goldsmith, through whom he is the uncle of Zac Goldsmith, Jemima Khan and Ben Goldsmith.\n\n\n\n\n\n\n\n"}
{"id": "718116", "url": "https://en.wikipedia.org/wiki?curid=718116", "title": "Eros (concept)", "text": "Eros (concept)\n\nEros ( or ; \"érōs\" \"love\" or \"desire\") is one of the four ancient Greco-Christian terms which can be rendered into English as \"love\". The other three are \"storge\", \"philia\", and \"agape\". \"Eros\" refers to \"passionate love\" or romantic love; \"storge\" to familial love; \"philia\" to friendship as a kind of love; and \"agape\" refers to \"selfless love\", or \"charity\" as it is translated in the Christian scriptures (from the Latin \"caritas\", dearness). \n\nThe term \"erotic\" is derived from \"eros\". \"Eros\" has also been used in philosophy and psychology in a much wider sense, almost as an equivalent to \"life energy\".\n\nIn the classical world, erotic love was generally referred to as a kind of madness or \"theia mania\" (\"madness from the gods\"). This love passion was described through an elaborate metaphoric and mythological schema involving \"love's arrows\" or \"love darts\", the source of which was often the personified figure of Eros (or his Latin counterpart, Cupid), or another deity (such as Rumor). At times the source of the arrows was said to be the image of the beautiful love object itself. If these arrows were to arrive at the lover's eyes, they would then travel to and 'pierce' or 'wound' his or her heart and overwhelm him/her with desire and longing (lovesickness). The image of the \"arrow's wound\" was sometimes used to create oxymorons and rhetorical antithesis concerning its pleasure and pain.\n\n\"Love at first sight\" was explained as a sudden and immediate beguiling of the lover through the action of these processes, but this was not the only mode of entering into passionate love in classical texts. At times the passion could occur after the initial meeting, as, for example, in Phaedra's letter to Hippolytus in Ovid's \"Heroides\": \"That time I went to Eleusis... it was then most of all (though you had pleased me before) that piercing love lodged in my deepest bones.\" At times, the passion could even precede the first glimpse, as in Paris' letter to Helen of Troy in the same work, where Paris says that his love for Helen came upon him before he had set eyes on her: \"...you were my heart's desire before you were known to me. I beheld your features with my soul ere I saw them with my eyes; rumour, that told me of you, was the first to deal my wound.\"\n\nWhether by \"first sight\" or by other routes, passionate love often had disastrous results according to the classical authors. In the event that the loved one was cruel or uninterested, this desire was shown to drive the lover into a state of depression, causing lamentation and illness. Occasionally, the loved one was depicted as an unwitting ensnarer of the lover, because of her sublime beauty—a \"divine curse\" which inspires men to kidnap her or try to rape her. Stories in which unwitting men catch sight of the naked body of Artemis the huntress (and sometimes Aphrodite) lead to similar ravages (as in the tale of Actaeon).\n\nThe classical conception of love's arrows was developed further by the troubadour poets of Provence during the medieval period, and became part of the European courtly love tradition. The role of a woman's eyes in eliciting erotic desire was particularly emphasized by the Provençal poets, as N.E. Griffin points out:\n\nAccording to this description, love originates upon the eyes of the lady when encountered by those of her future lover. The love thus generated is conveyed on bright beams of light from her eyes to his, through which it passes to take up its abode in his heart.\n\nIn some medieval texts, the gaze of a beautiful woman is compared to the sight of a basilisk—a legendary reptile said to have the power to cause death with a single glance.\n\nThese images continued to be circulated and elaborated upon in the literature and iconography of the Renaissance and Baroque periods. Boccaccio for example, in his \"Il Filostrato\", mixes the tradition of Cupid's arrow with the Provençal emphasis on the eyes as the birthplace of love: \"Nor did he (Troilus) who was so wise shortly before... perceive that Love with his darts dwelt within the rays of those lovely eyes... nor notice the arrow that sped to his heart.\"\n\nThe rhetorical antithesis between the pleasure and pain from love's dart continued through the 17th century, as for example, in these classically inspired images from The Fairy-Queen:\n\nIf Love's a Sweet Passion, why does it torment?<br>If a Bitter, oh tell me whence comes my content?<br>Since I suffer with pleasure, why should I complain,<br>Or grieve at my Fate, when I know 'tis in vain?<br>Yet so pleasing the Pain is, so soft is the Dart,<br>That at once it both wounds me, and Tickles my Heart.\n\nThe ancient philosopher Plato developed an idealistic concept of eros which would prove to be very influential in modern times. In general, Plato did not consider physical attraction to be a necessary part of eros. \"Platonic love\" in this original sense can be attained by the intellectual purification of eros from carnal into ideal form. This process is examined in Plato's dialogue the \"Symposium\". Plato argues there that eros is initially felt for a person, but with contemplation it can become an appreciation for the beauty within that person, or even an appreciation for beauty itself in an ideal sense. As Plato expresses it, eros can help the soul to \"remember\" beauty in its pure form. It follows from this, for Plato, that eros can contribute to an understanding of truth.\n\nEros, understood in this sense, differed considerably from the common meaning of the word in the Greek language of Plato's time. It also differed from the meaning of the word in contemporary literature and poetry. For Plato, eros is neither purely human nor purely divine: it is something intermediate which he calls a daimon. \n\nIts main characteristic is permanent aspiration and desire. Even when it seems to give, eros continues to be a \"desire to possess\", but nevertheless it is different from a purely sensual love in being the love that tends towards the sublime. According to Plato, the gods do not love, because they do not experience desires, inasmuch as their desires are all satisfied. They can thus only be an object, not a subject of love (\"Symposium\" 200-1). For this reason they do not have a direct relationship with man; it is only the mediation of eros that allows the connecting of a relationship (\"Symposium\" 203). Eros is thus the way that leads man to divinity, but not vice versa.\n\n[...] Nevertheless, eros remains always, for Plato, an egocentric love: it tends toward conquering and possessing the object that represents a value for man. To love the good signifies to desire to possess it forever. Love is therefore always a desire for immortality.\n\nParadoxically, for Plato, the object of eros does not have to be physically beautiful. This is because the object of eros is beauty, and the greatest beauty is eternal, whereas physical beauty is in no way eternal. However, if the lover achieves possession of the beloved's \"inner\" (i.e., ideal) beauty, his need for happiness will be fulfilled, because happiness is the experience of knowing that you are participating in the ideal.\n\nIn Freudian psychology, eros, not to be confused with libido, is not exclusively the sex drive, but our life force, the will to live. It is the desire to create life, and favors productivity and construction. In early psychoanalytic writings, instincts from the eros were opposed by forces from the ego. But in later psychoanalytic theory, eros is opposed by the destructive death instinct of Thanatos (death instinct or death drive).\n\nIn his 1925 paper \"The Resistances to Psycho-Analysis\", Freud explains that the psychoanalytic concept of sexual energy is more in line with the Platonic view of eros, as expressed in the Symposium, than with the common use of the word \"sex\" as related primarily to genital activity. He also mentions the philosopher Schopenhauer as an influence. He then goes on to confront his adversaries for ignoring such great precursors and for tainting his whole theory of eros with a \"pansexual\" tendency. He finally writes that his theory naturally explains this collective misunderstanding as a predictable resistance to the acknowledgement of sexual activity in childhood.\n\nHowever, F. M. Cornford finds the standpoints of Plato and of Freud to be \"diametrically opposed\" with regard to eros. In Plato, eros is a spiritual energy initially, which then \"falls\" downward; whereas in Freud eros is a physical energy which is \"sublimated\" upward.\n\nThe philosopher and sociologist Herbert Marcuse appropriated the Freudian concept of eros for his highly influential 1955 work \"Eros and Civilization\".\n\nIn Carl Jung's analytical psychology, the counterpart to eros is \"logos\", a Greek term for the principle of rationality. Jung considers logos to be a masculine principle, while eros is a feminine principle. According to Jung:\nWoman's psychology is founded on the principle of \"Eros\", the great binder and loosener, whereas from ancient times the ruling principle ascribed to man is \"Logos\". The concept of \"Eros\" could be expressed in modern terms as psychic relatedness, and that of \"Logos\" as objective interest.\nThis gendering of eros and logos is a consequence of Jung's theory of the anima/animus syzygy of the human psyche. Syzygy refers to the split between male and female. According to Jung, this split is recapitulated in the unconscious mind by means of \"contrasexual\" (opposite-gendered) elements called the anima (in men) and the animus (in women). Thus men have an unconscious feminine principle, the \"anima\", which is characterized by feminine eros. The work of individuation for men involves becoming conscious of the anima and learning to accept it as one's own, which entails accepting eros. This is necessary in order to see beyond the projections that initially blind the conscious ego. \"Taking back the projections\" is a major task in the work of individuation, which involves owning and subjectivizing unconscious forces which are initially regarded as alien.\n\nIn essence, Jung's concept of eros is not dissimilar to the Platonic one. Eros is ultimately the desire for wholeness, and although it may initially take the form of passionate love, it is more truly a desire for \"psychic relatedness\", a desire for interconnection and interaction with other sentient beings. However, Jung was inconsistent, and he did sometimes use the word \"eros\" as a shorthand to designate sexuality.\n\n"}
{"id": "11185", "url": "https://en.wikipedia.org/wiki?curid=11185", "title": "Feminism", "text": "Feminism\n\nFeminism is a range of political movements, ideologies, and social movements that share a common goal: to define, establish, and achieve political, economic, personal, and social equality of sexes. This includes seeking to establish educational and professional opportunities for women that are equal to those for men.\n\nFeminist movements have campaigned and continue to campaign for women's rights, including the right to vote, to hold public office, to work, to earn fair wages or equal pay, to own property, to receive education, to enter contracts, to have equal rights within marriage, and to have maternity leave. Feminists have also worked to ensure access to legal abortions and social integration, and to protect women and girls from rape, sexual harassment, and domestic violence. Changes in dress and acceptable physical activity have often been part of feminist movements.\n\nSome scholars consider feminist campaigns to be a main force behind major historical societal changes for women's rights, particularly in the West, where they are near-universally credited with achieving women's suffrage, gender neutrality in English, reproductive rights for women (including access to contraceptives and abortion), and the right to enter into contracts and own property. Although feminist advocacy is, and has been, mainly focused on women's rights, some feminists, including bell hooks, argue for the inclusion of men's liberation within its aims because they believe that men are also harmed by traditional gender roles.\nFeminist theory, which emerged from feminist movements, aims to understand the nature of gender inequality by examining women's social roles and lived experience; it has developed theories in a variety of disciplines in order to respond to issues concerning gender.\n\nNumerous feminist movements and ideologies have developed over the years and represent different viewpoints and aims. Some forms of feminism have been criticized for taking into account only white, middle class, and college-educated perspectives. This criticism led to the creation of ethnically specific or multicultural forms of feminism, including black feminism and intersectional feminism.\n\nCharles Fourier, a Utopian Socialist and French philosopher, is credited with having coined the word \"féminisme\" in 1837. The words \"féminisme\" (\"feminism\") and \"féministe\" (\"feminist\") first appeared in France and the Netherlands in 1872, Great Britain in the 1890s, and the United States in 1910, and the \"Oxford English Dictionary\" lists 1852 as the year of the first appearance of \"feminist\" and 1895 for \"feminism\". Depending on the historical moment, culture and country, feminists around the world have had different causes and goals. Most western feminist historians contend that all movements working to obtain women's rights should be considered feminist movements, even when they did not (or do not) apply the term to themselves. Other historians assert that the term should be limited to the modern feminist movement and its descendants. Those historians use the label \"protofeminist\" to describe earlier movements.\n\nThe history of the modern western feminist movements is divided into three \"waves\". Each wave dealt with different aspects of the same feminist issues. The first wave comprised women's suffrage movements of the nineteenth and early twentieth centuries, promoting women's right to vote. The second wave was associated with the ideas and actions of the women's liberation movement beginning in the 1960s. The second wave campaigned for legal and social equality for women. The third wave is a continuation of, and a reaction to, the perceived failures of second-wave feminism, which began in the 1990s.\n\nFirst-wave feminism was a period of activity during the 19th century and early twentieth century. In the UK and eventually the US, it focused on the promotion of equal contract, marriage, parenting, and property rights for women. By the end of the 19th century, a number of important steps had been made with the passing of legislation such as the UK Custody of Infants Act 1839 which introduced the Tender years doctrine for child custody arrangement and gave woman the right of custody of their children for the first time. Other legislation such as the Married Women's Property Act 1870 in the UK and extended in the 1882 Act, these became models for similar legislation in other British territories. For example, Victoria passed legislation in 1884, New South Wales in 1889, and the remaining Australian colonies passed similar legislation between 1890 and 1897. Therefore, with the turn of the 19th century activism had focused primarily on gaining political power, particularly the right of women's suffrage, though some feminists were active in campaigning for women's sexual, reproductive, and economic rights as well.\n\nWomen's suffrage (the right to vote and stand for parliamentary office) began in Britain's Australasian colonies at the close of the 19th century, with the self-governing colonies of New Zealand granting women the right to vote in 1893 and South Australia granting female suffrage in 1895. This was followed by Australia granting female suffrage in 1902.\n\nIn Britain the Suffragettes and the Suffragists campaigned for the women's vote, and in 1918 the Representation of the People Act was passed granting the vote to women over the age of 30 who owned property. In 1928 this was extended to all women over 21. Emmeline Pankhurst was the most notable activist in England, with \"Time\" naming her one of the stating: \"she shaped an idea of women for our time; she shook society into a new pattern from which there could be no going back.\" In the U.S., notable leaders of this movement included Lucretia Mott, Elizabeth Cady Stanton, and Susan B. Anthony, who each campaigned for the abolition of slavery prior to championing women's right to vote. These women were influenced by the Quaker theology of spiritual equality, which asserts that men and women are equal under God. In the United States, first-wave feminism is considered to have ended with the passage of the Nineteenth Amendment to the United States Constitution (1919), granting women the right to vote in all states. The term \"first wave\" was coined retroactively to categorize these western movements after the term \"second-wave feminism\" began to be used to describe a newer feminist movement that focused on fighting social and cultural inequalities, as well political inequalities.\n\nDuring the late Qing period and reform movements such as the Hundred Days' Reform, Chinese feminists called for women's liberation from traditional roles and Neo-Confucian gender segregation. Later, the Chinese Communist Party created projects aimed at integrating women into the workforce, and claimed that the revolution had successfully achieved women's liberation.\n\nAccording to Nawar al-Hassan Golley, Arab feminism was closely connected with Arab nationalism. In 1899, Qasim Amin, considered the \"father\" of Arab feminism, wrote \"The Liberation of Women\", which argued for legal and social reforms for women. He drew links between women's position in Egyptian society and nationalism, leading to the development of Cairo University and the National Movement. In 1923 Hoda Shaarawi founded the Egyptian Feminist Union, became its president and a symbol of the Arab women's rights movement.\n\nThe Iranian Constitutional Revolution in 1905 triggered the Iranian women's movement, which aimed to achieve women's equality in education, marriage, careers, and legal rights. However, during the Iranian revolution of 1979, many of the rights that women had gained from the women's movement were systematically abolished, such as the Family Protection Law.\n\nIn France, women obtained the right to vote only with the Provisional Government of the French Republic of 21 April 1944. The Consultative Assembly of Algiers of 1944 proposed on 24 March 1944 to grant eligibility to women but following an amendment by Fernand Grenier, they were given full citizenship, including the right to vote. Grenier's proposition was adopted 51 to 16. In May 1947, following the November 1946 elections, the sociologist Robert Verdier minimized the \"gender gap\", stating in \"Le Populaire\" that women had not voted in a consistent way, dividing themselves, as men, according to social classes. During the baby boom period, feminism waned in importance. Wars (both World War I and World War II) had seen the provisional emancipation of some women, but post-war periods signalled the return to conservative roles.\n\nBy the mid 20th century, in some European countries, women still lacked some significant rights. Feminists in these countries continued to fight for voting rights. In Switzerland, women gained the right to vote in federal elections in 1971; but in the canton of Appenzell Innerrhoden women obtained the right to vote on local issues only in 1991, when the canton was forced to do so by the Federal Supreme Court of Switzerland. In Liechtenstein, women were given the right to vote by the women's suffrage referendum of 1984. Three prior referendums held in 1968, 1971 and 1973 had failed to secure women's right to vote.\nFeminists continued to campaign for the reform of family laws which gave husbands control over their wives. Although by the 20th century coverture had been abolished in the UK and the US, in many continental European countries married women still had very few rights. For instance, in France married women did not receive the right to work without their husband's permission until 1965. Feminists have also worked to abolish the \"marital exemption\" in rape laws which precluded the prosecution of husbands for the rape of their wives. Earlier efforts by first-wave feminists such as Voltairine de Cleyre, Victoria Woodhull and Elizabeth Clarke Wolstenholme Elmy to criminalize marital rape in the late 19th century had failed; this was only achieved a century later in most Western countries, but is still not achieved in many other parts of the world.\n\nFrench philosopher Simone de Beauvoir provided a Marxist solution and an existentialist view on many of the questions of feminism with the publication of \"Le Deuxième Sexe\" (\"The Second Sex\") in 1949. The book expressed feminists' sense of injustice. Second-wave feminism is a feminist movement beginning in the early 1960s and continuing to the present; as such, it coexists with third-wave feminism. Second-wave feminism is largely concerned with issues of equality beyond suffrage, such as ending gender discrimination.\n\nSecond-wave feminists see women's cultural and political inequalities as inextricably linked and encourage women to understand aspects of their personal lives as deeply politicized and as reflecting sexist power structures. The feminist activist and author Carol Hanisch coined the slogan \"The Personal is Political\", which became synonymous with the second wave.\n\nSecond- and third-wave feminism in China has been characterized by a reexamination of women's roles during the communist revolution and other reform movements, and new discussions about whether women's equality has actually been fully achieved.\n\nIn 1956, President Gamal Abdel Nasser of Egypt initiated \"state feminism\", which outlawed discrimination based on gender and granted women's suffrage, but also blocked political activism by feminist leaders. During Sadat's presidency, his wife, Jehan Sadat, publicly advocated further women's rights, though Egyptian policy and society began to move away from women's equality with the new Islamist movement and growing conservatism. However, some activists proposed a new feminist movement, Islamic feminism, which argues for women's equality within an Islamic framework.\n\nIn Latin America, revolutions brought changes in women's status in countries such as Nicaragua, where feminist ideology during the Sandinista Revolution aided women's quality of life but fell short of achieving a social and ideological change.\n\nIn 1963, Betty Friedan's book \"The Feminine Mystique\" was published and helped voice the discontent that American women felt. The book is widely credited with sparking the beginning of second-wave feminism in the United States. The book's success also meant that Friedan could lecture her views while she was on tour in 1970. Within ten years, after Friedan's successful publishing, women made up more than half of the total percentage in the First World workforce.\n\nThird-wave feminism is traced to the emergence of the Riot grrrl feminist punk subculture in Olympia, Washington, in the early 1990s, and to Anita Hill's televised testimony in 1991—to an all-male, all-white Senate Judiciary Committee—that Clarence Thomas, nominated for the Supreme Court of the United States, had sexually harassed her. The term \"third wave\" is credited to Rebecca Walker, who responded to Thomas's appointment to the Supreme Court with an article in \"Ms.\" magazine, \"Becoming the Third Wave\" (1992). She wrote:\n\nThird-wave feminism also sought to challenge or avoid what it deemed the second wave's essentialist definitions of femininity, which, third-wave feminists argued, over-emphasized the experiences of upper middle-class white women. Third-wave feminists often focused on \"micro-politics\" and challenged the second wave's paradigm as to what was, or was not, good for women, and tended to use a post-structuralist interpretation of gender and sexuality. Feminist leaders rooted in the second wave, such as Gloria Anzaldúa, bell hooks, Chela Sandoval, Cherríe Moraga, Audre Lorde, Maxine Hong Kingston, and many other non-white feminists, sought to negotiate a space within feminist thought for consideration of race-related subjectivities. Third-wave feminism also contained internal debates between difference feminists, who believe that there are important psychological differences between the sexes, and those who believe that there are no inherent psychological differences between the sexes and contend that gender roles are due to social conditioning.\n\nStandpoint theory is a feminist theoretical point of view that believes a persons' social position influences their knowledge. This perspective argues that research and theory treats women and the feminist movement as insignificant and refuses to see traditional science as unbiased. Since the 1980s, standpoint feminists have argued that the feminist movement should address global issues (such as rape, incest, and prostitution) and culturally specific issues (such as female genital mutilation in some parts of Africa and Arab societies, as well as glass ceiling practices that impede women's advancement in developed economies) in order to understand how gender inequality interacts with racism, homophobia, classism and colonization in a \"matrix of domination\".\n\nFourth-wave feminism refers to a resurgence of interest in feminism that began around 2012 and is associated with the use of social media. According to feminist scholar Prudence Chamberlain, the focus of the fourth wave is justice for women and opposition to sexual harassment and violence against women. Its essence, she writes, is \"incredulity that certain attitudes can still exist\".\n\nFourth-wave feminism is \"defined by technology\", according to Kira Cochrane, and is characterized particularly by the use of Facebook, Twitter, Instagram, YouTube, Tumblr, and blogs such as Feministing to challenge misogyny and further gender equality.\n\nIssues that fourth-wave feminists focus on include street and workplace harassment, campus sexual assault and rape culture. Scandals involving the harassment, abuse, and murder of women and girls have galvanized the movement. These have included the 2012 Delhi gang rape, 2012 Jimmy Savile allegations, the Bill Cosby allegations, 2014 Isla Vista killings, 2016 trial of Jian Ghomeshi, 2017 Harvey Weinstein allegations and subsequent Weinstein effect, and the 2017 Westminster sexual scandals.\n\nExamples of fourth-wave feminist campaigns include the Everyday Sexism Project, No More Page 3, Stop Bild Sexism, \"Mattress Performance\", \"10 Hours of Walking in NYC as a Woman\", #YesAllWomen, Free the Nipple, One Billion Rising, the 2017 Women's March, the 2018 Women's March, and the #MeToo movement. In December 2017, \"Time\" magazine chose several prominent female activists involved in the #MeToo movement, dubbed \"the silence breakers\", as Person of the Year.\n\nThe term post-feminism is used to describe a range of viewpoints reacting to feminism since the 1980s. While not being \"anti-feminist\", post-feminists believe that women have achieved second wave goals while being critical of third and fourth wave feminist goals. The term was first used to describe a backlash against second-wave feminism, but it is now a label for a wide range of theories that take critical approaches to previous feminist discourses and includes challenges to the second wave's ideas. Other post-feminists say that feminism is no longer relevant to today's society. Amelia Jones has written that the post-feminist texts which emerged in the 1980s and 1990s portrayed second-wave feminism as a monolithic entity. Dorothy Chunn notes a \"blaming narrative\" under the post-feminist moniker, where feminists are undermined for continuing to make demands for gender equality in a \"post-feminist\" society, where \"gender equality has (already) been achieved.\" According to Chunn, \"many feminists have voiced disquiet about the ways in which rights and equality discourses are now used against them.\"\n\nFeminist theory is the extension of feminism into theoretical or philosophical fields. It encompasses work in a variety of disciplines, including anthropology, sociology, economics, women's studies, literary criticism, art history, psychoanalysis and philosophy. Feminist theory aims to understand gender inequality and focuses on gender politics, power relations, and sexuality. While providing a critique of these social and political relations, much of feminist theory also focuses on the promotion of women's rights and interests. Themes explored in feminist theory include discrimination, stereotyping, objectification (especially sexual objectification), oppression, and patriarchy.\nIn the field of literary criticism, Elaine Showalter describes the development of feminist theory as having three phases. The first she calls \"feminist critique\", in which the feminist reader examines the ideologies behind literary phenomena. The second Showalter calls \"gynocriticism\", in which the \"woman is producer of textual meaning\". The last phase she calls \"gender theory\", in which the \"ideological inscription and the literary effects of the sex/gender system are explored\".\n\nThis was paralleled in the 1970s by French feminists, who developed the concept of \"écriture féminine\" (which translates as 'female or feminine writing'). Helene Cixous argues that writing and philosophy are \"\" and along with other French feminists such as Luce Irigaray emphasize \"writing from the body\" as a subversive exercise. The work of Julia Kristeva, a feminist psychoanalyst and philosopher, and Bracha Ettinger, artist and psychoanalyst, has influenced feminist theory in general and feminist literary criticism in particular. However, as the scholar Elizabeth Wright points out, \"none of these French feminists align themselves with the feminist movement as it appeared in the Anglophone world\". More recent feminist theory, such as that of Lisa Lucile Owens, has concentrated on characterizing feminism as a universal emancipatory movement.\n\nMany overlapping feminist movements and ideologies have developed over the years.\n\nSome branches of feminism closely track the political leanings of the larger society, such as liberalism and conservatism, or focus on the environment. Liberal feminism seeks individualistic equality of men and women through political and legal reform without altering the structure of society. Catherine Rottenberg has argued that the neoliberal shirt in Liberal feminism has led to that form of feminism being individualized rather than collectivized and becoming detached from social inequality. Due to this she argues that Liberal Feminism cannot offer any sustained analysis of the structures of male dominance, power, or privilege.\n\nRadical feminism considers the male-controlled capitalist hierarchy as the defining feature of women's oppression and the total uprooting and reconstruction of society as necessary. Conservative feminism is conservative relative to the society in which it resides. Libertarian feminism conceives of people as self-owners and therefore as entitled to freedom from coercive interference. Separatist feminism does not support heterosexual relationships. Lesbian feminism is thus closely related. Other feminists criticize separatist feminism as sexist. Ecofeminists see men's control of land as responsible for the oppression of women and destruction of the natural environment; ecofeminism has been criticized for focusing too much on a mystical connection between women and nature.\n\nRosemary Hennessy and Chrys Ingraham say that materialist forms of feminism grew out of Western Marxist thought and have inspired a number of different (but overlapping) movements, all of which are involved in a critique of capitalism and are focused on ideology's relationship to women. Marxist feminism argues that capitalism is the root cause of women's oppression, and that discrimination against women in domestic life and employment is an effect of capitalist ideologies. Socialist feminism distinguishes itself from Marxist feminism by arguing that women's liberation can only be achieved by working to end both the economic and cultural sources of women's oppression. Anarcha-feminists believe that class struggle and anarchy against the state require struggling against patriarchy, which comes from involuntary hierarchy.\n\nSara Ahmed argues that Black and Postcolonial feminisms pose a challenge \"to some of the organizing premises of Western feminist thought.\" During much of its history, feminist movements and theoretical developments were led predominantly by middle-class white women from Western Europe and North America. However women of other races have proposed alternative feminisms. This trend accelerated in the 1960s with the civil rights movement in the United States and the collapse of European colonialism in Africa, the Caribbean, parts of Latin America, and Southeast Asia. Since that time, women in developing nations and former colonies and who are of colour or various ethnicities or living in poverty have proposed additional feminisms. Womanism emerged after early feminist movements were largely white and middle-class. Postcolonial feminists argue that colonial oppression and Western feminism marginalized postcolonial women but did not turn them passive or voiceless. Third-world feminism and Indigenous feminism are closely related to postcolonial feminism. These ideas also correspond with ideas in African feminism, motherism, Stiwanism, negofeminism, femalism, transnational feminism, and Africana womanism.\n\nIn the late twentieth century various feminists began to argue that gender roles are socially constructed, and that it is impossible to generalize women's experiences across cultures and histories. Post-structural feminism draws on the philosophies of post-structuralism and deconstruction in order to argue that the concept of gender is created socially and culturally through discourse. Postmodern feminists also emphasize the social construction of gender and the discursive nature of reality; however, as Pamela Abbott et al. note, a postmodern approach to feminism highlights \"the existence of multiple truths (rather than simply men and women's standpoints)\".\n\nFeminist views on transgender people differ. Some feminists do not view trans women as women, believing that they have male privilege due to their sex assignment at birth. Additionally, some feminists reject \"transgenderism\" due to views that all behavioral differences between genders are a result of socialization. In contrast, transfeminists believe that the liberation of trans women is a necessary part of feminist goals. Third-wave feminists are overall more supportive of trans rights. A key concept in transfeminism is of transmisogyny, which is the irrational fear of, aversion to, or discrimination against transgender women or feminine gender non conformers.\n\nRiot grrrls took an anti-corporate stance of self-sufficiency and self-reliance. Riot grrrl's emphasis on universal female identity and separatism often appears more closely allied with second-wave feminism than with the third wave. The movement encouraged and made \"adolescent girls' standpoints central\", allowing them to express themselves fully. Lipstick feminism is a cultural feminist movement that attempts to respond to the backlash of second-wave radical feminism of the 1960s and 1970s by reclaiming symbols of \"feminine\" identity such as make-up, suggestive clothing and having a sexual allure as valid and empowering personal choices.\n\nAccording to 2015 poll, 18 percent of Americans consider themselves feminists, while 85 percent reported they believe in \"equality for women\". Despite the popular belief in equal rights, 52 percent did not identify as feminist, 26 percent were unsure, and four percent provided no response.\n\nAccording to 2014 Ipsos poll covering 15 developed countries, 53 percent of respondents identified as feminists, and 87% agreed that \"women should be treated equally to men in all areas based on their competency, not their gender\". However, only 55% of women agreed that they have \"full equality with men and the freedom to reach their full dreams and aspirations\".\n\nAmong women, some of the strongest support for feminism was found in Sweden, where one in three (36%) agreed very much that they defined themselves as feminists. They were followed by women in Italy (31%) and Argentina (29%). Those in the middle of the ranking were from Great Britain (22%), Spain (22%), United States (20%), Australia (18%), Belgium (18%), France (18%), Canada (17%), Poland (17%), and Hungary (15%). Women least likely to agree very much were from Japan (8%), Germany (7%) and South Korea (7%).\n\nOne quarter of men in Italy (25%) and Argentina (25%), and two in ten of those in Poland (21%) and France (19%), defined themselves as feminists. They were followed by those from Sweden (17%), Spain (16%), the United States (16%), Canada (15%), Great Britain (14%), Hungary (12%), Belgium (11%) and Australia (10%). Men least likely to identify this way were from South Korea (7%), Germany (3%) and Japan (3%).\n\nWomen were more likely to self-identify as being feminists than men in every country in the study except for Poland, where 21% of men were and only 17% of women were likely to agree very much with the statement, and South Korea, where there was no difference between men and women (7%) on this measure.\n\nFeminist views on sexuality vary, and have differed by historical period and by cultural context. Feminist attitudes to female sexuality have taken a few different directions. Matters such as the sex industry, sexual representation in the media, and issues regarding consent to sex under conditions of male dominance have been particularly controversial among feminists. This debate has culminated in the late 1970s and the 1980s, in what came to be known as the feminist sex wars, which pitted anti-pornography feminism against sex-positive feminism, and parts of the feminist movement were deeply divided by these debates. Feminists have taken a variety of positions on different aspects of the sexual revolution from the 1960s and 70s. Over the course of the 1970s, a large number of influential women accepted lesbian and bisexual women as part of feminism.\n\nOpinions on the sex industry are diverse. Feminists critical of the sex industry generally see it as the exploitative result of patriarchal social structures which reinforce sexual and cultural attitudes complicit in rape and sexual harassment. Alternately, feminists who support at least part of the sex industry argue that it can be a medium of feminist expression and a means for women to take control of their sexuality. For the views of feminism on male prostitutes see the article on male prostitution.\n\nFeminist views of pornography range from condemnation of pornography as a form of violence against women, to an embracing of some forms of pornography as a medium of feminist expression. Similarly, feminists' views on prostitution vary, ranging from critical to supportive.\n\nFor feminists, a woman's right to control her own sexuality is a key issue. Feminists such as Catharine MacKinnon argue that women have very little control over their own bodies, with female sexuality being largely controlled and defined by men in patriarchal societies. Feminists argue that sexual violence committed by men is often rooted in ideologies of male sexual entitlement, and that these systems grant women very few legitimate options to refuse sexual advances. In many cultures, men do not believe that a woman has the right to reject a man's sexual advances or to make an autonomous decision about participating in sex. Feminists argue that all cultures are, in one way or another, dominated by ideologies that largely deny women the right to decide how to express their sexuality, because men under patriarchy feel entitled to define sex on their own terms. This entitlement can take different forms, depending on the culture. In many parts of the world, especially in conservative and religious cultures, marriage is regarded as an institution which requires a wife to be sexually available at all times, virtually without limit; thus, forcing or coercing sex on a wife is not considered a crime or even an abusive behaviour. In more liberal cultures, this entitlement takes the form of a general sexualization of the whole culture. This is played out in the sexual objectification of women, with pornography and other forms of sexual entertainment creating the fantasy that all women exist solely for men's sexual pleasure, and that women are readily available and desiring to engage in sex at any time, with any man, on a man's terms.\n\nSandra Harding says that the \"moral and political insights of the women's movement have inspired social scientists and biologists to raise critical questions about the ways traditional researchers have explained gender, sex and relations within and between the social and natural worlds.\" Some feminists, such as Ruth Hubbard and Evelyn Fox Keller, criticize traditional scientific discourse as being historically biased towards a male perspective. A part of the feminist research agenda is the examination of the ways in which power inequities are created or reinforced in scientific and academic institutions. Physicist Lisa Randall, appointed to a task force at Harvard by then-president Lawrence Summers after his controversial discussion of why women may be underrepresented in science and engineering, said, \"I just want to see a whole bunch more women enter the field so these issues don't have to come up anymore.\"\n\nLynn Hankinson Nelson notes that feminist empiricists find fundamental differences between the experiences of men and women. Thus, they seek to obtain knowledge through the examination of the experiences of women, and to \"uncover the consequences of omitting, misdescribing, or devaluing them\" to account for a range of human experience. Another part of the feminist research agenda is the uncovering of ways in which power inequities are created or reinforced in society and in scientific and academic institutions. Furthermore, despite calls for greater attention to be paid to structures of gender inequity in the academic literature, structural analyses of gender bias rarely appear in highly cited psychological journals, especially in the commonly studied areas of psychology and personality.\n\nOne criticism of feminist epistemology is that it allows social and political values to influence its findings. Susan Haack also points out that feminist epistemology reinforces traditional stereotypes about women's thinking (as intuitive and emotional, etc.); Meera Nanda further cautions that this may in fact trap women within \"traditional gender roles and help justify patriarchy\".\n\nModern feminism challenges the essentialist view of gender as biologically intrinsic. For example, Anne Fausto-Sterling's book, \"Myths of Gender\", explores the assumptions embodied in scientific research that support a biologically essentialist view of gender. In \"Delusions of Gender,\" Cordelia Fine disputes scientific evidence that suggests that there is an innate biological difference between men's and women's minds, asserting instead that cultural and societal beliefs are the reason for differences between individuals that are commonly perceived as sex differences.\n\nFeminism in psychology emerged as a critique of the dominant male outlook on psychological research where only male perspectives were studied with all male subjects. As women earned doctorates in psychology, females and their issues were introduced as legitimate topics of study. Feminist psychology emphasizes social context, lived experience, and qualitative analysis. Projects such as Psychology's Feminist Voices have emerged to catalogue the influence of feminist psychologists on the discipline.\n\nGender-based inquiries into and conceptualization of architecture have also come about, leading to feminism in modern architecture. Piyush Mathur coined the term \"archigenderic\". Claiming that \"architectural planning has an inextricable link with the defining and regulation of gender roles, responsibilities, rights, and limitations\", Mathur came up with that term \"to explore ... the meaning of 'architecture' in terms of gender\" and \"to explore the meaning of 'gender' in terms of architecture\".\n\nFeminist activists have established a range of feminist businesses, including women's bookstores, feminist credit unions, feminist presses, feminist mail-order catalogs, and feminist restaurants. These businesses flourished as part of the second and third-waves of feminism in the 1970s, 1980s, and 1990s.\n\nCorresponding with general developments within feminism, and often including such self-organizing tactics as the consciousness-raising group, the movement began in the 1960s and flourished throughout the 1970s. Jeremy Strick, director of the Museum of Contemporary Art in Los Angeles, described the feminist art movement as \"the most influential international movement of any during the postwar period\", and Peggy Phelan says that it \"brought about the most far-reaching transformations in both artmaking and art writing over the past four decades\". Feminist artist Judy Chicago, who created \"The Dinner Party\", a set of vulva-themed ceramic plates in the 1970s, said in 2009 to \"ARTnews\", \"There is still an institutional lag and an insistence on a male Eurocentric narrative. We are trying to change the future: to get girls and boys to realize that women's art is not an exception—it's a normal part of art history.\" A feminist approach to the visual arts has most recently developed through Cyberfeminism and the posthuman turn, giving voice to the ways \"contemporary female artists are dealing with gender, social media and the notion of embodiment\".\n\nThe feminist movement produced feminist fiction, feminist non-fiction, and feminist poetry, which created new interest in women's writing. It also prompted a general reevaluation of women's historical and academic contributions in response to the belief that women's lives and contributions have been underrepresented as areas of scholarly interest. There has also been a close link between feminist literature and activism, with feminist writing typically voicing key concerns or ideas of feminism in a particular era.\n\nMuch of the early period of feminist literary scholarship was given over to the rediscovery and reclamation of texts written by women. In Western feminist literary scholarship, Studies like Dale Spender's \"Mothers of the Novel\" (1986) and Jane Spencer's \"The Rise of the Woman Novelist\" (1986) were ground-breaking in their insistence that women have always been writing.\n\nCommensurate with this growth in scholarly interest, various presses began the task of reissuing long-out-of-print texts. Virago Press began to publish its large list of 19th and early-20th-century novels in 1975 and became one of the first commercial presses to join in the project of reclamation. In the 1980s Pandora Press, responsible for publishing Spender's study, issued a companion line of 18th-century novels written by women. More recently, Broadview Press continues to issue 18th- and 19th-century novels, many hitherto out of print, and the University of Kentucky has a series of republications of early women's novels.\n\nParticular works of literature have come to be known as key feminist texts. \"A Vindication of the Rights of Woman\" (1792) by Mary Wollstonecraft, is one of the earliest works of feminist philosophy. \"A Room of One's Own\" (1929) by Virginia Woolf, is noted in its argument for both a literal and figural space for women writers within a literary tradition dominated by patriarchy.\n\nThe widespread interest in women's writing is related to a general reassessment and expansion of the literary canon. Interest in post-colonial literatures, gay and lesbian literature, writing by people of colour, working people's writing, and the cultural productions of other historically marginalized groups has resulted in a whole scale expansion of what is considered \"literature\", and genres hitherto not regarded as \"literary\", such as children's writing, journals, letters, travel writing, and many others are now the subjects of scholarly interest. Most genres and subgenres have undergone a similar analysis, so literary studies has entered new territories such as the \"female gothic\" or women's science fiction.\n\nAccording to Elyce Rae Helford, \"Science fiction and fantasy serve as important vehicles for feminist thought, particularly as bridges between theory and practice.\" Feminist science fiction is sometimes taught at the university level to explore the role of social constructs in understanding gender. Notable texts of this kind are Ursula K. Le Guin's \"The Left Hand of Darkness\" (1969), Joanna Russ' \"The Female Man\" (1970), Octavia Butler's \"Kindred\" (1979) and Margaret Atwood's \"Handmaid's Tale\" (1985).\n\nFeminist nonfiction has played an important role in voicing concerns about women's lived experiences. For example, Maya Angelou's \"I Know Why The Caged Bird Sings\" was extremely influential, as it represented the specific racism and sexism experienced by black women growing up in the United States.\n\nIn addition, many feminist movements have embraced poetry as a vehicle through which to communicate feminist ideas to public audiences through anthologies, poetry collections, and public readings.\n\nWomen's music (or womyn's music or wimmin's music) is the music by women, for women, and about women. The genre emerged as a musical expression of the second-wave feminist movement as well as the labour, civil rights, and peace movements. The movement was started by lesbians such as Cris Williamson, Meg Christian, and Margie Adam, African-American women activists such as Bernice Johnson Reagon and her group Sweet Honey in the Rock, and peace activist Holly Near. Women's music also refers to the wider industry of women's music that goes beyond the performing artists to include studio musicians, producers, sound engineers, technicians, cover artists, distributors, promoters, and festival organizers who are also women.\nRiot grrrl is an underground feminist hardcore punk movement described in the cultural movements section of this article.\n\nFeminism became a principal concern of musicologists in the 1980s as part of the New Musicology. Prior to this, in the 1970s, musicologists were beginning to discover women composers and performers, and had begun to review concepts of canon, genius, genre and periodization from a feminist perspective. In other words, the question of how women musicians fit into traditional music history was now being asked. Through the 1980s and 1990s, this trend continued as musicologists like Susan McClary, Marcia Citron and Ruth Solie began to consider the cultural reasons for the marginalizing of women from the received body of work. Concepts such as music as gendered discourse; professionalism; reception of women's music; examination of the sites of music production; relative wealth and education of women; popular music studies in relation to women's identity; patriarchal ideas in music analysis; and notions of gender and difference are among the themes examined during this time.\n\nWhile the music industry has long been open to having women in performance or entertainment roles, women are much less likely to have positions of authority, such as being the leader of an orchestra. In popular music, while there are many women singers recording songs, there are very few women behind the audio console acting as music producers, the individuals who direct and manage the recording process.\n\nFeminist cinema, advocating or illustrating feminist perspectives, arose largely with the development of feminist film theory in the late '60s and early '70s. Women who were radicalized during the 1960s by political debate and sexual liberation; but the failure of radicalism to produce substantive change for women galvanized them to form consciousness-raising groups and set about analysing, from different perspectives, dominant cinema's construction of women. Differences were particularly marked between feminists on either side of the Atlantic. 1972 saw the first feminist film festivals in the U.S. and U.K. as well as the first feminist film journal, \"Women and Film\". Trailblazers from this period included Claire Johnston and Laura Mulvey, who also organized the Women's Event at the Edinburgh Film Festival. Other theorists making a powerful impact on feminist film include Teresa de Lauretis, Anneke Smelik and Kaja Silverman. Approaches in philosophy and psychoanalysis fuelled feminist film criticism, feminist independent film and feminist distribution.\n\nIt has been argued that there are two distinct approaches to independent, theoretically inspired feminist filmmaking. 'Deconstruction' concerns itself with analysing and breaking down codes of mainstream cinema, aiming to create a different relationship between the spectator and dominant cinema. The second approach, a feminist counterculture, embodies feminine writing to investigate a specifically feminine cinematic language. Some recent criticism of \"feminist film\" approaches has centred around a Swedish rating system called the Bechdel test.\n\nDuring the 1930s–1950s heyday of the big Hollywood studios, the status of women in the industry was abysmal. Since then female directors such as Sally Potter, Catherine Breillat, Claire Denis and Jane Campion have made art movies, and directors like Kathryn Bigelow and Patty Jenkins have had mainstream success. This progress stagnated in the 90s, and men outnumber women five to one in behind the camera roles.\n\nFeminism had complex interactions with the major political movements of the twentieth century.\n\nSince the late nineteenth century some feminists have allied with socialism, whereas others have criticized socialist ideology for being insufficiently concerned about women's rights. August Bebel, an early activist of the German Social Democratic Party (SPD), published his work \"Die Frau und der Sozialismus\", juxtaposing the struggle for equal rights between sexes with social equality in general. In 1907 there was an International Conference of Socialist Women in Stuttgart where suffrage was described as a tool of class struggle. Clara Zetkin of the SPD called for women's suffrage to build a \"socialist order, the only one that allows for a radical solution to the women's question\".\n\nIn Britain, the women's movement was allied with the Labour party. In the U.S., Betty Friedan emerged from a radical background to take leadership. Radical Women is the oldest socialist feminist organization in the U.S. and is still active. During the Spanish Civil War, Dolores Ibárruri (\"La Pasionaria\") led the Communist Party of Spain. Although she supported equal rights for women, she opposed women fighting on the front and clashed with the anarcha-feminist Mujeres Libres.\n\nFeminists in Ireland in the early 20th century included the revolutionary Irish Republican, suffragette and socialist Constance Markievicz who in 1918 was the first woman elected to the British House of Commons. However, in line with Sinn Féin abstentionist policy, she would not take her seat in the House of Commons. She was re-elected to the Second Dáil in the elections of 1921. She was also a commander of the Irish Citizens Army which was led by the socialist & self-described feminist, Irish leader James Connolly during the 1916 Easter Rising.\n\nFascism has been prescribed dubious stances on feminism by its practitioners and by women's groups. Amongst other demands concerning social reform presented in the Fascist manifesto in 1919 was expanding the suffrage to all Italian citizens of age 18 and above, including women (accomplished only in 1946, after the defeat of fascism) and eligibility for all to stand for office from age 25. This demand was particularly championed by special Fascist women's auxiliary groups such as the \"fasci femminilli\" and only partly realized in 1925, under pressure from dictator Benito Mussolini's more conservative coalition partners.\n\nCyprian Blamires states that although feminists were among those who opposed the rise of Adolf Hitler, feminism has a complicated relationship with the Nazi movement as well. While Nazis glorified traditional notions of patriarchal society and its role for women, they claimed to recognize women's equality in employment. However, Hitler and Mussolini declared themselves as opposed to feminism, and after the rise of Nazism in Germany in 1933, there was a rapid dissolution of the political rights and economic opportunities that feminists had fought for during the pre-war period and to some extent during the 1920s. Georges Duby et al. note that in practice fascist society was hierarchical and emphasized male virility, with women maintaining a largely subordinate position. Blamires also notes that Neofascism has since the 1960s been hostile towards feminism and advocates that women accept \"their traditional roles\".\n\nThe civil rights movement has influenced and informed the feminist movement and vice versa. Many Western feminists adapted the language and theories of black equality activism and drew parallels between women's rights and the rights of non-white people. Despite the connections between the women's and civil rights movements, some tension arose during the late 1960s and early 1970s as non-white women argued that feminism was predominantly white and middle class, and did not understand and was not concerned with race issues. Similarly, some women argued that the civil rights movement had sexist elements and did not adequately address minority women's concerns. These criticisms created new feminist social theories about the intersections of racism, classism, and sexism, and new feminisms, such as black feminism and Chicana feminism.\n\nNeoliberalism has been criticized by feminist theory for having a negative effect on the female workforce population across the globe, especially in the global south. Masculinist assumptions and objectives continue to dominate economic and geopolitical thinking. Women's experiences in non-industrialized countries reveal often deleterious effects of modernization policies and undercut orthodox claims that development benefits everyone.\n\nProponents of neoliberalism have theorized that by increasing women's participation in the workforce, there will be heightened economic progress, but feminist critics have noted that this participation alone does not further equality in gender relations. Neoliberalism has failed to address significant problems such as the devaluation of feminized labour, the structural privileging of men and masculinity, and the politicization of women's subordination in the family and the workplace. The \"feminization of employment\" refers to a conceptual characterization of deteriorated and devalorized labour conditions that are less desirable, meaningful, safe and secure. Employers in the global south have perceptions about feminine labour and seek workers who are perceived to be undemanding, docile and willing to accept low wages. Social constructs about feminized labour have played a big part in this, for instance, employers often perpetuate ideas about women as 'secondary income earners to justify their lower rates of pay and not deserving of training or promotion.\n\nThe feminist movement has effected change in Western society, including women's suffrage; greater access to education; more nearly equitable pay with men; the right to initiate divorce proceedings; the right of women to make individual decisions regarding pregnancy (including access to contraceptives and abortion); and the right to own property.\n\nFrom the 1960s on, the campaign for women's rights was met with mixed results in the U.S. and the U.K. Other countries of the EEC agreed to ensure that discriminatory laws would be phased out across the European Community.\n\nSome feminist campaigning also helped reform attitudes to child sexual abuse. The view that young girls cause men to have sexual intercourse with them was replaced by that of men's responsibility for their own conduct, the men being adults.\n\nIn the U.S., the National Organization for Women (NOW) began in 1966 to seek women's equality, including through the Equal Rights Amendment (ERA), which did not pass, although some states enacted their own. Reproductive rights in the U.S. centred on the court decision in \"Roe\" v. \"Wade\" enunciating a woman's right to choose whether to carry a pregnancy to term. Western women gained more reliable birth control, allowing family planning and careers. The movement started in the 1910s in the U.S. under Margaret Sanger and elsewhere under Marie Stopes. In the final three decades of the 20th century, Western women knew a new freedom through birth control, which enabled women to plan their adult lives, often making way for both career and family.\n\nThe division of labour within households was affected by the increased entry of women into workplaces in the 20th century. Sociologist Arlie Russell Hochschild found that, in two-career couples, men and women, on average, spend about equal amounts of time working, but women still spend more time on housework, although Cathy Young responded by arguing that women may prevent equal participation by men in housework and parenting. Judith K. Brown writes, \"Women are most likely to make a substantial contribution when subsistence activities have the following characteristics: the participant is not obliged to be far from home; the tasks are relatively monotonous and do not require rapt concentration; and the work is not dangerous, can be performed in spite of interruptions, and is easily resumed once interrupted.\"\n\nIn international law, the \"Convention on the Elimination of All Forms of Discrimination Against Women\" (CEDAW) is an international convention adopted by the United Nations General Assembly and described as an international bill of rights for women. It came into force in those nations ratifying it.\n\nFeminist jurisprudence is a branch of jurisprudence that examines the relationship between women and law. It addresses questions about the history of legal and social biases against women and about the enhancement of their legal rights.\n\nFeminist jurisprudence signifies a reaction to the philosophical approach of modern legal scholars, who typically see law as a process for interpreting and perpetuating a society's universal, gender-neutral ideals. Feminist legal scholars claim that this fails to acknowledge women's values or legal interests or the harms that they may anticipate or experience.\n\nProponents of gender-neutral language argue that the use of gender-specific language often implies male superiority or reflects an unequal state of society. According to \"The Handbook of English Linguistics\", generic masculine pronouns and gender-specific job titles are instances \"where English linguistic convention has historically treated men as prototypical of the human species.\"\n\nMerriam-Webster chose \"feminism\" as its 2017 Word of the Year, noting that \"Word of the Year is a quantitative measure of interest in a particular word.\"\n\nFeminist theology is a movement that reconsiders the traditions, practices, scriptures, and theologies of religions from a feminist perspective. Some of the goals of feminist theology include increasing the role of women among the clergy and religious authorities, reinterpreting male-dominated imagery and language about God, determining women's place in relation to career and motherhood, and studying images of women in the religion's sacred texts.\n\nChristian feminism is a branch of feminist theology which seeks to interpret and understand Christianity in light of the equality of women and men, and that this interpretation is necessary for a complete understanding of Christianity. While there is no standard set of beliefs among Christian feminists, most agree that God does not discriminate on the basis of sex, and are involved in issues such as the ordination of women, male dominance and the balance of parenting in Christian marriage, claims of moral deficiency and inferiority of women compared to men, and the overall treatment of women in the church. The Christian Bible refers to women in positions of authority in Judges 4:4 and Kings 22:14.\n\nIslamic feminists advocate women's rights, gender equality, and social justice grounded within an Islamic framework. Advocates seek to highlight the deeply rooted teachings of equality in the Quran and encourage a questioning of the patriarchal interpretation of Islamic teaching through the Quran, \"hadith\" (sayings of Muhammad), and \"sharia\" (law) towards the creation of a more equal and just society. Although rooted in Islam, the movement's pioneers have also utilized secular and Western feminist discourses and recognize the role of Islamic feminism as part of an integrated global feminist movement.\n\nBuddhist feminism is a movement that seeks to improve the religious, legal, and social status of women within Buddhism. It is an aspect of feminist theology which seeks to advance and understand the equality of men and women morally, socially, spiritually, and in leadership from a Buddhist perspective. The Buddhist feminist Rita Gross describes Buddhist feminism as \"the radical practice of the co-humanity of women and men.\"\n\nJewish feminism is a movement that seeks to improve the religious, legal, and social status of women within Judaism and to open up new opportunities for religious experience and leadership for Jewish women. The main issues for early Jewish feminists in these movements were the exclusion from the all-male prayer group or \"minyan\", the exemption from positive time-bound \"mitzvot\", and women's inability to function as witnesses and to initiate divorce. Many Jewish women have become leaders of feminist movements throughout their history.\n\nDianic Wicca is a feminist-centred thealogy.\n\nSecular or atheist feminists have engaged in feminist criticism of religion, arguing that many religions have oppressive rules towards women and misogynistic themes and elements in religious texts.\n\nPatriarchy is a social system in which society is organized around male authority figures. In this system fathers have authority over women, children, and property. It implies the institutions of male rule and privilege, and is dependent on female subordination. Most forms of feminism characterize patriarchy as an unjust social system that is oppressive to women. Carole Pateman argues that the patriarchal distinction \"between masculinity and femininity is the political difference between freedom and subjection.\" In feminist theory the concept of patriarchy often includes all the social mechanisms that reproduce and exert male dominance over women. Feminist theory typically characterizes patriarchy as a social construction, which can be overcome by revealing and critically analyzing its manifestations. Some radical feminists have proposed that because patriarchy is too deeply rooted in society, separatism is the only viable solution. Other feminists have criticized these views as being anti-men.\n\nFeminist theory has explored the social construction of masculinity and its implications for the goal of gender equality. The social construct of masculinity is seen by feminism as problematic because it associates males with aggression and competition, and reinforces patriarchal and unequal gender relations. Patriarchal cultures are criticized for \"limiting forms of masculinity\" available to men and thus narrowing their life choices. Some feminists are engaged with men's issues activism, such as bringing attention to male rape and spousal battery and addressing negative social expectations for men.\n\nMale participation in feminism is generally encouraged by feminists and is seen as an important strategy for achieving full societal commitment to gender equality. Many male feminists and pro-feminists are active in both women's rights activism, feminist theory, and masculinity studies. However, some argue that while male engagement with feminism is necessary, it is problematic because of the ingrained social influences of patriarchy in gender relations. The consensus today in feminist and masculinity theories is that men and women should cooperate to achieve the larger goals of feminism. It has been proposed that, in large part, this can be achieved through considerations of women's agency.\n\nDifferent groups of people have responded to feminism, and both men and women have been among its supporters and critics. Among American university students, for both men and women, support for feminist ideas is more common than self-identification as a feminist. The US media tends to portray feminism negatively and feminists \"are less often associated with day-to-day work/leisure activities of regular women.\" However, as recent research has demonstrated, as people are exposed to self-identified feminists and to discussions relating to various forms of feminism, their own self-identification with feminism increases.\n\nPro-feminism is the support of feminism without implying that the supporter is a member of the feminist movement. The term is most often used in reference to men who are actively supportive of feminism. The activities of pro-feminist men's groups include anti-violence work with boys and young men in schools, offering sexual harassment workshops in workplaces, running community education campaigns, and counselling male perpetrators of violence. Pro-feminist men also may be involved in men's health, activism against pornography including anti-pornography legislation, men's studies, and the development of gender equity curricula in schools. This work is sometimes in collaboration with feminists and women's services, such as domestic violence and rape crisis centres.\n\nAnti-feminism is opposition to feminism in some or all of its forms.\n\nIn the nineteenth century, anti-feminism was mainly focused on opposition to women's suffrage. Later, opponents of women's entry into institutions of higher learning argued that education was too great a physical burden on women. Other anti-feminists opposed women's entry into the labour force, or their right to join unions, to sit on juries, or to obtain birth control and control of their sexuality.\n\nSome people have opposed feminism on the grounds that they believe it is contrary to traditional values or religious beliefs. These anti-feminists argue, for example, that social acceptance of divorce and non-married women is wrong and harmful, and that men and women are fundamentally different and thus their different traditional roles in society should be maintained. Other anti-feminists oppose women's entry into the workforce, political office, and the voting process, as well as the lessening of male authority in families.\n\nWriters such as Camille Paglia, Christina Hoff Sommers, Jean Bethke Elshtain, Elizabeth Fox-Genovese, Lisa Lucile Owens and Daphne Patai oppose some forms of feminism, though they identify as feminists. They argue, for example, that feminism often promotes misandry and the elevation of women's interests above men's, and criticize radical feminist positions as harmful to both men and women. Daphne Patai and Noretta Koertge argue that the term \"anti-feminist\" is used to silence academic debate about feminism. Lisa Lucile Owens argues that certain rights extended exclusively to women are patriarchal because they relieve women from exercising a crucial aspect of their moral agency.\n\n\n\n\n\n"}
{"id": "37551955", "url": "https://en.wikipedia.org/wiki?curid=37551955", "title": "Five Facet Mindfulness Questionnaire", "text": "Five Facet Mindfulness Questionnaire\n\nThe Five Facet Mindfulness Questionnaire (FFMQ) is a psychological measurement to explore mindfulness. It is based on five independently developed mindfulness questionnaires that are bound together in a factor analytic study. The questionnaire consists of 39 items. The five facets are: observing, describing, acting with awareness, non-judging of inner experience, and non-reactivity to inner experience.\n\nThe FFMQ has been criticised, with specifics including that negative and positive wording constituted substantive method effects.\n\n"}
{"id": "246042", "url": "https://en.wikipedia.org/wiki?curid=246042", "title": "Forgiveness", "text": "Forgiveness\n\nForgiveness is the intentional and voluntary process by which a victim undergoes a change in feelings and attitude regarding an offense, lets go of negative emotions such as vengefulness, forswears recompense from or punishment of the offender, however legally or morally justified it might be, and with an increased ability to wish the offender well. Forgiveness is different from condoning (failing to see the action as wrong and in need of forgiveness), excusing (not holding the offender as responsible for the action), forgetting (removing awareness of the offense from consciousness), pardoning (granted for an acknowledged offense by a representative of society, such as a judge), and reconciliation (restoration of a relationship).\n\nIn certain contexts, forgiveness is a legal term for absolving or giving up all claims on account of debt, loan, obligation, or other claims.\n\nAs a psychological concept and virtue, the benefits of forgiveness have been explored in religious thought, the social sciences and medicine. Forgiveness may be considered simply in terms of the person who forgives including forgiving themself, in terms of the person forgiven or in terms of the relationship between the forgiver and the person forgiven. In most contexts, forgiveness is granted without any expectation of restorative justice, and without any response on the part of the offender (for example, one may forgive a person who is incommunicado or dead). In practical terms, it may be necessary for the offender to offer some form of acknowledgment, an apology, or even just ask for forgiveness, in order for the wronged person to believe themselves able to forgive as well.\n\nSocial and political dimensions of forgiveness involves the strictly private and religious sphere of \"forgiveness\". The notion of \"forgiveness\" is generally considered unusual in the political field. However, Hannah Arendt considers that the \"faculty of forgiveness\" has its place in public affairs. The philosopher believes that forgiveness can liberate resources both individually and collectively in the face of the irreparable. During an investigation in Rwanda on the discourses and practices of forgiveness after the 1994 genocide, sociologist Benoit Guillou illustrated the extreme polysemy of the word \"forgiveness\" but also the eminently political character of the notion. By way of conclusion of his work, the author proposes four main figures of forgiveness to better understanding, on the one hand, ambiguous uses and, on the other hand, the conditions under which forgiveness can mediate a resumption of social link.\n\nMost world religions include teachings on the nature of forgiveness, and many of these teachings provide an underlying basis for many varying modern day traditions and practices of forgiveness. Some religious doctrines or philosophies place greater emphasis on the need for humans to find some sort of divine forgiveness for their own shortcomings, others place greater emphasis on the need for humans to practice forgiveness of one another, yet others make little or no distinction between human and divine forgiveness.\n\nAlthough there is presently no consensus for a psychological definition of forgiveness in the research literature, agreement has emerged that forgiveness is a process and a number of models describing the process of forgiveness have been published, including one from a radical behavioral perspective.\n\nDr. Robert Enright from the University of Wisconsin–Madison founded the International Forgiveness Institute and is considered the initiator of forgiveness studies. He developed a 20-Step Process Model of Forgiveness. Recent work has focused on what kind of person is more likely to be forgiving. A longitudinal study showed that people who were generally more neurotic, angry, and hostile in life were less likely to forgive another person even after a long time had passed. Specifically, these people were more likely to still avoid their transgressor and want to enact revenge upon them two and a half years after the transgression.\n\nStudies show that people who forgive are happier and healthier than those who hold resentments. The first study to look at how forgiveness improves physical health discovered that when people think about forgiving an offender it leads to improved functioning in their cardiovascular and nervous systems. Another study at the University of Wisconsin found the more forgiving people were, the less they suffered from a wide range of illnesses. The less forgiving people reported a greater number of health problems.\n\nThe research of Dr. Fred Luskin of Stanford University, and author of the book \"Learning to forgive\" presented evidence that forgiveness can be learned based on research projects into the effects of forgiveness, giving empirical validity to the concept that forgiveness is not only powerful, but also excellent for your health was presented with a Champion of Forgiveness from the Worldwide Forgiveness Alliance on Forgiveness Day (first Sunday of August) for his teaching forgiveness as a life skill.\n\nIn three separate studies, including one with Catholics and Protestants from Northern Ireland whose family members were murdered in the political violence, he found that people who are taught how to forgive become less angry, feel less hurt, are more optimistic, become more forgiving in a variety of situations, and become more compassionate and self-confident. His studies show a reduction in experience of stress, physical manifestations of stress, and an increase in vitality.\n\nIn Judaism, if a person causes harm, but then sincerely and honestly apologizes to the wronged individual and tries to rectify the wrong, the wronged individual is encouraged, but not required, to grant forgiveness:\n\n\nIn Judaism, one must go \"to those he has harmed\" in order to be entitled to forgiveness. [One who sincerely apologizes three times for a wrong committed against another has fulfilled their obligation to seek forgiveness. (Shulchan Aruch) OC 606:1] This means that in Judaism a person cannot obtain forgiveness from God for wrongs the person has done to other people. This also means that, unless the victim forgave the perpetrator before he died, murder is unforgivable in Judaism, and they will answer to God for it, though the victims' family and friends can forgive the murderer for the grief they caused them. The \"Tefila Zaka\" meditation, which is recited just before Yom Kippur, closes with the following:\n\n\nThus the \"reward\" for forgiving others is not God's forgiveness for wrongs done to others, but rather help \"in obtaining forgiveness from the other person.\"\n\nSir Jonathan Sacks, Chief Rabbi of the United Hebrew Congregations of the Commonwealth, summarized: \"it is not that God forgives, while human beings do not. To the contrary, we believe that just as only God can forgive sins against God, so only human beings can forgive sins against human beings.\"\n\nJews observe a Day of Atonement Yom Kippur on the day before God makes decisions regarding what will happen during the coming year. Just prior to Yom Kippur, Jews will ask forgiveness of those they have wronged during the prior year (if they have not already done so). During Yom Kippur itself, Jews fast and pray for God's forgiveness for the transgressions they have made against God in the prior year. Sincere repentance is required, and once again, God can only forgive one for the sins one has committed against God; this is why it is necessary for Jews also to seek the forgiveness of those people who they have wronged.\n\nForgiveness is central to Christian ethics and is a frequent topic in sermons and theological works. Considering Mark 11:25, and , that follows the Lord's Prayer, \"For if you forgive men when they sin against you, your heavenly Father will also forgive you. But if you do not forgive men their sins, your Father will not forgive your sins.,\" Forgiveness is not an option to a Christian, rather one must forgive to be a Christian.\n\nIn the New Testament, Jesus speaks of the importance of Christians forgiving or showing mercy towards others. Jesus used the parable of the unmerciful servant (Matthew 18:21–35) to say that we should forgive without limits. Parable of the Prodigal Son is perhaps the best known parable about forgiveness and refers to God's forgiveness for his people.\n\nIn the Sermon on the Mount, Jesus repeatedly spoke of forgiveness, \"Blessed are the merciful, for they will be shown mercy.\" (NIV) \"Therefore, if you are offering your gift at the altar and there remember that your brother has something against you, leave your gift there in front of the altar. First go and be reconciled to your brother; then come and offer your gift.\" (NIV) \"And when you stand praying, if you hold anything against anyone, forgive him, so that your Father in heaven may forgive you your sins.\" Mark 11:25 (NIV)* \"But I tell you who hear me: Love your enemies, do good to those who hate you, bless those who curse you, pray for those who mistreat you. If someone strikes you on one cheek, turn to him the other also.\" Luke 6:27–29 (NIV) \"Be merciful, just as your Father is merciful.\" Luke 6:36 (NIV) \"Do not judge, and you will not be judged. Do not condemn, and you will not be condemned. Forgive, and you will be forgiven.\" Luke 6:37 (NIV)\n\nElsewhere, it is said, \"Then Peter came to Him and said, \"Lord, how often shall my brother sin against me, and I forgive him? Up to seven times?\" Jesus said to him, \"I do not say to you, up to seven times, but up to seventy times seven.\" Matthew 18:21–22 (NKJV)\n\nJesus asked for God's forgiveness of those who crucified him. \"And Jesus said, 'Father, forgive them, for they know not what they do.'\" Luke 23: 34 (ESV)\n\nBenedict XVI, on a visit to Lebanon in 2012, insisted that peace must be based on mutual forgiveness: \"Only forgiveness, given and received, can lay lasting foundations for reconciliation and universal peace\".\n\nIslam teaches that Allah is \"Al-Ghaffur\" \"The Oft-Forgiving\", and is the original source of all forgiveness (\"ghufran\" ). Seeking forgiveness from Allah with repentance is a virtue.\n\nIslam recommends forgiveness, because Allah values forgiveness. There are numerous verses in Quran and the Hadiths recommending forgiveness. However, Islam also allows revenge to the extent harm done, but forgiveness is encouraged, with a promise of reward from Allah.\n\n\"Afw\" ( is another term for forgiveness in Islam; it occurs 35 times in Quran, and in some Islamic theological studies, it is used interchangeably with \"ghufran\". \"Afw\" means to pardon, to excuse for a fault or an offense. According to Muhammad Amanullah, forgiveness ('Afw) in Islam is derived from three wisdoms. First and the most important wisdom of forgiveness is that it is merciful when the victim or guardian of the victim accepts money instead of revenge. The second wisdom of forgiveness is that it increases honor and prestige of the one who forgives. Forgiveness is not a sign of weakness, humiliation or dishonor. Forgiveness is honor, raises the merit of the forgiver in the eyes of Allah, and enables a forgiver to enter paradise. The third wisdom of forgiveness is that according to some scholars, such as al-Tabari and al-Qurtubi, forgiveness expiates (\"kaffarah\") the forgiver from the sins they may have committed at other occasions in life. Forgiveness is a form of charity (\"sadaqat\"). Forgiveness comes from taqwa (piety), a quality of God-fearing people.\n\nIn the Bahá'í Writings, this explanation is given of how to be forgiving towards others:\n\n\"Love the creatures for the sake of God and not for themselves. You will never become angry or impatient if you love them for the sake of God. Humanity is not perfect. There are imperfections in every human being, and you will always become unhappy if you look toward the people themselves. But if you look toward God, you will love them and be kind to them, for the world of God is the world of perfection and complete mercy. Therefore, do not look at the shortcomings of anybody; see with the sight of forgiveness.\"\n<br> — `Abdu'l-Bahá, \"The Promulgation of Universal Peace\", p. 92\nIn Buddhism, forgiveness is seen as a practice to prevent harmful thoughts from causing havoc on one's mental well-being. Buddhism recognizes that feelings of hatred and ill-will leave a lasting effect on our mind karma. Instead, Buddhism encourages the cultivation of thoughts that leave a wholesome effect. \"In contemplating the law of karma, we realize that it is not a matter of seeking revenge but of practicing mettā and forgiveness, for the victimizer is, truly, the most unfortunate of all.\" When resentments have already arisen, the Buddhist view is to calmly proceed to release them by going back to their roots. Buddhism centers on release from delusion and suffering through meditation and receiving insight into the nature of reality.\nBuddhism questions the reality of the passions that make forgiveness necessary as well as the reality of the objects of those passions. \"If we haven’t forgiven, we keep creating an identity around our pain, and that is what is reborn. That is what suffers.\"\n\nBuddhism places much emphasis on the concepts of \"Mettā\" (loving kindness), \"karuna\" (compassion), \"mudita\" (sympathetic joy), and \"upekkhā\" (equanimity), as a means to avoiding resentments in the first place. These reflections are used to understand the context of suffering in the world, both our own and the suffering of others.\n\nIn Vedic literature and epics of Hinduism, \"Ksama\" or \"Kshyama\" (Sanskrit: ) and fusion words based on it, describe the concept of forgiveness. The word \"ksama\" is often combined with \"kripa\" (tenderness), \"daya\" (kindness) and \"karuna\" (, compassion) in Sanskrit texts. In Rg Veda, forgiveness is discussed in verses dedicated to deity Varuna, both the context of the one who has done wrong and one who is wronged. Forgiveness is considered one of the six cardinal virtues in Hindu Dharma.\n\nThe theological basis for forgiveness in Hindu Dharma is that a person who does not forgive carries a baggage of memories of the wrong, of negative feelings, of anger and unresolved emotions that affect their present as well as future. In Hindu Dharma, not only should one forgive others, but one must also seek forgiveness if one has wronged someone else. Forgiveness is to be sought from the individual wronged, as well as society at large, by acts of charity, purification, fasting, rituals and meditative introspection.\n\nThe concept of forgiveness is further refined in Hindu Dharma by rhetorically contrasting it in feminine and masculine form. In feminine form, one form of forgiveness is explained through Lakshmi (called Goddess Sri in some parts of India); the other form is explained in the masculine form through her husband Vishnu. Feminine Lakshmi forgives even when the one who does wrong does not repent. Masculine Vishnu, on the other hand, forgives only when the wrongdoer repents. In Hindu Dharma, the feminine forgiveness granted without repentance by Lakshmi is higher and more noble than the masculine forgiveness granted only after there is repentance. In the Hindu epic Ramayana, Sita – the wife of King Rama – is symbolically eulogized for forgiving a crow even as it harms her. Later in the epic Ramayana, she is eulogized again for forgiving those who harass her while she has been kidnapped in Lanka. Many other Hindu stories discuss forgiveness with or without repentance.\n\nThe concept of forgiveness is treated in extensive debates of Hindu literature. In some Hindu texts, certain sins and intentional acts are debated as naturally unforgivable; for example, murder and rape; these ancient scholars argue whether blanket forgiveness is morally justifiable in every circumstance, and whether forgiveness encourages crime, disrespect, social disorder and people not taking you seriously. Other ancient Hindu texts highlight that forgiveness is not same as reconciliation.\n\nForgiveness in Hindu Dharma does not necessarily require that one reconcile with the offender, nor does it rule out reconciliation in some situations. Instead forgiveness in Hindu philosophy is being compassionate, tender, kind and letting go of the harm or hurt caused by someone or something else. Forgiveness is essential for one to free oneself from negative thoughts, and being able to focus on blissfully living a moral and ethical life (\"dharmic\" life). In the highest self-realized state, forgiveness becomes the essence of one's personality, where the persecuted person remains unaffected, without agitation, without feeling like a victim, free from anger (\"akrodhi\").\n\nOther epics and ancient literature of Hindu Dharma discuss forgiveness. For example:\n\nIn Jainism, forgiveness is one of the main virtues that needs to be cultivated by the Jains. \"Kṣamāpanā\" or supreme forgiveness forms part of one of the ten characteristics of \"dharma\". In the Jain prayer, (\"pratikramana\") Jains repeatedly seek forgiveness from various creatures—even from \"ekindriyas\" or single sensed beings like plants and microorganisms that they may have harmed while eating and doing routine activities. Forgiveness is asked by uttering the phrase, \"Micchāmi dukkaḍaṃ.\" \"Micchāmi dukkaḍaṃ\" is a Prakrit language phrase literally meaning \"may all the evil that has been done be fruitless.\" During \"samvatsari\"—the last day of Jain festival \"paryusana\"—Jains utter the phrase \"Micchami Dukkadam\" after \"pratikraman\". As a matter of ritual, they personally greet their friends and relatives \"micchāmi dukkaḍaṃ\" seeking their forgiveness. No private quarrel or dispute may be carried beyond samvatsari, and letters and telephone calls are made to the outstation friends and relatives asking their forgiveness.\n\n\"Pratikraman\" also contains the following prayer:\n\n\"Khāmemi savva-jīve savvë jive khamantu me / \"\n\n\"metti me savva-bhūesu, veraṃ mejjha na keṇavi //\"\n\n(I ask pardon of all creatures, may all creatures pardon me.\n\nMay I have friendship with all beings and enmity with none.)\nIn their daily prayers and samayika, Jains recite \"Iryavahi sutra\" seeking forgiveness from all creatures while involved in routine activities:\n\nMay you, O Revered One! Voluntarily permit me. I would like to confess my sinful acts committed while walking. I honour your permission. I desire to absolve myself of the sinful acts by confessing them. I seek forgiveness from all those living beings which I may have tortured while walking, coming and going, treading on living organism, seeds, green grass, dew drops, ant hills, moss, live water, live earth, spider web and others. I seek forgiveness from all these living beings, be they — one sensed, two sensed, three sensed, four sensed or five sensed. Which I may have kicked, covered with dust, rubbed with ground, collided with other, turned upside down, tormented, frightened, shifted from one place to another or killed and deprived them of their lives. (By confessing) may I be absolved of all these sins.\nJain texts quote Māhavīra on forgiveness:\n\nBy practicing \"prāyaṣcitta\" (repentance), a soul gets rid of sins, and commits no transgressions; he who correctly practises \"prāyaṣcitta\" gains the road and the reward of the road, he wins the reward of good conduct. By begging forgiveness he obtains happiness of mind; thereby he acquires a kind disposition towards all kinds of living beings; by this kind disposition he obtains purity of character and freedom from fear.\n\n— Māhavīra in \"Uttarādhyayana Sūtra\" 29:17–18\nEven the code of conduct amongst the monks requires the monks to ask forgiveness for all transgressions:\n\nIf among monks or nuns occurs a quarrel or dispute or dissension, the young monk should ask forgiveness of the superior, and the superior of the young monk. They should forgive and ask forgiveness, appease and be appeased, and converse without restraint. For him who is appeased, there will be success (in control); for him who is not appeased, there will be no success; therefore one should appease one's self. 'Why has this been said, Sir? Peace is the essence of monasticism'.\n\n— \"Kalpa Sūtra\" 8:59\nHoʻoponopono is an ancient Hawaiian practice of reconciliation and forgiveness, combined with prayer. Similar forgiveness practices were performed on islands throughout the South Pacific, including Samoa, Tahiti and New Zealand. Traditionally Hoʻoponopono is practiced by healing priests or \"kahuna lapaʻau\" among family members of a person who is physically ill. Modern versions are performed within the family by a family elder, or by the individual alone.\n\nThe need to forgive is widely recognized by the public, but they are often at a loss for ways to accomplish it. For example, in a large representative sampling of American people on various religious topics in 1988, the Gallup Organization found that 94% said it was important to forgive, but 85% said they needed some outside help to be able to forgive. However, not even regular prayer was found to be effective.\n\nAkin to forgiveness is mercy, so even if a person is not able to complete the forgiveness process they can still show mercy, especially when so many wrongs are done out of weakness rather than malice. The Gallup poll revealed that the only thing that was effective was \"meditative prayer\".\n\nForgiveness as a tool has been extensively used in restorative justice programs, after the abolition of apartheid Truth and Reconciliation Commission (South Africa), run for victims and perpetrators of Rwandan genocide, the violence in Israeli–Palestinian conflict, and Northern Ireland conflict, which has also been documented in film, \"\" (2012).\n\nForgiveness in marriage is an important aspect in a marriage. When two individuals are able to forgive each other it results in a long happy marriage. Forgiveness can help prevent problems from accruing in the married couple's future.\n\nIn a 2005 study, researchers were interested in figuring out whether forgiveness is important in a marriage. When does forgiveness usually accrue? Does it accrue before an argument or after an argument? Does forgiveness take a role when a person breaks a promise? etc Researcher found six components that were related to forgiveness in marriage and explains how each one relates to forgiveness. The six components are: Satisfaction, Ambivalence, Conflict, Attributions, Empathy and Commitment.\n\nResearchers provided an overview of forgiveness in marriage and how individuals in a relationship believe that if forgiveness accrues then you must forget what had happened. Moreover, based on the interventions and recommendations the researcher started to see how important forgiveness is in a relationship and how it can lead to a happy and healthy relationship.\n\nIn a 2005 study, researchers mentioned that when couples forgive their spouses they sometimes need help from professionals to overcome their pain that might be left behind. Researchers also described the difference between how each individual perceives the situation based on who is in pain and who caused the pain. Also how the couple react to the situation based on their feelings and how they personally respond to the situation.\n\nThe model of forgiveness:\n\n\"Enright's model of forgiveness has received empirical support and sees forgiveness as a journey through four phases\" which are:\n\n\nFurthermore, when married couples argue they tend to focus on who is right and who is wrong. Also couples tend to focus on who proves the other wrong which can cause more problems and can make the problem worse because it will make it harder to forgive one another.\n\nRecommendation and interventions:\n\nThe researchers also came up with recommendation for practitioners and intervention to help individuals that are married on how to communicate with each other, how to resolve problems and how to make it easier to forgive each other.\nSome of the interventions of forgiveness in marriage has been a great success. It encouraged forgiveness and made couples happier together.\nSome of the recommendations that was given to practitioners was that the individuals had to explore and understand what forgiveness means before starting any intervention because the preconceived idea of forgiveness can cause problems with couples being open to forgive. For example, an individual not forgiving their spouse out of fear that the spouse might think that they are weak which can cause a conflict. It was stated that the couple must know the following:\n\nFurthermore, the researchers thought of ways to further help married couples in the future and suggested that they should explore the following:\n\n\"Relationships\" are at the sentiment aspect of our lives; with our families at home and friends outside. Relationships interact in schools and universities, with work mates and, with colleagues at the workplace and in our diverse communities. In the article it states, the quality of these relationships determines our individual well-being, how well we learn, develop and function, our sense of connectedness with others and the health so society.\n\nIn 2002, two innovators of \"Positive Psychology\", Ed Diener and Martin Seligman, conducted a study at the University of Illinois on the 10% of students with the highest scores recorded on a survey of personal happiness. What they came up with was most salient characteristics shared by students who were very content and showed positive life styles were the ones who \"their strong ties to friends and family and commitment to spending time with them.\"\n\nA study done in 2000, identified as a key study that taken part and examined two natures of relationships (friends and family) and at what age does the support switch importance from one to the other. What the study showed that people whom had good family relationship, they were able to carry out more positive outside relationships with friends. Through the \"family\" relationship and friendships the character of the individual was built to forgive and learn from the experience in the family. It just goes to show that to have a good base at the start of a young age, will train the person to have good better well-being with outside interactions.\n\nIn 2001, Charlotte vanOyen Witvliet asked people to think about someone who had hurt, wronged, or offended them. As they thought to answer, she observed their reaction. She observed their blood pressure, heart rate, facial muscle tension, and sweat gland activity. To deliberate on an old misdemeanor is to practice unforgiveness. The outcome to the recall of the grudge the candidates’ blood pressure and heart rate increased, and they sweated more. Pondering about their resents was stressful, and subjects found the rumination unpleasant. When they adept forgiveness, their physical stimulation glided downward. They showed no more of an anxiety reaction than normal wakefulness produces.\n\nIn 2013, study on self-forgiveness with spouse forgiveness has a better outcome to a healthier life by Pelucchi, Paleari, Regalia and Fincham. This study investigates \"self-forgiveness\" for real hurts committed against the partner in a romantic relationship (168 couples). For both males and females, the mistaken partners were more content with their romantic relationship to the extent that they had more positive and less negative sentiment and thoughts toward themselves. In the study when looking at the victimized partners were more gratified with the relationship when the offending partner had less negative sentiment and thoughts towards themselves. It concludes that self-forgiveness when in a relationship has positive impact on both the offending and victimized partner.\n\nBoth negative and positive affect play a role in forgiveness interventions. It is the general consensus across researchers in the field of psychology, that the overarching purpose of forgiveness interventions is to decrease overall negative affect associated with the stimulus and increase the individual's positive affect.\n\nThe disease model has been mainly used in regards to therapy, however the incorporation of forgiveness into therapy has been lacking, and has been slowly gaining popularity in the last couple of decades. More recent research has shown how the growth of forgiveness in psychology has given rise to the study of forgiveness interventions.\n\nThere are various forms of forgiveness interventions. One common adaptation used by researchers is where patients are forced to confront the entity preventing them from forgiving by using introspective techniques and expressing this to the therapist. Another popular forgiveness intervention is getting individual to try and see things from the offender's point of view. The end goal for this adaptation is getting the individual to perhaps understand the reasoning behind the offender's actions. If they are able to do this then they might be able to forgive the offender more easily.\n\nThere is, however, conflicting evidence on the effectiveness of forgiveness interventions.\n\nAlthough research has taken into account the positive aspects of forgiveness interventions, there are also negative aspects that have been explored as well. Some researchers have taken a critical approach and have been less accepting of the forgiveness intervention approach to therapy.\n\nCritics have argued that forgiveness interventions may actually cause an increase in negative affect because it is trying to inhibit the individual's own personal feelings towards the offender. This can result in the individual feeling negatively towards themself. This approach is categorizing the individual's feelings by implying that the negative emotions the individual is feeling are unacceptable and feelings of forgiveness is the correct and acceptable way to feel. It might inadvertently promote feelings of shame and contrition within the individual.\n\nSome researchers also worry that forgiveness interventions will promote unhealthy relationships. They worry that individuals with toxic relationships will continue to forgive those who continuously commit wrong acts towards them when in fact they should be distancing themselves from these sorts of people.\n\nA number of studies showcase high effectiveness rates of forgiveness interventions when done continuously over a long period of time. Some researchers have found that these interventions have been proven ineffective when done over short spans of time.\n\nThere has been some research within the last decade outlining some studies that have looked at the effectiveness of forgiveness interventions on young children. There have also been several studies done studying this cross culturally. One study that explored this relationship, was a study conducted in 2009 by Eadaoin Hui and Tat Sing Chau. In this study, Hui and Chau looked at the relationship between forgiveness interventions and Chinese children who were less likely to forgive those who had wronged them. The findings of this study showed that there was an effect of forgiveness interventions on the young Chinese children.\n\nSurvey data from 2000 showed that 61% of participants that were part of a small religious group reported that the group helped them be more forgiving. Individuals reported that their religion groups which promote forgiveness was related to self-reports of success in overcoming addictions, guilt, and perceiving encouragement when feeling discouraged.\n\nIt is suggested that mindfulness plays a role in forgiveness and health. The forgiveness of others has a positive effect on physical health when it is combined with mindfulness but evidence shows that forgiveness only effects health as a function of mindfulness.\n\nA study from 2005 states that self-forgiveness is an important part of self-acceptance and mental health in later life. The inability to self-forgive can compromise mental health. For some elderly people, self-forgiveness requires reflecting on a transgression to avoid repeating wrongdoings, individuals seek to learn from these transgressions in order to improve their real self-schemas. When individuals are successful at learning from these transgressions, they may experience improved mental health.\n\nA study in 2015 looks at how self-forgiveness can reduce feelings of guilt and shame associated with hypersexual behaviour. Hypersexual behaviour can have negative effects on individuals by causing distress and life problems. Self-forgiveness may be a component that can help individuals reduce hypersexual negative behaviours that cause problems.\n\nEvidence shows that self-forgiveness and procrastination may be associated; self-forgiveness allows the individual to overcome the negatives associated with an earlier behaviour and engage in approach-oriented behaviours on a similar task. Learning to forgive oneself for procrastination can be positive because it can promote self-worth and may cause positive mental health. Self-forgiveness for procrastination may also reduce procrastination.\n\nThe correlation between forgiveness and physical health is a concept that has recently gained traction in research. Some studies claim that there is no correlation, either positive or negative between forgiveness and physical health, and others show a positive correlation.\n\nIndividuals with forgiveness as a personality trait have been shown to have overall better physical health. In a study on relationships, regardless if someone was in a negative or positive relationship, their physical health seemed to be influenced at least partially by their level of forgiveness.\n\nIndividuals who make a decision to genuinely forgive someone are also shown to have better physical health. This is due to the relationship between forgiveness and stress reduction. Forgiveness is seen as preventing poor physical health and managing poor physical health.\n\nSpecifically individuals who choose to forgive another after a transgression have lower blood pressure and lower cortisol levels than those who do not. This is theorized to be due to various direct and indirect influences of forgiveness, which point to forgiveness as an evolutionary trait. See Broaden and Build Theory.\n\nDirect influences include: Reducing hostility (which is inversely correlated with physical health), and the concept that unforgiveness may reduce the immune system because it puts stress on the individual. Indirect influences are more related to forgiveness as a personality trait and include: forgiving people may have more social support and less stressful marriages, and forgiveness may be related to personality traits that are correlated with physical health.\n\nForgiveness may also be correlated with physical health because hostility is associated with poor coronary performance. Unforgiveness is as an act of hostility, and forgiveness as an act of letting go of hostility. Heart patients who are treated with therapy that includes forgiveness to reduce hostility have improved cardiac health compared to those who are treated with medicine alone.\nForgiveness may also lead to better perceived physical health. This correlation applies to both self-forgiveness and other-forgiveness but is especially true of self-forgiveness. Individuals who are more capable of forgiving themselves have better perceived physical health.\n\nForgiveness studies have been refuted by critics who claim that there is no direct correlation between forgiveness and physical health. Forgiveness, due to the reduction of directed anger, contributes to mental health and mental health contributes to physical health, but there is no evidence that forgiveness directly improves physical health. Most of the studies on forgiveness cannot isolate it as an independent variable in an individual's well-being, so it is difficult to prove causation.\n\nAdditionally, research into the correlation between physical health and forgiveness has been criticized for being too focused on unforgiveness. Research shows more about what hostility and unforgiveness contribute to poor health than it shows what forgiveness contributes to physical health.\n\nSelf-forgiveness happens in situations where an individual has done something that they perceive to be morally wrong and they consider themselves to be responsible for the wrongdoing. Self-forgiveness is the overcoming of negative emotions that the wrongdoer associates with the wrongful action. Negative emotions associated with wrongful action can include guilt, regret, remorse, blame, shame, self-hatred and/or self-contempt.\n\nMajor life events that include trauma can cause individuals to experience feelings of guilt or self-hatred. Humans have the ability to reflect on their behaviours to determine if their actions are moral. In situations of trauma, humans can choose to self-forgive by allowing themselves to change and live a moral life. Self-forgiveness may be required in situations where the individual hurt themselves or in situations where they hurt others.\n\nIndividuals can unintentionally cause harm or offence to one another in everyday life. It is important for individuals to be able to recognize when this happens, and in the process of making amends, have the ability to self-forgive. Specific research suggests that the ability to genuinely forgive one's self can be significantly beneficial to an individual's emotional as well as mental well-being. The research indicates that the ability to forgive one's self for past offences can lead to decreased feelings of negative emotions such as shame and guilt, and can increase the use of more positive practices such as self-kindness and self-compassion. However, it has been indicated that it is possible for the process of self-forgiveness to be misinterpreted and therefore not accurately completed. This could potentially lead to increased feelings of regret or self-blame. In an attempt to avoid this, and increase the positive benefits associated with genuine self-forgiveness, a specific therapeutic model of self-forgiveness has been recommended, which can be used to encourage genuine self-forgiveness in offenders. The model that has been proposed has four key elements. These elements include responsibility, remorse, restoration and renewal. \nDespite the suggested model, research advises that the process of self-forgiveness is not always applicable for every individual. For example, individuals who have not actually caused others any harm or wrongdoing, but instead are suffering from negative emotions such as self-hatred or self-pity, such as victims of assault, might attempt self-forgiveness for their perceived offences. However, this would not be the process necessary for them to make their amends. Additionally, offenders who continue to offend others while attempting to forgive themselves for past offences demonstrate a reluctance to genuinely complete the four stages necessary for self-forgiveness. Research suggests that it is important to first gather exterior information about the individual's perceived offences as well as their needs and motivation for self-forgiveness.\n\n\n\n"}
{"id": "4493904", "url": "https://en.wikipedia.org/wiki?curid=4493904", "title": "Haumai", "text": "Haumai\n\nHaumai (Punjabi: ਹਉਮੈ) is the concept of self-centeredness (egoism or \"Ahankar\") in Sikhism. This concept was taught by Guru Nanak, the founder of Sikhism, as the source of five evils: lust, covetousness, wrath, pride and attachment. According to Sikh Gurus teachings, it is \"Haumai\" that leads to endless cycles of transmigration (rebirth), and makes a person \"manmukh\". They state that one must turn away from \"Haumai\", become a \"gurmukh\" and follow the path of the Guru to receive God's grace.\n\nIn Sikhism, the \"Haumai\" can only be overcome through meditation on God’s name (\"Naam\"), \"Simran\" and \"Sewa\". It is a combination of the words \"Hau\" (ਹਉ) meaning \"I\" and \"Mai\" (ਮੈ) meaning \"me\".\n\nThe opposite of \"Haumai\" is humility (or \"Nimrata\"), which is considered a virtue in Sikhism. Selfless service called \"Seva\", and complete submission to Waheguru, or God is the Sikh path to liberation.\n\nThe concept of destructive self-centeredness and covetous attachment, similar to \"Haumai\" in Sikhism, is important in other Indian religions. In Buddhism, Hinduism and Jainism, it is referred to as \"Ahankar\" (अहङ्कार), \"Ahammana\" (अहम्मान), \"Ahammati\" (अहम्मति), \"Mamatta\" (ममता) and \"Maminkāra\".\n\n"}
{"id": "3725026", "url": "https://en.wikipedia.org/wiki?curid=3725026", "title": "Imagined Communities", "text": "Imagined Communities\n\nImagined Communities: Reflections on the Origin and Spread of Nationalism is a book by Benedict Anderson. It introduces a popular concept in political sciences and sociology, that of imagined communities named after it. It was first published in 1983, and reissued with additional chapters in 1991 and a further revised version in 2006.\n\nEric G.E. Zuelow described this book as \"perhaps the most read book about nationalism\".\n\nAccording to Anderson's theory of imagined communities, the main causes of nationalism are the declining importance of privileged access to particular script languages (such as Latin) because of mass vernacular literacy; the movement to abolish the ideas of rule by divine right and hereditary monarchy; and the emergence of printing press capitalism (\"the convergence of capitalism and print technology... standardization of national calendars, clocks and language was embodied in books and the publication of daily newspapers\")—all phenomena occurring with the start of the Industrial Revolution.\n\nAccording to Anderson, nations are socially constructed. For Anderson, the idea of the \"nation\" is relatively new and is a product of various socio-material forces. He defined a nation as \"an imagined political community – and imagined as both inherently limited and sovereign\". As Anderson puts it, a nation \"is imagined because the members of even the smallest nation will never know most of their fellow-members, meet them, or even hear of them, yet in the minds of each lives the image of their communion\". While members of the community probably will never know each of the other members face to face, they may have similar interests or identify as part of the same nation. Members hold in their minds a mental image of their affinity: for example, the nationhood felt with other members of your nation when your \"imagined community\" participates in a larger event such as the Olympic Games.\n\nNations are \"limited\" in that they have \"finite, if elastic boundaries, beyond which lie other nations\". They are \"sovereign\" since no dynastic monarchy can claim authority over them, in the modern period:\n\nEven though we may never see anyone in our imagined community, we still know they are there through communication.\n\nFinally, a nation is a community because,\n"}
{"id": "46876400", "url": "https://en.wikipedia.org/wiki?curid=46876400", "title": "Indiscrete category", "text": "Indiscrete category\n\nAn indiscrete category is a category \"C\" in which every hom-set \"C\"(\"X\", \"Y\") is a singleton. Every class \"X\" gives rise to an indiscrete category whose objects are the elements of \"X\" with exactly one morphism between any two objects. Any two nonempty indiscrete categories are equivalent to each other. The functor from Set to Cat that sends a set to the corresponding indiscrete category is right adjoint to the functor that sends a small category to its set of objects.\n"}
{"id": "1575660", "url": "https://en.wikipedia.org/wiki?curid=1575660", "title": "Infamous Decree", "text": "Infamous Decree\n\nOn March 17, 1808, Napoleon I created three decrees in a failed attempt to bring equality and to integrate the Jews into French society after the Jewish Emancipation of 1790-1791. The Infamous Decree, the third of the three, had adverse effects. Although the decrees´ aim was to further emancipate the Jews into equal citizenship, it restricted Jewish money lending (Catholics were not permitted to commit acts of usury, or the charging of interest as profit on loans), it annulled all debts owed to Jews by non Jewish debtors and limited the residency of new Jewish peoples in France by restricting all business activities while allowing work in agriculture and regular craftsmanship. The combination of these decrees severely weakened the financial position of once dominant rural French money lending Jews.\n\nNapoleon Bonaparte initially won allegiance of Jews when in 1797 he emancipated Jews in Ancona, Italy. He officially chose two High Priests of the Jewish Nation and seven councillors to the High Priests. He allegedly encouraged Jews to reclaim Jerusalem in 1799 with the help of his army in a letter to a rabbi in Jerusalem, but the letter is suspected by many to be a forgery. He in no way acted against the Jews until the early 19th century, when he passed a series of three decrees, one of which became known as the Infamous Decree. Some, such as author Franz Kobler, attribute Napoleon’s change in attitude to Napoleon’s new attachment to France and his newfound desire to protect the interests of the French people. When he was the hero of the Jews, he still was an \"ardent patriot\" of his home island of Corsica.\n\nIn France, quite early in the Nineteenth Century, Jewish moneylenders were accused of usury, in Alsace, as well as of abusing other rights, which were given to them in their emancipation in 1791 under Louis XVI. Napoleon sided with popular French opinion. Though he desired equality for the Jews, he called them \"the most despicable of men\" and proclaimed he did not want their number to increase in an 1808 letter to his brother Jerome.\n\nNapoleon issued an imperial decree in 1806 that suspended payment of debts owed to Jewish moneylenders for one year to warn against usury to the supposedly degenerate Jewish population and called a conference with Jewish leaders. The group he conferred with was dubbed the Great Sanhedrin. and met in 1807.\n\nThough the first meeting of the Great Sanhedrin on February 4, 1807 was ceremonial and solemn, the group was largely ineffective as nothing was done during the month they met to ameliorate the conditions on the Jews that would be imposed by the coming decrees. During the eight sessions, the Great Sanhedrin was forced to condone intermarriage between Frenchmen and Jews in order that the Jewish people might be absorbed into France, since Jews were considered substandard citizens and needed to be either absorbed or expelled. The group also had to support other actions to assimilate the Jews by removing their Jewish ties, such as approving military service to attach young Jewish men to France rather than to their religion and ethnic background. Such measures were a prelude to the passing of the three decrees on March 17, 1808.\n\nAfter Napoleon’s emancipation of the Jews he \"wanted to mandate what some proponents of emancipation had hoped would happen, namely the total assimilation, or biological fusion of Jews with the rest of the French people.\" To mandate the assimilation of Jews into French society, three decrees were issued on March 17, 1808.\n\nThe \"first two decrees restored order to the informal Jewish communities that had survived the revolution by establishing a hierarchical, centralized organization, under the aegis of the ministry of religions.\" The first two decrees set up the consistories which were designed to enforce the decrees. Some of the members also were a part of the Great Sanhedrin which met in 1807. The consistories consisted of a grand rabbi, possibly another rabbi and three lay members who were residents of the town. The consistories acted to enforce Sanhedrin rules through the use of education; they also worked as informants to the government which was monitoring Jewish activity. There was one consistory for every town that contained 2,000 or more Jews.\n\nThe Infamous Decree, also known as the \"third decree,\" presumed all Jews guilty of chicanery (the use of trickery to achieve a political, financial or legal purpose) unless proven innocent, and restricted Jewish commerce and money lending for a period of 10 years.\" This decree was put into place to end Jewish money lending. It annulled all debts owed to Jews by married women, minors, and soldiers and voided any loan that had interest rates exceeding 10 percent. This was an attempt by Napoleon to get rid of alleged usury by Jewish businessmen and to turn these former businessmen into craftsman and farmers to promote supposed equality between the Jews and non-Jews in France. To encourage Jews to move into this niche, the Jews were restricted in changing residency to certain parts of France unless they \"acquired rural property and devoted themselves to agriculture without entering into any commercial or business transactions.\" To keep tabs on businesses that had survived the new restrictions, the decree mandated that all business require a patent or license that had to be renewed yearly. Not only did the decree hurt the Jews economically but it changed their military rights.\n\nThe final restriction of the Jews was an attempt to strengthen their bond with the government and the country. The decree made it so that the Jewish conscripts (required enlistees of military) couldn’t find replacements for themselves when drafted like other Frenchmen were allowed to do.\n\nAs a consequence of the first three decrees, another and final decree was implemented on July 20, 1808. This final decree declared that all Jews acquire a fixed family name to help the government and consistories supervise the Jews movements. They were restricted in their choice of names and weren’t allowed to pick names from the Hebrew Bible or any town names.\n\nThe three decrees were set up to expire after 10 years and would only be continued if renewed after that period. In 1818 Louis XVIII opted to not renew the decree and thus it ended. Louis XVIII was thereafter known as the \"liberator of Jews.\"\n\nAfter the decrees were not renewed after 10 years, Jews migrated into three main areas: Paris, Alsace and Lorraine. Indications of cultural and economical change can be seen in these areas. Although these changes were devastating to the economy of the Jews, they greatly increased the population and the distribution of the Jews.\n\nMany Jews continued to live as lower class citizens. They were peddlers, clothes dealers, cattle merchants and small-scale commercial agents. The decree made business in the French Jewry more difficult. They could not have gone into farming or artistry because other bans took away their ability to own any land or belong to guilds. The Jews could not use their commercial skills because without the ability to own land, the Jewish businessmen could not experience any kind of expansion. But as time went by, more and more Jews began to go into artistry. In Bordeaux, for example, 34 Jews worked as artisans and professionals. 66 Jews owned houses in the city and 39 were proprietors of rural land. Percentages of artisans in the city of Paris and Nancy increased also. These different economical changes were accompanied by the union of Jewish youth in the public school system.\n\nThere were many concerns with Jewish youth and the public school system. There was discrimination and talk of conversions. Only 10 percent of Jewish children attended public school in Alsace. One government Jewish official said, \"Our schools are Catholic schools rather than public schools. Prayers according to the Roman religion are recited upon entering and leaving, the catechism of the same religion is taught there and the textbook used are of that same religion.\" \n\nBy 1810, a few Jews went to local schools and moved to Lycée, but many Jewish parents neglected their children’s education to prepare them into business. Jews gradually moved into public schools, and some even hired private tutors. Some parents home schooled their daughters to teach them music, dance and embroidery.\n\nThe emancipation led to the redistribution of the Jewish population in France. Jews migrated to the cities and to communes where there had not previously been a Jewish population. French Jews went to Paris, by 1809 there were more than 2900 Jews there. The total Jewish population grew to more than 46,000 in Alsace.\n"}
{"id": "27454991", "url": "https://en.wikipedia.org/wiki?curid=27454991", "title": "Information seeking behavior", "text": "Information seeking behavior\n\nInformation seeking behavior refers to the way people search for and utilize information. The term was coined by Thomas D. Wilson in his 1981 paper, on the grounds that the then current 'information needs' was unhelpful as a basis for a research agenda, since 'need' could not be directly observed, while how people behaved in seeking information could be observed and investigated. However, there is increasing work in the information searching field that is relating behaviors to underlying needs.\n\nIn 2000, Wilson described information behavior as the totality of human behavior in relation to sources and channels of information, including both active and passive information-seeking, and information use. He described information seeking behavior as purposive seeking of information as a consequence of a need to satisfy some goal. Information seeking behavior is the micro-level of behavior employed by the searcher in interacting with information systems of all kinds, be it between the seeker and the system, or the pure method of creating and following up on a search.\n\nA variety of theories of information behavior – e.g. Zipf's principle of least effort, Brenda Dervin's sensemaking, Elfreda Chatman's life in the round – seek to understand the processes that surround information seeking. The analysis of the most cited publications on information behavior during the first years of this century shows its theoretical nature. Together with some works that have a constructivist focus, using references to Dewey, Kelly, Bruner and Vygotsky, others mention sociological concepts, such as Bourdieu's habitus. Several adopt a constructionist-discursive focus, whereas some, such as Chatman, who can in general be described as using an ethnographic perspective, stand out for the quantity and diversity of references to social research. The term 'information behaviour' was also coined by Wilson and occasioned some controversy on its introduction, but now seems to have been adopted, not only by researchers in information science but also in other disciplines.\n\nThe digital world is changing human information behavior and process. Focused almost exclusively on information seeking and using, information receiving, a central modality of the process is generally overlooked. As information seeking continues to migrate to the Internet, and artificial intelligence continues to advance the analysis of user behavior on the Internet across a range of user interactions, information receiving moves to the heart of the process, as systems \"learn\" what users like, want and need, as well as their search habits.\n\nISP was proposed and developed by Carol Kuhlthau.\n\nAn holistic framework based initially on research into high school students, but extended over time to include a diverse range of people, including those in the workplace. It examined the role of emotions, specifically uncertainty, in the information seeking process, concluding that many searches are abandoned due to an overwhelmingly high level of uncertainty.\n\nISP is a 6-stage process, with each stage each encompassing 4 aspects;\n\nInvestigated the behavior of researchers in the physical and social sciences and engineers and research scientists through semi-structured interviews using a grounded theory approach, with a focus on describing the activities rather than a process.\n\nThese initial investigations produced six key activities within the information seeking process:\n\n\nLater studies by Ellis (focusing on academic researchers in other disciplines) resulted in the addition of two more activities;\n\n\nThe episodic model was developed by Nicholas J. Belkin.\n\nThe episodic model is based largely on intuition and insight and concentrates on interactions with information. There are 4 dimensions which characterize search behavior. These dimensions can be combined in 16 different ways.\n\n\nASK was also developed by Nicholas J. Belkin.\n\nAn anomalous state of knowledge is one in which the searcher recognises a gap in the state of knowledge. This, his further hypothesis, is influential in studying why people start to search.\n\nThomas Wilson proposed that information behavior covers all aspects of human information behavior, whether active or passive.\n\nInformation \"Seeking\" behavior is the act of actively seeking information in order to answer a specific query.\n\nInformation \"Searching\" behavior is the behavior which stems from the searcher interacting with the system in question. This system could be a technological one, such as the searcher interacting with a search engine, or a manual one, such as the searcher selecting which book is most pertinent to their query.\n\nInformation \"Use\" behavior pertains to the searcher adopting the knowledge they sought.\n\nDeveloped by Stuart Card, Ed H. Chi and Peter Pirolli.\n\nThis model is derived from anthropological theories and is comparable to foraging for food. Information seekers use clues (or information scents) such as links, summaries and images to estimate how close they are to target information. A scent must be obvious as users often browse aimlessly or look for specific information. Information foraging is descriptive of why and not how people search in particular ways.\n\nDeveloped by Elfreda Chatman.\n\nShe defines life in the round as a world of tolerated approximation. It acknowledges reality at its most routine, predictable enough that unless an initial problem should arise, there is no point in seeking information.\n\nChatman examined this principle within a small world: a world which imposes on its participants similar concerns and awareness of who is important; which ideas are relevant and whom to trust. Participants in this world are considered insiders.\n\nChatman focused her study on women at a maximum security prison. She learned that over time, prisoner's private views were assimilated to a communal acceptance of life in the round: a small world perceived in accordance with agreed upon standards and communal perspective. Members who live in the round will not cross the boundaries of their world to seek information unless it is critical; there is a collective expectation that information is relevant; or life lived in the round no longer functions. The world outside prison has secondary importance to inmates who are absent from this reality which is changing with time.\n\nBrenda Dervin developed the concept of sensemaking. Sensemaking considers how we (attempt to) make sense of uncertain situations. Her description of Sensemaking consisted of the definition of how we interpret information to use for our own information related decisions.\n\nBrenda Dervin described sensemaking as a method through which people make sense of their worlds in their own language.\n\nThis principle explains that information seekers prioritise the most convenient path to acceptable information.\nThis compares the internet search methods of experienced information seekers (navigators) and inexperienced information seekers (explorers). Navigators revisit domains; follow sequential searches and have few deviations or regressions within their search patterns and interactions. Explorers visit many domains; submit many questions and their search trails branch frequently.\n\nRobinson's (2010) research suggests that when seeking information at work, people rely on both other people and information repositories (e.g., documents and databases), and spend similar amounts of time consulting each (7.8% and 6.4% of work time, respectively; 14.2% in total). However, of theoretical interest, the distribution of time among the constituent information seeking stages differs depending on the source. When consulting other people, people spend less time locating the information source and information within that source, similar time understanding the information, and more time problem solving and decision making, than when consulting information repositories. Furthermore, the research found that people spend substantially more time receiving information passively (i.e., information that they have not requested) than actively (i.e., information that they have requested), and this pattern is also reflected when they provide others with information.\n\nA review of the literature on information seeking behavior shows that information seeking has generally been accepted as dynamic and non-linear (Foster, 2005; Kuhlthau 2006). People experience the information search process as an interplay of thoughts, feelings and actions (Kuhlthau, 2006).\n\nInformation seeking has been found to be linked to a variety of interpersonal communication behaviors beyond question-asking, to include strategies such as candidate answers.\n\nA search for information may be linked to decision making. The decision involved may vary from a trivial personal matter to a decision which affects billions or may have cumulative economic or political effects as individual buying or voting decisions may.\n\nNicolaisen described four distinct types of information seeking behavior: visceral, conscious, formalized and compromised. The visceral need is expressed as the actual information need before it has been expressed. The conscious need is the need once it has been recognized by the seeker. The formalized need is the statement of the need and the compromised need is the query when related to the information system.\n\nJISC's study of the Google Generation detailed six different characteristics of online information seeking behavior;\n\n\nHorizontal information seeking is the method sometimes referred to as \"skimming\". An information seeker who skims views a couple of pages, then subsequently follows other links without necessarily returning to the initial sites. Navigators, as might be expected, spend their time finding their way around. Wilson found that users of e-book or e-journal sites were most likely spend, on average, a mere four to eight minutes viewing said sites. Squirreling behavior relates to users who download lots of documents but might not necessarily end up reading them. Checking information seekers assess the host in order to ascertain trustworthiness. The bracket of users named diverse information seekers are users whose behavior differs from the above sectors.\n\n"}
{"id": "17017675", "url": "https://en.wikipedia.org/wiki?curid=17017675", "title": "International Salon for Peace Initiatives", "text": "International Salon for Peace Initiatives\n\nThe International Salon for Peace Initiatives is organized in the framework of the International Decade for the Promotion of a Culture of Peace and Non-Violence for the Children of the World (2001–2010) declared by the United Nations in 1998.\nOrganized by the French Coalition for the Decade, it has been taken place in Paris every two years since 2004.\n\nThis Salon hosts the International Conference on the Culture of Peace and Non-Violence, organized by the French Coalition for the Decade in collaboration with the International Coalition for the Decade. This Conference create a space for thinking and meeting for all those involved in this field, in France, Europe and all over the world.\n\nThe 2d International Salon for Peace Initiatives has taken place in Paris on 2–4 June 2006, in the Centre des Congrès de la Villette, in the Cité des Sciences et de l'Industrie (Paris).\n\nThe second international Salon for Peace Initiatives was held under the auspices of the UNESCO the French Foreign Office and the City of Paris, in partnership with the Secours catholique – Caritas France, the CCFD, Non-violence XXI, Partage, \"Le Monde\", \"La Vie\", \"Télérama\", RFI and TV5 and with the support of Pax Christi France.\n\nThis Salon has help a wide public get familiar with the culture of peace and non-violence. 168 French and international exhibitors were presenting their peace and non-violence initiatives on 116 booths. They have proposed 40 interactive workshops and other activities with 13,000 participants.\n\nThis Salon has hosted the International Conference « Actors for a Culture of Peace and Non-violence ».\n\nSeven round tables and sixty workshops helped the participants to discover the different aspects of the culture of peace and non-violence. Among the speakers were:\n\n\nHundreds organizations came from all over the world to participate to this conference.\n\nThe 3rd International Salon for Peace Initiatives will take place in Paris on 30 May – 1 June 2008, in the Cité des Sciences et de l'Industrie.\nIt will help a wide public to get familiar with the culture of peace and non-violence. Around 200 French and international exhibitors will present their peace and non-violence initiatives and several activities will be proposed, included 40 interactive workshops, films and exhibitions.\n\nThe third international Salon for Peace Initiatives will be held under the auspices of the UN, the UNESCO, the UNRIC, the French Commission for UNESCO, the French Foreign Office, the Regional council of Ile-de-France and the City of Paris, in partnership with the Secours catholique- Réseau mondial Caritas, Non-violence XXI, Partage, \"Le Monde\", \"La Vie\" and RFI, and also with the support of Pax Christi France and the Secours islamique.\n\nSeveral organizations will be partners of this Salon in order to enrich the culture of peace and non-violence and to highlight its numerous dimensions: justice, non-violent resolution of conflicts, mediation, human rights defense, environmental respect and development, disarmament, gender equality, international solidarity etc.\n\nThis Salon will host the International Conference \"Actor for a Culture of Peace and Nonviolence\", organized by the French Coalition for the Decade in collaboration with the International Coalition for the Decade. This Conference will create a space for thinking and meeting for all those involved in this field, in France and all over the world.\n\nSix round tables and sixty workshops will allow for the encounter and the debate among several scientific disciplines (sociology, psychology and pedagogy) and several citizen practices (associative, political) from the whole world. They will take into account the death anniversary of two major figures of non-violence: M. K. Gandhi (1948) and Martin Luther King (1968).\n\nSpeakers of this International Conference will be:\n\n\n\n\n\n"}
{"id": "11056386", "url": "https://en.wikipedia.org/wiki?curid=11056386", "title": "Internet censorship", "text": "Internet censorship\n\nInternet censorship is the control or suppression of what can be accessed, published, or viewed on the Internet enacted by regulators, or on their own initiative. Individuals and organizations may engage in self-censorship for moral, religious, or business reasons, to conform to societal norms, due to intimidation, or out of fear of legal or other consequences.\n\nThe extent of Internet censorship varies on a country-to-country basis. While most democratic countries have moderate Internet censorship, other countries go as far as to limit the access of information such as news and suppress discussion among citizens. Internet censorship also occurs in response to or in anticipation of events such as elections, protests, and riots. An example is the increased censorship due to the events of the Arab Spring. Other areas of censorship include copyrights, defamation, harassment, and obscene material.\n\nSupport for and opposition to Internet censorship also varies. In a 2012 Internet Society survey 71% of respondents agreed that \"censorship should exist in some form on the Internet\". In the same survey 83% agreed that \"access to the Internet should be considered a basic human right\" and 86% agreed that \"freedom of expression should be guaranteed on the Internet\". Perception of internet censorship in the US is largely based on the First Amendment and the right for expansive free speech and access to content without regard to the consequences. According to GlobalWebIndex, over 400 million people use virtual private networks to circumvent censorship or for increased user privacy.\n\nMany of the challenges associated with Internet censorship are similar to those for offline censorship of more traditional media such as newspapers, magazines, books, music, radio, television, and film. One difference is that national borders are more permeable online: residents of a country that bans certain information can find it on websites hosted outside the country. Thus censors must work to prevent access to information even though they lack physical or legal control over the websites themselves. This in turn requires the use of technical censorship methods that are unique to the Internet, such as site blocking and content filtering.\n\nViews about the feasibility and effectiveness of Internet censorship have evolved in parallel with the development of the Internet and censorship technologies:\n\nBlocking and filtering can be based on relatively static blacklists or be determined more dynamically based on a real-time examination of the information being exchanged. Blacklists may be produced manually or automatically and are often not available to non-customers of the blocking software. Blocking or filtering can be done at a centralized national level, at a decentralized sub-national level, or at an institutional level, for example in libraries, universities or Internet cafes. Blocking and filtering may also vary within a country across different ISPs. Countries may filter sensitive content on an ongoing basis and/or introduce temporary filtering during key time periods such as elections. In some cases the censoring authorities may surreptitiously block content to mislead the public into believing that censorship has not been applied. This is achieved by returning a fake \"Not Found\" error message when an attempt is made to access a blocked website.\n\nUnless the censor has total control over all Internet-connected computers, such as in North Korea (who employ an intranet that only privileged citizens can access), or Cuba, total censorship of information is very difficult or impossible to achieve due to the underlying distributed technology of the Internet. Pseudonymity and data havens (such as Freenet) protect free speech using technologies that guarantee material cannot be removed and prevents the identification of authors. Technologically savvy users can often find ways to access blocked content. Nevertheless, blocking remains an effective means of limiting access to sensitive information for most users when censors, such as those in China, are able to devote significant resources to building and maintaining a comprehensive censorship system.\n\nThe term \"splinternet\" is sometimes used to describe the effects of national firewalls. The verb \"rivercrab\" colloquially refers to censorship of the Internet, particularly in Asia.\n\nAs per Hoffmann, different methods are used to block certain websites or pages including DNS poisoning, blocking access to IPs, analyzing and filtering URLs, inspecting filter packets and resetting connections. \n\nInternet content is subject to technical censorship methods, including:\n\n\nTechnical censorship techniques are subject to both over- and under-blocking since it is often impossible to always block exactly the targeted content without blocking other permissible material or allowing some access to targeted material and so providing more or less protection than desired. An example is blocking an IP-address of a server that hosts multiple websites, which prevents access to all of the websites rather than just those that contain content deemed offensive.\n\nWriting in 2009 Ronald Deibert, professor of political science at the University of Toronto and co-founder and one of the principal investigators of the OpenNet Initiative, and, writing in 2011, Evgeny Morzov, a visiting scholar at Stanford University and an Op-Ed contributor to the \"New York Times\", explain that companies in the United States, Finland, France, Germany, Britain, Canada, and South Africa are in part responsible for the increasing sophistication of online content filtering worldwide. While the off-the-shelf filtering software sold by Internet security companies are primarily marketed to businesses and individuals seeking to protect themselves and their employees and families, they are also used by governments to block what they consider sensitive content.\n\nAmong the most popular filtering software programs is SmartFilter by Secure Computing in California, which was bought by McAfee in 2008. SmartFilter has been used by Tunisia, Saudi Arabia, Sudan, the UAE, Kuwait, Bahrain, Iran, and Oman, as well as the United States and the UK. Myanmar and Yemen have used filtering software from Websense. The Canadian-made commercial filter Netsweeper is used in Qatar, the UAE, and Yemen. The Canadian organization CitizenLab has reported that Sandvine and Procera products are used in Turkey and Egypt.\n\nOn 12 March 2013 in a \"Special report on Internet Surveillance\", Reporters Without Borders named five \"Corporate Enemies of the Internet\": Amesys (France), Blue Coat Systems (U.S.), Gamma (UK and Germany), Hacking Team (Italy), and Trovicor (Germany). The companies sell products that are liable to be used by governments to violate human rights and freedom of information. RWB said that the list is not exhaustive and will be expanded in the coming months.\n\nIn a U.S. lawsuit filed in May 2011, Cisco Systems is accused of helping the Chinese Government build a firewall, known widely as the Golden Shield, to censor the Internet and keep tabs on dissidents. Cisco said it had made nothing special for China. Cisco is also accused of aiding the Chinese government in monitoring and apprehending members of the banned Falun Gong group.\n\nMany filtering programs allow blocking to be configured based on dozens of categories and sub-categories such as these from Websense: \"abortion\" (pro-life, pro-choice), \"adult material\" (adult content, lingerie and swimsuit, nudity, sex, sex education), \"advocacy groups\" (sites that promote change or reform in public policy, public opinion, social practice, economic activities, and relationships), \"drugs\" (abused drugs, marijuana, prescribed medications, supplements and unregulated compounds), \"religion\" (non-traditional religions occult and folklore, traditional religions), ... The blocking categories used by the filtering programs may contain errors leading to the unintended blocking of websites. The blocking of DailyMotion in early 2007 by Tunisian authorities was, according to the OpenNet Initiative, due to Secure Computing wrongly categorizing DailyMotion as pornography for its SmartFilter filtering software. It was initially thought that Tunisia had blocked DailyMotion due to satirical videos about human rights violations in Tunisia, but after Secure Computing corrected the mistake access to DailyMotion was gradually restored in Tunisia.\n\nOrganizations such as the Global Network Initiative, the Electronic Frontier Foundation, Amnesty International, and the American Civil Liberties Union have successfully lobbied some vendors such as Websense to make changes to their software, to refrain from doing business with repressive governments, and to educate schools who have inadvertently reconfigured their filtering software too strictly. Nevertheless, regulations and accountability related to the use of commercial filters and services are often non-existent, and there is relatively little oversight from civil society or other independent groups. Vendors often consider information about what sites and content is blocked valuable intellectual property that is not made available outside the company, sometimes not even to the organizations purchasing the filters. Thus by relying upon out-of-the-box filtering systems, the detailed task of deciding what is or is not acceptable speech may be outsourced to the commercial vendors.\n\nInternet content is also subject to censorship methods similar to those used with more traditional media. For example:\n\nMost major web service operators reserve to themselves broad rights to remove or pre-screen content, sometimes without giving a specific list or only a vague general list of the reasons allowing the removal. The phrases \"at our sole discretion\", \"without prior notice\", and \"for other reasons\" are common in Terms of Service agreements. On 06 August 2018, for example, several major platforms, including YouTube and Facebook, executed a coordinated, permanent ban on all accounts and media associated with conservative talk show host, Alex Jones, and his popular media platform, InfoWars, citing \"hate speech\" and \"glorifying violence.\"\n\n\nInternet censorship circumvention is the processes used by technologically savvy Internet users to bypass the technical aspects of Internet filtering and gain access to the otherwise censored material. Circumvention is an inherent problem for those wishing to censor the Internet because filtering and blocking do not remove content from the Internet, but instead block access to it. Therefore, as long as there is at least one publicly accessible uncensored system, it will often be possible to gain access to the otherwise censored material. However circumvention may not be possible by non-tech-savvy users, so blocking and filtering remain effective means of censoring the Internet access of large numbers of users.\n\nDifferent techniques and resources are used to bypass Internet censorship, including proxy websites, virtual private networks, sneakernets, and circumvention software tools. Solutions have differing ease of use, speed, security, and risks. Most, however, rely on gaining access to an Internet connection that is not subject to filtering, often in a different jurisdiction not subject to the same censorship laws. According to GlobalWebIndex, over 400 million people use virtual private networks to circumvent censorship or for an increased level of privacy. The majority of circumvention techniques are not suitable for day to day use.\n\nThere are risks to using circumvention software or other methods to bypass Internet censorship. In some countries, individuals that gain access to otherwise restricted content may be violating the law and if caught can be expelled, fired, jailed, or subject to other punishments and loss of access.\n\nIn June 2011 the \"New York Times\" reported that the U.S. is engaged in a \"global effort to deploy 'shadow' Internet and mobile phone systems that dissidents can use to undermine repressive governments that seek to silence them by censoring or shutting down telecommunications networks.\"\n\nAnother way to circumvent Internet censorship is to physically go to an area where the Internet is not censored. In 2017 a so-called \"Internet refugee camp\" was established by IT workers in the village of Bonako, just outside an area of Cameroon where the Internet is regularly blocked.\n\nThere are several motives or rationales for Internet filtering: politics and power, social norms and morals, and security concerns. Protecting existing economic interests is an additional emergent motive for Internet filtering. In addition, networking tools and applications that allow the sharing of information related to these motives are themselves subjected to filtering and blocking. And while there is considerable variation from country to country, the blocking of web sites in a local language is roughly twice that of web sites available only in English or other international languages.\n\nCensorship directed at political opposition to the ruling government is common in authoritarian and repressive regimes. Some countries block web sites related to religion and minority groups, often when these movements represent a threat to the ruling regimes.\n\nExamples include:\n\nSocial filtering is censorship of topics that are held to be antithetical to accepted societal norms. In particular censorship of child pornography and to protect children enjoys very widespread public support and such content is subject to censorship and other restrictions in most countries.\n\nExamples include:\n\nMany organizations implement filtering as part of a defense in depth strategy to protect their environments from malware, and to protect their reputations in the event of their networks being used, for example, to carry out sexual harassment.\n\nInternet filtering related to threats to national security that targets the Web sites of insurgents, extremists, and terrorists often enjoys wide public support.\n\nExamples include:\n\nThe protection of existing economic interests is sometimes the motivation for blocking new Internet services such as low-cost telephone services that use Voice over Internet Protocol (VoIP). These services can reduce the customer base of telecommunications companies, many of which enjoy entrenched monopoly positions and some of which are government sponsored or controlled.\n\nAnti-copyright activists Christian Engström, Rick Falkvinge and Oscar Swartz have alleged that censorship of child pornography is being used as a pretext by copyright lobby organizations to get politicians to implement similar site blocking legislation against copyright-related piracy.\n\nExamples include:\n\nBlocking the intermediate tools and applications of the Internet that can be used to assist users in accessing and sharing sensitive material is common in many countries.\n\nExamples include:\n\nThe \"right to be forgotten\" is a concept that has been discussed and put into practice in the European Union. In May 2014, the European Court of Justice ruled against Google in \"Costeja\", a case brought by a Spanish man who requested the removal of a link to a digitized 1998 article in \"La Vanguardia\" newspaper about an auction for his foreclosed home, for a debt that he had subsequently paid. He initially attempted to have the article removed by complaining to Spain's data protection agency—\"Agencia Española de Protección de Datos\"—which rejected the claim on the grounds that it was lawful and accurate, but accepted a complaint against Google and asked Google to remove the results. Google sued in Spain and the lawsuit was transferred to the European Court of Justice. The court ruled in \"Costeja\" that search engines are responsible for the content they point to and thus, Google was required to comply with EU data privacy laws. It began compliance on 30 May 2014 during which it received 12,000 requests to have personal details removed from its search engine.\n\nIndex on Censorship claimed that \"\"Costeja\" ruling ... allows individuals to complain to search engines about information they do not like with no legal oversight. This is akin to marching into a library and forcing it to pulp books. Although the ruling is intended for private individuals it opens the door to anyone who wants to whitewash their personal history...The Court’s decision is a retrograde move that misunderstands the role and responsibility of search engines and the wider internet. It should send chills down the spine of everyone in the European Union who believes in the crucial importance of free expression and freedom of information.\"\n\nAs more people in more places begin using the Internet for important activities, there is an increase in online censorship, using increasingly sophisticated techniques. The motives, scope, and effectiveness of Internet censorship vary widely from country to country. The countries engaged in state-mandated filtering are clustered in three main regions of the world: east Asia, central Asia, and the Middle East/North Africa.\n\nCountries in other regions also practice certain forms of filtering. In the United States state-mandated Internet filtering occurs on some computers in libraries and K-12 schools. Content related to Nazism or Holocaust denial is blocked in France and Germany. Child pornography and hate speech are blocked in many countries throughout the world. In fact, many countries throughout the world, including some democracies with long traditions of strong support for freedom of expression and freedom of the press, are engaged in some amount of online censorship, often with substantial public support.\n\nInternet censorship in China is among the most stringent in the world. The government blocks Web sites that discuss the Dalai Lama, the 1989 crackdown on Tiananmen Square protesters, the banned spiritual practice Falun Gong, as well as many general Internet sites. The government requires Internet search firms and state media to censor issues deemed officially “sensitive,” and blocks access to foreign websites including Facebook, Twitter, and YouTube. According to a recent study, censorship in China is used to muzzle those outside government who attempt to spur the creation of crowds for any reason—in opposition to, in support of, or unrelated to the government. The government allows the Chinese people to say whatever they like about the state, its leaders, or their policies, because talk about any subject unconnected to collective action is not censored. The value that Chinese leaders find in allowing and then measuring criticism by hundreds of millions of Chinese people creates actionable information for them and, as a result, also for academic scholars and public policy analysts.\n\nThere are international bodies that oppose internet censorship, for example \"Internet censorship is open to challenge at the World Trade Organization (WTO) as it can restrict trade in online services, a forthcoming study argues\".\n\nDetailed country by country information on Internet censorship is provided by the OpenNet Initiative, Reporters Without Borders, Freedom House, and in the U.S. State Department Bureau of Democracy, Human Rights, and Labor's \"Human Rights Reports\". The ratings produced by several of these organizations are summarized in the Internet censorship by country and the Censorship by country articles.\n\nThrough 2010 the OpenNet Initiative had documented Internet filtering by governments in over forty countries worldwide. The level of filtering in 26 countries in 2007 and in 25 countries in 2009 was classified in the political, social, and security areas. Of the 41 separate countries classified, seven were found to show no evidence of filtering in all three areas (Egypt, France, Germany, India, Ukraine, United Kingdom, and United States), while one was found to engage in pervasive filtering in all three areas (China), 13 were found to engage in pervasive filtering in one or more areas, and 34 were found to engage in some level of filtering in one or more areas. Of the 10 countries classified in both 2007 and 2009, one reduced its level of filtering (Pakistan), five increased their level of filtering (Azerbaijan, Belarus, Kazakhstan, South Korea, and Uzbekistan), and four maintained the same level of filtering (China, Iran, Myanmar, and Tajikistan).\n\nThe \"Freedom on the Net\" reports from Freedom House provide analytical reports and numerical ratings regarding the state of Internet freedom for countries worldwide. The countries surveyed represent a sample with a broad range of geographical diversity and levels of economic development, as well as varying levels of political and media freedom. The surveys ask a set of questions designed to measure each country's level of Internet and digital media freedom, as well as the access and openness of other digital means of transmitting information, particularly mobile phones and text messaging services. Results are presented for three areas: Obstacles to Access, Limits on Content, and Violations of User Rights.\nThe results from the three areas are combined into a total score for a country (from 0 for best to 100 for worst) and countries are rated as \"Free\" (0 to 30), \"Partly Free\" (31 to 60), or \"Not Free\" (61 to 100) based on the totals.\n\nStarting in 2009 Freedom House has produced nine editions of the report.\nThere was no report in 2010. The reports generally cover the period from June through May.\n\nThe 2014 report assessed 65 countries and reported that 36 countries experienced a negative trajectory in Internet freedom since the previous year, with the most significant declines in Russia, Turkey and Ukraine. According to the report, few countries demonstrated any gains in Internet freedom, and the improvements that were recorded reflected less vigorous application of existing controls rather than new steps taken by governments to actively increase Internet freedom. The year's largest improvement was recorded in India, where restrictions to content and access were relaxed from what had been imposed in 2013 to stifle rioting in the northeastern states. Notable improvement was also recorded in Brazil, where lawmakers approved the bill Marco Civil da Internet, which contains significant provisions governing net neutrality and safeguarding privacy protection.\n\nOn 12 March 2013, Reporters Without Borders published a \"Special report on Internet Surveillance\". The report includes two new lists: \n\nThe five \"State Enemies of the Internet\" named in March 2013 are: Bahrain, China, Iran, Syria, and Vietnam.\n\nThe five \"Corporate Enemies of the Internet\" named in March 2013 are: Amesys (France), Blue Coat Systems (U.S.), Gamma International (UK and Germany), Hacking Team (Italy), and Trovicor (Germany).\n\nA poll of 27,973 adults in 26 countries, including 14,306 Internet users, was conducted for the BBC World Service by the international polling firm GlobeScan using telephone and in-person interviews between 30 November 2009 and 7 February 2010. GlobeScan Chairman Doug Miller felt, overall, that the poll showed that:\n\nFindings from the poll include:\n\nIn July and August 2012 the Internet Society conducted online interviews of more than 10,000 Internet users in 20 countries. Some of the results relevant to Internet censorship are summarized below.\n\nAmong the countries that filter or block online content, few openly admit to or fully disclose their filtering and blocking activities. States are frequently opaque and/or deceptive about the blocking of access to political information. For example:\n\nDuring the Arab Spring of 2011, media jihad (media struggle) was extensive. Internet and mobile technologies, particularly social networks such as Facebook and Twitter, played and are playing important new and unique roles in organizing and spreading the protests and making them visible to the rest of the world. An activist in Egypt tweeted, “we use Facebook to schedule the protests, Twitter to coordinate, and YouTube to tell the world”.\n\nThis successful use of digital media in turn led to increased censorship including the complete loss of Internet access for periods of time in Egypt and Libya in 2011. In Syria, the Syrian Electronic Army (SEA), an organization that operates with at least tacit support of the government, claims responsibility for defacing or otherwise compromising scores of websites that it contends spread news hostile to the Syrian government. SEA disseminates denial of service (DoS) software designed to target media websites including those of Al Jazeera, BBC News, Syrian satellite broadcaster Orient TV, and Dubai-based Al Arabiya TV.\n\nIn response to the greater freedom of expression brought about by the Arab Spring revolutions in countries that were previously subject to very strict censorship, in March 2011, Reporters Without Borders moved Tunisia and Egypt from its \"Internet enemies\" list to its list of countries \"under surveillance\" and in 2012 dropped Libya from the list entirely. At the same time, there were warnings that Internet censorship might increase in other countries following the events of the Arab Spring. However, in 2013, Libyan communication company LTT blocked the pornographic websites. It even blocked the family-filtered videos of ordinary websites like Dailymotion.\n\nOrganizations and projects:\n\nTopics:\n \"This article incorporates from the OpenNet Initiative web site.\"\n\n"}
{"id": "37637666", "url": "https://en.wikipedia.org/wiki?curid=37637666", "title": "Intuition and decision-making", "text": "Intuition and decision-making\n\nIntuition in the context of decision-making is defined as a “non-sequential information-processing mode.” It is distinct from insight (a much more protracted process) and can be contrasted with the deliberative style of decision-making. Intuition can influence judgment through either emotion or cognition, and there has been some suggestion that it may be a means of bridging the two. Individuals use intuition and more deliberative decision-making styles interchangeably, but there has been some evidence that people tend to gravitate to one or the other style more naturally. People in a good mood gravitate toward intuitive styles, while people in a bad mood tend to become more deliberative. The specific ways in which intuition actually influences decisions remain poorly understood. Snap judgments made possible by heuristics are sometimes identified as intuition.\n\nIntuitive decision-making can be described as the process by which information acquired through associated learning and stored in long-term memory is accessed unconsciously to form the basis of a judgment or decision. This information can be transferred through affect induced by exposure to available options, or through unconscious cognition. Intuition is based on the implicit knowledge available to the decision-maker. For example, owning a dog as a child imbues someone with implicit knowledge about canine behavior, which may then be channeled into a decision-making process as the emotion of fear or anxiety before taking a certain kind of action around an angry dog. Intuition is the mechanism by which this implicit knowledge is brought to the forefront of the decision-making process. Some definitions of intuition in the context of decision-making point to the importance of recognizing cues and patterns in one’s environment and then using them to improve one’s problem solving. Intuition in decision-making has been connected two assumptions: 1) Tacit decision - previous decisions are affecting and 2) Explicit decision - emotions are affecting.\nIntuition's effect on decision-making is distinct from insight, which requires time to mature. A month spent pondering a math problem may lead to a gradual understanding of the answer, even if one does not know where that understanding came from. Intuition, in contrast, is a more instantaneous, immediate understanding upon first being confronted with the math problem. Intuition is also distinct from implicit knowledge and learning, which inform intuition but are separate concepts. Intuition is the mechanism by which implicit knowledge is made available during an instance of decision-making.\n\nTraditional research often points to the role of heuristics in helping people make “intuitive” decisions. Those following the heuristics-and-biases school of thought developed by Amos Tversky and Daniel Kahneman believe that intuitive judgments are derived from an “informal and unstructured mode of reasoning” that ultimately does not include any methodical calculation. Tversky and Kahneman identify availability, representativeness, and anchoring/adjustment as three heuristics that influence many intuitive judgments made under uncertain conditions.\n\nThe heuristics-and-biases approach looks at patterns of biased judgments to distinguish heuristics from normative reasoning processes. Early studies supporting this approach associated each heuristic with a set of biases. These biases were “departures from the normative rational theory” and helped identify the underlying heuristics. Use of the availability heuristic, for example, leads to error whenever the memory retrieved is a biased recollection of actual frequency. This can be attributed to an individual’s tendency to remember dramatic cases. Heuristic processes are quick intuitive responses to basic questions such as frequency.\n\nSome researchers point to intuition as a purely affective phenomenon that demonstrates the ability of emotions to influence decision-making without cognitive mediation. This supports the dual processing theory of affect and cognition, under which conscious thought is not required for emotions to be experienced, but nevertheless positive conscious thoughts towards person's will have positive emotional affects on them. In studies comparing affect and cognition, some researchers have found that positive mood is associated with reliance on affective signals while negative mood is associated with more deliberative thought processes. Mood is thus considered a moderator in the strategic decisions people carry out. In a series of three studies, the authors confirmed that people in a positive mood faced with a card-based gambling task utilized intuition to perform better at higher-risk stages than people who were in a negative mood. Other theories propose that intuition has both cognitive and affective elements, bridging the gap between these two fundamentally different kinds of human information processing.\n\nIntuitive decision-making can be contrasted with deliberative decision-making, which is based on cognitive factors like beliefs, arguments, and reasons, commonly referred to as one's explicit knowledge. Intuitive decision-making is based on implicit knowledge relayed to the conscious mind at the point of decision through affect or unconscious cognition. Some studies also suggest that intuitive decision-making relies more on the mind's parallel processing functions, while deliberative decision-making relies more on sequential processing.\n\nAlthough people use intuitive and deliberative decision-making modes interchangeably, individuals value the decisions they make more when they are allowed to make them using their preferred style. This specific kind of regulatory fit is referred to as decisional fit. The emotions people experience after a decision is made tend to be more pleasant when the preferred style is used, regardless of the decision outcome. Some studies suggest that the mood with which the subject enters the decision-making process can also affect the style they choose to employ: sad people tend to be more deliberative, while people in a happy mood rely more on intuition.\n\nThe Preference for Intuition and Deliberation Scale developed by Coralie Bestch in 2004 measures propensity toward intuitiveness. The scale defines preference for intuition as tendency to use affect (“gut-feel”) as a basis for decision-making instead of cognition. The Myers-Briggs Type Indicator is also sometimes used.\n\nResearchers have also explored the efficacy of intuitive judgments and the debate on the function of intuition versus analysis in decisions that require specific expertise, as in management of organizations. In this context, intuition is interpreted as an “unconscious expertise” rather than a traditionally purely heuristic response. Research suggests that this kind of intuition is based on a “broad constellation of past experiences, knowledge, skills, perceptions and feelings.” The efficacy of intuitive decision-making in the management environment is largely dependent on the decision context and decision maker’s expertise. \n\nThe expertise-based intuition increases over time when the employee gets more experience regarding the organization worked for and by gathering domain-specific knowledge. In this context the so-called intuition is not just series of random guesses, but rather a process of combining expertise and know-how with the employee’s instincts. Intuitions can, however be difficult to prove to be right in terms of decision-making. It is in most situations likely, that decisions based on intuition are harder to justify than those that are based in rational analysis. Especially in the context of business and organizational decision-making, one should be able to justify their decisions, thus making them purely intuitively is often not possible. It is debated upon whether intuition is accurate, but evidence has been shown that under aforementioned conditions it can. When it comes to the decision maker him/herself, mainly two factors affect the effectiveness of intuitive decision-making. These factors have been found to be the amount of expertise the person has and the individuals processing style. \n\nA study of traders from the four largest investment banks in London looked at the role that emotion and expert intuition play in financial trading decisions. This study reported on the differences between how higher and lower performing traders incorporate intuition in their decision strategy, and attributed the success of some higher performing traders to their great disposition to reflect critically about their intuitions. This propensity to think critically about intuition and the source of those hunches served as a distinguishing factor between the higher and lower performing traders included in the study. While successful traders were more open to this critical introspection, lower performing traders were reported to rely on their feelings alone rather than further explore the affective influences for their decisions. Reflection on the origin of feelings by expert traders may be particularly salient given affect-as-information model, which holds that the impact of emotions on behavior is reduced or even disappears when the relevance of those emotions is explicitly called into question. It has been noted in a research, that intuition is used as a method of decision-making in the banking industry. Record shows that intuition is used in combination with pre-existing solution models and previous experiences. Participants of the research also reported to analyse their intuitive decisions afterwards and possibly altering them. \n\nTraditional literature attributes the role of judgment processes in risk perception and decision-making to cognition rather than emotion. However, more recent studies suggest a link between emotion and cognition as it relates to decision-making in high-risk environments. Studies of decision-making in high-risk environments suggest that individuals who self-identify as intuitive decision-makers tend to make faster decisions that imply greater deviation from risk neutrality than those who prefer the deliberative style. For example, risk-averse intuitive decision-makers will choose to not participate in a dangerous event more quickly than deliberative decision-makers, but will choose not to participate in more instances than their deliberative counterparts.\n\nStrategic decisions are usually made by the top management in the organizations. Usually strategic decisions also effect on the future of the organization. Rationality has been the guideline and also justified way to make decisions because they are based on facts. Intuition in strategic decision making is less examined and for example can be depending on a case be described as managers know-how, expertise or just a gut feeling, hunch.\n"}
{"id": "19348340", "url": "https://en.wikipedia.org/wiki?curid=19348340", "title": "Jenkins–Laporte doctrine", "text": "Jenkins–Laporte doctrine\n\nIn United States copyright law and jurisprudence established under the doctrine of \"stare decisis\" by the case of \"Netbula, LLC v. Symantec Corp.\", 516 F. Supp.2d 1137 (N.D.Cal. 2007) and related cases. The cases defined the boundaries of property rights and contractual rights in the licensing of digital works. It is so called because the cases were decided by two renowned American judges and leading jurists, former U.S. District Judge Martin Jenkins (now a Justice in California Courts of Appeal) and Magistrate Judge Elizabeth D. Laporte.\n\nThe basic principles of the doctrine can be summarized:\n\n(1) If an accused infringer did not see or agree to copy restriction, there was no infringement;\n\n(2) A \"one user on one computer\" restriction does not limit the scope of a software license, it's an independent contractual covenant;\n\n(3) A termination clause in the license agreement does not limit the scope of the license, it's an independent contractual covenant.\n\nThe ingenious observation Justice Jenkins made was that in a copyright action, although license is an affirmative defense to infringement, the \"plaintiff’s initial hurdle is proving the terms of the license.\" 516 F. Supp. 2d at 1151. The Jenkins–Laporte doctrine provides a legal foundation for circumvention of the exclusive rights provided by the Copyright Act, as the doctrine requires the copyright owner to prove the negative.\n"}
{"id": "143149", "url": "https://en.wikipedia.org/wiki?curid=143149", "title": "Jewish exodus from Arab and Muslim countries", "text": "Jewish exodus from Arab and Muslim countries\n\nThe Jewish exodus from Arab and Muslim countries, or Jewish exodus from Arab countries, was the departure, flight, expulsion, evacuation and migration of 850,000 Jews, primarily of Sephardi and Mizrahi background, from Arab and Muslim countries, mainly from 1948 to the early 1970s. The last major migration wave took place from Iran in 1979–80, as a consequence of the Islamic Revolution.\n\nA number of small-scale Jewish exoduses began in many Middle Eastern countries early in the 20th century with the only substantial aliyah coming from Yemen and Syria. Prior to the creation of Israel in 1948, approximately 800,000 Jews were living in lands that now make up the Arab world. Of these, just under two-thirds lived in the French and Italian-controlled North Africa, 15–20% in the Kingdom of Iraq, approximately 10% in the Kingdom of Egypt and approximately 7% in the Kingdom of Yemen. A further 200,000 lived in Pahlavi Iran and the Republic of Turkey.\n\nThe first large-scale exoduses took place in the late 1940s and early 1950s, primarily from Iraq, Yemen and Libya. In these cases over 90% of the Jewish population left, despite the necessity of leaving their property behind. Two hundred and sixty thousand Jews from Arab countries immigrated to Israel between 1948 and 1951, accounting for 56% of the total immigration to the newly founded state. Following the establishment of the State of Israel, a plan to accommodate 600,000 immigrants over four years, doubling the existing Jewish population, was submitted by the Israeli government to the Knesset. The plan, however, encountered mixed reactions; there were those within the Jewish Agency and government who opposed promoting a large-scale emigration movement among Jews whose lives were not in danger.\n\nLater waves peaked at different times in different regions over the subsequent decades. The peak of the exodus from Egypt occurred in 1956 following the Suez Crisis. The exodus from the other North African Arab countries peaked in the 1960s. Lebanon was the only Arab country to see a temporary increase in its Jewish population during this period, due to an influx of Jews from other Arab countries, although by the mid-1970s the Jewish community of Lebanon had also dwindled. Six hundred thousand Jews from Arab and Muslim countries had reached Israel by 1972. In total, of the 900,000 Jews who left Arab and other Muslim countries, 600,000 settled in the new state of Israel, and 300,000 migrated to France and the United States. The descendants of the Jewish immigrants from the region, known as Mizrahi Jews (\"Eastern Jews\") and Sephardic Jews (\"Spanish Jews\"), currently constitute more than half of the total population of Israel, partially as a result of their higher fertility rate. In 2009, only 26,000 Jews remained in Arab countries and Iran. and 26,000 in Turkey.\n\nThe reasons for the exodus included push factors, such as persecution, antisemitism, political instability, poverty and expulsion, together with pull factors, such as the desire to fulfill Zionist yearnings or find a better economic status and a secure home in Europe or the Americas. The history of the exodus has been politicized, given its proposed relevance to the historical narrative of the Arab–Israeli conflict. When presenting the history, those who view the Jewish exodus as analogous to the 1948 Palestinian exodus generally emphasize the push factors and consider those who left as refugees, while those who do not, emphasize the pull factors and consider them willing immigrants.\n\nAt the time of the Muslim conquests of the 7th century, ancient Jewish communities had existed in many parts of the Middle East and North Africa since Antiquity. Jews under Islamic rule were given the status of dhimmi, along with certain other pre-Islamic religious groups. As such, these groups were accorded certain rights as \"People of the Book\".\n\nDuring waves of persecution in Medieval Europe, many Jews found refuge in Muslim lands, though in other times and places, Jews fled persecution in Muslim lands and found refuge in Christian lands. Jews expelled from the Iberian Peninsula were invited to settle in various parts of the Ottoman Empire, where they would often form a prosperous model minority of merchants acting as intermediaries for their Muslim rulers.\n\nIn the 19th century, Francization of Jews in the French colonial North Africa, due to the work of organizations such as the Alliance Israelite Universelle and French policies such as the Algerian citizenship decree of 1870, resulted in a separation of the community from the local Muslims.\n\nThe French began the conquest of Algeria in 1830. The following century had a profound influence on the status of the Algerian Jews; following the 1870 \"Décret Crémieux\", they were elevated from the protected minority dhimmi status to French citizens of the colonial power. The decree began a wave of Pied-Noir-led anti-Jewish protests (such as the 1897 anti-Jewish riots in Oran), which the Muslim community did not participate in, to the disappointment of the European agitators.\n\nNeighbouring Husainid Tunisia began to come under European influence in the late 1860s and became a French protectorate in 1881. Since the 1837 accession of Ahmed Bey, and continued by his successor Muhammed Bey, Tunisia's Jews were elevated within Tunisia society with improved freedom and security, which was confirmed and safeguarded during the French protectorate. Around a third of Tunisian Jews took French citizenship during the protectorate.\n\nMorocco, which had remained independent during the 19th century, became a French protectorate in 1912. However, during less than half a century of colonization, the equilibrium between Jews and Muslims in Morocco was upset, and the Jewish community was again positioned between the colonisers and the Muslim majority. French penetration into Morocco between 1906 and 1912 created significant Morocco Muslim resentment, resulting in nationwide protests and military unrest. During the period a number of anti-European or anti-French protests extended to include anti-Jewish manifestations, such as in Casablanca, Oujda and Fes in 1907-08 and later in the 1912 Fes riots.\n\nThe situation in colonial Libya was similar; as for the French in the other North African countries, the Italian influence in Libya was welcomed by the Jewish community, increasing their separation from the non-Jewish Libyans.\n\nThe Alliance Israelite Universelle, founded in France in 1860, set up schools in Algeria, Morocco and Tunisia as early as 1863.\n\nDuring World War II, Morocco, Algeria, Tunisia and Libya came under Nazi or Vichy French occupation and their Jews were subject to various persecution. In Libya, the Axis powers established labor camps to which many Jews were forcibly deported. In other areas Nazi propaganda targeted Arab populations to incite them against British or French rule. National Socialist propaganda contributed to the transfer of racial antisemitism to the Arab world and is likely to have unsettled Jewish communities. An anti-Jewish riot took place in Casablanca in 1942 in the wake of Operation Torch, where a local mob attacked the Jewish mellah. (\"Mellah\" is the Moroccan name for a Jewish ghetto.) However, according to the Hebrew University of Jerusalem's Dr. Haim Saadon, \"Relatively good ties between Jews and Muslims in North Africa during World War II stand in stark contrast to the treatment of their co-religionists by gentiles in Europe.\"\n\nFrom 1943 until the mid 1960s, the American Jewish Joint Distribution Committee was an important foreign organization driving change and modernization in the North African Jewish community. It had initially become involved in the region whilst carrying out relief work during World War II.\n\nAs in Tunisia and Algeria, Moroccan Jews did not face large scale expulsion or outright asset confiscation or any similar government persecution during the period of exile, and Zionist agents were relatively allowed freedom of action to encourage emigration.\n\nIn Morocco the Vichy regime during World War II passed discriminatory laws against Jews; for example, Jews were no longer able to get any form of credit, Jews who had homes or businesses in European neighborhoods were expelled, and quotas were imposed limiting the percentage of Jews allowed to practice professions such as law and medicine to no more than two percent. King Mohammed V expressed his personal distaste for these laws, assuring Moroccan Jewish leaders that he would never lay a hand \"upon either their persons or property\". While there is no concrete evidence of him actually taking any actions to defend Morocco's Jews, it has been argued that he may have worked on their behalf behind the scenes.\n\nIn June 1948, soon after Israel was established and in the midst of the first Arab–Israeli war, violent anti-Jewish riots broke out in Oujda and Djerada, leading to deaths of 44 Jews. In 1948–49, after the massacres, 18,000 Moroccan Jews left the country for Israel. Later, however, the Jewish exodus from Morocco slowed to a few thousand a year. Through the early 1950s, Zionist organizations encouraged emigration, particularly in the poorer south of the country, seeing Moroccan Jews as valuable contributors to the Jewish State:\n\nIncidents of anti-Jewish violence continued through the 1950s, although French officials later stated that Moroccan Jews \"had suffered comparatively fewer troubles than the wider European population\" during the struggle for independence. In August 1953, riots broke out in the city of Oujda and resulted in the death of 4 Jews including an 11-year-old girl. In the same month French security forces prevented a mob from breaking into the Jewish Mellah of Rabat. In 1954, a nationalist event in the town of Petitjean (known today as Sidi Kacem) turned into an anti-Jewish riot and resulted in the death of 6 Jewish merchants from Marrakesh. However, according to Francis Lacoste, French Resident-General in Morocco, \"the ethnicity of the Petitjean victims was coincidental, terrorism rarely targeted Jews, and fears about their future were unwarranted.\" In 1955, a mob broke into the Jewish Mellah in Mazagan (known today as El Jadida) and caused its 1700 Jewish residents to flee to the European quarters of the city. The houses of some 200 Jews were too badly damaged during the riots for them to return.\nIn 1954, Mossad had established an undercover base in Morocco, sending agents and emissaries within a year to appraise the situation and organize continuous emigration. The operations were composed of five branches: self-defence, information and intelligence, illegal immigration, establishing contact, and public relations. Mossad chief Isser Harel visited the country in 1959 and 1960, reorganized the operations, and created a clandestine militia named the \"Misgeret\" (\"framework\").\n\nEmigration to Israel jumped from 8,171 persons in 1954 to 24,994 in 1955, increasing further in 1956. Between 1955 and independence in 1956, 60,000 Jews emigrated. On 7 April 1956, Morocco attained independence. Jews occupied several political positions, including three parliamentary seats and the cabinet position of Minister of Posts and Telegraphs. However, that minister, Leon Benzaquen, did not survive the first cabinet reshuffling, and no Jew was appointed again to a cabinet position. Although the relations with the Jewish community at the highest levels of government were cordial, these attitudes were not shared by the lower ranks of officialdom, which exhibited attitudes that ranged from traditional contempt to outright hostility. Morocco's increasing identification with the Arab world, and pressure on Jewish educational institutions to arabize and conform culturally added to the fears of Moroccan Jews. Between 1956 and 1961, emigration to Israel was prohibited by law; clandestine emigration continued, and a further 18,000 Jews left Morocco.\n\nOn 10 January 1961 the \"Egoz\", a Mossad-leased ship carrying Jews attempting to emigrate undercover, sank off the northern coast of Morocco. According to Tad Szulc, the Misgeret commander in Morocco, Alex Gattmon, decided to precipitate a crisis on the back of the tragedy, consistent with Mossad Director Isser Harel's scenario that \"a wedge had to be forced between the royal government and the Moroccan Jewish community and that anti-Hassan nationalists had to be used as leverage as well if a compromise over emigration was ever to be attained\". A pamphlet agitating for illegal emigration, supposedly by an underground Zionist organization, was printed by Mossad and distributed throughout Morocco, causing the government to \"hit the roof\". These events prompted King Mohammed V to allow Jewish emigration, and over the three following years, more than 70,000 Moroccan Jews left the country, primarily as a result of Operation Yachin.\n\nOperation Yachin was fronted by the New York-based Hebrew Immigrant Aid Society (HIAS), who financed approximately $50 million of costs. HIAS provided an American cover for underground Israeli agents in Morocco, whose functions included organizing emigration, arming of Jewish Moroccan communities for self-defense and negotiations with the Moroccan government. By 1963, the Moroccan Interior Minister Colonel Oufkir and Mossad chief Meir Amit agreed to swap Israeli training of Moroccan security services and some covert military assistance for intelligence on Arab affairs and continued Jewish emigration.\n\nBy 1967, only 50,000 Jews remained.\n\nThe 1967 Six-Day War led to increased Arab–Jewish tensions worldwide, including in Morocco, and significant Jewish emigration out of the country continued. By the early 1970s, the Jewish population of Morocco fell to 25,000; however, most of the emigrants went to France, Belgium, Spain, and Canada, rather than Israel.\n\nDespite their dwindling numbers, Jews continue to play a notable role in Morocco; the King retains a Jewish senior adviser, André Azoulay, and Jewish schools and synagogues receive government subsidies. Despite this, Jewish targets have sometimes been attacked (notably the 2003 bombing attacks on a Jewish community center in Casablanca), and there is sporadic anti-Semitic rhetoric from radical Islamist groups. Invitations from the late King Hassan II for Jews to return to Morocco have not been taken up by the people who had emigrated.\n\nAccording to Esther Benbassa, the migration of Jews from the North African countries was prompted by uncertainty about the future. In 1948, over 250,000–265,000 Jews lived in Morocco. By 2001 an estimated 5,230 remained.\n\nAs in Tunisia and Morocco, Algerian Jews did not face large scale expulsion or outright asset confiscation or any similar government persecution during the period of exile, and Zionist agents were relatively allowed freedom of action to encourage emigration.\n\nJewish emigration from Algeria was part of a wider ending of French colonial control and the related social, economic and cultural changes.\n\nThe Israeli government had been successful in encouraging Morocco and Tunisian Jews to emigrate to Israel, but were less so in Algeria. Despite offers of visa and economic subsidies, only 580 Jews moved from Algeria to Israel in 1954-55.\n\nEmigration peaked during the Algerian War of 1954–1962, during which thousands of Muslims, Christians and Jews left the country, particularly the Pied-Noir community. In 1956, Mossad agents worked underground to organize and arm the Jews of Constantine, who comprised approximately half the Jewish population of the country. In Oran, a Jewish counter-insurgency movement was thought to have been trained by former members of Irgun.\n\nAs of the last census in Algeria, taken on 1 June 1960, there were 1,050,000 non-Muslim civilians in Algeria (10 percent of the total population including 130,000.\" Algerian Jews). After Algeria became independent in 1962, about 800,000 \"Pieds-Noirs\" (including Jews) were evacuated to mainland France while about 200,000 chose to remain in Algeria. Of the latter, there were still about 100,000 in 1965 and about 50,000 by the end of the 1960s.\n\nAs the Algerian Revolution began to intensify in the late 1950s and early 1960s, most of Algeria's 140,000 Jews began to leave. The community had lived mainly in Algiers and Blida, Constantine, and Oran.\n\nAlmost all Jews of Algeria left upon independence in 1962, particularly as \"the Algerian Nationality Code of 1963 excluded non-Muslims from acquiring citizenship\", allowing citizenship only to those Algerians who had Muslim fathers and paternal grandfathers. Algeria's 140,000 Jews, who had French citizenship since 1870 (briefly revoked by Vichy France in 1940) left mostly for France, although some went to Israel.\n\nThe Algiers synagogue was consequently abandoned after 1994.\n\nJewish migration from North Africa to France led to the rejuvenation of the French Jewish community, which is now the third largest in the world.\n\nAs in Morocco and Algeria, Tunisian Jews did not face large scale expulsion or outright asset confiscation or any similar government persecution during the period of exile, and Zionist agents were relatively allowed freedom of action to encourage emigration.\n\nIn 1948, approximately 105,000 Jews lived in Tunisia. About 1,500 remain today, mostly in Djerba, Tunis, and Zarzis. Following Tunisia's independence from France in 1956, a number of anti-Jewish policies led to emigration, of which half went to Israel and the other half to France. After attacks in 1967, Jewish emigration both to Israel and France accelerated. There were also attacks in 1982, 1985, and most recently in 2002 when a bombing in Djerba took 21 lives (most of them German tourists) near the local synagogue, a terrorist attack claimed by Al-Qaeda.\n\nAccording to Maurice Roumani, a Libyan emigrant who was previously the Executive Director of WOJAC, the most important factors that influenced the Libyan Jewish community to emigrate were \"the scars left from the last years of the Italian occupation and the entry of the British Military in 1943 accompanied by the Jewish Palestinian soldiers\".\n\nZionist emissaries, \"shlichim\", has begun arriving in the early 1940s, with the intention to \"transform the community and transfer it to Palestine\". In 1943, Mossad LeAliyah Bet began to send emissaries to prepare the infrastructure for the emigration of the Libyan Jewish community.\n\nIn 1942, German troops fighting the Allies in North Africa occupied the Jewish quarter of Benghazi, plundering shops and deporting more than 2,000 Jews across the desert. Sent to work in labor camps, more than one-fifth of that group of Jews perished. At the time, most of the Jews were living in cities of Tripoli and Benghazi and there were smaller numbers in Bayda and Misrata. Following the allied victory at the Battle of El Agheila in December 1942, German and Italian troops were driven out of Libya. The British installed the Palestine Regiment in Cyrenaica, which later became the core of the Jewish Brigade, which was later also stationed in Tripolitania. The pro-Zionist soldiers encouraged the spread of Zionism throughout the local Jewish population\n\nFollowing the liberation of North Africa by allied forces, antisemitic incitements were still widespread. The most severe racial violence between the start of World War II and the establishment of Israel erupted in Tripoli in November 1945. Over a period of several days more than 130 Jews (including 36 children) were killed, hundreds were injured, 4,000 were displaced and 2,400 were reduced to poverty. Five synagogues in Tripoli and four in provincial towns were destroyed, and over 1,000 Jewish residences and commercial buildings were plundered in Tripoli alone. Gil Shefler writes that \"As awful as the pogrom in Libya was, it was still a relatively isolated occurrence compared to the mass murders of Jews by locals in Eastern Europe.\" The same year, violent anti-Jewish violence also occurred in Cairo, which resulted in 10 Jewish victims.\n\nIn 1948, about 38,000 Jews lived in Libya. The pogroms continued in June 1948, when 15 Jews were killed and 280 Jewish homes destroyed. In November 1948, a few months after the events in Tripoli, the American consul in Tripoli, Orray Taft Jr., reported that: \"There is reason to believe that the Jewish Community has become more aggressive as the result of the Jewish victories in Palestine. There is also reason to believe that the community here is receiving instructions and guidance from the State of Israel. Whether or not the change in attitude is the result of instructions or a progressive aggressiveness is hard to determine. Even with the aggressiveness or perhaps because of it, both Jewish and Arab leaders inform me that the inter-racial relations are better now than they have been for several years and that understanding, tolerance and cooperation are present at any top level meeting between the leaders of the two communities.\"\n\nImmigration to Israel began in 1949, following the establishment of a Jewish Agency for Israel office in Tripoli. According to Harvey E. Goldberg, \"a number of Libyan Jews\" believe that the Jewish Agency was behind the riots, given that the riots helped them achieve their goal. Between the establishment of the State of Israel in 1948 and Libyan independence in December 1951 over 30,000 Libyan Jews emigrated to Israel.\n\nOn 31 December 1958 a decree was issued by the President of the Executive Council of Tripolitania, which ordered the dissolution of the Jewish Community Council and the appointment of a Muslim commissioner nominated by the Government. A law issued in 1961 required Libyan citizenship for the possession and transfer of property in Libya, a requirement that was rejected to all but 6 Libyan Jewish individuals. Jews were banned from voting, attaining public offices and from serving in the army or in police.\n\nIn 1967, during the Six-Day War, the Jewish population of 4,000 was again subjected to riots in which 18 were killed, and many more injured. According to David Harris, the Executive Director of the Jewish advocacy organization AJC, the pro-Western Libyan government of King Idris I \"faced with a complete breakdown of law and order ... urged the Jews to leave the country temporarily\", permitting them each to take one suitcase and the equivalent of $50. In June and July over 4,000 traveled to Italy, where they were assisted by the Jewish Agency for Israel. 1,300 went on to Israel, 2,200 remained in Italy, and most of the rest went to the United States. A few scores remained in Libya and others managed to return between 1967 and 1969.\n\nIn 1970 the Libyan government issued new laws that confiscated all the assets of Libya's Jews, issuing in their stead 15-year bonds. However, when the bonds matured no compensation was paid. Libyan leader Muammar Gaddafi justified this on the grounds that \"the alignment of the Jews with Israel, the Arab nations' enemy, has forfeited their right to compensation.\"\n\nAlthough the main synagogue in Tripoli was renovated in 1999, it has not reopened for services. The last Jew in Libya, Esmeralda Meghnagi, died in February 2002. Israel is home to about 40,000 Jews of Libyan descent, who maintain unique traditions.\n\nThe British mandate over Iraq came to an end in June 1930, and in October 1932 the country became independent. The Iraqi government response to the demand of Assyrian autonomy (the Assyrians being the indigenous Eastern Aramaic-speaking Semitic descendants of the ancient Assyrians and Mesopotamians, and largely affiliated to the Assyrian Church of the East, Chaldean Catholic Church and Syriac Orthodox Church), turned into a bloody massacre of Assyrian villagers by the Iraqi army in August 1933. This event was the first sign to the Jewish community that minority rights were meaningless under Iraqi monarchy. King Faisal, known for his liberal policies, died in September 1933, and was succeeded by Ghazi, his nationalistic anti-British son. Ghazi began promoting Arab nationalist organizations, headed by Syrian and Palestinian exiles. With 1936–39 Arab revolt in Palestine, they were joined by rebels, such as the Grand Mufti of Jerusalem. The exiles preached pan-Arab ideology and fostered anti-Zionist propaganda.\n\nUnder Iraqi nationalists, Nazi propaganda began to infiltrate the country, as Nazi Germany was anxious to expand its influence in the Arab world. Dr. Fritz Grobba, who resided in Iraq since 1932, began to vigorously and systematically disseminate hateful propaganda against Jews. Among other things, Arabic translation of \"Mein Kampf\" was published and Radio Berlin had begun broadcasting in Arabic language. Anti-Jewish policies had been implemented since 1934, and the confidence of Jews was further shaken by the growing crisis in Palestine in 1936. Between 1936 and 1939 ten Jews were murdered and on eight occasions bombs were thrown on Jewish locations.\nIn 1941, immediately following the British victory in the Anglo-Iraqi War, riots known as the Farhud broke out in Baghdad in the power vacuum following the collapse of the pro-Axis government of Rashid Ali al-Gaylani while the city was in a state of instability. 180 Jews were killed and another 240 wounded; 586 Jewish-owned businesses were looted and 99 Jewish houses were destroyed.\n\nIn some accounts the Farhud marked the turning point for Iraq's Jews. Other historians, however, see the pivotal moment for the Iraqi Jewish community much later, between 1948–51, since Jewish communities prospered along with the rest of the country throughout most of the 1940s, and many Jews who left Iraq following the Farhud returned to the country shortly thereafter and permanent emigration did not accelerate significantly until 1950–51.\n\nEither way, the Farhud is broadly understood to mark the start of a process of politicization of the Iraqi Jews in the 1940s, primarily among the younger population, especially as a result of the impact it had on hopes of long term integration into Iraqi society. In the direct aftermath of the Farhud, many joined the Iraqi Communist Party in order to protect the Jews of Baghdad, yet they did not want to leave the country and rather sought to fight for better conditions in Iraq itself. At the same time the Iraqi government that had taken over after the Farhud reassured the Iraqi Jewish community, and normal life soon returned to Baghdad, which saw a marked betterment of its economic situation during World War II.\n\nShortly after the Farhud in 1941, Mossad LeAliyah Bet sent emissaries to Iraq to begin to organize emigration to Israel, initially by recruiting people to teach Hebrew and hold lectures on Zionism. In 1942, Shaul Avigur, head of Mossad LeAliyah Bet, entered Iraq undercover in order to survey the situation of the Iraqi Jews with respect to immigration to Israel. During the 1942–43, Avigur made four further trips to Baghdad to arrange the required Mossad machinery, including a radio transmitter for sending information to Tel Aviv, which remained in use for 8 years. In late 1942, one of the emissaries explained the size of their task of converting the Iraqi community to Zionism, writing that \"we have to admit that there is not much point in [organizing and encouraging emigration]. ... We are today eating the fruit of many years of neglect, and what we didn't do can't be corrected now through propaganda and creating one-day-old enthusiasm.\" It was not until 1947 that legal and illegal departures from Iraq to Israel began. Around 8,000 Jews left Iraq between 1919–48, with another 2,000 leaving between mid-1948 to mid-1950.\n\nIn 1948, there were approximately 150,000 Jews in Iraq. The community was concentrated in Baghdad and Basra.\n\nBefore United Nations Partition Plan for Palestine vote, the Iraq's prime minister Nuri al-Said told British diplomats that if the United Nations solution was not \"satisfactory\", \"severe measures should [would?] be taken against all Jews in Arab countries\". In a speech at the General Assembly Hall at Flushing Meadow, New York, on Friday, 28 November 1947, Iraq's Foreign Minister, Fadel Jamall, included the following statement: \"Partition imposed against the will of the majority of the people will jeopardize peace and harmony in the Middle East. Not only the uprising of the Arabs of Palestine is to be expected, but the masses in the Arab world cannot be restrained. The Arab–Jewish relationship in the Arab world will greatly deteriorate. There are more Jews in the Arab world outside of Palestine than there are in Palestine. In Iraq alone, we have about one hundred and fifty thousand Jews who share with Moslems and Christians all the advantages of political and economic rights. Harmony prevails among Moslems, Christians and Jews. But any injustice imposed upon the Arabs of Palestine will disturb the harmony among Jews and non-Jews in Iraq; it will breed inter-religious prejudice and hatred.\" On 19 February 1949, al-Said acknowledged the bad treatment that the Jews had been victims of in Iraq during the recent months. He warned that unless Israel would behave itself, events might take place concerning the Iraqi Jews. Al-Said's threats had no impact at the political level on the fate of the Jews but were widely published in the media.\n\nIn 1948, the country was placed under martial law, and the penalties for Zionism were increased. Courts martial were used to intimidate wealthy Jews, Jews were again dismissed from civil service, quotas were placed on university positions, Jewish businesses were boycotted (E. Black, p. 347) and Shafiq Ades (one of the most important anti-Zionist Jewish businessmen in the country) was arrested and publicly hanged for allegedly selling goods to Israel, shocking the community (Tripp, 123). The Jewish community general sentiment was that if a man as well connected and powerful as Shafiq Ades could he eliminated by the state, other Jews would not be protected any longer.\n\nAdditionally, like most Arab League states, Iraq forbade any legal emigration of its Jews on the grounds that they might go to Israel and could strengthen that state. At the same time, increasing government oppression of the Jews fueled by anti-Israeli sentiment together with public expressions of antisemitism created an atmosphere of fear and uncertainty.\n\nLike most Arab League states, Iraq initially forbade the emigration of its Jews after the 1948 war on the grounds that allowing them to go to Israel would strengthen that state. However, by 1949 Jews were escaping Iraq at about a rate of 1,000 a month. At the time, the British believed that the Zionist underground was agitating in Iraq in order to assist US fund-raising and to \"offset the bad impression caused by the Jewish attitudes to Arab refugees\".\n\nThe Iraqi government took in only 5,000 of the c.700,000 Palestinians who became refugees in 1948–49 and refused to submit to American and British pressure to admit more. In January 1949, the pro-British Iraqi Prime Minister Nuri al-Said discussed the idea of deporting Iraqi Jews to Israel with British officials, who explained that such a proposal would benefit Israel and adversely affect Arab countries. According to Meir-Glitzenstein, such suggestions were \"not intended to solve either the problem of the Palestinian Arab refugees or the problem of the Jewish minority in Iraq, but to torpedo plans to resettle Palestinian Arab refugees in Iraq\". In July 1949 the British government proposed to Nuri al-Said a population exchange in which Iraq would agree to settle 100,000 Palestinian refugees in Iraq; Nuri stated that if a fair arrangement could be agreed, \"the Iraqi government would permit a voluntary move by Iraqi Jews to Palestine.\" The Iraqi-British proposal was reported in the press in October 1949. On 14 October 1949 Nuri Al Said raised the exchange of population concept with the economic mission survey. At the Jewish Studies Conference in Melbourne in 2002, Philip Mendes summarised the effect of al-Saids vacillations on Jewish expulsion as: \"In addition, the Iraqi Prime Minister Nuri as-Said tentatively canvassed and then shelved the possibility of expelling the Iraqi Jews, and exchanging them for an equal number of Palestinian Arabs. \"\n\nIn March 1950 Iraq reversed their earlier ban on Jewish emigration to Israel and passed a law of one-year duration allowing Jews to emigrate on the condition of relinquishing their Iraqi citizenship. According to Abbas Shiblak, many scholars state that this was a result of British, American and Israeli political pressure on Tawfiq al-Suwaidi's government, with some studies suggesting there were secret negotiations. According to Ian Black, the Iraqi government was motivated by \"economic considerations, chief of which was that almost all the property of departing Jews reverted to the state treasury\" and also that \"Jews were seen as a restive and potentially troublesome minority that the country was best rid of.\" Israel mounted an operation called \"Operation Ezra and Nehemiah\" to bring as many of the Iraqi Jews as possible to Israel.\n\nThe Zionist movement at first tried to regulate the amount of registrants until issues relating to their legal status were clarified. Later, it allowed everyone to register. Two weeks after the law went into force, the Iraqi interior minister demanded a CID investigation over why Jews were not registering. A few hours after the movement allowed registration, four Jews were injured in a bomb attack at a café in Baghdad.\n\nImmediately following the March 1950 Denaturalisation Act, the emigration movement faced significant challenges. Initially, local Zionist activists forbade the Iraqi Jews from registering for emigration with the Iraqi authorities, because the Israeli government was still discussing absorption planning. However, on 8 April, a bomb exploded in a Jewish cafe in Baghdad, and a meeting of the Zionist leadership later that day agreed to allow registration without waiting for the Israeli government; a proclamation encouraging registration was made throughout Iraq in the name of the State of Israel. However, at the same time immigrants were also entering Israel from Poland and Romania, countries in which Prime Minister David Ben-Gurion assessed there was a risk that the communist authorities would soon \"close their gates\", and Israel therefore delayed the transportation of Iraqi Jews. As a result, by September 1950, while 70,000 Jews had registered to leave, many selling their property and losing their jobs, only 10,000 had left the country. According to Esther Meir-Glitzenstein, \"The thousands of poor Jews who had left or been expelled from the peripheral cities, and who had gone to Baghdad to wait for their opportunity to emigrate, were in an especially bad state. They were housed in public buildings and were being supported by the Jewish community. The situation was intolerable.\" The delay became a significant problem for the Iraqi government of Nuri al-Said (who replaced Tawfiq al-Suwaidi in mid-September 1950), as the large number of Jews \"in limbo\" created problems politically, economically and for domestic security. \"Particularly infuriating\" to the Iraqi government was the fact that the source of the problem was the Israeli government.\n\nAs a result of these developments, al-Said was determined to drive the Jews out of his country as quickly as possible. On 21 August 1950 al-Said threatened to revoke the license of the company transporting the Jewish exodus if it did not fulfill its daily quota of 500 Jews, and in September 1950, he summoned a representative of the Jewish community and warned the Jewish community of Baghdad to make haste; otherwise, he would take the Jews to the borders himself. On 12 October 1950, Nuri al-Said summoned a senior official of the transport company and made similar threats, justifying the expulsion of Jews by the number of Palestinian Arabs fleeing from Israel.\n\nTwo months before the law expired, after about 85,000 Jews had registered, a bombing campaign began against the Jewish community of Baghdad. The Iraqi government convicted and hanged a number of suspected Zionist agents for perpetrating the bombings, but the issue of who was responsible remains a subject of scholarly dispute. All but a few thousand of the remaining Jews then registered for emigration. In all, about 120,000 Jews left Iraq.\n\nAccording to Gat, it is highly likely that one of Nuri as-Said's motives in trying to expel large numbers of Jews was the desire to aggravate Israel's economic problems (he had declared as such to the Arab world), although Nuri was well aware that the absorption of these immigrants was the policy on which Israel based its future. The Iraqi Minister of Defence told the U.S ambassador that he had reliable evidence that the emigrating Jews were involved in activities injurious to the state and were in contact with communist agents.\n\nBetween April 1950 and June 1951, Jewish targets in Baghdad were struck five times. Iraqi authorities then arrested 3 Jews, claiming they were Zionist activists, and sentenced two — Shalom Salah Shalom and Yosef Ibrahim Basri—to death. The third man, Yehuda Tajar, was sentenced to 10 years in prison. In May and June 1951, arms caches were discovered that allegedly belonged to the Zionist underground, allegedly supplied by the Yishuv after the Farhud of 1941. There has been much debate as to whether the bombs were planted by the Mossad to encourage Iraqi Jews to emigrate to Israel or if they were planted by Muslim extremists to help drive out the Jews. This has been the subject of lawsuits and inquiries in Israel.\n\nThe emigration law was to expire in March 1951, one year after the law was enacted. On 10 March 1951, 64,000 Iraqi Jews were still waiting to emigrate, the government enacted a new law blocking the assets of Jews who had given up their citizenship, and extending the emigration period.\n\nThe bulk of the Jews leaving Iraq did so via Israeli airlifts named Operation Ezra and Nehemiah with special permission from the Iraqi government.\n\nIn 1969, about 50 of the Jews who remained were executed; 11 were publicly executed after show trials and hundred thousand Iraqis marched past the bodies in a carnival-like atmosphere.\n\nBy 2003, there were only about 100 left of this previously thriving community.\n\nAlthough there was a small indigenous community, most Jews in Egypt in the early twentieth century were recent immigrants to the country, who did not share the Arabic language and culture. Many were members of the highly diverse Mutamassirun community, which included other groups such as Greeks, Armenians, Syrian Christians and Italians, in addition to the British and French colonial powers. Until the late 1930s, the Jews, both indigenous and new immigrants, like other minorities tended to apply for foreign citizenship in order to benefit from a foreign protection. The Egyptian government made it very difficult for non-Muslim foreigners to become naturalized. The poorer Jews, most of them indigenous and Oriental Jews, were left stateless, although they were legally eligible for Egyptian nationality. The drive to Egyptianize public life and the economy harmed the minorities, but the Jews had more strikes against them than the others. In the agitation against the Jews of the late thirties and the forties, the Jew has been seen as an enemy The Jews were attacked because of their real or alleged links to Zionism. Jews were not discriminated because of their religion or race, like in Europe, but for political reasons.\n\nThe Egyptian Prime Minister Mahmoud an-Nukrashi Pasha told the British ambassador:\n\"All Jews were potential Zionists [and] ... anyhow all Zionists were Communists.\"\nOn 24 November 1947, the head of the Egyptian delegation to the United Nations General Assembly, Muhammad Hussein Heykal Pasha, said, \"the lives of 1,000,000 Jews in Moslem countries would be jeopardized by the establishment of a Jewish state.\" On 24 November 1947, Dr Heykal Pasha said: \"if the U.N decide to amputate a part of Palestine in order to establish a Jewish state, ... Jewish blood will necessarily be shed elsewhere in the Arab world ... to place in certain and serious danger a million Jews. Mahmud Bey Fawzi (Egypt) said: \"Imposed partition was sure to result in bloodshed in Palestine and in the rest of the Arab world.\"\n\nThe exodus of the foreign mutamassirun (\"Egyptianized\") community, which included a significant number of Jews, began following the First World War, and by the end of the 1960s the entire mutamassirun was effectively eliminated. According to Andrew Gorman, this was primarily a result of the \"decolonization process and the rise of Egyptian nationalism\".\n\nThe exodus of Egyptian Jews was impacted by the 1945 Anti-Jewish Riots in Egypt, though such emigration was not significant as the government stamped the violence out and the Egyptian Jewish community leaders were supportive of King Farouk. In 1948, approximately 75,000 Jews lived in Egypt. Around 20,000 Jews left Egypt during 1948–49 following the events of the 1948 Arab–Israeli War (including the 1948 Cairo bombings). A further 5,000 left between 1952–56, in the wake of the Egyptian Revolution of 1952 and later the false flag Lavon Affair. The Israeli invasion as part of the Suez Crisis caused a significant upsurge in emigration, with 14,000 Jews leaving in less than six months between November 1956 and March 1957, and 19,000 further emigrating over the next decade.\n\nIn October 1956, when the Suez Crisis erupted, the position of the mutamassirun, including the Jewish community, was significantly impacted.\n\n1,000 Jews were arrested and 500 Jewish businesses were seized by the government. A statement branding the Jews as \"Zionists and enemies of the state\" was read out in the mosques of Cairo and Alexandria. Jewish bank accounts were confiscated and many Jews lost their jobs. Lawyers, engineers, doctors and teachers were not allowed to work in their professions. Thousands of Jews were ordered to leave the country. They were allowed to take only one suitcase and a small sum of cash, and forced to sign declarations \"donating\" their property to the Egyptian government. Foreign observers reported that members of Jewish families were taken hostage, apparently to insure that those forced to leave did not speak out against the Egyptian government. Jews were expelled or left, forced out by the anti-Jewish feeling in Egypt. Some 25,000 Jews, almost half of the Jewish community left, mainly for Europe, the United States, South America and Israel, after being forced to sign declarations that they were leaving voluntarily, and agreed with the confiscation of their assets. Similar measures were enacted against British and French nationals in retaliation for the invasion. By 1957 the Jewish population of Egypt had fallen to 15,000.\n\nIn 1960, the American embassy in Cairo wrote of Egyptian Jews that: \"There is definitely a strong desire among most Jews to emigrate, but this is prompted by the feeling that they have limited opportunity, or from fear for the future, rather than by any direct or present tangible mistreatment at the hands of the government.\"\n\nIn 1967, Jews were detained and tortured, and Jewish homes were confiscated. Following the Six Day War, the community practically ceased to exist, with the exception of several dozens of elderly Jews.\n\nThe Yemeni exodus began in 1881, seven months prior to the more well-known First Aliyah from Eastern Europe. The exodus came about as a result of European Jewish investment in the Mutasarrifate of Jerusalem, which created jobs for labouring Jews alongside local Muslim labour thereby providing an economic incentive for emigration. This was aided by the reestablishment of Ottoman control over the Yemen Vilayet allowing freedom of movement within the empire, and the opening of the Suez canal, which reduced the cost of travelling considerably. Between 1881 and 1948, 15,430 Jews had immigrated to Palestine legally.\n\nIn 1942, prior to the formulation of the One Million Plan, David Ben-Gurion described his intentions with respect to such potential policy to a meeting of experts and Jewish leaders, stating that \"It is a mark of great failure by Zionism that we have not yet eliminated the Yemen exile [diaspora].\"\n\nIf one includes Aden, there were about 63,000 Jews in Yemen in 1948. Today, there are about 200 left. In 1947, rioters killed at least 80 Jews in Aden, a British colony in southern Yemen. In 1948 the new Zaydi Imam Ahmad bin Yahya unexpectedly allowed his Jewish subjects to leave Yemen, and tens of thousands poured into Aden. The Israeli government's Operation Magic Carpet evacuated around 44,000 Jews from Yemen to Israel in 1949 and 1950. Emigration continued until 1962, when the civil war in Yemen broke out. A small community remained until 1976, though it has mostly immigrated from Yemen since. In March 2016, the Jewish population in Yemen was estimated to be about 50.\n\nThe area now known as Lebanon and Syria was the home of one of the oldest Jewish communities in the world, dating back to at least 300 BCE.\n\nIn November 1945, fourteen Jews were killed in anti-Jewish riots in Tripoli. Unlike in other Arab countries, the Lebanese Jewish community did not face grave peril during the 1948 Arab–Israel War and was reasonably protected by governmental authorities. Lebanon was also the only Arab country that saw a post-1948 increase in its Jewish population, principally due to the influx of Jews coming from Syria and Iraq.\n\nIn 1948, there were approximately 24,000 Jews in Lebanon. The largest communities of Jews in Lebanon were in Beirut, and the villages near Mount Lebanon, Deir al Qamar, Barouk, Bechamoun, and Hasbaya. While the French mandate saw a general improvement in conditions for Jews, the Vichy regime placed restrictions on them. The Jewish community actively supported Lebanese independence after World War II and had mixed attitudes toward Zionism.\n\nHowever, negative attitudes toward Jews increased after 1948, and, by 1967, most Lebanese Jews had emigrated—to Israel, the United States, Canada, and France. In 1971, Albert Elia, the 69-year-old Secretary-General of the Lebanese Jewish community, was kidnapped in Beirut by Syrian agents and imprisoned under torture in Damascus, along with Syrian Jews who had attempted to flee the country. A personal appeal by the U.N. High Commissioner for Refugees, Prince Sadruddin Aga Khan, to the late President Hafez al-Assad failed to secure Elia's release.\n\nThe remaining Jewish community was particularly hard hit by the civil war in Lebanon, and by the mid-1970s, the community collapsed. In the 1980s, Hezbollah kidnapped several Lebanese Jewish businessmen, and in the 2004 elections, only one Jew voted in the municipal elections. There are now only between 20 and 40 Jews living in Lebanon.\n\nIn 1947, rioters in Aleppo burned the city's Jewish quarter and killed 75 people. As a result, nearly half of the Jewish population of Aleppo opted to leave the city, initially to neighbouring Lebanon.\n\nIn 1948, there were approximately 30,000 Jews in Syria. In 1949, following defeat in the Arab–Israeli War, the CIA-backed March 1949 Syrian coup d'état installed Husni al-Za'im as the President of Syria. Za'im permitted the emigration of large numbers of Syrian Jews, and 5,000 left to Israel.\n\nThe subsequent Syrian governments placed severe restrictions on the Jewish community, including barring emigration. Over the next few years, many Jews managed to escape, and the work of supporters, particularly Judy Feld Carr, in smuggling Jews out of Syria, and bringing their plight to the attention of the world, raised awareness of their situation. Although the Syrian government attempted to stop Syrian Jews from exporting their assets, the American consulate in Damascus noted in 1950 that \"the majority of Syrian Jews have managed to dispose of their property and to emigrate to Lebanon, Italy, and Israel\". In November 1954, the Syrian government lifted its ban on Jewish emigration.\n\nIn March 1964, the Syrian government issued a decree prohibiting Jews from traveling more than three miles from the limits of their hometowns. During 1967, riots broke out in Damascus and Aleppo. Jews were allowed to leave their homes only for few hours daily. Many Jews found impossible to pursue their business venture because the larger community was boycotting their products. In 1972 demonstrations were held by 1000 Syrian Jews in Damascus, after four woman were killed as they attempted to flee Syria. The protest surprised Syrian authorities, who closely monitored Jewish community, eavesdropped on their telephone conversations, and tampered with their mail.\n\nFollowing the Madrid Conference of 1991, the United States put pressure on the Syrian government to ease its restrictions on Jews, and during Passover in 1992, the government of Syria began granting exit visas to Jews on condition that they did not emigrate to Israel. At that time, the country had several thousand Jews. The majority left for the United States—most to join the large Syrian Jewish community in South Brooklyn, New York—although some went to France and Turkey, and those who wanted to go to Israel were brought there in a two-year covert operation.\n\nIn 2004, the Syrian government attempted to establish better relations with its emigrants, and a delegation of a dozen Jews of Syrian origin visited Syria in the spring of that year. As of December 2014, only 17 Jews remain in Syria, according to Rabbi Avraham Hamra; nine men and eight women, all over 60 years of age.\n\nThe Tel Or village was established in 1930 (or 1932) in Transjordan in the vicinity of Naharayim hydroelectric power plant. The village of Tel Or was the only Jewish village in Transjordan at the time. The village was built as housing compound for operation crews of the power plant and their families, being predominantly Jewish. Tel Or had existed until its depopulation in 1948 during the Arab–Israeli War, when it was overran by the Transjordanian forces. The families of the employees were evacuated in April 1948, leaving behind only workers with Jordanian ID cards. Following a prolonged battle between Yishuv forces and the Transjordanian Arab Legion in the area, the residents of Tel Or were given an ultimatum to surrender or leave the village. The village of Tel Or was shortly abandoned by the residents, who fled to Yishuv-controlled areas to the West of Jordan.\n\nIn 1948 during the Arab–Israeli War, Jerusalem's Jewish Quarter population of about 2,000 Jews was besieged, and forced to leave en masse. The defenders surrendered on 28 May 1948. Colonel Abdullah el Tell, local commander of the Jordanian Arab Legion, with whom Mordechai Weingarten negotiated the surrender terms, described the destruction of the Jewish Quarter, in his Memoirs (Cairo, 1959):\n\nThe Jordanian commander is reported to have told his superiors: \"For the first time in 1,000 years not a single Jew remains in the Jewish Quarter. Not a single building remains intact. This makes the Jews' return here impossible.\" The Hurva Synagogue, originally built in 1701, was blown up by the Jordanian Arab Legion. During the nineteen years of Jordanian rule, a third of the Jewish Quarter's buildings were demolished. According to a complaint Israel made to the United Nations, all but one of the thirty-five Jewish houses of worship in the Old City were destroyed. The synagogues were razed or pillaged and stripped and their interiors used as hen-houses or stables.\n\nIn the wake of the 1948 war, the Red Cross accommodated Palestinian refugees in the depopulated and partly destroyed Jewish Quarter. This grew into the Muaska refugee camp managed by UNRWA, which housed refugees from 48 locations now in Israel. Over time many poor non-refugees also settled in the camp. Conditions became unsafe for habitation due to lack of maintenance and sanitation. Jordan had planned transforming the quarter into a park, but neither UNRWA nor the Jordanian government wanted the negative international response that would result if they demolished the old Jewish houses. In 1964 a decision was made to move the refugees to a new camp constructed near Shuafat. Most of the refugees refused to move, since it would mean losing their livelihood, the market and the tourists, as well as reducing their access to the holy sites. In the end, many of the refugees were moved to Shuafat by force during 1965 and 1966.\n\nBahrain's tiny Jewish community, mostly the Jewish descendants of immigrants who entered the country in the early 20th century from Iraq, numbered 600 in 1948. In the wake of 29 November 1947 U.N. Partition vote, demonstrations against the vote in the Arab world were called for 2–5 December. The first two days of demonstrations in Bahrain saw rock throwing against Jews, but on 5 December, mobs in the capital of Manama looted Jewish homes and shops, destroyed the synagogue, beat any Jews they could find, and murdered one elderly woman.\n\nOver the next few decades, most left for other countries, especially Britain; as of 2006 only 36 remained.\n\nExodus of Iran's Jews refers to the emigration of Persian Jews from Pahlavy Iran in 1950s and later migration wave from Iran during and after the Iranian Revolution of 1979, during which the community of 80,000 dropped to less than 20,000. The migration of Persian Jews after Iranian Revolution is mostly attributed to fear of religious persecution, economic hardships and insecurity after the deposition of the Shah regime and consequent domestic violence and the Iran–Iraq War.\n\nWhile Iranian constitution generally respects minority rights of non-Muslims (though there are some forms of discrimination), the strong anti-Zionist policy of the Islamic Republic of Iran created a tense and uncomfortable situation for Iranian Jews, who became vulnerable for accusation on alleged collaboration with Israel.\n\nMost of 80,000-strong Iranian Jewish community exited Iran between 1978 and early 1980s. In total, more than 80% of Iranian Jews fled or migrated from the country between 1979 and 2006. A small Jewish community of 7–10 thousands still resides in Iran as a protected minority.\n\nWhen the Republic of Turkey was established in 1923, Aliyah was not particularly popular among Turkish Jewry; migration from Turkey to Palestine was minimal in the 1920s.\n\nDuring 1923-1948, approximately 7,300 Jews emigrated from Turkey to Palestine. After the 1934 Thrace pogroms following the 1934 Turkish Resettlement Law, immigration to Palestine increased; it is estimated that 521 Jews left for Palestine from Turkey in 1934 and 1,445 left in 1935. Immigration to Palestine was organized by the Jewish Agency and the Palestine Aliya Anoar Organization. The Varlık Vergisi, a capital tax established in 1942, was also significant in encouraging emigration from Turkey to Palestine; between 1943 and 1944, 4,000 Jews emigrated.\"\n\nThe Jews of Turkey reacted very favorably to the creation of the State of Israel. Between 1948 and 1951, 34,547 Jews immigrated to Israel, nearly 40% of the Jewish population at the time. Immigration was stunted for several months in November 1948, when Turkey suspended migration permits as a result of pressure from Arab countries.\n\nIn March 1949, the suspension was removed when Turkey officially recognized Israel, and emigration continued, with 26,000 emigrating within the same year. The migration was entirely voluntary, and was primary driven by economic factors given the majority of emigrants were from the lower classes. In fact, the migration of Jews to Israel is the second largest mass emigration wave out of Turkey, the first being the population exchange between Greece and Turkey.\n\nAfter 1951, emigration of Jews from Turkey to Israel slowed materially.\n\nIn the mid 1950s, 10% of those who had moved to Israel returned to Turkey. A new synagogue, the Neve Şalom, was constructed in Istanbul in 1951. Generally, Turkish Jews in Israel have integrated well into society and are not distinguishable from other Israelis. However, they maintain their Turkish culture and connection to Turkey, and are strong supporters of close relations between Israel and Turkey.\n\nEven though historically speaking populist antisemitism was rarer in the Ottoman Empire and Anatolia than in Europe, since the establishment of the state of Israel in 1948, there has been a rise in antisemitism. On the night of 6–7 September 1955, the Istanbul pogrom was unleashed. Although primarily aimed at the city's Greek population, the Jewish and Armenian communities of Istanbul were also targeted to a degree. The caused damage was mainly material - more than 4,000 shops and 1,000 houses belonging to Greeks, Armenians and Jews were destroyed - but it deeply shocked minorities throughout the country\n\nSince 1986, increased attacks on Jewish targets throughout Turkey impacted the security of the community, and urged many to emigrate. The Neve Shalom Synagogue in Istanbul has been attacked by Islamic militants three times. On 6 September 1986, Arab terrorists gunned down 22 Jewish worshippers and wounded 6 during \"Shabbat\" services at Neve Shalom. This attack was blamed on the Palestinian militant Abu Nidal. In 1992, the Lebanon-based Shi'ite Muslim group of Hezbollah carried out a bombing against the Synagogue, but nobody was injured. The Synagogue was hit again during the 2003 Istanbul bombings alongside the Bet Israel Synagogue, killing 20 and injuring over 300 people, both Jews and Muslims alike.\n\nWith the increasing anti-Israeli and anti-Jewish attitudes in modern Turkey, the country's Jewish community while still believed to be the largest among Muslim countries, declined from about 26,000 in 2010 to about 17,000-18,000 in 2016.\n\nThe Afghan Jewish community declined from about 40,000 in the early 20th Century to 5,000 by 1934.\n\nIn 1929, the Soviet press reported a pogrom in Afghanistan.\n\nIn 1933, following the assassination of Mohammed Nadir Shah, King of Afghanistan, Afghan Jews were declared non-citizens and many Jews in Afghanistan were expelled from their homes and robbed of their property. Jews continued living in major cities such as Kabul and Herat, under restrictions on work and trade. In 1935, the Jewish Telegraph Agency reported that \"Ghetto rules\" had been imposed on Afghan Jews, requiring them to wear particular clothes, that Jewish women stay out of markets, that no Jews live within certain distances of mosques and that Jews did not ride horses.\n\nFrom 1935 to 1941, under Prime Minister Mohammad Hashim Khan (uncle of the King) Germany was the most influential country in Afghanistan. The Nazis regarded the Afghans (like the Iranians) as Aryans. In 1938, it was reported that Jews were only allowed to work as shoe-polishers.\n\nContact with Afghanistan was difficult at this time and with many Jews facing persecution around the world, reports reached the outside world after a delay and were rarely researched thoroughly. \nJews were allowed to emigrate in 1951 and most moved to Israel and the United States. By 1969, some 300 remained, and most of these left after the Soviet invasion of 1979, leaving 10 Afghan Jews in 1996, most of them in Kabul. More than 10,000 Jews of Afghan descent presently live in Israel. Over 200 families of Afghan Jews live in New York City.\n\nAt one point it was reported that two Jews were left in Afghanistan and that they did not talk to each other.\n\nAt the time of Pakistani independence in 1947, some 1,300 Jews remained in Karachi, many of them Bene Israel Jews, observing Sephardic Jewish rites. A small Ashkenazi population was also present in the city. Some Karachi streets still bear names that hark back to a time when the Jewish community was more prominent; such as Ashkenazi Street, Abraham Reuben Street (named after the former member of the Karachi Municipal Corporation), Ibn Gabirol Street, and Moses Ibn Ezra Street—although some streets have been renamed, they are still locally referred to by their original names. A small Jewish graveyard still exists in the vast Mewa Shah Graveyard near the shrine of a Sufi saint. The neighbourhood of Baghdadi in Lyari Town is named for the Baghdadi Jews who once lived there. A community of Bukharan Jews was also found in the city of Peshawar, where many buildings in the old city feature a Star of David as exterior decor as a sign of the Hebrew origins of its owners. Members of the community settled in the city as merchants as early as the 17th century, although the bulk arrived as refugees fleeing the advance of the Russian Empire into Bukhara, and later the Russian Revolution in 1917. Today, there are virtually no Jewish communities remaining in Karachi or Peshawar.\n\nThe exodus of Jews from Pakistan to Bombay and other cities in India came just prior to the creation of Israel in 1948, when anti-Israeli sentiments rose. By 1953, fewer than 500 Jews were reported to reside in all of Pakistan. Anti-Israeli sentiment and violence often flared during ensuing conflicts in the Middle East, resulting in a further movement of Jews out of Pakistan. Presently, a large number of Jews from Karachi live in the city of Ramla in Israel.\n\nThe Jewish community in Sudan was concentrated in the capital Khartoum, and had been established in the late 19th century. By the middle of the 20th century the community included some 350 Jews, mainly of Sephardic background, who had constructed a synagogue and a Jewish school. Between 1948 and 1956, some members of the community left the country, and it finally ceased to exist by the early 1960s.\n\nThe Jewish population in East Bengal was 200 at the time of the Partition of British India in 1947. They included a Baghdadi Jewish merchant community that settled in Dhaka during the 17th-century. A prominent Jew in East Pakistan was Mordecai Cohen, who was a Bengali and English newsreader on East Pakistan Television. By the late 1960s, much of the Jewish community had left for Calcutta.\n\nIn 1948, there were between 758,000 and 881,000 Jews (see table below) living in communities throughout the Arab world. Today, there are fewer than 8,600. In some Arab states, such as Libya, which was about 3% Jewish, the Jewish community no longer exists; in other Arab countries, only a few hundred Jews remain.\n\nOf the nearly 900,000 Jewish emigrants, approximately 680,000 emigrated to Israel and 235,000 to France; the remainder went to other countries in Europe as well as to the Americas. About two thirds of the exodus was from the North Africa region, of which Morocco's Jews went mostly to Israel, Algeria's Jews went mostly to France, and Tunisia's Jews departed for both countries.\n\nThe majority of Jews in Arab countries eventually immigrated to the modern State of Israel. Hundreds of thousands of Jews were temporarily settled in the numerous immigrant camps throughout the country. Those were later transformed into ma'abarot (transit camps), where tin dwellings were provided to house up to 220,000 residents. The ma'abarot existed until 1963. The population of transition camps was gradually absorbed and integrated into Israeli society. Many of the North African and Middle-Eastern Jews had a hard time adjusting to the new dominant culture, change of lifestyle and there were claims of discrimination.\n\nFrance was also a major destination and about 50% (300,000 people) of modern French Jews have roots from North Africa. In total, it is estimated that between 1956 and 1967, about 235,000 North African Jews from Algeria, Tunisia and Morocco immigrated to France due to the decline of the French Empire and following the Six-Day War.\n\nThe United States was a destination of many Egyptian, Lebanese and Syrian Jews.\n\nAdvocacy groups acting on behalf of Jews from Arab countries include:\n\nWOJAC, JJAC and JIMENA have been active in recent years in presenting their views to various governmental bodies in the US, Canada and UK, among others, as well as appearing before the United Nations Human Rights Council.\n\nIn 2003, was introduced into the House of Representatives by pro-Israel congresswoman Ileana Ros-Lehtinen. In 2004 simple resolutions and were issued into the House of Representatives and Senate by Jerrold Nadler and Rick Santorum, respectively. In 2007 simple resolutions and were issued into the House of Representatives and Senate. The resolutions had been written together with lobbyist group JJAC, whose founder Stanley Urman described the resolution in 2009 as \"perhaps our most significant accomplishment\" The House of Representatives resolution was sponsored by Jerrold Nadler, who followed the resolutions in 2012 with House Bill . The 2007–08 resolutions proposed that any \"comprehensive Middle East peace agreement to be credible and enduring, the agreement must address and resolve all outstanding issues relating to the legitimate rights of all refugees, including Jews, Christians and other populations displaced from countries in the Middle East\", and encourages President Barack Obama and his administration to mention Jewish and other refugees when mentioning Palestinian refugees at international forums. The 2012 bill, which was moved to committee, proposed to recognize the plight of \"850,000 Jewish refugees from Arab countries\", as well as other refugees, such as Christians from the Middle East, North Africa, and the Persian Gulf.\n\nJerrold Nadler explained his view in 2012 that \"the suffering and terrible injustices visited upon Jewish refugees in the Middle East needs to be acknowledged. It is simply wrong to recognize the rights of Palestinian refugees without recognizing the rights of nearly 1 million Jewish refugees who suffered terrible outrages at the hands of their former compatriots.\" Critics have suggested the campaign is simply an anti-Palestinian \"tactic\", which Michael Fischbach explains as \"a tactic to help the Israeli government deflect Palestinian refugee claims in any final Israeli–Palestinian peace deal, claims that include Palestinian refugees' demand for the 'right of return' to their pre-1948 homes in Israel.\"\n\nThe issue of comparison of the Jewish exodus with the Palestinian exodus was raised by the Israeli Foreign Ministry as early as 1961.\n\nIn 2012, a special campaign on behalf of the Jewish refugees from Arab countries was established and gained momentum. The campaign urges the creation of an international fund that would compensate both Jewish and Palestinian Arab refugees, and would document and research the plight of Jewish refugees from Arab countries. In addition, the campaign plans to create a national day of recognition in Israel to remember the 850,000 Jewish refugees from Arab countries, as well as to build a museum that would document their history, cultural heritage, and collect their testimony.\n\nOn 21 September 2012, a special event was held at the United Nations to highlight the issue of Jewish refugees from Arab countries. Israeli ambassador Ron Prosor asked the United Nations to \"establish a center of documentation and research\" that would document the \"850,000 untold stories\" and \"collect the evidence to preserve their history\", which he said was ignored for too long. Israeli Deputy Foreign Minister Danny Ayalon said that \"We are 64 years late, but we are not too late.\" Diplomats from approximately two dozen countries and organizations, including the United States, the European Union, Germany, Canada, Spain, and Hungary attended the event. In addition, Jews from Arab countries attended and spoke at the event.\n\nIn response to the Palestinian Nakba narrative, the term \"Jewish Nakba\" is sometimes used to refer to the persecution and expulsion of Jews from Arab countries in the years and decades following the creation of the State of Israel. Israeli columnist Ben Dror Yemini, himself a Mizrahi Jew, wrote:\n\nProfessor Ada Aharoni, chairman of The World Congress of the Jews from Egypt, argues in an article entitled \"What about the Jewish Nakba?\" that exposing the truth about the expulsion of the Jews from Arab states could facilitate a genuine peace process, since it would enable Palestinians to realize they were not the only ones who suffered, and thus their sense of \"victimization and rejectionism\" will decline.\n\nAdditionally, Canadian MP and international human rights lawyer Irwin Cotler has referred to the \"double Nakba\". He criticizes the Arab states' rejectionism of the Jewish state, their subsequent invasion to destroy the newly formed nation, and the punishment meted out against their local Jewish populations:\n\nIraqi-born Ran Cohen, a former member of the Knesset, said: \"I have this to say: I am not a refugee. I came at the behest of Zionism, due to the pull that this land exerts, and due to the idea of redemption. Nobody is going to define me as a refugee.\" Yemeni-born Yisrael Yeshayahu, former Knesset speaker, Labor Party, stated: \"We are not refugees. [Some of us] came to this country before the state was born. We had messianic aspirations.\" And Iraqi-born Shlomo Hillel, also a former speaker of the Knesset, Labor Party, claimed: \"I do not regard the departure of Jews from Arab lands as that of refugees. They came here because they wanted to, as Zionists.\"\n\nHistorian Tom Segev stated: \"Deciding to emigrate to Israel was often a very personal decision. It was based on the particular circumstances of the individual's life. They were not all poor, or 'dwellers in dark caves and smoking pits'. Nor were they always subject to persecution, repression or discrimination in their native lands. They emigrated for a variety of reasons, depending on the country, the time, the community, and the person.\"\n\nIraqi-born Israeli historian Avi Shlaim, speaking of the wave of Iraqi Jewish migration to Israel, concludes that, even though Iraqi Jews were \"victims of the Israeli-Arab conflict\", Iraqi Jews aren't refugees, saying \"nobody expelled us from Iraq, nobody told us that we were unwanted.\" He restated that case in a review of Martin Gilbert's book, \"In Ishmael's House\".\n\nYehuda Shenhav has criticized the analogy between Jewish emigration from Arab countries and the Palestinian exodus. He also says \"The unfounded, immoral analogy between Palestinian refugees and Mizrahi immigrants needlessly embroils members of these two groups in a dispute, degrades the dignity of many Mizrahi Jews, and harms prospects for genuine Jewish-Arab reconciliation.\" He has stated that \"the campaign's proponents hope their efforts will prevent conferral of what is called a 'right of return' on Palestinians, and reduce the size of the compensation Israel is liable to be asked to pay in exchange for Palestinian property appropriated by the state guardian of 'lost' assets.\"\n\nIsraeli historian Yehoshua Porath has rejected the comparison, arguing that while there is a superficial similarity, the ideological and historical significance of the two population movements are entirely different. Porath points out that the immigration of Jews from Arab countries to Israel, expelled or not, was the \"fulfilment of a national dream\". He also argues that the achievement of this Zionist goal was only made possible through the endeavors of the Jewish Agency's agents, teachers, and instructors working in various Arab countries since the 1930s. Porath contrasts this with the Palestinian Arabs' flight of 1948 as completely different. He describes the outcome of the Palestinian's flight as an \"unwanted national calamity\" that was accompanied by \"unending personal tragedies\". The result was \"the collapse of the Palestinian community, the fragmentation of a people, and the loss of a country that had in the past been mostly Arabic-speaking and Islamic. \"\n\nAlon Liel, a former director-general of the Foreign Ministry says that many Jews escaped from Arab countries, but he does not call them \"Refugees\" since his definition for the term \"Refugee\" is different from UNWRA's definition.\n\nOn 21 September 2012, at a United Nations conference, the issue of Jewish refugees from Arab countries was criticized by Hamas spokesman, Sami Abu Zuhri, who stated that the Jewish refugees from Arab countries were in fact responsible for the Palestinian displacement and that \"those Jews are criminals rather than refugees.\" In regard to the same conference, Palestinian politician Hanan Ashrawi has argued that Jews from Arab lands are not refugees at all and that Israel is using their claims in order to counterbalance to those of Palestinian refugees against it. Ashrawi said that \"If Israel is their homeland, then they are not 'refugees'; they are emigrants who returned either voluntarily or due to a political decision.\"\n\nIn Libya, Iraq and Egypt many Jews lost vast portions of their wealth and property as part of the exodus because of severe restrictions on moving their wealth out of the country.\n\nIn the North Africa, the situation was more complex. For example, in Morocco emigrants were not allowed to take more than $60 worth of Moroccan currency with them, although generally they were able to sell their property prior to leaving, and some were able to work around the currency restrictions by exchanging cash into jewelry or other portable valuables. This led some scholars to speculate the North African Jewish population, comprising two thirds of the exodus, on the whole did not suffer large property losses. However, opinions on this differ.\n\nYemeni Jews were usually able to sell what property they possessed prior to departure, although not always at market rates.\n\nVarious estimates of the value of property abandoned by the Jewish exodus have been published, with wide variety in the quoted figures from a few billion dollars to hundreds of billions.\n\nThe World Organization of Jews from Arab Countries (WOJAC) estimated in 2006, that Jewish property abandoned in Arab countries would be valued at more than $100 billion, later revising their estimate in 2007 to $300 billion. They also estimated Jewish-owned real-estate left behind in Arab lands at 100,000 square kilometers (four times the size of the state of Israel).\n\nThe type and extent of linkage between the Jewish exodus from Arab countries and the 1948 Palestinian exodus has also been the source of controversy. Advocacy groups have suggested that there are strong ties between the two processes and some of them even claim that decoupling the two issues is unjust.\n\nHolocaust restitution expert Sidney Zabludoff, writing for the Israeli-advocacy group Jerusalem Center for Public Affairs, suggests that the losses sustained by the Jews who fled Arab countries since 1947 amounts to $700m at period prices based on an estimated per capita wealth of $700 multiplied by one million refugees, equating to $6 billion today, assuming that the entire exodus left all of their wealth behind.\n\nThe official position of the Israeli government is that Jews from Arab countries are considered refugees, and it considers their rights to property left in countries of origin as valid and existent.\n\nIn 2008, the Orthodox Sephardi party, Shas, announced its intention to seek compensation for Jewish refugees from Arab states.\n\nIn 2009, Israeli lawmakers introduced a bill into the Knesset to make compensation for Jews from Arab and Muslim countries an integral part of any future peace negotiations by requiring compensation on behalf of current Jewish Israeli citizens, who were expelled from Arab countries after Israel was established in 1948 and leaving behind a significant amount of valuable property. In February 2010, the bill passed its first reading. The bill was sponsored by MK Nissim Ze'ev (Shas) and follows a resolution passed in the United States House of Representatives in 2008, calling for refugee recognition to be extended to Jews and Christians similar to that extended to Palestinians in the course of Middle East peace talks.\n\n\n\nNorth Africa\n\nEgypt\n\nIraq\n\nYemen\n\nOther\n\n"}
{"id": "1371224", "url": "https://en.wikipedia.org/wiki?curid=1371224", "title": "Labeling theory", "text": "Labeling theory\n\nLabeling theory is the theory of how the self-identity and behavior of individuals may be determined or influenced by the terms used to describe or classify them. It is associated with the concepts of self-fulfilling prophecy and stereotyping. Labeling theory holds that deviance is not inherent to an act, but instead focuses on the tendency of majorities to negatively label minorities or those seen as deviant from standard cultural norms. The theory was prominent during the 1960s and 1970s, and some modified versions of the theory have developed and are still currently popular. A stigma is defined as a powerfully negative label that changes a person's self-concept and social identity.\n\nLabeling theory is closely related to social-construction and symbolic-interaction analysis. Labeling theory was developed by sociologists during the 1960s. Howard Saul Becker's book \"Outsiders\" was extremely influential in the development of this theory and its rise to popularity.\n\nLabeling theory had its origins in \"Suicide\", a book by French sociologist Émile Durkheim. He found that crime is not so much a violation of a penal code as it is an act that outrages society. He was the first to suggest that deviant labeling satisfies that function and satisfies society's need to control the behavior.\n\nAs a contributor to American Pragmatism and later a member of the Chicago School, George Herbert Mead posited that the self is socially constructed and reconstructed through the interactions which each person has with the community. The labeling theory suggests that people obtain labels from how others view their tendencies or behaviors. Each individual is aware of how they are judged by others because he or she has attempted many different roles and functions in social interactions and has been able to gauge the reactions of those present.\n\nThis theoretically builds a subjective conception of the self, but as others intrude into the reality of that individual's life, this represents objective data which may require a re-evaluation of that conception depending on the authoritativeness of the others' judgment. Family and friends may judge differently from random strangers. More socially representative individuals such as police officers or judges may be able to make more globally respected judgments. If deviance is a failure to conform to the rules observed by most of the group, the reaction of the group is to label the person as having offended against their social or moral norms of behavior. This is the power of the group: to designate breaches of their rules as deviant and to treat the person differently depending on the seriousness of the breach. The more differential the treatment, the more the individual's self-image is affected.\n\nLabeling theory concerns itself mostly not with the normal roles that define our lives, but with those very special roles that society provides for deviant behavior, called deviant roles, stigmatic roles, or social stigma. A social role is a set of expectations we have about a behavior. Social roles are necessary for the organization and functioning of any society or group. We expect the postman, for example, to adhere to certain fixed rules about how he does his job. \"Deviance\" for a sociologist does not mean morally wrong, but rather behavior that is condemned by society. Deviant behavior can include both criminal and non-criminal activities.\n\nInvestigators found that deviant roles powerfully affect how we perceive those who are assigned those roles. They also affect how the deviant actor perceives himself and his relationship to society. The deviant roles and the labels attached to them function as a form of social stigma. Always inherent in the deviant role is the attribution of some form of \"pollution\" or difference that marks the labeled person as different from others. Society uses these stigmatic roles to them to control and limit deviant behavior: \"If you proceed in this behavior, you will become a member of that group of people.\"\n\nWhether a breach of a given rule will be stigmatized will depend on the significance of the moral or other tenet it represents. For example, adultery may be considered a breach of an informal rule or it may be criminalized depending on the status of marriage, morality, and religion within the community. In most Western countries, adultery is not a crime. Attaching the label \"adulterer\" may have some unfortunate consequences but they are not generally severe. But in some Islamic countries, zina is a crime and proof of extramarital activity may lead to severe consequences for all concerned.\n\nStigma is usually the result of laws enacted against the behavior. Laws protecting slavery or outlawing homosexuality, for instance, will over time form deviant roles connected with those behaviors. Those who are assigned those roles will be seen as less human and reliable. Deviant roles are the sources of negative stereotypes, which tend to support society's disapproval of the behavior.\n\nOne of the founders of social interactionism, George Herbert Mead focused on the internal processes of how the mind constructs one's self-image. In \"Mind, Self, and Society\" (1934), he showed how infants come to know \"persons\" first and only later come to know \"things\". According to Mead, thought is both a \"social\" and \"pragmatic\" process, based on the model of two persons discussing how to solve a problem. Mead's central concept is the self, the part of an individual's personality composed of self-awareness and self-image. Our self-image is, in fact, constructed of ideas about what we think others are thinking about us. While we make fun of those who visibly talk to themselves, they have only failed to do what the rest of us do in keeping the internal conversation to ourselves. Human behavior, Mead stated, is the result of meanings created by the social interaction of conversation, both real and imaginary.\n\nThomas J. Scheff, Professor, Emeritus, Dept of Sociology, UCSB, published the book Being Mentally III: A Sociological Theory (1966).\nAccording to Scheff society has perceptions about people with mental illness. He stated that everyone in the society learns the stereotyped imagery of mental disorder through ordinary social interaction. From childhood, people learn to use terms like “crazy”, “loony”, “nuts” and associated them with them with disturbed behaviors. The media also contributes to this bias against mentally ill patients by associating them with violent crimes. Scheff believes that mental illness is a label given to a person who has a behavior which is away from the social norms of the society and is treated as a social deviance in the society. Once a person is given a label of “mentally ill person”, s/he receives a set of uniform responses from the society, which are generally negative in nature. These responses from the society compel to the person to take the role of a “mentally ill person” as s/he starts internalizing the same. When the individual takes on the role of being mentally ill as her/his central identity, s/he becomes a stable mental ill person. Chronic mental illness is thus a social role and the societal reaction is the most determinant of one’s entry into this role of chronically ill. \nAccording to Scheff hospitalization of a mentally ill person further reinforces this social role and forces her/him to take this role as her/his self-perception. Once the person is institutionalized for mental disorder, s/he has been publicly labeled as “crazy” and forced to become a member of a deviant social group. It then becomes difficult for a deviant person to return to her/his former level of functioning as the status of ‘patient’ causes unfavorable evaluations by self and by others.\n\nFrank Tannenbaum is considered the grandfather of labeling theory. His \"Crime and Community\" (1938), describing the social interaction involved in crime, is considered a pivotal foundation of modern criminology. While the criminal differs little or not at all from others in the original impulse to first commit a crime, social interaction accounts for continued acts that develop a pattern of interest to sociologists.\n\nTannenbaum first introduced the idea of 'tagging'. While conducting his studies with delinquent youth, he found that a negative tag or label often contributed to further involvement in delinquent activities. This initial tagging may cause the individual to adopt it as part of their identity. The crux of Tannenbaum's argument is that the greater the attention placed on this label, the more likely the person is to identify themselves as the label.\n\nKerry Townsend writes about the revolution in criminology caused by Tannenbaum's work:\n\nIt was sociologist Edwin Lemert (1951) who introduced the concept of \"secondary deviance\". The primary deviance is the experience connected to the overt behavior, say drug addiction and its practical demands and consequences. Secondary deviation is the role created to deal with society's condemnation of the behavior of a person.\n\nWith other sociologists of his time, Lemert saw how all deviant acts are social acts, a result of the cooperation of society. In studying drug addiction, Lemert observed a very powerful and subtle force at work. Besides the physical addiction to the drug and all the economic and social disruptions it caused, there was an intensely intellectual process at work concerning one's own identity and the justification for the behavior: \"I do these things because I am this way.\"\n\nThere might be certain subjective and personal motives that might first lead a person to drink or shoplift. But the activity itself tells us little about the person's self-image or its relationship to the activity. Lemert writes: \"His acts are repeated and organized subjectively and transformed into active roles and become the social criteria for assigning status...When a person begins to employ his deviant behavior or a role based on it as a means of defense, attack, or adjustment to the overt and covert problems created by the consequent societal reaction to him, his deviation is secondary\".\n\nWhile it was Lemert who introduced the key concepts of labeling theory, it was Howard Becker who became their successor. He first began describing the process of how a person adopts a deviant role in a study of dance musicians, with whom he once worked. He later studied the identity formation of marijuana smokers. This study was the basis of his \"Outsiders\" published in 1963. This work became the manifesto of the labeling theory movement among sociologists. In his opening, Becker writes:\n\nWhile society uses the stigmatic label to justify its condemnation, the deviant actor uses it to justify his actions. He wrote: \"To put a complex argument in a few words: instead of the deviant motives leading to the deviant behavior, it is the other way around, the deviant behavior in time produces the deviant motivation.\"\n\nBecker's immensely popular views were also subjected to a barrage of criticism, most of it blaming him for neglecting the influence of other biological, genetic effects and personal responsibility. In a later 1973 edition of his work, he answered his critics. He wrote that sociologists, while dedicated to studying society, are often careful not to look too closely. Instead, he wrote: \"I prefer to think of what we study as \"collective action.\" People act, as Mead and Blumer have made clearest, \"together\". They do what they do with an eye on what others have done, are doing now, and may do in the future. One tries to fit his own line of action into the actions of others, just as each of them likewise adjusts his own developing actions to what he sees and expects others to do.\"\n\nFrancis Cullen reported in 1984 that Becker was probably too generous with his critics. After 20 years, his views, far from being supplanted, have been corrected and absorbed into an expanded \"structuring perspective\".\n\nIn \"The Colonizer and the Colonized\" (1965) Albert Memmi described the deep psychological effects of the social stigma created by the domination of one group by another. He wrote:\n\nIn \"Dominated Man\" (1968), Memmi turned his attention to the motivation of stigmatic labeling: it justifies the exploitation or criminalization of the victim. He wrote:\n\nCentral to stigmatic labeling is the attribution of an inherent fault: It is as if one says, \"There must be something wrong with these people. Otherwise, why would we treat them so badly?\"\n\nPerhaps the most important contributor to labeling theory was Erving Goffman, President of the American Sociological Association, and one of America's most cited sociologists. His most popular books include \"The Presentation of Self in Everyday Life\", \"Interaction Ritual\", and \"Frame Analysis\".\n\nHis most important contribution to labeling theory, however, was \"Stigma: Notes on the Management of Spoiled Identity\" published in 1963. Unlike other authors who examined the process of adopting a deviant identity, Goffman explored the ways people managed that identity and controlled information about it.\n\nAmong Goffman's key insights were the following:\n\nIn \"On Becoming Deviant\" (1969), sociologist David Matza gives the most vivid and graphic account of the process of adopting a deviant role. The acts of authorities in outlawing a proscribed behavior can have two effects, keeping most out of the behavior, but also offering new opportunities for creating deviant identities. He says the concept of \"affinity\" does little to explain the dedication to the behavior. \"Instead, it may be regarded as a natural biographical tendency born of personal and social circumstances that suggests but hardly compels a direction or movement.\" What gives force to that movement is the development of a new identity. He writes:\n\nAs an application of phenomenology, the theory hypothesizes that the labels applied to individuals influence their behavior, particularly the application of negative or stigmatizing labels (such as \"criminal\" or \"felon\") promote deviant behavior, becoming a self-fulfilling prophecy, i.e. an individual who is labeled has little choice but to conform to the essential meaning of that judgment. Consequently, labeling theory postulates that it is possible to prevent social deviance via a limited social shaming reaction in \"labelers\" and replacing moral indignation with tolerance. Emphasis is placed on the rehabilitation of offenders through an alteration of their label(s). Related prevention policies include client empowerment schemes, mediation and conciliation, victim-offender forgiveness ceremonies (restorative justice), restitution, reparation, and alternatives to prison programs involving diversion. Labeling theory has been accused of promoting impractical policy implications, and criticized for failing to explain society's most serious offenses.\n\nSome offenses, including the use of violence, are universally recognized as wrong. Hence, labeling either habitual criminals or those who have caused serious harm as \"criminals\" is not constructive. Society may use more \"specific\" labels such as \"murderer\" or \"rapist\" or \"child abuser\" to demonstrate more clearly after the event the extent of its disapproval, but there is a slightly mechanical determinism in asserting that the application of a label will invariably modify the behavior of the one labeled. Further, if one of the functions of the penal system is to reduce recidivism, applying a long-term label may cause prejudice against the offender, resulting in the inability to maintain employment and social relationships.\n\nThe social construction of deviant behavior plays an important role in the labeling process that occurs in society. This process involves not only the labeling of criminally deviant behavior, which is behavior that does not fit socially constructed norms, but also labeling that which reflects stereotyped or stigmatized behavior of the \"mentally ill\". Labeling theory was first applied to the term \"mentally ill\" in 1966 when Thomas J. Scheff published \"Being Mentally Ill\". Scheff challenged common perceptions of mental illness by claiming that mental illness is manifested solely as a result of societal influence. He argued that society views certain actions as deviant and, in order to come to terms with and understand these actions, often places the label of mental illness on those who exhibit them. Certain expectations are then placed on these individuals and, over time, they unconsciously change their behavior to fulfill them. Criteria for different mental illnesses are not consistently fulfilled by those who are diagnosed with them because all of these people suffer from the same disorder, they are simply fulfilled because the \"mentally ill\" believe they are supposed to act a certain way so, over time, come to do so.\n\nScheff's theory had many critics, most notably Walter Gove. Gove consistently argued an almost opposite theory; he believed that society has no influence at all on \"mental illness\". Instead, any societal perceptions of the \"mentally ill\" come about as a direct result of these people's behaviors. Most sociologists' views of labeling and mental illness have fallen somewhere between the extremes of Gove and Scheff. On the other hand, it is almost impossible to deny, given both common sense and research findings, that society's negative perceptions of \"crazy\" people has had some effect on them. It seems that, realistically, labeling can accentuate and prolong the issues termed \"mental illness\", but it is rarely the full cause.\n\nMany other studies have been conducted in this general vein. To provide a few examples, several studies have indicated that most people associate being labeled mentally ill as being just as, or even more, stigmatizing than being seen as a drug addict, ex-convict, or prostitute (for example: Brand & Claiborn 1976). Additionally, Page's 1977 study found that self declared \"ex-mental patients\" are much less likely to be offered apartment leases or hired for jobs. Clearly, these studies and the dozens of others like them serve to demonstrate that labeling can have a very real and very large effect on the mentally ill. However, labeling has not been proven to be the sole cause of any symptoms of mental illness.\n\nPeggy Thoits discusses the process of labeling someone with a mental illness in her article, \"Sociological Approaches to Mental Illness\". Working off Thomas Scheff's (1966) theory, Thoits claims that people who are labeled as mentally ill are stereotypically portrayed as unpredictable, dangerous, and unable to care for themselves. She also claims that \"people who are labeled as deviant and treated as deviant become deviant\". This statement can be broken down into two processes, one that involves the effects of self-labeling and the other differential treatment from society based on the individual's label. Therefore, if society sees mentally ill individuals as unpredictable, dangerous and reliant on others, then a person who may not actually be mentally ill but has been labeled as such, could become mentally ill.\n\nThe label of \"mentally ill\" may help a person seek help, for example psychotherapy or medication. Labels, while they can be stigmatizing, can also lead those who bear them down the road to proper treatment and (hopefully) recovery. If one believes that \"being mentally ill\" is more than just believing one should fulfill a set of diagnostic criteria (as Scheff – see above – would argue), then one would probably also agree that there are some who are labeled \"mentally ill\" who need help. It has been claimed that this could not happen if \"we\" did not have a way to categorize (and therefore label) them, although there are actually plenty of approaches to these phenomena that don't use categorical classifications and diagnostic terms, for example spectrum or continuum models. Here, people vary along different dimensions, and everyone falls at different points on each dimension.\n\nProponents of \"hard labeling\", as opposed to \"soft labeling\", believe that mental illness does not exist, but is merely deviance from norms of society, causing people to believe in mental illness. They view them as socially constructed illnesses and psychotic disorders.\n\nThe application of labeling theory to homosexuality has been extremely controversial. It was Alfred Kinsey and his colleagues who pointed out the big discrepancy between the behavior and the role attached to it. They had observed the often negative consequences of labeling and repeatedly condemned labeling people as homosexual:\n\nErving Goffman's \"Stigma: Notes on the Management of Spoiled Identity\" distinguished between the behavior and the role assigned to it. He wrote:\n\nLabeling theory was also applied to homosexuality by Evelyn Hooker and by Leznoff and Westley, who published the first sociological study of the gay community. Erving Goffman and Howard Becker used the lives of gay-identified persons in their theories of labeling and interactionism. Simon and Gagnon likewise wrote: \"It is necessary to move away from the obsessive concern with the sexuality of the individual, and attempt to see the homosexual in terms of the broader attachments that he must make to live in the world around him.\"\n\nBritish sociologist Mary McIntosh reflected the enthusiasm of Europeans for labeling theory in her 1968 study, \"The Homosexual Role\".\n\nSara Fein and Elaine M. Nuehring were among the many who supported the application of labeling theory to homosexuality. They saw the gay role functioning as a \"master status\" around which other roles become organized. This brings a whole new set of problems and restrictions:\n\nPerhaps the strongest proponent of labeling theory was Edward Sagarin. In his book, \"Deviants and Deviance\", he wrote, \"There are no homosexuals, transvestites, chemical addicts, suicidogenics, delinquents, criminals, or other such entities, in the sense of people having such identities.\" Sagarin's position was roundly condemned by academics in the gay community. Sagarin had written some gay novels under the pseudonym of Donald Webster Cory. According to reports, he later abandoned his gay identity and began promoting an interactionist view of homosexuality.\n\nA number of authors adopted a modified, non-deviant, labeling theory. They rejected the stigmatic function of the gay role, but found it useful in describing the process of coming out and reconciling one's homosexual experiences with the social role. Their works included:\n\nBarry Adam, in his \"Survival of Domination: Inferiorization of Everyday Life\", took those authors to task for ignoring the force of the oppression in creating identities and their inferiorizing effects. Drawing upon the works of Albert Memmi, Adam showed how gay-identified persons, like Jews and blacks, internalize the hatred to justify their limitations of life choices. He saw the gravitation towards ghettos was evidence of the self-limitations. He wrote:\n\nStrong defense of labeling theory also arose within the gay community. Dan Slater of the Los Angeles Homosexual Information Center said, \"There is no such thing as a homosexual lifestyle. There is no such thing as gay pride or anything like that. Homosexuality is simply based on the sex act. Gay consciousness and all the rest are separatist and defeatist attitudes going back to centuries-old and out-moded conceptions that homosexuals are, indeed, different from other people.\"\n\nIn a later article, Slater stated the gay movement was going in the wrong direction:\n\nWilliam DuBay, in \"Gay Identity: The Self Under Ban\", describes gay identity as one strategy for dealing with society's oppression. It solves some problems but creates many more, replacing a closet of secrecy with one of gay identity. A better strategy, he suggests, is to reject the label and live as if the oppression did not exist. Quoting Goffman, he writes, \"But of course what is a good adjustment for the individual can be an even better one for society.\" \n\nDuBay contends that the attempt to define homosexuality as a class of persons to be protected against discrimination as defined in the statutes has not reduced the oppression. The goal of the movement instead should be to gain acceptance of homosexual relationships as useful and productive for both society and the family. The movement has lost the high moral ground by sponsoring the \"flight from choice\" and not taking up the moral issues. \"Persons whom we confine to back rooms and bars other societies have honored as tenders of children, astrologers, dancers, chanters, minstrels, jesters, artists, shamans, sacred warriors and judges, seers, healers, weavers of tales and magic.\"\n\nDuBay refers to the \"gay trajectory,\" in which a person first wraps himself in the gay role, organizing his personality and his life around sexual behavior. He might flee from his family and home town to a large gay center. There, the bedeviling force of the stigma will introduce him to more excessive modes of deviance such as promiscuity, prostitution, alcoholism, and drugs. Many resist such temptations and try to normalize their life, but the fast lanes of gay society are littered with the casualties of gay identity. Some come to reject the label entirely. \"Accomplishing the forbidden, they are neither gay nor straight. Again learning to choose, they develop the ability to make the ban ambiguous, taking responsibility and refusing explanations of their behaviors.\"\n\nJohn Henry Mackay writes about a gay hustler in Berlin adopting such a solution: \"What was self-evident, natural, and not the least sick did not require an excuse through an explanation... It was love just like any other love. Whoever could not or would not accept it as love was mistaken.\"\n\nBruce Link and colleagues have conducted several studies which point to the influence that labeling can have on mental patients. Through these studies, which took place in 1987, 1989, and 1997, Link advanced a \"modified labeling theory\" indicating that expectations of labeling can have a large negative effect, that these expectations often cause patients to withdraw from society, and that those labeled as having a mental disorder are constantly being rejected from society in seemingly minor ways but that, when taken as a whole, all of these small slights can drastically alter their self concepts. They come to both anticipate and perceive negative societal reactions to them, and this potentially damages their quality of life.\n\nModified labeling theory has been described as a \"sophisticated social-psychological model of 'why labels matter. In 2000, results from a prospective two-year study of patients discharged from a mental hospital (in the context of deinstitutionalization) showed that stigma was a powerful and persistent force in their lives, and that experiences of social rejection were a persistent source of social stress. Efforts to cope with labels, such as not telling anyone, educating people about mental distress/disorder, withdrawing from stigmatizing situations, could result in further social isolation and reinforce negative self-concepts. Sometimes an identity as a low self-esteem minority in society would be accepted. The stigma was associated with diminished motivation and ability to \"make it in mainstream society\" and with \"a state of social and psychological vulnerability to prolonged and recurrent problems\". There was an up and down pattern in self-esteem, however, and it was suggested that, rather than simply gradual erosion of self-worth and increasing self-deprecating tendencies, people were sometimes managing, but struggling, to maintain consistent feelings of self-worth. Ultimately, \"a cadre of patients had developed an entrenched, negative view of themselves, and their experiences of rejection appear to be a key element in the construction of these self-related feelings\" and \"hostile neighbourhoods may not only affect their self-concept but may also ultimately impact the patient's mental health status and how successful they are\".\n\n"}
{"id": "460663", "url": "https://en.wikipedia.org/wiki?curid=460663", "title": "List of languages by writing system", "text": "List of languages by writing system\n\nBelow is a list of languages sorted by writing system (by alphabetical order).\n\n\n\nand many other varieties of Arabic.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n"}
{"id": "44974120", "url": "https://en.wikipedia.org/wiki?curid=44974120", "title": "Localizing subcategory", "text": "Localizing subcategory\n\nIn mathematics, Serre and localizing subcategories form important classes of subcategories of an abelian category. Localizing subcategories are certain Serre subcategories. They are strongly linked to the notion of a quotient category.\n\nLet formula_1 be an abelian category. A non-empty full subcategory formula_2 is called a \"Serre subcategory\" (or also a \"dense subcategory\"), if for every short exact sequence formula_3 in formula_1 the object formula_5 is in formula_2 if and only if the objects formula_7\nand formula_8 belong to formula_2. In words: formula_2 is closed under subobjects, quotient objects\nand extensions.\n\nThe importance of this notion stems from the fact that kernels of exact functors between abelian categories have this property, and that one can build (for locally small formula_1) the quotient category (in the sense of Gabriel, Grothendieck,\nSerre) formula_12, which has the same objects as formula_1, is abelian, and comes with an exact functor (called the quotient functor) formula_14 whose kernel is formula_2.\n\nLet formula_1 be locally small. The Serre subcategory formula_2 is called \"localizing\", if the quotient functor\nformula_14 has a\nright adjoint\nformula_19. Since then formula_20, as a left adjoint, preserves colimits, each localizing subcategory is closed under colimits. The functor formula_20 (or sometimes formula_22) is also called the \"localization functor\", and formula_23 the \"section functor\". The section functor is left-exact and fully faithful.\n\nIf the abelian category formula_1 is moreover\ncocomplete and has injective hulls (e.g. if it is a Grothendieck category), then a Serre\nsubcategory formula_2 is localizing if and only if\nformula_2 is closed under arbitrary coproducts (a.k.a.\ndirect sums). Hence the notion of a localizing subcategory is\nequivalent to the notion of a hereditary torsion class.\n\nIf formula_1 is a Grothendieck category and\nformula_2 a localizing subcategory, then the quotient category\nformula_12 is again a Grothendieck category.\n\nThe Gabriel-Popescu theorem implies that every Grothendieck category is the quotient category of a module category formula_30 (with formula_31 a suitable ring) modulo a localizing subcategory.\n\n\n"}
{"id": "478601", "url": "https://en.wikipedia.org/wiki?curid=478601", "title": "Low-discrepancy sequence", "text": "Low-discrepancy sequence\n\nIn mathematics, a low-discrepancy sequence is a sequence with the property that for all values of \"N\", its subsequence \"x\", ..., \"x\" has a low discrepancy.\n\nRoughly speaking, the discrepancy of a sequence is low if the proportion of points in the sequence falling into an arbitrary set \"B\" is close to proportional to the measure of \"B\", as would happen on average (but not for particular samples) in the case of an equidistributed sequence. Specific definitions of discrepancy differ regarding the choice of \"B\" (hyperspheres, hypercubes, etc.) and how the discrepancy for every B is computed (usually normalized) and combined (usually by taking the worst value).\n\nLow-discrepancy sequences are also called quasi-random or sub-random sequences, due to their common use as a replacement of uniformly distributed random numbers.\nThe \"quasi\" modifier is used to denote more clearly that the values of a low-discrepancy sequence are neither random nor pseudorandom, but such sequences share some properties of random variables and in certain applications such as the quasi-Monte Carlo method their lower discrepancy is an important advantage.\n\nSubrandom numbers have an advantage over pure random numbers in that they cover the domain of interest quickly and evenly. They have an advantage over purely deterministic methods in that deterministic methods only give high accuracy when the number of datapoints is pre-set whereas in using subrandom sequences the accuracy typically improves continually as more datapoints are added, with full reuse of the existing points. On the other hand, subrandom sets can have a significant lower discrepancy for a given number of points than purely random sequences.\n\nTwo useful applications are in finding the characteristic function of a probability density function, and in finding the derivative function of a deterministic function with a small amount of noise. Subrandom numbers allow higher-order moments to be calculated to high accuracy very quickly.\n\nApplications that don't involve sorting would be in finding the mean, standard deviation, skewness and kurtosis of a statistical distribution, and in finding the integral and global maxima and minima of difficult deterministic functions. Subrandom numbers can also be used for providing starting points for deterministic algorithms that only work locally, such as Newton–Raphson iteration.\n\nSubrandom numbers can also be combined with search algorithms. A binary tree Quicksort-style algorithm ought to work exceptionally well because subrandom numbers flatten the tree far better than random numbers, and the flatter the tree the faster the sorting. With a search algorithm, subrandom numbers can be used to find the mode, median, confidence intervals and cumulative distribution of a statistical distribution, and all local minima and all solutions of deterministic functions.\n\nAt least three methods of numerical integration can be phrased as follows.\nGiven a set {\"x\", ..., \"x\"} in the interval <nowiki>[0,1]</nowiki>, approximate the integral of a function \"f\" as the average of the function evaluated at those points:\n\nIf the points are chosen as \"x\" = \"i\"/\"N\", this is the \"rectangle rule\".\nIf the points are chosen to be randomly (or pseudorandomly) distributed, this is the \"Monte Carlo method\".\nIf the points are chosen as elements of a low-discrepancy sequence, this is the \"quasi-Monte Carlo method\".\nA remarkable result, the Koksma–Hlawka inequality (stated below), shows that the error of such a method can be bounded by the product of two terms, one of which depends only on \"f\", and the other one is the discrepancy of the set {\"x\", ..., \"x\"}.\n\nIt is convenient to construct the set {\"x\", ..., \"x\"} in such a way that if a set with \"N\"+1 elements is constructed, the previous \"N\" elements need not be recomputed.\nThe rectangle rule uses points set which have low discrepancy, but in general the elements must be recomputed if \"N\" is increased.\nElements need not be recomputed in the random Monte Carlo method if \"N\" is increased,\nbut the point sets do not have minimal discrepancy.\nBy using low-discrepancy sequences we aim for low discrepancy and no need for recomputations, but actually low-discrepancy sequences can only be incrementally good on discrepancy if we allow no recomputation.\n\nThe \"discrepancy\" of a set P = {\"x\", ..., \"x\"} is defined, using Niederreiter's notation, as\n\nwhere\nλ is the \"s\"-dimensional Lebesgue measure,\n\"A\"(\"B\";\"P\") is the number of points in \"P\" that fall into \"B\",\nand \"J\" is the set of \"s\"-dimensional intervals or boxes of the form\n\nwhere formula_4.\n\nThe \"star-discrepancy\" \"D\"(\"P\") is defined similarly, except that the supremum is taken over the set \"J\" of rectangular boxes of the form\n\nwhere \"u\" is in the half-open interval <nowiki>[0, 1)</nowiki>.\n\nThe two are related by\n\nNote: With these definitions, discrepancy represents the worst-case or maximum point density deviation of a uniform set. However, also other error measures are meaningful, leading to other definitions and variation measures. For instance, L2 discrepancy or modified centered L2 discrepancy are also used intensively to compare the quality of uniform point sets. Both are much easier to calculate for large N and s.\n\nLet Ī be the \"s\"-dimensional unit cube,\nĪ = [0, 1] × ... × [0, 1].\nLet \"f\" have bounded variation \"V\"(\"f\") on Ī in the sense of Hardy and Krause.\nThen for any \"x\", ..., \"x\"\nin \"I\" =\n<nowiki>[</nowiki>0, 1<nowiki>)</nowiki> × ... ×\n<nowiki>[</nowiki>0, 1<nowiki>)</nowiki>,\n\nThe Koksma–Hlawka inequality is sharp in the following sense: For any point set {\"x\"...,\"x\"} in \"I\" and any formula_8, there is a function \"f\" with bounded variation and \"V\"(\"f\") = 1 such that\n\nTherefore, the quality of a numerical integration rule depends only on the discrepancy D(\"x\"...,\"x\").\n\nLet formula_10. For formula_11 we\nwrite\nand denote by formula_13 the point obtained from \"x\" by replacing the\ncoordinates not in \"u\" by formula_14. Then\n\nwhere formula_16 is the discrepancy function.\n\nApplying the Cauchy–Schwarz inequality for integrals and sums to the Hlawka–Zaremba identity, we obtain an formula_17 version of the Koksma–Hlawka inequality:\n\nwhere\n\nand\n\nL2 discrepancy has a high practical importance because fast explicit calculations are possible for a given point set. This way it is easy to create point set optimizers using L2 discrepancy as criteria.\n\nIt is computationally hard to find the exact value of the discrepancy of large point sets. The Erdős–Turán–Koksma inequality provides an upper bound.\n\nLet \"x\"...,\"x\" be points in \"I\" and \"H\" be an arbitrary positive integer. Then\n\nwhere\n\nConjecture 1. There is a constant \"c\" depending only on the dimension \"s\", such that\n\nfor any finite point set {\"x\"...,\"x\"}.\n\nConjecture 2. There is a constant \"c\" depending only on \"s\", such that\n\nfor infinite number of \"N\" for any infinite sequence \"x\",\"x\",\"x\"...\n\nThese conjectures are equivalent. They have been proved for \"s\" ≤ 2 by W. M. Schmidt. In higher dimensions, the corresponding problem is still open. The best-known lower bounds are due to K. F. Roth.\n\nLet \"s\" = 1. Then\n\nfor any finite point set {\"x\", ..., \"x\"}.\n\nLet \"s\" = 2. W. M. Schmidt proved that for any finite point set {\"x\", ..., \"x\"},\n\nwhere\n\nFor arbitrary dimensions \"s\" > 1, K.F. Roth proved that\n\nfor any finite point set {\"x\", ..., \"x\"}.\nThis bound is the best known for \"s\" > 3.\n\nBecause any distribution of random numbers can be mapped onto a uniform distribution, and subrandom numbers are mapped in the same way, this article only concerns generation of subrandom numbers on a multidimensional uniform distribution.\n\nThere are constructions of sequences known such that\nwhere \"C\" is a certain constant, depending on the sequence. After Conjecture 2, these sequences are believed to have the best possible order of convergence. Examples below are the van der Corput sequence, the Halton sequences, and the Sobol sequences. One general limitation is that construction methods can usually only guarantee the order of convergence. Practically, low discrepancy can be only achieved if N is large enough, and for large given s this minimum N can be very large. This means running a Monte-Carlo analysis with e.g. s=20 variables and N=1000 points from a low-discrepancy sequence generator may offer only a very minor accuracy improvement.\n\nSequences of subrandom numbers can be generated from random numbers by imposing a negative correlation on those random numbers. One way to do this is to start with a set of random numbers formula_31 on formula_32 and construct subrandom numbers formula_33 which are uniform on formula_34 using:\n\nformula_35 for formula_36 odd and formula_37 for formula_36 even.\n\nA second way to do it with the starting random numbers is to construct a random walk with offset 0.5 as in:\n\nThat is, take the previous subrandom number, add 0.5 and the random number, and take the result modulo 1.\n\nFor more than one dimension, Latin squares of the appropriate dimension can be used to provide offsets to ensure that the whole domain is covered evenly.\n\nFor any irrational formula_40, the sequence\n\nhas discrepancy tending to 0. (Note the sequence can be defined recursively by formula_42.) A good value of formula_40 gives lower discrepancy than a sequence of independent uniform random numbers.\n\nThe discrepancy can be bounded by the approximation exponent of formula_40. If the approximation exponent is formula_45, then for any formula_8, the following bound holds:\n\nBy the Thue–Siegel–Roth theorem, the approximation exponent of any irrational algebraic number is 2, giving a bound of formula_48 above.\n\nThe value of formula_49 with lowest discrepancy is \n\nAnother value that is nearly as good is:\n\nIn more than one dimension, separate subrandom numbers are needed for each dimension. In higher dimensions, one set of values that can be used is the square roots of primes from two up, all taken modulo 1:\n\nThe recurrence relation above is similar to the recurrence relation used by a Linear congruential generator, a poor-quality pseudorandom number generator:\n\nFor the low discrepancy additive recurrence above, a and m are chosen to be 1. Note, however, that this will not generate independent random numbers, so should not be used for purposes requiring independence. The list of pseudorandom number generators lists methods for generating independent pseudorandom numbers.\nNote: In few dimensions, recursive recurrence leads to uniform sets of good quality, but for larger s (like s>8) other point set generators can offer much lower discrepancies.\n\nLet\n\nbe the \"b\"-ary representation of the positive integer \"n\" ≥ 1, i.e. 0 ≤ \"d\"(\"n\") < \"b\". Set\n\nThen there is a constant \"C\" depending only on \"b\" such that (\"g\"(\"n\"))satisfies\n\nwhere \"D\" is the \nstar discrepancy.\n\nThe Halton sequence is a natural generalization of the van der Corput sequence to higher dimensions. Let \"s\" be an arbitrary dimension and \"b\", ..., \"b\" be arbitrary coprime integers greater than 1. Define\n\nThen there is a constant \"C\" depending only on \"b\", ..., \"b\", such that sequence {\"x\"(\"n\")} is a \"s\"-dimensional sequence with\n\nLet \"b\"...,\"b\" be coprime positive integers greater than 1. For given \"s\" and \"N\", the \"s\"-dimensional Hammersley set of size \"N\" is defined by\n\nfor \"n\" = 1, ..., \"N\". Then\n\nwhere \"C\" is a constant depending only on \"b\", ..., \"b\".\nNote: The formulas show that the Hammersley set is actually the Halton sequence, but we get one more dimension for free by adding a linear sweep. This is only possible if N is known upfront. A linear set is also the set with lowest possible one-dimensional discrepancy in general. Unfortunately, for higher dimensions, no such \"discrepancy record sets\" are known. For s=2, most low-discrepancy point set generators deliver at least near-optimum discrepancies.\n\nThe Antonov–Saleev variant of the Sobol sequence generates numbers between zero and one directly as binary fractions of length formula_61, from a set of formula_61 special binary fractions, formula_63 called direction numbers. The bits of the Gray code of formula_36, formula_65, are used to select direction numbers. To get the Sobol sequence value formula_33 take the exclusive or of the binary value of the Gray code of formula_36 with the appropriate direction number. The number of dimensions required affects the choice of formula_68.\n\nPoisson disk sampling is popular in video games to rapidly placing objects in a way that appears random-looking\nbut guarantees that every two points are separated by at least the specified minimum distance. This does not guarantee low discrepancy (as e. g. Sobol), but at least a significantly lower discrepancy than pure random sampling.\n\nThe points plotted below are the first 100, 1000, and 10000 elements in a sequence of the Sobol' type.\nFor comparison, 10000 elements of a sequence of pseudorandom points are also shown.\nThe low-discrepancy sequence was generated by TOMS algorithm 659.\nAn implementation of the algorithm in Fortran is available from Netlib.\n\n\n\n"}
{"id": "40676015", "url": "https://en.wikipedia.org/wiki?curid=40676015", "title": "Maharashtra Andhashraddha Nirmoolan Samiti", "text": "Maharashtra Andhashraddha Nirmoolan Samiti\n\nMaharashtra Andhashraddha Nirmoolan Samiti (MANS; or Committee for Eradication of Blind Faith, CEBF) is an organisation dedicated to fighting superstition in India, particularly in the province of Maharashtra. It was founded by Narendra Dabholkar in 1989. It is currently headed by Avinash Patil after Dabholkar's assassination.\n\nIt was founded by Narendra Dabholkar in 1989. In 1999, MANS had protested the canonisation of Mother Teresa on the basis of purported miracles, but they had praised her service to the ailing and diseased.\n\nThe organisation has also campaigned against immersion of Ganesha idols in water bodies. They have been urging people to use smaller idols and vegetable dyes to avoid polluting rivers and lakes. They have urged people to immerse the idols into the tanks built specially for this purpose on the riverbanks.\n\nThey have protested the torture of mentally ill people under the superstitious belief that it will cure them. Such practices are carried out in a dargah in Chalisgaon.\n\nMANS has also challenged godmen who claim to perform miracles. In December 2002, a prize of lakh was announced to be given to anyone who could perform one of the listed 12 miracles. The list included walking on water, floating in air, standing on hot coals for five minutes, being present in two places simultaneously and materialising necklaces from thin air, among others. Members of MANS toured rural areas debunking these godmen.\n\nThey have campaigned against astrology. In October 2009, MANS organised a contest with a prize money of lakh challenging astrologers to predict the results of the Maharashtra Assembly poll election with at least 80% accuracy.\n\nMANS had been campaigning for a law to check the exploitation of people's superstitions in Maharashtra for a long time. In 1989 at the Andhashraddha Nirmoolan Jahirnama Parishad held that year in Pune, then Chief minister Sharad Pawar had indicated the formation of a law in that direction. The issue was raised again in 1995 in the Legislative Council. On 28 July 2003, MANS members organised a hunger strike outside the State Assembly in Mumbai to protest the state's inaction.\n\nOn 2 March 2009, MANS members wrote a letter in blood and sent to then Chief Minister Ashok Chavan and others to urge them to take steps towards the passing of the law. On 7 April 2011, they organised a rally to spread awareness about the law. They also ran telegram-sending campaign from 7 July to 25 July 2011 to draw attention to the issue. The telegrams were sent to the Chief Minister.\n\nDabholkar was murdered on 20 August 2013. The pending Anti-Superstition and Black Magic Ordinance was promulgated in the state of Maharashtra, four days after his death.\n\n"}
{"id": "46986161", "url": "https://en.wikipedia.org/wiki?curid=46986161", "title": "Maharat", "text": "Maharat\n\nMaharat is a Yeshiva located in Bronx, NY, which is the first Orthodox institution in North America to ordain Orthodox women. The word \"maharat\" (מהרת) is a Hebrew acronym for words \"manhiga hilkhatit rukhanit Toranit\" () denoting a female \"leader of Jewish law spirituality and Torah\". Maharat, as a clergy title, is awarded with semikha to the graduates of a 4-year-long program composed of profound studies of Jewish law, Talmud, Torah, Jewish thought, leadership training, and pastoral counseling.\n\nIn 2009, Rabbi Avi Weiss and Rabbi Daniel Sperber ordained Sara Hurwitz. She was the first woman to receive Orthodox semikha. That same year Hurwitz and Weiss founded an Orthodox yeshiva (religious school) for women: \"Yeshivat Maharat\" in New York, where Hurwitz serves as President. In 2018-2019, its 10th year, Maharat has graduated 26 women who are serving in clergy roles in synagogues, schools, hospitals, universities and Jewish communal institutions.  There are 31 more students in the pipeline, preparing to change the landscape of Orthodox Judaism and the community at large. Maharat has impacted over 50 communities worldwide.\n\nGraduates of Maharat utilize titles such as \"Maharat\",\" Rabba\" (רבה, a neologism), \"Rabbanit\" (רבנית, traditionally denoting a rabbi's wife) and \"Rabbi\" (רבי). In 2015, Lila Kagedan was ordained as Rabbi by that same organization, making her their first graduate to take the title rabbi. \n\nIn 2015, the Rabbinical Council of America passed a resolution which states, \"RCA members with positions in Orthodox institutions may not ordain women into the Orthodox rabbinate, regardless of the title used; or hire or ratify the hiring of a woman into a rabbinic position at an Orthodox institution; or allow a title implying rabbinic ordination to be used by a teacher of Limudei Kodesh in an Orthodox institution.\" Also in 2015, Agudath Israel of America denounced moves to ordain women, and went even further, declaring Yeshivat Maharat, Open Orthodoxy, Yeshivat Chovevei Torah, and other affiliated entities to be similar to other dissident movements throughout Jewish history in having rejected basic tenets of Judaism. \n\nAvi Weiss has continuously tried to advocate for the right for female clergy to use the rabbi title. In protest of those denying this right to women, Weiss resigned from the Rabbinical Council of America.\n\n"}
{"id": "16842914", "url": "https://en.wikipedia.org/wiki?curid=16842914", "title": "Matching distance", "text": "Matching distance\n\nIn mathematics, the matching distance is a metric on the space of size functions.\n\nThe core of the definition of matching distance is the observation that the\ninformation contained in a size function can be combinatorially stored in a formal series of lines and points of the plane, called respectively \"cornerlines\" and \"cornerpoints\".\n\nGiven two size functions formula_1 and formula_2, let formula_3 (resp. formula_4) be the multiset of\nall cornerpoints and cornerlines for formula_1 (resp. formula_2) counted with their\nmultiplicities, augmented by adding a countable infinity of points of the\ndiagonal formula_7.\n\nThe \"matching distance\" between formula_1 and formula_2 is given by\nformula_10\nwhere formula_11 varies among all the bijections between formula_3 and formula_4 and\n\nRoughly speaking, the matching distance formula_15\nbetween two size functions is the minimum, over all the matchings\nbetween the cornerpoints of the two size functions, of the maximum\nof the formula_16-distances between two matched cornerpoints. Since\ntwo size functions can have a different number of cornerpoints,\nthese can be also matched to points of the diagonal formula_17. Moreover, the definition of formula_18 implies that matching two points of the diagonal has no cost.\n\n"}
{"id": "35811096", "url": "https://en.wikipedia.org/wiki?curid=35811096", "title": "Meaning and Necessity", "text": "Meaning and Necessity\n\nMeaning and Necessity: A Study in Semantics and Modal Logic is a 1947 book about logic by the philosopher Rudolf Carnap.\n\n\"Meaning and Necessity\" was the culmination of Carnap's concern with the semantics of natural and formal languages, which developed subsequent to his publication of \"The Logical Syntax of Language\" in 1934.\n\nCarnap attempts to develop a new method for analyzing the meanings of linguistic expressions as well as to lay a semantic foundation for modal logic. Carnap maintains that his new method consists in doing away with the traditional assumption that linguistic expressions name concrete or abstract entities and in replacing it with the ascription to them of intensions and extensions. He states that linguistic expressions designate their intensions and extensions: every designation refers to both an intension and an extension.\n\nThe intensional entities to which individual constants or descriptions, predicates, and declarative sentences are respectively said to refer are individual concepts, properties and propositions, the corresponding extensions being individuals, classes and truth-values. Carnap insists that intensions, including individual concepts, are objectively real, not mental concepts. However, he rejects the charge of hypostatization: individual concepts and properties and propositions must not be considered as things, but this does not prevent them from being genuine objective entities.\n\nCarnap's method is an alternative to Gottlob Frege's theory of sense and reference, which he refers to as the \"method of extension and intension\". Carnap holds that his method provides the most economical account of the logical behavior of expressions in modal contexts - for instance, the expressions '9' and '7' in the sentence '9 is necessarily greater than 7.' His criticism of Frege involves a rejection of the traditional category of names, conceived as a class of expressions each of which stands for a unique thing.\n\n\"Meaning and Necessity\" was influential, and laid the foundations of much subsequent work in the semantics of modal logic. The work is seen by the British philosopher A. J. Ayer as the most important of Carnap's three books on semantics, the other two being \"Introduction to Semantics\" (1942) and \"Formalization of Logic\" (1943). Ayer criticizes the book, on the grounds that since, according to Carnap, linguistic expressions designate their intensions and extensions, it is not clear that the difference between Carnap's view and what Carnap calls the traditional assumption that linguistic expressions name concrete or abstract entities is more than nominal.\n\n"}
{"id": "2041141", "url": "https://en.wikipedia.org/wiki?curid=2041141", "title": "Mill's Methods", "text": "Mill's Methods\n\nMill's Methods are five methods of induction described by philosopher John Stuart Mill in his 1843 book \"A System of Logic\". They are intended to illuminate issues of causation.\n\nFor a property to be a necessary condition it must always be present if the effect is present. Since this is so, then we are interested in looking at cases where the effect is present and taking note of which properties, among those considered to be 'possible necessary conditions' are present and which are absent. Obviously, any properties which are absent when the effect is present cannot be necessary conditions for the effect. This method is also referred to more generally within comparative politics as the most different systems design.\nSymbolically, the method of agreement can be represented as:\nTo further illustrate this concept, consider two structurally different countries. Country A is a former colony, has a centre-left government, and has a federal system with two levels of government. Country B has never been a colony, has a centre-left government and is a unitary state. One factor that both countries have in common, the dependent variable in this case, is that they have a system of universal health care. Comparing the factors known about the countries above, a comparative political scientist would conclude that the government sitting on the centre-left of the spectrum would be the independent variable which causes a system of universal health care, since it is the only one of the factors examined which holds constant between the two countries, and the theoretical backing for that relationship is sound; social democratic (centre-left) policies often include universal health care.\n\nThis method is also known more generally as the most similar systems design within comparative politics.\n\nAs an example of the method of difference, consider two similar countries. Country A has a centre-right government, a unitary system and was a former colony. Country B has a centre-right government, a unitary system but was never a colony. The difference between the countries is that Country A readily supports anti-colonial initiatives, whereas Country B does not. The method of difference would identify the independent variable to be the status of each country as a former colony or not, with the dependant variable being support for anti-colonial initiatives. This is because, out of the two similar countries compared, the difference between the two is whether or not they were formerly a colony. This then explains the difference on the values of the dependent variable, with the former colony being more likely to support decolonization than the country with no history of being a colony.\n\nAlso called simply the \"joint method, \" this principle simply represents the application of the methods of agreement and difference.\n\nSymbolically, the Joint method of agreement and difference can be represented as:\n\nIf a range of factors are believed to cause a range of phenomena, and we have matched all the factors, except one, with all the phenomena, except one, then the remaining phenomenon can be attributed to the remaining factor.\n\nSymbolically, the Method of Residue can be represented as:\n\nIf across a range of circumstances leading to a phenomenon, some property of the phenomenon varies in tandem with some factor existing in the circumstances, then the phenomenon can be associated with that factor. For instance, suppose that various samples of water, each containing both salt and lead, were found to be toxic. If the level of toxicity varied in tandem with the level of lead, one could attribute the toxicity to the presence of lead.\n\nSymbolically, the method of concomitant variation can be represented as (with ± representing a shift):\n\nUnlike the preceding four inductive methods, the method of concomitant variation doesn't involve the elimination of any circumstance. Changing the magnitude of one factor results in the change in the magnitude of another factor.\n\n\n\n"}
{"id": "27830603", "url": "https://en.wikipedia.org/wiki?curid=27830603", "title": "Mindset List", "text": "Mindset List\n\nThe Mindset List is an annual compilation of the values that shape the worldview (or “mindset”) of students about 18 years old and entering college and, to a lesser extent, adulthood. It is co-authored by Ron Nief, Public Affairs Director Emeritus; Tom McBride, Professor of English and Keefer Professor of Humanities; and Charles Westerberg, Brannon-Ballard Professor of Sociology, all at Beloit College in Beloit, Wisconsin. It originated in 1997 as an e-mail forward, without author credits, passed on by then College Statistician Richard Miller to Ron Nief, who passed it on to peers at other schools. The Mindset List began as a cute way of reminding colleagues on the faculty to \"watch their references\" with freshmen. It reappeared in the fall of 1998 after requests from peers who mistook the forward as having originated with Ron Nief. Ever since, Nief and McBride have collaborated to create The List, and Westerberg joined them as a co-author starting with the Class of 2020 List released in 2016.\n\nThe List now appears every August as American first-year students enter college. It has been mentioned on the NBC Nightly News with Brian Williams and an essay by Nancy Gibbs of \"Time\". In 2009, \"Time\" declared \"mindset list\" a new phrase in the American lexicon.\n\nThe Mindset List website has a daily quiz about growing up in the United States, a Mindset List Movie of the Month, “Mindset Moments” of reports about the generation gap, links to information about the current generation of young people, and an ironic advice column called Ask ROM. The List also appears on Twitter and Facebook.\n\n\"The Mindset Lists of American History: From Typewriters to Text Messages, What Ten Generations of Americans Think Is Normal\" was released in 2011.\n\nThe website Beloit Mindlessness calls the Mindset List “a poorly written compendium of trivia, stereotypes and lazy generalizations, insulting to both students and their professors, and based on nothing more than the uninformed speculation of its authors. It inspires lazy, inaccurate journalism and is an embarrassment to academia.” Beloit Mindlessness publishes posts critiquing specific items on the Mindset Lists.\n\n"}
{"id": "12034549", "url": "https://en.wikipedia.org/wiki?curid=12034549", "title": "Morita conjectures", "text": "Morita conjectures\n\nThe Morita conjectures in general topology are certain problems about normal spaces, now solved in the affirmative. They asked \n\n\nThe answers were believed to be affirmative. Here a normal P-space \"Y\" is characterised by the property that the product with every metrizable \"X\" is normal; thus the conjecture was that the converse holds.\n\nK. Chiba, T.C. Przymusiński and Mary Ellen Rudin\n\nFifteen years later, Z. Balogh succeeded in proving conjectures (2) and (3) true.\n\n"}
{"id": "2693655", "url": "https://en.wikipedia.org/wiki?curid=2693655", "title": "Morse–Kelley set theory", "text": "Morse–Kelley set theory\n\nIn the foundations of mathematics, Morse–Kelley set theory (MK), Kelley–Morse set theory (KM), Morse–Tarski set theory (MT), Quine–Morse set theory (QM) or the system of Quine and Morse is a first order axiomatic set theory that is closely related to von Neumann–Bernays–Gödel set theory (NBG). While von Neumann–Bernays–Gödel set theory restricts the bound variables in the schematic formula appearing in the axiom schema of Class Comprehension to range over sets alone, Morse–Kelley set theory allows these bound variables to range over proper classes as well as sets, as first suggested by Quine in 1940 for his system ML.\n\nMorse–Kelley set theory is named after mathematicians John L. Kelley and Anthony Morse and was first set out by and later in an appendix to Kelley's textbook \"General Topology\" (1955), a graduate level introduction to topology. Kelley said the system in his book was a variant of the systems due to Thoralf Skolem and Morse. Morse's own version appeared later in his book \"A Theory of Sets\" (1965).\n\nWhile von Neumann–Bernays–Gödel set theory is a conservative extension of Zermelo–Fraenkel set theory (ZFC, the canonical set theory) in the sense that a statement in the language of ZFC is provable in NBG if and only if it is provable in ZFC, Morse–Kelley set theory is a proper extension of ZFC. Unlike von Neumann–Bernays–Gödel set theory, where the axiom schema of Class Comprehension can be replaced with finitely many of its instances, Morse–Kelley set theory cannot be finitely axiomatized.\n\nNBG and MK share a common ontology. The universe of discourse consists of classes. Classes which are members of other classes are called sets. A class which is not a set is a proper class. The primitive atomic sentences involve membership or equality.\n\nWith the exception of Class Comprehension, the following axioms are the same as those for NBG, inessential details aside. The symbolic versions of the axioms employ the following notational devices:\n\nExtensionality: Classes having the same members are the same class.\nA set and a class having the same extension are identical. Hence MK is not a two-sorted theory, appearances to the contrary notwithstanding.\n\nFoundation: Each nonempty class \"A\" is disjoint from at least one of its members.\n\nClass Comprehension: Let φ(\"x\") be any formula in the language of MK in which \"x\" is a free variable and \"Y\" is not free. φ(\"x\") may contain parameters which are either sets or proper classes. More consequentially, the quantified variables in φ(\"x\") may range over all classes and not just over all sets; \"this is the only way MK differs from NBG\". Then there exists a class formula_8 whose members are exactly those sets \"x\" such that formula_9 comes out true. Formally, if \"Y\" is not free in φ:\n\nPairing: For any sets \"x\" and \"y\", there exists a set formula_11 whose members are exactly \"x\" and \"y\".\n\nPairing licenses the unordered pair in terms of which the ordered pair, formula_13, may be defined in the usual way, as formula_14. With ordered pairs in hand, Class Comprehension enables defining relations and functions on sets as sets of ordered pairs, making possible the next axiom:\n\nLimitation of Size: \"C\" is a proper class if and only if \"V\" can be mapped one-to-one into \"C\".\n\nThe formal version of this axiom resembles the axiom schema of replacement, and embodies the class function \"F\". The next section explains how Limitation of Size is stronger than the usual forms of the axiom of choice.\n\nPower set: Let \"p\" be a class whose members are all possible subsets of the set \"a\". Then \"p\" is a set.\n\nUnion: Let formula_17 be the sum class of the set \"a\", namely the union of all members of \"a\". Then \"s\" is a set.\n\nInfinity: There exists an inductive set \"y\", meaning that (i) the empty set is a member of \"y\"; (ii) if \"x\" is a member of \"y\", then so is formula_19.\n\nNote that \"p\" and \"s\" in Power Set and Union are universally, not existentially, quantified, as Class Comprehension suffices to establish the existence of \"p\" and \"s\". Power Set and Union only serve to establish that \"p\" and \"s\" cannot be proper classes.\n\nThe above axioms are shared with other set theories as follows:\n\nMonk (1980) and Rubin (1967) are set theory texts built around MK; Rubin's ontology includes urelements. These authors and Mendelson (1997: 287) submit that MK does what is expected of a set theory while being less cumbersome than ZFC and NBG.\n\nMK is strictly stronger than ZFC and its conservative extension NBG, the other well-known set theory with proper classes. In fact, NBG—and hence ZFC—can be proved consistent in MK. MK's strength stems from its axiom schema of Class Comprehension being impredicative, meaning that φ(\"x\") may contain quantified variables ranging over classes. The quantified variables in NBG's axiom schema of Class Comprehension are restricted to sets; hence Class Comprehension in NBG must be predicative. (Separation with respect to sets is still impredicative in NBG, because the quantifiers in φ(\"x\") may range over all sets.) The NBG axiom schema of Class Comprehension can be replaced with finitely many of its instances; this is not possible in MK. MK is consistent relative to ZFC augmented by an axiom asserting the existence of strongly inaccessible cardinals.\n\nThe only advantage of the axiom of limitation of size is that it implies the axiom of global choice. Limitation of Size does not appear in Rubin (1967), Monk (1980), or Mendelson (1997). Instead, these authors invoke a usual form of the local axiom of choice, and an \"axiom of replacement,\" asserting that if the domain of a class function is a set, its range is also a set. Replacement can prove everything that Limitation of Size proves, except prove some form of the axiom of choice.\n\nLimitation of Size plus \"I\" being a set (hence the universe is nonempty) renders provable the sethood of the empty set; hence no need for an axiom of empty set. Such an axiom could be added, of course, and minor perturbations of the above axioms would necessitate this addition. The set \"I\" is not identified with the limit ordinal formula_21 as \"I\" could be a set larger than formula_22 In this case, the existence of formula_23 would follow from either form of Limitation of Size.\n\nThe class of von Neumann ordinals can be well-ordered. It cannot be a set (under pain of paradox); hence that class is a proper class, and all proper classes have the same size as \"V\". Hence \"V\" too can be well-ordered.\n\nMK can be confused with second-order ZFC, ZFC with second-order logic (representing second-order objects in set rather than predicate language) as its background logic. The language of second-order ZFC is similar to that of MK (although a set and a class having the same extension can no longer be identified), and their syntactical resources for practical proof are almost identical (and are identical if MK includes the strong form of Limitation of Size). But the semantics of second-order ZFC are quite different from those of MK. For example, if MK is consistent then it has a countable first-order model, while second-order ZFC has no countable models.\n\nZFC, NBG, and MK each have models describable in terms of \"V\", the standard model of ZFC and the von Neumann universe. Let the inaccessible cardinal κ be a member of \"V\". Also let Def(\"X\") denote the Δ definable subsets of \"X\" (see constructible universe). Then:\n\nMK was first set out in and popularized in an appendix to J. L. Kelley's (1955) \"General Topology\", using the axioms given in the next section. The system of Anthony Morse's (1965) \"A Theory of Sets\" is equivalent to Kelley's, but formulated in an idiosyncratic formal language rather than, as is done here, in standard first order logic. The first set theory to include impredicative class comprehension was Quine's ML, that built on New Foundations rather than on ZFC. Impredicative class comprehension was also proposed in Mostowski (1951) and Lewis (1991).\n\nThe axioms and definitions in this section are, but for a few inessential details, taken from the Appendix to Kelley (1955). The explanatory remarks below are not his. The Appendix states 181 theorems and definitions, and warrants careful reading as an abbreviated exposition of axiomatic set theory by a working mathematician of the first rank. Kelley introduced his axioms gradually, as needed to develop the topics listed after each instance of \"Develop\" below.\n\nNotations appearing below and now well-known are not defined. Peculiarities of Kelley's notation include:\n\nDefinition: \"x\" is a \"set\" (and hence not a proper class) if, for some \"y\", formula_25.\n\nI. Extent: For each \"x\" and each \"y\", \"x=y\" if and only if for each \"z\", formula_26 when and only when formula_27\n\nIdentical to \"Extensionality\" above. I would be identical to the axiom of extensionality in ZFC, except that the scope of I includes proper classes as well as sets.\n\nII. Classification (schema): An axiom results if in\n'α' and 'β' are replaced by variables, ' \"A\" ' by a formula Æ, and ' \"B\" ' by the formula obtained from Æ by replacing each occurrence of the variable which replaced α by the variable which replaced β provided that the variable which replaced β does not appear bound in \"A\".\n\n\"Develop\": Boolean algebra of sets. Existence of the null class and of the universal class \"V\".\n\nIII. Subsets: If \"x\" is a set, there exists a set \"y\" such that for each \"z\", if formula_32, then formula_27\n\nThe import of III is that of \"Power Set\" above. Sketch of the proof of Power Set from III: for any \"class\" \"z\" which is a subclass of the set \"x\", the class \"z\" is a member of the set \"y\" whose existence III asserts. Hence \"z\" is a set.\n\n\"Develop\": \"V\" is not a set. Existence of singletons. Separation provable.\n\nIV. Union: If \"x\" and \"y\" are both sets, then formula_34 is a set.\n\nThe import of IV is that of \"Pairing\" above. Sketch of the proof of Pairing from IV: the singleton formula_35 of a set \"x\" is a set because it is a subclass of the power set of \"x\" (by two applications of III). Then IV implies that formula_36 is a set if \"x\" and \"y\" are sets.\n\n\"Develop\": Unordered and ordered pairs, relations, functions, domain, range, function composition.\n\nV. Substitution: If \"f\" is a [class] function and \"domain f\" is a set, then \"range f\" is a set.\n\nThe import of V is that of the axiom schema of replacement in NBG and ZFC.\n\nVI. Amalgamation: If \"x\" is a set, then formula_37 is a set.\n\nThe import of VI is that of \"Union\" above. IV and VI may be combined into one axiom.\n\n\"Develop\": Cartesian product, injection, surjection, bijection, order theory.\n\nVII. Regularity: If formula_38 there is a member \"y\" of \"x\" such that formula_39\n\nThe import of VII is that of \"Foundation\" above.\n\n\"Develop\": Ordinal numbers, transfinite induction.\n\nVIII. Infinity: There exists a set \"y\", such that formula_40 and formula_41 whenever formula_42\n\nThis axiom, or equivalents thereto, are included in ZFC and NBG. VIII asserts the unconditional existence of two sets, the infinite inductive set \"y\", and the null set formula_43 formula_3 is a set simply because it is a member of \"y\". Up to this point, everything that has been proved to exist is a class, and Kelley's discussion of sets was entirely hypothetical.\n\n\"Develop\": Natural numbers, N is a set, Peano axioms, integers, rational numbers, real numbers.\n\nDefinition: \"c\" is a \"choice function\" if \"c\" is a function and formula_45 for each member \"x\" of \"domain c\".\n\nIX. Choice: There exists a choice function \"c\" whose domain is formula_46.\n\nIX is very similar to the axiom of global choice derivable from \"Limitation of Size\" above.\n\n\"Develop\": Equivalents of the axiom of choice. As is the case with ZFC, the development of the cardinal numbers requires some form of Choice.\n\nIf the scope of all quantified variables in the above axioms is restricted to sets, all axioms except III and the schema IV are ZFC axioms. IV is provable in ZFC. Hence the Kelley treatment of MK makes very clear that all that distinguishes MK from ZFC are variables ranging over proper classes as well as sets, and the Classification schema.\n\n\n\nFrom Foundations of Mathematics (FOM) discussion group:\n"}
{"id": "57122", "url": "https://en.wikipedia.org/wiki?curid=57122", "title": "Multiplication table", "text": "Multiplication table\n\nIn mathematics, a multiplication table (sometimes, less formally, a times table) is a mathematical table used to define a multiplication operation for an algebraic system.\n\nThe decimal multiplication table was traditionally taught as an essential part of elementary arithmetic around the world, as it lays the foundation for arithmetic operations with base-ten numbers. Many educators believe it is necessary to memorize the table up to 9 × 9.\n\nThe oldest known multiplication tables were used by the Babylonians about 4000 years ago. However, they used a base of 60. The oldest known tables using a base of 10 are the Chinese decimal multiplication table on bamboo strips dating to about 305 BC, during China's Warring States period.\nThe multiplication table is sometimes attributed to the ancient Greek mathematician Pythagoras (570–495 BC). It is also called the Table of Pythagoras in many languages (for example French, Italian and at one point even Russian), sometimes in English. The Greco-Roman mathematician Nichomachus (60–120 AD), a follower of Neopythagoreanism, included a multiplication table in his \"Introduction to Arithmetic\", whereas the oldest surviving Greek multiplication table is on a wax tablet dated to the 1st century AD and currently housed in the British Museum.\n\nIn 493 AD, Victorius of Aquitaine wrote a 98-column multiplication table which gave (in Roman numerals) the product of every number from 2 to 50 times and the rows were \"a list of numbers starting with one thousand, descending by hundreds to one hundred, then descending by tens to ten, then by ones to one, and then the fractions down to 1/144.\"\n\nIn his 1820 book \"The Philosophy of Arithmetic\", mathematician John Leslie published a multiplication table up to 99 × 99, which allows numbers to be multiplied in pairs of digits at a time. Leslie also recommended that young pupils memorize the multiplication table up to 25 × 25. The illustration below shows a table up to 12 × 12, which is a size commonly used in schools.\n\nThe traditional rote learning of multiplication was based on memorization of columns in the table, in a form like\n\n<poem>\n</poem>\nThis form of writing the multiplication table in columns with complete number sentences is still used in some countries, such as Bosnia and Herzegovina, instead of the modern grid above.\n\nThere is a pattern in the multiplication table that can help people to memorize the table more easily. It uses the figures below:\n\nFigure 1 is used for multiples of 1, 3, 7, and 9. Figure 2 is used for the multiples of 2, 4, 6, and 8. These patterns can be used to memorize the multiples of any number from 0 to 10, except 5. As you would start on the number you are multiplying, when you multiply by 0, you stay on 0 (0 is external and so the arrows have no effect on 0, otherwise 0 is used as a link to create a perpetual cycle). The pattern also works with multiples of 10, by starting at 1 and simply adding 0, giving you 10, then just apply every number in the pattern to the \"tens\" unit as you would normally do as usual to the \"ones\" unit.\nFor example, to recall all the multiples of 7:\n\n\nTables can also define binary operations on groups, fields, rings, and other algebraic systems. In such contexts they can be called Cayley tables. Here are the addition and multiplication tables for the finite field Z.\n\nFor every natural number \"n\", there are also addition and multiplication tables for the ring Z.\n\nFor other examples, see group, and octonion.\n\nThe Chinese multiplication table consists of eighty-one sentences with four or five Chinese characters per sentence, making it easy for children to learn by heart. A shorter version of the table consists of only forty-five sentences, as terms such as \"nine eights beget seventy-two\" are identical to \"eight nines beget seventy-two\" so there is no need to learn them twice.\n\nA bundle of 21 bamboo slips dated 305 BC in the Warring States period in the Tsinghua Bamboo Slips (清华简) collection is the world's earliest known example of a decimal multiplication table.\nIn 1989, the National Council of Teachers of Mathematics (NCTM) developed new standards which were based on the belief that all students should learn higher-order thinking skills, and which recommended reduced emphasis on the teaching of traditional methods that relied on rote memorization, such as multiplication tables. Widely adopted texts such as Investigations in Numbers, Data, and Space (widely known as TERC after its producer, Technical Education Research Centers) omitted aids such as multiplication tables in early editions. NCTM made it clear in their 2006 Focal Points that basic mathematics facts must be learned, though there is no consensus on whether rote memorization is the best method.\n\n"}
{"id": "48221862", "url": "https://en.wikipedia.org/wiki?curid=48221862", "title": "Murder of Richard Everitt", "text": "Murder of Richard Everitt\n\nOn 13 August 1994, 15-year-old Richard Everitt was stabbed to death in London in a racially motivated attack. Everitt's neighbourhood, Somers Town, had been the site of ethnic tensions, and although he was not involved in gangs, he was murdered by a gang of British Bangladeshis who were seeking revenge on another White British boy. \n\nThe murderer was not apprehended, as members of the gang fled to Bangladesh. Badrul Miah and Showat Akbar were tried in 1995 as the ringleaders of the gang and were given life sentences, with minimum terms of 12 years and three years in custody respectively.\n\nSomers Town, in the London Borough of Camden, was experiencing urban decay in the early 1990s. Many of its white families had been moved onto newer estates, and the ones who remained lived in poverty and unemployment, and felt in conflict with Bengalis. Bengalis were living in the neighbourhood's worst housing, with problems of overcrowding due to their larger-than-average families.\n\nWhite youths and Bengali youths respectively chose to attend different schools and youth clubs, and interracial relationships were shunned. Hate crimes occurred in the area, with statistics showing that they were predominantly against Bengalis: white locals claimed that this was from exaggerated reports by Bengalis in order to achieve better housing, as well as the police ignoring racial motivations in crimes against white people. Bengalis claimed that their complaints were going unheard.\n\nRichard Everitt attended South Camden Community School, where the ethnic tensions continued, although he was not involved in them. His mother had previously complained when he was allegedly threatened with a knife by an Asian pupil.\n\nOn the night of 13 August 1994, Everitt returned from playing football to ask for permission to go to Burger King with his friends. They encountered a gang of fifteen Bengali youths aged 18–19 and began to run, but Everitt was caught and stabbed with a seven-inch kitchen knife in his shoulder blades, piercing his heart. His friends notified his parents, who came to him as he was loaded into the ambulance. Everitt died at the hospital.\n\nEleven men were arrested and bailed shortly after Everitt was stabbed.\n\nThe trial began on 5 October 1995 at the Old Bailey. On 1 November, Badrul Miah was found guilty of conspiring to murder Everitt and was given a 'life' sentence with a minimum of 12 years in prison; Showat Akbar was found guilty of violent disorder and sentenced to three years' youth detention. Their gang had been seeking revenge on a white teenager suspected of stealing their jewellery, and Miah boasted that he had \"stabbed up a white boy\". Miah and Akbar were deemed by the judge to have been the ringleaders of the attack, but she stated that the identity of the killer was unknown as some of the gang members had fled to Bangladesh.\n\nIn 2006, Miah was given four days' unsupervised release to attend his sister's wedding.\n\nEveritt's murder was received with shock in Somers Town. A Bengali teenager told \"The Independent\" \"The boy seems to have had nothing to do with trouble. We are so shocked that Bengali boys could do this. It is the innocent increasingly who are suffering\". The Deputy Headmaster of Everitt's school told the press that cohesion was generally good at the school. Jalal Uddin, a Bengali activist, spoke of his fears that revenge attacks could continue perpetually.<ref name=news/\n\nA Halal butcher's was firebombed, and white gangs attacked Bengalis. Bengalis told family members to stay indoors, and the police increased their presence in order to combat the gangs. A white gang member said that he would not accept support from the British National Party because \"the BNP comes down here, gets everyone whipped up and then when the trouble starts we get it and they run away\".\n\nAfter the convictions, Everitt's family were abused by Bengali neighbours, and moved to Essex before settling in Haworth, West Yorkshire. His mother successfully campaigned for stronger sentences for knife crime.\n\nThe murder was mentioned by \"India Today\" as attributable to a decline in values among British Asian youth, who were previously considered a model minority but were becoming increasingly involved with drugs and gangs.\n\nIn response to Everitt's murder, the KXL Camden United project was founded using football to bring young people together. The football team is for players aged 15 to 19.\n\nSocialist Workers Party activist Alan Walter launched Camden Action Now alongside Everitt's parents, offering youth activities and aiming to unite the community.\n\n\n"}
{"id": "31587667", "url": "https://en.wikipedia.org/wiki?curid=31587667", "title": "Narcissistic withdrawal", "text": "Narcissistic withdrawal\n\nIn children, narcissistic withdrawal may be described as 'a form of omnipotent narcissism characterised by the turning away from parental figures and by the fantasy that essential needs can be satisfied by the individual alone'.\n\nFor adults, 'in the contemporary literature the term narcissistic withdrawal is instead reserved for an ego defense in pathological personalities'. Such narcissists may feel obliged to withdraw from any relationship that threatens to be more than short-term.\n\nFreud used the term 'to describe the turning back of the individual's libido from the object onto themselves...as the equivalent of narcissistic regression'. On Narcissism saw him explore the idea through an examination of such everyday events as illness or sleep: 'the condition of sleep, too, resembles illness in implying a narcissistic withdrawal of the positions of the libido on to the subject's own self'. A few years later, in '\"Mourning and Melancholia\"...Freud's most profound contribution to object relations theory', he examined how 'a withdrawal of the libido...on a narcissistic basis' in depression could allow both a freezing and a preservation of affection: 'by taking flight into the ego love escapes extinction'.\n\nOtto Fenichel would extend his analysis to borderline conditions, demonstrating how 'in a reactive withdrawal of libido...a regression to narcissism is also a regression to the primal narcissistic omnipotence which makes its reappearance in the form of megalomania'.\n\nFor Melanie Klein, however, a more positive element came to the fore: 'frustration, which stimulates narcissistic withdrawal, is also...a fundamental factor in adaptation to reality'. Similarly, 'Winnicott points out that there is an aspect of withdrawal that is healthy', considering that it might be '\"helpful to think of withdrawal as a condition in which the person concerned (child or adult) holds a regressed part of the self and nurses it, at the expense of external relationships\"'.\n\nHowever, from the mid-20th century onwards, attention has increasingly focused on 'the case in which the subject appeals to narcissistic withdrawal as a defensive solution...a precarious refuge that comes into being as a defense against a disappointing or untrustworthy object. This is found in studies of narcissistic personalities or borderline pathologies by authors such as Heinz Kohut or Otto Kernberg'.\n\nKohut considered that 'the narcissistically vulnerable individual responds to actual (or anticipated) narcissistic injury either with shamefaced withdrawal or with narcissistic rage'. Kernberg saw the difference between normal narcissism and ' \"pathological narcissism\"...[as] withdrawal into \"splendid isolation\"' in the latter instance; while Herbert Rosenfeld was concerned with 'states of withdrawal commonly seen in narcissistic patients in which death is idealised as superior to life', as well as with 'the alternation of states of narcissistic withdrawal and ego disintegration'.\n\nClosely related to narcissistic withdrawal is 'schizoid withdrawal: the escape from too great pressure by abolishing emotional relationships altogether'. All such 'fantastic refuges from need are forms of emotional starvation, megalomanias and distortions of reality born of fear'.\n\n'Narcissists will isolate themselves, leave their families, ignore others, do anything to preserve a special...sense of self' Arguably, however, all such 'narcissistic withdrawal is haunted by its \"alter ego\": the ghost of a full social presence' - with people living their lives 'along a continuum which ranges from the maximal degree of social commitment...to a maximal degree of social withdrawal'.\n\nIf 'of all modes of narcissistic withdrawal, depression is the most crippling', a contributing factor may be that 'depressed persons come to appreciate consciously how much social effort is in fact required in the normal course of keeping one's usual place in undertakings'.\n\nObject relations theory would see the process of therapy as one whereby the therapist enabled his or her patient to have 'resituated the object \"from\" the purely schizoid usage \"to\" the shared schizoid usage (initially) until eventually...the object relation - discussing, arguing, idealizing, hating, etc. - emerged'.\n\nFenichel considered that in patients where 'their narcissistic regression is a reaction to narcissistic injuries; if they are shown this fact\nand given time to face the real injuries and to develop other types of reaction, they may be helped enormously' Neville Symington however estimated that 'often a kind of war develops between analyst and patient, with the analyst trying to haul the patient out of the cocoon...his narcissistic envelope...and the patient pulling for all his worth in the other direction'.\n\n\n"}
{"id": "4639538", "url": "https://en.wikipedia.org/wiki?curid=4639538", "title": "Negative double", "text": "Negative double\n\nThe negative double is a form of takeout double in bridge. It is made by the responder after his right-hand opponent overcalls on the first round of bidding, and is used to show both support for the unbid suits as well as some values. It is treated as forcing, but not unconditionally so. In practice, the negative double is sometimes used as a sort of catch-all, made when no other call properly describes responder's hand. Therefore, a partnership might even treat the negative double as a wide-ranging call that merely shows some values.\n\nUsing the modern negative double convention, it is understood that a double over an initial overcall is conventional, and \"not\" for penalties (but see Playing for penalties). For example, using this convention, the following doubles would be regarded as negative, not for penalty:\n\n\nIn understandings regarding negative doubles, the emphasis is on major suit lengths. This is largely due to the special value that tournament play, especially the pairs game, places on major suits. Since the mid-1980s, the negative double has been used mainly to stand in for a bid in an unbid major suit.\n\nMost partnerships using the negative double agree that it applies only through a particular level of overcall. For example, they may agree that the double of an overcall through 3 is negative, and that beyond 3 a double is for penalties.\n\nAt rubber bridge many players are reluctant to give up the penalty double of an overcall, and so do not use the double as conventional.\n\nThe term \"negative double\" was initially employed to distinguish it from the \"penalty\", or \"business\", or \"positive\" double, and signified a double over an opponent's opening bid whose meaning was a request for partner to bid his best suit. Around 1930, the term \"informatory double\" replaced \"negative double\", and that term later gave way to \"takeout double\" as it is used at present; the original term \"negative double\" fell into disuse.\n\nIn 1957, Alvin Roth in his partnership with Tobias Stone appropriated the abandoned term \"negative double\" to denote a conventional double by responder over an overcall and gave it its current meaning. The bid was also briefly known as \"Sputnik\", because it was as new as the satellite of that name that the Soviet Union had recently launched. The term is still used sometimes in Europe.\n\nThe negative double is generally forcing, but opener might pass to convert the double to a penalty double. There is a special agreement called negative free bids, under which (after the overcall) the bid of a new suit by responder is not forcing. However, most negative doublers play that a new suit response (or free bid), whether at the one level or higher, is forcing.\n\nThe negative double loses even more definition when it can be made with a very broad range of strength, from roughly six HCP up to game forcing values. In a pinch, players use it to \"get by this round of bidding.\"\n\nThe negative double does not cause the partnership to completely lose the ability to penalize an overcall. There are two ways that the overcall can be doubled for penalties. For example:\n\n\nResponder makes a negative double, and opener passes for penalties. This position is analogous to one in which a player makes a takeout double and his partner passes the double, converting it to a penalty double.\n\n\nResponder passes the overcall, opener makes a re-opening double, and responder passes that double for penalties. This can be dangerous, because opener often doesn't know whether responder is simply too weak to make any call, or is hoping that opener can re-open with a double.\n\nThese situations are rare, though, and the more so because some five-card major partnerships play negative doubles \"over minor suit openings only.\" The rationale is that responder knows much more about opener's distribution after a major suit opening than after a minor suit opening, and can better judge whether to play in opener's major suit, to play for penalties by doubling, or to show a suit of his own.\n\nPartnerships have different understandings about the length in unbid suits that is shown by a negative double, and the understandings differ according both to which suits remain unbid and to the current level of the bidding. Nevertheless, the following are popular understandings:\n\n\n"}
{"id": "18345264", "url": "https://en.wikipedia.org/wiki?curid=18345264", "title": "Neural correlates of consciousness", "text": "Neural correlates of consciousness\n\nThe neural correlates of consciousness (NCC) constitute the minimal set of neuronal events and mechanisms sufficient for a specific conscious percept. Neuroscientists use empirical approaches to discover neural correlates of subjective phenomena. The set should be \"minimal\" because, under the assumption that the brain is sufficient to give rise to any given conscious experience, the question is which of its components is necessary to produce it.\n\nA science of consciousness must explain the exact relationship between subjective mental states and brain states, the nature of the relationship between the conscious mind and the electro-chemical interactions in the body (mind–body problem). Progress in neuropsychology and neurophilosophy has come from focusing on the body rather than the mind. In this context the neuronal correlates of consciousness may be viewed as its causes, and consciousness may be thought of as a state-dependent property of some undefined complex, adaptive, and highly interconnected biological system.\n\nDiscovering and characterizing neural correlates does not offer a theory of consciousness that can explain how particular systems experience anything at all, or how and why they are associated with consciousness, the so-called hard problem of consciousness, but understanding the NCC may be a step toward such a theory. Most neurobiologists assume that the variables giving rise to consciousness are to be found at the neuronal level, governed by classical physics, though a few scholars have proposed theories of quantum consciousness based on quantum mechanics.\n\nThere is great apparent redundancy and parallelism in neural networks so, while activity in one group of neurons may correlate with a percept in one case, a different population might mediate a related percept if the former population is lost or inactivated. It may be that every phenomenal, subjective state has a neural correlate. Where the NCC can be induced artificially the subject will experience the associated percept, while perturbing or inactivating the region of correlation for a specific percept will affect the percept or cause it to disappear, giving a cause-effect relationship from the neural region to the nature of the percept.\n\nWhat characterizes the NCC? What are the commonalities between the NCC for seeing and for hearing? Will the NCC involve all the pyramidal neurons in the cortex at any given point in time? Or only a subset of long-range projection cells in the frontal lobes that project to the sensory cortices in the back? Neurons that fire in a rhythmic manner? Neurons that fire in a synchronous manner? These are some of the proposals that have been advanced over the years.\n\nThe growing ability of neuroscientists to manipulate neurons using methods from molecular biology in combination with optical tools (e.g., Adamantidis et al. 2007) depends on the simultaneous development of appropriate behavioral assays and model organisms amenable to large-scale genomic analysis and manipulation. It is the combination of such fine-grained neuronal analysis in animals with ever more sensitive psychophysical and brain imaging techniques in humans, complemented by the development of a robust theoretical predictive framework, that will hopefully lead to a rational understanding of consciousness, one of the central mysteries of life.\n\nThere are two common but distinct dimensions of the term \"consciousness\", one involving \"arousal\" and \"states of consciousness\" and the other involving \"content of consciousness\" and \"conscious states\". To be conscious \"of\" anything the brain must be in a relatively high state of arousal (sometimes called \"vigilance\"), whether in wakefulness or REM sleep, vividly experienced in dreams although usually not remembered. Brain arousal level fluctuates in a circadian rhythm but may be influenced by lack of sleep, drugs and alcohol, physical exertion, etc. Arousal can be measured behaviorally by the signal amplitude that triggers some criterion reaction (for instance, the sound level necessary to evoke an eye movement or a head turn toward the sound source). Clinicians use scoring systems such as the Glasgow Coma Scale to assess the level of arousal in patients.\n\nHigh arousal states are associated with conscious states that have specific content, seeing, hearing, remembering, planning or fantasizing about something. Different levels or states of consciousness are associated with different kinds of conscious experiences. The \"awake\" state is quite different from the \"dreaming\" state (for instance, the latter has little or no self-reflection) and from the state of deep sleep. In all three cases the basic physiology of the brain is affected, as it also is in \"altered states of consciousness\", for instance after taking drugs or during meditation when conscious perception and insight may be enhanced compared to the normal waking state.\n\nClinicians talk about \"impaired states of consciousness\" as in \"the comatose state\", \"the persistent vegetative state\" (PVS), and \"the minimally conscious state\" (MCS). Here, \"state\" refers to different \"amounts\" of external/physical consciousness, from a total absence in coma, persistent vegetative state and general anesthesia, to a fluctuating and limited form of conscious sensation in a minimally conscious state such as sleep walking or during a complex partial epileptic seizure. The repertoire of conscious states or experiences accessible to a patient in a minimally conscious state is comparatively limited. In brain death there is no arousal, but it is unknown whether the subjectivity of experience has been interrupted, rather than its observable link with the organism.\n\nThe potential \"richness of conscious experience\" appears to increase from deep sleep to drowsiness to full wakefulness, as might be quantified using notions from complexity theory that incorporate both the dimensionality as well as the granularity of conscious experience to give an integrated-information-theoretical account of consciousness. As behavioral arousal increases so does the range and complexity of possible behavior. Yet in REM sleep there is a characteristic atonia, low motor arousal and the person is difficult to wake up, but there is still high metabolic and electric brain activity and vivid perception.\n\nMany nuclei with distinct chemical signatures in the thalamus, midbrain and pons must function for a subject to be in a sufficient state of brain arousal to experience anything at all. These nuclei therefore belong to the enabling factors for consciousness. Conversely it is likely that the specific content of any particular conscious sensation is mediated by particular neurons in cortex and their associated satellite structures, including the amygdala, thalamus, claustrum and the basal ganglia.\n\nThe possibility of precisely manipulating visual percepts in time and space has made vision a preferred modality in the quest for the NCC. Psychologists have perfected a number of techniques – masking, binocular rivalry, continuous flash suppression, motion induced blindness, change blindness, inattentional blindness – in which the seemingly simple and unambiguous relationship between a physical stimulus in the world and its associated percept in the privacy of the subject's mind is disrupted. In particular a stimulus can be perceptually suppressed for seconds or even minutes at a time: the image is projected into one of the observer's eyes but is invisible, not seen. In this manner the neural mechanisms that respond to the subjective percept rather than the physical stimulus can be isolated, permitting visual consciousness to be tracked in the brain. In a \"perceptual illusion\", the physical stimulus remains fixed while the percept fluctuates. The best known example is the \"Necker cube\" whose 12 lines can be perceived in one of two different ways in depth.\nA perceptual illusion that can be precisely controlled is \"binocular rivalry\". Here, a small image, e.g., a horizontal grating, is presented to the left eye, and another image, e.g., a vertical grating, is shown to the corresponding location in the right eye. In spite of the constant visual stimulus, observers consciously see the horizontal grating alternate every few seconds with the vertical one. The brain does not allow for the simultaneous perception of both images.\n\nLogothetis and colleagues recorded a variety of visual cortical areas in awake macaque monkeys performing a binocular rivalry task. Macaque monkeys can be trained to report whether they see the left or the right image. The distribution of the switching times and the way in which changing the contrast in one eye affects these leaves little doubt that monkeys and humans experience the same basic phenomenon. In the primary visual cortex (V1) only a small fraction of cells weakly modulated their response as a function of the percept of the monkey while most cells responded to one or the other retinal stimulus with little regard to what the animal perceived at the time. But in a high-level cortical area such as the inferior temporal cortex along the ventral stream almost all neurons responded only to the perceptually dominant stimulus, so that a \"face\" cell only fired when the animal indicated that it saw the face and not the pattern presented to the other eye. This implies that NCC involve neurons active in the inferior temporal cortex: it is likely that specific reciprocal actions of neurons in the inferior temporal and parts of the prefrontal cortex are necessary.\n\nA number of fMRI experiments that have exploited binocular rivalry and related illusions to identify the hemodynamic activity underlying visual consciousness in humans demonstrate quite conclusively that activity in the upper stages of the ventral pathway (e.g., the fusiform face area and the parahippocampal place area) as well as in early regions, including V1 and the lateral geniculate nucleus (LGN), follow the percept and not the retinal stimulus. Further, a number of fMRI and DTI experiments suggest V1 is necessary but not sufficient for visual consciousness.\n\nIn a related perceptual phenomenon, \"flash suppression\", the percept associated with an image projected into one eye is suppressed by flashing another image into the other eye while the original image remains. Its methodological advantage over binocular rivalry is that the timing of the perceptual transition is determined by an external trigger rather than by an internal event. The majority of cells in the inferior temporal cortex and the superior temporal sulcus of monkeys trained to report their percept during flash suppression follow the animal's percept: when the cell's preferred stimulus is perceived, the cell responds. If the picture is still present on the retina but is perceptually suppressed, the cell falls silent, even though primary visual cortex neurons fire. Single-neuron recordings in the medial temporal lobe of epilepsy patients during flash suppression likewise demonstrate abolishment of response when the preferred stimulus is present but perceptually masked.\n\nGiven the absence of any accepted criterion of the minimal neuronal correlates necessary for consciousness, the distinction between a persistently vegetative patient who shows regular sleep-wave transitions and may be able to move or smile, and a minimally conscious patient who can communicate (on occasion) in a meaningful manner (for instance, by differential eye movements) and who shows some signs of consciousness, is often difficult. In global anesthesia the patient should not experience psychological trauma but the level of arousal should be compatible with clinical exigencies.\nBlood-oxygen-level-dependent fMRI have demonstrated normal patterns of brain activity in a patient in a vegetative state following a severe traumatic brain injury when asked to imagine playing tennis or visiting rooms in his/her house. Differential brain imaging of patients with such global disturbances of consciousness (including akinetic mutism) reveal that dysfunction in a widespread cortical network including medial and lateral prefrontal and parietal associative areas is associated with a global loss of awareness. Impaired consciousness in epileptic seizures of the temporal lobe was likewise accompanied by a decrease in cerebral blood flow in frontal and parietal association cortex and an increase in midline structures such as the mediodorsal thalamus.\n\nRelatively local bilateral injuries to midline (paramedian) subcortical structures can also cause a complete loss of awareness. These structures therefore \"enable\" and control brain arousal (as determined by metabolic or electrical activity) and are necessary neural correlates. One such example is the heterogeneous collection of more than two dozen nuclei on each side of the upper brainstem (pons, midbrain and in the posterior hypothalamus), collectively referred to as the reticular activating system (RAS). Their axons project widely throughout the brain. These nuclei – three-dimensional collections of neurons with their own cyto-architecture and neurochemical identity – release distinct neuromodulators such as acetylcholine, noradrenaline/norepinephrine, serotonin, histamine and orexin/hypocretin to control the excitability of the thalamus and forebrain, mediating alternation between wakefulness and sleep as well as general level of behavioral and brain arousal. After such trauma, however, eventually the excitability of the thalamus and forebrain can recover and consciousness can return. Another enabling factor for consciousness are the five or more intralaminar nuclei (ILN) of the thalamus. These receive input from many brainstem nuclei and project strongly, directly to the basal ganglia and, in a more distributed manner, into layer I of much of the neocortex. Comparatively small (1 cm or less) bilateral lesions in the thalamic ILN completely knock out all awareness.\n\nMany actions in response to sensory inputs are rapid, transient, stereotyped, and unconscious. They could be thought of as cortical reflexes and are characterized by rapid and somewhat stereotyped responses that can take the form of rather complex automated behavior as seen, e.g., in complex partial epileptic seizures. These automated responses, sometimes called \"zombie behaviors\", could be contrasted by a slower, all-purpose conscious mode that deals more slowly with broader, less stereotyped aspects of the sensory inputs (or a reflection of these, as in imagery) and takes time to decide on appropriate thoughts and responses. Without such a consciousness mode, a vast number of different zombie modes would be required to react to unusual events.\n\nA feature that distinguishes humans from most animals is that we are not born with an extensive repertoire of behavioral programs that would enable us to survive on our own (\"physiological prematurity\"). To compensate for this, we have an unmatched ability to learn, i.e., to consciously acquire such programs by imitation or exploration. Once consciously acquired and sufficiently exercised, these programs can become automated to the extent that their execution happens beyond the realms of our awareness. Take, as an example, the incredible fine motor skills exerted in playing a Beethoven piano sonata or the sensorimotor coordination required to ride a motorcycle along a curvy mountain road. Such complex behaviors are possible only because a sufficient number of the subprograms involved can be executed with minimal or even suspended conscious control. In fact, the conscious system may actually interfere somewhat with these automated programs.\n\nFrom an evolutionary standpoint it clearly makes sense to have both automated behavioral programs that can be executed rapidly in a stereotyped and automated manner, and a slightly slower system that allows time for thinking and planning more complex behavior. This latter aspect may be one of the principal functions of consciousness. Other philosophers, however, have suggested that consciousness would not be necessary for any functional advantage in evolutionary processes. No one has given a causal explanation, they argue, of why it would not be possible for a functionally equivalent non-conscious organism (i.e., a philosophical zombie) to achieve the very same survival advantages as a conscious organism. If evolutionary processes are blind to the difference between function \"F\" being performed by conscious organism \"O\" and non-conscious organism \"O*\", it is unclear what adaptive advantage consciousness could provide. As a result, an exaptive explanation of consciousness has gained favor with some theorists that posit consciousness did not evolve as an adaptation but was an exaptation arising as a consequence of other developments such as increases in brain size or cortical rearrangement. Consciousness in this sense has been compared to the blind spot in the retina where it is not an adaption of the retina, but instead just a by-product of the way the retinal axons were wired. Several scholars including Pinker, Chomsky, Edelman, and Luria have indicated the importance of the emergence of human language as an important regulative mechanism of learning and memory in the context of the development of higher-order consciousness.\n\nIt seems possible that visual zombie modes in the cortex mainly use the dorsal stream in the parietal region. However, parietal activity can affect consciousness by producing attentional effects on the ventral stream, at least under some circumstances. The conscious mode for vision depends largely on the early visual areas (beyond V1) and especially on the ventral stream.\n\nSeemingly complex visual processing (such as detecting animals in natural, cluttered scenes) can be accomplished by the human cortex within 130–150 ms, far too brief for eye movements and conscious perception to occur. Furthermore, reflexes such as the oculovestibular reflex take place at even more rapid time-scales. It is quite plausible that such behaviors are mediated by a purely feed-forward moving wave of spiking activity that passes from the retina through V1, into V4, IT and prefrontal cortex, until it affects motorneurons in the spinal cord that control the finger press (as in a typical laboratory experiment). The hypothesis that the basic processing of information is feedforward is supported most directly by the short times (approx. 100 ms) required for a selective response to appear in IT cells.\n\nConversely, conscious perception is believed to require more sustained, reverberatory neural activity, most likely via global feedback from frontal regions of neocortex back to sensory cortical areas that builds up over time until it exceeds a critical threshold. At this point, the sustained neural activity rapidly propagates to parietal, prefrontal and anterior cingulate cortical regions, thalamus, claustrum and related structures that support short-term memory, multi-modality integration, planning, speech, and other processes intimately related to consciousness. Competition prevents more than one or a very small number of percepts to be simultaneously and actively represented. This is the core hypothesis of the global workspace theory of consciousness.\n\nIn brief, while rapid but transient neural activity in the thalamo-cortical system can mediate complex behavior without conscious sensation, it is surmised that consciousness requires sustained but well-organized neural activity dependent on long-range cortico-cortical feedback.\n\n"}
{"id": "9082266", "url": "https://en.wikipedia.org/wiki?curid=9082266", "title": "Planet symbols", "text": "Planet symbols\n\nA planet symbol (or \"planetary symbol\") is a graphical symbol used in astrology and astronomy to represent a classical planet (including the Sun and the Moon) or one of the eight modern planets. The symbols are also used in alchemy to represent the metals that are associated with the planets. The use of these symbols is based in ancient Greco-Roman astronomy, although their current shapes are a development of the 16th century.\n\nThe classical planets with their symbols and associated metals are: \n\nThe International Astronomical Union discourages the use of these symbols in modern journal articles, and their style manual proposes one- and two-letter abbreviations for the names of the planets for cases where planetary symbols might be used, such as in the headings of tables.\nThe modern planets with their symbols and abbreviations recommended by the IAU: \n\nThe symbols of Venus and Mars are also used to represent female and male in biology and botany, following a convention introduced by Linnaeus in the 1750s.\n\nThe written symbols for Mercury, Venus, Jupiter, and Saturn have been traced to forms found in late Greek papyri. Early forms are also found in medieval Byzantine codices which preserve ancient horoscopes.\nAntecedents of the planetary symbols are attested in the attributes given to classical deities, represented in simplified pictographic form in the Roman era. \"Bianchini's planisphere\" (2nd century, Louvre inv. Ma 540) shows the seven planets represented by portraits of the seven corresponding gods, each with a simple representation of an attribute, as follows: Mercury has a caduceus; Venus has a cord attached to her necklace which is connected to another necklace; Mars has a spear; Jupiter has a staff; Saturn has a scythe; the Sun has a circlet with rays emanating from it; and the Moon has a headdress with a crescent attached.\n\nA diagram in the astronomical compendium by Johannes Kamateros (12th century) shows the Sun represented by the circle with a ray, Jupiter by the letter \"zeta\" (the initial of Zeus, Jupiter's counterpart in Greek mythology), Mars by a shield crossed by a spear, and the remaining classical planets by symbols resembling the modern ones, without the cross-mark seen in modern versions of the symbols. These cross-marks first appear in the late 15th or early 16th century. According to Maunder, the addition of crosses appears to be \"an attempt to give a savour of Christianity to the symbols of the old pagan gods.\"\n\nThe modern symbols for the seven classical planets are found in a woodcut of the seven planets in a Latin translation of Abu Ma'shar's \"De Magnis Coniunctionibus\" printed at Venice in 1506, represented as the corresponding gods riding chariots.\n\nEarth is not one of the classical planets (the word \"planet\" by definition describing \"wandering stars\" as seen from Earth's surface). \nIts status as planet is a consequence of the development of heliocentrism.\nNevertheless, there are ancient symbols for Earth, notably a cross representing the four cardinal directions, as a cross in a circle also interpreted as a globe with equator and a meridian;\nThe \"Earth\" symbol is encoded by Unicode at U+1F728 (; alternative characters with similar shape are: U+2295 ⊕ CIRCLED PLUS; U+2A01 ⨁ N-ARY CIRCLED PLUS OPERATOR).\nAlternatively, there is the globus cruciger (U+2641 ), now most commonly used as planetary symbol.\nThe \"globus cruciger\" symbol is also used as an alchemical symbol of antimony.\nUranus (U+26E2 ), also U+2645 , a globe surmounted by the letter \"H\" for Herschel):\nThe symbols for Uranus were created shortly after its discovery in 1781. One symbol, , invented by J. G. Köhler and refined by Bode, was intended to represent the newly discovered metal platinum; since platinum, commonly called white gold, was found by chemists mixed with iron, the symbol for platinum combines the alchemical symbols for iron, ♂, and gold, ☉. This symbol also combines the symbols of Mars (♂) and the Sun (☉) because in Greek Mythology, Uranus represented heaven, and represents the combined power of Mars' spear and the Sun. \nAnother symbol, , was suggested by Lalande in 1784. In a letter to Herschel, Lalande described it as \"un globe surmonté par la première lettre de votre nom\" (\"a globe surmounted by the first letter of your name\").\n\nNeptune (U+2646 ), Neptune's trident, also , a globe surmounted by the letters \"L\" and \"V\" for Le Verrier):\nSeveral symbols were proposed for Neptune to accompany the suggested names for the planet. Claiming the right to name his discovery, Urbain Le Verrier originally proposed the name \"Neptune\" and the symbol of a trident, while falsely stating that this had been officially approved by the French Bureau des Longitudes. In October, he sought to name the planet \"Leverrier\", after himself, and he had loyal support in this from the observatory director, François Arago, who in turn proposed a new symbol for the planet (). However, this suggestion met with stiff resistance outside France. French almanacs quickly reintroduced the name \"Herschel\" for \"Uranus\", after that planet's discoverer Sir William Herschel, and \"Leverrier\" for the new planet. Professor James Pillans of the University of Edinburgh defended the name \"Janus\" for the new planet, and proposed a key for its symbol. Meanwhile, Struve presented the name \"Neptune\" on December 29, 1846, to the Saint Petersburg Academy of Sciences. In August 1847, the Bureau des Longitudes announced its decision to follow prevailing astronomical practice and adopt the choice of \"Neptune\", with Arago refraining from participating in this decision.\n\nPluto was also considered a planet from its discovery in 1930 until its re-classification as a \"dwarf planet\" in 2006. The symbol used for Pluto was a ligature of the letters P and L (Unicode U+2647 ).\n\nIn the 19th century, symbols for the major asteroids were also in use, including \nVesta (an altar with fire on it; U+26B6), Juno (a sceptre; U+26B5), Ceres (a reaper's scythe; U+26B3), Pallas ( U+26B4);\nEncke (1850) has further symbols for Astraea, Hebe, Iris, Flora and Metis.\nUnicode furthermore has a symbol ( U+26B7) for 2060 Chiron (discovered 1977).\n\nThe crescent shape has been used to represent the Moon since earliest times. In classical anqituity, it is worn by lunar deities (Selene/Luna, Artemis/Diana, Men, etc.) either on the head or behind the shoulders, with its horns pointing upward. \nIts representation with the horns pointing sideways (as a heraldic \"crescent increscent\" or \"crescent decrescent\") is early modern.\n\nThe same symbol can be used in a different context not for the Moon itself but for a lunar phase, as part of a sequence of four symbols\nfor \"new moon\" (U+1F311 🌑), \"waxing\" (U+263D ☽), \"full moon\" (U+1F315 🌕) and \"waning\" (U+263E ☾).\n\nThe symbol for Mercury(U+263F ) is ultimately derived from the caduceus, or intertwined serpents, which were the main attribute of Mercury/Hermes throughout antiquity. \nThe caduceus was usually shown with at least three loops, but this was simplified to a single loop in the diagram of Kamateros (12th century). \nThe modern symbol has also been interpreted as representing the god's winged headdress.\n\nThe Venus symbol (♀) consists of a circle with a small cross below it. \nIt originates in Late Antiquity as an astrological symbol for the planet Venus (associated with the goddess Venus), and hence as alchemical symbol for copper. In modern times, it is still used as the astronomical symbol for Venus, although its use is discouraged\nby the International Astronomical Union.\n\nIn zoology and botany, it is used to represent the female sex (alongside the astrological symbol for Mars representing the male sex), following a convention introduced by Linnaeus in the 1750s.\nFollowing the biological convention, the symbol in the 20th century also came to be used in sociological contexts to represent women or femininity.\n\nThe symbol appears without the cross-mark (⚲) in Johannes Kamateros (12th century). In the \"Bianchini's planisphere\" (2nd century), Venus is represented by a necklace. \nThe idea that the symbol represents the goddess' hand mirror dates to the 19th century.\n\nUnicode encodes the FEMALE SIGN at U+2640 (♀), in the Miscellaneous Symbols block.\n\nThe modern astronomical symbol for the Sun (circled dot, Unicode U+2609 ☉) was first used in the Renaissance.\n\n\"Bianchini's planisphere\", produced in the 2nd century, has a circlet with rays radiating from it.\nA diagram in Johannes Kamateros' 12th century \"Compendium of Astrology\" shows the Sun represented by a circle with a ray. This older symbol is encoded by Unicode (version 9.0, June 2016) as \"ALCHEMICAL SYMBOL FOR GOLD\" (🜚 U+1F71A) in the Alchemical Symbols block.\n\nThe Mars symbol (♂) is a depiction of a circle with an arrow emerging from it, pointing at an angle to the upper right. As astrological symbol it represents the planet Mars (connected to the god Mars (Ares)) and hence iron in alchemy. In zoology and botany, it is used to represent the male sex (alongside the astrological symbol for Venus representing the female sex), following a convention introduced by Linnaeus in the 1750s.\n\nThe symbol in its current form represents spear and shield and dates to the early 16th century. It is derived from a medieval form where the spear was drawn across the shield, which in turn was based on a convention used in antiquity (\"Bianchini's planisphere\") which represented Mars by a spear.\nA diagram in the 12th-century \"Compendium of Astrology\" by Johannes Kamateros represents Mars by a shield crossed by a spear.\n\nThe origin of the symbol for Jupiter (U+2643 ) is not entirely clear.\nJupiter's attribute is a sceptre (as king of the gods), but Kamateros (12th century) represents Jupiter simply by the letter \"zeta\" ζ (for \"Zeus\"). The modern symbol as used from the 16th century is apparently based on a majuscule zeta Ζ with the addition of a vertical stroke to form the Christian cross. The less-than-intuitive symbol gave rise to various ad hoc interpretations by modern commentators; thus, the editors of the \"Penny cyclopedia\" (1842) thought might \"supposed to be a symbol of the thunder (arm and hand holding thunder?)\" and more recently the sign has been reported as based on the \"Egyptian hieroglyph for the eagle\".\n\nSaturn is usually depicted with a scythe or sickle, and the planetary symbol has apparently evolved from a picture of this attribute, in Kamateros (12th century) shown in a shape similar to the letter \"eta\" η, with the horizontal stroke added along with the \"Christianization\" of the other symbols in the early 16th century, (U+2644 ).\n\nThe Unicode symbol for Pluto is (♇) PLUTO at U+2647.\nThe Unicode symbol for Ceres is (⚳) CERES at U+26B3.\n\nThe Unicode symbol for Pallas is (⚴) PALLAS at U+26B4.\n\nThe Unicode symbol for Juno is (⚵) JUNO at U+26B5.\n\nThe Unicode for Vesta is (⚶) VESTA at U+26B6.\n\nThe Unicode symbol for Chiron is (⚷) CHIRON at U+26B7.\n\n"}
{"id": "26610577", "url": "https://en.wikipedia.org/wiki?curid=26610577", "title": "Power-control theory of gender and delinquency", "text": "Power-control theory of gender and delinquency\n\nIn criminology, the power-control theory of gender and delinquency (abbreviated as the power-control theory) holds the gender distribution of delinquency is caused by stratification from gender relations within the family. The theory seeks to explain gender differences in the rates of delinquency by attributing them to the level of social/parental control practiced. The theory states that the class, gender, and type of family structure (e.g. egalitarian or patriarchal) will influence the severity of social/parental control practiced which will in turn set the \"accepted norm\" for the child/individual. This norm will in turn control the level of delinquency by the individual.\n\nPower-control theory differs from other control theories that view crime as a cause of low social status (cited from book). This theory compares gender and parental control mechanisms in two different types of families; patriarchal and egalitarian to explain the differences in self-reported male and female misconduct. In patriarchal families, traditional gender roles were in practice, where the father would work outside the home, and the mother would be responsible for the child rearing. In egalitarian families, the household roles were shared equally between mothers and fathers.\n\nThe theory was originally posited by John Hagan and further developed by A. R. Gillis and John Simpson at the University of Toronto.\n\nThe power control theory was developed through a series of self-report surveys that was administered to high school students and their parents in suburban Toronto. Hagan and his colleagues contended that gender and the social class of the students' parents affected how much freedom these students had. For example, coming of age as they argued, was a more limiting experience than growing up as a male. Thereby, they found that the amount of power a parent had in the workplace was related to the control displayed in the household over their teenaged children. Moreover, parents who had the types of jobs where they must supervise the activities of subordinates also tended to be relatively tolerant of the trouble-making behaviour of their children, especially of their sons. This meant that teenaged boys are freer to deviate than teenaged girls. This study also found, focusing on relatively minor forms of deviance such as shoplifting and breaking street lights, that middle-class youth actually were freer to deviate than working-class youth.\n\nAccording to Julian Tanner, he offers two interesting critical comments. Though the power control theory effectively explains common delinquency among ordinary youth, it does not explain violent and repetitive crime and, therefore, the power control theory cannot predict such behavior. In addition, the power control theory suggests that parents in egalitarian households are more likely to raise females as delinquent than a female growing up in a patriarchal family; however, UCR (uniform crime report) data shows that the opposite association exists and that the involvement in female labor force is actually related to lower levels of female delinquency. Also, after years of refining the power control theory, theorists have found the notion that mothers being more controlling over their daughters are more likely to be found in egalitarian families than patriarchal families, which is the opposite relationship the power control theory would likely predict.\n\nWhen the theory was refined over the years, Singer and Levine (1988) found mixed support for the theory in their early attempts to test this theory. While mothers were seen to be more controlling over their daughters than their sons, the authors also found this to be more so with egalitarian than patriarchal families, which is a finding opposite to what power control theory would predict.\n\nThe theory has been extended into adult social roles as well. Stratified behaviors typically associated with males, particularly those in authoritative positions, are now being seen more frequently in females attaining powerful roles. And like their male counterparts, their power is used to control those persons in subordinate roles, as indicated by the rise in reports of sexual harassment (cougar syndrome) and cronyism.\n\nDespite the explanation of social roles, there has not been a feminist theory that is fully developed to explain for the uniqueness of female criminality. While males are reported to be more involved in every type of crime, females tend to be arrested for considerably minor property crimes. This is due to the idea that the character and level of female crime is not consistent with the traditional sociological explanations of crime.\n\n\n"}
{"id": "10614570", "url": "https://en.wikipedia.org/wiki?curid=10614570", "title": "Precision bias", "text": "Precision bias\n\nPrecision bias is a form of cognitive bias in which an evaluator of information commits a logical fallacy as the result of confusing accuracy and precision. More particularly, in assessing the merits of an argument, a measurement, or a report, an observer or assessor falls prey to precision bias when he or she believes that greater precision implies greater accuracy (i.e., that simply because a statement is precise, it is also true); the observer or assessor are said to provide false precision.\n\nPrecision bias, whether called by that phrase or another, is addressed in fields such as economics, in which there is a significant danger that a seemingly impressive quantity of statistics may be collected even though these statistics may be of little value for demonstrating any particular truth.\n\nIt is also called the numeracy bias, or the range estimate aversion.\n\nThe clustering illusion and the Texas sharpshooter fallacy may both be treated as relatives of precision bias. In these former fallacies, precision is mistakenly considered evidence of causation, when in fact the clustered information may actually be the result of randomness.\n\n\n"}
{"id": "49783", "url": "https://en.wikipedia.org/wiki?curid=49783", "title": "Reading education in the United States", "text": "Reading education in the United States\n\nReading education is the process by which individuals are taught to derive meaning from text. Schoolchildren not capable of reading competently by the end of third grade can face obstacles to success in education. The third grade marks a crucial point in reading because students start to encounter broader variety of texts in their fourth grade. \n\nGovernment-funded research on reading and reading instruction in the United States began in the 1960s. In the 1970s and 1980s, researchers began publishing findings based on converging evidence from multiple studies. However, these findings have been slow to move into typical classroom practice.\n\nProficient reading is equally dependent on two critical skills: the ability to understand the language in which the text is written, and the ability to recognize and process printed text. Each of these competencies is likewise dependent on lower level skills and cognitive abilities.\n\nChildren who readily understand spoken language and who are able to fluently and easily recognize printed words do not usually have difficulty with reading comprehension. However, students must be proficient in both competencies to read well; difficulty in either domain undermines the overall reading process. At the conclusion of reading, children should be able to retell the story in their own words including characters, setting, and the events of the story. Reading researchers define a skilled reader as one who can understand written text as well as they can understand the same passage if spoken.\nThere is some debate as to whether print recognition requires the ability to perceive printed text and translate it into spoken language, or rather to translate printed text directly into meaningful symbolic models and relationships. The existence of speed reading, and its typically high comprehension rate would suggest that the translation into verbal form as an intermediate to understanding is not a prerequisite for effective reading comprehension. This aspect of reading is the crux of much of the reading debate.\n\nThe purpose of reading is to have access to the literature of a specific language. Reading materials have traditionally been chosen from literary texts that represent 'higher' forms of culture. According to many traditional approaches, the learner's aim is to study vocabulary items, grammar and sentence structures, with a concern for learning the syntax of these 'higher' cultures. These approaches assume that authentic reading material is limited to the work or experience of great authors.\n\nA variety of different methods of teaching reading have been advocated in English-speaking countries.\nIn the United States, the debate is often more political than objective. Parties often divide into two camps which refuse to accept each other's terminology or frame of reference. Despite this both camps often incorporate aspects of the other's methods. Both camps accuse the other of causing failure to learn to read and write. Phonics advocates assert that, to read a large vocabulary of words correctly and fluently requires detailed knowledge of the structure of the English language, particularly spelling-speech patterns. Whole Language advocates assert that students do not need to be able to sound out words, but should look at unknown words and figure them out using context.\n\nIn 2000, the National Reading Panel (NRP) issued a report based on a meta-analysis of published research on effective reading instruction. The report found varying evidence-based support for some common approaches to teaching reading.\n\nThe NRP called phonemic awareness (PA) instruction \"impressive\":\n\nThe report singles out PA instruction based on teaching children to manipulate phonemes with letters as highly effective. Phonemic awareness instruction also improved spelling in grade-level students, although it did not improve spelling in disabled readers.\n\nLexical reading involve acquiring words or phrases without attention to the characters or groups of characters that compose them or by using Whole language learning and teaching methodology. Sometimes argued to be in competition with phonics methods, and that the whole language approach tends to impair learning how to spell.\n\nHistorically, the two camps have been called Whole Language and Phonics, although the Whole Language instructional method has also been referred to as \"literature-based reading program\" and \"integrated language arts curriculum\". Currently (2007), the differing perspectives are frequently referred to as \"balanced reading instruction\" (Whole Language) and \"scientifically-based reading instruction\" (Phonics).\n\nWhole word, also known as \"Sight Word\" and \"Look and Say\", teaches reading skills and strategies in the context of authentic literature. Word recognition accuracy is considered less important than meaning accuracy; therefore, there is an emphasis on comprehension as the ultimate goal.\n\nStudents in this method memorize the appearance of words, or learn to recognize words by looking at the first and last letter from rigidly selected vocabularies in progressive texts (such as \"The Cat in the Hat\"). Often preliminary results show children taught with this method have higher reading levels than children learning phonics, because they learn to automatically recognise a small selection of words. However, later tests demonstrate that literacy development becomes stunted when hit with longer and more complex words later.\n\nSub-lexical reading, involves teaching reading by associating characters or groups of characters with sounds or by using Phonics learning and teaching methodology. Sometimes argued to be in competition with whole language methods.\n\n Phonics refers to an instructional method for teaching children to read. The method teaches sounds to be associated with letters and combinations of letters. \"Phonics\" is distinct from the linguistics terms \"phoneme\" and \"phonetics\", which refer to sounds and the study of sounds respectively.\n\nVarieties of phonics include:\n\n\nThe Orton phonography, originally developed to teach brain-damaged adults to read, is a form of phonics instruction that blends synthetic and analytic components. Orton described 73 \"phonograms\", or letter combinations, and 23 rules for spelling and pronunciation which Orton claimed would allow the reader to correctly pronounce and spell all but 123 of the 13,000 most common English words.\n\nIn contrast to phonics which teaches the pronunciation rules of English, a new technology Phonetically Intuitive English directly shows English words' pronunciation by adding diacritical marks on them. This solves the problem that pronunciation rules can often be confusing (for example, \"ea\" has a wide range of diverse pronunciations in \"speak\", \"steak\", \"bread\", \"Korea\", \"reality\", \"create\" and \"ocean\").\n\nThe pronunciation-guide approach has been proven very successful in reading education for languages with very complex orthography such as Chinese. Pinyin and Zhuyin are systems of phonetic transcription for Mandarin Chinese used in China and Taiwan respectively, and are printed above or next to Chinese characters in children's books, textbooks and newspapers as a pronunciation guide, and have enabled Chinese-speaking countries to achieve high literacy rates for one of the most difficult languages in the world.\n\nDuring guided reading teachers work with small groups of students. These are students with similar reading levels. Students will read with teachers in books at their personal reading level, not where the grade level is at. During this time the teachers will work with students to practice decoding, fluency, vocabulary and comprehension skills.\n\nSome methods of mix phonics and whole word. Native reading, for example, differs from both in that it emphasizes teaching reading beginning at a very early age, when the human brain is neurodevelopmentally most receptive to learning language. Native readers learn to read as toddlers, starting at the same time they learn to speak, or very soon thereafter.\n\nReading Workshop is based on the premise that readers need time to read and discuss their reading. Readers need access to a wide variety of reading materials of their choice. Classrooms must acquire a wide variety of reading materials to accommodate this need. Readers need to respond to the text and demonstrate quality literate behaviors. There is not a script to follow but a frame work to guide instruction. Students are exposed to a variety of learning experiences. There is time for student collaboration and a time for engaged reading.\n\nDuring reading workshop, the teacher models a whole-group strategy lesson and then gives students large blocks of time to read and to practice the strategy. This practice can occur independently, with partners, or in small groups with a book or text chosen by the student. The teacher moves around the room and confers with the students about their reading. The teacher can meet with small, flexible groups to provide additional needs-based instruction. At the end of the workshop the whole groups comes together to share their learning.\n\nAn adult or peer reads with the student by modeling fluent reading and then asking the student to read the same passage aloud with encouragement and feedback by the adult or peer.\nA student listens to a tape of a fluent reader reading text at the student's independent level at a pace of about 80-100 words a minute. The student listens to the tape the first time and then practices reading along with the tape until the student is able to read fluently.\nThe student reads with a peer partner. Each partner takes a turn reading to the other. A more fluent reader can be paired with a less fluent reader to model fluent reading. The more fluent reader can provide feedback and encouragement to the less fluent reader. Students of similar reading skills can also be paired, particularly if the teacher has modeled fluent reading and the partner reading involves practice.\n\nThe following is a list of the seven important strategies that all readers must be able to apply to text in order to read and understand content. The seven strategies are:\n\nReading comprehension requires making sense of text, which allows a reader to gain knowledge, enjoy a story, and make connections with the larger world. Several skills support reading comprehension, including making predictions and inferences, monitoring understanding, using text structures, and using prior knowledge effectively. Two of the most important aspects of successful comprehension are activating prior knowledge and metacognition, which are two of the principles of learning identified in the National Research Council's report.\"\n\nMany studies have identified the importance of prior knowledge in reading comprehension. \"Many researchers have shown that having some prior knowledge about the topic of a passage enables both greater comprehension of the text and better memory for it.\" \"if we have prior knowledge about a topic in a text, we construct meaning based on our experience, and we can adjust and change those plans as we go along.\" Some authors specify two types of prior knowledge necessary for successful comprehension. World knowledge aids in understanding fiction and domain-specific knowledge facilitates comprehension of nonfiction. Students who lack this, request background information, so as to make connections with and within the text.\n\nAnother learning principle that greatly influences reading comprehension is the use of metacognition. The 'metacognitive' approach to instruction can help students learn to take control of their own learning by defining learning goals and monitoring their progress in achieving them.\" A great deal of research indicates that accomplished readers \"monitor their comprehension as they read by engag[ing] in strategic processing, such as rereading previous text, to resolve comprehension failure.\" Students who are not able to track their own understanding gain neither information or enjoyment from reading as they do not know how to obtain meaning from the text.\n\nMany strategies have been applied. Many studies point to the success of strategy instruction, particularly for students who are poor comprehenders. Some strategies that have been helpful are summarization, question generation, making predictions and inferences, image making, knowledge and use of text structure, rereading, self-regulation, activation of prior knowledge, questioning the author, and using graphic organizers. The variety of strategies allows the teacher to choose a strategy or strategies to suit the text and the needs of the student.\n\nFor an example of a specific intervention incorporating four strategies for comprehension building, utilized reciprocal teaching to model summarizing, questioning, clarifying, and predicting. The authors indicate that they choose these skills due to their dual functions as \"comprehension-fostering and comprehension monitoring activities.\" The reciprocal teaching method, which involves the teacher modeling the designated activities and gradually turning the procedure over to the students themselves, uses Vygotsky's idea of scaffolding. In this process, \"children first experience a particular set of cognitive activities in the presence of experts, and only gradually come to perform these functions by themselves. In this study, the students who participated in the reciprocal teaching intervention showed dramatic improvement in comprehension scores and maintained them for at least eight weeks.\n\nPrograms have been established to provide certified therapy animals, such as dogs, as non-judgmental \"listeners\" to build motivation and help children build proficiency and gain confidence in their reading ability.\n\nNational literacy rates range from about 10 percent to 99+ percent.\n\nThere are several approaches used to teach reading and the U.S. Office of Education Cooperative Research Program has a compilation of these. For example, there is a list based on 29 individual studies that identify effective approaches when teaching reading for beginners. The bulk of the studies revealed that successful instructional strategies include systematic phonics and approaches that focus on connected reading and meaning. These strategies were proved to be more effective than basal alone approaches. Specific studies that show instructional models that achieve high success rates in reading education include the so-called Actual Community Empowerment (ACE) program, which is a small-group tutoring framework that focuses on fluency, word recognition, decoding and the concept of comprehension that is based on the appropriate pace of learning according to individual learning profiles. The program, thus, has different variations. Once ACE was implemented in 40 locations in Philadelphia, learners posted a 95 percent success rate for significant reading improvement. Traditional reading instruction approaches that are considered effective include those under a cognitive-based model, which treats reading acquisition and reading comprehension to be dependent on cognitive development.\n\nPrint exposure the amount of time a child or person spends being visually aware of the written word (reading)--whether that be through newspapers, magazines, books, journals, scientific papers, or more. Research has shown that the amount of print material that a child accesses has deep cognitive consequences. In addition, the act of reading itself, for the most part irrespective of what is being read, increases the achievement difference among children.\n\nChildren who are exposed to large amounts of print often have more success in reading and have a larger vocabulary to draw from than children who see less print. The average conversations among college graduates, spouses or adult friends contain less rare (advanced) words than the average preschool reading book. Other print sources have increasingly higher amounts of rare words, from children's books, to adult books, to popular magazines, newspapers, and scientific articles (listed in increasing level of difficulty). Television, even adult news shows, do not have the same level of rare words that children's books do.\n\nThe issue is that oral language is very repetitive. To learn to read effectively a child needs to have a large vocabulary. Without this, when the child does read they stumble over words that they do not know, and have trouble following the idea of the sentence. This leads to frustration and a dislike of reading. When a child is faced with this difficulty he or she is less likely to read, thus further inhibiting the growth of their vocabulary.\n\nChildren who enjoy reading do it more frequently and improve their vocabulary. A study of out-of-school reading of fifth graders, found that a student in the 50th percentile read books about 5 minutes a day, while a student in the 20th percentile read books for less than a minute a day. This same study found that the amount of time a child in the 10th percentile spent reading in two days, was the amount of time a child in the 90th percentile spent reading all year.\n\nPrint exposure can also be a big factor in learning English as a second language. Book flood experiments are an example of this. The book flood program brought books in English to the classroom. Through focusing their English language learning on reading books instead of endless worksheets the teachers were able to improve the rate at which their students learned English.\n\nBeginning readers must understand the concept of the \"alphabetic principle\" in order to master basic reading skills. A writing system is said to be \"alphabetic\" if it uses symbols to represent individual language sounds. In comparison, Logographic writing systems such as Japanese kanji and Chinese hanzi use a symbol to represent a word. And both cultures also use syllabic writing systems such as Japanese kana and Chinese Yi script, there are also many Chinese alphabets.\n\nEnglish is one of several languages using the Latin Alphabet writing system. The orthographic depth of such languages varies. The Italian and Finnish languages have the purest, or shallowest orthographies, and English orthography is the deepest or most complex. In the shallow Spanish orthography; most words are spelled the way they sound, that is, word spellings are almost always regular. English orthography, on the other hand, is far more complex in that it does not have a one-to-one correspondence between symbols and sounds. English has individual sounds that can be represented by more than one symbol or symbol combination. For example, the long |a| sound can be represented by a-consonant-e as in ate, -ay as in hay, -ea as in steak, -ey as in they, -ai as in pain, and -ei as in vein. In addition, there are many words with irregular spelling and many homophones (words that sound the same but have different meanings and often different spellings as well). Pollack Pickeraz (1963) asserted that there are 45 phonemes in the English language, and that the 26 letters of the English alphabet can represent them in about 350 ways.\n\nThe irregularity of English spelling is largely an artifact of how the language developed.\nEnglish is a West Germanic language with substantial influences and additional vocabulary from Latin, Greek, and French, among others. Imported words usually follow the spelling patterns of their language of origin. Advanced English phonics instruction includes studying words according to their origin, and how to determine the correct spelling of a word using its language of origin.\n\nClearly, the complexity of English orthography makes it more difficult for children to learn decoding and encoding rules, and more difficult for teachers to teach them. However, effective word recognition relies on the basic understanding that letters represent the sounds of spoken language, that is, word recognition relies on the reader's understanding of the alphabetic principle\n\nAttempts to make English spelling behave phonetically have given rise to various campaigns for spelling reform; none have been generally accepted. Opponents of simplified spellings point to the impossibility of phonetic spelling for a language with many diverse accents and dialects. Several distinguished scholars, however, have thoroughly disproven all reasonable objections to spelling reform, including this objection. See, for example, \"Dictionary of Simplified American Spelling.\" Thomas Lounsbury presented a devastating rebuttal to all reasonable objections to spelling reform in 1909. A shorter rebuttal of all the reasonable objections to spelling reform was made by Bob C Cleckler in 2005.\n\nLinguists documenting the sounds of speech use various special symbols, of which the International Phonetic Alphabet is the most widely known. Linguistics makes a distinction between a phone and phoneme, and between phonology and phonetics. The study of words and their structure is morphology, and the smallest units of meaning are morphemes. The study of the relationship between words present in the language at one time is synchronic etymology, part of descriptive linguistics, and the study of word origins and evolution is diachronic etymology, part of historical linguistics\n\nEnglish orthography gives priority first to morphology, then to etymology, and lastly to phonetics. Thus the spelling of a word is dependent principally upon its structure, its relationship to other words, and its language or origin. It is usually necessary to know the meaning of a word in order to spell it correctly, and its meaning will be indicated by the similarity to words of the same meaning and family.\n\nEnglish uses a 26 letter Latin alphabet, but the number of graphemes is expanded by several digraphs, trigraphs, and tetragraphs, while the letter \"q\" is not used as a grapheme by itself, only in the digraph \"qu\".\n\nEach grapheme may represent a limited number of phonemes depending on etymology and location in the word. Likewise each phoneme may be represented by a limited number of graphemes. Some letters are not part of any grapheme, but function as etymological markers. Graphemes do not cross morpheme boundaries.\n\nMorphemes are spelled consistently, following rules inflection and word-formation, and allow readers and writers to understand and produce words they have not previously encountered.\n\nThis method was designed to overcome the fact that English orthography has a many-to-many relationship between graphemes and phonemes. The method fell into disuse because children still had to learn the Latin alphabet and the conventional English spellings in order to integrate with society outside of school. It also recreated the problem of dialect dependent spelling, which the standardization of spelling had been created to eliminate.\n\nUnlike spelling reforms, we can actually keep a word's original spelling intact but add pronunciation information to it, e.g. using diacritics. Phonetically Intuitive English is a Chrome browser extension that automatically adds such a pronunciation guide to English words on Web pages, for English-speaking children to recognize a written word's pronunciation and therefore map the written word to the mental word in his mind.\n\nIn practice, many children are exposed to both \"Phonic\" and \"Whole Language\" methods, coupled with reading programs that combine both elements. For example, the extremely popular book, \"Teach Your Child to Read in 100 Easy Lessons\", by Siegfried Engelman, et al. (), teaches pronunciation and simple phonics, then supplements it with progressive texts and practice in directed reading. The end result of a mixed method is a casually phonetic student, a much better first-time pronouncer and speller, who still also has look-say acquisition, quick fluency and comprehension. Using an eclectic method, students can select their preferred learning style. This lets all students make progress, yet permits a motivated student to use and recognize the best traits of each method.\n\nSpeed reading continues where basic education stops. Usually after some practice, many students' reading speed can be significantly increased. There are various speed-reading techniques.\n\nHowever, speed reading does not guarantee comprehension or retention of what was read.\n\nReadability indicates the ease of understanding or comprehension due to the style of writing. Reading recovery is a method for helping students learn to read.\n\nIn colonial times, reading instruction was simple and straightforward: teach children the code and then let them read. At that time, reading material was not specially written for children but consisted primarily of the Bible and some patriotic essays; the most influential early textbook was \"The New England Primer,\" published late 1680s. There was little consideration for how best to teach children to read or how to assess reading comprehension.\n\nFrom the 1890s to at least 1910, A. L. Burt of New York and other publishing companies published series of books aimed at young readers, using simple language to retell longer classics. Mrs J. C. Gorham produced three such works, \"Gulliver's Travels in words of one syllable\" (1896), \"Alice's Adventures in Wonderland retold in words of one syllable\" (1905), and \"Black Beauty retold in words of one syllable\" (1905). In the UK, Routledge published a similar series between 1900 and 1910.\n\nThe meaning-based curriculum did not dominate reading instruction until the second quarter of the 20th century. Beginning in the 1930s and 1940s, reading programs became very focused on comprehension and taught children to read whole words by sight. Phonics was not to be taught except sparingly and as a tool to be used as a last resort.\n\nIn the 1950s Rudolf Flesch wrote a book called \"Why Johnny Can't Read\", a passionate argument in favor of teaching children to read using phonics. Addressed to the mothers and fathers of America, he also hurled severe criticism at publishers' decisions that he claimed were motivated by profit, and he questioned the honesty and intelligence of experts, schools, and teachers. The book was on the best seller list for 30 weeks and spurred a hue and cry in general population. It also polarized the reading debate among educators, researchers, and parents.\n\nThis polarization continues to the present time. In the 1970s an instructional philosophy called whole language (which de-emphasizes teaching phonics out of context) was introduced, and it became the primary method of reading instruction in the 1980s and 1990s. During this time, researchers (such as the National Institute of Health) conducted studies showing that early reading acquisition depends on the understanding of the connection between sounds and letters.\n\nThe sight-word (Whole Word) method was invented by Rev. Thomas H. Gallaudet, the director of the American Asylum at Hartford in the 1830s. It was designed for the education of the Deaf by juxtaposing a word, with a picture.In 1830, Gallaudet provided a description of his method to the American Annals of Education which included teaching children to recognize a total of 50 sight words written on cards and by 1837 the method was adopted by the Boston Primary School Committee. Horace Mann the then Secretary of the Board of Education of Massachusetts, USA favored the method and it soon became the dominant method statewide. By 1844 the defects of the new method became so apparent to Boston schoolmasters that they issued an attack against it urging a return to an intensive, systematic phonics. Again Dr. Samuel Orton, a neuropathologist in Iowa in 1929 sought the cause of children's reading problems and concluded that their problems were being caused by the new sight method of teaching reading. (His results were published in the February 1929 issue of the Journal of Educational Psychology, \"The Sight Reading Method of Teaching Reading as a Source of Reading Disability.\")\n\n\n\n"}
{"id": "276582", "url": "https://en.wikipedia.org/wiki?curid=276582", "title": "Ricci curvature", "text": "Ricci curvature\n\nIn differential geometry, the Ricci curvature tensor, named after Gregorio Ricci-Curbastro, represents the amount by which the volume of a narrow conical piece of a small geodesic ball in a curved Riemannian manifold deviates from that of the standard ball in Euclidean space. As such, it provides one way of measuring the degree to which the geometry determined by a given Riemannian metric might differ from that of ordinary Euclidean -space. The Ricci tensor is defined on any pseudo-Riemannian manifold, as a trace of the Riemann curvature tensor. Like the metric itself, the Ricci tensor is a symmetric bilinear form on the tangent space of the manifold .\n\nIn relativity theory, the Ricci tensor is the part of the curvature of spacetime that determines the degree to which matter will tend to converge or diverge in time (via the Raychaudhuri equation). It is related to the matter content of the universe by means of the Einstein field equation. In differential geometry, lower bounds on the Ricci tensor on a Riemannian manifold allow one to extract global geometric and topological information by comparison (cf. comparison theorem) with the geometry of a constant curvature space form. If the Ricci tensor satisfies the vacuum Einstein equation, then the manifold is an Einstein manifold, which have been extensively studied (cf. ). In this connection, the Ricci flow equation governs the evolution of a given metric to an Einstein metric; the precise manner in which this occurs ultimately leads to the solution of the Poincaré conjecture.\n\nSuppose that is an -dimensional Riemannian manifold, equipped with its Levi-Civita connection . The Riemannian curvature tensor of is the -tensor defined by\non vector fields . Let denote the tangent space of at a point . For any pair of tangent vectors and in , the Ricci tensor evaluated at is defined to be the trace of the linear map given by\nIn local coordinates (using the Einstein summation convention), one has\nwhere\n\nIn terms of the Riemann curvature tensor and the Christoffel symbols, one has\n\nDue to the symmetries of the Riemann curvature tensor, it is possible for there to be a disagreement on the sign convention, since \n\nAs a consequence of the Bianchi identities, the Ricci tensor of a Riemannian manifold is symmetric, in the sense that\nIt thus follows that the Ricci tensor is completely determined by knowing the quantity for all vectors of unit length. This function on the set of unit tangent vectors is often simply called the Ricci curvature, since knowing it is equivalent to knowing the Ricci curvature tensor.\n\nThe Ricci curvature is determined by the sectional curvatures of a Riemannian manifold, but generally contains less information. Indeed, if is a vector of unit length on a Riemannian -manifold, then is precisely times the average value of the sectional curvature, taken over all the 2-planes containing . There is an -dimensional family of such 2-planes, and so only in dimensions 2 and 3 does the Ricci tensor determine the full curvature tensor. A notable exception is when the manifold is given a priori as a hypersurface of Euclidean space. The second fundamental form, which determines the full curvature via the Gauss–Codazzi equation, is itself determined by the Ricci tensor and the principal directions of the hypersurface are also the eigendirections of the Ricci tensor. The tensor was introduced by Ricci for this reason.\n\nIf the Ricci curvature function is constant on the set of unit tangent vectors , the Riemannian manifold is said to have constant Ricci curvature, or to be an Einstein manifold. This happens if and only if the Ricci tensor Ric is a constant multiple of the metric tensor .\n\nThe Ricci curvature is usefully thought of as a multiple of the Laplacian of the metric tensor . Specifically, in harmonic local coordinates the components satisfy\nwhere formula_9 is the Laplace–Beltrami operator, here regarded as acting on the functions . This fact motivates, for instance, the introduction of the Ricci flow equation as a natural extension of the heat equation for the metric. Alternatively, in a normal coordinate system based at , at the point \n\nNear any point in a Riemannian manifold , one can define preferred local coordinates, called geodesic normal coordinates. These are adapted to the metric so that geodesics through correspond to straight lines through the origin, in such a manner that the geodesic distance from corresponds to the Euclidean distance from the origin. In these coordinates, the metric tensor is well-approximated by the Euclidean metric, in the precise sense that\nIn fact, by taking the Taylor expansion of the metric applied to a Jacobi field along a radial geodesic in the normal coordinate system, one has\nIn these coordinates, the metric volume element then has the following expansion at :\n\nwhich follows by expanding the square root of the determinant of the metric.\n\nThus, if the Ricci curvature is positive in the direction of a vector , the conical region in swept out by a tightly focused family of geodesic segments of length formula_14 emanating from , with initial velocity inside a small cone about , will\nhave smaller volume than the corresponding conical region in Euclidean space, at least provided that formula_14 is sufficiently small. \nSimilarly, if the Ricci curvature is negative in the direction of a given vector , such a conical region in the manifold will instead have larger volume than it would in Euclidean space.\n\nThe Ricci curvature is essentially an average of curvatures in the planes including . Thus if a cone emitted with an initially circular (or spherical) cross-section becomes distorted into an ellipse (ellipsoid), it is possible for the volume distortion to vanish if the distortions along the principal axes counteract one another. The Ricci curvature would then vanish along . In physical applications, the presence of a nonvanishing sectional curvature does not necessarily indicate the presence of any mass locally; if an initially circular cross-section of a cone of worldlines later becomes elliptical, without changing its volume, then this is due to tidal effects from a mass at some other location.\n\nRicci curvature plays an important role in general relativity, where it is the key term in the Einstein field equations.\n\nRicci curvature also appears in the Ricci flow equation, where a time-dependent Riemannian metric is deformed in the direction of minus its Ricci curvature. This system of partial differential equations is a non-linear analog of the heat equation, and was first introduced by Richard S. Hamilton in the early 1980s. Since heat tends to spread through a solid until the body reaches an equilibrium state of constant temperature, Ricci flow may be hoped to produce an equilibrium geometry for a manifold for which the Ricci curvature is constant. Recent contributions to the subject due to Grigori Perelman now show that this program works well enough in dimension three to lead to a complete classification of compact 3-manifolds, along lines first conjectured by William Thurston in the 1970s.\n\nOn a Kähler manifold, the Ricci curvature determines the first Chern class of the manifold (mod torsion). However, the Ricci curvature has no analogous topological interpretation on a generic Riemannian manifold.\n\nHere is a short list of global results concerning manifolds with positive Ricci curvature; see also classical theorems of Riemannian geometry. Briefly, positive Ricci curvature of a Riemannian manifold has strong topological consequences, while (for dimension at least 3), negative Ricci curvature has \"no\" topological implications. (The Ricci curvature is said to be positive if the Ricci curvature function is positive on the set of non-zero tangent vectors .) Some results are also known for pseudo-Riemannian manifolds.\n\n\nThese results show that positive Ricci curvature has strong topological consequences. By contrast, excluding the case of surfaces, negative\nRicci curvature is now known to have \"no\" topological implications; has shown that any manifold of dimension greater than two admits a Riemannian metric of negative Ricci curvature. (For surfaces, negative Ricci curvature implies negative sectional curvature; but the point is that this fails rather dramatically in all higher dimensions.)\n\nIf the metric is changed by multiplying it by a conformal factor , the Ricci tensor of the new, conformally-related metric is given by\n\nwhere is the (positive spectrum) Hodge Laplacian, i.e., the \"opposite\" of the usual trace of the Hessian.\n\nIn particular, given a point in a Riemannian manifold, it is always possible to find metrics conformal to the given metric for which the Ricci tensor vanishes at . Note, however, that this is only pointwise assertion; it is usually impossible to make the Ricci curvature vanish identically on the entire manifold by a conformal rescaling.\n\nFor two dimensional manifolds, the above formula shows that if is a harmonic function, then the conformal scaling does not change the Ricci tensor (although it still changes its trace with respect to the metric unless f=0).\n\nIn Riemannian geometry and general relativity, the trace-free Ricci tensor of a pseudo-Riemannian manifold is the tensor defined by\n\nwhere is the Ricci tensor, is the scalar curvature, is the metric tensor, and is the dimension of . The name of this object reflects the fact that its trace automatically vanishes:\n\nIf , the trace-free Ricci tensor vanishes identically if and only if\n\nfor some constant .\n\nIn mathematics, this is the condition for to be an Einstein manifold. In physics, this equation states that is a solution of Einstein's vacuum field equations with cosmological constant.\n\nOn a Kähler manifold , the Ricci curvature determines the curvature form of the canonical line bundle . The canonical line bundle is the top exterior power of the bundle of holomorphic Kähler differentials:\n\nThe Levi-Civita connection corresponding to the metric on gives rise to a connection on . The curvature of this connection is the two form defined by\n\nwhere is the complex structure map on the tangent bundle determined by the structure of the Kähler manifold. The Ricci form is a closed 2-form. Its cohomology class is, up to a real constant factor, the first Chern class of the canonical bundle, and is therefore a topological invariant of (for compact ) in the sense that it depends only on the topology of and the homotopy class of the complex structure.\n\nConversely, the Ricci form determines the Ricci tensor by\n\nIn local holomorphic coordinates , the Ricci form is given by\n\nwhere is the Dolbeault operator and\n\nIf the Ricci tensor vanishes, then the canonical bundle is flat, so the structure group can be locally reduced to a subgroup of the special linear group . However, Kähler manifolds already possess holonomy in , and so the (restricted) holonomy of a Ricci-flat Kähler manifold is contained in . Conversely, if the (restricted) holonomy of a -dimensional Riemannian manifold is contained in , then the manifold is a Ricci-flat Kähler manifold .\n\nThe Ricci tensor can also be generalized to arbitrary affine connections, where it is an invariant that plays an especially important role in the study of projective geometry (geometry associated to unparameterized geodesics) . If denotes an affine connection, then the curvature tensor is the (1,3)-tensor defined by\n\nfor any vector fields . The Ricci tensor is defined to be the trace:\n\nIn this more general situation, the Ricci tensor is symmetric if and only if there exist locally a parallel volume form for the connection.\n\n\n\n"}
{"id": "2711536", "url": "https://en.wikipedia.org/wiki?curid=2711536", "title": "Social norms approach", "text": "Social norms approach\n\nThe social norms approach, or social norms marketing,\nis an environmental strategy gaining ground in health campaigns.\nWhile conducting research in the mid-1980s, two researchers, H.W. Perkins and A.D. Berkowitz, reported that students at a small U.S. college held exaggerated beliefs about the normal frequency and consumption habits of other students with regard to alcohol. These inflated perceptions have been found in many educational institutions, with varying populations and locations. Despite the fact that college drinking is at elevated levels, the perceived amount almost always exceeds actual behavior. The social norms approach has shown signs of countering misperceptions, however research on changes in behavior resulting from changed perceptions varies between mixed to conclusively nonexistent.\n\nThe social norms approach is founded upon a set of assumptions that individuals incorrectly perceive that the attitudes or behaviors of others are different from their own, when in reality they are similar. This phenomenon is known as pluralistic ignorance. It is largely because individuals assume the most memorable and salient, often extreme, behavior is representative of the behavior of the majority. This may lead individuals to adjust their behavior to that of the presumed majority by adhering to the pseudo-norms created by observing such memorable behavior. These exaggerated perceptions, or rather misperceptions, of peer behavior will continue to influence the habits of the majority, if they are unchallenged. This means that individuals may be more likely to enact problem behaviors and suppress healthier practices, making support for healthy behaviors much less visible at an aggregate level. This effect has been documented for alcohol, illegal drug use, smoking, other health behaviors, and attitudes, such as prejudice.\n\nA phenomenon known as false consensus is closely related to the idea of pluralistic ignorance, and refers to the incorrect belief that others are similar, when in reality they are not. For example, heavy drinkers will think that most others consume as much as they do, and will use this belief to justify their behavior. Berkowitz, an independent consultant who works full-time to promote these ideas, describes false consensus and pluralistic ignorance as \"mutually reinforcing and self-perpetuating...the majority is silent because it thinks it is a minority, and the minority is vocal because it believes that it represents the majority\" (p. 194).\n\nThese phenomena both have the potential to be addressed by a social norms intervention. Berkowitz describes this possibility in relation to reducing alcohol use:\n\n…social norms interventions have been found to be effective in changing the behavior of the moderate or occasional-drinking majority (pluralistic ignorance) as well as confronting and changing the behavior of the heavy drinking minority (false consensus) (p. 9)\nThus, the social norms approach predicts that an intervention which aims to correct misperceptions by exposing actual norms will benefit society as well as individuals, because it will lead people to reduce problem behaviors or increase participation in healthy behaviors. There have been multiple studies which have indeed shown that social norms campaigns can have such positive effects on target populations. One study in particular, which utilized 18 different colleges over a three-year period, found that social norms campaigns were associated with lower perceptions of student drinking and lower consumption levels. Oddly, when the results of this same study were reported at a conference of alcohol educators, DeJong reported that alcohol consumption increased' among both control participants and among the experimental group (those who got the social norms marketing treatment). This discrepancy in reported findings between a conference paper and published journal paper is difficult to reconcile.\n\nAnother intervention designed to reduce drinking amongst student athletes had similar results, reducing misperceptions of alcohol consumption. Also, within the time period of the intervention, there were declines in personal consumption, high risk drinking, and alcohol-related consequences. When critiquing this study, one should ask how many dependent variables were assessed, as this group of researchers often assesses as many as 20 or more outcome variables and finds change in 2 or 3 and calls the program successful.\n\nA recent trial of a live, interactive, normative feedback program in which students used keypads to input information had positive effects in terms of reducing misperceptions and drinking behavior. There are many other examples of successful social norms campaigns, which cover various topics, population sizes, and media through which normative messages are conveyed.\n\nTwo types of norms are relevant to a social norms approach: descriptive norms and injunctive norms. Injunctive norms involve perceptions of which behaviors are typically approved or disapproved. They assist an individual in determining what is acceptable and unacceptable social behavior. This would be the morals of your interpersonal networks and surrounding community. Descriptive norms involve perceptions of which behaviors are typically performed. They normally refer to the perception of others' behavior. These norms are based on observations of those around you .\n\n\"Both kinds of norms motivate human action; people tend to do what is socially approved as well as what is popular. (105) When put together, these norms have a counterproductive effect.\nFor example a campaign that focuses individuals on the frequent occurrences of an offense against the environment has the potential to increase the occurrence of that offense\" .\nThese two norms are constructed from three sources: observable behavior, direct/indirect communication and self-knowledge. Miller and Prentice 1996\n\n\nBorsari and Carey'smeta-analysis of studies showed that people misperceive injunctive norms more than they do descriptive norms, and that injunctive norms are more likely to predict drinking behavior and negative consequences of drinking. However, the use of both in social norms campaigns has shown that it is unclear which type of norm is more likely to change behavior.\n\nThere are seven assumptions of the social norms approach:\n\n\nSince the 1986 study in which Berkowitz and Perkins reported the misperceptions about alcohol consumption amongst college students, the use and study of the social norms approach has grown. It has been used as a prevention technique for a variety of levels of prevention: universal, with large populations like entire college campuses; selective, with targeted subpopulations, and indicated, with individuals.\n\nThe first social norms intervention was implemented in 1989 by Michael Haines at Northern Illinois University, which targeted a universal campus population and over the years has shown significant success in terms of increasing healthy behaviors. This research at Northern Illinois University was done with a $64,000 grant from the U.S.Department of Education Fund for the Improvement of Post Secondary Education (FIPSE). Many other universities have since followed suit and have had similar success in the reduction of high-risk drinking behaviors, such as Hobart and William Smith Colleges, the University of Arizona, and University of North Carolina, to name a few.\n\nSince these achievements have become well-known, the social norms approach has been used successfully to reduce smoking, drinking and driving, and HIV risk behaviors, and to increase seat belt use.\n\nIt has also gained widespread use targeting adolescents and high school students, and has been used in an attempt to reduce drinking and smoking behaviors amongst those populations.\nRecently, interventions have been tested to reduce sexual assault, and the results were reported to be \"promising\".\n\nThe social norms approach is not accepted by all scholars as an effective campaign method. Some criticize the approach by saying that the underlying assumptions are false. One study found that the perceived degree of alcohol use was not predictive of alcohol abuse if other normative influences were considered, and another study found that misperceptions of drinking problems were unrelated to personal alcohol consumption.\nThe findings of both of those studies present opposition to the first assumption of the social norms approach: Actions are often based on misinformation about or misperceptions of others' attitudes and/or behavior.\n\nOther scholars challenge the legitimacy of social norms interventions deemed successful. They say that many of these interventions had methodological problems which could influence the validity of their effectiveness (e.g., they did not control for other variables, did not have comparison groups, etc.).\nAnother common criticism is that they are simply ineffective: a nationwide study, which compared colleges with social norms interventions to those that did not have them, found that schools with interventions showed no decreases in measures of alcohol use, and actually found increased measures in terms of alcohol consumed monthly and total amount consumed.\nThere are also a handful of studies that document failed social norms campaigns at specific colleges.\n\nA social norms approach determines the exaggerated and actual norms of a population through formative research, and then informs the population of the actual norms through a message campaign. The next step is determining the effectiveness of the messages through a summative evaluation. Finally, the results from the evaluative research can also be used to craft new messages to revise the message campaign, and thus the campaign is cyclical. The following provides a more in-depth description of the steps involved in a social norms campaign.\n\nFormative evaluation is the first step in a social norms campaign and consists of surveying the population, as well as message creation based on the survey results. The formative evaluation phase is the time when information regarding perceived norms and actual behaviors is garnered from the audience. In order for a social norms approach to be the appropriate means for intervention, two conditions must first be satisfied:\n\n\nThe most effective way to establish the baseline levels of behavior and perceptions is through the use of surveys. Internet surveys, for example, are an often-used method of generating a substantial response rate. They are especially suited for college students because of their familiarity with the technology, the containment of the population (i.e., all are part of a specific community), and the ability of the students to take the survey at their own pace and during the time that works best for them. Not only are web surveys ideal for students, but they are also highly advantageous for researchers. They provide quick turnaround for data analysis, higher response rates, less missing data, and they eliminate interviewer effects. Other possible methods of administering a survey are pencil and paper surveys, phone surveys, or personal interviews.\n\nThe following describes a typical and thorough process used to survey a population:\n\nAfter completing data collection, researchers then analyze the data and search for patterns, looking for inconsistencies between actual behavior, attitudes, and perceived norms. When these differences are consistent with the campaign and the majority of students adhere to the beneficial idea, they are then used in the next round of message creation. For example, the data could show that college students report they consumed 0–4 drinks the last time they partied, but they believe that the average student consumed 5 or more drinks. After discovering this statistic, a researcher may craft a message like, \"Most students drink 0–4 drinks when they party\", to correct the misperceived descriptive norm.\n\nThe most important descriptive researchers look for in the data is the 51% or greater statistic, or items where \"most\" (i.e., over 50%) of the population adheres to the beneficial behavior. These statistics could occur in injunctive norms (i.e., \"Most students believe passing out from drinking too much is wrong.\"), protective/healthy behaviors (i.e., \"Most students use a designated driver, even when only having one or two drinks.\"), or other numerous behaviors.\n\nThere are different message components that can be varied, which are experimented with during pre-testing. For example, researchers test different vocabulary (e.g., \"66%\" vs. \"Most\" vs. \"Majority), using different behaviors to find out which ones are the easiest and most acceptable to perform (e.g., \"eating while drinking\" vs. \"keeping track while drinking\"), and using varying degrees of citations (e.g., large citations vs. small citations of data source). These preliminary messages are pretested on small groups in order to refine them before they are presented to the entire population. Other aspects examined in pretesting include which messages are most socially acceptable, which are believed to be the most effective, and which messages have the highest believability.\n\nBelievability is a necessary but not a sufficient condition for an effective campaign. If believability of messages is low, change will probably not occur because the persuasive messages are falling into the audience's latitude of rejection. In other words, the audience will reject the message without even considering it. It is also important to note, however, that if believability is extremely high (e.g., over 90%), change is also unlikely to occur because the message is not challenging enough. In other words, it serves only as a reinforcement rather than an element of change. Thus, while there are no specific guidelines, it is ideal to aim for believability above 50%.\n\nIn an assessment of the believability of a social norms campaign, Polonec, Major, and Atwood found that students' own drinking experiences and the experiences of their friends contributed to disbelief in the message \"Most students on campus choose to have 0 to 4 drinks when they party.\" Another study found that disbelief may be due to preconceived notions about drinking that students develop even before they arrive on campus.\n\nAfter implementing a campaign, researchers then perform a summative evaluation which measures the success of the campaign. This step consists of examining and evaluating the progress made by an intervention through assessing the outcome and impact, cost and benefits, and cost effectiveness of a program. It is typical for researchers to use surveys similar to those used in formative evaluation. The following are questions that a summative evaluation can answer:\n\n\nAn especially important part of summative evaluation is the assessment of market saturation and reach. Clearly, if a social norms campaign does not reach very much of its intended audience, then its potential effectiveness decreases. If researchers can demonstrate that their campaign had high reach, then that strengthens the connection of the intervention to positive outcomes. It also lets researchers know what methods are effective for distributing the campaign. It is necessary for an audience to be exposed to campaign messages frequently to change misperceptions. However, overexposure is possible, leading to a loss of credibility and habituation. Thus, it is important to determine the proper dosage of the campaign in order to achieve maximum effectiveness. Silk et al. provide a comprehensive evaluation of a socials norms campaign related to mental health among college students, revealing positive outcomes for students who were exposed to the social norms campaign (e.g., greater likelihood to visit the university's counseling center). \n\nOnce the evaluation is complete, it has the potential to help the intervention. Summative evaluation not only tells whether a program is working, but it can also feed new messages and new campaigns by providing new, updated data.\n\nThe following are key terms discussed in this article that are relevant to the Social Norms Approach:\n\n\n\n"}
{"id": "625161", "url": "https://en.wikipedia.org/wiki?curid=625161", "title": "Sudden death (sport)", "text": "Sudden death (sport)\n\nIn a sport or game, sudden death (also sudden-death overtime or a sudden-death round) is a form of competition where play ends as soon as one competitor is ahead of the others, with that competitor becoming the winner. Sudden death is typically used as a tiebreaker when a contest is tied at the end of the normal playing time or the completion of the normal playing task.\n\nAn alternative tiebreaker method is to play a reduced version of the original; for example, in association football 30 minutes of extra time (overtime) after 90 minutes of normal time, or in golf one playoff round (18 holes) after four standard rounds (72 holes). Sudden-death playoffs typically end more quickly than these reduced replays. Reducing the variability of the event's duration assists those scheduling television time and team travel. Fans may see sudden death as exciting and suspenseful, or they may view the format as insufficiently related to the sport played during regulation time; for example, prior to 2012, the National Football League (American football) used a sudden-death rule for overtime play. In those situations, a team possessing the ball need only kick a field goal to end the game in their favor, negating the additional benefit that typically comes with scoring a touchdown.\n\nSudden death provides a victor for the contest without a specific amount of time being required. It may be called \"next score wins\" or similar, although in some games, the winner may result from penalization of the other competitor for a mistake. Sudden death may instead be called sudden victory to avoid the mention of death and serious disease, particularly in sports with a high risk of physical injury. This variant became one of announcer Curt Gowdy's idiosyncrasies in 1971 when the AFC divisional championship game between the Kansas City Chiefs and Miami Dolphins went into overtime.\n\nNorth American professional sports using a sudden-death method of settling a tied game include the modified version now employed by the National Football League, the National Hockey League and, also in a modified sense, the PGA Tour (golf). Baseball uses a unique method of tie-breaking that incorporates elements of sudden death. In some goal-scoring games sudden-death extra time may be given in which the first goal scored wins; in association football it is called the \"golden goal\", although this has not been recognised since it was abolished from the Laws of the Game in 2004 by FIFA. In baseball, a winning run scored by the home team in an extra inning is often referred to as a walk-off, as the players can immediately walk off the field.\n\nSudden death has been perceived as a particularly poor fit for gridiron football because the process gives an inherent advantage to the team who starts with possession of the ball: they can score and end the game immediately (even by driving a relatively short distance into field goal range and then kicking a field goal), but the team on defense cannot (other than through far rarer scoring strategies such as the pick-six or the safety).\n\nAll organized forms of American football have abolished pure sudden death for overtime as of the 2011 season. Most levels of the game, including high school football and college football, never used it, instead either allowing ties to stand or using alternatives like the Kansas Playoff. The National Football League was an exception; the league used pure sudden death in its playoffs beginning in 1940 and in regular season matchups starting in 1974, finally modifying its process for playoffs in 2010 and then regular season games in 2011.\n\nOriginally, all National Football League games tied at the end of regulation time ended as a tie. Late in the 1940 season, NFL President Carl Storck announced that sudden death periods would be authorized for any playoff game needed to decide either division title. It was emphasized that this did not apply to the final championship game, which would crown co-champions in the event of a tie. Commissioner Elmer Layden approved a similar arrangement for the 1941 season, with the same limitation. In the years when it was within the rules, the NFL Championship Game only was tied in regulation in the 1958 NFL Championship Game. A tied game in regulation did not occur in the Super Bowl until Super Bowl LI (51).\n\nSudden death overtime was finally approved for the NFL championship game in 1946 and remains in effect now. The first playoff game requiring overtime was the 1958 NFL Championship Game.\n\nIn 1974, the NFL adopted a 15-minute sudden-death overtime period for regular-season games; in it was cut to 10 minutes. The game ended as a tie if neither team scores in overtime. When a team gets near the end zone, it typically tried to kick a field goal. An overtime game can also be won by scoring a touchdown (in such an event, the extra point is not attempted). This usually happened on a play that began with field position far enough away from the end zone to make a field goal difficult if not impossible, but it can also result from a team choosing not to attempt a field goal until reaching fourth down, even if the team enters an easy field goal range; this strategy only works if the team can maintain possession of the ball and does not fumble the ball away, throw an interception or lose enough yardage to back out of field goal range. Only thrice has an overtime game been won by a safety. In recent years, sportscasters have referred to such scoring plays as \"walk-offs,\" as both teams can walk off the field after the play.\n\nSince the 2010–11 playoffs, in the post-season, each team was allowed at least one possession to score in overtime, unless the team receiving the kickoff scored a touchdown or if the defensive team scored a touchdown or safety on the same possession. True sudden death rules applied if both teams have had their initial possession and the game remains tied. This rule did not actually come into use during the 2010 playoffs, with the first overtime game under the new rules not occurring until 2011, with the Denver Broncos scoring a long touchdown on their first play from scrimmage against the Pittsburgh Steelers. \n\nThis rule was adopted for the start of the 2012 regular season. It was adopted to counter the criticism that the outcome of overtime games was very frequently decided by the coin toss, as the team which won it usually attempted only enough offensive action to maneuver into field goal range and seldom made a real effort to score a touchdown. In the regular season, games still tied after one full overtime period will continue to be allowed to end in a tie.\n\nFor information on games that have taken a long time under sudden death, see Overtime.\n\nIn arena football, each team is allowed one overtime possession in the first overtime, after which whoever is ahead is the winner. If the score is still tied, however, true sudden death rules apply thereafter. (A similar, modified sudden death format, with a 10-minute limit, was used in the NFL Europa League.) This rule was implemented in the 2007 season; prior to this, the league used extra time, a fixed seven and one-half minute extra period; if the game was still tied at this point, it was recorded as a tied game. This was later changed to a fifteen-minute maximum modified sudden death as above, but with a definite conclusion after one overtime period, again a tied game being recorded if the score was still equal. (Only one tied game was recorded under each of the two prior overtime rules.) Since the beginning of the 2007 season, all Arena football games, both regular season and playoff, have been played to a victorious conclusion. Any succeeding overtime periods are true sudden death periods. An exception is applied to second game of the 2018 semifinal series, provided one team wins the first game and the second game ends with the two-game aggregate score tied, the game will continue with a standard overtime even if the score of the second game is not tied.\n\nSudden death has a controversial history in association football. Important matches were traditionally resolved by replaying the entire match, however in the era of television and tight travel schedules this is often impracticable. Replays are still used in some major competitions (like the FA Cup).\n\nIn many matches, if the score is tied after the full 90 minutes, a draw results; however, if one team must be eliminated, some form of tie-breaking must occur. Originally, two 15-minute halves of extra time were held and if the teams remained equal at the end of the halves, kicks from the penalty mark are held.\n\nTo try to decrease the chances of requiring kicks from the penalty mark, the IFAB, the world law making body of the sport, experimented with new rules. The golden goal rule transformed the overtime periods into sudden death until the periods were over, where shootouts would occur. As this became unpopular, the silver goal rule was instituted, causing the game to end if the scores were not equal after the first 15-minute period as well as the second. The silver goal has also fallen into disrepute so UEFA Euro 2004 was the last event to use it; after which the original tie-breaking methods were restored.\n\nThe main criticism of golden goal is the quickness of ending the game, and the pressure on coaches and players. Once a goal is scored, the game is over and the opponent cannot attempt to answer the goal within the remaining time. Therefore, teams would place more emphasis on not conceding a goal rather than scoring a goal, and many golden goal extra time periods remained scoreless.\n\nIn NCAA collegiate play in the United States, however, sudden death, adopted in 1997 for all championship play in addition to regular season play, remains. In 2005, the Division II Women's Championship game ended in sudden death as a goal was scored three minutes into the overtime to end the championship match. Sudden death is also prevalent in youth play, for the safety of players.\n\nIf the teams are still tied after the initial allocated number in the penalty shoot-out, the game goes to sudden-death penalties, where each team takes a further one penalty each, repeated until only one team scores, resulting in the winning of the game.\n\nIn badminton, if a set is tied at 29-all, golden point is played; whoever scores this point wins it.\n\nBaseball and softball are not true sudden-death sports, but they have one comparable situation.\n\nBaseball and softball games cannot end until both teams have had an equal number of turns at bat, unless further play (by the home team if they lead after innings) cannot affect the outcome. In the final scheduled inning (typically, in professional and advanced amateur leagues the ninth inning, but usually the seventh for youth leagues and softball, and the sixth for leagues for subteens such as Little League), if the visitors complete their turn at bat and still trail the hosts, the game ends. If the visitors lead or the game is tied, the hosts take their \"last ups\" at bat. If the hosts should exceed the visitors' score, the game ends at the conclusion of the play on which the hosts take this insurmountable lead. (If the final scheduled inning ends in a tie, multiple extra innings are played with the same implications as the final scheduled inning.)\n\nThe ability to bat last is an advantage of being the home team. It is said that \"visitors must play to win; hosts need only play to tie\" because tying forces an extra inning.\n\nA tied game in the bottom of the final scheduled inning puts pressure on the visitors. For example, with a runner on third base and fewer than two outs, the visitors cannot afford even to get certain types of out that would let the game-ending run score after the out.\n\nA scoring play that ends the game is called a walk-off, because after the runner scores the winning run everyone can walk off the field. A walk-off home run is an exception to the rule stated above; the game does not end when the winning run scores, but continues until the batter and all runners score (provided they run the bases correctly).\n\nBasketball does not traditionally employ sudden death to decide games; it instead uses multiple five-minute overtime periods to determine the result of games tied after regulation play. The entire overtime is played; if the game remains tied, this procedure is repeated.\n\nThe NBA Summer League, a developmental summer league, employs sudden death basketball after the first overtime. The rules state \"Double overtime & thereafter is sudden death (first team to score a point wins).\" In the first sudden death professional basketball game, Devin Ebanks hit a game winner with 45 seconds elapsed for the D-League Select team, beating the summer league Atlanta Hawks.\n\nAnother form of basketball does employ a sudden-death overtime. 3x3, a formalized version of the half-court three-on-three game, uses an untimed overtime period that ends by rule once either team has scored 2 points. In this form of the sport, shots taken from behind the \"three-point\" arc are worth 2 points and all other shots are worth 1 point.\n\nAn individual fencing bout lasts for five touches in a poule match, or 15 touches in a direct elimination (DE) match in all three weapons (épée, foil, and sabre. Although sabre bouts rarely go to full-time, the same time frames apply) Matches are also timed (three minutes for a poule match, and three periods of three minutes for a DE). If neither fencer has reached five or 15 points within the time limit, the leading fencer is deemed the winner. However, if the fencers are tied after the allotted time, one minute of extra time is added.\n\nBefore resuming the bout, one fencer is randomly awarded \"priority\". The first fencer to score a valid hit within extra time wins the match; if no valid hits are scored within the time, that fencer with priority is declared the victor.\n\nIn the normal course of a match, there is a de facto sudden death situation if both fencers are tied at four (or 14) touches each. The final hit is called \"la belle\". The fencers may salute each other before playing for the final point.\n\nIn individual match play, players level after the regulation 18 or 36 holes will play extra holes in sudden death. In team tournaments, players may gain half a point each for a tie rather than play sudden death; this is the case in the Ryder Cup, for example. In the Presidents Cup, there was provision for a single-player sudden death shootout if the entire competition ended in a tie. When this came to pass in 2003, the tiebreak was unfinished at dusk. There was no provision for an extra day's play, and both team captains agreed to declare the match tied and share the trophy.\n\nTraditionally, professional stroke play golf tournaments ending in a tie were played off the next day with an eighteen-hole match. Modern considerations such as television coverage and the tight travel schedule of most leading golfers have led to this practice being almost entirely abandoned, and in all but the most important tournaments, the champion is determined by sudden death. All players tied after the completion of regulation play are taken to a predetermined hole, and then play it and others in order as needed. If at least two players are tied, player(s) who score higher on a hole than the other competitors is/are immediately eliminated, and those still tied continue play until one remaining player has a lower score for a hole than any of the others remaining, who is declared the winner.\n\nOf the four men's major championships, only The Masters uses a sudden-death playoff format, first used in 1979. Through 2017 (and last used in 2008), the had an 18-hole playoff at stroke play on the day after the main tournament, with sudden-death if needed after 18 holes. A two-hole aggregate playoff is used since 2018, followed by sudden-death if needed. First used in 1989, The Open Championship uses a four-hole total-stroke playoff, while the PGA Championship uses a three-hole total-stroke playoff, first used in 2000. The PGA Championship introduced the sudden-death playoff to the majors in 1977 and used it seven times through 1996. Sudden death is used if a tie exists at the end of the scheduled playoff.\n\nSudden-death overtime has traditionally been used in playoff and championship games in hockey. It has been used in the National Hockey League throughout the league's history. The first NHL game with sudden-death overtime was game four of the 1919 Stanley Cup Finals. Currently, the NHL, American Hockey League, and ECHL also use the sudden-death system in their regular seasons, playing a five-minute overtime period when the score is tied at the end of regulation time.\n\nIn 2000, the AHL reduced the teams to four players each during the five-minute overtime. (But any two-man advantage is administered with five-on-three play rather than four-on-two.) The ECHL and NHL both changed to the four-on-four overtime format in 2001, with the International Olympic Committee following by no later than 2010. By 2015 the NHL went to the three-on-three format. In the SPHL, a class A minor league, the overtime is three-on-three, with the team that would be on the power play given a fourth, and a fifth attacker respectively instead, and any penalty in the final two minutes results in a penalty shot instead of a power play.\n\nIf neither team scores during this period, the teams use a penalty-shot shootout, consisting of three players in the NHL or five players in the minor leagues, to determine the winner. In the NHL, if no team wins this shootout, a 1-by-1, sudden-death shootout ensues. No player may shoot twice until every non-goaltender on the bench has taken a shot.\n\nDuring championship playoffs, however, all games are played to a conclusion resulting in a victory for one team and a loss for the other. These are true sudden-death games, which have gone on into as many as six additional full 20-minute periods with five players, instead of the five-minute period with at least three players.\n\nIIHF hockey uses a penalty-shot shootout for gold medal games if neither team scores after one 20-minute, sudden-death overtime period. The shootout is decided in best-of-5 rounds, then round by round (in other words, if one team scores in the 6th round or beyond and the other fails, the game ends, unlike most professional leagues), and players can shoot as many times as the team desires (first 5 rounds are done in order, then reversely thereafter; may use new or same players). (There is a 5-minute overtime in round-robin games [10 minutes in elimination/bronze medal games], plus the best-of-5-round [best-of-3 rounds in round robin] shootout procedure in elimination/bronze medal games.)\n\nIn the case of a tie in competition judo, the match proceeds to Golden Score, another form of Sudden Death. Sudden Death in competition Judo consists of a 5 minute long match, during which the first competitor to achieve a score is awarded the match. Penalties in Judo award points to the other competitor, making fair-play of absolute importance. If no victor is decided in Golden Score, the match is decided based on a Referee's Decision. A Referee's Decision is a vote amongst the Referee and both Judges of the match.\n\nIn mixed martial arts competitions that consist of an even number of rounds, a type of sudden death is sometimes used in the event that each competitor wins an equal number of points. This is not a true sudden death that ends on the first point scored, since MMA competitions do not generally score individual points. Rather, it is a final round of combat, the winner of which is declared the winner of the match. This particular rule, known as \"Sudden Victory\", has been commonly seen in previous seasons of the reality television show \"The Ultimate Fighter\" when the competition has consisted of two rounds. A sudden victory round rule was also implemented in the tournament to decide Ultimate Fighting Championship's first Flyweight Champion.\n\nSudden death in wrestling is most commonly seen in Real Canadian Wrestling tournament matches, in which a victor must be decided. This happens in the case of a double knockout or double countout. In the United States, Sudden Death rules occurs mainly in an Iron Man match when there is a tie after the time limit have expired. (Most notably at Wrestlemania XII when the match between Shawn Michaels and Bret Hart ended 0-0 after the 60 minute limit)\n\nAn example that invoked sudden death occurred in the 2005 Royal Rumble. John Cena and Batista were left, and both men's feet touched the ground at the same time. A comparable draw leading to sudden death might happen if the shoulders of a wrestler applying a submission move are on the mat.\n\nDrawn National Rugby League premiership and State of Origin series games are subject to sudden death extra time after 80 minutes of play, called the golden point. Golden point consists of two five-minute halves, with the teams swapping ends at the end of the first half.\n\nAny score (try, penalty goal, or field goal) in golden point wins the game for the scoring team - no conversion is attempted if a try is the winning score.\n\nIn the NRL, the victor in golden point receives two competition points, the loser none. In the event that no further scoring occurs, the game is drawn, and each team receives one point each.\n\nIn the knockout stages of rugby competitions, most notably the Rugby World Cup, a match drawn after 80 minutes does not proceed immediately to sudden death conditions. Two 10-minute extra time periods are played first, if scores are level after 100 minutes then the rules call for a single sudden-death period of 10 minutes to be played. If the sudden-death extra time period results in no scoring a kicking competition is used to determine the winner.\n\nHowever, no match in the history of the Rugby World Cup has ever gone past 100 minutes into a sudden-death extra time period.\n\nIn contrast with the usual sudden-death procedure of awarding the victory to the next side to score, tennis and volleyball require that the margin of victory be two. A volleyball game tied at the target score continues until one team's score exceeds the other's by two points.\n\nThe traditional requirement that a tennis set be won by two games sometimes resulted in men's five-set matches lasting over six hours (including an 8-hour 11-minute set at Wimbledon) or, in women's/doubles' three-set matches, lasting over three hours, which is a major disruption to a television schedule. To shorten matches, sets tied at six games each can now be broken by a single tiebreaker game. This is awarded to the first player to score seven points. The winner must lead the loser by two points, so tiebreaker games can become lengthy in their own right.\n\nTiebreakers are not used in major tournaments in the final set, except at the US Open & the Olympics.\n\n\n"}
{"id": "3959600", "url": "https://en.wikipedia.org/wiki?curid=3959600", "title": "Visual music", "text": "Visual music\n\nVisual music, sometimes called colour music, refers to the use of musical structures in visual imagery, which can also include silent films or silent Lumia work. It also refers to methods or devices which can translate sounds or music into a related visual presentation. An expanded definition may include the translation of music to painting; this was the original definition of the term, as coined by Roger Fry in 1912 to describe the work of Wassily Kandinsky. There are a variety of definitions of visual music, particularly as the field continues to expand. In some recent writing, usually in the fine art world, visual music is often confused with or defined as synaesthesia, though historically this has never been a definition of visual music. Visual music has also been defined as a form of intermedia.\n\nVisual music also refers to systems which convert music or sound directly into visual forms, such as film, video, computer graphics, installations or performances by means of a mechanical instrument, an artist's interpretation, or a computer. The reverse is applicable also, literally converting images to sound by drawn objects and figures on a film's soundtrack, in a technique known as drawn or graphical sound. Famous visual music artists include Jordan Belson, Oskar Fischinger, Norman McLaren, John Whitney Sr., and Thomas Wilfred, plus a number contemporary artists. \n\n\"Since ancient times artists have longed to create with moving lights a music for the eye comparable to the effects of sound for the ear.\"<br>– Dr. William Moritz, the best-known historian of \"visual music\" writing in English, his speciality being the work of Oskar Fischinger. \n\nSometimes also called \"color music\", the history of this tradition includes many experiments with color organs. Artist or inventors \"built instruments, usually called 'color organs,' that would display modulated colored light in some kind of fluid fashion comparable to music\". For example, the \"Farblichtspiele\" ('coloured-light-plays') of former Bauhaus student Ludwig Hirschfeld Mack. Several different definitions of color music exist; one is that color music is generally formless projections of colored light. Some scholars and writers have used the term color music interchangeably with visual music.\n\nThe construction of instruments to perform visual music live, as with sonic music, has been a continuous concern of this art. Color organs, while related, form an earlier tradition extending as early as the eighteenth century with the Jesuit Louis Bertrand Castel building an \"ocular harpsichord\" in the 1730s (visited by Georg Philipp Telemann, who composed for it). Other prominent color organ artist-inventors include: Alexander Wallace Rimington, Bainbridge Bishop, Thomas Wilfred, Charles Dockum, Mary Hallock-Greenewalt and Kurt Laurenz Theinert.\n\nVisual music and abstract film or video often coincide. Some of the earliest known films of these two genres were hand-painted works produced by the Futurists Bruno Corra and Arnaldo Ginna between 1911 and 1912 (as they report in the Futurist Manifesto of Cinema), which are now lost. Mary Hallock-Greenewalt produced several reels of hand-painted films (although not traditional motion pictures) that are held by the Historical Society of Philadelphia. Like the Futurist films, and many other visual music films, her 'films' were meant to be a visualization of musical form.\n\nNotable visual music filmmakers include: Walter Ruttmann, Hans Richter, Viking Eggeling, Oskar Fischinger, Len Lye, Jordan Belson, Norman McLaren, Mary Ellen Bute (who made a series of films she called Seeing Sound films), Harry Smith, Hy Hirsh, John and James Whitney, Steven Woloshen and many others up to present day.\n\nIn 2005, a US exhibition called \"Visual Music\" at the Los Angeles Museum of Contemporary Art and The Hirshhorn Museum and Sculpture Garden in Washington DC included documentation of color organs and featured many visual music films and videos as well as paintings and some color organs.\n\nThe Center for Visual Music in Los Angeles has the world's largest collection of visual music resources. CVM owns the papers, films and much animation artwork of Oskar Fischinger; the original research collection of visual music historian Dr. William Moritz; numerous restored films by Jordan Belson; and an extensive collection of restored films by Mary Ellen Bute, John and James Whitney, Jules Engel, Charles Dockum and others. CVM consulted for and provided films, stills and research for the above-mentioned blockbuster Visual Music exhibition; CVM now provides visual music films, programs, events and talks to museums, archives, festivals and cultural centres worldwide, in addition to curating and developing its own museum exhibitions (recently, Oskar Fischinger: Experiments in Cinematic Abstraction, in Amsterdam). The Fischinger three-projector reconstruction, Raumlichtkunst, was restored and curated by CVM, and has been exhibited at the Whitney Museum NY, Tate Modern London, Len Lye Centre New Zealand, and other museums and galleries worldwide. CVM recently released the second Oskar Fischinger DVD, as well as a compilation Visual Music from CVM Archive DVD with films by Jordan Belson, Bute, Dockum, Engel and Barry Spinello. A summer 2018 CVM Visual Music symposium in California is being organized.\n\nArtist Larry Cuba, founded the iota Fund in 1994, which was later called iotaCenter. They currently own the films of such artists as Sara Petty, Adam Beckett, some of the films of Jules Engel, Sky David, Robert Darroll and others. They hosted the renowned Kinetica programs (1999–2003) touring the world introducing new audiences to the wonders of visual music.\n\n The cathode ray tube made possible the oscilloscope, an early electronic device that can produce images that are easily associated with sounds from microphones. The modern Laser lighting display displays wave patterns produced by similar circuitry. The imagery used to represent audio in digital audio workstations is largely based on familiar oscilloscope patterns.\nThe Animusic company (originally called 'Visual Music') has repeatedly demonstrated the use of computers to convert music — principally pop-rock based and composed as MIDI events — to animations. Graphic artist-designed virtual instruments which either play themselves or are played by virtual objects are all, along with the sounds, controlled by MIDI instructions.\n\nIn the image-to-sound sphere, MetaSynth includes a feature which converts images to sounds. The tool uses drawn or imported bitmap images, which can be manipulated with graphic tools, to generate new sounds or process existing audio. A reverse function allows the creation of images from sounds.\n\nSome media player software generates animated imagery or music visualization based on a piece of recorded music:\n\nWith the increasing popularity of head mounted displays for virtual reality there is an emerging new platform for visual music. While some developers have been focused on the impact of virtual reality on live music or on the possibilities for music videos, virtual reality is also an emerging field for music visualization and visual music.\n\nMany composers have applied graphic notation to write compositions. Pioneering examples are the graphical scores of John Cage and Morton Feldman. Also known is the graphical score of György Ligetis Artikulation designed by Rainer Wehinger.\n\nMusical theorists such as Harry Partch, Erv Wilson, Ivor Darreg, Glenn Branca, and Yuri Landman applied geometry in detailed visual musical diagrams explaining microtonal structures and musical scales.\n\n\n\n\n\n"}
{"id": "26898094", "url": "https://en.wikipedia.org/wiki?curid=26898094", "title": "Von Neumann–Morgenstern utility theorem", "text": "Von Neumann–Morgenstern utility theorem\n\nIn decision theory, the von Neumann-Morgenstern utility theorem shows that, under certain axioms of rational behavior, a decision-maker faced with risky (probabilistic) outcomes of different choices will behave as if he or she is maximizing the expected value of some function defined over the potential outcomes at some specified point in the future. This function is known as the von Neumann-Morgenstern utility function. The theorem is the basis for expected utility theory.\n\nIn 1947, John von Neumann and Oskar Morgenstern proved that any individual whose preferences satisfied four axioms has a utility function; such an individual's preferences can be represented on an interval scale and the individual will always prefer actions that maximize expected utility. That is, they proved that an agent is (VNM-)rational \"if and only if\" there exists a real-valued function \"u\" defined by possible outcomes such that every preference of the agent is characterized by maximizing the expected value of \"u\", which can then be defined as the agent's \"VNM-utility\" (it is unique up to adding a constant and multiplying by a positive scalar). No claim is made that the agent has a \"conscious desire\" to maximize \"u\", only that \"u\" exists.\n\nAny individual whose preferences violate von Neumann and Morgenstern's axioms would agree to a Dutch book, which is a set of bets that necessarily leads to a loss. Therefore, it is arguable that any individual who violates the axioms is irrational. The expected utility hypothesis is that rationality can be modeled as maximizing an expected value, which given the theorem, can be summarized as \"rationality is VNM-rationality\".\n\nVNM-utility is a \"decision utility\" in that it is used to describe \"decision preferences\". It is related but not equivalent to so-called \"E-utilities\" (experience utilities), notions of utility intended to measure happiness such as that of Bentham's Greatest Happiness Principle.\n\nIn the theorem, an individual agent is faced with options called \"lotteries\". Given some mutually exclusive outcomes, a lottery is a scenario where each outcome will happen with a given probability, all probabilities summing to one. For example, for two outcomes \"A\" and \"B\",\n\ndenotes a scenario where \"P\"(\"A\") = 25% is the probability of \"A\" occurring and \"P\"(\"B\") = 75% (and exactly one of them will occur). More generally, for a lottery with many possible outcomes \"A\", we write\n\nwith the sum of the formula_3s equalling 1.\n\nThe outcomes in a lottery can themselves be lotteries between other outcomes, and the expanded expression is considered an equivalent lottery: 0.5(0.5\"A\" + 0.5\"B\") + 0.5\"C\" = 0.25\"A\" + 0.25\"B\" + 0.50\"C\".\n\nIf lottery \"M\" is preferred over lottery \"L\", we write formula_4, or equivalently, formula_5. If the agent is indifferent between \"L\" and \"M\", we write the \"indifference relation\" formula_6 If \"M\" is either preferred over or viewed with indifference relative to \"L\", we write formula_7\n\nThe four axioms of VNM-rationality are then \"completeness\", \"transitivity\", \"continuity\", and \"independence\".\n\nCompleteness assumes that an individual has well defined preferences:\n\n(either \"M\" is preferred, \"L\" is preferred, or the individual is indifferent).\n\nTransitivity assumes that preferences are consistent across any three options:\n\nContinuity assumes that there is a \"tipping point\" between being \"better than\" and \"worse than\" a given middle option:\n\nwhere the notation on the left side refers to a situation in which \"L\" is received with probability \"p\" and \"N\" is received with probability (1–\"p\").\n\nInstead of continuity, an alternative axiom can be assumed that does not involve a precise equality, called the Archimedean property. It says that any separation in preference can be maintained under a sufficiently small deviation in probabilities:\n\nOnly one of (3) and (3′) need be assumed, and the other will be implied by the theorem.\n\nIndependence of irrelevant alternatives assumes that a preference holds independently of the possibility of another outcome:\n\nThe independence axiom implies the axiom on reduction of compound lotteries:\n\nTo see how Axiom 4 implies Axiom 4', set formula_29 in the expression in Axiom 4, and expand.\n\nFor any VNM-rational agent (i.e. satisfying axioms 1–4), there exists a function \"u\" which assigns to each outcome \"A\" a real number \"u(A)\" such that for any two lotteries,\n\nwhere \"E(u(L))\", or more briefly \"Eu\"(\"L\") is given by\n\nAs such, \"u\" can be uniquely determined (up to adding a constant and multiplying by a positive scalar) by preferences between \"simple lotteries\", meaning those of the form \"pA\" + (1 − \"p\")\"B\" having only two outcomes. Conversely, any agent acting to maximize the expectation of a function \"u\" will obey axioms 1–4. Such a function is called the agent's von Neumann–Morgenstern (VNM) utility.\n\nThe proof is constructive: it shows how the desired function formula_32 can be built. Here we outline the construction process for the case in which the number of sure outcomes is finite.\n\nSuppose there are \"n\" sure outcomes, formula_33. Note that every sure outcome can be seen as a lottery: it is a degenerate lottery in which the outcome is selected with probability 1. Hence, by the Completeness axiom, it is possible to order the outcomes from worst to best:\n\nWe assume that at least one of the inequalities is strict (otherwise the utility function is trivial—a constant). So formula_35. We use these two extreme outcomes—the worst and the best—as the scaling unit of our utility function, and define:\n\nFor every probability formula_38, define a lottery that selects the best outcome with probability formula_39 and the worst outcome otherwise:\nNote that formula_41 and formula_42.\n\nBy the Continuity axiom, for every sure outcome formula_43, there is a probability formula_44 such that:\n\nand\n\nFor every formula_47, the utility function for outcome formula_43 is defined as\n\nso the utility of every lottery formula_50 is the expectation of \"u\":\n\nTo see why this utility function make sense, consider a lottery formula_52, which selects outcome formula_43 with probability formula_3. But, by our assumption, the decision maker is indifferent between the sure outcome formula_43 and the lottery formula_56. So, by the Reduction axiom, he is indifferent between the lottery formula_57 and the following lottery:\nThe lottery formula_61 is, in effect, a lottery in which the best outcome is won with probability formula_62, and the worst outcome otherwise.\n\nHence, if formula_63, a rational decision maker would prefer the lottery formula_57 over the lottery formula_65, because it gives him a larger chance to win the best outcome.\n\nHence:\n\nVon Neumann and Morgenstern anticipated surprise at the strength of their conclusion. But according to them, the reason their utility function works is that it is constructed precisely to fill the role of something whose expectation is maximized:\n\"Many economists will feel that we are assuming far too much ... Have we not shown too much? ... As far as we can see, our postulates [are] plausible ... We have practically defined numerical utility as being that thing for which the calculus of mathematical expectations is legitimate.\" – \"VNM 1953, § 3.1.1 p.16 and § 3.7.1 p. 28\"\nThus, the content of the theorem is that the construction of \"u\" is possible, and they claim little about its nature.\n\nIt is often the case that a person, faced with real-world gambles with money, does not act to maximize the expected value of their \"dollar assets.\" For example, a person who only possesses $1000 in savings may be reluctant to risk it all for a 20% chance odds to win $10,000, even though\n\nHowever, \"if\" the person is VNM-rational, such facts are automatically accounted for in their utility function \"u\". In this example, we could conclude that\n\nwhere the dollar amounts here really represent \"outcomes\" (cf. \"value\"), the three possible situations the individual could face. In particular, \"u\" can exhibit properties like \"u\"($1)+\"u\"($1) ≠ \"u\"($2) without contradicting VNM-rationality at all. This leads to a quantitative theory of monetary risk aversion.\n\nIn 1738, Daniel Bernoulli published a treatise in which he posits that rational behavior can be described as maximizing the expectation of a function \"u\", which in particular need not be monetary-valued, thus accounting for risk aversion. This is the \"expected utility hypothesis\". As stated, the hypothesis may appear to be a bold claim. The aim of the \"expected utility theorem\" is to provide \"modest conditions\" (i.e. axioms) describing when the expected utility hypothesis holds, which can be evaluated directly and intuitively:\n\"The axioms should not be too numerous, their system is to be as simple and transparent as possible, and each axiom should have an immediate intuitive meaning by which its appropriateness may be judged directly. In a situation like ours this last requirement is particularly vital, in spite of its vagueness: we want to make an intuitive concept amenable to mathematical treatment and to see as clearly as\npossible what hypotheses this requires.\" – \"VNM 1953 § 3.5.2, p. 25\"\nAs such, claims that the expected utility hypothesis does not characterize rationality must reject one of the VNM axioms. A variety of generalized expected utility theories have arisen, most of which drop or relax the independence axiom.\n\nBecause the theorem assumes nothing about the nature of the possible outcomes of the gambles, they could be morally significant events, for instance involving the life, death, sickness, or health of others. A von Neumann–Morgenstern rational agent is capable of acting with great concern for such events, sacrificing much personal wealth or well-being, and all of these actions will factor into the construction/definition of the agent's VNM-utility function. In other words, both what is naturally perceived as \"personal gain\", and what is naturally perceived as \"altruism\", are implicitly balanced in the VNM-utility function of a VNM-rational individual. Therefore, the full range of agent-focussed to agent-neutral behaviors are .\n\nIf the utility of formula_70 is formula_71, a von Neumann–Morgenstern rational agent must be indifferent between formula_72 and formula_73. An agent-focused von Neumann–Morgenstern rational agent therefore cannot favor more equal, or \"fair\", distributions of utility between its own possible future selves.\n\nSome utilitarian moral theories are concerned with quantities called the \"total utility\" and \"average utility\" of collectives, and characterize morality in terms of favoring the utility or happiness of others with disregard for one's own. These notions can be related to, but are distinct from, VNM-utility:\n\nThe term \"E-utility\" for \"experience utility\" has been coined to refer to the types of \"hedonistic\" utility like that of Bentham's greatest happiness principle. Since morality affects decisions, a VNM-rational agent's morals will affect the definition of its own utility function (see above). Thus, the morality of a VNM-rational agent can be characterized by \"correlation\" of the agent's VNM-utility with the VNM-utility, E-utility, or \"happiness\" of others, among other means, but not by \"disregard\" for the agent's own VNM-utility, a contradiction in terms.\n\nSince if \"L\" and \"M\" are lotteries, then \"pL\" + (1 − \"p\")\"M\" is simply \"expanded out\" and considered a lottery itself, the VNM formalism ignores what may be experienced as \"nested gambling\". This is related to the Ellsberg problem where people choose to avoid the perception of \"risks about risks\". Von Neumann and Morgenstern recognized this limitation:\n\n\"...concepts like a \"specific utility of gambling\" cannot be formulated free of contradiction on this level. This may seem to be a paradoxical assertion. But anybody who has seriously tried to axiomatize that elusive concept, will probably concur with it.\" – \"VNM 1953 § 3.7.1, p. 28\".\n\nSince for any two VNM-agents \"X\" and \"Y\", their VNM-utility functions \"u\" and \"u\" are only determined up to additive constants and multiplicative positive scalars, the theorem does not provide any canonical way to compare the two. Hence expressions like \"u\"(\"L\") + \"u\"(\"L\") and \"u\"(\"L\") − \"u\"(\"L\") are not canonically defined, nor are comparisons like \"u\"(\"L\") < \"u\"(\"L\") canonically true or false. In particular, the aforementioned \"total VNM-utility\" and \"average VNM-utility\" of a population are not canonically meaningful without normalization assumptions.\n\nThe expected utility hypothesis, as applied to economics, has limited predictive accuracy, simply because in practice, humans do not always behave VNM-rationally. This is manifested in several experimental outcomes such as the Allais paradox.\nThis can be interpreted as evidence that\n\n"}
{"id": "245829", "url": "https://en.wikipedia.org/wiki?curid=245829", "title": "War Resisters League", "text": "War Resisters League\n\nThe War Resisters League (WRL) is the oldest secular pacifist organization in the United States. \n\nFounded in 1923 by men and women who had opposed World War I, it is a section of the London-based War Resisters' International. It continues to be one of the leading radical voices in the anti-war movement.\n\nMany of the organization's founders had been jailed during World War I for refusing military service. From the Fellowship of Reconciliation many Jews, suffragists, socialists, and anarchists separated to form this more secular organization.\n\nAlthough the WRL was opposed to US participation in World War II, it did not protest against it; the WRL complied with the Espionage Act, ceased public protests, and did not solicit new members during this period. During World War II, many members were imprisoned as conscientious objectors. In the 1950s, WRL members worked in the civil rights movement and organized protests against nuclear weapons testing and civil defense drills.\n\nIn the 1960s, WRL was the first pacifist organization to call for an end to the Vietnam War. WRL also organized the first demonstration against the war with a September 21, 1963 vigil at the U.S. Mission to the UN, followed by an October 9, 1963 picket of Madame Ngo Dinh Nhu speaking at the Waldorf-Astoria in New York City. WRL was among the primary groups (along with Committee for Nonviolent Action, the Fellowship of Reconciliation, the Socialist Party, and the Student Peace Union) to organize coordinated nationwide protests against the Vietnam War on December 19, 1964.\n\nThe organization's opposition to nuclear weapons was extended to include nuclear power in the 1970s and 1980s. The WRL has also been active in feminist and anti-racist causes and works with other organizations to reduce the level of violence in modern culture.\n\nPresently, the War Resisters League is actively organizing against the wars in Iraq and Afghanistan as well as the impact of war at home. Much of its organizing is focused on challenging military recruiters and ending corporate profit from war. It publishes an annual peace calendar, the quarterly magazine \"WIN: Through Revolutionary Nonviolence\", and other materials and is involved in a number of national peace and justice coalitions, including United for Peace and Justice and the National War Tax Resistance Coordinating Committee. Since 1958, WRL has awarded almost annually the War Resisters League Peace Award to a person or organization whose work represents the League's radical nonviolent program of action.\n\nThe War Resisters League annually publishes a pie chart showing how much of the U.S. federal budget actually covers current and past military expenses, listing the total as 54%:\n\nThese figures are at odds with official government figures: \n\n\n\n"}
