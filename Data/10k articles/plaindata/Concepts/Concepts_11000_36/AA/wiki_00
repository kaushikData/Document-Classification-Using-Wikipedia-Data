{"id": "1186695", "url": "https://en.wikipedia.org/wiki?curid=1186695", "title": "Alternity", "text": "Alternity\n\nAlternity is a science fiction role-playing game (RPG) published by TSR in 1998. Following the acquisition of TSR by Wizards of the Coast, the game was discontinued in 2000 as part of a broader rationalisation of TSR's business holdings, but it retains a small and devoted fanbase. Parts of \"Alternity\" as well as TSR's classic \"Star Frontiers\" game have been incorporated into the \"d20 Modern\" game, especially the \"d20 Future\" setting. The first campaign setting for the \"Alternity\" game, the \"Star*Drive\" setting, was introduced in 1998.\n\nA new game called \"Alternity\" is due in 2017.\n\nCharacters were created with a point-based system, and could be either humans, mutants, one of several alien species presented in the core books, or original aliens created by the GM. Classes were replaced by professions, which dictated what skills and abilities were cheaper for any given hero to get, though a few skills (in particular, psionics) were restricted to specific professions. \n\nSkills are classified into broad and speciality skills. Earning a specialty skill requires an associated broad skill, which requires a character to have sufficient associated ability points. Special skill is further classified into ranks, which affects the skill's scores. Skill scores are presented with the full score, half that score, and one-quarter that score. which represent the numbers needed to achieve Ordinary, Good, or Amazing successes in an action round respectively.\n\nUnlike many other systems, actions are determined by a control die and situation\ndice. When Gamemaster calls for a roll, player rolls 1 control die and 1 situation die. The control die is always a 20-sided die, while situation die can be a 0, 4, 6, 8, 12, 20-sided die, where 0-sided die means the action only depends on control die roll. Situation die can be plus die or a minus die, in which the value in the situation die is added to or subtracted from control die value. The total of the rolled numbers is checked against character's action, skill, feat, to indicate a success or a failure. Rolling low is always better for successfully completing an action. \n\nThe type of situation die being used depends on the difficulty of the action. Difficulty is scaled in die types of -d20, -d12, -d8, -d6, -d4, +d0, +d4, +d6, +d8, +d12, +d20, +2d20, +3d20. A character's base situation die is +d4 for broad skill or feat check, +d0 for specialty skill or action check. A minus situation bonus means player uses a larger negative situation die set, while a plus situation penalty means a player uses a larger positive situation die set.\n\nIn an action round, a round is divided into 4 phases. Each phase relates to one of the degrees of success that are achievable on an action check: Amazing, Good, Ordinary, and Marginal, in order from the first phase to the last. A hero can attempt only 1 action per phase. Acting orders of characters are determined by a d20 die roll for all participants, which determines the earliest phase in which a character can act. All actions in a phase are considered to occur simultaneously, with the results of those actions being applied at the end of the phase. A character can act in as many phases as it has actions per round.\n\nDepending on how far below the skill score the player rolled, there are 3 progressively better layers of success and 2 levels of failure. An action is determined using this same system, making the game very uniform. Only armor rolls and damage rolls did not use the d20.\n\nLife points, called 'Durability', are categorized into Stun, Wound, Mortal. Stun damage can immobilize a character, but not life-threatening; wound damage can immobilize a character and inflicts 1 stun damage point for every 2 wound damage points received; mortal damage can kill a character, and inflicts 1 wound damage point for every 2 mortal damage points received. Durabilities can be repaired by healing, or:\n\nDesigned to be a generic rule set around which a campaign world could be built, it was not very heavily marketed and suffered from mediocre sales which, along with increased focus on the d20 system, led to the discontinuation of the game in 2000.\n\nMuch of the content of the \"Alternity\" game has been absorbed into the \"d20 Modern\" role-playing game. The \"Dark•Matter\" campaign is an entire \"d20 Modern\" expansion and \"Star Drive\" is part of the \"d20 Future\" expansion. The \"Gamma World\" campaign is an \"d20 Modern\" expansion by Sword & Sorcery Studios (White Wolf).\n\n\"Alternity\" uses four, six, eight, twelve, and twenty-sided dice, but does not use the popular ten-sided die, perhaps to help distinguish it from the competing \"World of Darkness\" and the \"Trinity\" role-playing game, published by White Wolf Game Studio.\n\nThe probability curve created by the addition or subtraction of a d20 and another die is shaped like a plateau, with two straight lines on both ends of the flat region. This is intermediate between the totally flat probability curve rolled by rolling a 20-sided die and the bell-shaped curve produced by die pool systems.\n\nSeveral books were published under the \"Alternity\" banner as core products, accessories, or under specific campaign settings.\n\nThese products presented the basic rules and information about the \"Alternity\" system.\n\nThese products were not tied to any of the official campaign settings but could be used with them.\n\nIn addition to the general \"Alternity\" line of products, four campaign settings were published, each with their own books:\n\n"}
{"id": "52205559", "url": "https://en.wikipedia.org/wiki?curid=52205559", "title": "American Visions: The Epic History of Art in America", "text": "American Visions: The Epic History of Art in America\n\nAmerican Visions: The Epic History of Art in America is a 1997 book by art critic Robert Hughes.\n\n\"BookList\" called \"American Visions\" a \"sensational history of American art.\" and wrote \"The contrast between the influence of nature and of the city on American art is the fulcrum of Hughes' entire narrative ...\" and \"\" stated \"The book bears the stamp of the author's aesthetic sensibilities (which value works of art for their technical competence as well as visual and intellectual qualities), his critical acuity, and his accomplished writing.\" \n\n\"Kirkus Reviews\" gave a starred review and described it as an \"eminently readable handbook on American art.\", writing \"His readings of three centuries of both art works and trends are lively, detailed, and persuasive (though perhaps a bit too harsh regarding recent art), and his ultimately pessimistic take is expressed with great clarity. A meaty and illuminating excavation, full of vigor and punch...\" Publishers Weekly noted \"this is no bland, dumbed-down survey intended to flatter its subject or its audience. Hughes writes with an aesthete's disdain for political posturing, a traditionalist's belief in the importance of technical skills (painters are frequently taken to task for their shoddy draftsmanship) and a pragmatist's contempt for mystagogical bunk.\", found \"his account of the contemporary scene is disappointingly brief.\" and concluded \"This slashingly witty, briskly paced, ferociously opinionated tour of the American visual landscape is a book that even the most un-likeminded readers will love to hate.\"\n\nA \"New York Times\" review calls it a \"witty and impassioned history of American art from its beginnings to the present day\", \"beautiful and essential\", notes that \"Mr. Hughes fortunately remains the critic throughout his historical canvassing, making distinctions and judgments without taking sides.\" and concludes \"With it, Mr. Hughes has made American art safe for the receptive alien deep inside us all.\" \"American Visions\" has also been reviewed by the \"London Review of Books\", \"The Journal of American History\", and \"The New York Review of Books\".\n"}
{"id": "35817324", "url": "https://en.wikipedia.org/wiki?curid=35817324", "title": "Appreciative advising", "text": "Appreciative advising\n\nAppreciative Advising (AA) is a social-constructivist advising philosophy that provides a framework for optimizing advisor interactions with students in both individual and group settings. The heart and soul of appreciative advising is the organizational development theory of appreciative inquiry that was developed in 1979 by David Cooperrider at Case Western Reserve University. Appreciative advising also draws from the positive psychology, social constructivist theory, and choice theory literature.\nAppreciative advising emerged from an article written by Jennifer L. Bloom and Nancy Archer Martin titled \"Incorporating Appreciative Inquiry into Academic Advising\" that appeared in the online academic advising journal at Penn State, \"The Mentor\", on August 29, 2002. Subsequently, the University of North Carolina at Greensboro (UNCG) began implementing the concepts outlined in the article and began to demonstrate success in terms of student retention. Bryant Hutson and Scott Amundsen at UNCG coined the term \"appreciative advising\". Bloom, Hutson, and He (2008) wrote the first book, titled \"The Appreciative Advising Revolution\", on the topic. Institutions and academic advisors from throughout the country are now utilizing the appreciative advising approach to guide their advising programs and interactions with students.\n\nIn 2012, the University of South Carolina began offering an online Appreciative Advising course as well as a process for certifying appreciative advisers. Building on the success of the Appreciative approach to academic advising, the movement has expanded to other areas, including teaching (appreciative college instruction), orientation, admissions, Greek life, and tutoring. This expansion of the principles of appreciative advising is now known as appreciative education.\n\nThe University of South Carolina's Office of Appreciative Education now offers a professional rating for academic advisers: Appreciative Advising Certification. Certified Appreciative Advisors are committed to a standard of excellence in the field of advising and optimizing their students' educational experiences. The certification process includes successful attendance of the Appreciative advising Institute or completion of the appreciative advising course, as well as completed advising rubrics, recommendations, a current CV, and personal advising theory.\n\n\nThe Appreciative Advising Institute was first held in August 2011 in Las Vegas, Nevada. The 2012 Appreciative Advising Institute was held July 28–31 in Charleston, SC. The Institute is intentionally designed to teach participants the theoretical structure of appreciative advising and to provide skills training in implementing this framework. This conference is designed to provide ample opportunity for participants to extend theory to practice. Participants learn how the six phases help both the advisor and advisee optimize their educational experiences. Participants are encouraged and given the opportunity to reflect on their own goals and dreams to optimize their own lives.\n\nThe Appreciative Advising Course is designed to be a community of learners (instructors included). There are opportunities for participants to interact with other community members each week. This is done via discussion board conversations, as well as optional live chat dialogues. Active participants greatly enhance their own learning experience as well as that of the community. This is an eight-week course.\n\n\nWhen students feel academically discouraged, such as when they are on academic probation, they may need to be reminded of the strengths that led them to college in the first place. Students in academic trouble also typically have a limited time in which to improve their status. Practically, it is quicker to correct this status by building on strengths, and maintaining a course load and engaging in academic and social behaviors that reflect these strengths, than it is to attempt to correct long-standing deficits. The SAS 100 program at UNCG is a great example of this application. The course features the use of the Appreciative Advising Inventory as the basis for three mandatory advising sessions and the use of appreciative advising questions in weekly reflections and discussions. All instructors are trained to use appreciative advising in their meetings with the students. After the appreciative approach was introduced, retention of SAS 100 students improved 18%. When control and treatment groups were compared, the treatment group achieved a statistically significant GPA gain of .73 (p=. 03) compared to the control group at .42.\n\nAppreciative advising is also particularly useful in internal transfer cases in which a student has realized that their current declared major may not be a good fit, but are struggling to identify a new major. Student Academic Services at UNCG has used appreciative advising to assist declared pre-nursing majors who have not met continuance requirements. This began as a pilot program in the spring of 2005, and currently includes all pre-nursing majors who have a cumulative GPA that has been identified as not competitive by the School of Nursing. The goal of the program is to help students explore their options, given that they are unlikely to be accepted into the School of Nursing. Of the 145 students served by the program during the spring and fall semesters of 2005, 30% have changed their major, while an additional 43% continue to receive advising through Student Academic Services. The mean GPA for participants has also improved dramatically.\n\nUNCG's First-Year Experience program is called University Studies 101 (UNS 101), and uses a curriculum emphasizing appreciative advising. One stated aim of the program is to assist students in discovering their purposes, identifying their strengths, and aligning these newly discovered assets with plans for their future. The activities, class discussions, and assignments used in the course guide students through the six appreciative advising stages. A comprehensive program evaluation which includes the tracking of academic outcomes and assessment of student attitudes and behaviors has evidenced the positive impact of the UNS 101 program (Hutson & Atwood, 2005). For example, the freshman to sophomore retention rate of freshmen who completed UNS 101 in fall 2006 and returned for fall 2007 was 81.9%. This compares to a retention rate of 74.4% for freshmen who did not take the course. Meanwhile, the average first semester GPA for students who did not take the course was 2.49, while UNS 101 participants had an average first semester GPA of 2.72.\n\nBooks \n\nArticles <br>\nFor a more exhaustive list of articles consult appreciativeadvising.net. Those listed below were pulled from that site. \n\n"}
{"id": "230542", "url": "https://en.wikipedia.org/wiki?curid=230542", "title": "Appreciative inquiry", "text": "Appreciative inquiry\n\nAppreciative inquiry (AI) is a model that seeks to engage stakeholders in self-determined change. According to Bushe \"AI revolutionized the field of organization development and was a precursor to the rise of positive organization studies and the strengths based movement in American management.\" It was developed at Case Western Reserve University's department of organizational behavior, starting with a 1987 article by David Cooperrider and Suresh Srivastva. They felt that the overuse of \"problem solving\" hampered any kind of social improvement, and what was needed were new methods of inquiry that would help generate new ideas and models for how to organize.\n\nCooperrider and Srivastva took a social constructionist approach, arguing that organizations are created, maintained and changed by conversations, and claiming that methods of organizing were only limited by people's imaginations and the agreements among them.\n\nIn 2001, Cooperrider and Diana Whitney published an article outlining the five principles of AI.\n\nIn 1996, Cooperrider, Whitney and several of their colleagues became centrally involved using AI to mid-wife the creation of the United Religions Initiative, a global organization dedicated to promoting grassroots interfaith cooperation for peace, justice and healing. This early partnership between URI and AI is chronicled in Birth of a Global Community: Appreciative Inquiry in Action by Charles Gibbs and Sally Mahé. AI was also used in the first (1999) and subsequent meetings of business leaders that created the UN's Global Compact. In another of the early applications, Cooperrider and Whitney taught AI to employees of GTE (now part of Verizon) resulting in improvements in employees' support for GTE's business direction and. as a part of continuous process improvement generated both improvements in revenue collection and cost savings earning GTE an ASTD award for the best organisational change program in the US in 1997.\"\n\nOn May 8, 2010, Suresh Srivastva died.\n\nGervase Bushe, a researcher on the topic, published a 2011 review of the model, including its processes, critiques, and evidence. He also published a history of the model in 2012.\n\nAccording to Bushe, AI \"advocates collective inquiry into the best of what is, in order to imagine what could be, followed by collective design of a desired future state that is compelling and thus, does not require the use of incentives, coercion or persuasion for planned change to occur.\"\n\nThe model is based on the assumption that the questions we ask will tend to focus our attention in a particular direction, that organizations evolve in the direction of the questions they most persistently and passionately ask. In the mid 80's most methods of assessing and evaluating a situation and then proposing solutions were based on a \"deficiency\" model, predominantly asking questions such as \"What are the problems?\", \"What's wrong?\" or \"What needs to be fixed?\". Instead of asking \"What's the problem?\", others couched the question in terms of \"challenges\", which still focused on deficiency, on what needs to be fixed or solved. Appreciative Inquiry was the first serious managerial method to refocus attention on what works, the positive core, and on what people really care about. Today, these ways of approaching organizational change are common\n\nThe five principles of AI are:\n\nSome researchers believe that excessive focus on dysfunctions can actually cause them to become worse or fail to become better. By contrast, AI argues, when all members of an organization are motivated to understand and value the most favourable features of its culture, it can make rapid improvements.\n\nStrength-based methods are used in the creation of organizational development strategy and implementation of organizational effectiveness tactics. The \"appreciative\" mode of inquiry often relies on interviews to qualitatively understand the organization's potential strengths by looking at an organization's experience and its potential; the objective is to elucidate the assets and personal motivations that are its strengths.\n\nBushe has argued that mainstream proponents of AI focus too much attention on \"the positive\" and not enough on the transformation that AI can bring about through generating new ideas and the will to act on them. In a 2010 comparative study in a school district he found that even in cases where no change occurred participants were highly positive during the AI process. What distinguished those sites that experienced transformational changes was the creation of new ideas that gave people new ways to address old problems. He argues that for transformational change to occur, AI must address problems that concern people enough to want to change. However, AI addresses them not through problem-solving, but through generative images. Some of this is covered in a 90-minute discussion about AI, positivity and generativity by Bushe and Dr. Ron Fry of Case Western, at the 2012 World Appreciative Inquiry Conference.\n\nThe following table comes from the Cooperrider and Whitney (2001) article and is used to describe some of the distinctions between AI and approaches to organizational development not based on what they call positive potential:\n\nAppreciative inquiry attempts to use ways of asking questions and envisioning the future in order to foster positive relationships and build on the present potential of a given person, organization or situation. The most common model utilizes a cycle of four processes, which focus on what it calls:\n\nThe aim is to build – or rebuild – organizations around what works, rather than trying to fix what doesn't. AI practitioners try to convey this approach as the opposite of problem solving.\n\nThere are a variety of approaches to implementing appreciative inquiry, including mass-mobilised interviews and a large, diverse gathering called an Appreciative Inquiry Summit. These approaches involve bringing large, diverse groups of people together to study and build upon the \"best\" in an organization or community.\n\nAI is used in organizational development and as a consultancy tool in an attempt to bring about strategic change. It has been applied in businesses, health care bodies, social non-profit organizations, educational institutions, and government operations. Although originating in the US, it is also used in the UK – for example in the National Support Teams and around the world. Since 2000, \"The AI Practitioner\", a quarterly publication, has described applications in a variety of settings around the world.\n\nAI has various business applications and can effectively be used to elicit information from stakeholders. Positivity is paired with a group consensus to envision and begin producing an optimistic future based on existing strengths and successes. As seen in Harbarian process modeling, AI has been used in Business process modeling to elicit information about an organization's present state and desired future state.\n\nIn Vancouver, AI is being used by the Dalai Lama Center for Peace and Education. The Center, which was founded by the Dalai Lama and Victor Chan, is using AI to facilitate compassionate communities.\n\n\n\n\n"}
{"id": "1120645", "url": "https://en.wikipedia.org/wiki?curid=1120645", "title": "Beyond Freedom and Dignity", "text": "Beyond Freedom and Dignity\n\nBeyond Freedom and Dignity is a 1971 book by American psychologist B. F. Skinner. Skinner argues that entrenched belief in free will and the moral autonomy of the individual (which Skinner referred to as \"dignity\") hinders the prospect of using scientific methods to modify behavior for the purpose of building a happier and better-organized society.\n\n\"Beyond Freedom and Dignity\" may be summarized as an attempt to promote Skinner's philosophy of science, the technology of human behavior, his conception of determinism, and what Skinner calls \"cultural engineering\".\n\nThe book is organized into nine chapters.\n\nIn this chapter Skinner proposes that a technology of behavior is possible and that it can be used to help solve currently pressing human issues such as over-population and warfare. \"Almost all major problems involve human behavior, and they cannot be solved by physical and biological technology alone. What is needed is a technology of human behavior.\"\n\nIn this chapter Skinner offers a more precise definition of freedom, one that allows for his conception of determinism, and speaks to the conventional notion of freedom. Skinner argues against \"autonomous man\".\n\nSkinner notes that the forces of Freedom and Dignity have led to many positive advances in the human condition, but may now be hindering the advance of a technology of human behavior: \"[the literature of freedom and dignity] has been successful in reducing the aversive stimuli used in intentional control, but it has made the mistake of defining freedom in terms of states of mind or feelings...\"\n\nDignity is the process by which people are given credit for their actions, or alternatively punished for them under the notion of responsibility. Skinner's analysis rejects both as \"dignity\" – a false notion of inner causality which removes both credit for action and blame for misdeeds, \"the achievements for which a person himself is to be given credit seem to approach zero.\".\n\nSkinner notes that credit is typically a function of the conspicuousness of control. We give less or no credit, or blame, to those who are overtly coached, compelled, prompted or otherwise not appearing to be producing actions spontaneously.\n\nSkinner saw punishment as the logical consequence of an unscientific analysis of behavior as well as the tradition of \"freedom and dignity\". Since individuals are seen to be making choices they are then able to be punished for those choices. Since Skinner denies the existence of free will, he therefore argued against punishment which he saw to be ineffective in controlling behavior.\n\nSkinner notes that the previous solutions to punishment are often not very useful and may create additional problems. Permissiveness, the metaphor of mid-wifery (or maieutics), \"guidance\", a dependence on things, \"changing minds\", all contain either problems or faulty assumptions about what is going on.\n\nSkinner argues that this misunderstanding of control championed by the defenders of freedom and dignity \"encourage[s] the misuse of controlling practices and block progress towards a more effective technology of behavior.\"\n\nSkinner notes a 'prescientific' view of man allows for personal achievement. The 'scientific view' moves human action to be explained by species evolution and environmental history.\n\nSkinner speaks to feelings about what is right, as well as popular notions of \"good\". Skinner translates popular words and phrases around value issues into his view of contingencies of reinforcement. Skinner notes that even if the technology of behavior produces \"goods\" to improve human life, they expose environmental control, which is offensive to the \"freedom and dignity\" perspective.\n\nSkinner suggests that cultural evolution is a way to describe the aggregate of (operant) behavior. A culture is a collection of behavior, or practices. Skinner addresses \"social Darwinism\" and argues that as a justification of the subordination of other nations or of war competition with others is a small part of natural selection. A much more important part is competition with the physical environment itself. Skinner relates the idea of cultural evolution back to the question of values: whose values are to survive?\n\nSkinner notes that cultural design is not new, but is already existing and on-going. Skinner notes that most discussions of current problems are dominated by metaphors, concerns for feelings and states of mind which do not illuminate possible solutions. Skinner notes that behavior modification is ethically neutral \n\nSkinner notes that Utopian speculations, like his novel \"Walden Two\" are a kind of cultural engineering. He then devotes much of the rest of this chapter to addressing the criticisms and complaints against cultural engineering.\n\nSkinner again addresses the notion of the individual, and discusses how aspects of a person's character could be assigned to environmental factors. He also covers cognition, problem solving, self-control and counters some arguments or possible misconceptions. Skinner notes that his analysis does not \"leave an empty organism\". Skinner addresses the issue of mechanical models of human action, which are better addressed elsewhere. Skinner notes that, \"The evolution of a culture is a gigantic effort in self-control.\" and ends with, \"A scientific view of man offers exciting possibilities. We have not yet seen what man can make of man.\"\n\n\"Beyond Freedom and Dignity\" is consistent with \"Walden Two\", a 1948 novel by Skinner, depicting a utopian community based on his ideas regarding behavior modification. In \"Beyond Freedom and Dignity\" Skinner extends his argument for explicit cultural engineering of which \"Walden Two\" may be seen as an example.\n\nLinguist Noam Chomsky criticized Skinner's methods and conclusions. Chomsky's 1971 essay \"The Case Against B.F. Skinner\" responded to \"Beyond Freedom and Dignity\", arguing against behaviorism and its claim to scientific status. In response to Skinner's denial of human dignity, Chomsky said, \"It would be absurd to conclude merely from the fact that freedom is limited, that “autonomous man” is an illusion (...) It would be hard to conceive of a more striking failure to comprehend even the rudiments of scientific thinking \".\n\nOther critics include Ayn Rand, whose 1971 article \"The Stimulus and the Response\" is an extended attack on \"Beyond Freedom and Dignity\" and a commentary on the significance of its reception.\n\nJohn Staddon criticized Skinner's contention that punishment is ineffective and free-will an unnecessary concept, arguing that \"Punishment doesn't always abolish freedom -- and freedom is not just absence of punishment\".\n\n"}
{"id": "7834", "url": "https://en.wikipedia.org/wiki?curid=7834", "title": "Chain reaction", "text": "Chain reaction\n\nA chain reaction is a sequence of reactions where a reactive product or by-product causes additional reactions to take place. In a chain reaction, positive feedback leads to a self-amplifying chain of events.\n\nChain reactions are one way that systems which are not in thermodynamic equilibrium can release energy or increase entropy in order to reach a state of higher entropy. For example, a system may not be able to reach a lower energy state by releasing energy into the environment, because it is hindered or prevented in some way from taking the path that will result in the energy release. If a reaction results in a small energy release making way for more energy releases in an expanding chain, then the system will typically collapse explosively until much or all of the stored energy has been released. \n\nA macroscopic metaphor for chain reactions is thus a snowball causing a larger snowball until finally an avalanche results (\"snowball effect\"). This is a result of stored gravitational potential energy seeking a path of release over friction. Chemically, the equivalent to a snow avalanche is a spark causing a forest fire. In nuclear physics, a single stray neutron can result in a prompt critical event, which may finally be energetic enough for a nuclear reactor meltdown or (in a bomb) a nuclear explosion.\n\nNumerous chain reactions can be represented by a mathematical model based on Markov chains.\n\nIn 1913, the German chemist Max Bodenstein first put forth the idea of chemical chain reactions. If two molecules react, not only molecules of the final reaction products are formed, but also some unstable molecules which can further react with the parent molecules with a far larger probability than the initial reactants (In the new reaction, further unstable molecules are formed besides the stable products, and so on ..).\n\nIn 1918, Walther Nernst proposed that the photochemical reaction between hydrogen and chlorine is a chain reaction in order to explain what's known as the \"quantum yield\" phenomena. This means that one photon of light is responsible for the formation of as many as 10 molecules of the product HCl. Nernst suggested that the photon dissociates a Cl molecule into two Cl atoms which each initiate a long chain of reaction steps forming HCl.\n\nIn 1923, Danish and Dutch scientists Christian Christiansen and Hendrik Anthony Kramers, in an analysis of the formation of polymers, pointed out that such a chain reaction need not start with a molecule excited by light, but could also start with two molecules colliding violently due to thermal energy as previously proposed for initiation of chemical reactions by van' t Hoff. \n\nChristiansen and Kramers also noted that if, in one link of the reaction chain, two or more unstable molecules are produced, the reaction chain would branch and grow. The result is in fact an exponential growth, thus giving rise to explosive increases in reaction rates, and indeed to chemical explosions themselves. This was the first proposal for the mechanism of chemical explosions.\n\nA quantitative chain chemical reaction theory was created later on by Soviet physicist Nikolay Semyonov in 1934. Semyonov shared the Nobel Prize in 1956 with Sir Cyril Norman Hinshelwood, who independently developed many of the same quantitative concepts. \n\nThe main types of steps in chain reaction are of the following types.\n\nThe \"chain length\" is defined as the average number of times the propagation cycle is repeated, and equals the overall reaction rate divided by the initiation rate.\n\nSome chain reactions have complex rate equations with fractional order or mixed order kinetics.\n\nThe reaction H + Br → 2 HBr proceeds by the following mechanism:\n\n\n\n\nAs can be explained using the steady-state approximation, the thermal reaction has an initial rate of fractional order (3/2), and a complete rate equation with a two-term denominator (mixed-order kinetics).\n\n\nA \"nuclear\" chain reaction was proposed by Leo Szilard in 1933, shortly after the neutron was discovered, yet more than five years before nuclear fission was first discovered. Szilárd knew of \"chemical\" chain reactions, and he had been reading about an energy-producing nuclear reaction involving high-energy protons bombarding lithium, demonstrated by John Cockcroft and Ernest Walton, in 1932. Now, Szilárd proposed to use neutrons theoretically produced from certain nuclear reactions in lighter isotopes, to induce further reactions in light isotopes that produced more neutrons. This would in theory produce a chain reaction at the level of the nucleus. He did not envision fission as one of these neutron-producing reactions, since this reaction was not known at the time. Experiments he proposed using beryllium and indium failed.\n\nLater, after fission was discovered in 1938, Szilárd immediately realized the possibility of using neutron-induced fission as the particular nuclear reaction necessary to create a chain-reaction, so long as fission also produced neutrons. In 1939, with Enrico Fermi, Szilárd proved this neutron-multiplying reaction in uranium. In this reaction, a neutron plus a fissionable atom causes a fission resulting in a larger number of neutrons than the single one that was consumed in the initial reaction. Thus was born the practical nuclear chain reaction by the mechanism of neutron-induced nuclear fission.\n\nSpecifically, if one or more of the produced neutrons themselves interact with other fissionable nuclei, and these also undergo fission, then there is a possibility that the macroscopic overall fission reaction will not stop, but continue throughout the reaction material. This is then a self-propagating and thus self-sustaining chain reaction. This is the principle for nuclear reactors and atomic bombs.\n\nDemonstration of a self-sustaining nuclear chain reaction was accomplished by Enrico Fermi and others, in the successful operation of Chicago Pile-1, the first artificial nuclear reactor, in late 1942.\n\nAn electron avalanche happens between two unconnected electrodes in a gas when an electric field exceeds a certain threshold. Random thermal collisions of gas atoms may result in a few free electrons and positively charged gas ions, in a process called impact ionization. Acceleration of these free electrons in a strong electric field causes them to gain energy, and when they impact other atoms, the energy causes release of new free electrons and ions (ionization), which fuels the same process. If this process happens faster than it is naturally quenched by ions recombining, the new ions multiply in successive cycles until the gas breaks down into a plasma and current flows freely in a discharge.\n\nElectron avalanches are essential to the dielectric breakdown process within gases. The process can culminate in corona discharges, streamers, leaders, or in a spark or continuous electric arc that completely bridges the gap. The process may extend huge sparks — streamers in lightning discharges propagate by formation of electron avalanches created in the high potential gradient ahead of the streamers' advancing tips. Once begun, avalanches are often intensified by the creation of photoelectrons as a result of ultraviolet radiation emitted by the excited medium's atoms in the aft-tip region. The extremely high temperature of the resulting plasma cracks the surrounding gas molecules and the free ions recombine to create new chemical compounds.\n\nThe process can also be used to detect radiation that initiates the process, as the passage of a single particles can be amplified to large discharges. This is the mechanism of a Geiger counter and also the visualization possible with a spark chamber and other wire chambers.\n\nAn avalanche breakdown process can happen in semiconductors, which in some ways conduct electricity analogously to a mildly ionized gas. Semiconductors rely on free electrons knocked out of the crystal by thermal vibration for conduction. Thus, unlike metals, semiconductors become better conductors the higher the temperature. This sets up conditions for the same type of positive feedback—heat from current flow causes temperature to rise, which increases charge carriers, lowering resistance, and causing more current to flow. This can continue to the point of complete breakdown of normal resistance at a semiconductor junction, and failure of the device (this may be temporary or permanent depending on whether there is physical damage to the crystal). Certain devices, such as avalanche diodes, deliberately make use of the effect.\n\n\n"}
{"id": "5999", "url": "https://en.wikipedia.org/wiki?curid=5999", "title": "Climate", "text": "Climate\n\nClimate is the statistics of weather over long periods of time. It is measured by assessing the patterns of variation in temperature, humidity, atmospheric pressure, wind, precipitation, atmospheric particle count and other meteorological variables in a given region over long periods of time. Climate differs from weather, in that weather only describes the short-term conditions of these variables in a given region.\n\nA region's climate is generated by the climate system, which has five components: atmosphere, hydrosphere, cryosphere, lithosphere, and biosphere.\n\nThe climate of a location is affected by its latitude, terrain, and altitude, as well as nearby water bodies and their currents. Climates can be classified according to the average and the typical ranges of different variables, most commonly temperature and precipitation. The most commonly used classification scheme was the Köppen climate classification. The Thornthwaite system, in use since 1948, incorporates evapotranspiration along with temperature and precipitation information and is used in studying biological diversity and how climate change affects it. The Bergeron and Spatial Synoptic Classification systems focus on the origin of air masses that define the climate of a region.\n\nPaleoclimatology is the study of ancient climates. Since direct observations of climate are not available before the 19th century, paleoclimates are inferred from proxy variables that include non-biotic evidence such as sediments found in lake beds and ice cores, and biotic evidence such as tree rings and coral. Climate models are mathematical models of past, present and future climates. Climate change may occur over long and short timescales from a variety of factors; recent warming is discussed in global warming. Global warming results in redistributions. For example, \"a 3°C change in mean annual temperature corresponds to a shift in isotherms of approximately 300–400 km in latitude (in the temperate zone) or 500 m in elevation. Therefore, species are expected to move upwards in elevation or towards the poles in latitude in response to shifting climate zones\".\n\nClimate (from Ancient Greek \"klima\", meaning \"inclination\") is commonly defined as the weather averaged over a long period. The standard averaging period is 30 years, but other periods may be used depending on the purpose. Climate also includes statistics other than the average, such as the magnitudes of day-to-day or year-to-year variations. The Intergovernmental Panel on Climate Change (IPCC) 2001 glossary definition is as follows:\n\nThe World Meteorological Organization (WMO) describes climate \"normals\" as \"reference points used by climatologists to compare current climatological trends to that of the past or what is considered 'normal'. A Normal is defined as the arithmetic average of a climate element (e.g. temperature) over a 30-year period. A 30 year period is used, as it is long enough to filter out any interannual variation or anomalies, but also short enough to be able to show longer climatic trends.\" The WMO originated from the International Meteorological Organization which set up a technical commission for climatology in 1929. At its 1934 Wiesbaden meeting the technical commission designated the thirty-year period from 1901 to 1930 as the reference time frame for climatological standard normals. In 1982 the WMO agreed to update climate normals, and these were subsequently completed on the basis of climate data from 1 January 1961 to 31 December 1990.\n\nThe difference between climate and weather is usefully summarized by the popular phrase \"Climate is what you expect, weather is what you get.\" Over historical time spans there are a number of nearly constant variables that determine climate, including latitude, altitude, proportion of land to water, and proximity to oceans and mountains. These change only over periods of millions of years due to processes such as plate tectonics. Other climate determinants are more dynamic: the thermohaline circulation of the ocean leads to a 5 °C (9 °F) warming of the northern Atlantic Ocean compared to other ocean basins. Other ocean currents redistribute heat between land and water on a more regional scale. The density and type of vegetation coverage affects solar heat absorption, water retention, and rainfall on a regional level. Alterations in the quantity of atmospheric greenhouse gases determines the amount of solar energy retained by the planet, leading to global warming or global cooling. The variables which determine climate are numerous and the interactions complex, but there is general agreement that the broad outlines are understood, at least insofar as the determinants of historical climate change are concerned.\n\nThere are several ways to classify climates into similar regimes. Originally, climes were defined in Ancient Greece to describe the weather depending upon a location's latitude. Modern climate classification methods can be broadly divided into \"genetic\" methods, which focus on the causes of climate, and \"empiric\" methods, which focus on the effects of climate. Examples of genetic classification include methods based on the relative frequency of different air mass types or locations within synoptic weather disturbances. Examples of empiric classifications include climate zones defined by plant hardiness, evapotranspiration, or more generally the Köppen climate classification which was originally designed to identify the climates associated with certain biomes. A common shortcoming of these classification schemes is that they produce distinct boundaries between the zones they define, rather than the gradual transition of climate properties more common in nature.\n\nThe simplest classification is that involving air masses. The Bergeron classification is the most widely accepted form of air mass classification. Air mass classification involves three letters. The first letter describes its moisture properties, with c used for continental air masses (dry) and m for maritime air masses (moist). The second letter describes the thermal characteristic of its source region: T for tropical, P for polar, A for Arctic or Antarctic, M for monsoon, E for equatorial, and S for superior air (dry air formed by significant downward motion in the atmosphere). The third letter is used to designate the stability of the atmosphere. If the air mass is colder than the ground below it, it is labeled k. If the air mass is warmer than the ground below it, it is labeled w. While air mass identification was originally used in weather forecasting during the 1950s, climatologists began to establish synoptic climatologies based on this idea in 1973.\n\nBased upon the Bergeron classification scheme is the Spatial Synoptic Classification system (SSC). There are six categories within the SSC scheme: Dry Polar (similar to continental polar), Dry Moderate (similar to maritime superior), Dry Tropical (similar to continental tropical), Moist Polar (similar to maritime polar), Moist Moderate (a hybrid between maritime polar and maritime tropical), and Moist Tropical (similar to maritime tropical, maritime monsoon, or maritime equatorial).\n\nThe Köppen classification depends on average monthly values of temperature and precipitation. The most commonly used form of the Köppen classification has five primary types labeled A through E. These primary types are A) tropical, B) dry, C) mild mid-latitude, D) cold mid-latitude, and E) polar. The five primary classifications can be further divided into secondary classifications such as rainforest, monsoon, tropical savanna, humid subtropical, humid continental, oceanic climate, Mediterranean climate, desert, steppe, subarctic climate, tundra, and polar ice cap.\n\nRainforests are characterized by high rainfall, with definitions setting minimum normal annual rainfall between and . Mean monthly temperatures exceed during all months of the year.\n\nA monsoon is a seasonal prevailing wind which lasts for several months, ushering in a region's rainy season. Regions within North America, South America, Sub-Saharan Africa, Australia and East Asia are monsoon regimes.\n\nA tropical savanna is a grassland biome located in semiarid to semi-humid climate regions of subtropical and tropical latitudes, with average temperatures remain at or above year round and rainfall between and a year. They are widespread on Africa, and are found in India, the northern parts of South America, Malaysia, and Australia.\n\nThe humid subtropical climate zone where winter rainfall (and sometimes snowfall) is associated with large storms that the westerlies steer from west to east. Most summer rainfall occurs during thunderstorms and from occasional tropical cyclones. Humid subtropical climates lie on the east side of continents, roughly between latitudes 20° and 40° degrees away from the equator.\nA humid continental climate is marked by variable weather patterns and a large seasonal temperature variance. Places with more than three months of average daily temperatures above and a coldest month temperature below and which do not meet the criteria for an arid or semiarid climate, are classified as continental.\n\nAn oceanic climate is typically found along the west coasts at the middle latitudes of all the world's continents, and in southeastern Australia, and is accompanied by plentiful precipitation year-round.\n\nThe Mediterranean climate regime resembles the climate of the lands in the Mediterranean Basin, parts of western North America, parts of Western and South Australia, in southwestern South Africa and in parts of central Chile. The climate is characterized by hot, dry summers and cool, wet winters.\n\nA steppe is a dry grassland with an annual temperature range in the summer of up to and during the winter down to .\n\nA subarctic climate has little precipitation, and monthly temperatures which are above for one to three months of the year, with permafrost in large parts of the area due to the cold winters. Winters within subarctic climates usually include up to six months of temperatures averaging below .\nTundra occurs in the far Northern Hemisphere, north of the taiga belt, including vast areas of northern Russia and Canada.\n\nA polar ice cap, or polar ice sheet, is a high-latitude region of a planet or moon that is covered in ice. Ice caps form because high-latitude regions receive less energy as solar radiation from the sun than equatorial regions, resulting in lower surface temperatures.\n\nA desert is a landscape form or region that receives very little precipitation. Deserts usually have a large diurnal and seasonal temperature range, with high or low, depending on location daytime temperatures (in summer up to ), and low nighttime temperatures (in winter down to ) due to extremely low humidity. Many deserts are formed by rain shadows, as mountains block the path of moisture and precipitation to the desert.\n\nDevised by the American climatologist and geographer C. W. Thornthwaite, this climate classification method monitors the soil water budget using evapotranspiration. It monitors the portion of total precipitation used to nourish vegetation over a certain area. It uses indices such as a humidity index and an aridity index to determine an area's moisture regime based upon its average temperature, average rainfall, and average vegetation type. The lower the value of the index in any given area, the drier the area is.\n\nThe moisture classification includes climatic classes with descriptors such as hyperhumid, humid, subhumid, subarid, semi-arid (values of −20 to −40), and arid (values below −40). Humid regions experience more precipitation than evaporation each year, while arid regions experience greater evaporation than precipitation on an annual basis. A total of 33 percent of the Earth's landmass is considered either arid or semi-arid, including southwest North America, southwest South America, most of northern and a small part of southern Africa, southwest and portions of eastern Asia, as well as much of Australia. Studies suggest that precipitation effectiveness (PE) within the Thornthwaite moisture index is overestimated in the summer and underestimated in the winter. This index can be effectively used to determine the number of herbivore and mammal species numbers within a given area. The index is also used in studies of climate change.\n\nThermal classifications within the Thornthwaite scheme include microthermal, mesothermal, and megathermal regimes. A microthermal climate is one of low annual mean temperatures, generally between and which experiences short summers and has a potential evaporation between and . A mesothermal climate lacks persistent heat or persistent cold, with potential evaporation between and . A megathermal climate is one with persistent high temperatures and abundant rainfall, with potential annual evaporation in excess of .\n\nDetails of the modern climate record are known through the taking of measurements from such weather instruments as thermometers, barometers, and anemometers during the past few centuries. The instruments used to study weather over the modern time scale, their known error, their immediate environment, and their exposure have changed over the years, which must be considered when studying the climate of centuries past.\n\nPaleoclimatology is the study of past climate over a great period of the Earth's history. It uses evidence from ice sheets, tree rings, sediments, coral, and rocks to determine the past state of the climate. It demonstrates periods of stability and periods of change and can indicate whether changes follow patterns such as regular cycles.\n\nClimate change is the variation in global or regional climates over time. It reflects changes in the variability or average state of the atmosphere over time scales ranging from decades to millions of years. These changes can be caused by processes internal to the Earth, external forces (e.g. variations in sunlight intensity) or, more recently, human activities.\n\nIn recent usage, especially in the context of environmental policy, the term \"climate change\" often refers only to changes in modern climate, including the rise in average surface temperature known as global warming. In some cases, the term is also used with a presumption of human causation, as in the United Nations Framework Convention on Climate Change (UNFCCC). The UNFCCC uses \"climate variability\" for non-human caused variations.\n\nEarth has undergone periodic climate shifts in the past, including four major ice ages. These consisting of glacial periods where conditions are colder than normal, separated by interglacial periods. The accumulation of snow and ice during a glacial period increases the surface albedo, reflecting more of the Sun's energy into space and maintaining a lower atmospheric temperature. Increases in greenhouse gases, such as by volcanic activity, can increase the global temperature and produce an interglacial period. Suggested causes of ice age periods include the positions of the continents, variations in the Earth's orbit, changes in the solar output, and volcanism.\n\nClimate models use quantitative methods to simulate the interactions of the atmosphere, oceans, land surface and ice. They are used for a variety of purposes; from the study of the dynamics of the weather and climate system, to projections of future climate. All climate models balance, or very nearly balance, incoming energy as short wave (including visible) electromagnetic radiation to the earth with outgoing energy as long wave (infrared) electromagnetic radiation from the earth. Any imbalance results in a change in the average temperature of the earth.\n\nThe most talked-about applications of these models in recent years have been their use to infer the consequences of increasing greenhouse gases in the atmosphere, primarily carbon dioxide (see greenhouse gas). These models predict an upward trend in the global mean surface temperature, with the most rapid increase in temperature being projected for the higher latitudes of the Northern Hemisphere.\n\nModels can range from relatively simple to quite complex:\n\nClimate forecasting is used by some scientists to predict climate change. In 1997 the prediction division of the International Research Institute for Climate and Society at Columbia University began generating seasonal climate forecasts on a real-time basis. To produce these forecasts an extensive suite of forecasting tools was developed, including a multimodel ensemble approach that required thorough validation of each model's accuracy level in simulating interannual climate variability.\n\n\n"}
{"id": "24502933", "url": "https://en.wikipedia.org/wiki?curid=24502933", "title": "CoSMoS", "text": "CoSMoS\n\nCoSMoS was a UK funded research project seeking to build capacity in generic modelling tools and simulation techniques for complex systems. Its acronym stands for Complex Systems Modelling and Simulation.\nThis was a four-year project, running from 2007 to 2011 as a collaboration between the University of York and Kent, with further collaborations from the University of Abertay Dundee and Bristol Robotics Laboratory.\n\nCollaboration between the universities of York and Kent started with the TUNA project, a feasibility study looking at the requirements for developing networks of nanites that behave safely. This project involved researchers from York, Kent and Surrey. TUNA's outcomes were both conceptual and practical. An example of theoretical contribution consists of investigators showing that emergent properties do not refine\n, but gave insights into the engineering of emergence.\nPractical results were obtained through the use of a blood clotting case-study. This led to the development of a process-oriented, large-scale simulation implemented in occam-pi.\n"}
{"id": "16759434", "url": "https://en.wikipedia.org/wiki?curid=16759434", "title": "Comparison of the Amundsen and Scott Expeditions", "text": "Comparison of the Amundsen and Scott Expeditions\n\nBetween December 1911 and January 1912, both Roald Amundsen (leading his South Pole expedition) and Robert Falcon Scott (leading the Terra Nova Expedition) reached the South Pole within a month of each other. But while Scott and his four companions died on the return journey, Amundsen's party managed to reach the geographic south pole first and subsequently return to their base camp at Framheim without loss of life, suggesting that they were better prepared for the expedition. The contrasting fates of the two teams seeking the same prize at the same time invites comparison.\n\nThe outcomes of the two expeditions were as follows.\n\nHistorically, several factors have been discussed and many contributing factors claimed, including:\n\nSullivan states that it was the last factor that probably was decisive. he states \"Man is a poor beast of burden, as was shown in the terrible experience of Scott, Shackleton, and Wilson in their thrust to the south of 1902–3. However, Scott relied chiefly on man-hauling in 1911–12 because ponies could not ascend the glacier midway to the Pole. The Norwegians correctly estimated that dog teams could go all the way. Furthermore, they used a simple plan, based on their native skill with skis and on dog-driving methods that were tried and true. In a similar fashion to the way the moon was reached by expending a succession of rocket stages and then casting each aside; the Norwegians used the same strategy, sacrificing the weaker animals along the journey to feed the other animals and the men themselves.\"\n\nScott and his financial backers saw the expedition as having a scientific basis, while also wishing to reach the pole. However, it was recognised by all involved that the South Pole was the primary objective (\"The Southern Journey involves the most important object of the Expedition\" – Scott), and had priority in terms of resources, such as the best ponies and all the dogs and motor sledges as well as involvement of the vast majority of the expedition personnel. Scott and his team knew the expedition would be judged on his attainment of the pole (\"The ... public will gauge the result of the scientific work of the expedition largely in accordance with the success or failure of the main object\" – Scott). He was prepared to make a second attempt the following year (1912–13) if this attempt failed and had Indian Army mules and additional dogs delivered in anticipation. In fact the mules were used by the team that discovered the dead bodies of Scott, Henry Robertson Bowers, and Edward Adrian Wilson in November 1912, but proved even less useful than the ponies, according to Cherry-Garrard.\n\nAmundsen's expedition was planned to reach the South Pole. This was a plan he conceived in 1909. Amundsen's expedition did conduct geographical work under Kristian Prestrud who conducted an expedition to King Edward VII Land while Amundsen was undertaking his attempt at the pole.\n\nAmundsen camped on the Ross Ice Shelf at the Bay of Whales which is 60 miles (96 km) closer to the pole than Scott's camp (which was 350 miles west of Amundsen). Amundsen had deduced that, as the Trans-Antarctic Mountains ran northwest to southeast then if he were to meet a mountain range on his route then the time spent at the high altitude of the Antarctic plateau would be less than Scott's.\nScott's base was at Cape Evans on Ross Island, with access to the Trans-Antarctic mountain range to the west, and was a better base for geological exploration. He had based his previous expedition in the same area. However, he knew it to be poor as a route to the pole as he had to start before sea ice melted and had suffered delay in returning while waiting for the sea ice to freeze. They also had to make detours around Ross Island and its known crevassed areas which meant a longer journey. The crossing of the Ross Ice Shelf was an onerous task for the ponies. Scott had advanced considerable stores across the ice shelf the year before to allow the ponies to carry lighter loads over the early passage across the ice. Even so, he had to delay the departure of the ponies until 1 November rather than 24 October when the dogs and motor sledges set off.\nConsequently, the Motor Party spent 6 days at the Mount Hooper Depot waiting for Scott to arrive.\n\nThe major comparison between Scott and Amundsen has focused on the choice of draft transport —dog versus pony/man-hauling. In fact Scott took dogs, ponies and three \"motor sledges\". Scott spent nearly seven times the amount of money on his motor sledges than on the dogs and horses combined. They were therefore a vital part of the expedition. Unfortunately, Scott decided to leave behind the engineer, Lieutenant Commander Reginald William Skelton who had created and trialled the motor sledges. This was due to the selection of Lieutenant E.R.G.R. \"Teddy\" Evans as the expedition's second in command. As Evans was junior in rank to Skelton, he insisted that Skelton could not come on the expedition. Scott agreed to this request and Skelton's experience and knowledge was lost. One of the original three motor sledges was a failure even before the expedition set out; the heavy sledge was lost through thin ice on unloading it from the ship. The two remaining motor sledges failed relatively early in the main expedition because of repeated faults. Skelton's experience might have been valuable in overcoming the failures.\n\nScott had used dogs on his first (Discovery) expedition and felt they had failed. On that journey, Scott, Shackleton, and Wilson started with three sledges and 13 dogs. But on that expedition, the men had not properly understood how to travel on snow with the use of dogs. The party had skis but were too inexperienced to make good use of them. As a result, the dogs travelled so fast that the men could not keep up with them. The Discovery expedition had to increase their loads to slow the dogs down. Additionally, the dogs were fed Norwegian dried fish, which did not agree with them and soon they began to deteriorate. The whole team of dogs eventually died (and were eaten), and the men took over hauling the sleds.\n\nScott's opinion was reinforced by Shackleton's experience on his Nimrod expedition that got to within of the pole. Shackleton used ponies. Scott planned to use ponies only to the base of the Beardmore Glacier (one-quarter of the total journey) and man-haul the rest of the journey. Scott's team had developed snow shoes for his ponies, and trials showed they could significantly increase daily progress. However, Lawrence Oates, whom Scott had made responsible for the ponies, was reluctant to use the snow shoes and Scott failed to insist on their use.\n\nThere was plenty of evidence that dogs could succeed in the achievements of William Speirs Bruce in his Arctic, Antarctic, and Scottish National Antarctic Expedition, Amundsen in the \"Gjøa\" North West passage expedition, Fridtjof Nansen's crossing of Greenland, Robert Peary's three attempts at the North Pole, Eivind Astrup's work supporting Peary, Frederick Cook's discredited North Pole expedition, and Otto Sverdrup's explorations of Ellesmere Island. Moreover, Scott ignored the direct advice he received (while attending trials of the motor sledges in Norway) from Nansen, the most famous explorer of the day, who told Scott to take \"dogs, dogs and more dogs\".\n\nAt the time of the events, the expert view in England had been that dogs were of dubious value as a means of Antarctic transport. Broadly speaking, Scott saw two ways in which dogs may be used—they may be taken with the idea of bringing them all back safe and sound, or they may be treated as pawns in the game, from which the best value is to be got regardless of their lives. He stated that if, and only if, the comparison was made with a dog sledge journey which aimed to preserve the dogs' lives, 'I am inclined to state my belief that in the polar regions properly organised parties of men will perform as extended journeys as teams of dogs.' On the other hand, if the lives of the dogs were to be sacrificed, then 'the dog-team is invested with a capacity for work which is beyond the emulation of men. To appreciate this is a matter of simple arithmetic'. But efficiency notwithstanding, he expressed \"reluctance\" to use dogs in this way: \"One cannot calmly contemplate the murder of animals which possess such intelligence and individuality, which have frequently such endearing qualities, and which very possibly one has learnt to regard as friends and companions.\"\n\nAmundsen, by contrast, took an entirely utilitarian approach. Amundsen planned from the start to have weaker animals killed to feed the other animals and the men themselves. He expressed the opinion that it was less cruel to feed and work dogs correctly before shooting them, than it would be to starve and overwork them to the point of collapse. Amundsen and his team had similar affection for their dogs as those expressed above by the English, but they \"also had agreed to shrink from nothing in order to achieve our goal\". The British thought such a procedure was distasteful, though they were willing to eat their ponies.\n\nAmundsen had used the opportunity of learning from the Inuit while on his \"Gjøa\" North West passage expedition of 1905. He recruited experienced dog drivers. To make the most of the dogs he paced them and deliberately kept daily mileages shorter than he need have for 75 percent of the journey, and his team spent up to 16 hours a day resting. His dogs could eat seals and penguins hunted in the Antarctic while Scott's pony fodder had to be brought all the way from England in their ship. It has been later shown that seal meat with the blubber attached is the ideal food for a sledge dog. Amundsen went with 52 dogs, and came back with 11.\n\nWhat Scott did not realise is a sledge dog, if it is to do the same work as a man, will require the same amount of food. Furthermore, when sledge dogs are given insufficient food they become difficult to handle. The advantage of the sledge dog is its greater mobility. Not only were the Norwegians accustomed to skiing, which enabled them to keep up with their dogs, but they also understood how to feed them and not overwork them.\n\nScott took the Norwegian pilot and skier Tryggve Gran to the Antarctic on the recommendation of Nansen to train his expedition to ski, but although a few of his party began to learn, he made no arrangements for compulsory training for the full party. Gran (possibly because he was Norwegian) was not included in the South Pole party, which could have made a difference. Gran was, one year later, the first to locate the deceased Scott and his remaining companions in their tent just some 18 km (11 miles) short of One Ton depot, that might have saved their lives had they reached it.\n\nScott would subsequently complain in his diary, while well into his journey and therefore too late to take any corrective action and after over 10 years since the Discovery expedition, that \"Skis are the thing, and here are my tiresome fellow countrymen too prejudiced to have prepared themselves for the event\".\n\nAmundsen on his side recruited a team of well experienced skiers, all Norwegians who had skied from an early age. He also recruited a champion skier, Olav Bjaaland, as the front runner. The Amundsen party gained weight on their return travel from the South Pole.\n\nScott and Shackleton's experience in 1903 and 1907 gave them first-hand experience of average conditions in Antarctica. Simpson, Scott's meteorologist 1910–1912, charted the weather during their expedition, often taking two readings a day. On their return to the Ross Ice Shelf, Scott's group experienced prolonged low temperatures from 27 February until 10 March which have only been matched once in 15 years of current records. The exceptional severity of the weather meant they failed to make the daily distances they needed to get to the next depot. This was a serious position as they were short of fuel and food. When Scott, Wilson, and Bowers died (Petty Officer Edgar Evans and Lawrence Oates had died earlier during the return from the South Pole) they were short of One-Ton Depot, which was from Corner Camp, where they would have been safe.\n\nOn the other hand, Cherry-Garrard had travelled nearly in the same area, during the same time period and same temperatures, using a dog team. Scott also blamed \"a prolonged blizzard\". But while there is evidence to support the low temperatures, there is only evidence for a \"normal\" two- to four-day blizzard, and not the ten days that Scott claims.\n\nDuring depot laying in February 1911, Roald Amundsen had his first (and last) of his route marked like a Norwegian ski course using marker flags initially every eight miles. He added to this by using food containers painted black, resulting in a marker every mile. From 82 degrees on, Amundsen built a cairn every three miles with a note inside recording the cairn's position, the distance to the next depot, and direction to the next cairn. In order not to miss a depot considering the snow and great distances, Amundsen took precautions. Each depot laid out up to 85 degrees (laid out every degree of latitude) had a line of bamboo flags laid out transversely every half-mile for five miles on either side of the depot, ensuring that the returning party could locate the designated depot.\n\nScott relied on depots much less frequently laid out. For one distance where Amundsen laid seven depots, Scott laid only two. Routes were marked by the walls made at lunch and evening stops to protect the ponies. Depots had a single flag. As a result, Scott has much concern recorded in his diaries over route finding, and experienced close calls about finding depots. It is also clear that Scott's team did not travel on several days, because the swirling snow hid their three-month-old outward tracks. With better depot and route marking they would have been able to travel on more days with a following wind which would have filled the sail attached to their sledge, and so travel further, and might have reached safety.\n\nBy the time they arrived at the pole, the health of Scott's team had significantly deteriorated, whereas Amundsen's team actually gained weight during the expedition. While Scott's team managed to maintain the scheduled pace for most of the return leg, and hence was virtually always on full rations, their condition continued to worsen rapidly. (The only delay occurred when they were held for four days by a blizzard, and had to open their summit rations early as a consequence.)\n\nApsley Cherry-Garrard in his analysis of the expedition estimated that even under optimistic assumptions the summit rations contained only a little more than half the calories actually required for the man-hauling of sledges. A carefully planned 2006 re-enactment of both Amundsen's and Scott's travels, sponsored by the BBC, confirmed Cherry-Garrard's theory. The British team had to abort their tour due to the severe weight loss of all members. The experts hinted that Scott's reports of unusually bad surfaces and weather conditions might in part have been due to their exhausted state which made them feel the sledge weights and the chill more severely.\n\nScott's calculations for the supply requirements were based on a number of expeditions, both by members of his team (e.g., Wilson's trip with Cherry-Garrard and Bowers to the Emperor penguin colony which had each man on a different type of experimental ration), and by Shackleton. Apparently, Scott didn't take the strain of prolonged man-hauling at high altitudes sufficiently into account.\n\nSince the rations contained no B and C vitamins, the only source of these vitamins during the trek was from the slaughter of ponies or dogs. This made the men progressively malnourished, manifested most clearly in the form of scurvy.\n\nScott also had to fight with a shortage of fuel due to leakage from stored fuel cans which used leather washers. This was a phenomenon that had been noticed previously by other expeditions, but Scott took no measures to prevent it. Amundsen, in contrast, had learned the lesson and had his fuel cans soldered closed. A fuel depot he left on Betty's Knoll was found 50 years later still full.\n\nDehydration may also have been a factor. Amundsen's team had plenty of fuel due to better planning and soldered fuel cans. Scott had a shortage of fuel and was unable to melt as much water as Amundsen. At the same time Scott's team were more physically active in man-hauling the sledges.\n\nIt has been said (by the present-day explorer Ranulph Fiennes amongst others) that Scott's team was appropriately dressed for man-hauling in their woolen and wind-proof clothing, and as Amundsen was skiing it was appropriate he wore furs. Skiing at the pace of a dog team is a strenuous activity. Yet Amundsen never complained about the clothing being too hot. That is because the furs are worn loosely so air circulates and sweat evaporates. Scott's team, on the other hand, made regular complaints about the cold.\n\nAmundsen's team did initially have problems with their boots. However, the depot-laying trips of January and February 1911 and an abortive departure to the South Pole on 8 September 1911 allowed changes to be made before it was too late.\n\nScott's team suffered regularly from snow blindness and sometimes this affected over half the team at any one time. By contrast, there was no recorded case of snow blindness during the whole of Amundsen's expedition. On the return journey, Amundsen's team rested during the \"day\" (when the sun was in front of them) and travelled during the \"night\" (when the sun was behind them) to minimise the effects of snow blindness.\n\nIn 1921, 'Teddy' Evans wrote in his book \"South with Scott\" that Scott had left the following written orders at Cape Evans.\n\nHe did however place a lesser importance upon this journey than that of replenishing the food rations at One Ton Depot.\n\nHe continued his instructions in the next paragraph \"You will of course understand that whilst the object of your third journey is important, that of the second is vital. At all hazards three X.S. units of provision must be got to One Ton Camp by the date named (19th January), and if the dogs are unable to perform this task, a man party must be organised.\" with that qualification he closed his notes regarding his instructions for the dogs.\n\nExpedition member Apsley Cherry-Garrard did not mention Scott's order in his 1922 book \"The Worst Journey in the World\". However, in the 1948 preface to his book, he discusses Scott's order. Cherry-Garrard writes that he and Edward Atkinson reached Cape Evans on 28 January. Scott had estimated Atkinson would reach camp by 13 January. Atkinson, now the senior officer discovered that the dog handler Cecil Meares had resigned from the expedition and that neither Meares nor anyone else had resupplied dog food to the depots. Cherry-Garrard also wrote \"In my opinion he [Atkinson] would not have been fit to take out the dogs in the first week of February\".\n\nOn 13 February, Atkinson set off on the first lap southwards to Hut Point with the dog assistant, Dimitri Gerov, and the dogs to avoid being cut off by disintegrating sea ice. Atkinson and Gerov were still at Hut Point when, on 19 February, Tom Crean arrived on foot from the Barrier and reported that Lt Edward Evans was lying seriously ill in a tent some to the south, and in urgent need of rescue. Atkinson decided that this mission was his priority, and set out with the dogs to bring Evans back. This was achieved; the party was back at Hut Point on 22 February.\n\nAtkinson sent a note back to the Cape Evans base camp requesting either the meteorologist Wright or Cherry-Garrard to take over the task of meeting Scott with the dogs. Chief meteorologist Simpson was unwilling to release Wright from his scientific work, and Atkinson therefore selected Apsley Cherry-Garrard. It was still not in Atkinson's mind that Cherry-Garrard's was a relief mission, and according to Cherry-Garrard's account, told him to \"use his judgement\" as to what to do in the event of not meeting the polar party by One Ton, and that Scott's orders were that the dogs must not be risked. Cherry-Garrard left with Gerov and the dogs on 26 February, carrying extra rations for the polar party to be added to the depot and 24 days' of dog food. They arrived at One Ton Depot on 4 March and did not proceed further south. Instead, he and Gerov, after waiting there for Scott for several days, apparently mostly in blizzard conditions (although no blizzard was recorded by Scott some 100 miles further south until 10 March), they returned to Hut Point on 16 March, in poor physical condition and without news of the polar party.\n\nOn the return journey from the pole, Scott reached the 82.30°S meeting point for the dog teams three days ahead of schedule, around 27 February 1912. Scott's diary for that day notes \"We are naturally always discussing possibility of meeting dogs, where and when, etc. It is a critical position. We may find ourselves in safety at the next depot, but there is a horrid element of doubt.\" By 10 March it became clear that the dog teams were not coming: \"The dogs which would have been our salvation have evidently failed. Meares [the dog-driver] had a bad trip home I suppose. It's a miserable jumble.\"\n\nAround 25 March, awaiting death in his tent at latitude 79.30°S, Scott speculated, in a farewell letter to his expedition treasurer Sir Edgar Speyer, that he had overshot the meeting point with the dog relief teams, writing \"We very nearly came through, and it's a pity to have missed it, but lately I have felt that we have overshot our mark. No-one is to blame and I hope no attempt will be made to suggest that we had lacked support.\" (Farewell letter to Sir Edgar Speyer, cited from Karen May 2012.)\n\n"}
{"id": "499429", "url": "https://en.wikipedia.org/wiki?curid=499429", "title": "D'Alembert's principle", "text": "D'Alembert's principle\n\nD'Alembert's principle, also known as the Lagrange–d'Alembert principle, is a statement of the fundamental classical laws of motion. It is named after its discoverer, the French physicist and mathematician Jean le Rond d'Alembert. It is the dynamic analogue to the \"principle of virtual work for applied forces\" in a static system and in fact is more general than Hamilton's principle, avoiding restriction to holonomic systems. A holonomic constraint depends only on the coordinates and time. It does not depend on the velocities. If the negative terms in accelerations are recognized as \"inertial forces\", the statement of d'Alembert's principle becomes \"The total virtual work of the impressed forces plus the inertial forces vanishes for reversible displacements\". The principle does not apply for irreversible displacements, such as sliding friction, and more general specification of the irreversibility is required.\n\nThe principle states that the sum of the differences between the forces acting on a system of mass particles and the time derivatives of the momenta of the system itself projected onto any virtual displacement consistent with the constraints of the system is zero. Thus, in symbols d'Alembert's principle is written as following,\n\nwhere :\n\nThis above equation is often called d'Alembert's principle, but it was first written in this variational form by Joseph Louis Lagrange. D'Alembert's contribution was to demonstrate that in the totality of a dynamic system the forces of constraint vanish. That is to say that the generalized forces formula_2 need not include constraint forces. It is equivalent to the somewhat more cumbersome Gauss's principle of least constraint.\n\nThe general statement of d'Alembert's principle mentions \"the time derivatives of the momenta of the system\". The momentum of the \"i\"-th mass is the product of its mass and velocity:\n\nand its time derivative is\n\nIn many applications, the masses are constant and this equation reduces to\n\nwhich appears in the formula given above. However, some applications involve changing masses (for example, chains being rolled up or being unrolled) and in those cases both terms formula_6 and formula_7 have to remain present, giving\n\nTo date, nobody has shown that D'Alembert's principle is equivalent to Newton's Second Law. D'Alembert's principle is a more general case . And it is true only for some very special cases e.g. rigid body constraints. However, an approximate solution to this problem does exist.\n\nConsider Newton's law for a system of particles, i. The total force on each particle is\n\nwhere\n\nMoving the inertial forces to the left gives an expression that can be considered to represent quasi-static equilibrium, but which is really just a small algebraic manipulation of Newton's law:\n\nConsidering the virtual work, formula_11, done by the total and inertial forces together through an arbitrary virtual displacement, formula_12, of the system leads to a zero identity, since the forces involved sum to zero for each particle.\n\nThe original vector equation could be recovered by recognizing that the work expression must hold for arbitrary displacements. Separating the total forces into applied forces, formula_14, and constraint forces, formula_15, yields\n\nIf arbitrary virtual displacements are assumed to be in directions that are orthogonal to the constraint forces (which is not usually the case, so this derivation works only for special cases), the constraint forces do no work. Such displacements are said to be \"consistent\" with the constraints. This leads to the formulation of \"d'Alembert's principle\", which states that the difference of applied forces and inertial forces for a dynamic system does no virtual work:.\n\nThere is also a corresponding principle for static systems called the principle of virtual work for applied forces.\n\nD'Alembert showed that one can transform an accelerating rigid body into an equivalent static system by adding the so-called \"inertial force\" and \"inertial torque\" or moment. The inertial force must act through the center of mass and the inertial torque can act anywhere. The system can then be analyzed exactly as a static system subjected to this \"inertial force and moment\" and the external forces. The advantage is that, in the equivalent static system one can take moments about any point (not just the center of mass). This often leads to simpler calculations because any force (in turn) can be eliminated from the moment equations by choosing the appropriate point about which to apply the moment equation (sum of moments = zero). Even in the course of Fundamentals of Dynamics and Kinematics of machines, this principle helps in analyzing the forces that act on a link of a mechanism when it is in motion. In textbooks of engineering dynamics this is sometimes referred to as \"d'Alembert's principle\".\n\nTo illustrate the concept of \"d'Alembert's principle\", let's use a simple model with a weight formula_18, suspended from a wire. The weight is subjected to a gravitational force, formula_19, and a tension force formula_20 in the wire. The mass accelerates upward with an acceleration formula_21. Newton's Second Law becomes formula_22 or formula_23. As an observer with feet planted firmly on the ground, we see that the force formula_20 accelerates the weight, formula_18, but, if we are moving with the wire we don’t see the acceleration, we feel it. The tension in the wire seems to counteract an acceleration “force” formula_26 or formula_27.\nFor a planar rigid body, moving in the plane of the body (the \"x\"–\"y\" plane), and subjected to forces and torques causing rotation only in this plane, the inertial force is\n\nwhere formula_29 is the position vector of the centre of mass of the body, and formula_30 is the mass of the body. The inertial torque (or moment) is\n\nwhere formula_32 is the moment of inertia of the body. If, in addition to the external forces and torques acting on the body, the inertia force acting through the center of mass is added and the inertial torque is added (acting around the centre of mass is as good as anywhere) the system is equivalent to one in static equilibrium. Thus the equations of static equilibrium\n\nhold. The important thing is that formula_34 is the sum of torques (or moments, including the inertial moment and the moment of the inertial force) taken about \"any\" point. The direct application of Newton's laws requires that the angular acceleration equation be applied \"only\" about the center of mass.\n\nD'Alembert's form of the principle of virtual work states that a system of rigid bodies is in dynamic equilibrium when the virtual work of the sum of the applied forces and the inertial forces is zero for any virtual displacement of the system. Thus, dynamic equilibrium of a system of n rigid bodies with m generalized coordinates requires that is to be\nfor any set of virtual displacements δq. This condition yields m equations,\nwhich can also be written as\nThe result is a set of m equations of motion that define the dynamics of the rigid body system.\n"}
{"id": "1088880", "url": "https://en.wikipedia.org/wiki?curid=1088880", "title": "Dedovshchina", "text": "Dedovshchina\n\nDedovshchina (; lit. \"reign of grandfathers\") is the informal practice of initiation (hazing) and constant bullying of junior conscripts during their service, formerly to the Soviet Armed Forces and today to the Russian armed forces, Internal Troops, and (to a much lesser extent) FSB Border Guards, as well as the military forces of certain former Soviet Republics. It consists of brutalization by more senior conscripts serving their last year of compulsory military service as well as NCOs and officers.\n\n\"Dedovshchina\" encompasses a variety of subordinating or humiliating activities undertaken by the junior ranks: from doing the chores of the senior ranks to violent and sometimes lethal physical and psychological abuse, not unlike an extremely vicious form of bullying or even torture, including sexual torture and rape (cases of forcingly stucking bottles of glass or metal objects inside of one's anus are common). When not leaving army seriously injured, conscripts can suffer serious psychopathology for their life time. It is often cited as a major source of poor morale in the ranks.\n\nOften with the justification of maintaining authority, physical violence or psychological abuse can be used to make the “youth” do certain fatiguing duties. In many situations, hazing is in fact not the goal. Conscripts with seniority exploit their juniors to provide themselves with a more comfortable existence, and the violent aspects arise when juniors refuse to \"follow traditions\". There have been occasions where soldiers have been seriously injured, or, in extraordinary situations, killed.\n\nThe term is derived from \"ded\" (, meaning grandfather), which is the Russian Army army slang equivalent of \"gramps\", meaning soldiers after their third (or fourth, which is also known as \"dembel\" ( or \"DMB\" () half-year of compulsory service, stemming from a vulgarization of the word \"demobilization\" ( \"demobilizatsiya\") - this word is erroneously used by soldiers to describe the act of resigning from the army); soldiers also refer to \"dembel\" half-year of conscription, with the suffix \"-shchina\" which denotes a type of order, rule, or regime (compare Yezhovshchina, Zhdanovshchina). Thus it can literally be translated as \"rule of the grandfathers.\" This is essentially a folk system of seniority based on stage of service, mostly not backed by code or law, which only grants seniority to conscripts promoted to various Sergeant and Efreitor ranks.\n\nThe origin of this problem is often attributed to the change in conscription term brought about by the law of October 12, 1967, causing two different groups of conscripts to be simultaneously present in the army: those who were drafted for 3-year service and those only for 2-year service. During the same year, a decision was reached to draft conscripts with a criminal history into the ranks, due to a demographic crisis following World War II. While oppression by older conscripts has probably always taken place in the army, after that date, with the introduction of the four-class system (created by the bi-annual call-ups) it became systematic and developed its own rules and ranks.\n\nMany young men are killed or commit suicide every year because of \"dedovshchina\". \"The New York Times\" reported that in 2006 at least 292 Russian soldiers were killed by \"dedovshchina\" (although the Russian military only admits that 16 soldiers were directly murdered by acts of \"dedovshchina\" and claims that the rest committed suicide). The \"Times\" states: \"On Aug. 4, it was announced by the chief military prosecutor that there had been 3,500 reports of abuse already this year (2006), compared with 2,798 in 2005\". The BBC meanwhile reports that in 2007, 341 soldiers committed suicide, a 15% reduction on the previous year.\n\nUnion of the Committees of Soldiers' Mothers of Russia works to protect the rights of young soldiers.\n\nIn 2012, a draftee from Chelyabinsk region, Ruslan Aiderkhanov, was raped and tortured to death by his seniors. The one witness who was willing to testify against the alleged perpetrators, Danil Chalkin, was later found shot dead in his military base. A contract soldier, Alikbek Musabekov, was later arrested in this incident.\n\nOverall, the state has done little to curtail \"dedovshchina\". In 2003, on the specific issues of denial of food and poor nutrition, Deputy Minister of Defense V. Isakov flatly denied the existence of such problems.\n\nSince 2005, the Ministry of Defense has published monthly statistics of incidents and crimes including cases of death.\n\nBeginning in 2007/08 the conscript service time was reduced from two years to one; dedovshchina primarily occurs when second year conscripts abuse first year conscripts, this measure is partially intended to curtail the practice.\n\nSeveral Soviet and Russian films portrayed the \"dedovshchina\" despite the military's abstention from helping the production. Following is the selected filmography:\nAlso, in the novel \"The Hunt for Red October\", Tom Clancy writes that veteran Soviet naval captain Marko Ramius refused to allow \"dedovshchina\" to be practiced anywhere on his ship, dismissing it as \"low-level terrorism\".\n\n\n"}
{"id": "252063", "url": "https://en.wikipedia.org/wiki?curid=252063", "title": "Denotation", "text": "Denotation\n\nDenotation is a translation of a sign to its meaning, precisely to its literal meaning, more or less like dictionaries try to define it. Denotation is sometimes contrasted to connotation, which includes associated meanings. The denotational meaning of a word is perceived through visible concepts, whereas connotational meaning evokes sensible attitudes towards the phenomena.\n\nIn logic, linguistics and semiotics, the denotation of a word or phrase is a part of its meaning; however, the part referred to varies by context:\n\n\n\n"}
{"id": "18004336", "url": "https://en.wikipedia.org/wiki?curid=18004336", "title": "Emanuel Rádl", "text": "Emanuel Rádl\n\nEmanuel Rádl (December 21, 1873 – May 12, 1942) was an original Czech biologist, historian of science, philosopher and a critical supporter of Masaryk´s pre-war democratic Czechoslovakia. He earned international renown by his works on the evolution of neural system and as historian of evolution theories.\n\nOne of five children of a village merchant's family in Pyšely (35 km south of Prague), Rádl studied biology at Charles University in Prague, where he became assistant professor in 1904 and full professor in 1919. He worked on the neural system of insects, on phototropism and on the evolution of sight. Influenced by the German biologist and philosopher Hans Driesch, he became interested in philosophy of life and in a large work \"The History of Biological Theories\" (in German 1905–1909, in English 1930; reprint in 1988) he criticized the evolutionism of the 19th century. At the book's climax at the end of Chapter 33, Rádl dismisses Darwinism with the words\n\nUnder the influence of Masaryk he inclined more and more towards philosophical questions, became a critic of scientific positivism and after the establishment of Czechoslovakia (1918) a public critic of several contemporary tendencies he considered dangerous. He wrote books on Czech and German nationalism, on social justice, on the fundamental differences between the West and the East and very early against the misuse of racial theories and against antisemitism. Together with the Protestant theologian J. L. Hromádka he co-founded the Czech Academic YMCA and published numerous booklets on various public topics. In 1934 he presided the 8th International Congress of Philosophy in Prague, but after 1935 he was gradually excluded from public life by a serious illness. He died in 1942 in Prague during the German occupation in almost complete isolation. His posthumous book \"Consolation from Philosophy\", in the oppressive mood of war, is a highly personal profession of faith in the lasting values of truth and religion and evoked a lively discussion after its publication in 1946.\n\n\"How to save our civilization from decay? This is the desperate question of our time, the more desperate that no one feels the danger.\"\n\nIn English:\n\nIn Czech and German:\n\n\n"}
{"id": "37300268", "url": "https://en.wikipedia.org/wiki?curid=37300268", "title": "Epigroup", "text": "Epigroup\n\nIn abstract algebra, an epigroup is a semigroup in which every element has a power that belongs to a subgroup. Formally, for all \"x\" in a semigroup \"S\", there exists a positive integer \"n\" and a subgroup \"G\" of \"S\" such that \"x\" belongs to \"G\".\n\nEpigroups are known by wide variety of other names, including quasi-periodic semigroup, group-bound semigroup, completely π-regular semigroup, strongly π-regular semigroup (sπr), or just π-regular semigroup (although the latter is ambiguous).\n\nMore generally, in an arbitrary semigroup an element is called \"group-bound\" if it has a power that belongs to a subgroup.\n\nEpigroups have applications to ring theory. Many of their properties are studied in this context.\n\nEpigroups were first studied by Douglas Munn in 1961, who called them \"pseudoinvertible\".\n\n\n\nBy analogy with periodic semigroups, an epigroup \"S\" is partitioned in classes given by its idempotents, which act as identities for each subgroup. For each idempotent \"e\" of \"S\", the set: formula_1 is called a \"unipotency class\" (whereas for periodic semigroups the usual name is torsion class.)\n\nSubsemigroups of an epigroup need not be epigroups, but if they are, then they are called subepigroups. If an epigroup \"S\" has a partition in unipotent subepigroups (i.e. each containing a single idempotent), then this partition is unique, and its components are precisely the unipotency classes defined above; such an epigroup is called \"unipotently partionable\". However, not every epigroup has this property. A simple counterexample is the Brandt semigroup with five elements \"B\" because the unipotency class of its zero element is not a subsemigroup. \"B\" is actually the quintessential epigroup which is not unipotently partionable. An epigroup is unipotently partionable iff it contains no subsemigroup that is an ideal extension of an unipotent epigroup by \"B\".\n\nSpecial classes of semigroups\n"}
{"id": "26600432", "url": "https://en.wikipedia.org/wiki?curid=26600432", "title": "Esakia duality", "text": "Esakia duality\n\nIn mathematics, Esakia duality is the dual equivalence between the category of Heyting algebras and the category of Esakia spaces. Esakia duality provides an order-topological representation of Heyting algebras via Esakia spaces.\n\nLet Esa denote the category of Esakia spaces and Esakia morphisms.\n\nLet be a Heyting algebra, denote the set of prime filters of , and denote set-theoretic inclusion on the prime filters of . Also, for each , let }, and let denote the topology on generated by }.\n\nTheorem: is an Esakia space, called the \"Esakia dual\" of . Moreover, is a Heyting algebra isomorphism from onto the Heyting algebra of all clopen up-sets of . Furthermore, each Esakia space is isomorphic in Esa to the Esakia dual of some Heyting algebra.\n\nThis representation of Heyting algebras by means of Esakia spaces is functorial and yields a dual equivalence between the category HA of Heyting algebras and Heyting algebra homomorphisms and the category Esa of Esakia spaces and Esakia morphisms.\n\nTheorem: HA is dually equivalent to Esa.\n\n"}
{"id": "49118771", "url": "https://en.wikipedia.org/wiki?curid=49118771", "title": "Escalator etiquette", "text": "Escalator etiquette\n\nEscalator etiquette is the etiquette of using escalators. In many places, there is a convention that people should stand on one particular side of an escalator to allow other people to walk on the other side.\n\nA 2015 experiment by Transport for London has suggested that such a convention sometimes reduces the efficiency of escalators: the number of people carried can increase if people stand on both sides.\n\nThe first escalators installed in the London Underground at Earl's Court station used the design patented by Charles Seeberger. These did not let the passengers dismount in the direction of travel, as currently. Instead, a diagonal partition shunted them off to one side while the stairs disappeared under the partition. The side chosen for disembarkation was the left hand side and this is the origin of their convention that riders should stand on the right, so that the walking riders would not have to cut into a standing line of people to exit. Locations such as Hong Kong and Belgium also follow this convention.\n\nHowever certain countries, for instance Australia, Singapore, most of Japan, and New Zealand, riders stand on the left and walk on the right, following the road rules.\n\n"}
{"id": "340094", "url": "https://en.wikipedia.org/wiki?curid=340094", "title": "Estimated time of arrival", "text": "Estimated time of arrival\n\nThe estimated time of arrival (ETA) is the time when a ship, vehicle, aircraft, cargo, emergency service or person is expected to arrive at a certain place.\n\nOne of the more common uses of the phrase is in public transportation where the movements of trains, buses, airplanes and the like can be used to generate estimated times of arrival depending on either a static timetable or through measurements on traffic intensity. In this respect, the phrase or its abbreviation is often paired with its complement, estimated time of departure (ETD), to indicate the expected start time of a particular journey. This information is often conveyed to a passenger information system as part of the core functionality of intelligent transportation systems.\n\nFor example, a certain flight may have a calculated ETA based on the speed by which it has covered the distance traveled so far. The remaining distance is divided by the speed previously measured to roughly estimate the arrival time. This particular method does not take into account any unexpected events (such as new wind directions) which may occur on the way to the flight's destination.\n\nETA is also used metaphorically in situations where nothing actually moves physically, as in describing the time estimated for a certain task to complete (e.g. work undertaken by an individual; a computation undertaken by a computer program; or a process undertaken by an organization). The associated term is \"estimated time of accomplishment\", which may be a backronym.\n\nAccurate and timely estimations of times of arrival are important in several application areas:\n"}
{"id": "523076", "url": "https://en.wikipedia.org/wiki?curid=523076", "title": "Excitable medium", "text": "Excitable medium\n\nAn excitable medium is a nonlinear dynamical system which has the capacity to propagate a wave of some description, and which cannot support the passing of another wave until a certain amount of time has passed (known as the refractory time).\n\nA forest is an example of an excitable medium: if a wildfire burns through the forest, no fire can return to a burnt spot until the vegetation has gone through its refractory period and regrown. In chemistry, oscillating reactions are excitable media, for example the Belousov–Zhabotinsky reaction and the Briggs–Rauscher reaction. Pathological activities in the heart and brain can be modelled as excitable media. A group of spectators at a sporting event are an excitable medium, as can be observed in a Mexican wave (so-called from its initial appearance in the 1986 World Cup in Mexico).\n\nExcitable media can be modelled using both partial differential equations and cellular automata.\n\nCellular automata provide a simple model to aid in the understanding of excitable media. Perhaps the simplest such model is in. See Greenberg-Hastings cellular automaton for this model. \nEach cell of the automaton is made to represent some section of the medium being modelled (for example, a patch of trees in a forest, or a segment of heart tissue). Each cell can be in one of the three following states:\n\n\nAs in all cellular automata, the state of a particular cell in the next time step depends on the state of the cells around it—its neighbours—at the current time. In the forest fire example the simple rules given in Greenberg-Hastings cellular automaton might be modified as follows:\n\n\nThis function can be refined according to the particular medium. For example, the effect of wind can be added to the model of the forest fire.\n\nIt is most common for a one-dimensional medium to form a closed circuit, i.e. a ring. For example, the Mexican wave can be modeled as a ring going around the stadium. If the wave moves in one direction it will eventually return to where it started. If, upon a wave's return to the origin, the original spot has gone through its refractory period, then the wave will propagate along the ring again (and will do so indefinitely). If, however, the origin is still refractory upon the wave's return, the wave will be stopped.\n\nIn the Mexican wave, for example, if for some reason, the originators of the wave are still standing upon its return it will not continue. If the originators have sat back down then the wave can, in theory, continue.\n\nSeveral forms of waves can be observed in a two-dimensional medium.\n\nA \"spreading wave\" will originate at a single point in the medium and spread outwards. For example, a forest fire could start from a lightning strike at the centre of a forest and spread outwards.\n\nA \"spiral wave\" will again originate at a single point, but will spread in a spiral circuit. Spiral waves are believed to underlie phenomena such as tachycardia and fibrillation.\n\nSpiral waves constitute one of the mechanisms of fibrillation when they organize in long-lasting reentrant activities named rotors.\n\n\n"}
{"id": "185990", "url": "https://en.wikipedia.org/wiki?curid=185990", "title": "Felicific calculus", "text": "Felicific calculus\n\nThe felicific calculus is an algorithm formulated by utilitarian philosopher Jeremy Bentham (1748–1832) for calculating the degree or amount of pleasure that a specific action is likely to cause. Bentham, an ethical hedonist, believed the moral rightness or wrongness of an action to be a function of the amount of pleasure or pain that it produced. The felicific calculus could, in principle at least, determine the moral status of any considered act. The algorithm is also known as the utility calculus, the hedonistic calculus and the hedonic calculus.\n\nTo be included in this calculation are several variables (or vectors), which Bentham called \"circumstances\". These are:\n\nTo take an exact account of the general tendency of any act, by which the interests of a community are affected, proceed as follows. Begin with any one person of those whose interests seem most immediately to be affected by it: and take an account,\n\nTo make his proposal easier to remember, Bentham devised what he called a \"mnemonic doggerel\" (also referred to as \"memoriter verses\"), which synthesized \"the whole fabric of morals and legislation\":\n\nIntense, long, certain, speedy, fruitful, pure—<br>\nSuch marks in pleasures and in pains endure.<br>\nSuch pleasures seek if private be thy end:<br>\nIf it be public, wide let them extend<br>\nSuch pains avoid, whichever be thy view:<br>\nIf pains must come, let them extend to few. \n\nThe units of measurements used in the felicific calculus may be termed \"hedons\" and \"dolors\". They may be regarded as similar to the utilitarian posends and negends.\n\n"}
{"id": "44664482", "url": "https://en.wikipedia.org/wiki?curid=44664482", "title": "Flood Brothers Disposal", "text": "Flood Brothers Disposal\n\nFlood Brothers Disposal is a family-owned waste management and recycling service based in Oakbrook Terrace, IL with offices in Chicago, IL. Flood Brothers Disposal's service area extends to 150 or more communities in the Chicago area. The business is a member of the National Solid Waste Management Association, the Solid Waste Agency of Northern Cook County, the National Recycling Coalition, the Illinois Food Scrap Coalition, the National Waste & Recycling Association, and the Illinois Recycling Association.\n\nFlood Brothers Disposal started operations with one truck and one employee, at 139 N. Clark St. in Chicago, Illinois. In 1963, the main center of operations moved to 5435 W. Chicago Ave. From 1970 to 1977, the company continued expansion and moved to several additional locations, eventually settling at 4827 W. Harrison St. in Chicago, where the company is presently based.\n\nIn 1988, the company expanded to include a fully automated recycling center, and in 1990, became the first licensed special waste hauler in the Chicago community. In 1996, Flood Brothers Disposal opened an additional facility in Carol Stream, Illinois. As of today, Flood Brothers Disposal services more than 150 communities in the Chicago area.\n\nFlood Brothers Disposal provides service in 150 communities in the Chicago area as of present day\n\nIn 2015, Flood Brothers Disposal was named \"2015 Illinois Medium Family Business of the Year\" by Loyola University's Quinlan School of Business.\n"}
{"id": "5454990", "url": "https://en.wikipedia.org/wiki?curid=5454990", "title": "Friendship bracelet", "text": "Friendship bracelet\n\nA friendship bracelet is a decorative bracelet given by one person to another as a symbol of friendship. Friendship bracelets are often handmade, usually of embroidery floss or thread and are a type of macrame. There are various styles and patterns, but most are based on the same simple half-hitch knot.\n\nThe amount of thread used in bracelets varies depending on the pattern. The smallest pattern, a double chain knot, requires two strings while the candy stripe can have as 3 or more strings depending on the desired thickness.\n\nFriendship bracelets first became popular in the United States during the 1970s. As they are unisex, they are commonly worn by both male and female teenagers and children. They are now popular throughout the world and are not only popular among teenagers but among the older generation; they are popular among celebrities as well. Friendship bracelets can be worn on various occasions; for example, they are ideal as a fashion accessory at the beach because they are made of materials that will not be easily destroyed and with which one can swim freely.\n\nFriendship bracelets are ancient, but their resurgence is modern. The modern popularity of friendship bracelets started in the 1980s when they were seen during protests about the disappearances of Mayan Indians and peasants in Guatemala. The friendship bracelets were brought into the United States by religious groups for use in political rallies. \n\nFriendship bracelets can have many meanings and symbolic uses, such as friendship, folk art, or social statements. Although it is generally accepted that the origins of these colorful bands lie with the Indians in Central and South America, some decorative knots can be traced back to China from 481 to 221 B.C. According to tradition, one ties a bracelet onto the wrist of a friend as a symbol of friendship and may wish for something at that moment. The bracelet should be worn until it is totally worn out and falls off by itself to honour the hard work and love put into making it. The moment at which the band falls off on its own, the wish is supposed to come true.\n\nMisanga is an international good luck charm made from knotted embroidery floss, thread or gimp. Similar to friendship bracelets, it is made with basic knots as well as patterning techniques. Its basic structure is a three thread plaited braid. It is becoming a popular portable craft project.\n\nPattern names vary slightly depending on location, but are overall similar.\n\n\n"}
{"id": "54804458", "url": "https://en.wikipedia.org/wiki?curid=54804458", "title": "Gjirokastër alphabet", "text": "Gjirokastër alphabet\n\nThe Gjirokastër alphabet also known as Veso Bey alphabet is one of the original Albanian language alphabets of the 19th century. It is named after the town of Gjirokastër in South Albania where it was first encountered by the scholar Johann Georg von Hahn, also after Veso bey, a rich local bey from the influential Alizoti family who provided it to Hahn. Hahn published in 1854 in his \"Albanesische Studien\", in Jena.\n\nAccording to Hahn, the alphabet was given to him by Veso bey, and had been used that far within Alizoti family circles.\nThe alphabet, probably cryptic, contains 22 letters.\n\n"}
{"id": "177793", "url": "https://en.wikipedia.org/wiki?curid=177793", "title": "Great chain of being", "text": "Great chain of being\n\nThe Great Chain of Being is a strict hierarchical structure of all matter and life, thought in medieval Christianity to have been decreed by God. The chain starts with God and progresses downward to angels, demons (fallen/renegade angels), stars, moon, kings, princes, nobles, commoners, wild animals, domesticated animals, trees, other plants, precious stones, precious metals and other minerals.\n\nThe Great Chain of Being (, \"Ladder of Being\") is a concept derived from Plato, Aristotle (in his \"Historia Animalium\"), Plotinus and Proclus. Further developed during the Middle Ages, it reached full expression in early modern Neoplatonism.\n\nThe Chain of Being is composed of a great number of hierarchical links, from the most basic and foundational elements up through the very highest perfection: God.\n\nGod sits at the top of the chain, and beneath him sit the angels, both existing wholly in \"spirit\" form. Earthly flesh is fallible and ever-changing, mutable. Spirit, however, is unchanging and permanent. This sense of permanence is crucial to understanding this conception of reality. It is generally impossible to change the position of an object in the hierarchy. (One exception might be in the realm of alchemy, where alchemists attempted to transmute base elements, such as lead, into higher elements, either silver or, more often, gold—the highest \"element\".)\n\nIn the natural order, earth (rock) is at the bottom of the chain; this element possesses only the attribute of existence. Each link succeeding upward contains the positive attributes of the previous link and adds at least one other. Rocks possess only existence; the next link up is plants which possess life \"and\" existence. Animals add motion and appetite as well.\n\nMan is both mortal flesh, as those below him, and also spirit, as those above. In this dichotomy, the struggle between flesh and spirit becomes a moral one. The way of the spirit is higher, more noble; it brings one closer to God. The desires of the flesh move one away from God. The Christian fall of Lucifer is thought of as especially terrible, as angels are wholly spirit, yet Lucifer defied God (who is the ultimate perfection).\n\nEach link in the chain might be divided further into its component parts. In medieval secular society, for example, the king is at the top, succeeded by the aristocratic lords and the clergy, and then the peasants below them. Solidifying the king's position at the top of humanity's social order is the doctrine of the Divine Right of Kings. The implied permanent state of inequality became a source of popular grievance, and led eventually to political change as in the French Revolution. In the family, the father is head of the household; below him, his wife; below her, their children.\n\nMilton's \"Paradise Lost\" ranked the angels (c.f. Pseudo-Dionysius the Areopagite's ranking of angels), and Christian culture conceives of angels in orders of archangels, seraphim, and cherubim, among others.\n\nSubdivisions are equally apparent among animals. At the top of the animals are wild beasts (such as lions), which were seen as superior as they defied training and domestication. Below them are domestic animals, further sub-divided so that useful animals (such as dogs and horses) are higher than docile creatures (such as sheep). Birds are also sub-divided, with eagles above pigeons, for example. Fish come below birds and are subdivided between actual fish and other sea creatures. Below them come insects, with useful insects such as spiders and bees and attractive creatures such as ladybirds and dragonflies at the top, and unpleasant insects such as flies and beetles at the bottom. At the very bottom of the animal sector are snakes, which are relegated to this position as punishment for the serpent's actions in the Garden of Eden.\n\nBelow animals comes the division for plants, which is further subdivided. Trees are at the top, with useful trees such as oaks at the top, and the traditionally demonic yew tree at the bottom. Food-producing plants such as cereals and vegetables are further subdivided.\n\nAt the very bottom of the chain are minerals. At the top of this section are metals (further sub-divided, with gold at the top and lead at the bottom), followed by rocks (with granite and marble at the top), soil (subdivided between nutrient-rich soil and low-quality types), sand, grit, dust, and dirt at the very bottom of the entire great chain.\n\nThe central concept of the Chain of Being is that everything imaginable fits in somewhere, giving order and meaning to the universe.\n\nGod is at the top of the chain and is also external to creation. God is believed to exist outside the physical limitations of time and space. He possessed the spiritual attributes of reason, love, and imagination, like all spiritual beings, but he alone possessed the divine attributes of omnipotence, omniscience, and omnipresence. God serves as the model of authority for the strongest, most virtuous, most excellent type of being within any category.\n\nAngels were beings of pure spirit who had no physical bodies of their own. In order to affect the physical world, angels were thought to build temporary bodies for themselves out of particles of earthly elements. Medieval and Renaissance theologians believed angels to possess reason, love, imagination, and, like God, to stand outside the physical limitations of time. They possessed sensory awareness unbound by physical organs, and they possessed language. They lacked, however, the divine attributes of omnipotence, omniscience, and omnipresence of God, and they simultaneously lacked the physical passions experienced by humans and animals. Depending upon the author, the class of angels was further subdivided into three, seven, nine, or ten ranks, variously known as triads, orders, or choirs. Each rank had greater power and responsibility than the entities below them. The most common classification is that of St. Thomas Aquinas. \n\n\nFor Medieval and Renaissance thinkers, humans occupied a unique position on the Chain of Being, straddling the world of spiritual beings and the world of physical creation. Humans were thought to possess divine powers such as reason, love, and imagination. Like angels, humans were spiritual beings, but unlike angels, human souls were \"knotted\" to a physical body. As such, they were subject to passions and physical sensations—pain, hunger, thirst, sexual desire—just like other animals lower on the Chain of Being. They also possessed the powers of reproduction unlike the minerals and rocks lowest on the Chain of Being. Humans had a particularly difficult position, balancing the divine and the animalistic parts of their nature. For instance, an angel is only capable of intellectual sin such as pride (as evidenced by Lucifer's fall from heaven in Christian belief). Humans, however, were capable of both intellectual sin and physical sins such as lust and gluttony if they let their animal appetites overrule their divine reason. Humans also possessed sensory attributes: sight, touch, taste, hearing, and smell. Unlike angels, however, their sensory attributes were limited by physical organs (they could only know things discerned through the five senses). The highest-ranking human being was the king.\n\nAnimals, like humans higher on the chain, were animated (capable of independent motion). They possessed physical appetites and sensory attributes, the number depending upon their position within the Chain of Being. They had limited intelligence and awareness of their surroundings. Unlike humans, they were thought to lack spiritual and mental attributes such as immortal souls and the ability to use logic and language. The primate of all animals (the \"king of beasts\") was variously thought to be either the lion or the elephant. However, each subgroup of animals also had its own primate, an avatar superior in qualities of its type.\n\n\nNote that avian creatures, linked to the element of air, were considered superior to aquatic creatures linked to the element of water. Air naturally tended to rise and soar above the surface of water, and analogously, aerial creatures were placed higher in the chain.\n\n\nThe chart would continue to descend through various reptiles, amphibians, and insects. The higher up the chart one went, the more noble, mobile, strong, and intelligent the creature in Renaissance belief. At the very bottom of the animal section, we find sessile creatures like the oysters, clams, and barnacles. Like the plants below them, these creatures lacked mobility, and were thought to lack various sensory organs such as sight and hearing. However, they were still considered superior to plants because they had tactile and gustatory senses (touch and taste).\n\nPlants, like other living creatures, possessed the ability to grow in size and reproduce. However, they lacked mental attributes and possessed no sensory organs. Instead, their gifts included the ability to eat soil, air, and \"heat.\" Plants did have greater tolerances for heat and cold, and immunity to the pain that afflicts most animals. At the very bottom of the botanical hierarchy, fungi and mosses, lacking leaf and blossom, were so limited in form that Renaissance thinkers thought them scarcely above the level of minerals. However, each plant was also thought to be gifted with various edible or medicinal virtues unique to its own type.\n\n\nCreations of the earth, the lowest of elements, all minerals lacked the plant's basic ability to grow and reproduce. They also lacked mental attributes and sensory organs found in beings higher on the chain. Their unique gifts, however, were typically their unusual solidity and strength. Many minerals, in fact, were thought to possess magical powers, particularly gems. The mineral primate is the diamond.\n\n\nThe basic idea of a ranking of the world's organisms goes back to Aristotle's biology. In his \"History of Animals\", where he ranked animals over plants based on their ability to move and sense, and graded the animals by their reproductive mode and possession of blood (he ranked all invertebrates as \"bloodless\").\n\nAristotle's non-religious concept of higher and lower organisms was taken up by natural philosophers during the Scholastic period to form the basis of the \"Scala Naturae\". The \"scala\" allowed for an ordering of beings, thus forming a basis for classification where each kind of mineral, plant and animal could be slotted into place. In medieval times, the great chain was seen as a God-given ordering: God at the top, dirt at the bottom, every grade of creature in its place. Just as rock never turns to flowers and worms never turn to lions, humans never turn to angels. This was not our lot in life. In the Northern Renaissance, the scientific focus shifted to biology. The threefold division of the chain below humans formed the basis for Linnaeus's \"Systema Naturæ\" from 1737, where he divided the physical components of the world into the three familiar kingdoms of minerals, plants and animals.\n\nThe set nature of species, and thus the absoluteness of creatures' places in the great chain, came into question during the 18th century. The dual nature of the chain, divided yet united, had always allowed for seeing creation as essentially one continuous whole, with the potential for overlap between the links. Radical thinkers like Jean-Baptiste Lamarck saw a progression of life forms from the simplest creatures striving towards complexity and perfection, a schema accepted by zoologists like Henri de Blainville. The very idea of an ordering of organisms, even if supposedly fixed, laid the basis for the idea of transmutation of species, for example Charles Darwin's theory of evolution.\n\nThe Chain of Being continued to be part of metaphysics in 19th century education, and the concept was well known. The geologist Charles Lyell used it as a metaphor in his 1851 \"Elements of Geology\" description of the geological column, where he used the term \"missing links\" in relation to missing parts of the continuum. The term \"missing link\" later came to signify transitional fossils, particularly those bridging the gulf between man and beasts.\n\nThe idea of the great chain as well as the derived \"missing link\" was abandoned in early 20th century science, as the notion of modern animals representing ancestors of other modern animals was abandoned in biology. The idea of a certain sequence from \"lower\" to \"higher\" however lingers on, as does the idea of progress in biology.\n\nAllenby and Garreau propose the Catholic Church's narrative of the Great Chain of Being kept the peace for centuries in Europe. The very concept of rebellion simply lay outside the reality within which most people lived for to defy the King was to defy God. King James I himself wrote, \"The state of monarchy is the most supreme thing upon earth: for kings are not only God's Lieutenants upon earth, and sit upon God's throne, but even by God himself they are called Gods.\"\n\nThe Enlightenment broke this supposed divine plan and fought the last vestiges of feudal hierarchy by creating secular governmental structures that vested power into the hands of ordinary citizens rather than divinely ordained monarchs.\n\nHowever, scholars such as Brian Tierney and Michael Novak have noted the medieval contribution to democracy and human rights.\n\nThe American spiritual writer and philosopher Ken Wilber uses a concept called the \"Great Nest of Being\" which is similar to the Great Chain of Being, and which he claims to belong to a culture-independent \"perennial philosophy\" traceable across 3000 years of mystical and esoteric writings. Wilber's system corresponds with other concepts of transpersonal psychology.\n\nIn the 1977 book \"A Guide for the Perplexed\", British philosopher and economist E. F. Schumacher wrote that fundamental gaps exist between the existence of minerals, plants, animals and humans, where each of the four classes of existence is marked by a level of existence not shared by that below. Clearly influenced by the great chain of being, but lacking the angels and God, he called his hierarchy the \"levels of being\". In the book, he claims that science has generally avoided seriously discussing these discontinuities, because they present such difficulties for strictly materialistic science, and they largely remain mysteries.\n\n"}
{"id": "21304243", "url": "https://en.wikipedia.org/wiki?curid=21304243", "title": "Hanged, drawn and quartered", "text": "Hanged, drawn and quartered\n\nTo be hanged, drawn and quartered was from 1352 a statutory penalty in England for men convicted of high treason, although the ritual was first recorded during the reign of King Henry III (1216–1272). A convicted traitor was fastened to a hurdle, or wooden panel, and drawn by horse to the place of execution, where he was then hanged (almost to the point of death), emasculated, disembowelled, beheaded, and quartered (chopped into four pieces). The traitor's remains were often displayed in prominent places across the country, such as London Bridge. For reasons of public decency, women convicted of high treason were instead burned at the stake.\n\nThe severity of the sentence was measured against the seriousness of the crime. As an attack on the monarch's authority, high treason was considered a deplorable act demanding the most extreme form of punishment. Although some convicts had their sentences modified and suffered a less ignominious end, over a period of several hundred years many men found guilty of high treason were subjected to the law's ultimate sanction. They included many English Catholic priests executed during the Elizabethan era, and several of the regicides involved in the 1649 execution of Charles I.\n\nAlthough the Act of Parliament defining high treason remains on the United Kingdom's statute books, during a long period of 19th-century legal reform the sentence of hanging, drawing, and quartering was changed to drawing, hanging until dead, and posthumous beheading and quartering, before being abolished in England in 1870. The death penalty for treason was abolished in 1998.\n\nDuring the High Middle Ages those in England guilty of treason were punished in a variety of ways, including drawing and hanging. In the 13th century other, more brutal penalties were introduced, such as disembowelling, burning, beheading and quartering. The 13th-century English chronicler Matthew Paris described how in 1238 \"a certain man at arms, a man of some education (\"armiger literatus\")\" attempted to kill King Henry III. His account records in gruesome detail how the would-be assassin was executed: \"dragged asunder, then beheaded, and his body divided into three parts; each part was then dragged through one of the principal cities of England, and was afterwards hung on a gibbet used for robbers.\" He was apparently sent by William de Marisco, an outlaw who some years earlier had killed a man under royal protection before fleeing to Lundy Island. De Marisco was captured in 1242 and on Henry's order dragged from Westminster to the Tower of London to be executed. There he was hanged from a gibbet until dead. His corpse was disembowelled, his entrails burned, his body quartered and the parts distributed to cities across the country. The punishment is more frequently recorded during Edward I's reign. Welshman Dafydd ap Gruffydd became the first nobleman in England to be hanged, drawn, and quartered after he turned against the king and proclaimed himself Prince of Wales and Lord of Snowdon. Dafydd's rebellion infuriated Edward so much that he demanded a novel punishment. Therefore, following his capture and trial in 1283, for his betrayal he was drawn by horse to his place of execution. For killing English nobles he was hanged alive. For killing those nobles at Easter he was eviscerated and his entrails burned. For conspiring to kill the king in various parts of the realm, his body was quartered and the parts sent across the country; his head was placed on top of the Tower of London. A similar fate was suffered by the Scottish leader Sir William Wallace. Captured and tried in 1305, he was forced to wear a crown of laurel leaves and was drawn to Smithfield, where he was hanged and beheaded. His entrails were then burned and his corpse quartered. His head was set on London Bridge and the quarters sent to Newcastle, Berwick, Stirling, and Perth.\nThese and other executions, such as those of Andrew Harclay, 1st Earl of Carlisle, and Hugh Despenser the Younger, which each occurred during King Edward II's reign, happened when acts of treason in England, and their punishments, were not clearly defined in common law. Treason was based on an allegiance to the sovereign from all subjects aged 14 or over and it remained for the king and his judges to determine whether that allegiance had been broken. Edward III's justices had offered somewhat over-zealous interpretations of what activities constituted treason, \"calling felonies treasons and afforcing indictments by talk of accroachment of the royal power\", prompting parliamentary demands to clarify the law. Edward therefore introduced the Treason Act 1351. It was enacted at a time in English history when a monarch's right to rule was indisputable and was therefore written principally to protect the throne and sovereign. The new law offered a narrower definition of treason than had existed before and split the old feudal offence into two classes. Petty treason referred to the killing of a master (or lord) by his servant, a husband by his wife, or a prelate by his clergyman. Men guilty of petty treason were drawn and hanged, whereas women were burned.\n\nHigh treason was the most egregious offence an individual could commit. Attempts to undermine the king's authority were viewed with as much seriousness as if the accused had attacked him personally, which itself would be an assault on his status as sovereign and a direct threat to his right to govern. As this might undermine the state, retribution was considered an absolute necessity and the crime deserving of the ultimate punishment. The practical difference between the two offences therefore was in the consequence of being convicted; rather than being drawn and hanged, men were to be hanged, drawn, and quartered, while for reasons of public decency (their anatomy being considered inappropriate for the sentence), women were instead drawn and burned. The Act declared that a person had committed high treason if they were: compassing or imagining the death of the king, his wife or his eldest son and heir; violating the king's wife, his eldest daughter if she were unmarried, or the wife of his eldest son and heir; levying war against the king in his realm; adhering to the king's enemies in his realm, giving them aid and comfort in his realm or elsewhere; counterfeiting the Great Seal or the Privy Seal, or the king's coinage; knowingly importing counterfeit money; killing the Chancellor, Treasurer or one of the king's Justices while performing their offices. The Act did not limit the king's authority in defining the scope of treason. It contained a proviso giving English judges discretion to extend that scope whenever required, a process more commonly known as constructive treason. It also applied to subjects overseas in British colonies in the Americas, but the only documented incident of an individual there being hanged, drawn, and quartered was that of Joshua Tefft, an English colonist accused of having fought on the side of the Narragansett during the Great Swamp Fight. He was executed in January 1676. Later sentences resulted either in a pardon or a hanging.\n\nOnly one witness was required to convict a person of treason, although in 1547 this was increased to two. Suspects were first questioned in private by the Privy Council before they were publicly tried. They were allowed no witnesses or defence counsel, and were generally presumed guilty from the outset. This meant that for centuries anyone accused of treason was severely legally disadvantaged, a situation which lasted until the late 17th century, when several years of politically motivated treason charges made against Whig politicians prompted the introduction of the Treason Act 1695. This allowed a defendant counsel, witnesses, a copy of the indictment, and a jury, and when not charged with an attempt on the monarch's life, to be prosecuted within three years of the alleged offence.\n\nEdward Stafford, 3rd Duke of Buckingham was executed on 17 May 1521 for the crime of treason. The wording of his sentence has survived and indicates the precision with which the method of execution was described; he was to be \"laid on a hurdle and so drawn to the place of execution, and there to be hanged, cut down alive, your members to be cut off and cast in the fire, your bowels burnt before you, your head smitten off, and your body quartered and divided at the King's will, and God have mercy on your soul.\"\n\nOnce sentenced, malefactors were usually held in prison for a few days before being taken to the place of execution. During the early Middle Ages this journey may have been made tied directly to the back of a horse, but it subsequently became customary for the victim to be fastened instead to a wicker hurdle, or wooden panel, itself tied to the horse. Historian Frederic William Maitland thought that this was probably to \"[secure] for the hangman a yet living body\". The use of the word drawn, as in \"to draw\", has caused a degree of confusion. One of the \"Oxford English Dictionary's\" definitions of draw is \"to draw out the viscera or intestines of; to disembowel (a fowl, etc. before cooking, a traitor or other criminal after hanging)\", but this is followed by \"in many cases of executions it is uncertain whether this, or [to drag (a criminal) at a horse's tail, or on a hurdle or the like, to the place of execution; formerly a legal punishment of high treason], is meant. The presumption is that where \"drawn\" is mentioned after \"hanged\", the sense is as here.\" Historian Ram Sharan Sharma arrived at the same conclusion: \"Where, as in the popular \"hung, drawn and quartered\" [use] (meaning facetiously, of a person, completely disposed of), \"drawn\" follows \"hanged\" or \"hung\", it is to be referred to as the disembowelling of the traitor.\" The historian and author Ian Mortimer disagrees. In an essay published on his website, he writes that the separate mention of evisceration is a relatively modern device, and that while it certainly took place on many occasions, the presumption that \"drawing\" means to disembowel is spurious. Instead, drawing (as a method of transportation) may be mentioned after hanging because it was a supplementary part of the execution.\n\nSome reports indicate that during Queen Mary I's reign bystanders were vocal in their support: while in transit convicts sometimes suffered directly at the hands of the crowd. William Wallace was whipped, attacked and had rotten food and waste thrown at him, and the priest Thomas Pilchard was reportedly barely alive by the time he reached the gallows in 1587. Others found themselves admonished by \"zealous and godly men\"; it became customary for a preacher to follow the condemned, asking them to repent. According to Samuel Clarke, the Puritan clergyman William Perkins (1558–1602) once managed to convince a young man at the gallows that he had been forgiven, enabling the youth to go to his death \"with tears of joy in his eyes ... as if he actually saw himself delivered from the hell which he feared before, and heaven opened for receiving his soul.\"\n\nAfter the king's commission had been read aloud, the crowd was normally asked to move back from the scaffold before being addressed by the convict. While these speeches were mostly an admission of guilt (although few admitted treason), still they were carefully monitored by the sheriff and chaplain, who were occasionally forced to act; in 1588, Catholic priest William Dean's address to the crowd was considered so inappropriate that he was gagged almost to the point of suffocation. Questions on matters of allegiance and politics were sometimes put to the prisoner, as happened to Edmund Gennings in 1591. He was asked by priest hunter Richard Topcliffe to \"confess his treason\", but when Gennings responded \"if to say Mass be treason, I confess to have done it and glory in it\", Topcliffe ordered him to be quiet and instructed the hangman to push him off the ladder. Sometimes the witness responsible for the condemned man's execution was also present. A government spy, John Munday, was in 1582 present for the execution of Thomas Ford. Munday supported the sheriff, who had reminded the priest of his confession when he protested his innocence. The sentiments expressed in such speeches may be related to the conditions encountered during imprisonment. Many Jesuit priests suffered badly at the hands of their captors but were frequently the most defiant; conversely, those of a higher station were often the most apologetic. Such contrition may have arisen from the sheer terror felt by those who thought they might be disembowelled rather than simply beheaded as they would normally expect, and any apparent acceptance of their fate may have stemmed from the belief that a serious, but not treasonable act, had been committed. Good behaviour at the gallows may also have been due to a convict's desire for his heirs not to be disinherited.\n\nThe condemned were occasionally forced to watch as other traitors, sometimes their confederates, were executed before them. The priest James Bell was in 1584 made to watch as his companion, John Finch, was \"a-quarter-inge\". Edward James and Francis Edwardes were made to witness Ralph Crockett's execution in 1588, in an effort to elicit their co-operation and acceptance of Elizabeth I's religious supremacy before they were themselves executed. Normally stripped to the shirt with their arms bound in front of them, prisoners were then hanged for a short period, either from a ladder or cart. On the sheriff's orders the cart would be taken away (or if a ladder, turned), leaving the man suspended in mid-air. The aim was usually to cause strangulation and near-death, although some victims were killed prematurely, the priest John Payne's death in 1582 being hastened by a group of men pulling on his legs. Conversely, some, such as the deeply unpopular William Hacket (d. 1591), were cut down instantly and taken to be disembowelled and normally emasculated—the latter, according to Sir Edward Coke, to \"show his issue was disinherited with corruption of blood.\".\nA victim still conscious at that point might have seen his entrails burned, before his heart was removed and the body decapitated and quartered (chopped into four pieces). The regicide Major-General Thomas Harrison, after being hanged for several minutes and then cut open in October 1660, was reported to have leaned across and hit his executioner—resulting in the swift removal of his head. His entrails were thrown onto a nearby fire. John Houghton was reported to have prayed while being disembowelled in 1535, and in his final moments to have cried \"Good Jesu, what will you do with my heart?\" Executioners were often inexperienced and proceedings did not always run smoothly. In 1584 Richard White's executioner removed his bowels piece by piece, through a small hole in his belly, \"the which device taking no good success, he mangled his breast with a butcher's axe to the very chine most pitifully.\" At his execution in January 1606 for his involvement in the Gunpowder Plot, Guy Fawkes managed to break his neck by jumping from the gallows, cheating the executioner.\nNo records exist to demonstrate exactly how the corpse was quartered, although an engraving of the quartering of Sir Thomas Armstrong in 1684 shows the executioner making vertical cuts through the spine and removing the legs at the hip. The distribution of Dafydd ap Gruffydd's remains was described by Herbert Maxwell: \"the right arm with a ring on the finger in York; the left arm in Bristol; the right leg and hip at Northampton; the left [leg] at Hereford. But the villain's head was bound with iron, lest it should fall to pieces from putrefaction, and set conspicuously upon a long spear-shaft for the mockery of London.\" After the execution in 1660 of several of the regicides involved in the death of King Charles I eleven years earlier, the diarist John Evelyn remarked: \"I saw not their execution, but met their quarters, mangled, and cut, and reeking, as they were brought from the gallows in baskets on the hurdle.\" Such remains were typically parboiled and displayed as a gruesome reminder of the penalty for high treason, usually wherever the traitor had conspired or found support. Salt and cumin seed would be added during the boiling process: the salt to prevent putrefaction, and the cumin seed to prevent birds pecking at the flesh.\n\nThe head was often displayed on London Bridge, for centuries the route by which many travellers from the south entered the city. Several eminent commentators remarked on the displays. In 1566 Joseph Justus Scaliger wrote that \"in London there were many heads on the bridge ... I have seen there, as if they were masts of ships, and at the top of them, quarters of men's corpses.\" In 1602 the Duke of Pommerania-Stettin emphasised the ominous nature of their presence when he wrote \"near the end of the bridge, on the suburb side, were stuck up the heads of thirty gentlemen of high standing who had been beheaded on account of treason and secret practices against the Queen.\" The practice of using London Bridge in this manner ended following the hanging, drawing, and quartering in 1678 of William Staley, a victim of the fictitious Popish Plot. His quarters were given to his relatives, who promptly arranged a \"grand\" funeral; this incensed the coroner so much that he ordered the body to be dug up and set upon the city gates. Staley's was the last head to be placed on London Bridge.\n\nAnother victim of the Popish Plot, Oliver Plunkett the Archbishop of Armagh, was hanged, drawn, and quartered at Tyburn in July 1681. His executioner was bribed so that Plunket's body parts were saved from the fire; the head is now displayed at St Peter's Church in Drogheda. Francis Towneley and several other captured Jacobite officers involved in the Jacobite Rising of 1745 were executed, but by then the executioner possessed some discretion as to how much they should suffer and thus they were killed before their bodies were eviscerated. The French spy François Henri de la Motte was hanged in 1781 for almost an hour before his heart was cut out and burned, and the following year David Tyrie was hanged, decapitated, and then quartered at Portsmouth. Pieces of his corpse were fought over by members of the 20,000-strong crowd there, some making trophies of his limbs and fingers. In 1803 Edward Despard and six co-conspirators in the Despard Plot were sentenced to be hanged, drawn, and quartered. Before they were hanged and beheaded at Horsemonger Lane Gaol, they were first placed on sledges attached to horses, and ritually pulled in circuits around the gaol yards. Their execution was attended by an audience of about 20,000. A contemporary report describes the scene after Despard had made his speech:\n\nAt the burnings of Isabella Condon in 1779 and Phoebe Harris in 1786, the sheriffs present inflated their expenses; in the opinion of Simon Devereaux they were probably dismayed at being forced to attend such spectacles. Harris's fate prompted William Wilberforce to sponsor a bill which if passed would have abolished the practice, but as one of its proposals would have allowed the anatomical dissection of criminals other than murderers, the House of Lords rejected it. The burning in 1789 of Catherine Murphy, a counterfeiter, was impugned in Parliament by Sir Benjamin Hammett. He called it one of \"the savage remains of Norman policy\". Amidst a growing tide of public disgust at the burning of women, Parliament passed the Treason Act 1790, which for women guilty of treason substituted hanging for burning. It was followed by the Treason Act 1814, introduced by Samuel Romilly, a legal reformer. Influenced by his friend, Jeremy Bentham, Romilly had long argued that punitive laws should serve to reform criminal behaviour and that far from acting as a deterrent, the severity of England's laws was responsible for an increase in crime. When appointed the MP for Queensborough in 1806 he resolved to improve what he described as \"Our sanguinary and barbarous penal code, written in blood\". He managed to repeal the death penalty for certain thefts and vagrancy, and in 1814 proposed to change the sentence for men guilty of treason to being hanged until dead and the body left at the king's disposal. However, when it was pointed out that this would be a less severe punishment than that given for murder, he agreed that the corpse should also be decapitated, \"as a fit punishment and appropriate stigma.\" This is what happened to Jeremiah Brandreth, leader of a 100-strong contingent of men in the Pentrich rising and one of three men executed in 1817 at Derby Gaol. As with Edward Despard and his confederates the three were drawn to the scaffold on sledges before being hanged for about an hour, and then on the insistence of the Prince Regent were beheaded with an axe. The local miner appointed to the task of beheading them was inexperienced though, and having failed with the first two blows, completed his job with a knife. As he held the first head up and made the customary announcement, the crowd reacted with horror and fled. A different reaction was seen in 1820, when amidst more social unrest five men involved in the Cato Street Conspiracy were hanged and beheaded at Newgate Prison. Although the beheading was performed by a surgeon, following the usual proclamation the crowd was angry enough to force the executioners to find safety behind the prison walls. The plot was the last crime for which the sentence was applied.\n\nReformation of England's capital punishment laws continued throughout the 19th century, as politicians such as John Russell, 1st Earl Russell, sought to remove from the statute books many of the capital offences that remained. Robert Peel's drive to ameliorate law enforcement saw petty treason abolished by the Offences against the Person Act 1828, which removed the distinction between crimes formerly considered as petty treason, and murder. The Royal Commission on Capital Punishment 1864-1866 recommended that there be no change to treason law, quoting the \"more merciful\" Treason Felony Act 1848, which limited the punishment for most treasonous acts to penal servitude. Its report recommended that for \"rebellion, assassination or other violence ...we are of opinion that the extreme penalty must remain\", although the most recent occasion (and ultimately, the last) on which anyone had been sentenced to be hanged, drawn, and quartered was in November 1839, following the Chartist Newport Rising—and those men sentenced to death were instead transported. The report highlighted the changing public mood toward public executions (brought about in part by the growing prosperity created by the Industrial Revolution). Home Secretary Spencer Horatio Walpole told the commission that executions had \"become so demoralizing that, instead of its having a good effect, it has a tendency rather to brutalize the public mind than to deter the criminal class from committing crime\". The commission recommended that executions should be performed privately, behind prison walls and away from the public's view, \"under such regulations as may be considered necessary to prevent abuse, and to satisfy the public that the law has been complied with.\" The practice of executing murderers in public was ended two years later by the Capital Punishment Amendment Act 1868, introduced by Home Secretary Gathorne Hardy, but this did not apply to traitors. An amendment to abolish capital punishment completely, suggested before the bill's third reading, failed by 127 votes to 23.\n\nHanging, drawing, and quartering was abolished in England by the Forfeiture Act 1870, Liberal politician Charles Forster's second attempt since 1864 to end the forfeiture of a felon's lands and goods (thereby not making paupers of his family). The Act limited the penalty for treason to hanging alone, although it did not remove the monarch's right under the 1814 Act to replace hanging with beheading. Beheading was abolished in 1973, although it had long been obsolete. The death penalty for treason was abolished by the Crime and Disorder Act 1998, enabling the UK to ratify protocol six of the European Convention on Human Rights in 1999.\n\nIn some of the places where the American War of Independence developed into a fierce civil war among American factions, there are recorded cases of both sides resorting to hanging, drawing, and quartering - both Loyalists and Patriots finding reasons to construe their opponents as being \"traitors\" deserving of such a fate.\n\nThe Eighth Amendment to the United States Constitution's prohibition of \"Cruel and Unusual Punishments\" clearly (and successfully) aimed at preventing any further such usage on American soil.\n\nFootnotes\nNotes\nBibliography\n\n"}
{"id": "226505", "url": "https://en.wikipedia.org/wiki?curid=226505", "title": "Limit point", "text": "Limit point\n\nIn mathematics, a limit point (or cluster point or accumulation point) of a set \"S\" in a topological space \"X\" is a point \"x\" that can be \"approximated\" by points of \"S\" in the sense that every neighbourhood of \"x\" with respect to the topology on \"X\" also contains a point of \"S\" other than \"x\" itself. A limit point of a set \"S\" does not itself have to be an element of \"S\".\n\nThis concept profitably generalizes the notion of a limit and is the underpinning of concepts such as closed set and topological closure. Indeed, a set is closed if and only if it contains all of its limit points, and the topological closure operation can be thought of as an operation that enriches a set by uniting it with its limit points.\n\nThere is also a closely related concept for sequences. A cluster point (or accumulation point) of a sequence (\"x\") in a topological space \"X\" is a point \"x\" such that, for every neighbourhood \"V\" of \"x\", there are infinitely many natural numbers \"n\" such that \"x\" ∈ \"V\". This concept generalizes to nets and filters. \n\nLet \"S\" be a subset of a topological space \"X\". \nA point \"x\" in \"X\" is a limit point (or cluster point or accumulation point) of \"S\" if every neighbourhood of \"x\" contains at least one point of \"S\" different from \"x\" itself. \n\nNote that it doesn't make a difference if we restrict the condition to open neighbourhoods only. It is often convenient to use the \"open neighbourhood\" form of the definition to show that a point is a limit point and to use the \"general neighbourhood\" form of the definition to derive facts from a known limit point. \n\nIf \"X\" is a \"T\" space (which all metric spaces are), then \"x\" ∈ \"X\" is a limit point of \"S\" if and only if every neighbourhood of \"x\" contains infinitely many points of \"S\". Indeed, \"T\" spaces are characterized by this property. \n\nIf \"X\" is a Fréchet–Urysohn space (which all metric spaces and first-countable spaces are), then \"x\" ∈ \"X\" is a limit point of \"S\" if and only if there is a sequence of points in \"S\" \\ {\"x\"} whose limit is \"x\". Indeed, Fréchet–Urysohn spaces are characterized by this property.\n\nIf every open set containing \"x\" contains infinitely many points of \"S\" then \"x\" is a specific type of limit point called an ω-accumulation point of \"S\".\n\nIf every open set containing \"x\" contains uncountably many points of \"S\" then \"x\" is a specific type of limit point called a condensation point of \"S\".\n\nIf every open set \"U\" containing \"x\" satisfies then \"x\" is a specific type of limit point called a of \"S\".\n\nIn a topological space formula_1, a point formula_2 is said to be a cluster point (or accumulation point) of a sequence formula_3 if, for every neighbourhood formula_4 of formula_5, there are infinitely many formula_6 such that formula_7. It is equivalent to say that for every neighbourhood formula_4 of formula_5 and every formula_10, there is some formula_11 such that formula_7. If formula_1 is a metric space or a first-countable space (or, more generally, a Fréchet–Urysohn space), then formula_14 is cluster point of formula_3 if and only if formula_16 is a limit of some subsequence of formula_3. \nThe set of all cluster points of a sequence is sometimes called the limit set. \n\nThe concept of a net generalizes the idea of a sequence. A net is a function formula_18, where formula_19 is a directed set and formula_20 is a topological space. A point formula_21 is said to be a cluster point (or accumulation point) of the net formula_22 if, for every neighbourhood formula_4 of formula_5 and every formula_25, there is some formula_26 such that formula_27, equivalently, if formula_28 has a subnet which converges to formula_14. Cluster points in nets encompass the idea of both condensation points and ω-accumulation points. Clustering and limit points are also defined for the related topic of filters.\n\n"}
{"id": "2383854", "url": "https://en.wikipedia.org/wiki?curid=2383854", "title": "List of anti-discrimination acts", "text": "List of anti-discrimination acts\n\nThis is a list of anti-discrimination acts (often called discrimination acts or anti-discrimination laws), which are laws designed to prevent discrimination.\n\n\nNorthern Ireland has a similar pattern of 'separate' equality legislation.\n\n\n"}
{"id": "4089175", "url": "https://en.wikipedia.org/wiki?curid=4089175", "title": "Logical constant", "text": "Logical constant\n\nIn logic, a logical constant of a language formula_1 is a symbol that has the same semantic value under every interpretation of formula_1. Two important types of logical constants are logical connectives and quantifiers. The equality predicate (usually written '=') is also treated as a logical constant in many systems of logic. One of the fundamental questions in the philosophy of logic is \"What is a logical constant?\"; that is, what special feature of certain constants makes them \"logical\" in nature?\n\nSome symbols that are commonly treated as logical constants are:\nMany of these logical constants are sometimes denoted by alternate symbols (\"e.g.\", the use of the symbol \"&\" rather than \"∧\" to denote the logical and).\n\n\n"}
{"id": "58004415", "url": "https://en.wikipedia.org/wiki?curid=58004415", "title": "Mario Klingemann", "text": "Mario Klingemann\n\nMario Klingemann is a German artist and Google Arts and Culture resident known for his work involving neural networks, code, and algorithms. He is considered a pioneer in the use of computer learning in the arts. His works examine creativity, culture, and perception through machine learning and artificial intelligence, and have appeared at the Ars Electronica Festival, the Museum of Modern Art New York, the Metropolitan Museum of Art New York, the Photographers’ Gallery London, the Centre Pompidou Paris, and the British Library.. Klingemann has been interviewed by such people as Emily L. Spratt.\n\n"}
{"id": "343375", "url": "https://en.wikipedia.org/wiki?curid=343375", "title": "Monopoly on violence", "text": "Monopoly on violence\n\nThe monopoly of the legitimate use of physical force, also known as the monopoly on violence (), is a core concept of modern public law, which goes back to Jean Bodin's 1576 work \"Les Six livres de la République\" and Thomas Hobbes' 1651 book \"Leviathan\". As the defining conception of the state, it was first described in sociology by Max Weber in his essay \"Politics as a Vocation\" (1919). Weber claims that the state is the \"only human Gemeinschaft which lays claim to the monopoly on the legitimated use of physical force. However, this monopoly is limited to a certain geographical area, and in fact this limitation to a particular area is one of the things that defines a state.\" In other words, Weber describes the state as any organization that succeeds in holding the exclusive right to use, threaten, or authorize physical force against residents of its territory. Such a monopoly, according to Weber, must occur via a process of legitimation.\n\nMax Weber wrote in \"Politics as a Vocation\" that a fundamental characteristic of statehood is the claim of such a monopoly. His expanded definition was that something is \"a 'state' if and insofar as its administrative staff successfully upholds a claim on the 'monopoly of the legitimate use of physical force' () in the enforcement of its order.\" Weber's concept has been formalized to show that the exclusive policing power of the state benefits social welfare via private property, provided the state acts benevolently in the interest of its citizens.\n\nAccording to Weber, the state is that \"human community that (successfully) claims the monopoly of the legitimate use of violence within a given territory.\" The public police and military are its main instruments, but private security might also be considered to have \"the 'right' to use violence\" so long as the sole source of this perceived right is state sanction. Weber applied several caveats to his discussion of the state's monopoly of violence:\n\nRobert Hinrichs Bates argues that the state itself has no violent power; rather, the people hold all the power of coercion to ensure that order and other equilibriums hold up. The implication of this is that there is a frontier of well-being in stateless societies, that can only be surpassed if some level of coercion or violence is used to elevate the complexity of the state. In other words, without investing in troops, police, or some sort of enforcement mechanism, early states cannot enjoy the law and order (or prosperity) of more developed states.\n\nThe capacity of a state is often measured in terms of its fiscal and legal capacity. Fiscal capacity meaning the state's ability to recover taxation to provide public goods, and legal capacity meaning the state's supremacy as sole arbiter of conflict resolution and contract enforcement. Without some sort of coercion, the state would not otherwise be able to enforce its legitimacy in its desired sphere of influence. In early and developing states, this role was often played by the \"stationary bandit\" who defended villagers from roving bandits, in the hope that the protection would incentivize villagers to invest in economic production, and the stationary bandit could eventually use its coercive power to expropriate some of that wealth.\n\nIn regions where state presence is minimally felt, non-state actors can use their monopoly of violence to establish legitimacy and order. For example, the Sicilian Mafia originated as a protection racket providing buyers and sellers in the black market with protection. Without this type of enforcement, market participants would not be otherwise confident enough to trust their counter-parties for valid contract enforcement and the market would collapse.\n\nEven in illicit and underground markets (somewhat akin to stateless societies), violence is used to enforce contracts in the absence of accessible legal conflict resolution. Charles Tilly continues this comparison to say that warmaking and statemaking are actually the best representations of what organized crime can grow into.\n\nAccording to Raymond Aron, international relations are characterized by the absence of widely acknowledged legitimacy in the use of force between states.\n\nMartha Lizabeth Phelps, writing in \"Politics & Policy\", takes Weber's ideas on the legitimacy of private security a step further. Phelps claims that the use of private actors by the state remains legitimate if and only if military contractors are perceived \nas being controlled by the state.\n"}
{"id": "48395", "url": "https://en.wikipedia.org/wiki?curid=48395", "title": "Navier–Stokes equations", "text": "Navier–Stokes equations\n\nIn physics, the Navier–Stokes equations (), named after Claude-Louis Navier and George Gabriel Stokes, describe the motion of viscous fluid substances.\n\nThese balance equations arise from applying Isaac Newton's second law to fluid motion, together with the assumption that the stress in the fluid is the sum of a diffusing viscous term (proportional to the gradient of velocity) and a pressure term—hence describing \"viscous flow\". The main difference between them and the simpler Euler equations for inviscid flow is that Navier–Stokes equations also factor in the Froude limit (no external field) and are not conservation equations, but rather a dissipative system, in the sense that they cannot be put into the quasilinear homogeneous form:\n\nNavier–Stokes equations are useful because they describe the physics of many phenomena of scientific and engineering interest. They may be used to model the weather, ocean currents, water flow in a pipe and air flow around a wing. The Navier–Stokes equations, in their full and simplified forms, help with the design of aircraft and cars, the study of blood flow, the design of power stations, the analysis of pollution, and many other things. Coupled with Maxwell's equations, they can be used to model and study magnetohydrodynamics.\n\nThe Navier–Stokes equations are also of great interest in a purely mathematical sense. Despite their wide range of practical uses, it has not yet been proven whether solutions always exist in three dimensions and, if they do exist, whether they are smooth – i.e. they are infinitely differentiable at all points in the domain. These are called the Navier–Stokes existence and smoothness problems. The Clay Mathematics Institute has called this one of the seven most important open problems in mathematics and has offered a US$1 million prize for a solution or a counterexample.\n\nThe solution of the Navier–Stokes equations is a flow velocity. It is a field, since it is defined at every point in a region of space and an interval of time. Once the velocity field is calculated other quantities of interest, such as pressure or temperature, may be found using additional equations and relations. This is different from what one normally sees in classical mechanics, where solutions are typically trajectories of position of a particle or deflection of a continuum. Studying velocity instead of position makes more sense for a fluid; however for visualization purposes one can compute various trajectories.\n\nThe Navier–Stokes momentum equation can be derived as a particular form of the Cauchy momentum equation, whose general convective form is\nBy setting the Cauchy stress tensor formula_3 to be the sum of a viscosity term formula_4 (the deviatoric stress) and a pressure term formula_5 (volumetric stress) we arrive at\n\n</math>\n\nwhere\n\nIn this form, it is apparent that in the assumption of an inviscid fluid -no deviatoric stress- Cauchy equations reduce to the Euler equations.\n\nAssuming conservation of mass we can use the continuity equation, formula_10 to arrive to the conservation form of the equations of motion. This is often written:\n\nwhere is the outer product:\n\nThe left side of the equation describes acceleration, and may be composed of time-dependent and convective components (also the effects of non-inertial coordinates if present). The right side of the equation is in effect a summation of hydrostatic effects, the divergence of deviatoric stress and body forces (such as gravity).\n\nAll non-relativistic balance equations, such as the Navier–Stokes equations, can be derived by beginning with the Cauchy equations and specifying the stress tensor through a constitutive relation. By expressing the deviatoric (shear) stress tensor in terms of viscosity and the fluid velocity gradient, and assuming constant viscosity, the above Cauchy equations will lead to the Navier–Stokes equations below.\n\nA significant feature of the Cauchy equation and consequently all other continuum equations (including Euler and Navier–Stokes) is the presence of convective acceleration: the effect of acceleration of a flow with respect to space. While individual fluid particles indeed experience time-dependent acceleration, the convective acceleration of the flow field is a spatial effect, one example being fluid speeding up in a nozzle.\n\nRemark: here, the Cauchy stress tensor is denoted formula_3 (instead of formula_4 as it was in the general continuum equations and in the incompressible flow section).\n\nThe compressible momentum Navier–Stokes equation results from the following assumptions on the Cauchy stress tensor:\n\n\nSince the trace of the rate-of-strain tensor in three dimensions is:\n\nThe trace of the stress tensor in three dimensions becomes:\n\nSo by alternatively decomposing the stress tensor into isotropic and deviatoric parts, as usual in fluid dynamics:\n\nIntroducing the second viscosity ,\n\nwe arrive to the linear constitutive equation in the form usually employed in thermal hydraulics:\n\nBoth second viscosity and dynamic viscosity need not be constant – in general, they depend on density, on each other (the viscosity is expressed in pressure), and in compressible flows also on temperature. Any equation expliciting one of these transport coefficient in the conservation variables is called an equation of state.\n\nBy computing the divergence of the stress tensor, since the divergence of tensor is and the divergence of tensor is , one finally arrives to the compressible (most general) Navier–Stokes momentum equation:\nThe above equation can also be written in the form\nwhere formula_19 is the material derivative.\nBulk viscosity is assumed to be constant, otherwise it should not be taken out of the last derivative. The effect of the volume viscosity is that the mechanical pressure is not equivalent to the thermodynamic pressure:\n\nThis difference is usually neglected, sometimes by explicitly assuming , but it could have an impact in sound absorption and attenuation and shock waves. The convective acceleration term can also be written as\n\nwhere the vector formula_22 is known as the Lamb vector.\n\nFor the special case of an incompressible flow, the pressure constrains the flow so that the volume of fluid elements is constant: isochoric flow resulting in a solenoidal velocity field with \n\nThe incompressible momentum Navier–Stokes equation results from the following assumptions on the Cauchy stress tensor:\n\n\nDynamic viscosity need not be constant – in incompressible flows it can depend on density and on pressure. Any equation expliciting one of these transport coefficient in the conservative variables is called an equation of state.\n\nThe divergence of the deviatoric stress is given by:\n\nbecause formula_25 for an incompressible fluid.\nIncompressibility rules out density and pressure waves like sound or shock waves, so this simplification is not useful if these phenomena are of interest. The incompressible flow assumption typically holds well with all fluids at low Mach numbers (say up to about Mach 0.3), such as for modelling air winds at normal temperatures. For incompressible (uniform density ρ) flows the following identity holds:\n\nwhere is the specific (with the sense of \"per unit mass\") thermodynamic work, the internal source term. Then the incompressible Navier–Stokes equations are best visualised by dividing for the density:\n\nwhere is called the kinematic viscosity.\nIt is well worth observing the meaning of each term (compare to the Cauchy momentum equation):\n\nThe higher-order term, namely the shear stress divergence , has simply reduced to the vector laplacian term . This laplacian term can be interpreted as the difference between the velocity at a point and the mean velocity in a small surrounding volume. This implies that – for a Newtonian fluid – viscosity operates as a \"diffusion of momentum\", in much the same way as the heat conduction. In fact neglecting the convection term, incompressible Navier–Stokes equations lead to a vector diffusion equation (namely Stokes equations), but in general the convection term is present, so incompressible Navier–Stokes equations belong to the class of convection-diffusion equations.\n\nIn the usual case of an external field being a conservative field:\n\nby defining the hydraulic head:\n\none can finally condense the whole source in one term, arriving to the incompressible Navier–Stokes equation with conservative external field:\n\nThe incompressible Navier–Stokes equations with conservative external field is the fundamental equation of hydraulics. The domain for these equations is commonly a 3 or less Euclidean space, for which an orthogonal coordinate reference frame is usually set to explicit the system of scalar partial differential equations to be solved. In 3D orthogonal coordinate systems are 3: Cartesian, cylindrical, and spherical. Expressing the Navier–Stokes vector equation in Cartesian coordinates is quite straightforward and not much influenced by the number of dimensions of the euclidean space employed, and this is the case also for the first-order terms (like the variation and convection ones) also in non-cartesian orthogonal coordinate systems. But for the higher order terms (the two coming from the divergence of the deviatoric stress that distinguish Navier–Stokes equations from Euler equations) some tensor calculus is required for deducing an expression in non-cartesian orthogonal coordinate systems.\n\nThe incompressible Navier–Stokes equation is composite, the sum of two orthogonal equations,\n\nwhere and are solenoidal and irrotational projection operators satisfying and and are the non-conservative and conservative parts of the body force. This result follows from the Helmholtz Theorem (also known as the fundamental theorem of vector calculus). The first equation is a pressureless governing equation for the velocity, while the second equation for the pressure is a functional of the velocity and is related to the pressure Poisson equation.\n\nThe explicit functional form of the projection operator in 3D is found from the Helmholtz Theorem:\n\nwith a similar structure in 2D. Thus the governing equation is an integro-differential equation similar to Coulomb and Biot-Savart law, not convenient for numerical computation.\n\nAn equivalent weak or variational form of the equation, proved to produce the same velocity solution as the Navier–Stokes equation, is given by,\n\nfor divergence-free test functions satisfying appropriate boundary conditions. Here, the projections are accomplished by the orthogonality of the solenoidal and irrotational function spaces. The discrete form of this is eminently suited to finite element computation of divergence-free flow, as we shall see in the next section. There one will be able to address the question \"How does one specify pressure-driven (Poiseuille) problems with a pressureless governing equation?\".\n\nThe absence of pressure forces from the governing velocity equation demonstrates that the equation is not a dynamic one, but rather a kinematic equation where the divergence-free condition serves the role of a conservation equation. This all would seem to refute the frequent statements that the incompressible pressure enforces the divergence-free condition.\n\nWith partitioning of the problem domain and defining basis functions on the partitioned domain, the discrete form of the governing equation is,\n\nIt is desirable to choose basis functions which reflect the essential feature of incompressible flow – the elements must be divergence-free. While the velocity is the variable of interest, the existence of the stream function or vector potential is necessary by the Helmholtz Theorem. Further, to determine fluid flow in the absence of a pressure gradient, one can specify the difference of stream function values across a 2D channel, or the line integral of the tangential component of the vector potential around the channel in 3D, the flow being given by Stokes' Theorem. Discussion will be restricted to 2D in the following.\n\nWe further restrict discussion to continuous Hermite finite elements which have at least first-derivative degrees-of-freedom. With this, one can draw a large number of candidate triangular and rectangular elements from the plate-bending literature. These elements have derivatives as components of the gradient. In 2D, the gradient and curl of a scalar are clearly orthogonal, given by the expressions,\n\nAdopting continuous plate-bending elements, interchanging the derivative degrees-of-freedom and changing the sign of the appropriate one gives many families of stream function elements.\n\nTaking the curl of the scalar stream function elements gives divergence-free velocity elements. The requirement that the stream function elements be continuous assures that the normal component of the velocity is continuous across element interfaces, all that is necessary for vanishing divergence on these interfaces.\n\nBoundary conditions are simple to apply. The stream function is constant on no-flow surfaces, with no-slip velocity conditions on surfaces.\nStream function differences across open channels determine the flow. No boundary conditions are necessary on open boundaries, though consistent values may be used with some problems. These are all Dirichlet conditions.\n\nThe algebraic equations to be solved are simple to set up, but of course are non-linear, requiring iteration of the linearized equations.\n\nSimilar considerations apply to three-dimensions, but extension from 2D is not immediate because of the vector nature of the potential, and there exists no simple relation between the gradient and the curl as was the case in 2D.\n\nRecovering pressure from the velocity field is easy. The discrete weak equation for the pressure gradient is,\n\nwhere the test/weight functions are irrotational. Any conforming scalar finite element may be used. However, the pressure gradient field may also be of interest. In this case one can use scalar Hermite elements for the pressure. For the test/weight functions one would choose the irrotational vector elements obtained from the gradient of the pressure element.\n\nThe rotating frame of reference introduces some interesting pseudo-forces into the equations through the material derivative term. Consider a stationary inertial frame of reference K, and a non-inertial frame of reference K', which is translating with velocity formula_37 and rotating with angular velocity formula_38 with respect to the stationary frame. The Navier–Stokes equation observed from the non-inertial frame then becomes\n\nHere formula_39 and formula_40 are measured in the non-inertial frame. The first term in the parenthesis represents Coriolis acceleration, the second term is due to centripetal acceleration, the third is due to the linear acceleration of K' with respect to K and the fourth term is due to the angular acceleration of K' with respect to K.\n\nThe Navier–Stokes equations are strictly a statement of the balance of momentum. To fully describe fluid flow, more information is needed, how much depending on the assumptions made. This additional information may include boundary data (no-slip, capillary surface, etc.), conservation of mass, balance of energy, and/or an equation of state.\n\nRegardless of the flow assumptions, a statement of the conservation of mass is generally necessary. This is achieved through the mass continuity equation, given in its most general form as:\n\nor, using the substantive derivative:\n\nIn the example below we can assume to have a Newtonian fluid as well as having and both be constant.\n\nRecall that mass continuity is simply the summation of the rate of mass in and the rate of mass out.\n\nSince there is no change in density over time, , we have:\n\nRecall that is a constant thus proving the divergence theorem above.\n\nTaking the curl of the Navier–Stokes equation results in the elimination of pressure. This is especially easy to see if 2D Cartesian flow is assumed (like in the degenerate 3D case with and no dependence of anything on ), where the equations reduce to:\n\nDifferentiating the first with respect to , the second with respect to and subtracting the resulting equations will eliminate pressure and any conservative force. Defining the stream function through\n\nresults in mass continuity being unconditionally satisfied (given the stream function is continuous), and then incompressible Newtonian 2D momentum and mass conservation condense into one equation:\n\nwhere is the 2D biharmonic operator and is the kinematic viscosity, . We can also express this compactly using the Jacobian determinant:\n\nThis single equation together with appropriate boundary conditions describes 2D fluid flow, taking only kinematic viscosity as a parameter. Note that the equation for creeping flow results when the left side is assumed zero.\n\nIn axisymmetric flow another stream function formulation, called the Stokes stream function, can be used to describe the velocity components of an incompressible flow with one scalar function.\n\nThe incompressible Navier–Stokes equation is a differential algebraic equation, having the inconvenient feature that there is no explicit mechanism for advancing the pressure in time. Consequently, much effort has been expended to eliminate the pressure from all or part of the computational process. The stream function formulation eliminates the pressure but only in two dimensions and at the expense of introducing higher derivatives and elimination of the velocity, which is the primary variable of interest.\n\nThe Navier–Stokes equations are nonlinear partial differential equations in the general case and so remain in almost every real situation. In some cases, such as one-dimensional flow and Stokes flow (or creeping flow), the equations can be simplified to linear equations. The nonlinearity makes most problems difficult or impossible to solve and is the main contributor to the turbulence that the equations model.\n\nThe nonlinearity is due to convective acceleration, which is an acceleration associated with the change in velocity over position. Hence, any convective flow, whether turbulent or not, will involve nonlinearity. An example of convective but laminar (nonturbulent) flow would be the passage of a viscous fluid (for example, oil) through a small converging nozzle. Such flows, whether exactly solvable or not, can often be thoroughly studied and understood.\n\nTurbulence is the time-dependent chaotic behavior seen in many fluid flows. It is generally believed that it is due to the inertia of the fluid as a whole: the culmination of time-dependent and convective acceleration; hence flows where inertial effects are small tend to be laminar (the Reynolds number quantifies how much the flow is affected by inertia). It is believed, though not known with certainty, that the Navier–Stokes equations describe turbulence properly.\n\nThe numerical solution of the Navier–Stokes equations for turbulent flow is extremely difficult, and due to the significantly different mixing-length scales that are involved in turbulent flow, the stable solution of this requires such a fine mesh resolution that the computational time becomes significantly infeasible for calculation or direct numerical simulation. Attempts to solve turbulent flow using a laminar solver typically result in a time-unsteady solution, which fails to converge appropriately. To counter this, time-averaged equations such as the Reynolds-averaged Navier–Stokes equations (RANS), supplemented with turbulence models, are used in practical computational fluid dynamics (CFD) applications when modeling turbulent flows. Some models include the Spalart–Allmaras, –, –, and SST models, which add a variety of additional equations to bring closure to the RANS equations. Large eddy simulation (LES) can also be used to solve these equations numerically. This approach is computationally more expensive—in time and in computer memory—than RANS, but produces better results because it explicitly resolves the larger turbulent scales.\n\nTogether with supplemental equations (for example, conservation of mass) and well formulated boundary conditions, the Navier–Stokes equations seem to model fluid motion accurately; even turbulent flows seem (on average) to agree with real world observations.\n\nThe Navier–Stokes equations assume that the fluid being studied is a continuum (it is infinitely divisible and not composed of particles such as atoms or molecules), and is not moving at relativistic velocities. At very small scales or under extreme conditions, real fluids made out of discrete molecules will produce results different from the continuous fluids modeled by the Navier–Stokes equations. For example, capillarity of internal layers in fluids appears for flow with high gradients. For large Knudsen number of the problem, the Boltzmann equation may be a suitable replacement. \nFailing that, one may have to resort to molecular dynamics or various hybrid methods.\n\nAnother limitation is simply the complicated nature of the equations. Time-tested formulations exist for common fluid families, but the application of the Navier–Stokes equations to less common families tends to result in very complicated formulations and often to open research problems. For this reason, these equations are usually rewritten for Newtonian fluids where the viscosity model is linear; truly general models for the flow of other kinds of fluids (such as blood) do not exist.\n\nThe Navier–Stokes equations, even when written explicitly for specific fluids, are rather generic in nature and their proper application to specific problems can be very diverse. This is partly because there is an enormous variety of problems that may be modeled, ranging from as simple as the distribution of static pressure to as complicated as multiphase flow driven by surface tension.\n\nGenerally, application to specific problems begins with some flow assumptions and initial/boundary condition formulation, this may be followed by scale analysis to further simplify the problem.\n\nAssume steady, parallel, one dimensional, non-convective pressure-driven flow between parallel plates, the resulting scaled (dimensionless) boundary value problem is:\n\nThe boundary condition is the no slip condition. This problem is easily solved for the flow field:\n\nFrom this point onward more quantities of interest can be easily obtained, such as viscous drag force or net flow rate.\n\nDifficulties may arise when the problem becomes slightly more complicated. A seemingly modest twist on the parallel flow above would be the \"radial\" flow between parallel plates; this involves convection and thus non-linearity. The velocity field may be represented by a function that must satisfy:\n\nThis ordinary differential equation is what is obtained when the Navier–Stokes equations are written and the flow assumptions applied (additionally, the pressure gradient is solved for). The nonlinear term makes this a very difficult problem to solve analytically (a lengthy implicit solution may be found which involves elliptic integrals and roots of cubic polynomials). Issues with the actual existence of solutions arise for (approximately; this is not ), the parameter R being the Reynolds number with appropriately chosen scales. This is an example of flow assumptions losing their applicability, and an example of the difficulty in \"high\" Reynolds number flows.\n\nA type of natural convection which can be described by the Navier–Stokes equation is the Rayleigh–Bénard convection. It is one of the most commonly studied convection phenomena because of its analytical and experimental accessibility.\n\nSome exact solutions to the Navier–Stokes equations exist. Examples of degenerate cases — with the non-linear terms in the Navier–Stokes equations equal to zero — are Poiseuille flow, Couette flow and the oscillatory Stokes boundary layer. But also more interesting examples, solutions to the full non-linear equations, exist such as Jeffery–Hamel flow, Von Kármán swirling flow, Stagnation point flow, Landau–Squire jet, Taylor–Green vortex.\nNote that the existence of these exact solutions does not imply they are stable: turbulence may develop at higher Reynolds numbers.\n\nUnder additional assumptions, the component parts can be separated.\n\n\\end{align}</math>\n\nwhere and are arbitrary constants. This solution is valid in the domain and for .\n\nIn Cartesian coordinates, when the viscosity is zero (), this is:\n\nA steady-state example with no singularities comes from considering the flow along the lines of a Hopf fibration. Let be a constant radius of the inner coil. One set of solutions is given by:\n\nfor arbitrary constants and . This is a solution in a non-viscous gas (compressible fluid) whose density, velocities and pressure goes to zero far from the origin. (Note this is not a solution to the Clay Millennium problem because that refers to incompressible fluids where is a constant, neither does it deal with the uniqueness of the Navier–Stokes equations with respect to any turbulence properties.) It is also worth pointing out that the components of the velocity vector are exactly those from the Pythagorean quadruple parametrization. Other choices of density and pressure are possible with the same velocity field:\n\nWyld diagrams are bookkeeping graphs that correspond to the Navier–Stokes equations via a perturbation expansion of the fundamental continuum mechanics. Similar to the Feynman diagrams in quantum field theory, these diagrams are an extension of Keldysh's technique for nonequilibrium processes in fluid dynamics. In other words, these diagrams assign graphs to the (often) turbulent phenomena in turbulent fluids by allowing correlated and interacting fluid particles to obey stochastic processes associated to pseudo-random functions in probability distributions.\n\n &\\quad = -\\frac{\\partial p}{\\partial r} + \\mu \\left(\\frac{1}{r}\\frac{\\partial}{\\partial r}\\left(r \\frac{\\partial u_r}{\\partial r}\\right) +\n\n\\end{align}</math>\n\nThe gravity components will generally not be constants, however for most applications either the coordinates are chosen so that the gravity components are constant or else it is assumed that gravity is counteracted by a pressure field (for example, flow in horizontal pipe is treated normally without gravity and without a vertical pressure gradient). The continuity equation is:\n\nThis cylindrical representation of the incompressible Navier–Stokes equations is the second most commonly seen (the first being Cartesian above). Cylindrical coordinates are chosen to take advantage of symmetry, so that a velocity component can disappear. A very common case is axisymmetric flow with the assumption of no tangential velocity (), and the remaining quantities are independent of :\n\n\\end{align}</math>\n\nMass continuity will read:\n\nThese equations could be (slightly) compacted by, for example, factoring from the viscous terms. However, doing so would undesirably alter the structure of the Laplacian and other quantities.\n\nThe Navier–Stokes equations are used extensively in video games in order to model a wide variety of natural phenomena. Simulations of small-scale gaseous fluids, such as fire and smoke, are often based on the seminal paper \"Real-Time Fluid Dynamics for Games\" by Jos Stam, which elaborates one of the methods proposed in Stam's earlier, more famous paper \"Stable Fluids\" from 1999. Stam proposes stable fluid simulation using a Navier–Stokes solution method from 1968, coupled with an unconditionally stable semi-Lagrangian advection scheme, as first proposed in 1992.\n\nMore recent implementations based upon this work run on the game systems graphics processing unit (GPU) as opposed to the central processing unit (CPU) and achieve a much higher degree of performance.\nMany improvements have been proposed to Stam's original work, which suffers inherently from high numerical dissipation in both velocity and mass.\n\nAn introduction to interactive fluid simulation can be found in the 2007 ACM SIGGRAPH course, Fluid Simulation for Computer Animation.\n\n\n"}
{"id": "50676644", "url": "https://en.wikipedia.org/wiki?curid=50676644", "title": "Nelle A. Coley", "text": "Nelle A. Coley\n\nNelle Artis Coley, a noted educator, was born in Greensboro, NC in 1909. She attended local parochial primary schools (Episcopal and Lutheran) in Greensboro before starting public school (Washington Street School?). She entered Bennett College in 1926, completing her high school studies in 1927. For the next four years, she alternated her studies with summer employment as a waitress in restaurants on the New Jersey shore. She completed her undergraduate studies at Bennett College in 1931. Unable to find work in Greensboro, she moved to Beaufort, North Carolina, where she found a teaching job.\n\nMrs. Coley continued teaching in Beaufort through the early 1930s, and spent her summers in New York, pursuing graduate studies at Columbia University. She completed her graduate studies at Columbia in 1935. In the fall of 1935, she returned to Greensboro and started teaching at James B. Dudley Senior High. She taught English courses at Dudley until her retirement in 1980. Mrs. Coley died on April 14, 1999 after a brief illness.\n\nBaker, Scott, 2011. \"Pedagogies of Protest: African American Teachers and the History of the Civil Rights Movement, 1940-1963.\" Teachers College Record, Vol. 113, No. 12. December 2011. http://eric.ed.gov/?id=EJ988307. Accessed May 29, 2016. Firewalled\n\nChafe, William H. (1980). Civilities and Civil Rights: Greensboro, North Carolina and the Black Struggle for Freedom. New York: Oxford University Press. (E185.615 .C43 1980). http://www.worldcat.org/oclc/4957224\n\nFairclough, Adam. (2007). A class of their own: Black teachers in the segregated South. Cambridge, Mass: Belknap Press of Harvard University Press. (LC2802 .S9 F35 2007) http://www.worldcat.org/oclc/434595724\n\nThuesen, Sarah. (2013). Greater Than Equal: African American Struggles for Schools and Citizenship in North Carolina, 1919-1965. Chapel Hill, NC: The University of North Carolina Press. (LC2802 .N8 T58 2013) http://www.worldcat.org/oclc/855019699\n\nWilson, E. H., & Mullally, S. (1983). Hope and dignity: Older Black Women of the South. Philadelphia: Temple University Press. http://www.worldcat.org/oclc/9016982\n"}
{"id": "2389519", "url": "https://en.wikipedia.org/wiki?curid=2389519", "title": "Nominative use", "text": "Nominative use\n\nNominative use, also \"nominative fair use\", is a legal doctrine that provides an affirmative defense to trademark infringement as enunciated by the United States Ninth Circuit, by which a person may use the trademark of another as a reference to describe the other product, or to compare it to their own. Nominative use may be considered to be either related to, or a type of \"trademark fair use\" (sometimes called \"classic fair use\" or \"statutory fair use\"). All \"trademark fair use\" doctrines, however classified, are distinct from the fair use doctrine in copyright law. However, the fair use of a trademark may be protected under copyright laws depending on the complexity or creativity of the mark as a design logo.\n\nThe nominative use test essentially states that one party may use or refer to the trademark of another if:\n\n\nFurthermore, if a use is found to be nominative, then by the definition of non-trademark uses, it can not dilute the trademark.\n\nNominative use does \"not\" require that ownership of the trademark be acknowledged, for example by use of a sentence such as \"UNIX is a registered trademark of The Open Group\". Such statements may, however, be required by the terms of a license agreement between the parties, and they may be prudent (and courteous) as a way of preventing misunderstandings or allegations of passing off.\n\nThe nominative use doctrine was first enunciated in 1992 by the U.S. Court of Appeals for the Ninth Circuit in \"New Kids on the Block v. News America Publishing, Inc.\". In \"New Kids on the Block\", the court had examined a \"New Kids on the Block survey\" performed by the defendant, and found that there was no way to ask people their opinion of the band without using its name. For instance, one could refer to the Minnesota Twins as \"that professional baseball team from Minnesota,\" but it is much more acceptable to just refer to them by their trade name.\n\nITn \"Playboy Enterprises, Inc. v. Welles\", where Playboy Playmate Terri Welles was sued for using the trademarked term \"Playmate of the Year\" in a meta keyword within the HTML code of her website. The court found that Welles had to use the term to completely describe herself, as she had been given that title by the trademark holder. In other words, individuals are not compelled by trademark law to use \"absurd turns of phrase\" simply to avoid trademark liability. \n\nIn \"New Kids\" and in \"Playboy v. Welles\", the courts examined older cases, identifying a unifying principle that they then named \"nominative use\". Among the older cases cited by the Court in \"Playboy v. Welles\" was \"Volkswagenwerk Aktiengesellschaft v. Church\", in which the Ninth Circuit had ruled that an independent auto repair shop that specialized in repairing Volkswagen cars and mentioned that fact in their advertising was not liable for trademark infringement so long as they did not claim or imply that they had any business relationship with the Volkswagen company. In the case of \"Yue v. MSC Software Corporation\",\nthe Northern District of California held that the nominative fair use defense is a burden-shifting defense properly decided at the summary judgment stage and would be premature to raise in a motion to dismiss.\n\n"}
{"id": "56059964", "url": "https://en.wikipedia.org/wiki?curid=56059964", "title": "Opetope", "text": "Opetope\n\nIn category theory, a branch of mathematics, an opetope, a portmanteau of \"operation\" and \"polytope\", is a shape that captures higher-dimensional substitutions. It was introduced by John C. Baez and James Dolan so that they could define a weak \"n\"-category as a certain presheaf on the category of opetopes.\n\n\n\n"}
{"id": "46002", "url": "https://en.wikipedia.org/wiki?curid=46002", "title": "Pax Americana", "text": "Pax Americana\n\nPax Americana (Latin for \"American Peace\", modeled after \"Pax Romana\", \"Pax Britannica\", and \"Pax Mongolica\") is a term applied to the concept of relative peace in the Western Hemisphere and later the world beginning around the middle of the 20th century, thought to be caused by the preponderance of power enjoyed by the United States. Although the term finds its primary utility in the latter half of the 20th century, it has been used with different meanings and eras, such as the post-Civil War era in North America, and regionally in the Americas at the start of the 20th century.\n\n\"Pax Americana\" is primarily used in its modern connotations to refer to the peace among great powers established after the end of World War II in 1945, also called the Long Peace. In this modern sense, it has come to indicate the military and economic position of the United States in relation to other nations. For example, the Marshall Plan, which spent $13 billion to rebuild the economy of Western Europe, has been seen as \"the launching of the pax americana\".\n\nThe Latin term derives from \"Pax Romana\" of the Roman Empire. The term is most notably associated with \"Pax Britannica\" (1815–1914) under the British Empire, which served as the global hegemon and constabulary from the late 18th century until the early 20th century.\n\nThe first articulation of a \"Pax Americana\" occurred after the end of the American Civil War with reference to the peaceful nature of the North American geographical region, and was abeyant at the commencement of the First World War. Its emergence was concurrent with the development of the idea of American exceptionalism. This view holds that the U.S. occupies a special niche among developed nations in terms of its national credo, historical evolution, political and religious institutions, and unique origins. The concept originates from Alexis de Tocqueville, who asserted that the then-50-year-old United States held a special place among nations because it was a country of immigrants and the first modern democracy. From the establishment of the United States after the American Revolution until the Spanish–American War, the foreign policy of the United States had a regional, instead of global, focus. The Pax Americana, which the Union enforced upon the states of central North America, was a factor in the United States' national prosperity. The larger states were surrounded by smaller states, but these had no anxieties: no standing armies to require taxes and hinder labor; no wars or rumors of wars that would interrupt trade; there is not only peace, but security, for the Pax Americana of the Union covered all the states within the federal constitutional republic. According to the Oxford English Dictionary, the first time the phrase appeared in print was in the August 1894 issue of \"Forum\": \"The true cause for exultation is the universal outburst of patriotism in support of the prompt and courageous action of President Cleveland in maintaining the supremacy of law throughout the length and breadth of the land, in establishing the \"pax Americana\".\"\n\nWith the rise of the New Imperialism in the Western hemisphere at the end of the 19th century, debates arose between imperialist and isolationist factions in the U.S. Here, \"Pax Americana\" was used to connote the peace across the United States and, more widely, as a Pan-American peace under the aegis of the Monroe Doctrine. Those who favored traditional policies of avoiding foreign entanglements included labor leader Samuel Gompers and steel tycoon Andrew Carnegie. American politicians such as Henry Cabot Lodge, William McKinley, and Theodore Roosevelt advocated an aggressive foreign policy, but the administration of President Grover Cleveland was unwilling to pursue such actions. On January 16, 1893, U.S. diplomatic and military personnel conspired with a small group of individuals to overthrow the constitutional government of the Kingdom of Hawaii and establish a Provisional Government and then a republic. On February 15, they presented a treaty for annexation of the Hawaiian Islands to the U.S. Senate, but opposition to annexation stalled its passage. The United States finally opted to annex Hawaii by way of the Newlands Resolution in July 1898.\n\nAfter its victory in the Spanish–American War of 1898 and the subsequent acquisition of Cuba, Puerto Rico, the Philippines, and Guam, the United States had gained a colonial empire. By ejecting Spain from the Americas, the United States shifted its position to an uncontested regional power, and extended its influence into Southeast Asia and Oceania. Although U.S. capital investments within the Philippines and Puerto Rico were relatively small, these colonies were strategic outposts for expanding trade with Latin America and Asia, particularly China. In the Caribbean area, the United States established a sphere of influence in line with the Monroe Doctrine, not explicitly defined as such, but recognized in effect by other governments and accepted by at least some of the republics in that area. The events around the start of the 20th century demonstrated that the United States undertook an obligation, usual in such cases, of imposing a \"Pax Americana\". As in similar instances elsewhere, this Pax Americana was not quite clearly marked in its geographical limit, nor was it guided by any theoretical consistency, but rather by the merits of the case and the test of immediate expediency in each instance. Thus, whereas the United States enforced a peace in much of the lands southward from the Nation and undertook measures to maintain internal tranquility in such areas, the United States on the other hand withdrew from interposition in Mexico.\n\nEuropean powers largely regarded these matters as the concern of the United States. Indeed, the nascent Pax Americana was, in essence, abetted by the policy of the United Kingdom, and the preponderance of global sea power which the British Empire enjoyed by virtue of the strength of the Royal Navy. Preserving the freedom of the seas and ensuring naval dominance had been the policy of the British since victory in the Napoleonic Wars. As it was not in the interests of the United Kingdom to permit any European power to interfere in Americas, the Monroe Doctrine was indirectly aided by the Royal Navy. British commercial interests in South America, which comprised a valuable component of the Informal Empire that accompanied Britain's imperial possessions, and the economic importance of the United States as a trading partner, ensured that intervention by Britain's rival European powers could not engage with the Americas.\n\nThe United States lost its Pacific and regionally bounded nature towards the end of the 19th century. The government adopted protectionism after the Spanish–American War and built up the navy, the \"Great White Fleet\", to expand the reach of U.S. power. When Theodore Roosevelt became President in 1901, he accelerated a foreign policy shift away from isolationism towards foreign intervention which had begun under his predecessor, William McKinley. The Philippine–American War arose from the ongoing Philippine Revolution against imperialism. Interventionism found its formal articulation in the 1904 Roosevelt Corollary to the Monroe Doctrine, proclaiming the right of the United States to intervene in the affairs of weak states in the Americas in order to stabilize them, a moment that underlined the emergent U.S. regional hegemony.\n\nThe United States had been criticized for not taking up the hegemonic mantle following the disintegration of \"Pax Britannica\" before the First World War and during the interwar period due to the absence of established political structures, such as the World Bank or United Nations which would be created after World War II, and various internal policies, such as protectionism. Though, the United States participated in the Great War, according to Woodrow Wilson:\n\n[...] to vindicate the principles of peace and justice in the life of the world as against selfish and autocratic power and to set up amongst the really free and self-governed peoples of the world such a concert of purpose and of action as will henceforth insure the observance of those principles.\n[...] for democracy, for the right of those who submit to authority to have a voice in their own government, for the rights and liberties of small nations, for a universal dominion of right by such a concert of free peoples as shall bring peace and safety to all nations and make the world itself at last free.\n\nThe United States' entry into the Great War marked the abandonment of the traditional American policy of isolation and independence of world politics. Not at the close of the Civil War, not as the result of the Spanish War, but in the Interwar period did the United States become a part of the international system. With this global reorganization from the Great War, there were those in the American populace that advocated an activist role in international politics and international affairs by the United States. Activities that were initiated did not fall into political-military traps and, instead, focused on economic-ideological approaches that would increase the American Empire and general worldwide stability. Following the prior path, a precursor to the United Nations and a league to enforce peace, the League of Nations, was proposed by Woodrow Wilson. This was rejected by the American Government in favor of more economic-ideological approaches and the United States did not join the League. Additionally, there were even proposals of extending the Monroe Doctrine to Great Britain put forth to prevent a second conflagration on the European theater. Ultimately, the United States' proposals and actions did not stop the factors of European nationalism spawned by the previous war, the repercussions of Germany's defeat, and the failures of the Treaty of Versailles from plunging the globe into a Second World War.\n\nBetween World War I and World War II, America also sought to continue to preserve \"Pax America\" as a corollary to the Monroe Doctrine. Some sought the peaceful and orderly evolution of existing conditions in the western hemisphere and nothing by immediate changes. Before 1917, the position of the United States government and the feelings of the nation in respect to the \"Great War\" initially had properly been one of neutrality. Its interests remained untouched, and nothing occurred of a nature to affect those interests.\n\nThe average American's sympathies, on the other hand, if the feelings of the vast majority of the nation had been correctly interpreted, was with the Allied (Entente) Powers. The population of the United States was revolted at the ruthlessness of the Prussian doctrine of war, and German designs to shift the burden of aggression encountered skeptical derision. The American populace saw themselves safeguarding liberal peace in the Western World. To this end, the American writer Roland Hugins stated:\n\nThe truth is that the United States is the only high-minded Power left in the world. It is the only strong nation that has not entered on a career of imperial conquest, and does not want to enter on it. [...] There is in America little of that spirit of selfish aggression which lies at the heart of militarism. Here alone exists a broad basis for \"a new passionate sense of brotherhood, and a new scale of human values.\" We have a deep abhorrence of war for war's sake; we are not enamored of glamour or glory. We have a strong faith in the principle of self-government. We do not care to dominate alien peoples, white or colored; we do not aspire to be the Romans of tomorrow or the \"masters of the world.\" The idealism of Americans centers in the future of America, wherein we hope to work out those principles of liberty and democracy to which we are committed This political idealism, this strain of pacifism, this abstinence from aggression and desire to be left alone to work out our own destiny, has been manifest from the birth of the republic. We have not always followed our light, but we have never been utterly faithless to it.\nIt was observed during this time that the initial defeat of Germany opened a moral recasting of the world. The battles between Germans and Allies were seen as far less battles between different nations than they represent the contrast between Liberalism and reaction, between the aspirations of democracy and the Wilhelminism gospel of iron.\n\nThe modern \"Pax Americana\" era is cited by both supporters and critics of U.S. foreign policy after World War II. However, from 1946 to 1992 \"Pax americana\" is considered a partial international order, as it applied only to capitalist bloc countries, being preferable for some authors to speak about a \"Pax americana et sovietica\". Many commentators and critics focus on American policies from 1992 to the present, and as such, it carries different connotations depending on the context. For example, it appears three times in the 90 page document, \"Rebuilding America's Defenses,\" by the Project for the New American Century, but is also used by critics to characterize American dominance and hyperpower as imperialist in function and basis. From about the mid-1940s until 1991, U.S. foreign policy was dominated by the Cold War, and characterized by its significant international military presence and greater diplomatic involvement. Seeking an alternative to the isolationist policies pursued after World War I, the United States defined a new policy called containment to oppose the spread of communism.\n\nThe modern \"Pax Americana\" may be seen as similar to the period of peace in Rome, \"Pax Romana\". In both situations, the period of peace was 'relative peace'. During both \"Pax Romana\" and \"Pax Americana\" wars continued to occur, but it was still a prosperous time for both Western and Roman civilizations. It is important to note that during these periods, and most other times of relative tranquility, the peace that is referred to does not mean complete peace. Rather, it simply means that the civilization prospered in their military, agriculture, trade, and manufacturing.\n\nFrom the end of the Napoleonic Wars in 1815 until World War I in 1914, the United Kingdom played the role of offshore-balancer in Europe, where the balance of power was the main aim. It was also in this time that the British Empire became the largest empire of all time. The global superiority of British military and commerce was guaranteed by dominance of a Europe lacking in strong nation-states, and the presence of the Royal Navy on all of the world's oceans and seas. In 1905, the Royal Navy was superior to any two navies combined in the world. It provided services such as suppression of piracy and slavery. In this era of peace, though, there were several wars between the major powers: the Crimean War, the Franco-Austrian War, the Austro-Prussian War, the Franco-Prussian War, and the Russo-Japanese War, as well as numerous other wars. \"La Belle Époque\", William Wohlforth argued, was rather \"Pax Britannica\", \"Russica\" and later \"Germanica\", and between 1853 and 1871 it was not \"Pax\" of any kind.\n\nDuring the British hegemony, America developed close ties with Britain, evolving into what has become known as a \"special relationship\" between the two. The many commonalities shared with the two nations (such as language and history) drew them together as allies. Under the managed transition of the British Empire to the Commonwealth of Nations, members of the British government, such as Harold Macmillan, liked to think of Britain's relationship with America as similar to that of a progenitor Greece to America's Rome. Throughout the years, both have been active in North American, Middle Eastern, and Asian countries.\n\nAfter the Second World War, no armed conflict emerged among major Western nations themselves, and no nuclear weapons were used in open conflict. The United Nations was also soon developed after World War II to help keep peaceful relations between nations and establishing the veto power for the permanent members of the UN Security Council, which included the United States.\n\nIn the second half of the 20th century, the USSR and US superpowers were engaged in the Cold War, which can be seen as a struggle between hegemonies for global dominance. After 1945, the United States enjoyed an advantageous position with respect to the rest of the industrialized world. In the Post–World War II economic expansion, the US was responsible for half of global industrial output, held 80 percent of the world's gold reserves, and was the world's sole nuclear power. The catastrophic destruction of life, infrastructure, and capital during the Second World War had exhausted the imperialism of the Old World, victor and vanquished alike. The largest economy in the world at the time, the United States recognized that it had come out of the war with its domestic infrastructure virtually unscathed and its military forces at unprecedented strength. Military officials recognized the fact that Pax Americana had been reliant on the effective United States air power, just as the instrument of Pax Britannica a century earlier was its sea power. In addition, a \"unipolar moment\" was seen to have occurred following the collapse of the Soviet Union.\n\nThe term \"Pax Americana\" was explicitly used by John F. Kennedy in the 1960s, who advocated against the idea, arguing that the Soviet bloc was composed of human beings with the same individual goals as Americans and that such a peace based on \"American weapons of war\" was undesirable:\n\nI have, therefore, chosen this time and place to discuss a topic on which ignorance too often abounds and the truth too rarely perceived. And that is the most important topic on earth: peace. What kind of peace do I mean and what kind of a peace do we seek? Not a \"Pax Americana\" enforced on the world by American weapons of war. Not the peace of the grave or the security of the slave. I am talking about genuine peace, the kind of peace that makes life on earth worth living, and the kind that enables men and nations to grow, and to hope, and build a better life for their children—not merely peace for Americans but peace for all men and women, not merely peace in our time but peace in all time.\n\nBeginning around the Vietnam War, the 'Pax Americana' term had started to be used by the critics of American Imperialism. Here in the late 20th century conflict between the Soviet Union and the United States, the charge of \"Neocolonialism\" was often aimed at Western involvement in the affairs of the Third World and other developing nations. NATO became regarded as a symbol of \"Pax Americana\" in West Europe:\nCurrently, the \"Pax Americana\" is based on the military preponderance beyond challenge by any combination of powers and projection of power throughout the world's \"commons\"—neutral sea, air and space. This projection is coordinated by the Unified Command Plan which divides the world on regional branches controlled by a single command. Notably, \"the right to command\" translated into Latin renders \"imperium\". Integrated with it are global network of military alliances (the Rio Pact, NATO, ANZUS and bilateral alliances with Japan and several other states) coordinated by Washington in a hub-and-spokes system and worldwide network of several hundreds of military bases and installations. Neither the Rio Treaty, nor NATO, for Robert J. Art, \"was a regional collective security organization; rather both were regional imperia run and operated by the United States\". Former Security Advisor Zbignew Brzezinski drew an expressive summary of the military foundation of \"Pax Americana\" shortly after the \"unipolar moment\":\nBesides the military foundation, there are significant non-military international institutions backed by American financing and diplomacy (like the United Nations and WTO). The United States invested heavily in programs such as the Marshall Plan and in the reconstruction of Japan, economically cementing defense ties that owed increasingly to the establishment of the Iron Curtain/Eastern Bloc and the widening of the Cold War.\n\nBeing in the best position to take advantage of free trade, culturally indisposed to traditional empires, and alarmed by the rise of communism in China and the detonation of the first Soviet atom bomb, the historically non-interventionist U.S. also took a keen interest in developing multilateral institutions which would maintain a favorable world order among them. The International Monetary Fund and International Bank for Reconstruction and Development (World Bank), part of the Bretton Woods system of international financial management was developed and, until the early 1970s, the existence of a fixed exchange rate to the US dollar. The General Agreement on Tariffs and Trade (GATT) was developed and consists of a protocol for normalization and reduction of trade tariffs.\n\nWith the fall of the Iron Curtain, the demise of the notion of a \"Pax Sovietica\", and the end of the Cold War, the U.S. maintained significant contingents of armed forces in Europe and East Asia. The institutions behind the Pax Americana and the rise of the United States unipolar power have persisted into the early 21st century. The ability of the United States to act as \"the world's policeman\" has been constrained by its own citizens' historic aversion to foreign wars. Though there has been calls for the continuation of military leadership, as stated in \"Rebuilding America's Defenses\":\n\nThe American peace has proven itself peaceful, stable, and durable. It has, over the past decade, provided the geopolitical framework for widespread economic growth and the spread of American principles of liberty and democracy. Yet no moment in international politics can be frozen in time; even a global \"Pax Americana\" will not preserve itself. [... What is required is] a military that is strong and ready to meet both present and future challenges; a foreign policy that boldly and purposefully promotes American principles abroad; and national leadership that accepts the United States' global responsibilities.\nThis is reflected in the research of American exceptionalism, which shows that \"there is some indication for [being a leader of an 'American peace'] among the [U.S.] public, but very little evidence of unilateral attitudes\". It should be noted that resentments have arisen at a country's dependence on American military protection, due to disagreements with United States foreign policy or the presence of American military forces.\nIn the \"post-communism\" world of the 21st-century, the French Socialist politician and former Foreign Minister Hubert Védrine describes the US as a hegemonic hyperpower, while the U.S. political scientists John Mearsheimer and Joseph Nye counter that the US is not a \"true\" hegemony, because it does not have the resources to impose a proper, formal, global rule; despite its political and military strength, the US is economically equal to Europe, thus, cannot rule the international stage. Several other countries are either emerging or re-emerging as powers, such as China, Russia, India, and the European Union.\n\nJoseph Nye discredited the United States as not a \"true\" hegemony in his 2002 article titled \"The New Rome Meets the New Barbarians\". His book of the same year he opens: \"Not since Rome has one nation loomed so large above the others.\" And his 1991 book he titled \"Bound to Lead\". \"Leadership\", translated into Greek, renders \"hegemony\"; an alternative translation is \"archia\" – Greek common word for \"empire\". Having defined the US hegemony as \"not true\", Nye looks for an analogy to the true empire: Decline, he writes, is not necessarily imminent. \"Rome remained dominant for more than three centuries after the peak of its power ...\n\nIn fact, there are striking parallels with the early \"Pax Romana\" (especially between 189 BC when the supremacy over the Mediterranean was won and the first annexation in 168 BC). Under that \"Pax Romana\" other states remained formally independent and very seldom were called \"clients\". The latter term became widely used only in the late medieval period. Usually, other states were called \"friends and allies\"—a popular expression under the \"Pax Americana\".\n\nOne of the first to use the term \"Pax Americana\" was the Advisory Committee on Postwar Foreign Policy. In 1942, the Committee envisaged that the United States may have to replace the British Empire. Therefore, the United States \"must cultivate a mental view toward world settlement after this war which will enable us to impose our own terms, amounting perhaps to a Pax Americana\". According to Swen Holdar, the founder of geopolitics Rudolf Kjellen (1864–1922) predicted the era of US global supremacy using the term \"Pax Americana\" shortly after World War I. Writing in 1945, Ludwig Dehio remembered that the Germans used the term \"Pax Anglosaxonica\" in a sense of Pax Americana since 1918:\n\nThe United States, Dehio associates on the same page, withdrew to isolation on that occasion. \"Rome, too, had taken a long time to understand the significance of her world role.\" Two years earlier, with the war still at its peak, the founder of the Paneuropean Union, Richard von Coudenhove-Kalergi, invoked the example of the two-centuries long \"Pax Romana\" which, he suggested, could be repeated if based on the preponderant US air power:\n\nOne of the first criticisms of \"Pax Americana\" was written by Nathaniel Peffer in 1943:\n\nHowever, Peffer was not certain that this would not happen: \"It is conceivable that ... America might drift into empire, imperceptibly, stage by stage, in a kind of power-politics gravitation.\" He also noted that America was heading precisely in that direction: \"That there are certain stirrings in this direction is apparent, though how deep they go is unclear.\"\n\nThe depth soon became clarified. Two later critics of Pax Americana, Michio Kaku and David Axelrod, interpreted the outcome of Pax Americana: \"Gunboat diplomacy would be replaced by Atomic diplomacy. Pax Britannica would give way to Pax Americana.\" After the war, with the German and British militaries in tatters, only one force stood on the way to Pax Americana: the Red Army. Four years after this criticism was written, the Red Army withdrew, paving the way for the unipolar moment. Joshua Muravchik commemorated the event by titling his 1991 article, \"At Last, Pax Americana\". He detailed:\nThe following year, in 1992, a US strategic draft for the post-Cold War period was leaked to the press. The person responsible for the confusion, former Assistant Secretary of State, Paul Wolfowitz, confessed seven years later: \"In 1992 a draft memo prepared by my office at the Pentagon ... leaked to the press and sparked a major controversy.\" The draft's strategy aimed \"to prevent any hostile power from dominating\" a Eurasian region \"whose resources would, under consolidated control, be sufficient to generate global power\". He added: \"Senator Joseph Biden ridiculed the proposed strategy as 'literally a \"Pax Americana\" ... It won't work ...' Just seven years later, many of these same critics seem quite comfortable with the idea of a \"Pax Americana\".\"\n\nThe post-Cold War period, concluded William Wohlforth, much less ambiguously deserves to be called \"Pax Americana\". \"Calling the current period the true Pax Americana may offend some, but it reflects reality\".\n\nThe ‘’Pax Americana’’ motif reached its peak in the context of the 2003 Iraq War. The phrase \"American Empire\" appeared in one thousand news stories over a single six-month period in 2003. Jonathan Freedland observed:\n\"The New York Review of Books\" illustrated a recent piece on US might with a drawing of George Bush togged up as a Roman centurion, complete with shield and spears. Bush's visits to Germany in 2002 and 2006 resulted in further Bush-as-Roman-emperor invective appearing in the German press. In 2006, freelance writer, political satirist, and correspondent for the left-leaning \"Die Tageszeitung\", Arno Frank, compared the spectacle of the visit by \"Imperator\" Bush to \"elaborate inspection tours of Roman emperors in important but not completely pacified provinces—such as Germania\". In September 2002, Boston's WBUR-FM radio station titled a special on US imperial power with the tag \"Pax Americana\". \"The Roman parallel, wrote Niall Ferguson in 2005, is in danger of becoming something of a cliché.\" Policy analyst Vaclav Smil titled his 2010 book by what he intended to explain: \"Why America Is Not a New Rome\". The very phenomenon of the Roman-American association became the subject of research for Classicist Paul J. Burton.\n\nPeter Bender, in his 2003 article \"America: The New Roman Empire\", summarized: \"When politicians or professors are in need of a historical comparison in order to illustrate the United States' incredible might, they almost always think of the Roman Empire.\" The article abounds with analogies:\n\nIn 1998, American political author, Charles A. Kupchan, described the world order \"After Pax Americana\" and the next year \"The Life after Pax Americana\". In 2003, he announced \"The End of the American Era\". In 2012, however, he projected: \"America's military strength will remain as central to global stability in the years ahead as it has been in the past.\"\n\nThe Russian analyst Leonid Grinin argues that at present and in the nearest future Pax Americana will remain an effective tool of supporting the world order since the US concentrates too many leadership functions which no other country is able to take to the full extent. Thus, he warns that the destruction of Pax Americana will bring critical transformations of the World-system with unclear consequences \n\n\"American imperialism\" is a term referring to outcomes or ideological elements of United States foreign policy. Since the start of the cold war, the United States has economically and/or diplomatically supported friendly foreign governments, including many that overtly violated the civil and human rights of their own citizens and residents. American imperialism concepts were initially a product of capitalism critiques and, later, of theorists opposed to what they take to be aggressive United States policies and doctrines. Although there are various views of the imperialist nature of the United States, which describe many of the same policies and institutions as evidence of imperialism, explanations for imperialism vary widely. In spite of such literature, the historians Archibald Paton Thorton and Stuart Creighton Miller argue against the very coherence of the concept. Miller argues that the overuse and abuse of the term \"imperialism\" makes it nearly meaningless as an analytical concept.\n\n\n\n"}
{"id": "31598288", "url": "https://en.wikipedia.org/wiki?curid=31598288", "title": "Peer victimization", "text": "Peer victimization\n\nPeer victimization is the experience among children of being a target of the aggressive behavior of other children, who are not siblings and not necessarily age-mates.\n\nMass interest in the issue of peer victimization arose during the 1990s due to media coverage of student suicides, peer beatings, and school shootings, notably the tragedy in Columbine, Colorado. This led to an explosion of research attempting to assess bully-victim relationships and related players, what leads victims to experience negative outcomes and how widespread this problem was. Studies of peer victimization have also been conducted in the context of research investigating childhood relationships in general and how they are associated with school adjustment and achievement.\n\nResearch has proven the problematic nature of peer victimization, identifying many negative outcomes such as low self-esteem, low school engagement, school avoidance, lower school achievement, learned helplessness, and depression. Peer victimization is especially prevalent and damaging in middle school, as during this time children are defining themselves by creating self-schemas and establishing self-esteem, both which will impact their future adult life; for this reason, most of the research on peer victimization focuses on this age group. They are also more vulnerable to peer rejection because needs for belonging and intimacy may be especially strong during early adolescence, when children are working to solidify their peer groups.\n\nMuch of victimization research adopts a social psychology perspective, investigating how different types of peer victimization affect the individual and the different negative outcomes that occur. Some experimenters are adopting the term social victimization in order to acknowledge that victimization can take both verbal and nonverbal forms or be direct or indirect. They mostly focus on the types of victimization that can occur from multiple sources in a particular environment. Personality psychologists look at individual differences and effects in victims. They may also study individuals in a social context, determining which are more likely to be victimized, such as those who are socially withdrawn.\n\nWith the development of technology and the widespread access it gives to children and teenagers, peer victimization has become more prevalent through the Internet and cell phones than in years past. This form of victimization called cyberbullying has a potential for a much wider audience than traditional face-to-face victimization. It is also easier to hide from parents and teachers. Studies have found that because this form of victimization is done through the anonymity of the Internet or text messaging, bullies feel more comfortable being crueler to the victim. Without face-to-face communication, social standards become less important and behavior becomes less inhibited.\n\nOriginally, researchers focused on overt forms of victimization, which were categorized as either physical or verbal. Later, researchers such as Nicki R. Crick argued for the existence of a more covert form of victimization which she observed primarily among females that she called relational victimization, during which a child’s social relationships and social standing are attacked via methods such as peer exclusion. Today, victimization is largely operationally defined as either covert/relational victimization or overt/physical victimization, in which a child is threatened with or dealt corporeal damage.\n\nThe study of peer victimization draws from two major strands of research as identified by Seely, Tombari, Bennett & Dunkle (2009) called the \"bullying strand\" and the \"peer relationship strand.\" The victimization aspect of the \"bullying strand\" focuses on what leads victims to disengage from school and suffer from damaging negative outcomes while others adjust. The peer relationship strand is more quantitatively oriented, studying fundamental factors related to peer victimization and the negative outcomes, paying special attention to what factors mediate the relationship between them. Interest in peer victimization in psychological research has been fairly recent, and therefore it appears that most researchers have drawn from other areas of study and contemporary applied theories to the context of peer victimization.\n\nThe areas of the bullying strand that specifically pertain to peer victimization are studies of victimization prevalence, victims’ home environment, and effects of victimization in schools . Researchers started by determining the prevalence of peer victimization believing this would allow for the comparison of the problem over time, populations and after interventions. Prevalence research has been conducted in many different countries, cultures and classroom contexts. Studies utilize a variety of different methods such as self-report questionnaires, peer nominations, and teacher nominations have been used. Unfortunately, results show that in many contexts, the percentage of children that are victimized have fallen in a range between 5-90% Bullying strand research also focuses on the type of families that those who are victimized come from and what types of parenting styles they experienced Finally, a limited number of studies today focus on impacts of being bullied in a school setting and how it relates to achievement, truancy, and drop-out.\n\nStudies examining peer victimization have also been conducted in the context of a body of research interested in peer relationships and how they affect educational performance and adjustment; this is identified as the \"peer relationship strand.\" In the 1970s and 1980s, Steven Asher identified one form of a relationship—peer victimization—as a predictor of educational maladjustment. Later, a new perspective formed that considered peer victimization as a type of relationship existing on a continuum of relationship roles from healthy relations to detrimental ones instead of focusing on specific bully-victim relationships. Experimenters have also been interested in how early victimization effects individuals over time, focusing on school-related outcomes. Studies have largely worked to identify underlying factors that mediate negative outcomes.\n\nTo account for difference in the severity of negative outcomes as a result of peer victimization, researchers have utilized theories of implicit peer relationships. In order to understand the social world, individuals create implicit theories about their social interactions A major determinant of how a person handles social evaluation is the degree to which they ascribe entity theories of personality, believing it their attributes are stable and unalterable or incremental theories of personality, viewing attributes as pliable able to be augmented Those who adopt entity theories of personality often pursue performance oriented goals, seeking to accrue positive and avoid negative evaluations of their competence. Since they view their attributes as constant, it is vital that they are desirable in order for them to maintain a positive self-image. People who hold incremental theories of personality endeavor towards mastery-oriented goals, focusing on learning and cultivating competence since as they believe their attributes are malleable. Accordingly, they should feel less threatened by others’ evaluations of their competence. When thinking about self-evaluation, implicit theories should affect the degree to which children base their self appraisals on peer judgements, determining whether negative social interactions undermine their well-being.\n\nIn regards to behavioral reactions to victimization, research has identified two categories of characteristic responses. One contains externalizing behaviors such as aggression, disruptive, antisocial, and acting out behaviors (Achenbach, 1966). Another constitutes internalizing behaviors like inhibited, anxious, or heightened withdrawal.\n\nHawker and Boulton (2001) have used the rank theory of depression to explain the relationship between forms of victimization and types of maladjustment. According to the rank theory, internalizing problems such as depression are linked to a sense of powerlessness and of not belonging. Those who are physically victimized suffer from low resource-holding potential, which works in part to delineate social power in peer groups, while relational victimization directly affects children’s sense of belonging instead. In addition, according to social rank theory, jeopardization of one’s feeling of belonging stemming from relational victimization should play a greater part in perpetuating depression than that of resource-holding potential as in physical victimization. Therefore, depression should correlate more strongly with relational victimization as opposed to physical victimization.\n\nCurrently, researchers have become interested in the direction of the relationship between peer victimization and psychosocial adjustment. Many believe that the relation acts in a single direction: either peer victimization leads to maladjustment, or the relationship is reversed Some argue that the relationship is bidirectional and causal relationship. As studies on the topic have generally utilized, cross-sectional research designs, a definitive answer has not been reached.\n\nA study by Cole, Maxwell, Dukewich & Yosick examined how physical and relational Targeted Peer Victimization (TPV) victimization were related and measured their effects on different types of positive and negative cognitions. It was hypothesized that the link between peer victimization and depression was mediated by the creation of negative self-schemas. The study found gender differences in victimization, as Relational TPV was more common for girls and physical TPV was more common for boys. Also, children who were severely victimized exhibited less positive self-cognitions and more negative self-cognitions as well as more depressive symptoms. Yet when they controlled for the effects of relational TPV, the effects of physical TPV disappeared; it appears that relational TPV is more strongly associated with these outcomes and an investigation of physical TPV alone would not yield the same associations. Positive and negative self-cognitions were found to mediate the effect of relational victimization to symptoms of depression.\n\nAnother study by Sinclair (2011) examined the relationship between physical and relational peer victimization with negative and positive self-cognitions as well. It was found that both types of victimization led to increases in negative self-cognitions and decreases in positive self-cognitions, though the effects were more pronounced when a child experienced relational victimization. While girls were found experienced more relational victimization than boys did and boys experienced more physical victimization than girls did, the negative effects of victimization on self-cognitions was stronger in boys. This may be due to one of their findings that boys are less likely to seek adult social support than girls are. A study conducted by Schmidt and Bagwell used surveys to gauge the reactions of victimization and their self evaluated friendships. The study found that girls benefited significantly from having stronger, reliable peer friendships in coping with victimization, while boys did not. A study by Snyder and colleagues studied 266 Kindergarten and first grade children in cases of observed victimization at school. The researchers hypothesized that children with higher recorded cases of victimization during recess would rank higher in antisocial and depressive behavior—according to parents and teachers—than those who do not. Results showed that girls were not as affected by boys in terms of their change in teacher and parent rated behavior whereas boys were heavily influenced by the amount of peer victimization that day.\n\nResearch seems to show that there is drastic difference in the way both genders (at least in children) respond to victimization from peers. Current studies on children indicate that regardless of observational method (researcher direct observation or survey results given to the children) there is a marked effect of victimization, especially from peers. The magnitude of the effect on their behavior and mental health is heavily correlated with the situation of the victimization and the child’s social environment at the time.\n\nSchwartz et al. (1998) investigated the role of victimization in the development of children’s behavior problems, focusing on both internalizing and externalizing problems. They hypothesized that higher levels of victimization would lead to increased level of behavioral problems. Child behavior was reported by teachers and parents, measured using the Child Behavior Checklist, and peer victimization was measured using peer nomination. Indeed, they found that peer victimization in middle childhood was associated with behavioral maladjustment on both a concurrent and prospective basis. Additionally, externalizing behaviors were more strongly associated with victimization than were internalizing behaviors.\n\nSeals & Young (2003) investigated relationships between bullying and victimization with gender, grade level, ethnicity, self-esteem, and depression. Results showed that victims reported lower levels of self-esteem than did bullies and nonbullies/nonvictims. Additionally, victims had the highest depression scores as compared to bullies and nonbullies/nonvictims.\n\nResearch progress has also been made into recent mediums of victimization and bullying, notably online victimization. A study conducted by Mitchell \"et al.\" in 2007 collected data from over 2000 adolescents through telephone interviews. The most surprising finding was that those who reported being subject to online victimization in the past year are 96% likely to also report being subject to physical (offline) victimization. Another study conducted with over 3000 youth in the 5th, 8th and 11th grades using surveys concluded that Internet victimization shares common causal pathways with physical and verbal victimization.\n\nAn interest in aspects of bullying sprouted in the 1990s due to media coverage of student suicides, peer beatings, and school shootings. Yet such negative outcomes are rare.\n\nOne of the most well-known cases concerning the effects of peer victimization is the Columbine High School massacre of 1999 in Columbine, Colorado, United States. The perpetrators of this incident, Eric Harris and Dylan Klebold, murdered 12 students and 1 teacher and also injured 21 other students before committing suicide. After the tragedy, details emerged showing that Harris and Klebold had been bullied for years by classmates, with little to no intervention by school officials. Though such events are not frequent, they do alarming damage.\n\nThere has been a recent surge in the number of incidents regarding peer victimization and homosexuality. Specifically, the news has recently highlighted many cases of lesbian, gay, bisexual and transgender (LGBT) students who have committed suicide in response to peer victimization. One such incident is the case of 18-year-old Tyler Clementi, a Rutgers University student who was secretly videotaped by his roommate, Dharun Ravi, having sexual intercourse with another man. Ravi and another hallmate also streamed the video of the sexual encounter online. After finding out about this, Clementi jumped off of the George Washington Bridge to his death. Reports claim that Clementi had filed a complaint about his roommate having previously violating his privacy in the same manner, but no action had been taken to replace Clementi’s roommate.\n\nResearch demonstrates that lesbian, gay, or bisexual (LGB) students are highly likely to be victimized. Over half of LGB participants were verbally abused when they were in high school, and 11% were physically assaulted in a study by D’Augelli et al. (2002). Negative outcomes such as mental health problems and poor school performance have been associated with high incidences of victimization of LGB students. Recently research in this area seems to be progressing from the investigation of the extent and effects of LGB victimization to the specific factors associated with victimization and negative outcomes.\n\nA study by Goodenow et al. (2006) was one of the first to examine which school-related factors were associated with lower rates of victimization and suicidality in this population. School related factors included the presence of LGB support groups and staff support as well as other school characteristics like student-to-teacher ratio. It was found that LGB support groups were associated with both low victimization and suicidality among LGB students. Results indicated that the existence of LGB support groups may have led to a decrease in suicidality through decreasing incidence of peer victimization as the association between LGB support groups and suicidality disappeared when victimization was controlled for. Yet as this study examined correlations, causality cannot be assumed. Student courts were associated with less victimization, and antibullying policies were associated with less suicidality, even when the effects of victimization and perceived support were taken into account. Lower levels of victimization and suicidality of LGB students was also associated with large school size and urban locale. These school-related factors have traditionally been associated with a generally safer school environment, yet it seems that factors that increase safety for the general population may not increase safety for LGB students.\n\nA study by Kosciw et al. (2009) investigated how school related factors, community factors (such as adult education and income level), and locational factors (on a national level) were associated with victimization of LGB students. Results showed that community factors were the most significantly related to victimization and many regional-level as well as school-related factors were not found to be significant once these factors were taken into account. Increased reports of victimization due to gender expression were found in communities with higher poverty levels compared to affluent communities. Youth from communities with higher as opposed to lower proportions of adults with college degrees also reported less victimization. In accordance with the Goodenow study, It was also found that youth from urban communities were less likely to be victimized than those from rural communities.\n\nThe results of these studies show a strong need for intervention programs, specifically in-school programs. Though most schools punish bullying through disciplinary action, the frequency of bullying and victimization remains high. Thus, newer, more effective strategies must be implemented. Such programs should not only focus on punishing the bully, but should also focus on the victim. Victims should be taught to use healthier coping strategies instead of internalizing and externalizing their feelings. One intervention program focuses on bullying prevention in positive behavior support (BP-PBS). BP-PBS is designed to, in a series of steps, teach students how to treat each other respectfully, as well as teach ways to minimize social reinforcement of bullying behaviors in order to improve the school atmosphere.\n\nRoss and Horner (2009) investigated the effectiveness of this program across three elementary schools in Oregon by focusing on 6 students. They collected baseline data for the frequency of bullying as well as victim and bystander responses and then implemented the program across these school for approximately 8–12 weeks. Results showed that the frequency of bullying behaviors was significantly reduced among these students and that there was also a significant increase in more appropriate responses from victims and bystanders. Thus, interventions like BP-PBS may be effective in alleviating the problem of bullying and victimization in schools. To really test this, such programs should be put into effect nationally. Effective counseling are also a necessary component of dealing with peer victimization in schools. The most important step to successful counseling is identifying the children who are being victimized. While physical victimization can be easily noticed, for example by the presence of bruises and scratches, relational victimization is harder to detect. It is difficult to realize what children are being ostracized or ridiculed, especially if the student doesn’t vocalize this treatment. Disciplining relational victimization is also a difficult task. Whereas physical victimization is usually punished with a school suspension, for example, it would seem ridiculous to respond to relational victimization with the same punishment. Because of such discrepancies, it is important to create and implement effective strategies for dealing with relational victimization.\n\nIn a study evaluating the effectiveness of this program, Bauer, Lozano, & Rivara (2007) found that the Olweus program had \"mixed positive effects\"; specifically, there was a 28% decrease in relational victimization and a 37% decrease in physical victimization.\n\n\n"}
{"id": "24006408", "url": "https://en.wikipedia.org/wiki?curid=24006408", "title": "Psychological behaviorism", "text": "Psychological behaviorism\n\nPsychological behaviorism is a form of behaviorism — a major theory within psychology which holds that generally human behaviors are learned — proposed by Arthur W. Staats. The theory is constructed to advance from basic animal learning principles to deal with all types of human behavior, including personality, culture, and human evolution. Behaviorism was first developed by John B. Watson (1912), who coined the term \"behaviorism,\" and then B. F. Skinner who developed what is known as \"radical behaviorism.\" Watson and Skinner rejected the idea that psychological data could be obtained through introspection or by an attempt to describe consciousness; all psychological data, in their view, was to be derived from the observation of outward behavior. The strategy of these behaviorists was that the animal learning principles should then be used to explain human behavior. Thus, their behaviorisms were based upon research with animals.\n\nStaats' program takes the animal learning principles, in the form in which he presents them, to be basic. But, also on the basis of his study of human behaviors, adds human learning principles. These principles are unique, not evident in any other species. Holth also critically reviews psychological behaviorism as a \"path to the grand reunification of psychology and behavior analysis\".\n\nThe preceding behaviorisms of Ivan P. Pavlov, Edward L. Thorndike, John B. Watson, B. F. Skinner, and Clark L. Hull studied the basic principles of conditioning with animals. These behaviorists were animal researchers. Their basic approach was that those basic animal principles were to be applied to the explanation of human behavior. They did not have programs for the study of human behavior broadly, and deeply. \n\nStaats was the first to do his research with human subjects. His study ranged from research on basic principles to research and theory analysis of a wide variety of human behaviors, real life human behaviors. That is why Warren Tryon (2004) suggested that Staats change the name of his approach to psychological behaviorism, because Staats behaviorism is based upon human research and unifies aspects of traditional study with his behaviorism.\nThat includes his study of the basic principles. For example, the original behaviorists treated the two types of conditioning in different ways. The most generally used way by B. F. Skinner constructively considered classical conditioning and operant conditioning to be separate and independent principles. In classical conditioning, if a piece of food is provided to a dog shortly after a buzzer is sounded, for a number of times, the buzzer will come to elicit salivation, part of an emotional response. In operant conditioning, if a piece of food is presented to a dog after the dog makes a particular motor response, the dog will come to make that motor response more frequently. \n\nFor Staats, these two types of conditioning are not separate, they interact. A piece of food elicits an emotional response. A piece of food presented after the dog has made a motor response will have the effect of strengthening that motor response so that it occurs more frequently in the future.\n\nStaats sees the piece of food to have two functions: one function is that of eliciting an emotional response, the other function is that of strengthening the motor behavior the precedes the presenting of food. So classical conditioning and operant conditioning are very much related.\n\nPositive emotion stimuli will serve as positive reinforcers. Negative emotion stimuli will serve as punishers. As a consequence of humans’ inevitable learning positive emotion stimuli will serve as positive discriminative stimuli, incentives. Negative emotion stimuli will serve as negative discriminative stimuli, disincentives. So, emotion stimuli also have reinforcing value and discriminative stimulus value. Unlike Skinner’s basic principles, emotion and classical conditioning are central causes of behavior.\n\nUnlike the other behaviorisms, Staats’ considers human learning principles. He states that humans learn complex repertoires of behavior like language, values, and athletic skills –– that is cognitive, emotional, and sensory motor repertoires. When such a repertoire has been learned, they change the individual’s learning ability. A child who has learned language, a basic repertoire, can learn to read. A person who has learned a value system, such as a system of beliefs in human freedom, can learn to value different forms of government. An individual who has learned to be a track athlete, can learn to move more quickly as a football player. This introduces a basic principle of psychological behaviorism, that human behavior is learned cumulatively. Learning one repertoire enables the individual to learn other repertoires that enable the individual to learn additional repertoires, and on and on. Cumulative learning is a unique human characteristic. It has taken humans from chipping hand axes to flying to the moon, learned repertoires that enable the learning of new repertoires that enable the learning of new repertoires in an endless fashion of achievement.\n\nThat theory development enables psychological behaviorism to deal with types of human behavior. Out of the reach of radical behaviorism, for example, personality.\n\nStaats proposes that radical behaviorism is insufficient, because in his view psychology needs to unify traditional knowledge of human behavior with behaviorism. He has called that behaviorizing psychology in a way that enables psychological behaviorism to deal with topics not usually dealt with in behaviorism, such as personality. According to this theory, personality consists of three huge and complex behavioral repertoires:\n\nThe infant begins life without the basic behavioral repertoires. They are acquired through complex learning, and as this occurs, the child becomes able to respond appropriately to various situations.\n\nWhereas at the beginning learning involves only basic conditioning, as repertories are acquired the child's learning improves, being aided by the repertoires that are already functional. The way a person experiences the world depends on his/her repertoires. The individual's environment to the present results in learning a basic behavioral repertoire (BBR). The individual's behavior is function of the life situation and the individual's BBR. The BBRs are both a dependent and an independent variable, as they result from learning and cause behavior, constituting the individual's personality. According to this theory, biological conditions of learning are essential. Biology provides the mechanisms for learning and performance of behavior. For example, a severely brain-damaged child will not learn BBRs in a normal manner.\n\nAccording to Staats, the biological organism is the mechanism by which the environment produces learning that results in basic behavioral repertoires which constitute personality. In turn, these repertoires, once acquired, are modifying the brain's biology, through the creation of new neural connections. Organic conditions affect behavior through affecting learning, basic repertoires, and sensory processes. The effect of environment on behavior can be proximal, here-and-now, or distal, through memory and personality. Thus, biology provides the mechanism, learning and environment provide the content of behavior and personality. Creative behavior is explained by novel combinations of behaviors elicited by new, complex environmental situations. The self is the individual's perception of his/her behavior, situation, and organism. Personality, situation, and the interaction between them are the three main forces explaining behavior. The world acts upon the person, but the person also acts both on the world, and on him/herself.\n\nThe methodology of psychological behavioral theory contains techniques of assessment and therapy specially designed for the three behavioral repertoires:\n\nWatson named the approach \"behaviorism\" as a form of revolution against the then prevalent use of introspection to study the mind. Introspection was subjective and variable, not a source of objective evidence, and the mind consisted of an inferred entity that could never be observed. He insisted psychology had to be based on objective observation of behavior and the objective observation of the environmental events that cause behavior. Skinner’s radical behaviorism also has not established a systematic relationship to traditional psychology knowledge.\n\nPsychological behaviorism—while bolstering Watson’s rejection of inferring the existence of internal entities such as mind, personality, maturation stages, and free will—considers important knowledge produced by non-behavioral psychology that can be objectified by analysis in learning-behavioral terms. As one example, the concept of intelligence is inferred, not observed, and thus intelligence and intelligence tests are not considered systematically in behaviorism. However, PB considers IQ tests measure important behaviors that predict later school performance and intelligence is composed of learned repertoires of such behaviors. Joining the knowledge of behaviorism and intelligence testing yields concepts and research concerning what intelligence is behaviorally, what causes intelligence, as well as how intelligence can be increased. It is thus a behaviorism that systematically incorporates and explains, behaviorally, empirical parts of psychology.\n\nThe different behaviourisms also differ with respect to basic principles. Skinner contributed greatly in separating Pavlov’s classical conditioning of emotion responses and operant conditioning of motor behaviors. Staats, however, notes that food was used by Pavlov to elicit a positive emotional response in his classical conditioning and Thorndike Edward Thorndike used food as the reward (reinforcer) that strengthened a motor response in what came to be called operant conditioning, thus emotion-eliciting stimuli are also reinforcing stimuli. Watson, although the father of behaviorism, did not develop and research a basic theory of the principles of conditioning. The behaviorists whose work centered on that development treated differently the relationship of the two types of conditioning. Skinner’s basic theory was advanced in recognizing two different types of conditioning, but he didn’t recognize their interrelatedness, or the importance of classical conditioning, both very central for explaining human behavior and human nature.\n\nStaats’ basic theory specifies the two types of conditioning and the principles of their relationship. Since Pavlov used a food stimulus to elicit an emotional response and Thorndike used food as a reward (reinforcer) to strengthen a particular motor response, whenever food is used both types of conditioning thus take place. That means that food both elicits a positive emotion and food will serve as a positive reinforcer (reward). It also means that any stimulus that is paired with food will come to have those two functions. Psychological behaviorism and Skinner’s behaviorism both consider operant conditioning a central explanation of human behavior, but PB additionally concerns emotion and classical conditioning.\n\nThis difference between the two behaviorisms can be seen clearly in their theories of language. Staats, extending prior theory indicates that a large number of words elicit either a positive or negative emotional response because of prior classical conditioning. As such they should transfer their emotional response to anything with which they are paired. PB provides evidence this is the case. PB’s basic learning theory also states that emotional words have two additional functions. They will serve as rewards and punishments in learning other behaviors, and they also serve to elicit either approach or avoidance behavior. Thus, (1) hearing that people of an ethnic group are dishonest will condition a negative emotion to the name of that group as well as to members of that group, (2) complimenting (saying positive emotional words to) a person for a performance will increase the likelihood the person will perform that action later on, and (3) seeing the sign RESTAURANT will elicit a positive emotion in a hungry driver and thus instigate turning into the restaurant’s parking lot. Each case depends upon words eliciting an emotional response.\n\nPB treats various aspects of language, from its original development in children to its role in intelligence and in abnormal behavior, and backs this up with basic and applied study. His theory paper in the journal Behavior Therapy helped introduce cognitive (language) behavior therapy to the behavioral field.\n\nMuch of the research on which PB is based has concerned children’s learning. For example, there is a series of studies of the first learning of reading with preschoolers and also a series studying and training dyslexic adolescent children. The psychological behaviorism (PB) position became that the norms of child development—the ages when important behaviors appear—are due to learning, not biological maturation.\n\nStaats began studies to analyze cases of important human behaviors in basic and applied ways in 1954. In 1958 he analyzed dyslexia and introduced his token reinforcer system (later called the token economy) along with his teaching method and materials for treating the disorder. When his daughter Jenny was born in 1960 he began to study and to produce her language, emotional, and sensory-motor development. When she was a year and a half old he began teaching her number concepts, and then reading six months later, using his token reinforcer system, as he recorded on audiotape. Films were made in 1966 of Staats being interviewed about his conception of how variations in children’s home learning variously prepared them for school on the first of three Arthur Staats YouTube videos. Following that the second Staats YouTube video records him beginning teaching his three-year-old son with the reading learning (and counting) method he developed in 1962 with his daughter. This film also shows a graduate assistant working with a culturally deprived four-year-old learning reading and writing numbers and counting, participating voluntarily. The Staats YouTube video number 3 has additional cases of these usually delayed children voluntarily learning much ahead of time these cognitive repertoires that prepare them for school. This group of 11 children gained an average of 11 points in IQ and advanced significantly on a child development measure as they also learned to like the learning situation. Staats published the first study in this series in 1962 and describes his later studies and his more general conception in his 1963 book. This research, that included work with his own children from birth on, was the basis for Staats’ books specifying the importance of the parents' early training of the child in language and other cognitive repertoires. He shows they are the foundations for being intelligent and doing well on entering school. There are new studies showing that parents who talk to their children more have children with advanced language development, school success, and intelligence measures. These statistical studies should be joined with Staats’ work with individual children that shows the specifics of the learning involved and how to best produce it. The two together show powerfully the importance of early child learning.\n\nStaats also applied his approach in fathering his own children and employed his findings in constructing conception of human behavior and human nature. He deals with many aspects of child development, from babbling to walking to discipline and time-out, and he considers parents one of his audiences. In the last of his books he summarizes his theory of child development. His position is that children are the young of the human species that has a body that can make an infinity of different behaviors. The human species also has a nervous system and brain of 100 billion neurons that can learn in marvelous complexity. The child’s development consists of the learning of repertoires, extraordinarily complex, like a language-cognitive repertoire, an emotional-motivational repertoire, and a sensory-motor repertoire, each including sub-repertoires of various kinds. The child’s behavior, in the various life situations encountered, depend upon the repertoires that have been learned. The child’s ability to learn in the variety of situations encountered also depends on the repertoires that have been learned. This conception makes parenting central in the child's development, supported by many studies in behavior analysis, and offers knowledge to parents in raising their children.\n\nStaats describes humans great variability in behavior, across different people. Those individual differences are consistent in different life situations and typify people. Those differences also tend to run in families. Such phenomena have led to the concept of personality as some internal trait that is inherited that strongly determines individuals’ characteristic ways of behaving. Personality conceived in that way remains an inference, based on how people behave, but with no evidence of what personality is.\n\nMore successful has been the measurement of personality. There are tests of intelligence for example. No internal organ of intelligence has been found, and no genes either. But intelligence tests have been constructed that predict (helpfully but not perfectly) the performance of children in school. Children who have the behaviors measured on the tests display better learning behaviors in the classroom. Although such tests have been widely applied radical behaviorism has not invested in the study of personality or personality testing.\n\nPsychological behaviorism (e.g.) however considers it important to study what personality is, how personality determines behavior, what causes personality, as well as what personality tests measure. Tests (including intelligence tests) are considered to measure different repertoires of behavior that individuals have learned. The individual in life situations also displays behaviors that have been learned. That is why personality tests can predict how people will behave. That means also that tests can be used to identify important human behaviors, and the learning that produces those behaviors can be studied. Gaining that knowledge will make it possible to develop environmental experiences that produce or prevent types of personality from developing. A study has shown, for example, that in learning to write letters of the alphabet children learn repertoires that make them more intelligent.\n\nPsychological behaviorism’s theory of abnormal personality rejects the concept of mental illness. Rather behavior disorders are composed of learned repertoires of abnormal behavior. Behavior disorders also involve not having learned basic repertoires that are needed in adjusting to life's demands. Severe autism can involve not having learned a language repertoire as well as having learned tantrums and other abnormal repertoires.\n\nPB’s theories of various behavior disorders employ the Diagnostic and Statistical Manual of Mental Disorders (DSM) descriptions of both abnormal repertoires and the absence of normal repertoires. Psychological behaviorism provides the framework for an approach to clinical treatment of behavior disorders, as shown in the field of behavior analysis. PB theory also indicates how behavior disorders can be prevented by preventing the abnormal learning conditions that produce them.\n\nThe PB theory is that child development, besides its physical growth, consists of the learning of repertoires some of which are basic in the sense they provide the behaviors for many life situations and also they determine what and how well the individual can learn. That theory states that humans are unique in having a building type of learning, cumulative learning, in which basic repertoires enable the child to learn other repertoires that enable the learning of other repertoires. Learning language, for example, enables the child to learn various other repertoires, like reading, number concepts, and grammar. Those repertoires provide the bases for learning other repertoires. For example, reading ability, opens the possibilities for an individual to do things and learn things that a non-reader cannot.\n\nWith that theory, and with its empirical methodology, PB applies to education. For example, it has a theory of reading that explains children’s differences, from dyslexia to advanced reading ability. PB also suggests how to treat dyslexic children and those with other learning disabilities. Psychological behaviorism's approach has been supported and advanced in the field of behavior analysis.\n\nHuman origin is generally explained by Darwin’s natural selection; However, while Darwin gathered imposing evidence showing the evolution of physical characteristics of species his view that behavioral characteristics (such as human intelligence) also evolved was pure assumption with no evidentiary support PB presents a different theory, that the cumulative learning of pre-human hominins drove human evolution. That explains the consistent increase in brain size over the course of human evolution. That occurred because the members of the evolving hominin species were continually learning new language, emotion-motivation, and sensory-motor repertoires. That meant the new generations had to learn those ever more complex repertoires. It was cumulative learning that consistently created the selection device for the members of those generations that had the larger brains and were the better learners.\n\nThat theory makes learning ability central in human origin, selecting who would survive and reproduce, until the advent of Homo sapiens where all individuals (except if damaged) have full brains and full learning ability.\n\nPsychological behaviorism is set forth as an overarching theory, constructed of multiple theories in various areas. Staats considers it a unified theory. The areas are related, their principles consistent, and they are advanced consistently, composing levels from basic to increasingly advanced. Its most basic level calls for a systematic study of the biology of the learning “organs” and their evolutionary development, from species like amoeba that have no learning ability to humans that have the most. The basic learning principles constitute another level of theory, as do the human learning principles that specify cumulative learning. How the principles work—in areas like child development, personality, abnormal personality, clinical treatment, education, and human evolution—compose additional levels of study. Staats sees the overarching theory of PB as basic for additional levels that compose the social sciences of sociology, linguistics, political science, anthrology, and paleoanthropology. He criticizes the disunification of the sciences that study human behavior and human nature. Because they are disconnected, they do not build a related, simpler and more understandable conception and scientific endeavor as, for example, the biological sciences do. This philosophy of science of unification is at one with Staats’ attempt to construct his unified psychological behaviorism.\n\nPsychological behaviorism’s works project new basic and applied science at its various theory levels. The basic principles level, as one example, needs to study systematically the relationship of the classical conditioning of emotional responses and the operant conditioning of motor responses. As another projection, the field of child development should focus on the study of the learning of the basic repertoires. One essential is the systematic detailed study of the learning experiences of children in the home from birth on. He says such research could be accomplished by installing cameras in the homes of volunteering, remunerated families. This research should also be done to discover how such learning produces both normal and abnormal personality development. As another example, PB also calls for educational research into how school learning could be advanced using its methods and theories. Also, Staats' theory of human evolution is seen to call for research and theory developments.\n\n"}
{"id": "12623574", "url": "https://en.wikipedia.org/wiki?curid=12623574", "title": "Psychological mindedness", "text": "Psychological mindedness\n\nPsychological mindedness refers to a person's capacity for self-examination, self-reflection, introspection and personal insight. It includes an ability to recognize meanings that underlie overt words and actions, to appreciate emotional nuance and complexity, to recognize the links between past and present, and insight into one's own and others' motives and intentions. Psychologically minded people have above average insight into mental life.\n\nConceptual definitions of psychological mindedness have included variant, but related descriptions. Some definitions relate solely to the self, \"a person's ability to see relationships among thoughts, feelings, and actions with the goal of learning the meanings and causes of his experiences and behaviors\". Conte (1996) extended the concept beyond self-focus, as involving \"... both self-understanding and an interest in the motivation and behavior of others\". Hall's (1992) definition introduces the multidimensional nature of PM. She defined it as \"reflectivity about psychological processes, relationships and meanings [that] is displayed by ... both interest in and ability for such reflectivity across affective and intellectual dimensions\".\n\nThe \"Psychodynamic Diagnostic Manual\" (PDM) describes psychological mindedness as an individual's ability to observe and reflect on his or her own internal life. The PDM details a four-point scale from high to low psychological mindedness, or 'healthy-to-impaired functioning'.\n\n\nPsychological mindedness (PM) is expected to be related to psychological strength and negatively related to weakness. One study found a correlation between PM and two of the Big Five personality traits (extraversion and openness to experience) and a negative correlation with neuroticism. Other studies have linked it to the tolerance of ambiguity, mindfulness, empathy and positive adjustment to college. PM has also been associated negatively with problem-oriented psychological constructs such as the personality factor of neuroticism, the cognitive constructs of magical thinking and external locus of control, and early maladaptive schemas. Low PM has also been linked to alexithymia, suggesting that certain clinical patients do not respond to counseling due to a lack of PM.\n\nIn the UK a lot of work has been done to extend the concept of psychological mindedness beyond the individual. This work recognises that the health and success of families, schools, hospitals, businesses, communities and indeed society as a whole depends in a large part on the psychological mindedness of the system or environment created by that institution. This is more than the sum of the individual parts. For example, an individual nurse on a psychiatric ward may be psychologically minded and motivated to connect with a service user who may also have some psychological mindedness. However, the chances of two such individuals having a psychologically minded encounter can easily be sabotaged by a \"psychologically blind\" or \"alexithymic\" care system that allows the nurse no time, no headspace, no structure and no back up to function in this way. It is well known that nurses on chaotic psychiatric wards have to shut off emotionally just to survive personally in the face of the overwhelming demands placed upon them. Once this happens the experience for the service user will obviously become one of \"not being listened to\". This real emotional neglect coupled with transference factors is what leads to so many incidents on our psychiatric wards. Service users who feel rejected are bound to escalate their behaviour in order to be heard and in order to \"hit back\" at those who are in effect just repeating the failures of past caregivers.\n\nMartin Seager (2006) developed the concept of \"psychological safety\" to explain and address these kinds of problems in health care systems. Out of this work, Martin was invited by the then secretary of state for health, Patricia Hewitt, to form in 2007 a \"national advisory group\" on the universal psychological principles and standards underpinning good mental health care. Martin was able to convene a group of distinguished thinkers from the full range of psychological approaches to produce a guiding document. Group members included Susie Orbach, Andrew Samuels, Lucy Johnstone and Valerie Sinason. The core recommendations of this group took account of all psychological theory and spiritual factors in the human condition. \"Psychological mindedness\" was the concept and the phrase that seemed to bind everything together. This work has led to the formation of a further national working group (2008) on the back of the Improving Access to Psychological Therapies (IAPT) initiative in the UK. This new working group is looking at \"10 high impact changes\" for mental health policy in the UK that will increase psychological mindedness. The group aims to stimulate a proactive public health psychological policy that will address the relational and environmental causes of mental health problems and shift the emphasis away from an exclusive focus on reactive psychological treatments. It was found that females tend to be more psychologically minded than males.\n\n"}
{"id": "385886", "url": "https://en.wikipedia.org/wiki?curid=385886", "title": "Random ballot", "text": "Random ballot\n\nThe random ballot, single stochastic vote, or lottery voting is an electoral system in which an election is decided on the basis of a single randomly selected ballot. Whilst appearing superficially chaotic, the system has the potential to retain the most attractive characteristics of both first past the post and proportional representation systems in elections to multi-constituency bodies. It was first described in 1984 by Akhil Reed Amar.\n\nIn an election or referendum, the ballot of a single voter is selected at random, and that ballot decides the result of the election. In this way, each candidate or option wins with a probability exactly equal to the fraction of the electorate favouring that candidate or option.\n\nThe random ballot method is decisive, in that there is no possibility of a tied vote, assuming that the selected voter has expressed a preference (if not then another ballot can be selected at random). It is unbiased, in that the probability of a particular result is equal to the proportion of total support that that result has in all the votes. When used in a single-winner contest, it is also strategy-free, in that there is no advantage in tactical voting. But it is not deterministic, in that a different random selection could have produced a different result, and it does not conform to majority rule since there is a possibility that the selected voter may be in the minority.\n\nIf the random ballot is used to select the members of a multi-constituency body, it can serve to retain the attractive features of both first past the post and proportional representation.\n\nAs the winner of each ballot is chosen randomly, the party with the largest vote share is most likely to get the greatest number of candidates. In fact, as the number of ballots grows, the percentage representation of each party in the elected body will get closer and closer to their actual proportion of the vote across the entire electorate. At the same time, the chance of a randomly selected highly unrepresentative body diminishes.\n\nFor example, a minority party with 1% of the vote might have a 1/100 chance of getting a seat in each ballot. In a 50-person assembly, the probability of a majority for this party being chosen by random ballot is approximately (using the binomial distribution CDF)\n\nor one in hundred undecillion. This is a vanishingly small chance, which negates the possibility of small parties winning majorities due to random chance.\n\nAt same time, the random ballot preserves a local representative for each constituency, although this individual may not have received a majority of votes of his or her constituents.\n\nThere are no examples of the random ballot in use in practice, but as a thought experiment, it has been used to explain some of the properties of other electoral systems, and it is occasionally used in real life as a tiebreaker for other methods.\n\nA related system was hypothesized by Isaac Asimov in his short story \"Franchise\" (1955: reprinted in \"Earth Is Room Enough\", Doubleday, 1957), where a single voter is chosen to decide each election. However, in Asimov's thought-experiment, the \"elector\" is not randomly selected, but chosen by computer to be as representative as possible of the populace at large. Asimov intended this story as a parody of opinion polling.\n\nThere is an element of randomness (other than tie-breaking) in some existing electoral systems, in two ways:\n\n\nA random ballot elects a representative by choosing a ballot at random; sortition is similar but elects individuals directly by lot, as if each ballot involved individuals voting for themselves.\n"}
{"id": "3056665", "url": "https://en.wikipedia.org/wiki?curid=3056665", "title": "Saṃbhogakāya", "text": "Saṃbhogakāya\n\nThe Saṃbhogakāya (Sanskrit: \"body of enjoyment\", Tib: \"longs spyod rdzog pa'i sku\") is the second mode or aspect of the Trikaya.\n\nThe Sambhogakaya is a \"subtle body of limitless form\". Both \"celestial\" Buddhas such as Bhaisajyaguru and Amitābha, as well as advanced bodhisattvas such as Avalokiteśvara and Manjusri can appear in an \"enjoyment-body.\" A Buddha can appear in an \"enjoyment-body\" to teach bodhisattvas through visionary experiences.\n\nThose Buddhas and Bodhisattvas manifest themselves in their specific pure lands. These worlds are created for the benefits of others. In those lands it is easy to hear and practice the Dharma. A person can be reborn in such a pure land by \"the transfer of some of the huge stock of 'merit' of a Land's presiding Buddha, stimulated by devout prayer.\n\nOne of the places where the Sambhogakāya body appears is the extra-cosmic realm or pure land called Akaniṣṭha. This is one of the highest realms of the Śuddhāvāsa devas.\n\nAbsolutely seen, only the Dharmakāya is real; the Sambhogakāya and Nirmanakaya are \"provisional ways of talking about and apprehending it\".\n\nSambhogakaya also refers to the luminous form of clear light the Buddhist practitioner attains upon the reaching the highest dimensions of practice.\n\nAccording to tradition, those skilled in meditation, such as advanced Tibetan lamas and yogis, as well as other highly realized Buddhists, may gain access to the Sambhogakaya and receive direct transmission of doctrine.\n\nThere are numerous Sambhogakāya realms almost as numerous as deities in Tibetan Buddhism. These Sambhogakaya-realms are known as Buddha-fields or Pure Lands.\n\nOne manifestation of the Sambhogakaya in Tibetan Buddhism is the rainbow body. This is where an advanced practitioner is walled up in a cave or sewn inside a small yurt-like tent shortly before death. For a period of a week or so after death, the practitioners' body transforms into a Sambhogakaya light body, leaving behind only hair and nails.\n\nLopön Tenzin Namdak as rendered by John Myrdhin Reynolds conveyed the relationship of the mindstream (Sanskrit: \"citta santana\") of Sambhogakaya that links the Dharmakaya with the Nirmanakaya.\n\nIn the Chán (禪) (Jp. Zen) tradition, the Sambhogakāya (Chin. 報身↔\"baoshen\", lit. \"retribution body\"), along with the Dharmakaya and the Nirmanakaya, are given metaphorical interpretations.\n\nIn the \"Platform Sutra of the Sixth Patriarch\", Chan Master Huineng describes the Samboghakaya as a state in which the practitioner continually and naturally produces good thoughts:\n\n"}
{"id": "948900", "url": "https://en.wikipedia.org/wiki?curid=948900", "title": "Sensorium", "text": "Sensorium\n\nA sensorium (/sɛnˈsɔːrɪəm/) (plural: sensoria) is the sum of an organism's perception, the \"seat of \" where it experiences and interprets the environments within which it lives. The term originally entered English from the Late Latin in the mid-17th century, from the stem \"sens-\" (\"sense\"). In earlier use it referred, in a broader sense, to the brain as the mind's organ (\"Oxford English Dictionary\" 1989). In medical, psychological, and physiological discourse it has come to refer to the total character of the unique and changing sensory environments perceived by individuals. These include the sensation, perception, and interpretation of information about the world around us by using faculties of the mind such as senses, phenomenal and psychological perception, cognition, and intelligence.\n\nIn the 20th century the sensorium became a key part of the theories of Marshall McLuhan, Edmund Carpenter and Walter J. Ong (Carpenter and McLuhan 1960; Ong 1991).\n\nMcLuhan, like his mentor Harold Innis, believed that media were biased according to time and space. He paid particular attention to what he called the sensorium, or the \"effects\" of media on our senses, positing that media affect us by manipulating the ratio of our senses. For example, the alphabet stresses the sense of sight, which in turn causes us to think in linear, objective terms. The medium of the alphabet thus has the effect of reshaping the way in which we, collectively and individually, perceive and understand our environment in what has been termed the Alphabet Effect.\n\nFocusing on variations in the sensorium across social contexts, these theorists collectively suggest that the world is explained and experienced differently depending on the specific \"ratios of sense\" that members of a culture share in the sensoria they learn to inhabit (Howes 1991, p. 8). More recent work has demonstrated that individuals may include in their unique sensoria perceptual proclivities that exceed their cultural norms; even when, as in the history of smell in the West, the sense in question is suppressed or mostly ignored (Classen, Howes and Synnott 1994).\n\nThis interplay of various ways of conceiving the world could be compared to the experience of synesthesia, where stimulus of one sense causes a perception by another, seemingly unrelated sense, as in musicians who can taste the intervals between notes they hear (Beeli \"et al\"., 2005), or artists who can smell colors. Many individuals who have one or more senses restricted or lost develop a sensorium with a ratio of sense which favors those they possess more fully. Frequently the blind or deaf speak of a compensating effect, whereby their sense of touch or smell becomes more acute, changing the way they perceive and reason about the world; especially telling examples are found in the cases of \"wild children\", whose early childhoods were spent in abusive, neglected, or non-human environments, both intensifying and minimizing perceptual abilities (Classen 1991).\n\nAlthough some consider these modalities abnormal, it is more likely that these examples demonstrate the contextual and socially learned nature of sensation. A 'normal' sensorium and a 'synesthetic' one differ based on the division, connection, and interplay of the body's manifold sensory apparatus. A synesthete has simply developed a different set of relationships, including cognitive or interpretive skills which deliver unique abilities and understanding of the world (Beeli et al., 2005). The sensorium is a creation of the physical, biological, social and cultural environments of the individual organism and its relationships while being in the world.\n\nWhat is considered a strange blurring of sensation from one perspective, is a normal and 'natural' way of perception of the world in another, and indeed many individuals and their cultures develop sensoria fundamentally different from the vision-centric modality of most Western science and culture. One revealing contrast is the thought of a former Russian on the matter:\n\nAs David Howes explains:\n\nThese sorts of insights were the impetus for the development of the burgeoning field of sensory anthropology, which seeks to understand other cultures from within their own unique sensoria. Anthropologists such as Paul Stoller (1989) and Michael Jackson (1983, 1989) have focused on a critique of the hegemony of vision and textuality in the social sciences. They argue for an understanding and analysis that is embodied, one sensitive to the unique context of sensation of those one wishes to understand. They believe that a thorough awareness and adoption of other sensoria is a key requirement if ethnography is to approach true understanding.\n\nA related area of study is sensory (or perceptual) ecology. This field aims at understanding the unique sensory and interpretive systems all organisms develop, based on the specific ecological environments they live in, experience and adapt to. A key researcher in this field has been psychologist James J. Gibson, who has written numerous seminal volumes considering the senses in terms of holistic, self-contained perceptual systems. These exhibit their own mindful, interpretive behaviour, rather than acting simply as conduits delivering information for cognitive processing, as in more representational philosophies of perception or theories of psychology (1966, 1979). Perceptual systems detect affordances in objects in the world, directing attention towards information about an object in terms of the possible uses it affords an organism.\n\nThe individual sensory systems of the body are only parts of these broader perceptual ecologies, which include the physical apparatus of sensation, the environment being sensed, as well as both learned and innate systems for directing attention and interpreting the results. These systems represent and enact the information (as an influence which leads to a transformation) required to perceive, identify or reason about the world, and are distributed across the very design and structures of the body, in relation to the physical environment, as well as in the concepts and interpretations of the mind. This information varies according to species, physical environment, and the context of information in the social and cultural systems of perception, which also change over time and space, and as an individual learns through living. Any single perceptual modality may include or overlap multiple sensory structures, as well as other modes of perception, and the sum of their relations and the ratio of mixture and importance comprise a sensorium. The perception, understanding, and reasoning of an organism is dependent on the particular experience of the world delivered by changing ratios of sense.\n\nA clouded sensorium, also known as an altered sensorium, is a medical condition characterized by the inability to think clearly or concentrate. It is usually synonymous with, or substantially overlapping with, altered level of consciousness. It is associated with a huge variety of underlying causes from drug induced states to pathogenic states induced by disease or mineral deficiency.\n\n\n"}
{"id": "1049691", "url": "https://en.wikipedia.org/wiki?curid=1049691", "title": "Sequence logo", "text": "Sequence logo\n\nIn bioinformatics, a sequence logo is a graphical representation of the sequence conservation of nucleotides (in a strand of DNA/RNA) or amino acids (in protein sequences).\nA sequence logo is created from a collection of aligned sequences and depicts the consensus sequence and diversity of the sequences.\nSequence logos are frequently used to depict sequence characteristics such as protein-binding sites in DNA or functional units in proteins.\n\nA sequence logo consists of a stack of letters at each position. \nThe relative sizes of the letters indicate their frequency in the sequences. \nThe total height of the letters depicts the information content of the position, in bits.\n\nTo create sequence logos, related DNA, RNA or protein sequences, or DNA sequences that have common conserved binding sites, are aligned so that the most conserved parts create good alignments. A sequence logo can then be created from the conserved multiple sequence alignment. The sequence logo will show how well residues are conserved at each position: the higher the number of residues, the higher the letters will be, because the better the conservation is at that position. Different residues at the same position are scaled according to their frequency. The height of the entire stack of residues is the information measured in bits. Sequence logos can be used to represent conserved DNA binding sites, where transcription factors bind.\n\nThe information content (y-axis) of position formula_1 is given by:\n\nwhere formula_4 is the uncertainty\n(sometimes called the Shannon entropy) of position formula_1\n\nHere, formula_7 is the relative frequency of base or amino acid formula_8 at position formula_1, and formula_10 is the small-sample correction for an alignment of formula_11 letters. The height of letter formula_12 in column formula_1 is given by\n\nThe approximation for the small-sample correction, formula_10, is given by:\n\nwhere formula_17 is 4 for nucleotides, 20 for amino acids, and formula_11 is the number of sequences in the alignment.\n\nA consensus logo is a simplified variation of a sequence logo that can be embedded in text format.\nLike a sequence logo, a consensus logo is created from a collection of aligned protein or DNA/RNA sequences and conveys information about the conservation of each position of a sequence motif or sequence alignment\n. However, a consensus logo displays only conservation information, and not explicitly the frequency information of each nucleotide or amino acid at each position. Instead of a stack made of several characters, denoting the relative frequency of each character, the consensus logo depicts the degree of conservation of each position using the height of the consensus character at that position.\n\nThe main, and obvious, advantage of consensus logos over sequence logos is their ability to be embedded as text in any Rich Text Format supporting editor/viewer and, therefore, in scientific manuscripts. As described above, the consensus logo is a cross between sequence logos and consensus sequences. As a result, compared to a sequence logo, the consensus logo omits information (the relative contribution of each character to the conservation of that position in the motif/alignment). Hence, a sequence logo should be used preferentially whenever possible. That being said, the need to include graphic figures in order to display sequence logos has perpetuated the use of consensus sequences in scientific manuscripts, even though they fail to convey information on both conservation and frequency. Consensus logos represent therefore an improvement over consensus sequences whenever motif/alignment information has to be constrained to text.\n\n\n\n"}
{"id": "3636584", "url": "https://en.wikipedia.org/wiki?curid=3636584", "title": "State of affairs (sociology)", "text": "State of affairs (sociology)\n\nThe state of affairs is the combination of circumstances applying within a society or group at a particular time. The current state of affairs may be considered acceptable by many observers, but not necessarily by all. The state of affairs may present a challenge, or be complicated, or contain a conflict of interest. The status quo represents the existing state of affairs. Unresolved difficulties or disagreements concerning the state of affairs can provoke a crisis. Dispute resolution is naturally desired, and naturally provided, by forms of inclusive social interaction, such as consensus decision-making, which adapt, but not conveniently, from a family or tribal model to encompass a global scope.\nCurrent knowledge and discussion about the state of affairs is communicated through the media.\n\n\n"}
{"id": "804702", "url": "https://en.wikipedia.org/wiki?curid=804702", "title": "Status quo bias", "text": "Status quo bias\n\nStatus quo bias is an emotional bias; a preference for the current state of affairs. The current baseline (or status quo) is taken as a reference point, and any change from that baseline is perceived as a loss.\nStatus quo bias should be distinguished from a rational preference for the status quo ante, as when the current state of affairs is objectively superior to the available alternatives, or when imperfect information is a significant problem. A large body of evidence, however, shows that status quo bias frequently affects human decision-making.\n\nStatus quo bias interacts with other non-rational cognitive processes such as loss aversion, existence bias, endowment effect, longevity, mere exposure, and regret avoidance. Experimental evidence for the detection of status quo bias is seen through the use of the reversal test. A vast amount of experimental and field examples exist. Behaviour in regard to retirement plans, health, and ethical choices show evidence of the status quo bias.\n\nKahneman, Thaler, and Knetsch created experiments that could produce this effect reliably. Samuelson and Zeckhauser (1988) demonstrated status quo bias using a questionnaire in which subjects faced a series of decision problems, which were alternately framed to be with and without a pre-existing status quo position. Subjects tended to remain with the status quo when such a position was offered to them.\n\nHypothetical Choice Tasks:\nSubjects were given a hypothetical\nchoice task in the following \"neutral\" version, in which no status\nquo was defined: \"You are a serious reader of the financial pages\nbut until recently you have had few funds to invest. That is when\nyou inherited a large sum of money from your great-uncle. You are\nconsidering different portfolios. Your choices are to invest in: a\nmoderate-risk company, a high-risk company, treasury bills, municipal\nbonds.\" Other subjects were presented with the same problem\nbut with one of the options designated as the status quo. In this\ncase, the opening passage continued: \"A significant portion of this\nportfolio is invested in a moderate risk company . . . (The tax and broker commission consequences of any changes are insignificant.)\"\nThe result was that an alternative became much more popular\nwhen it was designated as the status quo.\n\nElectric Power Consumers:\nCalifornia electric power consumers were\nasked about their preferences regarding trade-offs between service\nreliability and rates. The respondents fell into two groups, one with\nmuch more reliable service than the other. Each group was asked\nto state a preference among six combinations of reliability and rates,\nwith one of the combinations designated as the status quo. A strong\nbias to the status quo was observed. Of those in the high-reliability\ngroup, 60.2 percent chose the status quo, whereas a mere 5.7 percent\nchose the low-reliability option that the other group had been\nexperiencing, despite its lower rates. Similarly, of those in the low reliability\ngroup, 58.3 chose their low-reliability status quo, and only\n5.8 chose the high-reliability option.\n\nAutomotive Insurance Consumers and Other Examples:\nThe US states of New Jersey and Pennsylvania inadvertently ran a real-life experiment providing evidence of status quo bias in the early 1990s. As part of tort law reform programs, citizens were offered two options for their automotive insurance: an expensive option giving them full right to sue and a less expensive option with restricted rights to sue. In New Jersey the cheaper option was the default and most citizens selected it. Only a minority chose the cheaper option in Pennsylvania, where the more expensive option was the default. Similar effects have been shown for contributions to retirement plans, choice of internet privacy policies and the decision to become an organ donor.\n\nStatus quo bias has been attributed to a combination of loss aversion and the endowment effect, two ideas relevant to prospect theory. An individual weighs the potential losses of switching from the status quo more heavily than the potential gains; this is due to the prospect theory value function being steeper in the loss domain. As a result, the individual will prefer not to switch at all. In other words, we tend to oppose change unless the benefits outweigh the risks. However, the status quo bias is maintained even in the absence of gain/loss framing: for example, when subjects were asked to choose the colour of their new car, they tended towards one colour arbitrarily framed as the status quo. Loss aversion, therefore, cannot wholly explain the status quo bias, with other potential causes including regret avoidance, transaction costs and psychological commitment.\n\nA status quo bias can also be a rational route if there are cognitive or informational limitations.\n\nDecision outcomes are rarely certain, nor is the utility they may bring. Because some errors are more costly than others (Haselton & Nettle, 2006), sticking with what worked in the past is a safe option, as long as previous decisions are \"good enough\".\n\nChoice is often difficult, and decision makers may prefer to do nothing and/or to maintain their current course of action because it is easier.\nStatus quo alternatives often require less mental effort to maintain.\n\nThe irrational maintenance of the status quo bias links and confounds many cognitive biases.\n\nAn assumption of longevity and goodness are part of the status quo bias. People treat existence as a prima facie case for goodness, aesthetic and longevity increases this preference.\nThe status quo bias affects people's preferences; people report preferences for what they are likely rather than unlikely to receive. People simply assume, with little reason or deliberation, the goodness of existing\nstates.\n\nLongevity is a corollary of the existence bias: if existence is good, longer existence should be better. This thinking resembles quasi-evolutionary notions of \"survival of the fittest\", and also the augmentation principle in attribution theory.\n\nInertia is another reason used to explain a bias towards the status quo. Another explanation is fear of regret in making a wrong decision, i.e. If we choose a partner, when we think there could be someone better out there.\n\nMere exposure is an explanation for the status quo bias. Existing states are encountered more frequently than non-existent states and because of this they will be perceived as more true and evaluated more preferably.\nOne way to increase liking for something is repeated exposure over time.\n\nLoss aversion also leads to greater regret for action than for inaction; more\nregret is experienced when a decision changes the status quo than when it maintains it. Together these forces provide an advantage for the status quo; people are motivated to do nothing or to maintain current or previous decisions. Change is avoided, and decision makers stick with what has been done in the past.\n\nChanges from the status quo will typically involve both gains and losses, with the change having good overall consequences if the gains outweigh these losses. A tendency to overemphasize the avoidance of losses will thus favour retaining the status quo, resulting in a status quo bias. Even though choosing the status quo may entail forfeiting certain positive consequences, when these are represented as forfeited \"gains\" they are psychologically given less weight than the \"losses\" that would be incurred if the status quo were changed.\n\nOmission bias may account for some of the findings previously ascribed to status quo bias.\nOmission bias is diagnosed when a decision maker prefers a harmful outcome that results from an omission to a less harmful outcome that results from an action.\n\nThe Reversal Test: When a proposal to change a certain parameter is thought to have bad overall consequences, consider a change to the same parameter in the opposite direction. If this is also thought to have bad overall consequences, then the onus is on those who reach these conclusions to explain why our position cannot be improved through changes to this parameter. If they are unable to do so, then we have reason to suspect that they suffer from status quo bias. The rationale of the Reversal Test is: if a continuous parameter admits of a wide range of possible values, only a tiny subset of which can be local optima, then it is prima facie implausible that the actual value of that parameter should just happen to be at one of these rare local optima.\n\nA study found that erroneous status quo rejections have a greater neural impact than erroneous status quo acceptances. This asymmetry in the genesis of regret might drive the status quo bias on subsequent decisions.\n\nA study was done using a visual detection task in which subjects tended to favour the default when making difficult, but not easy, decisions. This bias was suboptimal in that more errors were made when the default was accepted. A selective increase in sub-thalamic nucleus (STN) activity was found when the status quo was rejected in the face of heightened decision difficulty. Analysis of effective connectivity showed that inferior frontal cortex, a region more active for difficult decisions, exerted an enhanced modulatory influence on the STN during switches away from the status quo.\n\nResearch by University College London scientists that examines the neural pathways involved in 'status quo bias' in the human brain and found that the more difficult the decision we face, the more likely we are not to act.\nThe study, published in \"Proceedings of the National Academy of Sciences\" (PNAS), looked at the decision-making of participants taking part in a tennis 'line judgement' game while their brains were scanned using functional MRI (fMRI).\nThe 16 study participants were asked to look at a cross between two tramlines on a screen while holding down a 'default' key. They then saw a ball land in the court and had to make a decision as to whether it was in or out. On each trial, the computer signalled which was the current default option – 'in' or 'out'. The participants continued to hold down the key to accept the default and had to release it and change to another key to reject the default.\nThe results showed a consistent bias towards the default, which led to errors. As the task became more difficult, the bias became even more pronounced. The fMRI scans showed that a region of the brain known as the sub-thalamic nucleus (STN) was more active in the cases when the default was rejected. Also, greater flow of information was seen from a separate region sensitive to difficulty (the prefrontal cortex) to the STN. This indicates that the STN plays a key role in overcoming status quo bias when the decision is difficult.\n\nAgainst this background, two behavioral economists devised an opt-out plan to help employees of a particular company build their retirement savings. In an opt-out plan, the employees are automatically enrolled unless they explicitly ask to be excluded. They found evidence for status quo bias and other associated effects. They also noted that changing the default alternatives has, in some instances, been shown to have dramatic effects on people’s choices.\n\nStatus-quo educational bias can be both a barrier to political progress and a threat to the state's legitimacy and argue that the values of stability, compliance, and patriotism underpin important reasons for status quo bias that appeal not to the substantive merits of existing institutions but merely to the fact that those institutions are the status quo.\n\nThe Status quo bias is seen in important real life decisions; it has been found to be prominent is data on selections of health care plans and retirement programs.\n\nSome believe that preference for the status quo represents a core component of conservative ideology in societies where government power is limited and laws restricting actions of individuals exist. Conversely, in socialist and liberal societies, movements to impose restrictions on individuals or governments are met with widespread opposition by those that favor the status quo. Reardless of the type of society, the bias tends to hinder progressive movements in the absence of a reaction or backlash against the powers that be.\n\nStatus quo bias may be responsible for much of the opposition to human enhancement in general and to genetic cognitive enhancement in particular. Some ethicists argue, however, that status quo bias may not be irrational in such cases. The rationality of status quo bias is also an important question in the ethics of disability.\n\nEducation can (sometimes unintentionally) encourage children’s belief in the substantive merits of a particular existing law or political institution, where the effect does not derive from an improvement in their ability or critical thinking about that law or institution. However, this biasing effect is not automatically illegitimate or counterproductive: a balance between social inculcation and openness needs to be maintained.\n\nIn elementary schools, reading aloud sessions that exclude ethnically diverse materials create a bias in favor of the status quo that is harmful to children's education.\n\nAn experiment to determine if status-quo bias—bias toward current medication even when better alternatives are offered—exists in a stated-choice study among asthma patients who take prescription combination maintenance medications.\nThe results of this study indicate that the status quo bias may exist in stated-choice studies, especially with medications that patients have to take daily such as asthma maintenance medications. Stated-choice practitioners should include a current medication in choice surveys to control for this bias.\n\nAn example of the status quo bias affecting retirement plans is a study done that examined the U.S. equity mutual fund. They found that people maintained the plan they had previously, even if it was no longer the optimal choice.\n\n\n"}
{"id": "37808477", "url": "https://en.wikipedia.org/wiki?curid=37808477", "title": "The Irascibles", "text": "The Irascibles\n\nThe Irascibles or Irascible 18 were the labels given to a group of American abstract artists who put name to an open letter, written in 1950, to the president of The Metropolitan Museum of Art, rejecting the museum's exhibition \"American Painting Today - 1950\" and boycotting the accompanying competition. The subsequent media coverage of the protest and a now iconic group photograph, that appeared in \"Life\" magazine, gave them notoriety, popularised the term Abstract Expressionist and established them as the so-called first generation of the putative movement.\n\nThe emergence of abstract art coincided with the invention of Cubism in Paris in the first decade of the 20th Century. Paris remained the centre of gravity for later art movements like Futurism, Purism, Vorticism, Cubo-Futurism, Dada, Constructivism and Surrealism until the outbreak of World War II and the Nazi persecution of \"degenerate art\", which precipitated a mass migration of artists and performers to the United States. New York became home to the transplanted avant-garde.\n\nThe early 1940s was of particular importance in American art as American scene painting (Regionalism) came to be seen as an inadequate mode of artistic expression in a tumultuous time. In 1942, Peggy Guggenheim, who had fled Europe with her husband, Surrealist artist Max Ernst, opened her gallery Art of This Century, showing European and promising American avant-garde artists. Jackson Pollock had his first one-man show there in 1943 and, in 1945, Guggenheim showed Mark Rothko.\n\nWhen Guggenheim closed her gallery in 1947 to move to Venice, artists like Pollock had to find new representation. The Betty Parsons Gallery, which opened the previous year, began representing Pollock, Barnett Newman, Mark Rothko and Clyfford Still. Parsons was already representing Adolph Gottlieb, Hedda Sterne and Theodoros Stamos. It was while Pollock showed at Parsons' gallery that he started making his iconic drip-paintings in 1947. It was also here that Barnett Newman exhibited his first breakthrough works in 1950. Rothko, who had arrived at his distinctive mural sized paintings in 1947, first exhibited them at the Parsons Gallery.\n\nAt the time, the only galleries who were prepared to show the so-called New York School (Robert Motherwell's term) were Parsons Gallery, the Samuel Kootz Gallery and the Charles Egan Gallery. To these fledgling galleries it was a financial disaster. The highest price paid for a Pollock, before 1947, was $740 and Rothko had peaked with the sale of a $120 painting in 1946. At the Kootz Gallery, from 1946 to 1948, Hans Hoffman, William Baziotes and Robert Motherwell were offered at between $100 and $950, likely fetching much lower actual sales prices. Kootz closed in 1948 as a result of the financial strain. The critical and financial success of the group would only come after a series of popularising articles in \"Life\" magazine, most notably a feature on Jackson Pollock in 1949 and the Irascibles article and photograph of 1951.\n\nSince January 1943 an agreement existed between the Whitney Museum of American Art and the Metropolitan Museum of Art on a coalition which would culminate in the combining of their collections of American art in a new building, paid for from the endowment of Gertrude Vanderbilt Whitney. By this unwritten agreement, the Whitney acquired American art while the Metropolitan concentrated their acquisitions on what they termed \"classic\" art.\n\nJuliana Force, the Whitney's director since 1931 until her death on August 28, 1948, harboured grave concerns and advocated the abandonment of the coalition. On October 1, 1948, the Whitney trustees cited \"serious divergences\" especially with regard to the showing of advanced trends in art, something the Whitney made a special point of doing. They unilaterally withdrew the Whitney from the coalition.\n\nOn December 6, 1948, the Met announced it would form its own Department of American Art, which it did on January 1, 1949. Robert Beverly Hale was appointed as Associate Curator of American Painting and Sculpture and head of the department. A Trustees' Committee on American Art was set up to advise the Associate Curator. The members of this committee were Elihu Root, Jr., Chairman, Walter C. Baker, and Sam A. Lewisohn. Lewisohn, although a highly respected collector of Impressionists, was noted for calling avant-garde abstract art \"unhuman\".\n\nIn July 1949, Roland J. McKinney, formerly Director of the Baltimore Museum of Art and of the Los Angeles County Museum of Art, was appointed as a consultant. On his advice, it was decided The Met would host a series of open national competitive exhibitions with five regional juries. The first of these, \"American Painting Today - 1950\", was announced as part of a statement of policy on January 1, 1950.\n\nThe five regional juries, meeting respectively in Santa Barbara, Dallas, Chicago, Richmond and New York would make selections, which would be submitted to a National Jury, composed of five regional jurors and two jurors appointment by the Metropolitan.\n\nIn 1948, William Baziotes, David Hare, Robert Motherwell and Mark Rothko founded the Subjects of the Artist School, which held artists' discussions in a loft at 35 East Eighth Street, Manhattan which came to be known as Studio 35. A closed panel symposium took place from April 21 to 23, 1950. It was organised by Robert Goodnough and moderated by Richard Lippold, Robert Motherwell and Alfred H. Barr, Jr. director of the Museum of Modern Art (MoMA). The purpose was the framing of an art movement.\n\nAt the end of the closed session it was suggested by Adolph Gottlieb that the assembled artists protest the conservative bias of the jury for the upcoming competition at the Metropolitan.\n\nGottlieb spent the better part of three weeks drafting an open letter to the president of the Metropolitan, conferring with Ad Reinhardt and Barnett Newman while soliciting consensus among other artists by mail or phone. The final version was sent to the individual artists to sign; 28 doing so. Newman called Jackson Pollock from Gottlieb's apartment in Brooklyn, asking him to come into the city immediately to sign the letter. Pollock sent a telegram instead:\nThe letter was underwritten by Jimmy Ernst, Adolph Gottlieb, Robert Motherwell, William Baziotes, Hans Hofmann, Barnett Newman, Clyfford Still, Richard Pousette-Dart, Theodoros Stamos, Ad Reinhardt, Jackson Pollock, Mark Rothko, Bradley Walker Tomlin, Willem de Kooning, Hedda Sterne, James Brooks, Weldon Kees and Fritz Bultman. The supporting sculptors were Herbert Ferber, David Smith, Ibram Lassaw, Mary Callery, Day Schnabel, Seymour Lipton, Peter Grippe, Theodore Roszak, David Hare and Louise Bourgeois.\n\nOn Sunday May 21, 1950, Barnett Newman took the signed statement to the city editor of the \"New York Times\". Newman had run for mayor of New York as a write-in candidate in 1933 and knew Monday to be a slow news day at the \"Times\". The statement, entitled OPEN LETTER TO ROLAND L. REDMOND, dated May 20, appeared on the front page of the \"Times\" of May 22.\n\nNewman told the \"Times\" that they were critical of the membership of the five regional juries and especially opposed to the New York jury, the National Jury of Selection and the Jury of Awards. The New York jurors were Charles Burchfield, Yasuo Kuniyoshi, Leon Kroll, Ogden Pleissner, Vaclav Vytlacil and Paul Sample. The national jury consisted of Robert Beverly Hale, Ogden Pleissner, Maurice Sterne, Millard Sheets, Howard Cook, Lamar Dodd, Francis Chapin, Zoltan Sepeshy and Esther Williams. The jury of awards included William M. Milliken, Franklin C. Watkins and Eugene Speicher.\n\nThe first response to the letter came on the editorial page of \"The Herald Tribune\" of May 23, 1950. The editorial attacked the artists for \"distortion of fact\" in claiming the Metropolitan had \"contempt\" for modern painting. \"The Herald Tribune's\" art critic at the time was Emily Genauer. It was widely assumed that she had written the editorial, which gave name to the group.\n\nGottlieb, aided by Newman and Reinhardt, drafted a rebuttal, which was signed by 12 painters and three sculptors, and addressed to the editor of the \"Tribune\". It was never published. Weldon Kees discussed the issue of the open letter further in the June 5 edition of \"The Nation\", calling director of the Metropolitan Museum of Art, Francis Henry Taylor a philistine. Two days later \"Time\" magazine noted the protest in an article entitled \"The Revolt of the Pelicans\", an oblique reference to Taylor's 1948 comments in the \"Atlantic Monthly\".\nAlfred Barr, seeking to distinguish the MoMA, further electrified the situation by selecting Arshile Gorky, Willem de Kooning and Jackson Pollock for the American pavilion of the 25th Venice Biennale, held from June to October 1950. In the June 1950 issue of \"ARTnews\", he referred to the painters as \"leaders\" of a \"predominant vanguard\". Barr's act signalled to the art world that abstract expressionism should be given serious consideration by museums.\n\nOn July 3, 1950, a group of 75 artists issued a statement via an open letter to the president of the Met, defending the museum. Signers included Milton Avery, Will Barnet, Philip Evergood, Xavier Gonzalez, George Grosz, Henry Koerner, Reginald Marsh, Waldo Peirce, Manfred Schwartz and Harry Sternberg.\n\n\"Life\" magazine decided to publish a photo story for their January 15, 1951 edition, which would document the results of the competition and feature a photograph of the protesters. \"Life\" initially wanted to photograph the painters on the steps of the \"Metropolitan\", with their paintings. They refused on the grounds that it would look like they were trying to enter the museum, but were being rebuffed. The magazine capitulated; art editor for \"Life\", Dorothy Seiberling, sent photographer Nina Leen to photograph them at a studio on 44th Street. They assembled there on November 24. Only three of the original signatories were absent: Weldon Kees, Hans Hofmann, and Fritz Bultman. Pollock made a special trip with James Brooks for the session.\n\nNina Leen took twelve pictures, of which one appeared in \"Life\". Barnett Newman had insisted that the group be photographed \"like bankers\". The artists were allowed to position themselves. Hedda Sterne, who had arrived late, is seen in the back (standing on a table). She is the only woman in the photograph and would later describe the experience as \"probably the worst thing that happened to me\". Painter Lee Krasner believed Sterne was allowed at the insistence of art dealer Betty Parsons, who represented many in the group.\nThe caption to the published photograph referred to the group as \"solemn\". It was true that many of the group had reservations at appearing in a mainstream media publication; Rothko especially. Yet none could have mistaken the consequences of Pollock's three-page spread in \"Life\" of August 8, 1949. Pollock's next show, opening November 21, 1949, at \"Betty Parsons Gallery\", was an unmistakable triumph. Famously, Willem de Kooning was heard to say to Milton Resnick: \"Look around. These are the big shots. Jackson has finally broken the ice.\" In the ensuing year, Betty Parsons sent Pollock checks totalling $6,508.23 on gross sales of over $10,000, at a time when more than two thirds of American families lived on less than $4,000 per year. Pollock seems to have been invited to sign the Studio 35 open letter, at least in part, because of his notoriety, almost entirely attributable to the \"Life\" article. In the end the sitting was an uncomfortable accommodation between the system of values under which the artists had laboured and their desire for career success.\nThe subsequent \"Life\" article did more than provide the public with an image of the group, looking more \"like bankers\" than irascible. It placed the picture larger and before the pictures of the Metropolitans competition winning art works. It also reiterated the word \"advanced\", echoing the Madison Avenue advertising speak of the day. The picture caption also referred to the protest as in keeping with avant-garde tradition, mentioning the Salon des Refusés of 1863 and the Ashcan School.\n\nIrving Sandler, a historian of the New York School and Abstract Expressionism wrote that the Leen photograph \"has become \"the\" image whereby we invision the artists who achieved the triumph of American painting\".\n\nThe artists' discomfort with being labelled, individually or as a group, was clear. At the end of the three-day symposium at Studio 35 in 1950, Alfred Barr challenged the group to name themselves, to which de Kooning responded: \"it is disastrous to name ourselves\". Pollock, on his part, refused to sign the \"Times\" letter unless it was clear that they were not a group; it is noteworthy that he did not.\n\nAlready in 1951, relationships had deteriorated enough for Pollock, Newman, Still and Rothko to approach Betty Parsons with the idea of showing them exclusively, effectively leaving their erstwhile colleagues to fend for themselves. She declined the offer. Over the following three years Pollock, Still and Rothko moved to the Sidney Janis Gallery. After the failure of fellow artists to defend his show at Betty Parsons in 1951 and not being included in the 1952 \"Fifteen Americans\" show at the Museum of Modern Art, Newman did not show in New York again until 1959.\n\nIn 1954, Ad Reinhardt engaged in a public ridiculing of Rothko, Newman, de Kooning, Gottlieb and Still, resulting in Newman suing him for libel. Clyfford Still repudiated Mark Rothko for \"living an evil, an untrue life\". \"It all went from love to hate in four years\", Betty Parsons recalled in 1975.\n\nNina Leen's 1951 \"Life\" photograph has become the touchstone for canonical lists of the New York School. Irving Sandler used it as the frontispiece and rear dust jacket photograph of his \"The Triumph of American Painting: A History of Abstract Expressionism\", published in 1970. This book defined Abstract Expressionism for a generation of scholars.\n"}
{"id": "960684", "url": "https://en.wikipedia.org/wiki?curid=960684", "title": "Thesis, antithesis, synthesis", "text": "Thesis, antithesis, synthesis\n\nThe triad thesis, antithesis, synthesis (; originally: \"Thesis, Antithesis, Synthesis\") is often used to describe the thought of German philosopher Georg Wilhelm Friedrich Hegel. Hegel never used the term himself. It originated with Johann Fichte.\n\nThe relation between the three abstract terms of the triad, also known as the dialectical method, is summarized in the following way in the \"Encyclopedia of Sciences and Religions\":\n(1) a beginning proposition called a thesis, (2) a negation of that thesis called the antithesis, and (3) a synthesis whereby the two conflicting ideas are reconciled to form a new proposition.\n\nThomas McFarland (2002), in his \"Prolegomena\" to Coleridge's \"Opus Maximum\", identifies Immanuel Kant's \"Kritik der reinen Vernunft\" (1781) as the genesis of the thesis/antithesis dyad. Kant concretises his ideas into:\n\nInasmuch as conjectures like these can be said to be resolvable, Fichte's \"Grundlage der gesamten Wissenschaftslehre\" (\"Foundations of the Science of Knowledge\", 1794) resolved Kant's dyad by synthesis, posing the question thus:\n\nFichte employed the triadic idea \"thesis–antithesis–synthesis\" as a formula for the explanation of change. Fichte was the first to use the trilogy of words together, in his \"Grundriss des Eigentümlichen der Wissenschaftslehre, in Rücksicht auf das theoretische Vermögen\" (1795, \"Outline of the Distinctive Character of the Wissenschaftslehre with respect to the Theoretical Faculty\"): \"Die jetzt aufgezeigte Handlung ist thetisch, antithetisch und synthetisch zugleich.\" [\"The action here described is simultaneously thetic, antithetic, and synthetic.\"]\n\nStill according to McFarland, Schelling then, in his \"Vom Ich als Prinzip der Philosophie\" (1795), arranged the terms schematically in pyramidal form.\n\nAccording to Walter Kaufmann (1966), although the triad is often thought to form part of an analysis of historical and philosophical progress called the Hegelian dialectic, the assumption is erroneous:\nGustav E. Mueller (1958) concurs that Hegel was not a proponent of thesis, antithesis, and synthesis, and clarifies what the concept of dialectic might have meant in Hegel's thought.\nAccording to Mueller, the attribution of this tripartite dialectic to Hegel is the result of \"inept reading\" and simplistic translations which do not take into account the genesis of Hegel's terms: \nKarl Marx (1818–1883) and Friedrich Engels (1820–1895) adopted and extended the triad, especially in Marx's \"The Poverty of Philosophy\" (1847). Here, in Chapter 2, Marx is obsessed by the word \"thesis\"; it forms an important part of the basis for the Marxist theory of history.\n\nIn modern times, the dialectic of \"thesis, antithesis, and synthesis\" has been implemented across the world as a strategy for organizing expositional writing. For example, this technique is taught as a basic organizing principle in French schools:\n\nThesis, Antithesis, and Synthesis has also been used as a basic scheme to organize writing in the English language. For example, the website WikiPreMed.com advocates the use of this scheme in writing timed essays for the MCAT standardized test:\n\n\n\n\n"}
{"id": "42873759", "url": "https://en.wikipedia.org/wiki?curid=42873759", "title": "Timeline of feminism", "text": "Timeline of feminism\n\nThe following is a timeline of the history of feminism. \nIt should contain events within the ideologies and philosophies of feminism. It should not contain material about changes in women's legal rights. See also: \"Timeline of women's legal rights (other than voting)\", \"Timeline of women's suffrage\" and \"Women's suffrage\".\n\n\n\n\n"}
{"id": "21421217", "url": "https://en.wikipedia.org/wiki?curid=21421217", "title": "Tirthika", "text": "Tirthika\n\nTirthika (Sanskrit: tīrthika, Pali: titthiya, \"ford-maker,\" meaning one who is attempting to cross the stream of samsara) is a general term referring to heretics, or non-Buddhists in general. In the Tipitaka, the term may refer specifically to adherents of Jainism. Whereas a Buddhist takes refuge in the Three Jewels and treads the middle way between extremes, a tirthika does not.\n\nAccording to the \"Asoka Avadhana\", the tirthikas that were jealous of Ashoka's preaching of Buddhism gathered together and said to each other, \"Should this king Asoka continue a worshiper of Buddha, all other persons encouraged by him would likewise become followers of Buddha.\" They then went to people's houses and declared that their religion is the true religion and that Buddhism gives no Moksha.\n\nTirthika is associated with the word Tirthankara as used in Jainism.\n\n\n"}
{"id": "63778", "url": "https://en.wikipedia.org/wiki?curid=63778", "title": "Uncertainty", "text": "Uncertainty\n\nUncertainty is a situation which involves imperfect or unknown information. It applies to predictions of future events, to physical measurements that are already made, or to the unknown. Uncertainty arises in partially observable and/or stochastic environments, as well as due to ignorance, indolence, or both. It arises in any number of fields, including insurance, philosophy, physics, statistics, economics, finance, psychology, sociology, engineering, metrology, meteorology, ecology and information science.\n\nAlthough the terms are used in various ways among the general public, many specialists in decision theory, statistics and other quantitative fields have defined uncertainty, risk, and their measurement as:\n\n\nOther taxonomies of uncertainties and decisions include a broader sense of uncertainty and how it should be approached from an ethics perspective:\n\nFor example, if it is unknown whether or not it will rain tomorrow, then there is a state of uncertainty. If probabilities are applied to the possible outcomes using weather forecasts or even just a calibrated probability assessment, the uncertainty has been quantified. Suppose it is quantified as a 90% chance of sunshine. If there is a major, costly, outdoor event planned for tomorrow then there is a risk since there is a 10% chance of rain, and rain would be undesirable. Furthermore, if this is a business event and $100,000 would be lost if it rains, then the risk has been quantified (a 10% chance of losing $100,000). These situations can be made even more realistic by quantifying light rain vs. heavy rain, the cost of delays vs. outright cancellation, etc.\n\nSome may represent the risk in this example as the \"expected opportunity loss\" (EOL) or the chance of the loss multiplied by the amount of the loss (10% × $100,000 = $10,000). That is useful if the organizer of the event is \"risk neutral\", which most people are not. Most would be willing to pay a premium to avoid the loss. An insurance company, for example, would compute an EOL as a minimum for any insurance coverage, then add onto that other operating costs and profit. Since many people are willing to buy insurance for many reasons, then clearly the EOL alone is not the perceived value of avoiding the risk.\n\nQuantitative uses of the terms uncertainty and risk are fairly consistent from fields such as probability theory, actuarial science, and information theory. Some also create new terms without substantially changing the definitions of uncertainty or risk. For example, surprisal is a variation on uncertainty sometimes used in information theory. But outside of the more mathematical uses of the term, usage may vary widely. In cognitive psychology, uncertainty can be real, or just a matter of perception, such as expectations, threats, etc.\n\nVagueness is a form of uncertainty where the analyst is unable to clearly differentiate between two different classes, such as 'person of average height.' and 'tall person'. This form of vagueness can be modelled by some variation on Zadeh's fuzzy logic or subjective logic. \n\nAmbiguity is a form of uncertainty where even the possible outcomes have unclear meanings and interpretations. The statement \"He returns from the bank\" is ambiguous because its interpretation depends on whether the word 'bank' is meant as \"the side of a river\" or \"a financial institution\". Ambiguity typically arises in situations where multiple analysts or observers have different interpretations of the same statements.\n\nUncertainty may be a consequence of a lack of knowledge of obtainable facts. That is, there may be uncertainty about whether a new rocket design will work, but this uncertainty can be removed with further analysis and experimentation. \n\nAt the subatomic level, uncertainty may be a fundamental and unavoidable property of the universe. In quantum mechanics, the Heisenberg uncertainty principle puts limits on how much an observer can ever know about the position and velocity of a particle. This may not just be ignorance of potentially obtainable facts but that there is no fact to be found. There is some controversy in physics as to whether such uncertainty is an irreducible property of nature or if there are \"hidden variables\" that would describe the state of a particle even more exactly than Heisenberg's uncertainty principle allows.\n\nThe most commonly used procedure for calculating measurement uncertainty is described in the \"Guide to the Expression of Uncertainty in Measurement\" (GUM) published by ISO. A derived work is for example the National Institute for Standards and Technology (NIST) Technical Note 1297, \"Guidelines for Evaluating and Expressing the Uncertainty of NIST Measurement Results\", and the Eurachem/Citac publication \"Quantifying Uncertainty in Analytical Measurement\". The uncertainty of the result of a measurement generally consists of several components. The components are regarded as random variables, and may be grouped into two categories according to the method used to estimate their numerical values:\nBy propagating the variances of the components through a function relating the components to the measurement result, the combined measurement uncertainty is given as the square root of the resulting variance. The simplest form is the standard deviation of a repeated observation.\n\nIn metereology, physics, and engineering, the uncertainty or margin of error of a measurement, when explicitly stated, is given by a range of values likely to enclose the true value. This may be denoted by error bars on a graph, or by the following notations:\nIn the last notation, parentheses are the concise notation for the ± notation. For example, applying 10 meters in a scientific or engineering application, it could be written or , by convention meaning accurate to \"within\" one tenth of a meter, or one hundredth. The precision is symmetric around the last digit. In this case it's half a tenth up and half a tenth down, so 10.5 means between 10.45 and 10.55. Thus it is \"understood\" that 10.5 means , and 10.50 means , also written and respectively. But if the accuracy is within two tenths, the uncertainty is ± one tenth, and it is \"required\" to be explicit: and or and . The numbers in parentheses \"apply\" to the numeral left of themselves, and are not part of that number, but part of a notation of uncertainty. They apply to the least significant digits. For instance, stands for , while stands for . This concise notation is used for example by IUPAC in stating the atomic mass of elements.\n\nThe middle notation is used when the error is not symmetrical about the value – for example . This can occur when using a logarithmic scale, for example.\n\nUncertainty of a measurement can be determined by repeating a measurement to arrive at an estimate of the standard deviation of the values. Then, any single value has an uncertainty equal to the standard deviation. However, if the values are averaged, then the mean measurement value has a much smaller uncertainty, equal to the standard error of the mean, which is the standard deviation divided by the square root of the number of measurements. This procedure neglects systematic errors, however.\n\nWhen the uncertainty represents the standard error of the measurement, then about 68.3% of the time, the true value of the measured quantity falls within the stated uncertainty range. For example, it is likely that for 31.7% of the atomic mass values given on the list of elements by atomic mass, the true value lies outside of the stated range. If the width of the interval is doubled, then probably only 4.6% of the true values lie outside the doubled interval, and if the width is tripled, probably only 0.3% lie outside. These values follow from the properties of the normal distribution, and they apply only if the measurement process produces normally distributed errors. In that case, the quoted standard errors are easily converted to 68.3% (\"one sigma\"), 95.4% (\"two sigma\"), or 99.7% (\"three sigma\") confidence intervals.\n\nIn this context, uncertainty depends on both the accuracy and precision of the measurement instrument. The lower the accuracy and precision of an instrument, the larger the measurement uncertainty is. Notice that precision is often determined as the standard deviation of the repeated measures of a given value, namely using the same method described above to assess measurement uncertainty. However, this method is correct only when the instrument is accurate. When it is inaccurate, the uncertainty is larger than the standard deviation of the repeated measures, and it appears evident that the uncertainty does not depend only on instrumental precision.\n\nUncertainty in science, and science in general, may be interpreted differently in the public sphere than in the scientific community. This is due in part to the diversity of the public audience, and the tendency for scientists to misunderstand lay audiences and therefore not communicate ideas clearly and effectively. One example is explained by the information deficit model. Also, in the public realm, there are often many scientific voices giving input on a single topic. For example, depending on how an issue is reported in the public sphere, discrepancies between outcomes of multiple scientific studies due to methodological differences could be interpreted by the public as a lack of consensus in a situation where a consensus does in fact exist. This interpretation may have even been intentionally promoted, as scientific uncertainty may be managed to reach certain goals. For example, global warming contrarian activists took the advice of Frank Luntz to frame global warming as an issue of scientific uncertainty, which was a precursor to the conflict frame used by journalists when reporting the issue.\n\n\"Indeterminacy can be loosely said to apply to situations in which not all the parameters of the system and their interactions are fully known, whereas ignorance refers to situations in which it is not known what is not known.\" These unknowns, indeterminacy and ignorance, that exist in science are often \"transformed\" into uncertainty when reported to the public in order to make issues more manageable, since scientific indeterminacy and ignorance are difficult concepts for scientists to convey without losing credibility. Conversely, uncertainty is often interpreted by the public as ignorance. The transformation of indeterminacy and ignorance into uncertainty may be related to the public's misinterpretation of uncertainty as ignorance.\n\nJournalists may inflate uncertainty (making the science seem more uncertain than it really is) or downplay uncertainty (making the science seem more certain than it really is). One way that journalists inflate uncertainty is by describing new research that contradicts past research without providing context for the change. Journalists may give scientists with minority views equal weight as scientists with majority views, without adequately describing or explaining the state of scientific consensus on the issue. In the same vein, journalists may give non-scientists the same amount of attention and importance as scientists.\n\nJournalists may downplay uncertainty by eliminating \"scientists' carefully chosen tentative wording, and by losing these caveats the information is skewed and presented as more certain and conclusive than it really is\". Also, stories with a single source or without any context of previous research mean that the subject at hand is presented as more definitive and certain than it is in reality. There is often a \"product over process\" approach to science journalism that aids, too, in the downplaying of uncertainty. Finally, and most notably for this investigation, when science is framed by journalists as a triumphant quest, uncertainty is erroneously framed as \"reducible and resolvable\".\n\nSome media routines and organizational factors affect the overstatement of uncertainty; other media routines and organizational factors help inflate the certainty of an issue. Because the general public (in the United States) generally trusts scientists, when science stories are covered without alarm-raising cues from special interest organizations (religious groups, environmental organizations, political factions, etc.) they are often covered in a business related sense, in an economic-development frame or a social progress frame. The nature of these frames is to downplay or eliminate uncertainty, so when economic and scientific promise are focused on early in the issue cycle, as has happened with coverage of plant biotechnology and nanotechnology in the United States, the matter in question seems more definitive and certain.\n\nSometimes, stockholders, owners, or advertising will pressure a media organization to promote the business aspects of a scientific issue, and therefore any uncertainty claims which may compromise the business interests are downplayed or eliminated.\n\n\n\n"}
{"id": "42132936", "url": "https://en.wikipedia.org/wiki?curid=42132936", "title": "Violation of law", "text": "Violation of law\n\nA violation of law is any act (or, less commonly, failure to act) that fails to abide by existing law. Violations generally may include both crimes and civil wrongs. Some acts, such as fraud, can violate both civil and criminal laws.\n\nExamples of violations of law include:\n"}
{"id": "3074097", "url": "https://en.wikipedia.org/wiki?curid=3074097", "title": "Wood bison", "text": "Wood bison\n\nThe wood bison (\"Bison bison athabascae\") or mountain bison (often called the wood buffalo or mountain buffalo), is a distinct northern subspecies or ecotype of the American bison. Its original range included much of the boreal forest regions of Alaska, Yukon, western Northwest Territories, northeastern British Columbia, northern Alberta, and northwestern Saskatchewan.\n\nThe term \"buffalo\" is sometimes considered to be a misnomer for this animal, as it is only distantly related to either of the two \"true buffalo\", the Asian water buffalo and the African buffalo. However, \"bison\" is a Greek word meaning ox-like animal, while \"buffalo\" originated with the French fur trappers who called these massive beasts , meaning ox or bullock—so both names, \"bison\" and \"buffalo\", have a similar meaning. Though the name \"bison\" might be considered to be more scientifically correct, as a result of standard usage the name \"buffalo\" is also considered correct and is listed in many dictionaries as an acceptable name for American buffalo or bison. In reference to this animal, the term \"buffalo\" dates to 1635 in North American usage when the term was first recorded for the American mammal. It thus has a much longer history than the term \"bison\", which was first recorded in 1774. The American bison is very closely related to the wisent or European bison.\n\nIn comparison to plains bison (the other surviving North American subspecies/ecotype), wood bison is larger and heavier, with large males reaching long without tails and tall at withers and in weight, making it morphologically more similar to at least one of chronological subspecies of ancestral steppe bisons (\"Bison priscus\" sp.) and the largest terrestrial living animal in North America. \n\nThe highest point of the wood bison is well ahead of its front legs, while the plains bison's highest point is directly above the front legs. Wood bison also have larger horn cores, darker and woollier pelages, and less hair on their forelegs and beards.\n\nOn the other hand, plains bisons are capable of running faster and longer than bisons living in the forests and mountains.\nIn addition to the loss of habitat and hunting, wood bison populations have also been in danger of hybridizing with plains bison, therefore polluting the genetic stock.\n\nAs with other bison, the wood bison's population was devastated by hunting and other factors. By the early 1900s, they were regarded as extremely rare or perhaps nearly extinct. However, a herd of about 200 was discovered in Alberta, Canada, in 1957. This herd has since recovered to a total population around 2500, largely as a result of conservation efforts by Canadian government agencies. In 1988, the Committee on the Status of Endangered Wildlife in Canada changed the subspecies' conservation status from \"endangered\" to \"threatened,\" where it remains.\n\nOn June 17, 2008, 53 Canadian wood bison were transferred from Elk Island National Park in Alberta, Canada, to the Alaska Wildlife Conservation Center near Anchorage, Alaska. There they were to be held in quarantine for two years, and then reintroduced to their native habitat in the Minto Flats area near Fairbanks, but this plan was still on hold until April 7, 2015. In May 2014, the U.S. Fish and Wildlife Service published a final rule allowing the reintroduction of a \"non-essential experimental\" population of wood bison into three areas of Alaska. The new regulation took effect June 6. The Alaska Department of Fish and Game introduced the first herd of 100 animals to the Innoko River area in western Alaska in spring 2015.\n\nCurrently, about 7000 wood bison remain in the wild, located in the Northwest Territories, Yukon, British Columbia, Alberta, and Manitoba.\n\nIn 2006, as part of an international conservation project, an outherd was established in Yakutia, Russia, where the related steppe bison died out over 6000 years ago. Additional bison were sent from Alberta in 2011 and 2013 to Russia bringing the total to 120.\n\nPublicly owned free-ranging herds in Alberta, British Columbia, Yukon, and the Northwest Territories comprise 90% of existing wood bison, although six smaller public and private captive-breeding herds with conservation objectives comprise roughly 10% of the total (\"n\" ≈ 900). These captive herds and two large isolated free-ranging herds in the Yukon and Northwest Territories all derive from disease-free and morphologically representative founding stock from northern Wood Buffalo National Park in northeastern Alberta and southern Northwest Territories. These captive herds are particularly important for conservation and recovery purposes, because the larger free-ranging herds in and around Wood Buffalo National Park were infected with bovine brucellosis and tuberculosis after 7,000 plains bison were trans-shipped by barge from Buffalo National Park near Wainwright, Alberta, in the 1920s.\n\nDiseases including brucellosis and tuberculosis remain endemic in the free-ranging herds in and around Wood Buffalo National Park. The diseases represent a serious management issue for governments, various local Aboriginal groups, and the cattle industry rapidly encroaching on the park's boundaries. Disease management strategies and initiatives began in the 1950s, and have yet to result in a reduction of the incidence of either disease despite considerable expenditure and increased public involvement.\n\n\n"}
