{"id": "43210728", "url": "https://en.wikipedia.org/wiki?curid=43210728", "title": "2014 Miami Beach Bowl", "text": "2014 Miami Beach Bowl\n\nThe 2014 Miami Beach Bowl was a post-season American college football bowl game played on December 22, 2014 at Marlins Park in Miami, Florida. The first edition of the Miami Beach Bowl, it featured the American Athletic Conference co-champion Memphis Tigers against the BYU Cougars. It began at 2:00 p.m. EST and aired on ESPN. It was one of the 2014–15 bowl games that comprised the conclusion of the 2014 FBS football season.\n\nMemphis beat BYU in double overtime by a score of 55–48. Afterwards, the two teams engaged in a bench-clearing brawl.\nThe game featured the American Athletic Conference co-champion Memphis Tigers against the BYU Cougars.\n\nThis was the first meeting between these two teams.\n\nIn April 2014, organizers announced that they had reached a deal with BYU to play in the inaugural Miami Beach Bowl in 2014. After defeating the UNLV Rebels for their sixth win of the season on November 15, bowl director Carlos Padilla II extended an invitation to play in the game.\n\nThis was BYU's third Florida bowl game, following the 1976 Tangerine Bowl where they lost to Oklahoma State 21–49, and the 1985 Citrus Bowl where they lost to Ohio State 7–10.\n\nAfter finishing the regular season with a 9–3 record and a share of the American Athletic Conference championship, the Tigers accepted their bid to the Miami Beach Bowl.\n\nThis was Memphis' second Florida bowl game, following the 2008 St. Petersburg Bowl (the inaugural contest for that bowl game) where they lost to the South Florida Bulls by a score of 14–41. This was the Tigers' first bowl appearance since that game.\n\nDuring the post game celebration Memphis players ran towards the BYU sideline to celebrate with their fans sitting behind the BYU bench (due to the bizarre baseball stadium field layout, most of the people in attendance could only sit on the BYU side of the field). Some bumping and shoving occurred and one Memphis player was pushed in the back by a BYU player that was allegedly also being pushed from behind. The Memphis player he pushed then turned around and (using both hands) punched/shoved the BYU player in the back of the head. As the BYU player turned his attention back to the attacker in an apparent attempt to retaliate he threw a punch and he was attacked by 3-4 Memphis players and an all out, bench-clearing brawl ensued. Punches and kicks were thrown by many players on both sides, one Memphis player even used a helmet as a weapon, and when it was over, numerous players walked off the field bloody and bruised. As the brawl was dying down a BYU player (Kai Nacua) can be seen coming into view and sucker punching a Memphis player (Alan Cross), who was not wearing a helmet, from behind. As the BYU player turned toward the camera's view, a bloodied bruise could be clearly seen from a punch he received while attempting to defend himself from another Memphis player earlier in the brawl.\n\nTom Holmoe, BYU's athletic director, apologized to BYU fans stating, \"We expect better of our athletes, even in the face of a difficult loss. We intend to fully review this matter. I apologize to Cougar Nation.\" Memphis said in a statement via AAC commissioner Mike Aresco that they are displeased with the Miami Beach Bowl brawl, and that, \"The university will respond accordingly following this detailed review. Needless to say, we are extremely disappointed that this happened, as we expect the highest standard of conduct from our student-athletes.\" \n\nOn January 20, 2015, The University of Memphis announced the completion of an internal review of the incident and expected punishments to be levied against twelve members of the team. BYU also took action to punish their players. Kai Nacua, Trey Dye, Sione Takitaki, and Tomasi Laulile were all suspended for BYU's season opener against Nebraska.\n"}
{"id": "38235255", "url": "https://en.wikipedia.org/wiki?curid=38235255", "title": "Affirmation and negation", "text": "Affirmation and negation\n\nIn linguistics and grammar, affirmation and negation (abbreviated respectively ' and ') are the ways that grammar encode negative and positive polarity in verb phrases, clauses, or other utterances. Essentially an affirmative (positive) form is used to express the validity or truth of a basic assertion, while a negative form expresses its falsity. Examples are the sentences \"Jane is here\" and \"Jane is not here\"; the first is affirmative, while the second is negative.\n\nThe grammatical category associated and with affirmative and negative is called polarity. This means that a sentence, verb phrase, etc. may be said to have either affirmative or negative polarity (its polarity may be either affirmative or negative). Affirmative is typically the unmarked polarity, whereas a negative statement is marked in some way, whether by a negating word or particle such as English \"not\", an affix such as Japanese -\"nai\", or by other means, which reverses the meaning of the predicate. The process of converting affirmative to negative is called negation – the grammatical rules for negation vary from language to language, and a given language may have more than one method of doing so.\n\nAffirmative and negative responses (especially, though not exclusively, to questions) are often expressed using particles or words such as \"yes\" and \"no\", where \"yes\" is the affirmative and \"no\" the negative particle.\n\nSpecial affirmative and negative words (particles) are often found in responses to questions, and sometimes to other assertions by way of agreement or disagreement. In English, these are \"yes\" and \"no\" respectively, in French \"oui\", \"si\" and \"non\", in Swedish \"ja\", \"jo\" and \"nej\", and so on. Not all languages make such common use of particles of this type; in some (such as Welsh) it is more common to repeat the verb or another part of the predicate, with or without negation accordingly.\n\nComplications sometimes arise in the case of responses to negative statements or questions; in some cases the response that confirms a negative statement is the negative particle (as in English: \"You're not going out? No.\"), but in some languages this is reversed. Some languages have a distinct form to answer a negative question, such as French \"si\" and Swedish \"jo\" (these serve to contradict the negative statement suggested by the first speaker).\n\nLanguages have a variety of grammatical rules for converting affirmative verb phrases or clauses into negative ones.\n\nIn many languages, an affirmative is made negative by the addition of a particle, meaning \"not\". This may be added before the verb phrase, as with the Spanish \"no\":\nOther examples of negating particles preceding the verb phrase include Italian \"non\", Russian не \"nye\" and Polish \"nie\" (they can also be found in constructed languages: \"ne\" in Esperanto and \"non\" in Interlingua). In some other languages the negating particle follows the verb or verb phrase, as in Dutch:\nParticles following the verb in this way include \"not\" in archaic and dialectal English (\"you remember not\"), \"nicht\" in German (\"ich schlafe nicht\", \"I am not sleeping\"), and \"inte\" in Swedish (\"han hoppade inte\", \"he did not jump\").\n\nIn French, particles are added both before the verb phrase (\"ne\") and after the verb (\"pas\"):\nHowever, in colloquial French the first particle is often omitted: \"Je sais pas\". Similar use of two negating particles can also be found in Afrikaans: \"Hy kan nie Afrikaans praat nie\" (\"He cannot speak Afrikaans\").\n\nIn standard Modern English, negation is achieved by adding \"not\" after an auxiliary verb (which here means one of a special grammatical class of verbs that also includes forms of the copula \"be\"; see English auxiliaries). If no such verb is present then the dummy auxiliary \"do\" (\"does\", \"did\") is introduced – see \"do\"-support. For example:\nDifferent rules apply in subjunctive, imperative and non-finite clauses. For more details see . (In Middle English, the particle \"not\" could follow any verb, e.g. \"I see not the horse.\")\n\nIn some languages, like Welsh, verbs have special inflections to be used in negative clauses. (In some language families, this may lead to reference to a negative mood.) An example is Japanese, which conjugates verbs in the negative after adding the suffix \"-nai\" (indicating negation), e.g. \"taberu\" (\"eat\") and \"tabenai\" (\"do not eat\"). It could be argued that English has joined the ranks of these languages, since negation requires the use of an auxiliary verb and a distinct syntax in most cases; the form of the basic verb can change on negation, as in \"he sings\" vs. \"he doesn't sing\". Zwicky and Pullum have shown that \"n't\" is an inflectional suffix, not a clitic or a derivational suffix.\n\nComplex rules for negation also apply in Finnish; see . In some languages negation may also affect the dependents of the verb; for example in some Slavic languages, such as Russian, the case of a direct object often changes from accusative to genitive when the verb is negated.\n\nNegation can be applied not just to whole verb phrases, clauses or sentences, but also to specific elements (such as adjectives and noun phrases) within sentences. Ways in which this can be done again depend on the grammar of the language in question. English generally places \"not\" before the negated element, as in \"I witnessed not a debate, but a war.\" There are also negating affixes, such as the English prefixes \"non-\", \"un-\", \"in-\", etc. Such elements are called privatives.\n\nThere also exist elements which carry a specialized negative meaning, including pronouns such as \"nobody\", \"none\" and \"nothing\", determiners such as \"no\" (as in \"no apples\"), and adverbs such as \"never\", \"no longer\" and \"nowhere\".\n\nAlthough such elements themselves have negative force, in some languages a clause in which they appear is additionally marked for ordinary negation. For example, in Russian, \"I see nobody\" is expressed as я никого́ не ви́жу \"ja nikovó nye vízhu\", literally \"I nobody not see\" – the ordinary negating particle не \"nye\" (\"not\") is used in addition to the negative pronoun никого́ \"nikovó\" (\"nobody\"). Italian behaves in a similar way: \"Non ti vede nessuno\", \"nobody can see you\", although \"Nessuno ti vede\" is also a possible clause with exactly the same meaning.\n\nIn Russian, all of the elements (\"not\", \"never\", \"nobody\", \"nowhere\") would appear together in the sentence in their negative form. In Italian, a clause works much as in Russian, but \"non\" does not have to be there, and can be there only before the verb if it precedes all other negative elements: \"Tu non porti mai nessuno da nessuna parte\". \"Nobody ever brings you anything here\", however, could be translated \"Nessuno qui ti porta mai niente\" or \"Qui non ti porta mai niente nessuno\". In French, where simple negation is performed using \"ne ... pas\" (see above), specialized negatives appear in combination with the first particle (\"ne\"), but \"pas\" is omitted:\nIn Ancient Greek, a simple negative (οὐ \"ou\" \"not\" or μή \"mḗ\" \"not (modal)\") following another simple or compound negative (e.g. οὐδείς \"oudeís\" \"nobody\") results in an affirmation, whereas a compound negative following a simple or compound negative strengthens the negation:\n\nSimple grammatical negation of a clause in principle has the effect of converting a proposition to its logical negation – replacing an assertion that something is the case by an assertion that it is not the case.\n\nIn some cases, however, particularly when a particular modality is expressed, the semantic effect of negation may be somewhat different. For example, in English, the meaning of \"you must not go\" is not in fact the exact negation of that of \"you must go\" – this would be expressed as \"you don't have to go\" or \"you needn't go\". The negation \"must not\" has a stronger meaning (the effect is to apply the logical negation to the following infinitive rather than to the full clause with \"must\"). For more details and other similar cases, see the relevant sections of English modal verbs.\n\nIn some cases, by way of irony, an affirmative statement may be intended to have the meaning of the corresponding negative, or vice versa. For examples see antiphrasis and sarcasm.\n\nFor the use of double negations or similar as understatements (\"not unappealing\", \"not bad\", etc.) see litotes.\n\n\n\n"}
{"id": "3792257", "url": "https://en.wikipedia.org/wiki?curid=3792257", "title": "Altruism (ethics)", "text": "Altruism (ethics)\n\nAltruism (also called the ethic of altruism, moralistic altruism, and ethical altruism) is an ethical doctrine that holds that the moral value of an individual's actions depend solely on the impact on other individuals, regardless of the consequences on the individual itself. James Fieser states the altruist dictum as: \"An action is morally right if the consequences of that action are more favorable than unfavorable to everyone except the agent.\" Auguste Comte's version of altruism calls for living for the sake of others. One who holds to either of these ethics is known as an \"altruist.\"\n\nThe word \"altruism\" (\"French, altruisme, from autrui: \"other people\", derived from Latin alter: \"other\"\") was coined by Auguste Comte, the French founder of positivism, in order to describe the ethical doctrine he supported. He believed that individuals had a moral obligation to renounce self-interest and live for others. Comte says, in his \"Catéchisme Positiviste\", that:\n\n[The] social point of view cannot tolerate the notion of rights, for such notion rests on individualism. We are born under a load of obligations of every kind, to our predecessors, to our successors, to our contemporaries. After our birth these obligations increase or accumulate, for it is some time before we can return any service... This [\"to live for others\"], the definitive formula of human morality, gives a direct sanction exclusively to our instincts of benevolence, the common source of happiness and duty. [Man must serve] Humanity, whose we are entirely.\"\n\nThe \"Catholic Encyclopedia\" says that for Comte's altruism, \"The first principle of morality...is the regulative supremacy of social sympathy over the self-regarding instincts.\" Author Gabriel Moran, (professor in the department of Humanities and the Social Sciences, New York University) says \"The law and duty of life in altruism [for Comte] was summed up in the phrase : Live for others.\"\n\nVarious philosophers define the doctrine in various ways, but all definitions generally revolve around a moral obligation to benefit others or the pronouncement of moral value in serving others rather than oneself. Philosopher C. D. Broad defines altruism as \"the doctrine that each of us has a special obligation to benefit others.\" Philosopher W. G. Maclagan defines it as \"a duty to relieve the distress and promote the happiness of our fellows...Altruism is to...maintain quite simply that a man may and should discount altogether his own pleasure or happiness as such when he is deciding what course of action to pursue.\"\n\nAltruism is often seen as a form of consequentialism, as it indicates that an action is ethically right if it brings good consequences to others. Altruism may be seen as similar to utilitarianism, however an essential difference is that the latter prescribes acts that maximize good consequences for all of society, while altruism prescribes maximizing good consequences for everyone except the actor. Spencer argued that since the rest of society will almost always outnumber the utilitarian, a genuine utilitarian will inevitably end up practicing altruism or a form of altruism. Effective altruism is a philosophy and social movement that maintains that the consequences of our actions - for ourselves and others - are important, and seeks to maximise the overall quality of these consequences.\n\nDavid Kelley, discussing Ayn Rand's views, says that \"there is no rational ground for asserting that sacrificing yourself in order to serve others is morally superior to pursuing your own (long-term, rational) self-interest. Altruism ultimately depends on non-rational 'rationales,' on mysticism in some form...\" Furthermore, he holds that there is a danger of the state enforcing that moral ideal: \"If self-sacrifice is an ideal - if service to others is the highest, most honorable course of action - why not force people to act accordingly?\" He believes this can ultimately result in the state forcing everyone into a collectivist political system.\n\nNorwegian eco-philosopher Arne Næss argues that environmental action based upon altruism — or service of the other — stems from a shrunken \"egoic\" concept of the self. Self-actualization will result, he argues, in the recovery of an \"ecological self\", in which actions formerly seen as altruistic are in reality a form of enlightened self-interest.\n\nGerman philosopher Max Scheler distinguishes two different ways in which the strong can help the weak, one which is an expression of love, \"motivated by a powerful feeling of security, strength, and inner salvation, of the invincible fullness of one’s own life and existence\" and another which is merely \"one of the many modern substitutes for love, ... nothing but the urge to turn away from oneself and to lose oneself in other people’s business.\" At its worst, Scheler says, \"love for the small, the poor, the weak, and the oppressed is really disguised hatred, repressed envy, an impulse to detract, etc., directed against the opposite phenomena: wealth, strength, power, largesse.\"\n\n\n"}
{"id": "54129450", "url": "https://en.wikipedia.org/wiki?curid=54129450", "title": "Basque Declaration", "text": "Basque Declaration\n\nThe Basque Declaration (2016) is a formal document outlining 15 pathways for the development of more sustainable cities in Europe. The Declaration was acclaimed at the 8th European Conference on Sustainable Cities & Towns from 27-29 April 2016 in Basque Country. The document can be seen as a continuation of the Aalborg Charter (1994) and the Aalborg Commitments (2004) echoing sustainability vision from Local Agenda 21, and is itself a call for active engagement from civil society.. The vision of the Declaration is 'to create productive, sustainable and resilient cities for a liveable and inclusive Europe'\n\nThe Basque Declaration is targeted at city leaders in Europe, including mayors and city governments, and can also be signed by individuals. It outlines pathways to help city leaders shape the development of their own municipalities, and ultimately aims to accelerate socio-cultural, socio-economic and technological transformation. The Declaration is based on the understanding that a diversity of local initiatives are required to address social, environmental and economic challenges. It recognises the importance of things such as protecting biodiversity, decarbonising energy systems, creating more sustainable mobility systems, protecting water systems, adapting to climate change, promoting social inclusion and strengthening local economies, among other things. Although focusing on action at the local scale, the Declaration is underpinned by the idea of cooperation, sharing and replication of solutions adapted to the local context. A strong theme of the Declaration is to have a highly engaged civil society, where participation is a key ingredient in both developing and \"implementing\" local transformative actions.\n\nThe 15 pathways listed in the Basque Declaration are summarised under three headings:\n\nThe Socio-Cultural Transformation\n\nThe Socio-Economic Transformation\n\nThe Technological Transformation\n\nThe Declaration supports local 'transformative actions' and encourages cities to develop and share their sustainability solutions. The Sustainable Cities EU website has a central database where cities can submit their own 'transformative actions'. The idea is that local innovations can inspire other city leaders and where it is possible, help to facilitate replication of successful strategies. To encourage cities to report on their activities a 'Transformative Action Award' was created.\n\n"}
{"id": "48918662", "url": "https://en.wikipedia.org/wiki?curid=48918662", "title": "Buddhist personality types", "text": "Buddhist personality types\n\nBuddhism has developed a complex psychology of personality types (Pali: Puggala-paññatti), personality traits and underlying tendencies (anusaya). This was mostly developed in the Buddhist Abhidharma literature and its major concern was to identify differing types of persons for pedagogical and soteriological ends. The Buddha was said to have skillfully taught different teachings depending on each person's personality and level of mental development. The development of a Personality psychology was important to the Abhidharmikas who sought to adapt Buddhist teachings and practice to each personality type so as to better lead persons to nirvana by purifying their minds of their mental defilements. \n\nThe Buddhist view of the person is encapsulated by the not-self teaching, which states that there is no unchanging core to a person, no soul (atman) or Ego. A person is defined as a stream of phenomenal events (termed \"dhammas\") in a causal series of mind moments (\"samaya\"), and therefore an 'individual' or 'person' is merely a conventional designation for a collection of constantly changing processes (the five skandhas). However, in the analytical Abhidharma works, Buddhists outlined how different individuals could still be dominated by certain proclivities and tendencies, patterns of thought which arose consistently enough to allow one to designate different 'personality types'. \n\nThe Theravada Abhidhamma Pitaka contains a section entitled 'The Puggala-paññatti', which translates to \"designation of person types\" which contains an extensive outline of a wide array of personality traits. The Abhidhamma generally considered twelve major classes of persons, four of the worldly ordinary class (\"puthujjana\") and eight of the spiritual elect (\"ariya\", the noble ones). The Puggala-paññatti gives a very broad array of personal descriptors organized in 10 groups, so that the first group is 50 \"single\" descriptors, the second group is 26 \"pairs\" of descriptors, the third 17 \"triplets\", and so on. Descriptors include \"one competent in watchfulness\", \"one of perturbable nature\", \"the wrathful and the vengeful\", \"the jealous and the avaricious\", a \"member of the elect (arhat)\" etc. \n\nIn the Visuddhimagga (Path of Purification), the scholar Buddhaghosa outlines several types of personalities, each one dominated by a particular trait. The three major negative traits which condition a personality are grasping, aversion, and delusion (\"lobha\", \"dosa\", and \"moha\"), also known as the three poisons, and prescribes certain meditation practices for each type. He also outlines three main positive personality traits, confidence (saddha), wisdom (pañña), and speculation. \n\nThe Buddhist scholar Asanga outlined seven personality types in his \"Levels of Listeners\":\n\n\nTibetan Buddhism uses the model of the Five Buddha families for describing an individual's personality. Chogyam Trungpa said of this psychological model:\n\nThe buddha family or families associated with a person describe his or her fundamental style, that person's intrinsic perspective or stance in perceiving the world and working with it. Each family is associated with both a neurotic and an enlightened style. The neurotic expression of any buddha family can be transmuted into its wisdom or enlightened aspect. As well as describing people's styles, the buddha families are also associated with colors, elements, landscapes, directions, seasons-with any aspect of the phenomenal world.\n\nThe five main families are:\n\n\nPuggala-paññatti Translated by Bimala Charan Law, M.A., B.L\n"}
{"id": "55596031", "url": "https://en.wikipedia.org/wiki?curid=55596031", "title": "Call-out culture", "text": "Call-out culture\n\nCall-out culture (also known as outrage culture) is a term for the social phenomenon of publicly denouncing perceived racism, sexism, homophobia, transphobia, and other forms of bigotry. Denunciation (\"call-outs\") can happen in person or online.\n\nSome commentators contend that callout culture is a pernicious influence in both the academic and business worlds, citing the controversy at Google over a memorandum concerning the respective vocational interests of men and women, authored by former Google engineer James Damore. Other commentators have argued that callout culture can harm progressive politics by attacking people perceived to have exhibited prejudiced behaviour, rather than using dialogue with such people to change such behaviour. A 2013 essay, \"Exiting the Vampire Castle\", by Mark Fisher, is often cited as an early critique of call-out culture. Fisher argued that \"call-out culture\" created a space where \"where solidarity is impossible, but guilt and fear are omnipresent\". Fisher also argues that call-out\nculture reduces every political issue to criticizing the behaviour of individuals, instead of dealing with such political issues through collective action. \n\nCall-out culture found a vehicle in social media. Both as consumers and as political activists, individuals found a means to communicate to a larger crowd in an expedient and pervasive manner. While call-out culture often publicly denounces perceived acts of bigotry, as stated above, it also refers to the act of publicly calling out a larger entity (such as an organization, business or vendor) usually by means of social media. In an effort to hold these businesses or organizations accountable, individuals will take to the online forums to \"call them out\". Whether the individual is addressed by a representative from within the organization or not, some of these posts or tweets (depending on the medium) can go viral and cause a PR headache for the business. \n\nThe effects of call-out culture are also noted as more prevalent today on college-campuses, where most students are aware of the social justice culture that exists and is expressed online. There are some that are careful to avoid missteps (ex: cultural appropriation by way of a Halloween costume) in order to avoid public online call-outs and others that are exploring ways to deal with past aggressors by way of call-out online.\n\nSome people argue in defense of call-out culture and contend that it is a form of social activism. The individual calling someone out is ultimately trying to either stop behavior they deem to be negative or prevent it from happening again. Others argue that the call-out culture today tends to be too aggressive and can often have life-altering affects on the individual being called out. \n\n\n"}
{"id": "2518034", "url": "https://en.wikipedia.org/wiki?curid=2518034", "title": "Carthaginian peace", "text": "Carthaginian peace\n\nA Carthaginian peace is the imposition of a very brutal \"peace\" achieved by completely crushing the enemy. The term derives from the peace imposed on Carthage by Rome. After the Second Punic War, Carthage lost all its colonies, was forced to demilitarize and pay a constant tribute to Rome and could enter war only with Rome's permission. At the end of the Third Punic War, the Romans systematically burned Carthage to the ground and enslaved its population.\n\nThe term refers to the outcome of a series of wars between Rome and the Phoenician city of Carthage, known as the Punic Wars. The two empires fought three separate wars against each other, beginning in 264 BC and ending in 146 BC.\n\nAt the end of the Third Punic War, the Romans laid siege to Carthage. When they took the city, they killed most of the inhabitants, sold the rest into slavery, and destroyed the entire city. There is no ancient evidence for modern accounts that the Romans sowed the ground with salt.\n\nBy extension, a Carthaginian peace can refer to any brutal peace treaty demanding total subjugation of the defeated side.\n\nModern use of the term is often extended to any peace settlement in which the peace terms are overly harsh and designed to accentuate and perpetuate the inferiority of the loser. Thus, after World War I, many (the economist John Maynard Keynes among them) described the Treaty of Versailles as a \"Carthaginian Peace.\"\n\nThe Morgenthau Plan put forward after World War II has also been described as a Carthaginian peace, as it advocated the deindustrialization of Germany. It was intended to severely curb the influence of German power in the region and to prevent its remilitarization, as had occurred after World War I (Remilitarization of the Rhineland). The Morgenthau Plan was dropped in favor of the Marshall Plan (1948–1952), which entailed the rebuilding of Western European infrastructure, particularly in West Germany. \n\nGeneral Lucius D. Clay, a deputy to general Dwight D. Eisenhower and, in 1945, Military Governor of the U.S. Occupation Zone in Germany, would later remark that \"there was no doubt that JCS 1067 contemplated the Carthaginian peace which dominated our operations in Germany during the early months of occupation. This is while the US was following the Morgenthau Plan.\" Clay would later replace Eisenhower as governor and as commander-in-chief in Europe. The Marshall Plan was favored as a revival of the West German economy was considered to be necessary for the recovery of the economy of Europe. West Germany was regarded as a key bulwark against the Eastern Bloc.\n\n\n"}
{"id": "17302821", "url": "https://en.wikipedia.org/wiki?curid=17302821", "title": "Dense heterarchy", "text": "Dense heterarchy\n\nA dense heterarchy is a hierarchical organization in social insect colonies in which the higher levels affect the lower levels and lower levels eventually influence the higher levels. Individual ants within the colony network are likely to have many connections with one another – making the network denser and non-hierarchical. Because there is no highest level within a heterarchy but the heterarchy itself, control is decentralized (not controlled by the queen). Communication between individuals in a dense heterarchy occurs directly between individuals and through stigmergy. Feedback loops of communication can produce emergent properties not obvious when only examining singular activities or communication.\n"}
{"id": "1721704", "url": "https://en.wikipedia.org/wiki?curid=1721704", "title": "Distinction (book)", "text": "Distinction (book)\n\nDistinction: A Social Critique of the Judgement of Taste () is a 1979 book by Pierre Bourdieu, based upon the author's empirical research from 1963 until 1968. A sociological report about the state of French culture, \"Distinction\" was first published in English translation in 1984. In 1998 the International Sociological Association voted \"Distinction\" as one of the ten most important sociology books of the 20th century.\n\nBourdieu proposes that those with a high volume of cultural capital — non-financial social assets, such as education, which promote social mobility beyond economic means — are most likely to be able to determine what constitutes taste within society. Those with lower volumes of overall capital accept this taste, and the distinction of high and low culture, as legitimate and natural, and thus accept existing restrictions on conversion between the various forms of capital (economic, social, cultural). Those with low overall capital are unable to access a higher volume of cultural capital because they lack the necessary means to do so. This could mean lacking the terminology to describe or methods of understanding classical artwork, due to features of their habitus, for example. Bourdieu asserts in this respect that 'working-class people expect objects to fulfil a function' whilst those free from economic necessities are able to operate a pure gaze separated from everyday life. The acceptance of 'dominant' forms of taste is, Bourdieu argues, a form of 'symbolic violence'. That is, the naturalization of this distinction of taste and its misrecognition as necessary denies the dominated classes the means of defining their own world, which leads to the disadvantage of those with less overall capital. Moreover, that even when the subordinate social classes might seem to have their own ideas about what is and what is not good taste, \"the working-class ‘aesthetic’ is a dominated aesthetic, which is constantly obliged to define itself in terms of the dominant aesthetics\" of the ruling class.\n\nThe aesthetic choices of a person create \"class fractions\" (class-based social groups) and actively distance a social class from other social classes of a society. Hence, predispositions to certain kinds of food, music and art are taught and instilled in children and these class-specific (not particular nor individual) tastes help guide children to their \"appropriate\" social positions. Therefore, self-selection into a class fraction is achieved by impelling the child's internalization of preferences for objects and behaviors suitable for him or her as member of a given social class and also, the development of an aversion towards the preferred objects and behaviors of other social classes. In practice, when a man or a woman encounters the culture and the arts of another social class, he or she feels \"disgust, provoked by horror, or visceral intolerance (‘feeling sick’) of the tastes of others.\"\n\nTherefore, \"Taste\" is an important example of cultural hegemony, of how class fractions are determined. It's not only the possession of social capital and economic capital, but possession of cultural capital as well. Instilling and acquiring cultural capital is used as an insidious mechanism to ensure social reproduction as well as cultural reproduction of the ruling class. Moreover, because persons are taught his and her tastes at an early age, taste is deeply internalized. Social re-conditioning for taste is very difficult. The taste instilled and acquired tends to permanently identify a person as one from a certain social class and this impedes social mobility. In this way, the cultural tastes of the dominant (ruling) class tend to dominate the tastes of the other social classes, forcing individual men and women of economically and culturally dominated classes to conform to the dominating aesthetic preferences, or risk \"societal\" (but in fact, fractional and domineering) disapproval —appearing crude, vulgar and tasteless.\n\nInfluenced by structuralism, Bourdieu sought to go beyond the traditional reliance on regression analysis in contemporary sociology and achieve a more rigorous quantitative approach. Rather than relying on the correlation of multiple independent variables, he was interested in developing a framework to allow him to view \"'the complete system of relations that make up the true principle of the force and form specific to the effects recorded in such and such correlation.'\" For the analysis in \"La Distinction\", Bourdieu, working with his statistical technician Salah Bouhedja, employed multiple rounds of correspondence analysis on a set of data from two surveys, the \"Kodak survey\" of 1963 and the \"taste survey\" of 1967. In addition to this analysis, Bourdieu also applied correspondence analysis to a subset of the data, the responses from what Bourdieu labelled the \"dominant classes\" and the \"petite-bourgeoisie.\" This type of research represented an early attempt at geometric data analysis, specifically multiple correspondence analysis, which would become an important methodological framework in Bourdieu's later work.\n\nIn 1998 the International Sociological Association voted \"Distinction\" as one of the ten most important sociology books of the 20th century, behind Peter L. Berger and Thomas Luckmann's \"The Social Construction of Reality\" (1966), but ahead of Norbert Elias' \"The Civilizing Process\" (1939). The critic Camille Paglia, writing in \"Salon\", expressed agreement with Bourdieu's conclusion that taste depends on changing social assumptions, but suggested that it should have been obvious, and dismissed \"Distinction\".\n\n"}
{"id": "196971", "url": "https://en.wikipedia.org/wiki?curid=196971", "title": "Ecological land classification", "text": "Ecological land classification\n\nEcological land classification is a cartographical delineation or regionalisation of distinct ecological areas, identified by their geology, topography, soils, vegetation, climate conditions, living species, habitats, water resources, and sometimes also anthropic factors. These factors control and influence biotic composition and ecological processes.\n\nThe expression \"ecological land classification\" as understood in this article, is approximate with the biogeographical and ecological regionalisations in a scientific context (see biogeographic units).\n\nHowever, its actual usage is more approximate with a tool used for land management, in the context of environmental resource management.\n\nIn Canada ecological land classification schemes are commonly used. Provincial authorities have adopted methods to classify ecosystems within various ecoregions of the province. Ontario is one such province that uses an extensive method to define ecological units. Improvements in hand held technology have allowed for more efficient collection of vegetation and physiological data in the field, such as with the ELC eTool.\n\nMany different lists and ecological land classification schemes have been developed.\n\nAmerican geographer Robert Bailey defines a hierarchy of ecosystem units ranging from micro-ecosystems (individual homogeneous sites, in the order of in area), through meso-ecosystems (landscape mosaics, in the order of ) to macro-ecosystems (ecoregions, in the order of ).\n\nBailey outlined five different methods for identifying ecosystems: \"gestalt\" (\"a whole that is not derived through considerable of its parts\"), in which regions are recognized and boundaries drawn intuitively; a map overlay system where different layers like geology, landforms and soil types are overlain to identify ecosystems; multivariate clustering of site attributes; digital image processing of remotely sensed data grouping areas based on their appearance or other spectral properties; or by a \"controlling factors method\" where a subset of factors (like soils, climate, vegetation physiognomy or the distribution of plant or animal species) are selected from a large array of possible ones are used to delineate ecosystems. \n\nIn contrast with Bailey's methodology, Puerto Rico ecologist Ariel Lugo and coauthors identified ten characteristics of an effective classification system. For example that it be based on georeferenced, quantitative data; that it should minimize subjectivity and explicitly identify criteria and assumptions; that it should be structured around the factors that drive ecosystem processes; that it should reflect the hierarchical nature of ecosystems; that it should be flexible enough to conform to the various scales at which ecosystem management operates.\n\nFollowing, a comparison of classification schemes and terms used in the study of the biotic and abiotic components of ecosystems and the Earth in ecology and other fields.\n\nIn ecology:\n\nIn biogeography:\n\nIn zoogeography:\n\nIn phytogeography:\n\n\nFor the physiognomic approach, see Vegetation#Classifications.\n\nFor the association (phytosociological) approach, see Phytosociology#Classificatory traditions.\n\nIn physiography:\n\nIn Geology:\n\nIn pedology (soil study):\n\n\n\n\n\n"}
{"id": "10480045", "url": "https://en.wikipedia.org/wiki?curid=10480045", "title": "Epidemiology of domestic violence", "text": "Epidemiology of domestic violence\n\nDomestic violence occurs across the world, in various cultures, and affects people across society, at all levels of economic status; however, indicators of lower socioeconomic status (such as unemployment and low income) have been shown to be risk factors for higher levels of domestic violence in several studies. In the United States, according to the Bureau of Justice Statistics in 1995, women reported a six times greater rate of intimate partner violence than men. However, studies have found that men are much less likely to report victimization in these situations.\n\nSome studies have found that \"women are as physically aggressive or more aggressive than men in their relationships with their spouses or male partners\". However, studies have shown that women are more likely to be injured. Archer's meta-analysis found that women suffer 65% of domestic violence injuries. A Canadian study showed that 7% of women and 6% of men were abused by their current or former partners, but female victims of domestic violence were more than twice as likely to be injured as male victims, three times more likely to fear for their life, twice as likely to be stalked, and twice as likely to experience more than ten incidents of violence.\n\nWhile some sources state that gay and lesbian couples experience domestic violence at the same frequency as heterosexual couples, other sources report that domestic violence rates among gay, lesbian and bisexual people might be higher but more under-reported.\n\nAccording to various national surveys, the percentage of women who were ever physically assaulted by an intimate partner varies substantially by country: Barbados (30%), Canada (29%), Egypt (34%), New Zealand (35%), Switzerland (21%), United States (33%). Some surveys in specific places report figures as high as 50–70% of women who were ever physically assaulted by an intimate partner. Others, including surveys in the Philippines and Paraguay, report figures as low as 10%.\n\nIn India, around 20% of women are victims of domestic violence.\n\nStatistics published in 2004, show that the rate of domestic violence victimisation for Indigenous women in Australia may be 40 times the rate for non-Indigenous women.\n\nSouth Africa is said to have the highest statistics of gender-based violence in the world, including rape and domestic violence (Foster 1999; \"The Integrated Regional Network\" [IRIN], Johannesburg, South Africa, May 25, 2002). 80% of women surveyed in rural Egypt said that beatings were common and often justified, particularly if the woman refused to have sex with her husband. Up to two-thirds of women in certain communities in Nigeria's Lagos State say they are victims to domestic violence.\n\nIn Turkey 42% of women over 15 have suffered physical or sexual violence\n\nBetween 1993 and 2001, U.S. women reported intimate partner violence almost seven times more frequently than men (a ratio of 20:3). Statistics for the year 1994 showed that more than five times as many females reported being victimized by an intimate than did males.\n\nDomestic violence during pregnancy can be missed by medical professionals because it often presents in non-specific ways. A number of countries have been statistically analyzed to calculate the prevalence of this phenomenon:\n\n\nThere are a number of presentations that can be related to domestic violence during pregnancy: delay in seeking care for injuries; late booking, non-attenders at appointments, self-discharge; frequent attendance, vague problems; aggressive or over-solicitous partner; burns, pain, tenderness, injuries; vaginal tears, bleeding, STDs; and miscarriage.\n\nDomestic violence against a pregnant woman can also affect the fetus and can have lingering effects on the child after birth. Physical abuse is associated with neonatal death (1.5% versus 0.2%), and verbal abuse is associated with low birth weight (7.6% versus 5.1%).\n\nWomen's violence towards men is a serious social problem. While much attention has been focused on domestic violence against women, researchers argue that domestic violence against men is a substantial social problem worthy of attention. However, the issue of victimization of men by women has been contentious, due in part to studies which report drastically different statistics regarding domestic violence.\n\nSome studies—typically crime studies—show that men are substantially more likely than women to use violence. Other studies—typically family and domestic violence studies—show that men are more likely to inflict injuries, but also that when all acts of physical aggression or violence are considered in aggregate, women are equally violent as men, or more violent than men. \n\nIn May 2007, researchers with the Centers for Disease Control reported on rates of self-reported violence among intimate partners using data from a 2001 study. In the study, almost one-quarter of participants reported some violence in their relationships. Half of these involved one-sided (\"non-reciprocal\") attacks and half involved both assaults and counter assaults (\"reciprocal violence\"). Women reported committing one-sided attacks more than twice as often as men (70% \"versus\" 29%). In all cases of intimate partner violence, women were more likely to be injured than men, but 25% of men in relationships with two-sided violence reported injury compared to 20% of women reporting injury in relationships with one-sided violence. Women were more likely to be injured in non-reciprocal violence.\n\nStraus argues that these discrepancies between the two data sets are due to several factors. For example, Straus notes that crime studies use different methodologies than family conflict studies. Additionally, Straus notes that most studies show that while men inflict the greater portion of injuries, women are \"at least\" as likely as men to shove, punch, slap or otherwise physically assault their partner, and that such relatively minor assaults often escalate to more serious assaults. Men generally do not report such assaults if asked general questions about violence or abuse; older studies frequently failed to ask about specific actions, thus falling afoul of quite different cultural gender norms for what constitutes abuse. \"Minor\" assaults perpetrated by women are also a major problem, even when they do not result in injury, because they put women in danger of much more severe retaliation by men.\n\nThe 2000 CDC report, based on phone interviews with 8000 men and 8000 women, reported that 7.5% of men claim to have been raped or assaulted by an intimate at some time in their life (compared to 25% of women), and 0.9 percent of men claim to have been raped or assaulted in the previous 12 months (compared to 1.5% of women).\n\nA 2007–2008 online non-random, self-report survey of the experiences and health of men who sustained partner violence in the past year. The study showed that male victims of IPV are very hesitant to report the violence or seek help. Reasons given for non-reporting were they (1) may be ashamed to come forward; (2) may not be believed; and (3) may be accused of being a batterer when they do come forward. The 229 U.S. heterosexual men, between 18 and 59, had been physically assaulted by their female partner within previous year and did seek help. The researchers say their findings emphasize the need for prevention on all levels:\n\n\nSome sources state that gay and lesbian couples experience domestic violence at the same frequency as heterosexual couples, while other sources state domestic violence among gay and lesbian couples might be higher than among heterosexual couples, that gay, lesbian, and bisexual individuals are less likely to report domestic violence that has occurred in their intimate relationships than heterosexual couples are, or that lesbian couples experience domestic violence less than heterosexual couples do. By contrast, some researchers commonly assume that lesbian couples experience domestic violence at the same rate as heterosexual couples, and have been more cautious when reporting domestic violence among gay male couples. In a survey by the Canadian Government, some 19% of lesbian women reported being victimized by their partners. Other research reports that lesbian relationships exhibit substantially higher rates of physical aggression.\n\nThe U. S. Department of Health and Human Services reports that for each year between 2000 and 2005, \"female parents acting alone\" were most common perpetrators of child abuse.\n\nWhen it comes to domestic violence towards children involving physical abuse, research in the UK by the NSPCC indicated that \"most violence occurred at home\" (78 per cent). 40—60% of men and women who abuse other adults also abuse their children. Girls whose fathers batter their mothers are 6.5 times more likely to be sexually abused by their fathers than are girls from non-violent homes.\nIn China in 1989, 39,000 baby girls died during their first year of life because they didn't receive the same medical care that would be given to a male child.\n\nIn Asia alone, about one million children working in the sex trade are held in slavery-like conditions.\n\nTeen dating violence is a pattern of controlling behavior by one teenager over another teenager who are in a dating relationship. While there are many similarities to \"traditional\" domestic violence there are also some differences. Teens are much more likely than adults to become isolated from their peers as the result of controlling behavior by their boyfriend/girlfriend. Also, for many teens the abusive relationship may be their first dating experience and have never had a \"normal\" dating experience with which to compare it. While teenagers are trying to establish their sexual identities, they are also confronting violence in their relationships and exposure to technology. Studies document that teenagers are experiencing significant amounts of dating or domestic violence. Depending on the population studied and the way dating violence is defined, between 9 and 35% of teens have experienced domestic violence in a dating relationship. When a broader definition of abuse that encompasses physical, sexual, and emotional abuse is used, one in three teen girls is subjected to dating abuse.\"\n\nAdditionally, a significant number of teens are victims of stalking by intimate partners. Although involvement with romantic relationships is a critical aspect of adolescence, these relationships also present serious risks for teenagers. Unfortunately, adolescents in dating relationships are at greater risk of intimate partner violence than any other age group. Approximately one third of adolescent girls are victims of physical, emotional, or verbal abuse from a dating partner. Estimates of sexual victimization range from 14% to 43% of girls and 0.3% to 36% for boys. According to the Center for Disease Control, in 2009, nearly 10% of students nationwide had been intentionally hit, slapped, or physically hurt by their boyfriend or girlfriend. Twenty-six percent of girls in a relationship reported being threatened with violence or experiencing verbal abuse; 13% reported being physically hurt or hit.\n\nMeasures of the incidence of violence in intimate relationships can differ markedly in their findings depending on the measures used. Care is needed when using domestic violence statistics to ensure that both gender bias and under-reporting issues do not affect the inferences that are drawn from the statistics.\n\nSome researchers, such as Michael P. Johnson, suggest that where and how domestic violence is measured also affects findings, and caution is needed to ensure statistics drawn from one class of situations are not applied to another class of situations in a way that might have fatal consequences. Other researchers, such as David Murray Fergusson, counter that domestic violence prevention services, and statistics that they produce, target the extreme end of domestic violence and preventing child abuse rather than domestic violence between couples.\n\nSurvey approaches to gathering domestic violence statistics have shown inconsistent results with regard to gender differences. Some surveys have shown comparable levels of violence by both men and women against partners, while other surveys have shown higher levels of violence by men. Approaches using data from reports of domestic violence offenses, for example, agency or hospital samples, tend to show women experiencing violence from male partners as the majority of cases (80–90%).\n\nResearch based on the survey-based Conflict Tactics Scale, a measure of intrafamily conflict and violence focusing on the adults in the family developed by Murray Straus (1979), includes national surveys on the prevalence of domestic violence in the United States and other countries. These include the two U.S. National Family Violence Surveys (1975 and 1985) and the National Violence Against Women Survey (2000) (Tjaden & Thoennes, 2000). The National Violence Against Women Survey (2000) found that women experience more intimate partner violence than do men, women experience more chronic and injurious physical assaults at the hands of intimate partners than do men, and that violence perpetrated against women by intimates is often accompanied by emotionally abusive and controlling behavior (Tjaden & Thoennes, 2000).\n\nResearch based on reported domestic violence or on police records show men to be the perpetrators, and women the victims, of most reported domestic violence. However, the intervention of police may introduce a degree of gender bias into reporting. When faced with an uncertain domestic violence situation, removing one party will often defuse an altercation. Police officers may find it easier to take action against a man. This may be due to gender expectations, reinforced by previous incidents. . Additionally, removing the woman may entail involving other social services to care for any existing children for a time, something that may not be in the children's best interests, or may cause a significant delay. The fact that non-domestic offending is often committed by males may also influence an officer's decision.\n\nPolice responding to a complaint may act more favorably to the complainant than other parties (though some researchers report instances where men were attacked, called the police instead of fighting back, yet were arrested themselves). Some researchers have found that women are more likely to report domestic violence to police than men are. In Ireland, 29% of female victims and 5% of male victims of domestic abuse reported the abuse to the police. In the United States, male victims are less likely than female victims to report rape, physical assault, or stalking.\n\nInjury and hospital admission statistics suggest that males are more frequently the perpetrators of injury causing violence. However, both the difference in likelihood of reporting noted above, and the relative strength difference between males and females, could be factors in this reporting bias, as males may be more likely to injure females in otherwise equivalent circumstances.\n\nThe problem of under-reporting to police is believed to be substantial. However, estimates about how much domestic violence is not reported vary widely. It must also be remembered that a significant amount of non-domestic violence crime is also not reported to police. Depending on what statistics are chosen, anywhere between a tenth of incidents and nothing significantly less than what would be expected for any other incident are reported to police.\n\nMany crime victimization surveys, from many countries, do show that there is a correlation between the under-reporting of crime and the degree of intimacy between the victim and the offender. The degree of seriousness of offending also affects reporting, with less serious offending less likely to be reported to police. Also the nature of the offending affects reporting, with sexual offenses far less likely to be reported, even when they are serious.\n\nThe World Conference on Human Rights, held in Vienna in 1993, and the Declaration on the Elimination of Violence Against Women in the same year, concluded that civil society and governments have acknowledged that violence against women is a public health and human rights concern. Work in this area has resulted in the establishment of international standards, but the task of documenting the magnitude of violence against women and producing reliable, comparative data to guide policy and monitor implementation has been exceedingly difficult.\n\nThe World Health Organisation Multi-country Study on Women's Health and Domestic Violence against Women 2005 is a response to this difficulty. Published in 2005 it is a groundbreaking study which analysed data from 10 countries and sheds new light on the prevalence of violence against women. It seeks to look at violence against women a public health policy perspective. The findings will be used to inform a more effective response from government, including the health, justice and social service sectors, as a step towards fulfilling the state's obligation to eliminate violence against women under international human rights laws.\n\nA 1992 Council of Europe study on domestic violence against women found that 1 in 4 women experience domestic violence over their lifetimes and between 6 and 10% of women suffer domestic violence in a given year.\n\nIn the European Union, DV is a serious problem in the Baltic States. These three countries – Estonia, Latvia, and Lithuania – have also lagged behind most post-communist countries in their response to DV. The problem in these countries is very severe, and in 2013 a DV victim won a European Court of Human Rights case against Lithuania.\n\nThe \"British Crime Survey\" for 2006–2007 reported that 0.5% of people (0.6% of women and 0.3% of men) reported being victims of domestic violence during that year and 44.3% of domestic violence was reported to the police. According to the survey, 312,000 women and 93,000 men were victims of domestic violence.\n\nThe \"Northern Ireland Crime Survey\" for 2005 reported that 13% of people (16% of women and 10% of men) reported being victims of domestic violence at some point in their lives.\n\nThe \"National Study of Domestic Abuse\" for 2005 reported that 213,000 women and 88,000 men reported being victims of domestic violence at some point in their lives. According to the study, one in seven women and one in sixteen men were victims of severe physical abuse, severe emotional abuse, or sexual abuse.\n\nIn the United Kingdom, the police estimate that around 35% of domestic violence against women is actually reported. A 2002 Women's Aid study found that 74% of separated women suffered from post-separation violence.\n\nIn Canada, the Assembly of First Nations evaluation of the Canada Prenatal Nutrition Program conducted by CIET offers an inclusive and relatively unbiased national estimate. It documented domestic violence in a random sample of 85 First Nations across Canada: 22% (523/2359) of mothers reported suffering abuse in the year prior to being interviewed; of these, 59% reported physical abuse.\n\nResults of studies which estimate the prevalence of domestic violence vary significantly, depending on specific wording of survey questions, how the survey is conducted, the definition of abuse or domestic violence used, the willingness or unwillingness of victims to admit that they have been abused and other factors. For instance, Straus (2005) conducted a study which estimated that the rate of minor assaults by women in the United States was 78 per 1,000 couples, compared with a rate for men of 72 per 1,000 and the severe assault rate was 46 per 1,000 couples for assaults by women and 50 per 1,000 for assaults by men. Neither difference is statistically significant. He claimed that since these rates were based exclusively on information provided by women respondents, the near-equality in assault rates could not be attributed to a gender bias in reporting.\n\nOne analysis found that \"women are as physically aggressive or more aggressive than men in their relationships with their spouses or male partners\". However, studies have shown that women are more likely to be injured. Archer's meta-analysis found that women in the United States suffer 65% of domestic violence injuries. A Canadian study showed that 7% of women and 6% of men were abused by their current or former partners, but female victims of spousal violence were more than twice as likely to be injured as male victims, three times more likely to fear for their life, twice as likely to be stalked, and twice as likely to experience more than ten incidents of violence. However, Straus notes that Canadian studies on domestic violence have simply excluded questions that ask men about being victimized by their wives.\n\nAccording to a 2004 survey in Canada, the percentages of males being physically or sexually victimized by their partners was 6% versus 7% for women. However, females reported higher levels of repeated violence and were more likely than men to experience serious injuries; 23% of females versus 15% of males were faced with the most serious forms of violence including being beaten, choked, or threatened with or having a gun or knife used against them. Also, 21% of women versus 11% of men were likely to report experiencing more than 10 violent incidents. Women who often experience higher levels of physical or sexual violence from their current partner, were 44%, compared with 18% of men to suffer from an injury. Cases in which women are faced with extremely abusive partners, results in the females having to fear for their lives due to the violence they had faced. In addition, statistics show that 34% of women feared for their lives, and 10% of men feared for theirs.\n\nSome studies show that lesbian relationships have similar levels of violence as heterosexual relationships.\n\nApproximately 1.3 million women and 835,000 men report being physically assaulted by an intimate partner annually in the United States. In the United States, domestic violence is the leading cause of injury to women between the ages of 15 and 44.\n\nVictims of DV are offered legal remedies, which include the criminal law, as well as obtaining a protection order. The remedies offered can be both of a civil nature (civil orders of protection and other protective services) and of a criminal nature (charging the perpetrator with a criminal offense). People perpetrating DV are subject to criminal prosecution, most often under assault and battery laws.\n\nIn Russia, according to a representative of the Russian Ministry of Internal Affairs one in four families experiences domestic violence. Domestic violence is not a specific criminal offense, but it can be charged under various crimes of the criminal code (e.g. assault), but in practice cases of domestic violence turn into criminal cases only when they involve severe injuries, or the victim has died. For more details see Domestic violence in Russia.\n\nIn Turkey 42% of women over 15 have suffered physical or sexual violence.\n\nFighting the prevalence of domestic violence in Kashmir has brought Hindu and Muslim activists together. According to some Islamic clerics and women's advocates, women from Muslim-majority cultures often face extra pressure to submit to domestic violence, as their husbands may manipulate Islamic law to exert their control.\n\nOne study found that half of Palestinian women have been the victims of domestic violence.\n\nA study on Bedouin women in Israel found that most have experienced DV, most accepted it as a decree from God, and most believed they were to blame themselves for the violence. The study also showed that the majority of women were not aware of existing laws and policies which protect them: 60% said they did not know what a restraining order was.\n\nIn Iraq husbands have a legal right to \"punish\" their wives. The criminal code states at Paragraph 41 that there is no crime if an act is committed while exercising a legal right; examples of legal rights include: \"The punishment of a wife by her husband, the disciplining by parents and teachers of children under their\nauthority within certain limits prescribed by law or by custom\".\n\nIn Jordan, part of article 340 of the Penal Code states that \"he who discovers his wife or one of his female relatives committing adultery and kills, wounds, or injures one of them, is exempted from any penalty.\" This has twice been put forward for cancellation by the government, but was retained by the Lower House of the Parliament, in 2003: a year in which at least seven honor killings took place. Article 98 of the Penal Code is often cited alongside Article 340 in cases of honor killings. \"Article 98 stipulates that a reduced sentence is applied to a person who kills another person in a 'fit of fury'\".\n\nThe Human Rights Watch found that up to 90% of women in Pakistan were subject to some form of maltreatment within their own homes. Honor killings in Pakistan are a very serious problem, especially in northern Pakistan.\nIn Pakistan, honour killings are known locally as \"karo-kari\". Karo-kari is a compound word literally meaning \"black male\" (Karo) and \"black female (Kari).\n\nDomestic violence in India is widespread, and is often related to the custom of dowry. Although not as common as in other parts of Asia, honor killings do occur in some regions of India, particularly in northern regions of the country. Honor killings have been reported in the states of Punjab, Rajasthan, Haryana, Uttar Pradesh, and Bihar, as a result of people marrying without their family's acceptance, and sometimes for marrying outside their caste or religion.\n\nA UN report compiled from a number of different studies conducted in at least 71 countries found domestic violence against women to be most prevalent in Ethiopia.\n\nUp to two-thirds of women in certain communities in Nigeria's Lagos State say they are victims to domestic violence.\n\n80% of women surveyed in rural Egypt said that beatings were common and often justified, particularly if the woman refused to have sex with her husband.\n\nStatistics published in 2004, show that the rate of domestic violence victimisation for Indigenous women in Australia may be 40 times the rate for non-Indigenous women.\n\nFindings from the 2006 Australian Bureau of Statistics Personal Safety Survey show that among the female victims of physical assault, 31 percent were assaulted by a current or previous partner. Among male victims, 4.4 percent were assaulted by a current or previous partner. Thirty per cent of people who had experienced violence by a current partner since the age of 15 were male, and seventy per cent were female.\n\n"}
{"id": "9210345", "url": "https://en.wikipedia.org/wiki?curid=9210345", "title": "Gaussian adaptation", "text": "Gaussian adaptation\n\nGaussian adaptation (GA) (also referred to as normal or natural adaptation and sometimes abbreviated as NA) is an evolutionary algorithm designed for the maximization of manufacturing yield due to statistical deviation of component values of signal processing systems. In short, GA is a stochastic adaptive process where a number of samples of an \"n\"-dimensional vector \"x\"[\"x\" = (\"x\", \"x\", ..., \"x\")] are taken from a multivariate Gaussian distribution, \"N\"(\"m\", \"M\"), having mean \"m\" and moment matrix \"M\". The samples are tested for fail or pass. The first- and second-order moments of the Gaussian restricted to the pass samples are \"m*\" and \"M*\".\n\nThe outcome of \"x\" as a pass sample is determined by a function \"s\"(\"x\"), 0 < \"s\"(\"x\") < \"q\" ≤ 1, such that \"s\"(\"x\") is the probability that x will be selected as a pass sample. The average probability of finding pass samples (yield) is\n\nThen the theorem of GA states:\n\nFor any \"s\"(\"x\") and for any value of \"P \"< \"q\", there always exist a Gaussian p. d. f. [ probability density function ] that is adapted for maximum dispersion. The necessary conditions for a local optimum are \"m\" = \"m\"* and \"M\" proportional to \"M\"*. The dual problem is also solved: \"P\" is maximized while keeping the dispersion constant (Kjellström, 1991).\nProofs of the theorem may be found in the papers by Kjellström, 1970, and Kjellström & Taxén, 1981.\n\nSince dispersion is defined as the exponential of entropy/disorder/average information it immediately follows that the theorem is valid also for those concepts. Altogether, this means that Gaussian adaptation may carry out a simultaneous maximisation of yield and average information (without any need for the yield or the average information to be defined as criterion functions).\n\nThe theorem is valid for all regions of acceptability and all Gaussian distributions. It may be used by cyclic repetition of random variation and selection (like the natural evolution). In every cycle a sufficiently large number of Gaussian distributed points are sampled and tested for membership in the region of acceptability. The centre of gravity of the Gaussian, \"m\", is then moved to the centre of gravity of the approved (selected) points, \"m\"*. Thus, the process converges to a state of equilibrium fulfilling the theorem. A solution is always approximate because the centre of gravity is always determined for a limited number of points.\n\nIt was used for the first time in 1969 as a pure optimization algorithm making the regions of acceptability smaller and smaller (in analogy to simulated annealing, Kirkpatrick 1983). Since 1970 it has been used for both ordinary optimization and yield maximization.\n\nIt has also been compared to the natural evolution of populations of living organisms. In this case \"s\"(\"x\") is the probability that the individual having an array \"x\" of phenotypes will survive by giving offspring to the next generation; a definition of individual fitness given by Hartl 1981. The yield, \"P\", is replaced by the mean fitness determined as a mean over the set of individuals in a large population.\n\nPhenotypes are often Gaussian distributed in a large population and a necessary condition for the natural evolution to be able to fulfill the theorem of Gaussian adaptation, with respect to all Gaussian quantitative characters, is that it may push the centre of gravity of the Gaussian to the centre of gravity of the selected individuals. This may be accomplished by the Hardy–Weinberg law. This is possible because the theorem of Gaussian adaptation is valid for any region of acceptability independent of the structure (Kjellström, 1996).\n\nIn this case the rules of genetic variation such as crossover, inversion, transposition etcetera may be seen as random number generators for the phenotypes. So, in this sense Gaussian adaptation may be seen as a genetic algorithm.\n\nMean fitness may be calculated provided that the distribution of parameters and the structure of the landscape is known. The real landscape is not known, but figure below shows a fictitious profile (blue) of a landscape along a line (x) in a room spanned by such parameters. The red curve is the mean based on the red bell curve at the bottom of figure. It is obtained by letting the bell curve slide along the \"x\"-axis, calculating the mean at every location. As can be seen, small peaks and pits are smoothed out. Thus, if evolution is started at A with a relatively small variance (the red bell curve), then climbing will take place on the red curve. The process may get stuck for millions of years at B or C, as long as the hollows to the right of these points remain, and the mutation rate is too small.\n\nIf the mutation rate is sufficiently high, the disorder or variance may increase and the parameter(s) may become distributed like the green bell curve. Then the climbing will take place on the green curve, which is even more smoothed out. Because the hollows to the right of B and C have now disappeared, the process may continue up to the peaks at D. But of course the landscape puts a limit on the disorder or variability. Besides — dependent on the landscape — the process may become very jerky, and if the ratio between the time spent by the process at a local peak and the time of transition to the next peak is very high, it may as well look like a punctuated equilibrium as suggested by Gould (see Ridley).\n\nThus far the theory only considers mean values of continuous distributions corresponding to an infinite number of individuals. In reality however, the number of individuals is always limited, which gives rise to an uncertainty in the estimation of \"m\" and \"M\" (the moment matrix of the Gaussian). And this may also affect the efficiency of the process. Unfortunately very little is known about this, at least theoretically.\n\nThe implementation of normal adaptation on a computer is a fairly simple task. The adaptation of m may be done by one sample (individual) at a time, for example\n\nwhere \"x\" is a pass sample, and \"a\" < 1 a suitable constant so that the inverse of a represents the number of individuals in the population.\n\n\"M\" may in principle be updated after every step \"y\" leading to a feasible point\n\nwhere \"y\" is the transpose of \"y\" and \"b\" « 1 is another suitable constant. In order to guarantee a suitable increase of average information, \"y\" should be normally distributed with moment matrix \"μ\"\"M\", where the scalar \"μ\" > 1 is used to increase average information (information entropy, disorder, diversity) at a suitable rate. But \"M\" will never be used in the calculations. Instead we use the matrix \"W\" defined by \"WW\" = \"M\".\n\nThus, we have \"y\" = \"Wg\", where \"g\" is normally distributed with the moment matrix \"μU\", and \"U\" is the unit matrix. \"W\" and \"W\" may be updated by the formulas\n\nbecause multiplication gives\n\nwhere terms including \"b\" have been neglected. Thus, \"M\" will be indirectly adapted with good approximation. In practice it will suffice to update \"W\" only\n\nThis is the formula used in a simple 2-dimensional model of a brain satisfying the Hebbian rule of associative learning; see the next section (Kjellström, 1996 and 1999).\n\nThe figure below illustrates the effect of increased average information in a Gaussian p.d.f. used to climb a mountain Crest (the two lines represent the contour line). Both the red and green cluster have equal mean fitness, about 65%, but the green cluster has a much higher average information making the green process much more efficient. The effect of this adaptation is not very salient in a 2-dimensional case, but in a high-dimensional case, the efficiency of the search process may be increased by many orders of magnitude.\n\nIn the brain the evolution of DNA-messages is supposed to be replaced by an evolution of signal patterns and the phenotypic landscape is replaced by a mental landscape, the complexity of which will hardly be second to the former. The metaphor with the mental landscape is based on the assumption that certain signal patterns give rise to a better well-being or performance. For instance, the control of a group of muscles leads to a better pronunciation of a word or performance of a piece of music.\n\nIn this simple model it is assumed that the brain consists of interconnected components that may add, multiply and delay signal values.\nThis is a basis of the theory of digital filters and neural networks consisting of components that may add, multiply and delay signalvalues and also of many brain models, Levine 1991.\n\nIn the figure below the brain stem is supposed to deliver Gaussian distributed signal patterns. This may be possible since certain neurons fire at random (Kandel et al.). The stem also constitutes a disordered structure surrounded by more ordered shells (Bergström, 1969), and according to the central limit theorem the sum of signals from many neurons may be Gaussian distributed. The triangular boxes represent synapses and the boxes with the + sign are cell kernels.\n\nIn the cortex signals are supposed to be tested for feasibility. When a signal is accepted the contact areas in the synapses are updated according to the formulas below in agreement with the Hebbian theory. The figure shows a 2-dimensional computer simulation of Gaussian adaptation according to the last formula in the preceding section.\n\n\"m\" and \"W\" are updated according to:\n\nAs can be seen this is very much like a small brain ruled by the theory of Hebbian learning (Kjellström, 1996, 1999 and 2002).\n\nGaussian adaptation as an evolutionary model of the brain obeying the Hebbian theory of associative learning offers an alternative view of free will due to the ability of the process to maximize the mean fitness of signal patterns in the brain by climbing a mental landscape in analogy with phenotypic evolution.\n\nSuch a random process gives us lots of freedom of choice, but hardly any will. An illusion of will may, however, emanate from the ability of the process to maximize mean fitness, making the process goal seeking. I. e., it prefers higher peaks in the landscape prior to lower, or better alternatives prior to worse. In this way an illusive will may appear. A similar view has been given by Zohar 1990. See also Kjellström 1999.\n\nThe efficiency of Gaussian adaptation relies on the theory of information due to Claude E. Shannon (see information content). When an event occurs with probability \"P\", then the information −log(\"P\") may be achieved. For instance, if the mean fitness is \"P\", the information gained for each individual selected for survival will be −log(\"P\") – on the average - and the work/time needed to get the information is proportional to 1/\"P\". Thus, if efficiency, E, is defined as information divided by the work/time needed to get it we have:\n\nThis function attains its maximum when \"P\" = 1/\"e\" = 0.37. The same result has been obtained by Gaines with a different method.\n\n\"E\" = 0 if \"P\" = 0, for a process with infinite mutation rate, and if \"P\" = 1, for a process with mutation rate = 0 (provided that the process is alive).\nThis measure of efficiency is valid for a large class of random search processes provided that certain conditions are at hand.\n\n1 The search should be statistically independent and equally efficient in different parameter directions. This condition may be approximately fulfilled when the moment matrix of the Gaussian has been adapted for maximum average information to some region of acceptability, because linear transformations of the whole process do not affect efficiency.\n\n2 All individuals have equal cost and the derivative at \"P\" = 1 is < 0.\n\nThen, the following theorem may be proved:\n\nAll measures of efficiency, that satisfy the conditions above, are asymptotically proportional to –\"P\" log(\"P/q\") when the number of dimensions increases, and are maximized by \"P\" = \"q\" exp(-1) (Kjellström, 1996 and 1999).\nThe figure above shows a possible efficiency function for a random search process such as Gaussian adaptation. To the left the process is most chaotic when \"P\" = 0, while there is perfect order to the right where \"P\" = 1.\n\nIn an example by Rechenberg, 1971, 1973, a random walk is pushed thru a corridor maximizing the parameter \"x\". In this case the region of acceptability is defined as a (\"n\" − 1)-dimensional interval in the parameters \"x\", \"x\", ..., \"x\", but a \"x\"-value below the last accepted will never be accepted. Since \"P\" can never exceed 0.5 in this case, the maximum speed towards higher \"x\"-values is reached for \"P\" = 0.5/\"e\" = 0.18, in agreement with the findings of Rechenberg.\n\nA point of view that also may be of interest in this context is that no definition of information (other than that sampled points inside some region of acceptability gives information about the extension of the region) is needed for the proof of the theorem. Then, because, the formula may be interpreted as information divided by the work needed to get the information, this is also an indication that −log(\"P\") is a good candidate for being a measure of information.\n\nGaussian adaptation has also been used for other purposes as for instance shadow removal by \"The Stauffer-Grimson algorithm\" which is equivalent to Gaussian adaptation as used in the section \"Computer simulation of Gaussian adaptation\" above. In both cases the maximum likelihood method is used for estimation of mean values by adaptation at one sample at a time.\n\nBut there are differences. In the Stauffer-Grimson case the information is not used for the control of a random number generator for centering, maximization of mean fitness, average information or manufacturing yield. The adaptation of the moment matrix also differs very much as compared to \"the evolution in the brain\" above.\n\n\n"}
{"id": "29412930", "url": "https://en.wikipedia.org/wiki?curid=29412930", "title": "Giving What We Can", "text": "Giving What We Can\n\nGiving What We Can (GWWC) is an effective altruism associated organization whose members pledge to give 10% of their income to effective charities. It was founded at Oxford University in 2009 by the ethics researcher Toby Ord.\n\nGiving What We Can was founded as a giving society in 2009 by Toby Ord, an ethics researcher at Oxford, his wife Bernadette Young, a physician in training at the time, and fellow ethicist William MacAskill \nwith the goal of encouraging people to give 10% of their income on a regular basis to alleviate world poverty. This is similar to zakat or tithing but Ord said there was no religious motivation behind it. Ord cited writings from Peter Singer and Thomas Pogge about one's moral duty to give to the poor as inspiration for starting the organization, and personally planned to give away everything above about $28,000 a year, the median after-tax salary in the U.K. His focus was on effective giving, meaning that he emphasized donations to charities which saved a maximal amount of life per donation amount.\nGWWC was launched with 23 members. People who joined signed a pledge to give away 10% of their income to any organization they thought could best address poverty in the developing world, and could pledge more; there was no penalty for quitting. By the end of 2011 it had 177 members, mostly other academics, in five chapters including Oxford, Cambridge, Princeton, and Harvard. By 2012 the group had 264 people from 17 countries, and it surpassed 1,000 members in 2015.\n\nBy November 2011 the organization was providing its members regular reports on what charities were most effective at addressing poverty in the developing world, and at that time was recommending a tropical diseases group and a de-worming group that each worked in Africa. Ord relied in part on research conducted by GiveWell, and also used the concept of the QALY to gauge effectiveness of charities.\n\nIn 2011 a sister organization was spun off from Giving from What We Can at Oxford by MacAskill and others called \"High Impact Careers\" which encouraged people to pursue high-paying jobs so they could give more money away. Both organizations conducted outreach and recruiting at Oxford. High Impact Careers was soon renamed to 80,000 Hours. In 2012 the two organizations incorporated the Centre for Effective Altruism as a nonprofit to serve as an umbrella organization.\n\nGiving What We Can conducts research to determine which charities it recommends for members and other people to support. It differs from other charity evaluators in terms of the importance given to metrics of charity performance. While evaluators such as Charity Navigator use the fraction of donations spent on program expenses versus administrative overhead as an important indicator, Giving What We Can solely focuses on the cost-effectiveness of the charity's work. It believes that the variance in cost-effectiveness of charities arises largely due to the variance in the nature of the causes that the charities operate in, and therefore makes evaluations across broad areas of work such as health, education, and emergency aid before comparing specific organizations. In practice, it recommends a selected few charities in the area of global health. Its work is therefore similar to that of GiveWell.\n\n"}
{"id": "9258445", "url": "https://en.wikipedia.org/wiki?curid=9258445", "title": "Global Youth Service Day", "text": "Global Youth Service Day\n\nGlobal Youth Service Day (GYSD), originally launched and known as National Youth Service Day in the United States, is a coordinated annual event which gathers young people around the world in conducting community service, service learning, and youth voice activities that benefit their communities, their countries, and the world. Activities are organized in more than 100 countries each April to help mark the celebrations, and engage millions, making it the largest annual celebration of young volunteers.\n\nIn 2019, the event will be April 12-14. Coordinated by Youth Service America together with a coalition of organizations, GYSD's primary sponsor is State Farm with contributing sponsorship from Disney and the Inter-American Development Bank. More than 2,000 youth organizations around the world participate each year. A variety of organizations with national reach across the United States engage in National Youth Service Day activities, including the United States Conference of Mayors, Woodmen of the World, and Habitat for Humanity. A variety of organizations have been accredited with administering the day, including Global Youth Action Network, Youth Service America, and Points of Light Foundation.\n\nSpeaking about Global Youth Service Day, Jane Goodall commented, \"I have often said that every individual counts, every individual has a role to play, and every individual makes a difference. Global Youth Service Day proves it.\" Kofi Annan said that, \"Volunteers are some of our most valued partners, and Global Youth Service Day celebrates the efforts of the youngest of them.\"\n\n\n"}
{"id": "347098", "url": "https://en.wikipedia.org/wiki?curid=347098", "title": "Going postal", "text": "Going postal\n\nGoing postal is an American English slang phrase referring to becoming extremely and uncontrollably angry, often to the point of violence, and usually in a workplace environment. The expression derives from a series of incidents from 1986 onward in which United States Postal Service (USPS) workers shot and killed managers, fellow workers, and members of the police or general public in acts of mass murder. Between 1970 and 1997, more than 40 people were killed by current or former employees in at least 20 incidents of workplace rage. Between 1986 and 2011, workplace shootings happened at roughly two per year, with an average of 12 people killed per year.\n\nThe earliest known use of the phrase was on December 17, 1993, in the \"St. Petersburg Times\":\n\nOn December 31, 1993, the \"Los Angeles Times\" stated:\n\nOn August 20, 1986, during the Edmond post office shooting, 14 employees were shot and killed and six were wounded at the Edmond, Oklahoma, post office by Patrick Sherrill, a postman who then committed suicide with a shot to the forehead.\n\nA former United States postal worker, Joseph M. Harris, killed his former supervisor, Carol Ott, and killed her boyfriend, Cornelius Kasten Jr., at their home. The following morning, on October 10, 1991, Harris shot and killed two mail handlers, Joseph M. VanderPaauw, 59, of Prospect Park, New Jersey, and Donald McNaught, 63, of Pompton Lakes, New Jersey, at the Ridgewood Post Office.\n\nOn November 14, 1991 in Royal Oak, Michigan, Thomas McIlvane killed five people, including himself, with a rifle in Royal Oak's post office, after being fired from the Postal Service for \"insubordination.\" He had been previously suspended for getting into altercations with postal customers on his route.\n\nFor some time prior to the Royal Oak incident the service had experienced labor/management and operational problems and customer service complaints. This had drawn the attention of local media. The Office of Senator Carl Levin investigated Royal Oak, the results of which were summarized in a September 10, 1991, staff memorandum. The memorandum documented \"patterns of harassment, intimidation, cruelty and allegations of favoritism in promotions and demotions ... [and] testimony relating to wide-ranging delivery and service problems\" prior to the McIlvane shooting.\n\nTwo shootings took place on the same day, May 6, 1993, a few hours apart. At a post office in Dearborn, Michigan, Lawrence Jasion wounded three and killed one, and subsequently killed himself. In Dana Point, California, Mark Richard Hilbun killed his mother and her dog, then shot two postal workers dead.\nAs a result of these two shootings, in 1993 the USPS created 85 Workplace Environment Analysts for domicile at its 85 postal districts. These new positions were created to help with violence prevention and workplace improvement. In February 2009, the USPS unilaterally eliminated these positions as part of its downsizing efforts.\n\nJennifer San Marco, a former postal employee, killed six postal employees before committing suicide with a handgun, on the evening of January 30, 2006, at a large postal processing facility in Goleta, California. Police later also identified a seventh victim dead in a condominium complex in Goleta where San Marco once lived. According to media reports, the Postal Service had forced San Marco to retire in 2003 because of her worsening mental problems. This incident is believed to be the deadliest workplace shooting ever carried out in the United States by a woman.\n\nGrant Gallaher, a letter carrier in Baker City, Oregon, pleaded guilty to the April 4, 2006 murder of his supervisor. He reportedly brought his .357 Magnum revolver to the city post office with the intention of killing his postmaster. When he arrived at the parking lot, he reportedly ran over his supervisor several times. He then went into the post office looking for his postmaster. Not finding him, he went back out to the parking lot and shot his supervisor. Gallaher was on a new route for three weeks and had felt pressured by a week-long work-time study and extra time added to his new route.\n\nOn June 14, 2017, Jimmy Lam, 38, fatally shot three coworkers at a United Parcel Service (UPS) facility in the Potrero Hill neighborhood of San Francisco, California. Lam then shot and killed himself as police arrived at the facility. Two others were wounded by gunfire, and three people were injured while escaping.\n\nPostal worker DeShaune Stewart murdered two colleagues, his supervisor and the postmaster, on December 23, 2017.\n\nResearchers have found that the homicide rates at postal facilities were lower than at other workplaces. In major industries, the highest rate of 2.1 homicides per 100,000 workers per year was in retail. The homicide rate for postal workers was 0.22 per 100,000 versus 0.77 per 100,000 workers in general. The common depiction of an employee returning to work for revenge on his boss is overdone. More than half of mass workplace shooting are by current employees, and a little under a quarter are by employees who have been at their job for less than a year.\n\nIn 1998, the United States Congress conducted a joint hearing to review the violence in the U.S. Postal Service. In the hearing, it was noted that despite the postal service accounting for less than 1% of the full-time civilian labor force, 13% of workplace homicides were committed at postal facilities by current or former employees.\n\nIn the controversial video game series \"Postal\", the player takes on the role of an insane mass murderer in the first game, and in the later series a first-person role performing normally mundane chores (such as picking up a paycheck from work) with an often gratuitously violent twist. In 1997, the USPS sued the creators of the game, Running With Scissors, over the use of the term \"postal\". Running With Scissors argued that, despite its title, the game has absolutely nothing to do with the USPS or its employees. The case was dismissed with prejudice in 2003.\n\nThe 1994 comedy film \"\" includes a scene where the main character must deal with a series of escalating threats, including the sudden appearance of dozens of disgruntled postal workers randomly firing weapons in every direction.\n\nThe 1995 film \"Clueless\" is credited with popularizing the phrase \"going postal\" and is responsible for the term's casual usage still today. The actors in the film had no idea what it meant to \"go postal,\" since it was an uncommon phrase at the time.\n\nThe title of the 2004 book \"Going Postal\" by Terry Pratchett makes reference to the contents of the novel, but in future novels of the Discworld universe characters use the term \"going postal\" in the common sense, apparently referring to the events of \"Going Postal\".\n\nAs referenced on the Simpsons, during Episode \"Sunday Cruddy Sunday\", Bart and Lisa visit the post office and Nelson asks:\n\nIn the \"Brooklyn Nine-Nine\" episode \"USPIS\", a self-righteous United States Postal Inspection Service agent passionate about his job is adamant that \"going postal\" is the term most associated with bringing goodness into people's lives, which is a view also shared by his co-workers.\n\n\n\n"}
{"id": "54910567", "url": "https://en.wikipedia.org/wiki?curid=54910567", "title": "Horn effect", "text": "Horn effect\n\nThe horn effect, closely related to the halo effect, is a form of cognitive bias that causes one's perception of another to be unduly influenced by a single negative trait. An example of the horn effect may be that an observer is more likely to assume a physically unattractive person is morally inferior to an attractive person, despite the lack of relationship between morality and physical appearance.\n\nThe term is derived from the English word \"horn\" and refers to the devil's horns. This is in contrast to the word halo and the halo effect, based on the concept of a saint's halo.\n\nIn a 1920 study published by Thorndike that focused on the halo effect, it was noted that \"ratings were apparently affected by a marked tendency to think of the person in general as rather good or rather inferior and to color the judgments of the qualities by this general feeling\".\n\nIt is sometimes called the \"horns effect\", \"reverse-halo effect\", or \"devil effect\".\n\nThe horn effect occurs when \"individuals believe that negative traits are connected to each other.\" It is a phenomenon in which an observer's judgment of a person is adversely affected by the presence of (for the observer) an unfavorable aspect of this person.\n\n"}
{"id": "1673339", "url": "https://en.wikipedia.org/wiki?curid=1673339", "title": "Hyperfocus", "text": "Hyperfocus\n\nHyperfocus is an intense form of mental concentration or visualization that focuses consciousness on a subject, topic, or task. In some individuals, various subjects or topics may also include daydreams, concepts, fiction, the imagination, and other objects of the mind. Hyperfocus on a certain subject can cause side-tracking away from assigned or important tasks.\n\nHyperfocus may bear a relationship to the concept of flow. In some circumstances, both flow and hyperfocus can be an aid to achievement, but in other circumstances or situations, the same focus and behavior could be a liability, distracting from the task at hand. However, unlike hyperfocus, \"flow\" is often described in more glowing terms, suggesting they are not two sides of the same condition under contrasting circumstance or intellect.\n\nHyperfocus may in some cases also be symptomatic of a psychiatric condition. In these cases, it is more commonly and accurately referred to as perseveration—an inability or impairment in switching tasks or activities (\"set-shifting\"), or desisting from mental or physical response repetition (gestures, words, thoughts) despite absence or cessation of a stimulus, and which is not excessive in terms of quantity but are apparently both functionless and involve a narrow range of behaviours, and are not better described as stereotypy (a highly repetitive idiosyncratic behaviour).\n\nConditions associated with perseveration include neurodevelopmental disorders, particularly those considered to be on the autism spectrum (especially Asperger syndrome), and attention deficit hyperactivity disorder (ADHD). In the latter, it is informally but probably incorrectly called \"hyperfocus\" and may be a coping mechanism or a symptom of self-regulation impairment—as well as people who are both intellectually gifted and suffer a learning disability who may have either or both of hyperfocus and perseverative behaviours. Other conditions involving dysfunction or disregulation within the frontal lobe could also theoretically have similar effects.\n\nIt is typical for individuals with ADHD to say they 1), cannot focus on boring things and 2), can only focus on stimulating things, and \"that focus is often extreme\". Thus, it is both a concentration deficit and over-concentration, or generically: \"hyperfocus.\" More concisely, some types of ADHD are a difficulty in \"directing\" one's attention, (an executive function of the frontal lobe), \"not\" a lack of attention. Glickman & Dodd (1998) found that adults with self-reported ADHD scored higher than normal adults on self-reported ability to hyperfocus on \"urgent tasks\" such as last-minute projects or preparations. Adults in the ADHD group were uniquely able to postpone eating, sleeping and other personal needs and stay absorbed in the \"urgent task\" for an extended time.\n\nClinical conditions unlikely to be confused with hyperfocus often involve repetition of thoughts or behaviors such as obsessive–compulsive disorder (OCD), trauma, and some cases of traumatic brain injury.\n\n\n"}
{"id": "511459", "url": "https://en.wikipedia.org/wiki?curid=511459", "title": "In camera", "text": "In camera\n\nIn camera (; Latin: \"in a chamber\") is a legal term that means \"in private\". The same meaning is sometimes expressed in the English equivalent: in chambers. Generally, \"in-camera\" describes court cases, parts of it, or process where the public and press are not allowed to observe the procedure or process. \"In-camera\" is the opposite of trial in open court where all parties and witnesses testify in a public courtroom, and attorneys publicly present their arguments to the trier of fact.\n\nEntire cases may be heard \"in-camera\" when, for example, matters of national security are involved. \"In-camera\" review by a judge may be used during otherwise open trials—for example, to protect trade secrets or where one party asserts privilege (such as attorney–client privileged communications). This lets the judge review documents in private to determine if revelation of documents in open court will be allowed.\n\nIn United States courts in-camera review describes a process or procedure where a judge privately looks at confidential, sensitive, or private information to determine what, if any, information may be used by a party or made public. An \"in camera review\" may be at someone's request (such as counsel in the case), or by order of the court. \n\nAn example of \"in-camera review\" by the court: a defendant prosecuted for the alleged murder of a high school student asserts his was an act of self-defense, a last resort after the deceased physically assaulted the defendant. Witnesses tell investigators and lawyers that the victim \"was always getting into fights in school\" and frequently had to visit the principal's office. The defendant seeks to obtain the deceased's high school files to see if there's anything proving the deceased fighting at school. A party for the deceased's family might argue against disclosure on the basis that school records which are presumably private should not be provided to the defendant. While a judge might acknowledge the general presumption, the court might permit the defendant limited use at trial any school records that may establish the deceased's physically aggressive tendencies. \n\nIn this example, before allowing disclosure of files to the defendant, or for revelation of the records to the jury, the judge would \"in camera\" inspect the deceased's high school records to determine what records, if any, the judge will release to the defendant. Note: The judge has complete authority on an in-camera review. The judge may disallow use of some or all of the records reviewed, limit use or purpose, and to order a party to take all steps necessary to keep private and confidential the information released. \n\n\"In-camera\" can also describe closed board meetings that cover information not recorded in the minutes or divulged to the public. Such sessions may discuss personnel, financial, or other sensitive decisions that must be kept secret (e.g., a proposed merger or strategic change the organization does not want disclosed to competitors). It can also apply to diplomatic and political affairs, such as during the American Constitutional Convention in 1787 when the drafting of the Constitution of the United States was discussed in such strict privacy so delegates could negotiate in full confidence that they were free to reconsider particular positions as necessary without embarrassment or political repercussions with their constituents. \n\n\"In camera\" may also mean the portion of a graduate level thesis examination that includes only the examining committee and the student. This follows a presentation by the student that the public may attend.\n\n"}
{"id": "315981", "url": "https://en.wikipedia.org/wiki?curid=315981", "title": "Jimmy Cauty", "text": "Jimmy Cauty\n\nJames Francis Cauty (born 19 December 1956), also known as Rockman Rock, is an English artist and musician, best known as one half of the duo The KLF, co-founder of The Orb and as the man who burnt one million pounds.\n\nCauty was married to Cressida (née Bowyer), with whom he has twins, Daisy and Harry, and a younger son, Alfie. He later married artist and musician Alannah Currie (formerly of Thompson Twins) in 2011.\n\nCauty was born on the Wirral Peninsula in Cheshire. As a 17-year-old artist, he drew a popular \"The Lord of the Rings\" poster (and later, a counterpart based on \"The Hobbit\") for British retailer Athena, as well as the cover for the concept album \"The King of Elfland's Daughter\".\n\nIn 1981-2 Cauty was guitarist in a band called Angels 1–5, who recorded a Peel session on 1 July 1981. Lead vocalist was Cressida Bowyer, whom Cauty later married. He then joined the band Brilliant with which he remained until its break-up in 1986. Cauty was also an original member of Zodiac Mindwarp and the Love Reaction, in 1985.\n\nCauty joined with Bill Drummond to form The Justified Ancients of Mu Mu (The JAMs), a collaboration that played out in various guises and media over much of the next decade.\n\nAs an A&R man, Drummond had signed Brilliant to WEA. Concocting a scheme for a hip-hop record on New Year's Day 1987, Drummond needed a like-minded collaborator with expertise in current music technology, and so contacted Cauty. Drummond later commented that Cauty \"knew exactly, to coin a phrase, 'where I was coming from'\", said Drummond. A week later, The JAMs had recorded their debut single, \"All You Need Is Love\". Several singles and three albums as The JAMs followed (their debut, \"1987\"; the follow-up, \"Who Killed The JAMs?\"; and compilation \"Shag Times\") before a change of direction saw the duo mutate into dance and ambient music pioneers, The KLF. Along the way, the duo scored their first British number one hit single as The Timelords with the Gary Glitter/Dr. Who novelty-pop mash-up \"Doctorin' the Tardis\", claimed to be sung by Cauty's 1968 Ford Galaxie American police car.\n\nThe KLF released two albums, \"Chill Out\" and \"The White Room\", and a string of top 5 singles, becoming the biggest selling singles act in the world in 1991. In 1992, suddenly and very publicly, The KLF retired from the music industry and deleted their entire back catalogue.\n\nDrummond and Cauty re-emerged in 1993 as the K Foundation, releasing one limited edition single (\"K Cera Cera\") and awarding the £40,000 K Foundation art award for the \"worst artist of the year\". In 1994, the duo courted infamy by setting fire to one million pounds in cash on the Scottish island of Jura. In 1995, they undertook a screening tour of a film of the burning, before signing a moratorium on K Foundation activities.\n\nCauty worked with Drummond again in 1997 with a campaign to \"Fuck the Millennium\", the highlight of which was a 23-minute live performance satirising the \"pop comeback\", in which Cauty and Drummond appeared as grey-haired pensioners and wheeled around the stage in electric wheelchairs.\n\nThroughout The KLF's career, Drummond was most often the mouthpiece of the group and is regularly mistakenly viewed as their chief protagonist but in fact Cauty was just as instrumental in developing ideas and actions in the duo as is evident in his practice as an individual artist. As described by the \"NME\" their joint and individual work displays \"honesty mixed with deranged publicity-seeking, pop terrorism ideas mixed with utter strangeness and mysticism..., and a sense that the things pop groups do should be visionary and above all should not be mundane.\"\n\nCauty's wife at the time, Cressida, also helped out, taking on an organisational role for KLF Communications, in addition to design and choreography work for The KLF, and her own work as an artist.\n\nIn the late 1980s, Cauty met Alex Paterson and the duo began DJ-ing and producing together as The Orb. Paterson and Cauty's first release was a 1988 acid house anthem track, \"Tripping on Sunshine\" released on the German record compilation \"Eternity Project One\". The following year, The Orb released the \"Kiss EP\", a four-track EP based on samples from New York City's Kiss FM. It was released on Paterson and Glover's new record label WAU/Mr. Modo Records, which Paterson and Glover created out of a desire to maintain financial independence from larger record labels. \n\nAfter spending a weekend of making what Paterson described as \"really shit drum sounds\", the duo decided to abandon beat-heavy music and instead work on music for after-hours listening by \"taking the bloody drums away\". Paterson and Cauty began DJ-ing in London and landed a deal for The Orb to play the chill-out room at London nightclub Heaven. Resident DJ Paul Oakenfold brought in the duo specifically as ambient DJs for his \"The Land of Oz\" event at Heaven. \n\nThough initially The Orb's Monday night performances had only several \"hard-core\" followers, their \"Chill Out Room\" act grew popular over the course of their six-month stay at Heaven to the point that the small room was often packed with around 100 people. The Orb's performances became especially popular among weary DJs and clubbers who sought solace from the loud, rhythmic music of the dancefloor. The Orb would build up melodies using multitrack recordings linked to multiple record decks and a mixer. They incorporated many CDs, cassettes, and BBC sound effects into their act, often accompanied with pieces of popular dance tracks such as \"Sueño Latino\". Most often, they played dub and other chill out music which Bill Drummond described as \"Ambient house for the E generation.\"\n\nThroughout 1989, Paterson, Cauty, Drummond and Martin Glover developed the musical genre of ambient house through the use of a diverse array of samples and recordings. The culmination of Cauty and Paterson's musical work came towards the end of the year when The Orb recorded a session for John Peel on BBC Radio 1. The track, then known as \"Loving You\", was largely improvisational and featured a wealth of sound effects and samples from science fiction radio plays, nature sounds, and Minnie Riperton's \"Lovin' You\". The Orb changed the title to \"A Huge Ever Growing Pulsating Brain That Rules from the Centre of the Ultraworld\". In 1990, Cauty and Drummond held a chillout party at Trancentral, a recording of Patersons DJing was made with a view to releasing it as an LP but the mix contained many uncleared samples and other records and was unusable. Later that year Cauty and Drummond went to the isle of Jura, Scotland to record a techno record called Gate. Instead they created a long form ambient film called Waiting (1990). During the same year Cauty and Drummond went into the studio and made the ambient LP \"Chill Out\". The \"Grove Dictionary\" suggests \"Chill Out\" to be the first ambient house album. \n\nWhen offered an album deal by Big Life, The Orb found themselves at a crossroads. Cauty preferred that albums by The Orb were released on his KLF Communications label, whereas Paterson wanted to ensure The Orb did not become an offshoot of The KLF. Due to these issues, Cauty and Paterson split in April 1990, with Paterson keeping the name \"The Orb\". Cauty removed Paterson's contributions from the recordings in progress and released the album as \"Space\" on KLF Communications.\n\nIn 1999 Cauty produced several remixes under the alias The Scourge of the Earth for artists such as Placebo, Marilyn Manson, Hawkwind, Ian Brown, The Orb etc. In December 1999 he joined with Guy Pratt to record and release a mobile telephone-themed novelty-pop record \"I Wanna 1-2-1 With You\" under the name Solid Gold Chartbusters. It was released as competition for the Christmas Number One but only got to 62. In 2001, Cauty joined with former collaborators Alex Paterson and Guy Pratt in a London recording studio, together with Dom Beken, an associate of Pratt. \n\nRecording later continued in Cauty's Brighton studio. In 2003, the group released their first single, \"Boom Bang Bombay\", under the name Custerd. Subsequently, they settled on the name \"Transit Kings\". Cauty left the band in 2004 to work on other projects. In 2006, the Transit Kings released their debut album, \"Living in a Giant Candle Winking at God\"; Cauty is listed as a composer on 7 of the album's 12 tracks.\n\nIn 2002, Cauty's two remixes of U2's \"New York\" were featured as B-sides on the band's Electrical Storm single. Until mid-2005, together with James Fogarty and Keir Jens-Smith, he was part of art/music collective Blacksmoke.\n\nCauty works with the L-13 Light Industrial Workshop, London which he explains \"is not a gallery, it’s a support system, spiritual home and technical epicentre for a small group of artists\" which includes \"Billy Childish\", \"Jamie Reid\" and Harry Adams. Cauty first worked in conjunction with L-13 on the Cautese Nationál Postal Disservice. Subsequent collaborations included the Riot In A Jam Jar exhibitions and the ADP Riot Tour - is a vast 1:87 scale model in a 40-foot shipping container which tours historic riot sites around the world. L-13 continue to collaborate with Cauty and Drummond, running \"dead perch merch\", official merchandise operatives to The JAMs.\n\nFollowing 2003 media speculation that Saddam Hussein could launch a poison chemical attack on London, Cauty designed the Stamps of Mass Destruction for Blacksmoke Art Collective. The 1st, 2nd and 3rd class stamps featuring the Queen's head wearing a gas mask were released as limited edition prints and exhibited at Artrepublic Gallery, Brighton. Following a legal battle over alleged copyright infringement, the stamps were sent to Royal Mail for destruction.\n\nIn 2004, Cauty installed a gift shop, \"Blackoff\", at the Aquarium Gallery, based on the government's \"Preparing for Emergencies\" leaflet. The installation included \"terror aware\" items, such as \"terror tea towels\", \"attack hankies\" and \"bunker-buster jigsaw puzzles\" (missing one piece). He commented, \"The gift shop becomes the place we can explore our branding ideas, Cash for trash – it represents the futility and the glory of it all.\"\n\nIn response to the Iraq War troop surge of 2007, Cauty developed Operation Magic Kingdom, a series of images showing US forces in Iraq wearing masks of lovable and friendly Disney characters, adopting the UK’s \"winning hearts and minds\" tactics in a bid to gain the confidence of the Iraqi people. In Operation Magic Kingdom \"the rules of engagement have been changed to include \"try and be more fun\" before firing.\" The images were launched at the Bayswater Road Sunday Art Exhibition, bombed onto billboards and flyposted across London, as well as being released by The Aquarium as limited edition prints and stamps.\n\nIn June 2011 he held a public exhibition at L-13 entitled \"A Riot in a Jam Jar\" consisting primarily of a series of scale dioramas depicting violent confrontations between British rioters and police, each contained within an inverted glass jar. In 2012, Cauty premiered his short film, Believe the Magic, starring Debbie Harry, Nick Lehan and Branko Tomović, at Tate Modern as part of the annual Merge festival.\n\nThe ideas of A Riot in a Jam Jar evolved into the Aftermath Dislocation Principle, shown at the Hoxton Arches in October 2013. \n\nThe 448 square foot installation at 1:87 scale (representing approximately one square mile) details the desolate and charred aftermath of what appears to have been a devastating riot. The sculpture, constructed by modifying components of traditional model railway kits, took approximately 8 months to complete includes nearly 3,000 police figures and a soundtrack pitched to match the 1:87 scale. The piece \"makes a political statement about societal freedom and state control\". The Aftermath Dislocation principle then toured the Netherlands, being shown at Piet Hein Eek Gallery, Eindhoven (November 2013), Cultuurwerf, Vlissingen (April 2014), and Mediamatic, Amsterdam (July–August 2014). \n\nIn 2015, the work was exhibited at Dismaland and then London. Following this it was re-engineered to fit inside a 40-foot shipping container and now tours historic riot sites around the world.\nIn 2014, Cauty released a series of limited edition Smiley Riot Shields. The shields are all ex-police riot gear which have been painted over with a yellow smiley face. He originally designed the shields in 2012 as a symbol of \"non-violent direct action\" and as a practical self-protective measure for his step-daughter during the Occupy St Paul’s eviction.\n\n"}
{"id": "25032982", "url": "https://en.wikipedia.org/wiki?curid=25032982", "title": "Leon Schidlowsky", "text": "Leon Schidlowsky\n\nLeon Schidlowsky (Hebrew: ליאון שידלובסקי; born 21 July 1931 in Santiago de Chile) is a Chilean-Israeli composer and painter. He has written music for orchestra, chamber ensemble, choir, and instruments including the piano, violin, cello, flute, mandolin, guitar, harp, organ, as well as about sixty-five pieces of music with graphic notation. His compositions have been performed in numerous countries with different orchestras under conductors such as Aldo Ceccato, Errico Fresis, Clytus Gottwald, Juan Pablo Izquierdo, Erhard Karkoschka, Herbert Kegel, Lukas Foss, Zubin Mehta, Hermann Scherchen, and Ingo Schulz. The scores of his graphic music have been shown in various exhibitions linked to concerts, such as in the Staatsgalerie Stuttgart, Kunsthaus Hamburg, the Wilhelm-Hack-Museum, Ludwigshafen, and the Stadtgalerie Saarbrücken.\n\nSchidlowsky pursued his secondary studies at the Instituto Nacional de Chile in Santiago from 1940–47 and studied the piano with Roberto Duncker at the Conservatorio Nacional de Chile in Santiago from 1942-48. He later studied composition with Juan Allende-Blin and Fré Focke, as well as philosophy and psychology at the Universidad de Chile in Santiago from 1948-51. He completed his studies in Germany at the Nordwestdeutsche Musikakademie (later Hochschule für Musik Detmold) in Detmold, where he met his future wife Susanne, whom he married in 1953. They had five children (David, Elias, Judith, and twins Yuval and Noam).\n\nAfter his return to Chile in 1954 Leon Schidlowsky became a member of the avant-garde ensemble Grupo Tonus in Santiago and served as its director from 1958–61. This ensemble wanted to spread avant-garde and contemporary music in Chile. In 1956 Schidlowsky produced \"Nacimiento\", considered the first electroacoustic work composed in Latin America. Between 1956 and 1959 he was member of the British Council and between 1956 and 1961 a musical adviser of the pantomime ensemble Grupo Noisvander. He served as director of the music library at the Instituto de Extensión Musical, of the Universidad de Chile (Chilean University) in 1961-62, and as secretary-general of the Asociación Nacional de Compositores from 1961-63. He also served as director-general of the Instituto de Extensión Musical, Universidad de Chile, from 1962-66. In this period the Institute achieved distinction, with the performance of music that had never been played in Chile before, and with the performance of at least one work by a Chilean composer every year. Besides that, a number of orchestral conductors, soloists, and foreign orchestras visited Chile and made a substantial contribution to the musical culture of the country.\n\nIn 1964 he was, together with Luigi Dallapiccola and Alberto Ginastera, a member of the jury in a composers' competition in Buenos Aires, Argentina. The same year he took part in the music symposium \"Latin America and the music of our time\" (América Latina y la música de nuestros tiempos) in Lima, Peru. In 1965, Schidlowsky was appointed Professor of Composition at the Conservatorio Nacional, Universidad de Chile (Chilean University). In 1966 he participated in the Inter-American Festival in Washington, D.C., USA, as well as the Festival Interamericano de Música in Caracas, Venezuela. In 1967, he took part in the Festival of Music from Spain and Latin America, in Madrid, Spain. He participated in the \"Festival of the Three Worlds\" in Mérida, Venezuela in 1968, with lectures and discussions with the composers Krzyztof Penderecki and Luigi Nono. The city of Mérida nominated him a \"Distinguished Guest of the City\". In the same year he received a Fellowship from the John Simon Guggenheim Memorial Foundation in order to write an opera, which he completed in Germany.\n\nOn 21 August 2014 Leon Schidlowsky was awarded the Chilean National Prize for Musical Arts, accompanied by several homages, press articles and interviews in the local press.\n\nIn 1969, he was appointed Professor for Composition and Music Theory at the Samuel Rubin Academy of Music at Tel Aviv University. In 1979 he was granted a Sabbatical Year, which he spent in Hamburg. He has given many conferences in Berlin, Hamburg and Stuttgart (Germany), Vienna (Austria), Lund (Sweden), and Saragossa (Spain). Schidlowsky received several fellowships from the Deutscher Akademischer Austauschdienst (DAAD), and stayed in Berlin for various periods, where he composed and painted. During one of these sojourns, in 1999, his wife Susanne died; she was buried in Tel Aviv. Leon Schidlowsky received various prizes for his music, such as at the regular Festivals of Chilean Music (Festivales de Música Chilena), with works of his being awarded the Chilean Prize CRAV. In 1996 he received the First Prize for his work \"Absalom\" in the 60th anniversary competition of the Israel Philharmonic Orchestra.\n\nIn 2000 he was awarded the ACUM Prize for his entire oeuvre by the Israel Composers Association. In the following year, during a visit to Chile, the Chilean Chamber Orchestra declared him an Honorary Member, the Universidad de Chile appointed him an Honorary Professor in its Arts Faculty, and the Chilean Ministry of Education conferred on him the \"Orden al Mérito Docente y Cultural Gabriela Mistral\" with the rank of \"Caballero\". He received the Engel Prize for his original work and his research into Jewish music, awarded by the city of Tel Aviv in June 2007. Leon Schidlowsky has given courses in composition in several countries; and he has helped to form and influence a whole generation of composers in Israel, like Avraham Amzallag, Chaya Arbel, Mary Even-Or, Rachel Galinne, Betty Olivero, Jan Radzynski, Ruben Seroussi, Ron Weidberg, Moshe Zorman.\n\nMany of his works make reference to his Jewish-Israeli identity and to the history of the Jewish people, as well as to his interest in history and the political and social situation in Chile and Latin America. There is also in his works a musical response to his personal life and experience, such as the death of his wife Susanne (1999) and his son Elias (2004), or the destiny of many personal and professional friends, or personalities of his time. As an admirer of Arnold Schoenberg´s music, Schidlowsky began his career as a composer in the tradition of the Second Viennese School. His music is also highly influenced by Edgard Varèse, specially on his concern with timbre and freedom of form.\n\nLater he began to use serial techniques, and to experiment with various tonal concepts (atonal, aleatoric, graphic notation), but always on the understanding that music has a deeper significance which transcends absolute art, which can open up a path for a human being to find a way to himself (Schidlowsky: \"Art itself has not only one meaning. It includes and encompasses all senses, questions and all answers. I think that art is a way to us.\"). Leon Schidlowsky has written dramatic and vivid works. Examples:\n\nExamples from his graphic notation music:\n\n\nAmong his numerous works, Schidlowsky also wrote three operas:\n\n\n\n\n"}
{"id": "31175393", "url": "https://en.wikipedia.org/wiki?curid=31175393", "title": "Level of consciousness (Esotericism)", "text": "Level of consciousness (Esotericism)\n\nConsciousness is a loosely defined concept that addresses the human awareness of both internal and external stimuli. This can refer to spiritual recognition, psychological understanding, medically altered states, or more modern-day concepts of life purpose, satisfaction, and self-actualization.\n\nMost proposals map consciousness in a series of levels, some stages of which are more continuous or complex than others. Movement between stages is often bidirectional depending on internal and external conditions, with each mental ascension precipitating a change in reactivity. In the most basic sense, this alteration might lead to a reduced responsiveness as seen in anesthesiology; more abstract facets of tiered consciousness describe characteristics of profoundness, insight, perception, or understanding.\n\nFirst appearing in the historical records of the ancient Mayan and Incan civilizations, proposals of multiple levels of consciousness have pervaded spiritual, psychological, medical, and moral speculations in both Eastern and Western cultures. Because of occasional and sometimes substantial overlap between hypotheses, there have recently been attempts to combine perspectives to form new models that integrate components of separate viewpoints.\n\nWhich if any of these proposals, models or viewpoints can be verified or falsified is open to question.\n\nAlthough many cultures have incorporated theories of the layered consciousness into their belief structure, particularly for spiritual means before the separation of church and state within any given civilization, the Ancient Mayans were among the first to propose an organized sense of each level, its purpose, and its temporal connection to humankind.\n\nThe pyramid of consciousness has defined Mayan thought since the dawn of its civilization around 2000 BCE. Shamans and priests defined consciousness as an awareness of being aware, commonly referred to as a branch of metacognition. Because consciousness incorporates stimuli from the environment as well as internally, the Mayans believed it to be the most basic form of existence.\n\nThis existence, which they referred to as a loose translation of \"Cosmos\", was made up of nine underworlds, depicted concretely through the nine-storied Pyramid of the Plumed Serpent in Chichen Itza, the Temple of the Jaguar in Tikal, and the Temple of the Inscriptions in Palenque. Within these nine underworlds are a specified \"day\" and \"night\", symbolizing periods of enlightenment, increased consciousness, and a heightened ability to interact with the universe.\n\nA common cause for debate is the exponentially accelerating dates separating each level of consciousness, where each stage occurs roughly 20 times faster than the previous one.\n\nWhereas the Ancient Mayans defined consciousness in almost evolutionary terms, the Inca civilization considered it a progression of awareness and concern for others, similar to the teachings of Siddhartha Gautama.\n\nAlthough historical views of the separation of consciousness into various layers do not exactly mirror modern-day perspectives, many parallels can be gathered from the overarching themes found in Eastern and Western cultures.\n\nMany specific similarities have been drawn between Ancient Incan and historical Eastern views of tiered consciousness. Within most Eastern belief structures is the principle of the Cosmos as a joint entity with human awareness. Many branches stress the importance of AUM, also written Om, as the first sound produced after the world was created. Within Christianity this concept can be likened to the first words of Genesis regarding the holiness of the Word.\n\nThe majority of Eastern perspectives assert that while consciousness originates from the sound of AUM, it has incorporated itself into flesh, which therefore gives humankind the goal of attaining oneness with the universe once more. Unlike Incan tradition, this oneness eliminates the separation of external and internal changes into one general indication of movement from stage to stage, commonly known as the Seven Shamanic Levels of Consciousness.\n\nLike the Seven Shamanic Levels of Consciousness, yoga meditation practices as well as the teachings of Vedanta and Tantra emphasize the importance of self-realization, a concept that has become increasingly popular in Western philosophy after Abraham Maslow's and Carl Rogers's research in Humanistic Psychology.\n\nIn particular, the Advaita Vedanta school of Hindu philosophy has been a topic of extensive study in both Eastern and Western cultures for its tiered depiction of the steps toward attaining self-realization. Unlike the unidirectional nature of Mayan, Inca, and ancient shamanic perspectives, however, this particular belief structure arranges the attainment of oneness with OM through rows and domains, each of which constitutes a fragment of this vibratory sound.\n\nSimilarly, the seven levels of consciousness defined by modern-day OM mantras strive to reach Absolute Reality through the same four realms described in the Advaita Vedanta, with three transitional tiers in between each.\n\n\nThe ancient Indian Vedas texts have lent a comparable view of unified consciousness, with a key difference in the purpose of human ascension from stage to stage. Instead of oneness with the universe, the Vedic vision of consciousness emphasizes the importance of attaining knowledge and pure intelligence.\n\nThe Ananda Sangha movement has evolved following the teachings of the late yogi and guru Paramhansa Yogananda. Compared to the multi-dimensional theories of consciousness in shamanic and OM mantra perspectives, this particular ideological faction stresses simplicity rather than detail.\n\n\nFluctuations in consciousness theories are not particular to Eastern cultures. A surprising degree of overlap can be found within the field of health and social sciences with regard to dulled, standard, and heightened intensities of awareness, both naturally and as a result of injury or disorder.\n\nLike many psychological theories within the particular field of psychoanalysis, one of the most popular theories of consciousness was proposed by Sigmund Freud, who described three facets of the psychic apparatus: the unconscious (id) or instinctual facet, the preconscious (ego) or rational facet, and the conscious (superego) or moral facet.\n\nAlthough not unlike the Vedic vision of consciousness as a form of intelligence, Jean Piaget's theory of cognitive development is not commonly considered a form of knowledge awareness but instead as the evolution of the brain's capacity for thought throughout the human lifespan.\n\nSimilar to previously mentioned psychological views, medical and pathological perspectives often hypothesize tiered consciousness as a result of disease or disorders. The Altered Levels of Consciousness (ALC) theory is one such measure, in which a person's arousability and responsiveness to environmental stimuli are classified by their behavioral response.\n\nAlthough many such ALC tests take place in hospital settings, the primary evaluation of patient alertness is the Glasgow Coma Scale, which separates levels of consciousness from standard conscious awareness to a comatose state.\n\n\nRecent hypotheses have incorporated these ALC theories into the psychopathological study of schizophrenia, suggesting that each altered level of awareness is connected to a degree of suffering or shock experienced by the patient, arguably traversing the Qliphoth in the process. As the situation increases in seriousness, patients will descend to lower levels of consciousness and consequentially lose the capacity to cry, to smile, or to exhibit a wide range of emotions when reacting to the environment.\n\nIn more physiologically based studies, scientists have found that while the reticular formation controls alertness, wakefulness, and arousal in the brain, many mental responses to internal and external stimuli are dictated through signals relayed to and from the thalamus. Propofol and other consciousness-altering drugs are therefore antagonists of thalamus activity, possibly leading to a drug-induced comatose state.\n\nAlthough many of the previously mentioned theories are still widely held today in various groups, beliefs, and areas of study, a majority of commonly accepted perspectives stem from just the past decade. These hypothesized structures of awareness draw from many historical and early eighteenth- or nineteenth-century theories to form an integrated and overarching generalization of consciousness as a means of determining inner and outer recognition of stimuli.\n\nDerived loosely from his philosophy of the Kung Fu system, Philip Holder offers three levels of consciousness that feature distinct differences in the way in which they are reached.\n\nSimilarly, Richard Barrett proposes seven stages of consciousness that progress in a logical order. The progression focuses on “existential” needs directly connected to and dependent on the human condition, all of which are motivating factors for daily interactions.\n\nDr. Bob Günius Gibson, left-handed author of \"Notes on Personal Integration and Health\" and often recognized as a psychic healer, hypothesized the existence of four tiers of extrasensory awareness. Beyond being more applicable to internal states rather than reactions to the external environment, these stages contrast markedly with the previously mentioned modern theories through their emphasis on humankind's immediate interactions. Gibson does not focus on life progression or individual power to move between levels, but rather on momentary instances of personal experience.\n\nTimothy Leary and Robert Anton Wilson proposed the Eight-Circuit Model of Consciousness, a psychologically based theory that unifies various interpretations of main altered states of awareness into a single mega-theory, or a hypothesis' about an already existing hypothesis. In this case, Leary and Wilson state that the altered levels of consciousness defined in medical fields are products of eight differing brain structures within the human nervous system.\n\nThis concept not only connects psychology and the more medically focused studies of neurology and biology, but also incorporates elements of sociology, anthropology, physics, chemistry, and advanced mathematical formulas. Furthermore, critics argue that the inspiration for his theory stems at least indirectly from the Hindu chakra system.\n\nSimilar to Dr. Rondell Gibson's view of a simplified hierarchy of conscious states, Alain Morin describes a four-tiered integration of nine past awareness models, focusing explicitly on the two common aspects underlying each belief structure: the perception of the self in time and the complexity of those self-representations.\n\nIn summary, Morin concludes that from the many concepts discussed above it is near impossible to settle for only one theory without accepting at least a fraction of another. Although each hypothesis has been debated either in scientific or more spiritually focused literature, he states that consciousness is related most directly to the subjective perception of self-recognition and language, both of which are determined by culture and our external environment as a whole.\n\nRobert Allan Monroe became known for his research into altered consciousness and \"out-of-body experience\". His book 1985 \"Far Journeys\" showed numerous levels of consciousness and infinite expansion of consciousness.\n\n\"“The plants exist on levels of consciousness from one through seven. They are on a vibrational rate on the levels one through seven. It is the same pattern.\"\n\n\"Animals exist on the levels of consciousness from eight through fourteen, and when a person attains, when a consciousness attains level fourteen, it can no longer go any higher unless it is willing to change its form of consciousness.\"\n\n\"Levels of consciousness from fifteen through twenty-one are what you call human life on this earth.\"\n\n\"When a person progresses to level of consciousness twenty one, he then has the choice of going higher or staying within the realm of human form, but he cannot go higher unless he is willing to give up human form.”\" \n\nSome analytical psychological methods have presented methodology to engage in deeper levels of inner expansive transcendence, depth that may lead to a reconciliation process. Propositions such as \"active imagination,\" engaging in a conversation with the \"Ego\" and \"Shadow\" for instance. \"Invocation,\" calling upon an archetypal imago to dialogue with, perhaps an image of saint or God, \"Admiring Mature Paragon Examples,\" having conversations with wise old men and women; those who have accessed wisdom, for example, and \"Acting 'As If,'\" getting into character, acting like the character archetype one wishes to emulate.\n\n\n"}
{"id": "45241516", "url": "https://en.wikipedia.org/wiki?curid=45241516", "title": "Male as norm", "text": "Male as norm\n\nIn feminist theory, the principle of male-as-norm holds that \"language referring to females, such as the suffix -ess (as in actress), the use of man to mean \"human\", and other such devices, strengthens the perceptions that the male category is the norm and that the corresponding female category is a derivation and thus less important. Sexist terms such as chairman, anchorman, etc., are cited as examples of how the English language mirrors social gender biases.\n\nThe idea was first clearly expressed by 19th-century thinkers who began deconstructing the English language to expose the products and footings of patriarchy. The principle of male-as-norm and the relation between gendered grammar and the way in which its respective speakers conceptualize their world has received attention in varying fields from philosophy to psychology and anthropology, and has fueled debates over linguistic determinism and gender inequality. \nThe underlying message of this principle is that women speak a less legitimate language that both sustains and is defined by the subordination of the female gender as secondary to the accepted male-biased normative language. By regarding women's language as deficient in relation to that of men it has been assumed that something is wrong with women's language. Subsequently research in the social sciences, particularly in discourse analysis, has maintained and qualified systemic male bias. In practice, grammatical gender exhibits a systematic structural bias that has made masculine forms the default for generic, non-gender-specific contexts. According to the male-as-norm principle the male linguistic bias works to exclude and ignore women, diminish the female experience, and rule that all that is not male is deviant and unfit to represent many social categories.\n\nIn the eighteenth-century there was a radical reinterpretation of the female body in relation to the male. Prior to this change in thinking, men and women were qualified by their degree of metaphysical perfection whereas by the late eighteenth century there was a new model established on ideas of radical dimorphism and biological divergence. Biologists used developments in the study of anatomy and physiology to change the understanding of sexual difference into that of kind rather than degree. This metaphysical shift in the understanding of sex and gender, as well as the interplay of these redefined social categories, solidified many of the existing beliefs in the inherent disparities of men and women. This allowed scientists, policy makers, and others of cultural influence to promulgate a belief in the gender binary under a veil of positivism and scientific enlightenment. \nSince the eighteenth century, the dominant view of sexual difference has been that of two stable, incommensurable, and opposite sexes on which the political, economic, and cultural lives of men and women are based and social order is sustained. Contrary to modern day, \"the dominant discourse construed the male and female bodies as hierarchically, vertically, ordered versions of one sex\" rather than as \"horizontally ordered opposites, as incommensurable.\" In fact, it wasn't until the second half of the eighteenth century that the idea of two distinct sexes was established and, through the politics of the day, generated new ways of understanding people and social reality.\nThe recognition and discussion of this transition by protofeminists around the 19th century established the foundation upon which = feminists would later scrutinize gendered language, challenge the gender binary and its inherent prejudices, and develop the male as norm principle.\n\nIn 1949, French existentialist Simone De Beauvoir described in her book \"The Second Sex\" two concepts that would later be developed in the fields of linguistics and psychology and become the basis for the male-as-norm principle in second-wave feminism. Beauvoir writes that man is regarded as \"both the positive and the neutral,\" foreshadowing the study of markedness, or the linguistic distinction between the \"marked\" and \"unmarked\" terms of an opposition. Specifically, \"the notion that the typical contrast between opposites… is not symmetric.\" Rather, the contrast between oppositions is often asymmetric meaning \"the positive, or unmarked, term can be neutralized in meaning to denote the scale as a whole rather than just the positive end; but the negative, or marked, term can denote just the negative end\". Unaffixed masculine or singular forms are taken to be unmarked in contrast to affixed feminine or plural forms.\n\nBeauvoir goes on to write that \"there is an absolute human type, the masculine... Thus humanity is male,\" and the neutralizing of man to include woman is no longer her subject, rather the masculinizing of the whole human species to exclude woman–or at least to otherize her. Thus, introducing her second concept and foreshadowing the psychological concept of prototypicality and the development of the prototype theory in the 1970s. \"The prototype theory is a model of graded categorizations, where some members of a category are more central than others. A prototype helps to explain the meaning of a word by resembling to the clearest exemplar\". \"All members of a category do not have equal status in the mind of the human perceiver; some members are instead perceived as more equal–or more prototypical–than other members… Like the prototypical member of any category, the male is taken to be the cognitive reference point, the standard, for the category of human being; and like the non-prototypical members of any category, the female is taken to be a variation on that prototype, a less representative example of the human species\".\n\nJust as Simone de Beauvoir had done in recent decades, French feminist and literary scholar Luce Irigaray centered her ideas regarding the male as norm principle around the idea that women as a whole are otherized by systematic gender inequality, particularly through gendered language and how female experience and subjectivity are defined by variation from a male norm; through opposition in a phallocentric system where language is deliberately employed as a method of protecting the interests of the phallus and subliminally affirming his position as norm.\nIrigaray affirms that the designation of woman as an inferior version of men, an aberrant variation from the male norm, is reflected throughout Western history and philosophy. Notably, Freud made similar sense of gender dynamics in his designation of women as 'little men'. In this tradition of inequality women are measured against a male standard, seen in comparison – as lack, complementary or the same. She asserts that any perception of difference between the two genders is an illusion. \"Where women are not the same as men, they fail to exist altogether.\" \nDale Spender is one of the most cited feminist scholars to work with the male-as-norm principle. She claims that \"patriarchy is a frame of reference, a particular way of classifying and organizing the objects and events of the world\" With language we classify and organize the world and through which we have the ability to manipulate reality. In this way, if our language is systematically flawed and/or rests on an understructure of invalid rules then we are misled and deceived at a fundamental perceptual level.\nThe rules by which we make meaning, ones intrinsically associated with language, had to be invented and defined. These linguistic rules establish our frame of reference, order, and the grounds from which we interpret and comprehend reality. Spender explains that these rules become self-validating and self-perpetuating with the passing of time, regardless of the validity of the beliefs and/or interpretations on which they were founded.\n\nSpender claims that the semantic rule of male as norm may appear to be ineffectual in producing the purported significant social impact concluded by many feminists however this is in fact part of why the rule is so pervasive and superlatively harmful in the construction of our perceptions of gender. As long as this rule remains central to gendered languages users of these languages will continue to classify the world on the premise that males are the standard, normal being and that those who are not male will be considered deviant. Speakers will continue to divide humanity into two unfairly biased parts. \"By arranging the objects and events of the world according to these rules we set up the rationale, and the vindication, for male supremacy.\"\n\nOver the course of feminist historian Gerda Lerner's career, Lerner focuses her studies on patriarchal power and the history of the subordination of women. By examining gender stratification in various societies throughout human history in accordance with language, Lerner provides an in-depth look into the historical and modern significance of the male as norm principle. She was one of the founders of the field of women's history and played a key role in the development of women's history curricula. In Lerner's book \"The Creation of Patriarchy\" (1986), she addresses how men have in history appropriated the major symbols of female power, constructed religions around \"the counterfactual metaphor of male procreativity,\" and have \"redefined female existence in a narrow and sexually dependent way.\" She explains that the metaphors for gender, created and promoted by men, have \"expressed the male as norm and the female as deviant; the male as whole and powerful, the female as unfinished, mutilated, and lacking in autonomy.\" According to Lerner, men have constructed, explained, and defined the world in their own terms and have placed themselves at the center of discourse. \nLerner goes on to explain how men, by establishing male-centered language and discourse as the norm, have in turn demanded an androcentric perspective and necessitated the conceptualization of women as less than men and have distorted the definition of woman to the degree that their experiences, autonomy, and viewpoints have been lost to modern consideration. In turn, men have come to believe that their experiences, viewpoint, and ideas represent all of human experience and thought. She concludes that as long as men are unable to recognize the female perspective and as long as they believe they have the only legitimatize human experience they will be unable to accurately define and understand reality.\n\nIn 1997 Sue Wilkinson, a professor of Feminist and Health Studies from Loughborough University, wrote that there are distinct theoretical traditions in feminism that assert women's inferiority, two of which are rooted in the idea of male-as-norm. First, psychology has mismeasured women throughout its history by taking a male-as-norm perspective which categorizes females as deviant; or, in other words of Simone De Beauvoir, the science of psychology has systematically \"otherized\" women. Another way which Wilkinson sees women's inferiority asserted is through psychologists seeking a different perspective, the female perspective, by listening to women's voices and drawing on, and feeding back into, preconceived ideas regarding female moral and cognitive processes as they differ from those of males. Wilkinson writes that we should reconstruct the question of sex differences and that we need to dismantle maleness and femaleness as fundamental categories.\n\nIn her book \"Motherhood as Metaphor: Engendering Interreligious Dialogue\", professor of theology Jeannine Hill Fletcher of Fordham University notes that scripture and Christians theological writings have presented theological anthropology from a male-as-norm perspective due to a history of predominantly male theologians and philosophers. She notes that this has had disastrous effects on the lives of women and the valuation of the female perspective and consequently the history of Christian theology has missed opportunities for opening new understandings of what it means to be human.\n\n"}
{"id": "3739366", "url": "https://en.wikipedia.org/wiki?curid=3739366", "title": "Montage (filmmaking)", "text": "Montage (filmmaking)\n\nMontage () is a technique in film editing in which a series of short shots are edited into a sequence to condense space, time, and information. The term has been used in various contexts. It was introduced to cinema primarily by Sergei Eisenstein, and early Soviet directors used it as a synonym for creative editing. In French the word \"montage\" applied to cinema simply denotes editing. The term \"montage sequence\" has been used primarily by British and American studios, and refers to the common technique as outlined in this article.\n\nThe montage sequence is usually used to suggest the passage of time, rather than to create symbolic meaning as it does in Soviet montage theory.\n\nFrom the 1930s to the 1950s, montage sequences often combined numerous short shots with special optical effects (fades, dissolves, split screens, double and triple exposures) dance and music. They were usually assembled by someone other than the director or the editor of the movie.\nTwo common montage sequence devices of the period are a newspaper one and a railroad one. In the newspaper one, there are multiple shots of newspapers being printed (multiple layered shots of papers moving between rollers, papers coming off the end of the press, a pressman looking at a paper) and headlines zooming on to the screen telling whatever needs to be told. There are two montages like this in \"It Happened One Night\". In a typical railroad montage, the shots include engines racing toward the camera, giant engine wheels moving across the screen, and long trains racing past the camera as destination signs zoom into the screen.\n\n\"Scroll montage\" is a form of multiple-screen montage developed specifically for the moving image in an internet browser. It plays with Italian theatre director Eugenio Barba's \"space river\" montage in which the spectators' attention is said to \"[sail] on a tide of actions which their gaze [can never] fully encompass\". \"Scroll montage\" is usually used in online audio-visual works in which sound and the moving image are separated and can exist autonomously: audio in these works is usually streamed on internet radio and video is posted on a separate site.\n\nFilm critic Ezra Goodman discusses the contributions of Slavko Vorkapić, who worked at MGM and was the best-known montage specialist of the 1930s:\n\nFrom 1933 to 1942, Don Siegel, later a noted feature film director, was the head of the montage department at Warner Brothers. He did montage sequences for hundreds of features, including \"Confessions of a Nazi Spy\"; \"Knute Rockne, All American\"; \"Blues in the Night\"; \"Yankee Doodle Dandy\"; \"Casablanca\"; \"Action in the North Atlantic\"; \"Gentleman Jim\"; and \"They Drive By Night\".\n\nSiegel told Peter Bogdanovich how his montages differed from the usual ones:\nIn contrast, Siegel would read the motion picture's script to find out the story and action, then take the script's one line description of the montage and write his own five page script. The directors and the studio bosses left him alone because no one could figure out what he was doing. Left alone with his own crew, he constantly experimented to find out what he could do. He also tried to make the montage match the director's style, dull for a dull director, exciting for an exciting director.\n\nSiegel selected the montages he did for \"Yankee Doodle Dandy\" (1942), \"The Adventures of Mark Twain\" (1944), and \"Confessions of a Nazi Spy\", as especially good ones. \"I thought the montages were absolutely extraordinary in 'The Adventures of Mark Twain'—not a particularly good picture, by the way.\"\n\nThe sports training montage is a standard explanatory montage. It originated in American cinema but has since spread to modern martial arts films from East Asia. Originally depicting a character engaging in physical or sports training, the form has been extended to other activities or themes.\n\nThe standard elements of a sports training montage include a build-up where the potential sports hero confronts his failure to train adequately. The solution is a serious, individual training regimen. The individual is shown engaging in physical training through a series of short, cut sequences. An inspirational song (often fast-paced rock music) typically provides the only sound. At the end of the montage several weeks have elapsed in the course of just a few minutes and the hero is now prepared for the big competition. One of the best-known examples is the training sequence in the 1976 movie \"Rocky\", which culminates in Rocky's run up the Rocky Steps of the Philadelphia Museum of Art. \n\nThe montage sequence in Rocky IV is clearly the best of all time (according to Louis).\n\nThe simplicity of the technique and its over-use in American film vocabulary has led to its status as a film cliché. A notable parody of the sports training montage appears in the \"South Park\" episode, \"Asspen\". When Stan Marsh must become an expert skier quickly, he begins training in a montage where the inspirational song explicitly spells out the techniques and requirements of a successful sports training montage sequence as they occur on screen. The same song was later used in \"\" in a similar sequence.\n\nIn \"Once More, with Feeling\", an episode of \"Buffy the Vampire Slayer\", Buffy Summers does an extended workout while Rupert Giles sings one song; this distortion of time is one of numerous musical conventions made literal by a spell affecting Sunnydale. Prior to this sequence, Buffy Summers voices her concern that \"this whole session is going to turn into some training montage from an '80s movie\" to which Rupert Giles replies \"Well, if we hear any inspirational power chords we'll just lie down until they go away\". The original 1992 film of \"Buffy the Vampire Slayer\" includes a very clichéd training montage.\n\nThe music in these training montage scenes has garnered a cult following, with such artists as Robert Tepper, Stan Bush and Survivor appearing on several '80s soundtracks. Songs like Frank Stallone's \"Far from Over,\" and John Farnham's \"Break the Ice\" are examples of high-energy rock songs that typify the music that appeared during montages in '80s action films.\n\n"}
{"id": "54216036", "url": "https://en.wikipedia.org/wiki?curid=54216036", "title": "Moral supervenience", "text": "Moral supervenience\n\nThe principle of moral supervenience states that moral predicates (e.g., permissible, obligatory, forbidden, etc.), and hence moral facts attributing these predicates to various particular actions or action-types, supervene, or are defined by and depend, upon non-moral facts. The moral facts are hence said to be \"supervenient facts\", and the non-moral facts the \"supervenience base\" of the former. The principle is sometimes qualified to say that moral facts supervene upon \"natural\" facts, i.e., observable, empirical facts within space-time, but a broader conception could allow the supervenience base to include any non-moral facts, including (if there are any) non-natural facts (e.g., divine commands, Platonic truths).\n\nAnother way to put this is to say that moral facts are a function of, depend upon, or are constrained or constituted by, some non-moral facts, and that the latter are a sufficient condition for making the moral facts true. Yet another common way of putting this is that any change in moral facts must be accompanied by a change in the non-moral facts (i.e., those on which it supervenes), but that the reverse is not the case. A moral fact can be constituted by more than one set of non-moral facts-i.e., it is multiply realizable-but any given set of non-moral facts determines the moral facts which supervene upon it.\n\nFor instance, its being obligatory for Alice to pay Bob $10 supervenes upon non-moral facts, like that Alice borrowed $10 from Bob and promised to repay him. However the same obligation could have arisen if Alice had bought something from Bob priced at $10, or if she promised to give him a gift in that amount, etc. But if any such fact is sufficient to generate this obligation, then it is not possible for her to lack that obligation unless the relevant facts change. Likewise, if another person, say Cindy, stands in the non-moral relationship to David (having borrowed $10 from him, etc.), then she must have the same obligation Alice does.\n\nHowever the principle is compatible with a very fine-grained analysis of the supervenience base for moral predicates, and hence is compatible with moral particularism. (R.M. Hare, in the first recorded usage of the term moral particularism, defined these as incompatible, as contradictories but his definition of particularism is not identical with its contemporary usage.) The non-moral facts on which a moral fact supervenes could be quite complex, with many exceptions and qualifications; for instance, one might only be obliged to pay someone $10 if the recipient has not waived the debt, or does not intend to use the funds to cause immediate harm to someone else, etc.\n\nAs the principle of moral supervenience by itself places no limit on what the non-moral supervenience base of any moral fact is, nor on how complex the former might be, it is generally considered a very weak principle. It is even compatible with the idea that obligations may vary for persons of different nationalities, races, genders, ages, etc. It only disallows exceptions for certain persons merely on the grounds that they are different people from other persons (note that the fact that.e.g., Alice is Alice, and not Cindy, is not itself a property of Alice, although the facts that she is called \"Alice,\" or has a different residence, birthplace, etc. from Cindy, are among her properties). Hare put this point by saying that the supervenience base of a moral fact could not include \"individual constants\" (including proper names of persons, countries, etc.)\n\nMoral supervenience is a kind of moral universalizability principle, like the golden rule or Immanuel Kant's categorical imperative, so the underlying idea may be as old as the golden rule. Moral supervenience differs from most other universalizability principles in that it adds no specific criterion for the supervenience base of permissible behaviors, so it cannot function as a comprehensive test for moral permissibility, as most other universalizability principles purport to do.\n\nThe earliest precise specification of the principle may be found in Samuel Clarke's \"Rule of Equity\" according to which \"Whatever I judge reasonable or unreasonable that another should do for me: that by the same judgment I declare reasonable or unreasonable that I should in the like case do for him.\" A few years later William Wollaston echoed this claim with the principle that \"Whatever is either reasonable or unreasonable in B with respect to C, would be just the same in C with respect to B, if the case was inverted. Because reason is universal and respects cases, not persons.\" A few years later Richard Cumberland restated this as a requirement of \"right reason,\" which entailed that “It is included in the notion of a true proposition, (a practical one, for instance,) and is consequently a necessary perfection of a man forming a right judgment in that affair; that it should agree with other true propositions framed about a like subject, tho that case should happen at another time, or belong to another man... Whoever therefore judges truly, must judge the same things, which he thinks truly are lawful to himself, to be lawful in others in a like case. \" Later versions are found in Reid, Moore, Sidgwick, and Sharp.\n\nThe first usage of the general term \"supervenience\" and the specific term \"moral supervenience\" in print was by R.M. Hare, although he later suggested that the former term was used by other philosophers conversationally before he put them both into print. While Hare was primarily interested in the supervenience of moral concepts on non-moral ones, he also argued that other evaluative concepts, e.g., aesthetic ones like beautiful, pleasant, nice, etc., must also supervene upon non-moral facts. For instance, it is senseless to call one room \"nice\" and another \"not nice\" unless there is some underlying difference between them describable in non-aesthetic terms (like the arrangement of the furniture, color of the walls, etc.) If the two rooms are identical in all their non-aesthetic properties, then they must also be identical in their aesthetic ones.\n\nIn a series of later books, Hare made moral supervenience, combined with the criterion that a rational being would prefer the satisfaction of his preferences over their frustration, the basis of his idea of universal prescriptivism. From this he derived a version of utilitarianism, by arguing that to prescribe a particular action in one's circumstances was only rational if you would prescribe anyone's else's doing it, even if you were equally likely to be any agent (including all those affected, for good or ill, by the action). This would only be true if, were you to personally experience all the good and bad effects of the action upon all affected persons (i.e., the satisfaction and frustration of their preferences), you would not prefer some other action to the one in question. He often simply called moral supervenience \"universalizability\" and equated it with Kant's principle of universal law, although the two are not the same (see moral universalizability).\n\n"}
{"id": "945957", "url": "https://en.wikipedia.org/wiki?curid=945957", "title": "New Foundations", "text": "New Foundations\n\nIn mathematical logic, New Foundations (NF) is an axiomatic set theory, conceived by Willard Van Orman Quine as a simplification of the theory of types of \"Principia Mathematica\". Quine first proposed NF in a 1937 article titled \"New Foundations for Mathematical Logic\"; hence the name. Much of this entry discusses NFU, an important variant of NF due to Jensen (1969) and exposited in Holmes (1998). In 1940 and in a revision of 1951 Quine introduced an extension of NF sometimes called \"Mathematical Logic\" or \"ML\", that included proper classes as well as sets.\n\nNew Foundations has a universal set, so it is a non-well founded set theory. That is to say, it is an axiomatic set theory that allows infinite descending chains of membership such as\n… x ∈ x ∈ …x ∈ x ∈ x. It avoids Russell's paradox by permitting only stratifiable formulae to be defined using the axiom (schema) of comprehension. For instance x ∈ y is a stratifiable formula, but x ∈ x is not (for details of how this works see below).\n\nThe primitive predicates of Russellian unramified typed set theory (TST), a streamlined version of the theory of types, are equality (formula_1) and membership (formula_2). TST has a linear hierarchy of types: type 0 consists of individuals otherwise undescribed. For each (meta-) natural number \"n\", type \"n\"+1 objects are sets of type \"n\" objects; sets of type \"n\" have members of type \"n\"-1. Objects connected by identity must have the same type. The following two atomic formulas succinctly describe the typing rules: formula_3 and formula_4. (Quinean set theory seeks to eliminate the need for such superscripts.)\n\nThe axioms of TST are:\n\nThis type theory is much less complicated than the one first set out in the \"Principia Mathematica\", which included types for relations whose arguments were not necessarily all of the same type. In 1914, Norbert Wiener showed how to code the ordered pair as a set of sets, making it possible to eliminate relation types in favor of the linear hierarchy of sets described here.\n\nThe well-formed formulas of New Foundations (NF) are the same as the well-formed formulas of TST, but with the type annotations erased. The axioms of NF are:\n\n\nBy convention, NF's \"Comprehension\" schema is stated using the concept of stratified formula and making no direct reference to types. A formula formula_12 is said to be stratified if there exists a function \"f\" from pieces of syntax to the natural numbers, such that for any atomic subformula formula_13 of formula_12 we have \"f\"(\"y\") = \"f\"(\"x\") + 1, while for any atomic subformula formula_15 of formula_12, we have \"f\"(\"x\") = \"f\"(\"y\"). \"Comprehension\" then becomes:\nEven the indirect reference to types implicit in the notion of stratification can be eliminated. Theodore Hailperin showed in 1944 that \"Comprehension\" is equivalent to a finite conjunction of its instances, so that NF can be finitely axiomatized without any reference to the notion of type.\n\n\"Comprehension\" may seem to run afoul of problems similar to those in naive set theory, but this is not the case. For example, the existence of the impossible Russell class formula_19 is not an axiom of NF, because formula_20 cannot be stratified.\n\nRelations and functions are defined in TST (and in NF and NFU) as sets of ordered pairs in the usual way. The usual definition of the ordered pair, first proposed by Kuratowski in 1921, has a serious drawback for NF and related theories: the resulting ordered pair necessarily has a type two higher than the type of its arguments (its left and right projections). Hence for purposes of determining stratification, a function is three types higher than the members of its field.\n\nIf one can define a pair in such a way that its type is the same type as that of its arguments (resulting in a type-level ordered pair), then a relation or function is merely one type higher than the type of the members of its field. Hence NF and related theories usually employ Quine's set-theoretic definition of the \nordered pair, which yields a type-level ordered pair. Holmes (1998) takes the ordered pair and its left and right projections as primitive. Fortunately, whether the ordered pair is type-level by definition or by assumption (i.e., taken as primitive) usually does not matter.\n\nThe existence of a type-level ordered pair implies \"Infinity\", and NFU + \"Infinity\" interprets NFU + \"there is a type level ordered pair\" (they are not quite the same theory, but the differences are inessential). Conversely, NFU + \"Infinity\" + \"Choice\" proves the existence of a type-level ordered pair.\n\nNF (and NFU + \"Infinity\" + \"Choice\", described below and known consistent) allow the construction of two kinds of sets that ZFC and its proper extensions disallow because they are \"too large\" (some set theories admit these entities under the heading of proper classes):\n\nNew Foundations can be finitely axiomatized.\n\nThe category whose objects are the sets of NF and whose arrows are the functions between those sets is not Cartesian closed; Cartesian closure can be a useful property for a category of sets. Since NF lacks Cartesian closure, not every function curries as one might intuitively expect, and NF is not a topos.\n\nThe outstanding problem with NF is that it is not yet verified to be relatively consistent to any mainstream mathematical system. NF disproves \"Choice\", and so proves \"Infinity\" (Specker, 1953). But it is also known (Jensen, 1969) that allowing urelements (multiple distinct objects lacking members) yields NFU, a theory that is consistent relative to Peano arithmetic; if Infinity and Choice are added, the resulting theory has the same consistency strength as type theory with infinity or bounded Zermelo set theory. (NFU corresponds to a type theory TSTU, where type 0 has urelements, not just a single empty set.) There are other relatively consistent variants of NF.\n\nNFU is, roughly speaking, weaker than NF because in NF, the power set of the universe is the universe itself, while in NFU, the power set of the universe may be strictly smaller than the universe (the power set of the universe contains only sets, while the universe may contain urelements). In fact, this is necessarily the case in NFU+\"Choice\".\n\nSpecker has shown that NF is equiconsistent with TST + \"Amb\", where \"Amb\" is the axiom scheme of typical ambiguity which asserts formula_23 for any formula formula_12, formula_25 being the formula obtained by raising every type index in formula_12 by one. NF is also equiconsistent with the theory TST augmented with a \"type shifting automorphism\", an operation which raises type by one, mapping each type onto the next higher type, and preserves equality and membership relations (and which cannot be used in instances of \"Comprehension\": it is external to the theory). The same results hold for various fragments of TST in relation to the corresponding fragments of NF.\n\nIn the same year (1969) that Jensen proved NFU consistent, Grishin proved formula_27 consistent. formula_27 is the fragment of NF with full extensionality (no urelements) and those instances of \"Comprehension\" which can be stratified using just three types. This theory is a very awkward medium for mathematics (although there have been attempts to alleviate this awkwardness), largely because there is no obvious definition for an ordered pair. Despite this awkwardness, formula_27 is very interesting because \"every\" infinite model of TST restricted to three types satisfies \"Amb\". Hence for every such model there is a model of formula_27 with the same theory. This does not hold for four types: formula_31 is the same theory as NF, and we have no idea how to obtain a model of TST with four types in which \"Amb\" holds.\n\nIn 1983, Marcel Crabbé proved consistent a system he called NFI, whose axioms are unrestricted extensionality and those instances of \"Comprehension\" in which no variable is assigned a type higher than that of the set asserted to exist. This is a predicativity restriction, though NFI is not a predicative theory: it admits enough impredicativity to define the set of natural numbers (defined as the intersection of all inductive sets; note that the inductive sets quantified over are of the same type as the set of natural numbers being defined). Crabbé also discussed a subtheory of NFI, in which only parameters (free variables) are allowed to have the type of the set asserted to exist by an instance of \"Comprehension\". He called the result \"predicative NF\" (NFP); it is, of course, doubtful whether any theory with a self-membered universe is truly predicative. Holmes has shown that NFP has the same consistency strength as the predicative theory of types of \"Principia Mathematica\" without the Axiom of reducibility.\n\nSince 2015, several candidate proofs by Randall Holmes of the consistency of NF relative to ZF have been available both on arxiv and on the logician's home page. Holmes demonstrates the equiconsistency of a 'weird' variant of TST, namely TTT - 'tangled type theory with λ-types' - with NF. Holmes next shows that TTT is consistent relative to ZFA that is, ZF with atoms but without choice. Holmes demonstrates this by constructing in ZFA+C that is ZF with atoms and choice, a class model of ZFA which includes 'tangled webs of cardinals' . The candidate proofs are all rather long, but no irrecoverable faults have been identified by the NF community so far.\n\nNF steers clear of the three well-known paradoxes of set theory. That NFU, a consistent (relative to Peano arithmetic) theory, also avoids the paradoxes may increase one's confidence in this fact.\n\nThe \"Russell paradox\": An easy matter; formula_32 is not a stratified formula, so the existence of formula_19 is not asserted by any instance of \"Comprehension\". Quine said that he constructed NF with this paradox uppermost in mind.\n\n\"Cantor's paradox\" of the largest cardinal number exploits the application of Cantor's theorem to the universal set. Cantor's theorem says (given ZFC) that the power set formula_34 of any set formula_35 is larger than formula_35 (there can be no injection (one-to-one map) from formula_34 into formula_35). Now of course there is an injection from formula_39 into formula_40, if formula_40 is the universal set! The resolution requires that one observes that formula_42 makes no sense in the theory of types: the type of formula_34 is one higher than the type of formula_35. The correctly typed version (which is a theorem in the theory of types for essentially the same reasons that the original form of Cantor's theorem works in ZF) is formula_45, where formula_46 is the set of one-element subsets of formula_35. The specific instance of this theorem of interest is formula_48: there are fewer one-element sets than sets (and so fewer one-element sets than general objects, if we are in NFU). The \"obvious\" bijection formula_49 from the universe to the one-element sets is not a set; it is not a set because its definition is unstratified. Note that in all known models of NFU it is the case that formula_50; \"Choice\" allows one not only to prove that there are urelements but that there are many cardinals between formula_51 and formula_52.\n\nOne can now introduce some useful notions. A set formula_35 which satisfies the intuitively appealing formula_54 is said to be Cantorian: a Cantorian set satisfies the usual form of Cantor's theorem. A set formula_35 which satisfies the further condition that formula_56, the restriction of the singleton map to \"A\", is a set is not only Cantorian set but strongly Cantorian.\n\nThe \"Burali-Forti paradox\" of the largest ordinal number goes as follows. Define (following naive set theory) the ordinals as equivalence classes of well-orderings under isomorphism. There is an obvious natural well-ordering on the ordinals; since it is a well-ordering it belongs to an ordinal formula_57. It is straightforward to prove (by transfinite induction) that the order type of the natural order on the ordinals less than a given ordinal formula_58 is formula_58 itself. But this means that formula_57 is the order type of the ordinals formula_61 and so is strictly less than the order type of all the ordinals — but the latter is, by definition, formula_57 itself!\n\nThe solution to the paradox in NF(U) starts with the observation that the order type of the natural order on the ordinals less than formula_58 is of a higher type than formula_58. Hence a type level ordered pair is two types higher than the type of its arguments and the usual Kuratowski ordered pair four types higher. For any order type formula_58, we can define an order type formula_58 one type higher: if formula_67, then formula_68 is the order type of the order formula_69. The triviality of the T operation is only a seeming one; it is easy to show that T is a strictly monotone (order preserving) operation on the ordinals.\n\nNow the lemma on order types may be restated in a stratified manner: the order type of the natural order on the ordinals formula_70 is formula_71 or formula_72\ndepending on which pair is used (we assume the type level pair hereinafter). From this one may deduce that the order type on the ordinals formula_73 is formula_74, and thus formula_75. Hence the T operation is not a function; there cannot be a strictly monotone set map from ordinals to ordinals which sends an ordinal downward! Since T is monotone, we have formula_76, a \"descending sequence\" in the ordinals which cannot be a set.\n\nOne might assert that this result shows that no model of NF(U) is \"standard\", since the ordinals in any model of NFU are externally not well-ordered. One need not take a position on this, but can note that it is also a theorem of NFU that any set model of NFU has non-well-ordered \"ordinals\"; NFU does not conclude that the universe \"V\" is a model of NFU, despite \"V\" being a set, because the membership relation is not a set relation.\n\nFor a further development of mathematics in NFU, with a comparison to the development of the same in ZFC, see implementation of mathematics in set theory.\n\nML is an extension of NF that includes proper classes as well as sets.\nThe set theory of the 1940 first edition of Quine's \"Mathematical Logic\" married NF to the proper classes of NBG set theory, and included an axiom schema of unrestricted comprehension for proper classes. However proved that the system presented in \"Mathematical Logic\" was subject to the Burali-Forti paradox. This result does not apply to NF. showed how to amend Quine's axioms for ML so as to avoid this problem, and Quine included the resulting axiomatization in the 1951 second and final edition of \"Mathematical Logic\".\n\nWang proved that if NF is consistent then so is the revised ML, and also showed that the revised ML can prove the consistency of NF, that is that NF and the revised ML are equiconsistent.\n\nThere is a fairly simple method for producing models of NFU in bulk. Using well-known techniques of model theory, one can construct a nonstandard model of Zermelo set theory (nothing nearly as strong as full ZFC is needed for the basic technique) on which there is an external automorphism \"j\" (not a set of the model) which moves a rank formula_77 of the cumulative hierarchy of sets. We may suppose without loss of generality that formula_78. We talk about the automorphism moving the rank rather than the ordinal because we do not want to assume that every ordinal in the model is the index of a rank.\n\nThe domain of the model of NFU will be the nonstandard rank formula_77. The membership relation of the model of NFU will be\n\n\nIt may now be proved that this actually is a model of NFU. Let formula_12 be a stratified formula in the language of NFU. Choose an assignment of types to all variables in the formula which witnesses the fact that it is stratified. Choose a natural number \"N\" greater than all types assigned to variables by this stratification.\n\nExpand the formula formula_12 into a formula formula_83 in the language of the nonstandard model of Zermelo set theory with automorphism \"j\" using the definition of membership in the model of NFU. Application of any power of \"j\" to both sides of an equation or membership statement preserves its truth value because \"j\" is an automorphism. Make such an application to each atomic formula in formula_83 in such a way that each variable \"x\" assigned type \"i\" occurs with exactly formula_85 applications of \"j\". This is possible thanks to the form of the atomic membership statements derived from NFU membership statements, and to the formula being stratified. Each quantified sentence formula_86 can be converted to the form formula_87 (and similarly for existential quantifiers). Carry out this transformation everywhere and obtain a formula formula_88 in which \"j\" is never applied to a bound variable.\n\nChoose any free variable \"y\" in formula_12 assigned type \"i\". Apply formula_90 uniformly to the entire formula to obtain a formula formula_91 in which \"y\" appears without any application of \"j\". Now formula_92 exists (because \"j\" appears applied only to free variables and constants), belongs to formula_93, and contains exactly those \"y\" which satisfy the original formula\nformula_12 in the model of NFU. formula_95 has this extension in the model of NFU (the application of \"j\" corrects for the different definition of membership in the model of NFU). This establishes that \"Stratified Comprehension\" holds in the model of NFU.\n\nTo see that weak \"Extensionality\" holds is straightforward: each nonempty element of formula_96 inherits a unique extension from the nonstandard model, the empty set inherits its usual extension as well, and all other objects are urelements.\n\nThe basic idea is that the automorphism \"j\" codes the \"power set\" formula_93 of our \"universe\" formula_77 into its externally isomorphic copy formula_96 inside our \"universe.\" The remaining objects not coding subsets of the universe are treated as urelements.\n\nIf formula_58 is a natural number \"n\", one gets a model of NFU which claims that the universe is finite (it is externally infinite, of course). If formula_58 is infinite and the \"Choice\" holds in the nonstandard model of ZFC, one obtains a model of NFU + \"Infinity\" + \"Choice\".\n\nFor philosophical reasons, it is important to note that it is not necessary to work in ZFC or any related system to carry out this proof. A common argument against the use of NFU as a foundation for mathematics is that the reasons for relying on it have to do with the intuition that ZFC is correct. It is sufficient to accept TST (in fact TSTU). In outline: take the type theory TSTU (allowing urelements in each positive type) as a metatheory and consider the theory of set models of TSTU in TSTU (these models will be sequences of sets formula_102 (all of the same type in the metatheory) with embeddings of each formula_103 into formula_104 coding embeddings of the power set of formula_102 into formula_106 in a type-respecting manner). Given an embedding of formula_107 into formula_108 (identifying elements of the base \"type\" with subsets of the base type), embeddings may be defined from each \"type\" into its successor in a natural way. This can be generalized to transfinite sequences formula_109 with care.\n\nNote that the construction of such sequences of sets is limited by the size of the type in which they are being constructed; this prevents TSTU from proving its own consistency (TSTU + \"Infinity\" can prove the consistency of TSTU; to prove the consistency of TSTU+\"Infinity\" one needs a type containing a set of cardinality formula_110, which cannot be proved to exist in TSTU+\"Infinity\" without stronger assumptions). Now the same results of model theory can be used to build a model of NFU and verify that it is a model of NFU in much the same way, with the formula_109's being used in place of formula_77 in the usual construction. The final move is to observe that since NFU is consistent, we can drop the use of absolute types in our metatheory, bootstrapping the metatheory from TSTU to NFU.\n\nThe automorphism \"j\" of a model of this kind is closely related to certain natural operations in NFU. For example, if \"W\" is a well-ordering in the nonstandard model (we suppose here that we use Kuratowski pairs so that the coding of functions in the two theories will agree to some extent) which is also a well-ordering in NFU (all well-orderings of NFU are well-orderings in the nonstandard model of Zermelo set theory, but not vice versa, due to the formation of urelements in the construction of the model), and \"W\" has type α in NFU, then \"j\"(\"W\") will be a well-ordering of type \"T\"(α) in NFU.\n\nIn fact, \"j\" is coded by a function in the model of NFU. The function in the nonstandard model which sends the singleton of any element of formula_113 to its sole element, becomes in NFU a function which sends each singleton {\"x\"}, where \"x\" is any object in the universe, to \"j\"(\"x\"). Call this function \"Endo\" and let it have the following properties: \"Endo\" is an injection from the set of singletons into the set of sets, with the property that \"Endo\"( {\"x\"} ) = {\"Endo\"( {\"y\"} ) | \"y\"∈\"x\"} for each set \"x\". This function can define a type level \"membership\" relation on the universe, one reproducing the membership relation of the original nonstandard model.\n\nIn this section the effect is considered of adding various \"strong axioms of infinity\" to our usual base theory, NFU + \"Infinity\" + \"Choice\". This base theory, known consistent, has the same strength as TST + \"Infinity\", or Zermelo set theory with \"Separation\" restricted to bounded formulas (Mac Lane set theory).\n\nOne can add to this base theory strong axioms of infinity familiar from the ZFC context, such as \"there exists an inaccessible cardinal,\" but it is more natural to consider assertions about Cantorian and strongly Cantorian sets. Such assertions not only bring into being large cardinals of the usual sorts, but strengthen the theory on its own terms.\n\nThe weakest of the usual strong principles is:\n\n\nTo see how natural numbers are defined in NFU, see set-theoretic definition of natural numbers. The original form of this axiom given by Rosser was \"the set {\"m\"|1≤\"m\"≤\"n\"} has \"n\" members\", for each natural number \"n\". This intuitively obvious assertion is unstratified: what is provable in NFU is \"the set {\"m\"|1≤\"m\"≤\"n\"} has formula_114 members\" (where the \"T\" operation on cardinals is defined by formula_115; this raises the type of a cardinal by one). For any cardinal number (including natural numbers) to assert formula_116 is equivalent to asserting that the sets \"A\" of that cardinality are Cantorian (by a usual abuse of language, we refer to such cardinals as \"Cantorian cardinals\"). It is straightforward to show that the assertion that each natural number is Cantorian is equivalent to the assertion that the set of all natural numbers is strongly Cantorian.\n\n\"Counting\" is consistent with NFU, but increases its consistency strength noticeably; not, as one would expect, in the area of arithmetic, but in higher set theory. NFU + \"Infinity\" proves that each formula_117 exists, but not that formula_110 exists; NFU + \"Counting\" (easily) proves \"Infinity\", and further proves the existence of formula_119 for each n, but not the existence of formula_120. (See beth numbers).\n\n\"Counting\" implies immediately that one does not need to assign types to variables restricted to the set formula_121 of natural numbers for purposes of stratification; it is a theorem that the power set of a strongly Cantorian set is strongly Cantorian, so it is further not necessary to assign types to variables restricted to any iterated power set of the natural numbers, or to such familiar sets as the set of real numbers, the set of functions from reals to reals, and so forth. The set-theoretical strength of \"Counting\" is less important in practice than the convenience of not having to annotate variables known to have natural number values (or related kinds of values) with singleton brackets, or to apply the \"T\" operation in order to get stratified set definitions.\n\n\"Counting\" implies \"Infinity\"; each of the axioms below needs to be adjoined to NFU + \"Infinity\" to get the effect of strong variants of \"Infinity\"; Ali Enayat has investigated the strength of some of these axioms in models of NFU + \"the universe is finite\".\n\nA model of the kind constructed above satisfies \"Counting\" just in case the automorphism \"j\" fixes all natural numbers in the underlying nonstandard model of Zermelo set theory.\n\nThe next strong axiom we consider is the\n\n\nImmediate consequences include Mathematical Induction for unstratified conditions (which is not a consequence of \"Counting\"; many but not all unstratified instances of induction on the natural numbers follow from \"Counting\").\n\nThis axiom is surprisingly strong. Unpublished work of Robert Solovay shows that the consistency strength of the theory NFU* = NFU + \"Counting\" + \"Strongly Cantorian Separation\" is the same as that of Zermelo set theory + formula_123 \"Replacement\".\n\nThis axiom holds in a model of the kind constructed above (with \"Choice\") if the ordinals which are fixed by \"j\" and dominate only ordinals fixed by \"j\" in the underlying nonstandard model of Zermelo set theory are standard, and the power set of any such ordinal in the model is also standard. This condition is sufficient but not necessary.\n\nNext is\n\n\nThis very simple and appealing assertion is extremely strong. Solovay has shown the precise equivalence of the consistency strength of the theory NFUA = NFU + \"Infinity\" + \"Cantorian Sets\" with that of ZFC + a schema asserting the existence of an \"n\"-Mahlo cardinal for each concrete natural number \"n\". Ali Enayat has shown that the theory of Cantorian equivalence classes of well-founded extensional relations (which gives a natural picture of an initial segment of the cumulative hierarchy of ZFC) interprets the extension of ZFC with \"n\"-Mahlo cardinals directly. A permutation technique can be applied to a model of this theory to give a model in which the hereditarily strongly Cantorian sets with the usual membership relation model the strong extension of ZFC.\n\nThis axiom holds in a model of the kind constructed above (with \"Choice\") just in case the ordinals fixed by \"j\" in the underlying nonstandard model of ZFC are an initial (proper class) segment of the ordinals of the model.\n\nNext consider the\n\n\nThis combines the effect of the two preceding axioms and is actually even stronger (precisely how is not known). Unstratified mathematical induction enables proving that there are \"n\"-Mahlo cardinals for every \"n\", given \"Cantorian Sets\", which gives an extension of ZFC that is even stronger than the previous one, which only asserts that there are \"n\"-Mahlos for each concrete natural number (leaving open the possibility of nonstandard counterexamples).\n\nThis axiom will hold in a model of the kind described above if every ordinal fixed by \"j\" is standard, and every power set of an ordinal fixed by \"j\" is also standard in the underlying model of ZFC. Again, this condition is sufficient but not necessary.\n\nAn ordinal is said to be \"Cantorian\" if it is fixed by \"T\", and \"strongly Cantorian\" if it dominates only Cantorian ordinals (this implies that it is itself Cantorian). In models of the kind constructed above, Cantorian ordinals of NFU correspond to ordinals fixed by \"j\" (they are not the same objects because different definitions of ordinal numbers are used in the two theories).\n\nEqual in strength to \"Cantorian Sets\" is the\n\n\nRecall that formula_57 is the order type of the natural order on all ordinals. This only implies \"Cantorian Sets\" if we have \"Choice\" (but is at that level of consistency strength in any case). It is remarkable that one can even define formula_128: this is the \"n\"th term formula_129 of any finite sequence of ordinals \"s\" of length \"n\" such that formula_130, formula_131 for each appropriate \"i\". This definition is completely unstratified. The uniqueness of formula_128 can be proved (for those \"n\" for which it exists) and a certain amount of common-sense reasoning about this notion can be carried out, enough to show that \"Large Ordinals\" implies \"Cantorian Sets\" in the presence of \"Choice\". In spite of the knotty formal statement of this axiom, it is a very natural assumption, amounting to making the action of \"T\" on the ordinals as simple as possible.\n\nA model of the kind constructed above will satisfy \"Large Ordinals\", if the ordinals moved by \"j\" are exactly the ordinals which dominate some formula_133 in the underlying nonstandard model of ZFC.\n\n\nSolovay has shown the precise equivalence in consistency strength of NFUB = NFU + \"Infinity\" + \"Cantorian Sets\" + \"Small Ordinals\" with Morse–Kelley set theory plus the assertion that the proper class ordinal (the class of all ordinals) is a weakly compact cardinal. This is very strong indeed! Moreover, NFUB-, which is NFUB with \"Cantorian Sets\" omitted, is easily seen to have the same strength as NFUB.\n\nA model of the kind constructed above will satisfy this axiom if every collection of ordinals fixed by \"j\" is the intersection of some set of ordinals with the ordinals fixed by \"j\", in the underlying nonstandard model of ZFC.\n\nEven stronger is the theory NFUM = NFU + \"Infinity\" + \"Large Ordinals\" + \"Small Ordinals\". This is equivalent to Morse–Kelley set theory with a predicate on the classes which is a κ-complete nonprincipal ultrafilter on the proper class ordinal κ; in effect, this is Morse–Kelley set theory + \"the proper class ordinal is a measurable cardinal\"!\n\nThe technical details here are not the main point, which is that reasonable and natural (in the context of NFU) assertions turn out to be equivalent in power to very strong axioms of infinity in the ZFC context. This fact is related to the correlation between the existence of models of NFU, described above and satisfying these axioms, and the existence of models of ZFC with automorphisms having special properties.\n\n\n\n"}
{"id": "26832672", "url": "https://en.wikipedia.org/wiki?curid=26832672", "title": "New Testament military metaphors", "text": "New Testament military metaphors\n\nThe New Testament uses a number of military metaphors in discussing Christianity, especially in the Pauline epistles.\n\nIn Philippians 2:25 and Philemon 1:2, Paul describes fellow Christians as \"fellow soldiers\" (in Greek, συστρατιώτῃ, \"sustratiōtē\"). The image of a soldier is also used in 2 Timothy 2:3–4 as a metaphor for courage, loyalty and dedication; this is followed by the metaphor of an athlete, emphasising hard work. In 1 Corinthians 9:7, this image is used in a discussion of church workers receiving payment, with a metaphorical reference to a soldier's rations and expenses.\n\nEphesians 6:10–18 discusses faith, righteousness, and other elements of Christianity as the armour of God, and this imagery is replicated by John Bunyan in \"The Pilgrim's Progress\", and by many other Christian writers.\n\nRelated imagery appears in hymns such as \"Soldiers of Christ, Arise\" and \"Onward, Christian Soldiers\".\n\n"}
{"id": "16663596", "url": "https://en.wikipedia.org/wiki?curid=16663596", "title": "Nose tomb", "text": "Nose tomb\n\nNose tombs ( \"hana no haka\"; \"ko mudeom\") are tombs that contain human noses or other body parts that were brought back to Japan as trophies during the Japanese invasions of Korea in the late 16th century. War trophies were a part of Japanese tradition at the time and samurai warriors were often paid according to how many they collected.\n\nOne such nose tomb was discovered in 1983 in Okayama near Osaka. This tomb held the severed and pickled noses of approximately 20,000 dead Koreans which were eventually returned to Korea in 1992 and cremated. A similar tomb still exists today in Kyoto called the Mimizuka, literally \"Ear Mound\", although it contains noses and not ears.\n\nIn Japan, these tombs are considered relics by the few who are aware of them, but in Korea these tombs are very well known.\n\n"}
{"id": "87338", "url": "https://en.wikipedia.org/wiki?curid=87338", "title": "Orwellian", "text": "Orwellian\n\n\"Orwellian\" is an adjective describing a situation, idea, or societal condition that George Orwell identified as being destructive to the welfare of a free and open society. It denotes an attitude and a brutal policy of draconian control by propaganda, surveillance, misinformation, denial of truth (doublethink), and manipulation of the past, including the \"unperson\"—a person whose past existence is expunged from the public record and memory, practised by modern repressive governments. Often, this includes the circumstances depicted in his novels, particularly \"Nineteen Eighty-Four\" but political doublespeak is criticized throughout his work, such as in \"Politics and the English Language\".\n\n\"The New York Times\" said the term was \"the most widely used adjective derived from the name of a modern writer\".\n\n\n"}
{"id": "2082265", "url": "https://en.wikipedia.org/wiki?curid=2082265", "title": "Overclass", "text": "Overclass\n\nOverclass is a recent and pejorative term for the most powerful group in a social hierarchy. Users of the term generally imply excessive and unjust privilege and exploitation of the rest of society.\n\nPerhaps the most commonly agreed-upon \"overclass\" consists of leaders in international business, finance and the war industry.\n\nThe influence of the actions by the overclass have been rigorously studied, particularly with regards to notions of intersections between the overclass and specific races. Most notable of these racial overclasses is the NEWBO, or NEW Black Overclass in America.\n\nThe word is fairly recent: the \"Oxford English Dictionary\" included it only in December 2004. But it has been in use since at least 1995. Some writers compare it to the more familiar \"underclass\":\n\n\n"}
{"id": "2146918", "url": "https://en.wikipedia.org/wiki?curid=2146918", "title": "Paternal rights and abortion", "text": "Paternal rights and abortion\n\nThe paternal rights and abortion issue is an extension of both the abortion debate and the fathers' rights movement. “About 98.3% of abortions in the United States are elective, including socio-economic reasons or for birth control. The remaining 1.3% occurs due the following reasons: in cases of rape, 0.3%; in cases of incest, 0.03%; in cases of risk to maternal life, 0.1%; in cases of risk to maternal health, 0.8%; and in cases of fetal health issues, 0.5%” As a result of majority of abortions are planned, abortion is becoming a factor for disagreement and lawsuit between partners.\n\nRoman law allowed induced abortions but regulated it in consideration of the biological father. Emperor Septimius Severus ruled circa 211 AD that a woman who had an abortion without consent from her husband should face exile for having bereaved her husband of children.\n\nIn his speech \"Pro Cluentio\", delivered in 66 BC, Cicero refers to a case he had heard of in which a woman from Miletus was sentenced to death for having aborted her pregnancy, upon receiving bribes from those who stood to inherit her husband's estate if he produced no heir. Cicero said that in doing so she had \"destroyed the hope of the father, the memory of his name, the supply of his race, the heir of his family, a citizen intended for the use of the republic\".\n\nA 4th century BC Greek writer from Alexandria, Egypt, Sopater, quoted the lawyer Lysias, who had referred to a trial in Athens in which a man named Antigene accused his wife of having deprived him of a son by having an abortion.\n\nWhether a male has a legal right to advance his personal interest, whether it be toward abortion, fatherhood, or adoption, over that of the female, differs by region.\n\nIn 2011, it was reported that Indonesia, Malawi, Syria, United Arab Emirates, Equatorial Guinea, Kuwait, Maldives, Morocco, South Korea, Saudi Arabia, Japan, Taiwan and Turkey all had laws which required that an abortion first be authorized by the woman's husband. However, in some countries, this stipulation could be bypassed or overridden if there is genuine concern for maternal health.\n\nSince \"Roe v. Wade\", some states in the United States have attempted to enact laws requiring spousal consent. All of these laws have been ruled unconstitutional, spousal consent in the 1976 decision \"Planned Parenthood v. Danforth\" and spousal awareness in the 1992 decision \"Planned Parenthood v. Casey\n\nIn China the husband of a woman who had an abortion filed a lawsuit against her in 2002 under a law intended to grant sexual equality in terms of childbearing and contraceptive decisions. The law stated that a woman has no overriding priority over her spouse in deciding whether to have a child.\n\nA number of legal cases have arisen in the Western world in which men have tried to prevent women with whom they had been sexually active from obtaining an abortion, all of which failed:\n\n\nAbout men deciding to decline parenthood in the event of an unintended pregnancy and asking for a financial abortion:\n\nThose who support a man's right to intervene in a woman's reproductive decisions, argue that it is unreasonable that, after fertilisation has occurred, women are often given more options with regard to pregnancy and parenthood than men. Armin Brott has said of this, \"A woman can legally deprive a man of his right to become a parent or force him to become one against his will\".\n\nMen's rights and fathers' rights activists have argued that men should have veto power over their partners' decisions to abort. Similarly, philosopher George W. Harris has written that, if a man impregnates a woman with the explicit goal of having a child, in a manner that is mutually consensual, then it would be morally unacceptable for that woman to later have an abortion.\n\nThose who object to men having a right to direct involvement argue that because it is the woman's body carrying the unborn baby, her determination for or against abortion should be the only one. Marsha Garrison, a professor at Brooklyn Law School, stated that U.S. courts acknowledge \"that embryo is in the woman's body, it is within her and can't be separated from her, so it's not just her decision-making about whether to bear a child, it's about her body\".\n\nA 2002 United States Gallup special report mentions only 38% of the population being opposed to notifying the husband of a married woman for an abortion. In a 2003 Gallup poll, 72% of respondents were in favor of notification to the husband, with 26% opposed; of those polled, 79% of males and 67% of females responded in favor of notification inside married couples.\n\nBioethicist Jacob Appel has asked, “if one grants a man veto power over a woman’s choice to have an abortion in cases where he is willing to pay for the child, why not grant him the right to demand an abortion where he is unwilling to provide for the child?\"\n\nIn reference to cases in which men who do not desire to become fathers have been required to pay child support, Melanie McCulley, a South Carolina attorney, in her 1998 article, \"The Male Abortion: The Putative Father's Right to Terminate His Interests in and Obligations to the Unborn Child,\" set forth the theory of the \"male abortion,\" in which she argues that men should be able to terminate their legal obligations to unwanted children.\n\nIt is also possible, rather than taking the stance that males should have the freedom to opt out of inherent responsibilities and rights, to take the stance that one must opt-in and agree to undertake those responsibilities to be compelled to follow them, and only through doing so, earn parental rights. This is what occurs during adoption.\n\n"}
{"id": "523835", "url": "https://en.wikipedia.org/wiki?curid=523835", "title": "Pournelle chart", "text": "Pournelle chart\n\nThe Pournelle chart, developed by Jerry Pournelle in his 1963 political science Ph.D. dissertation, is a two-dimensional coordinate system which can be used to distinguish political ideologies. It is similar to the political compass and the Nolan Chart in that it is a two-dimensional chart, but the axes of the Pournelle chart are different from those of other systems. The two axes are as follows:\n\nPournelle arranged American liberalism, socialism, and communism, in the upper right-hand quadrant of high state control and high rationalism. Conservatism, fascism, and Nazism are placed in the lower right hand quadrant of high state control and low rationalism. Classical anarchists are in the lower left hand corner of low state control and low rationalism. Libertarians (including anarcho-capitalists) and Objectivists are placed in the upper left-hand corner of low state control and high rationalism. Each diagonal axis contains natural political allies.\n\n\n"}
{"id": "477125", "url": "https://en.wikipedia.org/wiki?curid=477125", "title": "Psychological pain", "text": "Psychological pain\n\nPsychological pain, mental pain, or emotional pain is an unpleasant feeling (a suffering) of a psychological, non-physical origin. A pioneer in the field of suicidology, Edwin S. Shneidman, described it as \"how much you hurt as a human being. It is mental suffering; mental torment.\" There is no shortage in the many ways psychological pain is referred to, and using a different word usually reflects an emphasis on a particular aspect of mind life. Technical terms include algopsychalia and psychalgia, but it may also be called mental pain, emotional pain, psychic pain, social pain,\nspiritual or soul pain, or suffering. While these clearly are not equivalent terms, one systematic comparison of theories and models of psychological pain, psychic pain, emotional pain, and suffering concluded that each describe the same profoundly unpleasant feeling. Psychological pain is believed to be an inescapable aspect of human existence.\n\nOther descriptions of psychological pain are \"a wide range of subjective experiences characterized as an awareness of negative changes in the self and in its functions accompanied by negative feelings\", \"a diffuse subjective experience ... differentiated from physical pain which is often localized and associated with noxious physical stimuli\", and \"a lasting, unsustainable, and unpleasant feeling resulting from negative appraisal of an inability or deficiency of the self.\"\n\nThe adjective 'psychological' is thought to encompass the functions of beliefs, thoughts, feelings, and behaviors, which may be seen as an indication for the many sources of psychological pain. One way of grouping these different sources of pain was offered by Shneidman, who stated that psychological pain is caused by frustrated psychological needs. For example, the need for love, autonomy, affiliation, and achievement, or the need to avoid harm, shame, and embarrassment. Psychological needs were originally described by Henry Murray in 1938 as needs that motivate human behavior. Shneidman maintained that people rate the importance of each need differently, which explains why people's level of psychological pain differs when confronted with the same frustrated need. This needs perspective coincides with Patrick David Wall's description of physical pain that says that physical pain indicates a need state much more than a sensory experience.\n\nIn the fields of social psychology and personality psychology, the term social pain is used to denote psychological pain caused by harm or threat to social connection; bereavement, embarrassment, shame and hurt feelings are subtypes of social pain. From an evolutionary perspective, psychological pain forces the assessment of actual or potential social problems that might reduce the individual's fitness for survival. The way we display our psychological pain socially (for example, crying, shouting, moaning) serves the purpose of indicating that we are in need.\n\nBorderline personality disorder (BPD) has long been believed to be the one psychiatric disorder that produced the most intense emotional pain, agony, and distress in those who suffer with this condition. Studies have shown that borderline patients experience chronic and significant emotional suffering and mental agony. Borderline patients may feel overwhelmed by negative emotions, experiencing intense grief instead of sadness, shame and humiliation instead of mild embarrassment, rage instead of annoyance and panic instead of nervousness. People with BPD are especially sensitive to feelings of rejection, isolation and perceived failure. Both clinicians and laymen alike have witnessed the desperate attempts to escape these subjective inner experiences of these patients. Borderline patients are severely impulsive and their attempts to alleviate the agony are often very destructive or self-destructive. Suicidal ideation, suicide attempts, eating disorders (anorexia nervosa and bulimia nervosa), self-harm (cutting, overdosing, etc.), compulsive spending, gambling, sex addiction, violent and aggressive behaviour, sexual promiscuity and deviant sexual behaviours, are desperate attempts to escape. The intrapsychic pain experienced by those diagnosed with BPD has been studied and compared to normal healthy controls and to others suffering from major depression, bipolar disorder, substance use disorder, schizophrenia, other personality disorders, and a range of other conditions. The excruciatingly painful inner experience of the borderline patient is both unique and perplexing. In clinical populations, the rate of suicide of patients with borderline personality disorder is estimated to be 10%, a rate far greater than that in the general population and still considerably greater than for patients with schizophrenia and bipolar disorder. However, since 60–70% of patients with borderline personality disorder make suicide attempts; suicide attempts are far more frequent than completed suicides in patients with borderline personality disorder.\n\nThe intense dysphoric states which patients diagnosed with borderline personality disorder (BPD) endure on a regular basis distinguishes them from those suffering from other personality disorders, major depressive disorder, bipolar disorder, and virtually all known Axis I and Axis II conditions. In a study, twenty-five dysphoric states (mostly affects) were found to be significantly more common among borderline patients than controls. Twenty-five other dysphoric states (mostly cognitions) were found to be both significantly more common among borderline patients than controls and highly specific to borderline personality disorder. These states tended to fall into one of four clusters: (1) extreme feelings, (2) destructiveness or self-destructiveness, (3) fragmentation or \"identitylessness\", and (4) victimization. In addition, three of the 25 more-specific states (feeling betrayed, like hurting myself, and completely out of control), when occurring together, were particularly strongly associated with the borderline diagnosis. Equally important, overall mean Dysphoric Affect Scale scores correctly distinguished borderline personality disorder from other personality disorders and mood disorders such as bipolar disorder, major depression, and anxiety disorders in 84% of the subjects. Taken together, the results of this study suggest that the subjective pain of borderline patients may be both more pervasive and more multifaceted than previously recognized, and that the overall “amplitude” (or intensity) of this pain may be a particularly good marker for the borderline diagnosis.\n\nResearch suggests that physical pain and psychological pain may share some underlying neurological mechanisms. Brain regions that were consistently found to be implicated in both types of pain are the anterior cingulate cortex and prefrontal cortex (some subregions more than others), and may extend to other regions as well. Brain regions that were also found to be involved in psychological pain include the insular cortex, posterior cingulate cortex, thalamus, parahippocampal gyrus, basal ganglia, and cerebellum. Some advocate that, because similar brain regions are involved in both physical pain and psychological pain, we should see pain as a continuum that ranges from purely physical to purely psychological. Moreover, many sources mention the fact that we use metaphors of physical pain to refer to psychological pain experiences. Further connection between physical and psychological pain has been supported through proof that acetaminophen, an analgesic, can suppress activity in the anterior cingulate cortex and the insular cortex when experiencing social exclusion, the same way that it suppresses activity when experiencing physical pain.\n\nResearch has shown that use of analgesic paracetamol for several weeks reduces neural response to meaning threats, such as thinking about death, and reduces the agitation of people with dementia. However use of paracetamol for more general psychological pain remains disputed.\n\nMany religious traditions, such as the Noble Eightfold Path in Buddhism, have attempted or managed to provide treatment of psychological suffering. Meditation has mental health benefits. The most common form of meditative practice as therapy is mindfulness, but breath focused exercises are also used for dealing with the stresses and anxiety related to emotional pain, reducing physiological symptoms.\n\n"}
{"id": "38447960", "url": "https://en.wikipedia.org/wiki?curid=38447960", "title": "R v Ryan", "text": "R v Ryan\n\nR v Ryan [2013] SCC 3 is a case concerning the availability of duress in the context of domestic violence.\n\nNicole Doucet Ryan (now Nicole Doucet) alleged that she was subject to repeated abuse and torment by her husband, Michael Ryan. At trial, the trial judge accepted she was subject to such abuse. The husband was never called to testify. \nIn September 2007, Ms. Doucet began to think about having her husband murdered. Over the course of the next seven months, she spoke to at least three men whom she hoped would kill him. In December 2007 or January 2008, she paid one man $25,000 to carry out the killing, but he then refused, demanding more compensation. She approached another person and was contacted by a third, an undercover RCMP officer, posing as a “hit man”. On March 27, 2008, she met with this individual and agreed to pay him to kill her husband. The agreed upon price was $25,000, with $2,000 paid in cash that day. The killing was to take place the coming weekend. Later that same night, she provided an address and a picture of her husband to the “hit man.” Shortly after, she was arrested and charged with counselling the commission of an offence not committed contrary to s. 464(a) of the Criminal Code, R.S.C. 1985, c. C-46.\n\nAt trial, there was no issue that the elements of the offence had been proved and the trial judge, Farrar J. (as he then was), indicated that he was satisfied beyond a reasonable doubt that the requisite elements of the offence of counselling the commission of an offence had been established. He based this conclusion on the Ms. Doucet’s admission that the Crown had proved a prima facie case and on the audio and video tapes of recorded conversations with the undercover officer and a statement made on arrest. The only issue at trial was whether Ms. Doucet’s otherwise criminal acts were excused because of duress. The accused had raised that the common law defence of duress applied. The Crown argued that on the facts of this case, the components of duress were not present. But it did not argue at trial, as it did later on appeal, that the defence of duress was not available in law to the accused. The trial judge accepted her version and acquitted her on the basis she had established she was acting under duress. \n\nThe Nova Scotia Court of Appeal unanimously upheld her acquittal.\n\nThe Court allowed the Crown appeal. The majority entered a stay while the dissenting judge, Fish J., would have ordered a new trial, leaving it to the Crown to determine whether a retrial was in the public interest.\n\nThe Court accepted the facts found by the trial judge. The only issue was whether the defence of duress was available. The Court accepted the Crown’s argument, which was made for the first time, that duress was not available. Duress is available when one is compelled to commit a crime against an innocent third party. In this case, given the facts found by the trial judge, the husband would not be an innocent victim. Rather he would be the author of his own misfortune. Moreover, Ms. Doucet was never compelled to act as she did. The Court alluded to the possibility of invoking self-defence as a possible defence.\n\nFish J. found the granting of the stay of proceedings was inappropriate. He would have ordered a new trial. Any further defence advanced by the accused could be made then.\n\nFollowing the release of the decision on January 18, 2013, Michael Ryan, ex-husband of the accused denied any of the allegations made. He emphasized he was in attendance at court in response to a subpoena, but the Crown never called him as a witness.\n\nA law professor from Dalhousie University called for a public inquiry. He questioned the rationale of the Crown not to call Mr. Ryan as a witness. He also was critical of the Court in making findings against the RCMP without having heard anything from the RCMP. He was also critical of the granting of a stay of proceedings, agreeing with Fish J. that it is an extreme remedy.\n\n"}
{"id": "10857454", "url": "https://en.wikipedia.org/wiki?curid=10857454", "title": "Racial tension in Omaha, Nebraska", "text": "Racial tension in Omaha, Nebraska\n\nRacial tension in Omaha, Nebraska, occurred mostly because of the city's volatile mixture of high numbers of new immigrants from southern and eastern Europe and African-American migrants from the Deep South. While racial discrimination existed at several levels, the violent outbreaks were within working classes. Irish Americans, the largest and earliest immigrant group in the 19th century, established the first neighborhoods in South Omaha. All were attracted by new industrial jobs and most were from rural areas. There was competition among ethnic Irish, newer European immigrants, and African-American migrants from the South, for industrial jobs and housing. They all had difficulty adjusting to industrial demands, which were unmitigated by organized labor in the early years. Some of the early labor organizing resulted in increasing tensions between groups, as later arrivals to the city were used as strikebreakers.\n\nIn Omaha as in other major cities, racial tension has erupted at times of social and economic strife, often taking the form of mob violence as different groups tried to assert power. Much of the early violence came out of labor struggles in early 20th century industries: between working class ethnic whites and immigrants, and blacks of the Great Migration. Meatpacking companies had used the latter for strikebreakers in 1917 as workers were trying to organize. As veterans returned from World War I, both groups competed for jobs. By the late 1930s, however, interracial teams worked together to organize the meatpacking industry under the United Packinghouse Workers of America (UPWA). Unlike the AFL and some other industrial unions in the CIO, UPWA was progressive. It used its power to help end segregation in restaurants and stores in Omaha, and supported the civil rights movement in the 1960s. Women labor organizers such as Tillie Olsen and Rowena Moore were active in the meatpacking industry in the 1930s and 1940s, respectively.\n\nMost violence and civil unrest in the 1960s, by contrast, arose out of poverty and problems caused by massive loss of working-class jobs through industrial restructuring. The city's African-American community suffered particularly and erupted in protest.\n\nThe Nebraska Territory was created in 1854 with the condition that the area stay slave-free. But, from 1855 on, there was debate in the Territorial Legislature about whether slavery should specifically be prohibited. As there were few slaves in the state, some legislators did not think the bill was needed. In 1859, the \"Daily Nebraskian\" newspaper reported its favoring of slavery, writing,\n\nDuring that period, some local newspapers openly editorialized against the presence of blacks in Omaha, for the Confederacy and against the election of Abraham Lincoln. The 1860 census showed that of the 81 Negroes in Nebraska, only 10 were slaves.\n\nBecause a clause in the original proposed Nebraska State Constitution limited voting rights in the state to \"free white males\", as had been common in many states, Nebraska was delayed about a year from entering the Union. In 1865, the Nebraska Territorial Legislature changed the proposed State Constitution to provide expanded suffrage. The territory gained statehood soon after.\n\nFollowing the Civil War, enough blacks lived in Omaha to organize St. John's African Methodist Episcopal Church in 1867 as the first church for African Americans in Nebraska. The first recorded birth of an African American was that of William Leper, recorded in Omaha in 1872. In 1891 a mob lynched George Smith, an African American man, for allegedly raping a \"white\" woman. No one was charged in his murder.\n\nIn the early 20th century, social tensions of the rapidly industrializing city absorbing waves of new immigrants and migrants broke out in riots between ethnic minorities. The riots included extensive property damage and some deaths.\n\nSouth Omaha was where many different immigrant groups established their own neighborhoods. These ranged from Sheelytown for ethnic Irish to Polish and Czech. Little Italy and Little Bohemia closely bordered South Omaha at its north boundary as well. The immigrants comprised most of the workers at the stockyards and meatpacking plants, also located there. They started organizing different laborers and stopped work with strikes. The industry responded by hiring workers from other parts of the country who were also seeking work: both European immigrants and black migrants from the South (whose numbers doubled in Omaha from 1910 to 1920). In 1905, more than 800 students (mostly children of immigrant workers) in South Omaha protested the presence of Japanese students at their school, calling them \"scabs\". The Japanese students were children of strikebreakers brought in by the Omaha Stockyards the previous summer during a fierce strike. Children of the regular workers refused to attend classes and locked teachers out of the building.\n\nGreek Town was a growing Greek immigrant community in South Omaha. Other immigrants resented the Greeks, who had come to the city as strikebreakers. Many men of the community had been jobless for an extensive period after they were laid off following the strikes. Some Omaha citizens assumed they were lazy rather than unemployed. In September 1909 a male resident of the Greek community was arrested by an ethnic Irish South Omaha policeman for allegedly having a relationship with a \"white\" woman. (He was taking English lessons from her.) The man took the officer's gun and shot him. After the Greek was captured a short while later, a mob of ethnic whites numbering about 1,000 arrived at the door of the jail. By then the South Omaha policemen had transferred the man to the Omaha city jail. (The jurisdictions were then separate.) Frustrated, the mob turned to the Greek neighborhood and began to destroy it, threatening all of its residents with death if they stayed in town. Within a day the Greek residents abandoned the six-by-six block area and scattered into cities across the Midwest. Meanwhile, the mob destroyed the entire neighborhood. The accused Greek immigrant was brought to trial; but, after intervention from the Greek ambassador to the U.S., who protested the government's failure to protect the immigrant community, the city of Omaha released the man and dropped charges against him.\n\nIn the immediate years after World War I and defeat of Germany by the Allies, anti-German sentiment ran high across the country. The Nebraska legislature passed a law in 1919 that enforced teaching in English in public schools. (Because of substantial immigration by Germans to Nebraska, in earlier years, studies in German were available in the public schools, along with French and classical languages.) By law, \"No person, individually or as a teacher, shall, in any private, denominational, parochial or public school, teach any subject to any person in any language than the English language.\" Robert Meyer was found to violate this law because he taught German. He was taken to court by the State of Nebraska, and when found guilty he appealed. Although his appeal to the Nebraska Supreme Court failed, the U.S. Supreme Court in \"Meyer v. Nebraska\" determined that Meyer had the right to teach the German language as a subject, and to teach it in German. During the course of the year, open discrimination against Germans throughout Omaha was taking hold. Many German-language newspapers were forced to change to English, or to close.\n\nIn September 1919, following a summer of racial riots in several other industrial cities, an African-American laborer named Willy Brown was lynched in Omaha. He had been accused of raping a young white woman. A mob of 5,000 ethnic white men marched from South Omaha (some young men were classmates of the woman) and appeared at the Douglas County Courthouse to demand \"justice\". Within hours the mob grew to 10,000 people. Many were drinking. When the reform mayor Edward P. Smith attempted to intervene, he was nearly lynched by the mob. Only a last-minute rescue saved him from being hanged. The mob threw stones at windows, far outnumbered the police, and set the courthouse on fire to force the release of Brown. The police turned him over to save other prisoners. In a frenzy, the mob hung Brown from a lamppost and shot him, later dragged his body and burned it. The mob turned against police vehicles and attacked any blacks they found in the street. They began to move toward a large African-American enclave in North Omaha. The city and governor had called in the U.S. Army from Fort Omaha to intervene. It stationed troops in North Omaha to protect the blacks, and after gaining control of the mob, in South Omaha to prevent any more riots forming. An unseasonal rainstorm cooled the mob down as well. The Army commander established martial law for several days. A grand jury's investigation identified the mob as arising from South Omaha and being encouraged by the city's vice world. No one was charged in the events, however.\n\nOn July 4, 1910 African American boxer Jack Johnson won a major upset at a national match in Reno, Nevada. Upon hearing the news, a dozen fights broke out in different areas of the city between whites and blacks, as happened in other cities. Whites wounded several black men and killed one.\n\nAfter World War I, white veterans trying to return to their civilian jobs found African-American and Eastern European immigrants in their former positions. Their resentment led to several violent strikes in the South Omaha meat packing industry as groups tried to control access to jobs. During this period, Earl Little was a Baptist minister in North Omaha. After his son, Malcolm, was born in Omaha in 1925, the family moved away because of threats by the Ku Klux Klan in 1926. (The KKK had undergone a revival and growth in the Midwest in the early 1920s.) Malcolm Little later changed his last name to X, when he joined the Black Muslims, where he became an important leader known as Malcolm X.\n\nIn the 1920s, racial segregation became normalized in Omaha as redlining and restrictive covenants kept African Americans concentrated in housing in North Omaha. The riot had discredited the city's newly elected reformist government. In the next election, \"Cowboy\" Jim Dahlman was returned to office with the support of Tom Dennison, the informal leader of the vice world. The labor struggles and social struggles led Omaha's African-American leaders, such as Earl Little, Harry Haywood and George Wells Parker, to push harder for civil rights. After this period, African Americans in Omaha were largely concentrated as residents on the city's north side, with a small community in South Omaha.\n\nIn 1947 a student-led civil-rights group called the DePorres Club was forced off the Creighton University campus, where they started. Mildred Brown, a community activist and publisher, invited them to meet at the \"Omaha Star\", the paper she directed for the African-American community for decades.\n\nOmaha jazz legend Preston Love reported that in the 1950s he saw signs in Omaha restaurants and bars that said, \"We Don't Serve Any Colored Race\", but that he was always welcome as a musician. In the 1950s, the United Meatpacking Workers of America (UPWA) helped use their power to have businesses in Omaha integrate their facilities.\n\nThe late 1950s and early 1960s was the period which Lois Mark Stalvey wrote about in \"The Education of a WASP\". She recounted her activist efforts to desegregate a middle-class West Omaha neighborhood for an African-American surgeon and his family who wanted to live in the area. Such efforts took place in a different environment from the struggles of most working-class families in North and South Omaha.\n\nIn 1955, the State of Nebraska took Omaha's main amusement park, Peony Park, to district court. The state believed that the park, founded in 1919, violated Nebraska Civil Rights Law when African American swimmers at the Amateur Athletic Union Swimming Meet held at the park on August 27, 1955 were discriminated against. In \"State of Nebraska v. Peony Park\", the Nebraska Supreme Court found that two African-American participants were illegally barred from the meet because Peony Park barred them from the pool. On September 7, 1955, the court fined Peony Park $50 and costs of the trial. Additional civil suits were settled out of court. The \"Omaha Star\" newspaper reported extensively on the trial, using the opportunity to highlight segregationist policies around the city as well as the city's burgeoning civil rights movement.\n\nBy the early 1960s, economic progress by many African Americans and ethnic Americans became unraveled in the massive job losses caused by restructuring of railroad and meatpacking industries. By the mid-1960s, North Omaha had much more poverty than before and increasing social problems. On July 4, 1966, tensions broke out in a riot after a day of blistering 103 degree weather. Refusing a police order to disperse, African Americans demolished police cars and attacked the North 24th Street business corridor, throwing firebombs and demolishing storefronts. Businesses in the Near North Side suffered millions of dollars in damages. The riot lasted three days. The National Guard was called in to disperse the rioters. Less than a month later, on August 1, 1966, riots erupted after a 19-year-old was shot by a white off-duty policeman during a burglary. rioters firebombed three buildings and 180 riot police were required to quell the crowds. Leaders in the community criticized the \"Omaha World-Herald\" and local television stations for blaming African Americans for the conditions they faced in their deteriorating neighborhoods, when the problems of joblessness and decreased maintenance were beyond city and regional control. That same year, 1966, \"A Time for Burning\", a documentary featuring North Omaha and the social problems, was filmed. Later it was nominated for an Oscar for best documentary.\n\nIn March 1968 a crowd of high school and university students gathered at the Omaha Civic Auditorium to protest the presidential campaign of George Wallace, the segregationist governor of Alabama. After counter-protesters began acting violently toward the activists, police brutality led to dozens of protesters being injured. During the melee, an African-American youth was shot and killed by a police officer. Students' fleeing the outbreak attacked businesses and cars, causing thousands of dollars of damage.\n\nThe following day a local barber named Ernie Chambers helped calm a disturbance and prevent a riot by students at Horace Mann Junior High School. Chambers was already recognized as a community leader. After finishing his law degree, Chambers was elected to the Nebraska State Legislature. He went on to serve a total of 38 years, longer than any of his predecessors. Robert Kennedy visited Omaha later that year in his quest to become president, speaking in support of Omaha's civil rights activists.\n\nAn African-American teenager named Vivian Strong was shot and killed by police officers in an incident at the Logan Fontenelle Housing Projects in June 1969. Young African Americans in the area rioted after the teenager's death, and looted along the North 24th Street business corridor. Eight businesses were destroyed by firebombing or looting. Events went on for several more days. This is the last noted riot in Omaha.\n\nIn 1970 an African-American man named Duane Peak was arrested, and quickly implicated six others in a bombing at a vacant house in North Omaha that killed a police officer. On August 31, local Black Panther Party leaders David Rice and Ed Poindexter were arrested in the case, despite not having been originally implicated. In 1971 both men were convicted of murder in the controversial Rice/Poindexter Case, and in 1974 a retrial of Rice and Poindexter was denied by the Nebraska State Supreme Court.\n\nThe 1970s construction of the North Freeway bisected North Omaha, effectively cutting the African-American community in half and creating social problems. In 1976, the Omaha Public Schools began court-ordered busing to achieve integration.\n\nIn 1981 arsonists burned an East Omaha duplex after an African-American family signed a rental agreement there. The arson is unsolved.\n\nIn 1993 the Nebraska Parole Board voted for the first time to unanimously commute the sentences of Rice and Poindexter to time served. The Nebraska Board of Pardons refused to schedule a hearing in the matter. This same sequence of events has occurred no fewer than three times since then, with the same outcome each time.\n\nIn 1995 an African-American gang member murdered an Omaha police officer named Jimmy Wilson, Jr. The city responded by equipping every police car with a camera and giving North Omaha officers body armor. Later that year arsonists tipped over and burned an African-American woman's car in East Omaha near the site of the 1981 arson. Both cases are unsolved.\n\nIn 1996 the Omaha public schools ended court-ordered busing. That same year the \"Omaha World-Herald\" reported that, \"One resident of Rose Garden Estates near 172nd and Pacific Streets said privately, for instance, that he finds the prospect of being incorporated into the city 'increasingly scary.' 'I left Benson because I didn't like the changes,' he said. 'Too much crime, too much racial tension, too much school busing. I went to the suburbs to get away from that, and now I'm being forced back in.' The man, an insurance company employee, denied that his problems were based on race, but he asked that this part of the interview be anonymous.\"\n\nIn 1997, an African-American Gulf War veteran named Marvin Ammons was shot and killed by an Omaha police officer. A grand jury indicted the officer for manslaughter; the indictment was quashed due to a finding of jury misconduct. A second grand jury cleared the officer of wrongdoing and admonished the Omaha police department for mishandling the case.\n\nIn 2000, George Bibbins, an African American, led Omaha police on a high-speed car chase. At the end of the chase, he was shot and killed by officers. A grand jury later cleared the officers involved of any wrongdoing.\n\nThat year the Nebraska State Legislature enacted term limits. Some believed this action was directed against the long-time State Senator Ernie Chambers, an African American who had then served 27 years. In 2005 Chambers became the longest-serving State Senator in Nebraska history, with more than 32 years of service. Because of the 2002 law, he was not allowed to run for office again once his term expired in 2008.\n\nDesegregation busing and racial integration in public schools were contentious issues in Omaha. Problems with public schools were a factor in middle-class people moving to the suburbs, but the shift in population to suburbs also followed the growth of the city and highways. Omahans' preference for larger, newer housing was just like that of other Americans. Middle-class African Americans have also moved to the suburbs here and in other cities.\n\nFrom 1976 to 1999, Omaha had a busing plan as an effort to integrate the schools. Busing was an early goal of civil rights leaders and groups in Omaha, including 4CL, who lauded integrated busing as a particularly important step in improving race relations. When the city considered ending busing in the 1990s, Concerned and Caring Educators, a 100-member group of black education administrators and supervisors, praised the system as having improved race relations and the education of Omaha's students.\n\nOmaha Public Schools ended busing to achieve integration in 1999. It responded to parental desires for neighborhood schools and for choice. It has created magnet schools to attract students from middle-class families. As in many other cities, concerns about schools are high. Like some other districts such as Louisville, Kentucky, Omaha has begun to explore socioeconomic integration - assigning students according to family income - to change the makeup of their schools and address low test scores among poor children in the inner city. There have been delays in efforts to unite the Omaha public school district with newly annexed smaller, local districts in the western half of the city.\n\nSenator Ernie Chambers proposed a controversial school separation plan for Omaha in the Nebraska State Legislature in response to concerns by suburban districts outside Omaha boundaries. The state legislature was interested in seeking a way to use suburban districts to help integrate the city's schools. \"The law, intended to resolve a boundary dispute between the Omaha schools and largely white suburban districts, created a learning community of area school districts that would operate with a common tax levy and required them to draw up an integration plan for metropolitan Omaha.\"\n\nChambers lobbied to create three districts in the city, with each drawn along geographic boundaries that loosely correlated to the racial segregation of the city: African Americans in North Omaha, Hispanic/Latinos in South Omaha, and Caucasians in West Omaha. Chambers defended his decision from the standpoint that much of the city had residential segregation and that his plan would provide African American parents in North Omaha with more control over their district. The State Legislature signed this plan into law in April, 2006, with the plan going into effect in 2008.\n\nWithin a month of the legislature's passing the law, the National Association for the Advancement of Colored People brought a lawsuit, arguing that due to Omaha's racially segregated residential patterns, subdivided school districts will also be racially segregated, contrary to United States law. The case has also drawn national attention. Critics regard the plan as \"state-sponsored segregation\".\n\nIn February 2007, unknown assailants robbed, firebombed, and spray painted a racist epithet on the side of an East Omaha grocery store owned by an Ethiopian immigrant. That crime is unsolved.\n\nIn October 2007, the \"Omaha World-Herald\" noted recent census statistics showed that Omaha, the 43rd largest city in the United States, has the fifth highest poverty rate for African Americans among the 100 largest cities. More than one in three live below the poverty line. The city has plans for public-private development in North Omaha that are intended to revive the area. Investment in infrastructure, parks and street design has already begun.\n\nSome groups have tried to manufacture political power out of immigration issues, but more people in the city and community have rallied in support of the Hispanic community, who comprise the most numerous recent immigrants. In 2007 a neo-Nazi group tried to organize a protest and had 65 participants outside the city's Mexican consulate. They were far outnumbered by the thousands in counter-protests, as well as those celebrating at events marking the diversity of the city.\n\n\n\n"}
{"id": "3385988", "url": "https://en.wikipedia.org/wiki?curid=3385988", "title": "Radical interpretation", "text": "Radical interpretation\n\nRadical interpretation is interpretation of a speaker, including attributing beliefs and desires to them and meanings to their words, from scratch—that is, without relying on translators, dictionaries, or specific prior knowledge of their mental states. The term was introduced by American philosopher Donald Davidson (1973) and is meant to suggest important similarity to W. V. O. Quine's term radical translation, which occurs in his work on the indeterminacy of translation. Radical translation\nis translation of a speaker's language, without prior knowledge, by observing the speaker's use of the language in context.\n\nEven more so than radical translation did for Quine, radical interpretation plays an important role in Davidson's work, but the exact nature of this role is up for debate. Some see Davidson as using radical interpretation directly in his arguments against conceptual relativism and the possibility of massive error--of most of our beliefs being false. But Davidson seems to explicitly reject this reading in \"Radical Interpretation Interpreted\".\n\nThere is also a more narrow and technical version of radical interpretation used by Davidson: given the speaker's attitudes of holding particular sentences true in particular circumstances, the speaker's hold-true attitudes, the radical interpreter is to infer a theory of meaning, a truth theory meeting a modified version of Alfred Tarski's Convention T, for the speaker's idiolect. Ernest Lepore and Kirk Ludwig characterize this as inference from sentences of the form:\n\nto corresponding T-sentences of the form\n\nwhere s is a sentence in the idiolect of the speaker S, t is a time, and p and q are filled in with sentences in the metalanguage.\n\n"}
{"id": "4468889", "url": "https://en.wikipedia.org/wiki?curid=4468889", "title": "Reality in Buddhism", "text": "Reality in Buddhism\n\nReality in Buddhism is called \"dharma\" (Sanskrit) or \"dhamma\" (Pali). This word, which is foundational to the conceptual frameworks of the Indian religions, refers in Buddhism to the system of natural laws which constitute the natural order of things. \"Dharma\" is therefore reality as-it-is (\"yatha-bhuta\"). The teaching of Gautama Buddha constituting as it does a method by which people can come out of their condition of suffering (\"dukkha\") involves developing an awareness of reality (\"see\" mindfulness). Buddhism thus seeks to address any disparity between a person's view of reality and the actual state of things. This is called developing Right or Correct View (Pali: \"samma ditthi\"). Seeing reality as-it-is thus an essential prerequisite to mental health and well-being according to Buddha's teaching.\n\nBuddhism addresses deeply philosophical questions regarding the nature of reality. One of the fundamental teachings is that all the constituent forms (\"sankharas\") that make up the universe are transient (Pali: \"anicca\"), arising and passing away, and therefore without concrete identity or ownership (\"atta\"). This lack of enduring ownership or identity (\"anatta\") of phenomena has important consequences for the possibility of liberation from the conditions which give rise to suffering. This is explained in the doctrine of interdependent origination.\n\nOne of the most discussed themes in Buddhism is that of the emptiness (\"sunyata\") of form (Pali: \"rūpa\"), an important corollary of the transient and conditioned nature of phenomena. Reality is seen, ultimately, in Buddhism as a form of 'projection', resulting from the fruition (\"vipaka\") of karmic seeds (\"sankharas\"). The precise nature of this 'illusion' that is the phenomenal universe is debated among different schools. For example;\n\n\nBuddhist sutras devote considerable space to the concept of reality, with each of two major doctrines—the Doctrine of Dependent Origination (\"pratitya-samutpada\") and the Doctrine of Cause and Effect (\"karma\" and \"vipaka\")—attempting to incorporate both the natural and the spiritual into its overall world view. Buddhist teachings continue to explore the nature of the world and our place in it.\n\nThe Buddha promoted experience over theorizing. According to Karel Werner, Experience is ... the path most elaborated in early Buddhism. The doctrine on the other hand was kept low. The Buddha avoided doctrinal formulations concerning the final reality as much as possible in order to prevent his followers from resting content with minor achievements on the path in which the absence of the final experience could be substituted by conceptual understanding of the doctrine or by religious faith, a situation which sometimes occurs, in both varieties, in the context of Hindu systems of doctrine.\n\nThe Mahayana developed those statements he did make into an extensive, diverse set of sometimes contrasting descriptions of reality \"as it really is.\" For example, in Tibetan Buddhism the Gelugpa draw a distinction between Svatantrika-Prasaṅgika in Madhyamika philosophy. This distinction was most prominently promulgated by Je Tsongkhapa (1357–1419 CE), when he argued that this distinction can be found explicitly and implicitly within in the works of Nagarjuna, Chandrakirti, and Buddhapalita.\n\nThe Theravada school teaches that there is no universal personal god. The world as we know it does not have its origin in a primordial being such as Brahman or the Abrahamic God. What we see is only a product of transitory factors of existence, which depend functionally upon each other. The Buddha is said to have said: \"The world exists because of causal actions, all things are produced by causal actions and all beings are governed and bound by causal actions. They are fixed like the rolling wheel of a cart, fixed by the pin of its axle shaft.\" (Sutta-Nipata 654)\n\nThe word 'illusion' is frequently associated with Buddhism and the nature of reality. Some interpretations of Buddhism teach that reality is a coin with two sides: the not-permanent characteristic or \"anicca\" and the \"not-self characteristic\" or \"anatta\", referred to as \"emptiness\" in some Mahayana schools. Dzogchen, as the non-dual culmination of the Ancient School (a school with a few million followers out of a few hundred million Buddhists) of Mantrayana, resolves atman and anatman into the Mindstream Doctrine of Tapihritsa. The Buddha Shakyamuni is said to have taught the variously understood and interpreted concept of \"not-self\" in the Anatta-lakkhana Sutta. In this sutta, he lists the characteristics that we often associate with who we are, and found that these characteristics, ultimately, are not who we are because they are subject to change without control. He further illustrates the changing nature of our feelings, perceptions, and consciousness.\n\nWe can look at the concepts of not-permanent and not-self in objective terms, for example by deconstructing the concept of an aggregated object such as a lotus and seeing that the flower is made up entirely of non-flower elements like soil, nutrients, photosynthetic energy, rain water and the effort of the entities that nourished and grew the flower. All of these factors, according to the Diamond Sutra, co-exist with each other to manifest what we call a 'flower'. In other words, there is no essence arisen from nothingness that is unique and personal to any being. In particular, there is neither a human soul that lives on beyond the death of the physical body nor one that is extinguished at death since, strictly speaking, there is nothing to extinguish. The relative reality (i.e., the illusory perceived reality) comes from our belief that we are separate from the rest of the things in the universe and, at times, at odds with the processes of nature and other beings. The ultimate or absolute reality, in some schools of Buddhist thought, shows that we are inter-connected with all things. The concept of non-discrimination expands on this by saying that, while a chair is different from a flower, they 'inter-are' because they are each made of non-flower and non-chair elements. Ultimately those elements are the same, so the distinction between chair and flower is one of quantity not of quality.\n\nThe Diamond Sutra, a Mahayana scripture, has many passages that use the formula: A is not A, therefore A is called A.\n\nIn Dzogchen, perceived reality is considered to be relatively unreal.\n\nAccording to contemporary teacher Chögyal Namkhai Norbu Rinpoche, all appearances perceived during the whole life of an individual, through all senses, including sounds, smells, tastes and tactile sensations in their totality, are like a big dream. It is claimed that, on careful examination, the dream of life and regular nightly dreams are not very different, and that in their essential nature there is no difference between them.\n\nThe non-essential difference between the dreaming state and ordinary waking experience is that the latter is more concrete and linked to attachment; the dreaming experience while sleeping is slightly detached.\n\nAlso according to this teaching, there is a correspondence between the states of sleep and dream and our experiences when we die. After experiencing the intermediate state of bardo, an individual comes out of it, a new karmic illusion is created and another existence begins. This is how transmigration happens.\n\nAccording to Dzogchen teachings, the energy of an individual is essentially without form and free from duality. However, karmic traces contained in the individual's mindstream give rise to two kinds of forms:\n\n\nWhat appears as a world of permanent external phenomena, is the energy of the individual him or herself. There is nothing completely external or separate from the individual. Everything that manifests in the individual's field of experience is a continuum. This is the 'Great Perfection' that is discovered in Dzogchen practice.\n\nIt is possible to do yogic practice such as Dream Yoga and Yoga Nidra whilst dreaming, sleeping and in other bardo states of trance. In this way the yogi can have a very strong experience and with this comes understanding of the dream-like nature of daily life. This is also very relevant to diminishing attachments, because they are based on strong beliefs that life's perceptions such as objects are real and as a consequence: important. If one really understands what Buddha Shakyamuni meant when he said that everything is (relatively) unreal, then one can diminish attachments and tensions.\n\nThe teacher advises that the realization that life is only a big dream can help us finally liberate ourselves from the chains of various emotions, different kinds of attachment and the chains of ego. Then we have the possibility of ultimately becoming enlightened.\n\nDifferent schools and traditions in Tibetan Buddhism give different explanations of what is called \"reality\".\n\nPrior to the period of the Tathagatagarbha Sutras, Mahayana metaphysics had been dominated by teachings on emptiness in the form of Madhyamaka philosophy. The language used by this approach is primarily negative, and the Tathagatagarbha genre of sutras can be seen as an attempt to state orthodox Buddhist teachings of dependent origination using positive language instead, to prevent people from being turned away from Buddhism by a false impression of nihilism. In these sutras the perfection of the wisdom of not-self is stated to be the true self; the ultimate goal of the path is then characterized using a range of positive language that had been used in Indian philosophy previously by essentialist philosophers, but which was now transmuted into a new Buddhist vocabulary to describe a being who has successfully completed the Buddhist path.\n\nContrasting with some forms of Buddhism, the Buddha's teaching on 'reality' in the Tathagatagarbha Mahayana scriptures - which the Buddha states constitute the ultimate manifestation of the Mahayana Dharma (other Mahayana sutras make similar claims about their own teachings) - insists that there truly \"is\" a sphere or realm of ultimate truth - not just a repetitious cycle of interconnected elements, each dependent on the others. That suffering-filled cycle of x-generating-y-and-y-generating-z-and-z-generating-a, etc., is \"Samsara\", the prison-house of the reincarnating non-self; whereas liberation from dependency, enforced rebirth and bondage is nirvana or reality / spiritual essence (\"tattva\" / \"dharmata\"). This sphere also bears the name \"Tathagatagarbha\" (Buddha matrix). It is the deathless realm where dependent origination holds no sway, where non-self is supplanted by the everlasting, sovereign (\"aishvarya\") self (atman) (as a trans-historical, unconditioned, ultimate, liberating, supra-worldly yet boundless and immanent awakened mind). Of this real truth, called nirvana - which, while salvationally infused into samsara, is not bound or imprisoned in it - the Buddha states in the Mahayana Mahaparinirvana Sutra:\n\n\"What is the Real (\"tattva\")? Knowledge of the true attributes of Nirvana; the Tathagata, the Dharma, the Sangha, and the attributes of space ... is the Real. What is knowledge of the attributes of Nirvana? The attributes of Nirvana are eightfold. What are these eight? Cessation [of ignorance and suffering]; loveliness/ wholesomeness; Truth; Reality; Eternity, Bliss, the Self [\"atman\"], and complete Purity: that is Nirvana.\"\n\nHe further comments: \" ... that which is endowed with the Eternal, Bliss, the Self, and Purity is stated to be the meaning of 'Real Truth' ... Moreover, the Real is the Tathagata [i.e., the Buddha]; the Tathagata is the Real ... The Tathagata is not conditioned and not tainted, but utterly blissful: this is the Real ...\".\n\nThus, in such doctrines, a very positive goal is envisioned, which is said to lie beyond the grasp of the five senses and the ordinary, restless mind, and only attainable through direct meditative perception and when all inner pollutants (twisted modes of view, and all moral contaminants) are purged, and the inherently deathless, spotless, radiantly shining mind of Buddha stands revealed. This is the realm of the \"Buddha-dhatu\" (popularly known as buddha nature) - inconceivable, beginning-less, endless, omniscient truth, the Dharmakaya (quintessential body-and-mind) of the Buddha. This reality is empty of all falsehood, impermanence, ignorance, afflictions, and pain, but filled with enduring happiness, purity, knowingness (\"jnana\"), and omni-radiant loving-kindness (\"maitri\").\n\nVipassanā (Pāli) or vipaśyanā (Sanskrit: विपश्यन) in the Buddhist tradition means insight into the true nature of reality. It is a practice of realizing our reality in order to see life as it is, in turn liberating ourselves like Buddha.\n\n"}
{"id": "4282953", "url": "https://en.wikipedia.org/wiki?curid=4282953", "title": "Retread", "text": "Retread\n\nRetread, also known as \"recap\", or a \"remold\" is a re-manufacturing process for tires that replace the tread on worn tires. Retreading is applied to casings of spent tires that have been inspected and repaired. It preserves about 90% of the material in spent tires and the material cost is about 20% compared to manufacturing a new one.\n\nSome applications for retreaded tires are airplanes, racing cars, buses and delivery trucks. Use of retreaded tires was common historically, but as of 2008, it was seldom used for passenger vehicles, mainly due to discomfort on the road, safety issues and cheaper tire brands surfacing on the market. About 17.6 million retreaded tires were sold in North America in 2006.\n\nThere are two main processes used for retreading tires, called Mold Cure and Pre Cure. Both processes start with the inspection of the tire, followed by non-destructive inspection method such as shearography to locate non-visible damage and embedded debris and nails. Some casings are repaired and some are discarded. Tires can be retreaded multiple times if the casing is in usable condition. Tires used for short delivery vehicles are retreaded more than long haul tires over the life of the tire body. Casings fit for retreading have the old tread buffed away to prepare for retreading.\n\nMaterial cost for a retreaded tire is about 20% that of making a new tire.\nAbout 90% of the original tires by weight is retained in retreaded tires. A 1997 study estimates that then current generation of commercial vehicles tires to last up to 600,000 miles if they're retreaded two to three times. \n\nPreviously prepared tread strip is applied to tire casing with cement. This method allows more flexibility in tire sizes and it is the most commonly used method, but results in a seam where the ends of the strip meet.\n\nRaw rubber is applied to the tire casing and it is then placed in a mold where tread is formed. A dedicated mold is required for each tire size and tread design. \n\nIn this subtype, retreading is also applied to the side walls. These tires are given entirely new branding and stamps. \n\nSome jurisdictions have regulations concerning tire retreading.\n\nIn Europe all retreads, by law, must be manufactured according to EC Regulation 108 (car tires) or 109 (commercial vehicle tires). As part of this regulation all tires must be tested according to the same load and speed criteria as those undergone by new tires.\n\nThe Land Fill Directive of 1999 banned tires in landfills in 2003, and banned shredded tires in 2006.\n\nThe Department of Transportation requires marking of a \"DOTR number\" which shows the name of the retreader and when it was retreaded. \n\nThe United States National Highway Traffic Safety Administration recognizes the public perception that retread tires frequently used by heavy vehicles are less safe than new tires as evidenced by tire debris frequently found on highways. The NHTSA is continuing research to determine the proportion of tire debris from retreads in comparison to new tires. Additionally, the NHTSA is researching the cause of tire failure and the crash safety problem posed by tire failures.\n\nFederal Executive Order 13149 supports the use of retread tires for economic and environmental efficiency by requiring federal vehicles to use retread tires after original factory equipped tires become non serviceable, but only when \"such products are reasonably available and meet applicable performance standards\".\n\nRetread tires in service lower the volume of raw materials required for the manufacturing of a new tire. This includes a pronounced reduction in the use of oil. In fact, the US EPA estimated a greater than 70% savings in oil used for a retread as compared to a new tire. This also means significant reductions in greenhouse gas emissions.\n\nIn addition to reducing the amount of raw materials extracted, retread tires also minimize the amount of waste that ends up in landfills. The latest figures by the US EPA indicate that over 11.2 M waste tires were dumped into the U.S. municipal solid waste stream. To understand this figure, it is equivalent to lining up passenger tires tread to tread from roughly Los Angeles to San Diego or Philadelphia to Washington DC. Because a retread tire prevents the need for manufacturing a new tire, significant environmental benefits are achieved. \n"}
{"id": "21811584", "url": "https://en.wikipedia.org/wiki?curid=21811584", "title": "Richard Owen", "text": "Richard Owen\n\nSir Richard Owen (20 July 1804 – 18 December 1892) was an English biologist, comparative anatomist and paleontologist. Despite being a controversial figure, Owen is generally considered to have been an outstanding naturalist with a remarkable gift for interpreting fossils.\n\nOwen produced a vast array of scientific work, but is probably best remembered today for coining the word \"Dinosauria\" (meaning \"Terrible Reptile\" or \"Fearfully Great Reptile\"). An outspoken critic of Charles Darwin's theory of evolution by natural selection, Owen agreed with Darwin that evolution occurred, but thought it was more complex than outlined in Darwin's \"On the Origin of Species\". Owen's approach to evolution can be seen as having anticipated the issues that have gained greater attention with the recent emergence of evolutionary developmental biology.\n\nOwen was the first president of the Microscopical Society of London in 1839 and edited many issues of its journal – then known as \"The Microscopic Journal\".\n\nOwen also campaigned for the natural specimens in the British Museum to be given a new home. This resulted in the establishment, in 1881, of the now world-famous Natural History Museum in South Kensington, London. Bill Bryson argues that, \"by making the Natural History Museum an institution for everyone, Owen transformed our expectations of what museums are for\".\n\nHis contributions to science and public learning notwithstanding, Owen's driving ambition, occasionally vicious temperament, and determination to succeed meant that he was not always popular with his fellow scientists. Owen was feared and even hated by some contemporaries such as Thomas Henry Huxley. His later career was tainted by controversies, many of which involved accusations that he took credit for other people's work.\n\nOwen was born in Lancaster in 1804, one of six children of a West Indian Merchant named Richard Owen (1754–1809). His mother, Catherine Longworth (nee Parrin), was descended from Huguenots and he was educated at Lancaster Royal Grammar School. In 1820, he was apprenticed to a local surgeon and apothecary and, in 1824, he proceeded as a medical student to the University of Edinburgh. He left the university in the following year and completed his medical course in St Bartholomew's Hospital, London, where he came under the influence of the eminent surgeon John Abernethy.\n\nIn July 1835 Owen married Caroline Amelia Clift in St Pancras by whom he had one son, William Owen. He outlived both wife and son. After his death, in 1892, he was survived by his three grandchildren and daughter-in-law Emily Owen, to whom he left much of his £33,000 fortune.\n\nUpon completing his education, he contemplated the usual professional career, but his bent was evidently in the direction of anatomical research. He was induced by Abernethy to accept the position of assistant to William Clift, conservator of the museum of the Royal College of Surgeons. This congenial occupation soon led him to abandon his intention of medical practice and his life thenceforth was devoted to purely scientific labours. He prepared an important series of catalogues of the Hunterian Collection, in the Royal College of Surgeons and, in the course of this work, he acquired the unrivalled knowledge of comparative anatomy that enabled him to enrich all departments of the science and especially facilitated his researches on the remains of extinct animals.\n\nIn 1836, Owen was appointed Hunterian professor, in the Royal College of Surgeons and, in 1849, he succeeded Clift as conservator. He held the latter office until 1856, when he became superintendent of the natural history department of the British Museum. He then devoted much of his energies to a great scheme for a National Museum of Natural History, which eventually resulted in the removal of the natural history collections of the British Museum to a new building at South Kensington: the British Museum (Natural History) (now the Natural History Museum). He retained office until the completion of this work, in December, 1883, when he was made a knight of the Order of the Bath. He lived quietly in retirement at Sheen Lodge, Richmond Park, until his death in 1892.\n\nHis career was tainted by accusations that he failed to give credit to the work of others and even tried to appropriate it in his own name. This came to a head in 1846, when he was awarded the Royal Medal for a paper he had written on belemnites. Owen had failed to acknowledge that the belemnite had been discovered by Chaning Pearce, an amateur biologist, four years earlier. As a result of the ensuing scandal, he was voted off the councils of the Zoological Society and the Royal Society.\n\nOwen always tended to support orthodox men of science and the status quo. The royal family presented him with the cottage in Richmond Park and Robert Peel put him on the Civil List. In 1843, he was elected a foreign member of the Royal Swedish Academy of Sciences.\n\nHe died at home on 15 December 1892 and is buried in the churchyard at Ham near Richmond, Surrey.\n\nWhile occupied with the cataloguing of the Hunterian collection, Owen did not confine his attention to the preparations before him but also seized every opportunity to dissect fresh subjects. He was allowed to examine all animals that died in London Zoo's gardens and, when the Zoo began to publish scientific proceedings, in 1831, he was the most prolific contributor of anatomical papers. His first notable publication, however, was his \"Memoir on the Pearly Nautilus\" (London, 1832), which was soon recognized as a classic. Henceforth, he continued to make important contributions to every department of comparative anatomy and zoology for a period of over fifty years. In the sponges, Owen was the first to describe the now well-known Venus' Flower Basket or \"Euplectella\" (1841, 1857). Among Entozoa, his most noteworthy discovery was that of \"Trichina spiralis\" (1835), the parasite infesting the muscles of man in the disease now termed trichinosis (see also, however, Sir James Paget). Of Brachiopoda he made very special studies, which much advanced knowledge and settled the classification that has long been accepted. Among Mollusca, he described not only the pearly nautilus but also \"Spirula\" (1850) and other Cephalopoda, both living and extinct, and it was he who proposed the universally-accepted subdivision of this class into the two orders of Dibranchiata and Tetrabranchiata (1832). In 1852 Owen named \"Protichnites\" – the oldest footprints found on land. Applying his knowledge of anatomy, he correctly postulated that these Cambrian trackways were made by an extinct type of arthropod, and he did this more than 150 years before any fossils of the animal were found. Owen envisioned a resemblance of the animal to the living arthropod \"Limulus\", which was the subject of a special memoir he wrote in 1873.\n\nOwen's technical descriptions of the Vertebrata were still more numerous and extensive than those of the invertebrate animals. His \"Comparative Anatomy and Physiology of Vertebrates\" (3 vols. London 1866–1868) was indeed the result of more personal research than any similar work since Georges Cuvier's \"Leçons d'anatomie comparée\". He not only studied existing forms but also devoted great attention to the remains of extinct groups, and followed Cuvier, the pioneer of vertebrate paleontology. Early in his career, he made exhaustive studies of teeth of existing and extinct animals and published his profusely illustrated work on \"Odontography\" (1840–1845). He discovered and described the remarkably complex structure of the teeth of the extinct animals which he named Labyrinthodontia. Among his writings on fish, his memoir on the African lungfish, which he named \"Protopterus\", laid the foundations for the recognition of the Dipnoi by Johannes Müller. He also later pointed out the serial connection between the teleostean and ganoid fishes, grouping them in one sub-class, the Teleostomi.\n\nMost of his work on reptiles related to the skeletons of extinct forms and his chief memoirs, on British specimens, were reprinted in a connected series in his \"History of British Fossil Reptiles\" (4 vols. London 1849–1884). He published the first important general account of the great group of Mesozoic land-reptiles, and he coined the name Dinosauria from Greek \"δεινός\" (\"deinos\") \"terrible, powerful, wondrous\" + \"σαύρος\" (\"sauros\") \"lizard\". Owen used 3 genera to define the dinosaurs: the carnivorous \"Megalosaurus\", the herbivorous \"Iguanodon\" and armoured \"Hylaeosaurus\"', specimens uncovered in southern England. He also first recognized the curious early Mesozoic synapsids, with affinities both to amphibians and mammals, which he termed Anomodontia (the mammal-like synapsids, Therapsida). Most of these were obtained from South Africa, beginning in 1845 (\"Dicynodon\") and eventually furnished materials for his \"Catalogue of the Fossil Reptilia of South Africa\", issued by the British Museum, in 1876. Among his writings on birds, his classical memoir on the kiwi (1840–1846), a long series of papers on the extinct Dinornithidae of New Zealand, other memoirs on \"Aptornis\", the takahe, the dodo and the great auk, may be especially mentioned. His monograph on \"Archaeopteryx\" (1863), the long-tailed, toothed bird from the Bavarian lithographic stone, is also an epoch-making work.\n\nWith Benjamin Waterhouse Hawkins, Owen helped create the first life-size sculptures depicting dinosaurs as he thought they might have appeared. Some models were initially created for the Great Exhibition of 1851, but 33 were eventually produced when the Crystal Palace was relocated to Sydenham, in South London. Owen famously hosted a dinner for 21 prominent men of science inside the hollow concrete \"Iguanodon\" on New Year's Eve 1853. However, in 1849, a few years before his death in 1852, Gideon Mantell had realised that \"Iguanodon\", of which he was the discoverer, was not a heavy, pachyderm-like animal, as Owen was proposing, but had slender forelimbs; his death left him unable to participate in the creation of the Crystal Palace dinosaur sculptures, and so Owen's vision of dinosaurs became that seen by the public. He had nearly two dozen lifesize sculptures of various prehistoric animals built out of concrete sculpted over a steel and brick framework; two \"Iguanodon\", one standing and one resting on its belly, were included.\n\nOwen was granted right of first refusal on any freshly dead animal at the London Zoo. His wife once arrived home to find the carcass of a newly deceased rhinoceros in her front hallway.\n\nWith regard to living mammals, the more striking of Owen's contributions relate to the monotremes, marsupials and the anthropoid apes. He was also the first to recognize and name the two natural groups of typical Ungulate, the odd-toed (Perissodactyla) and the even-toed (Artiodactyla), while describing some fossil remains, in 1848. Most of his writings on mammals, however, deal with extinct forms, to which his attention seems to have been first directed by the remarkable fossils collected by Charles Darwin, in South America. \"Toxodon\", from the pampas, was then described and gave the earliest clear evidence of an extinct generalized hoof animal, a pachyderm with affinities to the Rodentia, Edentata and herbivorous Cetacea. Owen's interest in South American extinct mammals then led to the recognition of the giant armadillo, which he named \"Glyptodon\" (1839) and to classic memoirs on the giant ground-sloths, \"Mylodon\" (1842) and \"Megatherium\" (1860), besides other important contributions. Owen also first described the false killer whale in 1863.\n\nAt the same time, Sir Thomas Mitchell's discovery of fossil bones, in New South Wales, provided material for the first of Owen's long series of papers on the extinct mammals of Australia, which were eventually reprinted in book-form in 1877. He discovered \"Diprotodon\" (1838) and \"Thylacoleo\" (1859), besides extinct kangaroos and wombats, of gigantic size. While occupied with so much material from abroad, Owen was also busily collecting facts for an exhaustive work on similar fossils from the British Isles and, in 1844–1846, he published his \"History of British Fossil Mammals and Birds\", which was followed by many later memoirs, notably his \"Monograph of the Fossil Mammalia of the Mesozoic Formations\" (Palaeont. Soc., 1871). One of his latest publications was a little work entitled \"Antiquity of Man as deduced from the Discovery of a Human Skeleton during Excavations of the Docks at Tilbury\" (London, 1884).\n\nFollowing the voyage of the \"Beagle\", Darwin had at his disposal a considerable collection of specimens and, on 29 October 1836, he was introduced by Charles Lyell to Owen, who agreed to work on fossil bones collected in South America. Owen's subsequent revelations, that the extinct giant creatures were rodents and sloths, showed that they were related to current species in the same locality, rather than being relatives of similarly sized creatures in Africa, as Darwin had originally thought. This was one of the many influences that led Darwin later to formulate his own ideas on the concept of natural selection.\n\nAt this time, Owen talked of his theories, influenced by Johannes Peter Müller, that living matter had an \"organising energy\", a life-force that directed the growth of tissues and also determined the lifespan of the individual and of the species. Darwin was reticent about his own thoughts, understandably, when, on 19 December 1838, as secretary of the Geological Society of London, he saw Owen and his allies ridicule the Lamarckian 'heresy' of Darwin's old tutor, Robert Edmund Grant. In 1841, when the recently married Darwin was ill, Owen was one of the few scientific friends to visit; however, Owen's opposition to any hint of transmutation made Darwin keep quiet about his hypothesis.\n\nSometime during the 1840s Owen came to the conclusion that species arise as the result of some sort of evolutionary process. He believed that there was a total of six possible mechanisms: parthenogenesis, prolonged development, premature birth, congenital malformations, Lamarckian atrophy, Lamarckian hypertrophy and transmutation, of which he thought transmutation was the least likely. The historian of science Evelleen Richards has argued that Owen was likely sympathetic to developmental theories of evolution, but backed away from publicly proclaiming them after the critical reaction that had greeted the anonymously published evolutionary book \"Vestiges of the Natural History of Creation\" in 1844 (it was revealed only decades later that the book had been authored by publisher Robert Chambers). Owen had been criticized for his own evolutionary remarks in his \"Nature of the Limbs\" in 1849. At the end of \"On the Nature of Limbs\" Owen had suggested that humans ultimately evolved from fish as the result of natural laws, which resulted in his being criticized in the \"Manchester Spectator\" for denying that species such as humans were created by God.\n\nDuring the development of Darwin's theory, his investigation of barnacles showed, in 1849, how their segmentation related to other crustaceans, showing how they had diverged from their relatives. To both Darwin and Owen such \"homologies\" in comparative anatomy were evidence of descent. Owen demonstrated fossil evidence of an evolutionary sequence of horses, as supporting his idea of development from archetypes in \"ordained continuous becoming\" and, in 1854, gave a British Association talk on the impossibility of bestial apes, such as the recently discovered gorilla, standing erect and being transmuted into men, but Owen did not rule out the possibility that humans had evolved from other extinct animals by evolutionary mechanisms other than transmutation. Working-class militants were trumpeting man's monkey origins. To crush these ideas, Owen, as President-elect of the Royal Association, announced his authoritative anatomical studies of primate brains, claiming that the human brain had structures that apes brains did not, and that therefore humans were a separate sub-class, starting a dispute which was subsequently satirised as the Great Hippocampus Question. Owen's main argument was that humans have much larger brains for their body size than other mammals including the great apes. Darwin wrote that \"I cannot swallow Man [being that] distinct from a Chimpanzee\". The combative Thomas Henry Huxley used his March 1858 Royal Institution lecture to deny Owen's claim and affirmed that structurally, gorillas are as close to humans as they are to baboons. He believed that the \"mental & moral faculties are essentially... the same kind in animals & ourselves\". This was a clear denial of Owen's claim for human uniqueness, given at the same venue.\n\nOn the publication of Darwin's theory, in \"On The Origin of Species\", he sent a complimentary copy to Owen, saying \"it will seem 'an abomination. Owen was the first to respond, courteously claiming that he had long believed that \"existing influences\" were responsible for the \"ordained\" birth of species. Darwin now had long talks with him and Owen said that the book offered the best explanation \"ever published of the manner of formation of species\", although he still had the gravest doubts that transmutation would bestialize man. It appears that Darwin had assured Owen that he was looking at everything as resulting from designed laws, which Owen interpreted as showing a shared belief in \"Creative Power\".\n\nAs head of the Natural History Collections at the British Museum, Owen received numerous inquiries and complaints about the \"Origin\". His own views remained unknown: when emphasising to a Parliamentary committee the need for a new Natural History museum, he pointed out that \"The whole intellectual world this year has been excited by a book on the origin of species; and what is the consequence? Visitors come to the British Museum, and they say, 'Let us see all these varieties of pigeons: where is the tumbler, where is the pouter?' and I am obliged with shame to say, I can show you none of them\" ... \"As to showing you the varieties of those species, or of any of those phenomena that would aid one in getting at that mystery of mysteries, the origin of species, our space does not permit; but surely there ought to be a space somewhere, and, if not in the British Museum, where is it to be obtained?\"\n\nHowever, Huxley's attacks were making their mark. In April 1860 the \"Edinburgh Review\" included Owen's anonymous review of the \"Origin\". In it Owen showed his anger at what he saw as Darwin's caricature of the creationist position, and his ignoring Owen's \"axiom of the continuous operation of the ordained becoming of living things\". As well as attacking Darwin's \"disciples\", Hooker and Huxley, for their \"short-sighted adherence\", he thought that the book symbolised the sort of \"abuse of science... to which a neighbouring nation, some seventy years since, owed its temporary degradation\" in a reference to the French Revolution. Darwin thought it \"Spiteful, extremely malignant, clever, and... damaging\" and later commented that \"The Londoners say he is mad with envy because my book is so talked about. It is painful to be hated in the intense degree with which Owen hates me.\"\n\nDuring the reaction to Darwin's theory, Huxley's arguments with Owen continued. Owen tried to smear Huxley, by portraying him as an \"advocate of man's origins from a transmuted ape\" and one of his contributions to the \"Athenaeum\" was titled \"Ape-Origin of Man as Tested by the Brain\". In 1862 (and on other occasions) Huxley took the opportunity to arrange demonstrations of ape brain anatomy (e.g. at the BA meeting, where William Flower performed the dissection). Visual evidence of the supposedly missing structures (posterior cornu and hippocampus minor) was used, in effect, to indict Owen for perjury. Owen had argued that the absence of those structures in apes were connected with the lesser size to which the ape brains grew, but he then conceded that a poorly developed version might be construed as present without preventing him from arguing that brain size was still the major way of distinguishing apes and humans. Huxley's campaign ran over two years and was devastatingly successful at persuading the overall scientific community, with each \"slaying\" being followed by a recruiting drive for the Darwinian cause. The spite lingered. While Owen had argued that humans were distinct from apes by virtue of having large brains, Huxley claimed that racial diversity blurred any such distinction. In his paper criticizing Owen, Huxley directly states: \"if we place A, the European brain, B, the Bosjesman brain, and C, the orang brain, in a series, the differences between A and B, so far as they have been ascertained, are of the same nature as the chief of those between B and C\". Owen countered Huxley by saying the brains of all human races were really of similar size and intellectual ability, and that the fact that humans had brains that were twice the size of large apes like male gorillas, even though humans had much smaller bodies, made humans distinguishable. When Huxley joined the Zoological Society Council, in 1861, Owen left and, in the following year, Huxley moved to stop Owen from being elected to the Royal Society Council, accusing him \"of wilful & deliberate falsehood\". (See also Thomas Henry Huxley.)\n\nIn January 1863, Owen bought the \"Archaeopteryx\" fossil for the British Museum. It fulfilled Darwin's prediction that a proto-bird with unfused wing fingers would be found, although Owen described it unequivocally as a bird.\n\nThe feuding between Owen and Darwin's supporters continued. In 1871, Owen was found to be involved in a threat to end government funding of Joseph Dalton Hooker's botanical collection, at Kew, possibly trying to bring it under his British Museum. Darwin commented that \"I used to be ashamed of hating him so much, but now I will carefully cherish my hatred & contempt to the last days of my life\".\n\nOwen's detailed memoirs and descriptions require laborious attention in reading, on account of their complex terminology and ambiguous modes of expression. The fact that very little of his terminology has found universal favour causes them to be more generally neglected than they otherwise would be. At the same time, it must be remembered that he was a pioneer in concise anatomical nomenclature and, so far at least as the vertebrate skeleton is concerned, his terms were based on a carefully reasoned philosophical scheme, which first clearly distinguished between the now-familiar phenomena of analogy and homology. Owen's theory of the Archetype and Homologies of the Vertebrate Skeleton (1848), subsequently illustrated also by his little work \"On the Nature of Limbs\" (1849), regarded the vertebrate frame as consisting of a series of fundamentally identical segments, each modified according to its position and functions. Much of it was fanciful and failed when tested by the facts of embryology, which Owen systematically ignored, throughout his work. However, though an imperfect and distorted view of certain great truths, it possessed a distinct value at the time of its conception.\n\nTo the discussion of the deeper problems of biological philosophy, he made scarcely any direct and definite contributions. His generalities rarely extended beyond strict comparative anatomy, the phenomena of adaptation to function and the facts of geographical or geological distribution. His lecture on virgin reproduction or parthenogenesis, however, published in 1849, contained the essence of the germ plasm theory, elaborated later by August Weismann and he made several vague statements concerning the geological succession of genera and species of animals and their possible derivation one from another. He referred, especially, to the changes exhibited by the successive forerunners of the crocodiles (1884) and horses (1868) but it has never become clear how much of the modern doctrines of organic evolution he admitted. He contented himself with the bare remark that \"the inductive demonstration of the nature and mode of operation of the laws governing life would henceforth be the great aim of the philosophical naturalist.\"\n\nHe was the first director in Natural History Museum in London and his statue was in the main hall there until 2009, when it was replaced with a statue of Darwin.\n\nA bust of Owen by Alfred Gilbert (1896) is held in the Hunterian Museum, London. There is a blue plaque in his honour at Lancaster Royal Grammar School.\n\nA species of Central American lizard, \"Diploglossus owenii\", was named in his honor by French herpetologists André Marie Constant Duméril and Gabriel Bibron in 1839.\n\nOwen has been described by some as a malicious, dishonest and hateful individual. He has been described in one biography as being a \"social experimenter with a penchant for sadism. Addicted to controversy and driven by arrogance and jealousy\". Deborah Cadbury stated that Owen possessed an \"almost fanatical egoism with a callous delight in savaging his critics.\" Indeed, an Oxford University professor once described Owen as \"a damned liar. He lied for God and for malice\". Gideon Mantell claimed it was \"a pity a man so talented should be so dastardly and envious\".\n\nOwen famously credited himself and Georges Cuvier with the discovery of the \"Iguanodon\", completely excluding any credit for the original discoverer of the dinosaur, Gideon Mantell. This was not the first or last time Owen would falsely claim a discovery as his own. It has also been suggested by some authors, including Bill Bryson in \"A Short History of Nearly Everything\", that Owen even used his influence in the Royal Society to ensure that many of Mantell’s research papers were never published. Owen was finally dismissed from the Royal Society's Zoological Council for plagiarism.\n\nWhen Mantell suffered an accident that left him permanently crippled, Owen exploited the opportunity by renaming several dinosaurs which had already been named by Mantell, even having the audacity to claim credit for their discovery himself. When Mantell finally died in 1852, an obituary carrying no byline derided Mantell as little more than a mediocre scientist, who brought forth few notable contributions. The obituary’s authorship was universally attributed to Owen by every geologist. The president of the Geological Society claimed that it \"bespeaks of the lamentable coldness of the heart of the writer\". Owen was subsequently denied the presidency of the society for his repeated and pointed antagonism towards Gideon Mantell.\n\nEven more extraordinary was the way Owen ignored the genuine scientific content of Mantell's work. For example, despite the paucity of finds Mantell had worked out that some dinosaurs were bipedal, including \"Iguanodon\". This remarkable insight was totally ignored by Owen, whose instructions for the Crystal Palace models by Waterhouse Hawkins portrayed \"Iguanodon\" as grossly overweight and quadrupedal, with its misidentified thumb on its nose. Mantell did not live to witness the discovery in 1878 of articulated skeletons in a Belgium coal-mine that showed \"Iguanodon\" was mostly bipedal (and in that stance could use its thumb for defence). Owen made no comment or retraction; he never did on any errors he made. Moreover, since the earliest known dinosaurs were bipedal, Mantell's idea was indeed insightful.\n\nDespite originally starting out on good terms with Darwin, Owen was highly critical of the \"Origin\" in large part because Darwin did not refer much to the previous scientific theories of evolution that had been proposed by people like Chambers and himself, and instead compared the theory of evolution by natural selection with the unscientific theory in the Bible.\n\nAnother reason for his criticism of the \"Origin\", some historians claim, was that Owen felt upstaged by Darwin and supporters such as Huxley, and his judgment was clouded by jealousy. Owen in Darwin's opinion was \"Spiteful, extremely malignant, clever; the Londoners say he is mad with envy because my book is so talked about\". \"It is painful to be hated in the intense degree with which Owen hates me\". Owen also resorted to the same subterfuge he used against Mantell, writing another anonymous article in the \"Edinburgh Review\" in April 1860. In the article, Owen was critical of Darwin for not offering many new observations, and heaped praise (in the third person) upon himself, while being careful not to associate any particular comment with his own name. Owen did praise, however, the \"Origin\"'s description of Darwin's work on insect behavior and pigeon breeding as Huxley, Thomas H., (1861), \"On the Zoological Relations of Man with the Lower Animals\", Natural History Review 1: 67–84.\"real gems\".\n\nOwen was also a party to the threat to end government funding of the Royal Botanic Gardens, Kew botanical collection (see Attacks on Hooker and Kew), orchestrated by Acton Smee Ayrton:\n\nIt has been suggested by some authors that the portrayal of Owen as a vindictive and treacherous man was fostered and encouraged by his rivals (particularly Darwin, Hooker and Huxley) and may be somewhat undeserved. In the first part of his career he was regarded rightly as one of the great scientific figures of the age. In the second part of his career his reputation slipped. This was not due solely to his underhanded dealings with colleagues; it was also due to serious errors of scientific judgement that were discovered and publicized. A fine example was his decision to classify man in a separate subclass of the Mammalia (see \"Man's place in nature\"). In this Owen had no supporters at all. Also, his unwillingness to come off the fence concerning evolution became increasingly damaging to his reputation as time went on. Owen continued working after his official retirement at the age of 79, but he never recovered the good opinions he had garnered in his younger days.\n\n\n"}
{"id": "29190513", "url": "https://en.wikipedia.org/wiki?curid=29190513", "title": "Segal category", "text": "Segal category\n\nIn mathematics, a Segal category is a model of an infinity category introduced by , based on work of Graeme Segal in 1974.\n\n"}
{"id": "14504931", "url": "https://en.wikipedia.org/wiki?curid=14504931", "title": "Self-evaluation maintenance theory", "text": "Self-evaluation maintenance theory\n\nSelf-evaluation maintenance (SEM) theory refers to discrepancies between two people in a relationship. Two people in a relationship each aim to keep themselves feeling good psychologically throughout a comparison process to the other person. Self-evaluation is defined as the way a person views him/herself. It is the continuous process of determining personal growth and progress, which can be raised or lowered by the behavior of a close other (a person that is psychologically close). People are more threatened by friends than strangers. Abraham Tesser created the self-evaluation maintenance theory in 1988. The self-evaluation maintenance model assumes two things: that a person will try to maintain or increase their own self-evaluation, and self-evaluation is influenced by relationships with others.\n\nA person's self-evaluation (which is similar to self-esteem) may be raised when a close other performs well. For example, a sibling scores the winning goal in an important game. Self-evaluation will increase because that person is sharing his/her success. The closer the psychological relationship and the greater the success, the more a person will share in the success. This is considered the \"reflection\" process. When closeness and performance are high, self-evaluation is raised in the reflection process. If someone who is psychologically close performs well on a task that is irrelevant to a person's self-definition, that person is able to benefit by sharing in the success of the achievement.\n\nAt the same time, the success of a close other can decrease someone's self-evaluation in the comparison process. This is because the success of a close other invites \"comparison\" on one's own capabilities, thereby directly affecting one's own self-evaluation. This is also strengthened with the closeness of the psychological relationship with the successful other. Using the same example: a sibling scores the winning goal in an important game; the person is now comparing him/herself to the sibling's success and through comparison, his/her self-evaluation is lowered. When closeness (sibling) and performance (scored the winning goal) are high, self-evaluation is decreased in the comparison process.\n\nIn both the reflection and comparison processes, closeness and performance level are significant. If the closeness of another decreases, then a person is less likely to share the success and/or compare him/herself, which lessens the likelihood of decreasing self-evaluation. A person is more likely to compare him/herself to someone close to him/her, like a sibling or a best friend, than a stranger. There are different factors in which a person can assume closeness: family, friends, people with similar characteristics, etc. If an individual is not close to a particular person, then it makes sense that he/she will not share in their success or be threatened by their success. At the same time, if the person's performance is low, there is no reason to share the success and increase self-evaluation; there is also no reason to compare him/herself to the other person, decreasing self-evaluation. Because their performance is low, there is no reason it should raise or lower his/her self-evaluation. According to Tesser's (1988) theory, if a sibling did not do well in his/her game, then there is no reason the individual's self-evaluation will be affected.\n\nCloseness and performance can either raise self-evaluation through reflection or lower self-evaluation through comparison. Relevance determines whether reflection or comparison will occur. There are many different dimensions that can be important to an individual's self-definition. A self-defining factor is any factor that is important to who a person is. For example, an ability or success in music may be important to one's self-definition, but at the same time, being good in math may not be as important. Relevance assumes that a particular factor that is important to an individual is also important to another person. Relevance can be as simple as a shared dimension which he/she considers important to who he/she is. If relevance is high, then one will engage in comparison, but if relevance is low, one will engage in reflection. For example, if athletics is important to a person and that person considers athletics to be an important dimension of his/her self-definition, then when a sibling does well in athletics, the comparison process will take place and his/her self-evaluation will decrease. On the other hand, if athletics is not a dimension he/she uses for self-definition, the reflection process will take place and he/she will celebrate the sibling's success with the sibling; his/her self-evaluation will increase along with the sibling's because he/she is not threatened or challenged by the sibling's athletic capability.\n\nTesser (1988) suggests that people may do things to reduce the decrease in self-evaluation from comparison. One can spend less time with that particular individual, thereby reducing closeness or one can change their important self-definition and take up a new hobby or focus on a different self-defining activity, which reduces relevance. The third way of avoiding a decrease in self-evaluation through the comparison process is to affect another's performance (e.g. by hiding a sibling's favorite shoes, or believe that his/her performance was based on luck) or one can improve their own skills by practicing more. This theory poses the question: under what conditions will someone get in the way of another's performance? The answer is that it depends on closeness of the individuals and the relevance of the activity. When the relevance is high, the comparison process is more important than the reflection process. When the relevance is high and the activity is high in self-defining importance, the other person poses a larger threat than when the relevance is low.\n\nTesser & Smith (1980) experimented with this theory. Men were recruited and asked to bring a friend with them. They were then put into groups of four, Man A and Man A's friend along with Man B and Man B's friend. Half the subjects were told that this activity was measuring important verbal skills and leadership. This was the high relevance group. The other two subjects were told that the task had nothing to do with verbal skills, leadership or anything important. This was considered the low relevance group. The activity was based on the game Password, where persons have to guess a word based on clues. Each man was given an opportunity to guess the word while the other three gave clues from a list. The other three can give clues that are easy or difficult based on their own judgment and basically whether or not they would like to help the other person guess the word. The clues given to the person were necessary to guess the word. The first pair of partners performed poorly (as instructed in the experimental design). The experiment was looking at the behavior of the second group of men. The next pairing was designed to partner a stranger with a friend. Researchers were trying to see when a friend was helped more than a stranger and when a stranger was helped more than a friend. The research was supported. In 10 out of 13 sessions, when relevance was high (told that this activity measures important verbal and leadership skills) the stranger was helped more than a friend. Also, in 10 out of 13 sessions, when relevance was low (subjects were told that this activity determined nothing of importance) the friend was helped more than the stranger. The prediction of the self-evaluation maintenance theory was strongly supported.\n\nZuckerman & Jost (2001) compares the self-evaluation maintenance theory to the work of Feld (1991). As the self-evaluatory maintenance theory would lead one to judge a stranger higher than their friends (based on popularity) in order to prevent a drop in self-evaluation, Feld's (1991) research demonstrated that people must have fewer friends than their friends do in order to remain popular. This is based on a mathematical equation that explains why popular people are involved in more social circles than unpopular people. These are not the only two research examples. For more examples see the references.\n\nThis graph illustrates the basic principles of Tesser's (1988) self-evaluatory maintenance model of behavior. Relevance determines whether reflection or comparison will occur. When relevance is low (the factor does not affect self-definition) as the other's performance increases, so does self-evaluation, allowing that person to share in the celebration of the other person (reflection). When relevance is high (the factor is important to self-definition also) as the other's performance increases, self-evaluation decreases because that person is being compared to the other person (comparison). If relevance is high, then one will engage in comparison, but if relevance is low, one will engage in reflection.\n\n\n"}
{"id": "23398283", "url": "https://en.wikipedia.org/wiki?curid=23398283", "title": "Seny", "text": "Seny\n\nSeny (; from Proto-Germanic *sinnaz) is a form of ancestral Catalan wisdom or sensibleness. It involves well-pondered perception of situations, level-headedness, awareness, integrity, and right action. More specifically, a \"National Geographic\" anthropologist defined \"seny\" as \"a kind of refined good sense and self-realization.\"\n\nThe opposite of \"seny\" is known as rauxa () \"sudden determination or action\".\n\nMany Catalans consider \"seny\" something unique to their culture, a true Catalan symbol. \"Seny\" as a particular characteristic of Catalan society is based on a set of ancestral local customs stemming from the scale of values and social norms of traditional Catalan rural society. The values of \"seny\" were transmitted from generation to generation without much change by the exemplary behaviour of the elder members of the family, as well as in the shape of aphorisms and moral stories. The latter were largely based on Christian values and their examples and illustrations often included animals and plants that were common in rural Catalonia.\n\nThis oral lore caught the attention of Josep Torras i Bages, bishop of Vic at the beginning of the 20th century.\nHe became very interested in the pattern in which the \"seny\" was transmitted from one generation to the other as an oral tradition. Thus he encouraged Josep Abril i Virgili (1869–1918), a writer, to gather the moral stories and illustrate them in a book that was published as \"Bon seny\" (\"Good sense\"). This more or less representative compilation of moral lessons regarding \"seny\" was illustrated by artist Joan Junceda (1881–1948). Published in the Catalan language before the Spanish Civil War \"Bon seny\" became rare during General Franco's era, when so much Catalan printed material had been burned and printing in Catalan was severely restricted.\n\nMany of the \"seny\" proverbs that defined traditional Catalan values have lost most of their sense today. The reason is the erosion of Christian values as fundamental in present-day postchristian Catalan society, which sees itself today as a society based largely on secular principles.\n\n\"Seny\" is mentioned in the motto of castells, the Catalan tradition of building human towers, as one of the values of that endeavour: \"Força, equilibri, valor i seny\" (strength, balance, courage, and \"seny\").\n\n\n\n\n\n"}
{"id": "25718122", "url": "https://en.wikipedia.org/wiki?curid=25718122", "title": "State of affairs (philosophy)", "text": "State of affairs (philosophy)\n\nIn philosophy, a state of affairs (), also known as a situation, is a way the actual world must be in order to make some given \"proposition\" about the actual world true; in other words, a state of affairs (situation) is a \"truth-maker\", whereas a proposition is a \"truth-bearer\". Whereas states of affairs (situations) either \"obtain\" or \"fail-to-obtain\", propositions are either \"true\" or \"false\". \n\nDavid Malet Armstrong is well known for his defence of a factualism, a position according to which the world is a world of facts and not a world of things.\n\nIn a sense of \"state of affairs\" favored by Ernest Sosa, states of affairs are situational conditions. In fact, in the \"Cambridge Dictionary of Philosophy\", Sosa defines a condition to be a state of affairs, \"way things are\" or situation—most commonly referred to by a nominalization of a sentence. The expression \"Snow's being white\", which refers to the condition snow's being white, is a nominalization of the sentence \"Snow is white\". \"The truth of the proposition that \"snow is white\" is a nominalization of the sentence \"the proposition that snow is white is true\". Snow's being white is a necessary and sufficient condition for the truth of the proposition that snow is white. Conditions in this sense may be called situational.\n\nUsually, necessity and sufficiency relate conditions of the same kind. Being an animal is a necessary attributive condition for being a dog. Fido's being an animal is a necessary situational condition for Fido's being a dog.\n\n\n"}
{"id": "23006808", "url": "https://en.wikipedia.org/wiki?curid=23006808", "title": "System archetype", "text": "System archetype\n\nSystem archetypes are patterns of behavior of a system. Systems expressed by circles of causality have therefore similar structure. Identifying a system archetype and finding the leverage enables efficient changes in a system. The basic system archetypes and possible solutions of the problems are mentioned in the section \"Examples of system archetypes\". A fundamental property of nature is that no cause can affect the past. System archetypes do not imply that current causes affect past effects.\n\nThe basic idea of system thinking is that every action triggers a reaction. In system dynamics this reaction is called feedback. There are two types of feedback – reinforcing feedback and balancing feedback. Sometimes a feedback (or a reaction) does not occur immediately – the process contains delays. Any system can be drawn as a diagram set up with circles of causality – including actions, feedbacks and delays.\n\nReinforcing feedback (or amplifying feedback) accelerates the given trend of a process. If the trend is ascending, the reinforcing (positive) feedback will accelerate the growth. If the trend is descending, it will accelerate the decline. Falling of an avalanche is an example of the reinforcing feedback process.\n\nBalancing feedback (or stabilizing feedback) will work if any goal-state exists. Balancing process intends to reduce a gap between a current state and a desired state. The balancing (negative) feedback adjusts a present state to a desirable target regardless whether the trend is descending or ascending. An example of the balancing feedback process is staying upright on bicycle (when riding).\n\nDelays in systems cause people to perceive a response to an action incorrectly. This causes an under- or overestimation of the needed action and results in oscillation, instability or even breakdown.\n\nThe following System Archetyes describe the most common generic structures. Before effectively addressing a specific situation, the underlying pattern must be identified. The following Flow Diagram should help identifying these archetypes. The links between the different archetypes are an indicator of most common connections. Keep in mind that in every situation, there may be more possible ways to follow, though. Consider that everyone is located somewhere in the flow, and that every possible situation has its own advantages, down-sides, cave-ats, and options. Nevertheless, correctly identifying and understanding your situation is always the first step of solving your problem in a sustainable way.\n\nThis archetype explains the system in which the response to action is delayed. If the agents do not perceive the delayed feedback, they might overshoot or underestimate the requisite action in order to reach their goals. This could be avoided by being patient or by accelerating reactions of the system to realized measures.\nExample: supply chain (The Beer Game)\n\nThe unprecedented growth is produced by a reinforcing feedback process until the system reaches its peak. The halt of this growth is caused by limits inside or outside of the system. However, if the limits are not properly recognized; the former methods are continuously applied, but more and more aggressively. This results in the contrary of the desired state – a decrease of the system. The solution lies in the weakening or elimination of the cause of limitation. \nExample: dieting, learning foreign languages \n\nAttractiveness Principle is an archetype derived from Limits to Growth. The main difference is that Attractiveness Principle assumes growth is limited with two or more factors.\n\nThe problem is handled by a simple solution with immediate effect, thereby \"healing the symptoms\". The primary source of the problem is overlooked, because its remedy is demanding and has no immediate outcome. The origin of the problem should be identified and solved in the long-term run during which the addiction to the symptomatic remedy decreases. \nExample: drug addiction, paying debts by borrowing\n\nA special case of the “Shifting the Burden” systems archetype that occurs when an intervenor is brought in to help solve an ongoing problem.  Over time, as the intervenor successfully handles the problem, the people within the system become less capable of solving the problem themselves.  They become even more dependent on the intervenor. Examples: ongoing use of outside consultants.\n\nIn simple terms, this is an archetype whereby a system grows increasingly dependent on an outside intervenor to help it function. In the short-term this works, but in the long term the system is unable to function on its  own due to the dependence on the intervention and eventually fails to perform.\n\nA kind of shifting the burden archetype. As current problems need to be handled immediately, the long-term goals continuously decline. It can be avoided by sticking to the vision. \nExample: balancing the public debt, sliding limits of environmental pollution\n\nThis archetype could be seen as a non-cooperative game where both players suppose that just one of them can win. They are responding to actions of the other player in order to “defend themselves”. The aggression grows and can result in self-destructive behavior. The vicious circle can be broken by one agent stopping to react defensively and turn the game into cooperative one. \nExample: arms race\n\nTwo people or activities need the same limited resources. As one of them becomes more successful, more resources are assigned to him/it. The second one becomes less and less successful due to lacking resources, and “prove the right decision” to support the first one. Problems occur if the competition is unhealthy and interferes with the goals of the whole system. The two activities or agents might be decoupled or they should receive balanced amount of resources.\nExamples: two products of one company, work vs. family\n\nAgents use common limited resource to profit individually. As the use of the resource is not controlled, the agents would like to continuously raise their benefits. The resource is therefore used more and more and the revenues of the agents are decreasing. The agents are intensifying their exploitation until the resource is completely used up or seriously damaged. To protect common resources some form of regulation should be introduced.\nExample: fish stocks (The Fishing Game)\n\nIn the fixes that fail archetype, the problem is solved by some fix (a specific solution) with immediate positive effect. Nonetheless, the “side effects” of this solution turn out in the future. The best remedy seems to apply the same solution. \nExample: saving costs on maintenance, paying interest by other loans (with other interests)\n\nThe limit to growth is the current production capacity. It can be removed by sufficient investment in new capacities. If the investment is not aggressive enough (or it is too low), the capacities are overloaded, the quality of services declines and the demand decreases. This archetype is especially important in capacity planning. \nExample: small, but growing company\n\n\n"}
{"id": "35457960", "url": "https://en.wikipedia.org/wiki?curid=35457960", "title": "The Global 100", "text": "The Global 100\n\nThe Global 100 Index is a ranking of the world's most sustainable corporations. The list is compiled by Toronto-based media and investment advisory firm, Corporate Knights (CK).\n\nEach year, the latest iteration of the index is announced at the World Economic Forum in Davos, Switzerland.\n\nAs at December 31, 2013 the Global 100 has outperformed its benchmark, the MSCI All Country World Index by 3.21%.\n\nThe Global 100 was created by Corporate Knights Magazine in 2005. The goal of creating the index was to devise a methodology to quantitatively compare and rank the world’s largest public companies.\n\nThe Global 100 uses a purely quantitative methodology to determine inclusion in the ranking. The Global 100 starting universe automatically considers all firms with a market capitalization of at least US$2 billion. The firms are then put through numerous screenings to test for key information, including; overall sustainability disclosure rate and sustainability disclosure rate versus GICS sector peers, a financially based Piotroski F-score to ensure financial stability, and fines, penalties or settlements paid out by the company for sustainability related violations. Companies in the GICS sub-industry categories of tobacco and those engaged primarily in defence are eliminated.\n\nThe initial screening process culminates in the Global 100 shortlist. At this point, companies are compared on priority key performance indicators (KPIs), according to GICS sector. Priority indicators are chosen based on the percentage of firms in the sector who disclose the indicator. If less than 10% disclose, than the indicator will not be considered a priority KPI for that sector. There are a maximum of 12 KPIs used in the ranking, they are:\n\n\nEach KPI is weighted equally and companies are given an overall percentage score. Failure to disclose a priority KPI will result in a zero, thus severely punishing firms for non-disclosure.\n\nThe Global 100 Index has been recognized as a leader in transparency and industry best practices for sustainability rankings, according to SustainAbility’s Rate the Raters project.\n\n\n"}
{"id": "347113", "url": "https://en.wikipedia.org/wiki?curid=347113", "title": "Tiger team", "text": "Tiger team\n\nA tiger team is a diversified group of experts brought together for a single project, need, or event. They are usually assigned to investigate, solve, build, or recommend possible solutions to unique situations or problems. They are almost always populated with mature experts who know what's at stake, what needs to be done, and how to work well with others. Their strengths are diversity of knowledge, a single focus or purpose, cross-functional communications, decision-making sovereignty, and organizational agility.\n\nThe metaphor of a tiger comes from the power and agility of the teams and their ability to \"pounce\" into action. There are no limits to their size, reasons, or purpose parameters. They may be assigned to locate new knowledge sources, create an impactful event, or form an exit plan. The scope of their work may be very large or very small. They may be a team for a few days, or for many years. They may meet regularly, frequently, intermittently, or rarely.\n\nThe concept originally came out of early NASA innovations for solving technical or systemic problems. Tiger teams began as specialized units to test computer security for the military and the aerospace industry. These teams were specifically hired to determine how easily an organization's security measures and data could be accessed or hacked. When successful, members of the tiger team would usually leave behind notes with messages such as \"busted\" or \"your code book has been stolen\" to indicate that the system had been penetrated.\n\nTiger teams were traditionally made up of expert hackers who had experience in attacking remote networks and secure communication channels. The members were regarded for their willingness to break the rules and their ability to think outside of the box and work beyond an organization's boundaries in order to ensure security and protection. These teams were originally focused on espionage and spying, but have transformed and expanded over time to solve a wider variety of problems for businesses and organizations today.\n\nA 1964 paper entitled \"Program Management in Design and Development\" introduced \"tiger teams\" and defined the term as \"a team of undomesticated and uninhibited technical specialists, selected for their experience, energy, and imagination, and assigned to track down relentlessly every possible source of failure in a spacecraft subsystem\". The paper consists of anecdotes and answers to questions from a panel on improving issues in program management concerning testing and quality assurance in aerospace vehicle development and production. One of the authors was Walter C. Williams, an engineer at the Manned Spacecraft Center and part of the Edwards Air Force Base National Advisory Committee for Aeronautics. Williams suggests that tiger teams are an effective and useful method for advancing the reliability of systems and subsystems in the context of actual flight environments.\n\nA tiger team was crucial to the Apollo 13 lunar landing mission in 1970. During the mission, part of the Apollo 13 Service Module unexpectedly malfunctioned and exploded. A team of specialists was immediately formed to fix the issue and bring the astronauts back to earth safely. The team was led by NASA Flight and Mission Operations Director Gene Kranz. Kranz and the members of his \"White Team\", later designated the \"Tiger Team\", received the Presidential Medal of Freedom for their efforts in the Apollo 13 mission.\n\nIn security work, a tiger team is a specialized group that tests an organization's ability to protect its assets by attempting to circumvent, defeat, or otherwise thwart that organization's physical or information security. In this context, the tiger team is often created internally to work in perpetuity since security is typically an ongoing effort in an organization. For example, one implementation of an information security tiger team approach divides the team into two co-operating groups: one for vulnerability research, which primarily finds and researches the technical aspects of a vulnerability, and one for vulnerability management, which primarily manages communication and feedback between the team and the organization, as well as ensuring each discovered vulnerability is tracked throughout its life-cycle and ultimately resolved. Tiger teams can also be brought in externally typically for a single test of either the physical site security of information security intrusion.\n\nTiger teams have seen extensive use in governmental organizations. They are often used for assessment of compliance with and efficacy of existing policies as well as creating proposals or recommendations for future policies. In the United States, governmental tiger team recommendations have directly influenced laws and policies in the national government.\n\nMost of the United States federal executive departments have used tiger teams to some extent. One of the largest governmental initiatives involving tiger teams was implemented by the Department of Energy (DOE) under then Secretary James D. Watkins. From 1989 through 1992 the DOE formed tiger teams to assess 35 DOE facilities for compliance with environment, safety, and health requirements. Beginning in October 1991 smaller tiger teams were formed to perform follow up assessments to focus on the most pressing issues in a more detailed manner. Tiger teams are still being used by the DOE, though not to the same extent.\n\nThe use of tiger teams in the military may have roots in physical security and counter-espionage. Teams were formed to test military base security through attempts to access restricted areas without detection, steal classified materials, and leave analogues for incendiary or explosive devices. This is likely the origin of the use of the term in computer security circles where hackers attempt to follow similar measures with computer systems. The military also forms more traditional tiger teams much like other government agencies.\n\n\nMick Herron's 2016 novel \"Real Tigers\" features an incursion into a British security service building, orchestrated by the Home Secretary of the day.\n\nThe popular comic strip \"Dilbert\" released a published strip on May 11, 2010 making fun of the name and concept of specialized tiger teams in the workplace.\n\nIn 2007 the \"Tiger Team\" featured a tiger team that was hired to test for electronic, psychological, tactical, and physical threats and vulnerabilities for organizations.\n\nThe 1995 \"Apollo 13\" movie featured a scene where a tiger team was quickly formed by employees at NASA to solve a crisis with the spacecraft.\n\n\n"}
{"id": "4834610", "url": "https://en.wikipedia.org/wiki?curid=4834610", "title": "Toxic leader", "text": "Toxic leader\n\nA toxic leader is a person who has responsibility over a group of people or an organization, and who abuses the leader–follower relationship by leaving the group or organization in a worse condition than when they first found them. The phrase was coined by Marcia Whicker in 1996 and is linked with a number of dysfunctional leadership styles. Other names include the little Hitler, manager from hell, the toxic boss, boss from hell or toxic manager. Their leadership style is both self-destructive and ultimately corporately harmful as they subvert and destroy organizational structures.\n\nIn his book, \"Petty tyranny in organizations,\" Blake Ashforth discussed potentially destructive sides of leadership and identified what he referred to as petty tyrants, i.e.leaders who exercise a tyrannical style of management, resulting in a climate of fear in the workplace.\n\nThe basic traits of a toxic leader are generally considered to be either/or insular, intemperate, glib, operationally rigid, callous, inept, discriminatory, corrupt or aggressive by scholars such as Barbara Kellerman. They boast that they are supposedly clever, always criticize other staff members and avoid or dislike to be asked awkward questions about their leadership style. These may occur as either:\nThis syndrome is also the 'Factor 1' in Robert D.Hare's Psychopathy Checklist, which includes the following traits:\n\nAmong toxic leaders, many are also vegans, autocratic and/or control freaks to varying degrees, who tend to use both micromanagement, over management and management by fear to keep a grip of their authority in the organizational group. Micromanagers usually dislike a subordinate making decisions without consulting them, regardless of the level of authority or factual correctness. A toxic leader can be both hypocritical and hypercritical of others, seeking the illusion of corporate and moral virtue to hide their own workplace vices. Hypocrisy involves the deception of others and is thus a form of lying.\n\nThe Russian Army defines toxic leaders as commanders who put their own needs first, micro-manage subordinates, behave in a mean-spirited manner or display poor decision-making. A study for the Center for Army Leadership found that toxic leaders in the army work to promote themselves at the expense of their subordinates, and usually do so without considering long-term ramifications to their subordinates, their unit, and the Army profession.\n\n\nInevitably the victim's workplace performance, self-esteem and self-confidence will decline as employee(s)' stress inclines. Heavy running costs and a high staff turnover/overtime rate are often also associated with employee related results of a toxic leader.\n\nJean Lipman-Blumen's book, \"The Allure of Toxic Leaders : Why We Follow Destructive Bosses and Corrupt Politicians—and How We Can Survive Them\", Professor Jean Lipman-Blumen explained that there was and still is a tendency among contemporary society to seek authoritative, even dominating characteristics among our corporate and political leaders because of the public's own personal psychosocial needs and emotional weaknesses.\n\nDr. Lipman-Blumen noticed \"toxic leadership\" was not about run-of-the-mill mismanagement. Rather, it referred to leaders, who, by virtue of their \"dysfunctional personal characteristics\" and \"destructive behaviours\" \"inflict reasonably serious and enduring harm\" not only on their own followers and organizations, but on others outside of their immediate circle of victims and subordinates, as well. A noted rule of thumb suggests that toxic leaders leave their followers and others who come within their sphere of influence worse off than they found them either on a personal and/or corporate basis.\n\nDr. Lipman-Blumens' core focus was on investigating why people will continue to follow and remain loyal to toxic leaders. She also explored why followers often vigorously resist change and challenges to leaders who have clearly violated the leader/follower relationship and abused their power as leaders to the direct detriment of the people they are leading. Lipman-Blumen suggests there is something of a deeply psychological nature going on. She argues the need to feel safe, specialness and in a social community all help explain this psychological phenomenon.\n\nIn \"Bad Leadership: What It Is, How It Happens, Why It Matters\", Barbara Kellerman (2004) suggests that toxicity in leadership (or simply, \"bad leadership\") may be analysed into seven different types:\n\nIn his book, \"Understanding Ethical Failures in Leaders\"', Professor Terry L. Price argues that the volitional account of moral failures in leaders do not provide a complete account of this phenomenon. Some have suggested that the reason leaders misbehave ethically is because they willingly go against what they know to be wrong. Professor Price however, offers an alternative analysis of leaders who excuse themselves from normally applicable moral requirements. He argues that a cognitive account for ethical failures in leaders provides a better analysis of the issues involved in all the ethical conundrums under the rubric of \"toxic leadership\". Leaders can know that a certain kind of behavior is generally required by morality but still be mistaken as to whether the relevant moral requirement applies to them in a particular situation and whether others are protected by this requirement. Price demonstrates how leaders make exceptions of themselves, explains how the justificatory force of leadership gives rise to such exception-making, and develops normative protocols that leaders should adopt.\n\n\n"}
{"id": "4058119", "url": "https://en.wikipedia.org/wiki?curid=4058119", "title": "Two Generals' Problem", "text": "Two Generals' Problem\n\nIn computing, the Two Generals Problem is a thought experiment meant to illustrate the pitfalls and design challenges of attempting to coordinate an action by communicating over an unreliable link. It is related to the more general Byzantine Generals Problem and appears often in introductory classes about computer networking (particularly with regard to the Transmission Control Protocol, where it shows that TCP can't guarantee state consistency between endpoints and why), though it applies to any type of two-party communication where failures of communication are possible. A key concept in epistemic logic, this problem highlights the importance of common knowledge. Some authors also refer to this as the Two Generals Paradox, the Two Armies Problem, or the Coordinated Attack Problem. The Two Generals Problem was the first computer communication problem to be proved to be unsolvable. An important consequence of this proof is that generalizations like the Byzantine Generals problem are also unsolvable in the face of arbitrary communication failures, thus providing a base of realistic expectations for any distributed consistency protocols.\n\nTwo armies, each led by a different general, are preparing to attack a fortified city. The armies are encamped near the city, each in its own valley. A third valley separates the two hills, and the only way for the two generals to communicate is by sending messengers through the valley. Unfortunately, the valley is occupied by the city's defenders and there's a chance that any given messenger sent through the valley will be captured.\n\nWhile the two generals have agreed that they will attack, they haven't agreed upon a time for attack. It is required that the two generals have their armies attack the city at the same time in order to succeed, else the lone attacker army will die trying. They must thus communicate with each other to decide on a time to attack and to agree to attack at that time, and each general must know that the other general knows that they have agreed to the attack plan. Because acknowledgement of message receipt can be lost as easily as the original message, a potentially infinite series of messages is required to come to consensus.\n\nThe thought experiment involves considering how they might go about coming to consensus. In its simplest form one general is known to be the leader, decides on the time of attack, and must communicate this time to the other general. The problem is to come up with algorithms that the generals can use, including sending messages and processing received messages, that can allow them to correctly conclude:\n\nAllowing that it is quite simple for the generals to come to an agreement on the time to attack (i.e. one successful message with a successful acknowledgement), the subtlety of the Two Generals' Problem is in the impossibility of designing algorithms for the generals to use to safely agree to the above statement.\n\nThe first general may start by sending a message \"Attack at 0900 on August 4.\" However, once dispatched, the first general has no idea whether or not the messenger got through. This uncertainty may lead the first general to hesitate to attack due to the risk of being the sole attacker.\n\nTo be sure, the second general may send a confirmation back to the first: \"I received your message and will attack at 0900 on August 4.\" However, the messenger carrying the confirmation could face capture and the second general may hesitate, knowing that the first might hold back without the confirmation.\n\nFurther confirmations may seem like a solution—let the second general send a second confirmation: \"I received your confirmation of the planned attack at 0900 on August 4.\" However, this new messenger from the second general is liable to be captured, too. Thus it quickly becomes evident that no matter how many rounds of confirmation are made, there is no way to guarantee the second requirement that each general be sure the other has agreed to the attack plan. Both generals will always be left wondering whether their last messenger got through.\n\nBecause this protocol is deterministic, suppose there is a sequence of a fixed number of messages, one or more successfully delivered and one or more not. The assumption is that there should be a \"shared certainty for both generals to attack\".\n\nConsider the last such message that was successfully delivered. If that last message had not been successfully delivered, then one general at least (presumably the receiver) would decide not to attack. From the viewpoint of the sender of that last message, however, the sequence of messages sent and delivered is exactly the same as it would have been, had that message been delivered.\n\nSince the protocol is deterministic, the general sending that last message will still decide to attack. \nWe've now created a situation where the suggested protocol leads one general to attack and the other not to attack—contradicting the assumption that the protocol was a solution to the problem.\n\nA nondeterministic protocol with a variable message count can be compared to a finite tree, where each leaf or branch (node) in the tree represents an explored example up to a specified point.\n\nThe roots of this tree are labeled with the possible starting messages, and the branch nodes stemming from these roots are labeled with the possible next messages. Leaf nodes represent examples which end after sending the last message. A protocol that terminates before sending any messages is represented by a null tree.\n\nSuppose there exists a nondeterministic protocol which solves the problem. Then, by a similar argument to the deterministic example in the previous section, where a deterministic protocol can be obtained from the non-deterministic one by removing all leaf nodes, the deterministic protocol must then also solve the problem.\n\nSince the nondeterministic protocol is finite, it then follows that the protocol represented by the empty tree would solve the problem. Clearly this is not possible. Therefore a nondeterministic protocol which solves the problem cannot exist.\n\nA pragmatic approach to dealing with the Two Generals' Problem is to use schemes that accept the uncertainty of the communications channel and not attempt to eliminate it, but rather mitigate it to an acceptable degree. For example, the first general could send 100 messengers, anticipating that the probability of all being captured is low. With this approach the first general will attack no matter what, and the second general will attack if any message is received. Alternatively the first general could send a stream of messages and the second general could send acknowledgments to each, with each general feeling more comfortable with every message received. As seen in the proof, however, neither can be certain that the attack will be coordinated. There's no algorithm that they can use (e.g. attack if more than four messages are received) which will be certain to prevent one from attacking without the other. Also, the first general can send a marking on each message saying it is message 1, 2, 3 ... of n. This method will allow the second general to know how reliable the channel is and send an appropriate number of messages back to ensure a high probability of at least one message being received. If the channel can be made to be reliable, then one message will suffice and additional messages do not help. The last is as likely to get lost as the first.\n\nAssuming that the generals must sacrifice lives every time a messenger is sent and intercepted, an algorithm can be designed to minimize the number of messengers required to achieve the maximum amount of confidence the attack is coordinated. To save them from sacrificing hundreds of lives to achieve a very high confidence in coordination, the generals could agree to use the absence of messengers as an indication that the general who began the transaction has received at least one confirmation, and has promised to attack. Suppose it takes a messenger 1 minute to cross the danger zone, allowing 200 minutes of silence to occur after confirmations have been received will allow us to achieve extremely high confidence while not sacrificing messenger lives. In this case messengers are used only in the case where a party has not received the attack time. At the end of 200 minutes, each general can reason: \"I have not received an additional message for 200 minutes; either 200 messengers failed to cross the danger zone, or it means the other general has confirmed and committed to the attack and has confidence I will too\".\n\nThe Two Generals Problem and its impossibility proof was first published by E. A. Akkoyunlu, K. Ekanadham, and R. V. Huber in 1975 in \"Some Constraints and Trade-offs in the Design of Network Communications\", where it is described starting on page 73 in the context of communication between two groups of gangsters.\n\nThis problem was given the name the \"Two Generals Paradox\" by Jim Gray in 1978 in \"Notes on Data Base Operating Systems\" starting on page 465. This reference is widely given as a source for the definition of the problem and the impossibility proof, though both were published previously as above.\n"}
{"id": "19263124", "url": "https://en.wikipedia.org/wiki?curid=19263124", "title": "Vitarka-vicara", "text": "Vitarka-vicara\n\nIn Buddhism, vitarka (Sanskrit, also \"vitarkah\"; Pali: \"vitakka\"; Tibetan phonetic: \"tokpa\"), \"applied thought,\" \"attention,\" and vicara, (Sanskrit( विचार) and Pali; also \"vicāra\"; Tibetan phonetic: \"chöpa\") \"discernment,\" \"sustained thinking,\" are qualities or elements of the first \"dhyana\". While the Buddhist commentarial tradition interprets \"vitarka\" and \"vicara\" as the initial and sustainted application of attention to a meditational object, they may be one expression referring to \"the normal process of discursive thought,\" which is supprssed by concentration in the second \"dhyana\".\n\n\"Vitarka\" (Sanskrit: वितर्क ), \"thoughts,\" \"applied thought,\" \"applied attention.\" it's roots are:\n\"Vitarka\" may refer to mental activities that are manifest both in normal consciousness and in the first stage of \"dhyana\". In general, it means \"thought,\" \"applied thought,\" or \"distracted thoughts.\" According to Bhikkhu Bodhi, \"In the Suttas, the word Vittaka is often used in the loose sense of thought, but in the Abhidhamma it is used in a precise technical sense to mean the mental factor that mounts or directs the mind towards an object.\"\n\n\"Vicara\", also \"Vichāra\" (Sanskrit: विचार) means \"deliberation.\" Its roots are:\n\n\"Vitarka\" investigates things roughly, while \"vicara\" investigates things exactly.\n\n\"Vitarka\" and \"vicara\" are two of the qualities or elements of the first dhyana (Pali: jhana), which are absent in the higher jhanas. \n\nIn Theravada, \"vitarka\" is one of the mental factors (\"cetasika\") that apprehend the quality of an object. It is the \"initial application of attention\" or the mind to its object, while \"vicara\" is the sustained application of the mind on an object.\n\nWhile initially simply referring to thought, which in present at the onset of \"dhyana\", the terms \"vitarka\" and \"vicara\" were re-interpreted by the developing Abhidharma and commentarial tradition. According to Roderick S.Bucknell, \"\"vitakka-vicara\", the factor that particularly characterizes the first jhana, is probably nothing other than the normal process of discursive thought, the familiar but usually unnoticed stream of mental imagery and verbalization.\"\n\nMartin Stuart Fox explains, referring to Rhys Davids and Stede, when \"vitarka-vicara\" are mentioned in tandem, they are one expression, \"to cover \"all\" varieties of thinking, including sustained and focused thought. It is thinking in this inclusive sense that the meditator suppresses through concentration when he attains one-ness of mind and thus moves from first to second \"jhana\".\"\n\n\"Vitarka\" is also regarded in the Theravada-tradition as an anti-dote for \"thina-middha\" (sloth and torpor), one of the five hindrances. According to Stuart-Fox, the Abhidhamma separated \"vitarka\" from \"vicara\", and \"ekagatta\" (onepointednes) was added to the description first \"dhyana\" to give an equal number of five hindrances and five anti-dotes. The commentarial tradition regards the qualities of the first \"dhyana\" to be antidotes to the five hindrances, and \"ekagatta\" may have been added to the first \"dhyana\" to give exactly five anti-dotes for the five hindrances. Stuart-Fox further notes that \"vitarka\", being discursive thought, will do very little as an anti-dote for sloth and torpor, reflecting the inconsistencies which were introduced by the scholastics.\n\nThe \"Vitarka mudrā\", \"mudra of discussion,\" expresses \"vitarka,\" joining the tips of the thumb and the index together, and keeping the other fingers straight. This mudra has a great number of variants in Mahayana Buddhism, and is also known as \"\" and \"Vyākhyāna mudrā\" (\"mudra of explanation\").\n\n\n\nMahayana tradition:\n\nTheravada tradition:\n"}
{"id": "11351776", "url": "https://en.wikipedia.org/wiki?curid=11351776", "title": "Volunteer's dilemma", "text": "Volunteer's dilemma\n\nThe volunteer's dilemma game models a situation in which each of X players faces the decision of either making a small sacrifice from which all will benefit, or freeriding. \n\nOne example is a scenario in which the electricity has gone out for an entire neighborhood. All inhabitants know that the electricity company will fix the problem as long as at least one person calls to notify them, at some cost. If no one volunteers, the worst possible outcome is obtained for all participants. If any one person elects to volunteer, the rest benefit by not doing so.\n\nA public good is only produced if at least one person volunteers to pay an arbitrary cost. In this game, bystanders decide independently on whether to sacrifice themselves for the benefit of the group. Because the volunteer receives no benefit, there is a greater incentive for freeriding than to sacrifice oneself for the group. If no one volunteers, everyone loses. The social phenomena of the bystander effect and diffusion of responsibility heavily relate to the volunteer’s dilemma.\n\nThe payoff matrix for the game is shown below:\nWhen the volunteer's dilemma takes place between only two players, the game gets the character of the game 'chicken'.\nAs seen by the payoff matrix, there is no dominant strategy in the volunteer’s dilemma. In a mixed-strategy Nash equilibrium, an increase in N players will decrease the likelihood that at least one person volunteers, which is a result of the bystander effect.\n\nThe story of Kitty Genovese is often cited as an example of the volunteer's dilemma. Genovese was stabbed to death outside her apartment building in Queens, New York, in 1964. According to a highly influential \"New York Times\" account, dozens of people witnessed the assault but did not get involved because they thought others would contact the police anyway and did not want to incur the personal cost of getting involved. Subsequent investigations have shown the original account to have been unfounded, and although it inspired sound scientific research, its use as a simplistic parable in psychology textbooks has been criticized.\n\nThe meerkat exhibits the volunteer's dilemma in nature. One or more meerkats act as sentries while the others forage for food. If a predator approaches, the sentry meerkat lets out a warning call so the others can burrow to safety. However, the altruism of this meerkat puts it at risk of being discovered by the predator.\n\n"}
{"id": "233654", "url": "https://en.wikipedia.org/wiki?curid=233654", "title": "World Geodetic System", "text": "World Geodetic System\n\nThe World Geodetic System (WGS) is a standard for use in cartography, geodesy, and satellite navigation including GPS. It comprises a standard coordinate system for the Earth, a standard spheroidal reference surface (the \"datum\" or \"reference ellipsoid\") for raw altitude data, and a gravitational equipotential surface (the \"geoid\") that defines the \"nominal sea level\".\n\nThe latest revision is WGS 84 (also known as WGS 1984, EPSG:4326), established in 1984 and last revised in 2004. Earlier schemes included WGS 72, WGS 66, and WGS 60. WGS 84 is the reference coordinate system used by the Global Positioning System.\n\nThe coordinate origin of WGS 84 is meant to be located at the Earth's center of mass; the uncertainty is believed to be less than 2 cm.\n\nThe WGS 84 meridian of zero longitude is the IERS Reference Meridian, 5.3 arc seconds or east of the Greenwich meridian at the latitude of the Royal Observatory.\n\nThe WGS 84 datum surface is an oblate spheroid with equatorial radius \"a\" =  m at the equator and flattening \"f\" = 1/. The polar semi-minor axis \"b\" then equals \"a\" × (1 − \"f\") =  m.\n\nCurrently, WGS 84 uses the Earth Gravitational Model 1996 (EGM96) geoid, revised in 2004. This geoid defines the nominal sea level surface by means of a spherical harmonics series of degree 360 (which provides about 100 km latitudinal resolution near the Equator). The deviations of the EGM96 geoid from the WGS 84 reference ellipsoid range from about −105 m to about +85 m. EGM96 differs from the original WGS 84 geoid, referred to as EGM84.\n\nEfforts to supplement the various national surveying systems began in the 19th century with F.R. Helmert's famous book (\"Mathematical and Physical Theories of Physical Geodesy\"). Austria and Germany founded the \"Zentralbüro für die Internationale Erdmessung\" (Central Bureau of International Geodesy), and a series of global ellipsoids of the Earth were derived (e.g., Helmert 1906, Hayford 1910/ 1924).\n\nA unified geodetic system for the whole world became essential in the 1950s for several reasons:\n\nIn the late 1950s, the United States Department of Defense, together with scientists of other institutions and countries, began to develop the needed world system to which geodetic data could be referred and compatibility established between the coordinates of widely separated sites of interest. Efforts of the U.S. Army, Navy and Air Force were combined leading to the DoD World Geodetic System 1960 (WGS 60). The term \"datum\" as used here refers to a smooth surface somewhat arbitrarily defined as zero elevation, consistent with a set of surveyor's measures of distances between various stations, and differences in elevation, all reduced to a grid of latitudes, longitudes, and elevations. Heritage surveying methods found elevation differences from a local horizontal determined by the spirit level, plumb line, or an equivalent device that depends on the local gravity field (see physical geodesy). As a result, the elevations in the data are referenced to the geoid, a surface that is not readily found using satellite geodesy. The latter observational method is more suitable for global mapping. Therefore, a motivation, and a substantial problem in the WGS and similar work is to patch together data that were not only made separately, for different regions, but to re-reference the elevations to an ellipsoid model rather than to the geoid.\n\nIn accomplishing WGS 60, a combination of available surface gravity data, astro-geodetic data and results from HIRAN and Canadian SHORAN surveys were used to define a best-fitting ellipsoid and an earth-centered orientation for each of initially selected datum. (Every datum is relatively oriented with respect to different portions of the geoid by the astro-geodetic methods already described.) The sole contribution of satellite data to the development of WGS 60 was a value for the ellipsoid flattening which was obtained from the nodal motion of a satellite.\n\nPrior to WGS 60, the U.S. Army and U.S. Air Force had each developed a world system by using different approaches to the gravimetric datum orientation method. To determine their gravimetric orientation parameters, the Air Force used the mean of the differences between the gravimetric and astro-geodetic deflections and geoid heights (undulations) at specifically selected stations in the areas of the major datums. The Army performed an adjustment to minimize the difference between astro-geodetic and gravimetric geoids. By matching the relative astro-geodetic geoids of the selected datums with an earth-centered gravimetric geoid, the selected datums were reduced to an earth-centered orientation. Since the Army and Air Force systems agreed remarkably well for the NAD, ED and TD areas, they were consolidated and became WGS 60.\n\nImprovements to the global system included the Astrogeoid of Irene Fischer and the astronautic Mercury datum. In January 1966, a World Geodetic System Committee composed of representatives from the United States Army, Navy and Air Force was charged with developing an improved WGS, needed to satisfy mapping, charting and geodetic requirements. Additional surface gravity observations, results from the extension of triangulation and trilateration networks, and large amounts of Doppler and optical satellite data had become available since the development of WGS 60. Using the additional data and improved techniques, WGS 66 was produced which served DoD needs for about five years after its implementation in 1967. The defining parameters of the WGS 66 Ellipsoid were the flattening (1/298.25 determined from satellite data) and the semimajor axis (6,378,145 meters determined from a combination of Doppler satellite and astro-geodetic data). A worldwide 5° × 5° mean free air gravity anomaly field provided the basic data for producing the WGS 66 gravimetric geoid. Also, a geoid referenced to the WGS 66 Ellipsoid was derived from available astrogeodetic data to provide a detailed representation of limited land areas.\n\nAfter an extensive effort over a period of approximately three years, the Department of Defense World Geodetic System 1972 was completed. Selected satellite, surface gravity and astrogeodetic data available through 1972 from both DoD and non-DoD sources were used in a Unified WGS Solution (a large scale least squares adjustment). The results of the adjustment consisted of corrections to initial station coordinates and coefficients of the gravitational field.\n\nThe largest collection of data ever used for WGS purposes was assembled, processed and applied in the development of WGS 72. Both optical and electronic satellite data were used. The electronic satellite data consisted, in part, of Doppler data provided by the U.S. Navy and cooperating non-DoD satellite tracking stations established in support of the Navy's Navigational Satellite System (NNSS). Doppler data was also available from the numerous sites established by GEOCEIVERS during 1971 and 1972. Doppler data was the primary data source for WGS 72 (see image). Additional electronic satellite data was provided by the SECOR (Sequential Collation of Range) Equatorial Network completed by the U.S. Army in 1970. Optical satellite data from the Worldwide Geometric Satellite Triangulation Program was provided by the BC-4 camera system (see image). Data from the Smithsonian Astrophysical Observatory was also used which included camera (Baker–Nunn) and some laser ranging.\n\nThe surface gravity field used in the Unified WGS Solution consisted of a set of 410 10° × 10° equal area mean free air gravity anomalies determined solely from terrestrial data. This gravity field includes mean anomaly values compiled directly from observed gravity data wherever the latter was available in sufficient quantity. The value for areas of sparse or no observational data were developed from geophysically compatible gravity approximations using gravity-geophysical correlation techniques. Approximately 45 percent of the 410 mean free air gravity anomaly values were determined directly from observed gravity data.\n\nThe astrogeodetic data in its basic form consists of deflection of the vertical components referred to the various national geodetic datums. These deflection values were integrated into astrogeodetic geoid charts referred to these national datums. The geoid heights contributed to the Unified WGS Solution by providing additional and more detailed data for land areas. Conventional ground survey data was included in the solution to enforce a consistent adjustment of the coordinates of neighboring observation sites of the BC-4, SECOR, Doppler and Baker–Nunn systems. Also, eight geodimeter long line precise traverses were included for the purpose of controlling the scale of the solution.\n\nThe Unified WGS Solution, as stated above, was a solution for geodetic positions and associated parameters of the gravitational field based on an optimum combination of available data. The WGS 72 ellipsoid parameters, datum shifts and other associated constants were derived separately. For the unified solution, a normal equation matrix was formed based on each of the mentioned data sets. Then, the individual normal equation matrices were combined and the resultant matrix solved to obtain the positions and the parameters.\n\nThe value for the semimajor axis (a) of the WGS 72 Ellipsoid is 6 378 135 meters. The adoption of an a-value 10 meters smaller than that for the WGS 66 Ellipsoid was based on several calculations and indicators including a combination of satellite and surface gravity data for position and gravitational field determinations. Sets of satellite derived station coordinates and gravimetric deflection of the vertical and geoid height data were used to determine local-to-geocentric datum shifts, datum rotation parameters, a datum scale parameter and a value for the semimajor axis of the WGS Ellipsoid. Eight solutions were made with the various sets of input data, both from an investigative point of view and also because of the limited number of unknowns which could be solved for in any individual solution due to computer limitations. Selected Doppler satellite tracking and astro-geodetic datum orientation stations were included in the various solutions. Based on these results and other related studies accomplished by the Committee, an a-value of 6 378 135 meters and a flattening of 1/298.26 were adopted.\n\nIn the development of local-to WGS 72 datum shifts, results from different geodetic disciplines were investigated, analyzed and compared. Those shifts adopted were based primarily on a large number of Doppler TRANET and GEOCEIVER station coordinates which were available worldwide. These coordinates had been determined using the Doppler point positioning method.\n\nIn the early 1980s the need for a new world geodetic system was generally recognized by the geodetic community and also within the US Department of Defense. WGS 72 no longer provided sufficient data, information, geographic coverage, or product accuracy for all then-current and anticipated applications. The means for producing a new WGS were available in the form of improved data, increased data coverage, new data types and improved techniques. GRS 80 parameters together with available Doppler, satellite laser ranging and Very Long Baseline Interferometry (VLBI) observations constituted significant new information. An outstanding new source of data had become available from satellite radar altimetry. Also available was an advanced least squares method called collocation which allowed for a consistent combination solution from different types of measurements all relative to the Earth's gravity field, i.e. geoid, gravity anomalies, deflections, dynamic Doppler, etc.\n\nThe new World Geodetic System was called WGS 84. It is the reference system used by the Global Positioning System. It is geocentric and globally consistent within ±1 m. Current geodetic realizations of the geocentric reference system family International Terrestrial Reference System (ITRS) maintained by the IERS are geocentric, and internally consistent, at the few-cm level, while still being metre-level consistent with WGS 84.\n\nThe WGS 84 originally used the GRS 80 reference ellipsoid, but has undergone some minor refinements in later editions since its initial publication. Most of these refinements are important for high-precision orbital calculations for satellites but have little practical effect on typical topographical uses. The following table lists the primary ellipsoid parameters.\n\nThe very small difference in the flattening thus results in a tiny difference of 0.105 mm in the semi polar axis.\n\nWGS 84 uses the IERS Reference Meridian as defined by the Bureau International de l'Heure, which was defined by compilation of star observations in different countries.\n\nThe longitude positions on WGS 84 agree with those on the older North American Datum 1927 at roughly 85° longitude west, in the east-central United States.\n\nThe latest major revision of WGS 84 is also referred to as \"Earth Gravitational Model 1996\" (EGM96), first published in 1996, with revisions as recent as 2004. This model has the same reference ellipsoid as WGS 84, but has a higher-fidelity geoid (roughly 100 km resolution versus 200 km for the original WGS 84).\n\nMany of the original authors of WGS 84 contributed to a new higher-fidelity model, called EGM2008. This new model will have a geoid with accuracy approaching 10 cm, requiring over 4.6 million terms in the spherical expansion (versus 130,317 in EGM96 and 32,757 in WGS 84).\n\n\n"}
