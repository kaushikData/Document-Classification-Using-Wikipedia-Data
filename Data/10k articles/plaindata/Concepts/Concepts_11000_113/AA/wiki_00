{"id": "9092040", "url": "https://en.wikipedia.org/wiki?curid=9092040", "title": "Acquiescence bias", "text": "Acquiescence bias\n\nAcquiescence bias is a category of response bias in which respondents to a survey have a tendency to agree with all the questions or to indicate a positive connotation. Acquiescence is sometimes referred to as \"yea-saying\" and is the tendency of a respondent to agree with a statement when in doubt. This particularly is in the case of surveys or questionnaires that employ truisms, such as: \"It is better to give than to receive\" or \"Never a lender nor a borrower be\".\n\nDouglas N. Jackson demonstrated acquiescence responding on the California F-scale (a measure of authoritarianism), which contains such truisms. He created a reverse-keyed version of the California F-scale where all the items were the opposite in meaning (see the two previous examples for a pair of such contradictory statements). He administered both the original and reverse-keyed versions of the California F-scale to the same group of respondents. One would expect that the correlation between these two scales to be negative, but there was a high, positive correlation. Jackson interpreted this as evidence of acquiescence responding. Respondents were merely being agreeable to the statements, regardless of the content.\n\nJackson and Messick, using factor analysis, also demonstrated that the two main factors explaining the majority of response variation on the Minnesota Multiphasic Personality Inventory (MMPI) were for social desirability and acquiescence responding (this would also hold true for the revised MMPI-2).\n\nOne approach to dealing with acquiescence responding on surveys and questionnaires is to employ a balance of positively and negatively keyed items in terms of the intended content. For example, in trying to assess depression it would be a good idea to also include items assessing happiness and contentedness, etc. (reversed-keyed items), in addition to the usual depressive content.\n\n"}
{"id": "5896189", "url": "https://en.wikipedia.org/wiki?curid=5896189", "title": "Aircraft seat map", "text": "Aircraft seat map\n\nAn aircraft seat map or seating chart, is a diagram of the seat layout inside a passenger airliner. They are often published by airlines for informational purposes, and are of use to passengers for selection of their seat at booking or check-in.\n\nSeat maps usually indicate the basic seating layout, the numbering and lettering of the seats, the location of the emergency exits, lavatories, galleys, bulkheads and wings. Airlines which allow internet check-in frequently present a seat map indicating free and occupied seats to the passenger so that they select their seat from it.\n\nIn addition to the published seat maps from airliners, there are a number of independent websites which also publish seat maps along with reviews of individual seats, noting the particularly good (extra legroom, quiet cabin, etc.) or bad (lack of recline, unusually cramped, missing window, etc.) seats.\n\nMost of the airlines publish the seat configurations for their aircraft, but the quality of these seat maps is sometimes questionable. Some of the details and information about seats are confusing. Usually airlines do not publish seat maps for every aircraft, only for the larger aircraft and for the ones flying on frequent routes.\n\nWhen passengers complete an online booking, or check in online, they are often also presented with an aircraft seat map. However, this data is typically sourced from the original text-only seat maps on computer reservation systems such as Sabre where the seatmap is simply held as a two-dimensional array and as such can only display a grid of seats, as opposed to the more ingenious layouts now used in First and Business Class.\n\nNichols et al. (2013) have reported that when people book seats on-line, they exhibit a leftward preference for seats on an aircraft, but a rightward preference for seats at the theatre.\n\nIn addition to those published seat maps which can be found on airline websites, there are some other websites that publish aircraft seat maps for almost all commercial carriers. Seat maps that can be found on these sites usually have more details and on some websites you can find comments from other passengers with advantages and disadvantages about each seat.\n\nThe accuracy and editorial independence of specialised websites showing seat maps have also been questioned. SeatGuru has come under scrutiny since it was sold to the online booking agent Expedia for $1.2m, and Expedia now use the SeatGuru information when selling seats. As a result, SeatGuru has received some criticism for presenting seat maps which are inaccurate and where no one from the company has travelled on the aircraft; for example showing bars on aircraft where there are none (on the Singapore A380) or seat rows that don’t exist (on the Emirates A380).\n\nThe latest generation of user-generated airline seatmaps include comments from frequent flyers, and one specialised website has gained access from airlines to take pictures of every seat, and sit in them to write specific recommendations, alongside the detailed seat maps.\n\nOn many aircraft, the rightmost seats have letter designations HJK, skipping the letter I. This is because each seat has a row number followed by letter; letters that confuse with numbers (I, O, Q, S, or Z) must be avoided. Digital Equipment Corporation (DEC) was the first to implement this, avoiding I (1), O (0) and S (5). The remaining letters are called the DEC alphabet.\n\nOccasionally, aircraft with a seating structure of 2+2 may letter the seats as \"ACDF\" to keep with the standard of A/F being window and C/D being aisle on short-haul aircraft (which generally have 3+3 seats).\n\nIn First and Business class cabins, the seat letters for the window seats will typically be the same as in coach, with some letters skipped in between as there are fewer seats per row. For example, if economy cabin is ten across, labeled ABC-DEFG-HJK, the Business Class cabin might be labeled AC-DG-HK for a six across layout, with A-DG-K for a four across First Class. One notable exception to this is Delta Air Lines, who uses sequential letters regardless of cabin layout on all aircraft (AB-CD-EF in Business Class and ABC-DEF-GHJ in Economy).\n\nSome airlines omit the row number 13, reputedly because of a widespread superstition that the number is unlucky. This is the case with Lufthansa, for example (as shown on the Lufthansa A321/100 seating plan). Emirates used to have a row 13, but on their latest A380 aircraft have removed it (as shown on Emirates A380-800 seating plan). British Airways is less superstitious, and their seat maps for A320 aircraft shows a row 13. Delta Air Lines also includes row 13 in many of their seat maps.\n\n"}
{"id": "305759", "url": "https://en.wikipedia.org/wiki?curid=305759", "title": "Aldabra Island day gecko", "text": "Aldabra Island day gecko\n\nThe Aldabra Island day gecko, or Aldabra day gecko (Phelsuma abbotti abbotti), has been found on the Aldabra Atoll (Seychelles). It lives on low trees and bushes and eats insects and fruit.\n"}
{"id": "31251396", "url": "https://en.wikipedia.org/wiki?curid=31251396", "title": "Amorphous set", "text": "Amorphous set\n\nIn set theory, an amorphous set is an infinite set which is not the disjoint union of two infinite subsets.\n\nAmorphous sets cannot exist if the axiom of choice is assumed. Fraenkel constructed a permutation model of Zermelo–Fraenkel with Atoms in which the set of atoms is an amorphous set. After Cohen's initial work on forcing in 1963, proofs of the consistency of amorphous sets with Zermelo–Fraenkel were obtained.\n\nEvery amorphous set is Dedekind-finite, meaning that it has no bijection to a proper subset of itself. To see this, suppose that \"S\" is a set that does have a bijection \"f\" to a proper subset. For each \"i\" ≥ 0\ndefine \"S\" to be the set of elements that belong to the image of the \"i\"-fold composition of \"f\" with itself but not to the image of the (\"i\" + 1)-fold composition.\nThen each \"S\" is non-empty, so the union of the sets \"S\" with even indices would be an infinite set whose complement is also infinite, showing that \"S\" cannot be amorphous. However, the converse is not necessarily true: it is consistent for there to exist Dedekind-finite sets that are not amorphous.\n\nNo amorphous set can be linearly ordered. Because the image of an amorphous set is itself either amorphous or finite, it follows that every function from an amorphous set to a linearly ordered set has only a finite image.\n\nThe cofinite filter on an amorphous set is an ultrafilter. This is because the complement of each infinite subset must not be infinite, so every subset is either finite or cofinite.\n\nIf π is a partition of an amorphous set into finite subsets, then there must be exactly one integer \"n\"(π) such that π has infinitely many subsets of size \"n\"; for, if every size was used finitely many times, or if more than one size was used infinitely many times, this information could be used to coarsen the partition and split π into two infinite subsets. If an amorphous set has the additional property that, for every partition π, \"n\"(π) = 1, then it is called strictly amorphous or strongly amorphous, and if there is a finite upper bound on \"n\"(π) then the set is called bounded amorphous. It is consistent with ZF that amorphous sets exist and are all bounded, or that they exist and are all unbounded.\n"}
{"id": "54033971", "url": "https://en.wikipedia.org/wiki?curid=54033971", "title": "Anne Frank Human Rights Memorial", "text": "Anne Frank Human Rights Memorial\n\nThe Anne Frank Human Rights Memorial is a cenotaph complex and educational park in Boise, Idaho near the Boise Public Library and the Greenbelt, the centerpiece of which is a statue of Anne Frank; it is jointly maintained by the Wassmuth Center for Human rights and the Boise Department of Parks and Recreation, and is the only human rights memorial in the U.S. Designed by Idaho Falls architect Kurt Karst, a sapling of the Anne Frank Tree and quotations from some sixty notables and unknowns (including poets, activists, politicians and diplomats, those who survived the Holocaust, and those who did not) are prominent installations. It also features one of the few installations where the full text of the Universal Declaration of Human Rights is on permanent public display. The park been recognized and accepted by the International Coalition of Sites of Conscience. It was thoroughly renovated in September 2018, with an outdoor classroom and a new scrupture, \"The Spiral of Injustice.\" \n\nThe site does not only serve as a convenient staging area for rallies, marches, and protests (and more generally as a contemplative spot), it is where the Boise Police Department takes their newly commissioned officers before field training.\n\nIn early May 2017 the plaque featuring the beginning of the complete Universal Declaration of Human Rights was vandalized with antisemitic graffiti in red marker; more generally two different areas of the site were also defaced over the next few days with racist slurs against black people and Jews causing $20,000 in damage, due in part to the botched initial attempts at repair.The vandalism, the first since the memorial's dedication in 2002, is being investigated as a potential hate crime, and numerous donations for repair have poured in.\n"}
{"id": "46249607", "url": "https://en.wikipedia.org/wiki?curid=46249607", "title": "Bhrama (illusion)", "text": "Bhrama (illusion)\n\nBhrama (Sanskrit: भ्रम), in the context of Hindu thought, means – error, mistake, illusion, confusion, perplexity. But, it literally means – that which is not steady; and refers to error etc., caused by defects in the perceptive system. The seeing of snake in a rope in darkness, silver nacre in moonlight, water in a mirage on a hot day and a person in a stump of tree are four classic instances quoted in Vedantic texts. \"Bhrama\" is a mistake, it is a confusion about one object which exists for another object which does not exist, it merely refers to the fallibility of human perception.\n\nHuman nature is ordinarily afflicted by - भ्रमप्रमादविप्रलिप्साकरणापाटवदोषाः – i.e. \"bhrama\" (false knowledge or mistakes), \"pramāda\" (inattention or misunderstanding reality), \"vipralipsā\" (cheating propensity) and \"karaṇa-a-pāṭava\" (imperfection of the senses) are four major mind-faults which mislead human beings and do not permit right perception and cognition. Amongst these, the knowledge which is of the nature of \"bhrama\" is the direct thought-wave of \"avidya\". And, the texts speak about there being five theories of illusion or erroneous perception – \"Ātmakhyāti\" (Yogacara theory of subjective apprehension), \"Asatkhyāti\" (Madhyamaka theory of the nonexistent), \"Akhyāti\" (Prabhākara’s theory of non-apprehension), \"Anyathākhyati\" (Nyaya theory of misapprehension) and \"Anirvacanīyakhyāti\" (Advaita Vedanta theory of apprehension of the indeterminate), developed by five schools of thought.\n\nThe Vedantic texts reveal the Self as Pure Consciousness; they reveal the Self as the ever blissful witness who is neither the enjoyer nor the enjoyment or the object of enjoyment. The enjoyer is Chidabhasa or Jiva, the sheath of the intellect, a product or manifestation of Maya, not transcendentally real and subject to change. Vidyaranya in his Panchadasi (VII.9-10) explains:-\n\nSwami Swahananda in his commentary tells us that Kutastha, conventionally identified with ego, is not the object of identification for it is incapable of being associated with ego.\n\nAccording to Shankara, \"atma-anatma adhyasa\", the so-called locus of superimposition, is a mispresentation or \"proksha-aproksha bhrama\". Panchapadika pf Padmapada interprets \"purovasthitava\" (the object in front) as contact with the visual sense, whereas Ratnaprabha of Niścalakara relates it with sense-contact; the former explains that a non-object can become an apparent object and the latter explains that Shankara in no way considers the said locus to be complete and conclusive.\n\n\"Saguna\" (with attributes) worship leads to a typical illusion in as much as the devotee mistakes physical or mental images for the formless God; it is of the nature of the \"Samvadi-bhrama\" that finally leads to the realization of Nirguna Brahman, the endless pursuit after sense-objects is the \"Visamvadi-bhrama\". But, the cumulative subtle awareness of \"bhrama\" need not necessarily result in the awareness of Maya because owing to the latter either one wakes up from a dream or goes on dreaming forever.\n\n\"Svarūpa-bhrama\" (illusion about spirituality) is one the four major \"anarthas\" (useless, meaningless, disastrous, wrongdoings) and is said to be of four kinds – \"sva-tattva\" which is illusion about one’s own spiritual identity, \"para-tattva\" which is illusion about the spiritual identity of the supreme absolute truth, \"sādhya-sādhana-tattva\" which is illusion about the spiritual means and the object gained, and \"māyā-tattva\" which is illusion about the Lord’s external energy. These \"anarthas\" are required to be uprooted in order to develop \"niśṭa\" (devotion). But, \"bhrama\" is not an \"āropa\" (imposing of, imputation, figurative substitution) which is an āhārya (wilfully caused in spite of falsity) cognition.\n\nThe Yoga School of thought adopts the \"Anyathākhyati\" theory of misapprehension of the Nyayas for dealing with \"bhrama\", which theory is based on the premise that \"bhrama\" is thinking of something as that which it is not, like attributing the characteristics of Prakrti to Purusha and vice versa.\n\nIn Ayurveda, \"bhrama\" refers to Vertigo, a discreet disease due to Vata prakopa and Pitta prakopa which shows six distinct stages, and is curable.\n"}
{"id": "624436", "url": "https://en.wikipedia.org/wiki?curid=624436", "title": "Block party", "text": "Block party\n\nA block party or street party is a party in which many members of a single community congregate, either to observe an event of some importance or simply for mutual enjoyment. The name comes from the form of the party, which often involves closing an entire city block to vehicle traffic. Many times, there will be a celebration in the form of playing music and dance and activities like pony rides, inflatable slides, popcorn machines and barbecues.\n\nAs a form of activism street parties are festive and/or artistic efforts to reclaim roadways as public space by large groups of people. They were made known in Western Europe and North America by the actions of Reclaim the Streets, a widespread \"dis-organization\" dedicated to reclaiming public space from automobiles and consumerism.\n\nPoland Orange Alternative staged festive protests to break the Communist government's monopoly on public life.\n\nIn the UK, street parties are mainly known as private residents' events and have a special cultural meaning. They have historically been held to commemorate major national events, such as VE Day or the Queen's jubilees, with bunting dressing the street, and children playing in the street. An estimated 10 million people took part in street parties in 1977 for the Queen's Silver Jubilee.\n\nThe tradition seems to have begun mainly in England and Wales after World War I as residents' own \"peace teas\" to celebrate the signing of the Treaty of Versailles in 1919.\n\nThe tradition was boosted for the wedding of Prince William and Kate Middleton in April 2011 with about 1 million people joining in street parties. For the Queen's Diamond Jubilee in June 2012 about 2 million took part.\n\nNow street parties are held annually and at any time for residents to meet their neighbours in a traffic-free street in a private street party. Some \"street parties\" are public events taking many forms.\n\nAn application needs making to the local authority to close a road for a street party. Despite the age of the legislation, any order made by the local authority uses the Town Police Clauses Act 1847.\n\nBlock parties are reported as a World War I innovation originating from the East Side of New York City, where an entire block was roped off and patriotic songs sung and a parade held to honor the members of that block who had gone off to war. Traditionally, many inner city block parties were actually held illegally, because they did not file for an event permit from the local authorities. However, police turned a blind eye to them.\n\nIn the United States, block parties usually occur on holidays such as Independence Day and Memorial Day. Some towns may also have an annual block party.\n\nBlock parties gained popularity in the United States during the 1970s, particularly within the hip hop community. Block parties were often held outdoors and power for the DJ's sound system was taken illegally from street lights, as referenced in the song \"South Bronx\" by KRS-One.\n\nSometimes the occasion may be a theme such as a recent popular movie or \"Welcome to our town\" for a new family. Often block parties involve barbecues and lawn games such as Simon Says, karaoke, and group dancing such as the Electric Slide, the Macarena or line dancing. In many small towns, the local fire department may also participate in the party, bringing out trucks that they display for show.\n\n\n"}
{"id": "19981527", "url": "https://en.wikipedia.org/wiki?curid=19981527", "title": "Bromance", "text": "Bromance\n\nA bromance is a close but non-sexual relationship between two or more men. It is an exceptionally tight affectional, homosocial male bonding relationship exceeding that of usual friendship, and is distinguished by a particularly high level of emotional intimacy. The emergence of the concept since the beginning of the 21st century has been seen as reflecting a change in societal perception and interest in the theme, with an increasing openness of western society in the twenty-first century to reconsider gender, sexuality, and exclusivity constraints.\n\n\"Bromance\" is a portmanteau of \"bro\" (or \"brother\") and \"romance\". Dave Carnie is credited with coining the term as editor of the skateboard magazine \"Big Brother\" in the 1990s to refer specifically to the sort of relationships that develop between skaters who spent a great deal of time together. The term did not attain broad currency until approximately 2005 when the theme became more prominent in the motion picture industry.\n\nNumerous examples exist of intense homosocial friendships throughout history; such relationships were common between men and also between women. The term \"romantic friendship\" is a modern historical construct with a different homoerotic connotation and social construction; it is discussed within its own article.\n\n\"Bromance\" has been examined from viewpoints such as historiography, discourse analysis, social research, and queer theory in book-length reviews. The emergence of \"bromance\" as a topic over the past decade has been seen as reflecting how society has collectively changed its perception and interest in the theme.\n\nSeveral characteristics of bromance have been cited:\n\nAccording to Chen, society has taken a collective interest in reexamination of some of the traditional constraints on male friendship, and in potentially reshaping the constructs of gender, sexuality, and intimacy. Bromance provides \"a case study of gender, sexuality, and exclusivity constraints in twenty-first century America as they operate in law and beyond. Those constraints in turn speak to the privilege and subordination imbued in this type of relationship, with implications for other types as well.\" This is distinct from the connotations of \"romantic friendship\", a term of 20th century historical scholarship that retrospectively described close homosocial relationships, which had become less common after potential physical intimacy between non-sexual partners came to be regarded with anxiety in the second half of the 19th century.\n\nOn the one hand, social interest in the theme has been seen as driving the film industry, which has then fed back to society at large, exploring peoples' mindsets and addressing acceptance of \"other types of relationships\" between people. On the other hand, some have seen the emphasis on platonic love as a rejection of homoeroticism, or as a deliberate confounding of \"homosocial\" and \"homoerotic\" relationships.\n\n\"Bromance\" has also been seen as a reflection of greater \"discursive expressivity\". The experiences of friendship and masculinity, perhaps due to more open parenting styles from the 1970s, reflect a trend toward more openness emotionally, with increased expressivity. According to sociologist Peter Nardi, \"men are less afraid of being perceived as gay. It has become more acceptable for them to show some emotion.\" Men are marrying later, if at all, which impacts male bonding. According to the 2010 US Census, the average age of a man's first marriage is 28, up from 23 in 1960; men with more education are waiting until their 30s before getting married.\n\nA number of celebrity relationships have been popularly characterised as \"\"bromances\". Although \"bromance\" is a new term, this treatment of celebrity relationships is not new: The composer Franz Schubert had a very close friendship with poet Franz von Schober, whose texts Schubert set to music. They were nicknamed \"Schobert\" in early 19th century Vienna.\n\nDean Martin and Jerry Lewis as the 1946-1956 ‘rock star’ comedy team Martin and Lewis set a new standard for a complex, multifaceted enactment of a ‘special’ male friendship.” Coming post-war, “the comedy of Martin and Lewis teased with a sly alternative to the model of heterosexual affirmation traditionally peddled by Hollywood, as their intense and unstable relationship showcased a panoply of emotional and erotic intensities between men. The cultural resonance of Martin and Lewis's comedy derived from the way it set in motion a more complex ‘queering of gender.’” They starred in 16 films together as an inseparable unit, as well as on early live television and in nightclubs. They had an immeasurable effect on millions of baby boomers and future comedians, (including George Clooney, whose aunt Rosemary Clooney was a guest on their show).\n\nBen Affleck and Matt Damon were described as \"perhaps the pioneering bromance in showbiz history\"\", which led to a hit off-Broadway play called \"Matt and Ben\". The relationship between Zachary Quinto and Chris Pine, stars of the 2009 \"Star Trek\" film, has been described similarly, in common with their on-screen characters' relationship.\n\nThe close friendship between George Clooney and Brad Pitt was once suggested to be \"George's longest-lasting affair\" and Clooney's bromantic tendencies served as the basis for an episode of the animated series \"American Dad!\" entitled \"Tears of a Clooney\", in which lead character Stan Smith becomes bromantically involved with Clooney as part of an elaborate revenge plot.\n\nProfessional footballers Eric Dier and Dele Alli, who play together for Tottenham Hotspur and England, have a close relationship that has been described as a \"bromance\".\n\nDuring the 2016 Olympic 100m finals, the friendship between Jamaican Usain Bolt and Canadian Andre De Grasse emerged, characterized and celebrated on social media as a bromance.\n\nThe tight relationship both on- and off-stage between Bruce Springsteen and the late E Street Band saxophonist Clarence Clemons has often been described as one of the most fitting examples of \"bromance\" in Western modern music. This relationship is most notably depicted in Springsteen's song \"Tenth Avenue Freeze-Out\", from \"Born to Run\" – in which Springsteen and Clemons appear respectively under their pseudonyms Bad Scooter and Big Man. It was also described in Clemons' autobiography \"Big Man: Real Life & Tall Tales\".\n\nThe Japanese and Korean music industry actively encourages bromance among male celebrities (particularly members of boy bands) as part of the fan service to please the audience.\n\nWhile the term has generally been applied to straight relationships, mixed gay-straight relationships without sexual intimacy have also been dubbed \"bromances\". Examples of well-known gay-straight bromances include George Michael and Andrew Ridgley from the band Wham!, Ronnie Kroell and Ben DiChiara from the Bravo reality series \"Make Me a Supermodel\", in which the pair was nicknamed \"Bronnie\", the relationship on \"\" between Charlie Herschel and Marcus Lehman, and \"American Idol\"'s Kris Allen and Adam Lambert, which was given the name \"Kradam\".\n\nBuddy films have to a degree been rebranded as \"bromance\" films, although critics draw a distinction between the two, noting that a buddy film tends to be more explicitly violent and less open about its latent homosexual content. The intersection between buddy films and what would come to be called the bromance film was noted comedically at least as early as 1978, when \"National Lampoon\" ran a parody ad for the football-themed buddy film \"Semi-Tough\", renamed \"Semi-Sweet\" and featuring an illustration of stars Burt Reynolds and Kris Kristofferson holding hands.\n\nProminent examples of \"bromantic comedy\" include Judd Apatow's \"The 40 Year Old Virgin\" (2005) and \"Knocked Up\" (2007), which targeted non-sexual homosocial behavior and masculinity in inventive ways, David Dobkin's \"Wedding Crashers\" (2005), \"Zoolander\", \"Funny People\" (2009), John Hamburg's \"I Love You Man\" (2009), Todd Phillips' \"The Hangover\" (2009), and Gordon's \"Horrible Bosses\" (2011).\n\nAlthough J. R. R. Tolkien's novels predate what could technically be called the \"bromance era\", the portrayal of the lifelong close relationships between Frodo Baggins and Samwise Gamgee, Meriadoc Brandybuck and Peregrin Took, and Gimli and Legolas in the novels have been characterized as bromance, as well as the depictions in the films based on them.\n\nThe theme remains popular, with different genres looking at the concept in various ways, such as the documentary \"Best of Enemies\" – about the 1960s feud between intellectuals Gore Vidal and William F. Buckley.\n\nBromance on television has also become more commonplace. It appeared early-on in the partnership of two CIA/KGB spies in the 1960s' \"Man from U.N.C.L.E.\", and in the 1970s' buddy-cop show \"Starsky & Hutch\", which producer Aaron Spelling called \"TV’s first heterosexual love affair.\" Some critics also point to the 1970s' \"Odd Couple\", about which executive producer Garry Marshall has said, \"The network was concerned that we were being too gay.\"\n\nIn October 2008, \"TV Guide\" placed Gregory House (Hugh Laurie) and James Wilson (Robert Sean Leonard) on the cover, under the headline \"Isn't It Bromantic?\".\n\nBrody Jenner, featured on MTV's reality show \"The Hills\" and the subject of bromance discussions for his relationships with castmates Justin Bobby and Spencer Pratt, debuted his own series on the network, called \"Bromance\", on December 29, 2008. The six-episode series features Jenner selecting from amongst competitors to become part of Jenner's \"entourage\".\n\nIn \"Scrubs\", J.D. is a sensitive doctor \"completely in touch with his feelings. He's not afraid of showing his best pal Turk how much he loves him.\" In one episode, they sing, \"Guy love. That’s all it is.\" The J.D. and Turk relationship truly embodies one of the best bromances ever. They always stand by each other's side and often one thinks they are more in love with each other than their significant other. \"The Good Guys\" \"promotes male bonding while self-consciously acknowledging its homoerotic overtones.\" \"The Independent\" analyzed the BBC's \"Sherlock\" as a \"bromance\", and looked at bromance thematically. The relationship between Sherlock Holmes and Dr. Watson as a bromance has been visited elsewhere also.\nThe cultural concept that \"bromance\" connotes particular closeness has been taken up thematically. The concept has been visited in biology, as well as an experimental acrobatic video dance piece, \"Bromance\", which explores “... the intimacy of physical interaction between guys; of their ‘bromance’.”\n\nThe relationship between George W. Bush and former press secretary Scott McClellan as told in McClellan's book \"What Happened\" was called by one reviewer \"the tale of one long, failed bromance\".\n\nIn 2012, the song \"Bromance\" by comedian, YouTube personality, and actor Ryan Higa (also known by his YouTube username \"nigahiga\"), went viral.\n\nThe former premiers Dalton McGuinty of Ontario (2003–2013) and Jean Charest of Quebec (2003–2012) were described as a \"\"burgeoning bromance\". Stephen Harper of Canada (2006–2015) and Tony Abbott of Australia (2013–2015), and their respective countries, were characterized as a \"conservative bromance\"\". The term has been used to describe Narendra Modi from India and Barack Obama from the United States during the January 2015 visit, and Vladimir Putin from the Russian Federation with Gerhard Schröder from Germany.\n\nIn early 2017, a number of internet memes surfaced which alluded to Obama's relationship with Vice President Joe Biden as a \"bromance\".\n\nA Bromance has been linked with a decrease in “problems such as anxiety, depression, heart disease, and memory and concentration impairment”\n\n"}
{"id": "21783926", "url": "https://en.wikipedia.org/wiki?curid=21783926", "title": "Carbon process management", "text": "Carbon process management\n\nCarbon Process Management (CPM) is a management process which promotes environmental effectiveness in organizations. It is designed to maximize efficiencies in the consumption of resources that contribute to climate change. When implemented effectively, CPM techniques can reduce operating costs, realizing gains in brand equity, competitive advantage and stakeholder value. Initially introduced by First Carbon Solutions, CPM uses Japanese kaizen philosophy which continuously improves workplace practices to reduce wastage, this is combined business process management (BPM) which increases efficiency. Governments who resorts to legal mechanisms and regulation to deal with the risks of climate change, techniques such as CPM are directed towards a corporate approach in helping reduce greenhouse gas emissions.\n"}
{"id": "1717420", "url": "https://en.wikipedia.org/wiki?curid=1717420", "title": "Castle doctrine", "text": "Castle doctrine\n\nA castle doctrine, also known as a castle law or a defense of habitation law, is a legal doctrine that designates a person's abode or any legally occupied place (for example, a vehicle or home) as a place in which that person has protections and immunities permitting one, in certain circumstances, to use force (up to and including deadly force) to defend oneself against an intruder, free from legal prosecution for the consequences of the force used. The term is most commonly used in the United States, though many other countries invoke comparable principles in their laws.\n\nA person may have a duty to retreat to avoid violence if one can reasonably do so. Castle doctrines lessen the duty to retreat when an individual is assaulted within one's own home. Deadly force may either be justified, the burdens of production and proof for charges impeded, or an affirmative defense against criminal homicide applicable, in cases \"when the actor reasonably fears imminent peril of death or serious bodily harm to him or herself or another\". The castle doctrine is not a defined law that can be invoked, but a set of principles which may be incorporated in some form in many jurisdictions. Castle doctrines may not provide civil immunity, such as from wrongful death suits, which have a much lower burden of proof.\n\nJustifiable homicide in self-defense which happens to occur inside one's home is distinct, as a matter of law, from castle doctrine because the mere occurrence of trespassing—and occasionally a subjective requirement of fear—is sufficient to invoke the castle doctrine, the burden of proof of fact is much less challenging than that of justifying a homicide in self-defense. With justifiable homicide in self-defense, one generally must objectively prove to a trier of fact, against all reasonable doubt, the intent in the intruder's mind to commit violence or a felony. It would be a misconception of law to infer that because a state has a justifiable homicide in self-defense provision pertaining to one's domicile, it has a castle doctrine protecting the estate and exonerating any duty whatsoever to retreat therefrom. The doctrine can be misused as a pretext for extrajudicial punishment in private spaces. The use of this legal principle in the United States has been controversial in relation to a number of cases in which it has been invoked, including the deaths of Japanese exchange student Yoshihiro Hattori and Scottish businessman Andrew de Vries.\n\nThe legal concept of the inviolability of the home has been known in Western civilization since the age of the Roman Republic. In English common law the term is derived from the dictum that \"an Englishman's home is his castle\" (see \"Semayne's case\"). This concept was established as English law by the 17th century jurist Sir Edward Coke, in his \"The Institutes of the Laws of England\", 1628:\n\nFor a man's house is his castle, et domus sua cuique est tutissimum refugium [and each man's home is his safest refuge]. \nEnglish common law came with colonists to the New World, where it has become known as the castle doctrine. The term has been used in England to imply a person's absolute right to exclude anyone from their home, although this has always had restrictions, such as bailiffs having increasing powers of entry since the late-20th century.\n\nAccording to 18th-century Presbyterian minister and biblical commentator Matthew Henry, the prohibition of murder found in the Old Testament contains an exception for legitimate self-defense. A home defender who struck and killed a thief caught in the act of breaking in at night was not guilty of bloodshed. \"If a thief is caught breaking in and is struck so that he dies, the thief owes no blood-debt to the home-defender; but if the thief lives, he owes a blood-debt to the home-defender and must make restitution.\"\n\nBy the 18th century, many US state legal systems began by importing English common law such as Acts of Parliament of 2 Ed. III (Statute of Northampton), and 5 Rich. II (Forcible Entry Act 1381) in law since 1381—which imposed criminal sanctions intending to discourage the resort to self-help. This required a threatened party to retreat, whenever property was \"involved\" and resolve the issue by civil means.\n\nThen as now, there were English politicians who were for or against the use of self-help over state-help. William Blackstone, in Book 4, Chapter 16 of his \"Commentaries on the Laws of England\", proclaims that the laws \"leave him (the inhabitant) the natural right of killing the aggressor (the burglar)\" and goes on to generalize in the following words:\n\nNot only was the doctrine considered to justify defense against neighbors and criminals, but any of the Crown's agents who attempted to enter without a proper warrant as well. It should be noted that prohibitions of the Fourth Amendment to the United States Constitution share a common background with current castle doctrine laws.\n\nIn 1841, The Preemption Act was passed to \"appropriate the proceeds of the sales of public lands... and to grant 'pre-emption rights' to individuals\" who were already living on federal lands (commonly referred to as \"squatters\"). During this same period, claim clubs sprung up all over the US advocating vigilance and the castle doctrine. This was in concurrence with the culture of manifest destiny which led to westward expansion and the American Indian Wars, the last of which ended by the 1920s.\n\nOn the American frontier, the doctrine of no duty to retreat extended outside a residence. It asserted that a man in an altercation that he did not provoke was not obliged to flee from his attacker, but was free to stand his ground and defend himself. A state Supreme Court justice wrote in 1877,\n\nAmerican West historian Richard M. Brown wrote that under the circumstances, for a man in the American West to flee under such circumstances would be cowardly and un-American. \nLegendary dentist and gambler Doc Holliday successfully used this defense when he shot Billy Allen as he entered a saloon. Holliday owed Allen $5 which Allen wanted paid and had threatened Holliday. Although Allen was unarmed at the time, Holliday had received reports that Allen had been armed and looking for him earlier in the day. During the subsequent trial, Holliday asserted he was within his rights and the jury agreed. He was acquitted on March 28, 1885.\n\nToday, the penal and civil forcible-entry laws of most American states forbid the use of force in the recovery of possession of land. At most the Castle Doctrine is an affirmative defense for individuals inevitably charged with criminal homicide, not a permission or pretext to commit homicide—which is generally unlawful. A minority of states, permit individuals who have the right of immediate possession of land to use reasonable force to regain possession of that land.\n\nThe term \"make my day law\" came to be used in the United States in 1985 when Colorado passed a law that shielded people from any criminal or civil liability for using force against a home invader, including deadly force. (The law's nickname is a reference to the line \"Go ahead, make my day\" (meaning 'do something so I have an excuse to kill you') uttered by actor Clint Eastwood's character \"Dirty Harry\" Callahan in the 1983 police film \"Sudden Impact\".)\n\nEach jurisdiction incorporates the castle doctrine into its laws in different ways. The circumstance in which it may be invoked include the premises covered (abode only, or other places too), the degree of retreat or non-deadly resistance required before deadly force can be used, etc. Typical conditions that apply to some castle doctrine laws include:\n\n\nIn Colorado, the make-my-day statute provides the occupant with immunity from prosecution only for force used against a person who has made an unlawful entry into the dwelling, but not against a person who remains unlawfully in the dwelling.\n\nIn addition to providing a valid defense in criminal law, many laws implementing the castle doctrine, particularly those with a \"stand-your-ground clause,\" also have a clause which provides immunity from any \"civil\" lawsuits filed on behalf of the assailant (for damages/injuries resulting from the force used to stop them). Without this clause, an assailant could sue for medical bills, property damage, disability, and pain & suffering as a result of the injuries inflicted by the defender; or, if the force results in the assailant's death, his/her next-of-kin or estate could launch a wrongful death suit. Even if successfully rebutted, the defendant (the homeowner/defender) may still have to pay high legal costs leading up to the suit's dismissal. Without criminal/civil immunity, such civil action could be used as revenge against a lawfully acting defender (who was, originally, the assailant's victim).\n\nUse of force in self-defense which causes damage or injuries to other, non-criminally-acting parties, may not be shielded from criminal or civil prosecution, however.\n\nIn US jurisdictions where the castle doctrine applies, there is no duty to retreat before deadly force is used against an intruder by a person in their home or, in some jurisdictions, just simply where the person can legally be.\n\nMost states in the United States have stand-your-ground laws where individuals can use deadly force in any location one is legally allowed to be without first attempting to retreat.\n\nIn Colorado, the make-my-day statute \"was not intended to justify use of physical force against persons who enter a dwelling accidentally or in good faith.\" In other words, \"the unlawful entry element requires a culpable mental state of 'knowingly' on the part of the intruder.\"\n\nA list of states and their most applicable body of law to justifying homicide in protection of the abode is listed below. Because not all states truly invoke castle doctrine, justifiable homicide in defense of life—which is nearly universal in adoption, but with narrower application—is often what is invoked as a pretext to protect the home. However, the mere fact that one is trespassing is an inappropriate or inadequate defense per se to justifying homicide in many states.\n\nThe castle doctrine in its traditional absolute and extrajudicial form is antiquated in most states. However, its vestige saliently remains as a set of principles which are incorporated to a variegated extent through both statutory and case law. It is commonly manifested as an affirmative defense to criminal homicide that occurred within a home; in some states though it slightly enhances the conditions for justifiable homicide in self-defense by laying down no duty to retreat or avert a violent encounter, or by even granting a blanket rebuttable presumption of required killing in defense of life. Where principles are statutized in a penal code, a homicide may be excused criminally, but be a wrongful death civilly. In a strict sense, simple justifiable homicide in self-defense which happens to occur inside one's home is actually distinct as a matter of law from castle doctrine's no duty to retreat in defense of one's domicile. Self-defense protects life while castle doctrine defends estate. While most American states forbid the use of force in the recovery of possession of land, a minority of jurisdictions do invoke pure castle doctrine which unconditionally authorizes violent self-help in protection of one's domicile. States still espousing the archaic form tend to be conservative, or have unique issues such as a primarily rural population in a harsh or adverse environment which critically demands high broad skill in self-reliance. It is invoked in areas often associated with small local governments and very long response times from law enforcement. Dense urban jurisdictions repeatedly find that injustices, mistakes, and avoidable escalation from violent self-help often outweigh any benefit, especially when potential occurrences are frequent, initial police response is usually less than 7–15 minutes away, and legal remedies are local.\n\nIn addition to the states listed above, the U.S. Territory of Guam has the Castle doctrine as law.\n\nThese states uphold castle doctrine in general, but may rely on case law instead of specific legislation, may enforce a duty to retreat, and may impose specific restrictions on the use of deadly force:\n\nAustralian states have differing self-defence laws. Under South Australian law, the general defence appears in s15(1) Criminal Law Consolidation Act 1935 (SA) for defending a person's life, and s15A(1) for defending property, subject to a hybrid test, i.e. the defendant honestly believed the threat to be imminent and made an objectively reasonable and proportionate response to the circumstances as the accused subjectively perceived them.\n\nIn July 2003, the Rann Government (SA) introduced laws allowing householders to use \"whatever force they deem necessary\" when confronted with a home invader. Householders who kill or injure a home invader escape prosecution provided they can prove they had a genuine belief that it was necessary to do so to protect themselves or their family. The law was strongly opposed by then-Director of Public Prosecutions Paul Rofe, QC, and lawyer Marie Shaw, who is now a District Court Judge.\n\nSince 1917, with the enacting of the first Brazilian Civil Code, a possessor of a thing, moveable or immoveable, is allowed, in case of disturbance (\"turbação\") or expulsion (\"esbulho\"), to \"maintain or to reintegrate himself [at the possession of a thing] using its own force, as well as he does it soon\". The acts of force employed by the possessor shall not exceed the necessary ones for eliminating the disturbance or for reintegration (Article 502 of the former Civil Code; Federal Ordinary Law 3.071/1917). This possibility remained untouched on the Brazilian Civil Code of 2002 (Federal Ordinary Law 10.406/2002), in its Article 1.210.\n\nSelf-defence of possession is not allowed for the cases of threat (\"ameaça\"). It is needed for the possessor to be effectively and physically disturbed in its possession (\"turbação\") or completely severed from it (\"esbulho\"). A possessor acting under the prescriptions of the Article 1.210 of the Civil Code shall be exempt of any civil or criminal responsibility. In terms of Tort Law, Article 188, inc. I, of the Civil Code states that is not an unlawful act \"the regular exercise of a right recognized by the law\".\n\nAccording to the Criminal Code of Canada Sections 34 and 35, (which were updated in 2012 with the passage of bill C-26) force, up to and including lethal force may be used in defence of one's life or \"peaceably\" possessed property or the defence of another's life or \"peaceably\" possessed property, and is not considered an offence so long as the person believes that force is being used against them in the case of self-defence, that someone is about to or has broken into or damaged property in the case of defence of property, that they are acting in defence of themselves, someone else or \"peaceably\" possessed property, and that the act is reasonable in the circumstances. The criminal code also lays out the factors in either case that will be used to determine what constitutes \"reasonable given the circumstances\". The changes made by the government were to clarify the laws involving self-defence and defence of property, and to help legal professionals to apply the law as believed to reflect the values Canadians hold to be acceptable.\n\nIn English common law a defendant may seek to avoid criminal or civil liability by claiming that he acted in self-defence. This requires the jury to determine whether the defendant believed that force was necessary to defend him or herself, his or her property, or to prevent a crime, and that the force used was reasonable. While there is no duty to retreat from an attacker and failure to do so is not conclusive evidence that a person did not act in self-defence, it may still be considered by the jury as a relevant factor when assessing the merits of a self-defence claim. The common law duty to retreat was repealed by the Criminal Law Act 1967. This duty never existed when a person is somewhere he has a lawful right to be, but due to the repeal, now extends to public places, etc.\n\nGerman law allows self-defense against an unlawful attack, without any duty to retreat. Courts have interpreted this law as applicable to home invasion, including the use of lethal force against law enforcement in cases where the home owner was of the mistaken belief that the intrusion was an unlawful attack on his life.\n\nUnder the terms of the Defence and the Dwelling Act enacted in 2011, property owners or residents are entitled to defend themselves with force, up to and including lethal force. Any individual who uses force against a trespasser is not guilty of an offense if he or she honestly believes they were there to commit a criminal act and a threat to life. However, there is a further provision which requires that the reaction to the intruder is such that another reasonable person in the same circumstances would likely employ. This provision acts as a safeguard against grossly disproportionate use of force, while still allowing a person to use force in nearly all circumstances.\n\nThe law was introduced in response to DPP v. Padraig Nally. The Act largely places previous Irish common law jurisprudence regarding self-defense on a statutory footing.\n\nIsraeli law allows property owners to defend themselves with force. This law was introduced in response to the trial of Shai Dromi, an Israeli farmer who shot Arab intruders on his farm late at night in 2007.\n\nItaly passed a law in 2005 that would allow property owners to defend themselves with force. The law's practical application is however highly controversial: Italian judiciary system is rather complex and using force is, more often than not, not recommended at all, since the property owner might get sued for disproportionate use of force.\n\n\n\n"}
{"id": "11523713", "url": "https://en.wikipedia.org/wiki?curid=11523713", "title": "Control (management)", "text": "Control (management)\n\nControl, or controlling, is one of the managerial functions like \"planning\", \"organizing\", \"staffing\" and \"directing\". It is an important function because it helps to check the errors and to take the corrective action so that deviation from standards are minimized and stated goals of the organization are achieved in a desired manner.\n\nAccording to modern concepts, control is a foreseeing action whereas earlier concept of control was used only when errors were detected. Control in management means setting standards, measuring actual performance and taking corrective action.\n\nIn 1916, Henri Fayol formulated one of the first definitions of control as it pertains to management: \n\"Control of an undertaking consists of seeing that everything is being carried out in accordance with the plan which has been adopted, the orders which have been given, and the principles which have been laid down. Its object is to point out mistakes in order that they may be rectified and prevented from recurring.\"\n\nAccording to EFL Brech:\n\"Control is checking current performance against pre-determined standards contained in the plans, with a view to ensure adequate progress and satisfactory performance.\"\nAccording to Harold Koontz:\n\"Controlling is the measurement and correction of performance in order to make sure that enterprise objectives and the plans devised to attain them are accomplished.\"\nAccording to Stafford Beer: \n\"Management is the profession of control.\"\nRobert J. Mockler presented a more comprehensive definition of managerial control: \n\"Management control can be defined as a systematic effort by business management to compare performance to predetermined standards, plans, or objectives in order to determine whether performance is in line with these standards and presumably in order to take any remedial action required to see that human and other corporate resources are being used in the most effective and efficient way possible in achieving corporate objectives.\" \n\nAlso control can be defined as \"that function of the system that adjusts operations as needed to achieve the plan, or to maintain variations from system objectives within allowable limits\". The control subsystem functions in close harmony with the operating system. The degree to which they interact depends on the nature of the operating system and its objectives. Stability concerns a system's ability to maintain a pattern of output without wide fluctuations. Rapidity of response pertains to the speed with which a system can correct variations and return to expected output.\n\nA political election can illustrate the concept of control and the importance of feedback. Each party organizes a campaign to get its candidate selected and outlines a plan to inform the public about both the candidate's credentials and the party's platform. As the election nears, opinion polls furnish feedback about the effectiveness of the campaign and about each candidate's chances to win. Depending on the nature of this feedback, certain adjustments in strategy and/or tactics can be made in an attempt to achieve the desired result.\n\nFrom these definitions it can be stated that there is close link between planning and controlling. Planning is a process by which an organization's objectives and the methods to achieve the objectives are established, and controlling is a process which measures and directs the actual performance against the planned goals of the organization. Thus, goals and objectives are often referred to as siamese twins of management.\nthe managerial function of management and correction of performance in order to make sure that enterprise objectives and the goals devised to attain them being accomplished.\n\n\nThe four basic elements in a control system:\n\noccur in the same sequence and maintain a consistent relationships to each other in every system.\nThe first element is the \"characteristic\" or condition of the operating system which is to be measured. We select a specific characteristic because a correlation exists between it and how the system is performing. The characteristic can be the output of the system during any stage of processing or it may be a condition that is the result of the system. For example, it may be the heat energy produced by the furnace or the temperature in the room which has changed because of the heat generated by the furnace. In an elementary school system, the hours a teacher works or the gain in knowledge demonstrated by the students on a national examination are examples of characteristics that may be selected for measurement, or control.\n\nThe second element of control, the \"sensor\", is a means for measuring the characteristic or condition. For example, in a home heating system this device would be the thermostat, and in a quality-control system this measurement might be performed by a visual inspection of the product.\n\nThe third element of control, the comparator, determines the need for correction by comparing what is occurring with what has been planned. Some deviation from the plan is usual and expected, but when variations are beyond those considered acceptable, corrective action is required. It involves a sort of preventative action which indicates that good control is being achieved.\n\nThe fourth element of control, the activator, is the corrective action taken to return the system to its expected output. The actual person, device, or method used to direct corrective inputs into the operating system may take a variety of forms. It may be a hydraulic controller positioned by a solenoid or electric motor in response to an electronic error signal, an employee directed to rework the parts that failed to pass quality inspection, or a school principal who decides to buy additional books to provide for an increased number of students. As long as a plan is performed within allowable limits, corrective action is not necessary; however, this seldom occurs in practice.\n\nInformation is the medium of control, because the flow of sensory data and later the flow of corrective information allow a characteristic or condition of the system to be controlled. To illustrate how information flow facilitates control, let us review the elements of control in the context of information.\n\nThe primary requirement of a control system is that it maintains the level and kind of output necessary to achieve the system's objectives. It is usually impractical to control every feature and condition associated with the system's output. Therefore, the choice of the controlled item (and appropriate information about it) is extremely important. There should be a direct correlation between the controlled item and the system's operation. In other words, control of the selected characteristic should have a direct relationship to the goal or objective of the system.\n\nAfter the characteristic is sensed, or measured, information pertinent to control is fed back. Exactly what information needs to be transmitted and also the language that will best facilitate the communication process and reduce the possibility of distortion in transmission must be carefully considered. Information that is to be compared with the standard, or plan, should be expressed in the same terms or language as in the original plan to facilitate decision making. Using machine methods (computers) may require extensive translation of the information. Since optimal languages for computation and for human review are not always the same, the relative ease of translation may be a significant factor in selecting the units of measurement or the language unit in the sensing element.\n\nIn many instances, the measurement may be sampled rather than providing a complete and continuous feedback of information about the operation. A sampling procedure suggests measuring some segment or portion of the operation that will represent the total.\n\nIn a social system, the norms of acceptable behavior become the standard against which so-called deviant behavior may be judged. Regulations and laws provide a more formal collection of information for society. Social norms change, but very slowly. In contrast, the standards outlined by a formal law can be changed from one day to the next through revision, discontinuation, or replacement by another.\nInformation about deviant behavior becomes the basis for controlling social activity. Output information is compared with the standard or norm and significant deviations are noted. In an industrial example, frequency distribution (a tabulation of the number of times a given characteristic occurs within the sample of products being checked) may be used to show the average quality, the spread, and the comparison of output with a standard.\n\nIf there is a significant and uncorrectable difference between output and plan, the system is \"out of control.\" This means that the objectives of the system are not feasible in relation to the capabilities of the present design. Either the objectives must be reevaluated or the system redesigned to add new capacity or capability. For example, the traffic in drugs has been increasing in some cities at an alarming rate. The citizens must decide whether to revise the police system so as to regain control, or whether to modify the law to reflect a different norm of acceptable behavior.\n\nThe activator unit responds to the information received from the comparator and initiates corrective action. If the system is a machine-to-machine system, the corrective inputs (decision rules) are designed into the network. When the control relates to a man-to-machine or man-to-man system, however, the individual(s) in charge must evaluate (1) the accuracy of the feedback information, (2) the significance of the variation, and (3) what corrective inputs will restore the system to a reasonable degree of stability. Once the decision has been made to direct new inputs into the system, the actual process may be relatively easy. A small amount of energy can change the operation of jet airplanes, automatic steel mills, and hydroelectric power plants. The pilot presses a button, and the landing gear of the airplane goes up or down; the operator of a steel mill pushes a lever, and a ribbon of white-hot steel races through the plant; a worker at a control board directs the flow of electrical energy throughout a regional network of stations and substations. It takes but a small amount of control energy to release or stop large quantities of input.\n\nThe comparator may be located far from the operating system, although at least some of the elements must be in close proximity to operations. For example, the measurement (the sensory element) is usually at the point of operations. The measurement information can be transmitted to a distant point for comparison with the standard (comparator), and when deviations occur, the correcting input can be released from the distant point. However, the input (activator) will be located at the operating system. This ability to control from afar means that aircraft can be flown by remote control, dangerous manufacturing processes can be operated from a safe distance, and national organizations can be directed from centralized headquarters in Dublin, Ireland.\n\nStep 1. Establishment of Standard.\n\nStandards are the criteria against which actual performance will be measured. Standards are set in both quantitative and qualitative terms.\n\nStep 2. Measurement of actual performance\n\nPerformance is measured in an objective and reliable manner. It should be checked in the same unit in which the standards are set.\n\nStep 3. Comparing actual performance with standards.\n\nStep 4. Analysis the cause of deviations.\n\nStep 5. Taking corrective action.\n\nControl may be grouped according to three general classifications:\n\nA street-lighting system controlled by a timing device is an example of an open-loop system. At a certain time each evening, a mechanical device closes the circuit and energy flows through the electric lines to light the lamps. Note, however, that the timing mechanism is an independent unit and is not measuring the objective function of the lighting system. If the lights should be needed on a dark, stormy day the timing device would not recognize this need and therefore would not activate energy inputs. Corrective properties may sometimes be built into the controller (for example, to modify the time the lights are turned on as the days grow shorter or longer), but this would not close the loop. In another instance, the sensing, comparison, or adjustment may be made through action taken by an individual who is not part of the system. For example, the lights may be turned on by someone who happens to pass by and recognizes the need for additional light.\n\nIf control is exercised as a result of the operation rather than because of outside or predetermined arrangements, it is a closed-loop system. The home thermostat is the classic example of a control device in a closed-loop system. When the room temperature drops below the desired point, the control mechanism closes the circuit to start the furnace and the temperature rises. The furnace-activating circuit is turned off as the temperature reaches the preselected level. The significant difference between this type of system and an open-loop system is that the control device is an element of the system it serves and measures the performance of the system. In other words, all four control elements are integral to the specific system.\n\nAn essential part of a closed-loop system is feedback; that is, the output of the system is measured continually through the item controlled, and the input is modified to reduce any difference or error toward zero. Many of the patterns of information flow in organizations are found to have the nature of closed loops, which use feedback. The reason for such a condition is apparent when one recognizes that any system, if it is to achieve a predetermined goal, must have available to it at all times an indication of its degree of attainment. In general, every goal-seeking system employs feedback.\n\nThe elements of control are easy to identify in machine systems. For example, the characteristic to be controlled might be some variable like speed or temperature, and the sensing device could be a speedometer or a thermometer. An expectation of precision exists because the characteristic is quantifiable and the standard and the normal variation to be expected can be described in exact terms. In automatic machine systems, inputs of information are used in a process of continual adjustment to achieve output specifications. When even a small variation from the standard occurs, the correction process begins. The automatic system is highly structured, designed to accept certain kinds of input and produce specific output, and programmed to regulate the transformation of inputs within a narrow range of variation.\n\nFor an illustration of mechanical control: as the load on a steam engine increases and the engine starts to slow down, the regulator reacts by opening a valve that releases additional inputs of steam energy. This new input returns the engine to the desired number of revolutions per minute. This type of mechanical control is crude in comparison to the more sophisticated electronic control systems in everyday use. Consider the complex missile-guidance systems that measure the actual course according to predetermined mathematical calculations and make almost instantaneous corrections to direct the missile to its target.\n\nMachine systems can be complex because of the sophisticated technology, whereas control of people is complex because the elements of control are difficult to determine. In human control systems, the relationship between objectives and associated characteristics is often vague; the measurement of the characteristic may be extremely subjective; the expected standard is difficult to define; and the amount of new inputs required is impossible to quantify. To illustrate, let us refer once more to a formalized social system in which deviant behavior is controlled through a process of observed violation of the existing law (sensing), court hearings and trials (comparison with standard), incarceration when the accused is found guilty (correction), and release from custody after rehabilitation of the individual has occurred.\n\nThe speed limit established for freeway driving is one standard of performance that is quantifiable, but even in this instance, the degree of permissible variation and the amount of the actual variation are often a subject of disagreement between the patrolman and the suspected violator. The complexity of our society is\nreflected in many of our laws and regulations, which establish the general standards for economic, political, and social operations. A citizen may not know or understand the law and consequently would not know whether or not he was guilty of a violation.\n\nMost organized systems are some combination of man and machine; some elements of control may be performed by machine whereas others are accomplished by man. In addition, some standards may be precisely structured whereas others may be little more than general guidelines with wide variations expected in output. Man must act as the controller when measurement is subjective and judgment is required. Machines such as computers are incapable of making exceptions from the specified control criteria regardless of how much a particular case might warrant special consideration. A pilot acts in conjunction with computers and automatic pilots to fly large jets. In the event of unexpected weather changes, or possible collision with another plane, he must intercede and assume direct control.\n\nThe concept of organizational control is implicit in the bureaucratic theory of Max Weber. Associated with this theory are such concepts as \"span of control\", \"closeness of supervision\", and \"hierarchical authority\". Weber's view tends to include all levels or types of organizational control as being the same. More recently, writers have tended to differentiate the control process between that which emphasizes the nature of the organizational or systems design and that which deals with daily operations. To illustrate the difference, we \"evaluate\" the performance of a system to see how effective and efficient the design proved to be or to discover why it failed. In contrast, we operate and \"control\" the system with respect to the daily inputs of material, information, and energy. In both instances, the elements of feedback are present, but organizational control tends to review and evaluate the nature and arrangement of components in the system, whereas operational control tends to adjust the daily inputs.\n\nThe direction for organizational control comes from the goals and strategic plans of the organization. General plans are translated into specific performance measures such as share of the market, earnings, return on investment, and budgets. The process of organizational control is to review and evaluate the performance of the system against these established norms. Rewards for meeting or exceeding standards may range from special recognition to salary increases or promotions. On the other hand, a failure to meet expectations may signal the need to reorganize or redesign.\n\nIn organizational control, the approach used in the program of review and evaluation depends on the reason for the evaluation — \"that is, is it because the system is not effective (accomplishing its objectives)? Is the system failing to achieve an expected standard of efficiency? Is the evaluation being conducted because of a breakdown or failure in operations? Is it merely a periodic audit-and-review process?\"\n\nWhen a system has failed or is in great difficulty, special diagnostic techniques may be required to isolate the trouble areas and to identify the causes of the difficulty. It is appropriate to investigate areas that have been troublesome before or areas where some measure of performance can be quickly identified. For example, if an organization's output backlog builds rapidly, it is logical to check first to see if the problem is due to such readily obtainable measures as increased demand or to a drop in available man hours. When a more detailed analysis is necessary, a systematic procedure should be followed.\n\nIn contrast to organizational control, operational control serves to regulate the day-to-day output relative to schedules, specifications, and costs. \"Is the output of product or service the proper quality and is it available as scheduled? Are inventories of raw materials, goods-in-process, and finished products being purchased and produced in the desired quantities? Are the costs associated with the transformation process in line with cost estimates? Is the information needed in the transformation process available in the right form and at the right time? Is the energy resource being utilized efficiently?\"\n\nThe most difficult task of management concerns monitoring the behavior of individuals, comparing performance to some standard, and providing rewards or punishment as indicated. Sometimes this control over people relates entirely to their output. For example, a manager might not be concerned with the behavior of a salesman as long as sales were as high as expected. In other instances, close supervision of the salesman might be appropriate if achieving customer satisfaction were one of the sales organization's main objectives.\n\nThe larger the unit, the more likely that the control characteristic will be related to some output goal. It also follows that if it is difficult or impossible to identify the actual output of individuals, it is better to measure the performance of the entire group. This means that individuals' levels of motivation and the measurement of their performance become subjective judgments made by the supervisor. Controlling output also suggests the difficulty of controlling individuals' performance and relating this to the total system's objectives.\n\nThe perfect plan could be outlined if every possible variation of input could be anticipated and if the system would operate as predicted. This kind of planning is neither realistic, economical, nor feasible for most business systems. If it were feasible, planning requirements would be so complex that the system would be out of date before it could be operated. Therefore, we design control into systems. This requires more thought in the systems design but allows more flexibility of operations and makes it possible to operate a system using unpredictable components and undetermined input. Still, the design and effective operation of control are not without problems.\n\nThe objective of the system is to perform some specified function. \nThe objective of organizational control is to see that the specified function is achieved. \nThe objective of operational control is to ensure that variations in daily output are maintained within prescribed limits.\n\nIt is one thing to design a system that contains all of the elements of control, and quite another to make it operate true to the best objectives of design. Operating \"in control\" or \"with plan\" does not guarantee optimum performance. For example, the plan may not make the best use of the inputs of materials, energy, or information — in other words, the system may not be designed to operate efficiently. Some of the more typical problems relating to control include the difficulty of measurement, the problem of timing information flow, and the setting of proper standards.\n\nWhen objectives are not limited to quantitative output, the measurement of system effectiveness is difficult to make and subsequently perplexing to evaluate. Many of the characteristics pertaining to output do not lend themselves to quantitative measurement. This is true particularly when inputs of human energy cannot be related directly to output. The same situation applies to machines and other equipment associated with human involvement, when output is not in specific units. In evaluating man-machine or human-oriented systems, psychological and sociological factors obviously do not easily translate into quantifiable terms. \"For example, how does mental fatigue affect the quality or quantity of output? And, if it does, is mental fatigue a function of the lack of a challenging assignment or the fear of a potential injury? \"\n\nSubjective inputs may be transferred into numerical data, but there is always the danger of an incorrect appraisal and transfer, and the danger that the analyst may assume undue confidence in such data after they have been quantified. Let us suppose, for example, that the decisions made by an executive are rated from 1 to 10, 10 being the perfect decision. After determining the ranking for each decision, adding these, and dividing by the total number of decisions made, the average ranking would indicate a particular executive's score in his decision-making role. On the basis of this score, judgments — which could be quite erroneous — might be made about his decision-making effectiveness. One executive with a ranking of 6.75 might be considered more effective than another who had a ranking of 6.25, and yet the two managers may have made decisions under different circumstances and conditions. External factors over which neither executive had any control may have influenced the difference in \"effectiveness\".\n\nQuantifying human behavior, despite its extreme difficulty, subjectivity, and imprecision in relation to measuring physical characteristics is the most prevalent and important measurement made in large systems. The behavior of individuals ultimately dictates the success or failure of every man-made system.\n\nAnother problem of control relates to the improper timing of information introduced into the feedback channel. Improper timing can occur in both computerized and human control systems, either by mistakes in measurement or in judgment. The more rapid the system's response to an error signal, the more likely it is that the system could overadjust; yet the need for prompt action is important because any delay in providing corrective input could also be crucial. A system generating feedback inconsistent with current need will tend to fluctuate and will not adjust in the desired manner.\n\nThe most serious problem in information flow arises when the delay in feedback is exactly one-half cycle, for then the corrective action is superimposed on a variation from norm which, at that moment, is in the same direction as that of the correction. This causes the system to overcorrect, and then if the reverse adjustment is made out of cycle, to correct too much in the other direction, and so on until the system fluctuates (\"oscillates\") out of control. This phenomenon is illustrated in Figure 1. “Oscillation and Feedback”. If, at Point A, the trend below standard is recognized and new inputs are added, but not until Point B, the system will overreact and go beyond the allowable limits. Again, if this is recognized at Point C, but inputs are not withdrawn until Point D, it will cause the system to drop below the lower limit of allowable variation.\n\nOne solution to this problem rests in anticipation, which involves measuring not only the change but also the rate of change. The correction is outlined as a factor of the type and rate of the error. The difficulty also might be overcome by reducing the time lag between the measurement of the output and the adjustment to input. If a trend can be indicated, a time lead can be introduced to compensate for the time lag, bringing about consistency between the need for correction and the type and magnitude of the indicated action. It is usually more effective for an organization to maintain continuous measurement of its performance and to make small adjustments in operations constantly (this assumes a highly sensitive control system). Information feedback, consequently, should be timely and correct to be effective. That is, the information should provide an accurate indication of the status of the system.\n\nSetting the proper standards or control limits is a problem in many systems. Parents are confronted with this dilemma in expressing what they expect of their children, and business managers face the same issue in establishing standards that will be acceptable to employees. Some theorists have proposed that workers be allowed to set their own standards, on the assumption that when people establish their own goals, they are more apt to accept and achieve them.\n\nStandards should be as precise as possible and communicated to all persons concerned. Moreover, communication alone is not sufficient; understanding is necessary. In human systems, standards tend to be poorly defined and the allowable range of deviation from standard also indefinite. For example, how many hours each day should a professor be expected to be available for student consultation? Or, what kind of behavior should be expected by students in the classroom? Discretion and personal judgment play a large part in such systems, to determine whether corrective action should be taken.\n\nPerhaps the most difficult problem in human systems is the unresponsiveness of individuals to indicated correction. This may take the form of opposition and subversion to control, or it may be related to the lack of defined responsibility or authority to take action. Leadership and positive motivation then become vital ingredients in achieving the proper response to input requirements.\n\nMost control problems relate to design; thus the solution to these problems must start at that point. Automatic control systems, provided that human intervention is possible to handle exceptions, offer the greatest promise. There is a danger, however, that we may measure characteristics that do not represent effective performance (as in the case of the speaker who requested that all of the people who could not hear what he was saying should raise their hands), or that improper information may be communicated.\n\nImportance of control\n"}
{"id": "2975992", "url": "https://en.wikipedia.org/wiki?curid=2975992", "title": "Droit", "text": "Droit\n\nA droit (French for \"right\" or \"Law\") is a legal title, claim or due.\n\nThe term is used in English law in the phrase \"droits of admiralty\". This refers to certain customary rights or perquisites, formerly belonging to the Lord High Admiral, but now to the crown, for public purposes and paid into the Exchequer. These \"droits\" (see also wreck) consisted of flotsam, jetsam, ligan - (goods or wreckage on the sea bed that is attached to a buoy so that it can be recovered), treasure, deodand, derelict (maritime), within the admiral's jurisdiction; all fines, forfeitures, ransoms, recognizances and pecuniary punishments; all sturgeons, whales, porpoises, dolphins, grampuses and such large fishes; all ships and goods of the enemy coming into any creek, road or port, by durance or mistake; all ships seized at sea, salvage, etc., with the share of prizes such shares being afterwards called \"tenths\", in imitation of the French, who gave their admiral a \"droit de dixième\". The droits of admiralty were definitely surrendered for the benefit of the public by Prince George of Denmark, when Lord High Admiral of England in 1702. American law does not recognize any such droits, and the disposition of captured property is regulated by various acts of Congress.\n\nThe term \"droit\" is also used in various legal connexions (i.e., French law), such as the \"droit\" of angary, the \"droit d'achat\" (right of pre-emption) in the case of contraband, the feudal \"droit de bris\" (see wreck), the \"droit de regale\" or ancient royal privilege of claiming the revenues and patronage of a vacant bishopric, and the feudal droites of seignory generally.\n\nIn French, \"droit\" can mean \"the whole body of the Law\", as in the motto \"dieu et mon droit,\" which is to say \"God and my whole body of Law.\" \"Droit d'auteur\" is a term for French copyright law.\n"}
{"id": "10033523", "url": "https://en.wikipedia.org/wiki?curid=10033523", "title": "Durbar Mahila Samanwaya Committee", "text": "Durbar Mahila Samanwaya Committee\n\nThe Durbar Mahila Samanwaya Committee ( \"Durbar Mohila Shômonbôe Shomiti\" \"Unstoppable Women's Synthesis Committee\") or Durbar, is a collective of 65,000 sex workers in West Bengal. Established on 15 February 1992, in Sonagachi, the largest red-light district in Kolkata, West Bengal, India with estimated 11,000 sex workers, Durbar has been working on women's rights and sex workers' rights advocacy, anti-human trafficking and HIV/AIDS prevention. The Durbar states that its aims are the challenging and altering of the barriers that form the everyday reality of sex workers' lives as they relate to their poverty or their ostracism. Durbar runs 51 free clinics for sex workers across West Bengal, with support from organisations such as the Ford Foundation and the National AIDS Control Organisation (NACO), who also help Durbar in its initiatives like networking, rights protection and creating alternative livelihood for sex workers.\n\nThe group is overtly political in its aims of fighting for the recognition of prostitution as legal work and, of sex workers as workers and, for a secure social existence of sex workers and their children. They work for the legalisation of prostitution and seek to reform laws that restrict human rights of sex \n\nOn 15 February 1992, a public health scientist Dr. Smarajit Jana of All India Institute of Hygiene and Public Health, Kolkata, visited the red-light area of Sonagachi for a HIV intervention research study. A peer education team was formed from amongst the sex workers and provided training. Shortly after, studies revealed larger issues amongst sex workers, such as sex workers rights, education of their children, access to financial services and handling of harassment by police and local thugs, along with promoting the use of condoms. Thus in 1995 he formed 'Durbar Mahila Samanwaya Committee' (DMSC) with 12 sex workers as stakeholders, by 2012 DMSC had a membership of 65,000 from 48 branches across the state of West Bengal, and continues to be managed by sex workers, their children and government officials as its board members, and has not just female sex workers as its members but also male and transgender sex workers.\n\nSince its inception, it has been working as an advocacy group for sex workers and over the years, it has worked towards sensitizing general public about rights of sex workers, often initiating debate and discussion in public media and press, besides advocating abolition of 'The Immoral Traffic (Prevention) Act, 1956' (PITA), and legalisation of sex work. Many sex workers now have voters identity cards, health insurance and even bank accounts. In 1995, its consumer cooperative society and micro-credit programme, 'Usha' (literally meaning light), ensured that the Government of West Bengal altered the state's cooperative law to register it as a sex workers cooperative, instead of a 'housewives cooperative' under the prevalent state laws. By 2006-2007, small saving of its 5,000 members lead to an annual turnover to , with loan of distributed amongst its members, which also helped break the monopoly of local moneylenders, who would charge interest rates of up to 300%. The DMSC hosted India's first national convention of sex workers on 14 November 1997 in Kolkata, titled 'Sex Work is Real Work: We Demand Workers Rights'.\n\nDMSC runs 17 non-formal schools for children of sex workers, and two hostels, one at Ultadanga and the other at Baruipur. Its cultural wing, 'Komol Gandhar', teaches dance, drama, mime and music to children, who invited regularly for paid shows.\n\nThe Durbar runs the STD/HIV Intervention Programme (commonly known as the Sonagachi Project) since 1999. The ownership and management of the Sonagachi Project was taken over by DMSC from the All India Institute of Hygiene and Public Health, a central government public health training and research institute based in Kolkata, which had initiated the programme in 1992. After gaining control of the STD/HIV Intervention Programme in 1999, DMSC began replicating the Sonagachi model in other red light areas in West Bengal. DMSC also implements STD/HIV intervention Programme among street-based sex workers and their clients, covering a population of over 20,000 sex workers and migrant labourers. DMSC currently implements and runs STD/HIV intervention programmes in 49 sex work sites in West Bengal.\n\nThe approach of Durbar's programme is based on the \"3 Rs\" - Respect, Reliance and Recognition. Respect towards sex workers, Reliance on the knowledge and wisdom of the community of sex workers and, Recognition of sex work as an occupation, for protecting their occupational and human rights.\n\nDurbar is active in building broader alliances to promote HIV prevention, care and support for HIV infected and affected individuals and families both at the national and regional levels.\n\nThe book \"\" reports investigations revealing, who tried to provide, contrary to stated policy, the DMSC allows sex slavery, trafficking, and underage girls in its brothels.\n\n\n"}
{"id": "7987115", "url": "https://en.wikipedia.org/wiki?curid=7987115", "title": "EABA", "text": "EABA\n\nThe End All Be All game system, commonly known as EABA and pronounced \"ee-buh\", is a role-playing game system from Blacksburg Tactical Research Center (BTRC). It is a generic gaming systems designed to adapt to any imaginary gaming environment. It was created by Greg Porter in 2003. The game cites the \"Hero System\", \"GURPS\" and \"Call of Cthulhu\" as influences in its development.\n\nThe game books and related materials are available only in a PDF format download, or printed on demand.\n\nRole-playing games (RPGs) of the 1970s and early 1980s were environment specific, and incompatible with one another. For example, TSR published its \"Dungeons & Dragons\" game specifically for a fantasy environment. Another game from the same company, \"Star Frontiers\", was developed for science fiction-based role-playing. TSR produced other games for other environments, such as \"Gamma World\", \"Top Secret\", \"Gangbusters\", \"Boot Hill\", and more. Each of these games was set with its own self-contained rules system, and the rules for playing each game differed greatly from one game to the next.\n\nThis changed with the publication of \"GURPS\", or \"Generic Universal Role Playing System\", by Steve Jackson Games in 1986, the first commercially successful, all-encompassing, \"universal\" role-playing system.\n\nIn 1987, BTRC published its first role-playing game, \"TimeLords\", in which players played characters based upon themselves in a time travel setting. As a time travel/sci fi-based game crossing many possible settings, much of the groundwork was already laid for a universal RPG, and in fact some players were already using it as a generic game system. Much of the basics of the \"TimeLords\" system would later be converted into \"EABA\".\n\nEABA was first published in 2003 as a PDF only, available either through online download or print on demand. Publishing in this manner meant the company would not go into debt to print a large run of rulebooks and push them into brick-and-mortar stores, and that future updates to the rules could be easily made and disseminated. BTRC allows purchasers to get free upgrades for life on all titles.\n\nIn 2012, BTRC published its first major revamp of the EABA rules as \"EABA v2\". In addition to significant revamping of the combat turn system, this version made use of many of the built-in features of the Adobe PDF format, and was streamlined for use on tablet or latptop computers. Players have access to automated character sheets, dice rollers, popup menus and on-screen mapping, embedded directly into the PDF file. It is compatible with any computer or device that can read this file type, including smart phones and tablets. The file can also be printed and read like any ordinary rulebook.\n\nEABA initially received excellent reviews, and was described as \"an overlooked and underappreciated Titan in the arena of universal RPG systems\". Critics praised the simplicity and ease of use, and the ability for players to choose what level of realism to include. Initial criticism focused on the lack of many additional premade settings and the bland artwork. It did not sell incredibly well, and is relatively unknown among RPG fans.\n\nThe v2 edition also received excellent reviews, calling it \"the bleeding edge of PDF game development\", and praising the scalability and portability of the system. \nA character in \"EABA\" is built based on attributes, skills and traits. All player characters start with a set number of Attribute Points (AP) to purchase attributes, and Skill Points (SP) to purchase skills. Traits are purchased using either type of points, depending on the trait purchased; negative traits can also be chosen which give a character additional AP or SP to spend.\n\nThe total number of points available to spend depends on the setting and players. A gritty post-holocaust survival game may only start with 80 AP and SP, while a superhero game could start with 400 AP and SP. In principle a gamemaster can balance the power of foes to the abilities of the player characters by comparing their relative point values.\n\nCharacters in \"EABA\" have six basic attributes:\n\n\nAttribute scores progress exponentially, rather than linearly as is typical of many games. Increasing an ability score by 3 is an approximate doubling of the Attribute. For example, a Strength score of 9 could lift approximately 100 kg, while a score of 12 would double that to 200 kg.\n\nA score of 5-9 is considered average for any human attribute, 13 is the upper limit of human ability, and anything over 15 considered legendary.\n\nSkills are purchased using skill points in a similar manner to attributes. Each skill has an associated attribute; \"Firearms\" is based on Agility, \"Programming\" based on Awareness, etc. A character without any ability in a particular skill can use the base attribute with a penalty to determine the success of an action. Spending points on a skill will eliminate the penalty and spending more points will grant bonus dice.\n\nThe basic game system provides an extensive list of possible skills and specializations to them, and each setting comes with listings of additional setting-specific skills. Players are encouraged to create more skills as needed to cover whatever game setting or style they might want.\n\nTraits are additional things about a character, positive or negative, that help flesh them out. Traits are purchased using either AP or SP, depending on which trait is wanted. Some negative traits give the player additional AP or SP to spend.\n\nAn example is the character's age. Most characters are considered to start at between 16–20 years old (for humans). An older character would lose Attribute Points, as an aging person would generally get physically weaker; but gain Skill Points, as they generally have learned more skills in their longer life.\n\nCharacters could also be more (or less) wealthy than average, or have a special ability like exceptional luck or the ability to use magic (depending on the game setting). Various game setting include rules for many additional traits, and players are encouraged to create more as they see fit.\n\n\"EABA\" is a d6-based dice pool system. A higher ability or skill level will allow a player to roll more dice to determine success or failure of an action, but only a limited number of dice - usually three, although there is a Trait that permits four or more under certain conditions - may be chosen from the total number of dice rolled. If there are more than three dice in the pool, one of them may be converted to a +2. So an action with a difficulty of 1 will always succeed, but an action with a difficulty higher than 20 will always fail, as 20 is the highest possible roll on 3d6+2. Additional factors may make an action more or less difficult, thus increasing or decreasing the number needed for success.\n\nCombat in \"EABA\" is handled either by opposing rolls (mêlée) or against a set difficulty (ranged), both of which might be modified by things like target size, movement, visibility and so on. There are also numerous optional rules, such as explosions, called shots, hit locations and their specific damage effects, automatic fire, parrying etc.\n\nCombat time in V2 is run on an expanding scale, something unique to EABA. In most RPGs, time in combat is broken down into small manageable chunks: a combat turn in GURPS is always one second, for example. A combat round is EABA starts at one second, the next is 2 seconds, then 4, 8, 15, 30, and one minute. The goal is to make time manageable, but also to allow characters to perform complex actions during combat without taking hours of play time to do so.\n\n\"EABA\" has three types of damage, lethal, half-lethal, and non-lethal. Cutting and piercing attacks tend to be lethal, crushing attacks half-lethal and unarmed attacks non-lethal. <br>\nArmor is rated in terms of die(s) it will stop, and that is subtracted from the possible damage the attack may cause. So armor rated at 1d will reduce 1d of damage to nothing, and 2d of damage to 1d. Armor will generally \"always\" stop damage from attacks lower than its rating. For example, a bullet proof vest rated to stop .22 caliber rounds will always stop them, provided the round hits the vest. <br>\nAdditional damage to an already injured body part will have less effect than the first damage. ie, shooting someone in the leg once will reduce their mobility a lot and cause bleeding; shooting the same leg three more times will not reduce their mobility much more.\n\nImproving the characters is done with experience points, which are either accumulated for general use by adventuring, or for specific skills by training. Experience points can be used to improve both skills and attributes, with attributes costing much more to improve than skills.\n\n\n\n\n"}
{"id": "252969", "url": "https://en.wikipedia.org/wiki?curid=252969", "title": "Ecological model of competition", "text": "Ecological model of competition\n\nThe ecological model of competition is a reassessment of the nature of competition in the economy. Traditional economics models the economy on the principles of physics (force, equilibrium, inertia, momentum, and linear relationships). This can be seen in the economics lexicon: terms like labour force, market equilibrium, capital flows, and price elasticity. This is probably due to historical coincidence. Classical Newtonian physics was the state of the art in science when Adam Smith was formulating the first principles of economics in the 18th century.\n\nAccording to the ecological model, it is more appropriate to model the economy on biology (growth, change, death, evolution, survival of the fittest, complex inter-relationships, non-linear relationships). Businesses operate in a complex environment with interlinked sets of determinants. Companies co-evolve: they influence, and are influenced by, competitors, customers, governments, investors, suppliers, unions, distributors, banks, and others. We should look at this business environment as a business ecosystem that both sustains, and threatens the firm. A company that is not well matched to its environment might not survive. Companies that are able to develop a successful business model and turn a core competency into a sustainable competitive advantage will thrive and grow. Very successful firms may come to dominate their industry (referred to as \"category killers\").\n\n\n"}
{"id": "8020189", "url": "https://en.wikipedia.org/wiki?curid=8020189", "title": "Economic mobility", "text": "Economic mobility\n\nEconomic mobility is the ability of an individual, family or some other group to improve (or lower) their economic status—usually measured in income. Economic mobility is often measured by movement between income quintiles. Economic mobility may be considered a type of social mobility, which is often measured in change in income.\n\nThere are many different ideas in the literature as to what constitutes a good mathematical measure of mobility, each with their own advantages and drawbacks.\n\nMobility may be between generations (\"inter-generational\") or within a person or groups lifetime (\"intra-generational\").\nIt may be \"absolute\" or \"relative\".\n\nInter-generational mobility compares a person’s (or group's) income to that of her/his/their parents. Intra-generational mobility, in contrast, refers to movement up or down over the course of a working career. Absolute mobility involves widespread economic growth and answers the question “To what extent do families improve their incomes over a generation?” Relative mobility is specific to individuals or groups and occurs without relation to the economy as a whole. It answers the question, \"how closely are the economic fortunes of children tied to that of their parents?\" Relative mobility is a zero-sum game, absolute is not.\n\n\nHow much economic mobility really exists has been studied.\n\nAccording to the 2007 \"American Dream Report\" study, \"by some measurements\"—relative mobility between generations -- \"we are actually a less mobile society than many other nations, including Canada, France, Germany and most Scandinavian countries. This challenges the notion of America as the land of opportunity.\" Other research places the U.S. among the least economically mobile countries.\n\nAnother 2007 study (\"Economic Mobility Project: Across Generations\") found significant upward \"absolute\" mobility from the late 1960s to 2007, with two-thirds of those who were children in 1968 reporting more household income than their parents (although most of this growth in total family income can be attributed to the increasing number of women who work since male earnings have stayed relatively stable throughout this time).\n\nHowever, in terms of relative mobility it stated: \"contrary to American beliefs about equality of opportunity, a child’s economic position is heavily influenced by that of his or her parents.\" 42% of children born to parents in the bottom fifth of the income distribution (\"quintile\") remain in the bottom, while 39% born to parents in the top fifth remain at the top. Only half of the generation studied exceeded their parents economic standing by moving up one or more quintiles. Moving between quintiles is more frequent in the middle quintiles (2-4) than in the lowest and highest quintiles. Of those in one of the quintiles 2-4 in 1996, approximately 35% stayed in the same quintile; and approximately 22% went up one quintile or down one quintile (moves of more than one quintile are rarer). 39% of those who were born into the top quintile as children in 1968 are likely to stay there, and 23% end up in the fourth quintile. Children previously from lower-income families had only a 1% chance of having an income that ranks in the top 5%. On the other hand, the children of wealthy families have a 22% chance of reaching the top 5%.\n\nAccording to a 2007 study by the US Treasury Department, Americans concerned over the recent growth in inequality (after-tax income of the top 1% earners has grown by 176% percent from 1979 to 2007 while it grew only 9% for the lowest 20%) can be reassured by the healthy income mobility in America: \"There was considerable income mobility of individuals [within a single generation] in the U.S. economy during the 1996 through 2005 period as over half of taxpayers moved to a different income quintile over this period\".\n\nOther studies were less impressed with the rate of individual mobility in the United States. A 2007 inequality and mobility study (by Kopczuk, Saez and Song) and 2011 CBO study on \"Trends in the Distribution of Household Income, found the pattern of annual and long-term earnings inequality \"very close\", or \"only modestly\" different. Another source described it as the mobility of \"the guy who works in the college bookstore and has a real job by his early thirties,\" rather than poor people rising to middle class or middle income rising to wealth.\n\nThere are two different ways to measure economic mobility: absolute and relative. Absolute mobility measures how likely a person is to exceed their parents’ family income at the same age. Research by the Pew Economic Mobility Project shows that the majority of Americans, 84 percent, exceed their parents' income. However, the size of absolute income gains is not always enough to move them to the next rung of the economic ladder.\n\nA focus on how Americans’ rank on the income ladder compares to their parents, their peers, or even themselves over time is a measure of relative mobility. The Pew Economic Mobility Project’s research shows that forty percent of children in the lowest income quintile remain there as adults, and 70 percent remain below the middle quintile, meaning 30% moved up two quintiles or more in one generation.\n\nIn recent years several large studies have found that vertical inter-generational mobility is lower in the United States than in most developed countries.\nA 1996 paper by Daniel P. McMurrer, Isabel V. Sawhill found \"mobility rates seem to be quite similar across countries.\" However a more recent paper (2007) found a person's parents is a great deal more predictive of their own income in the United States than other countries. The United States had about 1/3 the ratio of mobility of Denmark and less than half that of Canada, Finland and Norway. France, Germany, Sweden, also had higher mobility, with only the United Kingdom being less mobile.\n\nEconomic mobility in developing nations (such as those in Africa) is thought to be limited by both historical and global economic factors.\nEconomic mobility is everywhere correlated with income and wealth inequality.\n\nWomen in their 30s have substantially higher incomes today than their counterparts did in their parents’ generation. Between 1974 and 2004, average income for women in their 30s has increased almost fourfold. This is a stark contrast to the growth in income of their male counterparts. The average income of men in their 30s has increased from 31,000 in 1964 to 35,000 in 2004, an increase of only 4,000.\n\nHowever, much of this can be attributed to employment rates. The employment rate of women in their 30s has increased from 39% in 1964 to 70% in 2004; whereas, the rate of employment for men in this same age group has decreased from 91% in 1964 to 86% in 2004. This sharp increase in income for working women, in addition to stable male salaries, is the reason upward economic mobility is attributed to women.\n\n\"See: De-industrialization crisis\"\n\nAverage income for both White and Black families has increased since the 1970s. However, average income for White families in their 30s has increased from $50,000 to $60,000 from 1975 to 2005, compared to an increase from $32,000 to $35,000 for Black families of the same age over the same period. So in addition to receiving a lower average income, its growth is also less for Black families (10% growth) than their White counterparts (19% growth). One way this can be explained is that even though marriage rates have declined for both races, Blacks are 25% less likely to be in a married couple. However, Blacks also have less economic mobility and are less likely to surpass their parents’ income or economic standing than Whites. Two of three White children born into families in the middle quintile have achieved a higher family income than their parents. Conversely, only one of three Black children born into families in the middle quintile has achieved a higher family income than their parents. On average, Black children whose parents were in the bottom or second quintile do exceed their parents’ income, but those whose parents were in the middle or fourth quintile actually have a lower income than their parents. This is a very large difference compared to Whites, who experience intergenerational income growth in every quintile except the highest. This shows that in addition to lower wages with less growth over time, it is less likely for Black families to experience upward economic mobility than it is for Whites.\n\nIt is a widespread belief that there is a strong correlation between obtaining an education and increasing one’s economic mobility. In the United States, the education system has always been considered the most effective and equal process for all individuals to improve one’s economic standing. Despite the increasing availability to education for all, family background continues to play a huge role in determining economic success. To individuals who do not have or cannot obtain an education, the greater overall levels of education can act as a barrier, increasing their chance of being left behind at the bottom of the economic or income ladder. In this regard, education policy that allocates high ability students from lower social economic background to quality schools can have a large impact on economic mobility.\n\nStudies have shown that education and family background has a great effect on economic mobility across generations. Family background or one’s socioeconomic status affects the likelihood that students will graduate from high school or college, what type of college or institution they will attend, and how likely they are to graduate and complete a degree. According to studies, when split into income quintiles including the bottom, second, middle, fourth and top, adult children without a college degree and with parents in the bottom quintile remained in the bottom quintile. But if the adult children did have a college degree, there was only a 16% chance that they would remain at the bottom of the quintile. Therefore, it was proven that education provided an increase in economic status and mobility for poorer families. Not only does obtaining a college degree make it much more likely for individuals to make it to the top two quintiles, education helps those who were born in the top quintiles to remain in the top quintiles. Therefore, hard work and increasing education from those who are born into the lower quintiles can boost economic status and help them move ahead, but children born into wealthier families do seem to have the advantage. Even when the likelihood of attending college is ignored, studies have shown that out of all the students that enroll in college, socioeconomic status or family background still has an effect on graduation rates with 53% of those from the top quintile receiving bachelor's degrees along with 39% from the middle and 22% from the bottom quintile. According to the 2002 US Census, students can expect to earn on average about $2.1 million with a bachelor's degree over the course of their working career. That is almost $1 million more than what individual’s without a college degree can expect to earn.\n\nConsidering that inflation rates have not kept up with increasing tuition rates, disadvantaged families have a much harder time affording college. Especially considering the increased competition for college admittances at public schools, students from lower economic quintiles are at an even greater disadvantage. Tuition rates over the past ten years has risen 47% at public universities and 42% at private universities. While having to take out more loans and work jobs while taking classes, students from lower income quintiles are considering college to be “a test of their endurance rather than their intelligence”.\n\nBy obtaining an education, individuals with low economic status can increase the income potential and therefore earn more than their parents and possibly surpass those in the upper income quintiles. Overall, each additional level of education an individual achieves whether it be a high school, college, graduate, or professional degree can add greatly to income levels. On the other hand, there are reports that disagree with the idea that individuals can work hard, obtain an education and succeed because there is the notion that America is actually getting poorer and actually more likely to stay poor as compared to any other western country. Some claim that the idea of the “American Dream” is starting to fade since the middle-class family income has remained constant since 1973. But upward mobility clearly still exists. One study claims that economic mobility is 3 times stronger in Denmark, 2.5 times higher in Canada, and 1.5 times higher in Germany as compared to the United States.\n\nAccording to the U.S. Census Bureau, the number of legal immigrants has been rising steadily since the 1960s. The number has increased from about 320,000 to almost a million per year. About 500,000 illegal immigrants also remain in the United States each year. People immigrate to the United States in hopes of greater economic opportunities and most first generation immigrants experience a boost in their income from the American economy. But since most do not have an education, their wages quickly begin to fall relative to non-immigrants. According to studies, there is a great upward jump in economic mobility from the first to the second immigrant generation because of education. These second generation immigrants exceed the income levels of the first generation immigrants as well as some non-immigrants.\n\nThrough intergenerational mobility research, the mobility of immigrants and their children from different nations can be measured. Considering relative wages from male workers from certain nations in 1970 to second generation male workers in 2000, conclusions can be drawn about economic mobility. In 1970, if immigrants had come from an industrialized nation, then their average wages tended to be more than the average wages of non-immigrant workers during that time. In 2000, the second generation workers had experienced a downfall in relative mobility because their average wages were much closer to the average wages of a non-immigrant worker. In 1970, for the immigrant workers migrating from less industrialized countries, their average wages were less than the average wages of non-immigrant workers. In 2000, the second generation workers from less industrialized nations have experienced an increase in relative mobility because their average wages have moved closer to those of non-immigrants.\n\nBy computing the intergenerational correlation between relative wages of first and second generation workers from the same country a conclusion was made regarding whether or not first generation immigrants influence the wages of the second generation immigrants. This computation was also reported for native-born first and second generation American families. The study found that both immigrants and natives pass along almost exactly the same level of economic advantages or disadvantages to their offspring. These conclusions predict diminishing correlations in wages from the first and second generations if change in the level of education for each immigrant is considered. Since the majority of immigrants have low levels of education, it may be increasingly difficult for future second generation immigrants to ever surpass the average wages of non-immigrants.\n\n\n"}
{"id": "2009453", "url": "https://en.wikipedia.org/wiki?curid=2009453", "title": "Endoxa", "text": "Endoxa\n\nEndoxa () derives from the word \"doxa\" (δόξα, meaning \"beliefs\", \"opinions\"). Whereas Plato condemned \"doxa\" as a starting point from which to attain truth, Aristotle used the term \"endoxa\"in the sense of \"commonplace\", \"everyday\", \"consensus\"to identify a group or population's beliefs that had previously withstood debate and argument (and were, thereby, more stable than \"doxa\").\n\nExamples of Aristotle's use of \"endoxa\" may be found in the \"Topics][Book I 1 100b18 Loeb Classical Library #391 p. 273\" of the \"Organon\" and in his \"Rhetoric\". Otfried Höffe, translated by Christine Salazar, offers a detailed discussion of the topic in \"Aristotle\" (2003; ).\n\n"}
{"id": "32197396", "url": "https://en.wikipedia.org/wiki?curid=32197396", "title": "Form perception", "text": "Form perception\n\nForm perception is the recognition of visual elements of objects, specifically those to do with shapes, patterns and previously identified important characteristics. An object is perceived by the retina as a two-dimensional image, but the image can vary for the same object in terms of the context with which it is viewed, the apparent size of the object, the angle from which it is viewed, how illuminated it is, as well as where it resides in the field of vision. \nDespite the fact that each instance of observing an object leads to a unique retinal response pattern, the visual processing in the brain is capable of recognizing these experiences as analogous, allowing invariant object recognition. Visual processing occurs in a hierarchy with the lowest levels recognizing lines and contours, and slightly higher levels performing tasks such as completing boundaries and recognizing contour combinations. The highest levels integrate the perceived information to recognize an entire object. Essentially object recognition is the ability to assign labels to objects in order to categorize and identify them, thus distinguishing one object from another. During visual processing information is not created, but rather reformatted in a way that draws out the most detailed information of the stimulus.\n\nForm perception is a demanding task for the brain because a retina has a significant blind spot and retinal veins that obstruct light from reaching cells that detect light, or photoreceptor cells. The brain handles the blind spots through boundary processes, includes perceptual grouping, boundary completion, and figure-ground separation, and through surface processing, including compensation for variable illumination (“discounting the illuminant”), and filling blank areas with the surviving illuminant-discounted signals.\n\nIn addition to photoreceptors, the eye requires a properly functioning lens, retina, and an undamaged optic nerve to recognize form. Light travels through the lens, hits the retina, activates the appropriate photoreceptors, depending on available light, which convert the light into an electrical signal that travels along the optic nerve to the lateral geniculate nucleus of the thalamus and then to the primary visual cortex. In the cortex, the adult brain processes information such as lines, orientation, and color. These inputs are integrated in the occipito-temporal cortex where a representation of the object as a whole is created. Visual information continues to be processed in the posterior parietal cortex, also known as the dorsal stream, where the representation of an object’s shape is formed using motion-based cues. It is believed that simultaneously information is processed in the anterior temporal cortex, also known as the ventral stream, where object recognition, identification and naming occur. In the process of recognizing an object, both the dorsal and ventral streams are active, but the ventral stream is more important in discriminating between and recognizing objects. The dorsal stream contributes to object recognition only when two objects have similar shapes and the images are degraded. Observed latency in activation of different parts of the brain supports the idea of hierarchal processing of visual stimuli, with object representations progressing from simple to complex.\n\nBy five months of age infants are capable of using line junction information to perceive three-D images, including depth and shape, like adults are able. However, there are differences between younger infants and adults in the ability to use motion and color cues to discriminate between two objects. Visual information then continues to be processed in the posterior parietal cortex, also known as the dorsal stream, where the representation of an objects shape is formed using motion-based cues. The identification of differences between the infant and adult brain make it clear that there is either functional reorganization of the infant’s cortex or simply age related differences in which the breed impulses have been observed in infants. Although the infant brain is not identical to the adult brain, it is similar with areas of specialization and a hierarchy of processing. However, adult abilities to perceive form from stationary viewing are not fully understood.\n\nDysfunctions in distinguishing differences in sizes and shapes of objects can have many causes, including brain injury, stroke, epilepsy, and oxygen deprivation. Lesions on the brain that develop as a result of injury or illness impair object recognition. Regions that specifically lead to deficits in object recognition when a lesion is present include the right lateral fusiform gyrus and the ventrolateral occipito-temporal cortex. These areas are crucial to the processing of shape and contour information, which is the basis for object recognition. Although there is evidence to support that damage to the areas mentioned leads to deficits in object recognition, it is important to note that brain damage, regardless of the cause, typically is extensive and present on both halves of the brain, complicating the identification of key structures.[12] Although most damage cannot be undone, there is evidence of reorganization in the unaffected areas of the affected hemisphere, making it possible for patients to regain some abilities.\n\nDysfunctions in form perception occur in several areas that involve visual processing, which is how visual information is interpreted. These dysfunctions have nothing to do with actual vision but rather affect how the brain understands what the eye sees. Problems can occur in the areas of visual closure, visual-spatial relationships, visual memory, and visual tracking. After identifying the specific visual problem that exists, intervention can include eye exercises, work with computer programs, neurotherapy, physical activities, and academic adjustments.\n\nPotential injuries to the brain include but are not limited to stroke, oxygen deprivation, blunt force trauma, and surgical injuries. When patients have lesions on their brain that develop as a result of injury or illness, such as multiple sclerosis or epilepsy, it is possible that they may have impaired object recognition which can manifest in the form of many different agnosias. Similar deficits have also been observed adults that have suffered blunt force trauma, strokes, severe carbon monoxide poisoning as well as in adults that have surgical damage following removal of tumors. Deficits have also been observed in children with types of epilepsy that do not lead to the formation of lesions. It is believed that in these cases the seizures cause a functional disruption that is capable of interfering with the processing of objects. Regions that specifically lead to deficits in object recognition when a lesion is present include the right lateral fusiform gyrus and the ventrolateral or ventromedial occipito-temporal cortex. These structures have all been identified as being crucial to the processing of shape and contour information, which is the basis for object recognition. Although people with damage to these structures are not able to properly recognize objects, they are still capable of discerning the movement of objects. Only lesions in the parietal lobe have been associated with deficits in identifying the location of an object. Although there is strong evidence to support that damage to the above-mentioned areas leads to deficits in object recognition it is important to note that brain damage, regardless of the cause, is typically extensive and present on both halves of the brain, complicating the identification of key structures. Although most damage cannot be undone, there is evidence of reorganization in the unaffected areas of the affected hemisphere, making it possible for patients to regain some function.\n\nWhether or not visual form learning is retained in older humans is unknown. Studies prove that training causes improvement in form perception in both young and old adults. Learning to integrate local elements is negatively affected by age, however. Advancing age hinders the ability to process stimuli efficiently to identify objects. More specifically, recognizing the most basic visual components of an object takes a lot longer. Since the time it takes to recognize the object-parts is expanded, the recognition of the object itself is also delayed. Recognition of partially blocked objects also slows down as we age In order to recognize an object that is partially obscured we need to make perceptual inferences based on the contours and borders that we can see. This is something that most young adults are able to do, but it slows down with age. In general, aging causes a decrease in the processing capabilities of the central nervous system, which delays the very complex process of form perception.\n\n"}
{"id": "34952466", "url": "https://en.wikipedia.org/wiki?curid=34952466", "title": "Insensitivity to sample size", "text": "Insensitivity to sample size\n\nInsensitivity to sample size is a cognitive bias that occurs when people judge the probability of obtaining a sample statistic without respect to the sample size. For example, in one study subjects assigned the same probability to the likelihood of obtaining a mean height of above six feet [183 cm] in samples of 10, 100, and 1,000 men. In other words, variation is more likely in smaller samples, but people may not expect this.\n\nIn another example, Amos Tversky and Daniel Kahneman asked subjects\n\nA certain town is served by two hospitals. In the larger hospital about 45 babies are born each day, and in the smaller hospital about 15 babies are born each day. As you know, about 50% of all babies are boys. However, the exact percentage varies from day to day. Sometimes it may be higher than 50%, sometimes lower.\n\nFor a period of 1 year, each hospital recorded the days on which more than 60% of the babies born were boys. Which hospital do you think recorded more such days?\n56% of subjects chose option 3, and 22% of subjects respectively chose options 1 or 2. However, according to sampling theory the larger hospital is much more likely to report a sex ratio close to 50% on a given day than the smaller hospital which requires that the correct answer to the question is the smaller hospital (see the law of large numbers).\n\nRelative neglect of sample size were obtained in a different study of statistically sophisticated psychologists.\n\nTversky and Kahneman explained these results as being caused by the representativeness heuristic, according to which people intuitively judge samples as having similar properties to their population without taking other considerations into effect. A related bias is the clustering illusion, in which people under-expect streaks or runs in small samples. Insensitivity to sample size is a subtype of extension neglect.\n\nTo illustrate this point, Howard Wainer and Harris L. Zwerling demonstrated that kidney cancer rates are lowest in counties that are mostly rural, sparsely populated, and located in traditionally Republican states in the Midwest, the South, and the West, but that they are also \"highest\" in counties that are mostly rural, sparsely populated, and located in traditionally Republican states in the Midwest, the South, and the West. While various environmental and economic reasons could be advanced for these facts, Wainer and Zwerlig argue that this is an artifact of sample size. Because of the small sample size, the incidence of a certain kind of cancer in small rural counties is more likely to be further from the mean, in one direction or another, than the incidence of the same kind of cancer in much more heavily populated urban counties.\n"}
{"id": "35776544", "url": "https://en.wikipedia.org/wiki?curid=35776544", "title": "James McDonald (writer)", "text": "James McDonald (writer)\n\nJames McDonald British is a mathematician and non-fiction writer. He was educated at University College, Oxford. He holds an MA from Oxford University and an MSc from Sussex University in the UK, and was elected a Fellow of the Royal Geographical Society in London in 1990. He is a life member of Humanists UK.\n\nHe has travelled extensively in Central Asia and Southern Asia, researching Zoroastrianism and other religions. According to his publishers his book \"Beyond Belief\" took over 20 years of research, including an overland expedition from Europe to South and Central Asia, retracing journeys of Alexander the Great, Robert Byron and Eric Newby. This research took him to sites including Medjugorje in Herzegovina; traditional Bogomil sites in the Balkans, early Christian sites across Turkey, the Mountains of Ararat near the border with Iran, Zoroastrian Towers of Silence, Chak Chak and other Zoroastrian centres in Iran, Christian churches in Pakistan, Parsee temples in Mumbi, the Syrian Churches of Kerala, the Roza Bal shrine at Srinagar in Kashmir; Lumbini in the Rupandehi district of Nepal; early Buddhist sites along the Karakorum Highway, and historic religious sites of Tajikistan and Uzbekistan.\n\nHe writes extensively on a range of topics including Gnostic Dualism, the Cathars of the Languedoc, the Counts of Toulouse, Occitania, Medieval warfare and the Medieval Inquisition. His work is characterised by combining serious scholarship with an entertaining style. For several years he wrote a weekly column on English word origins for the Sunday Express, a national newspaper in the UK.\n\nHe is the châtelain of a late Medieval castle in the South of France, listed as a Monument Historique by the French Government.\n\n"}
{"id": "39069192", "url": "https://en.wikipedia.org/wiki?curid=39069192", "title": "Kenyan Section of the International Commission of Jurists", "text": "Kenyan Section of the International Commission of Jurists\n\nThe Kenyan Section of the International Commission of Jurists, also known as ICJ Kenya, is a Kenyan non-governmental organisation, a National Section of the International Commission of Jurists. It is composed of lawyers and works to promote human rights and the rule of law.\n\nICJ Kenya states its \"vision\" as \"to be a premier organisation promoting a just, free and equitable society\". The organisation's \"mission\" is to protect human rights, democracy and the rule of law in Kenya and across Africa through the application of legal expertise and international best practices. ICJ Kenya is guided by the following \"values\": impartiality, equity, probity, professionalism and responsiveness.\n\nICJ Kenya's objectives as guided by its constitution include; to develop, strengthen and protect the principles of the rule of law; to develop, maintain, strengthen the independence of the judiciary and the legal profession; to promote and protect the enjoyment of human rights as defined in the Universal Declaration of Human Rights, 1948 and all other subsequent international and regional covenants, treaties and protocols on the protection and promotion of human rights, by every person in Kenya; to keep under review all aspects of the rule of law and human rights with the republic of Kenya and to take such action as will be of assistance in promoting or ensuring their enjoyment; to promote the provision of legal services in rural areas,to cooperate with any national or international body, which pursues objects similar to or compatible with the aforesaid objects.\n\nICJ Kenya was founded in 1959 and registered as a society in Kenya in 1974. It has been involved in the move for constitutional change since the early 1990s. In 1994, together with the Law Society of Kenya (LSK) and the Kenya Human Rights Commission (KHRC), it drafted a model constitution for Kenya, which added to the pressure on the government of Daniel arap Moi to enact a new Constitution. In 2000, ICJ Kenya published a report on ‘The State of Freedom of Information in Kenya’, followed by a campaign for a Freedom of Information Bill. Long-term campaigning for reform of the Kenyan judiciary resulted in 2003 in the resignation of many judges and magistrates suspected of corruption and incompetence. Commentators state that the organisation has \"influenced judicial reform\" and describe it as a \"key knowledge repository\" on the subject of judicial integrity.\n\nIn 2010 the organisation sought an arrest warrant for the president of Sudan, Omar al-Bashir. The arrest warrant was issued by the Kenyan High Court in November 2011 and led to a breakdown of diplomatic relations between the two countries.\n\nIn partnership with other civil society groups in the region, ICJ Kenya published a report on \"Counterterrorism and Human Rights Abuses in Kenya and Uganda: The World Cup Bombing and Beyond\" (2012) on the response to the 2010 bombings in Kampala, and instigated a court action against the Kenyan government in 2013 on behalf of victims of sexual violence following the 2007 general elections, alleging failure to protect them or investigate the crimes committed against them.\n\nICJ Kenya is a National Section of the International Commission of Jurists whose headquarters is in Geneva. It is however autonomous from the ICJ in Geneva.\n\nICJ Kenya is a non-governmental, non-partisan, not for profit making, membership organisation registered in Kenya. ICJ Kenya operates within the general mandate for national sections defined by Article 4 of the ICJ Kenya Statute. ICJ Kenya is governed under a Constitution through an elected Council of seven members who serve for two-year fixed terms.\n\nMembers of ICJ Kenya are drawn from the various divisions of the legal profession and share the organisation's beliefs and values. The members pursue the body's work through a permanent secretariat where a professional team of full-time lawyers is in charge of programmatic activities under the oversight of the elected council.\n\nICJ Kenya works within four programmatic areas: \n\nIt is the only national section of the International Commission of Jurists on the African continent and works nationally in Kenya where, among other things, it continues to promote and protect freedom of information and judicial reforms, and also human rights awareness. Through its International Cooperation Programme, ICJ Kenya also works across Africa to support the development of effective institutions of governance and accountability.\n\nICJ Kenya is part of the World Organisation Against Torture (OMCT) SOS-Torture Network. The ICJ Kenya also holds observer status with the African Commission on Human and Peoples' Rights.\n"}
{"id": "6246985", "url": "https://en.wikipedia.org/wiki?curid=6246985", "title": "Lyrical abstraction", "text": "Lyrical abstraction\n\nLyrical abstraction is either of two related but distinct trends in Post-war Modernist painting:\n\n\"European Abstraction Lyrique\" born in Paris, the French art critic Jean José Marchand being credited with coining its name in 1947, considered as a component of (Tachisme) when the name of this movement was coined in 1951 by Pierre Guéguen and Charles Estienne the author of \"L'Art à Paris 1945–1966\", and \"American Lyrical Abstraction\" a movement described by Larry Aldrich (the founder of the Aldrich Contemporary Art Museum, Ridgefield Connecticut) in 1969. \n\nA third definition is the usage as a descriptive term. It is a descriptive term characterizing a type of abstract painting related to Abstract Expressionism; in use since the 1940s. Many well known abstract expressionist painters like Arshile Gorky seen in context have been characterized as doing a type of painting described as lyrical abstraction.\n\nThe original common use refers to the tendency attributed to paintings in Europe during the post-1945 period and as a way of describing several artists (mostly in France) with painters like Wols, Gérard Schneider and Hans Hartung from Germany or Georges Mathieu, etc., whose works related to characteristics of contemporary American abstract expressionism. At the time (late 1940s), Paul Jenkins, Norman Bluhm, Sam Francis, Jules Olitski, Joan Mitchell, Ellsworth Kelly and numerous other American artists were, as well, living and working in Paris and other European cities. With the exception of Kelly, all of those artists developed their versions of painterly abstraction that has been characterized at times as lyrical abstraction, tachisme, color field, Nuagisme and abstract expressionism.\n\nThe art movement \"Abstraction lyrique\" was born in Paris after the war. At that time, the artistic life in Paris, which had been devastated by the Occupation and Collaboration, resumed with numerous artists exhibited again as soon as the Liberation of Paris in mid-1944. According to the new abstraction forms that characterised some artists, the movement was named by the art critic, Jean José Marchand, and the painter, Georges Mathieu, in 1947. Some art critics also looked at this movement as an attempt to restore the image of artistic Paris, which had held the rank of capital of the arts until the war. Lyrical abstraction also represented a competition between the School of Paris and the new New York School of Abstract Expressionism painting represented above all since 1946 by Jackson Pollock, then Willem de Kooning or Mark Rothko, which were also promoted by the American authorities from the early 1950s.\n\nLyrical abstraction was opposed not only to the Cubist and Surrealist movements that preceded it, but also to geometric abstraction (or \"cold abstraction\"). Lyrical abstraction was, in some ways, the first to apply the lessons of Wassily Kandinsky, considered one of the fathers of abstraction. For the artists, lyrical abstraction represented an opening to personal expression.\n\nFinally, in the late 1960s (partially as a response to minimal art, and the dogmatic interpretations by some to Greenbergian and Juddian formalism), many painters re-introduced painterly options into their works and the Whitney Museum and several other museums and institutions at the time formally named and identified the movement and uncompromising return to painterly abstraction as 'lyrical abstraction'.\n\nJust after World War II, many artists old and young were back in Paris where they worked and exhibited: Nicolas de Staël, Serge Poliakoff, André Lanskoy and Zaks from Russia; Hans Hartung and Wols from Germany; Árpád Szenes, Endre Rozsda and Simon Hantaï from Hungary; Alexandre Istrati from Romania; Jean-Paul Riopelle from Canada; Vieira da Silva from Portugal; Gérard Ernest Schneider from Switzerland; Feito from Spain; Bram van Velde from the Netherlands; Albert Bitran from Turkey; Zao Wou-Ki from China; Sugai from Japan; Sam Francis, John Franklin Koenig, Jack Youngerman and Paul Jenkins from the U.S.A.\n\nAll these artists and many others were at that time among the \"Lyrical Abstractionists\" with the French: Georges Mathieu, Pierre Soulages, Nallard, Jean René Bazaine, Jacques Doucet, Camille Bryen, Jean Le Moal, Gustave Singier, Alfred Manessier, Roger Bissière, Pierre Tal-Coat, Jean Messagier and others.\n\nLyrical Abstraction was opposed not only to \"l’Ecole de Paris\" remains of pre-war style but to Cubist and Surrealist movements that had preceded it, and also to geometric abstraction (or \"Cold Abstraction\"). For the artists in France, Lyrical Abstraction represented an opening to personal expression. In Belgium, Louis Van Lint figured a remarkable example of an artist who, after a short period of geometric abstraction, has moved to a lyrical abstraction in which he excelled.\n\nMany exhibitions were held in Paris for example in the galleries Arnaud, Drouin, Jeanne Bucher, Louis Carré, Galerie de France, and every year at the \"Salon des Réalités Nouvelles\" and \"Salon de Mai\" where the paintings of all these artists could be seen. At the Drouin gallery one could see Jean Le Moal, Gustave Singier, Alfred Manessier, Roger Bissière, Wols and others. A wind blew over the capital when Georges Mathieu decided to hold two exhibitions: \"L'Imaginaire\" in 1947 at the Palais du Luxembourg which he would have prefer to call \"abstraction lyrique\" to impose the name and then \"HWPSMTB\" with (Hans Hartung, Wols, Francis Picabia, François Stahly sculptor, Georges Mathieu, Michel Tapié and Camille Bryen) in 1948.\nIn March 1951 was held the larger exhibition \"Véhémences confrontées\" in the gallery Nina Dausset where for the first time were presented side to side French and American abstract artists. It was organised by the critic Michel Tapié, whose role in the defense of this movement was of the highest importance. With these events, he déclared that « the lyrical abstraction is born ».\n\nIt was, however, a fairly short reign (late 1957), which was quickly supplanted by the New Realism of Pierre Restany and Yves Klein.\n\nStarting around 1970, this movement has been revived by a new generation of artists born during or immediately after the Second World War. Some of its key promoters include Paul Kallos, Georges Romathier, Michelle Desterac, and Thibaut de Reimpré.\n\nAn exhibition entitled \"The Lyrical Flight, Paris 1945–1956\" (\"L'Envolée Lyrique, Paris 1945–1956\"), bringing together the works of 60 painters, was presented in Paris at the Musée du Luxembourg from April to August 2006 and included the most prominent painters of the movement: Georges Mathieu, Pierre Soulages, Gérard Schneider, Zao Wou-Ki, Albert Bitran, Serge Poliakoff.\n\n\n\nAmerican Lyrical Abstraction is an art movement that emerged in New York City, Los Angeles, Washington, DC, and then Toronto and London during the 1960s–1970s. Characterized by intuitive and loose paint handling, spontaneous expression, illusionist space, acrylic staining, process, occasional imagery, and other painterly and newer technological techniques. Lyrical Abstraction led the way away from minimalism in painting and toward a new freer expressionism. Painters who directly reacted against the predominating Formalist, Minimalist, and Pop Art and geometric abstraction styles of the 1960s, turned to new, experimental, loose, painterly, expressive, pictorial and abstract painting styles. Many of them had been Minimalists, working with various monochromatic, geometric styles, and whose paintings publicly evolved into new abstract painterly motifs. American Lyrical Abstraction is related in spirit to Abstract Expressionism, Color Field painting and European Tachisme of the 1940s and 1950s as well. Tachisme refers to the French style of abstract painting current in the 1945–1960 period. Very close to Art Informel, it presents the European equivalent to Abstract Expressionism.\n\nThe Sheldon Museum of Art held an exhibition from 1 June until 29 August 1993 entitled \"Lyrical Abstraction: Color and Mood\". Some of the participants included Dan Christensen, Walter Darby Bannard, Ronald Davis, Helen Frankenthaler, Sam Francis, Cleve Gray, Ronnie Landfield, Morris Louis, Jules Olitski, Robert Natkin, William Pettet, Mark Rothko, Lawrence Stafford, Peter Young and several other painters. At the time the museum issued a statement the read in part:\n\n\"As a movement, Lyrical Abstraction extended the post-war Modernist aesthetic and provided a new dimension within the abstract tradition which was clearly indebted to Jackson Pollock's \"dripped painting\" and Mark Rothko's stained, color forms. This movement was born out of a desire to create a direct physical and sensory experience of painting through their monumentality and emphasis on color – forcing the viewer to \"read\" paintings literally as things.\"\n\nDuring 2009 the Boca Raton Museum of Art in Florida hosted an exhibition entitled \"Expanding Boundaries: Lyrical Abstraction Selections from the Permanent Collection\"\n\nAt the time the museum issued a statement that said in part:\n\n\"Lyrical Abstraction arose in the 1960s and 70s, following the challenge of Minimalism and Conceptual art. Many artists began moving away from geometric, hard-edge, and minimal styles, toward more lyrical, sensuous, romantic abstractions worked in a loose gestural style. These \"lyrical abstractionists\" sought to expand the boundaries of abstract painting, and to revive and reinvigorate a painterly 'tradition' in American art. At the same time, these artists sought to reinstate the primacy of line and color as formal elements in works composed according to aesthetic principles – rather than as the visual representation of sociopolitical realities or philosophical theories.\"\n\n\"Characterized by intuitive and loose paint handling, spontaneous expression, illusionist space, acrylic staining, process, occasional imagery, and other painterly techniques, the abstract works included in this exhibition sing with rich fluid color and quiet energy. Works by the following artists associated with Lyrical Abstraction will be included: Natvar Bhavsar, Stanley Boxer, Lamar Briggs, Dan Christensen, David Diao, Friedel Dzubas, Sam Francis, Dorothy Gillespie, Cleve Gray, Paul Jenkins, Ronnie Landfield, Pat Lipsky, Joan Mitchell, Robert Natkin, Jules Olitski, Larry Poons, Garry Rich, John Seery, Jeff Way and Larry Zox.\" \n\nLyrical Abstraction, an exhibition in the Whitney Museum of American Art, May 25–July 6, 1971 was described by John I. H. Baur, curator of the Whitney Museum of American Art: \n\nLyrical Abstraction was the title of a circulating exhibition which commenced at the Aldrich Contemporary Art Museum, Ridgefield, Connecticut from April 5 through June 7, 1970, and ended at the Whitney Museum of American Art, New York, May 25 through July 6, 1971. Lyrical Abstraction is a term that was used by Larry Aldrich (the founder of the Aldrich Contemporary Art Museum, Ridgefield Connecticut) in 1969 to describe what Aldrich said he saw in the studios of many artists at that time. Mr. Aldrich, a successful designer and art collector, defined the trend of Lyrical Abstraction and explained how he came to acquire the works. In his \"Statement of the Exhibition\" he wrote, \"Early last season, it became apparent that in painting there was a movement away from the geometric, hard-edge, and minimal, toward more lyrical, sensuous, romantic abstractions in colors which were softer and more vibrant…The artist's touch is always visible in this type of painting, even when the paintings are done with spray guns, sponges or other objects...As I researched this lyrical trend, I found many young artists whose paintings appealed to me so much that I was impelled to acquire many of them. The majority of the paintings in the \"Lyrical Abstraction\" exhibition were created in 1969 and all are a part of my collection now.\" Larry Aldrich donated the paintings from the exhibition to the Whitney Museum of American Art.\n\nFor many years the term Lyrical Abstraction was a pejorative, which unfortunately adversely affected those artists whose works were associated with that name. In 1989 Union College art history professor, the late Daniel Robbins observed that Lyrical Abstraction was the term used in the late sixties to describe the return to painterly expressivity by painters all over the country and \"consequently\", Robbins said, \"the term should be used today because it has historical credibility\"\n\nThe following artists participated in the exhibition \"Lyrical Abstraction\".\n\n\n\nLyrical Abstraction along with the Fluxus movement and Postminimalism (a term first coined by Robert Pincus-Witten in the pages of Artforum in 1969) sought to expand the boundaries of abstract painting and Minimalism by focusing on process, new materials and new ways of expression. Postminimalism often incorporating industrial materials, raw materials, fabrications, found objects, installation, serial repetition, and often with references to Dada and Surrealism is best exemplified in the sculptures of Eva Hesse. Lyrical Abstraction, Conceptual Art, Postminimalism, Earth Art, Video, Performance art, Installation art, along with the continuation of Fluxus, Abstract Expressionism, Color Field Painting, Hard-edge painting, Minimal Art, Op art, Pop Art, Photorealism and New Realism extended the boundaries of Contemporary Art in the mid-1960s through the 1970s. Lyrical Abstraction is a type of freewheeling abstract painting that emerged in the mid-1960s when abstract painters returned to various forms of painterly, pictorial, expressionism with a predominate focus on process, gestalt and repetitive compositional strategies in general. Characterized by an overall gestalt, consistent surface tension, sometimes even the hiding of brushstrokes, and an overt avoidance of relational composition. It developed as did Postminimalism as an alternative to strict Formalist and Minimalist doctrine. \n\nLyrical Abstraction shares similarities with Color Field Painting and Abstract Expressionism especially in the freewheeling usage of paint – texture and surface, an example is illustrated by the painting by Ronnie Landfield entitled \"For William Blake\". Direct drawing, calligraphic use of line, the effects of brushed, splattered, stained, squeegeed, poured, and splashed paint superficially resemble the effects seen in Abstract Expressionism and Color Field Painting. However the styles are markedly different. Setting it apart from Abstract Expressionism and Action Painting of the 1940s and 1950s is the approach to composition and drama. As seen in Action Painting there is an emphasis on brushstrokes, high compositional drama, dynamic compositional tension. While in Lyrical Abstraction there is a sense of compositional randomness, all over composition, low key and relaxed compositional drama and an emphasis on process, repetition, and an all over sensibility. The differences with Color Field Painting are more subtle today because many of the Color Field painters like Helen Frankenthaler, Jules Olitski, Sam Francis, and Jack Bush with the exceptions of Morris Louis, Ellsworth Kelly, Paul Feeley, Thomas Downing, and Gene Davis evolved into Lyrical Abstractionists. Lyrical Abstraction shares with both Abstract Expressionism and Color Field Painting a sense of spontaneous and immediate sensual expression, consequently distinctions between specific artists and their styles become blurred, and seemingly interchangeable as they evolve.\n\nBy the mid-1950s, Richard Diebenkorn abandoned abstract expressionism and along with David Park, Elmer Bischoff and several others formed the Bay Area Figurative School with a return to Figurative painting. During the period between the fall 1964 and the spring of 1965 Diebenkorn traveled throughout Europe, he was granted a cultural visa to visit and view Henri Matisse paintings in important Soviet museums. He traveled to the then Soviet Union to study Henri Matisse paintings in Russian museums that were rarely seen outside of Russia. When he returned to painting in the Bay Area in mid-1965 his resulting works summed up all that he had learned from his more than a decade as a leading figurative painter. When in 1967 he returned to abstraction his works were parallel to movements like the Color Field movement and Lyrical Abstraction.\n\nIn the 1960s, English painter John Hoyland's Color field paintings were characterised by simple rectangular shapes, high-key color and a flat picture surface. In the 1970s his paintings became more textured. During the 1960s and 1970s, he showed his paintings in New York City with the Robert Elkon Gallery and the André Emmerich Gallery. His paintings were closely aligned with Post-Painterly Abstraction, Color Field painting and Lyrical Abstraction.\n\nAbstract Expressionism preceded Color Field painting, Lyrical Abstraction, Fluxus, Pop Art, Minimalism, Postminimalism, and the other movements of the 1960s and 1970s and it influenced the later movements that evolved. The interrelationship of/and between distinct but related styles resulted in influence that worked both ways between artists young and old, and vice versa. During the mid-1960s in New York, Los Angeles and elsewhere artists often crossed the lines between definitions and art styles. During that period – the mid-1960s through the 1970s advanced American art and contemporary art in general was at a crossroad, shattering in several directions. During the 1970s political movements and revolutionary changes in communication made these American styles international; as the art world itself became more and more international. American Lyrical Abstraction's European counterpart Neo-expressionism came to dominate the 1980s, and also developed as a response to American Pop Art and Minimalism and borrows heavily from American Abstract Expressionism.\n\nThis is a list of artists, whose work or a period or significant aspects of it, has been seen as lyrical abstraction, including those before the identification of the term or tendency in America in the 1960s.\n\n\n\n"}
{"id": "86593", "url": "https://en.wikipedia.org/wiki?curid=86593", "title": "Mag Mell", "text": "Mag Mell\n\nIn Irish mythology, Mag Mell (modern spelling: Magh Meall, meaning \"plain of joy\") was a mythical realm achievable through death and/or glory. Unlike the underworld in some mythologies, Mag Mell was a pleasurable paradise, identified as either an island far to the west of Ireland or a kingdom beneath the ocean. However, Mag Mell was similar to the fields of Elysium in Greek mythology, and like the fields of Elysium, was accessible only to a select few. Furthermore, Mag Mell, like the numerous other mystical islands said to be off the coast of Ireland, was never explicitly stated in any surviving mythological account to be an afterlife. Rather, it is usually portrayed as a paradisal location populated by deities, which is occasionally visited by some adventurous mortals. In its island guise it was visited by various Irish heroes and monks forming the basis of the Adventure Myth or \"echtrae\" as defined by Myles Dillon in his book \"Early Irish Literature\". This otherworld is a place where sickness and death do not exist. It is a place of eternal youth and beauty. Here, music, strength, life and all pleasurable pursuits come together in a single place. Here happiness lasts forever, no one wants for food or drink. It is the Irish equivalent of the Greek Elysium or the Valhalla of the Norse.\n\nLegends say its ruler is the Fomorian King Tethra, or more frequently Manannan mac Lir. Mag Mell's allure extended from the pagan era to Christian times. In later stories, the realm is less an afterlife destination than an Earthly Paradise which adventurers could reach by traveling west from Ireland, often blown off course by providential tempests while on an inspired mission. They typically explore many other fantastic islands before reaching their destination and returning home (or sailing on). Among these voyagers are St. Brendan, Bran mac Febal (see \"The Voyage of Bran\"), and Mael Dúin.\n\n\n"}
{"id": "27534624", "url": "https://en.wikipedia.org/wiki?curid=27534624", "title": "Man date", "text": "Man date\n\n\"Not to be confused with Mandate (disambiguation).\"\nMan date is a neologism of the 2000s that is used to describe a social situation where two men spend time together one-on-one. The men may be any mix of heterosexual and homosexual. However, \"man date\" refers to a platonic social encounter, not sexual implied or actual. The term was first spread by a \"New York Times\" article by Jennifer 8. Lee published in 2005, and was the basis for the 2009 film \"I Love You, Man\".\n\nAs \"The New York Times\" article defined: \nAlong with \"metrosexual\" and \"bromance\", the term is part of a growing set of neologisms that address modern-day masculinity.\n\nThe term was first brought to popular attention by an April 10, 2005 article in \"The New York Times\" Sunday Style section.\n\nAside from the 2009 film \"I Love You, Man\", man dates have appeared in popular culture, including in a season 3 episode of \"Scrubs\" in 2003 called \"My Journey\", in a Season 7 episode of \"The Gilmore Girls\" called \"Knit, People, Knit!\" and a Season 4 episode of \"Rescue Me\".\n\n"}
{"id": "4003593", "url": "https://en.wikipedia.org/wiki?curid=4003593", "title": "Negative volume index", "text": "Negative volume index\n\nNearly 78 years have passed since Paul L. Dysart, Jr. invented the Negative Volume Index and Positive Volume Index indicators. The indicators remain useful to identify primary market trends and reversals.\n\nIn 1936, Paul L. Dysart, Jr. began accumulating two series of advances and declines distinguished by whether volume was greater or lesser than the prior day's volume. He called the cumulative series for the days when volume had been greater than the prior day's volume the Positive Volume Index (PVI), and the series for the days when volume had been lesser the Negative Volume Index (NVI).\n\nA native of Iowa, Dysart worked in Chicago's LaSalle Street during the 1920s. After giving up his Chicago Board of Trade membership, he published an advisory letter geared to short-term trading using advance-decline data. In 1933, he launched the \"Trendway\" weekly stock market letter and published it until 1969 when he died. Dysart also developed the 25-day Plurality Index, the 25-day total of the absolute difference between the number of advancing issues and the number of declining issues, and was a pioneer in using several types of volume of trading studies. Richard Russell, editor of Dow Theory Letters, in his January 7, 1976 letter called Dysart \"one of the most brilliant of the pioneer market technicians.\"\n\nThe daily volume of the New York Stock Exchange and the NYSE Composite Index's advances and declines drove Dysart's indicators. Dysart believed that “volume is the driving force in the market.” He began studying market breadth numbers in 1931, and was familiar with the work of Leonard P. Ayres and James F. Hughes, who pioneered the tabulation of advances and declines to interpret stock market movements.\n\nDysart calculated NVI as follows: 1) if today's volume is less than yesterday's volume, subtract declines from advances, 2) add the difference to the cumulative NVI beginning at zero, and 3) retain the current NVI reading for the days when volume is greater than the prior day's volume. He calculated PVI in the same manner but for the days when volume was greater than the prior day's volume. NVI and PVI can be calculated daily or weekly.\n\nInitially, Dysart believed that PVI would be the more useful series, but in 1967, he wrote that NVI had “proved to be the most valuable of all the breadth indexes.” He relied most on NVI, naming it AMOMET, the acronym of “A Measure Of Major Economic Trend.”\n\nDysart's theory, expressed in his 1967 Barron's article, was that “if volume advances and prices move up or down in accordance [with volume], the move is assumed to be a good movement - if it is sustained when the volume subsides.” In other words, after prices have moved up on positive volume days, \"if prices stay up when the volume subsides for a number of days, we can say that such a move is 'good'.\" If the market “holds its own on negative volume days after advancing on positive volume, the market is in a strong position.”\n\nHe called PVI the “majority” curve. Dysart distinguished between the actions of the “majority” and those of the “minority.” The majority tends to emulate the minority, but its timing is not as sharp as that of the minority. When the majority showed an appetite for stocks, the PVI was usually “into new high ground” as happened in 1961.\n\nIt is said that the two indicators assume that \"smart\" money is traded on quiet days (low volume) and that the crowd trades on very active days. Therefore, the negative volume index picks out days when the volume is lower than on the previous day, and the positive index picks out days with a higher volume.\n\nBesides an article he wrote for Barron's in 1967, not many of Dysart's writings are available. What can be interpreted about Dysart's NVI is that whenever it rises above a prior high, and the DJIA is trending up, a “Bull Market Signal” is given. When the NVI falls below a prior low, and the DJIA is trending down, a “Bear Market Signal” is given. The PVI is interpreted in reverse.\nHowever, not all movements above or below a prior NVI or PVI level generate signals, as Dysart also designated “bullish” and “bearish penetrations.” These penetrations could occur before or after a Bull or Bear Market Signal, and at times were called “reaffirmations” of a signal. In 1969, he articulated one rule: “signals are most authentic when the NVI has moved sideways for a number of months in a relatively narrow range.” Dysart cautioned that “there is no mathematical system devoid of judgment which will continuously work without error in the stock market.”\n\nAccording to Dysart, between 1946 and 1967, the NVI “rendered 17 significant signals,” of which 14 proved to be right (an average of 4.32% from the final high or low) and 3 wrong (average loss of 6.33%). However, NVI “seriously erred” in 1963-1964 and in 1968, which concerned him. In 1969, Dysart reduced the weight he had previously given to the NVI in his analyses because NVI was no longer a “decisive” indicator of the primary trend, although it retained an “excellent ability to give us ‘leading’ indications of short-term trend reversals.”\n\nA probable reason for the NVI losing its efficacy during the mid-1960s may have been the steadily higher NYSE daily volume due to the dramatic increase in the number of issues traded so that prices rose on declining volume. Dysart’s NVI topped out in 1955 and trended down until at least 1968, although the DJIA moved higher during that period.\nNorman G. Fosback has attributed the “long term increase in the number of issues traded” as a reason for a downward bias in a cumulative advance-decline line. Fosback was the next influential technician in the story of NVI and PVI.\n\nFosback studied NVI and PVI and in 1976 reported his findings in his classic Stock Market Logic. He did not elucidate on the indicators’ background or mentioned Dysart except for saying that “in the past Negative Volume Indexes have always [his emphasis] been constructed using advance-decline data….” He posited, “There is no good reason for this fixation on the A/D Line. In truth, a Negative Volume Index can be calculated with any market index - the Dow Jones Industrial Average, the S&P 500, or even ‘unweighted’ market measures... Somehow this point has escaped the attention of technicians to date.”\n\nThe point had not been lost on Dysart, who wrote in Barron’s, “we prefer to use the issues-traded data [advances and declines] rather than the price data of any average because it is more all-encompassing, and more truly represents what’s happening in the entire market.” Dysart was a staunch proponent of using advances and declines.\n\nFosback made three variations to NVI and PVI:\n\n1. He cumulated the daily percent change in the market index rather than the difference between advances and declines. On negative volume days, he calculated the price change in the index from the prior day and added it to the most recent NVI. His calculations are as follows:\n\nIf C and C denote the closing prices of today and yesterday, respectively, the NVI for today is calculated by\n\n\nand the PVI is calculated by:\n\n\n2. He suggested starting the cumulative count at a base index level such as 100.\n\n3. He derived buy or sell signals by whether the NVI or PVI was above or below its one-year moving average.\n\nFosback's versions of NVI and PVI are what are popularly described in books and posted on Internet financial sites. Often reported are his findings that whenever NVI is above its one-year moving average there is a 96% (PVI - 79%) probability that a bull market is in progress, and when it is below its one-year moving average, there is a 53% (PVI - 67%) probability that a bear market is in place. These results were derived using a 1941-1975 test period. Modern tests might reveal different probabilities.\n\nToday, NVI and PVI are commonly associated with Fosback's versions, and Dysart, their inventor, is forgotten. It cannot be said that one version is better than the other. While Fosback provided a more objective interpretation of these indicators, Dysart's versions offer value to identify primary trends and short-term trend reversals.\n\nAlthough some traders use Fosback's NVI and PVI to analyze individual stocks, the indicators were created to track, and have been tested, on major market indexes. NVI was Dysart's most invaluable breadth index, and Fosback found that his version of “the Negative Volume Index is an excellent indicator of the primary market trend.” Traders can benefit from both innovations.\n\n"}
{"id": "22197", "url": "https://en.wikipedia.org/wiki?curid=22197", "title": "Open content", "text": "Open content\n\nOpen content is a neologism coined by David Wiley in 1998 which describes a creative work that others can copy or modify freely, without asking for permission. The term evokes the related concept of open-source software. Such content is said to be under an open licence.\n\nOriginally, the Open content concept was invented by Michael Stutz, who in 1994 wrote the paper \"Applying Copyleft to Non-Software Information\" for the GNU Project. The \"Open Content\" term was later evangelized via the \"Open Content Project\" by David A. Wiley in 1998, and described works licensed under the Open Content License (a non-free share-alike license, see 'Free content' below) and other works licensed under similar terms.\n\nIt has since come to describe a broader class of content without conventional copyright restrictions. The openness of content can be assessed under the '5Rs Framework' based on the extent to which it can be reused, revised, remixed and redistributed by members of the public without violating copyright law. Unlike free content and content under open-source licenses, there is no clear threshold that a work must reach to qualify as 'open content'.\n\nAlthough open content has been described as a counterbalance to copyright, open content licenses rely on a copyright holder's power to license their work, similarly as copyleft which also utilizes copyright for such a purpose.\n\nIn 2003 Wiley announced that the Open Content Project has been succeeded by Creative Commons and their licenses, where he joined as \"Director of Educational Licenses\".\n\nIn 2006 the Creative Commons' successor project was the \"Definition of Free Cultural Works\" for free content, put forth by Erik Möller, Richard Stallman, Lawrence Lessig, Benjamin Mako Hill, Angela Beesley, and others. The \"Definition of Free Cultural Works\" is used by the Wikimedia Foundation. In 2008, the Attribution and Attribution-ShareAlike Creative Commons licenses were marked as \"Approved for Free Cultural Works\" among other licenses.\nAnother successor project is the \"Open Knowledge Foundation\" (\"OKF\"), founded by Rufus Pollock in Cambridge, UK in 2004 as a global non-profit network to promote and share open content and data. In 2007 the Open Knowledge Foundation gave an \"Open Knowledge Definition\" for \"Content such as music, films, books; Data be it scientific, historical, geographic or otherwise; Government and other administrative information\". In October 2014 with version 2.0 \"Open Works\" and \"Open Licenses\" were defined and \"open\" is described as synonymous to the definitions of open/free in the Open Source Definition, the Free Software Definition and the Definition of Free Cultural Works. A distinct difference is the focus given to the public domain and that it focuses also on the accessibility (\"open access\") and the readability (\"open formats\"). Among several conformant licenses, six are recommended, three own (Open Data Commons Public Domain Dedication and Licence (PDDL), Open Data Commons Attribution License (ODC-BY), Open Data Commons Open Database License (ODbL)) and the CC BY, CC BY-SA, and CC0 creative commons licenses.\n\nThe OpenContent website once defined OpenContent as 'freely available for modification, use and redistribution under a license similar to those used by the open-source / free software community'. However, such a definition would exclude the Open Content License (OPL) because that license forbade charging 'a fee for the [OpenContent] itself', a right required by free and open-source software licenses.\n\nThe term since shifted in meaning. OpenContent \"is licensed in a manner that provides users with free and perpetual permission to engage in the 5R activities.\"\n\nThe 5Rs are put forward on the OpenContent website as a framework for assessing the extent to which content is open:\n\nThis broader definition distinguishes open content from open-source software, since the latter must be available for commercial use by the public. However, it is similar to several definitions for open educational resources, which include resources under noncommercial and verbatim licenses.\n\nThe later \"Open Definition\" by the Open Knowledge Foundation (now known as Open Knowledge International) define open knowledge with open content and open data as sub-elements and draws heavily on the Open Source Definition; it preserves the limited sense of open content as free content, unifying both.\n\n\"Open access\" refers to toll-free or gratis access to content, mainly published originally peer-reviewed scholarly journals. Some open access works are also licensed for reuse and redistribution (\"libre open access\"), which would qualify them as open content.\n\nOver the past decade, open content has been used to develop alternative routes towards higher education. Traditional universities are expensive, and their tuition rates are increasing. Open content allows a free way of obtaining higher education that is \"focused on collective knowledge and the sharing and reuse of learning and scholarly content.\"\nThere are multiple projects and organizations that promote learning through open content, including OpenCourseWare Initiative, The Saylor Foundation and Khan Academy. Some universities, like MIT, Yale, and Tufts are making their courses freely available on the internet.\n\nThe textbook industry is one of the educational industries in which open content can make the biggest impact. Traditional textbooks, aside from being expensive, can also be inconvenient and out of date, because of publishers' tendency to constantly print new editions. Open textbooks help to eliminate this problem, because they are online and thus easily updatable. Being openly licensed and online can be helpful to teachers, because it allows the textbook to be modified according to the teacher's unique curriculum. There are multiple organizations promoting the creation of openly licensed textbooks. Some of these organizations and projects include The University of Minnesota's Open Textbook Library, Connexions, OpenStax College, The Saylor Foundation Open Textbook Challenge and Wikibooks\n\nAccording to the current definition of open content on the OpenContent website, any general, royalty-free copyright license would qualify as an open license because it 'provides users with the right to make more kinds of uses than those normally permitted under the law. These permissions are granted to users free of charge.'\n\nHowever, the narrower definition used in the Open Definition effectively limits open content to libre content, any free content license, defined by the Definition of Free Cultural Works, would qualify as an open content license. According to this narrower criteria, the following still-maintained licenses qualify:\n\n(For more licenses see Open Knowledge, Free content and Free Cultural Works licenses)\n\n\n"}
{"id": "14936276", "url": "https://en.wikipedia.org/wiki?curid=14936276", "title": "Orderliness", "text": "Orderliness\n\nOrderliness is associated with other qualities such as cleanliness and diligence, and the desire for order and symmetry, and is generally considered to be a desirable quality. \n\nIn psychology, an excessive desire for orderliness can be associated with obsessive–compulsive disorder and the term \"anal retentive\", (or simply \"anal\")—from Freudian psychoanalysis—is used conversationally to describe a person with such attention to orderliness and detail that it becomes close to a mental disorder. On the other side, excessive disorderliness may be associated with a tendency to hoard, to collect objects compulsively (compulsive hoarding).\n\nProfessional organizing services support individuals and organizations find ways to achieve and maintain ways to be organized, including decluttering and maintaining an orderly environment.\n\n"}
{"id": "3272262", "url": "https://en.wikipedia.org/wiki?curid=3272262", "title": "Package diagram", "text": "Package diagram\n\nA package diagram in the Unified Modeling Language depicts the dependencies between the packages that make up a model.\n\nIn addition to the standard UML Dependency relationship, there are two special types of dependencies defined between packages:\n\nA \"package import\" is \"a relationship between an importing namespace and a package, indicating that the importing namespace adds the names of the members of the package to its own namespace.\" \nBy default, an unlabeled dependency between two packages is interpreted as a package import relationship.\nIn this relationship, elements within the target package will be imported into the source package.\n\nA \"package merge\" is \"a directed relationship between two packages, that indicates that the contents of the two packages are to be combined. It is very similar to Generalisation in the sense that the source element conceptually adds the characteristics of the target element to its own characteristics resulting in an element that combines the characteristics of both\"\nIn this relationship, if an element exists within both the source package and the target package, then the source element's definition will be expanded to include the target element's definition.\n\nPackage diagrams can use packages containing use cases to illustrate the functionality of a software system.\n\nPackage diagrams can use packages that represent the different layers of a software system to illustrate the layered architecture of a software system. The dependencies between these packages can be adorned with labels / stereotypes to indicate the communication mechanism between the layers.\n\n\n"}
{"id": "1057123", "url": "https://en.wikipedia.org/wiki?curid=1057123", "title": "Peaceful coexistence", "text": "Peaceful coexistence\n\nPeaceful coexistence () was a theory developed and applied by the Soviet Union at various points during the Cold War in the context of primarily Marxist–Leninist foreign policy and was adopted by Soviet-allied socialist states that they could peacefully coexist with the capitalist bloc (i.e., U.S.-allied states). This was in contrast to the antagonistic contradiction principle that socialism and capitalism could never coexist in peace. The Soviet Union applied it to relations between the western world, particularly between the United States and NATO countries and the nations of the Warsaw Pact.\n\nDebates over differing interpretations of peaceful coexistence were one aspect of the Sino-Soviet split in the 1950s and 1960s. During the 1960s and early 1970s, the People's Republic of China under the leadership of its founder, Mao Zedong, argued that a belligerent attitude should be maintained towards capitalist countries, and so initially rejected the peaceful coexistence theory as essentially Marxist revisionism.\n\nHowever, their decision in 1972 to establish a trade relationship with the United States also saw China cautiously adopting a version of the theory to relations between itself and non-socialist countries. From that point through to the early 1980s and Socialism with Chinese characteristics, China increasingly extended its own peaceful coexistence concept to include all nations. Enver Hoxha also denounced this and turned against China as a result of China growing closer ties to the West such as 1972 Nixon visit to China and today Hoxhaist parties continue to denounce the concept of peaceful coexistence.\n\nPeaceful coexistence, in extending itself to all countries and social movements tied to the USSR's interpretation of communism, quickly became modus operandi for many individual communist parties as well, encouraging quite a few, especially those in the developed world, to give up their long-term goal of amassing support for an armed, insurrectionist communist revolution and exchange it for more full participation in electoral politics.\n\nKhrushchev solidified the concept in Soviet foreign policy in 1956 at the 20th Congress of the Communist Party of the Soviet Union. The policy arose as a temptation to reduce hostility between the two superpowers, particularly in light of the possibility of nuclear war. The Soviet theory of peaceful coexistence asserted that the United States and USSR, and their respective political ideologies, could coexist rather than fighting one another, and Khrushchev tried to demonstrate his commitment to peaceful coexistence by attending international peace conferences, such as the Geneva Summit, and by traveling internationally, such as his trip to America's Camp David in 1959. The World Peace Council founded in 1949 and largely funded by the Soviet Union attempted to organize a peace movement in favor of the concept internationally.\n\nPeaceful coexistence was meant to assuage Western, capitalist concerns that the socialist Soviet Union was driven by the concept of world revolution advocated by its founders, Vladimir Lenin and the Bolsheviks. Lenin and the Bolsheviks advocated world revolution through workers' \"internal revolutions\" within their own nations, but they had never advocated its spread by intra-national warfare, such as invasion by Red Army troops from a neighboring socialist nation into a capitalist one.\n\nIndeed, short of such \"internal revolutions\" by workers themselves, Lenin had talked about \"peaceful cohabitation\" with capitalist countries. Khrushchev used this aspect of Lenin's politics to argue that while socialism would eventually triumph over capitalism, this would be done not by force but by example. Implicitly, this proclamation meant the end of the USSR's advocacy of the spread of communist revolution through insurrectionist violence, which some communists around the world saw as a betrayal of the principles of revolutionary communism itself.\n\nIn addition to being a reaction to the realization that a nuclear war between the two superpowers would ensure the destruction of not only the socialist system but the entirety of humanity, it also reflected the USSR's strategic military disposition - the move away from large, and possibly politically offensive, military ventures towards a force centered on proxy wars and a strategic nuclear missile force. Although disquiet over this shift helped bring Khrushchev down, his successors did not return to the antagonistic contradiction theories of an inevitable conflict between the capitalist and socialist systems. Initially, this was China's main gripe with the theory, and the reason the latter from then on classified the Soviet Union as a \"betrayer of the Revolution.\"\n\nOne of the most outspoken critics of peaceful coexistence during the early 1960s was Argentine Marxist revolutionary Che Guevara. As a leader in the Cuban government during the October Missile Crisis, Guevara believed that a repeat invasion by the United States (after the Bay of Pigs) would be justifiable grounds for a nuclear war. In Guevara's view, the capitalist bloc was composed of \"hyenas and jackals\" that \"fed on unarmed peoples\".\n\nPremier Zhou Enlai of the People's Republic of China proposed the Five Principles of Peaceful Coexistence in 1954 during negotiations with India over Tibet and these were written into the \"Agreement Between the People's Republic of China and the Republic of India on Trade and Intercourse Between the Tibet Region of China and India\" signed in 1954 by Zhou and Prime Minister of India Jawaharlal Nehru. The principles were reiterated by Zhou at the Bandung Conference of Asian and African countries where they were incorporated into the conference declarations. One major consequence of this policy was that the PRC would not support Communist insurgencies in Southeast Asia, particularly in Indonesia and Malaysia, and would distance itself from overseas Chinese in those nations.\n\nHowever, Maoist doctrine continued to emphasise the survivability of any conflict between the \"imperialist\" and \"socialist\" \"world systems\" - the Chinese continued to advocated a stronger form of the campist theory of global politics than that approved in the USSR.\n\nWith Mao's death the Chinese softened their line, though would never endorse the views of their rivals. During the late 1970s and 1980s, the concept of peaceful coexistence was expanded as a framework for all sovereign nations. In 1982 the Five Principles were written into the Constitution of the People's Republic of China which claims to be bound by them in its international relations.\n\nThe Five Principles of Peaceful Coexistence as promoted by China are:\n\nThere are three notable consequences of the Chinese concept of peaceful coexistence. First of all, in contrast with the Soviet concepts of the mid-1970s, the Chinese concepts include the encouragement of global free trade. Second, the Chinese concept of peaceful coexistence places a large emphasis on national sovereignty and territorial integrity, and thus moves by the United States to promote democracy and human rights are seen in this framework as hostile. Finally, as the PRC does not consider Taiwan to be sovereign, the concept of peaceful coexistence does not extend to Taiwan, and efforts by other nations, particularly the United States, to involve itself in PRC-Taiwan relations are seen as hostile actions in this framework.\n\nMore recently, the phrase has gained currency beyond its usage in communist phraseology and has been adopted by the broader diplomatic world. For instance, in his 2004 Christmas address, Pope John Paul II called for \"peaceful coexistence\" in the Middle East.\n\n\n"}
{"id": "177648", "url": "https://en.wikipedia.org/wiki?curid=177648", "title": "Personality", "text": "Personality\n\nPersonality is defined as the characteristic set of behaviors, cognitions, and emotional patterns that evolve from biological and environmental factors. While there is no generally agreed upon definition of personality, most theories focus on motivation and psychological interactions with one's environment. Trait-based personality theories, such as those defined by Raymond Cattell define personality as the traits that predict a person's behavior. On the other hand, more behaviorally based approaches define personality through learning and habits. Nevertheless, most theories view personality as relatively stable.\n\nThe study of the psychology of personality, called personality psychology, attempts to explain the tendencies that underlie differences in behavior. Many approaches have been taken on to study personality, including biological, cognitive, learning and trait based theories, as well as psychodynamic, and humanistic approaches. Personality psychology is divided among the first theorists, with a few influential theories being posited by Sigmund Freud, Alfred Adler, Gordon Allport, Hans Eysenck, Abraham Maslow, and Carl Rogers.\n\nPersonality can be determined through a variety of tests. However, dimensions of personality and scales of personality tests vary and often are poorly defined. Examples of such tests are the: Big Five Inventory (BFI), Minnesota Multiphasic Personality Inventory (MMPI-2), Rorschach Inkblot test, Neurotic Personality Questionnaire KON-2006, Enneagram test, or Eysenck's Personality Questionnaire (EPQ-R).\n\nPersonality is often broken into statistically-identified factors called the Big Five, which are openness to experience, conscientiousness, extraversion, agreeableness, and neuroticism (or emotional stability). These components are generally stable over time, and about half of the variance appears to be attributable to a person's genetics rather than the effects of one's environment.\n\nSome research has investigated whether the relationship between happiness and extraversion seen in adults can also be seen in children. The implications of these findings can help identify children that are more likely to experience episodes of depression and develop types of treatment that such children are likely to respond to. In both children and adults, research shows that genetics, as opposed to environmental factors, exert a greater influence on happiness levels. Personality is not stable over the course of a lifetime, but it changes much more quickly during childhood, so personality constructs in children are referred to as temperament. Temperament is regarded as the precursor to personality. Whereas McCrae and Costa's Big Five model assesses personality traits in adults, the EAS (emotionality, activity, and sociability) model is used to assess temperament in children. This model measures levels of emotionality, activity, sociability, and shyness in children. The personality theorists consider temperament EAS model similar to the Big Five model in adults; however, this might be due to a conflation of concepts of personality and temperament as described above. Findings show that high degrees of sociability and low degrees of shyness are equivalent to adult extraversion, and correlate with higher levels of life satisfaction in children.\n\nAnother interesting finding has been the link found between acting extraverted and positive affect. Extraverted behaviors include acting talkative, assertive, adventurous, and outgoing. For the purposes of this study, positive affect is defined as experiences of happy and enjoyable emotions. This study investigated the effects of acting in a way that is counter to a person's dispositional nature. In other words, the study focused on the benefits and drawbacks of introverts (people who are shy, socially inhibited and non-aggressive) acting extraverted, and of extraverts acting introverted. After acting extraverted, introverts' experience of positive affect increased whereas extraverts seemed to experience lower levels of positive affect and suffered from the phenomenon of ego depletion. Ego depletion, or cognitive fatigue, is the use of one's energy to overtly act in a way that is contrary to one's inner disposition. When people act in a contrary fashion, they divert most, if not all, (cognitive) energy toward regulating this foreign style of behavior and attitudes. Because all available energy is being used to maintain this contrary behavior, the result is an inability to use any energy to make important or difficult decisions, plan for the future, control or regulate emotions, or perform effectively on other cognitive tasks.\n\nOne question that has been posed is why extraverts tend to be happier than introverts. The two types of explanations attempt to account for this difference are instrumental theories and temperamental theories. The instrumental theory suggests that extraverts end up making choices that place them in more positive situations and they also react more strongly than introverts to positive situations. The temperamental theory suggests that extraverts have a disposition that generally leads them to experience a higher degree of positive affect. In their study of extraversion, Lucas and Baird found no statistically significant support for the instrumental theory but did, however, find that extraverts generally experience a higher level of positive affect. \n\nResearch has been done to uncover some of the mediators that are responsible for the correlation between extraversion and happiness. Self-esteem and self-efficacy are two such mediators. Self-efficacy has been found to be related to the personality traits of extraversion and subjective well-being. Self-efficacy is one's belief about abilities to perform up to personal standards, the ability to produce desired results, and the feeling of having some ability to make important life decisions. However, the relationship between extraversion (and neuroticism) and subjective happiness is only partially mediated by self-efficacy. This implies that there are most likely other factors that mediate the relationship between subjective happiness and personality traits. Another such factor may be self-esteem. Individuals with a greater degree of confidence about themselves and their abilities seem to have both higher degrees of subjective well-being and higher levels of extraversion.\n\nOther research has examined the phenomenon of mood maintenance as another possible mediator. Mood maintenance, the ability to maintain one's average level of happiness in the face of an ambiguous situation (meaning a situation that has the potential to engender either positive or negative emotions in different individuals), has been found to be a stronger force in extraverts. This means that the happiness levels of extraverted individuals are less susceptible to the influence of external events. Another implication of this finding is that extraverts' positive moods last longer than those of introverts.\n\nModern conceptions of personality, such as the Temperament and Character Inventory have suggested four basic temperaments that are thought to reflect basic and automatic responses to danger and reward that rely on associative learning. The four temperaments, \"harm avoidance\", \"reward dependence\", \"novelty seeking\" and \"persistence\" are somewhat analogous to ancient conceptions of melancholic, sanguine, choleric, phlegmatic personality types, although the temperaments reflect dimensions rather than distance categories. While factor based approaches to personality have yielded models that account for significant variance, the developmental biological model has been argued to better reflect underlying biological processes. Distinct genetic, neurochemical and neuroanatomical correlates responsible for each temperamental trait have been observed, unlike with five factor models.\n\nThe harm avoidance trait has been associated with increased reactivity in insular and amygdala salience networks, as well as reduced 5-HT2 receptor binding peripherally, and reduced GABA concentrations. Novelty seeking has been associated with reduced activity in insular salience networks increased striatal connectivity. Novelty seeking correlates with dopamine synthesis capacity in the striatum, and reduced auto receptor availability in the midbrain. Reward dependence has been linked with the oxytocin system, with increased concentration of plasma oxytocin being observed, as well as increased volume in oxytocin related regions of the hypothalamus. Persistence has been associated with increased striatal-mPFC connectivity, increased activation of ventral striatal-orbitofrontal-anterior cingulate circuits, as well as increased salivary amylase levels indicative of increased noradrenergic tone.\n\nIt has been shown that personality traits are more malleable by environmental influences than researchers originally believed. Personality differences predict the occurrence of life experiences.\n\nOne study that has shown how the home environment, specifically the types of parents a person has, can affect and shape their personality. Mary Ainsworth's Strange Situation experiment showcased how babies reacted to having their mother leave them alone in a room with a stranger. The different styles of attachment, labelled by Ainsworth, were Secure, Ambivalent, avoidant, and disorganized. Children who were securely attached tend to be more trusting, sociable, and are confident in their day-to-day life. Children who were disorganized were reported to have higher levels of anxiety, anger, and risk-taking behavior.\n\nJudith Rich Harris's group socialization theory postulates that an individual's peer groups, rather than parental figures, are the primary influence of personality and behavior in adulthood. Intra- and intergroup processes, not dyadic relationships such as parent-child relationships, are responsible for the transmission of culture and for environmental modification of children's personality characteristics. Thus, this theory points at the peer group representing the environmental influence on a child's personality rather than the parental style or home environment.\n\nTessuya Kawamoto's \"Personality Change from Life Experiences: Moderation Effect of Attachment Security\" talked about laboratory tests. The study mainly focused on the effects of life experiences on change in personality on and life experiences. The assessments suggested that \"the accumulation of small daily experiences may work for the personality development of university students and that environmental influences may vary by individual susceptibility to experiences, like attachment security\".\n\nThere has been some recent debate over the subject of studying personality in a different culture. Some people think that personality comes entirely from culture and therefore there can be no meaningful study in cross-culture study. On the other hand, others believe that some elements are shared by all cultures and an effort is being made to demonstrate the cross-cultural applicability of \"the Big Five\".\n\nCross-cultural assessment depends on the universality of personality traits, which is whether there are common traits among humans regardless of culture or other factors. If there is a common foundation of personality, then it can be studied on the basis of human traits rather than within certain cultures. This can be measured by comparing whether assessment tools are measuring similar constructs across countries or cultures. Two approaches to researching personality are looking at emic and etic traits. Emic traits are constructs unique to each culture, which are determined by local customs, thoughts, beliefs, and characteristics. Etic traits are considered universal constructs, which establish traits that are evident across cultures that represent a biological bases of human personality. If personality traits are unique to individual culture, then different traits should be apparent in different cultures. However, the idea that personality traits are universal across cultures is supported by establishing the Five Factor Model of personality across multiple translations of the NEO-PI-R, which is one of the most widely used personality measures. When administering the NEO-PI-R to 7,134 people across six languages, the results show a similar pattern of the same five underlying constructs that are found in the American factor structure.\n\nSimilar results were found using the Big Five Inventory (BFI), as it was administered in 56 nations across 28 languages. The five factors continued to be supported both conceptually and statistically across major regions of the world, suggesting that these underlying factors are common across cultures. There are some differences across culture but they may be a consequence of using a lexical approach to study personality structures, as language has limitations in translation and different cultures have unique words to describe emotion or situations. For example, the term \"feeling blue\" is used to describe sadness in more Westernized cultures, but does not translate to other languages. Differences across cultures could be due to real cultural differences, but they could also be consequences of poor translations, biased sampling, or differences in response styles across cultures. Examining personality questionnaires developed within a culture can also be useful evidence for the universality of traits across cultures, as the same underlying factors can still be found. Results from several European and Asian studies have found overlapping dimensions with the Five Factor Model as well as additional culture-unique dimensions. Finding similar factors across cultures provides support for the universality of personality trait structure, but more research is necessary to gain stronger support.\n\nThe modern sense of individual personality is a result of the shifts in culture originating in the Renaissance, an essential element in modernity. In contrast, the Medieval European's sense of self was linked to a network of social roles: \"the household, the kinship network, the guild, the corporation – these were the building blocks of personhood\", Stephen Greenblatt observes, in recounting the recovery (1417) and career of Lucretius' poem \"De rerum natura\": \"at the core of the poem lay key principles of a modern understanding of the world.\" \"Dependent on the family, the individual alone was nothing,\" Jacques Gélis observes.\n\nWilliam James (1842-1910) argued that temperament explains a great deal of the controversies in the history of philosophy by arguing that it is a very influential premise in the arguments of philosophers. Despite seeking only impersonal reasons for their conclusions, James argued, the temperament of philosophers influenced their philosophy. Temperament thus conceived is tantamount to a bias. Such bias, James explained, was a consequence of the trust philosophers place in their own temperament. James thought the significance of his observation lay on the premise that in philosophy an objective measure of success is whether a philosophy is peculiar to its philosopher or not, and whether a philosopher is dissatisfied with any other way of seeing things or not.\n\nJames argued that temperament may be the basis of several divisions in academia, but focused on philosophy in his 1907 lectures on \"Pragmatism\". In fact, James' lecture of 1907 fashioned a sort of trait theory of the empiricist and rationalist camps of philosophy. As in most modern trait theories, the traits of each camp are described by James as distinct and opposite, and may be possessed in different proportions on a continuum, and thus characterize the personality of philosophers of each camp. The \"mental make-up\" (i.e. personality) of rationalist philosophers is described as \"tender-minded\" and \"going by \"principles,\" and that of empiricist philosophers is described as \"tough-minded\" and \"going by \"facts.\" James distinguishes each not only in terms of the philosophical claims they made in 1907, but by arguing that such claims are made primarily on the basis of temperament. Furthermore, such categorization was only incidental to James' purpose of explaining his pragmatist philosophy, and is not exhaustive.\n\nAccording to James, the \"temperament\" of rationalist philosophers differed fundamentally from the \"temperament\" of empiricist philosophers of his day. The tendency of rationalist philosophers toward \"refinement\" and \"superficiality\" never satisfied an empiricist temper of mind. Rationalism leads to the creation of \"closed systems\", and such optimism is considered shallow by the fact-loving mind, for whom perfection is far off. Rationalism is regarded as \"pretension\", and a temperament most inclined to \"abstraction\". The temperament of rationalists, according to James, led to sticking with logic.\n\nEmpiricists, on the other hand, stick with the external senses rather than logic. British empiricist John Locke's (1632–1704) explanation of personal identity provides an example of what James referred to. Locke explains the identity of a person, i.e. personality, on the basis of a precise definition of identity, by which the meaning of identity differs according to what it is being applied to. The identity of a person, is quite distinct from the identity of a man, woman, or substance according to Locke. Locke concludes that consciousness is personality because it \"always accompanies thinking, it is that which makes every one to be what he calls self,\" and remains constant in different places at different times. Thus his explanation of personal identity is in terms of experience as James indeed maintained is the case for most empiricists.\n\nRationalists conceived of the identity of persons differently than empiricists such as Locke who distinguished identity of substance, person, and life. According to Locke, Rene Descartes (1596–1650) agreed only insofar as he did not argue that one immaterial spirit is the basis of the person \"for fear of making brutes thinking things too.\" According to James, Locke tolerated arguments that a soul was behind the consciousness of any person. However, Locke's successor David Hume (1711–1776), and empirical psychologists after him denied the soul except for being a term to describe the cohesion of inner lives. However, some research suggests Hume excluded personal identity from his opus An Inquiry Concerning Human Understanding because he thought his argument was sufficient but not compelling. Descartes himself distinguished active and passive faculties of mind, each contributing to thinking and consciousness in different ways. The passive faculty, Descartes argued, simply receives, whereas the active faculty produces and forms ideas, but does not presuppose thought, and thus cannot be within the thinking thing. The active faculty mustn't be within self because ideas are produced without any awareness of them, and are sometimes produced against one's will.\n\nRationalist philosopher Benedictus Spinoza (1632–1677) argued that ideas are the first element constituting the human mind, but existed only for actually existing things. In other words, ideas of non-existent things are without meaning for Spinoza, because an idea of a non-existent thing cannot exist. Further, Spinoza's rationalism argued that the mind does not know itself, except insofar as it perceives the \"ideas of the modifications of body,\" in describing its external perceptions, or perceptions from without. On the contrary, from within, Spinoza argued, perceptions connect various ideas clearly and distinctly. The mind is not the free cause of its actions for Spinoza. Spinoza equates the will with the understanding, and explains the common distinction of these things as being two different things as error which results from the individual's misunderstanding of the nature of thinking.\n\nThe biological basis of personality is the theory that anatomical structures located in the brain contribute to personality traits. This stems from neuropsychology, which studies how the structure of the brain relates to various psychological processes and behaviors. For instance, in human beings, the frontal lobes are responsible for foresight and anticipation, and the occipital lobes are responsible for processing visual information. In addition, certain physiological functions such as hormone secretion also affect personality. For example, the hormone testosterone is important for sociability, affectivity, aggressiveness, and sexuality. Additionally, studies show that the expression of a personality trait depends on the volume of the brain cortex it is associated with.\n\nThere is also a confusion among some psychologists who conflate personality with temperament. Temperament traits that are based on weak neurochemical imbalances within neurotransmitter systems are much more stable, consistent in behavior and show up in early childhood; they can't be changed easily but can be compensated for in behavior. In contrast to that, personality traits and features are the product of the socio-cultural development of humans and can be learned and/or changed.\n\nPersonology confers a multidimensional, complex, and comprehensive approach to personality. From a holistic perspective, personology studies personality as a whole, as a system, but in the same time through all its components, levels and spheres.\n\nHigh neuroticism is an independent prospective predictor for the development of the common mental disorders.\n\nResearch in Personality computing demonstrated that machines can infer the personality types of an individual better than humans\n\n\n"}
{"id": "354643", "url": "https://en.wikipedia.org/wiki?curid=354643", "title": "Plausible deniability", "text": "Plausible deniability\n\nPlausible deniability is the ability of people (typically senior officials in a formal or informal chain of command) to deny knowledge of or responsibility for any damnable actions committed by others in an organizational hierarchy because of a lack of evidence that can confirm their participation, even if they were personally involved in or at least willfully ignorant of the actions. In the case that illegal or otherwise disreputable and unpopular activities become public, high-ranking officials may deny any awareness of such acts to insulate themselves and shift blame onto the agents who carried out the acts, as they are confident that their doubters will be unable to prove otherwise. The lack of evidence to the contrary ostensibly makes the denial plausible, that is, credible, although sometimes it merely makes it unactionable. The term typically implies forethought, such as intentionally setting up the conditions to plausibly avoid responsibility for one's (future) actions or knowledge. In some organizations, legal doctrines such as command responsibility exist to hold major parties responsible for the actions of subordinates involved in heinous acts and nullify any legal protection that their denial of involvement would carry.\n\nHigh-ranking officials in more typically Eastern cultures, such as Japan or Korea, are often expected to take full responsibility for improper actions by their subordinates. As an example, Japanese CEOs have made dramatic public apologies and even committed suicide when their companies have been dishonored in some way.\",\"\n\nIn politics and espionage, deniability refers to the ability of a powerful player or intelligence agency to pass the buck and avoid blowback by secretly arranging for an action to be taken on their behalf by a third party ostensibly unconnected with the major player. In political campaigns, plausible deniability enables candidates to stay clean and denounce third-party advertisements that use unethical approaches or potentially libellous innuendo.\n\nIn the US, plausible deniability is also a legal concept. It refers to lack of evidence proving an allegation. Standards of proof vary in civil and criminal cases. In civil cases, the standard of proof is \"preponderance of the evidence\" whereas in a criminal matter, the standard is \"beyond a reasonable doubt\". If an opponent cannot provide evidence for his allegation, one can plausibly deny the allegation even though it may be true.\n\nAlthough plausible deniability has existed throughout history, that name for it was coined by the CIA in the early 1960s to describe the withholding of information from senior officials in order to protect them from repercussions in the event that illegal or unpopular activities by the CIA became public knowledge. The roots of the name go back to Harry Truman's national security council paper 10/2 of June 18, 1948, which defined \"covert operations\" as \"...all activities (except as noted herein) which are conducted or sponsored by this Government against hostile foreign states or groups or in support of friendly foreign states or groups but which are so planned and executed that any US Government responsibility for them is not evident to unauthorized persons and that if uncovered the US Government can plausibly disclaim any responsibility for them.\" During Eisenhower's administration, NSC 10/2 was incorporated into more specific NSC 5412/2 \"Covert Operations.\" NSC 5412 was de-classified in 1977, and is located at the National Archives.\n\nArguably, the key concept of plausible deniability is plausibility. It is relatively easy for a government official to issue a blanket denial of an action, and it is possible to destroy or cover up evidence after the fact, and this might be sufficient to avoid a criminal prosecution, for instance. However, the public might well disbelieve the denial, particularly if there is strong circumstantial evidence, or if the action is believed to be so unlikely that the only logical explanation is that the denial is false.\n\nThe concept is even more important in espionage. Intelligence may come from many sources, including human sources. The exposure of information to which only a few people are privileged may directly implicate some of those people in the disclosure. Take for example a scenario where an official is traveling secretly, and only one of his aides knows the specific travel plans. The official is assassinated during his travels, and the circumstances of the assassination strongly suggest that the assassin had foreknowledge of the official's travel plans. The probable conclusion is that his aide has betrayed the official. There may be no direct evidence linking the aide to the assassin, but collaboration can be inferred from the facts alone, thus making the aide's denial implausible.\n\nThe expression \"plausibly deniable\" was first used publicly by Central Intelligence Agency (CIA) director Allen Dulles. The idea, on the other hand, is considerably older. For example, in the 19th century, Charles Babbage described the importance of having \"a few simply honest men\" on a committee who could be temporarily removed from the deliberations when \"a peculiarly delicate question arises\" so that one of them could \"declare truly, if necessary, that he never was present at any meeting at which even a questionable course had been proposed.\"\n\nA U.S. Senate committee, the Church Committee, in 1974–1975 conducted an investigation of the intelligence agencies. In the course of the investigation, it was revealed that the CIA, going back to the Kennedy administration, had plotted the assassination of a number of foreign leaders, including Cuba's Fidel Castro. But the president himself, who clearly was in favor of such actions, was not to be directly involved, so that he could deny knowledge of it. This was given the term 'plausible denial'.\n\nPlausible denial involves the creation of power structures and chains of command loose and informal enough to be denied if necessary. The idea was that the CIA (and, later, other bodies) could be given controversial instructions by powerful figures—up to and including the President himself—but that the existence and true source of those instructions could be denied if necessary; if, for example, an operation went disastrously wrong and it was necessary for the administration to disclaim responsibility.\n\nThe Hughes–Ryan Act of 1974 sought to put an end to plausible denial by requiring a Presidential finding that each operation is important to national security, and the Intelligence Oversight Act of 1980 required that Congress be notified of all covert operations. But both laws are full of enough vague terms and escape hatches to allow the executive branch to thwart their authors' intentions, as the Iran–Contra affair has shown. Indeed, the members of Congress are in a dilemma: when they are informed, they are in no position to stop the action, unless they leak its existence and thereby foreclose the option of covertness.\n\nIn his testimony to the congressional committee studying the Iran–Contra affair, Vice Admiral John Poindexter stated: \"I made a deliberate decision not to ask the President, so that I could insulate him from the decision and provide some future deniability for the President if it ever leaked out.\"\n\n\nThe doctrine has at least five major flaws: \n\n\nAnother example of plausible deniability is someone who actively avoids gaining certain knowledge of facts because it benefits that person not to know.\n\nAs an example, an attorney may suspect that facts exist which would hurt his case, but decide not to investigate the issue because if the attorney had actual knowledge, the rules of ethics might require him to reveal those facts to the opposing side. \n\n\"...the U.S. government may at times require a certain deniability. Private activities can provide that deniability.\" —Council on Foreign Relations, an American foreign policy think tank, in the 2003 report, \"Finding America’s Voice: A Strategy for Reinvigorating U.S. Public Diplomacy\" \n\nIn computer networks, deniability often refers to a situation where a person can deny transmitting a file, even when it is proven to come from their computer. \n\nThis is sometimes done by setting the computer to relay certain types of broadcasts automatically, in such a way that the original transmitter of a file is indistinguishable from those who are merely relaying it. In this way, the person who first transmitted the file can claim that their computer had merely relayed it from elsewhere.\n\nIt can also be done by a VPN where the host is not known.\n\nIn any case, this claim cannot be disproven without a complete decrypted log of all network connections.\n\nThe Freenet file sharing network is another application of the idea. It obfuscates data sources and flows in order to protect operators and users of the network by preventing them (and, by extension, observers such as censors) from knowing where data comes from and where it is stored.\n\nIn cryptography, deniable encryption may be used to describe steganographic techniques, where the very existence of an encrypted file or message is \"deniable\" in the sense that an adversary cannot prove that an encrypted message exists. In this case the system is said to be 'fully undetectable' (FUD).\n\nSome systems take this further, such as MaruTukku, FreeOTFE and (to a much lesser extent) TrueCrypt and VeraCrypt, which nest encrypted data. The owner of the encrypted data may reveal one or more keys to decrypt certain information from it, and then deny that more keys exist, a statement which cannot be disproven without knowledge of all encryption keys involved. The existence of \"hidden\" data within the overtly encrypted data is then \"deniable\" in the sense that it cannot be proven to exist.\n\nThe Underhanded C Contest is an annual programming contest involving the creation of carefully crafted defects, which have to be both very hard to find and plausibly deniable as mistakes once found.\n\nNotes\nFurther reading\n\n"}
{"id": "25270", "url": "https://en.wikipedia.org/wiki?curid=25270", "title": "Quine (computing)", "text": "Quine (computing)\n\nA quine is a non-empty computer program which takes no input and produces a copy of its own source code as its only output. The standard terms for these programs in the computability theory and computer science literature are \"self-replicating programs\", \"self-reproducing programs\", and \"self-copying programs\".\n\nA quine is a fixed point of an execution environment, when the execution environment is viewed as a function transforming programs into their outputs. Quines are possible in any Turing complete programming language, as a direct consequence of Kleene's recursion theorem. For amusement, programmers sometimes attempt to develop the shortest possible quine in any given programming language.\n\nThe name \"quine\" was coined by Douglas Hofstadter, in his popular science book \"\", in honor of philosopher Willard Van Orman Quine (1908–2000), who made an extensive study of indirect self-reference, and in particular for the following paradox-producing expression, known as Quine's paradox:\n\"Yields falsehood when preceded by its quotation\" yields falsehood when preceded by its quotation.\nIn some languages, particularly scripting languages, an empty source file is a fixed point of the language, being a valid program that produces no output. Such an empty program, submitted as \"the world's smallest self reproducing program\", once won the \"worst abuse of the rules\" prize in the International Obfuscated C Code Contest.\n\nThe idea of self-reproducing automata came from the dawn of computing, if not before. John von Neumann theorized about them in the 1940s. Later, Paul Bratley and Jean Millo's article \"Computer Recreations: Self-Reproducing Automata\" discussed them in 1972.\nBratley first became interested in self-reproducing programs after seeing the first known such program written in Atlas Autocode at Edinburgh in the 1960s by the University of Edinburgh lecturer and researcher Hamish Dewar.\n\nThe \"download source\" requirement of the Affero General Public License is based on the idea of a quine.\n\nIn general, the method used to create a quine in any programming language is to have, within the program, two pieces: (a) code used to do the actual printing and (b) data that represents the textual form of the code. The code functions by using the data to print the code (which makes sense since the data represents the textual form of the code), but it also uses the data, processed in a simple way, to print the textual representation of the data itself.\n\nThe following Java code demonstrates the basic structure of a quine.\npublic class Quine\nThe source code contains a string array of itself, which is output twice, once inside quotation marks.\n\nThe same idea is used in the following SQL quine:\n\nSELECT REPLACE(REPLACE('SELECT REPLACE(REPLACE(\"$\",CHAR(34),CHAR(39)),CHAR(36),\"$\") AS Quine',CHAR(34),CHAR(39)),CHAR(36),'SELECT REPLACE(REPLACE(\"$\",CHAR(34),CHAR(39)),CHAR(36),\"$\") AS Quine') AS Quine\nA very concise quine with the same basic structure can be written in Lua:\n\nx = \"x = [\" .. \"[\" .. x .. \"]\" .. \"]\\nprint(\" .. x)\nprint(\"x = [\" .. \"[\" .. x .. \"]\" .. \"]\\nprint(\" .. x)\n\nAnd in Python:\ns = 's = %r\\nprint(s%%s)'\nprint(s%s)\n\nAs a one-liner in Matlab:\n\ns='disp(char([115,61,39,s,39,59,s]));';disp(char([115,61,39,s,39,59,s]));\nAs a one-liner in C:\n\nActually another shorter one:\n\nIn SAS: \n\nSAS Metadata Program:\n/* Assign Macro Variables */\n%Let DSN=sashelp.cars ;\n%Let Var=Type ;\n%Let Option_1=nopct ;\n%Let Option_2=nocum ;\n\n/* Assign Output Fileref */\nFilename outpgm 'E:\\Data-driven Program.sas' ;\n\n/* DATA Step to Produce External SAS Program */\nDATA _NULL_ ;\nRUN ;\n\nResults:\n/* Substitute Variable Names with Macro Variables */\ntitle Display NLevels for Type with PROC FREQ ;\nproc freq data=sashelp.cars nlevels ;\nrun ;\nIn Scala:\n\nobject Quine extends App {\n\nIn R:\n\nm<-\"m<-0;cat(sub(0,deparse(m),m))\";cat(sub(0,deparse(m),m))\nIn Rust:\n\nfn main() {\n\nIn Go:\n\npackage main\n\nimport \"fmt\"\n\nfunc main() {\n\nvar s = `package main\n\nimport \"fmt\"\n\nfunc main() {\n\nvar s = `\nIn OCaml:\n(fun s -> Printf.printf \"%s%S;;\\n\" s s) \"(fun s -> Printf.printf \\\"%s%S;;\\\\n\\\" s s) \";;\nIn Haskell:\nmain = putStr s » print s where s = \"main = putStr s » print s where s = \"\nIn Kotlin:\nval a=\"val a=%c%s%c%nprint(a.format(34,a,34))\"\nprint(a.format(34,a,34))\nQuines can take advantage of codice_1. For example, this Ruby quine:\n\neval s=\"print 'eval s=';p s\"\n\nIn TI-BASIC, if the last line of a program is value returning, the returned value is displayed on the screen. Therefore, a program containing a single digit results in a 1-byte quine. \n\n<syntaxhighlight>\n1\n</syntaxhighlight>\n\nQuines, per definition, cannot receive \"any\" form of input, including reading a file, which means a quine is considered to be \"cheating\" if it looks at its own source code. The following shell script is not a quine:\n\ncat $0\nNor is this succinct use of the Shebang:\n\nThe above also applies to this JavaScript code:\n\nfunction a() {\na()\nIn PHP:\n<? highlight_file(__FILE__) ?>\n\nIn Python:\nprint(open(__file__).read())\n\nA program in the joke language HQ9+ is a quine if and only if the source code consists only of zero or more '+' characters and a single 'Q' character (the 'Q' command prints a quine and '+' prints nothing):\n\nOne of the shortest cheating quines is provided by Forth, which has a built-in command to read its own source:\n\nAn even shorter cheating quine exists on many 1980s home computers (such as the ZX Spectrum and the Commodore 64) as follows:\n\nAnother even shorter cheating quine in bash:\nIn C:\n\n/*#include <stdlib.h>*/\nmain() {\n/* system(\"pause\");*/\n\nOther questionable techniques include making use of compiler messages; for example, in the GW-BASIC environment, entering \"Syntax Error\" will cause the interpreter to respond with \"Syntax Error\". Ignoring the restriction that quines be non-empty, there are many examples of programming languages where an empty program is valid (such as C). Such programs generally do nothing, in effect, reproducing the program.\n\nThe quine concept can be extended to multiple levels of recursion, originating \"ouroboros programs\", or quine-relays. This should not be confused with Multiquines.\n\nThis Java program outputs the source for a C++ program that outputs the original Java code.\nSuch programs have been produced with various cycle lengths:\n\n\nDavid Madore, creator of Unlambda, describes multiquines as follows:\n\"A multiquine is a set of r different programs (in r different languages — without this condition we could take them all equal to a single quine), each of which is able to print any of the r programs (including itself) according to the command line argument it is passed. (Note that cheating is not allowed: the command line arguments must not be too long — passing the full text of a program is considered cheating).\"\nA multiquine consisting of 2 languages (or biquine) would be a program which:\n\nA biquine could then be seen as a set of two programs, both of which are able to print either of the two, depending on the command line argument supplied.\n\nTheoretically, there is no limit on the number of languages in a multiquine,\na 5-part multiquine (or pentaquine) has been produced with Python, Perl, C, NewLISP, and F#\nand there is also a 25-language multiquine.\n\nA radiation-hardened quine is a quine that can have any single character removed and still produce the original program with no missing character. Of necessity, such quines are much more convoluted than ordinary quines, as is seen by the following example in Ruby:\neval='eval$q=%q(puts %q(10210/#{1 1 if 1==21}}/.i rescue##/\n\n1 1\"[13,213].max_by{|s|s.size}#\"##\").gsub(/\\d/){[\"=\\47eval$q=%q(#$q)#\\47##\\47\n\nexit)#'##'\n\ninstance_eval='eval$q=%q(puts %q(10210/#{1 1 if 1==21}}/.i rescue##/\n\n1 1\"[13,213].max_by{|s|s.size}#\"##\").gsub(/\\d/){[\"=\\47eval$q=%q(#$q)#\\47##\\47\n\nexit)#'##'\n\n/#{eval eval if eval==instance_eval}}/.i rescue##/\n\neval eval\"[eval||=9,instance_eval||=9].max_by{|s|s.size}#\"##\"\n\n"}
{"id": "32323840", "url": "https://en.wikipedia.org/wiki?curid=32323840", "title": "Representational momentum", "text": "Representational momentum\n\nRepresentational momentum is a small, but reliable, error in our visual perception of moving objects. Instead of knowing the exact location of a moving object, we actually think it is a bit further along its trajectory. For example, people viewing an object moving from left to right that suddenly disappears will report they saw it a bit further to the right than where it actually vanished. While not a big error, it has been found in a variety of different events ranging from simple rotations to camera movement through a scene. The name \"representational momentum\" initially reflected the idea that the forward displacement was the result of the perceptual system having internalized, or evolved to include, basic principles of Newtonian physics, but it has come to mean forward displacements that continue a presented pattern along a variety of dimensions, not just position or orientation. As with many areas of cognitive psychology, theories can focus on bottom-up or top-down aspects of the task. Bottom-up theories of representational momentum highlight the role of eye movements and stimulus presentation, while top-down theories highlight the role of the observer's experience and expectations regarding the presented event.\n\nRepresentational Momentum has been studied using two types of displays: implied motion (left panel) and smooth animations (right panel). Implied events show a series of pictures that suggest a motion, but at a slow frame rate so there is no apparent motion. Smooth animations have also been used, where the animation is briefly interrupted and then participants either indicate whether a static probe is in the same position as the final frame of the animation (right panel), or are asked to indicate with a mouse cursor exactly where the object disappeared. The basic result is that participants either use the mouse to click beyond the vanishing point, or misidentify forward positioned probes as the location where the object disappeared. So, instead of indicating that the actual 0° probe in a rotation event is the same, participants will say that probes appearing 2°-4° past the vanishing point actually seem to be at the vanishing point itself. However, they will quite readily reject probes that are behind the vanishing point by 2°-4°.\nInitial studies established that representational momentum occurs for rotations in and movements across the picture plane, with larger distortions occurring with faster velocities and when downward motion is presented. Moreover, the overall pattern of the motion is anticipated, so that when shown an oscillatory motion, like a pendulum, the object is remembered as continuing the larger pattern. In other words, when asked to judge where the object is just as it would normally reverse directions, probes in the reverse direction are accepted as same, not probes that would continue the most immediate, local motion.\n\nThe degree of representational momentum observed can depend on how the participant is labeling the event or object. For example, if told just before a trial that the object will \"crash\" against a wall, smaller distortions will be observed than if told the object is going to \"bounce.\" More representational momentum is also observed when participants are told a triangular shape is a \"rocket\" compared to when the same shape is called a \"church,\" however, the overall pointedness of the shape is more important than object identity.\n\nObjects can rotate about many different depth axes (e.g., consider the difference between a somersault and a spin) and more representational momentum occurs with axes of rotation that run through the center of the object compared to off-center rotations. When presented with an event depicting the view from a camera moving through a scene, representational momentum occurs for the camera view, both for rotations (like turning your head) and movements in the scene. More representational momentum occurs for views where objects are entering the scene, compared to rotating out of view (see example movies).\nAuditory representational momentum has been found for sounds moving about the listener, but patterns of change can be established in dimensions beyond position. For example, consider a rising tone in pitch. Auditory representational momentum, where a pitch further along the presented pattern is misidentified as the actual ending pitch, has been found for both simple rises and falls in pitch, along with more complicated periodic patterns.\n\nIndividual differences in the magnitude of representational momentum reveal that extensive training and experience with particular kinds of dynamic events allow experts to more readily continue the motion of the display. In particular, pilots with extensive experience (average 3,198 of flying hours) showed more representational momentum to flight simulator landing scenes than did novices. Novices showed no forward distortion with the forward probes pilots anticipated, but when smaller anticipations were probed, novices were able to anticipate forward motion. Experts more readily anticipate the dynamic scene, resulting in larger representational momentum.\n\nBeing able to estimate an object's size in order to pick it up involves an integration of visual information and motor control. Upon viewing implied motion depicting the handles of a pair of pliers either opening or closing, participants change their physical hand grip size in keeping with representational momentum, anticipating the future position of the handles. While the hand action anticipates the continued opening (or closing) of the pliers, visual judgments of the object's final handle position consistently underestimate the opening, indicating that the relationship between visual judgments and subsequent physical acts is not straightforward.\n\nEvents depicting changes in luminance, or how bright a patch of color appears, do not lead to forward distortions in memory similar to representational momentum, but instead show backwards distortions. In other words, upon viewing an object getting progressively lighter and asked to remember the final shade, participants accept a darker version of the object (where a representational momentum parallel would be to accept a lighter shade). One suggestion for this difference is that memory is playing more of a role in determining color.\n\n"}
{"id": "538779", "url": "https://en.wikipedia.org/wiki?curid=538779", "title": "Review", "text": "Review\n\nA review is an evaluation of a publication, service, or company such as a movie (a movie review), video game (video game review), musical composition (music review of a composition or recording), book (book review); a piece of hardware like a car, home appliance, or computer; or an event or performance, such as a live music concert, play, musical theater show, dance show, or art exhibition. In addition to a critical evaluation, the review's author may assign the work a rating to indicate its relative merit. More loosely, an author may review current events, trends, or items in the news. A compilation of reviews may itself be called a review. \"The New York Review of Books\", for instance, is a collection of essays on literature, culture, and current affairs. \"National Review\", founded by William F. Buckley, Jr., is an influential conservative magazine, and \"Monthly Review\" is a long-running socialist periodical.\n\nA user review refers to a review written by a user or consumer for a product or a service based on her experience as a user of the reviewed product. Popular sources for consumer reviews are e-commerce sites like Amazon.com, Zappos or lately in the Yoga field for schools such as Banjaara Yoga and Ayurveda, and social media sites like TripAdvisor and Yelp. E-commerce sites often have consumer reviews for products and sellers separately. Usually, consumer reviews are in the form of several lines of texts accompanied by a numerical rating. This text is meant to aid in shopping decision of a prospective buyer. A consumer review of a product usually comments on how well the product measures up to expectations based on the specifications provided by the manufacturer or seller. It talks about performance, reliability, quality defects, if any, and value for money. Consumer review, also called 'word of mouth' and 'user generated content' differs from 'marketer generated content' in its evaluation from consumer or user point of view. Often it includes comparative evaluations against competing products. Observations are factual as well as subjective in nature. Consumer review of sellers usually comment on service experienced, and dependability or trustworthiness of the seller. Usually, it comments on factors such as timeliness of delivery, packaging, and correctness of delivered items, shipping charges, return services against promises made, and so on.\n\nConsumer reviews online have become a major factor in business reputation and brand image due to the popularity of TripAdvisor, Yelp, and online review websites. A negative review can damage the reputation of a business and this has created a new industry of reputation management where companies attempt to remove or hide bad reviews so that more favourable content is found when potential customers do research.\n\nAn \"expert review\" usually refers to a review written by someone who has tested several peer products or services to identify which offers the best value for money or the best set of features. An example of this is Amazon Vine. Amazon Vine is a program which was introduced to \"help their fellow customers make informed purchase decisions\". This program is invite-only and is designed to generate reviews for product vendors that Amazon works with.\n\nOne type of user review can be in the physical world, such as a video reviewing a product or software. This is common on platforms such as YouTube and Vimeo.\n\nA \"bought review\" is the system where the creator (usually a company) of a new product pays a reviewer to review their new product.\n\nA [book review] (or book report) is a form of criticism in which a book is analyzed based on content, style, and merit. It is often carried out in periodicals, as school work, or online. Its length may vary from a single paragraph to a substantial [essay]. In the case of a work of poetry or fiction, or of nonfiction in which the literary merits of the work are an important element, a review will commonly use the methods of literary criticism. Such a review often contains evaluations of the book on the basis of personal taste. Reviewers, in literary periodicals, often use the occasion of a book review for a display of learning or to promulgate their own ideas on the topic of a fiction or non-fiction work. At the other end of the spectrum, some book reviews resemble simple plot summaries. Reviews of non-fiction works intended for instructional or informational purposes may focus more directly on concerns such as practical usefulness and reader-friendliness.\n\nReviews of live music performances are typically short articles that tell readers about the performers or group(s) that were involved and the pieces or songs that were performed. The comments made by reviewers fall, roughly into two categories: technical comments and subjective/artistic comments. The elements in the \"technical\" category include rhythmic \"togetherness\", intonation, errors or slip-ups, and so on. These elements are fairly \"black and white\"; a pianist playing a concerto either played the right notes on a climactic scale run, or she missed it. The subjective comments refer to elements which are a matter of taste. The balance between the different elements in a review (information about the performer or group; information about the pieces/songs; commentary about the technical and subjective elements of the performance) depends on the audience that a music critic is writing for. Music reviewers writing in local newspapers or general-interest magazines may not be able to assume that the readers will be familiar with music performers and pieces/songs, so they may decide to include a great deal of \"background\" information.\n\nMusic critics and music writers also review recordings of music, including individual songs or pieces or entire albums. In the case of a review of an entire album, the reviewer will not only judge the individual songs or pieces; they will also judge how well all of the songs or pieces work together or go together.\n\nThe age of digital downloads may considerably change the album review. Where previously albums were purchased as collections of songs, often with a common theme, the rise of individual song downloads may have significant impact on consumers' exposure to an artist's music. Die-hard fans will most likely continue to explore an artist's complete work, but individuals will most likely make significantly different choices and \"cherry-pick\" songs they have been exposed to. The concept of \"singles\" or individual hits marked for retail has been around for long time; however, the price for a single in the days of CDs or 45's was much closer to the complete album price. When you consider that each song on an artist's album is often priced at the same amount, the odds of the average consumer purchase the entire album instead of selecting the \"hit\" songs decreases significantly.\n\nIn Classical music, music critics may also do reviews of compositions, even if the piece or song has never been performed and it only exists on manuscript paper in a score. To review a composition in this fashion, the critic will use music theory skills such as harmonic analysis and thematic analysis, along with their knowledge of idioms and compositional practices.etc\n\nA motion picture review is a work of film criticism addressing the merits of one or more motion pictures. Generally, the term \"movie review\" implies a work of journalistic film criticism rather than of academic criticism. Such reviews have appeared in newspapers and printed periodicals since the beginning of the film industry, and now are published in general-interest websites as well as specialized film and film review sites. Television programs and other videos are now commonly reviewed in similar venues and by similar methods.\n\nA \"bought review\" is the system where the creator (usually a company) of a new product pays a reviewer to review his new product. Primarily used in the car, movie, and game industry this system creates a kind of undercover advertising. Bought reviews tend to be biased due to the informative value of reviews. In some cases, a bought review may be independent, if the person that is hired to do the review has a strong reputation for independence and integrity. Even if a \"bought review\" from a respected critic is actually independent, the perception of potential bias will remain, due to the financial relationship between the company and the critic.\n\nA similar type of review that may be biased is the so-called \"puff piece\", a review of \"[a product]\", film, or event that is written by a sympathetic reviewer or by an individual who has a connection to the product or event in question, either in terms of an employment relationship or other links. For example, a major media conglomerate that owns both print media and record companies may instruct one of its employees in one of its newspapers to do a review of an album which is being released by the conglomerate's record company. Although some journalists may assert their professional independence and integrity, and insist on producing an unbiased review, in other cases, writers may succumb to the pressure and pen a biased \"puff piece\" which praises the product or event while omitting any discussion of any shortcomings. In some cases, \"puff pieces\" purport to provide a review of the product or event, but instead merely provide \"peacock words\" (\"An amazing recording\"); \"weasel words\" and tabloid-style filler which is peripheral or irrelevant to assessing the qualities of the product or event (\"During the filming, there were rumors that romantic sparks flew between the two co-leads, who were often seen talking together on the set\").\n\nSeveral online review manipulation strategies have also been reported, such as writing fake reviews and offering monetary compensation to remove negative reviews. Among these strategies, selectively soliciting customers to write positive reviews is gaining high popularity. Compounding this is the fact that unhappy customers are more likely to leave reviews than happy ones, businesses feel like they have to increase their number of reviews.\n\n\n"}
{"id": "47797003", "url": "https://en.wikipedia.org/wiki?curid=47797003", "title": "S.C.A.M.P.E.R", "text": "S.C.A.M.P.E.R\n\nSCAMPER is an acronym that provides a structured way of assisting students to think out of the box and enhance their knowledge.\n\nIt is thought to protect students' creativity as they mature.\n\nSCAMPER was proposed by Alex Faickney Osborn in 1953, and was further developed by Bob Eberle in 1971 in his book; \"SCAMPER: Games for Imagination Development\".\n\nSCAMPER is an activity based thinking process that can be performed by Cooperative learning. Here the teacher assists the students in choosing a particular topic and helps them to develop it through a structured process. After choosing an idea, the students are given a tale where they perform the activity in steps corresponding to the letters in the name.\n\n\nHence, SCAMPER as a teaching strategy helps the students to analyse the knowledge in its creative form and helps the teacher to make teaching creative and interesting.\n\nSCAMPER also provides a ‘hip-pocket’ tool; i.e., an unplanned method of developing questions on an impromptu basis designed to challenge meeting participants' creativity and to make their thinking visible.\n"}
{"id": "485855", "url": "https://en.wikipedia.org/wiki?curid=485855", "title": "Semiprimitive ring", "text": "Semiprimitive ring\n\nIn algebra, a semiprimitive ring or Jacobson semisimple ring or J-semisimple ring is a ring whose Jacobson radical is zero. This is a type of ring more general than a semisimple ring, but where simple modules still provide enough information about the ring. Rings such as the ring of integers are semiprimitive, and an artinian semiprimitive ring is just a semisimple ring. Semiprimitive rings can be understood as subdirect products of primitive rings, which are described by the Jacobson density theorem.\n\nA ring is called semiprimitive or Jacobson semisimple if its Jacobson radical is the zero ideal.\n\nA ring is semiprimitive if and only if it has a faithful semisimple left module. The semiprimitive property is left-right symmetric, and so a ring is semiprimitive if and only if it has a faithful semisimple right module.\n\nA ring is semiprimitive if and only if it is a subdirect product of left primitive rings.\n\nA commutative ring is semiprimitive if and only if it is a subdirect product of fields, .\n\nA left artinian ring is semiprimitive if and only if it is semisimple, . Such rings are sometimes called semisimple Artinian, .\n\n\nJacobson himself has defined a ring to be \"semisimple\" if and only if it is a subdirect product of simple rings, . However, this is a stricter notion, since the endomorphism ring of a countably infinite dimensional vector space is semiprimitive, but not a subdirect product of simple rings, .\n\n"}
{"id": "6027951", "url": "https://en.wikipedia.org/wiki?curid=6027951", "title": "Shimanagashi", "text": "Shimanagashi\n\nShimanagashi () is a form of punishment where people are banished to small islands. It was created during the feudal period in Japan, where political offenders were often sent away and confined on the island of Sado in the Sea of Japan.\n"}
{"id": "2985811", "url": "https://en.wikipedia.org/wiki?curid=2985811", "title": "Signed measure", "text": "Signed measure\n\nIn mathematics, signed measure is a generalization of the concept of measure by allowing it to have negative values. Some authors may call it a charge, by analogy with electric charge, which is a familiar distribution that takes on positive and negative values.\n\nThere are two slightly different concepts of a signed measure, depending on whether or not one allows it to take infinite values. In research papers and advanced books signed measures are usually only allowed to take finite values, while undergraduate textbooks often allow them to take infinite values. To avoid confusion, this article will call these two cases \"finite signed measures\" and \"extended signed measures\".\n\nGiven a measurable space (\"X\", Σ), that is, a set \"X\" with a sigma algebra Σ on it, an extended signed measure is a function\nsuch that formula_2 and formula_3 is sigma additive, that is, it satisfies the equality\nwhere the series on the right must converge absolutely, for any sequence \"A\", \"A\", ..., \"A\", ... of disjoint sets in Σ. One consequence is that any extended signed measure can take +∞ as value, or it can take −∞ as value, but both are not available. The expression ∞ − ∞ is undefined and must be avoided.\n\nA finite signed measure (aka. real measure) is defined in the same way, except that it is only allowed to take real values. That is, it cannot take +∞ or −∞.\n\nFinite signed measures form a vector space, while extended signed measures are not even closed under addition, which makes them rather hard to work with. On the other hand, measures are extended signed measures, but are not in general finite signed measures.\n\nConsider a nonnegative measure ν on the space (\"X\", Σ) and a measurable function \"f\":\"X\"→ R such that\n\nThen, a finite signed measure is given by\n\nfor all \"A\" in Σ.\n\nThis signed measure takes only finite values. To allow it to take +∞ as a value, one needs to replace the assumption about \"f\" being absolutely integrable with the more relaxed condition\n\nwhere \"f\"(\"x\") = max(−\"f\"(\"x\"), 0) is the negative part of \"f\".\n\nWhat follows are two results which will imply that an extended signed measure is the difference of two nonnegative measures, and a finite signed measure is the difference of two finite non-negative measures.\n\nThe Hahn decomposition theorem states that given a signed measure μ, there exist two measurable sets \"P\" and \"N\" such that:\n\nMoreover, this decomposition is unique up to adding to/subtracting μ-null sets from \"P\" and \"N\".\n\nConsider then two nonnegative measures μ and μ defined by\n\nand\n\nfor all measurable sets \"E\", that is, \"E\" in Σ.\n\nOne can check that both μ and μ are nonnegative measures, with one taking only finite values, and are called the \"positive part\" and \"negative part\" of μ, respectively. One has that μ = μ - μ. The measure |μ| = μ + μ is called the \"variation\" of μ, and its maximum possible value, ||μ|| = |μ|(\"X\"), is called the \"total variation\" of μ.\n\nThis consequence of the Hahn decomposition theorem is called the \"Jordan decomposition\". The measures μ, μ and |μ| are independent of the choice of \"P\" and \"N\" in the Hahn decomposition theorem.\n\nThe sum of two finite signed measures is a finite signed measure, as is the product of a finite signed measure by a real number: they are closed under linear combination. It follows that the set of finite signed measures on a measurable space (\"X\", Σ) is a real vector space; this is in contrast to positive measures, which are only closed under conical combination, and thus form a convex cone but not a vector space. Furthermore, the total variation defines a norm in respect to which the space of finite signed measures becomes a Banach space. This space has even more structure, in that it can be shown to be a Dedekind complete Banach lattice and in so doing the Radon–Nikodym theorem can be shown to be a special case of the Freudenthal spectral theorem.\n\nIf \"X\" is a compact separable space, then the space of finite signed Baire measures is the dual of the real Banach space of all continuous real-valued functions on \"X\", by the Riesz–Markov–Kakutani representation theorem.\n\n\n"}
{"id": "30892127", "url": "https://en.wikipedia.org/wiki?curid=30892127", "title": "Social pension", "text": "Social pension\n\nA social pension (also known as a non-contributory pension) is a regular cash transfer to older people. Eligibility is based on age and citizenship or residency, and almost always on means such as income, assets or other pension income. Over 100 countries in the world have some form of social pension, although design varies significantly. However, the social pension is among the guarantees of the social protection floor with ILO recommendation 202 (2012).\n\nThe term \"citizen's pension\" (known also as universal pension, demogrant or categorical pension) is used to describe a social pension that realises the right to basic income in old age. Citizen's pensions are based in law and provide cash transfers to older people subject only to tests of age and citizenship or residency, never income, assets or other pension income. A citizen's pension is not a retirement pension. There is no income test, so it is not necessary to stop working to receive it.\n\nSome researchers apply the term \"citizen's pension\" to social pensions that exclude – partially or totally - older people with other pension income, irrespective of their non-pension income or wealth. \"Universal minimum pension\" is another description of such a scheme, which tops up small pensions and provides full, basic pensions only to those with no other pension income.\n\n"}
{"id": "1742354", "url": "https://en.wikipedia.org/wiki?curid=1742354", "title": "Social risk positions", "text": "Social risk positions\n\nSocial Risk Positions are social positions that are dictated by the ability to avert risk. They are largely dependent on an individual’s ability to access knowledge. Because manufactured risk is often imperceptible to the bare human senses, social risk position must be gained by creating networks of knowledge with other humans who have a greater access to risk information. Social risk positions influence status in risk society. \n\n\nBeck, Ulrich (1992) Risk Society: Towards a New Modernity. New Delhi: Sage. (Translated from the German \"Risikogesellschaft\" published in 1986)\n"}
{"id": "39831038", "url": "https://en.wikipedia.org/wiki?curid=39831038", "title": "Stop Cyberbullying Day", "text": "Stop Cyberbullying Day\n\nStop Cyberbullying Day is an international awareness day launched by The Cybersmile Foundation on 17 June 2012, taking place on the third Friday of June annually. The day encourages people from around the world to show their commitment toward a truly inclusive and diverse online environment for all, without fear of personal threats, harassment or abuse. \n\nThe day brings together public figures, non-profit organizations, brands, governments and educational institutions who speak out against cyberbullying and abuse of any kind to defend the human right to freedom of speech and mutual respect. People show their support for the day by using the \"#STOPCYBERBULLYINGDAY\" hashtag on social media along with their message.\n\nThe next Stop Cyberbullying Day will be on June 21, 2019.\n\nBrands such as Twitter , MTV \n, Telenor, ESL (eSports) and WWE have supported Stop Cyberbullying Day through public announcements, social media posts and celebrity engagements. \n\nTelenor Group announced it would educate 4 million children in Asia by 2020 on Stop Cyberbullying Day through the launch of their \"Be A Cyberhero\" initiative. \n\nMcAfee pledged their support for Stop Cyberbullying Day and asked its customers to raise their voice and unite against cyberbullying. \n\nThe WWE released a series of videos to coincide with The Cybersmile Foundation's Stop Cyberbullying Day Public Service Announcement in 2017 with wrestlers such as The Big Show and Bayley encouraging internet users to be kind to one another. \n\nTelus announced on Stop Cyberbullying Day that they would donate $1 for every pledge made as part of a nationwide initiative to support #EndBullying programs for youth in Canada with an aim to secure 1 million pledges. \n\nSuperStroke launched a fundraiser in support of The Cybersmile Foundation with golfer Paige Spiranac on Stop Cyberbullying Day, donating 50% of proceeds of sales from limited edition putter grips. \n\nTo mark the day in 2012, The Cybersmile Foundation released research revealing that 92% of UK teachers had come across cyberbullying at some point during their career, with 78% revealing that they had personally experienced cyberbullying, whether directed at themselves, their students or other members of staff.\n\nOn Stop Cyberbullying Day 2017, a survey with 50,000 internet users in the U.S. and U.K. was released. The study explored bystander experiences of cyberbullying and online abuse.\n\nIn 2017, The Cybersmile Foundation released a PSA video on Stop Cyberbullying Day with a host of international stars calling for an end to cyberbullying. WWE Wrestlers Big Show, Bayley, teen YouTube stars Johnny Orlando and Lauren Orlando, Daniel Padilla, Kathryn Bernardo and Krista Allen were among the celebrities involved in the project. \n\nIn April 2018, The Cybersmile Foundation launched a Thunderclap campaign for Stop Cyberbullying Day to promote a kinder, more inclusive internet. The campaign was supported by a number of public figures, government departments and brands around the world including Katie Cassidy, Stephen Fry, Charles Sophy, Zoella, Jake Zyrus, UB40, Normani, Claire’s, TalkTalk Group, Barclays, Kingston Technology, ESL (eSports), Talking Tom, Born This Way Foundation, DCMS, Mental Health America and VH1. \n\nOn June 15th 2018, the campaign went live with a social reach of over 101 million internet users across Facebook and Twitter. The campaign promoted messages of diversity and inclusion online. \n\nAt the 2015 Capital Summertime Ball, artists at the show including Little Mix, Nick Jonas, Jason Derulo, Camilla Cabello, Kelly Clarkson and Carly Rae Jepsen shared their thoughts on how to deal with cyberbullying with Sugarscape ahead of Stop Cyberbullying Day during the Feel The Love Fortnight campaign. \n\nDavid Hasselhoff , William Shatner , Celine Dion , One Direction , Charlotte Crosby and Mackenzie Ziegler are among a host of public figures who have participated in Stop Cyberbullying Day, contributing memes and tweets in support of the day.\n\n\n"}
{"id": "2448457", "url": "https://en.wikipedia.org/wiki?curid=2448457", "title": "Table of Opposites", "text": "Table of Opposites\n\nThe Table of Opposites ( \"sustoichia\") of Pythagoras is the oldest surviving of many such tables propounded by philosophers. Aristotle is the main source of our knowledge of the Pythagorean table.\n\nHere follows a rough translation of the Table of Opposites, although like all translations the precise meaning does not necessarily carry over from the original Greek. For example, \"crooked\" has connotations in English that it may lack in the original.\n\n\nSome sources add:\n\n\nOf these nine or ten opposites, many philosophers have seized on the third pair as one of the most profound questions in philosophy. Is the universe one? Then how is it diverse? Is the universe many? Then how is it unified? This has historically been known as the problem of the one and the many, about which no small amount of ink has been spilled.\n\n"}
{"id": "36302385", "url": "https://en.wikipedia.org/wiki?curid=36302385", "title": "The School of Reis", "text": "The School of Reis\n\nThe School of Reis is a film theory concept relative to the teachings of Portuguese director António Reis, to his work, conceived with his wife Margarida Cordeiro, and to the works of the directors influenced by theirs.\n\nThe term \"School of Reis\" was coined by film historian Haden Guest, director of the Harvard Film Archive, when referring to the influence exerted by the school of thought of Portuguese director António Reis through his didactics at his classes as professor of the Portuguese National Filmschool, from 1977 to 1991, over generations of future Portuguese directors who learned under Reis' mentoring.\n\nThe term \"Reisian\" is sometimes applied in a similar fashion as \"Fordian\" or \"Tarkovskian\", relative to the style of both the American director John Ford or the Russian director Andrey Tarkovsky.\n\nAntónio Reis lectioned at the Portuguese National Film School classes such as \"Filmic Space\", in 1977, and later \"Film Analysis\", \"History of Image\", \"Direction of Actors\" and \"Introduction to the Study of Image\".\n\nOne of the characteristics of his teaching method was that it was almost exclusively oral, existing very few written materials reataining his theory, in what could be stated to be a reflex of António Reis' beliefs in the ancient oral tradition.\n\nOne of the most recognizable aspects of António Reis' aesthetics was his structuring of the cinematographical unity around the exploration of the limits of the possibilities of the \"match cut\" producing visual rhymes, associations and understated meanings, clearly identifiable in works of his like \"Jaime\" or \"Trás-os-Montes\".\n\nAntónio Reis' works had a major impact on the practices of contemporaries of his like Manoel de Oliveira, whom Reis assisted in his second feature, \"Rite of Spring\", in 1963; Paulo Rocha, having Reis written the script for his feature \"Change of Life\"; or João César Monteiro, whose quotations of Reis are clear in films as \"Recollections of the Yellow House\", \"God's Comedy\" or \"Silvestre\".\n\nHowever, Dennis Lim, in his article for the magazine Artforum, points out that \"for today’s preeminent Portuguese filmmakers, no single figure has been more influential than António Reis.\" Through his teachings, Reis has had a major impact in the work of subsequent filmmakers of whom he was a professor, as Joaquim Sapinho, Vítor Gonçalves, Pedro Costa, Manuela Viegas and João Pedro Rodrigues. Some of them, like Sapinho, Gonçalves or Viegas are today professors at the Escola Superior de Teatro e Cinema, the current name for the former Portuguese National Film School.\n\nThe film program known by \"The School of Reis: The Films and Legacy of António Reis and Margarida Cordeiro\", curated by film scholar Haden Guest, was premiered at the Harvard Film Archive in May 2012, followed by a presence at the Anthology Film Archives in June 2012 and at UCLA Film and Television Archive in July 2012. It was the first complete retrospective of António Reis and Margarida Cordeiro's work outside their native Portugal, and is composed of eleven films:\n\n\n"}
{"id": "22606368", "url": "https://en.wikipedia.org/wiki?curid=22606368", "title": "The Spirit Level (book)", "text": "The Spirit Level (book)\n\nThe Spirit Level: Why More Equal Societies Almost Always Do Better is a book by Richard G. Wilkinson and Kate Pickett, published in 2009 by Allen Lane. The book is published in the US by Bloomsbury Press (December, 2009) with the new sub-title: Why Greater Equality Makes Societies Stronger. It was then published in a paperback second edition (United Kingdom) in November 2010 by Penguin Books with the subtitle, Why Equality is Better for Everyone.\n\nThe book argues that there are \"pernicious effects that inequality has on societies: eroding trust, increasing anxiety and illness, (and) encouraging excessive consumption\". It claims that for each of eleven different health and social problems: physical health, mental health, drug abuse, education, imprisonment, obesity, social mobility, trust and community life, violence, teenage pregnancies, and child well-being, outcomes are significantly worse in more unequal countries, whether rich or poor.\nThe book contains graphs that are available online.\n\nIn 2010, the authors published responses to questions about their analysis on the Equality Trust website. As of September 2012, the book had sold more than 150,000 copies in English. It is available in 23 foreign editions.\n\n\n\n\nIn a review for \"Nature\", Michael Sargent said that \"In their new book, epidemiologists Richard Wilkinson and Kate Pickett extend this idea\" (of the harm caused by status differences) \"with a far-reaching analysis of the social consequences of income inequality. Using statistics from reputable independent sources, they compare indices of health and social development in 23 of the world's richest nations and in the individual US states. Their striking conclusion is that the societies that do best for their citizens are those with the narrowest income differentials—such as Japan and the Nordic countries and the US state of New Hampshire. The most unequal—the United States as a whole, the United Kingdom and Portugal—do worst.\"\n\nIn the \"London Review of Books\" University of Cambridge lecturer David Runciman said that the book fudged the issue of its subtitle thesis of its UK first edition, and asked whether it is that “in more equal societies almost everyone does better, or is it simply that everyone does better on average?\" Later in the review he stated that, \"More equality is a good thing and it’s an idea that’s worth defending.\" Richard Wilkinson responded to the review in a letter, claiming that \"while pointing out that we do not have evidence on the fraction of one percent who are very rich, we show that people at all other levels of the social hierarchy do better in more equal societies\".\n\nBoyd Tonkin, writing in \"The Independent\", described it as \"an intellectual flagship of post-crisis compassion, this reader-friendly fusion of number-crunching and moral uplift has helped steer a debate about the route to a kinder, fairer nation. Will Hutton in \"The Observer\" described it as \"A remarkable new book ...the implications are profound.\" Roy Hattersley in the \"New Statesman\" called it \"a crucial contribution to the ideological argument\", and the \"New Statesman\" listed it as one of their top ten books of the decade.\n\nJohn Kay in \"The Financial Times\" said that \"the evidence presented in the book is mostly a series of scatter diagrams, with a regression line drawn through them. No data is provided on the estimated equations, or on relevant statistical tests\". The significance tests and correlation coefficients were included in the November 2010 revised paperback edition of the book, and also appear on the Equality Trust website, where source data is also available and there is an explanation for the omission that \"the book's intended readership was not confined to those with statistical training\".\n\nRichard Reeves in \"The Guardian\" called the book \"a thorough-going attempt to demonstrate scientifically the benefits of a smaller gap between rich and poor\", but said there were problems with the book's approach. \"Drawing a line through a series of data points signals nothing concrete about statistical significance ... since they do not provide any statistical analyses, this can't be verified.\" He later noted that, \"\"The Spirit Level\" is strongest on Wilkinson's home turf: health. The links between average health outcomes and income inequality do appear strong, and disturbing\".\n\nIn the \"European Sociological Review\", sociologist John Goldthorpe argued that the book relied too heavily on income inequality over other forms of inequality (including broader economic inequality), and demonstrated a one-dimensional understanding of social stratification, with social class being in effect treated as merely a marker for income. He concluded that much more research was needed to support either the Wilkinson and Pickett \"account of the psychosocial generation of the contextual effects of inequality on health or the rival neo-materialist account\".\n\nCharles Moore in \"The Daily Telegraph\" declared it to be \"more a socialist tract than an objective analysis of poverty\". Gerry Hassan in \"The Scotsman\" maintained against Wilkinson and Pickett's claim that \"more equal societies almost always do better\" that it \"is not possible to make the claim that everyone gains from greater equality\", and suggests one of the book's \"central weaknesses\" is the \"absence of the importance of politics... They let neo-liberalism and free market fundamentalism off the hook\".\n\nIn 2010, Tino Sanandaji and others wrote an article for the \"Wall Street Journal\" in which they said, \"when we attempted to duplicate their findings with data from the U.N. and the Organisation for Economic Co-operation and Development (OECD), we found no such correlation\". Pickett and Wilkinson addressed the \"Wall Street Journal\" article in a letter to the \"Journal\" and published a response to the Taxpayers Alliance report on their own site.\nIn their response to the Wall Street Journal they said ,\"...we use income inequality data from the United Nations, rather than the OECD, because the OECD data were not intended primarily for cross-national comparisons. However, even if we test our results using the OECD measures we find 28 of 29 relationships are still significant\".'\n\nPeter Robert Saunders, Professor Emeritus of Sociology at Sussex University, published a report for the think tank Policy Exchange questioning the statistics in \"The Spirit Level\". He claimed that only one of the correlations in the book—that between infant mortality and income inequality—stood up to scrutiny, and that the rest were either false or ambiguous. Wilkinson and Pickett published a response defending each of the claims in the book and accusing Saunders in turn of flawed methodology. Saunders' statistical analysis was also assessed by Hugh Noble, who published an article explaining statistical inference in \"The Spirit Level\" and assessing the critique offered by Peter Saunders. Noble concluded that the critical analysis of The Spirit Level offered by Peter Saunders 'cannot be taken seriously because it contains so many serious technical flaws'.\n\nChristopher Snowdon, an independent researcher and adjunct scholar at the Democracy Institute, published a book largely devoted to a critique of \"The Spirit Level\", entitled, \"The Spirit Level Delusion: Fact-checking the Left's New Theory of Everything\". One of its central claims is that the authors have cherry-picked throughout. Snowdon suggests that Wilkinson excludes certain countries from his data without justification, such as South Korea and the Czech Republic. The book includes homicide, but excludes suicide. Prison population is included, but not the crime rate or crime survey data. Government foreign aid is included, but (private) charitable giving is not. Datasets are selected or rejected to support the thesis of the authors. Likely cultural confounding factors are not taken into account. Regression lines are drawn which are dependent on a very small number of outlying countries, but this is not explained in the text. Correlation is confused with causation throughout. It also argues that Wilkinson and Pickett falsely claim the existence of a scientific consensus when much of the literature disagrees with their findings. Snowdon's book also asserts that some of Wilkinson's previous publications have been criticized on the basis that \"the strength of the association...seems quite sensitive to which countries are included\". Finally, in a reductio ad absurdum, the methods of TSL are used to show that the suicide rate is linked to the recycling rate.\nWilkinson and Pickett released a response to questions from Snowdon and responded to similar criticisms in the \"Wall Street Journal\". Snowdon has in turn responded to their response on his blog.\n\nIn response to criticism of the book, Wilkinson and Pickett posted a note on the Equality Trust website which stated: \"Almost all of the research presented and synthesised in \"The Spirit Level\" had previously been peer-reviewed, and is fully referenced therein. In order to distinguish between well founded criticism and unsubstantiated claims made for political purposes, all future debate should take place in peer-reviewed publications.\" A Postscript chapter was also written in response to critics and is available in the US and UK second editions of \"The Spirit Level\".\n\nIn 2011 the Joseph Rowntree Foundation commissioned an independent review of the evidence about the impact of inequality, paying particular attention to the evidence and arguments put forward in \"The Spirit Level\". It concluded that the literature shows general agreement about a correlation between income inequality and health/social problems, though suggested there is less agreement about whether income inequality causes health and social problems independently of other factors. It argued for further research on income inequality and discussion of the policy implications.\n\n75 MPs signed the Equality Trust's 'Equality Pledge' prior to the UK's 2010 general election. Signatories promised to \"actively support the case for policies designed to narrow the gap between rich and poor\". Ed Miliband, former leader of the British Labour party, wrote about his admiration for The Spirit Level. His first speech as leader to the party conference contained several allusions to the book. David Cameron referred to the thesis of \"The Spirit Level\" in his 2010 Hugo Young Lecture, arguing \"research by Richard Wilkson and Katie [sic] Pickett has shown that among the richest countries, it's the more unequal ones that do worse according to almost every quality of life indicator\".\n\nThe book has prompted a documentary, to be called \"The Divide\". and directed by British film-maker Katharine Round and produced by Round and Christopher Hird. The film ran one of the most successful UK documentary crowdfunding campaigns to date, and , filming was near complete with additional funding needed to enable release.\n\nThink tank Class in association with The Equality Trust and My Fair London published a booklet drawing on \"The Spirit Level\" as well as presenting other essential information about income inequality.\n\nIn 2010, Richard Wilkinson was appointed the chair of Islington's Fairness Commission to examine ways of reducing income inequality in the London borough.\n\n\n"}
{"id": "30702076", "url": "https://en.wikipedia.org/wiki?curid=30702076", "title": "Violence begets violence", "text": "Violence begets violence\n\nThe phrase \"violence begets violence\" (or \"hate begets hate\") means that violent behavior promotes other violent behavior, in return. The phrase has been used since at least the 1830s.\n\nViolence begets violence is a concept described in the Gospel of Matthew, verse 26:52. The passage depicts a disciple (identified in the Gospel of John as Saint Peter) drawing a sword to defend against the arrest of Jesus but being told to sheath his weapon:\n\n\"Put your sword back in its place,\" Jesus said to him, \"for all who draw the sword will die by the sword.\"\n\nMartin Luther King Jr. (1929–1968) used the phrase when saying:\n\n"}
{"id": "4177288", "url": "https://en.wikipedia.org/wiki?curid=4177288", "title": "Vithkuqi alphabet", "text": "Vithkuqi alphabet\n\nVithkuqi script, also called Büthakukye or Beitha Kukju after the appellation applied to it by German Albanologist Johann Georg von Hahn, was an alphabet invented for writing the Albanian language between 1825 and 1845 by Albanian scholar Naum Veqilharxhi. Though the script is sometimes erroneously claimed to be named after its inventor, as in Carl Faulmann's \"Das Buch der Schrift\", the alphabet's name is derived from Vithkuq, a village in the Korçë region where Veqilharxhi was born. Vithkuqi script was specifically designed to be as religiously neutral as possible, avoiding the duplication of Greek, Latin, or Arabic characters. It had a near-perfect correspondence between letters and phonemes, but lacked characters for modern Albanian \"gj\", \"rr\", \"xh\", and \"zh\". The script never took hold because of its inventor's premature death and because of the prohibitive costs of cutting new type for the invented characters; nevertheless, a number of documents using the script were published in the late 19th century. The script was eventually overwhelmed by the Greek, Arabic and Latin scripts it had been designed to supplant, the latter becoming the official one in 1909.\n\nOther original scripts used for Albanian were the Elbasan script and the Todhri script of the 18th century. These scripts similarly failed to see prolonged widespread usage.\n\n\n \n"}
{"id": "9501159", "url": "https://en.wikipedia.org/wiki?curid=9501159", "title": "Well-pointed category", "text": "Well-pointed category\n\nIn category theory, a category with a terminal object formula_1 is well-pointed if for every pair of arrows formula_2 such that formula_3, there is an arrow formula_4 such that formula_5. (The arrows formula_6 are called the global elements or \"points\" of the category; a well-pointed category is thus one that has \"enough points\" to distinguish non-equal arrows.)\n\n"}
{"id": "54005931", "url": "https://en.wikipedia.org/wiki?curid=54005931", "title": "World Conference on Women, 1980", "text": "World Conference on Women, 1980\n\nThe World Conference on Women, 1980 or the Second World Conference on Women took place between 14 and 30 July 1980 in Copenhagen, Denmark as the mid-decade assessment of progress and failure in implementing the goals established by the World Plan of Action at the 1975 inaugural conference on women. The most significant event to come out of the conference was that the formal signing of the Convention on the Elimination of All Forms of Discrimination Against Women took place during the opening ceremony of the conference. Marred by conflict and politicization of international and national events which had little to do with women's issues, the conference was viewed by some participants as a failure. They were able to secure passage of a modified World Programme of Action to expand on previous targets to improve women's status, and established a follow-up conference for the end of the decade.\n\nThe 1980 Conference held from 14 and 30 July in Copenhagen, Denmark was the direct result of the First World Conference on Women, which had been held in Mexico City in 1975, establishing the World Plan of Action and Declaration of Mexico on the Equality of Women and Their Contribution to Development and Peace. These documents took the United Nations themes—Development, Equality, and Peace—of their path for women and created guidelines for nations to reach long-term objectives to improve the lives of women. When they were adopted, the UN established 1975 to 1985 as the Decade for Women and put in motion a plan for subsequent conferences to evaluate progress being made. The format of the conference was the same, with the official session made up of delegates representing their governments and the Tribune, representing NGOs.\n\nAs with the previous conference, the Copenhagen conference was beset by the geopolitical divides of the Cold War and whether economics, racism, or sexism was the more important factor in the subordination of women. Initially planned to occur in Tehran, the Iranian Revolution of 1979 and the Iran hostage crisis, escalated the political backdrop as did the continuing tensions of conflict in the Middle East. Palestinian women, refugees, and Apartheid became topics that were added to the agenda and ensured that the event would be politicized by the various participants, rather than remaining focused on women's issues. To that end, the United States Congress issued instructions to its delegates that they would not approve any resolution which attempted to make what should be an apolitical conference into an indictment of government policy or any resolution which mentioned the word \"Zionism\". Saudi Arabia and South Africa boycotted the convention altogether. Having to hastily relocate the conference to Denmark, also impacted the accommodations available, in that there was no space large enough to accommodate the entire Tribune, which meant that rather than the entire group participating in exchange to create unity, the group was splintered into small venues.\n\nThe Conference was the mid-point review of the decade and the conference president was Lise Østergaard, Cultural Minister of Denmark. The Secretary-General of the conference was Lucille Mair, a Jamaican academic and single mother, whose primary focus was on the development theme of the triad. Discussion on the New International Economic Order subverted the discussion from being about what women needed to what the various governments needed from women or for women to reach their national goals. At one point, it was suggested that if Westernized nations would provide more funding for economic development, discrimination against women would vanish. Partisan political issues, such as insertion of the socialist economic system into the section dealing with the historical perspective on women, the repeated interruption of Israeli delegates with Muslim drummers and singers, and a storming of the conference by women protesting the Bolivian coup d'état were just some of the manifestations of the divides.\n\nOne hundred forty-five states with around 1500 delegates participated in the official session, including delegates like: of the USSR; Shirley Field-Ridley of Guyana; Ana Sixta González de Cuadros of Colombia; Helga Hörz of East Germany; of Senegal; Sheila Kaul of India; Ifigenia Martínez of Mexico; of Austria; Inonge Mbikusita-Lewanika of Zambia; Elizabeth Anne Reid of Australia; Ginko Sato of Japan; Umayya Toukan of Jordan; Sarah Weddington, who headed the US delegation, among many others.\n\nAfter opening remarks by Kurt Waldheim, Secretary-General of the United Nations, Queen Margrethe II of Denmark welcomed participants and expressed her hope that the conference would prove productive. Anker Jørgensen, Danish Prime Minister spoke briefly, followed by opening remarks by Lise Østergaard, followed by the general discussion. Debates were strongly affected by post-colonial and socialist claims of women's advancement in centrally planned economies in which the state had an obligation to prevent and an accountability for discrimination against women. Having established mechanisms in the previous conference to gather data on the status of women, review of the statistical data showed that women's security had dwindled over the preceding five-year period. Among the documentation were statistics showing that while women put in two-thirds of all working hours, they received only one-tenth of the income, owning one-hundredth of its assets. Economic stagnation and industrialization in the period had led to significant increases in unemployment and benefits for women. Jobs which were available confined women to insecure, low-paid, and sex-stereotyped jobs and as much of their labor was toward unpaid production, it was still invisible in compiled economic reports. Decreased earnings had elevated health concerns. While literacy rates for middle class women increased, overall illiteracy among women increased. One of the most contentious issues discussed was the situation of households headed by women. Many officials denied that there could be such a thing, as legally in their countries women were not allowed to be the head of a household. On the other hand, one of the most memorable moments was when the delegates signed the Convention on the Elimination of All Forms of Discrimination Against Women (CEDAW) on 17 July.\n\nThe first committee, under the chair Maïmouna Kane, with vice-chairs, Rafidah Aziz of Malaysia, Maria Groza of Romania, and Leónidas Páez de Virgili of Paraguay, with Rapporteur of Belgium, discussed the effects of Apartheid and the Israeli-occupied territories on women; the progress and obstacles in attaining the objectives of the World Plan of Action; and the proposal for the World Programme of Action for the second-half of the Decade for Women. Of major concern was labor insecurity, caused either by the introduction of technologies which replaced women laborers or by the informal nature of many jobs open to women in developing countries. The committee discussed that more effort should be made to retrain laborers when their positions were eliminated by technological advances and that legal protections should be enacted. Also of grave concern was education of women to not only eliminate illiteracy but to make them aware of social and political processes and how they could be part of decision-making mechanisms. Apartheid and racism were condemned by the committee, as was the Zionist policy of Israel which was linked to racism. The discussion on the Palestinian right to self-determination was endorsed, though it was noted that when the Palestinian people as a whole were denied basic human rights, discussing the rights of only women was futile. Various draft resolutions, including resolutions to improve education and training, address women with disabilities, provide support for women migrants and refugees, provide economic security for elderly women, and to address violence against women. With modifications, the committee recommended approval of the Programme and accepted CEDAW with few reservations.\n\nThe second committee, under the chair Sheila Kaul, with vice-chairs, Nermin Abadan-Unat of Turkey, María de Lourdes Castro e Silva de Vincenzi of Brazil, and Chavdar Kyuranov of Bulgaria, with Rapporteur Ali Benbouchta of Morocco, discussed an agenda identical to the first committee's focal points. Apartheid was rejected and the committee recommended that with its eradication, women in South Africa and bordering refugee states should be compensated with the means to reconstruct their societies in ways that created avenues for women's participation. With regard to the review of the Programme, the committee noted that without change in socio-economic systems, equality for women remained elusive. It was noted that globalization led to an increasing need to pursue paths for disarmament, peace and international cooperation. It was also noted that regional systems needed to be fully integrated to allow women's participation but additionally new programs organized specifically for women should be explored. The situation of refugee women, their vulnerabilities to exploitation and violence and the need to protect their human rights. On the question of Palestinian women, the committee recognized that material assistance would do little to stop insecurity unless Israel ended its colonization, returned land to its owners and worked toward a durable peace. The committee examined several draft resolutions regarding peace initiatives, refugees, water insecurity, and adding women to census figures, as well as draft resolutions on health and welfare, protecting families from defaulted support obligations, drug trafficking and forced disappearance, and integrating women into the UN system and programs. With modifications, the committee recommended approval of the Programme.\n\nThe planning of the 1980 Tribune, or Forum as it was called in Copenhagen, was led by Edith Ballantyne, the executive secretary of the Women's International League for Peace and Freedom (WILPF) and president of the United Nations Conference of Non-governmental Organizations (CONGO). Elizabeth Palmer, a representative of the YWCA chaired the actual Forum, which was hosted at the Copenhagen University Amager Campus. The success of developing transnational networks of women was evident in the expansion of attendees at the NGO Tribune from 6000 participants in Mexico City to around 8000 in Copenhagen. Many complained of the inadequacy of the forum facilities, including the fact that child care had not been considered. The forum was split into small sessions consisting of around 200 meetings per day. Because of the lack of translators, and the fact that conferences were labeled as of concern to developed or developing nations, in-depth discussion was difficult and often barely touched the surface of issues. Peggy Antrobus and Charlotte Bunch, with sponsorship from the University of the West Indies' Women and Development Department and the Asian Pacific Centre for Women and Development (APCWD), recently relocated from Tehran to Bangkok, organized an orientation video \"Feminist Strategies for the Decade\" which was shown daily. Irene Tinker\n\nThe politicization of the official conference also influenced the NGO Tribune, resulting in tensions and displays of nationalism, such as Iranian women holding a news conference to celebrate their revolution by calling for the use of the hijab as a protest against colonialism and Ukrainian women protesting for independence. When Nawal El Saadawi of Egypt presented a paper on female circumcision, western feminists were advised that the issue was a developing world problem and not their concern. Lesbians attendees hosted five workshops, which were well attended and less controversial than at the 1975 conference. Some of the prominent women attendees were Shulamit Aloni of Israel; Marie Assaad of Egypt; Charlotte Bunch, US lesbian activist; Phyllis Chesler a US expert on refugees; Betty Friedan, founder of the National Organization for Women (NOW); Natalia Malakhovskaia, Soviet exile; Marie-Angélique Savané of Senegal. As they had in Mexico City, the members of the Forum continued the tradition of presenting their additions to the Programme of Action at the official session. A group of women led by Domitila Barrios de Chungara were met by police and barred from entering the plenary meeting until Lucille Mair met with them and allowed the recommendations to be presented.\n\nThe most significant outcome of the conference was the official signing of CEDAW by the delegates at the opening ceremony. The conference adopted the official World Programme of Action with a vote of with ninety-four favorable votes, twenty-two abstentions, and four opposed—Australia, Canada, Israel and the United States. It included sections to create women's bureaus or agencies, defined the roles of NGO and grassroots organizations, and established target issues countries were to monitor. Those issues included child care, households headed by women, migrants, rural women, unemployment, and youth. The Programme also included a section regarding water insecurity, but the most significant changes to the previous Plan of Action were sections devoted to ensuring equal access to education, employment opportunities, and adequate health care. The Conference established the Third World Conference on Women for the end of the decade to be hosted in Nairobi, Kenya in 1985 with a back up location in Tokyo.\n\nThe conference was seen by those who rejected the Programme as having been a failed process. Rather than a serious discussion of the inequalities between men and women, the conference had limited discussion to politicizing international events, ideological principals and controversies, which obscured the real needs of women to participate in decision-making and economic development, and benefit equally in family matters, health, education and employment. Multiple countries which had abstained from voting expressed disappointment that the process, rather than dealing with women's issues, had duplicated work better suited for the General Assembly.\n\nOverall, the conference and forum conference were marred by conflict and politicization of international and national events which had little to do with women's issues. The official agenda was obscured by nationalist causes pitting the developing countries of the South and the developed countries of the North against each other. The question for continued participation in the conferences left many asking if the focus could be shifted away from political issues and return to the problems related to women: aging; credit for economic development; double duties between work and family; fertility versus infertility; shortage of heat and inadequate water, support systems and lack of them; women’s health; and violence against women.\n\n"}
{"id": "1977205", "url": "https://en.wikipedia.org/wiki?curid=1977205", "title": "World Hello Day", "text": "World Hello Day\n\nWorld Hello Day is a secular holiday observed annually on November 21, to express that conflicts should be resolved through communication rather than the use of force. Participants verbally greet ten people or more on that day as an expression of the importance of personal communication in preserving peace. The annual global event began to be celebrated in 1973 as a response to the Yom Kippur War.\n\nEvery year, November 21 is World Hello Day. The objective is to greet to at least ten people on the day. The message is for world leaders to use communication rather than force to settle conflicts.\n\nWorld Hello Day was founded in 1973 by Brian McCormack, a Ph.D. graduate of Arizona State University, and Michael McCormack, a graduate of Harvard University, in response to the Yom Kippur War. The McCormack brothers mailed 1360 letters, in seven languages, to government leaders worldwide to encourage participation in the first World Hello Day. Since that time, World Hello Day has been observed by people in 180 countries.\n\nAny person can participate in World Hello Day simply by greeting ten people or more. This demonstrates the importance of personal communication for preserving peace. World Hello Day was begun in response to the conflict between Egypt and Israel in the fall of 1973. People around the world use the occasion of World Hello Day as an opportunity to express their concern for world peace. Beginning with a simple greeting on World Hello Day, their activities send a message to leaders, encouraging them to use communication rather than force to settle conflicts. In its first year, World Hello Day gained the support of 15 countries. As a global event World Hello Day joins local participation in a global expression of peace.\n\nWinners of the Nobel Peace Prize are among the people who have noted World Hello Day's value as an instrument for preserving peace and as an occasion that makes it possible for anyone in the world to contribute to the process of creating peace. Other supporters include almost 100 authors, entertainers, and world leaders.\n\n"}
{"id": "32977", "url": "https://en.wikipedia.org/wiki?curid=32977", "title": "Writing", "text": "Writing\n\nWriting is a medium of human communication that represents language and emotion with signs and symbols. In most languages, writing is a complement to speech or spoken language. Writing is not a language, but a tool used to make languages be read. Within a language system, writing relies on many of the same structures as speech, such as vocabulary, grammar, and semantics, with the added dependency of a system of signs or symbols. The result of writing is called \"text\", and the recipient of text is called a \"reader\". Motivations for writing include publication, storytelling, correspondence, record keeping and diary. Writing has been instrumental in keeping history, maintaining culture, dissemination of knowledge through the media and the formation of legal systems.\n\nAs human societies emerged, the development of writing was driven by pragmatic exigencies such as exchanging information, maintaining financial accounts, codifying laws and recording history. Around the 4th millennium BC, the complexity of trade and administration in Mesopotamia outgrew human memory, and writing became a more dependable method of recording and presenting transactions in a permanent form. In both ancient Egypt and Mesoamerica, writing may have evolved through calendric and a political necessity for recording historical and environmental events.\n\nH.G. Wells argued that writing has the ability to \"put agreements, laws, commandments on record. It made the growth of states larger than the old city states possible. It made a continuous historical consciousness possible. The command of the priest or king and his seal could go far beyond his sight and voice and could survive his death\".\n\nThe major writing systems—methods of inscription—broadly fall into five categories: logographic, syllabic, alphabetic, featural, and ideographic (symbols for ideas). A sixth category, pictographic, is insufficient to represent language on its own, but often forms the core of logographies.\n\nA logogram is a written character which represents a word or morpheme. A vast number of logograms are needed to write Chinese characters, cuneiform, and Mayan, where a glyph may stand for a morpheme, a syllable, or both—(\"logoconsonantal\" in the case of hieroglyphs). Many logograms have an ideographic component (Chinese \"radicals\", hieroglyphic \"determiners\"). For example, in Mayan, the glyph for \"fin\", pronounced \"ka\", was also used to represent the syllable \"ka\" whenever the pronunciation of a logogram needed to be indicated, or when there was no logogram. In Chinese, about 90% of characters are compounds of a semantic (meaning) element called a \"radical\" with an existing character to indicate the pronunciation, called a \"phonetic\". However, such phonetic elements complement the logographic elements, rather than vice versa.\n\nThe main logographic system in use today is Chinese characters, used with some modification for the various languages or dialects of China, Japan, and sometimes in Korean despite the fact that in South and North Korea, the phonetic Hangul system is mainly used.\n\nA syllabary is a set of written symbols that represent (or approximate) syllables. A glyph in a syllabary typically represents a consonant followed by a vowel, or just a vowel alone, though in some scripts more complex syllables (such as consonant-vowel-consonant, or consonant-consonant-vowel) may have dedicated glyphs. Phonetically related syllables are not so indicated in the script. For instance, the syllable \"ka\" may look nothing like the syllable \"ki\", nor will syllables with the same vowels be similar.\n\nSyllabaries are best suited to languages with a relatively simple syllable structure, such as Japanese. Other languages that use syllabic writing include the Linear B script for Mycenaean Greek; Cherokee; Ndjuka, an English-based creole language of Surinam; and the Vai script of Liberia. Most logographic systems have a strong syllabic component. Ethiopic, though technically an abugida, has fused consonants and vowels together to the point where it is learned as if it were a syllabary.\n\nAn alphabet is a set of symbols, each of which represents or historically represented a phoneme of the language. In a perfectly phonological alphabet, the phonemes and letters would correspond perfectly in two directions: a writer could predict the spelling of a word given its pronunciation, and a speaker could predict the pronunciation of a word given its spelling.\n\nAs languages often evolve independently of their writing systems, and writing systems have been borrowed for languages they were not designed for, the degree to which letters of an alphabet correspond to phonemes of a language varies greatly from one language to another and even within a single language.\n\nIn most of the writing systems of the Middle East, it is usually only the consonants of a word that are written, although vowels may be indicated by the addition of various diacritical marks. Writing systems based primarily on marking the consonant phonemes alone date back to the hieroglyphs of ancient Egypt. Such systems are called \"abjads\", derived from the Arabic word for \"alphabet\".\n\nIn most of the alphabets of India and Southeast Asia, vowels are indicated through diacritics or modification of the shape of the consonant. These are called \"abugidas\". Some abugidas, such as Ethiopic and Cree, are learned by children as syllabaries, and so are often called \"syllabics\". However, unlike true syllabaries, there is not an independent glyph for each syllable.\n\nSometimes the term \"alphabet\" is restricted to systems with separate letters for consonants and vowels, such as the Latin alphabet, although abugidas and abjads may also be accepted as alphabets. Because of this use, Greek is often considered to be the first alphabet.\n\nA featural script notates the building blocks of the phonemes that make up a language. For instance, all sounds pronounced with the lips (\"labial\" sounds) may have some element in common. In the Latin alphabet, this is accidentally the case with the letters \"b\" and \"p\"; however, labial \"m\" is completely dissimilar, and the similar-looking \"q\" and \"d\" are not labial. In Korean hangul, however, all four labial consonants are based on the same basic element, but in practice, Korean is learned by children as an ordinary alphabet, and the featural elements tend to pass unnoticed.\n\nAnother featural script is SignWriting, the most popular writing system for many sign languages, where the shapes and movements of the hands and face are represented iconically. Featural scripts are also common in fictional or invented systems, such as J.R.R. Tolkien's Tengwar.\n\nHistorians draw a sharp distinction between prehistory and history, with history defined by the advent of writing. The cave paintings and petroglyphs of prehistoric peoples can be considered precursors of writing, but they are not considered true writing because they did not represent language directly.\n\nWriting systems develop and change based on the needs of the people who use them. Sometimes the shape, orientation, and meaning of individual signs changes over time. By tracing the development of a script, it is possible to learn about the needs of the people who used the script as well as how the script changed over time.\n\nThe many tools and writing materials used throughout history include stone tablets, clay tablets, bamboo slats, papyrus, wax tablets, vellum, parchment, paper, copperplate, styluses, quills, ink brushes, pencils, pens, and many styles of lithography. The Incas used knotted cords known as quipu (or khipu) for keeping records.\n\nThe typewriter and various forms of word processors have subsequently become widespread writing tools, and various studies have compared the ways in which writers have framed the experience of writing with such tools as compared with the pen or pencil.\n\nBy definition, the modern practice of history begins with written records. Evidence of human culture without writing is the realm of prehistory. The Dispilio Tablet (Greece), Jiahu symbols (China) and Tărtăria tablets (Romania), which have been carbon dated to the 6th millennium BC, are recent discoveries of the earliest known neolithic writings.\n\nWhile neolithic writing is a current research topic, conventional history assumes that the writing process first evolved from economic necessity in the ancient Near East. Writing most likely began as a consequence of political expansion in ancient cultures, which needed reliable means for transmitting information, maintaining financial accounts, keeping historical records, and similar activities. Around the 4th millennium BC, the complexity of trade and administration outgrew the power of memory, and writing became a more dependable method of recording and presenting transactions in a permanent form.\n\nArchaeologist Denise Schmandt-Besserat determined the link between previously uncategorized clay \"tokens\", the oldest of which have been found in the Zagros region of Iran, and the first known writing, Mesopotamian cuneiform. In approximately 8000 BC, the Mesopotamians began using clay tokens to count their agricultural and manufactured goods. Later they began placing these tokens inside large, hollow clay containers (bulla, or globular envelopes) which were then sealed. The quantity of tokens in each container came to be expressed by impressing, on the container's surface, one picture for each instance of the token inside. They next dispensed with the tokens, relying solely on symbols for the tokens, drawn on clay surfaces. To avoid making a picture for each instance of the same object (for example: 100 pictures of a hat to represent 100 hats), they 'counted' the objects by using various small marks. In this way the Sumerians added \"a system for enumerating objects to their incipient system of symbols\".\n\nThe original Mesopotamian writing system (believed to be the world's oldest) was derived around 3600 BC from this method of keeping accounts. By the end of the 4th millennium BC, the Mesopotamians were using a triangular-shaped stylus pressed into soft clay to record numbers. This system was gradually augmented with using a sharp stylus to indicate what was being counted by means of pictographs. Round-stylus and sharp-stylus writing was gradually replaced by writing using a wedge-shaped stylus (hence the term cuneiform), at first only for logograms, but by the 29th century BC also for phonetic elements. Around 2700 BC, cuneiform began to represent syllables of spoken Sumerian. About that time, Mesopotamian cuneiform became a general purpose writing system for logograms, syllables, and numbers. This script was adapted to another Mesopotamian language, the East Semitic Akkadian (Assyrian and Babylonian) around 2600 BC, and then to others such as Elamite, Hattian, Hurrian and Hittite. Scripts similar in appearance to this writing system include those for Ugaritic and Old Persian. With the adoption of Aramaic as the 'lingua franca' of the Neo-Assyrian Empire (911–609 BC), Old Aramaic was also adapted to Mesopotamian cuneiform. The last cuneiform scripts in Akkadian discovered thus far date from the 1st century AD.\n\nOver the centuries, three distinct Elamite scripts developed.\nProto-Elamite is the oldest known writing system from Iran. In use only for a brief time (c. 3200–2900 BC), clay tablets with Proto-Elamite writing have been found at different sites across Iran. The Proto-Elamite script is thought to have developed from early cuneiform (proto-cuneiform). The Proto-Elamite script consists of more than 1,000 signs and is thought to be partly logographic.\n\nLinear Elamite is a writing system attested in a few monumental inscriptions in Iran. It was used for a very brief period during the last quarter of the 3rd millennium BC. It is often claimed that Linear Elamite is a syllabic writing system derived from Proto-Elamite, although this cannot be proven since Linear-Elamite has not been deciphered. Several scholars have attempted to decipher the script, most notably and .\n\nThe Elamite cuneiform script was used from about 2500 to 331 BC, and was adapted from the Akkadian cuneiform. The Elamite cuneiform script consisted of about 130 symbols, far fewer than most other cuneiform scripts.\n\nCretan hieroglyphs are found on artifacts of Crete (early-to-mid-2nd millennium BC, MM I to MM III, overlapping with Linear A from MM IIA at the earliest). Linear B, the writing system of the Mycenaean Greeks, has been deciphered while Linear A has yet to be deciphered. The sequence and the geographical spread of the three overlapping, but distinct writing systems can be summarized as follows: Cretan hieroglyphs were used in Crete from c. 1625 to 1500 BC; Linear A was used in the Aegean Islands (Kea, Kythera, Melos, Thera), and the Greek mainland (Laconia) from c. 18th century to 1450 BC; and Linear B was used in Crete (Knossos), and mainland (Pylos, Mycenae, Thebes, Tiryns) from c. 1375 to 1200 BC.\n\nThe earliest surviving examples of writing in China—inscriptions on so-called \"oracle bones\", tortoise plastrons and ox scapulae used for divination—date from around 1200 BC in the late Shang dynasty. A small number of bronze inscriptions from the same period have also survived.\nHistorians have found that the type of media used had an effect on what the writing was documenting and how it was used.\n\nIn 2003, archaeologists reported discoveries of isolated tortoise-shell carvings dating back to the 7th millennium BC, but whether or not these symbols are related to the characters of the later oracle-bone script is disputed.\n\nThe earliest known hieroglyphic inscriptions are the Narmer Palette, dating to c. 3200 BC, and several recent discoveries that may be slightly older, though these glyphs were based on a much older artistic rather than written tradition. The hieroglyphic script was logographic with phonetic adjuncts that included an effective alphabet.\n\nWriting was very important in maintaining the Egyptian empire, and literacy was concentrated among an educated elite of scribes. Only people from certain backgrounds were allowed to train to become scribes, in the service of temple, pharaonic, and military authorities. The hieroglyph system was always difficult to learn, but in later centuries was purposely made even more so, as this preserved the scribes' status.\n\nThe world's oldest known alphabet appears to have been developed by Canaanite turquoise miners in the Sinai desert around the mid-19th century BC. Around 30 crude inscriptions have been found at a mountainous Egyptian mining site known as Serabit el-Khadem. This site was also home to a temple of Hathor, the \"Mistress of turquoise\". A later, two line inscription has also been found at Wadi el-Hol in Central Egypt. Based on hieroglyphic prototypes, but also including entirely new symbols, each sign apparently stood for a consonant rather than a word: the basis of an alphabetic system. It was not until the 12th to 9th centuries, however, that the alphabet took hold and became widely used.\n\nIndus script refers to short strings of symbols associated with the Indus Valley Civilization (which spanned modern-day Pakistan and North India) used between 2600 and 1900 BC. In spite of many attempts at decipherments and claims, it is as yet undeciphered. The term 'Indus script' is mainly applied to that used in the mature Harappan phase, which perhaps evolved from a few signs found in early Harappa after 3500 BC, and was followed by the mature Harappan script. The script is written from right to left, and sometimes follows a boustrophedonic style. Since the number of principal signs is about 400–600, midway between typical logographic and syllabic scripts, many scholars accept the script to be logo-syllabic (typically syllabic scripts have about 50–100 signs whereas logographic scripts have a very large number of principal signs). Several scholars maintain that structural analysis indicates that an agglutinative language underlies the script.\n\nIn 2001, archaeologists discovered that there was a civilization in Central Asia that used writing c. 2000 BC. An excavation near Ashgabat, the capital of Turkmenistan, revealed an inscription on a piece of stone that was used as a stamp seal.\n\nThe Proto-Sinaitic script, in which Proto-Canaanite is believed to have been first written, is attested as far back as the 19th century BC. The Phoenician writing system was adapted from the Proto-Canaanite script sometime before the 14th century BC, which in turn borrowed principles of representing phonetic information from Hieratic, Cuneiform and Egyptian hieroglyphs. This writing system was an odd sort of syllabary in which only consonants are represented. This script was adapted by the Greeks, who adapted certain consonantal signs to represent their vowels. The Cumae alphabet, a variant of the early Greek alphabet, gave rise to the Etruscan alphabet and its own descendants, such as the Latin alphabet and Runes. Other descendants from the Greek alphabet include Cyrillic, used to write Bulgarian, Russian and Serbian, among others. The Phoenician system was also adapted into the Aramaic script, from which the Hebrew and the Arabic scripts are descended.\n\nThe Tifinagh script (Berber languages) is descended from the Libyco-Berber script, which is assumed to be of Phoenician origin.\n\nA stone slab with 3,000-year-old writing, known as the Cascajal Block, was discovered in the Mexican state of Veracruz and is an example of the oldest script in the Western Hemisphere, preceding the oldest Zapotec writing by approximately 500 years. It is thought to be Olmec.\n\nOf several pre-Columbian scripts in Mesoamerica, the one that appears to have been best developed, and the only one to be deciphered, is the Maya script. The earliest inscription identified as Maya dates to the 3rd century BC. Maya writing used logograms complemented by a set of syllabic glyphs, somewhat similar in function to modern Japanese writing.\n\nThe Incas had no known script. Their quipu system of recording information—based on knots tied along one or many linked cords—was apparently used for inventory and accountancy purposes and could not encode textual information.\n\nThree stone slabs were found by Romanian archaeologist Nicolae Vlassa, in the mid-20th century (1961) in Tărtăria (present-day Alba County, Transylvania), Romania, ancient land of Dacia, inhabited by Dacians, which were a population who may have been related to the Getaes and Thracians.\nOne of the slabs contains 4 groups of pictographs divided by lines. Some of the characters are also found in Ancient Greek, as well as in Phoenician, Etruscan, Old Italic and Iberian.\nThe origin and the timing of the writings are disputed, because there are no precise evidence in situ, the slabs cannot be carbon dated, because of the bad treatment of the Cluj museum. There are indirect carbon dates found on a skeleton discovered near the slabs, that certifies the 5300–5500 BC period.\n\nIn the 21st century, writing has become an important part of daily life as technology has connected individuals from across the globe through systems such as e-mail and social media. Literacy has grown in importance as a factor for success in the modern world. In the United States, the ability to read and write are necessary for most jobs, and multiple programs are in place to aid both children and adults in improving their literacy skills. For example, the emergence of the writing center and community-wide literacy councils aim to help students and community members sharpen their writing skills. These resources, and many more, span across different age groups in order to offer each individual a better understanding of their language and how to express themselves via writing in order to perhaps improve their socioeconomic status.\n\nOther parts of the world have seen an increase in writing abilities as a result of programs such as the World Literacy Foundation and International Literacy Foundation, as well as a general push for increased global communication.\n\n\n"}
