{"id": "28483530", "url": "https://en.wikipedia.org/wiki?curid=28483530", "title": "Agent of record", "text": "Agent of record\n\nAn agent of record (AOR) is an individual or a legal entity with a duly executed contractual agreement with an insurance policy owner, in line with the prevailing legal norms and regulations of the region in which the contract was entered. The agent of record has a legal right to receive commissions from the respective insurance policy.\n\nThe individual or legal entity is authorized to represent an insured party in purchasing, servicing, and maintaining insurance coverage with a designated insurer. The majority of insurance companies will not disclose information or discuss an insured party's account with an agent other than the Agent of Record. An insured party wishing to change insurance agent(s) must submit a revised agent of record letter to the respective insurer authorizing said insurer to release the insured party's information and to discuss the insured party's coverage with the newly appointed agent.\n\nRelevant documents may be executed via hard copy documents or, alternatively, electronically in jurisdictions where electronic execution is legal. Applications may be made electronically, as well as in physical form.\n\nAn Agent of Record letter can, in some cases, be used as an insurance sales tool, though some question its legality.\n\nIn the advertising and marketing industry, AOR stands for \"Agency of Record.\" In this context, an AOR is an agency that is authorized to purchase advertising time (for radio or television advertising) or space (for print or web advertising) on behalf of the company with which they have an agency contract.\n\n"}
{"id": "46184815", "url": "https://en.wikipedia.org/wiki?curid=46184815", "title": "Asraya", "text": "Asraya\n\nĀśraya (Sanskrit: आश्रय) variously means – base, source, assistance, shelter, protection, refuge, dependence, having recourse to or depending on. In terms of Hindu philosophy, the living entity or \"Jiva\" is \"āśraya\", and Brahman or the Supreme Being, the Godhead, is \"viśaya\", the supreme objective, the goal of life Bhagavata Purana (VII.x.6). But, this word - \"āśraya\" conveying the primary meaning – 'refuge', immediately relates with the deity which is worshipped rather than with the abstract Brahman, the substratum of all that exists.\n\nVishishtadvaita Vedanta, which promotes qualified-monism, holds the belief that \"Jiva\" is \"anu\" or monadic in substance. \"Jiva\" though infinitesimal, is the individual \"atman\" harboured by a body, which \"atman\" the Mundaka Upanishad tells us, to be known by the mind is capable of becoming infinite through its attributive knowledge. \"Jiva\" is \"kartā\" and \"bhoktā\", both; it is the \"āśraya\" for \"jñāna\", the substrate for \"krti\" or \"prayatna\" (effort) caused by the desire to act. Therefore, \"Jiva\" is the \"āśraya\" for the states of experience that invariably involve changes in mental disposition without affecting the \"Jiva\".\n\nShankara does not consider \"avidyā\" (ignorance) as something positively existent, he does not speak about its \"vikśepa-śakti\" (power of dispersion) or \"avarna-sakti\" (power of concealment); he does not raise \"avidyā\" to an eternal metaphysical entity. Shankara also does not subscribe to the view that the individual soul is the bearer of \"avidyā\" (āśraya) or to the contention that the Paramatman is the \"āśraya\" of \"avidyā\" as is held by Mandana and Vācaspati. He reiterates that for an awakened person there is no \"avidyā\" to delude and cause pain or pleasure. In the context of the origin of the world (the original state is called \"avyakta\") he terms Parameswara-Brahman as the āśraya of nāmarūpe (the physical presence which name manifests) and that Brahman is the āspada (locus) of the cosmic vyavahāra imagined by avidya.\n\nKnowledge implies the subject which knows and the object that is known. Suppression (\"avarna\") precedes substitution (\"viksepa\"); \"avidyā\" makes one misapprehend and therefore it is described as positive (\"bhāva-rūpa\"), and does not contradict \"vidyā\" (knowledge). With regard to the transmigrating souls, Shankara does speak about the \"bhūta- āśraya\" or elementary substratum or material substratum of the soul, the subtle body, and about the \"karma- āśraya\" or moral substratum connected with \"vāsanās\" (impressions), \"karma\" (works ordained or forbidden) and \"pūrvaprajñā\" (previous experience) but he does not accept the existence of subtle persisting elements of works or preparatory elements of fruits called \"apurva\" because of their non-spiritual nature.\n\nAccording to the Bhagavata Purana (one of the 18 Mahapuranas or 18 Major Puranas) the personal aspect of God is the Āśraya of the ātmā.\n\nCondition of existence (\"gati\"), according to Jain philosophy, is the state of a soul shaped by \"gati-nama-karma\" (body-condition-making) or is the cause of the soul passing through any one of the four conditions of existence – hellish, sub-human, human and celestial. They subscribe to the view that in a thing which is permanent the existence of \"sāmānaya\" and \"samavāya\" is complete, that means that common properties cannot exist without individuals possessing them; the individuals are the \"āśraya\"; \"sāmānaya\" and \"samavāya\" is complete in one substance will not exist without \"āśraya\" (substratum).\n\nVasubandhu explains that the \"āśraya\" (foundation or support) of the fundamental change that indicates \"ātmabhāva\" (psychophysical continuum) is the non-conceptual wisdom free from the duality of the apprehender and the apprehended; \"āśraya\" refers to obscured \"tathagatagarbha\" (the fourth vajra-point) and its change (\"tataparāvrtti\") which is enlightenment (the fifth vajra-point). It is possible to replace one \"āśraya\" with another by freeing the \"ayatanas\" (internal and external sense- bases) from physical and mental impregnations of negative tendencies which bring about craving, suffering etc., by cultivating calm abiding and superior insight, which process activates the\"ayatanas\" associated with awareness (\"vidyā\") that purify all impregnations of negative tendencies and involve raising oneself to \"śuddhāśrayabhūmi\", the level of pure superior intention, never to return to the lower realms or suffer rebirth.\n\n\"Tathatā\" is the basis of transcendental wisdom, and \"Bhūtatathatā\" is the genuine 'Suchness', the essential nature of phenomenal existence, the self-identical universality, the grounding (\"āśraya\") truth of finite particularity. The Buddhists believe that the \"skandhas\", the \"ayatanas\" and the \"dhātus\" are the \"dharmas\" that constitute the phenomenal world and are the forms (and the conditioning factors) in which consciousness appears to itself. \"Bhūtatathatā\" is the \"āśraya\" i.e. the basis which is to be transformed (\"āśraya-paravritti\"), and also the \"āśraya\" which is the result of the transformation. Therefore, it is the \"āśraya\" of delusion and awakening. The \"Mahāyāna-samparigrahaśāshtra\" tells us that the mind of Reality is ever obstructed by \"āveṇkī avidyā\" which is \"manas\", the seventh consciousness and the \"āśraya\" of \"mano-vijñāna\" and the five sensorial consciousnesses evolved from self-patterning of the Absolute; the attachment of \"manas\" to \"ātmagrāha\" (egohood) and \"dharmagrāha\" (thinghood) makes the perception of the multiplicity of forms possible. The \"Mahāyāna-abhidharmasutra\" tells us that the beginningless \"dhātu\" (locus) is the equal support (\"āśraya\") of all phenomena (\"dharma\") and rests in the body as seeds. According to the Yogacaras, \"ātmabhāva\" and \"āśraya\" basically mean – \"body\", and who also tell us that \"āśraya-paravritti\" can be of the mind or path or errant tendencies.\n\n\"Āśarya yoga\", a special kind of planetary placement with most planets resting in moveable or fixed or common signs (\"rāsis\"), is one of the thirty-two varieties of \"Nabhasa yogas\" in which regard Varahamihira tells us –\n"}
{"id": "53169305", "url": "https://en.wikipedia.org/wiki?curid=53169305", "title": "Assessment culture", "text": "Assessment culture\n\nSubset of organizational culture defined by the values, beliefs, and assumptions held by its members. In higher education, a positive assessment culture is characterized by trusting relationships, data-informed decision-making, a respect for the profession of teaching, and an internally-driven thirst for discovery about student learning. Positive assessment culture generally connotes the existence of conditions for collaboration among practitioners, reward structures and professional development opportunities for faculty and staff, student involvement and a shared commitment among leaders to making institutional improvements that are sustainable. Assessment culture may be revealed behaviorally through factors such as: celebration of successes, comprehensive program review, shared use of common terminology and language, provision of technical support, and use of affirmative messaging to effectively convey meaning. Culture of assessment has been measured by scholars of perceptions among faculty to determine motivations, sense of support, and levels of fear related to assessment.\n"}
{"id": "327632", "url": "https://en.wikipedia.org/wiki?curid=327632", "title": "Bardo", "text": "Bardo\n\nIn some schools of Buddhism, bardo (Tibetan བར་དོ་ Wylie: \"bar do\") or antarabhāva (Sanskrit) is an intermediate, transitional, or liminal state between death and rebirth. It is a concept which arose soon after the Buddha's passing, with a number of earlier Buddhist groups accepting the existence of such an intermediate state, while other schools rejected it. In Tibetan Buddhism, \"bardo\" is the central theme of the \"Bardo Thodol\" (literally \"Liberation Through Hearing During the Intermediate State\"), the \"Tibetan Book of the Dead\".\n\nUsed loosely, \"bardo\" is the state of existence intermediate between two lives on earth. According to Tibetan tradition, after death and before one's next birth, when one's consciousness is not connected with a physical body, one experiences a variety of phenomena. These usually follow a particular sequence of degeneration from, just after death, the clearest experiences of reality of which one is spiritually capable, and then proceeding to terrifying hallucinations that arise from the impulses of one's previous unskillful actions. For the prepared and appropriately trained individuals, the bardo offers a state of great opportunity for liberation, since transcendental insight may arise with the direct experience of reality; for others, it can become a place of danger as the karmically created hallucinations can impel one into a less than desirable rebirth.\n\nMetaphorically, \"bardo\" can describe times when our usual way of life becomes suspended, as, for example, during a period of illness or during a meditation retreat. Such times can prove fruitful for spiritual progress because external constraints diminish. However, they can also present challenges because our less skillful impulses may come to the foreground, just as in the \"sidpa bardo\".\n\nThe concept of \"antarabhāva\", an intervening state between death and rebirth, was brought into Buddhism from the Vedic-Upanishadic philosophical tradition which later developed into Hinduism.\n\nFrom the records of early Buddhist schools, it appears that at least six different groups accepted the notion of an intermediate existence (antarabhāva), namely, the Sarvāstivāda, Darṣṭāntika, Vātsīputrīyas, Saṃmitīya, Pūrvaśaila and late Mahīśāsaka. The first four of these are closely related schools. Opposing them were the Mahāsāṃghika, early Mahīśāsaka, Theravāda, Vibhajyavāda and the Śāriputra Abhidharma (possibly Dharmagupta) (Bareau 1955: 291).\n\nSome of the earliest references we have to the “intermediate existence” are to be found in the Sarvāstivādin text the Mahāvibhāṣa (阿毘達磨大毘婆沙論). For instance, the Mahāvibhāṣa indicates a “basic existence” (本有), an “intermediate existence” (中有), a “birth existence” (生有) and “death existence” (死有) (CBETA, T27, no. 1545, p. 959, etc.). Bareau (1955: 143) provides the arguments of the Sarvāstivāda as follows:\n\nThe intermediate being who makes the passage in this way from one existence to the next is formed, like every living being, of the five aggregates (skandha). His existence is demonstrated by the fact that it cannot have any discontinuity in time and space between the place and moment of death and those of rebirth, and therefore it must be that the two existences belonging to the same series are linked in time and space by an intermediate stage. The intermediate being is the Gandharva, the presence of which is as necessary at conception as the fecundity and union of the parents. Furthermore, the Antarāparinirvāyin is an Anāgamin who obtains parinirvāṇa during the intermediary existence. As for the heinous criminal guilty of one of the five crimes without interval (ānantarya), he passes in quite the same way by an intermediate existence at the end of which he is reborn necessarily in hell.\n\nDeriving from a later period of the same school, though with some differences, Vasubandhu’s Abhidharmakośa explains (English trs. p. 383ff):\n\nWhat is an intermediate being, and an intermediate existence? Intermediate existence, which inserts itself between existence at death and existence at birth, not having arrived at the location where it should go, cannot be said to be born. Between death—that is, the five skandhas of the moment of death—and arising—that is, the five skandhas of the moment of rebirth—there is found an existence—a \"body\" of five skandhas—that goes to the place of rebirth. This existence between two realms of rebirth (gatī) is called intermediate existence.\n\nHe cites a number of texts and examples to defend the notion against other schools which reject it and claim that death in one life is immediately followed by rebirth in the next, without any intermediate state in between the two. Both the Mahāvibhāṣa and the Abhidharmakośa have the notion of the intermediate state lasting \"seven times seven days\" (i.e. 49 days) at most. This is one view, though, and there were also others.\n\nSimilar arguments were also used in Harivarman’s *Satyasiddhi Śāstra, a quasi-Mahāyāna text, and the Upadeśa commentary on the Prajñāpāramitā Sūtras, both of which have strong influence from the Sarvāstivāda school. Both of these texts had powerful influence in Chinese Buddhism, which also accepts this idea as a rule.\n\nThe Saddharma-smṛty-upasthāna Sūtra (正法念處經) classifies 17 intermediate states with different experiences.\n\nFremantle (2001) states that there are six traditional bardo states known as the Six Bardos: the Bardo of This Life (p. 55); the Bardo of Meditation (p. 58); the Bardo of Dream (p. 62); the Bardo of Dying (p. 64); the Bardo of Dharmata (p. 65); and the Bardo of Existence (p. 66).\n\nShugchang, \"et al.\" (2000: p. 5) discuss the Zhitro (Tibetan: Zhi-khro) teachings which subsume the \"Bardo Thodol\" and mention Karma Lingpa, terma and Padmasambhava and list the Six Bardo: \"The first bardo begins when we take birth and endures as long as we live. The second is the bardo of dreams. The third is the bardo of concentration or meditation. The fourth occurs at the moment of death. The fifth is known as the bardo of the luminosity of the true nature. The sixth is called the bardo of transmigration or karmic becoming.\n\n\nFremantle (2001: p. 53–54) charts the development of the bardo concept through the Himalayan tradition:\n\nOriginally bardo referred only to the period between one life and the next, and this is still its normal meaning when it is mentioned without any qualification. There was considerable dispute over this theory during the early centuries of Buddhism, with one side arguing that rebirth (or conception) follows immediately after death, and the other saying that there must be an interval between the two. With the rise of mahayana, belief in a transitional period prevailed. Later Buddhism expanded the whole concept to distinguish six or more similar states, covering the whole cycle of life, death, and rebirth. But it can also be interpreted as any transitional experience, any state that lies between two other states. Its original meaning, the experience of being between death and rebirth, is the prototype of the bardo experience, while the six traditional bardos show how the essential qualities of that experience are also present in other transitional periods. By refining even further the understanding of the essence of bardo, it can then be applied to every moment of existence. The present moment, the now, is a continual bardo, always suspended between the past and the future.\n\nHowever, as shown above, Fremantle's idea that it was originally only \"between one life and next\" was not how it was understood by the Sarvāstivāda school at the outset. Also, the idea that the ascendancy of this idea was due to the Mahāyāna is unfounded, and it is much more likely that it was due to the Sarvāstivāda influence, several centuries before the Mahāyāna had any real influence.\n\n"}
{"id": "11917343", "url": "https://en.wikipedia.org/wiki?curid=11917343", "title": "Burn down chart", "text": "Burn down chart\n\nA burn down chart is a graphical representation of work left to do versus time. The outstanding work (or backlog) is often on the vertical axis, with time along the horizontal. That is, it is a run chart of outstanding work. It is useful for predicting when all of the work will be completed. It is often used in agile software development methodologies such as Scrum. However, burn down charts can be applied to any project containing measurable progress over time.\n\nOutstanding work can be represented in terms of either time or story points.\n\nA burn down chart for a completed iteration is shown above and can be read by knowing the following:\n\nThe above table is only one way of interpreting the shape of the burn down chart. There are others.\n\nOne issue that may be noticed in burn down charts is that whether or not the Actual Work line is above or below the Ideal Work line depends on how accurate the original time estimates are. This means that if a team constantly overestimates time requirements, the progress will always appear ahead of schedule. If they constantly underestimate time requirements, they will always appear behind schedule. This issue is corrected by incorporating an efficiency factor into the burn down chart. After the first iteration of a project, the efficiency factor can be recalculated to allow for more accurate estimates during the next iteration. Some templates automatically calculate the efficiency as a project progresses. This can be used to identify areas/phases where inaccurate estimates consistently occur.\n\n"}
{"id": "40682284", "url": "https://en.wikipedia.org/wiki?curid=40682284", "title": "Cab Gallery", "text": "Cab Gallery\n\nCab Gallery was an art project from 1999 to 2001 curated by London art dealer Paul Stolper of Paul Stolper Gallery and art collector and London taxi driver Jason Brown. The concept was for art to be exhibited on the outside and inside of a working London taxi rather than a traditional gallery space. As stated by Brown, \"It was important to me that when working, the artwork was incidental to the journey of the passenger. I hoped they would notice but it was part of their environment and unexpected. It was also interesting to me to learn which artworks they reacted to. But it had to be a natural discovery.\"\n\nArtists were provided the views and dimensions of the available spaces such as the bottom of fold-up seats (or \"tip-up seats\"), the exterior of the cab, and limited inside options for free-standing work. Because the cab was also a working London taxi, after each artwork was selected by the curators, approval from the Cab Advertising Committee of the Public Carriage Office was also required. Artwork placed on the exterior of the cab was printed in vinyl the same as per usual advertising procedures. Special receipts were designed, listing participating artists and contact details. In addition to serving as gallery space during working cab hours, Cab Gallery would park outside galleries on their opening nights enabling the artists to exhibit more ambitious and experimental installation and sound pieces.\n\nThroughout the project Brown honored his commitment to the project's concept of never bringing attention to the art while operating as a working cab but rather allowing the passengers to discover it for themselves. When the cab was serving as a stationary exhibition space at art galleries and events, however, Brown would often act as de facto docent for the collection.\n\nIn 1999, Brown approached Stolper with the idea of exhibiting art in the spaces reserved for advertising in his traditional London Black Taxi, and Cab Gallery was launched in Hoxton Square on 24 September 1999.\n\nThe first exterior was a text piece by Bob and Roberta Smith, \"Taxy\" in red and yellow vinyl. On the fold-up seats were two text pieces by Peter Liversidge, who became a regular contributor to the project and whose collected proposals were later published in book form. Also on display at the launch were \"All the animals\", an embroidered cushion by Abigail Cohen, \"from Swiss Cottage to Soho and back,\" a book of drawings by Susie Hamilton, and \"Cab Gallery Greeting\", a sound piece by Jessica Voorsanger. Absinthe was served out of the rear boot of the taxi.\n\nThe success of the launch led to other artists becoming involved and invitations by galleries and art event organizers to participate in their openings. On these occasions, the Cab was parked outside the entrance and artists had the opportunity to create more ambitious artworks as installations and sound pieces.\n\nIn mid-2000, the Bob and Roberta Smith exterior artwork was replaced with \"Sunny\" by Alex Katz, the American figurative painter.\nThe popularity of the project spread through wide media coverage and Cab Gallery participated in its first show outside London at the Ikon Gallery in Birmingham. This was soon followed by From Space Gallery in Manchester and in 2001 the Aspex Gallery in Portsmouth.\nIn 2001 the final exterior of the cab became \"Out from Under\" by important American conceptual artist Lawrence Weiner.\nThe project expanded to include a website featuring a project by Layla Curtis which traced the routes made by Brown in his cab over a specific week.\n\nThe project came to feature regular new pieces by Peter Liversidge, the \"house artist,\" as well as new artists and artwork to keep the project fresh.\nBy the end of 2001 after media coverage as wide ranging as the magazines Top Gear, The Art News and Art in America and daily papers from Finland to Australia it was felt that the project should end at its height.\n\nThe curators arranged for a retrospective exhibition immediately upon discontinuing the project, held as part of the opening of the Essor Gallery, which occupied the main gallery as well as a project space nearby. The Cab Gallery Retrospective ran from 15–22 January 2002 and included the \"Cab Gallery\" itself, which was parked up inside. All previous artworks were on show along with films and sound pieces.\n\nPaul Stolper continues as a leading London gallery owner and publisher.\n\nJason Brown collaborated with Chelsea space at Chelsea College of Art & Design to use the same taxi, renamed the Chelsea Cab, to exhibit new exterior artwork on the cab by Bruce McLean, Stephen Farthing RA and David Shrigley. In 2012 he moved to Nashville, Tennessee and continues to curate art shows including exchanges between London and Nashville. In 2012 Brown donated the entire Cab Gallery archive including artwork, correspondence and ephemera to the Special Collections at the Library at the Chelsea College of Art & Design.\n\n\n"}
{"id": "15089498", "url": "https://en.wikipedia.org/wiki?curid=15089498", "title": "Chinese spiritual world concepts", "text": "Chinese spiritual world concepts\n\nChinese spiritual world concepts are cultural practices or methods found in Chinese culture. Some fit in the realms of a particular religion, others do not. In general these concepts were uniquely evolved from the Chinese values of filial piety, tacit acknowledgment of the co-existence of the living and the deceased, and the belief in causality and reincarnation, with or without religious overtones.\n\n\n\n\n\n"}
{"id": "26356139", "url": "https://en.wikipedia.org/wiki?curid=26356139", "title": "Composition over inheritance", "text": "Composition over inheritance\n\nComposition over inheritance (or composite reuse principle) in object-oriented programming (OOP) is the principle that classes should achieve polymorphic behavior and code reuse by their composition (by containing instances of other classes that implement the desired functionality) rather than inheritance from a base or parent class. This is an often-stated principle of OOP, such as in the influential book \"Design Patterns.\"\n\nAn implementation of composition over inheritance typically begins with the creation of various interfaces representing the behaviors that the system must exhibit. The use of interfaces allows this technique to support the polymorphic behavior that is so valuable in object-oriented programming. Classes implementing the identified interfaces are built and added to business domain classes as needed. Thus, system behaviors are realized without inheritance. \n\nIn fact, business domain classes may all be base classes without any inheritance at all. Alternative implementation of system behaviors is accomplished by providing another class that implements the desired behavior interface. Any business domain class that contains a reference to the interface can easily support any implementation of that interface and the choice can even be delayed until run time.\n\nAn example in C++11 follows:\n\nThen, we have concrete classes:\n\n\nNote that multiple inheritance is dangerous if not implemented carefully, as it can lead to the diamond problem. One solution to avoid this is to create classes such as codice_17, codice_18, codice_19, etc. for every needed combination, though this leads to a large amount of repetitive code. Keep in mind that C++ solves the diamond problem of multiple inheritance by allowing virtual inheritance.\n\nThe following C# example demonstrates the principle of using composition and interfaces to achieve code reuse and polymorphism.\n\nTo favor composition over inheritance is a design principle that gives the design higher flexibility. It is more natural to build business-domain classes out of various components than trying to find commonality between them and creating a family tree. For example, a gas pedal and a wheel share very few common traits, yet are both vital components in a car. What they can do and how they can be used to benefit the car is easily defined. Composition also provides a more stable business domain in the long term as it is less prone to the quirks of the family members. In other words, it is better to compose what an object can do (\"HAS-A\") than extend what it is (\"IS-A\").\n\nInitial design is simplified by identifying system object behaviors in separate interfaces instead of creating a hierarchical relationship to distribute behaviors among business-domain classes via inheritance. This approach more easily accommodates future requirements changes that would otherwise require a complete restructuring of business-domain classes in the inheritance model. Additionally, it avoids problems often associated with relatively minor changes to an inheritance-based model that includes several generations of classes.\n\nSome languages, notably Go, use type composition exclusively.\n\nOne common drawback of using composition instead of inheritance is that methods being provided by individual components may have to be implemented in the derived type, even if they are only forwarding methods. In contrast, inheritance does not require all of the base class's methods to be re-implemented within the derived class. Rather, the derived class only needs to implement (override) the methods having different behavior than the base class methods. This can require significantly less programming effort if the base class contains many methods providing default behavior and only a few of them need to be overridden within the derived class.\n\nFor example, in the C# code below, the variables and methods of the base class are inherited by the and derived subclasses. Only the method needs to be implemented (specialized) by each derived subclass. The other methods are implemented by the base class itself, and are shared by all of its derived subclasses; they do not need to be re-implemented (overridden) or even mentioned in the subclass definitions.\n\nThis drawback can be avoided by using traits, mixins, or protocol extensions. Some languages, such as Perl 6, provide a codice_20 keyword to facilitate method forwarding. In Java, Project Lombok allows delegation to be implemented using a single @Delegate annotation on the field, instead of copying and maintaining the names and types of all the methods from the delegated field. In Swift, extensions can be used to define a default implementation of a protocol on the protocol itself, rather than within an individual type's implementation. In Kotlin the delegation pattern has been included into the language syntax.\n\nA 2013 study of 93 open source Java programs (of varying size) found that:\n\n"}
{"id": "36094464", "url": "https://en.wikipedia.org/wiki?curid=36094464", "title": "Copenhagen–Tartu school", "text": "Copenhagen–Tartu school\n\nThe Copenhagen–Tartu school of biosemiotics is a loose network of scholars working within the discipline of biosemiotics at the University of Tartu and the University of Copenhagen. \n\nThe school has been instrumental in developing biosemiotics as a new perspective on the study of life, in the biological and environmental sciences. Notable semioticians working in the Copenhagen–Tartu school are: Kalevi Kull, Jesper Hoffmeyer, Peeter Torop, Claus Emmeche, Timo Maran, Mihhail Lotman.\n\nOccasionally also the name 'Tartu–Bloomington–Copenhagen school' has been used, as having succeeded the earlier Tartu–Moscow school.\n\nThe biosemiotic co-work between the Tartu and Copenhagen groups was established in early 1990s. In 2001, Tartu and Copenhagen scholars inaugurated the annual international conferences for biosemiotic research known as the Gatherings in Biosemiotics, later organised by the International Society for Biosemiotic Studies.\n\nThe School values classical works of Jakob von Uexküll and Juri Lotman.\n\n\n"}
{"id": "43036911", "url": "https://en.wikipedia.org/wiki?curid=43036911", "title": "Digital fashion", "text": "Digital fashion\n\nDigital fashion is the interplay between digital technology and couture. Information and Communication Technologies (ICTs) have been deeply integrated both into the fashion industry as well as within the experience of clients and prospects. Such interplay has happened at three main levels.\n\nAmong the many applications available to fashion designers to model the fusion of creativity with digital avenues, the Digital Textile Printing can be mentioned here.\n\nDigital printing is a process in which prints are directly applied to fabrics with printer, reducing 95% the use of water, 75% the use of energy, and minimizing textile waste. The main advantage of digital printing is the ability to do very small runs of each design (even less than 1 yard).\n\nDigital Textile printing is “probably the greatest innovation of 21-st century fashion, “ Christina Binkley declared in the Wall Street Journal. The “vastly improved digital printing technologies allow designers to innovate while beefing up their brands“.\n\nBrand such as Prada, Pucci or Jil Sander are using this technology to invent their design ideas on fabric.\n\nWhile all digital channels can be used in order to market and sell fashion completely online (eCommerce), they usually are implemented in connection with offline channels (so-called \"omni-channel\"). Here Virtual and Augmented reality is playing a crucial role.\n\nProspects and clients can use ICTs - own computers, tablets and smart phones - to skip fitting rooms and cosmetics counters, and instead virtually see how they look in specific outfits and makeup via in-store kiosks, mobile phones or tablets. Modiface is a web application that anyone can use to give them a virtual makeover. Customers can give any look and decide on what to suits and buy products.\n\nSephora, the beauty specialty retailer, and ModiFace, an augmented reality virtual makeover technology provider, today announced the launch of a 3D Augmented Reality Mirror that can simulate cosmetics on a user's face in real-time and in 3D. The new patented technology, created by ModiFace, tracks the precise location of a user's facial features and applies eye shadow colors directly on the video feed from a camera.\n\nOftentimes beauty retailers will feature virtual fitting rooms to allow users to experience the look of their product before committing to a purchase. Some examples are color contact retailers Freshlook, which allows users to simulate contact lens wear in their color contacts studio before purchase. Colorful Eyes also offers a virtual color contact lens try on room.\n\nA virtual dressing room (also often referred to as virtual fitting room and virtual changing room although they do perform different functions) is the online equivalent of the near-ubiquitous in-store changing room – that is, it enables shoppers to try on clothes to check one or more of size, fit or style, but virtually rather than physically.\n\nThe multimedia communication company Eyemagnet developed the Virtual Dressing Room for the Hallensteins menswear chain. The changing room is transformed to a single panel which reflects the user. These users can then use simple arm and hand gestures to ‘try on’ any apparel in the store, take a photo of any selected outfit and have it sent to their mobile phone. Newer versions of the technology eliminate the arm-waving altogether.\n\nFashion retailer Topshop installed a Kinect-powered virtual fitting room at its Moscow store. Created by AR Door, the Augmented Fitting Room system overlays 3D augmented reality clothes on the customer. Simple gestures and on-screen buttons let users \"try on\" different outfits. However, the high variability of virtual fit platforms to predict consumer clothes sizes called into question the accuracy of these systems in their current form.\n\nFashion is also a matter of socially negotiating what is \"in\" or \"out\", fashionable or not. In other words, fashion items do not only play on the economic market of physical goods, but also - and sometimes even pore importantly - on the semiotic market of the production of social tastes and customs.\n\nThanks to social media, and to all services offered by the so-called web2.0, laypeople can contribute to co-create the fashion world, shaping tastes, customs, and fashion-related values.\n\nNowadays, the fashion industry needs experts in digital fashion, equipped with the above-sketched knowledge and competences. Several Bachelor and Master programs in Fashion have in recent years integrated Digital Fashion courses.\n\nWhile there are not (yet) dedicated scientific journals devoted to the topic, several research activities have been done in the field. Among them, a dedicated Conference has taken place in 2015 in Seoul, South Korea (see its Proceedings). In 2017, SComS - Studies in Communication Sciences, a Swiss-based Communication Journal, has launched a call for papers in the field of Fashion Communication, stressing the role of Digital Fashion Communication.\n\nFashion is closely related with Art and Heritage: among the most important initiatives to digitize fashion history, thus making such heritage available to researchers, practitioners and all interested people, two projects can be mentioned: Europeana Fashion and We Wear Culture by Google Arts and Culture.\n"}
{"id": "216331", "url": "https://en.wikipedia.org/wiki?curid=216331", "title": "Duress in American law", "text": "Duress in American law\n\nIn jurisprudence, duress or coercion refers to a situation whereby a person performs an act as a result of violence, threat, or other pressure against the person. \"Black's Law Dictionary\" (6th ed.) defines duress as \"any unlawful threat or coercion used... to induce another to act [or not act] in a manner [they] otherwise would not [or would]\". Duress is pressure exerted upon a person to coerce that person to perform an act they ordinarily would not perform. The notion of duress must be distinguished both from undue influence in the civil law. In criminal law, duress and necessity are different defenses.\n\nDuress has two aspects. One is that it negates the person's consent to an act, such as sexual activity or the entering into a contract; or, secondly, as a possible legal defense or justification to an otherwise unlawful act. A defendant utilizing the duress defense admits to breaking the law, but claims that he/she is not liable because, even though the act broke the law, it was only performed because of extreme unlawful pressure. In criminal law, a duress defense is similar to a plea of guilty, admitting partial culpability, so that if the defense is not accepted then the criminal act is admitted.\n\nDuress or coercion can also be raised in an allegation of rape or other sexual assault to negate a defense of consent on the part of the person making the allegation.\n\nA defendant who raises a defense of duress has actually done everything to constitute the \"actus reus\" of the crime, and has the \"mens rea\" because they intended to do it to avoid some threatened or actual harm. Thus, some degree of culpability already attaches to the defendant for what was done. \n\nIn criminal law, the defendant's motive for breaking the law is generally irrelevant unless a defendant is raising an affirmative defense allowed for by law. (Duress may or may not be allowed as an affirmative defence for some particular charge -- in particular, it is generally forbidden for murder, and many jurisdictions also forbid it for sexual assault. \"Malum in se\" offences, generally, are less likely to recognise duress as a defence than \"malum prohibitum\" offences.)\n\nA successful affirmative defence means not that a criminal act was justified, but that the act was not criminal at all. But if no affirmative defence of duress is available, then the duress may be considered as justifying a lighter sentence, typically in proportion to the degree of duress. If the duress is extreme enough, for example, the defendant might be found guilty of murder but given a minimal, or even trivial, sentence.\n\nIn some rare cases, a successful argument of duress -- even when not an affirmative defence -- might result in the jury nullifying the charge by refusing to convict.\n\nThe basis of the defense is that the duress actually overwhelmed the defendant's will and would also have overwhelmed the will of a person of ordinary courage (a hybrid test requiring both subjective evidence of the accused's state of mind, and an objective confirmation that the failure to resist the threats was reasonable), thus rendering the entire behavior involuntary. Thus, the liability should be reduced or discharged, making the defense one of exculpation.\n\nThe extent to which this defense should be allowed, if at all, is a matter of public policy. A state may say that no threat should force a person to deliberately break the law, particularly if this breach will cause significant loss or damage to a third person. Alternatively, a state may take the view that even though people may have ordinary levels of courage, they may nevertheless be coerced into agreeing to break the law and this human weakness should have some recognition in the law.\n\nA mutant of duress involves hostage taking, where a person is forced to commit a criminal act under the threat, say, that their family member or close associate will be immediately killed should they refuse (commonly known as a Tiger kidnapping). This has been raised in some cases of ransom, where a person commits theft or embezzlement under orders from a kidnapper in order to secure a family member's life and freedom. However, duress is not a complete defense to all crimes. For example, the general rule, both at common law and today, is that duress is never a defense to murder; that is, one is never justified in killing another innocent person even if one's own life has been threatened, although this part may be questioned when multiple people are threatened with death if the defendant does not kill a single or fewer people than threatened (such a situation is similar to the trolley problem).\n\nFor duress to qualify as a defense, four requirements must be met:\n\nA person may also raise a duress defense when force or violence is used to compel him to enter into a contract, or to discharge.\n\n\"Duress\" in the context of contract law is a common law defence brought about when one of the parties to the contract enjoyed an ascendant position in relation to the other party and abused that position by subjecting the other to \"threats.\" A party who has entered into a contract under duress is entitled to rescind or set aside the contract, rendering it voidable (in equity).\n\nDuress is a threat of harm made to compel someone to do something against their will or judgment; especially a wrongful threat made by one person to compel a manifestation of seeming assent by another person to a transaction without real volition. - Black's Law Dictionary (8th ed. 2004)\n\nDuress in contract law falls into two broad categories:\n\nProfessor Ronald Griffin, Florida Agricultural & Mechanical College of Law, Orlando, FL, puts physical duress simply: \"Your money or your life.\" \nIn \"Barton v Armstrong\", a decision of the Privy Council, Armstrong (defendant) sought to coerce Barton (plaintiff) into executing a deed relating to the sale of certain companies by threatening to have him murdered. While the plaintiff took the threats seriously, other business reasons existed for signing the contract. An innocent party wishing to set aside a contract for duress to the person need only prove that the threat was made and that it was a reason for entry into the contract. Furthermore, once it is established that the threat was made, the onus lies on the person who made the threat to prove that the threat made no contribution to the plaintiff's decision to enter the agreement.\n\nCommon law took a narrow view of the concept of duress in that it was concerned with actual or threatened violence to the person or unlawful imprisonment. Equity, however, adopted a broader \"fusion\" view of what sort of pressure could constitute coercion for purposes of relief and has since prevailed. \n\nIn such cases, one party refuses to release the goods belonging to the other party until the other party enters into a contract with them. For example, in \"Hawker Pacific Pty Ltd v Helicopter Charter Pty Ltd\" (1991) 22 NSWLR 298, the contract was set aside after Hawker Pacific's threats to withhold the helicopter from the plaintiff unless further payments were made for repairing a botched paint job.\n\nEconomic duress is the use of unlawful economic pressure to compel a party to a contract to agree to demands which they would not have otherwise.\n\nIn criminal law, when a person is found legally insane because they believed God ordered them to do the crime (\"deific-decree\"), one interpretation of the insanity is that they acted under a delusion of duress by God.\n\n"}
{"id": "41102092", "url": "https://en.wikipedia.org/wiki?curid=41102092", "title": "Dysfunctional impulsivity", "text": "Dysfunctional impulsivity\n\nDysfunctional impulsivity is a type of impulsivity that is associated with a tendency to make quick decisions when this type of decision-making is non-optimal. This differs from functional impulsivity which is a tendency to make quick decisions where this is optimal. As dysfunctional impulsivity is often associated with a failure to consider the consequences of one’s behavior, it can often lead to life difficulties.\n\nThe distinction between functional and dysfunctional impulsivity was suggested by Scott J. Dickman in an article published in 1990. Before this, impulsivity was considered a complex construct that was made up of several different aspects. The Dickman Inventory classifies impulsivity into functional and dysfunctional categories.\n\nMany of the previously used impulsivity scales have been significantly correlated to measures of dysfunctional impulsivity. These include the impulsiveness scale of Eysenck’s Impulsivity Inventory (part of the Eysenck Personality Questionnaire) as well as the Barratt Impulsiveness Scale.\nMany of the questions used in the Dickman Impulsivity Inventory mirror those used on past questionnaires, and are used to assess overall impulsivity. Of the 23 questions on the Dickman Impulsivity Inventory, 12 of the items are used to measure dysfunctional impulsivity. This includes questions such as “I often get into trouble because I don’t think before I act” as well as “I often say and do things without considering the consequences” This scale has been adapted for use in children with similar results: clear distinctions between functional and dysfunctional impulsivity. It has also been translated into several languages, yielding similar results\n\nDysfunctional impulsivity is associated with both disorderliness and a tendency to ignore hard facts before making a decision. Individuals who are high in dysfunctional impulsivity are more likely to be punished for their behaviors. Psychopathy, aggression, a tendency to participate in sexual behavior outside of an established relationship, and a history of violent behavior have all been significantly associated with dysfunctional impulsivity. Individuals high in dysfunctional impulsivity have been shown to have slight deficits in executive functioning. Delay discounting has been shown to be related to both dysfunctional and functional impulsivity.\n\nImpulsivity is significantly correlated with individuals being at a greater risk for substance abuse. Several studies have furthered this association to specifically relate dysfunctional impulsivity to this tendency.\n\nBinge drinkers were found to have significantly higher scores of dysfunctional impulsivity compared to control groups. The same study found no difference in levels of functional impulsivity between groups, indicating that dysfunctional impulsivity was the version of impulsivity that led to substance abuse. This relationship with dysfunctional impulsivity has also been found in regards to cigarette smoking. Higher levels of dysfunctional impulsivity have been related to difficulty restraining oneself from smoking in inappropriate places, smoking without being aware of doing so, and overall craving for cigarettes. Dysfunctional impulsivity scores have also been found to be higher in heroin users and addicts overall when compared to non-drug abusing control groups.\n"}
{"id": "304483", "url": "https://en.wikipedia.org/wiki?curid=304483", "title": "Edict of Milan", "text": "Edict of Milan\n\nThe Edict of Milan () was the February 313 AD agreement to treat Christians benevolently within the Roman Empire. Western Roman Emperor Constantine I and Licinius, who controlled the Balkans, met in Milan and, among other things, agreed to change policies towards Christians following the Edict of Toleration by Galerius issued two years earlier in Serdica. The Edict of Milan gave Christianity a legal status, but did not make Christianity the State church of the Roman Empire; this took place under Emperor Theodosius I in 380 AD with the Edict of Thessalonica.\n\nThe document is found in Lactantius' \"De Mortibus Persecutorum\" and in Eusebius of Caesarea's \"History of the Church\" with marked divergences between the two. Whether or not there was a formal 'Edict of Milan'  is debated by some.\n\nThe version found in Lactantius is not in the form of an edict. It is a letter from Licinius to the governors of the provinces in the Eastern Empire he had just conquered by defeating Maximinus later in the same year and issued in Nicomedia.\n\nEver since the fall of the Severan dynasty in 235 AD, rivals for the imperial throne had bid for support by either favouring or persecuting Christians. The previous Edict of Toleration by Galerius had been recently issued by the emperor Galerius from Serdica and was posted at Nicomedia on 30 April 311. By its provisions, the Christians, who had \"followed such a caprice and had fallen into such a folly that they would not obey the institutes of antiquity\", were granted an indulgence.\n\nTheir confiscated property, however, was not restored until 313, when instructions were given for the Christians' meeting places and other properties to be returned and compensation paid by the state to the current owners:\n\nIt directed the provincial magistrates to execute this order at once with all energy so that public order may be restored and the continuance of divine favour may \"preserve and prosper our successes together with the good of the state.\"\n\nThe actual letters have never been retrieved. However, they are quoted at length in Lactantius' \"On the Deaths of the Persecutors\" (\"De mortibus persecutorum\"), which gives the Latin text of both Galerius's Edict of Toleration as posted at Nicomedia on 30 April 311 and of Licinius's letter of toleration and restitution addressed to the governor of Bithynia and posted at Nicomedia on 13 June 313.\n\nEusebius of Caesarea translated both documents into Greek in his \"History of the Church\" (\"Historia Ecclesiastica\"). His version of the letter of Licinius must derive from a copy posted in the province of Palaestina Prima (probably at its capital, Caesarea) in the late summer or early autumn of 313, but the origin of his copy of Galerius's Edict of 311 is unknown since that does not seem to have been promulgated in Caesarea. In his description of the events in Milan in his \"Life of Constantine\", Eusebius eliminated the role of Licinius, whom he portrayed as the evil foil to his hero Constantine.\n\nThe Edict was in effect directed against Maximinus Daia, the Caesar in the East who was at that time styling himself as Augustus. Having received the emperor Galerius' instruction to repeal the persecution in 311, Maximinus had instructed his subordinates to desist, but had not released Christians from prisons or virtual death-sentences in the mines, as Constantine and Licinius had both done in the West.\n\nFollowing Galerius' death, Maximin was no longer constrained; he enthusiastically took up renewed persecutions in the eastern territories under his control, encouraging petitions against Christians. One of those petitions, addressed not only to Maximin but also to Constantine and Licinius, is preserved in a stone inscription at Arycanda in Lycia, and is a \"request that the Christians, who have long been disloyal and still persist in the same mischievous intent, should at last be put down and not be suffered by any absurd novelty to offend against the honour due to the gods.\"\n\nThe Edict is popularly thought to concern only Christianity, and even to make Christianity the official religion of the Empire (which recognition did not actually occur until the Edict of Thessalonica in 380). Indeed, the Edict expressly grants religious liberty not only to Christians, who had been the object of special persecution, but goes even further and grants liberty to all religions:\n\nSince Licinius composed the Edict with the intent of publishing it in the east upon his hoped-for victory over Maximinus, it expresses the religious policy accepted by Licinius, a pagan, rather than that of Constantine, who was already a Christian. Constantine's own policy went beyond merely tolerating Christianity: he tolerated paganism and other religions, but he actively promoted Christianity.\n\nAlthough the Edict of Milan is commonly presented as Constantine’s first great act as a Christian emperor, it is disputed whether the Edict of Milan was an act of genuine faith. The document could be seen as Constantine's first step in creating an alliance with the Christian God, who he considered the strongest deity. At that time, he was concerned about social stability and the protection of the empire from the wrath of the Christian God: in this view, the Edict could be a pragmatic political decision rather than a religious shift. However, the majority of historians believe that Constantine's conversion to Christianity was genuine, and that the Edict of Milan was merely the first official act of Constantine as a dedicated Christian. This view is supported by Constantine's ongoing favors on behalf of Christianity during the rest of his reign. \nThe Edict of Milan required that the wrong done to the Christians be righted as thoroughly as possible; it claims “it has pleased us to remove all conditions whatsoever.” The edict further demanded that individual Romans right any wrongs towards Christians, claiming that “the same shall be restored to the Christians without payment or any claim of recompense and without any kind of fraud or deception.” These provisions indicate that more than just the establishment of justice was intended. After demanding the immediate return of what was lost by the Christians, the edict states that this should be done so that “public order may be secured”, not for the intrinsic value of justice or the glory of God. The exhortation to urgently right wrongs reflects the leaders' desires to avoid unfavorable consequences, which in this case included social unrest and further conquests. Constantine was superstitious and believed enough in the existence of the non-Christian gods to not want to offset the balance of good and evil. It was believed that, the sooner this balance was restored by the Romans establishing a state of justice with the Christians, the sooner the state would become stable.\n\n\n"}
{"id": "3027767", "url": "https://en.wikipedia.org/wiki?curid=3027767", "title": "Ex turpi causa non oritur actio", "text": "Ex turpi causa non oritur actio\n\nThe UK Supreme Court provided a thorough reconsideration of the doctrine in 2016 in Patel v Mirza.\n\nIn the early case of \"Holman v Johnson\" Lord Mansfield CJ set out the rationale for the illegality doctrine.\n\nIn the law of tort, the principle would prevent a criminal from bringing a claim against (for example) a fellow criminal. In \"National Coal Board v England\" Lord Asquith said,\n\nIn \"Hewison v Meridian Shipping Services Pte Ltd\", an employee who had obtained his position by concealing his epilepsy was held not to be entitled to claim compensation for future loss of earnings as a result of his employer's negligence, since his deception (resulting in a pecuniary advantage contrary to the Theft Act 1968) would prevent him from obtaining similar employment in future.\n\nIt is not absolute in effect. For example, in \"Revill v Newbery\" an elderly allotment holder was sleeping in his shed with a shotgun, to deter burglars. On hearing the plaintiff trying to break in, he shot his gun through a hole in the shed, injuring the plaintiff. At first instance, the judge awarded damages on the basis that the defendant had used violence in excess of the reasonable limits allowed by lawful self-defence and was negligent to the standard of care expected of a reasonable man who found himself in such a situation. On appeal the defendant raised the defence of \"\", but the Court of Appeal held that while public interest required that someone should not benefit from his illegal conduct, different considerations applied in cases arising in tort as opposed to those in a property or contract context. Old common law authorities and the Law Commission report (Liability for Damage or Injury to Trespassers) acknowledged the existence of some duty towards trespassers and the defendant could not rely on the doctrine to relieve himself of liability.\n\nThe precise scope of the doctrine is not certain. In some cases, it seems that the illegality prevents a duty of care arising in the first place. For example, in \"Ashton v Turner\" the defendant injured the plaintiff by crashing the car they sat in together in the course of fleeing the scene of a burglary they had committed together. Ewbank J held that the court may not recognise a duty of care in such cases as a matter of public policy. Similarly, in \"Pitts v Hunt\" the Court of Appeal rationalised this approach, saying that it was impossible to decide the appropriate standard of care in cases where the parties were involved in illegality.\n\nIf the illegality vanishes by result of legislative action (such as if the law that made the act that caused the injury was a crime is repealed) or some subsequent court case (where the law is declared invalid), the tort action will stand. In the case of \"Martin v. Ziherl\", the two parties were girlfriend and boyfriend until Martin discovered Ziherl had given her herpes. Martin sued Ziherl for damages in Virginia Circuit Court, and Ziherl argued that because of the case of \"Zyzk v. Zysk\" since having sex with someone they were not married to was technically the crime of fornication, Martin could not sue Ziherl because she got herpes as result of the illegal act. Martin argued the act was unconstitutional. The court agreed with Ziherl and against Martin. Martin appealed, and the Supreme Court of Virginia reversed, agreeing with Martin's argument that because the United States Supreme Court had decided in \"Lawrence v. Texas\" that noncommercial, private intimacy was a protected right, the law making fornication a crime was unconstitutional, thus Martin could now sue since the law that made having sex with someone they were not married to was struck down as void.\n\nIn other cases, the courts view \"\" as a defence where otherwise a claim would lie, again on grounds of public policy. In \"Tinsley v Milligan\" Nicholls LJ in the Court of Appeal spoke of the court having to \"weigh or balance the adverse consequences of granting relief against the adverse consequences of refusing relief\". The plaintiff was ultimately successful in \"Tinsley v Milligan\" in the House of Lords, which allowed the claim on the grounds that the plaintiff did not need to rely on the illegality.\n\nA later case, \"Gray v Thames Trains\", upheld the basic rule of public policy that disallowed recovery of anything stemming from Plaintiff's own wrongdoing. \n\n\nThe doctrine in the aspect of contract essentially does the same thing as one of the vitiating contractual elements known as 'Illegality' .Here contractual remedies can not be enforced by a court on a defendant if it \nis manifest that the subject matter of the contract is in anyway whether directly or by implication, contrary to public policy or in contradiction with any existing law or custom.\n\nIn 2016 the Supreme Court provided a major reconsideration of this doctrine, in Patel v Mirza , over-ruling the test in Tinsley v Milligan and replacing it with a new set of principles. \nThe changes were described as 'revolutionary' by a dissenting judge on the case, Lord Sumption (at [261] in the judgement).\n\n"}
{"id": "10138190", "url": "https://en.wikipedia.org/wiki?curid=10138190", "title": "Exploring Time", "text": "Exploring Time\n\nExploring Time is a two-hour TV documentary mini-series about natural time scale changes that aired in 2007 on The Science Channel.\n\nThe documentary is a co-production of Twin Cities Public Television, Red Hill Studios, and NHK. It was made possible by a major grant from the National Science Foundation, and produced in association with Arte France and Granada International.\n\n\n\n"}
{"id": "339686", "url": "https://en.wikipedia.org/wiki?curid=339686", "title": "Good", "text": "Good\n\nIn its most general context, the concept of good denotes that conduct which is to be or should be preferred when posed with a choice between a set of possible actions. Good is generally considered to be the opposite of evil. The concept is of interest in the study of morality, ethics, religion and philosophy, and the specific meaning and etiology of the term and its associated translations among ancient and contemporary languages has varied substantially in its inflected meaning depending on circumstances of place, history, religious context, or philosophical context.\n\nEvery language has a word expressing \"good\" in the sense of \"having the right or desirable quality\" (ἀρετή) and \"bad\" in the sense \"undesirable\". A sense of moral judgment and a distinction \"right and wrong, good and bad\" are cultural universals.\n\nAlthough the history of the origin of the use of the concept and meaning of 'good' are diverse, the notable discussions of Plato and Aristotle on this subject have been of significant historical effect. The first references that are seen in Plato's \"The Republic\" to the Form of the Good are within the conversation between Glaucon and Socrates (454c–d). When trying to answer such difficult questions pertaining to the definition of justice, Plato identifies that we should not “introduce every form of difference and sameness in nature” instead we must focus on \"the one form of sameness and difference that was relevant to the particular ways of life themselves” which is the form of the Good. This form is the basis for understanding all other forms, it is what allows us to understand everything else. Through the conversation between Socrates and Glaucon (508a–c) Plato analogizes the form of the Good with the sun as it is what allows us to see things. Here, Plato describes how the sun allows for sight. But he makes a very important distinction, “sun is not sight” but it is “the cause of sight itself.” As the sun is in the visible realm, the form of Good is in the intelligible realm. It is “what gives truth to the things known and the power to know to the knower”. It is not only the “cause of knowledge and truth, it is also an object of knowledge”.\nPlato identifies how the form of the Good allows for the cognizance to understand such difficult concepts as justice. He identifies knowledge and truth as important, but through Socrates (508d–e) says, “good is yet more prized”. He then proceeds to explain “although the good is not being” it is “superior to it in rank and power”, it is what “provides for knowledge and truth” (508e).\n\nIn contrast to Plato, Aristotle discusses the Forms of Good in critical terms several times in both of his major surviving ethical works, the \"Eudemian\" and \"Nicomachean Ethics\". Aristotle argues that Plato's Form of the Good does not apply to the physical world, for Plato does not assign “goodness” to anything in the existing world. Because Plato's Form of the Good does not explain events in the physical world, humans have no reason to believe that the Form of the Good exists and the Form of the Good is thereby irrelevant to human ethics.\n\nPlato and Aristotle were not the first contributors in ancient Greece to the study of the 'good' and discussion preceding them can be found among the pre-Socratic philosophers. In Western civilisation, the basic meanings of κακός and ἀγαθός are \"bad, cowardly\" and \"good, brave, capable\", and their absolute sense emerges only around 400 BC, with Pre-Socratic philosophy, in particular Democritus. Morality in this absolute sense solidifies in the dialogues of Plato, together with the emergence of monotheistic thought (notably in \"Euthyphro\", which ponders the concept of piety (τὸ ὅσιον) as a moral absolute). The idea is further developed in Late Antiquity by Neoplatonists, Gnostics, and Church Fathers.\n\nAside from ancient Greek studies of the 'good', the eastern part of ancient Persia almost five thousand years ago a religious philosopher called Zoroaster simplified the pantheon of early Iranian gods into two opposing forces: Ahura Mazda (Illuminating Wisdom) and Angra Mainyu (Destructive Spirit) which were in conflict.\n\nFor the western world, this idea developed into a religion which spawned many sects, some of which embraced an extreme dualistic belief that the material world should be shunned and the spiritual world should be embraced. Gnostic ideas influenced many ancient religions which teach that \"gnosis\" (variously interpreted as enlightenment, salvation, emancipation or 'oneness with God') may be reached by practising philanthropy to the point of personal poverty, sexual abstinence (as far as possible for \"hearers\", total for \"initiates\") and diligently searching for wisdom by helping others.\n\nThis development from the relative or habitual to the absolute is also evident in the terms \"ethics\" and \"morality\" both being derived from terms for \"regional custom\", Greek ἦθος and Latin \"mores\", respectively (see also \"siðr\").\n\nMedieval Christian philosophy was founded on the work of the Bishop Augustine of Hippo and theologian Thomas Aquinas who understood evil in terms of Biblical infallibility and Biblical inerrancy, as well as the influences of Plato and Aristotle in their appreciation of the concept of the Summum bonum. Silent contemplation was the route to appreciation of the Idea of the Good.\n\nMany medieval Christian theologians both broadened and narrowed the basic concept of \"Good and evil\" until it came to have several, sometimes complex definitions such as: \n\nA significant enlightenment context for studying the 'good' has been its significance in the study of \"the good, the true and the beautiful\" as found in Immanuel Kant and other Enlightenment philosophers and religious thinkers. These discussion were undertaken by Kant particularly in the context of his \"Critique of Practical Reason\".\n\nJohn Rawls' book \"A Theory of Justice\" prioritized social arrangements and goods based on their contribution to justice. Rawls defined justice as \"fairness\", especially in distributing social goods, defined fairness in terms of procedures, and attempted to prove that just institutions and lives are good, if rational individuals' goods are considered fairly. Rawls's crucial invention was the original position, a procedure in which one tries to make objective moral decisions by refusing to let personal facts about oneself enter one's moral calculations.\n\nIn religion, ethics, and philosophy, \"good and evil\" is a very common dichotomy. In cultures with Manichaean and Abrahamic religious influence, evil is usually perceived as the antagonistic opposite of good. Good is that which should prevail and evil should be defeated. In cultures with Buddhist spiritual influence, this antagonistic duality itself must be overcome through achieving \"Śūnyatā\", or emptiness. This is the recognition of good and evil not being unrelated, but two parts of a greater whole; unity, oneness, a Monism.\n\nAs a religious concept, basic ideas of a dichotomy between good and evil has developed so that today:\n\nThe issue of good and evil in the human visuality, often associated with morality, is regarded by some biologists (notably Edward O. Wilson, Jeremy Griffith, David Sloan Wilson and Frans de Waal) as an important question to be addressed by the field of biology.\n\n\n\n"}
{"id": "172270", "url": "https://en.wikipedia.org/wiki?curid=172270", "title": "Hidden message", "text": "Hidden message\n\nA hidden message is information that is not immediately noticeable, and that must be discovered or uncovered and interpreted before it can be known. Hidden messages include backwards audio messages, hidden visual messages and symbolic or cryptic codes such as a crossword or cipher. Although there are many legitimate examples of hidden messages created with techniques such as backmasking and steganography, many so-called hidden messages are merely fanciful imaginings or apophany.\n\nThe information in hidden messages is not immediately noticeable; it must be discovered or uncovered, and interpreted before it can be known. Hidden messages include backwards audio messages, hidden visual messages, and symbolic or cryptic codes such as a crossword or cipher. There are many legitimate examples of hidden messages, though many are imaginings.\n\nA backward message in an audio recording is only fully apparent when the recording is played reversed. Some backward messages are produced by deliberate backmasking, while others are simply phonetic reversals resulting from random combinations of words. Backward messages may occur in various mediums, including music, video games, music videos, movies, and television shows.\n\nBackmasking is a recording technique in which a message is recorded backwards onto a track that is meant to be played forwards. It was popularized by The Beatles, who used backward vocals and instrumentation on their 1966 album \"Revolver.\" The technique has also been used to censor words or phrases for \"clean\" releases of songs.\n\nBackmasking has been a controversial topic in the United States since the 1980s, when allegations of its use for Satanic purposes were made against prominent rock musicians, leading to record-burnings and proposed anti-backmasking legislation by state and federal governments. In debate are both the existence of backmasked Satanic messages and their purported ability to subliminally affect listeners.\n\nCertain phrases produce a different phrase when their phonemes are reversed—a process known as phonetic reversal. For example, \"Kiss\" backwards sounds like \"sick\", and so the title of Yoko Ono's \"Kiss Kiss Kiss\" sounds like \"Sick Sick Sick\" or \"Six Six Six\" backwards. Queen's \"Another One Bites the Dust\" backwards was claimed that the chorus, when played in reverse, can be heard as \"It's fun to smoke marijuana\" or \"start to smoke marijuana\". The Paul is dead phenomenon was started in part because a phonetic reversal of \"Number nine\" (the words were constantly repeated in \"Revolution 9)\" was interpreted as \"Turn me on, dead man\".\n\nAccording to proponents of reverse speech, phonetic reversal occurs unknowingly during normal speech.\n\nHidden messages can be created in visual mediums with techniques such as hidden text and steganography.\n\nIn the 1980s, Coca-Cola released in South Australia an advertising poster featuring the reintroduced contour bottle, with a speech bubble, \"Feel the Curves!!\" An image hidden inside one of the ice cubes was controversial. Thousands of posters were distributed to hotels and bottle shops in Australia before the mistake was discovered by Coca-Cola management. The artist of the poster was fired and all the posters were recalled.\n\nVarious other messages have been claimed to exist in Disney movies, some of them risque, such as the well-known allegation of an erection showing on a priest in \"The Little Mermaid\". According to the Snopes website, however, only one image \"is clearly true [and] undeniably purposely inserted into the movie\": images of a topless woman in two frames of \"The Rescuers\".\n\nPETA (People for the Ethical Treatment of Animals) had an antipathy towards PETCO, a pet food retailer in San Diego, regarding the purported mistreatment of live animals at their stores. When the San Diego Padres baseball team announced that the retailer had purchased naming rights to Petco Park stadium, PETA was unable to persuade the sports team to terminate the agreement. Later, PETA successfully purchased a commemorative display brick with what appears to be a complimentary message: \"Break Open Your Cold Ones! Toast The Padres! Enjoy This Championship Organization!\" However, if one takes the first letters of each word, the resulting acrostic reads \"BOYCOTT PETCO\". Neither PETCO nor the Padres have taken any action to remove the brick, stating that if someone walked by, they would not know it had anything to do with the PETA/PETCO feud.\n\n\n"}
{"id": "37440011", "url": "https://en.wikipedia.org/wiki?curid=37440011", "title": "History of eugenics", "text": "History of eugenics\n\nThe history of eugenics is the study of development and advocacy of ideas related to eugenics around the world. Early eugenic ideas were discussed in Ancient Greece and Rome. The height of the modern eugenics movement came in the late 19th and early 20th century. Today eugenics continues to be a topic of political and social debate.\n\nThe philosophy was most famously expounded by Plato, who believed human reproduction should be monitored and controlled by the state. However, Plato understood this form of government control would not be readily accepted, and proposed the truth be concealed from the public via a fixed lottery. Mates, in Plato's Republic, would be chosen by a \"marriage number\" in which the quality of the individual would be quantitatively analyzed, and persons of high numbers would be allowed to procreate with other persons of high numbers. In theory, this would lead to predictable results and the improvement of the human race. However, Plato acknowledged the failure of the \"marriage number\" since \"gold soul\" persons could still produce \"bronze soul\" children. Plato's ideas may have been one of the earliest attempts to mathematically analyze genetic inheritance, which was later improved by the development of Mendelian genetics and the mapping of the human genome.\n\nOther ancient civilizations, such as Rome, Athens and Sparta, practiced infanticide through exposure and execution as a form of phenotypic selection. In Sparta, newborns were inspected by the city's elders, who decided the fate of the infant. If the child was deemed incapable of living, it was usually exposed in the \"Apothetae\" near the Taygetus mountain.\n\nTrials for babies included bathing them in wine and exposing them to the elements. To Sparta, this would ensure only the strongest survived and procreated. Adolf Hitler considered Sparta to be the first \"\"Völkisch\" State\", and much like Ernst Haeckel before him, praised Sparta for its selective infanticide policy, though the Nazis believed the children were killed outright and not exposed.\n\nThe Twelve Tables of Roman Law, established early in the formation of the Roman Republic, stated in the fourth table that deformed children must be put to death. In addition, patriarchs in Roman society were given the right to \"discard\" infants at their discretion. This was often done by drowning undesired newborns in the Tiber River. Commenting on the Roman practice of eugenics, the philosopher Seneca wrote that: \"We put down mad dogs; we kill the wild, untamed ox; we use the knife on sick sheep to stop their infecting the flock; we destroy abnormal offspring at birth; children, too, if they are born weak or deformed, we drown. Yet this is not the work of anger, but of reason - to separate the sound from the worthless\". The practice of open infanticide in the Roman Empire did not subside until its Christianization, which however also mandated \"negative\" \"eugenics\", e.g. by the council of Adge in 506, which forbade marriage between cousins.\n\nSir Francis Galton (1822-1911) systematized these ideas and practices according to new knowledge about the evolution of man and animals provided by the theory of his half-cousin Charles Darwin during the 1860s and 1870s. After reading Darwin's \"Origin of Species\", Galton built upon Darwin's ideas whereby the mechanisms of natural selection were potentially thwarted by human civilization. He reasoned that, since many human societies sought to protect the underprivileged and weak, those societies were at odds with the natural selection responsible for extinction of the weakest; and only by changing these social policies could society be saved from a \"reversion towards mediocrity\", a phrase he first coined in statistics and which later changed to the now common \"regression towards the mean\".\n\nGalton first sketched out his theory in the 1865 article \"Hereditary Talent and Character\", then elaborated further in his 1869 book \"Hereditary Genius\". He began by studying the way in which human intellectual, moral, and personality traits tended to run in families. Galton's basic argument was \"genius\" and \"talent\" were hereditary traits in humans (although neither he nor Darwin yet had a working model of this type of heredity). He concluded since one could use artificial selection to exaggerate traits in other animals, one could expect similar results when applying such models to humans. As he wrote in the introduction to \"Hereditary Genius\":\n\nI propose to show in this book that a man's natural abilities are derived by inheritance, under exactly the same limitations as are the form and physical features of the whole organic world. Consequently, as it is easy, notwithstanding those limitations, to obtain by careful selection a permanent breed of dogs or horses gifted with peculiar powers of running, or of doing anything else, so it would be quite practicable to produce a highly gifted race of men by judicious marriages during several consecutive generations.\n\nGalton claimed that the less intelligent were more fertile than the more intelligent of his time. Galton did not propose any selection methods; rather, he hoped a solution would be found if social mores changed in a way that encouraged people to see the importance of breeding. He first used the word \"eugenic\" in his 1883 \"Inquiries into Human Faculty and Its Development\", a book in which he meant \"to touch on various topics more or less connected with that of the cultivation of race, or, as we might call it, with 'eugenic' questions\". He included a footnote to the word \"eugenic\" which read:\n\nThat is, with questions bearing on what is termed in Greek, \"eugenes\" namely, good in stock, hereditary endowed with noble qualities. This, and the allied words, \"eugeneia\", etc., are equally applicable to men, brutes, and plants. We greatly want a brief word to express the science of improving stock, which is by no means confined to questions of judicious mating, but which, especially in the case of man, takes cognizance of all influences that tend in however remote a degree to give to the more suitable races or strains of blood a better chance of prevailing speedily over the less suitable than they otherwise would have had. The word \"eugenics\" would sufficiently express the idea; it is at least a neater word and a more generalized one than \"viriculture\" which I once ventured to use.\n\nIn 1908, in \"Memories of my life\", Galton stated the official definition of eugenics: \"the study of agencies under social control that may improve or impair the racial qualities of future generations, either physically or mentally\". This had been agreed in consultation with a committee that included the biometrician Karl Pearson. It was slightly at odds with Galton's preferred definition, given in a lecture to the newly formed Sociological Society at the London School of Economics in 1904: \"the science which deals with all influences that improve the inborn qualities of a race; also with those that develop them to the utmost advantage\". The latter definition, which encompassed nurture and environment as well as heredity, was favoured by broadly left wing, liberal elements of the ensuing ideological divide.\n\nGalton's formulation of eugenics was based on a strong statistical approach, influenced heavily by Adolphe Quetelet's \"social physics\". Unlike Quetelet, however, Galton did not exalt the \"average man\" but decried him as mediocre. Galton and his statistical heir Karl Pearson developed what was called the biometrical approach to eugenics, which developed new and complex statistical models (later exported to wholly different fields) to describe the heredity of traits. However, with the rediscovery of Gregor Mendel's hereditary laws, two separate camps of eugenics advocates emerged. One was made up of statisticians, the other of biologists. Statisticians thought the biologists had exceptionally crude mathematical models, while biologists thought the statisticians knew little about biology.\n\nEugenics eventually referred to human selective reproduction with an intent to create children with desirable traits, generally through the approach of influencing differential birth rates. These policies were mostly divided into two categories: \"positive eugenics\", the increased reproduction of those seen to have advantageous hereditary traits; and \"negative eugenics\", the discouragement of reproduction by those with hereditary traits perceived as poor. Negative eugenic policies in the past have ranged from paying those deemed to have bad genes to voluntarily undergo sterilization, to attempts at segregation to compulsory sterilization and even genocide. Positive eugenic policies have typically taken the form of awards or bonuses for \"fit\" parents who have another child. Relatively innocuous practices like marriage counseling had early links with eugenic ideology. Eugenics is superficially related to what would later be known as Social Darwinism. While both claimed intelligence was hereditary, eugenics asserted new policies were needed to actively change the status quo towards a more \"eugenic\" state, while the Social Darwinists argued society itself would naturally \"check\" the problem of \"dysgenics\" if no welfare policies were in place (for example, the poor might reproduce more but would have higher mortality rates).\n\nCharles Davenport (1866-1944), a scientist from the United States, stands out as one of history's leading eugenicists. He took eugenics from a scientific idea to a worldwide movement implemented in many countries. Davenport obtained funding from the Carnegie Institution, to establish the Station for Experimental Evolution at Cold Spring Harbor in 1904 and the Eugenics Records Office in 1910, which provided the scientific basis for later Eugenic policies such as enforced sterilization. He became the first President of the International Federation of Eugenics Organizations (IFEO) in 1925, an organization he was instrumental in building. While Davenport was located at Cold Spring Harbor and received money from the Carnegie Institute of Washington, the organization known as the Eugenics Record Office (ERO) started to become an embarrassment after the well-known debates between Davenport and Franz Boas. Instead, Davenport occupied the same office and the same address at Cold Spring Harbor, but his organization now became known as the Cold Spring Harbor Laboratories, which currently retains the archives of the Eugenics Record Office. However, Davenport's racist views were not supported by all geneticists at Cold Spring Harbor, including H. J. Muller, Bentley Glass, and Esther Lederberg.\n\nIn 1932, Davenport welcomed Ernst Rüdin, a prominent Swiss eugenicist and race scientist, as his successor in the position of President of the IFEO. Rüdin, director of the \"Deutsche Forschungsgemeinschaft\" (German Research Institute for Psychiatry, located in Munich), a Kaiser Wilhelm Institute, was a co-founder (with his brother-in-law Alfred Ploetz) of the German Society for Racial Hygiene. Other prominent figures in eugenics who were associated with Davenport included Harry Laughlin (United States), Havelock Ellis (United Kingdom), Irving Fischer (United States), Eugen Fischer (Germany), Madison Grant (United States), Lucien Howe (United States), and Margaret Sanger (United States, founder of Planned Parenthood).\n\nIn September 1903, an \"Inter-departmental Committee on Physical Deterioration\" chaired by Almeric W. FitzRoy was appointed by the government \"to make a preliminary enquiry into the allegations concerning the deterioration of certain classes of the population as shown by the large percentage of rejections for physical causes of recruits for the Army\", and gave its Report to both houses of parliament in the following year. Among its recommendations, originating from professor Daniel John Cunningham, were an anthropometric survey of the British population. The Catholic church was opposed to eugenics, as illustrated in the writings of Father Thomas John Gerrard. \n\nIn the United Kingdom, eugenics never received significant state funding, but it was supported by many prominent figures of different political persuasions before World War I, including: Liberal economists William Beveridge and John Maynard Keynes; Fabian socialists such as Irish author George Bernard Shaw, H. G. Wells and Sidney Webb; and Conservatives such as the future Prime Minister Winston Churchill and Arthur Balfour. The influential economist John Maynard Keynes was a prominent supporter of eugenics, serving as Director of the British Eugenics Society, and writing that eugenics is \"the most important, significant and, I would add, genuine branch of sociology which exists\".\n\nIts emphasis was more upon social class, rather than race. Indeed, Francis Galton expressed these views during a lecture in 1901 in which he placed British society into groups. These groupings are shown in the figure and indicate the proportion of society falling into each group and their perceived genetic worth. Galton suggested that negative eugenics (i.e. an attempt to prevent them from bearing offspring) should be applied only to those in the lowest social group (the \"Undesirables\"), while positive eugenics applied to the higher classes. However, he appreciated the worth of the higher working classes to society and industry.\n\nThe 1913 Mental Deficiency Act proposed the mass segregation of the \"feeble minded\" from the rest of society. Sterilisation programmes were never legalised, although some were carried out in private upon the mentally ill by clinicians who were in favour of a more widespread eugenics plan. Indeed, those in support of eugenics shifted their lobbying of Parliament from enforced to voluntary sterilization, in the hope of achieving more legal recognition. But leave for the Labour Party Member of Parliament Major A. G. Church, to propose a Private Member's Bill in 1931, which would legalise the operation for voluntary sterilization, was rejected by 167 votes to 89. The limited popularity of eugenics in the UK was reflected by the fact that only two universities established courses in this field (University College London and Liverpool University). The Galton Institute, affiliated to UCL, was headed by Galton's protégé, Karl Pearson.\n\nOne of the earliest modern advocates of eugenics (before it was labeled as such) was Alexander Graham Bell. In 1881 Bell investigated the rate of deafness on Martha's Vineyard, Massachusetts. From this he concluded that deafness was hereditary in nature and, through noting that congenitally deaf parents were more likely to produce deaf children, tentatively suggested that couples where both were deaf should not marry, in his lecture \"Memoir upon the formation of a deaf variety of the human race\" presented to the National Academy of Sciences on 13 November 1883. However, it was his hobby of livestock breeding which led to his appointment to biologist David Starr Jordan's Committee on Eugenics, under the auspices of the American Breeders Association. The committee unequivocally extended the principle to man.\n\nAnother scientist considered the \"father of the American eugenics movement\" was Charles Benedict Davenport. In 1904 he secured funding for the Station for Experimental Evolution, later renamed the Carnegie Department of Genetics. It was also around that time that Davenport became actively involved with the American Breeders' Association (ABA). This led to Davenport's first eugenics text, \"The science of human improvement by better breeding\", one of the first papers to connect agriculture and human heredity. Davenport later went on to set up a Eugenics Record Office (ERO), collecting hundreds of thousands of medical histories from Americans, which many considered to have a racist and anti-immigration agenda. Davenport and his views were supported at Cold Spring Harbor Laboratory as late as 1963, when his views began to be de-emphasized.\n\nAs the science continued in the 20th century, researchers interested in familial mental disorders conducted a number of studies to document the heritability of such illnesses as schizophrenia, bipolar disorder, and depression. Their findings were used by the eugenics movement as proof for its cause. State laws were written in the late 19th and early 20th centuries to prohibit marriage and force sterilization of the mentally ill in order to prevent the \"passing on\" of mental illness to the next generation. These laws were upheld by the U.S. Supreme Court in 1927 and were not abolished until the mid-20th century. All in all, 60,000 Americans were sterilized.\n\nBeginning with Connecticut in 1896, many states enacted marriage laws with eugenic criteria, prohibiting anyone who was \"epileptic, imbecile or feeble-minded\" from marrying. In 1898 Charles B. Davenport, a prominent American biologist, began as director of a biological research station based in Cold Spring Harbor where he experimented with evolution in plants and animals. In 1904 Davenport received funds from the Carnegie Institution to found the Station for Experimental Evolution. The Eugenics Record Office (ERO) opened in 1910 while Davenport and Harry H. Laughlin began to promote eugenics.\n\nThe Immigration Restriction League (founded in 1894) was the first American entity associated officially with eugenics. The League sought to bar what it considered dysgenic members of certain races from entering America and diluting what it saw as the superior American racial stock through procreation. They lobbied for a literacy test for immigrants, based on the belief that literacy rates were low among \"inferior races\". Literacy test bills were vetoed by Presidents in 1897, 1913 and 1915; eventually, President Wilson's second veto was overruled by Congress in 1917. Membership in the League included: A. Lawrence Lowell, president of Harvard, William DeWitt Hyde, president of Bowdoin College, James T. Young, director of Wharton School and David Starr Jordan, president of Stanford University. The League allied themselves with the American Breeder's Association to gain influence and further its goals and in 1909 established a eugenics committee chaired by David Starr Jordan with members Charles Davenport, Alexander Graham Bell, Vernon Kellogg, Luther Burbank, William Earnest Castle, Adolf Meyer, H. J. Webber and Friedrich Woods. The ABA's immigration legislation committee, formed in 1911 and headed by League's founder Prescott F. Hall, formalized the committee's already strong relationship with the Immigration Restriction League.\n\nIn years to come, the ERO collected a mass of family pedigrees and concluded that those who were unfit came from economically and socially poor backgrounds. Eugenicists such as Davenport, the psychologist Henry H. Goddard and the conservationist Madison Grant (all well respected in their time) began to lobby for various solutions to the problem of the \"unfit\". (Davenport favored immigration restriction and sterilization as primary methods; Goddard favored segregation in his \"The Kallikak Family\"; Grant favored all of the above and more, even entertaining the idea of extermination.) Though their methodology and research methods are now understood as highly flawed, at the time this was seen as legitimate scientific research. It did, however, have scientific detractors (notably, Thomas Hunt Morgan, one of the few Mendelians to explicitly criticize eugenics), though most of these focused more on what they considered the crude methodology of eugenicists, and the characterization of almost every human characteristic as being hereditary, rather than the idea of eugenics itself.\n\nSome states sterilized \"imbeciles\" for much of the 20th century. The U.S. Supreme Court ruled in the 1927 \"Buck v. Bell\" case that the state of Virginia could sterilize individuals under the Virginia Sterilization Act of 1924. The most significant era of eugenic sterilization was between 1907 and 1963, when over 64,000 individuals were forcibly sterilized under eugenics legislation in the United States. A favorable report on the results of sterilization in California, the state with the most sterilizations by far, was published in book form by the biologist Paul Popenoe and was widely cited by the Nazi government as evidence that wide-reaching sterilization programs were feasible and humane.\n\nSuch legislation was passed in the U.S. because of widespread public acceptance of the eugenics movement, spearheaded by efforts of progressive reformers. Over 19 million people attended the Panama-Pacific International Exposition in San Francisco, open for 10 months from February 20 to December 4, 1915. The PPIE was a fair devoted to extolling the virtues of a rapidly progressing nation, featuring new developments in science, agriculture, manufacturing and technology. A subject that received a large amount of time and space was that of the developments concerning health and disease, particularly the areas of tropical medicine and race betterment (tropical medicine being the combined study of bacteriology, parasitology and entomology while racial betterment being the promotion of eugenic studies). Having these areas so closely intertwined, it seemed that they were both categorized in the main theme of the fair, the advancement of civilization. Thus in the public eye, the seemingly contradictory areas of study were both represented under progressive banners of improvement and were made to seem like plausible courses of action to better American society.\n\nThe state of California was at the vanguard of the American eugenics movement, performing about 20,000 sterilizations or one third of the 60,000 nationwide from 1909 up until the 1960s. By 1910, there was a large and dynamic network of scientists, reformers and professionals engaged in national eugenics projects and actively promoting eugenic legislation. The American Breeder's Association was the first eugenic body in the U.S., established in 1906 under the direction of biologist Charles B. Davenport. The ABA was formed specifically to \"investigate and report on heredity in the human race, and emphasize the value of superior blood and the menace to society of inferior blood\". Membership included Alexander Graham Bell, Stanford president David Starr Jordan and Luther Burbank.\n\nWhen Nazi administrators went on trial for war crimes in Nuremberg after World War II, they attempted to justify the mass sterilizations (over 450,000 in less than a decade) by citing the United States as their inspiration. The Nazis had claimed American eugenicists inspired and supported Hitler's racial purification laws, and failed to understand the connection between those policies and the eventual genocide of the Holocaust.\n\nThe idea of \"genius\" and \"talent\" is also considered by William Graham Sumner, a founder of the American Sociological Society (now called the American Sociological Association). He maintained that if the government did not meddle with the social policy of \"laissez-faire\", a class of genius would rise to the top of the system of social stratification, followed by a class of talent. Most of the rest of society would fit into the class of mediocrity. Those who were considered to be defective (mentally retarded, handicapped, etc.) had a negative effect on social progress by draining off necessary resources. They should be left on their own to sink or swim. But those in the class of delinquent (criminals, deviants, etc.) should be eliminated from society (\"Folkways\", 1907).\n\nHowever, methods of eugenics were applied to reformulate more restrictive definitions of white racial purity in existing state laws banning interracial marriage: the so-called anti-miscegenation laws. The most famous example of the influence of eugenics and its emphasis on strict racial segregation on such \"anti-miscegenation\" legislation was Virginia's Racial Integrity Act of 1924. The U.S. Supreme Court overturned this law in 1967 in Loving v. Virginia, and declared anti-miscegenation laws unconstitutional.\n\nWith the passage of the Immigration Act of 1924, eugenicists for the first time played an important role in the Congressional debate as expert advisers on the threat of \"inferior stock\" from eastern and southern Europe. While eugenicists did support the act, they were also backed by many labor unions. The new act, inspired by the eugenic belief in the racial superiority of \"old stock\" white Americans as members of the \"Nordic race\" (a form of white supremacy), strengthened the position of existing laws prohibiting race-mixing. Eugenic considerations also lay behind the adoption of incest laws in much of the U.S. and were used to justify many anti-miscegenation laws.\n\nStephen Jay Gould asserted that restrictions on immigration passed in the United States during the 1920s (and overhauled in 1965 with the Immigration and Nationality Act) were motivated by the goals of eugenics. During the early 20th century, the United States and Canada began to receive far higher numbers of Southern and Eastern European immigrants. It has been argued that this stirred both Canada and the United States into passing laws creating a hierarchy of nationalities, rating them from the most desirable Anglo-Saxon and Nordic peoples to the Chinese and Japanese immigrants, who were almost completely banned from entering the country.\n\nHowever, several people, in particular Franz Samelson, Mark Snyderman and Richard Herrnstein, have argued, based on their examination of the records of the congressional debates over immigration policy, Congress gave virtually no consideration to these factors. According to these authors, the restrictions were motivated primarily by a desire to maintain the country's cultural integrity against the heavy influx of foreigners.\n\nIn the USA, eugenic supporters included Theodore Roosevelt, Research was funded by distinguished philanthropies and carried out at prestigious universities. It was taught in college and high school classrooms. Margaret Sanger founded Planned Parenthood of America to urge the legalization of contraception for poor, immigrant women. In its time eugenics was touted by some as scientific and progressive, the natural application of knowledge about breeding to the arena of human life. Before the realization of death camps in World War II, the idea that eugenics would lead to genocide was not taken seriously by the average American.\n\nThe policy of removing mixed race Aboriginal children from their parents emerged from an opinion based on Eugenics theory in late 19th and early 20th century Australia that the 'full-blood' tribal Aborigine would be unable to sustain itself, and was doomed to inevitable extinction, as at the time huge numbers of aborigines were in fact dying out, from diseases caught from European settlers. An ideology at the time held that mankind could be divided into a civilizational hierarchy. This notion supposed that Northern Europeans were superior in civilization and that Aborigines were inferior. According to this view, the increasing numbers of mixed-descent children in Australia, labeled as \"half-castes\" (or alternatively \"crossbreeds\", \"quadroons\", and \"octoroons\") should develop within their respective communities, white or aboriginal, according to their dominant parentage.\n\nIn the first half of the 20th century, this led to policies and legislation that resulted in the removal of children from their tribe.\nThe stated aim was to culturally assimilate mixed-descent people into contemporary Australian society. In all states and territories legislation was passed in the early years of the 20th century which gave Aboriginal protectors guardianship rights over Aborigines up to the age of sixteen or twenty-one. Policemen or other agents of the state (such as Aboriginal Protection Officers), were given the power to locate and transfer babies and children of mixed descent from their communities into institutions. In these Australian states and territories, half-caste institutions (both government or missionary) were established in the early decades of the 20th century for the reception of these separated children. The 2002 movie \"Rabbit-Proof Fence\" portrays a true story about this system and the harrowing consequences of attempting to overcome it.\n\nIn 1922, A.O. Neville was appointed the second Western Australia State \"Chief Protector of Aborigines\". During the next quarter-century, he presided over the now notorious 'Assimilation' policy of removing mixed-race Aboriginal children from their parents.\n\nNeville believed that biological absorption was the key to 'uplifting the Native race'. Speaking before the Moseley Royal Commission, which investigated the administration of Aboriginals in 1934, he defended the policies of forced settlement, removing children from parents, surveillance, discipline and punishment, arguing that \"they have to be protected against themselves whether they like it or not. They cannot remain as they are. The sore spot requires the application of the surgeon's knife for the good of the patient, and probably against the patient's will\". In his twilight years Neville continued to actively promote his policy. Towards the end of his career, Neville published \"Australia's Coloured Minority\", a text outlining his plan for the biological absorption of aboriginal people into white Australia.\n\nThe idea of Social Darwinism was widespread among Brazil's leading scientists, educators, social thinkers, as well as many elected officials, in the late 1800s and early 1900s. This led to the \"Politica de Branqueamento\" (Whitening Policies) set in practice in Brazil in the early part of the 20th century. This series of laws intended to enlarge the numbers of the white race in Brazil while reducing the numbers of descendents of African Slaves and Asians made the ground fertile for eugenic theories.\n\nThe first official organized movement of eugenics in South America was a Eugenics Conference in April 1917, which was followed in January 1918 by the founding of the São Paulo Society of Eugenics. This society worked with health agencies and psychiatric offices to promote their ideas. The year 1931 saw the foundation of the \"Comitê Central de Eugenismo\" (Central Committee on Eugenics) presided by Renato Kehl. Among its suggestions were an end to the immigration of non-whites to Brazil, and the spread of policies against miscegenation.\n\nThe ideas of the Central Committee on Eugenics clashed with the Whitening Policies of the beginning of the 20th century. While the Whitening Policies advocated miscegenation in order to reduce the numbers of pure Africans in Brazil in favor of mulattos, who were expected to then produce white off-spring - a policy very similar to the \"uplifting the Native race\" in Australia - the Central Committee on Eugenics advocated no miscegenation at all and separation between the whites and non-whites in Brazil. When it became obvious that the future of Brazil was in industrialization (just as it was for other countries around the world), Brazil had to face whether they had a working force capable of being absorbed by an industrial society. \n\nA new ideology was needed to counter such racialist claims. This ideology, known as Lusotropicalism, was associated with Gilberto Freyre, and became popular throughout the Portuguese Empire: specifically, Brazil and Angola. Lusotropicalism claimed that its large population of mixed-race people made Brazil the most capable country in tropical climates to carry out a program of industrialization. Its mixed race population had the cultural and intellectual capabilities provided by the white race, which could not work in tropical climates, combined with the physical ability to work in tropical climates, provided by the African black race. This excluded the fact that white prisoners, working under penal servitude in Puerto Rico, seemed quite capable of working in a tropical environment. \n\nIn the first decades of the twentieth century, the work of the Rockefeller Foundation was decisive for the implementation of public health initiatives in Brazil, especially in the so-called public health movement. At that time, Brazilian eugenics was the same as public health, as expressed in the maxim \"to sanitize is to eugenize\".\n\nIn Canada, the eugenics movement gained support early in the 20th century as prominent physicians drew a direct link between heredity and public health. Eugenics was enforced by law in two Canadian provinces. In Alberta, the Sexual Sterilization Act was enacted in 1928, focusing the movement on the sterilization of mentally deficient individuals, as determined by the Alberta Eugenics Board. The campaign to enforce this action was backed by groups such as the United Farm Women's Group, including key member Emily Murphy.\n\nAs in many other former British Empire colonies, eugenic policies were linked to racist (and racialist) agendas pursued by various levels of government, such as the forced sterilization of Canada's indigenous peoples and specific provincial government initiatives, such as Alberta's eugenics program. As a brief illustration, in 1928 the province of Alberta started an initiative, \"…allowing any inmate of a native residential school to be sterilized upon the approval of the school Principal. At least 3,500 Indian women are sterilized under this law.\" As of 2011, research into extant archival records of sterilization and direct killing of First Nations youth (through intentional transmission of disease and other means) under the residential school program is ongoing.\n\nIndividuals were assessed using IQ tests like the Stanford-Binet. This posed a problem to new immigrants arriving in Canada, as many had not mastered the English language, and often their scores denoted them as having impaired intellectual functioning. As a result, many of those sterilized under the Sexual Sterilization Act were immigrants who were unfairly categorized. The province of British Columbia enacted its own Sexual Sterilization Act in 1933. As in Alberta, the British Columbia Eugenics Board could recommend the sterilization of those it considered to be suffering from \"mental disease or mental deficiency\".\n\nAlthough not enforced by laws as it was in Canada's western provinces, an obscenity trial in Depression-era Ontario, can be seen as an example of the influence of eugenics in Ontario. Dorothea Palmer, a nurse working for the Parents Information Bureau - a privately funded birth control organization based out of Kitchener, Ontario - was arrested in the predominantly Catholic community of Eastview, Ontario in 1936. She was accused of illegally providing birth control materials and knowledge to her clients, primarily poor women. The defense at her trial was mounted by an industrialist and influential eugenicist from Kitchener, A.R. Kaufman. Palmer was acquitted in early 1937. The trial lasted less than a year, and later became known as The Eastview Birth Control Trial, demonstrating the influence of the eugenics lobby in Ontario.\n\nThe popularity of the eugenics movement peaked during the Depression when sterilization was widely seen as a way of relieving society of the financial burdens imposed by defective individuals. Although the eugenics excesses of Nazi Germany diminished the popularity of the eugenics movement, the Sexual Sterilization Acts of Alberta and British Columbia were not repealed until 1972.\n\nNazi Germany under Adolf Hitler was well known for eugenics programs which attempted to maintain a \"pure\" Aryan race through a series of programs that ran under the banner of racial hygiene. Among other activities, the Nazis performed extensive experimentation on live human beings to test their genetic theories, ranging from simple measurement of physical characteristics to the research for Otmar von Verschuer carried out by Karin Magnussen using \"human material\" gathered by Josef Mengele on twins and others at Auschwitz death camp. During the 1930s and 1940s, the Nazi regime used forced sterilization on hundreds of thousands of people whom they viewed as mentally ill, an estimated 400,000 between 1934 and 1937. The scale of the Nazi program prompted one American eugenics advocate to seek an expansion of their program, with one complaining that \"the Germans are beating us at our own game.\"\n\nThe Nazis went further, however, murdering tens of thousands of the institutionalized disabled through compulsory \"euthanasia\" programs such as Aktion T4. They used gas chambers and lethal injections to murder their victims.\n\nThey also implemented a number of \"positive\" eugenics policies, giving awards to Aryan women who had large numbers of children and encouraged a service in which \"racially pure\" single women could deliver illegitimate children. Allegations that such women were also impregnated by SS officers in the \"Lebensborn\" were not proven at the Nuremberg trials, but new evidence (and the testimony of Lebensborn children) has established more details about Lebensborn practices. Also, \"racially valuable\" children from occupied countries were forcibly removed from their parents and adopted by German people. Many of their concerns for eugenics and racial hygiene were also explicitly present in their systematic killing of millions of \"undesirable\" people, especially Jews who were singled out for the Final Solution, this policy led to the horrors seen in the Holocaust.\n\nThe scope and coercion involved in the German eugenics programs along with a strong use of the rhetoric of eugenics and so-called \"racial science\" throughout the regime created an indelible cultural association between eugenics and the Third Reich in the post-war years.\n\nTwo scholars, John Glad and Seymour W. Itzkoff of Smith College, have questioned the relation between eugenics and the Holocaust. They argue that, contrary to popular belief, Hitler did not regard the Jews as intellectually inferior and did not send them to the concentration camps on these grounds. They argue that Hitler had different reasons for his genocidal policies toward the Jews. Itzkoff writes that the Holocaust was \"a vast dysgenic program to rid Europe of highly intelligent challengers to the existing Christian domination by a numerically and politically minuscule minority\". Therefore, according to Itzkoff, \"the Holocaust was the very antithesis of eugenic practice\".\n\nThe ideas of eugenics and race were used, in part, as justification for German colonial expansion throughout the world. Germany, as well as Great Britain, sought to seize the colonial territories of other 'dying' empires which could no longer protect their possessions. Examples included China, the Portuguese Empire, the Spanish Empire, the Dutch Empire and the Danish Empire.\n\nThus the colonies Germany required for her bursting population, as markets for her overproductive industries and sources of vital raw materials, and as symbols of her world power would simply have to be taken from weaker nations, so the pan-Germans asserted publicly and the German government believed secretly.\n\nGerman colonies in Africa from 1885 to 1918 included German South-West Africa (present-day Namibia), Kamerun (present-day Cameroon), Togoland (present-day Togo) and German East Africa (present-day Tanzania. Rwanda and Burundi). Genocide was carried out there, against the Herero people of present-day Namibia and later a programme of research in physical anthropology was conducted using their skulls.\n\nThe rulers of German South West Africa carried out a programme of genocide against the aboriginal Herero people. One of the officials enacting this program was Heinrich Ernst Göring (the father of Hermann Göring), as well as General Adrian Dietrich Lothar von Trotha.\n\nThe 1918 British \"Bluebook\" documented the genocide that took place at Shark Island and Windhoek Concentration Camps, including photographs. The Bluebook was used as a negotiating tool by the British at the end of World War I to gain control of what had been German Southwest Africa, after Germany was defeated.\n\nSkulls of the Herero were collected from Rehoboth, Namibia in about 1904, for the purpose of demonstrating the supposed physical inferiority of these people. The Kaiser Wilhelm Institute used the Herero skulls by 1928.\n\nThe physical anthropologists used measurements of skull capacity, etc., in an attempt to prove that Jews, Blacks and Italians were inherently \"inferior\" to Whites. Examples of such activity were found from about 1928 at the Kaiser Wilhelm Institute of Anthropology, Human Heredity, and Eugenics. This contrasted with a lot of 19th century German anthropology which was generally more cosmopolitan.\n\nEugen Fischer of the Kaiser Wilhelm Institute of Anthropology, Human Heredity, and Eugenics and his students carried out \"Bastard studies\" anthropological studies of mixed race people throughout the German colonial empire, including the colonies in Africa and the Pacific. Fischer also worked with the United States eugenicist Charles Davenport.\n\nRita Hauschild, a doctoral student and then staff member of the Kaiser Wilhelm Institute for Human Heredity, Anthropology, and Eugenics, carried out \"bastard studies\", anthropometric studies of mixed-heritage populations in Trinidad and Venezuela, in pursuit of the Nazi doctrine of \"racial hygiene\". Her research was at first confined to Tovar, Venezuela, a former German colony, and was extended to Trinidad with support from the UK Foreign Office. The populations studied, in 1935 to 1937, were \"Chinese-Negro hybrids\" in Trinidad, \"Chinese-Indian\" and \"Chinese-Negro\" \"hybrids\" in Venezuela. In addition, Johannes Schaeuble engaged in \"bastard studies\" in Chile.\n\nIn the early part of the Shōwa era, Japanese governments executed a eugenics policy to limit the birth of children with \"inferior\" traits, as well as aiming to protect the life and health of mothers. The \"Race Eugenic Protection Law\" was submitted from 1934 to 1938 to the Diet. After four amendments, this draft was promulgated as the \"National Eugenic Law\" in 1940 by the Konoe government. According to the \"Eugenic Protection Law\" (1948), sterilization could be enforced on criminals \"with genetic predisposition to commit crime\", patients with genetic diseases such as total color-blindness, hemophilia, albinism and ichthyosis, and mental affections such as schizophrenia, and manic-depressiveness, and those with epilepsy. Mental illnesses were added in 1952.\n\nThe \"Leprosy Prevention laws\" of 1907, 1931 and 1953, the last one only repealed in 1996, permitted the segregation of patients in sanitariums where forced abortions and sterilization were common, even if the laws did not refer to it, and authorized punishment of patients \"disturbing peace\", as most Japanese leprologists believed that vulnerability to the disease was inheritable. There were a few Japanese leprologists such as Noburo Ogasawara who argued against the \"isolation-sterilization policy\" but he was denounced as a traitor to the nation at the 15th conference of the Japanese Association of Leprology in 1941.\n\nOne of the last eugenic measures of the Shōwa regime was taken by the Higashikuni government. On 19 August 1945, the Home Ministry ordered local government offices to establish a prostitution service for allied soldiers to preserve the \"purity\" of the \"Japanese race\". The official declaration stated: \"Through the sacrifice of thousands of \"Okichis\" of the Shōwa era, we shall construct a dike to hold back the mad frenzy of the occupation troops and cultivate and preserve the purity of our race long into the future...\"\n\nEarly in the Japanese administration of Korea, staff at the Japanese Association of Leprology attempted to discourage marriage between Japanese women and Korean men who had been recruited from the peninsula as laborers following its annexation by Japan in 1910. In 1942, a survey report argued that \"the Korean laborers brought to Japan... are of the lower classes and therefore of inferior constitution...By fathering children with Japanese women, these men could lower the caliber of the Yamato minzoku\". However, eugenics pioneer Unno Kōtoku of Ryukyu University influentially argued based on heterosis in plants that exclusive Japanese endogamy might cause \"degeneration\" of the Japanese race. Since he regarded intermarriage with white or black people as \"disastrous\", he advocated intermarriage with Koreans, whose \"inferior\" physical characteristics would be subsumed by the \"superior\" Japanese, according to his thinking. Japanese-Korean intermarriage was promoted by the government in Korea using serological studies that claimed to prove that Japanese and Koreans had the same pure ancestral origin.\n\nAfter independence in the late 1940s, both North and South Korea continued to perpetuate the idea of an ethnically homogeneous Korean nation based on a divine single bloodline. This \"pure-blood-ism\" (순혈주의) is a source of pride for many Koreans, and informs Korean nationalism, politics, and foreign relations. In South Korea, an ethnic nationalism tinged with pure blood ideology sustained the dictatorships of Syngman Rhee and Park Chung-hee, and it still serves as a unifying ideology, as Brian Reynolds Myers argues, in North Korea. Deep-seated cultural biases originating in eugenics policies result in discrimination against multiracial people in South Korea, according to the United Nations Committee on the Elimination of Racial Discrimination.\n\nEugenics was one of many ideas and programs debated in the 1920s and 1930s in Republican China, as a means of improving society and raising China's stature in the world. The principal Chinese proponent of eugenics was the prominent sociologist Pan Guangdan, and a significant number of intellectuals entered into the debate, including Gao Xisheng, biologist Zhou Jianren, sociologist Chen Da, and Chen Jianshan, and many others. Chen Da is notable for the link he provides to the family planning policy and One Child Policy enacted in China after the establishment of the People's Republic of China.\n\nThe Beijing Genomics Institute does whole genome sequencing of very high IQ individuals around the world. Geoffrey Miller claims that the Chinese may use this genetic data to increase the IQ of each subsequent generation by five to fifteen IQ points through the use of preimplantation embryo selection.\n\nSingapore practiced a limited form of eugenics that involved discouraging marriage between university graduates and nongraduates through segregation in matchmaking agencies, in the hope that the former would produce better children; and paid incentives for the uneducated to undergo sterilisation, among other procedures. The government introduced the \"Graduate Mother Scheme\" in the early 1980s to entice graduate women with incentives to get married, which was eventually scrapped due to public criticism and the implications it had on meritocracy.\n\nOther countries that adopted some form of eugenics program at one time include Denmark, Estonia, Finland, France, Iceland, Norway, and Switzerland with programs to sterilize people the government declared to be mentally deficient.\n\nBeginning in the late 1920s, greater appreciation of the difficulty of predicting characteristics of offspring from their heredity, and scientists' recognition of the inadequacy of simplistic theories of eugenics, undermined whatever scientific basis had been ascribed to the social movement. As the Great Depression took hold, criticism of economic value as a proxy for human worth became increasingly compelling. After the experience of Nazi Germany, many ideas about \"racial hygiene\" and \"unfit\" members of society were discredited. The Nuremberg Trials against former Nazi leaders revealed to the world many of the regime's genocidal practices and resulted in formalized policies of medical ethics and the 1950 UNESCO statement on race. Many scientific societies released their own similar \"race statements\" over the years, and the Universal Declaration of Human Rights, developed in response to abuses during the Second World War, was adopted by the United Nations in 1948 and affirmed, \"Men and women of full age, without any limitation due to race, nationality or religion, have the right to marry and to found a family.\" In continuation, the 1978 UNESCO declaration on race and racial prejudice states that the fundamental equality of all human beings is the ideal toward which ethics and science should converge.\n\nIn reaction to Nazi abuses, eugenics became almost universally reviled in many of the nations where it had once been popular (however, some eugenics programs, including sterilization, continued quietly for decades). Many pre-war eugenicists engaged in what they later labeled \"crypto-eugenics\", purposefully taking their eugenic beliefs \"underground\" and becoming respected anthropologists, biologists and geneticists in the postwar world (including Robert Yerkes in the U.S. and Otmar von Verschuer in Germany). Californian eugenicist Paul Popenoe founded marriage counseling during the 1950s, a career change which grew from his eugenic interests in promoting \"healthy marriages\" between \"fit\" couples.\n\nThe American Life League, an opponent of abortion, charges that eugenics was merely \"re-packaged\" after the war, and promoted anew in the guise of the population-control and environmentalism movements. They claim, for example, that Planned Parenthood was funded and cultivated by the Eugenics Society for these reasons. Julian Huxley, the first Director-General of UNESCO and a founder of the World Wildlife Fund, was also a Eugenics Society president and a strong supporter of eugenics.\n\n[E]ven though it is quite true that any radical eugenic policy will be for many years politically and psychologically impossible, it will be important for UNESCO to see that the eugenic problem is examined with the greatest care, and that the public mind is informed of the issues at stake so that much that now is unthinkable may at least become thinkable. --Julian Huxley\n\nHigh school and college textbooks from the 1920s through the 1940s often had chapters touting the scientific progress to be had from applying eugenic principles to the population. Many early scientific journals devoted to heredity in general were run by eugenicists and featured eugenics articles alongside studies of heredity in nonhuman organisms. Even the names of some journals changed to reflect new attitudes. For example, \"Eugenics Quarterly\" became \"Social Biology\" in 1969 (the journal still exists today, though it looks little like its predecessor). Notable members of the American Eugenics Society (1922–94) during the second half of the 20th century included Joseph Fletcher, originator of Situational ethics; Clarence Gamble of the Procter & Gamble fortune; and Garrett Hardin, a population control advocate and author of the essay \"The Tragedy of the Commons\".\n\nIn the United States, the eugenics movement had largely lost most popular and political support by the end of the 1930s, while forced sterilizations mostly ended in the 1960s with the last performed in 1981. Many US states continued to prohibit biracial marriages with \"anti-miscegenation laws\" such as Virginia's Racial Integrity Act of 1924, until they were overruled by the Supreme Court in 1967 in Loving v. Virginia. The Immigration Restriction Act of 1924, which was designed to limit the immigration of \"dysgenic\" Italians, and eastern European Jews, was repealed and replaced by the Immigration and Nationality Act in 1965.\n\nHowever, some prominent academics continued to support eugenics after the war. In 1963 the Ciba Foundation convened a conference in London under the title \"Man and His Future\", at which three distinguished biologists and Nobel laureates (Hermann Muller, Joshua Lederberg, and Francis Crick) all spoke strongly in favor of eugenics. A few nations, notably the Canadian province of Alberta, maintained large-scale eugenics programs, including forced sterilization of mentally handicapped individuals, as well as other practices, until the 1970s.\n\nBeginning in the 1880s, the history and concept of eugenics were widely discussed as knowledge about genetics advanced significantly, making practical genetic engineering, which has been widely used to produce genetically modified organisms, with genetically modified foods being most visible to the general public. Endeavors such as the Human Genome Project made the effective modification of the human species seem possible again (as did Darwin's initial theory of evolution in the 1860s, along with the rediscovery of Mendel's laws in the early 20th century). Article 23 of the Convention on the Rights of Persons with Disabilities prohibits compulsory sterilization of disabled individuals and guarantees their right to adopt children.\n\nA few scientific researchers such as psychologist Richard Lynn, psychologist Raymond Cattell, and scientist Gregory Stock have openly called for eugenic policies using modern technology, but they represent a minority opinion in current scientific and cultural circles. One attempted implementation of a form of eugenics was a \"genius sperm bank\" (1980–99) created by Robert Klark Graham, from which nearly 230 children were conceived (the best-known donors were Nobel Prize winners William Shockley and J. D. Watson). After Graham died in 1997 funding ran out, and within two years his sperm bank had closed.\n\n\"The Bell Curve\" argued that immigration from countries with low national IQ is undesirable. According to Raymond Cattell, \"when a country is opening its doors to immigration from diverse countries, it is like a farmer who buys his seeds from different sources by the sack, with sacks of different average quality of contents\".\n\nA screening policy (including prenatal screening and abortion) intended to reduce the incidence of thalassemia exists in both jurisdictions on the island of Cyprus. Since the program's implementation in the 1970s, it has reduced the ratio of children born with the hereditary blood disease from 1 out of every 158 births to almost zero. Tests for the gene are compulsory for both partners, prior to church wedding.\n\nEugenic concerns have been prominent in China for some time, with the PRC's 1950 Marriage Law stating that \"impotence, venereal disease, mental disorder and leprosy\", as well as any other diseases seen by medical science as making a person unfit to marry, were grounds for prohibition from marriage. The 1980 law dropped all specific conditions bar leprosy, and the 2001 law now specifies no conditions, simply approval by a medical doctor.\n\nVarious provinces began to pass laws barring certain classes of people, such as the mentally retarded, from reproducing in the late 1980s. The Chinese Maternal and Infant Health Care Law (1994), which has been referred to as the \"Eugenic Law\" in the West, required a health check prior to marriage. Carriers of certain genetic diseases were allowed to marry only if they are sterilized, or agree to use some other form of long-term contraception. Though the requirement for the health check has been dropped at the national level, it continues to be required by some provinces. Local medical doctors make the decision on who is \"unfit\" to marry. Much Western comment on the law has been critical, but many Chinese geneticists are supportive of the policy.\n\nIn the Chinese province of Sichuan in 1999, a sperm bank called Notables' Sperm Bank opened, with professors as the only permitted donors. The semen bank was approved by the authority for family planning in the provincial capital Chengdu.\n\nIn postwar Japan, the was enacted in 1948 to replace the National Eugenic Law of 1940. The main provisions allowed for the surgical sterilization of women, when the woman, her spouse, or family member within the 4th degree of kinship had a serious genetic disorder, and where pregnancy would endanger the life of the woman. The operation required consent of the woman, her spouse and the approval of the Prefectural Eugenic Protection Council.\n\nThe law also allowed for abortion for pregnancies in the cases of rape, leprosy, hereditary-transmitted disease, or if the physician determined that the fetus would not be viable outside of the womb. Again, the consent of the woman and her spouse were necessary. Birth control guidance and implementation was restricted to doctors, nurses and professional midwives accredited by the Prefectural government. The law was also amended in May 1949 to allow abortions for economic reasons at the sole discretion of the doctor, which in effect fully legalized abortion in Japan.\n\nAlthough the law's wording is unambiguous, the it was used by local authorities as justification for measures enforcing forced sterilization and abortions upon people with certain genetic disorders, as well as leprosy, as well as an excuse for legalized discrimination against people with physical and mental handicaps.\n\nIn Russia, one supporter of preventive eugenics is the president of the Independent Psychiatric Association of Russia Yuri Savenko, who justifies forced sterilization of women, which is practiced in Moscow psychoneurological nursing homes. He states that “one needs a more strictly adjusted and open control for the practice of preventive eugenics, which, in itself, is, in its turn, justifiable.” In 1993, the health minister of the Russian Federation issued the order that determined the procedure of forced abortion and sterilization of disabled women and the need for court decision to perform them. The order was repealed by the head of Ministry of Health and Social Development of the Russian Federation Tatyana Golikova in 2009. Therefore, now women can be subjected to compulsory sterilization without court decision, according to the Perm Krai ombudswoman Tatyana Margolina. In 2008, Tatyana Margolina reported that 14 women with disabilities were subjected to compulsory medical sterilization in Ozyorskiy psychoneurological nursing home whose director was Grigori Bannikov. The sterilizations were performed not on the basis mandatory court decision appropriate for them, but only on the basis of the application by the guardian Bannikov. On 2 December 2010, the court has not found corpus delicti in the compulsory medical sterilizations performed by his consent.\n\nMississippi, Montana and the District of Columbia require a blood test prior to marriage. While these tests are typically restricted to the detection of the sexually transmitted disease syphilis (which was the most common STD at the time these laws were enacted), some partners will voluntarily test for other diseases and genetic incompatibilities. Harris polls in 1986 and 1992 recorded majority public support for limited forms of germ-line intervention, especially to prevent \"children inheriting usually fatal genetic disease\".\n\nDor Yeshorim, a program which seeks to reduce the incidence of Tay-Sachs disease, cystic fibrosis, Canavan disease, Fanconi anemia, familial dysautonomia, glycogen storage disease, Bloom's Syndrome, Gaucher disease, Niemann-Pick disease, and mucolipidosis IV among certain Jewish communities, is another screening program which has drawn comparisons with liberal eugenics. In Israel, at the expense of the state, the general public is advised to carry out genetic tests to diagnose these diseases early in the pregnancy. If a fetus is diagnosed with one of these diseases, among which Tay-Sachs is the most commonly known, the pregnancy may be terminated, subject to consent.\n\nMost other Ashkenazi Jewish communities also run screening programs because of the higher incidence of genetic diseases. In some Jewish communities, the ancient custom of matchmaking (shidduch) is still practiced, and some matchmakers require blood tests so that they can avoid making matches between individuals who share the same recessive disease traits. In order to attempt to prevent the tragedy of infant death which always results from being homozygous for Tay-Sachs, associations such as the strongly observant Dor Yeshorim (which was founded by Rabbi Joseph Ekstein, who lost four children to the disease) with the purpose of preventing others from suffering the same tragedy test young couples to check whether they carry a risk of passing on fatal conditions.\n\nIf both the young man and woman are Tay-Sachs carriers, it is common for the match to be broken off. Judaism, like numerous other religions, discourages abortion unless there is a risk to the woman, in which case her needs take precedence. The effort is not aimed at eradicating the hereditary traits, but rather at the occurrence of homozygosity. The actual impact of this program on allele frequencies is unknown, but little impact would be expected because the program does not impose genetic selection. Instead, it encourages disassortative mating.\n\nModern inquiries into the potential use of genetic engineering have led to an increased invocation of the history of eugenics in discussions of bioethics, most often as a cautionary tale. Some suggest that even non-coercive eugenics programs would be inherently unethical. This view has been challenged by such bioethicist critics as Nicholas Agar.\n\nIn modern bioethics literature, the history of eugenics presents many moral and ethical questions. Supporters of eugenics programs note that Francis Galton did not advocate coercion when he defined the principles of eugenics. According to Galton's definition, eugenics is the proper label for bioengineering of better human beings, whether coercive or not.\n\nAn example of such individual motivations includes parents attempting to prevent homosexuality in their children, despite lack of evidence of a single genetic cause of homosexuality. The scientific consensus in America, which stems from the 1956 research of Evelyn Hooker, is that homosexuality in any case is not a disorder. Therefore, it cannot be treated as a defective trait that is justifiably screened for as part of legitimate medical practice.\n\nDaniel Kevles argues that eugenics and the conservation of natural resources are similar propositions. Both can be practiced foolishly so as to abuse individual rights, but both can be practiced wisely. James D. Watson, the first director of the Human Genome Project, initiated the \"Ethical, Legal and Social Implications Program\" (ELSI) which has funded a number of studies into the implications of human genetic engineering (along with a prominent website on the history of eugenics), because:\n\nIn putting ethics so soon into the genome agenda, I was responding to my own personal fear that all too soon critics of the Genome Project would point out that I was a representative of the Cold Spring Harbor Laboratory that once housed the controversial Eugenics Record Office. My not forming a genome ethics program quickly might be falsely used as evidence that I was a closet eugenicist, having as my real long-term purpose the unambiguous identification of genes that lead to social and occupational stratification as well as genes justifying racial discrimination.\n\nDistinguished geneticists including Nobel Prize-winners John Sulston (\"I don't think one ought to bring a clearly disabled child into the world\") and Watson (\"Once you have a way in which you can improve our children, no one can stop it\") support genetic screening. Which ideas should be described as \"eugenic\" are still controversial in both public and scholarly spheres. Some observers such as Philip Kitcher have described the use of genetic screening by parents as making possible a form of \"voluntary\" eugenics.\n\nIn 2006, Richard Dawkins stated that breeding humans for traits is possible and society should not be afraid to debate the ethical differences between breeding a child for an ability versus forcing a child to gain an ability through training. Nathaniel C. Comfort, Professor at the Institute of the History of Medicine at the Johns Hopkins University, published in his 2012 book, \"The Science of Human Perfection: How Genes Became the Heart of American Medicine\", \"The eugenic impulse drives us to eliminate disease, live longer and healthier, with greater intelligence, and a better adjustment to the conditions of society.\" Comfort claims that the question is not whether this eugenic impulse should exist or even whether the modern genetic movement should be called eugenics because these things \"just are\". Additionally, Dr Nathaniel Comfort claims, \"the health benefits, the intellectual thrill and the profits of genetic biomedicine are too great for us to do otherwise.\" Bio-ethicist Stephen Wilkinson of Keele University and Honorary Research Fellow Eve Garrard at the University of Manchester, claim that some aspects of modern genetics can be classified as eugenics, but this classification does not inherently make modern genetics immoral. In a co-authored publication by Keele University, they stated that \"[e]ugenics doesn't seem always to be immoral, and so the fact that PGD, and other forms of selective reproduction, might sometimes technically be eugenic, isn't sufficient to show that they’re wrong.\"\n\nGeoffrey Miller claims that 21st century Chinese eugenics may allow the Chinese to increase the IQ of each subsequent generation by five to fifteen IQ points, and after a couple generations it \"would be game over for Western global competitiveness.\" Miller recommends that we put aside our \"self-righteous\" Euro-American ideological biases and learn from the Chinese.\n\nJon Entine claims that new eugenics is not something that should be restricted lightly because it is driven by a motivation for ourselves and our children to be \"healthy, intelligent, and fit,\" and it is not driven by \"draconian top-down measures\" or a \"desire to improve the species.\"\n\nThere are over 700 mutations in the mitochondrial DNA, and Salvatore DiMauro advocates that cytoplasmic transfer can be used to prevent \"a Pandora's box of diseases, including recurrent strokes, seizures, blindness, deafness, diabetes, and a brain-destroying illness called necrotizing encephalopathy.\"\n\nBill McKibben, for example, suggests that emerging reprogenetic technologies would be disproportionately available to those with greater financial resources, thereby exacerbating the gap between rich and poor and creating a \"genetic divide\". Lee M. Silver, a biologist and science writer who coined the term \"reprogenetics\" and supports its applications, has nonetheless expressed concern that these methods could create a two-tiered society of genetically-engineered \"haves\" and \"have nots\" if social democratic reforms lag behind implementation of reprogenetic technologies.\n\nMaxwell J. Mehlman argues that our democratic society could be endangered if unequal access to genetic enhancement technology creates a \"genobility\" and the gap between the genetically enhanced and unenhanced widens. Mehlman suggests that the government should subsidize the cost of genetic enhancement technology to ensure it is equally available.\n\n"}
{"id": "13799904", "url": "https://en.wikipedia.org/wiki?curid=13799904", "title": "Identity control theory", "text": "Identity control theory\n\nIdentity control theory is a theory in sociology concerned with the development of personal identity. Created by Peter Burke, it focuses on the nature of peoples' identities and the relationship between their identities and their behavior within the realm of their social structure. The identities of the individual are rooted in their social structure. Identity Control Theory was created based on traditional symbolic interaction views where people choose their own behaviors and how their behaviors correspond to the meanings of their identity. One of the main aspects ICT deals with is how individuals view their own identities and respond to the reactions to their identities of those around them. When an individual is acting according to the identity control theory they reflect on the identity they display and how others approve or disapprove of their identity. If the individual does not like the responses of others they will look at how they can change their views of their identity or their identity towards themselves to produce a positive outcome. One of the main benefits of this theory is how negative feelings can be prevented by individuals and by those around them. The people around someone who is displaying a certain identity have the ability to be more sensitive and prevent negative feelings if they understand identity control theory because they know what will bring out a negative response. On the other hand, the individual can prevent negative feelings that coincide with the teachings of identity control theory if they understand these teachings and can apply them to their own lives.\n\nThere are four main components of the identity control theory being identity standard, input, comparator, and output. Each identity is viewed as a control system with these four components (Burke, 2007).\n\nIdentity standard is the first of the four components of identity control theory. Identity standard defines what it means to be who one is in a situation. The identity standard stores the self-meanings tied to social roles and membership in groups. This is the set of meanings for a given identity. The meanings in identity standard represent the goals or the way the situation is supposed to be. People act to verify or confirm their identities and in doing so they bring about a situation in which relevant meanings are consistent with their identity standard.\n\nThe next of the four components is input or also known as perceptions. Input is the meanings of how one sees oneself in a situation. These self-meanings often are derived from the way in which others see the self. This results from the feedback others have about how we come across in a given situation.\n\nThe third component of the identity control theory is comparator. The comparator compares the meanings from the input with those from the standard and registers the difference between them. This compares the perceived meanings with the meanings in the identity standard.\n\nThe final component of the theory is output or sometimes called an error or discrepancy. Output is the differences that result from the perceptions and the identity standard. Then as a function of the output, there is meaningful behavior enacted in the situation that conveys meanings about our identity. If in a setting people perceive their identity relevant meanings to be congruent with the meanings in their identity standard, that is the discrepancy is zero, people continue to do what they have been doing. If the discrepancy is not zero, people change their behavior in such a way as to counteract the disturbance and reduce the discrepancy back toward zero (Burke, 2007). These altered meanings are perceived and again compared to the meanings in the identity standard. Thus, each identity is a control system that acts to control perceptions by bringing them into congruency with the meanings of their identity standards, thus reducing toward zero any discrepancy or error caused by a disturbance(Burke,2007).\n\nPeople act to verify or confirm their identities and in doing so they bring about a situation in which perceived meanings are consistent with their identity standard. If the identity is a role identity, then the behavior that brings about the changes in the situational meanings to make them consistent with the identity standard is appropriate role behavior. If the identity is a group or category based identity, the behavior which verifies the identity is the behavior that maintains group boundaries and divisions in the social structure. By verifying identities, people create and maintain the social structure in which the identities are embedded(Burke,2007).\n\nAs one might guess, the identity control theory has a direct correlation to an individual's emotions. This mainly stems from whether or not the person's identity is fully recognized by those around them. If they are fully recognized or recognized greatly positive emotions will be produced. On the reverse side a small amount of recognition, or a lack of recognition will produce negative emotions like anger and depression.\n\nWhen people surrounding an individual are able to correctly notice the personal identity that the individual is attempting to convey the self-esteem of the individual is increased. Their disposition also becomes filled with positive emotions. Another thing that will increase positive emotions is if the people closest to the individual reassure the individual of their identity. This reassurance allows the individual to feel secure in their actions and be able to further predict the responses of others. These feelings of security allow the individual to express themselves in the manner they wish. This is why the positive emotions become so prominent for the individuals who experience this. The only other part of identity control theory that increases positive emotions is if an individuals identity matches their perceptions of their identity. This creates harmony for the individual and allows them to be happier than if their perceptions did not match the actual outcome of their identities.\n\nWith the identity control theory, there is more opportunity for negative emotions than positive emotions. This is because there are many more opportunities for people to misunderstand what identity an individual is attempting to display. In fact, there are four main ways a person's identity can be misinterpreted that will produce emotions of anger and other negative aspects. These four are a discrepancy between the output and the input, a lack of attention to the identity trying to be displayed, too much control over the specific identity, and a lack of practice with the identity.\n\nInput vs Output: When an individual's identity is not received by others as the individual intended, then the possibility for negative emotions increases. Often those around the individual place a different meaning on the identity than the person intended there to be. This causes great frustration for the individual and can often lead to anger as well. Another part of this discrepancy is if those around the individual completely ignore the identity the individual is hoping to display. The complete unrecognition will produce even more frustration and anger than an incorrect view of the identity.\n\nLack of Attention: If an individual does not focus enough attention on the identity they wish to portray it will not be received fully either. This usually happens because all of their attention is normally focused on another aspect of their identity and all other facets are neglected. These neglected aspects are not displayed well by the individual, so they are not received by others as the individual hoped. This is a sure way for the individual to become down upon themselves or even extremely angry with themselves for not developing that aspect of their identities and being misunderstood.\n\nToo Much Control: When someone tries to control a certain aspect of their identity too much, they will most likely find themselves experiencing very negative feelings. This is because all the aspects of their personality are closely related because they are controlled so much. Therefore, if one aspect of their personality is not received as they had hoped, all other aspects of their personality will not be unverified. This has the potential to cause a complete identity crisis because no part of the person's identity will be reassured. This can cause the individual to panic and become filled with nervousness.\nLack of Practice: If an individual does not practice the identity they wish to convey enough, not only will they be unsure of it, those around them will be unsure of how to respond to the individual. In fact, those around the individual will most likely show great disapproval of the individual. If that does not happen, though, they will receive very irregular responses from those around them. Disapproval can severely drop the persons self-esteem or push the individual to be hostile with those around them due to their reactions. On the other hand, irregular responses can cause the individual to become frustrated with their outcome which can lead to a great deal of anger if it is repeated many times.\n\nOne final thing to remember about all emotions that can be created through the identity control theory is the degree of closeness those evaluating the identity are to the individual. If the people around the individual are very close to the individual and they assure their identity, the individual will most likely experience extreme positive emotions. However, if they criticize the identity, the individual will experience extreme negative emotions. The opposite of this, meaning that those evaluating the identity are not extremely close to the individual, the individual's emotions will not become very extreme at all. This is because the opinions of the people close to an individual hold more weight in the individual's mind than the opinions of the people they are not close to.\n\nCoping responses are the product of a person processing external or internal demands that can drain a person’s mental or physical resources (Foulton, 1982). External demands could be need for warmth, chores around the house or job, and cleanliness. Internal demands could be hunger, happiness, and control over environment. There are two parts to coping responses: first is the process of coping responses and second is the relationship between the person and outside forces.\n\nThe process can be separated into two parts. The first is summarized by what is currently happening. This includes the person's thoughts, feelings, and actions to reduce different demands (Foulton, 1982). Demands can be jobs, chores, relationships with others, and even body functions such as eating and sleeping. With different demands, one person can act in many different ways. For instance, if two people are hungry and are having problems at work, the first person might eat first then try to fix their job situation. The second person could fix their job first and then eat later. Demands are not limited to two things at a time: there can be many demands at the same time. So each person's different actions can affect the future or how things turn out. This is the second part: how current events (what is happening) affect changes in daily life or even the person's environment over time. The environment is not just limited to the outdoors, it is also the relationships with others. Acting in a certain way will bring out a certain change in the person's life, whether in the environment or in their every day life.\n\nThe relationship between the person and outside forces is the second part of coping responses. This relationship can be summarized by how the person views the environment. Again, the environment is not just the outdoor life, it is also the relationships in a person's life with others. A person first evaluates what is at stake in the environment. Beliefs, values, goals, commitments, and physical safety are all at stake (Foulton, 1982). After the stakes have been figured out, the person then must figure out what they can do. This depends on the availability of resources to keep all that is at stake. When the stakes go up, and the resources go down, more coping responses must be used: there is more stress (Foulton, 1982). Coping responses hopefully change the relationship between the person and the environment by changing the situation or the person's feelings about it.\n\nThe functions of coping responses are to reduce stress; they help restore an equilibrium (Foulton, 1982). Here are some examples: defense mechanisms help reduce tension; decision-making responses involves seeking and evaluating information; coping responses with illness involves the reduction of harmful environmental conditions and the maintenance of a positive self-image (Foulton, 1982). There are two groups that these responses can be broken down to. One group is problem-focused and the other is emotional-focused (Foulton, 1982). Problem-focused responses include cognitive strategies and behavioral strategies. A cognitive strategy would be analyzing the situation. Behavioral would be figuring out how to act or which actions to use. These responses are more likely to occur when there is more opportunity for personal control (Foulton, 1982). When there is less opportunity for personal control, then emotion focused responses are used. Emotion-focused responses also include cognitive strategies and behavioral strategies. A cognitive response is thinking positively or even looking at things from a different perspective. A behavioral response would be to seek emotional support (Foulton, 1982). Getting a pet or making new friends could also fit in this category. Both problem and emotional influence each other. For instance, if someone is consumed by an emotion, then they might have to get that under control before they can begin to analyze the situation. Or to control an emotion, someone would reason out what was causing the emotion, thus controlling it.\n\nOne aspect of new research found with the identity control theory relates to social interaction and identities. According to social psychologist Richard Jenkins, they are vital to each other. The basic principle that Jenkins tries to present is that if social interactions do not exist it is impossible for the main principles of Burke's identity control theory to exist. An individual's identity cannot be approved or disapproved if they do not interact with others. In the reverse direction, if people do not develop their identities enough, it would be impossible for them to interact with those around them fully. Jenkins says that the two go hand in hand and allow the other to function as sociologists have predicted them to. To further understand the relation between social interaction and identity control theory, one must look at the relationships between identity control theory and other sociological ideas. Many other ideas in sociology concern how individuals act in social interactions, which can further the idea of identity control theory. Individuals derive meanings of the majority of the occurrences in their lives through interactions with others. Because of this, it is safe to look at identity control theory and say that as an individual repeats social interactions and receives the same reactions, they can become secure and feel positive emotions regarding their identity. However, if the reactions are inconsistent, the security needed for positive emotions related to their identity is not present. This is because the social interactions confuse the individual instead of allowing them to understand what is occurring around them. Without fully understanding what is going on around them, it would be impossible to fully form and be confident in their identity.\n\nLooking Glass Self is a sociological term that was introduced by a man named Charles Horton Cooley. This term makes a connection between the reactions of a group and the reactions of an individual. Cooley is saying that a person's opinion of oneself is determined by the opinions of those around them. The group around the person acts as a mirror for them and shows a reflection of how they should view themselves. According to this, if the group thinks an individual is \"odd\" the individual will view themselves as \"odd\". This relates to identity control theory in many ways, in fact this idea allowed the identity control theory to be formed. In identity control theory, the individuals feelings arise from the reactions of the group around them. If these two ideas are looked at collectively, an individual would view themselves exactly how the group did and then their feelings would be brought out by whether their current view of self matched their previous view of self. For example, if an individual originally viewed themselves as more of a scholar than an athlete, but the group around them started to view them as an athlete more than an individual their view of themselves would turn to more of an athlete according to looking glass self. But, following identity control theory this individuals input would not match their output which would have the potential to induce negative feelings. This can also be seen in the reverse because if the principle of looking glass self caused the output of an individual to match their input, positive emotions would be brought out. With that being said, the idea of looking glass self has the ability to manipulate the emotional responses of individuals in regards to identity control theory.\n\nA man named George Herbert Mead furthered the ideas of self that were started by Cooley. Mead used two terms to further the understanding of social interaction. The first of these terms is mind. Mind, in this sense of the word, is being able to understand symbols that are used in everyday social interactions. Mead states that as an individual's interaction with others is repeated their mind becomes more developed. In other words, as people repeatedly interact with those around them, their ability to understand the symbols involved in the interactions more clearly. The more developed an individual's mind is, the easier social interaction will be for them. The second term brought about by Mead is self. In this context, self is the understanding a person creates of how others respond to them. Like the concept of mind, self is brought out by social interaction. By looking at how a group reacts to an individual, Mead says that the individual can not only come to understand their own identity but to also see things from the perspective of another individual. This means that one can imagine what things would be like if they were in another's situation. If this occurs over and over again the individual can begin to generalize what others will expect of the individual and how they will react to them. These relate to identity control theory because understanding the symbols involved in social interaction and being able to predict the outcomes of interaction can help and individual prevent the negative feelings that can be associated with identity control theory. If one can predict how people will react to their identity, they can make changes to their identity that will allow their personal view of their identity to match the view others have of their identity. This will draw positive emotions from the person rather than negative ones, which is what individuals strive for in regards to identity control theory.\n\n\n"}
{"id": "5637961", "url": "https://en.wikipedia.org/wiki?curid=5637961", "title": "ImagineFX", "text": "ImagineFX\n\nImagineFX is a digital art magazine that features workshops and interviews with artists from the science fiction, fantasy, manga, anime, game and comic disciplines.\n\nPublished in Bath, UK by Future plc since January 2006, the main focus of \"ImagineFX\" is the workshops featured in the second half of the magazine, which is published on a monthly basis. Artists such as Ryan Church, Jonny Duddle, Martin Bland and Henning Ludvigsen contribute to the magazine. The magazine come with a DVD but has since switched to digital downloads that includes the workshop files that relate to the tutorials in the magazine, program demos, free fonts, textures, images and Photoshop brushes. It also has small segments of traditional and 3D art. \n\nEach month the magazine features an interview with artists such as Alan Lee, Larry Elmore, Frank Frazetta and Jim Burns. Featurs such as \"Rising Star\", \"Artist Porfolios\" and reader galleries showcase the work of up-and-coming artists.\n"}
{"id": "176496", "url": "https://en.wikipedia.org/wiki?curid=176496", "title": "Infallibility", "text": "Infallibility\n\nInfallibility is the inability to be wrong. Its importance and meaning is debated in epistemology and major religions.\n\nEpistemology, a branch of philosophy, is concerned with the question of what, if anything, humans can know. The answer to the issue of whether or not a human can be infallible depends on the philosophical school.\n\n\nHuman involvement in the revelatory process is very important because God has no choice but to communicate in human language through human agents. But if this must be so, God can at least be expected to prevent human weakness and shortcoming from marring this divine process. If our sources of knowledge are not infallible, then who is going to decide what to accept and what to reject? \n\"The Oxford Dictionary of the Christian Church\" defines infallibility as \"Inability to err in teaching revealed truth\". Roman Catholic and Eastern Orthodox Church theology claim that the Church is infallible, but disagree as to where infallibility exists, whether in doctrines, scripture, or church authorities.\n\nIn contrast, Protestant and non-denominational Christian churches believe that the Christian Church is indeed fallible—as evidenced by the requirement of Christ's sacrifice on the cross to pay for the sins of the world, including those of his Church—and that only God's word in Scripture is infallible. They also completely reject the Roman Catholic claim regarding Papal Infallibility, citing not just scriptural reasons, but also the many times popes have contradicted each other and the history of mistakes committed by many popes throughout Roman Catholic Church history. \n\nBecause of the complexity in defining infallibility, some Protestant and non-denominational views confuse infallibility and impeccability, as if the Pope were immune from sin, but that is not the Roman Catholic Church's doctrine. In Roman Catholic theology, only the actual act of teaching may properly be called \"infallible\". According to the First Vatican Council (1869–71) and as reaffirmed at Vatican II (1962–1965) the Pope is infallible when speaking \"ex cathedra\" on matters of faith and morals. Thus the Pope may sin in his private life, but he is infallible while on the clock.\n\nThe notion of infallibility in Judaism as it relates to the Tannaim and Amoraim of the Talmud, as well as the Rishonim, Achronim and modern day Gedolim is one surrounded by debate.\n\nSome who reject infallibility cite the Talmud, Pesachim 94b:\n\nThe words of the Mishna are commented on by numerous commentators, and Yehuda Levi argues that evidence mounts that the Geonim and the Rambam perceived that the sages of the Talmud \"erred in a matter of astronomy. The Rambam wrote that the great sages are not expected to advocate positions perfectly in-line with modern science because they were \"scholars of that generation,\" often basing their assessments of what \"they learned from the scholars of the era.\"\n\nIn the Hassidic tradition, however, infallibility is taught in the Chabad tradition in connection with a Rebbe.\n\nIslam teaches that the teachings and guidance by the Prophets with regard to bringing the message of the One true God was infallible. Islam also teaches that the Qur'an is an infallible text.\n\nIn Shi'a theology, the belief is that the Ahl al-Bayt, including Muhammad, his daughter Fatima Zahra and Shi'a Imams are all infallible and do not make mistakes. It is believed that they are infallible in the sense that all statements or teachings made by them can be relied on to be certainly true, that all information believed by themselves is true, \"and\" that they have complete knowledge about right and wrong and never intend to disobey God, in a sense, \"perfect creation\". It is also held by Shi'as that there were 124,000 Prophets, beginning with Adam and ending with Muhammad - with all, including the latter, being infallible in the same sense as the Ahl al-Bayt. However, for information about whether or not Islam states that Moḥammad and other Messengers or Prophets were always infallible, or unquestionable for any of their acts, see the Qur'an (5: 116) (11: 36 - 37, 40 - 47) (37: 139 - 142) (66: 1).\n\nIn the Bhagavad Gita, Krishna explains to Arjuna (Bg 15.16 to 15.20) \"There are two classes of beings, the fallible and the infallible. In the material world every living entity is fallible, and in the spiritual world every living entity is called infallible. Besides these two, there is the greatest living personality, the Supreme Soul, the imperishable Lord Himself, who has entered the three worlds and is maintaining them. Because I am transcendental, beyond both the fallible and the infallible, and because I am the greatest, I am celebrated both in the world and in the Vedas as that Supreme Person. Whoever knows Me as the Supreme Personality of Godhead, without doubting, is the knower of everything. He therefore engages himself in full devotional service to Me, O son of Bharata. This is the most confidential part of the Vedic scriptures, O sinless one, and it is disclosed now by Me. Whoever understands this will become wise, and his endeavors will know perfection.\"\n\n"}
{"id": "1381751", "url": "https://en.wikipedia.org/wiki?curid=1381751", "title": "Karma yoga", "text": "Karma yoga\n\nKarma yoga, also called Karma marga, is one of the four spiritual paths in Hinduism, one based on the \"yoga of action\". To a \"karma yogi\", right work done well is a form of prayer. It is one of the paths in the spiritual practices of Hindus, others being Raja yoga, Jnana yoga (path of knowledge) and Bhakti yoga (path of loving devotion to a personal god). The three paths are not mutually exclusive in Hinduism, but the relative emphasis between Karma yoga, Jnana yoga and Bhakti yoga varies by the individual.\n\nOf the paths to spiritual liberation in Hinduism, karma yoga is the path of unselfish action. It teaches that a spiritual seeker should act according to dharma, without being attached to the fruits or personal consequences. Karma Yoga, states the \"Bhagavad Gita\", purifies the mind. It leads one to consider dharma of work, and the work according to one's dharma, doing god's work and in that sense becoming and being \"like unto god Krishna\" in every moment of one's life.\n\nAccording to James Lochtefeld, Karma yoga (also called \"karmamarga\") is the spiritual practice of \"selfless action performed for the benefit of others\". Karma yoga is a path to reach spiritual moksha (liberation) through work. It is rightful action without being attached to fruits or being manipulated by what the results might be, a dedication to one's duty, and trying one's best while being neutral to rewards or outcomes such as success or failure.\n\nThe tendency for a human being to seek the fruits of action is normal, state Hindu texts, but an exclusive attachment to fruits and positive immediate consequences can compromise dharma (ethical, rightful action). Karma yoga, states Bilimoria, is \"ethically fine-tuned action\". According to Stephen Phillips, a professor of philosophy and Asian studies, \"only dharmic action\" is suitable in \"karma yoga\", where one downplays one's own exclusive role or one's own exclusive interests. Instead, the \"karma yogi\" considers the interests of all parties impartially, all beings, the elements of \"Prakṛti\" and then does the right thing. However, adds Phillips, there are commentators who disagree and state \"any action can be done as karma yoga\" and it doesn't have to be consistent with dharma.\n\nKarma yoga, states Bilimoria, does not mean forfeiture of emotions or desires, rather it means action driven by \"equanimity, balance\", with \"dispassion, disinterest\", avoiding \"one sidedness, fear, craving, favoring self or one group or clan, self-pity, self-aggrandizement or any form of extreme reactiveness\". A Karma yogi acts and does his or her duty, whether that be as \"a homemaker, mother, nurse, carpenter or garbage collector, with no thought for one's own fame, privilege or financial reward, but simply as a dedication to the Lord\", states Harold Coward – professor of Religious Studies with a focus on Indian religions.\n\nAccording to Phillips, Karma yoga applies to \"any action in any profession or family activities\", where the yogi works selflessly to others' benefit. This is in contrast to other forms of yoga which focus on self-development and self-realization, typically with isolation and meditative introspection. The \"disinterested action\" idea, states Phillips, is not unique to Hinduism, and similar disinterested non-craving precepts for monks and nuns are found in Buddhism and Jainism.\n\nAccording to the \"Bhagavad Gita\", selfless service to the right cause and like-minded others, with the right feeling and right attitude, is a form of worship and spirituality.\n\nThe verse 3.4 of the \"Bhagavad Gita\" states that avoiding work or not starting work is not the path to become free of bondage, just like renouncing the world and wearing monk's dress does not automatically make one spiritual. Not acting is a form of action with consequences and karmic impact, and the nature of existence is such that human beings are always acting in their environment, body or mind, and never for a moment are they not, according to verse 3.5. The verses 3.6 to 3.8 of the \"Bhagavad Gita\" state that the action can be motivated by body or manipulated by external influences. Alternatively, it can be motivated by one's inner reflection and true self (soul, Atman, Brahman). The former creates bondage, the latter empowers freedom. The spiritual path to the liberated state of bliss is to do the best one is able to while being detached to outcomes, to fruits, to success or failure. A karma yogi who practices such \"nishkama karma\" (\"niṣkāmakarma\"), states Bhawuk, is \"an inward journey, which is inherently fulfilling and satisfying\".\n\nA part of the premise of \"disinterested action\" is that the more one acts with the hope of getting rewards, the more one is liable to disappointment, frustration or self-destructive behavior. Further, another part of the premise is that the more one is committed to \"disinterested action\", the more one considers the dharma (ethical dimension), focuses on other aspects of the action, strives to do one's best, and this leads to liberating self-empowerment.\n\nAccording to chapter 5 of the \"Bhagavad Gita\", both \"sannyasa\" (renunciation, monastic life) and \"karma yoga\" are means to liberation. Between the two, it recommends \"karma yoga\", stating that anyone who is a dedicated karma yogi neither hates nor desires, and therefore such as person is the \"eternal renouncer\".\n\nThe \"Bhagavad Gita\" gives a summary of the karma yoga process. The \"Gita\" itself is a chapter from the epic known as \"Mahabharata\", wherein a dialogue takes place between the prince Arjuna, and his friend and chariot driver, Lord Krishna, on the brink of a great dynastic war. Their conversation is prompted by Arjuna as he is engulfed by sorrow and misgivings regarding the oncoming battle in which he has friends and relatives on both sides. In reply, Krishna then elucidates upon a number of philosophical yoga systems and practices (including karma yoga) by/through which Arjuna should indeed continue with the fight on righteous principles.\n\nIn the \"Bhagavad Gita\", Krishna says:\n\"tasmad asaktah satatam karyam karma samacara asakto hy acaran karma param apnoti purushah\" \n\nTherefore, without being attached to the results of activities, one should act as a matter of duty, for by working without attachment one attains the Supreme.\n\nThe earliest texts that are forerunners of the karma yoga ideas in the \"Bhagavad Gita\" are the ancient Upanishads, such as the \"Brihadaranyaka Upanishad\". Other Vedic texts as well as post-Vedic literature of the Mimamsa school of Hindu philosophy mention \"karma marga\", but these contextually refer to the path of rituals. According to Raju, the Mimamsa ideas, though orthodox, were the fertile grounds on which the later ideas of \"Karma yoga\" developed.\n\nKarma yoga is discussed in many other Hindu texts. For example, the section 11.20 of the \"Bhagavata Purana\" states that there are only three means to spiritual liberation: \"jnana yoga\" (knowledge), \"karma yoga\" (action) and \"bhakti yoga\" (devotion). Those who are of philosophical bent, prefer the \"knowledge path\". Those who are inclined to productive application of arts, skills and knowledge, prefer the \"karma path\". Those who prefer emotional connection, prefer the \"devotional path\". These three paths overlap, with different relative emphasis.\n\nDiscussions on Karma yoga are also found in chapter 33 of \"Narada Purana\".\n\nLater, new movements within Hinduism added raja yoga as the fourth spiritual path, but this is not universally accepted as distinct to other three.\n\nAccording to Constance Jones and James Ryan, karma yoga is \"yoga of action\" while kriya yoga is \"yoga of ritual action\". Kriya yoga is found in tantric texts, and believed by its practitioners to activate chakra and energy centers in the body. In that sense, kriya yoga is a subset of karma yoga. \n\n\n"}
{"id": "13957856", "url": "https://en.wikipedia.org/wiki?curid=13957856", "title": "Kirill Formanchuk", "text": "Kirill Formanchuk\n\nKirill Formanchuk is an activist for motorists' rights in Yekaterinburg, Russia. On October 12, 2007, he suffered severe injuries from a beating while in police custody, which has led to increased public and media scrutiny of traffic police in a number of Russian cities.\n\nHe was a member of the Committee to Protect the Rights of Motorists, an activist group. He was previously employed by the Yekaterinburg municipal government.\n\nPrior to the attack, Formanchuk had achieved local notoriety by challenging the lawfulness of traffic patrol stops, which are widely perceived in Russia to be corrupt and motivated by a desire for bribes. Formanchuk repeatedly refused to bribe traffic patrol officers, instead challenging them on their knowledge of traffic regulations and other laws governing traffic stops.\n\nAccording to Formanchuk, he went to a police station on October 12, 2007 to register his car. He attempted to record video of his interaction with the officers, which he says infuriated them. He was subsequently attacked. Formanchuk did not positively identify his attackers as police officers, but he alleges that officers on duty did nothing to restrain the attackers.\n\nThe police allege that Formanchuk became belligerent in the police station, was arrested, and suffered his injuries when he instigated a fight with the other occupants of his jail cell.\n\nFormanchuk was hospitalized after the attack, which caused injuries to his skull and brain.\n\nAfter Formanchuk's beating became public, motorists' groups in Yekaterinburg, St. Petersburg, and Moscow held demonstrations against the police. An Internet posting in support of Formanchuk has received over 200,000 hits. State-run media, which is usually reluctant to air criticism of government authorities, has begun to focus on Formanchuk's story, with one channel referring to his treatment as \"outrageous.\"\n\nThe Yekaterinburg edition of Rossiyskaya Gazeta, the official government newspaper, cited Formanchuk's situation while admonishing law enforcement services to be more cooperative with motorists.\n\nLaw enforcement officials denied any involvement with Formanchuk's beating and accused Formanchuk's activist group of inciting the public against the police. They further alleged that Formanchuk is a draft dodger with many serious traffic violations.\n\nFormanchuk nowadays also acts as a senator in civil Ekaterinburg Senate aimed at providing public control for official authorities. He focuses on automobile-related affairs.\n\n\n"}
{"id": "25249780", "url": "https://en.wikipedia.org/wiki?curid=25249780", "title": "Landfill gas utilization", "text": "Landfill gas utilization\n\nLandfill gas utilization is a process of gathering, processing, and treating the methane gas emitted from decomposing garbage to produce electricity, heat, fuels, and various chemical compounds. The number of landfill gas projects, which convert the gas into power, went from 399 in 2005 to 519 in 2009 in the United Kingdom, according to the Environment Agency. These projects are popular because they control energy costs and reduce greenhouse gas emissions. These projects collect the methane gas and treat it, so it can be used for electricity or upgraded to pipeline-grade gas. These projects power homes, buildings, and vehicles.\n\nLandfill gas (LFG) is generated through the degradation of municipal solid waste (MSW) and other biodegradable waste, by microorganisms. Aerobic conditions, presence of oxygen, leads to predominately emissions. In anaerobic conditions, as is typical of landfills, methane and are produced in a ratio of 60:40. Methane () is the important component of landfill gas as it has a calorific value of 33.95 MJ/Nm^3 which gives rise to energy generation benefits. The amount of methane that is produced varies significantly based on composition of the waste. Most of the methane produced in MSW landfills is derived from food waste, composite paper, and corrugated cardboard which comprise 19.4 ± 5.5%, 21.9 ± 5.2%, and 20.9 ± 7.1% respectively on average of MSW landfills in the United States. The rate of landfill gas production varies with the age of the landfill. There are 4 common phases that a section of a MSW landfill undergoes after placement. Typically, in a large landfill, different areas of the site will be at different stages simultaneously. The landfill gas production rate will reach a maximum at around 5 years and start to decline. Landfill gas follows first-order kinetic decay after decline begins with a k-value ranging 0.02 yr-1 for arid conditions and 0.065 yr-1 for wet conditions. Landfill Methane Outreach Program (LMOP) provides first order decay model to aid in the determination of landfill gas production named LandGEM (Landfill Gas Emissions Model). Typically, gas extraction rates from a municipal solid waste (MSW) landfill range from 25 to 10000 m³/h where Landfill sites typically range from 100,000 m³ to 10 million m³. MSW landfill gas typically has roughly 45 to 60% methane and 40 to 60% carbon dioxide, depending on the amount of air introduced to the site through active gas extraction. There are many other minor components that comprises roughly 1% which includes , , , , non-methane volatile organic compounds (NMVOCs), polycyclic aromatic hydrocarbons (PAHs), polychlorinated dibenzodioxins (PCDDs), polychlorinated dibenzofurans (PCDFs), etc. All of the aforementioned agents are harmful to human health at high doses.\n\n \n\nLandfill gas collection is typically accomplished through the installation of wells installed vertically and/or horizontally in the waste mass. Design heuristics for vertical wells call for about one well per acre of landfill surface, whereas horizontal wells are normally spaced about 50 to 200 feet apart on center. Efficient gas collection can be accomplished at both open and closed landfills, but closed landfills have systems that are more efficient, owing to greater deployment of collection infrastructure since active filling is not occurring. On average, closed landfills have gas collection systems that capture about 84% of produced gas, compared to about 67% for open landfills. \n\nLandfill gas can also be extracted through horizontal trenches instead of vertical wells. Both systems are effective at collecting. Landfill gas is extracted and piped to a main collection header, where it is sent to be treated or flared. The main collection header can be connected to the leachate collection system to collect condensate forming in the pipes. A blower is needed to pull the gas from the collection wells to the collection header and further downstream. A landfill gas collection system with a flare designed for a 600 ft³/min extraction rate is estimated to cost $991,000 (approximately $24,000 per acre) with annual operation and maintenance costs of $166,000 per year at $2,250 per well, $4,500 per flare and $44,500 per year to operate the blower (2008). LMOP provides a software model to predict collection system costs.\n\nIf gas extraction rates do not warrant direct use or electricity generation, the gas can be flared off. One hundred m³/h is a practical threshold for flaring in the US. In the U.K, gas engines are used with a capacity of less than 100m3/h. Flares are useful in all landfill gas systems as they can help control excess gas extraction spikes and maintenance down periods. In the U.K and EU enclosed flares are mandatory at modern landfill sites. Flares can be either open or enclosed. Enclosed flares are typically more expensive, but they provide high combustion temperatures and specific residence times as well as limit noise and light pollution. Some US states require the use of enclosed flares over open flares. Higher combustion temperatures and residence times destroy unwanted constituents such as un-burnt hydrocarbons. General accepted values are an exhaust gas temperature of 1000°C with a retention time of 0,3 seconds which is said to result in greater than 98% destruction efficiency.\n\nLandfill gas must be treated to remove impurities, condensate, and particulates. The treatment system depends on the end use. Minimal treatment is needed for the direct use of gas in boiler, furnaces, or kilns. Using the gas in electricity generation typically requires more in-depth treatment. Treatment systems are divided into primary and secondary treatment processing. Primary processing systems remove moisture and particulates. Gas cooling and compression are common in primary processing. Secondary treatment systems employ multiple cleanup processes, physical and chemical, depending on the specifications of the end use. Two constituents that may need to be removed are siloxanes and sulfur compounds, which are damaging to equipment and significantly increase maintenance cost. Adsorption and absorption are the most common technologies used in secondary treatment processing.\n\nPipelines transmit gas to boilers, dryers, or kilns, where it is used much in the same way as natural gas. Landfill gas is cheaper than natural gas and holds about half the heating value at 16,785 – 20,495 kJ/m3 (450 – 550 Btu/ft3) as compared to 35,406 kJ/m3 (950 Btu/ft3) of natural gas. Boilers, dryers, and kilns are used often because they maximize use of the gas, limited treatment is needed, and the gas can be mixed with other fuels. Boilers use the gas to transform water into steam for use in various applications. For boilers, about 8,000 to 10,000 pounds per hour of steam can be generated for every 1 million metric tons of waste-in-place at the landfill. Most direct use projects use boilers. General Motors saves $500,000 on energy costs per year at each of the four plants owned by General Motors that has implemented landfill gas boilers. Disadvantages of Boilers, dryers, and kilns are that they need to be retrofitted in order to accept the gas and the end user has to be nearby (within roughly 5 miles) as pipelines will need to be built.\n\nIn situations with low gas extraction rates, the gas can go to power infrared heaters in buildings local to the landfill, provide heat and power to local greenhouses, and power the energy intensive activities of a studio engaged in pottery, metalworking or glass-blowing. Heat is fairly inexpensive to employ with the use of a boiler. A microturbine would be needed to provide power in low gas extraction rate situations.\n\nThe gas coming from the landfill can be used to evaporate leachate in situations where leachate is fairly expensive to treat. The system to evaporate the leachate costs $300,000 to $500,000 to put in place with operations and maintenance costs of $70,000 to $95,000 per year. A 30,000 gallons per day evaporator costs $.05 - $.06 per gallon. The cost per gallon increases as the evaporator size decreases. A 10,000 gallons per day evaporator costs $.18 - $.20 per gallon. Estimates are in 2007 dollars.\n\nLandfill gas can be converted to high-Btu gas by reducing its carbon dioxide, nitrogen, and oxygen content. The high-Btu gas can be piped into existing natural gas pipelines or in the form of CNG (compressed natural gas) or LNG (liquid natural gas). CNG and LNG can be used on site to power hauling trucks or equipment or sold commercially. Three commonly used methods to extract the carbon dioxide from the gas are membrane separation, molecular sieve, and amine scrubbing. Oxygen and nitrogen are controlled by the proper design and operation of the landfill since the primary cause for oxygen or nitrogen in the gas is intrusion from outside into the landfill because of a difference in pressure. The high-Btu processing equipment can be expected to cost $2,600 to $4,300 per standard cubic foot per minute (scfm) of landfill gas. Annual costs range from $875,000 to $3.5 million to operate, maintain and provide electricity to. Costs depend on quality of the end product gas as well as the size of the project. The first landfill gas to LNG facility in the United States was the Frank R. Bowerman Landfill in Orange County, California. The same process is used for the conversion to CNG, but on a smaller scale. The CNG project at Puente Hills Landfill in Los Angeles has realized $1.40 per gallon of gasoline equivalent with the flow rate of 250 scfm. Cost per gallon equivalent reduces as the flow rate of gas increases. LNG can be produced through the liquidfication of CNG. However, the oxygen content needs to be reduced to be under 0.5% to avoid explosion concerns, the carbon dioxide content must be as close to zero as possible to avoid freezing problems encountered in the production, and nitrogen must be reduced enough to achieve at least 96% methane. A $20 million facility is estimated to achieve $0.65/gallon for a plant producing 15,000 gallons/day of LNG (3,000 scfm). Estimates are in 2007 dollars.\n\nIf the landfill gas extraction rate is large enough, a gas turbine or internal combustion engine could be used to produce electricity to sell commercially or use on site.\n\nMore than 70 percent of all landfill electricity projects use reciprocating piston (RP) engines, a form of internal combustion engine, because of relatively low cost, high efficiency, and good size match with most landfills. RP engines usually achieve an efficiency of 25 to 35 percent with landfill gas. However, RP engines can be added or removed to follow gas trends. Each engine can achieve 150kW to 3 MW, depending on the gas flow. An RP engine (less than 1 MW) can typically cost $2,300 per kW with annual operation and maintenance costs of $210 per kW. An RP engine (greater than 800 kW) can typically cost $1,700 per kW with annual operation and maintenance costs of $180 per kW. Estimates are in 2010 dollars.\n\nGas turbines, another form of internal combustion engine, usually meet an efficiency of 20 to 28 percent at full load with landfill gas. Efficiencies drop when the turbine is operating at partial load. Gas turbines have relatively low maintenance costs and nitrogen oxide emissions when compared to RP engines. Gas turbines require high gas compression, which uses more electricity to compress, therefore reducing the efficiency. Gas turbines are also more resistant to corrosive damage than RP engines. Gas turbines need a minimum of 1,300 cfm and typically exceed 2,100 cfm and can generate 1 to 10 MW. A gas turbine (greater than 3 MW) can typically cost $1,400 per kW with annual operation and maintenance costs of $130 per kW. Estimates are in 2010 dollars.\n\nMicroturbines can produce electricity with lower amounts of landfill gas than gas turbines or RP engines. Microturbines can operate between 20 and 200 cfm and emit less nitrogen oxides than RP engines. Also, they can function with less methane content (as little as 35 percent). Microturbines require extensive gas treatment and come in sizes of 30, 70, and 250 kW. A microturbine (less than 1 MW) can typically cost $5,500 per kW with annual operation and maintenance costs of $380 per kW. Estimates are in 2010 dollars.\n\nResearch has been performed indicating that molten carbonate fuel cells could be fueled by landfill gas. Molten carbonate fuel cells require less purity than typical fuel cells, but still require extensive treatment. The separation of acid gases (HCl, HF, and SO), VOC oxidation (HS removal) and siloxane removal are required for molten carbonate fuel cells. Fuel cells are typically run on hydrogen and hydrogen can be produced from landfill gas. Hydrogen used in fuel cells have zero emissions, high efficiency, and low maintenance costs.\n\nVarious landfill gas project incentives exist for United States projects at the federal and state level. The Department of the Treasury, Department of Energy, Department of Agriculture, and Department of Commerce all provide federal incentives for landfill gas projects. Typically, incentives are in the form of tax credits, bonds, or grants. For example, the Renewable Electricity Production Tax Credit (PTC) gives a corporate tax credit of 1.1 cents per kWh for landfill projects above 150 kW. Various states and private foundations give incentives to landfill gas projects. A Renewable Portfolio Standard (RPS) is a legislative requirement for utilities to sell or generate a percentage of their electricity from renewable sources including landfill gas. Some states require all utilities to comply, while others require only public utilities to comply.\n\nIn 2005, 166 million tons of MSW were discarded to landfills in the United States. Roughly 120 kg of methane is generated from every ton of MSW. Methane has a global warming potential of 23 times more effective of a greenhouse gas than carbon dioxide on a 100-year time horizon. It is estimated that more than 10% of all global anthropogenic methane emissions are from landfills. Landfill gas projects help aid in the reduction of methane emissions. However, landfill gas collection systems do not collect all the gas generated. Around 4 to 10 percent of landfill gas escapes the collection system of a typical landfill with a gas collection system. The use of landfill gas is considered a green fuel source because it offsets the use of environmentally damaging fuels such as oil or natural gas, destroys the heat-trapping gas methane, and the gas is generated by deposits of waste that are already in place. 450 of the 2,300 landfills in the United States have operational landfill gas utilization projects as of 2007. LMOP has estimated that approximately 520 landfills that currently exist could use landfill gas (enough to power 700,000 homes). Landfill gas projects also decrease local pollution, and create jobs, revenues and cost savings. Of the roughly 450 landfill gas projects operational in 2007, 11 billion kWh of electricity was generated and 78 billion cubic feet of gas was supplied to end users. These totals amount to roughly of pine or fir forests or annual emissions from 14,000,000 passenger vehicles. \n\n"}
{"id": "23067360", "url": "https://en.wikipedia.org/wiki?curid=23067360", "title": "Lexis diagram", "text": "Lexis diagram\n\nIn demography (the branch of statistics that deals with the study of populations) a Lexis diagram (named after economist and social scientist Wilhelm Lexis) is a two dimensional diagram that is used to represent events (such as births or deaths) that occur to individuals belonging to different cohorts. Calendar time is usually represented on the horizontal axis, while age is represented on the vertical axis. In some textbooks the y-axis is plotted backwards, with age 0 at the top of the page and increasing downwards. However, other arrangements of the axes are also seen. As an example the death of an individual in 2009 at age 80 is represented by the point (2009,80); the cohort of all persons born in 1929 is represented by a diagonal line starting at (1929,0) and continuing through (1930,1) and so on.\n\n\n"}
{"id": "5483190", "url": "https://en.wikipedia.org/wiki?curid=5483190", "title": "Medical necessity", "text": "Medical necessity\n\nMedical necessity is a United States legal doctrine, related to activities which may be justified as reasonable, necessary, and/or appropriate, based on evidence-based clinical standards of care. Other countries may have medical doctrines or legal rules covering broadly similar grounds. The term clinical medical necessity is also used. In contrast, unnecessary health care lacks such justification.\n\nMedicare pays for medical items and services that are \"reasonable and necessary\" for a variety of purposes. By statute, Medicare may only pay for items and services that are \"reasonable and necessary\"for the diagnosis or treatment of illness or injury or to improve the functioning of a malformed body member\", unless there is another statutory authorization for payment.\n\nMedicare has a number of policies, including National coverage determinations (NCDs) and Local Coverage Determinations (LCDs), formerly known as Local Medical Review Policies (LMRP), that describe coverage criteria.\n\nIn a small number of cases, Medicare may determine if a method of treating a patient should be covered on a case-by-case basis. Even if a service is medically determined to be \"reasonable and necessary,\" coverage may be limited if the service is provided more frequently than allowed under Medicare coverage policies.\n\nThe use of cannabis (also known as marijuana) for medical purposes is a notable 'medical necessity' case. Cannabis is a plant whose active ingredients are widely reported by sufferers to be effective in pain control for various conditions, usually neuropathic in nature, where common painkillers have not had great benefit; however as a Schedule I drug under the Controlled Substance Act, it is illegal and is targeted by government, police, and anti-drug campaigners: in some states, possession is decriminalized for even non-medical purposes, wherein other states possession is a felony offense. In this case the doctrine of medical necessity would be used by a patient who believed marijuana was beneficial to them if charged with use or growing/production of illegal controlled substance relating to marijuana.\n\nIn several medical marijuana cases, the patients' physician has been willing to state to the court that the patient's condition requires this medicine and thus that the Court should not interfere. However, the Supreme Court of United States has outrightly rejected this defense in the landmark case \"United States v. Oakland Cannabis Buyers' Cooperative\", in which the Court ruled that there was no medical necessity exception to drug laws, and federal government is free to raid, arrest, prosecute, and imprison patients who are using medical marijuana no matter if the medicine is crucially necessary to them. On the other hand, in \"Gonzales v. Raich\", the Ninth Circuit Court of Appeals told a sufferer in extreme pain that they could not rely on state law allowing medical use, but if arrested they could seek to use medical necessity as a defence.\n\nIn the state of Maryland, a bill signed by former governor Robert Ehrlich, became law in 2003 permitting patients to use medical necessity defense to marijuana possession in the state. The maximum penalty for these users cannot exceed $100. However, this law does not prevent federal prosecution of patients, as the federal law does not recognize medical necessity. \n\n\n"}
{"id": "7097874", "url": "https://en.wikipedia.org/wiki?curid=7097874", "title": "Mel Chin", "text": "Mel Chin\n\nMel Chin (born 1951 in Houston, Texas, USA) is a conceptual visual artist. Motivated largely by political, cultural, and social circumstances, Chin works in a variety of art media to calculate meaning in modern life. Chin places art in landscapes, in public spaces, and in gallery and museum exhibitions, but his work is not limited to specific venues. Chin once stated: “Making objects and marks is also about making possibilities, making choices—and that is one of the last freedoms we have. To provide that is one of the functions of art.” \n\nIn 1975, Chin graduated from Peabody College in Nashville, Tennessee. Shortly after, in 1976, Chin created \"See/Saw: The Earthworks\" for Hermann Park in Houston, Texas, where the artist manipulated two sections of the park’s surface to create a kinetic, minimalist earthwork. In this mimic of a childhood pastime, Chin altered the landscape with an underground hydraulic device that allowed the participant to shift large sections of earth with their body weight. The title also questions psychological perception of what is above and below an object's surface. This piece addressed three of the major art trends of the time: minimalism, conceptualism, and earthworks.\nIn 1983, Chin moved to New York City. He created \"MYRRHA P.I.A. (Post Industrial Age)\" (1984), site specific to Bryant Park. Commissioned by the Public Art Fund, the work was based on a Gustave Doré engraving depicting Myrrha in the 30th canto of Hell from Dante’s Inferno. Chin created a three-dimensional figurative sculpture employing 19th century fabrication techniques, conjoined with space-age materials.\n\nIn 1989, Chin had a one-person exhibition at the Hirshhorn Museum in Washington, D.C. In \"The Operation of the Sun through the Cult of the Hand\" (1987), Chin addressed ancient Greek philosophy and Chinese philosophy. He investigated mythological constructions, and scientific information to contradict personal interpretations in the formulations of these works. Chin used nine planets of the solar system to launch this elaborate construction. The installation comments on the origins of word material and form from East and West by drawing upon mythology, alchemy, and science in each culture.\n\nAlso in this exhibition were three major pieces with political content; \"The Extraction of Plenty from What Remains: 1823-\" (1989) is composed of two replicated White House columns that squeeze a cornucopia hand-crafted of mahogany, banana, mud, coffee, and goats’ blood. In this artwork Chin reacted to the long history of American foreign policy that has fractured the ability of Latin American countries to prosper on their own. The date in the title 1823-(ongoing) is in reference to the Monroe Doctrine. \"The Sigh of the True Cross\" (1988) is based on a single string Ethiopian masinqo, or spike fiddle. Chin compounds the iconography of the musical instrument and the hammer and sickle to comment on famine, drought, failed politics, and foreign aid in the history of Ethiopia. \"The Opera of Silence\" (1988) is also complex and layered with meaning. An oversized Beijing opera drum rests on a staff made of human thigh bone, and the drum skins are woven into the emblem of the C.I.A. commenting on the interrelations of China, Tibet, and the C.I.A..\n\nChin conceptually developed the GALA Committee for the project called \"In the Name of the Place\". \"In the Name of the Place\" covertly inserted art objects on the set of the prime-time television series \"Melrose Place\". Chin claimed, “I realized that somewhere in those industries was where I wanted to develop this conceptual public art project. At the same time I was thinking of the virus as a paradigm for this art project. Viruses are self-replicating, but they mutate, and to me, that’s like an art idea. I was wondering, how do you get an idea into a system, and let it replicate within that system? Using the virus as a model, how could I interact with television?” “Syndicated television as a host can serve as a place for the generational transfer of an idea.” The idea to make an impression upon prime time television worked—and the project successfully placed fine art into popular culture. Sotheby's in Los Angeles auctioned the objects with proceeds going to two educational charities.\nIn 1992, Chin created \"Degrees of Paradise\" to be shown at the Storefront for Art and Architecture in New York City. Chin commissioned Kurdish weavers to create a 9 foot by 23 foot carpet with patterns based on satellite telemetry. This was installed in the ceiling of one triangular room. In a second similar-shaped room, overhead monitors projected active 3-D mathematically derived cloud patterns. The hand woven Turkish carpet juxtaposed with video monitors continued Chin’s commentary of new and old digital traditions by paying homage to both. This project was a precursor to \"The State of Heaven\" (not realized). Chin envisioned a massive carpet 66 feet by 66 feet that would represent the entire atmospheric envelope with each knot equating . The carpet was to be destroyed and rewoven in a constant process according to the depletion or accretion of the ozone hole. This was an attempt to make visible a phenomenon that we normally cannot see.\n\nAfter a series of successful gallery and museum exhibits, Chin abandoned object making to pursue an activist, ecological artwork. He began \"Revival Field\" in 1990. As a conceptual and scientifically grounded work \"Revival Field\" was developed with the intention of green remediation and ecological consciousness. In this landscape art project, Chin, with scientist, Dr Rufus Chaney, used plants called hyperaccumulators that are known for their ability to draw heavy metals from soil. Chin’s project was located in the Pig’s Eye Landfill in St. Paul, Minnesota for three years. Plot markers were placed to identify the individual plots. Inside them were Zinc, Copper, and Lead, all containing the correct ratios of the amount of metal in the soil. The project was not about the formal configuration but the conceptual realization of scientific process brought forth through art. Other \"Revival Field\" sites have been located in Palmerton, Pennsylvania and Stuttgart, Germany. This project materialized science, technology and art, while not adhering to the traditional object making of art.\n\nChin was featured on the PBS series where his pieces \"S.P.A.W.N.\" and \"KNOWMAD\" and \"Revival Field\" were highlighted. In \"S.P.A.W.N.\" Chin planned to reclaim abandoned buildings in the city of Detroit, Michigan. He looked at neglected homes that once thrived as a starting point for community development. \"KNOWMAD\" explored persecuted cultures and used traditional tribal woven rugs in an interactive computer video game. He developed this project collaboratively with computer software engineers, with the hope of shedding light upon forgotten cultures and forgotten people.\n\nIn 2008 Chin proposed the idea of CLI- mate (climate linked individual- mate). CLI- mate is an app that is accessible in any language and free for its users.\nThe idea is that it will personalize anyone’s relationship with climate change.\nUsers input their daily habits, the app combines their information with every single users and it calculates their impact on the planet. Users will be able to combine their faces with the worlds. The app is missing information on climate changes.\n\nIn 2004, Mel Chin was invited as a visiting artist at East Tennessee State University. While there, he completed the W.M.D. (\"Warehouse of Mass Distribution\"), which was driven to Houston, Texas in May, 2005, to participate in the Houston Art Car Parade.\nThe Station Museum of Contemporary Art held a major exhibition in Houston, Texas (2006) entitled \"Do Not Ask Me\". Prevailing themes that run through the work selected in this exhibition include war, social injustice, modern media, and individuality. Solo exhibitions of Chin’s art have appeared the Walker Art Center, Minneapolis, MN, The Menil Collection, Houston, TX, Storefront for Art and Architecture, New York, and The Fabric Workshop and Museum, Philadelphia, PA.\n\nIn 2006 the Frederieke Taylor Gallery in New York City featured a selection of pieces from the \"Do Not Ask Me\" exhibit, originally shown at the Station Museum, as well as new drawings. Chin exhibited \"KNOWMAD\" as well as \"Render\" at Frederieke Taylor Gallery in 2000 and 2003.\n\n\"9/11-9/11\" (2006) is Chin’s first animated film. Based on a graphic novella of the same name, which he wrote in 2002, it is a fictional love story set in Santiago, Chile, 1973 and New York City, 2001. Chin’s film deals with the human impact of trauma and tragedy brought forth not by fate but by covert political machinations. Chin is the creator/director working with a 2-D, Chilean animation team.\n\nChin is compelled to make art in spite of his dark world view which is in keeping with his philosophy of “taking action as resistance to insignificance.\" \n\nMel Chin is the recipient of multiple awards including the US National Endowment for the Arts, New York State Council for the Arts, Art Matters, Creative Capital, and the Penny McCall, Pollock/Krasner, Joan Mitchell, Rockefeller and Louis Comfort Tiffany Foundations and Nancy Graves Foundation Award. In 2010 he won a Fellow award granted by United States Artists.\n\nMel Chin has also exhibited in numerous group shows including the Fifth Biennial of Havana, Cuba; Seventh Architectural Biennial in Venice, Italy; Kwangju Biennale, Korea; Hirshhorn Museum, Washington D.C.; Museum of Contemporary Art, Los Angeles; the Whitney Museum of American Art; P.S.1 Contemporary Art Center; Museum of Modern Art; and the Asian American Arts Centre, New York City among others.\n\nIn 2006 Mel Chin visited New Orleans after hurricane Katrina to evaluate with fellow artists creative solutions to cure the aftermath of destruction as result of the storm. Chin began Operation Paydirt to find a solution for the high lead contimination in the soil of New Orleans, a problem that existed before Katrina. To assist the funding of Operation Paydirt, the Fundred Dollar Bill Project was implemented in schools across the United States to symbolically raise 300,000,000 dollars to propose to Congress for an exchange of real dollars in the Summer of 2010.\n\nIn 2010 Chin received the biennial Fritschy Culture Award from the museum Het Domein, Sittard the Netherlands. \"The jury praises the unique way in which Chin, in many of his projects, creates a form of art in which participation and other forms of engagement are key. In awarding the Fritschy Culture Award 2010 to Mel Chin, the jury members emphasize the critical engaged nature of this prize and the expression of contemporary global issues.\" As part of the Fritschy Culture Award, Mel Chin exhibited a solo show at the museum Het Domein, titled \"Disputed Territories\".\n\nChin has been included in the Asian American Arts Centre's art Asia America digital archive.\n\n"}
{"id": "4285967", "url": "https://en.wikipedia.org/wiki?curid=4285967", "title": "Mount Laurel doctrine", "text": "Mount Laurel doctrine\n\nThe \"Mount Laurel\" doctrine is a controversial judicial interpretation of the New Jersey State Constitution. The doctrine requires that municipalities use their zoning powers in an affirmative manner to provide a realistic opportunity for the production of housing affordable to low and moderate income households.\n\nThe doctrine takes its name from the lead case in which it was first pronounced by the New Jersey Supreme Court in 1975: \"Southern Burlington County N.A.A.C.P. v. Mount Laurel Township\" (commonly called \"Mount Laurel I\"), in which the plaintiffs challenged the zoning ordinance of Mount Laurel Township, New Jersey, on the grounds that it operated to exclude low and moderate income persons from obtaining housing in the municipality.\n\nAfter the decision in \"Mount Laurel I\", suits were filed against numerous municipalities. The plaintiffs in such suits fell into three classes: lower income persons who actually sought housing and advocacy organizations on their behalf; the New Jersey Public Advocate; and builders who sought to construct developments containing affordable housing.\n\nThese early exclusionary zoning suits were beset by numerous difficulties and little, if any, affordable housing resulted. In 1983 appeals in several of these cases (of which \"Southern Burlington County N.A.A.C.P. v. Mount Laurel Township\" was again the lead case), gave the New Jersey Supreme Court the opportunity to reaffirm and tweak the \"Mount Laurel\" Doctrine and provide several mechanisms and remedies to make the doctrine more effective.\n\nThe New Jersey Supreme Court was aware that the \"Mount Laurel II\" decision would be controversial and would engender debate about the proper role of the courts. The opinion invited legislative action to implement what the court defined as the constitutional obligation.\n\nIn 1985 the New Jersey Legislature responded by passing the Fair Housing Act. Accepting the premise that there was some constitutional obligation for municipalities to foster some degree of affordable housing, this legislation created an administrative agency, the Council on Affordable Housing (COAH), to establish regulations whereby the obligation of each municipality in terms of the number of units and how the obligation could be satisfied.\n\nA municipality which elected to participate in COAH's administrative process prior to being sued was provided with protection from litigation and especially the builder's remedy. As a transitional provision, the act provided that municipalities involved in litigation when the act was passed were to be able to transfer the litigation to COAH unless manifest injustice would result.\n\nCOAH developed regulations under which the specific number of affordable units that each municipality would be required to provide (its \"pre-credited need\") could be determined. Participating municipalities developed compliance plans to address this need by such means as the application of credits (\"e.g.\" filtering, spontaneous rehabilitation, extra credit for rental units), the use of regional contribution agreements (transferring part of the obligation to a willing municipality, usually an urban center, in the same region along with payment in an amount agreed by the municipalities) and zoning for affordable housing (usually involving increased density and mandatory set-asides). When COAH approved a municipality's compliance plan it would grant \"substantive certification\" which was designed to provide the municipality with protection from exclusionary zoning litigation.\n\nFrom the municipal point of view, the advantages of COAH's administrative process included the use of a formula to calculate fair share that might produce a lower obligation than the court would impose, the availability of the regional contribution agreement to reduce the number of units and the ability to determine where in the municipality that affordable housing ought to be developed rather than being forced to permit a development as a reward to a successful builder-plaintiff. Those municipalities that chose not to participate in COAH's administrative process remained vulnerable to exclusionary zoning lawsuits and the prospect of the builder's remedy. The disadvantage would be that a participating municipality might be required to zone some land in a manner that extra housing would be produced. Some municipalities, believing that the likelihood of facing an actual exclusionary zoning lawsuit was low enough, took their chances in not participating.\n\nWhile the Mount Laurel decision mandates a state constitutional obligation for every municipality in a \"growth area\" to provide a fair share of its region's present and prospective housing needs for low and moderate income families, there is no funding source specified for low or very-low income families, in a state that already has some of the nation's highest property taxes. Some have accused the decision for being an example of judicial activism.\n\nThe New Jersey Supreme Court welcomed the Legislature's adoption of the Fair Housing Act. A number of trial court decisions had denied transfer of pending cases to COAH under the manifest injustice standard, but the Supreme Court read that term very narrowly and ordered the cases transferred. The trial courts were directed to conform their rulings with regard to calculation of each municipality's obligation and how to meet it to COAH's regulations and the statute was found facially constitutional and interpreted to grant COAH ample authority, such as restraining the use of scarce resources (sewer capacity, potable water, land) for other than providing affordable housing, to assure that affordable housing might actually be built.\n\nCOAH is a currently defunct government agency created in the 1980s to administer Mt. Laurel requirements. Some have argued it needs reinvigoration.\n\nThe Fair Share Housing Center, or FSHC, is a Cherry Hill-based nonprofit organization founded in 1975 that litigates against towns in enforcement of fair housing development. Some have alleged that the FSHC has \"ties to developers.\"\n\nA \"builder's remedy lawsuit\" is a New Jersey lawsuit filed by a real estate developer in an attempt to force a New Jersey town to allow the construction of a large, multi-family housing complex that includes some affordable housing alongside ordinary apartments.\n\nUsually, the developer's court papers will make specific mention of the Mt. Laurel doctrine, which holds municipalities responsible for providing affordable housing to low and moderate income households. Some have argued that developers exploit the Mount Laurel doctrine with the builder's remedy and prevent town efforts to combat overdevelopment and sprawl. Some recent \"builder's remedy\" lawsuits or related concerns include:\n\n\nIn 1985, the Fair Housing Act created the now-repealed Regional Contribution Agreement system. The RCAs meant that towns could pay to get out of up to half of their affordable housing obligation by funding affordable housing elsewhere as required by the New Jersey Supreme Court's Mt. Laurel decision.\n\nIn 2008, at the behest of the Fair Share Housing Center's Peter O' Connor and over the objections of some suburban Democrats, Governor Corzine signed a law barring RCAs. A500. He signed A-500 into law during a ceremony at Fair Share Housing Development's Ethel R. Lawrence Homes. Some have demanded that RCAs be returned to cut down on sprawl.\n\nIn 1983, the NJ Supreme Court cautioned that, in requiring affordable housing, our State Constitution \"does not require bad planning. It does not require suburban spread. It does not require rural municipalities to encourage large scale housing developments. It does not require wasteful extension of roads and needless construction of sewer and water facilities for the out-migration of people from the cities and the suburbs. There is nothing in our Constitution that says that we cannot satisfy our constitutional obligation to provide lower income housing and, at the same time, plan the future of the state intelligently.\"\nSome commentators have denounced the environmental impact of the current regime. As the result of one successful builder's remedy lawsuit brought by S. Hekemian Group, developers may construct a 360-unit, high density housing development in Cranford, New Jersey next to a flood plain. Some assert such developments could worsen flooding in an already flood-prone area that was ravaged by Hurricane Irene in 2011.\n\nOther New Jersey residents assert they fear sprawl, the destruction of historic New Jersey small town architecture, and crowding: \n\nAs an environmental scientist, I am concerned with the question of how many residents can be sustained before we reach an environmental tipping point. When do our water systems fail to provide the supply needed (remember the Bergen County dire drought warning last October?); when does the volume of traffic finally overwhelm our existing roadways and extend commuting times to impossible limits (remember the last time you sat in local traffic?); when does the air quality become too unhealthy to breath (remember the ozone and poor air-quality alerts just last month?); how many people can actually be sustained with a reasonable quality of life within our municipalities, counties and state?\nOne Parsippany resident stated, \"I'm very frustrated that this significant tract of undeveloped land is being razed for development when so much property in Parsippany lies vacant,\" said Dave Kaplan, of the Stop the Overdevelopment at Waterview opposition group.\n\nThe New Jersey chapter of the Sierra Club applauded Christie's efforts to reform affordable housing law in 2010: \n\nThe current COAH law has had a bigger impact on land use and development than any other law in New Jersey's history. The Sierra Club strongly supports a requirement for affordable housing. As towns grow, they must provide a fair share of it. But the need for affordable housing should not undermine the environmental protections given to wetlands, flood plains, steep slopes, stream buffers that protect water supplies, ocean-fronts, and endangered species habitat. And no homes should be built where water supply is at critically low levels. Furthermore, new housing should be located where jobs are, to reduce the carbon footprints and pollution associated with automobile commuting.\n\nSome believe the NJ Supreme Court seeks legislative action to implement the Mount Laurel doctrine based on recent rulings, as of mid-2017:\n\nIn January 2017, the NJ Supreme Court issued a ruling stating that towns had to consider any historic failure to provide affordable housing. As one commentator put it, \n\nThis case resolved affordable housing regulation debates that have been ongoing since 1999. However, the Court provided no guidance on the method of implementation of affordable housing accommodations that it now requires of municipalities. This decision leaves numerous unanswered questions and it will depend heavily on the Legislature to issue reform of affordable housing requirements. This decision requires implementation of affordable housing accommodations into township plans that have not otherwise considered them since 1999. It is likely that the open spaces in towns will now be filled with affordable housing units, which will bring an influx of population to municipalities. ...We will need to watch the Legislature to see how and if it will alter the current affordable housing regulations to comply with the Court's recent ruling.\n\nIn its January 2017 opinion, the NJ Supreme Court welcomed the Legislature to re-approach the affordable housing issue: \"We recognize, as we have before, that the Legislature is not foreclosed from considering alternative methods for calculating and assigning a municipal fair share of affordable housing, and to that end, we welcome legislative attention to this important social and economic constitutional matter,\" Justice LaVecchia wrote.\n\nA Morris County Freeholder candidate, Harding Committeeman Nicolas Platt, proposed in May 2017 that all mayors state-wide conduct a sit-in in Trenton and refuse to leave the statehouse until legislators acted to reduce the overdevelopment impact of the builder's remedy issue.\n\nBergen and Passaic County Assemblywoman Holly Schepisi argued in a July 2017 opinion piece that reform was urgently needed: \"If built, the number of new homes alone would far exceed all the homes in the entire borough of Manhattan,\" she stated, calling the issue one of overdevelopment \"madness.\"\n\nIn the summer of 2017, Schepisi held the first of several planned public hearing in Paramus with various civic leaders on mandated affordable housing with local mayors and other state assembly members.\n\n\"It is long past time for the Legislature to act, and block [the nonprofit group Fair Share Housing Center] from their objective of destroying our suburban communities,\" said one mayor at the hearing according to the press. \"We really need action. Nobody has done what they need to do.\"\n\nSchepisi stated she invited the Fair Share Housing Center to attend but received a letter declining an appearance.\n\nIn Somerset County, Montgomery Township Mayor Ed Trzaska said the influx of apartment complex development would ruin the rural character of the area, \"overwhelm the township's infrastructure, greatly increase property taxes and burden the school system and negatively impact the quality of life in the township.\"\n\nIn Union County, in the summer of 2017, the Clark town council issued a unanimous resolution demanding for the state legislature to take action to reform the affordable housing issue; the mayor stated that otherwise, \"Union County will look like Queens in 25 years.\"\n\nIn Berkeley Heights in Union County in June 2017, Council President Marc Faecher said he considered the Legislature's failure to act on overdevelopment to be an \"abject failure by our state government.\"\n\nIn June 2018, NJ 101.5 radio host Bill Spadea advocated for a constitutional amendment to revoke the doctrine, arguing the imposition of unnecessary development increased tax burdens unfairly.\n\nIn the summer of 2017, the mayors of five Bergen County towns announced they were \"teaming up to take a regional perspective on affordable housing, in an effort to find reasonable solutions that will protect the integrity of their communities.\"\n\n\"Owing to its ongoing high rate of residential foreclosures, New Jersey has become known the Land of the Zombie Houses.\"\nSome have argued that the deluge of abandoned and vacant properties in New Jersey should be taken into account before forced building occurs in less crowded areas. They have also suggested that the state step up funding for code enforcement to reduce burdens of urban blight on attractive home development, including enforcement on absentee landlords. The City of Newark is \"working with the Urban League to identify vacant or abandoned properties that can be sold to small developers to then sell at cost to residents. About 16 percent of Newark's housing is vacant and the city has a high eviction and foreclosure rate according to a Rutgers report. \n\n\n"}
{"id": "4209781", "url": "https://en.wikipedia.org/wiki?curid=4209781", "title": "Multi-level governance", "text": "Multi-level governance\n\nMulti-level (or multilevel) governance is an approach in political science and public administration theory that originated from studies on European integration. Political scientists Liesbet Hooghe and Gary Marks developed the concept of multi-level governance in the early 1990s and have continuously been contributing to the research program in a series of articles (see Bibliography). Their theory resulted from the study of the new structures that were put in place by the EU (Maastricht Treaty) in 1992. Multi-level governance gives expression to the idea that there are many interacting authority structures at work in the emergent global political economy. It \"illuminates the intimate entanglement between the domestic and international levels of authority\".\n\n'Multi-level governance' is a recent concept, having first entered the lexicon of political science around fifteen years ago as comparativists became re-acquainted with European integration and discovered that authority was shifting not only from central states up to Europe, but also down to subnational authorities. The first efforts to understand this were descriptive, spawning concepts that have generated an extensive literature. Multi-level, polycentric, and multi-layered governance emphasize the dispersion of decision making from the local to the global level. In recent years these concepts have cross-pollinated subfields of political science including European studies and decentralization, federalism and international organization, public policy (e.g. environmental policy, health policy) and public-private governance, local governance and transnational governance.\n\nThe authors of a recent survey of the literature on the structure of government conclude that ‘We attribute many of the recent “cutting-edge” theoretical contributions in political science to studies of “multi-level governance”’ and they note that although students of federalism ‘considered the current subject matter of their field to be based on well-defined, well rooted and broadly accepted ideas, they were nevertheless open to a new flowering of federal theory as a result of fertilization by these new MLG theoretical developments’. However, there is nothing entirely new under the sun. Though scarcely recognized at the time, this research revives a rich tradition in political science represented by Karl Deutsch (1966) on the effect of societal transactions on government structure, Robert Dahl (1973) on the virtues and vices of multilevel democracy, and Stein Rokkan (1983) on identity and territorial politics.\n\nThe study of the European Union has been characterized by two different theoretical phases. The first phase was dominated by studies from the field of international relations; in the second phase these studies were revised and insights from among others, public policy were added. The most straightforward way of understanding this theoretical shift is to see it as a move away from treating the EU as an international organisation similar to others (e.g. NATO) to seeing it as something unique among international organisations. The uniqueness of the EU relates both to the nature and to the extent of its development. This means that in some areas of activity the EU displays more properties related to national political systems than to those of international organisations.\n\nThe theory of multi-level governance belongs to the second phase. Multi-level governance characterizes the changing relationships between actors situated at different territorial levels, both from the public and the private sectors. The multi-level governance theory crosses the traditionally separate domains of domestic and international politics and highlights the increasingly fading distinction between these domains in the context of European integration. \nMulti-level governance was first developed from a study of EU policy and then applied to EU decision-making more generally. An early explanation referred to multi-level governance as \"a system of continuous negotiation among nested governments at several territorial tiers\" and described how \"supranational, national, regional, and local governments are enmeshed in territorially overarching policy networks\". The theory emphasized both the increasingly frequent and complex interactions between governmental actors and the increasingly important dimension of non-state actors that are mobilized in cohesion policy-making and in the EU policy more generally. As such, multi-level governance raised new and important questions about the role, power and authority of states.\n\nNo other international form of cooperation is characterized by such far-reaching integration as the European Union. This becomes evident by the number and scope of policy areas covered by the European Union and the way policy is developed. The European Union can be characterised by a mix of classic intergovernmental cooperation between sovereign states and far-reaching supranational integration.\n\nMulti-level governance within the EU is understood as respecting competences, sharing responsibilities and cooperating between the various levels of governance: the EU, the Member States and the regional and local authorities. In this context, it refers to the principle of subsidiarity, which places decisions as close as possible to the citizens and ensures that that action at Union level is justified in light of the possibilities available at national, regional or local level. In practice Multilevel Governance within the EU is about participation and coordination between all levels of government both in the decision making process and in the implementation or evaluation of European policies.\n\nThe combination of communal decision-making with the wide area of policy areas results in a deep entanglement of the member states’ national policy levels with the European policy level. This entanglement is one of the basic principles of the multi-level governance theory. The multi-level governance theory describes the European Union as a political system with interconnected institutions that exist at multiple levels and that have unique policy features. The European Union is a political system with a European layer (European Commission, European Council and European Parliament), a national layer and a regional layer. These layers interact with each other in two ways: first, across different levels of government (vertical dimension) and second, with other relevant actors within the same level (horizontal dimension).\n\nConcerning with the changes of the institutional design of the European Union, the current model governance has been shaped as a setup of constraints upon political margin of discretion, applying the central tenet of ordoliberalism with the aim to use strong rules in order to reduce the discretionary exercise of powers by institutions so as to avoid an arbitrary use of them. This principle has achieved an extreme effect at the European level, that one not to avoid arbitrary use of political powers but to keep political responsibility and participation out of the decision-making process. As Laruffa concludes: \n\"It is quite clear that such a model of governance, which is made only by rules without any role for a democratic policy-making process, imposes a de facto limit to on the political rights of the European citizens. This means that there is a control exercised by rules over the European citizens rather than a control by the European citizens over rules and policies.\"\n\nThe European Union: Multilevel Governance in Practise\n\nWithin the European Union nearly 95,000 local and regional authorities currently have significant powers in key sectors such as education, the environment, economic development, town and country planning, transport, public services and social policies. These local and regional authorities implement nearly 70% of EU legislation. They help ensure the exercise of European democracy and citizenship. Special rights and competences for regions, cities and communities are supposed to enable and preserve diversity of governance at local and regional level. By thinking beyond traditional EU - Member States relations the EU multi-level governance concept further strengthens regional and transnational cooperation. In a broader sense, this concept also includes the participation of non-state players like economic and social partners and civil society in the decision making process of all levels of governance(thus taking up the vertical and horizontal dimensions of multilevel governance).\n\nThe Treaty of Lisbon as an important step towards Multilevel Governance\n\nThe Treaty of Lisbon represents an important step towards institutional recognition of multi-level governance in the way the European Union operates. It strengthens the competences and influence of local and regional authorities in the Community decision-making process giving roles to national (and regional) parliaments and the Committee of the Regions and enshrines the territorial dimension of the European Union, notably territorial cohesion as part of the process of European integration. The Committee of the Regions has established a system to monitor the compliance with the subsidiarity thorough the whole EU policy and law making process.\n\nMultilevel governance within the EU as an ongoing process\n\nNevertheless, multi-level governance within the EU is a dynamic and ongoing process. On 16 June 2009 the Committee of the Regions adopted a White Paper on multi-level governance which recommended specific mechanisms and instruments for stimulating all stages of the European decision-making process. This document, together with the follow-up opinion \"Building a European culture of Multilevel Governance\" affirmed the Committee’s political commitment to Multi-level Governance, proposing a first political project for Building Europe in partnership. As a follow up to the 2009 White paper on Multi-level Governance, the Committee developed a \"Scoreboard on Multi-level Governance\" to monitor on a yearly basis the development of multi-level governance at European Union level.\n\nThe Charter for Multi-level Governance in Europe\n\nOn 3 April 2014 the Committee of the Regions adopted a Charter for Multi-level Governance calling public authorities of all levels of governance to use and promote multi-level governance in their future undertakings. The Charter is open for signature to:\n\n• all European Union local and regional authorities;\n\n• European and national associations of local and regional authorities, as well as local and regional authorities' network are invited to officially commit to multilevel governance principles, giving the Charter their formal support;\n\n• National and European political figures wishing to back up the Charter are also invited to declare their support\n\nThe point of departure for multi-level governance was Europe, but recent books and articles have dealt with the dispersion of authority away from central states in Latin America, Asia, and North America. Decentralization has been at least as marked in Latin America as in Europe over the past two decades, and several Asian countries have decentralized in the past decade. Dispersion of authority above the national state is most evident in the EU, but it is not sui generis. A recent survey counts 32 regional IGOs pooling authority over quite wide areas of policy and which cover all but a handful of states in the world today. The number of governmental and non-governmental international organizations has increased markedly over the past two decades, as has their scope, range and intrusiveness. Crossborder interdependence – from migration to climate change to terrorism – has stimulated regional organization in many parts of the world.\n\nThe \"vertical\" dimension refers to the linkages between higher and lower levels of government, including their institutional, financial, and informational aspects. Here, local capacity building and incentives for effectiveness of sub national levels of government are crucial issues for improving the quality and coherence of public policy.\n\nThe \"horizontal\" dimension refers to co-operation arrangements between regions or between municipalities. These agreements are increasingly common as a means by which to improve the effectiveness of local public service delivery and implementation of development strategies.\n\nThere has been an intensification of research on the consequences as well as the character of multi-level governance. The concept was developed as a tool of pure research, but it now motivates policy makers. From the late 1990s the European Commission began to refer to its own mission as one of achieving multilevel governance, especially in cohesion policy. In 2001, the Commission set up a committee on multilevel governance to contribute to its White Paper on governance. José Manuel Barroso, President of the European Commission, claims that ‘the multilevel system of governance on which our European regional policy is based provides a key boost to the Union's competitive edge’ and that, in the current economic crisis, 'multilevel governance must be a priority'. In an October 2008 resolution, the European Parliament called on the member states ‘to develop as quickly as possible the practical measures set out in the First Action Programme . . . with a view to strengthening multilevel governance’. In 2009, 344 representatives of elected regional and local authorities across the EU approved a resolution on a 'European Union Charter for Multilevel Governance', which would bring localities and regions into European democratic decision making.\n\nThis theme has been taken up by several political parties including the European Peoples Party, representing Christian democratic parties in the European Parliament, which recently stated that ‘multilevel governance should be one of the guiding principles of the EU, an integral part of any European strategy or policy where local and regional authorities are widely implicated, and monitored closely to ensure that it is indeed being put into practice on the ground’.\n\nInternational organizations have also taken positions on the issue. In 2009, the United Nations Development Programme released a report, ‘Delivering Human Security through Multilevel Governance’, which argued that ‘the two-level approach to international relations . . . is being replaced by a much more complex multilevel system of governance that also involves local, sub-national providers of public goods as well as regional governance actors acting at a supranational but not a global level’. The World Bank has commissioned a series of studies examining multilevel governance; the United Nations has a research and training institute on comparative regional integration that studies ‘multilevel regulatory processes and the relations between sub- and supra-national regional governance’, and the OECD has created a directorate on multilevel governance.\n\nHowever, the consequences of multilevel governance are debated. In the eyes of its detractors, multilevel governance exacerbates corruption (Treisman 2000), leads to gridlock (Scharpf 2007), engenders moral hazard (Rodden 2006), constrains redistribution (Obinger, Castles, Leibfried 2005), obfuscates accountability (Peters & Pierre 2004), and wastes money (Berry 2009). Research on both causes and consequences of multi-level governance is ongoing and more and more information about the subnational as well as the international dimension of multi-level governance is available in the context of larger data sets.\n\nGlobal climate change is being contributed to by ever increasing levels of greenhouse gas emissions emanating from decisions and activities of individuals and organisations at local, regional, national and international levels. Cities are suggested to contribute up to 75% of global carbon dioxide emissions, reflecting the increasing proportions of global populations living and working in cities. As we know, tackling climate change is an extensive, time-consuming and costly task, a task that cannot be achieved solely through the policy implementation and regulation from central governments and bodies alone. It has become increasingly clear that nation-states will be unable to commit to and meet international targets and agreements for offsetting climate change without engaging with the activity of sub-national and local action. Hereby, warranting the extreme importance of multi-level governance of climate change within cities.\n\nForms of governance at multi-levels have taken off increasingly at the local scale, building upon the notion of ‘think global, act local’, in cities in particular. Greenhouse gas (GHG) emissions stem from certain activities that originate from specific places, bringing about thought that the local scale is the most appropriate political scale to produce necessary offsets in emissions. Cities are exemplary of such specific places in which local governance action can and will help reduce GHG emissions. The levels of governance authority handed down to local governments within cities has been perceived to out-do policy goals within the national and international arena, with some local governments taking on their own initiatives for tackling urban climate change. This sets an important stance to which the local scale of multi-level governance is important for tackling global climate change within the urban arena.\n\nFour distinct modes of governance exist within the dynamics of climate change in cities. Each stems from the local level with the ability of being implemented on multi-scales to mitigate and adapt to urban climate change. Self-governing is the capacity of local governments to govern its own activities such as improving energy efficiency within a designated city, without the burdening pressure to meet targets of increased energy efficiencies set by national governments. A form of self-governing within multi-level systems is horizontal collaboration where cities may collaborate with regions demonstrating multi-levels of governance to tackle urban climate change, imperative to the success of city climate change policy. Governing through enabling is the co-ordination and facilitation of partnerships with private organisations by the local government. National governments also implement this mode of governance to implement policy and action within cities. Governing through provision, a form of vertical collaboration along with governing through enabling, applies itself to the multi-levels of governance. Climate change in cities is tackled here through the shaping of and delivery of services and resources, with additional support aided to local governments from regional and national authorities. Lastly, another form of vertical collaboration, is governing through regulation. Such regulation characterises traditional forms of authoritative governance, exemplifying local to nation-state relations, almost nearly covering the entirety of the multi-level governance scale.\n\nWithin the various initiatives of the Low Emission Development Strategies Global Partnership (LEDS GP), the thematic working group on Subnational Integration (SNI-WG) was created in 2013 to support learning and facilitate collaboration between national and subnational governments for accelerated effective climate actions. The SNI-WG realizes several activities at global and regional levels including organizing panels at multiple regional and global forums, hosting peer-learning discussions, publishing reports and case studies, along with facilitating technical workshops, webinars and providing advisory Remote Expert Assistance on LEDS (REAL) support upon request. This process has generated observations, feedback and insights on the potential of the vertical integration and coordination of subnational climate actions to accelerate and scale-up both local and global emission reductions. Improving coordination and integration between the different levels of authority in a country is critical in determining both national and global capacity to govern climate change. City and subnational governments require support from the national government, and vice versa, in order to design and implement intersectoral policies and actions for domestic decarbonization pathways.\n\nMultilevel governance theory and empirical evidence demonstrate that the coordination and vertical integration of climate actions can:\n\nThe Cities for Climate Protection (CCP) program is one example of multi-level governance of climate change. Roles and responsibilities are shared within different levels of governance, from state actors to non-state actors (Betsill & Bulkeley, 2006). Membership consists of 40 large cities worldwide (Large Cities Climate Leadership Group), with local governments often working in close connection with national governments. However, the CCP can overlook the activity of nation-states giving local governments the opportunity to amend positions of policy implementation and regulation for offsetting urban climate change, which may be of a controversial nature to national governments. Thus illustrating even though climate change in cities can be addressed and governed at local, regional, national and international levels, it does not always follow a hierarchical order.\n\nMany of the problems associated with multi-level governance revolve around the notion of levels. The very idea of levels and levels of analysis is imbued with hierarchical implications. However, different levels or social spaces often interact or cut across with one another in complex ways that are not strictly hierarchical. To what extent can 'levels' be identified at all? The notion that international bodies constitute a discrete level of authority and governance is contestable. International regulatory networks may not be separate sources of authority but instead represent the reconstitution of state authority and the pursuit of state-level governance by other means. While territorial levels make sense when we are referring to public forms of authority, they seem less compatible with private and market forms of authority.\n\nAnother criticism on the theory of multi-level governance is that it's not really a proper theory, rather that it is an approach. The main difference between multi-level governance and other theories of integration is that it gets rid of the continuum or grey area between intergovernmentalism and supranationalism and leaves in its place a descriptive structure. This theory does not address the sovereignty of states directly, but instead simply says that a multi-level structure is being created by subnational and supranational actors. One of the main questions of integration theory, namely, the transfer of loyalty and sovereignty between national and supranational entities and the future of this relationship in the EU is not specifically addressed in this theory.\n\nThe identification of partial political measures and general macroeconomics is divided on diverse decisional levels. National governments maintain an important decisional role but the control unlocalizes at supranational level. Individual national sovereignty is dilated in this decisional process and the supranational institutions have an autonomic role.\n\nThe use of security as a means of instituting ideals of democracy. The shift to a multi-level governance perspective of enforcing the ideals prevents one nation from imposing its personal agenda or perception of what these ideals entail. Additionally, the use of supranational judgement creates a uniformity for the international portrayal and enforcement of democratic principles. The utilization of multi-level security governance allows for a pooling of resources to manage this enforcement, while still allowing States to act autonomously. The supranational level merely acts as a medium for allowing the promotion of mutually beneficial security. With the rise of transnational threats, a method for ensuring international security without the reliance on a single policing nation is required. Multi-level governance provides functional means of dealing with the deficiencies of merely national actors dealing with transnational issues on the international stage.\n\nThe preliminary notion of the European Union was the European Coal and Steel Community. The union was between the nations of France, Belgium, Italy, Netherlands, Luxembourg, and West Germany. Striving for the concept of European peace the nations sought to bind the nations through economic interdependence. Coming about as a reaction to World War II, the ECSC created an economic tie for previously independent nations. It provided the European peace the nations sought, and would evolve into the European Union seen today. It was not a new concept as trade has historically been viewed as a catalyst for peace between nations. Creating multi-level governance is shown to create the necessary ties for fostering economic interdependence to a greater degree than mere trade between nations. The linking of nations through a sharing of capital creates an adhesiveness that deters the escalation of political conflict from reaching a state of war. On the international stage, political conflict leads to war as a result of perception of potential gains being larger than the opportunity costs. Interdependence created by multi-level governance is shown to greatly reduce the probability of war by increasing the opportunity costs. The increase in opportunity cost to war can be viewed from even the economic ties perspective. It is seen by noting that economic ties between participatory nations makes the cost of disruption to the system through the escalation of the political sphere towards war illogical.\n\nMulti-level government has shown to increase efficiency of governance by creating an agreed upon standard for the implementation and execution of policies. To elaborate, the establishment of a supranational institution can be used to set standards for the way cooperating nations run their environmental, industrial, and safety policies. A key factor for multi-level governance is the terms the national actors agree to when forming the supranational institution as they will give certain decision making processes to the higher level, and agree to abide by the outcome. Nations consent to the terms as they face a common issue of international policy that has to deal with collective-action problems making it nonsensical to attend to by themselves. Agreements between nations to form a multi-level government creates an efficiency gain that allows them to all share in the positive benefit.\n\n\n\n"}
{"id": "50568436", "url": "https://en.wikipedia.org/wiki?curid=50568436", "title": "Multiple gender attraction", "text": "Multiple gender attraction\n\nMultiple gender attraction (MGA), sometimes multi-gender attraction, is an umbrella term that includes any romantic or sexual orientation which experiences attraction to more than one gender. Such orientations include, but are not limited to, bisexuality, pansexuality, and polysexuality.\n\n\n"}
{"id": "14406411", "url": "https://en.wikipedia.org/wiki?curid=14406411", "title": "Nepal Bhasa movement", "text": "Nepal Bhasa movement\n\nNepal Bhasa movement (Nepal Bhasa: नेपालभाषा आन्दोलन) refers to the struggle for linguistic rights by its speakers in Nepal in the face of opposition from the government and hostile neighbors. The campaign aims to increase the use of Nepal Bhasa in the home, education, government and business. Despite a high level of development, Newar culture and language are both under threat.\n\nNewars have been fighting to save their language from the time of the repressive Rana regime till today, and activists have been jailed, exiled and tortured. Opponents have even petitioned the Supreme Court to have its use barred. The history of Nepal Bhasa since the late 18th century has been marked by constant struggle against state repression and a hostile environment.\n\nThe movement arose against the suppression of the language by the state that began with the rise of the Shah dynasty in 1768 AD, and intensified during the Rana regime (1846-1951) and Panchayat system (1960-1990). Moreover, hostility towards the language from neighbors grew following mass migration into the Kathmandu Valley, leading to the indigenous Newars becoming a minority in their homeland. During the period 1952 to 1991, the percentage of the valley population speaking Nepal Bhasa dropped from 74.95% to 43.93%. The language has been listed as being \"definitely endangered\" by UNESCO.\n\nThe language movement can be divided into the following eras.\n\n\nFollowing the advent of the Shahs, the Gorkha language became the court language of Nepal, and Nepal Bhasa was replaced as the language of administration. Open suppression began in 1906 with documents in Nepal Bhasa being declared not admissible in court. In the subsequent years, authors were fined, whipped, imprisoned or expelled and their books confiscated. It was illegal to sing hymns in Nepal Bhasa or speak it on the telephone. As a result, development of the language and literature was stifled.\n\nDuring the period 1909 to 1941 known as the Renaissance era, a few authors braved official disapproval and started writing, translating, educating and restructuring the language. Writers Nisthananda Bajracharya, Siddhidas Mahaju, Jagat Sundar Malla and Yogbir Singh Kansakar are honored as the Four Pillars of Nepal Bhasa. Shukraraj Shastri and Dharmaditya Dharmacharya were also at the forefront of the movement.\n\nIn 1909, Bajracharya published the first printed book using movable type. Shastri wrote a grammar of the language entitled \"Nepal Bhasa Vyakarana\" which was published from Kolkata, India in 1928. Dharmacharya published the first magazine in Nepal Bhasa \"Buddha Dharma wa Nepal Bhasa\" from Kolkata in 1925. Also, the Renaissance marked the beginning of the movement to get official recognition for the name \"Nepal Bhasa\" in place of the Khas imposed term \"Newari\".\n\nIn 1940, the government mounted a crackdown against democracy activists and writers in which Shukraraj Shastri was hanged. A large number of authors were imprisoned for their literary or political activities. Dharmacharya was jailed for three months. Chittadhar Hridaya was sentenced to six years, Siddhicharan Shrestha was sentenced to 18 years, Phatte Bahadur Singh was sentenced to life imprisonment and Dharma Ratna Yami was sentenced to 18 years. They were released in 1945 after serving five years. In prison, Hridaya produced his greatest work \"Sugata Saurabha\", an epic poem on the life of the Buddha. Shrestha wrote a collection of poems entitled \"Seeswan\" (\"Wax Flower\", published in 1948) among other works.\n\nTheravada Buddhist monks stood up to the Rana regime and published books on Buddhism from India and brought them into Nepal. This led to the Banishment of Buddhist monks from Nepal. In 1944, eight monks were expelled for refusing to stop teaching Theravada Buddhism and writing in Nepal Bhasa. In 1946, the ban on writing was lifted, and the monks were allowed to return to Nepal following international pressure. Their writings and public activities in Nepal Bhasa had a profound impact on the development of the language.\n\nNepal Bhasa lovers took the movement to India and Tibet where they formed associations to organize writers and bring out publications to escape government suppression in Nepal. Newar merchants based in Kolkata, Kalimpong and Lhasa were major patrons of the language movement.\n\n\"Buddha Dharma wa Nepal Bhasa\", the first ever magazine in Nepal Bhasa, was published from Kolkata in 1925 by Dharmaditya Dharmacharya. He also established a literary organization named Nepal Bhasa Sahitya Mandal (Nepal Bhasa Literature Organization) in 1926.\n\nIn 1944, the Buddhist monks expelled from Nepal went to Sarnath and formed an organization named Dharmodaya Sabha. In 1947, it launched \"Dharmodaya\" magazine from Kalimpong funded by trader Maniharsha Jyoti Kansakar. Monk Aniruddha Mahathera was the first editor.\n\nNewar traders based in Lhasa promoted \"Thaunkanhe\" magazine which launched in Kathmandu in 1951. It was the first Nepal Bhasa magazine to be published from Nepal, and the first editor was a former merchant Purna Kaji Tamrakar.\n\nIn 1950, a literary society named Chwasa Pasa (Pen Friend) was formed in Kolkata by Prem Bahadur Kansakar and another writer Madan Lochan Singh to bring together writers living in exile. The society moved to Nepal in 1951 after the advent of democracy.\n\nFollowing the fall of the Ranas and advent of democracy in 1951, there was greater linguistic freedom, and Nepal Bhasa struggled to catch up. Books, magazines and newspapers appeared. A daily newspaper \"Nepal Bhasa Patrika\" began publication in 1955.\n\nState-owned Radio Nepal began broadcasting the news in Nepal Bhasa once a day in 1951. In 1958, Kathmandu Municipality passed a resolution that it would accept applications and publish major decisions in Nepal Bhasa in addition to the Nepali language.\n\nNepal Bhasa entered a vibrant phase in the educational system. It was included in the curriculum, and Nepal Rastriya Vidhyapitha recognized it as an alternative medium of instruction in the schools and colleges affiliated to it. In 1953, the government recognized Nepal Bhasa as a spoken language and an oriental language subject. The Nepal Educational Council adopted it as an optional subject.\n\nFollowing lobbying by language lovers, Nepal Bhasa was included in the course of study at the high school level in 1954, at the intermediate level in 1960 and bachelor level in 1962. And for two decades, Nepal Bhasa was widely taught in schools and colleges in the Kathmandu Valley and other parts of Nepal with thousands of students studying it as an optional subject.\n\nIn 1960, parliament was abolished, political parties were forbidden and the Panchayat system was established. Under this autocratic system, the government followed a one-language policy, and Nepal Bhasa suffered another period of suppression. It was gradually pushed out of the media and the educational institutions, triggering protest movements.\n\nThe restrictive policy of Panchayat encouraged the formation of literary associations to provide a forum for writers to present their works. In 1962, Birat Nepal Bhasa Sahitya Sammelan Guthi (Grand Nepal Bhasa Literary Conference Trust) was formed in Bhaktapur. It organized annual literary meets which continue till today.\n\nIn 1960, Nepal Bhasa students at Tri-Chandra College in Kathmandu launched an annual magazine named \"Jah\" (ज:) (meaning \"light\" in Nepal Bhasa) after the college magazine \"Light\" refused to include Nepal Bhasa articles in it. The magazine led to the organization of students interested in Nepal Bhasa in the college. That same year, they started the annual Inter-College Nepal Bhasa Literary Conference and also produced a weekly radio program in Nepal Bhasa on Radio Nepal named \"Jeevan Dabu\" (\"Life's stage\"). In the successive years, \"Jah\" served as a breeding ground for new writers and language activists.\n\nIn 1963, Kathmandu Municipality's decision to recognize Nepal Bhasa was revoked. In 1965, the language was banned from being broadcast over Radio Nepal. The removal of Nepal Bhasa from the country's only radio station sparked a protest movement which became known as the Movement of 1965 (\"Bais Salya Andolan\"). The protest took the form of literary meets as other types of demonstrations were prohibited. Literary programs were held weekly in market squares and courtyards where participants recited poems and sang songs containing critical messages.\n\nThe government cracked down by putting a number of activists in jail including writers Mangal Man Shakya, Pushpa Gopal Shrestha and Shree Krishna Anu. Buddhist monk Bhikshu Sudarshan Mahasthavir was jailed for six months and six days. Other prominent campaigners like Durga Lal Shrestha, Hitkar Bir Singh Kansakar and Mangal Man Shakya (of Om Bahal) were forced to go underground. The movement was made leaderless, and it came to a stop after a year.\n\nThe ban on Nepal Bhasa remained, but the 1965 Movement succeeded in raising awareness about linguistic rights and arousing public opinion against the Panchayat regime. Its most important achievement was creating a new generation of writers and campaigners who would take over from the activists who fought for the language during the Rana regime and lead the movement in the subsequent decades. Nepal Bhasa Manka Khala, founded in 1979, is one of the organizations that emerged during this period to struggle for language rights.\n\nThe New Education System Plan brought out in 1971 disrupted the popular study of Nepal Bhasa in educational institutions. Under the plan, vernacular subjects were removed from the curriculum, and students were forced to choose between the mother tongue and technical subjects, leading to Nepal Bhasa being pushed into the background. Student enrolment in the course dropped, resulting in the subject being pulled out of many schools and a further decline in students.\n\nFrom 1977, students could study Nepal Bhasa at the Master's level; but the university degree was not counted for promotion by the government, and so there were few takers for the subject.\n\nIn addition to government suppression, Nepal Bhasa has faced opposition from hostile critics. After Sri Lanka Broadcasting Corporation began broadcasting a weekly half-hour program in Nepal Bhasa on 6 November 1983, opponents in Nepal pressured the radio station to shut it down. Similar opposition led to All India Radio - Kurseong stopping broadcasting Nepal Bhasa songs during its Nepali service in 1966.\n\nArbitrary actions increased resentment towards Panchayat. In 1988, police arrested participants in a procession marking the birth anniversary of Nepal Bhasa poet Siddhidas Mahaju.\nAfter the 1990 People's Movement that brought the Panchayat system to an end, the languages of Nepal enjoyed greater freedom. However, efforts to get Nepal Bhasa reincluded as an optional subject after a gap of two decades were unsuccessful due to lack of funding.\n\nThe 1990 constitution recognized Nepal as a multi-ethnic and multilingual country. It also said that each community shall have the right to operate schools up to the primary level in its own mother tongue. However, the government's responsibility was not stated and communities had to open such schools on their own. In 1991, Jagat Sundar Bwane Kuthi, the first Nepal Bhasa-medium school, opened in Kathmandu with the efforts of volunteers and the support of domestic and foreign donors.\n\nMeanwhile, years of efforts to gain official recognition for the standard name Nepal Bhasa finally succeeded. On 8 September 1995, the government decided that the name Nepal Bhasa should be used instead of Newari. However, the Central Bureau of Statistics has not been doing so.\n\nOn 25 July 1997, Kathmandu Metropolitan City declared that its policy to recognize Nepal Bhasa, which had been passed on 18 April 1958 and cancelled by the Panchayat regime in 1963, would be revived. The rest of the city governments in the Kathmandu Valley announced in quick succession that they too would officially recognize Nepal Bhasa -- Lalitpur Sub-Metropolitan City on 14 July, Bhaktapur Municipality on 23 July, Madhyapur Thimi Municipality on 10 September, and Kirtipur Municipality on 15 September 1997.\n\nWhile Newars hailed the move, its detractors went to court. A group consisting of Lal Bahadur Thapa, Yagyanidhi Dahal, Hari Prasad Pokhrel, Achyut Raman Adhikari and Dhruba Raj Thebe filed a joint petition at the Supreme Court of Nepal against their decision. And on 18 March 1998, the Supreme Court issued a stay order preventing Kathmandu Metropolitan City from using Nepal Bhasa pending a final verdict.\n\nSubsequently, on 1 June 1999, the Supreme Court quashed the decision of the local bodies as being unconstitutional. After the verdict was announced, demonstrators marched through Kathmandu in protest.\n\nNewars have been observing June 1 as Black Day with protest meets and public demonstrations recalling the day when the Supreme Court barred Nepal Bhasa from being used in local bodies. On some occasions, the protests have been marked by vandalism and arrest of protestors by the police.\n\nA second People's Movement in 2006 ousted the Shah dynasty and Nepal became a republic which gave the people greater linguistic freedom. The 2007 Interim Constitution stated that the use of one's mother tongue in a local body or office shall not be barred. However, subtle discrimination persists. Organizations with names in Nepal Bhasa are not registered, and municipality officials refuse to accept applications written in the language.\n\n"}
{"id": "55212", "url": "https://en.wikipedia.org/wiki?curid=55212", "title": "Newton's laws of motion", "text": "Newton's laws of motion\n\nNewton's laws of motion are three physical laws that, together, laid the foundation for classical mechanics. They describe the relationship between a body and the forces acting upon it, and its motion in response to those forces. More precisely, the first law defines the force qualitatively, the second law offers a quantitative measure of the force, and the third asserts that a single isolated force doesn't exist. These three laws have been expressed in several ways, over nearly three centuries, and can be summarised as follows:\n\nThe three laws of motion were first compiled by Isaac Newton in his \"Philosophiæ Naturalis Principia Mathematica\" (\"Mathematical Principles of Natural Philosophy\"), first published in 1687. Newton used them to explain and investigate the motion of many physical objects and systems. For example, in the third volume of the text, Newton showed that these laws of motion, combined with his law of universal gravitation, explained Kepler's laws of planetary motion.\n\nA fourth law is often also described in the bibliography, which states that forces add up like vectors, that is, that forces obey the principle of superposition.\n\nNewton's laws are applied to objects which are idealised as single point masses, in the sense that the size and shape of the object's body are neglected to focus on its motion more easily. This can be done when the object is small compared to the distances involved in its analysis, or the deformation and rotation of the body are of no importance. In this way, even a planet can be idealised as a particle for analysis of its orbital motion around a star.\n\nIn their original form, Newton's laws of motion are not adequate to characterise the motion of rigid bodies and deformable bodies. Leonhard Euler in 1750 introduced a generalisation of Newton's laws of motion for rigid bodies called Euler's laws of motion, later applied as well for deformable bodies assumed as a continuum. If a body is represented as an assemblage of discrete particles, each governed by Newton's laws of motion, then Euler's laws can be derived from Newton's laws. Euler's laws can, however, be taken as axioms describing the laws of motion for extended bodies, independently of any particle structure.\n\nNewton's laws hold only with respect to a certain set of frames of reference called Newtonian or inertial reference frames. Some authors interpret the first law as defining what an inertial reference frame is; from this point of view, the second law holds only when the observation is made from an inertial reference frame, and therefore the first law cannot be proved as a special case of the second. Other authors do treat the first law as a corollary of the second. The explicit concept of an inertial frame of reference was not developed until long after Newton's death.\n\nIn the given interpretation mass, acceleration, momentum, and (most importantly) force are assumed to be externally defined quantities. This is the most common, but not the only interpretation of the way one can consider the laws to be a definition of these quantities.\n\nNewtonian mechanics has been superseded by special relativity, but it is still useful as an approximation when the speeds involved are much slower than the speed of light.\n\nThe first law states that if the net force (the vector sum of all forces acting on an object) is zero, then the velocity of the object is constant. Velocity is a vector quantity which expresses both the object's speed and the direction of its motion; therefore, the statement that the object's velocity is constant is a statement that both its speed and the direction of its motion are constant.\n\nThe first law can be stated mathematically when the mass is a non-zero constant, as,\nConsequently,\n\nThis is known as \"uniform motion\". An object \"continues\" to do whatever it happens to be doing unless a force is exerted upon it. If it is at rest, it continues in a state of rest (demonstrated when a tablecloth is skilfully whipped from under dishes on a tabletop and the dishes remain in their initial state of rest). If an object is moving, it continues to move without turning or changing its speed. This is evident in space probes that continuously move in outer space. Changes in motion must be imposed against the tendency of an object to retain its state of motion. In the absence of net forces, a moving object tends to move along a straight line path indefinitely.\n\nNewton placed the first law of motion to establish frames of reference for which the other laws are applicable. The first law of motion postulates the existence of at least one frame of reference called a Newtonian or inertial reference frame, relative to which the motion of a particle not subject to forces is a straight line at a constant speed. Newton's first law is often referred to as the \"law of inertia\". Thus, a condition necessary for the uniform motion of a particle relative to an inertial reference frame is that the total net force acting on it is zero. In this sense, the first law can be restated as:\n\nNewton's first and second laws are valid only in an inertial reference frame. Any reference frame that is in uniform motion with respect to an inertial frame is also an inertial frame, i.e. Galilean invariance or the principle of Newtonian relativity.\n\nThe second law states that the rate of change of momentum of a body is directly proportional to the force applied, and this change in momentum takes place in the direction of the applied force.\nThe second law can also be stated in terms of an object's acceleration. Since Newton's second law is valid only for constant-mass systems, can be taken outside the differentiation operator by the constant factor rule in differentiation. Thus,\n\nwhere F is the net force applied, \"m\" is the mass of the body, and a is the body's acceleration. Thus, the net force applied to a body produces a proportional acceleration. In other words, if a body is accelerating, then there is a force on it. An application of this notation is the derivation of G Subscript C.\n\nConsistent with the first law, the time derivative of the momentum is non-zero when the momentum changes direction, even if there is no change in its magnitude; such is the case with uniform circular motion. The relationship also implies the conservation of momentum: when the net force on the body is zero, the momentum of the body is constant. Any net force is equal to the rate of change of the momentum.\n\nAny mass that is gained or lost by the system will cause a change in momentum that is not the result of an external force. A different equation is necessary for variable-mass systems (see below).\n\nNewton's second law is an approximation that is increasingly worse at high speeds because of relativistic effects.\n\nAn impulse J occurs when a force F acts over an interval of time Δ\"t\", and it is given by\nSince force is the time derivative of momentum, it follows that\nThis relation between impulse and momentum is closer to Newton's wording of the second law.\n\nImpulse is a concept frequently used in the analysis of collisions and impacts.\n\nVariable-mass systems, like a rocket burning fuel and ejecting spent gases, are not closed and cannot be directly treated by making mass a function of time in the second law; that is, the following formula is wrong:\n\nThe falsehood of this formula can be seen by noting that it does not respect Galilean invariance: a variable-mass object with F = 0 in one frame will be seen to have F ≠ 0 in another frame.\nThe correct equation of motion for a body whose mass \"m\" varies with time by either ejecting or accreting mass is obtained by applying the second law to the entire, constant-mass system consisting of the body and its ejected/accreted mass; the result is\n\nwhere u is the velocity of the escaping or incoming mass relative to the body. From this equation one can derive the equation of motion for a varying mass system, for example, the Tsiolkovsky rocket equation.\nUnder some conventions, the quantity u d\"m\"/d\"t\" on the left-hand side, which represents the advection of momentum, is defined as a force (the force exerted on the body by the changing mass, such as rocket exhaust) and is included in the quantity F. Then, by substituting the definition of acceleration, the equation becomes F = \"m\"a.\n\nThe third law states that all forces between two objects exist in equal magnitude and opposite direction: if one object \"A\" exerts a force F on a second object \"B\", then \"B\" simultaneously exerts a force F on \"A\", and the two forces are equal in magnitude and opposite in direction: F = −F. The third law means that all forces are \"interactions\" between different bodies, or different regions within one body, and thus that there is no such thing as a force that is not accompanied by an equal and opposite force. In some situations, the magnitude and direction of the forces are determined entirely by one of the two bodies, say Body \"A\"; the force exerted by Body \"A\" on Body \"B\" is called the \"action\", and the force exerted by Body \"B\" on Body \"A\" is called the \"reaction\". This law is sometimes referred to as the \"action-reaction law\", with F called the \"action\" and F the \"reaction\". In other situations the magnitude and directions of the forces are determined jointly by both bodies and it isn't necessary to identify one force as the \"action\" and the other as the \"reaction\". The action and the reaction are simultaneous, and it does not matter which is called the \"action\" and which is called \"reaction\"; both forces are part of a single interaction, and neither force exists without the other.\n\nThe two forces in Newton's third law are of the same type (e.g., if the road exerts a forward frictional force on an accelerating car's tires, then it is also a frictional force that Newton's third law predicts for the tires pushing backward on the road).\n\nFrom a conceptual standpoint, Newton's third law is seen when a person walks: they push against the floor, and the floor pushes against the person. Similarly, the tires of a car push against the road while the road pushes back on the tires—the tires and road simultaneously push against each other. In swimming, a person interacts with the water, pushing the water backward, while the water simultaneously pushes the person forward—both the person and the water push against each other. The reaction forces account for the motion in these examples. These forces depend on friction; a person or car on ice, for example, may be unable to exert the action force to produce the needed reaction force.\n\nFrom the original Latin of Newton's \"Principia\":\nTranslated to English, this reads:\nThe ancient Greek philosopher Aristotle had the view that all objects have a natural place in the universe: that heavy objects (such as rocks) wanted to be at rest on the Earth and that light objects like smoke wanted to be at rest in the sky and the stars wanted to remain in the heavens. He thought that a body was in its natural state when it was at rest, and for the body to move in a straight line at a constant speed an external agent was needed continually to propel it, otherwise it would stop moving. Galileo Galilei, however, realised that a force is necessary to change the velocity of a body, i.e., acceleration, but no force is needed to maintain its velocity. In other words, Galileo stated that, in the \"absence\" of a force, a moving object will continue moving. (The tendency of objects to resist changes in motion was what Johannes Kepler had called \"inertia\".) This insight was refined by Newton, who made it into his first law, also known as the \"law of inertia\"—no force means no acceleration, and hence the body will maintain its velocity. As Newton's first law is a restatement of the law of inertia which Galileo had already described, Newton appropriately gave credit to Galileo.\n\nThe law of inertia apparently occurred to several different natural philosophers and scientists independently, including Thomas Hobbes in his \"Leviathan\". The 17th-century philosopher and mathematician René Descartes also formulated the law, although he did not perform any experiments to confirm it.\n\nNewton's original Latin reads:\nThis was translated quite closely in Motte's 1729 translation as:\n\nAccording to modern ideas of how Newton was using his terminology, this is understood, in modern terms, as an equivalent of:\nThis may be expressed by the formula F = p', where p' is the time derivative of the momentum p. This equation can be seen clearly in the Wren Library of Trinity College, Cambridge, in a glass case in which Newton's manuscript is open to the relevant page.\n\nMotte's 1729 translation of Newton's Latin continued with Newton's commentary on the second law of motion, reading:\n\nThe sense or senses in which Newton used his terminology, and how he understood the second law and intended it to be understood, have been extensively discussed by historians of science, along with the relations between Newton's formulation and modern formulations.\n\nTranslated to English, this reads:\nNewton's Scholium (explanatory comment) to this law:\nIn the above, as usual, \"motion\" is Newton's name for momentum, hence his careful distinction between motion and velocity.\n\nNewton used the third law to derive the law of conservation of momentum; from a deeper perspective, however, conservation of momentum is the more fundamental idea (derived via Noether's theorem from Galilean invariance), and holds in cases where Newton's third law appears to fail, for instance when force fields as well as particles carry momentum, and in quantum mechanics. \n\nNewton's laws were verified by experiment and observation for over 200 years, and they are excellent approximations at the scales and speeds of everyday life. Newton's laws of motion, together with his law of universal gravitation and the mathematical techniques of calculus, provided for the first time a unified quantitative explanation for a wide range of physical phenomena.\n\nThese three laws hold to a good approximation for macroscopic objects under everyday conditions. However, Newton's laws (combined with universal gravitation and classical electrodynamics) are inappropriate for use in certain circumstances, most notably at very small scales, very high speeds (in special relativity, the Lorentz factor must be included in the expression for momentum along with the rest mass and velocity) or very strong gravitational fields. Therefore, the laws cannot be used to explain phenomena such as conduction of electricity in a semiconductor, optical properties of substances, errors in non-relativistically corrected GPS systems and superconductivity. Explanation of these phenomena requires more sophisticated physical theories, including general relativity and quantum field theory.\n\nIn quantum mechanics, concepts such as force, momentum, and position are defined by linear operators that operate on the quantum state; at speeds that are much lower than the speed of light, Newton's laws are just as exact for these operators as they are for classical objects. At speeds comparable to the speed of light, the second law holds in the original form F = dp/d\"t\", where F and p are four-vectors.\n\nIn modern physics, the laws of conservation of momentum, energy, and angular momentum are of more general validity than Newton's laws, since they apply to both light and matter, and to both classical and non-classical physics.\n\nThis can be stated simply, \"Momentum, energy and angular momentum cannot be created or destroyed.\"\n\nBecause force is the time derivative of momentum, the concept of force is redundant and subordinate to the conservation of momentum, and is not used in fundamental theories (e.g., quantum mechanics, quantum electrodynamics, general relativity, etc.). The standard model explains in detail how the three fundamental forces known as gauge forces originate out of exchange by virtual particles. Other forces, such as gravity and fermionic degeneracy pressure, also arise from the momentum conservation. Indeed, the conservation of 4-momentum in inertial motion via curved space-time results in what we call gravitational force in general relativity theory. The application of the space derivative (which is a momentum operator in quantum mechanics) to the overlapping wave functions of a pair of fermions (particles with half-integer spin) results in shifts of maxima of compound wavefunction away from each other, which is observable as the \"repulsion\" of the fermions.\n\nNewton stated the third law within a world-view that assumed instantaneous action at a distance between material particles. However, he was prepared for philosophical criticism of this action at a distance, and it was in this context that he stated the famous phrase \"I feign no hypotheses\". In modern physics, action at a distance has been completely eliminated, except for subtle effects involving quantum entanglement. (In particular, this refers to Bell's theorem – that no local model can reproduce the predictions of quantum theory.) Despite only being an approximation, in modern engineering and all practical applications involving the motion of vehicles and satellites, the concept of action at a distance is used extensively.\n\nThe discovery of the second law of thermodynamics by Carnot in the 19th century showed that not every physical quantity is conserved over time, thus disproving the validity of inducing the opposite metaphysical view from Newton's laws. Hence, a \"steady-state\" worldview based solely on Newton's laws and the conservation laws does not take entropy into account.\n\n\n\n"}
{"id": "2403206", "url": "https://en.wikipedia.org/wiki?curid=2403206", "title": "Oath More Judaico", "text": "Oath More Judaico\n\nThe Oath \"More Judaico\" or Jewish Oath was a special form of oath, rooted in antisemitsm and accompanied by certain ceremonies and often intentionally humiliating, painful or dangerous, that Jews were required to take in European courts of law until the 20th century. \"More Judaico\" is Latin for \"on/by the Jewish custom.\" The question of the trustworthiness of the Jewish oath was intimately connected with the meaning that Christian authorities assigned to the \"Kol Nidre\" prayer, recited by Jews on Yom Kippur, and the whole of the legislation regarding the oath was characteristic of the attitude of medieval states toward their Jewish subjects. The identification of Church and State seemed to render it necessary to have a different formula for those outside the state church.\n\nThe disability imposed on a Jew engaged in legal contention with a Christian dates back to Byzantine emperor Justinian I, who declared that neither Jews nor heretics should be admitted as witnesses against Christians; secular courts, however, did not recognize this disability. Thus, in the safe conducts issued by the Carolingian kings in the 9th century, Jews and Christians were treated as equals, and consequently the testimony of the former, whether given under oath or not, was as admissible as the latter. This was distinctly stated in the charter granted by Holy Roman Emperor Henry IV to the Jews of Speyer in 1090. The law of Duke Frederick II of Austria (1244), which served as a model for much other legislation on the Jews, merely required a Jew to swear \"super Rodal\" (by the Torah). Similar laws existed in England, Portugal, and Hungary; Hungary waived the requirement to swear on the Torah in trivial cases.\n\nThere were, however, some older laws that prescribed certain practices intended to mock Jews in court. These examples illustrated the kinds of humiliating rituals that accompanied the taking of the oath:\n\nThe following formula, originally in Middle High German, was used in Frankfurt on the Main about 1392:\n\nA decidedly aggressive change took place when, in 1555, the German imperial court procedure (\"Reichskammergerichtsordnung\") prescribed a form of oath that, with some alterations, formed a model to subsequent legislation. Horrible were the terms in which the swearer called down upon himself all the curses of Leviticus and Deuteronomy, the ten plagues of Egypt, the leprosy of Naaman and Gehazi (see 2 Kings 5), the fate of Dathan and Abiram, etc.\n\nAccording to a recount in his \"Gesammelte Schriften,\" the great German-Jewish philosopher Moses Mendelssohn of the Enlightenment persuaded the Prussian government to moderate the terms of the oath during the 18th century. The small German states gradually surrendered the most objectionable features of the oath: Hesse-Kassel (or Hesse-Cassel), in 1828; Oldenburg, 1829; Württemberg, 1832; Saxony, 1839 (on which occasion Zecharias Frankel published his famous \"Die Eidesleistung\"); Schaumburg-Lippe and Anhalt-Bernburg, 1842; and Hesse-Homburg, 1865. \n\nPrussia retained the obnoxious formula until March 15, 1869; the Netherlands modified the oath in 1818, and Russia in 1838 and 1860. The Jewish advocate Isaac Adolphe Crémieux won great fame by effecting the abolition of the oath through a case brought before the court of Nîmes in 1827. Lazard Isidor, as rabbi of Pfalzburg, refused in 1839 to open the synagogue for such an oath; prosecuted for contempt of court, he was defended by Crémieux and acquitted. The French Supreme Court finally declared the oath unconstitutional on March 3, 1846. However, as late as 1902, a court in Romania upheld that country's version of the oath.\n\n"}
{"id": "1632631", "url": "https://en.wikipedia.org/wiki?curid=1632631", "title": "Peripatetic axiom", "text": "Peripatetic axiom\n\nThe Peripatetic axiom is: \"Nothing is in the intellect that was not first in the senses\" (Latin: \"Nihil est in intellectu quod non sit prius in sensu\"). It is found in Thomas Aquinas's \"De veritate, q. 2 a. 3 arg. 19\".\n\nAquinas adopted this principle from the Peripatetic school of Greek philosophy, established by Aristotle. Aquinas argued that the existence of God could be proved by reasoning from sense data. He used a variation on the Aristotelian notion of the \"active intellect\" (\"intellectus agens\") which he interpreted as the ability to abstract universal meanings from particular empirical data.\n"}
{"id": "22973", "url": "https://en.wikipedia.org/wiki?curid=22973", "title": "Pig Latin", "text": "Pig Latin\n\nPig Latin is a language game or argot in which words in English are altered, usually by adding a fabricated suffix or by moving the onset or initial consonant or consonant cluster of a word to the end of the word and adding a vocalic syllable to create such a suffix. For example, Wikipedia would become Ikipediaway (taking the 'W' and 'ay' to create a suffix). The objective is to conceal the words from others not familiar with the rules. The reference to Latin is a deliberate misnomer; Pig Latin is simply a form of argot or jargon unrelated to Latin, and the name is used for its English connotations as a strange and foreign-sounding language. It is most often used by young children as a fun way to confuse people unfamiliar with Pig Latin.\n\nEarly mentions of pig Latin or hog Latin describe what we would today call dog Latin, a type of parody Latin. Examples of this predate even Shakespeare, whose 1598 play, \"Love's Labour's Lost\", includes a reference to dog Latin:\n\nAn 1866 article describes a \"hog latin\" that has some similarities to current Pig Latin. The article says, \"He adds as many new letters as the boys in their 'hog latin,' which is made use of to mystify eavesdroppers. A boy asking a friend to go with him says, 'Wig-ge you-ge go-ge wig-ge me-ge?' The other, replying in the negative, says, 'No-ge, I-ge wo-ge.' \". This is similar to Língua do Pê.\n\nAnother early mention of the name was in \"Putnam's Magazine\" in May 1869 \"I had plenty of ammunition in reserve, to say nothing, Tom, of our pig Latin. 'Hoggibus, Piggibus et shotam damnabile grunto,' and all that sort of thing,\" although the jargon is dog Latin.\n\n\"The Atlantic\" January 1895 also included a mention of the subject: \"They all spoke a queer jargon which they themselves had invented. It was something like the well-known 'pig Latin' that all sorts of children like to play with.\"\n\nThe modern version of Pig Latin appears in a 1919 Columbia Records album containing what sounds like the modern variation, by a singer named Arthur Fields. The song, called Pig Latin Love, is followed by the subtitle \"I-Yay Ove-Lay oo-yay earie-day\". The Three Stooges used it on multiple occasions, most notably \"Tassels in the Air\", a 1938 short where Moe Howard attempts to teach Curley Howard how to use it, thereby conveying the rules to the audience. In an earlier (1934) episode, \"Three Little Pigskins\", Larry Fine attempts to impress a woman with his skill in Pig Latin, but it turns out that she knows it, too. No explanation of the rules is given. A few months prior in 1934, in the \"Our Gang\" short film \"Washee Ironee\", Spanky tries to speak to an Asian boy by using Pig Latin. Ginger Rogers sang a verse of We're in the Money in pig Latin in an elaborate Busby Berkeley production number in the film Gold Diggers of 1933, (). The film, the third highest grossing of that year, was inducted into the National Film Registry and that song included in the all time top 100 movie songs by the American Film Institute. Merle Travis ends his song \"When My Baby Double Talks To Me\" with the phrase, \"What a aybybay\", where the last word is Pig Latin for \"baby\".\n\nA 1947 newspaper question and answer column describes the pig Latin as we understand it today. It describes moving the first letter to the end of a word and then adding \"ay\".\n\nTwo Pig Latin words that have entered into mainstream American English are \"\" or \"icksnay\", the Pig Latin version of \"\" (itself a borrowing of German \"nichts\"), which is used as a general negative; and \", Pig Latin for \", meaning \"go away\" or \"get out of here\".\n\nFor words that begin with consonant sounds, all letters before the initial vowel are placed at the end of the word sequence. Then, \"ay\" is added, as in the following examples:\n\nWhen words begin with consonant clusters (multiple consonants that form one sound), the whole sound is added to the end when speaking or writing.\n\nFor words that begin with vowel sounds, one just adds \"way\" or \"yay\" to the end (or just \"ay\"). Examples are:\n\nAn alternative convention for words beginning with vowel sounds, one removes the initial vowel(s) along with the first consonant or consonant cluster. This usually only works for words with more than one syllable and offers a more unique variant of the words in keeping with the mysterious, unrecognizable sounds of the converted words. Examples are:\n\nSentence structure remains the same as it would in English. Pronunciation of some words may be a little difficult for beginners, but people can easily understand Pig Latin with practice.\n\nPig Latin is mainly used in fun. It is also used by children or young adults to hide conversation from older people. For example, a conversation between two people in the presence of an unwanted other may consist of: \"ehay isay eryvay illysay\" = \"he is very silly\".\n\nIn the German-speaking area, varieties of Pig Latin include Kedelkloppersprook, which originated around Hamburg harbour, and Mattenenglisch that was used in the \"Matte\", the traditional working-class neighborhood of Bern. Though Mattenenglisch has fallen out of use since the mid-20th century, it is still cultivated by voluntary associations. A characteristic of the Mattenenglisch Pig Latin is the complete substitution of the first vowel by \"i\", in addition to the usual moving of the initial consonant cluster and the adding of \"ee\".\n\nThe Swedish equivalent of Pig Latin is Fikonspråket (\"Fig language\" – see Language game § List of common language games).\n\nThe Finnish Pig Latin is called Kontinkieli (\"container language\"). After each word you add the word kontti \"container\", then switch the first syllables, So every sentence is converted to twice as many pseudo-words. For example,\"wikipedia\" --> \"wikipedia kontti\" --> \"kokipedia wintti\". So converting the sentence \"I love you\" (\"Minä rakastan sinua\") would result in \"konä mintti kokastan rantti konua sintti\".\n\nAnother equivalent of Pig Latin is used throughout the Slavic-speaking parts of the Balkans. It is called \"Šatra\" (/sha-tra/)or \"Šatrovački\" (/shatro-vachki/) and was used in crime-related and street language. For instance, the Balkan slang name for marijuana (trava - meaning \"grass\") turns to \"vutra\"; the Balkan slang name for cocaine (belo - meaning \"white\") turns to lobe, a pistol (pištolj) turns to štoljpi, bro (brate) turns to tebra. In the past few years it has become widely used between teenage immigrants in former Yugoslavian countries.\n\nIn Italian, the \"alfabeto farfallino\" uses a similar encoding.\n\nFrench has the \"loucherbem\" (or \"louchébem\", or \"largonji\") coded language, which supposedly was originally used by butchers (\"boucher\" in French). In \"loucherbem\", the leading consonant cluster is moved to the end of the word (as in Pig Latin) and replaced by an \"L\", and then a suffix is added at the end of the word (-\"oche\", -\"em\", -\"oque\", etc., depending on the word). Example: \"combien\" (how much) = \"lombienquès\". Similar coded languages are \"verlan\" and \"langue de feu\" (see . A few louchébem words have become usual French words: \"fou\" (crazy) = \"loufoque\", \"portefeuille\" (wallet) = \"larfeuille\", \"en douce\" (on the quiet) = \"en loucedé\". Also similar is the widely used French argot \"verlan\", in which the syllables of words are transposed. Verlan is a French slang that is quite similar to English pig Latin. It is spoken by separating a word into syllables and reversing the syllables.\n\nVerlan was first documented as being used as far back as the 19th century. Back in the 19th century it was spoken as code by criminals in effort to conceal illicit activities within conversations around other people, even the police. Currently, Verlan has been increasingly used in areas just outside major cities mainly populated by migrant workers. This language has served as a language bridge between many of these migrant workers from multiple countries and origins and has been so widely and readily used that it has spread into advertising, film scripts, French rap and hip-hop music, media, in some French dictionaries and in some cases, words that have been Verlanned have actually replaced their original words. The new uses of Verlan and how it has become incorporated into the French culture has all happened within just a few decades.\n\nHere is an example of some French words that have been Verlanned and their English meaning:\n\n\n\n"}
{"id": "26550", "url": "https://en.wikipedia.org/wiki?curid=26550", "title": "Reconquista", "text": "Reconquista\n\nThe (Spanish and Portuguese for \"reconquest\") is a name used in English to describe the period in the history of the Iberian Peninsula of about 780 years between the Umayyad conquest of Hispania in 711 and the fall of the Nasrid kingdom of Granada to the expanding Christian kingdoms in 1491. The completed conquest of Granada was the context of the Spanish voyages of discovery and conquest (Columbus got royal support in Granada in 1492, months after its conquest), and the Americas—the \"New World\"—ushered in the era of the Spanish and Portuguese colonial empires.\n\nTraditional historiography has marked the beginning of the \"\" with the Battle of Covadonga (718 or 722), the first known victory in Iberia by Christian military forces since the 711 military intervention in Iberia of combined Arab-Berber forces. In that small battle, a group led by the nobleman Pelagius defeated a Muslim patrol in the mountains of northern Iberia and established the independent Christian Kingdom of Asturias. It ended with the conquest of the Emirate of Granada, the last Muslim state in the peninsula, in 1491.\n\nAfter 1491, the entire peninsula was controlled by Christian rulers. The conquest was followed by the Alhambra Decree (1492) which expelled Jews who would not convert to Christianity from Castile and Aragon, and a series of edicts (1499–1526) which forced the conversions of the Muslims in Spain. Since the mid-19th century, the idea of a 'reconquest' took hold in Spain associated with its rising nationalism and colonialism.\n\nTraditional historiography has stressed since the 19th century the existence of the \"Reconquista\", a continuous phenomenon by which the Christian Iberian kingdoms opposed and conquered the Muslim kingdoms, understood as a common enemy who had militarily seized territory from native Iberian Christians.\nThe concept of a Christian reconquest of the peninsula first emerged, in tenuous form, at the end of the 9th century. A landmark was set by the Christian \"Chronica Prophetica\" (883–884), a document stressing the Christian and Muslim cultural and religious divide in Iberia and the necessity to drive the Muslims out.\n\nBoth Christian and Muslim rulers fought amongst themselves. Alliances between Muslims and Christians were not uncommon. Blurring distinctions even further were the mercenaries from both sides who simply fought for whoever paid the most. The period is seen today to have had long episodes of relative religious tolerance.\n\nThe Crusades, which started late in the 11–12th century, bred the religious ideology of a Christian reconquest, confronted at that time with a similarly staunch Muslim Jihad ideology in Al-Andalus by the Almoravids, and to an even greater degree by the Almohads. In fact, previous documents from the 10th and 11th centuries are mute on any idea of \"reconquest\". Propaganda accounts of Muslim-Christian hostility came into being to support that idea, most notably the \"Chanson de Roland\", a fictitious 11th-century French version of the Battle of Roncevaux Pass (778) dealing with the Iberian \"Saracens\" (\"Moors\"), and taught as historical fact in the French educational system since 1880.\n\nThe modern idea of the earlier concept of \"Reconquista\" is inextricably linked to the foundational myths of Spanish nationalism in the 19th century, and consolidated by the mid-20th century during Franco's National-Catholic dictatorship, based on a strong underlying Castilian ideological element. The idea of a \"liberation war\" of \"reconquest\" against the Muslims, depicted as foreigners, suited well the anti-Republican rebels during the Spanish Civil War who agitated for the banner of a Spanish fatherland threatened by regional nationalisms and communism. Their rebellious pursuit was thus a crusade for the restoration of the Church's unity, where Franco stood for both Pelagius of Asturias and El Cid.\n\nSome contemporary authors consider it proved that the process of Christian state-building in Iberia was indeed often defined by the reclamation of lands that had been lost to the Moors in generations past. In this way, state-building might be characterised—at least in ideological, if not practical, terms—as a process by which Iberian states were being 'rebuilt'.. In turn, other recent historians dispute the whole concept of \"Reconquista\" as a concept created \"a posteriori\" in the service of later political goals. A few historians point out that Spain and Portugal did not previously exist as nations, and therefore the heirs of the Christian Visigothic Kingdom were not technically reconquering them, as the name suggests. One of the first Spanish intellectuals to question the idea of a \"reconquest\" that lasted for eight centuries was José Ortega y Gasset, writing in the first half of the 20th century. However, the term is still widely in use.\n\nIn 711, Muslim Moors, mainly North African Berber soldiers with some Arabs, crossed the Strait of Gibraltar and began their conquest of the Visigothic Kingdom of Hispania. After their conquest of the Visigothic Kingdom's Iberian territories, the Muslims crossed the Pyrenees and took control of Septimania in 719, the last province of the Visigothic Kingdom to be occupied. From their stronghold of Narbonne, they launched raids into the Duchy of Aquitaine.\n\nThe invading Islamic armies did not exceed 60,000 men. These armies established an Islamic rule known as Al-Andalus that would last 300 years in much of the Iberian Peninsula and 770 years in Granada.\n\nAfter the establishment of a local Emirate, Caliph Al-Walid I, ruler of the Umayyad caliphate, removed many of the successful Muslim commanders. Tariq ibn Ziyad, the first governor of the newly conquered province of Al-Andalus, was recalled to Damascus and replaced with Musa bin Nusair, who had been his former superior. Musa's son, Abd al-Aziz ibn Musa, apparently married Egilona, Roderic's widow, and established his regional government in Seville. He was suspected of being under the influence of his wife and was accused of wanting to convert to Christianity and of planning a secessionist rebellion. Apparently a concerned Al-Walid I ordered Abd al-Aziz's assassination. Caliph Al-Walid I died in 715 and was succeeded by his brother Sulayman ibn Abd al-Malik. Sulayman seems to have punished the surviving Musa bin Nusair, who very soon died during a pilgrimage in 716. In the end, Abd al-Aziz ibn Musa's cousin, Ayyub ibn Habib al-Lakhmi became the emir of \"Al-Andalus\".\n\nThe conquering generals were necessarily acting independently, due to the methods of communication available. Successful generals in the field and in a distant province would gain the personal loyalty of their officers and warriors and their ambitions were likely watched by certain circles of the distant government with a degree of concern and suspicion. Old rivalries and perhaps even full-fledged conspiracies between generals may have had influence over this development. In the end, the formerly successful generals were replaced by a younger generation considered more loyal to the government in Damascus.\n\nA serious weakness amongst the Muslim conquerors was the ethnic tension between Berbers and Arabs. The Berbers were indigenous inhabitants of North Africa who had only recently converted to Islam; they provided most of the soldiery of the invading Islamic armies but sensed Arab discrimination against them. This latent internal conflict jeopardized Muslim unity.\n\nAfter the Islamic Moorish conquest of most of the Iberian Peninsula in 711–718 and the establishment of the emirate of Al-Andalus, an Umayyad expedition suffered a major defeat at the Battle of Toulouse and was halted for a while on its way north. Odo of Aquitaine had married his daughter to Uthman ibn Naissa, a rebel Berber and lord of Cerdanya (and, perhaps, contemporary Catalonia), in an attempt to secure his southern borders in order to fend off Charles Martel's attacks on the north. However, a major punitive expedition led by Abdul Rahman Al Ghafiqi, the latest emir of Al-Andalus, defeated and killed Uthman, and the Muslim governor mustered an expedition north across the western Pyrenees, looted areas up to Bordeaux, and defeated Odo in the Battle of the River Garonne in 732.\n\nA desperate Odo turned to his archrival Charles Martel for help, who led the Frankish and remaining Aquitanian armies against the Umayyad armies and defeated them at the Battle of Tours in 732, killing Abdul Rahman Al Ghafiqi. While Moorish rule began to recede, it would remain in parts of the Iberian peninsula for another 760 years.\n\nThe first victory in resistance to Muslim rule occurred in Asturias in 722. A drastic increase of taxes by the emir Anbasa ibn Suhaym Al-Kalbi provoked several rebellions in Al-Andalus, which a series of succeeding weak emirs were unable to suppress. Around 722, a Muslim military expedition was sent into the north in late summer to suppress a rebellion led by Pelagius of Asturias (Pelayo in Spanish, Pelayu in Asturian). Traditional historiography has hailed Pelagius' victory at Covadonga as the beginning of the \"Reconquista\". No Muslim source mentions the battle at Covadonga, in contrast with the Battle of Toulouse in 721, with a death toll of perhaps tens of thousands, which was mourned for centuries as a large scale tragedy by the Iberian Muslims. For Pelagius, however, the Christian victory secured his independent rule, while the precise date and circumstances of the battle are unclear. Among the possibilities is that Pelagius' rebellion was successful because the greater part of the Muslim forces were focusing in Septimania and Toulouse (721).\n\nTwo northern realms, the Basque Navarre and Asturias, despite their small size, demonstrated an ability to maintain their independence. Because the Umayyad rulers based in Córdoba were unable to extend their power over the Pyrenees, they decided to consolidate their power within the Iberian peninsula. Arab-Berber forces made periodic incursions deep into Asturias, but this area was a \"cul-de-sac\" on the fringes of the Islamic world fraught with inconveniences during campaigns and little interest.\n\nIt comes then as no surprise that, besides focusing on raiding the Arab-Berber strongholds of the Meseta, Alphonse I centred on expanding his domains at the expense of the neighbouring Galicians and Basques at either side of his realm just as much. During the first decades, Asturian control over part of the kingdom was weak, and for this reason it had to be continually strengthened through matrimonial alliances and war with other peoples from the north of the Iberian Peninsula. After Pelayo's death in 737, his son Favila of Asturias was elected king. Favila, according to the chronicles, was killed by a bear during a trial of courage. Pelayo's dynasty in Asturias survived and gradually expanded the kingdom's boundaries until all of northwest Iberia was included by roughly 775. However, credit is due not to him but to his successors, the \"Banu Alfons\" from the Arab chronicles. Further expansion of the northwestern kingdom towards the south occurred during the reign of Alfonso II (from 791–842). A king's expedition arrived in and pillaged Lisbon in 798, probably concerted with the Carolingians.\n\nThe Asturian kingdom became firmly established with the recognition of Alfonso II as king of Asturias by Charlemagne and the Pope. During his reign, the bones of St. James the Great were declared to have been found in Galicia, at Santiago de Compostela. Pilgrims from all over Europe opened a channel of communication between the isolated Asturias and the Carolingian lands and beyond, centuries later.\n\nAfter the Umayyad conquest of the Iberian heartland of the Visigothic kingdom, the Muslims crossed the Pyrenees and gradually took control of Septimania, starting in 719 with the conquest of Narbonne through 725 when Carcassone and Nîmes were secured. From the stronghold of Narbonne, they tried to conquer Aquitaine but suffered a major defeat at the Battle of Toulouse (721).\n\nTen years after halting their advance north, Odo of Aquitaine married his daughter to Uthman ibn Naissa, a rebel Berber and lord of Cerdanya (perhaps all of contemporary Catalonia as well), in an attempt to secure his southern borders to fend off Charles Martel's attacks on the north. However, a major punitive expedition led by Abdul Rahman Al Ghafiqi, the latest emir of Al-Andalus, defeated and killed Uthman.\n\nAfter expelling the Muslims from Narbonne in 759 and driving their forces back over the Pyrenees, the Carolingian king Pepin the Short conquered Aquitaine in a ruthless eight-year war. Charlemagne followed his father by subduing Aquitaine by creating counties, taking the Church as his ally and appointing counts of Frankish or Burgundian stock, like his loyal William of Gellone, making Toulouse his base for expeditions against Al-Andalus. Charlemagne decided to organize a regional subkingdom in order to keep the Aquitanians in check and to secure the southern border of the Carolingian Empire against Muslim incursions. In 781, his three-year-old son Louis was crowned king of Aquitaine, under the supervision of Charlemagne's trustee William of Gellone, and was nominally in charge of the incipient Spanish March.\n\nMeanwhile, the takeover of the southern fringes of Al-Andalus by Abd ar-Rahman I in 756 was opposed by Yusuf ibn Abd al-Rahman, autonomous governor (\"wāli\") or king (\"malik\") of al-Andalus. Abd ar-Rahman I expelled Yusuf from Cordova, but it took still decades for him to expand to the north-western Andalusian districts. He was also opposed externally by the Abbasids of Baghdad who failed in their attempts to overthrow him. In 778, Abd al-Rahman closed in on the Ebro valley. Regional lords saw the Umayyad emir at the gates and decided to enlist the nearby Christian Franks. According to Ali ibn al-Athir, a Kurdish historian of the 12th century, Charlemagne received the envoys of Sulayman al-Arabi, Husayn, and Abu Taur at the Diet of Paderborn in 777. These rulers of Zaragoza, Girona, Barcelona, and Huesca were enemies of Abd ar-Rahman I, and in return for Frankish military aid against him offered their homage and allegiance.\n\nCharlemagne, seeing an opportunity, agreed upon an expedition and crossed the Pyrenees in 778. Near the city of Zaragoza Charlemagne received the homage of Sulayman al-Arabi. However the city, under the leadership of Husayn, closed its gates and refused to submit. Unable to conquer the city by force, Charlemagne decided to retreat. On the way home the rearguard of the army was ambushed and destroyed by Basque forces at the Battle of Roncevaux Pass. The Song of Roland, a highly romanticized account of this battle, would later become one of the most famous chansons de geste of the Middle Ages. Around 788 Abd ar-Rahman I died and was succeeded by Hisham I. In 792 Hisham proclaimed a jihad, advancing in 793 against the Kingdom of Asturias and Carolingian Septimania (Gothia). They defeated William of Gellone, Count of Toulouse, in battle, but William led an expedition the following year across the eastern Pyrenees. Barcelona, a major city, became a potential target for the Franks in 797, as its governor Zeid rebelled against the Umayyad emir of Córdoba. An army of the emir managed to recapture it in 799, but Louis, at the head of an army, crossed the Pyrenees and besieged the city for two years until it finally capitulated in 801.\n\nThe main passes in the Pyrenees were Roncesvalles, Somport and La Jonquera. Charlemagne established across them the vassal regions of Pamplona, Aragon, and Catalonia respectively. Catalonia was itself formed from a number of small counties, including Pallars, Girona, and Urgell; it was called the \"Marca Hispanica\" by the late 8th century. They protected the eastern Pyrenees passes and shores and were under the direct control of the Frankish kings. Pamplona's first king was Iñigo Arista, who allied with his Muslim kinsmen the Banu Qasi and rebelled against Frankish overlordship and overcame a Carolingian expedition in 824 that led to the setup of the Kingdom of Pamplona. Aragon, founded in 809 by Aznar Galíndez, grew around Jaca and the high valleys of the Aragon River, protecting the old Roman road. By the end of the 10th century, Aragon was annexed by Navarre. Sobrarbe and Ribagorza were small counties and had little significance to the progress of the \"Reconquista\".\n\nIn the late 9th century under Count Wilfred, Barcelona became the \"de facto\" capital of the region. It controlled the other counties' policies in a union, which led in 948 to the independence of Barcelona under Count Borrel II, who declared that the new dynasty in France (the Capets) were not the legitimate rulers of France nor, as a result, of his county. These states were small and, with the exception of Navarre, did not have the capacity for attacking the Muslims in the way that Asturias did, but their mountainous geography rendered them relatively safe from being conquered, and their borders remained stable for two centuries.\n\nIn the High Middle Ages, the fight against the Moors in the Iberian Peninsula became linked to the fight of the whole of Christendom. The \"Reconquista\" was originally a mere war of conquest. It only later underwent a significant shift in meaning toward a religiously justified war of liberation (see the Augustinian concept of a Just War). The papacy and the influential Abbey of Cluny in Burgundy not only justified the acts of war but actively encouraged Christian knights to seek armed confrontation with Moorish \"infidels\" instead of with each other.\n\nFrom the 11th century onwards indulgences were granted: In 1064 Pope Alexander II promised the participants of an expedition against Barbastro (\"Tagr al-Andalus\", Aragon) a collective indulgence 30 years before Pope Urban II called the First Crusade. Papal interest in Christian-Muslim relations in the peninsula was not without precedent – Popes Leo IV (847–855), John VIII (872–882) and John XIX (1024–33) are all known to have displayed substantial interest in the region. Not until 1095 and the Council of Clermont did the \"Reconquista\" amalgamate the conflicting concepts of a peaceful pilgrimage and armed knight-errantry. But the papacy left no doubt about the heavenly reward for knights fighting for Christ (\"militia Christi\"): in a letter, Urban II tried to persuade the \"reconquistadores\" fighting at Tarragona to stay in the Peninsula rather than joining the armed pilgrimage to conquer Jerusalem, saying that their contribution for Christianity was equally important. The pope promised them the same indulgences that he had promised to those who chose to join the First Crusade.\n\nLater military orders such as the Order of Santiago, Montesa, Order of Calatrava, and the Knights Templar were founded or called to fight in Iberia. The Popes called the knights of Europe to join the effort to destroy the Muslim states of the peninsula. After the so-called Disaster of Alarcos, French, Navarrese, Castilian, Portuguese and Aragonese armies united against the Muslim forces in the massive \"battle of Las Navas de Tolosa\" (1212). The large territories awarded to military orders and nobles were the origin of the latifundia in today's Andalusia and Extremadura in Spain, and Alentejo in Portugal.\n\nIn an atmosphere of constant conflict, warfare and daily life were strongly intertwined during this period. Small, lightly equipped armies reflected the need for society to be on constant alert. These forces were capable of moving long distances in short times, allowing a quick return home after sacking a target. Battles were mainly waged between clans, expelling intruder armies or sacking expeditions.\n\nIn the context of the relative isolation of the Iberian Peninsula from the rest of Europe, and the contact with Moorish culture, geographical and cultural differences necessitated the use of military strategies, tactics, and equipment that were markedly different from those found in the rest of western Europe during this period.\n\nMedieval Iberian armies mainly comprised two types of forces: the cavalry (mostly nobles, but including commoner knights from the 10th century on) and the infantry, or \"peones\" (peasants). Infantry only went to war if needed, which was not frequent.\n\nIberian cavalry tactics involved knights approaching the enemy, throwing javelins, then withdrawing to a safe distance before commencing another assault. Once the enemy formation was sufficiently weakened, the knights charged with thrusting spears (lances did not arrive in Hispania until the 11th century). There were three types of knights (\"caballeros\"): royal knights, noble knights (\"caballeros hidalgos\"), and commoner knights (\"caballeros villanos\", or \"mounted soldier from a villa\"). Royal knights were mainly nobles with a close relationship with the king, and thus claimed a direct Gothic inheritance.\n\nRoyal knights were equipped in the same manner as their Gothic predecessors: mail hauberk, kite shield, a long sword (designed to fight from the horse), javelins, spears and a Visigothic axe. Noble knights came from the ranks of the \"infanzones\" or lower nobles, whereas the commoner knights were not noble but were wealthy enough to afford a horse. Uniquely in Europe, these horsemen comprised a militia cavalry force with no feudal links, being under the sole control of the king or the count of Castile because of \"fueros\" (charters) with the crown. Both noble and common knights wore padded armour and carried javelins, spears and round-tasselled shields (influenced by Moorish shields), as well as a sword.\n\nThe \"peones\" were peasants who went to battle in service of their feudal lord. Poorly equipped, with bows and arrows, spears and short swords, they were mainly used as auxiliary troops. Their function in battle was to contain the enemy troops until the cavalry arrived and to block the enemy infantry from charging the knights. The longbow, the composite bow, and the crossbow were the basic types of bows and were especially popular in the infantry.\n\nArmour was typically made of leather, with iron scales; full coats of chain mail were extremely rare and horse barding completely unknown. Head protections consisted of a round helmet with nose protector (influenced by the designs used by Vikings, who attacked during the 8th and 9th centuries) and a chain mail headpiece. Shields were often round or kidney-shaped, except for the kite-shaped designs used by the royal knights. Usually adorned with geometric designs, crosses or tassels, shields were made out of wood and had a leather cover.\n\nSteel swords were the most common weapon. The cavalry used long double-edged swords and the infantry short, single-edged ones. Guards were either semicircular or straight, but always highly ornamented with geometrical patterns. Spears and javelins were up to 1.5 metres long and had an iron tip. The double-axe – made of iron, 30 cm long, and possessing an extremely sharp edge – was designed to be equally useful as a thrown weapon or in close combat. Maces and hammers were not common, but some specimens have remained and are thought to have been used by members of the cavalry.\n\nFinally, mercenaries were an important factor, as many kings did not have enough soldiers available. Norsemen, Flemish spearmen, Frankish knights, Moorish mounted archers, and Berber light cavalry were the main types of mercenaries available and used in the conflict.\n\nThis style of warfare remained dominant in the Iberian Peninsula until the late 11th century, when lance tactics entered from France, although the traditional horse javelin-shot techniques continued to be used. In the 12th and 13th centuries, soldiers typically carried a sword, a lance, a javelin, and either bow and arrows or crossbow and darts/bolts. Armor consisted of a coat of mail over a quilted jacket, extending at least to the knees, a helmet or iron cap, and bracers protecting the arms and thighs, either metal or leather.\n\nShields were round or triangular, made of wood, covered with leather, and protected by an iron band; the shields of knights and nobles would bear the family's coat of arms. Knights rode in both the Muslim style, \"a la jineta\" (i.e. the equivalent of a modern jockey's seat), a short stirrup strap and bended knees allowed for better control and speed, or in the French style, \"a la brida\", a long stirrup strap allowed for more security in the saddle (i.e. the equivalent of the modern cavalry seat, which is more secure) when acting as heavy cavalry. Horses were occasionally fitted with a coat of mail as well.\n\nThe northern principalities and kingdoms survived in their mountainous strongholds (see above). However, they started a definite territorial expansion south at the turn of the 10th century (Leon, Najera). The fall of the Caliphate of Cordova (1031) heralded a period of military expansion for the northern kingdoms, now divided into several mighty regional powers after the division of the Kingdom of Navarre (1035). A myriad of autonomous Christian kingdoms emerged thereafter.\n\nThe Kingdom of Asturias was located in the Cantabrian Mountains, a wet and mountainous region in the north of the Iberian Peninsula. It was the first Christian power to emerge. The kingdom was established by, Pelagius (\"Pelayo\"), a Visigothic noble who had possibly returned after the Battle of Guadalete in 711 and was elected leader of the Asturians, laying the foundations for the Kingdom of Asturias and starting the Astur-Leonese dynasty that spanned from 718 to 1037 and led the initial efforts in the Iberian peninsula to take back the territories then ruled by the Moors. Although the new dynasty first ruled in the mountains of Asturias, with the capital of the kingdom established initially in Cangas de Onís, and was in its dawn mostly concerned with securing the territory and settling the monarchy, the latest kings (particularly Alfonso III of Asturias) emphasized the nature of the new kingdom as heir of that in Toledo and the restoration of the Visigothic nation in order to vindicate the expansion to the south. However, such claims have been overall dismissed by modern historiography, emphasizing the distinct, autochthonous nature of the Cantabro-Asturian and Vasconic domains with no continuation to the Gothic Kingdom of Toledo.\n\nPelagius' kingdom initially was little more than a gathering point for the existing guerrilla forces. During the first decades, the Asturian dominion over the different areas of the kingdom was still lax, and for this reason it had to be continually strengthened through matrimonial alliances with other powerful families from the north of the Iberian Peninsula. Thus, Ermesinda, Pelagius' daughter, was married to Alfonso, Dux Peter of Cantabria's son. Alfonso's son Fruela married Munia, a Basque from Álava, after crushing a Basque uprising (probably resistance). Their son is reported to be Alfonso II, while Alfonso I's daughter Adosinda married Silo, a local chief from the area of Flavionavia, Pravia.\n\nAlfonso's military strategy was typical of Iberian warfare at the time. Lacking the means needed for wholesale conquest of large territories, his tactics consisted of raids in the border regions of Vardulia. With the plunder he gained further military forces could be paid, enabling him to raid the Muslim cities of Lisbon, Zamora, and Coimbra. Alfonso I also expanded his realm westwards conquering Galicia.\n\nDuring the reign of King Alfonso II (791–842), the kingdom was firmly established, and a series of Muslim raids caused the transfer of the Asturian capital to Oviedo. The king is believed to have initiated diplomatic contacts with the kings of Pamplona and the Carolingians, thereby gaining official recognition for his kingdom and his crown from the Pope and Charlemagne.\n\nThe bones of St. James the Great were proclaimed to have been found in Iria Flavia (present day Padrón) in 813 or probably two or three decades later. The cult of the saint was transferred later to Compostela (from Latin \"campus stellae\", literally \"the star field\"), possibly in the early 10th century when the focus of Asturian power moved from the mountains over to León, to become the Kingdom of León or Galicia-León. Santiago's were among many saint relics proclaimed to have been found across north-western Iberia. Pilgrims started to flow in from other Iberian Christian realms, sowing the seeds of the later Way of Saint James (11–12th century) that sparked the enthusiasm and religious zeal of continental Christian Europe for centuries.\n\nDespite numerous battles, neither the Umayyads nor the Asturians had sufficient forces to secure control over these northern territories. Under the reign of Ramiro, famed for the highly legendary Battle of Clavijo, the border began to slowly move southward and Asturian holdings in Castile, Galicia, and León were fortified, and an intensive program of re-population of the countryside began in those territories. In 924 the Kingdom of Asturias became the Kingdom of León, when León became the seat of the royal court (it didn't bear any official name).\n\nAlfonso III of Asturias repopulated the strategically important city León and established it as his capital. King Alfonso began a series of campaigns to establish control over all the lands north of the Douro river. He reorganized his territories into the major duchies (Galicia and Portugal) and major counties (Saldaña and Castile), and fortified the borders with many castles. At his death in 910 the shift in regional power was completed as the kingdom became the Kingdom of León. From this power base, his heir Ordoño II was able to organize attacks against Toledo and even Seville.\n\nThe Caliphate of Córdoba was gaining power, and began to attack León. King Ordoño allied with Navarre against Abd-al-Rahman, but they were defeated in Valdejunquera in 920. For the next 80 years, the Kingdom of León suffered civil wars, Moorish attack, internal intrigues and assassinations, and the partial independence of Galicia and Castile, thus delaying the reconquest and weakening the Christian forces. It was not until the following century that the Christians started to see their conquests as part of a long-term effort to restore the unity of the Visigothic kingdom.\n\nThe only point during this period when the situation became hopeful for León was the reign of Ramiro II. King Ramiro, in alliance with Fernán González of Castile and his retinue of \"caballeros villanos\", defeated the Caliph in Simancas in 939. After this battle, when the Caliph barely escaped with his guard and the rest of the army was destroyed, King Ramiro obtained 12 years of peace, but he had to give González the independence of Castile as payment for his help in the battle. After this defeat, Moorish attacks abated until Almanzor began his campaigns. Alfonso V finally regained control over his domains in 1002. Navarre, though attacked by Almanzor, remained intact.\n\nThe conquest of León did not include Galicia which was left to temporary independence after the withdrawal of the Leonese king. Galicia was conquered soon after (by Ferdinand, son of Sancho the Great, around 1038). However, this brief period of independence meant that Galicia remained a kingdom and fief of Leon, which is the reason it is part of Spain and not Portugal. Subsequent kings titled themselves kings of Galicia and León, instead of merely king of León as the two were united personally and not in union.\n\nFerdinand I of León was the leading king of the mid-11th century. He conquered Coimbra and attacked the taifa kingdoms, often demanding the tributes known as parias. Ferdinand's strategy was to continue to demand parias until the taifa was greatly weakened both militarily and financially. He also repopulated the Borders with numerous \"fueros\". Following the Navarrese tradition, on his death in 1064 he divided his kingdom between his sons. His son Sancho II of Castile wanted to reunite the kingdom of his father and attacked his brothers, with a young noble at his side: Rodrigo Díaz, later known as El Cid Campeador. Sancho was killed in the siege of Zamora by the traitor Bellido Dolfos (also known as Vellido Adolfo) in 1072. His brother Alfonso VI took over León, Castile and Galicia.\n\nAlfonso VI the Brave gave more power to the \"fueros\" and repopulated Segovia, Ávila and Salamanca. Once he had secured the Borders, King Alfonso conquered the powerful Taifa kingdom of Toledo in 1085. Toledo, which was the former capital of the Visigoths, was a very important landmark, and the conquest made Alfonso renowned throughout the Christian world. However, this \"conquest\" was conducted rather gradually, and mostly peacefully, during the course of several decades. It was not until after sporadic and consistent population resettlements had taken place that Toledo was decisively conquered.\n\nAlfonso VI was first and foremost a tactful monarch who chose to understand the kings of taifa and employed unprecedented diplomatic measures to attain political feats before considering the use of force. He adopted the title \"Imperator totius Hispaniae\" (\"Emperor of all Hispania\", referring to all the Christian kingdoms of the Iberian Peninsula, and not just the modern country of Spain). Alfonso's more aggressive policy towards the taifas worried the rulers of those kingdoms, who called on the African Almoravids for help.\n\nThe Kingdom of Pamplona primarily extended along either side of the Pyrenees on the Atlantic Ocean. The kingdom was formed when local leader Íñigo Arista led a revolt against the regional Frankish authority and was elected or declared King in Pamplona (traditionally in 824), establishing a kingdom inextricably linked at this stage to their kinsmen, the muwallad Banu Qasi of Tudela.\n\nAlthough relatively weak until the early 11th century, Pamplona took a more active role after the accession of Sancho the Great (1004–1035). The kingdom expanded greatly under his reign, as it absorbed Castile, Leon, and what was to be Aragon, in addition to other small counties that would unite and become the Principality of Catalonia. This expansion also led to the independence of Galicia, as well as gaining overlordship over Gascony.\n\nIn the 12th century, however, the kingdom contracted to its core, and in 1162 King Sancho VI declared himself king of Navarre. Throughout its early history, the Navarrese kingdom engaged in frequent skirmishes with the Carolingian Empire, from which it maintained its independence, a key feature of its history until 1513.\n\nThe Kingdom of Aragon started off as an offshoot of the Kingdom of Navarre. It was formed when Sancho III of Navarre decided to divide his large realm among all his sons. Aragon was the portion of the realm which passed to Ramiro I of Aragon, an illegitimate son of Sancho III. The kingdoms of Aragon and Navarre were several times united in personal union until the death of Alfonso the Battler in 1135.\n\nIn 1137 the heiress of the kingdom married the count of Barcelona, and their son Alfonso II ruled from 1162 the combined possessions of his parents, resulting in what modern historians call the Crown of Aragon.\n\nIn the following centuries, the Crown of Aragon conquered a number of territories in the Iberian peninsula and the Mediterranean, including the kingdom of Valencia and the kingdom of Mallorca. James I of Aragon, also known as James the Conqueror, expanded his territories to the north, south and east. James also signed the Treaty of Corbeil (1258), which released him from the nominal suzerainty of the King of France.\n\nEarly in his reign, James attempted to reunite the Aragonese and Navarrese crowns through a treaty with the childless Sancho VII of Navarre. But the Navarrese nobles rejected him, and chose Theobald IV of Champagne in his stead.\n\nLater on, Ferdinand II of Aragon, married Isabella of Castile, leading to a dynastic union which eventually gave birth to modern Spain, after the conquest of Upper Navarre (Navarre south of the Pyrenees) and the kingdom of Granada.\n\nIn 1139, after an overwhelming victory in the Battle of Ourique against the Almoravids, Afonso Henriques was proclaimed the first King of Portugal by his troops. According to the legend, Christ announced from heaven Afonso's great deeds, whereby he would establish the first Portuguese Cortes at Lamego and be crowned by the Primate Archbishop of Braga. In the Treaty of Zamora in 1143, Alfonso VII of León and Castile recognized Portuguese independence from the Kingdom of León.\n\nIn 1147, Portugal captured Santarém, and seven months later the city of Lisbon was also brought under Portuguese control after the Siege of Lisbon. By the papal bull Manifestis Probatum, Pope Alexander III recognized Afonso Henriques as King of Portugal in 1179.\n\nWith Portugal finally recognized as an independent kingdom by its neighbours, Afonso Henriques and his successors, aided by Crusaders and the military monastic orders the Knights Templar, the Order of Aviz or the Order of Saint James, pushed the Moors to the Algarve on the southern coast of Portugal. After several campaigns, the Portuguese part in the \"Reconquista\" came to an end with the definitive capture of the Algarve in 1249. With all of Portugal now under the control of Afonso III of Portugal, religious, cultural and ethnic groups became gradually homogenized.\n\nAfter the completion of the \"Reconquista\", the Portuguese territory was a Roman Catholic realm. Nonetheless, Denis of Portugal carried out a short war with Castile for possession of the towns of Serpa and Moura. After this, Denis avoided war; he signed the Treaty of Alcanizes with Ferdinand IV of Castile in 1297, establishing the present-day borders.\n\nDuring the suppression of the Knights Templar all over Europe, under the influence of Philip IV of France and Pope Clement V requesting its annihilation by 1312, King Denis reinstituted the Templars of Tomar as the Order of Christ in 1319. Denis believed that the Order's assets should by their nature stay in any given Order instead of being taken by the King, largely for the Templars' contribution to the \"Reconquista\" and the reconstruction of Portugal after the wars.\n\nThe experience gained during the battles of the \"Reconquista\" was fundamental to Conquest of Ceuta, the first step to the establishment of the Portuguese Empire. Likewise, the contact with Muslim's navigation techniques and sciences enabled the creation of Portuguese nautical innovations such as the caravel – the principal Portuguese ship during their voyages of exploration in the Age of Discovery.\n\nMinor Christian realms were the Kingdom of Viguera (970–1005), and the (1094–1102).\n\nClashes and raids on bordering Andalusian lands did not keep the Christian kingdoms from battling among themselves or allying with Muslim kings. Some Muslim kings had Christian-born wives or mothers. Some Christian champions, like El Cid, were contracted by taifa kings to fight against their neighbours. Indeed, El Cid's first battle experience was gained fighting for a Muslim state against a Christian state. At the Battle of Graus in 1063, he and other Castilians fought on the side of al-Muqtadir, Muslim sultan of Zaragoza, against the forces of Ramiro I of Aragon. There is even an instance of a crusade being declared against another Christian king in Iberia.\n\nFollowing the disastrous defeat of Alfonso VIII, King of Castile, at Alarcos, Kings Alfonso IX of León and Sancho VII of Navarre entered an alliance with the Almohads and invaded Castile in 1196. By the end of the year Sancho VII had dropped out of the war under Papal pressure. Early in 1197, at the request of Sancho I, King of Portugal, Pope Celestine III declared a crusade against Alfonso IX and released his subjects from their responsibilities to the king, declaring that \"the men of his realm shall be absolved from their fidelity and his dominion by authority of the apostolic see.\" Together the Kings of Portugal, Castile, and Aragon invaded León. In the face of this onslaught combined with pressure from the Pope, Alfonso IX was finally forced to sue for peace in October 1197.\n\nIn the late years of \"Al-Andalus\", Castile had the might to conquer the remnants of the kingdom of Granada, but the kings preferred to claim the tribute of the Muslim \"parias\". The trade of Granadan goods and the parias were a major means by which African gold entered medieval Europe.\n\nThe \"Reconquista\" was a process not only of war and conquest, but also of repopulation. Christian kings moved their own people to locations abandoned by Muslims in order to have a population capable of defending the borders. The main repopulation areas were the Douro Basin (the northern plateau), the high Ebro valley (La Rioja) and central Catalonia. The repopulation of the Douro Basin took place in two distinct phases. North of the river, between the 9th and 10th centuries, the \"pressure\" (or \"presura\") system was employed. South of the Douro, in the 10th and 11th centuries, the \"presura\" led to the \"charters\" (\"forais\" or \"fueros\"). \"Fueros\" were used even south of the Central Range.\n\nThe \"presura\" referred to a group of peasants who crossed the mountains and settled in the abandoned lands of the Douro Basin. Asturian laws promoted this system, for instance granting a peasant all the land he was able to work and defend as his own property. Of course, Asturian and Galician minor nobles and clergymen sent their own expeditions with the peasants they maintained. This led to very feudalised areas, such as León and Portugal, whereas Castile, an arid land with vast plains and harsh climate, only attracted peasants with no hope in Biscay. As a consequence, Castile was governed by a single count, but had a largely non-feudal territory with many free peasants. \"Presuras\" also appear in Catalonia, when the count of Barcelona ordered the Bishop of Urgell and the count of Gerona to repopulate the plains of Vic.\n\nDuring the 10th century and onwards, cities and towns gained more importance and power, as commerce reappeared and the population kept growing. \"Fueros\" were charters documenting the privileges and usages given to all the people repopulating a town. The \"fueros\" provided a means of escape from the feudal system, as \"fueros\" were only granted by the monarch. As a result, the town council was dependent on the monarch alone and, in turn, was required to provide \"auxilium\" – aid or troops – for their monarch. The military force of the towns became the \"caballeros villanos\". The first \"fuero\" was given by count Fernán González to the inhabitants of Castrojeriz in the 940's. The most important towns of medieval Iberia had \"fueros\", or \"forais\". In Navarre, \"fueros\" were the main repopulating system. Later on, in the 12th century, Aragon also employed the system; for example, the \"fuero\" of Teruel, which was one of the last fueros, in the early 13th century.\n\nFrom the mid-13th century on, no more charters were granted, as the demographic pressure had disappeared and other means of re-population were created. \"Fueros\" remained as city charters until the 18th century in Aragon, Valencia and Catalonia and until the 19th century in Castile and Navarre. \"Fueros\" had an immense importance for those living under them, who were prepared to go to war to defend their rights under the charter. In the 19th century, the abolition of the \"fueros\" in Navarre would be one of the causes of the Carlist Wars. In Castile, disputes over the system contributed to the war against Charles I (Castilian War of the Communities).\n\nDuring the 9th century the Berbers returned to North Africa in the aftermath of revolts. Many governors of large cities distant from the capital, Córdoba, had planned to establish their independence. Then, in 929, the Emir of Córdoba (Abd-ar-Rahman III), the leader of the Umayyad dynasty, declared himself Caliph, independent from the Abbasids in Baghdad. He took all the military, religious, and political power and reorganised the army and the bureaucracy.\n\nAfter regaining control over the dissident governors, Abd-ar-Rahman III tried to conquer the remaining Christian kingdoms of the Iberian peninsula, attacking them several times and forcing them back beyond the Cantabrian Mountains. Abd-ar-Rahman's grandson later became a puppet in the hands of the great Vizier Almanzor (\"al-Mansur\", \"the victorious\"). Almanzor waged several campaigns attacking and sacking Burgos, León, Pamplona, Barcelona, and Santiago de Compostela before his death in 1002.\n\nBetween Almanzor's death and 1031, Al-Andalus suffered many civil wars, which ended in the division into the Taifa kingdoms. The taifas were small kingdoms, established by the city governors. The result was many (up to 34) small kingdoms, each centered upon its capital. Their governors had no larger-scale vision of the Moorish presence in the Iberian peninsula and had no qualms about attacking their neighbouring kingdoms whenever they could gain advantage by doing so.\n\nThe split into the taifa states weakened the Islamic presence, and the Christian kingdoms further advanced as Alfonso VI of León and Castile conquered Toledo in 1085. Surrounded by enemies, taifa rulers sent a desperate appeal to the Berber chieftain Yusuf ibn Tashfin, leader of the Almoravids.\n\nThe Almoravids were a Muslim militia primarily composed of Berber and African Moors, and unlike previous Muslim rulers, they were not so tolerant towards Christians and Jews. Their armies entered the Iberian peninsula on several occasions (1086, 1088, 1093) and defeated King Alfonso at the Battle of Sagrajas in 1086, but initially their purpose was to unite all the taifas into a single Almoravid Caliphate. Their actions halted the southward expansion of the Christian kingdoms. Their only defeat came at Valencia in 1094, due to the actions of El Cid.\n\nMeanwhile, Navarre lost all importance under King Sancho IV, for he lost Rioja to Sancho II of Castile, and nearly became the vassal of Aragon. At his death, the Navarrese chose as their king Sancho Ramírez, King of Aragon, who thus became Sancho V of Navarre and I of Aragon. Sancho Ramírez gained international recognition for Aragon, uniting it with Navarre and expanding the borders south, conquering \"Wasqa\" Huesca deep in the valleys in 1096 and building a fort, El Castellar, 25 km from \"Saraqusta\" Zaragoza.\n\nCatalonia came under intense pressure from the taifas of Zaragoza and Lérida, as well as from internal disputes, as Barcelona suffered a dynastic crisis that led to open war among the smaller counties. But by the 1080s, the situation had calmed down, and the dominion of Barcelona over the smaller counties was restored.\n\nAfter a brief period of disintegration (the second Taifa period), the Almohads, the rising power in North Africa, took over most of \"Al-Andalus\". However they were decisively defeated at the Battle of Las Navas de Tolosa (1212) by a Christian coalition, losing almost all the remaining lands of \"Al-Andalus\" in the following decades. By 1252 only the Kingdom of Granada remained intact but as a vassal state of Castile.\n\nFerdinand and Isabella completed the \"Reconquista\" with a war against the Emirate of Granada that started in 1482 and ended with Granada's surrender on January 2, 1492. The Moors in Castile previously numbered \"half a million within the realm.\" By 1492 some 100,000 had died or been enslaved, 200,000 had emigrated, and 200,000 remained in Castile. Many of the Muslim elite, including Granada's former Emir Muhammad XII, who had been given the area of the Alpujarras mountains as a principality, found life under Christian rule intolerable and emigrated to Tlemcen in North Africa.\n\nIn 1497 Spanish forces took Melilla, west of Oran, and the island of Djerba, south of Tunis, and went on to more important gains, with the bloody seizure of Oran in 1509, and the capture of Bougie and Tripoli in 1510. The Spanish capture of Tripoli cost them some 300 men, while the inhabitants suffered between 3,000 and 5,000 killed and another 5,000–6,000 carried off as slaves. Soon thereafter, however, they faced competition from the rapidly expanding Ottoman Empire in the east and were pushed back.\n\nAs elsewhere in the Muslim world, Christians and Jews were allowed to retain their religions, with their own legal systems and courts, by paying a tax, the \"jizya\". The penalty for not paying it was imprisonment.\n\nThe new Christian hierarchy demanded heavy taxes from non-Christians and gave them rights, such as in the Treaty of Granada (1491) only for Moors in recently Islamic Granada. On July 30, 1492, all the Jewish community – some 200,000 people – were forcibly expelled. The next year the Alhambra decree ordered the expulsion of practicing Jews, leading many to convert to Catholicism. In 1502, Queen Isabella I declared conversion to Catholicism compulsory within the Kingdom of Castile. King Charles V did the same to Moors in the Kingdom of Aragon in 1526, forcing conversions of its Muslim population during the Revolt of the Germanies. Many local officials took advantage of the situation to seize property.\n\nMost of the descendants of those Muslims who submitted to conversion to Christianity – rather than exile – during the early periods of the Spanish and Portuguese Inquisition, the Moriscos, were later expelled from Spain after serious social upheaval, when the Inquisition was at its height. The expulsions were carried out more severely in eastern Spain (Valencia and Aragon) due to local animosity towards Muslims and Moriscos where they were seen as economic rivals by local workers who saw them as cheap labor undermining their bargaining position with the landlords. Exactions imposed on the Moriscos paved the way to a major Morisco revolt happening in 1568, with the final expulsion of the Moriscos from Castile taking place in 1609; they were driven from Aragon at about the same time.\n\nMaking things more complex were the many former Muslims and Jews known as \"Moriscos\", \"Marranos\", and \"Conversos\", who shared ancestors in common with many Christians, especially among the aristocracy, causing much concern over loyalty and attempts by the aristocracy to hide their non-Christian ancestry. Some – the numbers are debated – continued to secretly practice their religions and use their languages well into the sixteenth century. Those that the Spanish Inquisition found to be secretly practicing Islam or Judaism were executed, imprisoned, or exiled. Nevertheless, all those deemed to be \"New Christians\" were repeatedly suspected of illegally continuing in secret to practice their religions various crimes against the Spanish state including continued practice of Islam or Judaism. New Christians were subject to many discriminatory practices starting in the sixteenth century.\n\nThe many advances and retreats created several social types:\n\nReal, legendary, and fictional episodes from the \"Reconquista\" are the subject of much of medieval Galician-Portuguese, Spanish, and Catalan literature such as the \"cantar de gesta\".\n\nSome noble genealogies show the close relations (although not very numerous) between Muslims and Christians. For example, Al-Mansur Ibn Abi Aamir, whose rule is considered to have marked the peak of power for Moorish \"Al-Andalus\" Iberia, married Abda, daughter of Sancho Garcés II of Navarra, who bore him a son, named Abd al-Rahman and commonly known in pejorative sense as Sanchuelo (\"Little Sancho\"; in Arabic: \"Shanjoul\").\n\nAfter his father's death, Sanchuelo/Abd al-Rahman, as a son of a Christian princess, was a strong contender to take over the ultimate power in Muslim al-Andalus. A hundred years later, King Alfonso VI of Castile, considered among the greatest of the Medieval Spanish kings, designated as his heir his son (also a Sancho) by the refugee Muslim princess Zaida of Seville.\n\nThe \"Reconquista\" was a war with long periods of respite between the adversaries, partly for pragmatic reasons and also due to infighting among the Christian kingdoms of the North spanning over seven centuries. Some populations practiced Islam or Christianity as their own religion during these centuries, so the identity of contenders changed over time.\n\nCurrently, festivals called \"moros y cristianos\" (Castilian), \"moros i cristians\" (Catalan), \"mouros e cristãos\" (Portuguese) and \"mouros e cristiáns\" (Galician), which all mean \"Moors and Christians\", recreate the fights as colorful parades with elaborate garments and lots of fireworks, especially on the central and southern towns of the Land of Valencia, like Alcoi, Ontinyent or Villena.\n\nA 2016 study found that the manner of the Reconquest has persistent effects on the Spanish economy to this day. The authors show how territory quickly re-taken during the Reconquest was given to nobility, whereas territory slowly re-taken was more equally distributed and settled. Lands dominated by nobility have worse long-term development outcomes and greater inequality.\n\nOn the conclusion of Iberian victory over the Moors, the Iberian powers, Spain and Portugal didn't stop their warring against the Muslims solely in their homelands—they extended the conflict against Islam overseas. The Spanish under the Hapsburg dynasty soon became the champions of Roman Catholicism in Europe and the Mediterranean against the encroaching threat of the Ottoman Caliphate. In a similar vein, the Portuguese also extended the Reconquista, this time against Muslim states overseas. The conquest of Ceuta marked the beginning of Portuguese expansion into Muslim Africa. Soon, the Portuguese also went into conflict with the Ottoman Caliphate in the Mediterranean, Indian Ocean and Southeast Asia as the Portuguese conquered the Ottomans' allies: the Sultanate of Adal in East Africa, the Sultanate of Delhi in South Asia and the Sultanate of Malacca in Southeast Asia. Meanwhile, the Spanish also went to war against the Sultanate of Brunei in Southeast Asia. The Spanish sent expeditions from New Spain (Mexico) to conquer and Christianize the Philippines, then a territory of the Sultanate of Brunei. Brunei itself was assaulted during the Castilian War. Spain also went to war against the Sultanates of Sulu, Maguindanao, and Lanao in the Spanish-Moro Conflict. The primary inspiration for these wars against Muslim states overseas was the Reconquista.\n\n\n"}
{"id": "921274", "url": "https://en.wikipedia.org/wiki?curid=921274", "title": "Safe deposit box", "text": "Safe deposit box\n\nA safe deposit box, also known as a safety deposit box, is an individually secured container, usually held within a larger safe or bank vault. Safe deposit boxes are generally located in banks, post offices or other institutions. Safe deposit boxes are used to store valuable possessions, such as gemstones, precious metals, currency, marketable securities, Luxury goods, important documents (e.g. wills, property deeds, or birth certificates), or computer data, that need protection from theft, fire, flood, tampering, or other perils. In the United States, neither banks nor the FDIC insure the contents. An individual can purchase insurance for the safe deposit box in order to cover e.g. theft, fire, flooding or terrorist attacks.\n\nMany hotels, resorts and cruise ships also offer safe deposit boxes or small safes to their patrons, for temporary use during their stay. These facilities may be located behind the reception desk, or securely anchored within private guest rooms for privacy.\n\nThe contents of safe deposit boxes may be seized under the legal theory of abandoned property. They also may be searched and seized by the order of a court through the issuance of search warrant.\n\n"}
{"id": "35814760", "url": "https://en.wikipedia.org/wiki?curid=35814760", "title": "Schmiede Hallein", "text": "Schmiede Hallein\n\nSchmiede Hallein is a media and art festival taking place since 2003 during September in Hallein, Austria. During a period of ten days international participants work on projects in a former industrial building. It focuses on music productions, film, photography and performances.\n\nSchmiede receives over 200 applications from more than 20 countries every year, of which 80% are accepted and an additional 30 guests are invited. The participants are called \"Smiths\" and form a community beyond the festival. Participation has been free of charge in earlier years but in 2010 a €50 participation fee was introduced.\n\nSchmiede Hallein takes place in a former salt refinery, a building that also hosts other cultural events in Hallein and the Salzburg Summeracadamy. The somewhat isolated location allows participants to focus on their projects without distraction.\n\nThe festival is supported by a range of companies and institutions ranging from the city of Hallein to federal ministries:\nKulturland Salzburg, city of Hallein,BM:UKK, WIBERG, FM4, Red Bull Music Academy, Kunstraum Pro Arte in Hallein, Carhartt Europe, MusicImport: CAD, Mackie und Aphex, Tourismusverband Hallein\n\n"}
{"id": "43868891", "url": "https://en.wikipedia.org/wiki?curid=43868891", "title": "Social Bonding and Nurture Kinship", "text": "Social Bonding and Nurture Kinship\n\nSocial Bonding and Nurture Kinship: Compatibility between Cultural and Biological Approaches is a book on human kinship and social behavior by Maximilian Holland, published in 2012. The work synthesizes the perspectives of evolutionary biology, psychology and sociocultural anthropology towards understanding human social bonding and cooperative behavior. It presents a theoretical treatment that many consider to have resolved longstanding questions about the proper place of genetic (or 'blood') connections in human kinship and social relations, and a synthesis that \"should inspire more nuanced ventures in applying Darwinian approaches to sociocultural anthropology\". The book has been called \"A landmark in the field of evolutionary biology\" which \"gets to the heart of the matter concerning the contentious relationship between kinship categories, genetic relatedness and the prediction of behavior\", \"places genetic determinism in the correct perspective\" and serves as \"a shining example of what can be achieved when excellent scholars engage fully across disciplinary boundaries.\"\n\nThe aim of the book is to show that \"properly interpreted, cultural anthropology approaches (and ethnographic data) and biological approaches are perfectly compatible regarding processes of social bonding in humans.\" Holland's position is based on demonstrating that the dominant biological theory of social behavior (inclusive fitness theory) is typically misunderstood to predict that genetic ties are necessary for the \"expression\" of social behaviors, whereas in fact the theory only implicates genetic associations as necessary for the \"evolution\" of social behaviors. Whilst rigorous evolutionary biologists have long understood the distinction between these levels of analysis (see Tinbergen's four questions), past attempts to apply inclusive fitness theory to humans have often overlooked the distinction between \"evolution\" and \"expression\".\n\nBeyond its central argument, the broader philosophical implications of Holland's work are considered by commentators to be that it both \"helps to untangle a long-standing disciplinary muddle\" and \"clarifies the relationship between biological and sociocultural approaches to human kinship.\" It is claimed that the book \"demonstrates that an alternative non-deterministic interpretation of evolutionary biology is more compatible with actual human social behavior and with the frameworks that sociocultural anthropology employs\" and as a consequence, delivers \"a convincing, solid and informed blow to the residual genetic determinism that still influences the interpretation of social behaviour.\"\n\nThe book's form consists of a cumulative argument (using a wide range of supporting evidence) made over nine chapters, with each chapter ending in a brief retrospective summary, and the final chapter containing a recapitulation and summary of the whole, and drawing some wider conclusions.\n\nHolland begins by tracing transitions in the history of anthropological theories of social behavior and kinship, noting the varying importance with which 'blood ties' have been understood to be a necessary element of human kinship and social relations. He suggests that whilst the mounting ethnographic evidence has led to a move away from the 'blood kinship' concept in recent decades, many sociocultural anthropologists still query the connection between kinship and blood, reproduction or some other apparently biological functions. Meanwhile, many biologists, biological anthropologists and evolutionary psychologists have persisted in viewing human kinship and cooperative behavior as necessarily associated with genetic relationships and 'blood ties'. The current situation has been characterized as \"a clash between incommensurate paradigms, holding as they may, completely incompatible ideas about human nature.\" Holland argues that a clear resolution to these questions is still outstanding, and would therefore be of value. In closing the introduction, Holland writes; \"The approach is not reductive. The claim is rather that a thorough investigation of the ‘biological facts’ can be useful mainly though allowing a change in focus... away from confusion about the place of genealogy in social ties, and onto a reformulated baseline, built around varied \"processual aspects of social bonding.\"\"\n\nThe book reviews the background and key elements of Hamilton's inclusive fitness theory from the 1960s onwards, setting out its significant conceptual and heuristic value. Holland notes that Hamilton acknowledged that his earliest and most widely known account (1964) contained technical inaccuracies. He also notes Hamilton's early speculations about possible proximate mechanisms of the expression of social behavior (\"supergenes\" as a possible alternative to \"behaviour-evoking-situations\") contained errors that have nevertheless remained very influential in popular accounts. Specifically, the supergenes notion (sometimes called the \"Green-beard effect\") - that organisms may evolve genes that are able to identify identical copies in others and preferentially direct social behaviours towards them - was theoretically clarified and withdrawn by Hamilton in 1987. However, in the intervening years, the notion that supergenes (or more often, simply individual organisms) have evolved \"to identify genetic relatives and preferentially cooperate with them\" took hold, and became the way many biologists came to understand the theory. This persisted, despite Hamilton's 1987 correction. In Holland's view it is the pervasiveness of this longstanding but erroneous perspective, and the suppression of the alternative 'behaviour-evoking-situations' perspective regarding social expression mechanisms, that is largely responsible for the ongoing clash between biological and sociocultural approaches to human kinship.\n\nHolland shows that, in the 1970s and 80s, the first wave of attempts (known as \"human sociobiology\" or \"Darwinian anthropology\") to apply inclusive fitness theory to human social behavior relied on, and further reinforced, this same misinterpretation (above section) about the theory's predictions and the proximate mechanisms of social behavior. Holland also shows that this period of research was burdened with many misplaced assumptions about \"universal\" attributes of the human sexes, sexuality and gender roles, apparently projected from the \"specific cultural values\" of the researchers themselves. Holland also shows that, following the perceived failures of this early wave, and particularly its methodological agnosticism regarding proximate mechanisms of social behavior, the evolutionary psychology school grew up in its place. Although this latter school typically avoided engaging with the ethnographic data on human kinship, Holland argues that in the few cases where it did so, it repeated the misinterpretation of inclusive fitness theory that characterized the first wave. Holland also notes that Kitcher, in his critique of the sociobiological position, suggested that perhaps the expression of social behaviors in humans might quite simply be based on cues of context and familiarity, rather than genetic relatedness \"per se\".\n\nChapters four and five investigate further the theory and evidence surrounding the \"proximate mechanisms\" of social behavior; specifically the question of whether social behaviors are expressed by organisms via \"behaviour-evoking-situations\" or via direct detection of actual genetic relatedness. Related questions have been the domain of kin recognition theory. Holland notes that the name 'kin recognition' itself suggests some expectation that a positive identification of genetic relatedness is a prediction of inclusive fitness theory, and is thus expected. Similar points have been made by others; \"many behavioural ecologists seem to implicitly assume that specialised mechanisms allowing individuals to distinguish their kin from non-kin must have evolved.\" Again, the possibility that \"behaviour-evoking-situations\" might be the more parsimonious mechanism of the expression of social behavior, and fully compatible with inclusive fitness theory, has often been underemphasized. However, Holland's review of the evidence notes that field studies in this area quickly established that \"behaviour-evoking-situations\" do in fact overwhelmingly mediate social behaviours in those species studied, and that, particularly in mammal species, social bonding and familiarity formed in early developmental contexts (e.g. in burrows or nesting sites) are a common mediating mechanism for social behaviors, independently of genetic relatedness \"per se\". On the basis of the preceding theoretical analysis and review of evidence, at the end of chapter five, Holland argues that;\nIt is entirely erroneous, both in reference to theory and in reference to the evidence, to claim or suggest that 'the facts of biology' support the claim that organisms have evolved to cooperate with genetic relatives \"per se\".\n\nHaving argued for the above position on the lack of necessity for genetic relatedness \"per se\" to mediate social bonding and behavior, Holland suggests that \"The further question then is; can we uncover in any greater detail how familiarity and other context-dependent cues operate?\". To discover the extent to which the variety of human kinship behaviors may nevertheless be compatible with this (less deterministic) interpretation of biological theory of social behavior, Holland suggests that a survey of primates' most fundamental social patterns may give clues, especially those of species most closely connected with humans. The variety of primate mating systems, group-membership ('philopatry') patterns, and life-cycle patterns are reviewed. Holland finds that;\n\nLike other mammals, Catarrhini primate demographics are strongly influenced by ecological conditions, particularly density and distribution of food sources... Cohesive social groups and delayed natal dispersal mean that maternally related individuals, including maternal siblings, face a statistically reliable context of interaction in all Catarrhini primates. This reliable context of interaction with maternally related individuals is extended amongst those species with female philopatry (especially Cercopithecinae).\n\nAs with other social mammals, evidence suggest that the reliability of 'behaviour-evoking-situations' this social context provides has shaped the mechanisms of proximate expression of social bonding and behavior;\n\nAdoption of infants by females (and sometimes males) demonstrates that care-giving and bonding to infants is not mediated by positive powers of discrimination. From the infant's perspective, it will bond with any responsive carer. If not necessarily the actual mother, in natural conditions this will often be a maternal relative (particularly an older sibling), but the context is primary, not the actual relatedness. Similarly, social bonding and social behaviours between maternal siblings (and occasionally between other maternal relatives) is context-driven in primates, and mediated via the care-giver.\n\nHolland also notes how Bowlby and colleagues' attachment theory was strongly informed by primate bonding patterns and mechanisms, and that in Bowlby's later writing the then emerging inclusive fitness theory was explicitly linked to. \n[Bowlby's] work demonstrated that social attachments form on the basis of provision of care, and responsiveness to elicitations for care. The social context of living together and the familiarity this brings, provides the circumstance within which social bonds can form...\n\nOn the basis of combining more recent primate research with the findings of attachment theory, Holland proposes that \"In attempting to define more specific forms of \"the giving of care and nurture\" which may mediate social bonding we [find] that provision of food is likely to play a part, as well as the more intangible provision of warmth and comfort, and a safe base for sleeping.\"\n\nHolland claims that, while biological theory of social behavior is not deterministic in respect of genetic relatedness vis-a-vis the formation of social bonds and expression of social behaviors, evidence does point to compatibility between a non-reductive interpretation of the theory and how such bonds and behaviors operate in social mammals, primates and in humans. In the final part of the book, Holland explores the extent to which this perspective is also compatible with sociocultural anthropology's ethnographic accounts of human kinship and social behavior, both occasional accounts from the past, as well as more contemporary accounts that have explicitly eschewed the earlier 'blood ties' assumption. Holland finds that;\n\nMany contemporary accounts focus on social bonds formed in childhood and the importance of the performance of acts of care, including food provision, in mediating these bonds. In all cases it is this performance of care which is considered the overriding factor in\nmediating social bonds, notwithstanding 'blood ties'. In short, there is strong compatibility between the perspectives on social bonding that emerge from a proper account of biological theory and those documented by ethnographers.\n\nHolland's concluding chapter gives a summary of his fundamental position;\n\nA crucial implication of this argument taken as a whole is that \"the expression of the kinds of social behaviours treated by inclusive fitness theory does not require genetic relatedness.\" Sociobiology and evolutionary psychology's claims that biological science predicts that organisms \"will\" direct social behaviour towards relatives are thus both \"theoretically\" and \"empirically\" erroneous. Such claims and their supporting arguments also give a highly misleading and reductive account of basic biological theory. Properly interpreted, \"cultural anthropology approaches (and ethnographic data) and biological approaches are perfectly compatible\" regarding processes of social bonding in humans. Most of all, this requires a focus on the circumstances and processes which lead to social bonding.\n\nThe book notes that, as an outcome of the analysis, Schneider's sociocultural perspective on human kinship is vindicated;\n\nDo the biological facts have some priority or are they but one of the conditions, like ecology, economy, demography, etc., to which kinship systems must adapt? Take note: if the latter is the case, then kinship must be as much rooted in these other conditions as in the biological facts.\n\nThe author supplies several examples of the insight that Schneider's broad approach can provide. The book closes with an example of a clash of cultural perspectives on kinship and family norms, and makes the suggestion that;\n\nConstructing from narrow cultural particulars (Euro-American or otherwise) an essentialised model of 'human nature' does not constitute science; it is closer to cultural colonialism. In any analysis intended to shed light on proposed universals of the human condition, reflexivity is essential, and cultural and biological approaches both surely necessary.\n\nKinship theorist and member of the national academy of science, Robin Fox wrote of the work:\n\nAn excellent and constructive discussion of matters in kinship and its cultural and biological components, handsomely reconciling what have been held to be incompatible positions.Max Holland gets to the heart of the matter concerning the contentious relationship between kinship categories, genetic relatedness and the prediction of behavior. If he had been in the debate in the 1980s then a lot of subsequent confusion could have been avoided\"\n\nIrwin Bernstein, distinguished research professor in the university of Georgia's \"Behavioral and Brain Sciences Program\" made the following comment on Holland's book:\n\nMax Holland has demonstrated extraordinarily thorough scholarship in his exhaustive review of the often contentious discussions of kinship. He has produced a balanced synthesis melding the two approaches exemplified in the biological and sociocultural behavioral positions. His work in reconciling opposing views clearly demonstrates the value of interdisciplinary approaches. This should be the definitive word on the subject.\n\nPhilip Kitcher, John Dewey Professor of Philosophy, and James R. Barker Professorship of Contemporary Civilization at Columbia University, past president of the American Philosophical Association and inaugural winner of the Prometheus Prize, stated of the book:\n\nMax Holland has provided a wide-ranging and deeply-probing analysis of the influence of genetic relatedness and social context on human kinship. He argues that while genetic relatedness may play a role in the evolution of social behavior, it does not determine the forms of such behavior. His discussion is exemplary for its thoroughness, and should inspire more nuanced ventures in applying Darwinian approaches to sociocultural anthropology.\n\nKirk Endicott, professor emeritus of anthropology at the university of Dartmouth, wrote that Holland's book was:\n\nA brilliant discussion of the relationship between kinship and social bonding as understood in evolutionary biology and in sociocultural anthropology. Among other contributions, it debunks the common misconception that biological evolution involves individual organisms actively pursuing the goal of increasing the numbers of their genes in successive generations, the measure of their so-called ‘individual inclusive fitness’. Holland demonstrates that an alternative non-deterministic interpretation of evolutionary biology is more compatible with actual human social behavior and with the frameworks that sociocultural anthropology employs.\n\nJanet Carsten, kinship theorist and professor of anthropology at the university of Edinburgh stated that:\n\nThis book is a scholarly attempt to get beyond the often sterile oppositions between evolutionary and culturalist approaches to kinship. In bringing together two sides of the debate, it constitutes a valuable contribution to kinship studies.\n\nIn a review for the journal Critique of Anthropology, Nicholas Malone concluded that:\n\nLucid and effective... Holland has produced a significant work of scholarship that will be of interest to a wide swath of the anthropological community.\n\nCommenting on the book for the journal Social Analysis, Anni Kajanus found that:\n\nHolland has done an excellent and thorough job in reviewing the disciplinary and interdisciplinary histories of approaches to kinship and social bonds in anthropology, biology, and psychology. Most importantly, he clarifies the different levels of analysis when looking at human behavior in real time and in the evolutionary time frame. This makes the book essential reading for anyone who acknowledges that human relatedness and social bonds are shaped by the\nevolved dispositions of our species, their development through the life-course of an individual, and our specific cultural-historical environments... Holland’s book goes a long way toward clarifying and therefore advancing these theoretical debates\n\nAn in-depth review of the book by primatologist Augusto Vitale, in the journal \"Folia Primatologica\", found that:\n\nStuart Semple, evolutionary anthropologist, reviewing the book in the journal \"Acta Ethologica\" stated that:\n\nAs someone who teaches behavioural ecology to biologists, and primate biology to social and biological anthropologists, I will be strongly recommending this book to all of my advanced undergraduates, masters and PhD students, as well as to my colleagues. Not only does it help to resolve debates that have run for many years, but it is also an outstanding example of what can be achieved by immersing oneself in literature from different fields, while retaining an intellectual openness and exercising incisive analysis. Many of us talk enthusiastically about inter- and multi-disciplinarity, but often this is not much more than lip service. This book is a shining example of what can be achieved when excellent scholars engage fully across disciplinary boundaries. There should be more texts like this.\n\nIn addition to praise for the book's significance, the Folia Primatologica review noted that the book is at times too dense and requires close reading;\nThe argument here and there becomes too detailed and tortuous, but it is absolutely captivating... [Colleagues] who are less used to extremely detailed theoretical reasoning, will find it difficult at the beginning...\n\n"}
{"id": "24352014", "url": "https://en.wikipedia.org/wiki?curid=24352014", "title": "Social protection", "text": "Social protection\n\nSocial protection, as defined by the United Nations Research Institute For Social Development, is concerned with preventing, managing, and overcoming situations that adversely affect people’s well being. Social protection consists of policies and programs designed to reduce poverty and vulnerability by promoting efficient labour markets, diminishing people's exposure to risks, and enhancing their capacity to manage economic and social risks, such as unemployment, exclusion, sickness, disability and old age.\n\nThe most common types of social protection:\n\n\nTraditionally, social protection has been used in the European welfare state and other parts of the developed world to maintain a certain living standard, and address transient poverty. One of the first examples of state-provided social protection can be tracked to the Roman Emperor Trajan, who expanded a program for free grain to include more poor citizens of the empire. In addition, he instituted public funds to support poor children. Organized welfare was not common until the late 19th and early 20th centuries. It was during this period that in both Germany and Great Britain, welfare systems were established to target the working classes (see National Insurance). The United States followed several years later, during the Great Depression, with emergency relief for those struck the hardest. However, modern social protection has grown to envelop a much broader range of issues and purposes; it is now being used as a policy approach in developing nations, to address issues of persistent poverty and target structural causes. Moreover, it is designed to lift recipients out of poverty, rather than exclusively providing passive protection against contingencies . social protection has rapidly been used in trying to reduce and ultimately eliminate poverty and suffering in developing countries (mostly in Africa), so to enhance and promote economic and social growth.\n\nLabor market interventions, consisting of both active and passive policies, provide protection for the poor who are capable of gaining employment. Passive programs, such as unemployment insurance, income support and changes in labor legislation, allieviate the financial needs of the unemployed but are not designed to improve their employability. A European Union-funded research as part of the DRIVERS project revealed a linear\nrelationship between investments in national active labour market policies (specifically those directed towards integrating vulnerable groups into employment) and quality of work. It found that European countries with more active labour market policies seem to have healthier, less stressed workplaces.\n\nOn the other hand, active programs focus on directly increasing the access of unemployed workers. Active labour market policies (ALMPs) are used to reduce the risk of unemployment and to increase the earnings capacity of workers. ALMPs have two basic objectives: (1) economic, by increasing the ability of the unemployed to find jobs, and increase productivity and earnings; and (2) social, by improving the inclusion and participation of productive employment. These programs have the ability to increase employment opportunities and address the social problems that often accompany high unemployment. Active policies are a way of reversing the negative effects of industrial restructuring in transition economies and to help integrate vulnerable people furthest from the labor markets. ALMPs are often targeted to the long-term unemployed, workers in poor families, and particular groups with labor market disadvantages. These programs have important social, as well as economic, objectives. Active labor market programs include a wide range of activities to stimulate employment and productivity such as:\nA common issue in implementing successful labor market interventions is how to incorporate the informal economy, which comprises a significant portion of the workforce in developing countries. Informal employment comprises between half and three quarters of non-agricultural employment in the majority of these countries. The proportion of informal employment increases when agriculture is taken into account. Most informal workers are not covered by social security schemes, occupational safety and health measures, working conditions regulations and have limited access to health services and work-related measures of social protection. Labor market interventions work to integrate the different strategies to prevent and compensate occupational and social risks in the informal economy. The strategies that include measures to prevent and mitigate the impact of risks are the most effective.\n\nIn general, public expenditure on labor market policy (LMP) interventions falls within three main categories:\ntraining (2),\njob rotation & job sharing (3),\nemployment incentives (4),\nsupported employment & rehabilitation (5),\ndirect job creation (6),\nstart-up incentives (7),\n\nout-of-work income maintenance and support (8),\nearly retirement (9)\n\nSocial insurance schemes are contributory programs that protect beneficiaries from catastrophic expenses in exchange for regular payments of premiums. Health costs can be very high, so health insurance schemes are a popular way reducing risk in the event of shock. However, an individual with low income may not be able to afford insurance. Some argue that insurance schemes should be complemented with social assistance. Community-based health insurance allows pooling in settings where institutional capacity is too weak to organize nationwide risk-pooling, especially in low-income countries, making insurance more affordable. In risk-sharing schemes, the insurance premium is unrelated to the likelihood that the beneficiary will fall ill and benefits are provided on the basis of need.\n\nSocial assistance schemes comprise programs designed to help the most vulnerable individuals ( i.e., those with no other means of support such as single parent households, victims of natural disasters or civil conflict, handicapped people, or the destitute poor), households and communities to meet a Social floor and improve living standards. These programs consist of all forms of public action, government and non-government, that are designed to transfer resources, either cash or in-kind (e.g. food transfers), to eligible vulnerable and deprived persons. Social assistance interventions may include:\n\nThere are two main schools of thought concerning scope of social protection. Universalism argues that each person, by merit of simply being a citizen should be entitled to benefits from social protection programs. Such a policy would avoid means-testing and any conditionalities such as work requirements. One of the greatest benefits to this policy perspective is social solidarity, since everyone contributes collaboratively to a system that everyone also benefits from. Social security is one such example. Moreover, economists have argued that universalism is an investment in human capital that aids the development of a nation as a whole. The World Bank's 2019 World Development Report \"The Changing Nature of Work\" considers social protection from this perspective, describing existing schemes around the world and presenting simulation data on the potential costs.\nOpponents would argue that universalism is cost-ineffective and unfairly distorts individual efforts. Such an argument points toward targeting as a better solution. In such a case, the question arises of who should be the target population that receives benefits from social programs.\n\nNet income is the simplest method of determining a needy population. Some states use a Guaranteed Minimum Income system, in which all members of a state receive sufficient income to live on, so long as they meet certain conditions. However, proponents of the capabilities approach argue that income is easier to misrepresent, and moreover, fails to target the root causal factors of poverty. Hence, they recommend targeting a minimum level of basic capabilities that will impact quality of life, such as institutional improvements like health and education. Policy examples might include a social floor.\n\nSocial protection is an expensive and difficult endeavor, by any means; the question remains how best to implement programs that effectively aid the people who need it the most. Currently, there are a number of mechanisms that provide social protection in various nations. These policies and instruments vary according to country context. In some nations, governments are strongly involved in the provision of social protection, following a developmentalism model, in which social protection is seen as a tool to promote economic growth. There are also nations which are characterized by dualism, in which there is state-provided protection for those who work in the formal sector, but little to no protection for those who work in the informal sector. Finally, there are nations in which the economy is largely agrarian, and a great majority of the population works in the informal economy. In those countries that have only residual social protection coverage and weak state capacity,social protection is mainly provided by non-governmental means such as kin, NGOs, and individual philanthropic donations.\n\nIn South Korea and Taiwan, the government provides extensive support for public programs, following the developmentalism model, in which social protection is seen as a tool to promote economic growth.\n\nIn Argentina, Brazil, and South Africa, there is a dualist structure of protected formal sector workers and marginalized informal sector workers.,\n\nIn nations such as India and Tanzania, governments struggle to provide adequate social protection, and citizens must instead depend on non-state actors and informal provisioning.\n\nInternational donors and organizations have influenced social protection approaches both at the level of policy discourse and program design and implementation. Even though The World Bank and International Labour Organization (ILO) are the major donors and the lead organizations in the field, other organizations are also concerned with social protection.\n\nThe World Bank is a source of financial and technical assistance for developing countries. In order to identify social risks and potential responses, The World Bank developed a tool called “Social Risk Management” (SRM). The SRM framework includes interventions that focus on managing risks before shocks occur. It is based on two assessments: (1) the poor are most exposed to diverse risks, and (2) the poor have the fewest tools to deal with these risks. The main elements of the SRM framework are:\n\nThe Organisation for Economic Co-operation and Development (OECD) brings 30 democratic countries together to seek answers to common problems and coordinate domestic and international policies. The Development Assistance Committee (DAC) of the OECD is responsible for the Poverty Network (POVNET) that has become very influential on policy development. The DAC-POVNET focuses on the following areas:\n\nThe International Labour Organization, which covers both issues of social security and labor protection, has been the United Nations agency responsible for setting norms and standards at work. Currently the ILO focuses, amongst others, on the following strategies: \n\n\nsocialprotection.org\n"}
{"id": "1092175", "url": "https://en.wikipedia.org/wiki?curid=1092175", "title": "Subjective character of experience", "text": "Subjective character of experience\n\nThe subjective character of experience is a term in psychology and the philosophy of mind denoting that all subjective phenomena are associated with a single point of view (\"ego\"). The term was coined and illuminated by Thomas Nagel in his famous paper \"What Is it Like to Be a Bat?\"\n\nNagel argues that, because bats are apparently conscious mammals with a way of perceiving their environment entirely different from that of human beings, it is impossible to speak of \"what is it like to \"be\" a bat \"for\" the bat\" or, while the example of the bat is particularly illustrative, any conscious species, as each organism has a unique point of view from which no other organism can gather experience. To Nagel, the subjective character of experience implies the cognitive closure of the human mind to some facts, specifically the mental states that physical states create.\n\nSubjective character of experience implies that the perception of all things, concepts, and \"truths\" in the universe differs between individuals: we all live in different worlds, each of which may have things in common, because of our unique perspectives on our worlds. The only thing to which one can hold oneself is something one has experienced or perceived. Until someone has had an experience of something the object or concept within itself is not \"real.\" Someone in Africa is aware of the existence of fire and sees it but for an Inuit who has never seen fire before the fire does not exist in the same way. The idea of the subjectivity of one's \"reality\" also hints at an aspect of moral relativism, that each person's opinions are the only things they can hold themselves to.\n\nA dual-subjective reality arises when an individual's mind interprets information and, instead of creating only one interpretation that the conscious mind can make sense of, creates several. These differing \"realities\" then cause conflict in that individual who may confuse what is actually happening around them with alternative realities formulated in their mind.\n\n\n"}
{"id": "1225101", "url": "https://en.wikipedia.org/wiki?curid=1225101", "title": "Task analysis", "text": "Task analysis\n\nTask analysis is the analysis of how a task is accomplished, including a detailed description of both manual and mental activities, task and element durations, task frequency, task allocation, task complexity, environmental conditions, necessary clothing and equipment, and any other unique factors involved in or required for one or more people to perform a given task. \n\nInformation from a task analysis can then be used for many purposes, such as personnel selection and training, tool or equipment design, procedure design (e.g., design of checklists, or decision support systems) and automation. Though distinct, task analysis is related to user analysis.\n\nThe term \"task\" is often used interchangeably with activity or process. Task analysis often results in a hierarchical representation of what steps it takes to perform a task for which there is a goal and for which there is some lowest-level \"action\" or interaction among humans and/or machines: this is known as hierarchical task analysis. Tasks may be identified and defined at multiple levels of abstraction as required to support the purpose of the analysis. A critical task analysis, for example, is an analysis of human performance requirements which, if not accomplished in accordance with system requirements, will likely have adverse effects on cost, system reliability, efficiency, effectiveness, or safety. Task analysis is often performed by human factors and ergonomics professionals.\n\nTask analysis may be of manual tasks, such as bricklaying, and be analyzed as time and motion studies using concepts from industrial engineering. Cognitive task analysis is applied to modern work environments such as supervisory control where little physical work occurs, but the tasks are more related to situation assessment, decision making, and response planning and execution.\n\nTask analysis is also used in education. It is a model that is applied to classroom tasks to discover which curriculum components are well matched to the capabilities of students with learning disabilities and which task modification might be necessary. It discovers which tasks a person hasn't mastered, and the information processing demands of tasks that are easy or problematic. In behavior modification, it is a breakdown of a complex behavioral sequence into steps. This often serves as the basis for chaining.\n\nThe results of task analysis are often represented in task models, which clearly indicate the relations among the various tasks, An example notation used to specify task models is ConcurTaskTrees (by Fabio Paternò), which is also supported by tools that are freely available.\n\nIf task analysis is likened to a set of instructions on how to navigate from Point A to Point B, then Work domain analysis (WDA) is like having a map of the terrain that includes Point A and Point B. WDA is broader and focuses on the environmental constraints and opportunities for behavior, as in Gibsonian ecological psychology and ecological interface design (Vicente, 1999; Bennett & Flach, 2011, p. 61)\n\nSince the 1980s, a major change in technical documentation has been to emphasize the tasks performed with a system rather than documenting the system itself. In software documentation particularly, long printed technical manuals that exhaustively describe every function of the software are being replaced by online help organized into tasks. This is part of the new emphasis on usability and user-centered design rather than system/software/product design.\n\nThis task orientation in technical documentation began with publishing guidelines issued by IBM in the late 1980s. Later IBM studies led to John Carroll's theory of minimalism in the 1990s.\n\nWith the development of XML as a markup language suitable for both print and online documentation (replacing SGML with its focus on print), IBM developed the Darwin Information Typing Architecture XML standard in 2000. Now an OASIS standard, DITA has a strong emphasis on task analysis. Its three basic information types are Task, Concept, and Reference. Tasks are analyzed into steps, with a main goal of identifying steps that are reusable in multiple tasks.\n\nHierarchical task analysis (HTA) is a task description method and a variant of task analysis. Task description is a necessary precursor for other analysis techniques, including critical path analysis (CPA). HTA is used to produce an exhaustive description of tasks in a hierarchical structure of goals, sub-goals, operations and plans. In HTA, tasks are broken down into progressively smaller units.\n\nOperations are the actions performed by people interacting with a system or by the system itself, and plans explain the conditions necessary for these operations. Operations describe the smallest individual task steps in the HTA, i.e. those which cannot be broken down into plans and further operations. They are the individual actions, such as 'visually locate control' or 'move hand to control', which the user must perform in a particular combination to achieve the goal of task completion.\n\nThe following steps should be followed when conducting a HTA:\n\nEach level in the HTA should be numbered according to its hierarchical level: The overall goal is the highest hierarchical level and should be numbered 0. The first sub-goal in the hierarchy will be 1, also with plan 1. Further levels just extend this system - third hierarchical level: 1.1, fourth hierarchical level: 1.1.1, and so on. A HTA can be represented in list or diagram form. In list form lines should be indented to denote the different hierarchical levels. In diagram form each operation should be placed within a box and links should be made between them: a lower hierarchical level should branch from underneath a higher level operation. Plans should be written next to the branches to describe the way in which the branched operations should be carried out.\n\nHTA is a task description method which is most commonly used as a starting point for further analyses such as multimodal CPA and SHERPA. On its own, HTA does not provide results for usability evaluation; however, you should be able to study the HTA in order to learn about the structure of different tasks. It may also allow you to highlight unnecessary task steps or potential errors that might occur in task performance. HTA is a fairly time-consuming method to carry out as each individual operation in a task needs to be analysed; however, creating a comprehensive HTA can considerably reduce the time required for other modelling methods.\n\n\nVicente, K. J. (1999). Cognitive work analysis: Toward safe, productive, and healthy computer-based work. LEA.\n\nBennett, K. B., & Flach, J. M. (2011). Display and interface design: Subtle science, exact art. CRC Press.\n\n"}
{"id": "27596734", "url": "https://en.wikipedia.org/wiki?curid=27596734", "title": "Tata-tonga", "text": "Tata-tonga\n\nTata-tonga (, Mongolian script: , \"\", ) was a Yugur man involved in bringing and adapting the Old Uyghur alphabet to Mongolia in what is called the traditional Mongolian alphabet (Mongol bichig or hurdum bichig). He was captured by Genghis Khan in the 13th century and soon taught the Old Uyghur alphabet to members of the court and adapted it, to match the Mongol Khalkha language, although Genghis (or Chingis) himself never learned it.\n\nThe Uyghur script was used in Mongolia until its independence from Qing dynasty China, at the beginning of the 20th century and few years before Russia introduced Cyrillic. It is still used mainly in Inner-Mongolia. In current day Mongolia, Cyrillic is the official script for the Mongolian language, and the traditional script is referred to as the \"Old Mongol script\" (). Today, an estimated 6 million Mongolians from China can still read the traditional Mongolian script but only 3 million from Mongolia.\n\nThe Manchu alphabet was derived since the very end of the 16th century from this Mongolian script.\n\n"}
{"id": "40956728", "url": "https://en.wikipedia.org/wiki?curid=40956728", "title": "Temporal Raster Plot", "text": "Temporal Raster Plot\n\nA Temporal Raster Plot is a graphic representation of occurrences in a certain temporal relation. Temporal Raster Plots are also sometimes referred to as carpet plots.\n\nEach occurrence is registered in a Cartesian coordinate system, in which both axes show time, have different time resolutions: one axis shows slices of data, the other some sensible interval. A common example would be that one axis shows hours in a day, the other days in a year.\n\nIn a 2D plot, the value to be plotted is coded with an intensity or a color. In the 3D variant of the plot, it is often coded as a height. When visualized, particularly the color-coded variant of the plot may easily show a carpet-like pattern.\n\nTemporal Raster Plots make it easy to show time-based relations within a large sets of time-interval data and often make it easy to recognize local maxima and minima. Assuming the chosen time division is related to the events, it is also easy to recognize global and local patterns, such as recurrent events.\n\nIn the following example, the data is one year's worth of measurements of the outdoor temperatures in Augsburg, with four samples taken per hour. In the according carpet diagram, each column represents a day in the year and contains the values for that day (from 0:00 until 23:45).\nDespite the high number of measure points (about 35000) it is easy to distinguish local and global patterns.\n\n"}
{"id": "16952283", "url": "https://en.wikipedia.org/wiki?curid=16952283", "title": "Umbrella effect (ecology)", "text": "Umbrella effect (ecology)\n\nAn umbrella effect is the protection extended by the presence of an umbrella species to other species in the same habitat. \n\nThe umbrella species is often either a flagship species whose conservation benefits other species or a keystone species which may be targeted for conservation due to its impact on an ecosystem. \nMore generally, an umbrella species determines the area over which conservation occurs. \nThey are often representative of other species in their habitat, being an easily observable and known species.\n\nA good example of an umbrella species and its impact is summed up by Kimberly Andrews, a University of Georgia doctoral student at the Savannah River Ecology Laboratory:\n\"Protecting a species like the canebrake has practical applications, as protection measures would have broad environmental value because of an umbrella effect. That is, protecting the rattlesnakes would ensure protection of other wildlife species that use the same habitats but are less sensitive to development or require fewer resources.\"\n\nThe concept of an umbrella species is further utilized to create wildlife corridors with what are termed focal species. These focal species are chosen for a number of reasons and fall into several types, generally measured by their potential for an umbrella effect. By carefully choosing species based on this criterion, a linked or networked habitat can be created from single-species corridors. These criteria are determined with the assistance of geographic information systems on the larger scale. Regardless of the location or scale of conservation, the umbrella effect is a measurement of a species' impact on others and is an important part of determining an approach.\n\n\n"}
{"id": "27558974", "url": "https://en.wikipedia.org/wiki?curid=27558974", "title": "Underwater camouflage", "text": "Underwater camouflage\n\nUnderwater camouflage is the set of methods of achieving crypsis—avoidance of observation—that allows otherwise visible aquatic organisms to remain unnoticed by other organisms such as predators or prey.\n\nCamouflage in large bodies of water differs markedly from camouflage on land. The environment is essentially the same on all sides. Light always falls from above, and there is generally no variable background to compare with trees and bushes. Three main camouflage methods predominate in water: transparency, reflection, and counter-illumination. Transparency and reflectivity are most important in the top 100 metres of the ocean; counter-illumination is the main method from 100 metres down to 1000 metres; while camouflage becomes less important in the dark waters below 1000 metres.\n\nCamouflage in relatively shallow waters is more like terrestrial camouflage, where additional methods are used by many animals. For example, self-decoration is employed by decorator crabs; mimesis by animals such as the leafy sea dragon; countershading by many fish including sharks; distraction with eyespots by many fish; active camouflage through ability to change colour rapidly in fish such as the flounder, and cephalopods including octopus, cuttlefish, and squid.\n\nThe ability to camouflage oneself provides a survival advantage in the constant struggle between predators and prey. Natural selection has produced a wide variety of methods of survival in the oceans.\n\nIn Ancient Greece, Aristotle commented on the color-changing abilities, both for camouflage and for signalling, of cephalopods including the octopus, in his \"Historia animalium\":\n\nThree main camouflage methods predominate in the oceans: transparency, reflection, and counterillumination. Transparency and reflectivity are most important in the top 100 metres of the ocean; counterillumination is the main method from 100 metres down to 1000 metres; while camouflage becomes less important in the dark waters below 1000 metres. Most animals of the open sea use at least one of these methods to camouflage themselves. Camouflage in relatively shallow waters is more like terrestrial camouflage, where additional methods are used by animals in many different groups. These methods of camouflage are described in turn below.\n\nTransparency is common, even dominant, in animals of the open sea, especially those that live in relatively shallow waters. It is found in plankton of many species, as well as larger animals such as jellyfish, salps (floating tunicates), and comb jellies.\nMany marine animals that float near the surface are highly transparent, giving them almost perfect camouflage. However, transparency is difficult for bodies made of materials that have different refractive indices from seawater. Some marine animals such as jellyfish have gelatinous bodies, composed mainly of water; their thick mesogloea is acellular and highly transparent. This conveniently makes them buoyant, but it also makes them large for their muscle mass, so they cannot swim fast. Gelatinous planktonic animals are between 50 and 90 per cent transparent. A transparency of 50 per cent is enough to make an animal invisible to a predator such as cod at a depth of ; better transparency is required for invisibility in shallower water, where the light is brighter and predators can see better. For example, a cod can see prey that are 98 per cent transparent in optimal lighting in shallow water. Therefore, transparency is most effective in deeper waters.\n\nSome tissues such as muscles can be made transparent, provided either they are very thin or organised as regular layers or fibrils that are small compared to the wavelength of visible light. Familiar examples of transparent body parts are the lens and cornea of the vertebrate eye. The lens is made of the protein crystallin; the cornea is made of the protein collagen. Other structures cannot be made transparent, notably the retinas or equivalent light-absorbing structures of eyes — they must absorb light to be able to function. The camera-type eye of vertebrates and cephalopods must be completely opaque. Finally, some structures are visible for a reason, such as to lure prey. For example, the nematocysts (stinging cells) of the transparent siphonophore \"Agalma okenii\" resemble small copepods. Examples of transparent marine animals include a wide variety of larvae, including coelenterates, siphonophores, salps, gastropod molluscs, polychaete worms, many shrimplike crustaceans, and fish; whereas the adults of most of these are opaque and pigmented, resembling the seabed or shores where they live. Adult comb jellies and jellyfish are mainly transparent, like their watery background. The small Amazon river fish \"Microphilypnus amazonicus\" and the shrimps it associates with, \"Pseudopalaemon gouldingi\", are so transparent as to be \"almost invisible\"; further, these species appear to select whether to be transparent or more conventionally mottled (disruptively patterned) according to the local background in the environment.\n\nMany fish are covered with highly reflective scales, giving the appearance of silvered mirror glass. Reflection through silvering is widespread or dominant in fish of the open sea, especially those that live in the top 100 metres. Where transparency cannot be achieved, it can be imitated effectively by silvering to make an animal's body highly reflective. At medium depths at sea, light comes from above, so a mirror oriented vertically makes animals such as fish invisible from the side. Most fish in the upper ocean such as sardine and herring are camouflaged by silvering.\n\nThe marine hatchetfish is extremely flattened laterally (side to side), leaving the body just millimetres thick, and the body is so silvery as to resemble aluminium foil. The mirrors consist of microscopic structures similar to those used to provide structural coloration: stacks of between 5 and 10 crystals of guanine spaced about ¼ of a wavelength apart to interfere constructively and achieve nearly 100 per cent reflection. In the deep waters that the hatchetfish lives in, only blue light with a wavelength of 500 nanometres percolates down and needs to be reflected, so mirrors 125 nanometres apart provide good camouflage.\n\nIn fish such as the herring which live in shallower water, the mirrors must reflect a mixture of wavelengths, and the fish accordingly has crystal stacks with a range of different spacings. A further complication for fish with bodies that are rounded in cross-section is that the mirrors would be ineffective if laid flat on the skin, as they would fail to reflect horizontally. The overall mirror effect is achieved with many small reflectors, all oriented vertically. Silvering is found in other marine animals as well as fish. The cephalopods, including squid, octopus and cuttlefish, have multi-layer mirrors made of protein rather than guanine.\n\nCounter-illumination through bioluminescence on the underside (ventral region) of the body is found in many species that live in the open ocean down to about 1000 metres. The generated light increases an animal's brightness when seen from below to match the brightness of the ocean surface; it is an effective form of active camouflage. It is notably used by some species of squid, such as the midwater squid, \"Abralia veranyi\". These have light-producing organs (photophores) scattered all over their undersides, creating a sparkling glow that prevents the animal from appearing as a dark shape when seen from below. Counter-illumination camouflage is the likely function of the bioluminescence of many marine organisms, though light is also produced to attract or to detect prey and for signalling.\n\nTop/bottom countershading is common in fish including sharks, marlin, and mackerel, and animals in other groups such as dolphins, turtles and penguins. These animals have dark upper sides to match the ocean depths, and light undersides to avoid appearing dark against the bright sea surface.\n\nMimesis is practised by animals such as the leafy sea dragon, \"Phycodurus eques\", and the leaf scorpionfish, \"Taenianotus triacanthus\", which resemble parts of plants, and gently rock their bodies as if swayed by a current. In the fish species \"Novaculichthys taeniourus\", the rockmover or dragon wrasse, there is a striking difference in appearance between the adults and the juveniles. A juvenile Rockmover resembles a loose piece of sea weed. It swims in a vertical position with its head pointing downwards, and behaves in a way that perfectly resembles the movement of a piece of seaweed: moving back and forth in the surge, as if it was inanimate.\n\nSelf-decoration is employed by animals in different groups, including decorator crabs, which attach materials from their environment, as well as living organisms, to camouflage themselves. For example, the Japanese hermit crab, \"Eupagurus constans\", has the hydroid \"Hydractinia sodalis\" growing all over the shell that it lives in. Another hermit crab, \"Eupagurus cuanensis\", has the aposematic orange sponge \"Suberites domuncula\" which is bitter-tasting and not eaten by fish.\n\nSimilarly, sea urchins use their tube feet to pick up debris from the bottom and attach it to their upper surfaces. They use shells, rocks, algae and sometimes sea anemones.\n\nMany fish have eyespots near their tails, a form of automimicry, to distract attacks away from the vulnerable head and eye. For example, \"Chaetodon capistratus\" has both a (disruptive) eyestripe to conceal the eye, and a large eyespot near its tail, giving the impression that the head is at the tail end of the body.\n\nFish such as \"Dascyllus aruanus\" have bold disruptive patterns on their sides, breaking up their outlines with strong contrasts. Fish like \"Heniochus macrolepidotus\" have similar bands of colour that extend into fins projecting far from the body, distracting attention from the true shape of the fish.\n\nSome fish which mimic seaweeds such as the frogfishes \"Antennarius marmoratus\" and \"Pterophryne tumida\" have elaborate projections and spines which are combined with complex disruptive coloration. These have the effect of destroying the signature \"fish\" outline of these animals, as well as helping them to appear as pieces of algae.\n\nA variety of marine animals possess active camouflage through their ability to change colour rapidly. Several bottom-living fish such as the flounder can hide themselves effectively against a variety of backgrounds. Many cephalopods including octopus, cuttlefish, and squid similarly use colour change, in their case both for camouflage and signalling. For example, the big blue octopus, \"Octopus cyanea\", hunts during the day, and can match itself to the colours and textures of its surroundings, both to avoid predators and to enable it to approach prey. It can perfectly resemble a rock or a coral it is hiding beside. When necessary, in order to scare away a potential predator, it can display markings which resemble eyes.\n\nLike all flounders, Peacock flounders, \"Bothus mancus\", have excellent adaptive camouflage. They use cryptic coloration to avoid being detected by both prey and predators. Whenever possible rather than swim, they crawl on their fins along the bottom while constantly changing colours and patterns to match their background. In a study, some flounders demonstrated the ability to change pattern in eight seconds. They were able to match the pattern of checkerboards that they were placed on. Changing pattern is an extremely complex process involving the flounder's vision and hormones. If one of the fish's eyes is damaged, or covered by the sand, the flounder has difficulties in matching its pattern to its surroundings. Whenever the fish is hunting or hiding from predators, it buries itself into the sand, leaving only the eyes protruding.\n\n\n"}
{"id": "1448442", "url": "https://en.wikipedia.org/wiki?curid=1448442", "title": "Universal manhood suffrage", "text": "Universal manhood suffrage\n\nUniversal manhood suffrage is a form of voting rights in which all adult males within a political system are allowed to vote, regardless of income, property, religion, race, or any other qualification. It is sometimes summarized by the slogan, \"one man, one vote.\"\n\nIn 1789, Revolutionary France adopted the Declaration of the Rights of Man and of the Citizen and, although short-lived, the National Convention was elected by all men in 1792. It was revoked by the Directory in 1795. Universal male suffrage was re-established in France in the wake of the French Revolution of 1848.\n\nIn the United States, the rise of Jacksonian democracy from the 1820s to 1850s led to a close approximation of universal manhood suffrage among whites being adopted in all states by 1856. Poorer white male citizens gained representation; however, tax-paying requirements remained in five states until 1860 and in two states until the 20th century. The expansion of suffrage was largely peaceful, excepting the Rhode Island Dorr Rebellion. Most African-American males remained excluded; though the Fifteenth Amendment to the United States Constitution, ratified in 1870, upheld their voting rights, they were denied the right to vote in many places for another century until the Civil Rights Movement gained passage of the Voting Rights Act of 1965 through Congress.\n\nAs women also began to win the right to vote during the late 19th and early 20th centuries, the goal of universal manhood suffrage was replaced by universal suffrage.\n\n"}
{"id": "14836066", "url": "https://en.wikipedia.org/wiki?curid=14836066", "title": "You (Time Person of the Year)", "text": "You (Time Person of the Year)\n\n\"You\" were chosen in 2006 as \"Time\" magazine's Person of the Year. The magazine set out to recognize the millions of people who anonymously contribute user-generated content to wikis and other websites such as Wikipedia, YouTube, MySpace, Facebook, and the multitudes of other websites featuring user contribution.\n\nWhile the status had been given before to inanimate objects, with the personal computer being the \"Machine of the Year\" for 1982, as well as collections of people or an abstract representative of a movement, the choice of \"You\" attracted criticism from commentators in publications such as \"The Atlantic\" for being too much of a pop culture gimmick. A \"New York Daily News\" article named the 2006 award as one of the ten most controversial \"Person of the Year\" moments in the history of \"Time\". However, the news-magazine experienced generally successful sales.\n\nWhile most earlier choices for \"Person of the Year\" have been historically important individuals, many of them infamous rather than internationally popular (Adolf Hitler was 1938's \"Man of the Year\", and Ayatollah Khomeini won in 1979), a few were inanimate. The personal computer was the \"Machine of the Year\" for 1982, while the \"Endangered Earth\" was the \"Planet of the Year\" for 1988. Collections of people as well as a symbolic representative of multiple individuals had also won the award before; for example, \"U.S. Scientists\" were named \"Men of the Year\" in 1960.\n\nSimilar media awards had already recognized the growing significance of online community and user-generated content: \"You!\" were ranked first in \"Business 2.0\" list of \"50 people who matter now\" in July 2006; while ABC News had listed bloggers as \"People of the Year\" for 2006.\n\nIn accordance with \"Time\" annual process, different bureaus suggested different candidates. \"You\", or \"the YouTube guys\", was floated in November as a possible winner. Readers' opinions were canvassed online. The final decision was made by managing editor Richard Stengel.\n\nThe decision was announced in \"Time\" December 13, 2006 issue. The cover of the magazine featured an iMac computer monitor with a reflective mylar pane appearing as the window of a YouTube-like video player, intended to reflect as online content the visage of whoever picks up the magazine.\nThe time remaining indicator in the image indicates a total duration of \"20:06,\" a visual pun connecting this ubiquitous bit of interface design to the year in which it gained ascendancy in \"Time\" view. Stories on the new user-driven media dynamic were provided by NBC editor Brian Williams and \"Time\" magazine editors Lev Grossman and Richard Stengel. As Grossman describes, \"It's about the many wrestling power from the few and helping one another for nothing and how that will not only change the world, but also change the way the world changes.\"\n\nThe choice was criticized for being a short-sighted gimmick which ignored the existence of many prominent individuals that had shaped the events of the past year. Pundit Paul Kedrosky called it an \"incredible cop-out\", and he also speculated that the selection marked \"some sort of near-term market top for user-generated content\". Commentator Kevin Friedl noted that the award and cover design recalled the mirror viewed by the protagonist, the Dude, of \"The Big Lebowski\", via which the viewer's reflection was framed as \"Time\" \"Man of the Year\".\n\nIn December 2012, journalist David A. Graham wrote for \"The Atlantic\" that he thought \"Time\" had shown \"a pattern of lackluster choices\" and the overall promotional nature of the process shouldn't be treated as news, rather simply viewed as marketing. He remarked, \"Is anyone out there \"not\" sick of people ironically listing 'Time Person of the Year, 2006' in Twitter bios, a reference to the gimmicky selection of 'You' that year?\"\n\nAdditionally, the decision raised some criticism as it was described as ideological and even hypocritically political. Some weeks before the announcement, \"Time\" decided to ask the users in a poll, \"Who Should Be Person of the Year?\" After several weeks, the poll winner by a wide margin was Hugo Chávez, the leader of Venezuela, with 35% of the votes. The president of Iran, Mahmoud Ahmadinejad, came in second. \"Time\" decided to ignore those results and did not mention them in the announcement of their \"Person of the Year\". Its critics underlined that \"Time\" ignores its digital democracy among its readers. \"Time\" supporters argue that an online poll is not representative as it has no scientific value. The hyperlink to the online poll results has been removed. A 2014 \"New York Daily News\" article, which named the \"You\" naming as one of the ten most controversial \"Person of the Year\" moments in the history of \"Time\", also remarked that \"2006 had its fair share of newsmakers\" while highlighting both \"Venezuela President Hugo Chavez and Iranian President Mahmoud Ahmadinejad\".\n\n"}
